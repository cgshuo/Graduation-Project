 Alex G. Hauptmann ALEX @ CS . CMU . EDU Conditional exponential model has been one of the popular conditional models in machine-learning field and has been successfully a pplied to many different machine-learning problems, such as automatic speech recognition (Rosenfeld, 1996), text classification (Nigam, Lafferty &amp; McCallum, 1999), text segmentation (Beefman, Berger &amp; Lafferty, 1997 &amp; 1999), name identity extraction (Borthwick et. al, 1998) and part-of-speech (POS) taggi ng (Ratnaparkhi, 1996). One advantage of the conditional exponential model versus the other models is that it is able to combine many correlated input evidences for predicting the class labels without requiring input features to be independent from each other. Furthermore, by assigning high weights to the relevant features and low weights to those irrelevant ones, the conditional exponential model can be quite resilient to the introduction of irrelevant features. Another interesting aspect of the conditional exponential model is that it is strongly associated with Maximum Entropy (ME) model (Jelinek, 1997; Berger, Pietra &amp; Pietra, 1996). More precisely, it has been shown that the conditional exponential model is actually a dual problem of ME model and therefore has the unique global maximum. To find the optimal conditional exponential model for given training data, two groups of approaches have been used in the past research. One is named iterative scaling approach (Brown, 1959), including the Generalized Iterative Scali ng (GIS) (Darroch &amp; Ratcli, 1972) and the Improved Iterative Scaling (IIS) (Berger, 1997). The underlying idea for iterative scaling approaches is similar to the idea of Expectation-Maximization (EM) approach: by approximating the log-likelihood function of the conditional exponential model as some kind of  X  X imple X  auxiliary function, the iterative scaling methods are able to decouple the correlation between the parameters and the search for the maximum point can be operated along many directions simultaneously. By carrying out this procedure iteratively, the approximated optimal point found over the  X  X implified X  function is guaranteed to converge to the true optimal point due to the convexity of the objective function. The distinction between GIS and IIS is that the GIS method requires the sum of input features to be a constant ov er all the examples while the IIS method doesn X  X . This constraints can limits the application of GIS, particularly when the sum of features is not bounded. Furthermore, in the previous studies, people have found that the IIS method is able to find the optimal parameters for the conditional exponential model significantly faster than the GIS method, particularly for the applications of natural language processing. Therefore, we will only consider the IIS method as the comparison peer for the proposed method. The second group of approaches are mainly the generic approaches for non linear optimization, including the conjugate gradient approach (CG) (Shewchuk, 1994) and the quasi-Newton method (Liu &amp; Norcedal, 1989). Previous studies have shown that both the conjugate gradient and the quasi-Newton method are able to find the optimal parameters for the conditional exponential model much faster than the iterative scaling methods (Minka, 2001;Malbouf, 2002). One advantage of the conjugate gradient approach versus the quasi-Newton approach is that the quasi-Newton method requires the explicit computation of the approximate Hessian matrix while the conjugate gradient approach does not. Since the number of elements within a Hessian matrix is equal to the square of the number of parameters for the problem, the storage of a Hessian matrix can be extremely expensive if the problem involves hundreds of thousands of parameters. Therefore, in the paper, we will only include the conjugate gradient approach for the comparison. In this paper, we propose a new iterative scaling method, which shares the similar idea with the previous iterative scaling methods, namely for each iteration, approximating the original log-likelihood function with a lower bound auxiliary function and find the optimal point over the auxiliary function as the approximation to the global optimal solution for the original log-likelihood function. The only difference between this work and previous work on iterative scaling methods is that, this work provides a better approximate auxiliary function that is able to bounds the original log-likelihood function tighter. Therefore, we would expect this new iterative scaling method is able to converge to the global optimium faster than the previous iterative scaling methods. Empirical studies on the text classification over three different collections have shown that the new iterative scaling method is able to achieve significantly faster convergence rate than IIS method. Furthermore, we compared the proposed iterative scaling method to CG method over the same testbed and found that the new algorithm also runs faster than the CG method over all three collections. The rest of the paper is arranged as follows: The formal description and analysis of the new iterative scaling method will be presented in Section 2. The empirical studies on the effectiveness of the new iterative algorithm are presented in Section 3. Within it, we will examine the convergence ra te of the new algorithm with respect to IIS method and CG method, respectively. Conclusion and future works will be presented in Section 4. As already mentioned in the introduction section, the basic idea of the IIS algorithm is to approximate the log-likelihood function with a lower bound auxiliary function and compute the optimal point over the auxiliary function as the approximation of the global optimal solution for the true log-likelihood function. Therefore, a lower bound auxiliary function that is able to bound the log-likelihood function tighter than the IIS method will lead to a faster convergence rate. In order to propose a better lower bound auxiliary function, we first examine how the IIS algorithm bounds the log-likelihood function in Section 2.1 and then a better auxiliary function is proposed in Section 2.2. For the sake of simplicity, throughout the rest of this paper, we assume that all th e features are nonnegative. 2.1 Overview of Improved Iterative Scaling (IIS) The key component for a conditional model is to compute the p ( y | x ), namely the likelihood for an instance to have a class label y given the input x . For a conditional exponential model, p ( y | x ) is usually written as: where f i ( x , y ) stands for the i th feature extracted from the input x and the output y , and  X  i stands for the corresponding weight. Symbol Z ( x ) is the normalization constant, which enforces the sum of p ( y | x ) over different class labels y to be one, i.e. For the purpose of simplicity, let X  X  assume that every class uses the same set of features { f i ( x )}. Under that assumption, the general form (1) can be rewritten as As seen from Equation (1 X ), the weight  X  y,i has two index. The goal of the training proced ure is to find the set of weights {  X  y,i } that maximizes the log-likelihood of the training data. Given the empirical data distribution ~ y x p obtained from the training examples, the log-likelihood will be written as: where ) ( ~ x p stands for the empirical data distribution for input x . Since directly optimizing Equation (2) can be difficult, people take the iterative approach, namely dividing the procedure of maximization into many steps and each iteration will only increase the log-likelihood slightly from the previous iteration. Let  X  y,i stands for change in the weight  X  y,i between two consecutive iterations. Then, the difference in the log-likelihood L for two consecutive iterations will be expressed as the function of  X  y,i , which is As seen from Equation (3), the complexity in maximizing  X  L comes from the second term where the set of parameters {  X  y,i } are coupled with each other through the exponential function and the logarithm function. The IIS method uses the inequality parameters {  X  y,i } due to the logarithm function and p ( x ), to decouple the correlation caused by the exponential function. With these two inequalities, the resulted lower bound auxiliary function for  X  written as: where symbol # f stands for the sum of all the features, i.e.  X  i i x f ) ( . With the inequality (4), instead of optimizing the true log-likelihood function  X  L , we can maximize the auxiliary function Q IIS . Since the auxiliary function Q IIS has all the interaction between variables {  X  y,i } removed, we can simply optimize it with respect to each variable  X  y,i independently from other variables. Furthermore, since Q IIS low bounds the difference in log-likelihood function  X  L , by maximizing Q IIS , we can make sure  X  L to be at least non-negative, which means that the log-likelihood function will never decrease in the iterative procedure. One of the usual procedure used for optimizing Q the univariate Newton method. 2.2 A New Low Bound Auxiliary Function The lower bound auxiliary function Q IIS for the IIS method in Equation (4) can be rewritten as a sum of a set of functions { g y,i } and each function g depends on a single variable  X  y,I , i.e., Therefore, the correlation between variables {  X  y,i been completely decoupled in the IIS method. However, the price paid for the full decoupling is that, the auxiliary function may not be able to bound the original log-likelihood function tightly enough. In in the IIS method. As a result, many iterations are required in order to reach the true optimal solution. Clearly, there is a tradeoff between the complexity of auxiliary function and number of iteration. On one hand, by bounding the log-likelihood function with a simple auxiliary function, we are able to obtain the optimal solution over the auxiliary function quickly however we may have to run through the iterative procedure many times. On the other hand, a complicated auxiliary function may be able to bound the log-likelihood function more tightly however computing the optimal solution of the complicated bounding function may be expensive. The basic idea of improving the IIS algorithm is to introduce an auxiliary function, which only decouples part of the interaction between parameters. Unlike the IIS method, where Q IIS consists of functions only with a single variable, the new auxiliary function will be the sum of functions { g i } related to multiple variables. By keeping some of the interaction between variable alive in the approximation, we are able to achieve an auxiliary function that bounds the original log-likelihood function more tightly than the IIS algorithm. Meanwhile, only a small number of variables are related to each g i in the auxiliary function. Therefore the optimization of each function g i can still be solved efficiently by using traditional numerical methods such as the method of multivariate Newton. The most critical component in the derivation of the proposed auxiliary function is so called  X  X older Sum Inequality X  (Abramowitz &amp; Stegun, 1972). In this subsection, we will give a brief introduction of this inequality and its extension. The original version of Holder Inequality can be stated as follows: For a set of non-negative variables { a k } k=1 n and { b the following inequality will always hold Inequality is a special case of this inequality when both p and q are set to be 2. Furthermore, the Holder Inequality can be extended to a more general form. Considering the function form is not difficult to show that the following inequality will always hold, i.e. for any set of { q k }, as long as all the q k are positive and satisfies the constraint 1 1 =  X   X  k k q . A proof of the extension of Holder Inequality is provided in the Appendix. To understand why inequality in (6) is useful in building up auxiliary function, we can simply take the logarithm of the both sides of the inequality, i.e. On the LHS of the above inequality, we have all the variables k i ,  X  couple due to the existence of product and the logarithm function. However, on the RHS of this inequality, we only have k i ,  X  with same index k interacted with each other and all the other couplings between variables { k i ,  X  } are removed from the object function. Therefore, by applying inequality (6), we are able to delete part of the interaction between variables so that the original optimization problem is simplified. Now consider how to apply the extension of Holder Inequality to find a better lower bound auxiliary function for the log-likelihood function in (3). Notice that, the most complicated term within (3) is term algorithm, let ) ( # x f stands for the sum of all the log-likelihood function can be rewritten as: Then, according to the extension of Holder Inequality, we have an upper bound for the log-likelihood function as: By setting ) ( / ) ( # x f x f q i i = , we have Equation (7) simplified as: By substituting Equation (7 X ) for the term will have the following inequality According to Equation (8), the auxiliary function Q FIS is a sum of a set of functions g i and each g i only involved in variables  X  y,i with same feature index i . In general, the number of features is substantially larger than the number of classes. Therefore, the lower bound auxiliary function in (8) is able to remove most of the correlation between variables and only the interaction between variables  X  y,i with the same feature index i are kept. Furthermore, it is not difficult to see that each function g within Equation (8) is a convex function by simply checking if the Hessian matrix of each function g semi-positive definite. Theref ore, simple methods such as a Newton method can be employed for finding the optimal solution of function g i because each g i function only contains a small number of parameters (equal to the number of classes). Comparing Q FIS in (8) to Q IIS in (4), we can show that Q
FIS is an upper bound of Q IIS by using inequality Equation (9). Therefore, the new iterative scaling algorithm forms a tighter lower bound for the original log-likelihood function. As a result, we would expect the new algorithm is able to converge to the global optimal solution in a significantly smaller number of iteration than the IIS method. However, as mentioned before, the computation complexity of each iteration and the number of iteration form a tradeoff pair. The new algorithm may use a smaller number of iterations but each iteration could consume more computation cycles. In order to account for the total amount of computation complexity, in the experiment, we simply use the total amount of time consumed CPU by both algorithms, which can be obtained by the matlab command  X  X putime X . The algorithm that is able to find the set of good parameters within a smaller amount of CPU time is deemed as a faster algorithm.  X  Finally, it may be attractive to think that, the inequality (8) can be obtained by simply applying Jensen inequality to both the exponential function and logarithm function. However, that is not true because the Jensen inequality for logarithm function only leads to a lower bound for logarithm function, namely for any p.d.f p(x). Instead, in the above derivation, we need an upper bound function for logarithm as illustrated in Equation (7 X ). Therefore, using Jensen inequality for logarithm won X  X  lead to the results in (8). 3.1 Experiment Design The goal of this experiment is to examine the efficiency of the proposed algorithm on the text classification task. The efficiency issue invo lves in two aspects: 1) Whether the proposed algorithm is able to increase the log-likelihood function more efficiently than other learning algorithms? As pointed out before, though the new algorithm yields a better auxiliary function that bounds the original log-likelihood function more tightly than the IIS method, it may still not be as efficient as the IIS method because in the new algorithm each iteration consumes more computation cycles. Therefore, we need to examine whether the introduction of a tightly bound but complicated auxiliary function is worthwhile. Furthermore, since the conjugate gradient method has been shown to be more efficient than the iterative scaling methods in some of previous studies, we will also compare the proposed iterative scaling method to the conjugate gradient method. 2) Whether the solution found by the proposed method results in lower classification error when the model is not full trained? In many cases, due to the limitation of time, we may have to stop the learning algorithm when it is still far from the global optimal solution. Under that circumstance, we need to know the quality of the parameters found by the learning algorithm. A learning algorithm is preferred when it is able to find  X  X ecent X  parameters that result in low testing errors even it is far from the convergence point. No tice that it is not always true that parameters that result in a larger value of log-likelihood function of training data will definitely lead to a lower testing error, particularly in case that the model is not fully trained.
 For the first efficiency issu e, we compute the value of the likelihood function vers us the accumulative CPU time for every iteration. An algorithm that is able to achieve a large value of log-likelihood function within a small amount of CPU time is deemed to be a good algorithm. To determine the quality of learned parameters in the middle of learning process, for every 20 iterations, we compute the classification errors on a separate testing dataset using the learned parameters. An algorithm that achieves lower testing error within smaller amount of CPU time is believed to be a better algorithm. Three collections of text classification are used in this experiment and for each collection. For each collection, we split it in to a training set and a testing set by 70% vs. 30% shares. The details are described in Table 1. For comparison methods, we will mainly compare the proposed algorithm to the previous iterative scaling algorithm, namely the IIS method, because both of them use very similar techniques except for the auxiliary function. Meanwhile, previous studies on the conditional exponential model have indicated that the CG method appears to be more efficient than IIS algorithm for learning an exponential model (Minka, 2001; Malbouf, 2002). Theref ore, we will also compare the proposed algorithm with respect to the CG method. In terms of implementation, we try to make each algorithm as efficiently as possible. For the IIS algorithm, the key computation complexity is on the optimization of the auxiliary function Q IIS in (4). Usually, a uni-variate Newton method is used for finding the optimal solution over Q IIS . Since Newton method is an iterative method, it usually requires at least several iterations to find the optimal solution over the auxiliary function. However, it may not be worthwhile to find the optimal point over the auxiliary function since it is just an approximation of the original log-likelihood function and our goal is to find the optimal solution over the likelihood function not the auxiliary function. In fact, as long as the solution  X  y,i (4) is able to increase the log-likelihood, the whole iterative scaling method is guaranteed to find the global optimal solution. Therefore, in practice, instead of running the Newton method through many iterations, we simply run it once over the auxiliary function. Furthermore, a linear search is applied in order to guarantee that the new point found in each iteration is always better than the prev ious one. Our empirical studies have found that this implementation is able to find the global optimal solution substantially faster than the implementation of running the Newton method till it converges. The same strategy applies to the implementation of the proposed FIS algorithm. For the CG method, the choice of s earch direction has great impact on the convergence speed. In our implementation, we choose Hestenes-Stiefel (Moller, 1993) method since it has been found very efficiently in practice. 3.2 Conditional Exponential Model for Text The conditional exponential model has been found to be an effective method for text classification in the previous study (Nigram et al., 1999). The main idea is to treat each unique word as a separate feature and try to find the appropriate weights of words for different classes using the conditional exponential model. In addition to the standard practice for conditional exponential model, two main issues need to be considered for the case of text classification: 1) Feature selection . As indicated in Table 1, the vocabulary size of each collection is considerably large, around the order of 10,000. Apparently, most of words will not be informative to indicate the category of documents. Thus, it is important to remove those uninformative words and only leave the informative words as the representation features. We use Information Gain (Nigram et al., 1999) as the feature selection criterion, and the top 300 features with the highest information gain are selected. For each feature, the corresponding unigram probability, namely the term frequency of the corresponding word divided by the document length, is used as its value. In addition, we also conducted the same experiments but with top 500 and 1000 selected features . The results are extremely similar to the experiment with only 300 selected features. Due to the limited space, we will only show the results for 300 features. 2) Regularization . The conditional exponential model sometimes can give overly large weights to words, particularly those rare words. Consider the case that a word only appears in one document within the whole training corpus. According to the conditional exponential model, this word can have an infinitive large weight. However, this is definitely undesirable since the word may be accidentally used for that document and may not be informative at all. A general practice to avoid this kind of disaster is to introduce some kind of regularization factor. For text classification, people have tried the Gaussian prior as the regularization factor and found it is quite effective (Nigram et al., 1999), which prevents weights from growing too large. Furthermore, people have found that by introducing the regularization factor into the conditional exponential model, we are able to even improve the classification ac curacy. We use the similar regularization approach for all the learning algorithms to be compared. 3.3 Results And Discussions Figure 1 shows the results for IIS, CG and the proposed method FIS over three datasets for text classification. Among all the diagrams, the horizontal axis is the number of seconds used by CPU and the vertical axis represents the log-likelihood. The parameters are initialized to be zeros for all three algorithms. Due to the large negative values of log-likelihood for the first several iterations (on the order  X  X og(num_of_class)), we only show the curve of log-likelihood since the 20 iterations. The same strategy applies to the Figure 2, when the curve of testing errors is displayed. Clearly, the curve of the FIS algor ithm is able to reach the maximum of likelihood much more quickly than the other two algorithms. In addition, the experiments with 500 and 1000 selected feat ures are conducted and the similar behavior is observed, namely the FIS algorithm reaches the maximum of like lihood much faster than both the IIS method and CG. These observations indicate that in the text cl assification task, the proposed algorithm  X  X IS X  is a more effi cient algorithm in learning the conditional exponential model than both the IIS algorithm and the CG algorithm. The other interesting observation from Figure 1 is that, the IIS algorithm performs at least as well as the CG algorithm over all the three datasets, which is quite different from what other researchers have claimed (Minka, 2001; Malouf, 2002). We think that it can be attributed either to the speci al characteristics of the text classification task or to the particular implementation of IIS algorithm used in this paper such as how to find the optimal point over the auxiliary function. In addition to the conver gence rate, we are also concerned with the quality of parameters learned from the algorithm particularly when the model is not fully trained. Figure 2 plots the behavior of the testing errors with respect to the amount of CPU time devoted to computing. Similar to the previous experiment, parameters are set to be zeros for all three algorithms and the plotted curves start from 20 iterations due to the large testing errors at the beginning of the learning. According Figure 2, the FIS algorithm is able to reach the lower classification error much faster than the other two algorithms. Meanwhile, for the collection  X  X ndustry Sector X , we can see the overfitting problem for the FIS algorithm. By varying the regularization constant, we are able to avoid the overfitting problem but obtain the same classification error at the end. This fact of overfitting in the FIS algorithm indicates the importance of regularization in learning the conditional exponential model. The same experiment with 500 and 1000 selected features ar e conducted and the similar behaviors are observed, namely the FIS algorithm is able to achieve lower testing errors faster than the IIS algorithm and the CG algorithm. Thus, we conclude that the proposed algorithm FIS is able to not only optimize the log-likelihood function faster than the other two algorithms but also find  X  X ecent X  parameters faster. The other interesting observation is that, for collection  X  X ndustry Sector X , according to Figure 1, it seems that both the IIS and the CG algorithms have very similar behavior in the convergence of log-likelihood. However, according to Figure 2, for most of time, the IIS algorithm appears to achieve lower testing errors than the CG algorithm in collection  X  X ndustry Sector X . This fact again i ndicates that a larger log-likelihood of training data may not necessarily lead to a lower testing error, particularly when the model is not fully trained. In this paper, we propose a novel iterative scaling algorithm, named  X  X IS X . Compared to the previous work on iterative scaling method, the FIS algorithm uses an auxiliary function that is able to bound the original log-likelihood function tighter. In our empirical studies of text classification problems over three datasets, the FIS method is able to converge significantly faster than th e IIS algorithm and the CG algorithm. Furthermore, the new algorithm FIS is able to obtain  X  X ecent X  estimation of parameters (e.g. parameters resulting in low testing error) even when the learning process is still far away from the convergence point. As a future work, we would like to examine the effectiveness of this new iterative scaling algorithm on other tasks such as part of speech tagging. Abramowitz, M. and Stegun, C. A. (Eds.) (1972) Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables, 9th printing. New York: Dover, p. 11, 1972. D. Beeferman, A. Berger and J. Lafferty (1999), Statistical Models for Text Segmentation. In Machine Learning, 34:177-210, 1999. A. Berger, V. Pietra and S. Pietra (1996), A Maximum Entropy Approach to Natural Language Processing. In Computational Linguistics, 22:39--71, 1996. A. Berger (1997), The improved iterative scaling www.cs.cmu.edu/afs/~aberg er/www/ps/scaling.ps A. Borthwick, J. Sterling, E. Agichtein and R. 
Grishman (1998), Exploiting diverse knowledge sources via maximum entropy in named entity recognition. In Proceedings of the Sixth Workshop on Very Large Corpora, 1998. J. Darroch and D. Ratcli (1972), Generalized iterative scaling for log-linear models. Annals of Math. Statistics, 43(5):1470-1480, 1972. F. Jelinek (1997). Statis tical Methods for Speech Recognition. The MIT Press, Cambridge, Massachusetts, London, England, 1997. T. Minka (2001), Algorithms for maximum-likelihood logistic regression, CMU Statistics Tech Report 758, http://www.stat.cmu.edu/~mi nka/papers/logreg.html, 2001. K. Nigam, J. Lafferty and A. McCallum (1999), Using 
Maximum Entropy for Text Cl assification. In IJCAI-99 Workshop on Machine Learning for Information Filtering, 1999. A. Ratnaparkhi (1996), A Maximum Entropy Model for Part-of-Speech Tagging. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 1996. R. Rosenfeld (1996), A Maximum Entropy Approach to Adaptive Statistical Language Modeling. In Computer, Speech and Language, 10:187-228, 1996. J. Shewchuk(1994), An Introduction to the Conjugate Gradient Method Without the Agonizing Pain, 1994. M. Moller (1993), A Scaled Conjugate Gradient Algorithm for Fast Supervised Learning, Neural Network, 6, 525-533. R. Malouf (2002), A Comparison of Algorithms for Maximum Entropy Parameter Estimation, Proceedings of CoNLL-2002 D.C. Liu &amp; J. Nocedal (1989) On the Limited Memory BFGS Method for Large Scale Optimization, Math. Prog. 45, 503-528, 1989 The extension of Holder Sum Inequality claims that the following inequality will always hold for any set of { q k }, as long as all the q k are positive and satisfies the constraint 1 1 =  X   X  k k q . The above inequality can simply be proved by the induction on k : (1) k =1: inequality in (6) hold s because the RHS of the inequality is identical to the LHS of the inequality. (2) Assuming inequality in (6) holds for any k  X  l and need to prove when k = l +1. Using Holder Sum Inequality, we have the following inequality hold further expanded as: According to the induction assumption, the extension of Holder Sum Inequality holds for any k  X  l . Therefore, we can use it to upper bound the second item in the RHS of above equation, i.e. By merging inequality (A3) and (A2) together, we have extension of Holder Sum Inequality proved when k = l +1. With this induction step, we proved the 
