 Abstract Lexica and terminology databases play a vital role in many NLP appli-cations, but currently most such resources are published in application-specific formats, or with custom access interfaces, leading to the problem that much of this data is in  X  X  X ata silos X  X  and hence difficult to access. The Semantic Web and in particular the Linked Data initiative provide effective solutions to this problem, as well as possi-bilities for data reuse by inter-lexicon linking, and incorporation of data categories by dereferencable URIs. The Semantic Web focuses on the use of ontologies to describe semantics on the Web, but currently there is no standard for providing complex lexical information for such ontologies and for describing the relationship between the lex-icon and the ontology. We present our model, lemon, which aims to address these gaps while building on existing work, in particular the Lexical Markup Framework, the ISOcat Data Category Registry, SKOS (Simple Knowledge Organization System) and the LexInfo and LIR ontology-lexicon models.
 Keywords Lexica Terminology Semantic Web Linked data Ontologies 1 Introduction Lexica and terminology databases form an essential part of many modern NLP systems and frequently consist of large amounts of highly detailed and well curated entries. Examples of such resources are the lexical semantic network WordNet (Fellbaum 1998 ) and subcategorisation lexica such as COMLEX (Grishman et al. 1994 ). However, there is currently a great diversity of formats for representing such lexical resources, thus making it difficult to share and interlink them. Current work on the Semantic Web, in particular that of the Linking Open Data project (Bizer et al. 2009 ), has focused on the challenge of using Web representation formalisms, RDF in particular, to connect such  X  X  X ata silos X  X  and allows for interlinking different datasets. This linking supports the reuse of entries from a lexicon within another one and allows third parties to extend an existing lexicon. However, so far there is no principled model to connect ontological knowledge with lexical knowledge, that would enable the creation of an interface between an ontology and an appropriate lexicon. Such an ontology-lexicon interface represents an essential component in the scenario of the Semantic Web, since it will enable an appropriate exploitation of the available knowledge by end-user applications, which are frequently language-based. Thus, it seems natural that any attempt to exchange lexica on the Semantic Web should build on Semantic Web representation formalisms, i.e. RDF and OWL. While there exist many terminology resources, they rarely have sufficient semantic information to enable these resources to be used for more complex reasoning. Similarly, while there exist many large semantic resources, such as DBPedia (Auer et al. 2007 ), and in particular models of domain semantics such as the Gene Ontology (Ashburner et al. 2000 ), they are rarely connected to complex linguistic and lexical information. Our goal is thus to provide a formalisms that  X  X onnects project is also working on publishing links between the OLiA reference model and the GOLD and ISOcat models. The relative sizes of each resource are given in Table 1 . 3 3 The lemon model In the light of current existing linguistic resource standards, we propose lemon as a model for exchanging lexicon resources on the Web with the following goals:  X  LMF-like structure facilitating the conversion to existing formats (TBX, TEI,  X  RDF-native form to enable leveraging existing Semantic Web technologies  X  Separation of the lexicon vs. ontology layers with the result that the semantic  X  The semantic inventory (ontology) is external to the lexicon model. Thus the  X  Linking to data categories in order to allow for arbitrarily complex linguistic  X  A small model using the principle of least power  X  X he less expressive the
The lemon model, as illustrated in Fig. 2 , is available in RDF with extra OWL constraints at http://www.monnet-project.eu/lemon . 3.1 The core The core of lemon covers the basic elements required to define lexical entries and associate them to their lexical forms as well as to concepts in the ontology representing their meaning. This is done primarily by defining the following elements:  X  Lexicon: The object representing the lexicon as a whole. This must be marked  X  Lexical Entry: An entry in a lexicon is a container for one or several forms and  X  Lexical Form: An inflectional form of an entry. The entry must have one  X  Representation: A given lexical form may have several representations in  X  Lexical Sense: A sense links the lexical entry to the reference used to describe  X  Component: A lexical entry may also be broken up into a number of In this way we give a clearer textual-conceptual path than is possible with SKOS. The following example gives a simple lexicon with a single lexical entry:
In this example (illustrated in Fig. 3 ), we have an English lexicon with a single entry, with canonical form  X  X  X urrent asset X  X , and a sense that refers to the entry in the Linked Data resource DBPedia (Auer et al. 2007 ) from which further semantic information about the entry can be obtained. 3.2 Linking to data categories While the core is useful for representing many aspects of lexical information, it is frequently necessary to include more information about morphology, syntax, terminological distinctions, versioning, authorship information etc. It would be very difficult to include all such categories in a way that would satisfy all users of the model. As a solution to this, we follow current Semantic Web practices, supporting the reuse of existing data categories by referencing their URIs. By this, users of the lemon model have absolute flexibility with respect to the choice of specific data categories. Consequently, the approach also scales in the sense that arbitrarily complex linguistic information can be included in the lemon model by referencing sources such as ISOcat, OLiA, GOLD for linguistic information, and vocabularies such as Dublin core 4 for authorship information. It is important to note that this does not solve the interoperability problem between category ontologies. However, this is also not the goal of lemon , but our position is that the reuse of unique identifiers and the ability to dereference these identifiers would support the alignment of categories across lexical resources. For example, we will show an entry for the Dutch feminine noun  X  X  X ergunning X  X  ( X  X  X ermit X  X ), with plural form  X  X  X ergunningen X  X . 5
Here we use ISOcat URIs to reference each of the properties, so that extra information about the data category can be obtained by dereferencing this link. The relation between these external properties and the lemon model is established by declaring them as sub-properties of lemon  X  X  property , so that the role of the property in the lemon model is properly defined. The use of URIs implies that the specification of the linguistic category becomes unambiguous. Furthermore, the source and provenance as well as ownership and responsibility for the data category can be clearly identified. In addition, we use the Dublin Core vocabulary to provide non-linguistic annotations, e.g. to indicate the author of the lexical entry. The use of RDF for data categories may allow to express ontological relationships and constraints on a lexicon (see McCrae et al. 2011 for a preliminary discussion). 3.3 Linking between lexica One of the most interesting aspects of using RDF and Semantic Web standards is that there are possibilities of data reuse not available to static resources. For example the medical term  X  X  X ospital-acquired pneumonia X  X , is composed of the words  X  X  X ospital X  X ,  X  X  X cquired X  X  and  X  X  X neumonia X  X , and we can provide appropriate morpho-syntactic and terminological information for each of these entries. However, it is inefficient for every single lexicon to repeat non-domain-specific words like  X  X  X cquired X  X . Thus, we shall expand on our previous example to show how RDF can aid in data reuse:
In this example (illustrated in Fig. 4 ), we see that  X  X  X ospital-acquired pneumonia X  X  is defined as being composed of an ordered list of components each of which refers to a lexical entry. 6 Two of these entries have URIs in the  X  X  X ommon lexicon X  X  (identified by, for example, http://www.example.org/common_lexicon#hospital ) and one in the same lexicon, the  X  X  X iomedical lexicon X  X  (identified by the URI http://www.example.org/biomedical_lexicon ). As such, any extra information that is stated in the common lexicon about the entries is then automatically available for users of the domain lexicon. Because these lexical entries are included by use of their URIs, they can be imported from any lexicon published on the Semantic Web, lexical entries are updated, the lexicon importing it will also automatically update these changes, a clear benefit of referencing in contrast to static import or duplication. 3.4 Lexicon-ontology mapping The lemon model does not intend to be a semantic model, but instead it allows semantics to be represented by referencing extant semantic resources, in particular ontologies. The lemon model approaches this by means of its  X  X (lexical) sense X  X  object, which differs significantly from the concept of a word sense found in existing models, which has been criticised by many authors (Kilgariff 1997 ). Technically, a sense is unique for every pair of lexical entry and reference, i.e., the sense refers to a single ontology entity and a single lexical entry. Thus, each word has a different sense for each distinct reference. In fact, a sense may have multiple reference URI values, but this implies that the reference URIs represent ontologically equivalent entities. 7 The sense object in lemon plays three roles: first, the set of all senses defines a many-to-many mapping between lexical entries and ontological entities. This models the fact that lexical entries can have different meanings with respect to a given ontology and the fact that ontology elements can be verbalised linguistically in various ways. Second, the sense object represents the (lexical) meaning of the lexical entry when interpreted as the given ontological concept. Third, the sense also represents an ontological specialisation of the referenced ontology entity which accounts for the specific lexico-semantic connotations that the lexical entry introduces.
 lexicalisation are equivalent. It rather indicates that there are linguistic contexts in which the lexical entry is used with this meaning and conversely this entity may sometimes be lexicalised with the given lexical entry. Therefore, it follows that the sense object belongs neither truly to the lexicon nor the ontology but instead acts as a bridge between the two and represents an underspecified relationship between the actual uses of a given lexical entry and the ontology entity it refers to. The contexts in which it is legitimate to interpret the lexical entry as representing the meaning of a given concept can be further constrained by attaching additional contextual and pragmatic conditions at the sense object. For example, we might express that the verb  X  X  X ressen X  X  (in German) is typically used for animals as agents, while  X  X  X ssen X  X  (in German) is used for human agents.

The lemon model represents subcategorisation with a frame object that can have a number of syntactic arguments indicated with the synArg property, which may be sub-typed to indicate specific roles played by syntactic arguments. The link to the ontology is then represented by linking the sense to each of these arguments with subjOfProp, objOfProp and isA (used for classes which we model as unary predicates). An example of such a mapping for the subcategor- X  X  X  X  X  the object entity. 8
This example (illustrated in Fig. 5 ) shows how we define a subcategorisation frame for a verb, in this case by indicating its arguments with ISOcat data categories that are specified as sub-properties of synArg . These arguments are then also linked to the sense, and indicated as the subject and object of the property referred to by this sense. In this way we can precisely describe the correspondence between a lexical entry and an ontology property or class.

These examples cover only a small part of the model, a full technical manual is available at http://lexinfo.net/lemon-cookbook.pdf , which also covers other features of the lemon model including:  X  Mapping with ternary (e.g.,  X  X  X onative X  X ) and other multiple-argument  X  Relations between lexical entries  X  Representing syntax trees  X  Combining syntax trees with subcategorisations  X  Specifying sense contexts and conditions  X  Assigning subject fields to lexica  X  Asserting global lexicon constraints  X  Providing compact representations of inflection and agglutination 4 Using lemon In general, the most important step for instantiating a lemon lexicon is identifying selection file to state which set of data categories are used in a given file. Instead, as each data category is uniquely identified by a URI, they can simply be used without prior identification. As such, in order to use lemon to represent a lexicon, the following steps should be carried out: 1. Identify which properties/relations you wish to use to define specific linguistic 2. Look up appropriate data categories from some source (e.g., ISOcat) and 3. If there are properties that are not covered by any standardised source, you may 4. Align the data source with the lemon core model. For example, it is commonly 5. Publish the lexicon as an RDF/XML document. The URIs for each entry should
We have also created a number of tools to support the creation and use of lemon models. Firstly, as lemon is developed from LMF, we have implemented methods supporting the conversion from and to the LMF format. 9 We are also working on import/export facilities to a number of other formats including XLIFF and TBX. We have also developed a web interface that allows people to upload and modify lemon models. 10 This service can also create lemon models automatically from OWL ontology files. It works by extracting the labels for each concept from the ontology through an annotation such as rdfs:label or skos:prefLabel . Otherwise the system uses the URI of the entity to attempt to obtain a label for the concept, for example by de-camel-casing the fragment. Then, the system applies a tokeniser and then a part-of-speech tagger and uses this to create the core structure of the lemon entry. Finally, as in the work of Cimiano et al. ( 2011 ), we apply syntactic analysis to infer the subcategorisation frame of the term and the phrase structure, if desired. Another important aspect of lemon is that it is based on established Semantic Web technologies and hence a number of tools already exist to enable the sharing and integration of models on the Web. For example, several Semantic Web search engines (SWSE) maintain an index of all RDF data published on the Semantic Web. As such, if someone chooses to publish their lemon lexicon on the Web, it can be submitted to a SWSE. It is then easy for other users to find lexica and share them, as SWSEs allow for particular properties to be queried. For example, querying for all triples using the property lemon:writtenRep and value  X   X  X at X   X  would retrieve all lemon lexica that use the word  X  X  X at. X  X  In addition there is a Java API for handling lemon documents and converting them to other formats. 11 5 Conclusion In this paper, we have proposed the lemon model as a format allowing to bring together two  X  X  X orlds X  X : the world of ontological knowledge, which builds on Web-based knowledge representation formalisms such as OWL and RDF(S) and the world of lexical and linguistic resources, which builds on various standards to represent lexica (e.g. LMF) and terminological resources (e.g. TBX). The lemon model has been designed to describe ontology lexica, which specify how the concepts in a given ontology are lexicalised, thus providing NLP applications with the required background knowledge to interpret natural language with respect to an ontology. The lemon RDF model allows for ontology-lexica to be shared and interlinked on the Web and integrated with ontologies in the Web Ontology Language (OWL). This allows for greater reuse of existing data than is possible using current lexicon formats and the integration with ontologies allows for deeper semantic relationship than a lexicon alone would provide. The lemon model is based on several existing resources, in particular LMF, SKOS, LIR, and LexInfo and as such maintains a high degree of compatibility with these models. However, its focus on compactness and expressivity allows for a large amount of linguistic information to be represented, while keeping the model fairly small. It maintains a high degree of flexibility and extensibility by the use of data categories, allowing the model to discussed tools that facilitate easy usage of the lemon model and interaction with existing standards in both lexicography and the Semantic Web. As such we hope that this will lead to a consensus model for the exchange of lexica on the Semantic Web. We are currently working towards building a community that can continue to develop and apply the model. 12 References
