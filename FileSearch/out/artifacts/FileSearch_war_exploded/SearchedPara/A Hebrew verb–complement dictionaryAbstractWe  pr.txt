 Abstract We present a verb X  X omplement dictionary of Modern Hebrew, auto-matically extracted from text corpora. Carefully examining a large set of examples, we defined ten types of verb complements that cover the vast majority of the occurrences of verb complements in the corpora. We explored several collocation measures as indicators of the strength of the association between the verb and its complement. We then used these measures to automatically extract verb comple-ments from corpora. The result is a wide-coverage, accurate dictionary that lists not only the likely complements for each verb, but also the likelihood of each com-plement. We evaluated the quality of the extracted dictionary both intrinsically and extrinsically. Intrinsically, we showed high precision and recall on randomly (but systematically) selected verbs. Extrinsically, we showed that using the extracted information is beneficial for two applications, prepositional phrase attachment disambiguation and Arabic-to-Hebrew machine translation.
 Keywords Verb subcategorization Hebrew Lexicography 1 Introduction The core of syntactic structure, according to most contemporary syntactic theories and for most languages, revolves around verbs and their complements. The relations between verbs and their complements are syntactic in nature, but they reflect semantic relations that hold between the action or state denoted by the verb, and the complement constructions to such semantic relations: understanding the syntactic relations between verbs and their complements is thus instrumental for understand-ing the meaning of natural language sentences. Correctly identifying verb complements in naturally-occurring texts is therefore important both theoretically, for linguistic investigations, and practically, for natural language processing (NLP) applications. A crucial resource needed for this task is a dictionary listing the number and types of complements that are most likely to occur with each verb, ideally with some statistical measure of the strength of the relation between the verb and each of its complements.
 The importance of such a resource must not be underestimated. Briscoe and Carroll ( 1993 ) observed that half of the errors made by a parser tested on unseen data were due to inaccurate subcategorization information in a manually-compiled dictionary. Briscoe and Carroll ( 1997 ) then described a novel way for extracting such a dictionary from corpora, and showed a small improvement in the accuracy of parsing. Carroll et al. ( 1998 ) repeated the same experiment, on a much larger scale, and demonstrated that the use of subcategorization frames can improve both precision and recall in the task of inducing bracketing on sentences, whereas for the task of assigning grammatical relations, precision improved by 9 % points (from 79 to 88 %), at the cost of only half a point drop in recall. A similar improvement is also observed when dependency parsers are concerned (Zeman 2002 ).

This problem holds for modern parsers, too. Kummerfeld et al. ( 2012 ), experimenting with a large number of English parsers, demonstrated that prepositional phrase (PP) attachment  X  X  X s the largest contributor to errors, across all parsers X  X . Kummerfeld et al. ( 2013 ) conducted a similar investigation of Chinese parsers, and revealed that the error types were quite different from the errors made by the English parsers. We experimented with the state-of-the-art Hebrew parser of Goldberg ( 2011 ); this is a dependency parser based on the EasyFirst parsing algorithm (Goldberg and Elhadad 2010 ), enhanced with morphology-based features which greatly improve its accuracy. It was trained on the Hebrew dependency treebank, which was automatically converted from a manually constructed constituent-structure treebank (Sima X  X n et al. 2001 ; Guthmann et al. 2009 ). Testing on 25 newspaper sentences containing 51 verb occurrences, the F-score of the parser on identifying the correct verb complements was below 0.85. Indeed, Goldberg ( 2011 ) specifically mentions (p. 93) that  X  X  X odes... which are assigned an incorrect head are predominantly PPs X  X  and that  X  X  X ll parsers have a hard time dealing with PP attachment. X  X 
Other applications that have been shown to benefit from information on subcategorization include automatic classification of verbs to semantic classes (Schulte im Walde and Brew 2002 ), information extraction (Surdeanu et al. 2003 ), machine translation (MT) (Hajic  X  et al. 2004 ) and more. Knowledge of verb subcategorization frames also affects human sentence processing (Garnsey et al. 1997 ), and a subcategorization dictionary is therefore highly useful for psycholin-guistic experimentation (Lapata et al. 2001 ; Baldewein 2004 ). We introduce the first automatically-created verb X  X omplement dictionary of Modern Hebrew, extracted from large text corpora. Using available resources, we morphologically analyzed and syntactically parsed the corpora. We employed standard collocation measures to assess the degree to which potential complements tend to combine with each verb, focusing on a small set of potential complement types, which covers the vast majority of complement instances in the corpora. More importantly, we did not attempt to construct full subcategorization frames; rather, we viewed each complement type in isolation, and determined its likelihood to combine with the verb. We also favored high-frequency complements that can be extracted with high precision, at the expense of potentially lower recall.
The result is a wide-coverage dictionary of almost 3,000 verb lemmas, listing more than 6,500 verb X  X omplement pairs, each with a statistically-derived score. We Intrinsically, we manually constructed a set of representative verbs and their canonical complements; our automatically-extracted dictionary achieves high precision and recall on this test set. Extrinsically, we incorporated linguistic knowledge derived from our verb X  X omplement dictionary in two computational tasks: reducing the ambiguity of PP-attachment and translating from Arabic to Hebrew. We demonstrated that knowledge derived from our dictionary is instrumental in significantly improving the accuracy of these two tasks. The contribution of this work is thus a digital, freely-available, wide-coverage and accurate verb X  X omplement dictionary of Hebrew.

After reviewing related work in the next section, we outline the structure of verb X  complement constructions in Hebrew in Sect. 3 . We describe the research methodology, as well as the required language resources, in Sect. 4 . The results are discussed in Sect. 5 , followed by an evaluation of their quality in Sect. 6 .We conclude with a discussion and suggestions for future research. 2 Related work The verb subcategorization frame (Chomsky 1965 ) determines the number and type of verb complements. Clearly, subcategorization frames are part of the syntax X  semantic interface (Levin 1993 ): they determine the syntactic structure of verb phrases, but they are typically shaped by the verb X  X  argument structure, reflecting the verb X  X  meaning. Indeed, subcategorization frames can be used to categorize verbs semantically (Sun et al. 2008a , b ; Sun and Korhonen 2009 ), and semantic knowledge can improve the extraction of subcategorization frames (Korhonen 2000 , 2002a ; Korhonen and Preiss 2003 ).

Syntactic theories tend to distinguish between complements and adjuncts . The former are phrases that are syntactically required by the verb; without them, verb phrases are incomplete. The latter are more general verb modifiers, that are typically optional, and may occur more than once with a given verb instance. Generally, there is a mapping of complements to verb arguments: the meanings of verb complements are considered crucial to understanding the meaning of a predicate, whereas other verb modifiers are less central semantically.

Clearly, the distinction between complements and adjuncts is vague (Huddleston and Pullum 2002 , Chapter 4, Section 1.2). There is overlap in the syntactic realization of both types of verb modifiers, and both are frequently realized as PPs. For example, the PP in I slept on the floor is considered an adjunct, whereas in I rely on you it is considered a complement. While in some cases there is a clear distinction between complements and adjuncts, the degree of relationship between a complements from adjuncts in many cases. Having said that, distnguishing between complements and adjuncts has been found useful for applications such as PP attachment (Merlo and Ferrer 2006 ), see Sect. 6.3.1 .

One of the first works to address automatic acquisition of subcategorization frames introduces the Lerner system (Brent 1991 , 1993 ). Lerner uses large un-annotated corpora and no dictionary, identifying English verbs through simple morphological cues. It focuses on six subcategorization frames using a simple, finite-state grammar of English. Complements include direct objects, clauses and infinitival verb phrases, but no PPs. Hypothesis testing, with binomial frequency data as the collocation measure, is used to determine whether a candidate is indeed a parameters can yield perfect recall at 50 % precision, and vice versa, on a set of 193 manually selected verbs; for clauses and infinitival verb phrases, accuracy is much higher.

The Lerner system was a pioneering work, and we follow its spirit by using hypothesis testing as the main tool for determining the statistical validity of a decision on a verb X  X omplement pair. We extended the scope of our study to more (ten) complement types, particularly PPs, and we experimented with several collocation measures. We also took advantage of the availability of morphologically analyzed and syntactically parsed corpora of Hebrew.

With the proliferation of language resources, contemporary approaches to subcategorization frame induction tend to use as many data sources as are available. For example, Sarkar and Zeman ( 2000 ), working on Czech, used the manually-constructed Prague Dependency Treebank for this task. Since word order in Czech is much freer than in English, complements are sought around the verb, and not just immediately following it. Induction was done iteratively: first, a wide subcatego-rization frame was assumed for each verb, with all elements that are dependent on the verb in the training material as candidate complements. Then, iteratively, the wide frame was replaced by proper subsets thereof, based on statistical consider-ations. Sarkar and Zeman ( 2000 ) employed three hypothesis testing measures, likelihood ratio, t test and binomial frequency, yielding three different subcatego-rization dictionaries. For each measure, candidate complements that did not pass the test were removed from the frame, until convergence.

Again, our method is very similar, but unlike Czech, Hebrew only has a very small treebank (see Sect. 4.2 ; the Hebrew treebank includes some 6,000 sentences, compared with over 115,000 for Czech). We also experimented with more than one collocation measure. Unlike Sarkar and Zeman ( 2000 ), we did not begin with the widest frame observed in a treebank (since our treebank is so small). Rather, we treated each potential complement independently of other complements, and only attempted to determine the strength of its own attachment to the verb. This approach is similar to the one used by De  X bowski ( 2009 ), who also collected single possible complements from a (Polish) corpus; however, De  X bowski ( 2009 ) also defined a second filtering step in which full frames are constructed.
 When a treebank is unavailable, automatically parsed data can be used instead. This is the main resource used by Briscoe and Carroll ( 1997 ), who inspired many subsequent works for Chinese (Han et al. 2004 ), English (Li and Brew 2005 ) French (Chesley and Salmon-alt 2006 ), Italian (Ienco et al. 2008 ), Portuguese (Zanette et al. 2012 ), and other languages. Again, the approach is to first assume a wide frame for each verb, sometimes based on existing, manually-created lexicons, and sometimes on assumed frames observed in the corpus. Then, a refinement step constrains the set of possible complements for each verb, based on the strength of the association between the verb and the candidate complement. Briscoe and Carroll ( 1997 ) used binomial frequency; Korhonen ( 2002b ) compared three different collocation measures [binomial frequency, log-likelihood ratio (LLR) and raw frequency (RF)], and showed that RF produces the best results.

Korhonen et al. ( 2006 ) extended the work of Korhonen ( 2002b ) to a full subcategorization dictionary of English verbs, called Valex . The dictionary includes not just the complements of each verb, but also the likelihood of their realization, as obtained from a large corpus. Each verb was associated with a subset of the full set of 163 subcategorization frame types, with an average of 33 frames per verb. A similar dictionary for French, LexSchem , was compiled by Messiant et al. ( 2008 ).
More recently, approaches based on topic modeling have been used to automat-ically induce lexical semantic information, in particular selectional preferences (Ritter et al. 2010 ;O  X  Se  X  aghdha, 2010 ). These are completely unsupervised methods, which may be useful for the task at hand, but are beyond the scope of this paper.
The only available information source on Hebrew subcategorization so far is the verb dictionary of Stern ( 1994 ), which includes 833 verbs and 1,430 subcatego-rization frames. While the information was manually collected from corpora of written and spoken language, news articles, literary texts, etc., being a manually compiled dictionary its coverage is obviously limited. For comparison, the MILA Hebrew computational lexicon (Itai and Wintner 2008 ) contains almost 5,000 verbs. The advantages of automatic extraction of verb subcategorization frames are obvious: not only does the method provide better coverage (at the expense of reduced precision, of course), but it also facilitates adaptation of the extracted dictionary to a specific genre, domain, register, etc. Furthermore, our approach provides probabilistic estimates of the likelihood of various complements, which may be more useful than the deterministic information listed in Stern ( 1994 ). 3 Hebrew verb subcategorization In light of the discussion in Sect. 2 , we refrained from making a clear distinction between complements and adjuncts in this work. Rather, we used a working definition whereby a particular type of modifier was considered part of the subcategorization frame of a verb if it frequently occured with the verb in text corpora. According to this definition, both argument-denoting complements and frequent adjuncts may be listed along with each verb. We did not include subjects in this investigation, as they are trivially required by all verbs.

Verbs can be ambiguous, with more than one subcategorization frame, often reflecting semantic variability. For example, when the verb 1 nicx takes a direct object, its meaning is  X  X  X in X  X ; when its complement is a PP headed by yl  X  X  X n X  X , its meaning is  X  X  X onduct, direct X  X . In this work we made no attempt to distinguish between the various meanings of ambiguous verbs. If our system inferred that the verb nicx is strongly associated both with a PP headed by yl  X  X  X n X  X  and with a direct object, then both were included in the complement dictionary for the verb.
Syntactically, we addressed four types of complements in this work: noun phrases, PPs, clauses and infinitival verb phrases. We now exemplify these complements and the way they are realized in text corpora. We discuss the various types of complements (Sect. 3.1 ), the number of complements (Sects. 3.2 , 3.3 ), and their order (Sect. 3.4 ). Finally, Sect. 3.5 provides some numerical data on the actual realization of verb complements in our corpora. 3.1 Types of complements In what follows, we use slanted font for natural language examples, bold face for the target verb and underline for the target complement. 3.1.1 Noun phrases Direct objects , clearly verb complements, are realized as noun phrases in Hebrew: must be introduced by an accusative marker, at , which we gloss as  X  X  X CC X  X . The accusative marker behaves like a typical preposition; in particular, it can combine with a pronominal enclitic: 3.1.2 Prepositional phrases Indirect objects, as well as several types of adverbials, are realized as PPs. 3.1.3 Clauses Several verbs take clausal complements. These are often introduced by the subordinating conjunctions ki  X  X  X hat X  X  and  X   X  X  X hat X  X : Clausal complements include also quoted speech and clauses introduced by relative/ interrogative pronouns and question words. 3.1.4 Infinitival verb phrases Sometimes, verbs take complements that are realized as verb phrases in the infinitive: 3.2 Number of complements The number of elements on a verb X  X  subcategorization list varies. Some verbs, traditionally known as intransitive , take no complements: We view such verbs as having empty subcategorization lists.

Other verbs take one, two or even three complements, as in the case of htyrb  X  X  X et X  X :
Sometimes, complements that have the same function can be realized in more than one way. This is common with cognitive verbs, which can have noun phrase, clausal, or verb phrase complements: Other verbs can only take one or two variants of these complements. For example, msr  X  X  X eport X  X  can take a clause or a noun phrase, but not a verb phrase; hxliT  X  X  X ecide X  X  can take a clause or a verb phrase, but not a noun phrase. Consequently, we view the three possible complements of cognitive verbs as different, and treat them independently of one another. 3.3 Internal complementation Certain verbs that are typically intransitive, with empty subcategorization frames, can sometimes be complemented by an object whose meaning is very close to the meaning of the verb (often, a nominalization of the verb itself). Such complements, known as internal objects , are not considered part of the verb X  X  subcategorization frame: Similar examples include rqd Tngw  X  X  X ance the tango X  X , xik xiwk rxb  X  X  X mile a wide smile X  X , mt mwwt  X qT  X  X  X ie a peaceful death X  X , etc. 3.4 Linear precedence inside the Hebrew verb phrase Hebrew constituent order is relatively free; in particular, verb complements and modifiers, including the subject, can both precede and succeed the verb (Belletti and Shlonsky 1995 ):
Having said that, sometimes the order is fixed, or there is a strong tendency towards a particular order. This is the case with idiomatic expressions, which tend to occur in a fixed order: Here, the alternative order would be awkward.

As in other languages (Ross 1967 ), a strong tendency towards a particular order can result from heaviness considerations; when one of the complements is a pronoun, for example, it strongly tends to precede a full noun phrase: Again, the two alternative orders are awkward. 3.5 Realization of verb complements in text corpora We listed above general, textbook properties of Hebrew verb subcategorization. Often, language use differs significantly from such generalizations. We therefore used text corpora to quantify some of these properties. Specifically, we used a treebank of 5,281 sentences (Sima X  X n et al. 2001 ), which include 1,423 verb types and 7,561 verb tokens, to which 9,486 complement tokens are attached (in this section, when the number of complements is mentioned, it refers to tokens, not types). Section 4.2 provides more detail about the treebank. The observations that we drew from the treebank drove the design of our subcategorization frame extraction algorithm (Sect. 4.1 ).

We first addressed the distance, in words, between the verb and (the first word of) its complements. Table 1 lists the data; as can be seen, the vast majority (87.46 %) of the complements follow the verb, and as many as 52.42 % of the complements immediately follow the verb. Consequently, we focused on complements that occur immediately after the verb in our extraction algorithm.

Next, we addressed the types of complements. The treebank includes 5,983 PPs that modify verbs, headed by as many as 129 preposition types. Table 2 lists the number of PP complements corresponding to the various prepositions in the treebank. The two most frequent prepositions, b  X  X  X n X  X  and l  X  X  X o X  X , account for more than half of the instances, and the top six prepositions account for almost 80 % of them. All other prepositions account for no more than 1 % of the complements each. Consequently, our algorithm focuses only on PPs headed by the six most frequent prepositions.

Noun phrases occur as verb complements in the treebank 2,207 times. Of these, 1,141 instances (51.7 %) are indefinite, and occur without the accusative marker. Consequently, we considered both bare noun phrases and noun phrases that were introduced by the accusative marker as potential complements.

Since in Hebrew the verb may precede the subject, some noun phrases that immediately follow verbs are in fact subjects. Of the 3,692 verb tokens in the treebank that have a subject, the subject immediately follows the verb in 476 instances (12.89 %). In order to filter out some of the noise introduced by subjects that immediately follow their verbs, we considered as complements only noun phrases that do not agree with the target verb in number, gender or person. Since in Hebrew the subject must agree with the verb, such candidates are obviously not subjects.

Turning now to clausal complements, we observed that of the 554 instances of such complements in the treebank, 281 (50.72 %) were introduced by  X   X  X  X hat X  X , whereas 273 (49.28 %) were introduced by ki  X  X  X hat X  X . We therefore addressed both of these subordinating conjunctions in our algorithm.

Table 3 summarizes the distribution of complement types in the treebank, listing only the types of complements we addressed in this work. Of the 9,486 complements in the corpus, the ones we addressed constitute 84.67 %.

Finally, we addressed the number of verb complements in the treebank. As is evident from Table 4 , the vast majority (93.61 %) of the verb occurrences in the treebank have at most one complement. Consequently, we focused on extracting each complement independently of other potential complements of the same verb.
 4 Methodological issues 4.1 Task definition In light of the observations of Sect. 3.5 , we defined our task as follows. First, we focused on ten types of complements only: (1 X 6) PPs with the six most frequent infinitival verb phrases; (9) clauses headed by  X   X  X  X hat X  X  and ki  X  X  X hat X  X ; and (10) the empty subcategorization frame, indicating that the verb phrase does not require a complement. Then, our goal was to associate each verb in a given Hebrew corpus with a measure of the strength of the association between the verb and each of the ten complements. We also defined a threshold such that only complements whose association strength exceeds the threshold were included in the dictionary.
Notice that this definition is somewhat different from the traditional definition of subcategorization frames; in particular, we have no way to distinguish between a subcategorization frame of two complements (e.g., hsbir  X  X  X xplain X  X , which subcategorizes for a noun phrase and a PP headed by l  X  X  X o X  X ) and two single-complement frames for a single verb. In light of Table 4 , however, this does not seem to be a major drawback, as very few verbs have more than one complement. 4.2 Resources We used the MILA corpus of written Modern Hebrew (Itai and Wintner 2008 ), consisting of newspaper articles, newswire items and parliament proceedings. The total number of tokens in the corpus is over 40 million, with 1.8 million verb tokens reflecting 4,358 verb lemmas.

The corpus is morphologically analyzed and disambiguated using the MILA tools (Itai and Wintner 2008 ). The current disambiguation module does not always fully resolve the ambiguity of some forms. For example, when two analyses differ only in the lemma, they remain ambiguous. This happens quite frequently with verbs, where two different analyses differ only in the pattern ( binyan ), as in x X bh , which can mean either  X  X  X he thought X  X  in one pattern or  X  X  X he calculated X  X  in another (this latter form is prefers certain patterns over others in order to fully resolve the ambiguity in such cases. We refer to this corpus as the morphologically analyzed corpus . Recently, two syntactic parsers have been made available for Hebrew, facilitating automatic computation of constituent-and dependency-structures (Goldberg 2011 ). We applied the dependency parser to the same corpus; we refer to the result as the syntactically parsed corpus .
 We also used the much smaller Hebrew Treebank (Sima X  X n et al. 2001 ; Guthmann et al. 2009 ). This is a set of 6,219 sentences from the HaAretz newspaper, which were manually parsed and then semi-automatically converted to a dependency representation (Goldberg and Elhadad 2009 ). The treebank lists three types of syntactic relations between the verb and its modifiers: OBJ ect, used for direct objects; COM plement, indicating other subcategorized complement; and DEP endency, used for adjuncts. We considered only the first two as complements. Of the 6,219 sentences we used only 5,281; we filtered out sentences with quoted speech, since verb dependents were not accurately indicated in such sentences. We divided this set into development and test subsets, as indicated in Table 5 . 4.3 Hypothesis testing We employed four different statistical measures to assess the strength of the association between a verb and its complement: RF, LLR, t test and pointwise mutual information (PMI).

Let v be a verb lemma 2 and c , c 0 be specific complements (of the ten complement types listed above). Given a corpus with N tokens, of which V are (possibly inflected forms of) verbs, we define the following counts: n v , c The number of occurrences of any inflected form of v in the corpus, with c as n v The number of occurrences of any inflected form of v in the corpus; i.e., n c The number of occurrences of verb complements in the corpus; i.e., n c = n : v ; c The number of occurrences of any inflected form of any verb other than v in n : v The number of occurrences of any inflected form of verbs other than v in the
Using maximum likelihood, we estimate: With these, we define:
Raw frequency The likelihood of a complement c to occur with a verb v . This is Log likelihood ratio Following Dunning ( 1993 ), we define LLR as where for all p , k , and n , T-score We use the adapted definition of Sarkar and Zeman ( 2000 ): where for all n , p , Pointwise mutual information Following Church and Hanks ( 1990 ), we define PMI as 4.4 Thresholds Each of the four association measures defined above provides a way to estimate the strength of the association between a verb and its complement. To determine whether this association is strong enough for the complement to be included in the dictionary, we needed to set thresholds for each measure; only complements whose association is higher than the threshold were considered part of the subcategori-zation frame of the verb.
 To set the threshold, we used the development part of the treebank described in Sect. 4.2 . For each collocation measure, independently, we searched for a threshold that maximized the F-score of the task of identifying the correct complements of verbs in the development set. We used an exhaustive search with finely separated thresholds (obtained by dividing the full range of values the test can yield into 100 evenly-spaced intervals), and obtained the following threshold values: for RF, 0.11; LLR, 544.17; PMI, 0.12; and for t -score, 0.12 ( t -score values are multiplied by 1,000 for readability).

In spite of the relatively small size of the development set, the accuracy is not highly sensitive to the precise value of the threshold. Figure 1 shows the F-score on the development set with respect to varying thresholds, for PMI and t -score. Clearly, significant changes in the value of the threshold (for PMI, from 0 to 0.75; for RF, from 0.05 to 0.2) result in minor changes to the F-score. The other measures are similarly robust.

We used these threshold values in the remainder of this work: whenever the association by a verb and a potential complement was higher than the threshold, the complement was considered a member of the subcategorization frame of the verb according to the specific measure. 5 Results 5.1 Extracting a verb dictionary from a morphologically analyzed corpus We applied the association measures defined in Sect. 4.3 , with the thresholds defined in Sect. 4.4 , to the entire morphologically analyzed corpus (Sect. 4.2 ). For each occurrence of a verb in the corpus, we considered the token that immediately follows the verb. As shown in Sect. 3.5 , most complements occur immediately after their head verb, so we restricted the search to this position. Furthermore, we only considered as candidates instances in which the token immediately following the verb is either (1) one of the six prepositions and two conjunctions we focus on, or (2) an infinitival verb, or (3) a noun phrase that either is preceded by the accusative marker, or does not agree with the verb in either number, gender, or person (to rule out potential subjects). In all other cases, we considered the empty subcategorization frame as a candidate.

We then computed the association between the verb and its candidate complement, according to each of the association measures defined in Sect. 4.3 If it was above the threshold, the candidate was considered a complement of the verb.
The result of this process is a large set of verb X  X omplement (V X  X ) pairs for each association measure; we refer to these sets as the verb dictionaries . Data on the four verb dictionaries extracted from the morphologically analyzed corpus are listed in Table 6 .

To exemplify the results, we now list some of the entries in the verb dictionary induced by PMI; as we will show below, PMI turns out to be a good association measure, providing not only wide coverage but also relatively high accuracy.  X  The verb tm  X  X  X xpire, be finished X  X  was correctly associated only with the empty  X  The verb amr  X  X  X ay X  X  was correctly associated with l  X  X  X o X  X  and with a clause. The  X  The verb hxliT  X  X  X ecide X  X  was a complete success: all and only the correct  X  The same applies to the verb pwnh  X  X  X e evacuated X  X , for which PPs with al  X  X  X o X  X ,  X  The verb nhr  X  X  X tream, flow X  X  was correctly associated with al  X  X  X o X  X , but also  X  The verb ndbq is ambiguous; it can mean  X  X  X tick X  X  (typically with l  X  X  X o X  X  or al
The complete verb dictionaries induced by each of the association measures, including numeric values reflecting the strength of the association, are available for download from the MILA website. 3 5.2 Extracting a verb dictionary from a syntactically parsed corpus We used the syntactically parsed corpus (Sect. 4.2) for the task of extracting verb complements. Recall that this is the corpus used above, but each sentence was parsed with the dependency parser of Goldberg ( 2011 ). The reported accuracy of the parser is approximately 80 %, so many errors can be expected.

For each verb occurrence in the corpus, we considered as potential complements all the phrases that depend on the verb with any of the three dependency labels: OBJ , COM and DEP . We considered the empty subcategorization frame as a candidate if none of the other complement types are dependent on the verb. We then used the same association measures as in Sect. 4.3 , and the same thresholds as in Sect. 4.4 ,to determine whether the candidate should be included in the dictionary entry of the verb.

Again, the result is a set of four verb dictionaries, one for each association measure. Data on the dictionaries are listed in Table 7 .

The main difference between the parsed corpus and the morphologically analyzed one is that the former facilitates a wider scope in which to search for complements, as it is not limited to complements occurring immediately after the verb. This improved recall but potentially harmed precision. This also prevented verbs in which the subject tends to immediately follow the verb (e.g., amr  X  X  X ay X  X ) from being wrongly associated with the empty frame. Indeed, using the parsed corpus, the algorithm decided to include a potential complement in the dictionary much more frequently than with the morphologically analyzed corpus, except for the empty frame, as can be seen in Table 8 . 6 Evaluation To assess the quality of the verb dictionaries discussed in Sect. 5 , we conducted experiments we used the verb X  X omplement dictionaries but ignored the strength of the association between the verb and its complements (as long as it was above threshold, of course.) 6.1 Intrinsic evaluation Our evaluation measure is F-score. Define: TP The number of extracted verb X  X omplement pairs that are indeed correct.
 TN The number of verb X  X omplement candidates that are not extracted, and are FP The number of extracted pairs that are not correct.
 FN The number of correct pairs that are not extracted.
 Then the precision is P = TP /( TP ? FP ), the recall is R = TP /( TP ? FN ), and the F-score is their harmonic mean, F = 2 9 P 9 R /( P ? R ).

In order to apply these measures, one needs to determine what is indeed  X  X  X orrect X  X . For this, we manually constructed the verb dictionaries of 58 verbs, with various subcategorization frames and frequencies. The verbs in the evaluation set were chosen randomly (and uniformly) according to their distribution in the entire corpus. Many of them are consequently highly frequent (e.g., amr  X  X  X ay X  X , 39,356 occurrences, hgiy  X  X  X rrive X  X , 16,818), while others are rarer (e.g., htrgz  X  X  X et angry X  X , 31 occurrences only, or crx  X  X  X cream X  X , 41). We asked two lexicographers to specify the complements of each verb in this list. The instructions given to the annotators were:
Determine whether the verb has a complement of the specific construction (e.g., a PP with the specific preposition). A subcategorized complement denotes an argument of the verb; its meaning is necessary for complete understanding of the meaning of the verb. Syntactically, a subcategorized complement can only occur once, and if it is omitted the verb phrase is conceived as incomplete.
 Several examples, both positive and negative, were also specified. Since we were concerned with 10 complement types and 58 verbs, there were 580 decisions to be made; the two annotators disagreed on 93 (16 %) of them. The annotators then discussed each manually annotated complements for 58 verbs, a subset of which is listed in Table 9 .
Table 10 shows the number of verb lemmas in the gold set that are associated with each of the ten complement types. Evidently, with the exception of ym  X  X  X ith X  X , all complement types are well represented in the gold set.

As a baseline, we performed the following experiment: we considered the syntactically parsed corpus as a gold standard, and viewed every verb X  X omplement included a sentence in which a complement c was annotated as a dependent of the verb v , and the dependency was labeled either OBJ or COM , we considered the pair v  X  c as correct. For each verb in the test set we thus obtained a list of complements, and compared it to the gold annotations exemplified in Table 9 . This yielded high recall at the expense of precision, of course. The baseline results on our test set are listed as the first row of Tables 11 and 12 .

We then used the morphologically analyzed corpus, and extracted, for each verb in the test set, the above-threshold candidates. Next we compared them to the gold annotations of Table 9 . The results are listed in Table 11 . We found that PMI is the best association measure, yielding both the highest recall and the second highest precision on this set. While recall is lower than the baseline, precision is much higher, resulting in a much higher F-score. T -score and RF both do well, while LLR is below the baseline.

We repeated the evaluation with the verb dictionaries that were extracted from the syntactically parsed corpus; the results are listed in Table 12 . Surprisingly, the F-score of the PMI dictionary does not improve. By contrast, all other measures actually improve somewhat, though PMI remains the best measure. Our conclusion is that the use of the syntactically parsed corpus does not contribute significantly to this task.
We also performed a weighted evaluation with the manual annotation, where the contribution of each verb in the gold set is proportional to the verb X  X  frequency in the corpus. The results are very similar, typically within 1 % point difference from the balanced evaluation results.

Our results clearly indicate that PMI is the best collocation measure for the task at hand. Other works that dealt with induction of verb valence and subcategorization frames promoted different collocation measures. For example, Korhonen et al. ( 2000 ) compared two methods for hypothesis testing, binomial hypothesis test and maximum likelihood to estimate probabilities. The latter performed best, and Korhonen et al. ( 2000 ) suggested as an explanation the Zipfian distribution of subcategorization frames. However, for many other tasks that involve the induction of collocations, PMI seems to be a preferred test (Chang et al. 2002 ; Villavicencio et al. 2007 ; Tsvetkov and Wintner 2010 , 2012 ), and Pecina ( 2005 ) actually advocated the combination of several collocation measures. We conclude that it is always important to experiment with more than one measure, as we do here.
 6.2 Error analysis The association measures we used reflect the frequency of the various complements as they immediately follow the verb. Sometimes this frequency is clear-cut. For example, 98 % of the occurrences of the verb tm  X  X  X xpire, be finished X  X  in the corpus are with the empty subcategorization frame; all the measures thus correctly associated this verb with the empty frame. Other verbs, however, do not behave as nicely. Consider amr  X  X  X ay X  X ; especially in the journalistic genre that constitutes a significant portion of our corpus, this verb tends to occur with a post-verbal subject (55 % of the instances). Our simplistic method considered such occurrences as instances of the empty subcate-gorization frame, and neglected to find the object, which is often pre-verbal.
The cause of many other errors is the lower frequency of the expected complement immediately after the verb. Consider the verb nhr  X  X  X tream, flow X  X , which should be complemented by l  X  X  X o X  X  or al  X  X  X o X  X . As mentioned above, many  X  X  X nstances X  X  of this verb are in fact mistagged instances of the noun nhr  X  X  X iver X  X . In addition, the subject of the verb frequently occurs post-verbally. Consequently, only 9 % of the instances of this verb in the corpus are immediately followed by the expected preposition.
Similarly, the verb aixl  X  X  X ish, congratulate X  X  takes two complements, a noun phrase and a l  X  X  X o X  X  PP, but in the typical order the PP precedes the noun phrase (possibly because the l  X  X  X o X  X  preposition typically combines with a pronoun, and thus is lighter). Consequently, our method found the preposition complement but not the noun phrase.

Another major source of errors is data sparsity. The verb htiiyc  X  X  X onsult X  X  occurs 219 times in the corpus. This frequency is sufficient for all the collocation measures to extract the complement ym  X  X  X ith X  X , but not to identify the less frequent, and typically second, complement yl  X  X  X bout X  X . The ambiguous verb mxh can either mean  X  X  X rotest X  X , in which case it takes yl  X  X  X n X  X ; or  X  X  X rase, wipe X  X , in which case it takes a noun phrase. The former meaning is far more frequent, and hence all association measures yielded the yl  X  X  X n X  X  complement, but none yielded the noun phrase.
For a more quantitative error analysis, refer to Table 13 , which depicts the accuracy of identifying the complements of verbs in the gold set, using the PMI dictionary extracted from the morphologically analyzed corpus, broken down by complement type.

The highest accuracy was obtained, not surprisingly, for noun phrase comple-ments, the most common complement type in our gold set. It is surprising, however, that the recall of identifying noun phrase complements is perfect; since we quite aggressively filtered out NP complements that agree with the verb, one would expect many such complements to be mistakenly filtered out, resulting in a lower recall. Evidently, this was not the case. Table 13 also shows that the empty frame is not identified accurately; this is consistent with the discussion above: often, unrelated PPs are mistaken to be complements, and data sparseness can cause actual complements not to be identified. 6.3 Extrinsic evaluation The intrinsic evaluation of Sect. 6.1 is necessarily limited to a small set of verbs. As a more robust evaluation, we used the automatically extracted dictionaries in two natural language processing tasks, and showed a significant improvement in the performance of those tasks.

It is worth noting that our verb X  X omplement dictionaries are extracted in a way that favors high-frequency data, whereby frequent complements are more likely to be recorded (at the expense of lower recall). For the two applications we discuss below, higher-precision frequent data most probably suffice for improving the performance, hence the gains we witness. 6.3.1 PP attachment First, we address the problem of PP attachment : in Hebrew, as in many other languages, PPs can be attached both to verbs and to nouns. Determining the correct attachment of PPs is challenging, and can significantly affect the accuracy of parsing (Lin 1998 ; Goldberg 2011 ). The task has attracted much interest, and several works attempt to address it, using pure statistical methods (Resnik and Hearst 1993 ; Hindle and Rooth 1993 ; Ratnaparkhi et al. 1994 ), or through approaches that incorporate additional linguistic knowledge (Wilks et al. 1985 ; Dahlgren and McDowell 1986 ; Jensen and Binot 1987 ; Hirst 1988 ). In particular, several works showed that information on verb subcategorization is beneficial for this task (Stetina and Nagao 1997 ; Yeh and Vilain 1998 ; Pantel and Lin 2000 ; Volk 2002 ). More specifically, Merlo and Ferrer ( 2006 ) argued that a distinction between complements and adjuncts is needed in order to properly attach PPs, and suggested a (supervised) machine-learning-based classification method for the task. They found that  X  X  X oth linguistic diagnostics of argumenthood and lexical semantic classes are useful. X  X 
Subcategorization information can indeed help determine the correct attachment: when a PP is a subcategorized complement of a verb, its occurrence is likely to be attached to the verb, rather than to some intervening noun. Consider the following examples (again, subcategorized complements are underlined): Both sentences involve a verb, followed by the noun r X iwnwt  X  X  X icenses X  X , followed by a PP with l  X  X  X o X  X . Since such a PP is subcategorized by the verb hrah  X  X  X how X  X , but not by nmca  X  X  X e found X  X , the PP is more likely to attach to the verb in the second example, but to the noun in the first example. This is indeed the correct attachment.
For evaluation, we used the test subset of the treebank (Sect. 4.2 ). We focused on constructions of the form verb X  X oun X  X reposition, allowing any number of words from other POS classes to intervene between the verb and the noun and between the noun and the preposition. The test set included 323 such constructions, with 204 different verbs. The task was to determine whether the preposition attaches to the verb or to the noun. 4
The baseline was obtained by always attaching the preposition to the noun. A better-informed baseline uses the syntactically parsed corpus as a gold standard, and considers each verb X  X omplement pair as correct (as in Sect. 6.1 ). This turns out to be worse than the na X   X  ve baseline, probably because the parser seems to have a clear preference toward attaching PPs to the verb (a tendency which we do not fully understand).

To improve upon the baselines we used information from the verb dictionaries, albeit in a very simplistic way: if the preposition was strongly associated with the verb (above the threshold), we attached it to the verb. We compared this decision with the correct attachment, as reflected by the treebank X  X  annotation.

The results, with each of the verb dictionaries corresponding to the four association measures, are listed in Table 14 . We report accuracy (Acc) , defined as ( TP ? TN )/( TP ? FP ? TN ? FN ), as well as error rate reduction (ERR) . Evidently, all the verb dictionaries are instrumental in this task; the best accuracy, obtained by t -score, is over 65 % (reflecting a reduction of almost 30 % of the errors compared with the baseline), but the PMI and RF dictionaries also reduce the error rate by more than 20 %. Implementing a voting mechanism among the four dictionaries did not improve the results. We also repeated this evaluation with the dictionaries that were extracted from the syntactically parsed corpus; accuracy improved for PMI (from 61.61 % to 65.02 %), but deteriorated slightly for the three other measures. Again, as in the case of the intrinsic evaluation, the morphologically analyzed corpus yielded higher accuracy than the syntactically parsed corpus. 6.3.2 Machine translation As another method of extrinsic evaluation, we incorporated knowledge extracted from the verb dictionaries into a transfer-based MT system, and showed improved results. 5 Specifically, we used translation from Arabic to Hebrew (Shilon et al. 2010 , 2012b ); the system was developed in the framework of Stat-XFER (Lavie 2008 ), which facilitates the explicit expression of synchronous (extended) context-free transfer rules.

Prepositions are hard to translate, especially when they are required by their governing verb, since in such cases the choice of preposition tends to be arbitrary. In fact, the choice of preposition can vary among synonymous verbs even in the same language. Thus, Hebrew hkh  X  X  X it X  X  takes the accusative preposition at , whereas the synonymous hrbic  X  X  X it X  X  takes l  X  X  X o X  X . While Hebrew and Arabic are both Semitic languages, and several verbs and prepositions in the two languages are cognate, there is no clear mapping of subcategorization frames from one language to another. Clearly, then, prepositions cannot be translated literally, and the head that they modify, as well as the object of the preposition, have to be taken into account when a preposition is chosen to be generated.

We used the (PMI-induced) verb dictionary in a transfer-based MT system as follows. The system uses a morphological generator to generate inflected forms of lemmas obtained from a bilingual dictionary. Each such form is associated with a feature structure that describes some properties of the form (e.g., its gender, number and person). To the feature structures of verbs we added an additional feature, ALLOWED _ PREPS , whose value is the list of prepositions licensed by the verb, as determined by the verb dictionary. In this way, verbs were specified for the prepositions with which they are most likely to occur.

As the MT system is transfer-based, it allows the specification of synchronous languages. We thus implemented several transfer rules that map verb X  X omplement constructions between Arabic and Hebrew. When these rules are applied, they have access to (the surface form of) the actual preposition in the source and target phrases. To these rules we added constraints that only allow them to fire when the actual preposition is indeed licensed by the verb to which it is attached. For example, the rule that combines a verb with a PP in Arabic, to yield a verb phrase, is synchronized with a similar rule that combines a verb with a PP in Hebrew. We added a requirement that the actual preposition that heads the Hebrew PP be licensed by the Hebrew verb (as determined by the verb dictionary). See Shilon et al. ( 2012a ) for the details.

To evaluate the contribution of the verb dictionary, we created a test set of 300 sentences from newspaper texts, which were manually translated by three human translators. Of those, we selected short sentences (up to 10 words), for which the bilingual dictionary used by the system had full lexical coverage. This resulted in a set of 28 sentences (still with three reference translations each), which allowed us to focus on the actual contribution of the preposition-mapping solution rather than on other limitations of the MT system. (Unfortunately, evaluation on the entire test set of 300 sentences without accounting for full lexical coverage yields such poor translations that the comparison between different configurations of the system is meaningless.) As a baseline system, we used exactly the same setup, but withheld all the verb X  X reposition association knowledge. Table 15 lists the BLEU (Papineni et al. 2002 ) and METEOR (Denkowski and Lavie 2011 ) scores of both systems.
The system that incorporates linguistic knowledge on prepositions significantly ( p &lt; 0.05) outperformed the baseline system, as Table 15 shows. A detailed analysis of the obtained translations revealed that the baseline system generated prepositions that were not licensed by their head verb, and the language model failed to choose the hypothesis with the correct preposition, if such a hypothesis was generated at all. 7 Conclusions We presented an automatically-created verb dictionary of Hebrew, specifying the most likely complements to occur with each verb, along with a quantitative degree of the strength of the association between the complement and the verb. As it is extracted from a large corpus, the dictionary has wide coverage, and its accuracy is satisfying. It was proven beneficial for two natural language processing applica-tions, and we trust that is will be useful for various other purposes in the future.
This is a preliminary work. Specifically, it views each complement of a verb in isolation, and does not attempt to construct full subcategorization frames. While the current dictionary is still useful, in the future we would like to refine it by extending the verb X  X omplement relations to full, multi-complement subcategorization frames. We are also interested in developing methods for disambiguation: when a verb has more than one meaning, with different subcategorization frames, we would like to be able to obtain multiple frames from the the extraction procedure.

As more and more corpora become available, we plan to generate domain-and corpus-specific dictionaries, for more focused applications. We are particularly keen on developing such a dictionary for a corpus of spoken Hebrew that is currently being compiled (Nir et al. 2010 ; Albert et al. 2012 ). We would also like to extend the extracted relations to triplets, including also the noun that heads the object of the preposition. Such triplets can often indicate multi-word expressions, such as hbia b ? x X bwn  X  X  X rought in ? calculation ) consider X  X , or ymd yl dytw  X  X  X tood on his-mind ) insist X  X ; as such, they can be instrumental for the construction of a multi-word dictionary of Hebrew. We leave these directions for future research.
 References
 Abstract We present a verb X  X omplement dictionary of Modern Hebrew, auto-matically extracted from text corpora. Carefully examining a large set of examples, we defined ten types of verb complements that cover the vast majority of the occurrences of verb complements in the corpora. We explored several collocation measures as indicators of the strength of the association between the verb and its complement. We then used these measures to automatically extract verb comple-ments from corpora. The result is a wide-coverage, accurate dictionary that lists not only the likely complements for each verb, but also the likelihood of each com-plement. We evaluated the quality of the extracted dictionary both intrinsically and extrinsically. Intrinsically, we showed high precision and recall on randomly (but systematically) selected verbs. Extrinsically, we showed that using the extracted information is beneficial for two applications, prepositional phrase attachment disambiguation and Arabic-to-Hebrew machine translation.
 Keywords Verb subcategorization Hebrew Lexicography 1 Introduction The core of syntactic structure, according to most contemporary syntactic theories and for most languages, revolves around verbs and their complements. The relations between verbs and their complements are syntactic in nature, but they reflect semantic relations that hold between the action or state denoted by the verb, and the complement constructions to such semantic relations: understanding the syntactic relations between verbs and their complements is thus instrumental for understand-ing the meaning of natural language sentences. Correctly identifying verb complements in naturally-occurring texts is therefore important both theoretically, for linguistic investigations, and practically, for natural language processing (NLP) applications. A crucial resource needed for this task is a dictionary listing the number and types of complements that are most likely to occur with each verb, ideally with some statistical measure of the strength of the relation between the verb and each of its complements.
 The importance of such a resource must not be underestimated. Briscoe and Carroll ( 1993 ) observed that half of the errors made by a parser tested on unseen data were due to inaccurate subcategorization information in a manually-compiled dictionary. Briscoe and Carroll ( 1997 ) then described a novel way for extracting such a dictionary from corpora, and showed a small improvement in the accuracy of parsing. Carroll et al. ( 1998 ) repeated the same experiment, on a much larger scale, and demonstrated that the use of subcategorization frames can improve both precision and recall in the task of inducing bracketing on sentences, whereas for the task of assigning grammatical relations, precision improved by 9 % points (from 79 to 88 %), at the cost of only half a point drop in recall. A similar improvement is also observed when dependency parsers are concerned (Zeman 2002 ).

This problem holds for modern parsers, too. Kummerfeld et al. ( 2012 ), experimenting with a large number of English parsers, demonstrated that prepositional phrase (PP) attachment  X  X  X s the largest contributor to errors, across all parsers X  X . Kummerfeld et al. ( 2013 ) conducted a similar investigation of Chinese parsers, and revealed that the error types were quite different from the errors made by the English parsers. We experimented with the state-of-the-art Hebrew parser of Goldberg ( 2011 ); this is a dependency parser based on the EasyFirst parsing algorithm (Goldberg and Elhadad 2010 ), enhanced with morphology-based features which greatly improve its accuracy. It was trained on the Hebrew dependency treebank, which was automatically converted from a manually constructed constituent-structure treebank (Sima X  X n et al. 2001 ; Guthmann et al. 2009 ). Testing on 25 newspaper sentences containing 51 verb occurrences, the F-score of the parser on identifying the correct verb complements was below 0.85. Indeed, Goldberg ( 2011 ) specifically mentions (p. 93) that  X  X  X odes... which are assigned an incorrect head are predominantly PPs X  X  and that  X  X  X ll parsers have a hard time dealing with PP attachment. X  X 
Other applications that have been shown to benefit from information on subcategorization include automatic classification of verbs to semantic classes (Schulte im Walde and Brew 2002 ), information extraction (Surdeanu et al. 2003 ), machine translation (MT) (Hajic  X  et al. 2004 ) and more. Knowledge of verb subcategorization frames also affects human sentence processing (Garnsey et al. 1997 ), and a subcategorization dictionary is therefore highly useful for psycholin-guistic experimentation (Lapata et al. 2001 ; Baldewein 2004 ). We introduce the first automatically-created verb X  X omplement dictionary of Modern Hebrew, extracted from large text corpora. Using available resources, we morphologically analyzed and syntactically parsed the corpora. We employed standard collocation measures to assess the degree to which potential complements tend to combine with each verb, focusing on a small set of potential complement types, which covers the vast majority of complement instances in the corpora. More importantly, we did not attempt to construct full subcategorization frames; rather, we viewed each complement type in isolation, and determined its likelihood to combine with the verb. We also favored high-frequency complements that can be extracted with high precision, at the expense of potentially lower recall.
The result is a wide-coverage dictionary of almost 3,000 verb lemmas, listing more than 6,500 verb X  X omplement pairs, each with a statistically-derived score. We Intrinsically, we manually constructed a set of representative verbs and their canonical complements; our automatically-extracted dictionary achieves high precision and recall on this test set. Extrinsically, we incorporated linguistic knowledge derived from our verb X  X omplement dictionary in two computational tasks: reducing the ambiguity of PP-attachment and translating from Arabic to Hebrew. We demonstrated that knowledge derived from our dictionary is instrumental in significantly improving the accuracy of these two tasks. The contribution of this work is thus a digital, freely-available, wide-coverage and accurate verb X  X omplement dictionary of Hebrew.

After reviewing related work in the next section, we outline the structure of verb X  complement constructions in Hebrew in Sect. 3 . We describe the research methodology, as well as the required language resources, in Sect. 4 . The results are discussed in Sect. 5 , followed by an evaluation of their quality in Sect. 6 .We conclude with a discussion and suggestions for future research. 2 Related work The verb subcategorization frame (Chomsky 1965 ) determines the number and type of verb complements. Clearly, subcategorization frames are part of the syntax X  semantic interface (Levin 1993 ): they determine the syntactic structure of verb phrases, but they are typically shaped by the verb X  X  argument structure, reflecting the verb X  X  meaning. Indeed, subcategorization frames can be used to categorize verbs semantically (Sun et al. 2008a , b ; Sun and Korhonen 2009 ), and semantic knowledge can improve the extraction of subcategorization frames (Korhonen 2000 , 2002a ; Korhonen and Preiss 2003 ).

Syntactic theories tend to distinguish between complements and adjuncts . The former are phrases that are syntactically required by the verb; without them, verb phrases are incomplete. The latter are more general verb modifiers, that are typically optional, and may occur more than once with a given verb instance. Generally, there is a mapping of complements to verb arguments: the meanings of verb complements are considered crucial to understanding the meaning of a predicate, whereas other verb modifiers are less central semantically.

Clearly, the distinction between complements and adjuncts is vague (Huddleston and Pullum 2002 , Chapter 4, Section 1.2). There is overlap in the syntactic realization of both types of verb modifiers, and both are frequently realized as PPs. For example, the PP in I slept on the floor is considered an adjunct, whereas in I rely on you it is considered a complement. While in some cases there is a clear distinction between complements and adjuncts, the degree of relationship between a complements from adjuncts in many cases. Having said that, distnguishing between complements and adjuncts has been found useful for applications such as PP attachment (Merlo and Ferrer 2006 ), see Sect. 6.3.1 .

One of the first works to address automatic acquisition of subcategorization frames introduces the Lerner system (Brent 1991 , 1993 ). Lerner uses large un-annotated corpora and no dictionary, identifying English verbs through simple morphological cues. It focuses on six subcategorization frames using a simple, finite-state grammar of English. Complements include direct objects, clauses and infinitival verb phrases, but no PPs. Hypothesis testing, with binomial frequency data as the collocation measure, is used to determine whether a candidate is indeed a parameters can yield perfect recall at 50 % precision, and vice versa, on a set of 193 manually selected verbs; for clauses and infinitival verb phrases, accuracy is much higher.

The Lerner system was a pioneering work, and we follow its spirit by using hypothesis testing as the main tool for determining the statistical validity of a decision on a verb X  X omplement pair. We extended the scope of our study to more (ten) complement types, particularly PPs, and we experimented with several collocation measures. We also took advantage of the availability of morphologically analyzed and syntactically parsed corpora of Hebrew.

With the proliferation of language resources, contemporary approaches to subcategorization frame induction tend to use as many data sources as are available. For example, Sarkar and Zeman ( 2000 ), working on Czech, used the manually-constructed Prague Dependency Treebank for this task. Since word order in Czech is much freer than in English, complements are sought around the verb, and not just immediately following it. Induction was done iteratively: first, a wide subcatego-rization frame was assumed for each verb, with all elements that are dependent on the verb in the training material as candidate complements. Then, iteratively, the wide frame was replaced by proper subsets thereof, based on statistical consider-ations. Sarkar and Zeman ( 2000 ) employed three hypothesis testing measures, likelihood ratio, t test and binomial frequency, yielding three different subcatego-rization dictionaries. For each measure, candidate complements that did not pass the test were removed from the frame, until convergence.

Again, our method is very similar, but unlike Czech, Hebrew only has a very small treebank (see Sect. 4.2 ; the Hebrew treebank includes some 6,000 sentences, compared with over 115,000 for Czech). We also experimented with more than one collocation measure. Unlike Sarkar and Zeman ( 2000 ), we did not begin with the widest frame observed in a treebank (since our treebank is so small). Rather, we treated each potential complement independently of other complements, and only attempted to determine the strength of its own attachment to the verb. This approach is similar to the one used by De  X bowski ( 2009 ), who also collected single possible complements from a (Polish) corpus; however, De  X bowski ( 2009 ) also defined a second filtering step in which full frames are constructed.
 When a treebank is unavailable, automatically parsed data can be used instead. This is the main resource used by Briscoe and Carroll ( 1997 ), who inspired many subsequent works for Chinese (Han et al. 2004 ), English (Li and Brew 2005 ) French (Chesley and Salmon-alt 2006 ), Italian (Ienco et al. 2008 ), Portuguese (Zanette et al. 2012 ), and other languages. Again, the approach is to first assume a wide frame for each verb, sometimes based on existing, manually-created lexicons, and sometimes on assumed frames observed in the corpus. Then, a refinement step constrains the set of possible complements for each verb, based on the strength of the association between the verb and the candidate complement. Briscoe and Carroll ( 1997 ) used binomial frequency; Korhonen ( 2002b ) compared three different collocation measures [binomial frequency, log-likelihood ratio (LLR) and raw frequency (RF)], and showed that RF produces the best results.

Korhonen et al. ( 2006 ) extended the work of Korhonen ( 2002b ) to a full subcategorization dictionary of English verbs, called Valex . The dictionary includes not just the complements of each verb, but also the likelihood of their realization, as obtained from a large corpus. Each verb was associated with a subset of the full set of 163 subcategorization frame types, with an average of 33 frames per verb. A similar dictionary for French, LexSchem , was compiled by Messiant et al. ( 2008 ).
More recently, approaches based on topic modeling have been used to automat-ically induce lexical semantic information, in particular selectional preferences (Ritter et al. 2010 ;O  X  Se  X  aghdha, 2010 ). These are completely unsupervised methods, which may be useful for the task at hand, but are beyond the scope of this paper.
The only available information source on Hebrew subcategorization so far is the verb dictionary of Stern ( 1994 ), which includes 833 verbs and 1,430 subcatego-rization frames. While the information was manually collected from corpora of written and spoken language, news articles, literary texts, etc., being a manually compiled dictionary its coverage is obviously limited. For comparison, the MILA Hebrew computational lexicon (Itai and Wintner 2008 ) contains almost 5,000 verbs. The advantages of automatic extraction of verb subcategorization frames are obvious: not only does the method provide better coverage (at the expense of reduced precision, of course), but it also facilitates adaptation of the extracted dictionary to a specific genre, domain, register, etc. Furthermore, our approach provides probabilistic estimates of the likelihood of various complements, which may be more useful than the deterministic information listed in Stern ( 1994 ). 3 Hebrew verb subcategorization In light of the discussion in Sect. 2 , we refrained from making a clear distinction between complements and adjuncts in this work. Rather, we used a working definition whereby a particular type of modifier was considered part of the subcategorization frame of a verb if it frequently occured with the verb in text corpora. According to this definition, both argument-denoting complements and frequent adjuncts may be listed along with each verb. We did not include subjects in this investigation, as they are trivially required by all verbs.

Verbs can be ambiguous, with more than one subcategorization frame, often reflecting semantic variability. For example, when the verb 1 nicx takes a direct object, its meaning is  X  X  X in X  X ; when its complement is a PP headed by yl  X  X  X n X  X , its meaning is  X  X  X onduct, direct X  X . In this work we made no attempt to distinguish between the various meanings of ambiguous verbs. If our system inferred that the verb nicx is strongly associated both with a PP headed by yl  X  X  X n X  X  and with a direct object, then both were included in the complement dictionary for the verb.
Syntactically, we addressed four types of complements in this work: noun phrases, PPs, clauses and infinitival verb phrases. We now exemplify these complements and the way they are realized in text corpora. We discuss the various types of complements (Sect. 3.1 ), the number of complements (Sects. 3.2 , 3.3 ), and their order (Sect. 3.4 ). Finally, Sect. 3.5 provides some numerical data on the actual realization of verb complements in our corpora. 3.1 Types of complements In what follows, we use slanted font for natural language examples, bold face for the target verb and underline for the target complement. 3.1.1 Noun phrases Direct objects , clearly verb complements, are realized as noun phrases in Hebrew: must be introduced by an accusative marker, at , which we gloss as  X  X  X CC X  X . The accusative marker behaves like a typical preposition; in particular, it can combine with a pronominal enclitic: 3.1.2 Prepositional phrases Indirect objects, as well as several types of adverbials, are realized as PPs. 3.1.3 Clauses Several verbs take clausal complements. These are often introduced by the subordinating conjunctions ki  X  X  X hat X  X  and  X   X  X  X hat X  X : Clausal complements include also quoted speech and clauses introduced by relative/ interrogative pronouns and question words. 3.1.4 Infinitival verb phrases Sometimes, verbs take complements that are realized as verb phrases in the infinitive: 3.2 Number of complements The number of elements on a verb X  X  subcategorization list varies. Some verbs, traditionally known as intransitive , take no complements: We view such verbs as having empty subcategorization lists.

Other verbs take one, two or even three complements, as in the case of htyrb  X  X  X et X  X :
Sometimes, complements that have the same function can be realized in more than one way. This is common with cognitive verbs, which can have noun phrase, clausal, or verb phrase complements: Other verbs can only take one or two variants of these complements. For example, msr  X  X  X eport X  X  can take a clause or a noun phrase, but not a verb phrase; hxliT  X  X  X ecide X  X  can take a clause or a verb phrase, but not a noun phrase. Consequently, we view the three possible complements of cognitive verbs as different, and treat them independently of one another. 3.3 Internal complementation Certain verbs that are typically intransitive, with empty subcategorization frames, can sometimes be complemented by an object whose meaning is very close to the meaning of the verb (often, a nominalization of the verb itself). Such complements, known as internal objects , are not considered part of the verb X  X  subcategorization frame: Similar examples include rqd Tngw  X  X  X ance the tango X  X , xik xiwk rxb  X  X  X mile a wide smile X  X , mt mwwt  X qT  X  X  X ie a peaceful death X  X , etc. 3.4 Linear precedence inside the Hebrew verb phrase Hebrew constituent order is relatively free; in particular, verb complements and modifiers, including the subject, can both precede and succeed the verb (Belletti and Shlonsky 1995 ):
Having said that, sometimes the order is fixed, or there is a strong tendency towards a particular order. This is the case with idiomatic expressions, which tend to occur in a fixed order: Here, the alternative order would be awkward.

As in other languages (Ross 1967 ), a strong tendency towards a particular order can result from heaviness considerations; when one of the complements is a pronoun, for example, it strongly tends to precede a full noun phrase: Again, the two alternative orders are awkward. 3.5 Realization of verb complements in text corpora We listed above general, textbook properties of Hebrew verb subcategorization. Often, language use differs significantly from such generalizations. We therefore used text corpora to quantify some of these properties. Specifically, we used a treebank of 5,281 sentences (Sima X  X n et al. 2001 ), which include 1,423 verb types and 7,561 verb tokens, to which 9,486 complement tokens are attached (in this section, when the number of complements is mentioned, it refers to tokens, not types). Section 4.2 provides more detail about the treebank. The observations that we drew from the treebank drove the design of our subcategorization frame extraction algorithm (Sect. 4.1 ).

We first addressed the distance, in words, between the verb and (the first word of) its complements. Table 1 lists the data; as can be seen, the vast majority (87.46 %) of the complements follow the verb, and as many as 52.42 % of the complements immediately follow the verb. Consequently, we focused on complements that occur immediately after the verb in our extraction algorithm.

Next, we addressed the types of complements. The treebank includes 5,983 PPs that modify verbs, headed by as many as 129 preposition types. Table 2 lists the number of PP complements corresponding to the various prepositions in the treebank. The two most frequent prepositions, b  X  X  X n X  X  and l  X  X  X o X  X , account for more than half of the instances, and the top six prepositions account for almost 80 % of them. All other prepositions account for no more than 1 % of the complements each. Consequently, our algorithm focuses only on PPs headed by the six most frequent prepositions.

Noun phrases occur as verb complements in the treebank 2,207 times. Of these, 1,141 instances (51.7 %) are indefinite, and occur without the accusative marker. Consequently, we considered both bare noun phrases and noun phrases that were introduced by the accusative marker as potential complements.

Since in Hebrew the verb may precede the subject, some noun phrases that immediately follow verbs are in fact subjects. Of the 3,692 verb tokens in the treebank that have a subject, the subject immediately follows the verb in 476 instances (12.89 %). In order to filter out some of the noise introduced by subjects that immediately follow their verbs, we considered as complements only noun phrases that do not agree with the target verb in number, gender or person. Since in Hebrew the subject must agree with the verb, such candidates are obviously not subjects.

Turning now to clausal complements, we observed that of the 554 instances of such complements in the treebank, 281 (50.72 %) were introduced by  X   X  X  X hat X  X , whereas 273 (49.28 %) were introduced by ki  X  X  X hat X  X . We therefore addressed both of these subordinating conjunctions in our algorithm.

Table 3 summarizes the distribution of complement types in the treebank, listing only the types of complements we addressed in this work. Of the 9,486 complements in the corpus, the ones we addressed constitute 84.67 %.

Finally, we addressed the number of verb complements in the treebank. As is evident from Table 4 , the vast majority (93.61 %) of the verb occurrences in the treebank have at most one complement. Consequently, we focused on extracting each complement independently of other potential complements of the same verb.
 4 Methodological issues 4.1 Task definition In light of the observations of Sect. 3.5 , we defined our task as follows. First, we focused on ten types of complements only: (1 X 6) PPs with the six most frequent infinitival verb phrases; (9) clauses headed by  X   X  X  X hat X  X  and ki  X  X  X hat X  X ; and (10) the empty subcategorization frame, indicating that the verb phrase does not require a complement. Then, our goal was to associate each verb in a given Hebrew corpus with a measure of the strength of the association between the verb and each of the ten complements. We also defined a threshold such that only complements whose association strength exceeds the threshold were included in the dictionary.
Notice that this definition is somewhat different from the traditional definition of subcategorization frames; in particular, we have no way to distinguish between a subcategorization frame of two complements (e.g., hsbir  X  X  X xplain X  X , which subcategorizes for a noun phrase and a PP headed by l  X  X  X o X  X ) and two single-complement frames for a single verb. In light of Table 4 , however, this does not seem to be a major drawback, as very few verbs have more than one complement. 4.2 Resources We used the MILA corpus of written Modern Hebrew (Itai and Wintner 2008 ), consisting of newspaper articles, newswire items and parliament proceedings. The total number of tokens in the corpus is over 40 million, with 1.8 million verb tokens reflecting 4,358 verb lemmas.

The corpus is morphologically analyzed and disambiguated using the MILA tools (Itai and Wintner 2008 ). The current disambiguation module does not always fully resolve the ambiguity of some forms. For example, when two analyses differ only in the lemma, they remain ambiguous. This happens quite frequently with verbs, where two different analyses differ only in the pattern ( binyan ), as in x X bh , which can mean either  X  X  X he thought X  X  in one pattern or  X  X  X he calculated X  X  in another (this latter form is prefers certain patterns over others in order to fully resolve the ambiguity in such cases. We refer to this corpus as the morphologically analyzed corpus . Recently, two syntactic parsers have been made available for Hebrew, facilitating automatic computation of constituent-and dependency-structures (Goldberg 2011 ). We applied the dependency parser to the same corpus; we refer to the result as the syntactically parsed corpus .
 We also used the much smaller Hebrew Treebank (Sima X  X n et al. 2001 ; Guthmann et al. 2009 ). This is a set of 6,219 sentences from the HaAretz newspaper, which were manually parsed and then semi-automatically converted to a dependency representation (Goldberg and Elhadad 2009 ). The treebank lists three types of syntactic relations between the verb and its modifiers: OBJ ect, used for direct objects; COM plement, indicating other subcategorized complement; and DEP endency, used for adjuncts. We considered only the first two as complements. Of the 6,219 sentences we used only 5,281; we filtered out sentences with quoted speech, since verb dependents were not accurately indicated in such sentences. We divided this set into development and test subsets, as indicated in Table 5 . 4.3 Hypothesis testing We employed four different statistical measures to assess the strength of the association between a verb and its complement: RF, LLR, t test and pointwise mutual information (PMI).

Let v be a verb lemma 2 and c , c 0 be specific complements (of the ten complement types listed above). Given a corpus with N tokens, of which V are (possibly inflected forms of) verbs, we define the following counts: n v , c The number of occurrences of any inflected form of v in the corpus, with c as n v The number of occurrences of any inflected form of v in the corpus; i.e., n c The number of occurrences of verb complements in the corpus; i.e., n c = n : v ; c The number of occurrences of any inflected form of any verb other than v in n : v The number of occurrences of any inflected form of verbs other than v in the
Using maximum likelihood, we estimate: With these, we define:
Raw frequency The likelihood of a complement c to occur with a verb v . This is Log likelihood ratio Following Dunning ( 1993 ), we define LLR as where for all p , k , and n , T-score We use the adapted definition of Sarkar and Zeman ( 2000 ): where for all n , p , Pointwise mutual information Following Church and Hanks ( 1990 ), we define PMI as 4.4 Thresholds Each of the four association measures defined above provides a way to estimate the strength of the association between a verb and its complement. To determine whether this association is strong enough for the complement to be included in the dictionary, we needed to set thresholds for each measure; only complements whose association is higher than the threshold were considered part of the subcategori-zation frame of the verb.
 To set the threshold, we used the development part of the treebank described in Sect. 4.2 . For each collocation measure, independently, we searched for a threshold that maximized the F-score of the task of identifying the correct complements of verbs in the development set. We used an exhaustive search with finely separated thresholds (obtained by dividing the full range of values the test can yield into 100 evenly-spaced intervals), and obtained the following threshold values: for RF, 0.11; LLR, 544.17; PMI, 0.12; and for t -score, 0.12 ( t -score values are multiplied by 1,000 for readability).

In spite of the relatively small size of the development set, the accuracy is not highly sensitive to the precise value of the threshold. Figure 1 shows the F-score on the development set with respect to varying thresholds, for PMI and t -score. Clearly, significant changes in the value of the threshold (for PMI, from 0 to 0.75; for RF, from 0.05 to 0.2) result in minor changes to the F-score. The other measures are similarly robust.

We used these threshold values in the remainder of this work: whenever the association by a verb and a potential complement was higher than the threshold, the complement was considered a member of the subcategorization frame of the verb according to the specific measure. 5 Results 5.1 Extracting a verb dictionary from a morphologically analyzed corpus We applied the association measures defined in Sect. 4.3 , with the thresholds defined in Sect. 4.4 , to the entire morphologically analyzed corpus (Sect. 4.2 ). For each occurrence of a verb in the corpus, we considered the token that immediately follows the verb. As shown in Sect. 3.5 , most complements occur immediately after their head verb, so we restricted the search to this position. Furthermore, we only considered as candidates instances in which the token immediately following the verb is either (1) one of the six prepositions and two conjunctions we focus on, or (2) an infinitival verb, or (3) a noun phrase that either is preceded by the accusative marker, or does not agree with the verb in either number, gender, or person (to rule out potential subjects). In all other cases, we considered the empty subcategorization frame as a candidate.

We then computed the association between the verb and its candidate complement, according to each of the association measures defined in Sect. 4.3 If it was above the threshold, the candidate was considered a complement of the verb.
The result of this process is a large set of verb X  X omplement (V X  X ) pairs for each association measure; we refer to these sets as the verb dictionaries . Data on the four verb dictionaries extracted from the morphologically analyzed corpus are listed in Table 6 .

To exemplify the results, we now list some of the entries in the verb dictionary induced by PMI; as we will show below, PMI turns out to be a good association measure, providing not only wide coverage but also relatively high accuracy.  X  The verb tm  X  X  X xpire, be finished X  X  was correctly associated only with the empty  X  The verb amr  X  X  X ay X  X  was correctly associated with l  X  X  X o X  X  and with a clause. The  X  The verb hxliT  X  X  X ecide X  X  was a complete success: all and only the correct  X  The same applies to the verb pwnh  X  X  X e evacuated X  X , for which PPs with al  X  X  X o X  X ,  X  The verb nhr  X  X  X tream, flow X  X  was correctly associated with al  X  X  X o X  X , but also  X  The verb ndbq is ambiguous; it can mean  X  X  X tick X  X  (typically with l  X  X  X o X  X  or al
The complete verb dictionaries induced by each of the association measures, including numeric values reflecting the strength of the association, are available for download from the MILA website. 3 5.2 Extracting a verb dictionary from a syntactically parsed corpus We used the syntactically parsed corpus (Sect. 4.2) for the task of extracting verb complements. Recall that this is the corpus used above, but each sentence was parsed with the dependency parser of Goldberg ( 2011 ). The reported accuracy of the parser is approximately 80 %, so many errors can be expected.

For each verb occurrence in the corpus, we considered as potential complements all the phrases that depend on the verb with any of the three dependency labels: OBJ , COM and DEP . We considered the empty subcategorization frame as a candidate if none of the other complement types are dependent on the verb. We then used the same association measures as in Sect. 4.3 , and the same thresholds as in Sect. 4.4 ,to determine whether the candidate should be included in the dictionary entry of the verb.

Again, the result is a set of four verb dictionaries, one for each association measure. Data on the dictionaries are listed in Table 7 .

The main difference between the parsed corpus and the morphologically analyzed one is that the former facilitates a wider scope in which to search for complements, as it is not limited to complements occurring immediately after the verb. This improved recall but potentially harmed precision. This also prevented verbs in which the subject tends to immediately follow the verb (e.g., amr  X  X  X ay X  X ) from being wrongly associated with the empty frame. Indeed, using the parsed corpus, the algorithm decided to include a potential complement in the dictionary much more frequently than with the morphologically analyzed corpus, except for the empty frame, as can be seen in Table 8 . 6 Evaluation To assess the quality of the verb dictionaries discussed in Sect. 5 , we conducted experiments we used the verb X  X omplement dictionaries but ignored the strength of the association between the verb and its complements (as long as it was above threshold, of course.) 6.1 Intrinsic evaluation Our evaluation measure is F-score. Define: TP The number of extracted verb X  X omplement pairs that are indeed correct.
 TN The number of verb X  X omplement candidates that are not extracted, and are FP The number of extracted pairs that are not correct.
 FN The number of correct pairs that are not extracted.
 Then the precision is P = TP /( TP ? FP ), the recall is R = TP /( TP ? FN ), and the F-score is their harmonic mean, F = 2 9 P 9 R /( P ? R ).

In order to apply these measures, one needs to determine what is indeed  X  X  X orrect X  X . For this, we manually constructed the verb dictionaries of 58 verbs, with various subcategorization frames and frequencies. The verbs in the evaluation set were chosen randomly (and uniformly) according to their distribution in the entire corpus. Many of them are consequently highly frequent (e.g., amr  X  X  X ay X  X , 39,356 occurrences, hgiy  X  X  X rrive X  X , 16,818), while others are rarer (e.g., htrgz  X  X  X et angry X  X , 31 occurrences only, or crx  X  X  X cream X  X , 41). We asked two lexicographers to specify the complements of each verb in this list. The instructions given to the annotators were:
Determine whether the verb has a complement of the specific construction (e.g., a PP with the specific preposition). A subcategorized complement denotes an argument of the verb; its meaning is necessary for complete understanding of the meaning of the verb. Syntactically, a subcategorized complement can only occur once, and if it is omitted the verb phrase is conceived as incomplete.
 Several examples, both positive and negative, were also specified. Since we were concerned with 10 complement types and 58 verbs, there were 580 decisions to be made; the two annotators disagreed on 93 (16 %) of them. The annotators then discussed each manually annotated complements for 58 verbs, a subset of which is listed in Table 9 .
Table 10 shows the number of verb lemmas in the gold set that are associated with each of the ten complement types. Evidently, with the exception of ym  X  X  X ith X  X , all complement types are well represented in the gold set.

As a baseline, we performed the following experiment: we considered the syntactically parsed corpus as a gold standard, and viewed every verb X  X omplement included a sentence in which a complement c was annotated as a dependent of the verb v , and the dependency was labeled either OBJ or COM , we considered the pair v  X  c as correct. For each verb in the test set we thus obtained a list of complements, and compared it to the gold annotations exemplified in Table 9 . This yielded high recall at the expense of precision, of course. The baseline results on our test set are listed as the first row of Tables 11 and 12 .

We then used the morphologically analyzed corpus, and extracted, for each verb in the test set, the above-threshold candidates. Next we compared them to the gold annotations of Table 9 . The results are listed in Table 11 . We found that PMI is the best association measure, yielding both the highest recall and the second highest precision on this set. While recall is lower than the baseline, precision is much higher, resulting in a much higher F-score. T -score and RF both do well, while LLR is below the baseline.

We repeated the evaluation with the verb dictionaries that were extracted from the syntactically parsed corpus; the results are listed in Table 12 . Surprisingly, the F-score of the PMI dictionary does not improve. By contrast, all other measures actually improve somewhat, though PMI remains the best measure. Our conclusion is that the use of the syntactically parsed corpus does not contribute significantly to this task.
We also performed a weighted evaluation with the manual annotation, where the contribution of each verb in the gold set is proportional to the verb X  X  frequency in the corpus. The results are very similar, typically within 1 % point difference from the balanced evaluation results.

Our results clearly indicate that PMI is the best collocation measure for the task at hand. Other works that dealt with induction of verb valence and subcategorization frames promoted different collocation measures. For example, Korhonen et al. ( 2000 ) compared two methods for hypothesis testing, binomial hypothesis test and maximum likelihood to estimate probabilities. The latter performed best, and Korhonen et al. ( 2000 ) suggested as an explanation the Zipfian distribution of subcategorization frames. However, for many other tasks that involve the induction of collocations, PMI seems to be a preferred test (Chang et al. 2002 ; Villavicencio et al. 2007 ; Tsvetkov and Wintner 2010 , 2012 ), and Pecina ( 2005 ) actually advocated the combination of several collocation measures. We conclude that it is always important to experiment with more than one measure, as we do here.
 6.2 Error analysis The association measures we used reflect the frequency of the various complements as they immediately follow the verb. Sometimes this frequency is clear-cut. For example, 98 % of the occurrences of the verb tm  X  X  X xpire, be finished X  X  in the corpus are with the empty subcategorization frame; all the measures thus correctly associated this verb with the empty frame. Other verbs, however, do not behave as nicely. Consider amr  X  X  X ay X  X ; especially in the journalistic genre that constitutes a significant portion of our corpus, this verb tends to occur with a post-verbal subject (55 % of the instances). Our simplistic method considered such occurrences as instances of the empty subcate-gorization frame, and neglected to find the object, which is often pre-verbal.
The cause of many other errors is the lower frequency of the expected complement immediately after the verb. Consider the verb nhr  X  X  X tream, flow X  X , which should be complemented by l  X  X  X o X  X  or al  X  X  X o X  X . As mentioned above, many  X  X  X nstances X  X  of this verb are in fact mistagged instances of the noun nhr  X  X  X iver X  X . In addition, the subject of the verb frequently occurs post-verbally. Consequently, only 9 % of the instances of this verb in the corpus are immediately followed by the expected preposition.
Similarly, the verb aixl  X  X  X ish, congratulate X  X  takes two complements, a noun phrase and a l  X  X  X o X  X  PP, but in the typical order the PP precedes the noun phrase (possibly because the l  X  X  X o X  X  preposition typically combines with a pronoun, and thus is lighter). Consequently, our method found the preposition complement but not the noun phrase.

Another major source of errors is data sparsity. The verb htiiyc  X  X  X onsult X  X  occurs 219 times in the corpus. This frequency is sufficient for all the collocation measures to extract the complement ym  X  X  X ith X  X , but not to identify the less frequent, and typically second, complement yl  X  X  X bout X  X . The ambiguous verb mxh can either mean  X  X  X rotest X  X , in which case it takes yl  X  X  X n X  X ; or  X  X  X rase, wipe X  X , in which case it takes a noun phrase. The former meaning is far more frequent, and hence all association measures yielded the yl  X  X  X n X  X  complement, but none yielded the noun phrase.
For a more quantitative error analysis, refer to Table 13 , which depicts the accuracy of identifying the complements of verbs in the gold set, using the PMI dictionary extracted from the morphologically analyzed corpus, broken down by complement type.

The highest accuracy was obtained, not surprisingly, for noun phrase comple-ments, the most common complement type in our gold set. It is surprising, however, that the recall of identifying noun phrase complements is perfect; since we quite aggressively filtered out NP complements that agree with the verb, one would expect many such complements to be mistakenly filtered out, resulting in a lower recall. Evidently, this was not the case. Table 13 also shows that the empty frame is not identified accurately; this is consistent with the discussion above: often, unrelated PPs are mistaken to be complements, and data sparseness can cause actual complements not to be identified. 6.3 Extrinsic evaluation The intrinsic evaluation of Sect. 6.1 is necessarily limited to a small set of verbs. As a more robust evaluation, we used the automatically extracted dictionaries in two natural language processing tasks, and showed a significant improvement in the performance of those tasks.

It is worth noting that our verb X  X omplement dictionaries are extracted in a way that favors high-frequency data, whereby frequent complements are more likely to be recorded (at the expense of lower recall). For the two applications we discuss below, higher-precision frequent data most probably suffice for improving the performance, hence the gains we witness. 6.3.1 PP attachment First, we address the problem of PP attachment : in Hebrew, as in many other languages, PPs can be attached both to verbs and to nouns. Determining the correct attachment of PPs is challenging, and can significantly affect the accuracy of parsing (Lin 1998 ; Goldberg 2011 ). The task has attracted much interest, and several works attempt to address it, using pure statistical methods (Resnik and Hearst 1993 ; Hindle and Rooth 1993 ; Ratnaparkhi et al. 1994 ), or through approaches that incorporate additional linguistic knowledge (Wilks et al. 1985 ; Dahlgren and McDowell 1986 ; Jensen and Binot 1987 ; Hirst 1988 ). In particular, several works showed that information on verb subcategorization is beneficial for this task (Stetina and Nagao 1997 ; Yeh and Vilain 1998 ; Pantel and Lin 2000 ; Volk 2002 ). More specifically, Merlo and Ferrer ( 2006 ) argued that a distinction between complements and adjuncts is needed in order to properly attach PPs, and suggested a (supervised) machine-learning-based classification method for the task. They found that  X  X  X oth linguistic diagnostics of argumenthood and lexical semantic classes are useful. X  X 
Subcategorization information can indeed help determine the correct attachment: when a PP is a subcategorized complement of a verb, its occurrence is likely to be attached to the verb, rather than to some intervening noun. Consider the following examples (again, subcategorized complements are underlined): Both sentences involve a verb, followed by the noun r X iwnwt  X  X  X icenses X  X , followed by a PP with l  X  X  X o X  X . Since such a PP is subcategorized by the verb hrah  X  X  X how X  X , but not by nmca  X  X  X e found X  X , the PP is more likely to attach to the verb in the second example, but to the noun in the first example. This is indeed the correct attachment.
For evaluation, we used the test subset of the treebank (Sect. 4.2 ). We focused on constructions of the form verb X  X oun X  X reposition, allowing any number of words from other POS classes to intervene between the verb and the noun and between the noun and the preposition. The test set included 323 such constructions, with 204 different verbs. The task was to determine whether the preposition attaches to the verb or to the noun. 4
The baseline was obtained by always attaching the preposition to the noun. A better-informed baseline uses the syntactically parsed corpus as a gold standard, and considers each verb X  X omplement pair as correct (as in Sect. 6.1 ). This turns out to be worse than the na X   X  ve baseline, probably because the parser seems to have a clear preference toward attaching PPs to the verb (a tendency which we do not fully understand).

To improve upon the baselines we used information from the verb dictionaries, albeit in a very simplistic way: if the preposition was strongly associated with the verb (above the threshold), we attached it to the verb. We compared this decision with the correct attachment, as reflected by the treebank X  X  annotation.

The results, with each of the verb dictionaries corresponding to the four association measures, are listed in Table 14 . We report accuracy (Acc) , defined as ( TP ? TN )/( TP ? FP ? TN ? FN ), as well as error rate reduction (ERR) . Evidently, all the verb dictionaries are instrumental in this task; the best accuracy, obtained by t -score, is over 65 % (reflecting a reduction of almost 30 % of the errors compared with the baseline), but the PMI and RF dictionaries also reduce the error rate by more than 20 %. Implementing a voting mechanism among the four dictionaries did not improve the results. We also repeated this evaluation with the dictionaries that were extracted from the syntactically parsed corpus; accuracy improved for PMI (from 61.61 % to 65.02 %), but deteriorated slightly for the three other measures. Again, as in the case of the intrinsic evaluation, the morphologically analyzed corpus yielded higher accuracy than the syntactically parsed corpus. 6.3.2 Machine translation As another method of extrinsic evaluation, we incorporated knowledge extracted from the verb dictionaries into a transfer-based MT system, and showed improved results. 5 Specifically, we used translation from Arabic to Hebrew (Shilon et al. 2010 , 2012b ); the system was developed in the framework of Stat-XFER (Lavie 2008 ), which facilitates the explicit expression of synchronous (extended) context-free transfer rules.

Prepositions are hard to translate, especially when they are required by their governing verb, since in such cases the choice of preposition tends to be arbitrary. In fact, the choice of preposition can vary among synonymous verbs even in the same language. Thus, Hebrew hkh  X  X  X it X  X  takes the accusative preposition at , whereas the synonymous hrbic  X  X  X it X  X  takes l  X  X  X o X  X . While Hebrew and Arabic are both Semitic languages, and several verbs and prepositions in the two languages are cognate, there is no clear mapping of subcategorization frames from one language to another. Clearly, then, prepositions cannot be translated literally, and the head that they modify, as well as the object of the preposition, have to be taken into account when a preposition is chosen to be generated.

We used the (PMI-induced) verb dictionary in a transfer-based MT system as follows. The system uses a morphological generator to generate inflected forms of lemmas obtained from a bilingual dictionary. Each such form is associated with a feature structure that describes some properties of the form (e.g., its gender, number and person). To the feature structures of verbs we added an additional feature, ALLOWED _ PREPS , whose value is the list of prepositions licensed by the verb, as determined by the verb dictionary. In this way, verbs were specified for the prepositions with which they are most likely to occur.

As the MT system is transfer-based, it allows the specification of synchronous languages. We thus implemented several transfer rules that map verb X  X omplement constructions between Arabic and Hebrew. When these rules are applied, they have access to (the surface form of) the actual preposition in the source and target phrases. To these rules we added constraints that only allow them to fire when the actual preposition is indeed licensed by the verb to which it is attached. For example, the rule that combines a verb with a PP in Arabic, to yield a verb phrase, is synchronized with a similar rule that combines a verb with a PP in Hebrew. We added a requirement that the actual preposition that heads the Hebrew PP be licensed by the Hebrew verb (as determined by the verb dictionary). See Shilon et al. ( 2012a ) for the details.

To evaluate the contribution of the verb dictionary, we created a test set of 300 sentences from newspaper texts, which were manually translated by three human translators. Of those, we selected short sentences (up to 10 words), for which the bilingual dictionary used by the system had full lexical coverage. This resulted in a set of 28 sentences (still with three reference translations each), which allowed us to focus on the actual contribution of the preposition-mapping solution rather than on other limitations of the MT system. (Unfortunately, evaluation on the entire test set of 300 sentences without accounting for full lexical coverage yields such poor translations that the comparison between different configurations of the system is meaningless.) As a baseline system, we used exactly the same setup, but withheld all the verb X  X reposition association knowledge. Table 15 lists the BLEU (Papineni et al. 2002 ) and METEOR (Denkowski and Lavie 2011 ) scores of both systems.
The system that incorporates linguistic knowledge on prepositions significantly ( p &lt; 0.05) outperformed the baseline system, as Table 15 shows. A detailed analysis of the obtained translations revealed that the baseline system generated prepositions that were not licensed by their head verb, and the language model failed to choose the hypothesis with the correct preposition, if such a hypothesis was generated at all. 7 Conclusions We presented an automatically-created verb dictionary of Hebrew, specifying the most likely complements to occur with each verb, along with a quantitative degree of the strength of the association between the complement and the verb. As it is extracted from a large corpus, the dictionary has wide coverage, and its accuracy is satisfying. It was proven beneficial for two natural language processing applica-tions, and we trust that is will be useful for various other purposes in the future.
This is a preliminary work. Specifically, it views each complement of a verb in isolation, and does not attempt to construct full subcategorization frames. While the current dictionary is still useful, in the future we would like to refine it by extending the verb X  X omplement relations to full, multi-complement subcategorization frames. We are also interested in developing methods for disambiguation: when a verb has more than one meaning, with different subcategorization frames, we would like to be able to obtain multiple frames from the the extraction procedure.

As more and more corpora become available, we plan to generate domain-and corpus-specific dictionaries, for more focused applications. We are particularly keen on developing such a dictionary for a corpus of spoken Hebrew that is currently being compiled (Nir et al. 2010 ; Albert et al. 2012 ). We would also like to extend the extracted relations to triplets, including also the noun that heads the object of the preposition. Such triplets can often indicate multi-word expressions, such as hbia b ? x X bwn  X  X  X rought in ? calculation ) consider X  X , or ymd yl dytw  X  X  X tood on his-mind ) insist X  X ; as such, they can be instrumental for the construction of a multi-word dictionary of Hebrew. We leave these directions for future research.
 References
