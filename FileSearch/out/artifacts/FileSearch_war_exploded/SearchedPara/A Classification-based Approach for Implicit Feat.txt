 1 Introduction Nowadays, an increasing number of people are buying products on the web. Prod-uct reviews posted on the web can provide a lot of valuable information for those potential customers. At the same time, the product manufacturers can also obtain useful feedbacks about products from users. However, as the number of reviews that a product receives grows rapidly, sometimes the amount of comments of a product may exceed one thousand or even more, which makes it very hard for a potential customer to read all these reviews to obtain useful information. In order to auto-matically process and analyze reviews on the web, a lot of research efforts[4, 9, 5] have been done on opinion mining and sentiment analysis from the magnitude of reviews.
 tional orientation. Sentence-level sentiment analysis determines whether each sen-tence expressed a positive, negative, or neutral opinion, which is closely related to subjectivity classification[19, 21, 20] that distinguish subjective sentences with opinions from objective sentences. However, both document-level and sentence-level analysis can not discover what exactly people like or do not like, thus simply judging the sentiment orientation of a review unit fails to detect many significant details. In order to extract specific features and opinions from reviews, many researchers began to study the problem of finer-grained opinion mining, which is known as feature-level opinion mining[13, 4, 9, 5].
 Example 1.  X   X   X   X  U  X   X   X   X   X  d  X  k : B  X   X  U  X  x  X   X  x  X  '  X   X  (Very beautiful, there are plenty of functions that worth to buy, the price is a little expensive, really like the white color, the delivery is also very fast!) its corresponding aspect or feature. In product review mining, feature is usually the component or attribute of the product. Example 1 is a digital camera review about Nikon D90 . Explicit features such as  X   X  U  X  (function),  X  d  X   X  (price) and  X  x  X   X  (delivery) can be extracted from the above comment. Except for explicit feature, there is another significant kind of feature that doesn X  X  directly appear in the review sentences but can be deduced from the opinion word, which is known as implicit feature. In the above example review, the opinion word  X   X   X  (beautiful) has implied that the feature which the user talked about is the camera X  X   X  *  X  (exterior) although this feature doesn X  X  explicitly appear in the sentence. mainly focused on the problem of extracting product features and opinions that explicitly appeared. However, according to the observation, in our crawled Chinese reviews of five kinds of digit cameras, we statistically discover that at least 28 per-cent of the sentences are implicit sentences that imply implicit features, which is a considerable proportion.
 Our approach is very different from existing research works. The approach that former researches used is based on association rule mining. The core idea of this method is to use mined association rules to identify the implicit feature by finding the mapping of a specific feature for the opinion word. Although the association rule based approach is very useful and effective to identify the implicit feature for some kinds of opinion words that have relatively certain collocated features, for example, the opinion word  X  B  X   X  (cheap) is always used to describe the product X  X  feature  X  d  X   X  (price). But it fails to deal with many complex situations, for example, the opinion word  X   X   X (good) are often used to describe a lot of features, such as  X  &amp;  X   X  (signal),  X   X  4  X  (screen) and  X   X  fi  X  (camera), by using the mined rules it can only map the opinion word  X   X   X  (good) to a specific feature, which is not correct for many other different situations. By considering both the associated relation and the context of the opinion word, our classification-based approach is able to identify different implicit feature for the opinion word with different situations. duce some related works. The details of our proposed classification-based approach are introduced in section 3. In section 4, the experimental results are evaluated and discussed. our conclusion and future work are presented in section 5. 2 Related Work Opinion mining has been extensively studied by many researchers in recent years. Most of these researches have focused on two main research directions: one is senti-ment classification and the other direction is feature-based information extraction. Research efforts[10, 17, 11, 14] on sentiment classification deal with the task of clas-sifying each customer review as positive, negative or neutral. While feature-based opinion mining[4, 6, 5, 8] focused on the task of extracting opinions consisting of in-formation about features. In contrast to sentiment classification, opinion extraction aims at producing richer information and requires an in-depth analysis of reviews. The most representative researches in feature-level opinion mining are Hu and Liu X  X  works[4, 5, 9]. The conception of implicit feature was first mentioned in their papers based on the analysis of English reviews. In contrast to explicit feature that directly appears in review sentences, implicit feature is the feature that does not occur in the comment, but can be deduced from opinion words and contexts based on the understanding of human language.
 used to infer the implicit features [15]. They predefined a domain-specific feature set as candidate implicit features, and then take the mutual information approach to map a opinion indicator to a certain feature of the feature set. In [16], a clustering method was proposed to map implicit opinion words to their corresponding explicit features. They clustered product features and opinion words simultaneously and iteratively by fusing both their content information and association relation, and then construct the sentiment association set between the groups of features and opinion words by identifying their strongest n sentiment links.
 [opinion-word, explicit-feature] from review sentences based on the co-occurrence of the opinion-word and explicit-feature. Then they cluster the explicit features to generate more robust rules. When given a new opinion word with no explicit fea-ture, they searched a matched list of rules, among which the rule with the highest frequency weight is fired to map the opinion word to its identified implicit feature. In [18], they proposed a hybrid association rule mining approach for the task of im-plicit feature identification. Their approach used several complementary algorithms to mine as many association rules as possible. They firstly extract candidate feature indicators and then compute the co-occurrence degree between the candidate fea-ture indicators and the feature words. Each indicator and the corresponding feature word constitute a rule(feature indicator  X  feature word). They used such rules to identify implicit features. 3 Classification-based Approach In this section, we first illustrate the problem of implicit feature identification and present some definitions we have used in this paper. The framework of our proposed classification-based approach has also been presented. Then we explain the main steps of our approach in detail. In this paper, we focus on the feature-level opinion mining of product reviews. On the online shopping websites, such as Amazon or Taobao Marketplace, each product can receive a large number of customer reviews that have been posted by people who have bought this product. The set of products can be represented as R i = { r 1 , r 2 , r 3 , ..., r m } . The customer reviews can be regarded as text documents, although some of them may be very short and consisted of just a few sentences, but there are also many long reviews that can be as long as articles. Each review r j can may be consisted of several clauses s k = { c 1 , c 2 , c 3 , ..., c h } . Definition 1 implicit feature : A product feature f is defined as the whole product, service or the attribute or component of the product. If a feature f appears in review sentences, then it is defined as explicit feature . If f does not appear in review sentences, but it is implied, which means that people who read the review can understand what feature has been talked about, then this feature f is regarded as implicit feature .
 Definition 2 implicit sentence : Implicit sentence is a sentence in a review that contains at least one implicit feature. Explicit sentence is defined similarly, a sentence that contains at least one explicit feature is called explicit sentence . It should be noted that a implicit sentence can also be a explicit sentence.
 Definition 3 feature-opinion pair : A feature-opinion pair is consisted of a feature and an opinion word, and the opinion word is used to modify the feature. If opinion word and its modified feature co-occur in a sentence, then such feature-opinion pair is defined as the sentence X  X  explicit feature-opinion pair . The feature-opinion pair is denoted as &lt; f eature, opinion &gt; . of the approach and the introduction of the main steps, and then explain each step in details. As it has been shown in Fig. 1, it takes the corpus of customer reviews that have been crawled from the online shopping websties as input, and generates the opinion mining summary consisting of both explicit feature-opinion pairs and implicit feature-opinion pairs as the output.
 opinion pair extraction, feature-opinion pair training document construction and implicit feature identification. The detail of each step is described in the following subsections.
 There are many existing research works on feature-level opinion mining that are dedicated to extract explicit feature-opinion pairs from customer reviews. Some su-pervised learning models, such as HMM(Hidden Markov Model) model and CR-F(Conditional Random Fields) model, and topic models, such as the MaxEnt-LDA (a Maximum Entropy and LDA combination)[23] hybrid model, are widely used in this task. In this paper, we propose a rule based method to extract feature-opinion pairs from review sentences.
 extract feature-opinion pairs. Firstly, we use Chinese dependency grammar to set several rules. Then we make use of these rules to extract candidate feature-opinion pairs. In order to improve the precision of feature-opinion pair extraction, we con-struct the candidate feature word set CF and the candidate opinion word set CO for each product. Since adjectives are quite likely to be opinion words and nouns are likely to feature words, so we extract adjectives and nouns from review sentences, and consider adjectives as candidate opinion words and nouns as candidate feature words. In addition, we use a stopword list to filter many product-irrelevant adjectives and nouns from the candidate set CO and CF . Some frequently used non-adjective opinion words and non-noun feature words are also supplemented.
 we find that most of the discussed features are in subject-predicate(SBV) structure or DE ( X   X ) structure. Therefore, we mainly exploit the two kind of dependency relation as rules to extract feature-opinion pairs. According to our observation, when the feature word appears before the opinion word, the feature usually satisfy the SBV relation with the opinion word, and when the feature appears after the opinion word, there usually exist a DE structure between the feature and the opinion word. Based on the above observations, Three different rules have been defined to tackle different types of sentence structures to extract the explicit feature-opinion pairs. A summarized representation of these rules is presented in the following paragraphs. sbv ( w 1 , w 2 ), which means that word w 2 depends on word w 1 through SBV, if word w 2 belongs to the opinion word set CO and word w 1 belongs to the feature word set CF , then &lt; w 1 , w 2 &gt; can be extracted as feature-opinion pair.
 sbv ( w 1 , w 2 ), which means that word w 2 depends on word w 1 through SBV, if word w 1 belongs to the feature word set CF and word w 2 doesn X  X  belong to the opinion word set CO , and after word w 2 there is a word w 3 that belongs to the opinion word set CO , then &lt; w 1 , w 3 &gt; can be extracted as feature-opinion pair. opinion word set CO before the word  X   X  and a word w 2 belongs to the feature word set CF after the word  X   X , then &lt; w 2 , w 1 &gt; can be extracted as feature-opinion pair.
 word segmentation, part-of-speech(POS) tagging and dependency parsing to process the customer reviews. Based on the results of the preprocessing, it can be easy to judge whether a sentence satisfied a rule. If we regard each explicit sentence as a training text, then the topic or category of this sentence can be labeled as the sentence X  X  feature-opinion pair. For example, for the explicit sentence  X  x  X   X   X   X  @  X  e  X  e  X   X  x  X   X  (Delivering is very fast, order in the morning and have received in the afternoon!), the feature-opinion topic. If a sentence s k contains more than one feature-opinion pair ( F O k denotes the sentence s k  X  X  feature-opinion pair set), then the sentence can be classified into each feature-opinion pair topic of F O k .
 more one feature-opinion pair that contains the opinion word. For a feature-opinion pair &lt; f, o &gt; , it means that the opinion word o is used to describe the feature word f . In review sentences, a opinion word generally can be used to describe several different features. For example, the opinion word  X   X   X  (good) is often used to describe a lot of product features, such as  X   X   X   X (mobile phone),  X   X  4  X  (screen), or  X   X   X   X  (quality). In product reviews, many different feature words or phrases may be used to express the same feature. For example, features  X   X   X   X  (vocality quality),  X   X  W  X  (music) and  X   X   X  (sound effect) are all related to the same product feature  X  (  X   X  (vocality). So for each opinion word o , we cluster the feature-opinion pairs on the conceptual and semantical relation of these features F ( o ) = { f 1 , f 2 , ..., f n } . Our clustering method is based on [22], we mainly exploit the sharing words and the lexical similarity to cluster features. The size of the feature set F ( o ) is relatively small compared with the whole set of features F , so it is much easier and more effective to the clustering of feature-opinion pairs.
 document for each clustered feature-opinion pair. For each clustered feature-opinion pair, we collect the sentences that contain the feature-opinion pair into a document, which is labeled by the clustered feature-opinion pair. The document constructing process is presented in algorithm 2. By constructing the feature-opinion pair training set, the problem of identifying implicit features can be formulated into a text classification problem. Thus many existing text classification approaches can be used to solve this problem. In this step, we mainly deal with the implicit sentences. For each implicit sentence I s k , the set identification is to find the implicit feature f i for each opinion word o i in I o . The set of clustered feature-opinion pair that contains opinion word o i can be denoted as to find the feature f c i that the opinion word o i in implicit sentence I s k has modified regarded as the sentence X  X  topic or category, thus the problem of finding the implicit feature f c i for opinion word o i in implicit sentence I s k has been transformed into a text classification problem.
 classifier based on [2]. We modify the centroid construction and classification process to accommodate the situation in this problem.
 proaches in [2] that uses all the words in the corpse to form the lexicon set, we use on-ly a small set of feature-related discriminative words in the training set to construct the lexicon set. For instance, considering the collected training set of feature-opinion in this topic, while only a very small number of words contribute to the feature space of this topic, such as word  X   X   X   X  (speed),  X  e  X   X  (order) and so on. Many other with a very high frequency, hardly have any discrimination for this topic. More-over, such irrelevant words could bring on a lot of noise in the representation of the topic. Therefore, in the construction of the lexicon set, we only consider nouns, adjectives and verbs in the training set, and we also construct a filter word set to remove the stop words and irrelevant words. The constructed lexicon set is denoted sented by a word vector Centroid j = { wf 1 j , wf 2 j , ..., wf Lj } , where wf kj (1  X  k  X  L ) represents the weight for word wf k .
 calculation of the weight for word wf k . The weight for word wf k of topic &lt; f j , o j &gt; is calculated as following: where f w given opinion word o j , | CF w contains the word w k . When a word w k occurs in every feature-opinion topic, the value of wf kj is 0 because log( | C | discrimination for the topic. Thus our weight calculation method can produce more discriminative features for the feature-opinion topic.
 plicit sentence is classified by using a denormalized cosine measure: where  X  X  X  s i is the word vector representation for the implicit sentence I s k , since the sentence is usually very short, so we only concern the word X  X  appearance or not. We use the binary representation to denote the word X  X  weight in  X  X  X  s i . By using this denor-malized cosine measure, it preserves the discriminative capability of feature-opinion pair topic X  X  centroid vector. Since the size of the vector space here is relatively small, so the denormalized measure can be more discriminative for the classification. 4 Experiments In this section, we conducted several experiments and evaluate the performance of our approach. Firstly, we describe the data sets used in our experiments. Then we give the definition of several performance metrics. Lastly, experiment results and corresponding analysis are described. Both the results of explicit feature-opinion pair extraction and implicit feature identification have been evaluated. Since there is no standard data set for our experiment, so we crawled the experiment data from the popular Chinese shopping website, Amazon.cn 1 , the regional website of Amazon.com in China. Customer reviews are collected from two different domains: cell phone and digital camera. There are totally 4083 reviews and 12760 sentences in our data set. Both the explicit feature-opinion pair and implicit feature-opinion pair of each sentence are manually annotated by two research students in our lab. To be fair, those sentences that are annotated inconsistently have been removed and the rest has been confirmed by the author. The details of the data sets are given in Table 1.
 to evaluate our experiment results of both explicit feature-opinion pair extraction and implicit feature identification. The F-measure is defined as follows: An important step of our approach is to extract the explicit feature-opinion pairs from explicit sentences. The construction of the training document is based on the result of the extracted explicit feature-opinion pairs. In this paper, we use LTP 2 to accomplish the Chinese word segmentation, part-of-speech(POS) tagging and dependency parsing.
 rule based method. As we can see from the table, our rule based method achieves a comparatively satisfactory result in the extraction of feature-opinion pairs. In the construction of the candidate feature word set CF and the candidate opinion word set CO for each product, we consider nouns as candidate features and adjectives as candidate opinion words, and also add some verbs to complement the candidate word set. For example, the verb  X  x  X   X  (deliver) is frequently used as feature and the verb  X  U  X   X  (like) is frequently used as opinion word in customer reviews. A filter word list was constructed to remove many product-irrelevant nouns and adjectives from the candidate set, such as  X  * l  X  (friends),  X   X  %  X  (sad) and so on. In the end, we give the final experimental results via using our proposed classification-based approach. Our classification-based approach is compare with the rule based approach coAR[3]. We implement the approach coAR proposed in [3]. The best results for each approach is listed in Table 3. co-occurrence of opinion word and feature word, and then used the clustered rules to identify the implicit feature for a given opinion word.
 evaluation metrics for corpora in both cell phone data set and digital camera data set. Co-AR used the mined association rules from the review corpus to identify the implicit feature for the given opinion word by rule matching, which means that their approach always map the opinion word to the same feature word without considering the context of the implicit sentence. While our classification-based approach not only exploit the association relations by extracting explicit feature-opinion pairs, but also take into account the context of the implicit sentence by using the category-feature-centroid classifier to map the opinion word in a specific implicit sentence to the most probable feature word. Thus our approach X  X  precision is higher than coAR. In addition, our approach X  X  recall is also higher than the coAR approach. This is because that the rule based coAR approach only adopted the association rules whose weight is greater than the threshold as robust rules. The higher threshold can weed out the lower-frequency association rules and promote the precision, but it would reduce the recall. No matter what threshold is selected, it can not capture a significant number of uncommon association rules. This shortcoming of the rule based approach determines that the recall of coAR is limited to a certain extent. 5 Conclusion and Feature Work In this paper, we propose a novel classification-based approach to deal with the problem of implicit feature identification. By constructing the document for the clustered feature-opinion pair, the training document that has been labeled by the specific clustered feature-opinion pair can be obtained. Then the problem of implicit feature identification has been formulated into a text classification problem. A rule based method has been proposed to extract explicit feature-opinion pairs from cus-tomer reviews. In the phase of implicit feature identification, a topic-feature-centroid classifier has been designed to perform the classification task. It should be pointed out that other feature-opinion pair extraction methods and text classification meth-ods can also be used in our approach. Compared with the rule based approach coAR, our approach overcomes the shortcomings and limitations of the rule based approach and achieves a much better performance on all the measure metrics. However, some undesirable errors still exist in the result of implicit feature identification. Some are caused by the incorrect classification, some are caused by the wrong identification of implicit feature indicators. In our future work, we will explore the performance of approach by using several other text classification approaches in the implicit feature identification step.
 References
