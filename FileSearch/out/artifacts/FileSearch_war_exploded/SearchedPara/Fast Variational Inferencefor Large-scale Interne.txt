 Internet content providers, such as MSN, Google and Yahoo, all depend on the correct functioning of the wide-area Internet to communicate with their users and provide their services. When these content providers lose network connectivity with some of their users, it is critical that they quickly resolve the problem, even if the failure lies out side their own wide-area Internet infrastructure and the causes of user request failures. Requests may f ail because of problems in the content provider X  X  systems or faults in the network inf rastructure anywhere between the user and the content provider, including routers, proxies, firewalls , and DNS servers. Other failing requests may be due to denial of service attacks or bugs in the user X  X  software. To compound the diagnosis problem, these faults may be int ermittent: we must use probabilistic inference to perform diagnosis, rather than using logi c. A second challenge is the scale involved. Not only do popular Internet content provi ders receive billions of HTTP requests a week, but the number of potential causes of fail ure are numerous. Counting only the coarse-grained Autonomous Systems (ASes) through which users receive Internet connectivity, there are over 20k potential causes of failure. In this paper, we show that approximate Bayesian inference scales to handle this high rate of observations and accurately estimates the underlying failure rates of such a larg e number of potential causes of failure.
 To scale Bayesian inference to Internet-sized problems, we must make several simpl ifying approximations. First, we introduce a bipartite graphical model using overla pping noisy-ORs, to model the interactions between faults and observations. Second, we use mean-field variational inference to map the diagnosis problem to a reasonably-sized optim ization problem. Third, we further approximate the integral in the variational method. Fourth, we speed up the optimization problem using stochastic gradient descent.
 The paper is structured as follows: Section 1.1 discusses related work to this pap er. We describe the graphical model in Section 2, and the approximate inference in that model in Section 2.1, including stochastic gradient descent (in Section 3). We present infer ence results on synthetic and real data in Section 4 and then draw conclusions. 1.1 Previous Work The original application of Bayesian diagnosis was medicine. One of the origina l diagno-sis network was QMR-DT [14], a bipartite graphical model that used noisy-OR to mo del symptoms given diseases. Exact inference in such networks is intractable (expo nential in the number of positive symptoms,[2]), so different approximation and sampl ing algorithms were proposed. Shwe and Cooper proposed likelihood-weighted sampling [13], while J aakkola and Jordan proposed using a variational approximation to unlink each input to t he net-work [3]. With only thousands of possible symptoms and hundreds of diseases, QMR -DT was considered very challenging.
 More recently, researchers have applied Bayesian techniques for the diagnosis of co mputers and networks [1][12][16]. This work has tended to avoid inference in large netw orks, due to speed constraints. In contrast, we attack the enormous inference problem directly . The initial graphical model for diagnosis is shown in Figure 1. Starting at t he bottom, we observe a large number of binary random variables, each corresponding to the success /failure of a single HTTP request. The failure of an HTTP request can be modeled as a nois y-OR [11] of a set of Bernoulli-distributed binary variables, each of which models the underlyi ng factors that can cause a request to fail: where r ij is the probability that the observation is a failure if a single underlying faul t d ij is present. The matrix r ij is typically very sparse, because there are only a small number of possible causes for the failure of any request. The r i 0 parameter models the probability of a spontaneous failure without any known cause. The r ij are set by elicitation of probabilities from an expert.
 The noisy-OR models the causal structure in the network, and its connections are derivabl e from the metadata associated with the HTTP request. For example, a single req uest can fail Figure 2: Graphical model after integrating out instantaneous faults: a bipart ite noisy-OR network with Beta distributions as hidden variables because its server has failed, or because a misconfigured or overloaded router can cause a n AS to lose connectivity to the content provider, or because the user agent is not compa tible with the service. All of these underlying causes are modeled independently for each request, because possible faults in the system can be intermittent.
 Each of the Bernoulli variables D ij depends on an underlying continuous fault rate variable F j  X  [0 , 1]: where  X  j is the probability of a fault manifesting at any time. We model the F j as inde-pendent Beta distributions, one for each fault: where B is the beta function. The fan-out for each of these fault rates can be different: some of these fault rates are connected to many observations, while less common ones are connected to fewer.
 Our goal is to model the posterior distribution P ( ~ F | ~ V ) in order to identify hidden faults and track them through time. The existence of the D ij random variable is a nuisance. We not interesting. Fortunately, we can exactly integrate out these nuisance vari ables, because they are connected to only one observation thru a noisy-OR.
 After integrating out the D ij , the graphical model is shown in Figure 2. The model is now completely analogous to the QMR-DT mode [14], but instead of the noisy-OR combining binary random variables, they combine rate variables: One can view (4) as a generalization of a noisy-OR to continuous [0 , 1] variables. 2.1 Approximations to make inference tractable simple, robust approximate inference algorithm: mean-field variational inference [4 ]. Mean-For inferring fault rates, we choose to approximate P with a product of beta distributions Mean-field variational inference maximizes a lower bound on the evidence of the model: This integral can be broken into two terms: a cross-entropy between the approx imate pos-terior and the prior, and an expected log-likelihood of the observations: The first integral is the negative of a sum of cross-entropies between Beta distri butions with a closed form: where  X  is the digamma function.
 However, the expected log likelihood of a noisy-OR integrated over a product of Beta dis-tributions does not have an analytic form. Therefore, we employ the MF(0) approx imation of Ng and Jordan [9], replacing the expectation of the log likelihood with the log likelihood of the expectation. The second term then becomes the sum of a set of log likelihoods, one per observation: For the Internet diagnosis case, the MF(0) approximation is reasonable: we exp ect the posterior distribution to be concentrated around its mean, due to the large amo unt of data that is available. Ng and Jordan [9] have have proved accuracy bounds for MF(0) ba sed on the number of parents that an observation has.
 The final cost function for a minimization routine then becomes In order to apply unconstrained optimization algorithms to minimize (10), we need transform the variables: only positive  X  j and  X  j are valid, so we parameterize them by and the gradient computation becomes with a similar gradient for b j . Note that this gradient computation can be quite computa-tionally expensive, given that i sums over all of the observations.
 For Internet diagnosis, we can decompose the observation stream into blocks , where the size of the block is determined by how quickly the underlying rates of faults change, and how finely we want to sample those rates. We typically use blocks of 100,000 obs ervations, which can make the computation of the gradient expensive. Further, we repeat the inference ov er and over again, on thousands of blocks of data: we prefer a fast optimization pr ocedure over a highly accurate one.
 Therefore, we investigated the use of stochastic gradient descent for optimizi ng the vari-ational cost function. Stochastic gradient descent approximates the full gradient with a Algorithm 1 Variational Gradient Descent Require: Noisy-OR parameters r ij , priors  X  0 j , X  0 j , observations V i Initialize a j = log(  X  0 j ) ,b j = log(  X  0 j )
Initialize y i ,z j to 0 for k = 1 to number of epochs do end for single term from the gradient: the state of the optimization is updated using that single term [5]. This enables the system to converge quickly to an approximate answer . The details of stochastic gradient descent are shown in Algorithm 1.
 Estimating the sum in equation (12) with a single term adds a tremendous amount of noise to the estimates. For example, the sign of a single L ( V i ) gradient term depends only on the sign of V i . In order to reduce the noise in the estimate, we use momentum [15]: we exponentially smooth the gradient with a first-order filter before applying it t o the state variables. This momentum modification is shown in Algorithm 1. We typicall y use a large step size (  X  = 0 . 1) and momentum term (  X  = 0 . 99), in order to both react quickly to changes in the fault rate and to smooth out noise.
 Stochastic gradient descent can be used as a purely on-line method (where each data poin t is seen only once), setting the  X  X umber of epochs X  in Algorithm 1 to 1. Alternati vely, it can get higher accuracy if it is allowed to sweep through the data multiple times. 3.1 Other possible approaches We considered and tested several other approaches to solving the approximate inference problem.
 Jaakkola and Jordan propose a variational inference method for bipartite no isy-OR net-works [3], where one variational parameter is introduced to unlink one observat ion from the network. We typically have far more observations than possible faults : this previous approach would have forced us to solve very large optimization problems (wi th 100,000 pa-rameters). Instead, we solve an optimization that has dimension equal to the n umber of faults.
 We originally optimized the variational cost function (10) with both BF GS and the trust-region algorithm in the Matlab optimization toolbox. This turned out to be far worse than stochastic gradient descent. We found that a C# implementation of L-BFGS, as des cribed in Nocedal and Wright [10] sped up the exact optimization by orders of magnitude. We report on the L-BFGS performance, below: it is within 4x the speed of the stochastic gradient descent. We experimented with Metropolis-Hastings to sample from the posterior , using a Gaussian random walk in ( a j ,b j ). We found that the burn-in time was very long. Also, each update is slow, because the speed of a single update depends on the fan-out of each fault. In t he Internet diagnosis network, the fan-out is quite high (because a single fault affect s many observations). Thus, Metropolis-Hastings was far slower than variat ional inference. We did not try loopy belief propagation [8], nor expectation propagation [ 6]. Because the Beta distribution is not conjugate to the noisy OR, the messages passed by either al gorithm do not have a closed form.
 Finally, we did not try the idea of learning to predict the posterior from the obser vations by sampling from the generative model and learning the reverse mapping [7]. For In ternet diagnosis, we do not know the structure of graphical model for a block of data ahead of time: the structure depends on the metadata for the requests in the log. Thus, we cannot amortize the learning time of a predictive model. We test the approximations and optimization methods used for Internet diagnosis on both synthetic and real data. 4.1 Synthetic data with known hidden state Testing the accuracy of approximate inference is very difficult, because, for large gra phical models, the true posterior distribution is intractable. However, we can prob e the reliability of the model on a synthetic data set.
 We start by generating fault rates from a prior (here, 2000 faults drawn fro m Beta(5e-3,1)). We randomly generate connections from faults to observations, with pro bability 5  X  10  X  3 . Each connection has a strength r ij drawn randomly from [0 , 1]. We generate 100,000 observations from the noisy-OR model (4). Given these observations, we predict an approximate posterior.
 Given that the number of observations is much larger than the number of faults, we expect that the posterior distribution should tightly cluster around the rate that g enerated the observations. Difference between the true rate and the mean of the approximate pos terior should reflect inaccuracies in the estimation. Figure 3: The error in estimate of rate versus true underlying rate. Black dot s are L-BFGS, Red dots are Stochastic Gradient Descent with 20 epochs.
 The results for a run is shown in Figure 3. The figure shows that the errors in the estimate are small enough to be very useful for understanding network errors. There is a slig ht systematic bias in the stochastic gradient descent, as compared to L-BFGS. Ho wever, the improvement in speed shown in Table 1 is worth the loss of accuracy: we need inference to be as fast as possible to scale to billions of samples. The run times are f or a uniprocessor Pentium 4, 3 GHz, with code in C#.
 4.2 Real data from web server logs We then tested the algorithm on real data from a major web service. Each observ ation consists of a success or failure of a single HTTP request. We selected 18848 pos sible faults that occur frequently in the dataset, including the web server that received the request, which autonomous system that originated the request, and which  X  X ser agent X  (bro wer or robot) generated the request.
 We have been analyzing HTTP logs collected over several months with the stochas tic gra-dient descent algorithm. In this paper, we present an analysis of a short 2.5 hour window containing an anomalously high rate of failures, in order to demonstrate tha t our algo-rithm can help us understand the cause of failures based on observations in a real-worl d environment.
 We broke the time series of observations into blocks of 100,000 observat ions, and inferred the hidden rates for each block. The initial state of the optimizer was set to be the state of the optimizer at convergence of the previous block. Thus, for stochastic gradien t descent, the momentum variables were carried forward from block to block. Figure 4: The inferred fault rate for two Autonomous Systems, as a function of time. These are the only two faults with high rate.
 The results of this tracking experiment are shown in Figure 4. In this figure, w e used stochastic gradient descent and a Beta(0.1,100) prior. The figure shows the onl y two faults whose probability went higher than 0.1 in this time interval: they correspond t o two ASes in the same city, both causing failures at roughly the same time. This could be due t o a router that is in common between them, or perhaps an denial of service attack that origi nated in that city.
 The speed of the analysis is much faster than real time. For a data set of 10 mi llion samples, L-BFGS required 209 CPU seconds, while SGD (with 3 passes of data per blo ck) only required 51 seconds. This allows us to go through logs containing billions o f entries in a matter of hours. This paper presents high-speed variational inference to diagnose problems on the scale of the Internet. Given observations at a web server, the diagnosis can determine whether a web server needs rebooting, whether part of the Internet is broken, or whether the web server is compatible with a browser or user agent.
 In order to scale inference up to Internet-sized diagnosis problems, we make several a p-proximations. First, we use mean-field variational inference to approximate t he posterior distribution. The expected log likelihood inside of the variational cost functio n is approxi-mated with the MF(0) approximation. Finally, we use stochastic gradien t descent to perform the variational optimization.
 We are currently using variational stochastic gradient descent to analyze lo gs that contain billions of requests. We are not aware of any other applications of variati onal inference at this scale. Future publications will include conclusions of such analysis, and implica tions for web services and the Internet at large.
 [1] M. Chen, A. X. Zheng, J. Lloyd, M. I. Jordan, and E. Brewer. Failure diagnosi s using [2] D. Heckerman. A tractable inference algorithm for diagnosing multiple disea ses. In [3] T. Jaakkola and M. Jordan. Variational probabilistic inference and the QM R-DT [4] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. K. Saul. An introducti on to [5] H. J. Kushner and G. G. Yin. Stochastic Approximation and Recursive Algorithms and [6] T. P. Minka. Expectation propagation for approximate bayesian infer ence. In Proc. [7] Q. Morris. Recognition networks for approximate inference in BN20 networ ks. In Proc. [8] K. P. Murphy, Y. Weiss, and M. I. Jordan. Loopy belief propagation for a pproximate [9] A. Y. Ng and M. Jordan. Approximate inference algorithms for two-layer ba yesian [10] J. Nocedal and S. J. Wright. Numerical Optimization . Springer, 2nd edition, 2006. [11] J. Pearl. Probabilistic Reasoning In Intelligent Systems: Networks of Plausible Infer-[12] I. Rish, M. Brodie, and S. Ma. Accuracy vs. efficiency tradeoffs in probabilistic diag-[13] M. A. Shwe and G. F. Cooper. An empirical analysis of likelihood-weigh ting simulation [14] M. A. Shwe, B. Middleton, D. E. Heckerman, M. Henrion, E. J. Horvitz, H. P . Lehmann, [15] J. J. Shynk and S. Roy. The LMS algorithm with momentum updating. In Proc. Intl. [16] M. Steinder and A. Sethi. End-to-end service failure diagnosis using belief networks .
