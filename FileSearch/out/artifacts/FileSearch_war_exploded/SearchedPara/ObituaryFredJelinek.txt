 University of Pennsylvania
Frederick Jelinek died, peacefully and unexpectedly, on 14 September 2010. Over a distinguished career of nearly fifty years, Fred made important contributions in areas ranging from coding theory and speech recognition to parsing and machine translation.
But more important than these specific contributions was his role in persuading the fields of speech and language engineering to adopt statistical methods and the  X  X oisy channel model, X  returning to the path opened up by Claude Shannon in 1948. And more important still was the role that he played in defining, exemplifying, and promoting what has become the standard research paradigm in an even wider range of fields: the competitive evaluation of alternative algorithms based on precise quantitative criteria defined in advance, relative to a shared body of training and testing material. After receiving his Ph.D. from MIT in 1962, Fred taught at Cornell from 1962 to 1972, worked at IBM from 1972 to 1993, and taught at Johns Hopkins from 1993 to 2010. Fred X  X  many technical accomplishments during this long and productive career can be seen as episodes in two epic narratives, which, like the Iliad and the Odyssey , are related but have separate themes and story lines. The theme of the first epic is the return of Information Theory to center stage in speech and language processing; and the theme of the second epic is the development of a new relationship between science and engineering in speech recognition, computational linguistics, and artificial intelligence (AI) more generally.
 Fred gave us a vivid first-person narrative of the first of these epic adventures in his
ACL Lifetime Achievement Award speech (Jelinek 2009). But missing from this recital is a picture of the dire state of the information-theoretic forces when Fred joined the fray by undertaking speech recognition research at IBM in 1972. To understand what the world was like then, we need to go back to the mid 1950s.
 Claude Shannon (1956, page 3) wrote: Ironically, the seeds of that overnight collapse were at that very moment being sown by a young linguist with a fresh Ph.D. from Penn, whose lecture notes for an MIT undergraduate course were being prepared for publication in the Netherlands. Noam Chomsky X  X  (1957, page 16) opus Syntactic Structure s famously argued that
Although this assertion was not further justified X  X nd would later be shown to be false as a general indictment of  X  X ny statistical model for grammaticalness X  (e.g., in
Pereira 2000) X  X t plausibly and effectively undermined the value of empirical n -gram approximations as models of natural-language syntax. And more importantly, Syn-tactic Structures pointed the way to larger issues in mathematical and computational linguistics, whose exploration occupied many productive years of research over the next several decades. At the same time, AI researchers were promoting the view that intelligence should be seen as a matter of applied logic, with everything from perceptual classification and motor planning to chess playing and conversational interaction being modeled as particular kinds of theorem proving.

As a result, by the time that Fred Jelinek went to IBM in 1972 to work on speech recognition, the Information Theory bandwagon of the 1950s was lying forgotten in a ditch, at least as far as applications in speech and language processing were concerned.
One personal memory may help to make this point to those who didn X  X  live through the period.

In the 1980s, Ken Church was one of the heroes fighting effectively for corpus-trained statistical methods in computational linguistics. But in the late 1970s, when I first met him, Ken embodied a very different set of attitudes. He was working on an MIT dissertation applying context-free parsing to phonotactic speech recognition, assuming a non-stochastic grammar. I was curious about the redundancy of phonotactics in general, and also felt that a stochastic phonotactic grammar would do a better job, so I suggested that Ken should find or create a collection of phonetic transcriptions, and use it to associate probabilities with his rewrite rules. Ken X  X  response was to quote Richard Nixon X  X  remark about Daniel Ellsberg:  X  X e could kill him X  X ut that would be wrong. X 
Further discussion elicited a quote from one of his AI lab professors:  X  X f you need to count higher than one, you X  X e made a mistake. X  The partisans of what John Bridle has called the  X  X ybernetic underground, X  with
Fred Jelinek as one of their most important leaders, soon taught Ken and others of his generation why it is a good idea to count higher than one, to use the counts to estimate the parameters of statistical models, and to use those models to resolve ambiguity.
Fred X  X  success in this struggle was tied to the second epic adventure in which he played a role. And again, the stage for this second story was set while he was working on information theory at Cornell.

It started in the 1960s with two interventions by John R. Pierce, then a high-ranking executive in the research area at Bell Laboratories. The effect of these interventions was to halt most research in the United States in the areas of machine translation and speech recognition, on the grounds that the scientific foundations of these fields were not adequately established, and that engineering work in advance of fundamental science was a waste of time and money. This general view of the relationship between science and technology was typical of the men who led U.S. engineering research during
World War II and the post-war period, and John Pierce had both the credentials and the 596 confidence to apply these ideas in an authoritative way, and to persuade funders and researchers to his point of view. Pierce had supervised the team that developed the transistor, and coined the word transistor itself; he supervised the development of the first communication satellites; and he had made contributions in areas as far afield as computer music and science fiction.
 The topic of John Pierce X  X  first intervention was machine translation. He chaired a committee of the National Academy of Sciences, whose 1966 report (Pierce and Carroll 1966, page 30) persuaded the U.S. government to stop funding machine translation (MT) research. It is well known that the ALPAC report torpedoed MT funding in the U.S., but it is less well known that it promoted fundamental research in computational linguistics as an alternative: Pierce X  X  second intervention came in the form of a letter to the Journal of the Acousti-cal Society of America (Pierce 1969). Because it was not written by a committee, it was muchmoredirect:
The key problem, Pierce thought, was failure to build on past accomplishments in the way that successful science and engineering do: Pierce argues that  X  X  general phonetic typewriter is simply impossible unless the typewriter has an intelligence and a knowledge of language comparable to those of a native speaker of English X  (page 1050). The clear implication is that engineers should stop trying to solve the general speech recognition problem until the relevant scientific foundations have been laid. This letter had an even more devastating effect than the ALPAC report did. While
Fred was leading IBM X  X  effort to solve the general dictation problem during the decade or so following 1972, most other U.S. companies and academic researchers were work-ing on very limited problems such as speaker-dependent small-vocabulary isolated-word recognition, or were staying out of the field entirely.

However, Fred X  X  information-theoretic approach provided a purely engineering-based way to make speech recognition research an  X  X xperiment X  rather than an  X  X x-perience. X  Comparing the quantitative performance of alternative algorithms on stable training and testing sets, using fixed and automatically calculated evaluation metrics, offered a nearly glamour-and deceit-proof way out of Pierce X  X  trap.

This was the mode of work in Fred X  X  group at IBM, first applied to speech recogni-tion and later to a variety of other problems, including especially machine translation.
From the beginning, Fred was strongly in favor of sharing resources, evaluation metrics, and algorithmic ideas with researchers outside of IBM. In fact, some of the seeds of
DARPA X  X  efforts in this area developed out of Fred X  X  efforts, beginning in the mid 1980s, to decrease his group X  X  costs by sharing the development of expensive resources such as dictionaries and parallel text corpora. Under Fred X  X  leadership, in 1989 IBM donated its aligned version of the Canadian Hansards X  X he parallel text corpus used in his pioneering MT research X  X o the ACL X  X  Data Collection Initiative.

Charles Wayne, starting a new speech-recognition program at DARPA in 1986, adopted the idea of quantitative comparison of alternative algorithms on a fixed task. In the context of this program, the formal quantitiative competition was not only among algorithms but among research groups, with all the sites involved in the project sharing a predefined automatic evaluation metric and a body of material for training and testing.

At first, DARPA X  X  key motivation for this  X  X ommon task method X  seems mainly to have been to persuade skeptics that the new program would successfully avoid glamour and deceit. And at first, many researchers complained that the frequent quantitative evaluations made them feel as if they had returned to kindergarten. But it soon became clear that this approach had a number of key advantages as a method of research management. It lowered barriers to entry, by providing well-defined tasks and the resources needed to undertake them; it created a research community with shared goals and assumptions; and, perhaps most important, it offered proof of gradual progress that could be used to justify stable funding for speech and language technology devel-opment over several decades, even when no  X  X iller app X  had yet emerged.
 As a result of this demonstrated success, DARPA X  X  investment in Human Language
Technology continued, and grew to include text retrieval, information extraction, topic detection and tracking, summarization, machine translation, and many other problems.
And speech and language researchers have come to take this paradigm for granted, and to apply it even when it is not imposed by funders.

Contrary to the expectations of many well-informed people, this approach has allowed a very large number of small algorithmic improvements to accumulate over several decades, to the point where without any major breakthroughs, speech recogni-tion and machine translation are now quite workable in many applications.
And this history now puts us in a position to apply John Pierce X  X  perspective back-to-front. Like most of the rest of his generation, Pierce felt that the natural progression was for scientific understanding to serve as the foundation for engineering applications.
But instead, more than three decades of engineering development in human language technology may now permit rapid scientific progress. 598 Independent of their value in practical applications, the algorithms developed by the process that Fred Jelinek pioneered offer marvelous new tools for scientists. Ap-plying these tools to the vast stores of digital speech and text now becoming available, we can observe linguistic patterns in space, time, and cultural context, on a scale many orders of magnitude greater than in the past, and simultaneously in much greater detail.
Rather than evoking the impact of particle accelerators, as the ALPAC report did, it may be more appropriate to compare these tools to the invention of the microscope and telescope in the 17th century: Everywhere we look, there are interesting patterns previously unseen.
 In the published version of his 2009 ACL Lifetime Achievement Award speech, Fred Jelinek wrote (page 484):
Perhaps, in the end, this was the best way for Fred to contribute to linguistics. He lived to see the triumph of his ideas in speech and language engineering; we should remember him as we explore the world that his ideas are opening up to us in speech and language science.
 References
