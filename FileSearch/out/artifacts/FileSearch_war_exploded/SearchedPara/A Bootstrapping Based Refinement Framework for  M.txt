 This paper proposes a novel bootstrapping based framework jointed with automatic refinement to extract opinion words and targets. We employ a reasonable set of opinion seed words and pre -defined rules to start bootstrapping. We leverage statistical word co -occurrence and dependency patterns for propagation between opinion words and targets. A Sentiment Graph Model (SGM) is constructed to evaluate these opinion relations. Furthermore, we employ Automatic Rule Refinement (ARR) to refine the rules to extract f alse results. By using false results pruning and ARR process, we can efficiently alleviate the error propagation problem in traditional bootstrapping -based methods. Preliminary evaluation shows t he effectiveness of our method. H.3.3 [ Information Search and Retrieval ]:Information Filtering; I.2.7 [ Artificial Intelligence ]: Natural Language Processing  X  Text Analysis Experimentation, Performance.
 Opinion mining; Sentiment analysis; Bootstrapp ing; Ref inement. In this paper, we investigate the methods for opinion words and target extraction. In this task , identifying the relations between opinion words and targets plays an important role. Syntactic dependency structures are often used to understand grammatical modification relation between opinion words and their targets [1][2]. Recent researches on opinion targets extraction have shown the effectiveness of syntactic patterns for opinion words and targets extraction [3][4][5 ]. Similarly , in this paper, we utilize the dependency tree to d iscover the potential relations between opinion words and targets. Corresponding Author Existing approaches on opinion words and targets extraction have two types of framework: one is pipeline framework ; the other is propagation (or bootstrapping -based) framework. In the pipeline framework, candidates of opinion expressions and opinion targets are generated first, and then they filter false results with refinement methods [6]. In the refinement process, they took rule -based or machine learning approaches to identify potential relations between opinions and targets. The main challenge is the effectiveness of the refinement methods, because it decides the extraction result. In addition to the pipeline framework, researchers try to identi fy opinion words and targets iteratively in the propagation framework [3][4]. The extraction result extends with heuristic rules in the iterative propagation process, but it could be affected by the error propagation.
 Based on previous researchers, we point out some major challenges in the opinion words and targets extraction: ! False opinion targets pruning. The problem of error ! Long -tail opinion targets discovery. Pre -defined In this paper, we propose novel bootstrapping based refinement framework to extract opinion words and ta rgets. The basic idea of our method is to adopt re finement methods jointed with propagation. Our contributions in this paper are summarized as follows: (1) We propose a novel framework that combines the refinement process based on bootstrapping in a jo inted framework. By using this method we can alleviate the problems of error propagation and long -tail results discovery in previous propagation or pipeline methods. (2) We identify potential opinion relations to extract more latent opinion words and t argets in the case of informal texts and error parsing in real world. Meanwhile, we employ Automatic Rule Refinement (ARR) to pruning false results and update rules of extraction iteratively to improve the extraction performance. (3) We evaluate our me thod using real -world datasets, and experimental results show the effectiveness of our approach compared with the state -of-art methods.
 Our framework is based on bootstrapping. Figure 1 introduces the detailed process of our refinement framework. We take opinion seed words set, dependency patterns and review data as the system input. We scan all the sentences in the dataset , and we adopt a syntactic parsing method to capture the dependency structure on each sentence . At the beginning, we generate two candidate sets of opinion words and targets by employing the pre -defined rules. Then we iteratively extract opinion words and targets using predefined extraction rules and existing result set. There is a rule set containing several rules to identify the conditions for extraction. Most of the rules describe the latent relations bet ween opinion words and targets, i.e. word co -occurrence or dependency patterns. The details of the rules will be described later in section 3 . Figure 1: A Bootstrapping based Refinement Framework In the propagation process, existing opinion words are used to find new opinion targets, which satisfy the rules of extraction. At the same time, the relations between opinion words and targets are identified during the extra ction. We apply the structure of Sentiment Graph Model (SGM) to measure the relations between opinion words and targets, and quantize the relations by computing the weight on each edge on the graph. After the extraction, we employ several refinement method s to prune false results. 
In the refinement process, we check the conditions of the rules to prune false opinion words and targets in the candidate sets { OC } and { TC }. After pruning and refining, the remained extracted opinion words and targets are added to the refined result set { O } and { T }, and pruned words generate a false result {O} and {T} to update SGM by adjusting the model parameters. We also take the rule refinement by the false res ult set { O and { T false } to update or remove rules of extraction. The refined opinion words and targets { O } and { T }, updated SGM, as well as the refined rules of extraction are all applied for further opinion words and targets extraction. Repeat the p ropagation of extraction until no new opinion words and targets are identified. The advantages of our refinement framework are listed below: ! Domain -independence . Our framework employ heuristic ! Automatic rule refinement method. We update the rules ! Potential dependency patterns discovery. Different types Therefore, we may draw the conclusion that our bootstrapping based refinement framework is domain -independent, scalable and high-performance for opinion words and targets extraction Sentiment Graph Model : is a weighted, directed graph. Opinion words, opinion targets and dependency patterns are represented as vertices in the graph model.
 First, we need to generate two candidate sets of opinion words and targets. Then we connect pair s of co-occurrence candidates in these sets. As dependency patterns are useful to identify relations between opinions and targets, we add them as vertices to the SGM . Each dependency represent s a syntactic relation between opinion words and targets. Though it is difficult to construct a comprehensive set of dependency relations between targets and opinions to cover all real -world cases, we discover potential dependency patterns and measure its confidence to discover new opinion words and targets. New edges that connect the patterns and opinion words o r targets would be also added to the graph. The construction of the graph is shown in Figure 2 . Now we introduce the estimation of the weight on the SGM . First, we calculate a frequency table of two terms  X  and  X  , which represent opinion word or target candidates. As shown in Table 1,  X  ! , ! is the number of reviews containing term  X  and  X  ;  X  the number of reviews containing term  X  but not  X  ;  X  number of reviews containing term  X  but not  X  ;  X  ! , ! of reviews containing neither  X  nor  X  . 
Then we measure the association of pair -wise terms as the support level for each pair of candidates. Here is the function to calculate the support level: where,  X  is the number of reviews.  X  ! is the frequency of term  X  in the corpus.  X   X   X  is the conditional probability of term  X  when term  X  occurs. We define  X  X  X  X  X  X  (  X  ,  X  ) as the support level of term  X  to  X  . Then we use  X  X  X  X  X  X  (  X  ,  X  ) as the weight of the edge  X  :  X  on the Sentiment Graph. Similarly, we use  X  X  X  X  X  X  (  X  ,  X  ) and  X  X  X  X  X  X  (  X  ,  X  ) as the weight of edges  X  :  X  !  X   X  ! representatively . We compute the support level for each associated pattern and opinion word, or target, which are used to evaluate the confidence of the dependency pattern used to extract new opinion words and tar gets . We take the support level as the weights on the Sentiment Graph Model. We evaluate the confidence of each dependency pattern by employing the following function:  X  X  X  X  X  X   X  is th e sum of weights on all associated opinion words and targets with the pattern. Only with high confidence can the patterns be used to extract new opinion words and targets. The confidence score is used in rules of extraction. After refinement process, the c onfidence score need to be updated as some false results have been pruned. In the propagation process, we define several rules of extraction to discover new opinion words and targets . The initial rule set is shown in the Table 2 below: The first two rules are used to generate the initial candidate sets of opinion words and targets. We simply extract adjective as opinion words and nouns as opinion targets candidates. The rest of the rules contain different restriction to specify the c onditions for extraction. In the propagation process, these rules are applied to filter the candidate set and identify opinion words and targets that satisfy the words co -occurrence threshold or match the dependency patterns with high confidence score.
 We construct the SGM on the candidate result set before propagation. Then we apply the rules of extraction to filter the candidate set. Taking R3 as example to demonstrate the process of extraction, we find an opinion word o existing in the result set in a sentence. If there is a target candidate t in the same sentence, we check the support level of o and t on the SGM. Then we identify t as a target if the support level is higher then the threshold. After dependency parsing o n one sentence, we check the rules with dependency patterns. If one pattern matches the dependency path on the sentence, we apply the corresponding rules to extract new opinion words or targets. We also discover potential dependency pattern s with the help of extracted opinion words and targets.
 In addition , we also update our rules of extraction by considering the pruned false results. This process is called automatic rule refinement. We collect the pruned candidates to a false result set. The false re sults are examples of incorrect extraction. Then we find out the rules used to extract these results, and adjust parameters in these rules, such as threshold, support level of opinion relation and confidence score of patterns. We expect to learn and update the rules with the help of the extraction results automatically, which is self -adaption in different domain and application. Modifying a rule to remove false result can simultaneously remove other false results. However, this action may also remove some c orrect results. Only when the false results are extracted by specific rule frequently, can the rule be refined seriously in order to reduce the side effect. We select a real world dataset in Chinese to evaluate our method. The dataset s contain reviews on different products, so we test the performance of our method on cross -domain data. The dataset published in COAE2008 1 has about 5000 sentences, which contains Chinese review data on camera (D1) and car (D2) . Besides some pre -annotated opinion t argets in the datasets, we manually annotate opinion words and targets in sentences.
Evaluation Metrics : We evaluate our method by precision ( P ), recall ( R ) and F -measure ( F ). We evaluate our opinion words and targets extraction performance of the proposed framework against four state -of-art competitors listed below : ! DP : Double Propagation in [3] . ! DPHITS : DP with hyperlink -induced topic search ! LSTBOOT : likelihood ratio tests for bootstrapping in [7]. ! TSF : Two -Stage Framework in [5]. All of the above competitors are unsupervised methods. The first three methods are based on bootstrapping framework. DP extracts opinion words and targets using syntactic dependency relations . Some syntactic rules are manually defined for extraction. DPHITS uses hyperlink -induced topic search algorithm (HITS) to validate potential targets recognized by DP plus two additional syntactic patterns of  X  X art -whole X  and  X  X o X . The last competitor TSF is a typical pipeline framework. TSF first generates candid ates of opinion words and targets, and then uses well -designed models to refine the result. http://ir -china.org.cn/coae2008.html A ll of the above approaches use same five common opinion word seeds as {good, bad, nice, poor, perfect }. The choice of opinion seeds seems reasonable, as most people can easily use this opinion words to express their basic opinion and sentiment orientation.

We take the task of the opinion target extraction on these five methods. As DPHITS and LRTBOOT don X  X  extract opinion words, we only show the performance of o pinion words extraction on DP, TSF and our JPR method.
 Table 3 shows the experimental results for opinion targets extraction and Table 4 shows the results for opinion words extraction. We have the following analysis from the results table : (1 ) Our method outperforms the four competitors in terms of F-measure on all domains , and it outperforms the method ranked only second to our method at 0.03 -0.05 in two tasks. It indicates the effectiveness and domain -independence of our method. (2) Our method achieves highest 0.22 impr ovement in F-measure compared with DP. Our method also outperforms the other two bootstrapping methods at 0.06 -0.10 in F-measure. We believe the improvement on recall benefits from our pattern discovery, as new patterns can identify more opinion words and targets. The improvement in precision indicates the effectiveness of our iterative refinement process, which reduces the error propagation. In addition, the automatic rule refinement also makes contributions to extract more correct opinion words and targets compared with static and rules chosen manually. (3) Our method outperforms pipeline methods in terms of preci sion at 0.06 and has comparable recall. It indicates that the process of refinement during the iterations plays an important role to reduce fa lse extraction. The reason for t he close score of recall is that some correct results are filtered in the refinement process. Therefore , the refinement process should be carried out carefully to reduce such side effect. This paper proposes a no vel bootstrapping based r efinement framework for opinion words and targets extraction. Unlike the existing propagation framework or pipeline framework, our framework combines the refinement process based on bootstrapping. We employ a Sentiment Graph Model con taining dependency patterns to evaluate the relations between opinion words and targets. We also adopt an automatic rule refinement to pruning the false results and update the rules for extraction to improve performance. The experimental results show that ours achieves higher performance over current state of the art unsupervised methods. 
In the future, we plan to focus on improving the precision of opinion words and targets extraction by working on the refinement methods. We also plan to reduce the fa lse drop to increase recall in the process of refinement, which is a side effect of rule refinement. Then we will also try to design new models to improve the Sentiment Graph Model to discover the potential relations between opinion words and targets. This work is supported by National Natural Science Fou ndation of China (61303164), Beijing Natur al Science Foundation (9144037), National Basic Research Program of China (973 Program) (2013CB329305) and National High Technology Research and Dev elopment Program of China (863 P rogra m) (2012AA011206) . [1] A. Popescu and O. Etzioni. 2005. Extracting product [2] N. Kobayashi, K . Inui, and Y . Matsumoto. 2007. Opinion [3] G. Qiu, B . Liu, J . Bu, and C. Chen. 2009. Expanding [4] L. Zhang, B. Liu, S. H. Lim, and E. O'Brien -Strain. 2010. [5] L. Xu, K. Liu, S. Lai, Y. Chen and J. Zhao. 2013. Mining [6] Y. Wu, Q. Zhang, X . Huang, and L. Wu. 2009. Phrase [7] Z. Hai, K. Chang, and G. Cong. 2012. One seed to find 
