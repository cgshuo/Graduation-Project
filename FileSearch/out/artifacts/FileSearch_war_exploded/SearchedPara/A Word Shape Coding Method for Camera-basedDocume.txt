 This paper reports a word shape coding method to facilitate retrieval of camera-based document images without OCR. Due to perspective distortion, many reported word shape coding methods fail on camera-based images. In this paper, the problem is addressed by approximating the perspective transformation with an affine transformation, and employ-ing an affine invariant, namely length ratio, to represent the connected components. Components in a document image are classified into a few clusters, each of which is assigned with a representative symbol. Retrieval are based on X  X ords X  comprising of symbols. The experiment results showed that the proposed method achieved an average retrieval precision of 93.43% and recall of 94.22%.
 H.3.1 [ Information Systems ]: Information Storage and Retrieval X  content analysis and indexing Algorithms Perspective distortion, Document image retrieval
Word shape coding is a technique which has been reported for years as a complementary technique to Optical Character Recognition (OCR). Word shape coding is to map a com-ponent to a reduced symbol set, other than to give it the exact character identity as OCR does. Thus compared to OCR, word shape coding is much faster in speed and more reliable when image quality is degraded. It has been widely employed in document image processing tasks, such as lan-guage identification and duplication detection, on which fur-ther indexing and retrieval depend. Besides, it also plays an essential role in document image retrieval when full-scale OCR is too slow or too unreliable to be carried out[1][4][5].
With the rapid advances in camera technology, camera has become an emerging alternative to scanners. Images taken by a camera often suffer from perspective distortion, which never appears in an image produced by a scanner. Hence, word shape coding techniques developed specifically for scanner-based images no longer work on camera-based images. Also, no reliable OCR techniques for camera-based images are available currently. Thus, a word shape cod-ing method is presented in this paper to efficiently retrieve camera-based document images.
The basic assumption of our method is that: for each character in the image, the perspective transformation can be approximated by an affine transformation. Theoretically, when the perceived object depth is much smaller than the distance between the camera lens and the object, the per-spective transformation can be approximated by an affine transformation, which can be further decomposed into a scale, a rotation, a shearing, and a translation transforma-tion. Practically, English characters printed on an A4 sheet are generally within a 2  X  2 mm 2 bounding box. In order to take a photo of the whole sheet, the distance between the camera and the projection center on the sheet is at least 30 mm . In addition, since the image is taken for reading purpose, the camera projection angle is nearly perpendicu-lar to the sheet plane. The object depth of a character is hence very small. Therefore, the affine approximation holds.
Assume there is a connected component C , such as char-acter  X  X  X  in figure 1(a). Firstly, the centroid of the convex image of C , denoted by o , is located. The skeleton of C , as shown in figure 1(b), is gotten by a thinning operation. Then a line through o , shown as the bar in figure 1(c), is arbitrarily drawn. The line will have several intersections with the skeleton. For each pair of intersections, denoted by i and i 2 , the length ratio is calculated as: 8 &gt; &lt; &gt; : where oi k is the Euclidean distance between o and i k . In the next step, the line is rotated 360 degrees around o degree by degree, and length ratios are calculated meanwhile. Finally, for each component a histogram is constructed to record the occurrence of length ratios, if their absolute values are larger than 1. In the experiment, a histogram with 20 bins, starting with -10 and ending with 10 was used. In particular, bin 1 kept a record of the number of ratios which are greater than -10 and smaller than -9, and so on and so forth.
It has been proved that the centroid of a convex poly-gon preserves under affine transformations[2]. Also, it is well known that the ratio of length of line segments on a given line remains constant under affine transformations . Therefore, the normalized ratio histogram of C will remain unchanged when C is under any affine transformation.
In OCR process, components are assigned with identities in a character set, by being compared with character tem-plates. In our method, components are assigned with iden-tities in a reduced symbol set. The symbol set is found as follows: connected components are extracted from training document images of a fronto-parallel view, and their ratio histograms are calculated. KNN clustering algorithm is ap-plied to histograms with cosine distance as the distance mea-sure. k clusters are found and the centroid of each cluster is recorded as a symbol template. Different characters, which have similar histograms after normalization, are classified into the same cluster, such as  X  X  X ,  X  X  X , and  X  X  X . k was cho-sen as 23 in our experiment, to optimize the separation of clusters.

When an unknown document image is presented, each connected component in the image is compared with the k templates, and its identity is assigned as the identity of the most similar template. However, in the experiment, compo-nents smaller than 50 pixels were thrown away in order to avoid pixel quantization errors.
 Word boundaries are found by segmentation algorithm [3]. Then X  X ords X  X omprising of symbols are formed. Thereafter, traditional vector space model with tf.idf representation is applied to those  X  X ords X . Similarity between two document images is formulated as: where D u and D v are documents, and i is the dimension index of the  X  X ord X  space.
In order to test the efficiency of the proposed method, the retrieval experiment was designed as follows: 100 pages were selected from 6 documents of the U.S. patent database. These documents were in different categories assigned by the database. We assumed that pages from the same document were similar to each other in content, and different other-wise. These pages were printed out, and 2304  X  3072 pixel photos were taken by camera. Since it is natural that a printed paper has some warping distortion, this distortion
Doc. 1 2 3 4 5 6 1 0.425 0.079 0.062 0.106 0.117 0.050 2 0.079 0.453 0.108 0.192 0.023 0.151 3 0.062 0.108 0.528 0.088 0.117 0.175 4 0.106 0.192 0.088 0.378 0.066 0.188 5 0.117 0.023 0.117 0.066 0.422 0.138 6 0.050 0.151 0.175 0.188 0.138 0.511 Table 1: Similarity of pages of the same and different documents. was kept in these photos. It was guaranteed that all charac-ters in a photo were recognizable to people. Examples of the testing data are shown in figure 2. 10 photos were selected as queries. Each query was compared to other 90 photos by the proposed method. When the similarity was greater than a threshold  X  , two photos were considered as similar to each other.

In the experiment, an average precision of 93.43% and an average recall of 94.22% were achieved, with  X  = 0 . 3. Table 1 shows the similarity across pages of the same document and that of different documents. Scores were calculated by averaging the similarity between each pair of pages from document i and j . Particularly, the cells on the diagonal are the similarity of pages within the same document. These items are much greater than those off-diagonal items. Exhaustive study of this method will be done in future. The high recall and precision in our experiment indicate that the technique is also promising for more applications such as language identification and duplication detection. [1] D. Doermann. The indexing and retrieval of document [2] C. Gope and N. Kehtarnavaz. Affine invariant [3] L. Gorman. The document spectrum for page layout [4] Y. Lu and C. L. Tan. Information retrieval in document [5] C. L. Tan, W. Huang, Z. Yu, and Y. Xu. Image
