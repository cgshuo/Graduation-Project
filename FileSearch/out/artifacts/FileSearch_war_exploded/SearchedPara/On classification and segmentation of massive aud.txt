 Charu C. Aggarwal Abstract In recent years, the proliferation of VOIP data has created a number of applications in which it is desirable to perform quick online classification and recognition of massive voice streams. Typically such applications are encountered in real time intelligence and surveillance. In many cases, the data streams can be in compressed format, and the rate of data processing can often run at the rate of Gigabits per second. All known techniques for speaker voice analysis require the use of an offline training phase in which the system is trained with known segments of speech. The state-of-the-art method for text-independent speaker recognition is known as Gaussian mixture modeling (GMM), and it requires an ite-rative expectation maximization procedure for training, which cannot be implemented in real time. In many real applications (such as surveillance) it is desirable to perform the recognition process in online time, so that the system can be quickly adapted to new segments of the data. In many cases, it may also be desirable to quickly create databases of training profiles for speakers of interest. In this paper, we discuss the details of such an online voice recog-nition system. For this purpose, we use our micro-clustering algorithms to design concise signatures of the target speakers. One of the surprising and insightful observations from our experiences with such a system is that while it was originally designed only for efficiency, we later discovered that it was also more accurate than the widely used GMM. This was because of the conciseness of the micro-cluster model, which made it less prone to over training. This is evidence of the fact that it is often possible to get the best of both worlds and do better than complex models both from an efficiency and accuracy perspective. We present experimental results illustrating the effectiveness and efficiency of the method.
 Keywords Classification  X  Segmentation  X  Audio streams 1 Introduction The problem of speaker voice analysis and classification is useful in a number of applications such as real time monitoring, detection, and surveillance. In this paper, we are concentrating on the problem of text-independent speaker classification in which the actual textual content of the speech is not available for modeling purposes. A number of statistical and machine learning methods have been recently proposed for speaker classification. Some examples of such techniques may be found in [ 10 ].

A well-known method for speaker classification and identification is that of Gaussian mixture modeling (GMM) [ 11 , 12 ]. The first step is to extract multi-dimensional feature vectors in order to represent portions of sampled speech. In this method, it is assumed that each data point extracted from the speech segments from a number of known speakers are used to estimate the parameters of a GMM model. Then the data points from an unknown speech segment are applied to each speaker model in order to estimate the maximum likelihood fit. The model with the highest fit is reported as the relevant class label. The GMM modeling method has been widely popular because of its intuitive appeal and effectiveness, and has therefore been used extensively. A number of other pattern recognition models which are often used for speaker classification are discussed in [ 4 , 6 , 7 , 10 , 14 ].
 In many applications, it is desirable to perform the speaker identification in real time. In such cases, we need to have a system which is adaptive enough to learn characteristics of new speakers in real time, and used these learned profiles in order to construct the final model for speaker classification. Unfortunately, popularly used models such as GMM are not very appropriate for real time speaker modeling. This is because the first step of deter-mining the parameters of the mixture model requires an iterative computationally intensive approach known as the EM algorithm. The second stage of model fitting requires the eva-luation of a log likelihood criterion on the data set for each model. These techniques can be computationally intensive in practice, and are often difficult to use effectively for real time modeling and classification. Furthermore, we are also interested in other mining variations of the classification problem in which it is desirable to model or match individual segments of speech from unknown speakers in real time. This is not possible with an iterative approach such as the EM algorithm. In addition, since we are making the stream assumption for all data processing, we assume that each point in the data can be scanned only once throughout the computation. This assumption is also violated by all other speaker identification systems [ 4 , 6 , 10 ] known to us. Therefore, we need to construct a system which can work with the constraints of a one-pass system and still provide accurate results for speaker identification.
In addition to speaker classification, we would like to design a system which is capable of detecting quick changes in the pattern of the underlying data stream. Such a system is useful in applications in which it is desirable to segment portions of speech into different speakers. We note that this segmentation may need to be done in an unsupervised way, since example segments of the different speakers may not be known in advance. In order to design a system which can work with such challenges, we construct a number of techniques which are designed towards stream based online processing of massive amounts of audio data. We adapt our earlier research results for stream micro-clustering [ 2 ] in order to create fast cluster based signatures of the data. These signatures are constructed and used in real time in order to perform the speaker identification.

We also report a number of interesting observations about the behavior of the micro-clustering model. While our original aim was only to design an efficient online system for speaker recognition, the results also turn out to be qualitatively superior to the GMM model. This is because the GMM model requires a significantly large number of training parameters. In many cases, this can lead to overfitting, which reduces the effectiveness of the approach. On the other hand, the micro-clustering model is concise in its description of the data stream; a design which was originally motivated by efficiency, but also turns out to be more effective than the GMM model. This is because the concise signature representation of each speaker model is able to avoid the over-training of the GMM model. Thus, this application provides a nice example of the dual advantages of using more concise models [ 9 ] in machine learning.
This paper is organized as follows. In the next section, we will discuss the architecture of the system and discuss how the algorithms in [ 2 ] can be modified in order to perform the speaker identification. In Sect. 3 , we will present the experimental results obtained from deploying these algorithms over a number of real data sets. Section 4 contains a number of conclusions and observations. 2 The speaker identification system In this section, we will discuss the speaker identification system for audio data streams. We have illustrated the overall architecture in Fig. 1 . In this architecture, we do not distinguish between the training and test data streams, since all the streams are received along the same system. The main difference between the two is that the training stream is tagged with a speaker label, whereas the test stream is not. The voice profiles from the training stream are stored onto a disk subsystem which contains the known training profiles. These known training profiles are used for identification of unknown segments. We note that this architecture does not force us to perform the entire training phase ahead of the testing phase. Therefore, if new speech segments are received which need to be matched with one or more test segments, we can use this approach effectively.

The next issue is the particular choice of feature vectors which are used for the classifi-cation process. A common set of feature vectors which can be used are the mel frequency cepstral coefficients (MFCC). The feature vectors are considered as the standard vectors for speech recognition. The feature recognition process segments the digitized audio signal into overlapping windows of equal length. These segmented portions of the windows (frames) are created by sampling of the original signal every 10 or 20 ms. The length of a frame is about 30 ms. For speaker recognition tasks, sometimes longer frames are used in comparison to the feature extraction method used for speech recognition in order to increase spectral resolution. Each frame in the time domain is transformed to a MFCC vector. Therefore, the original speech signal is converted into a sequence of feature vectors, with each vector representing cepstral properties of the signal within the corresponding window. The feature extraction process creates a quantitative multi-dimensional format which can be used for the mining process. A second format of vectors which are often used are the linear prediction cepstral coefficients (LPCC) which are used in order to perform the modeling and prediction. In this paper, we will illustrate the use of our system with both kinds of data formats.
In our online voice recognition approach, we will use a non-parametric density estimation approach. The idea is to determine the probability distribution of the data for each speaker and map it to the behavior of unknown test segments in order to perform the matching. The reason for using a non-parametric approach is that most parametric methods such as the GMM model require an iterative approach to estimate the densities in the underlying data. On the other hand, a non-parametric approach adapts very well to an online application such as that of clustering data streams. A well known non-parametric method of finding the data distribution is that of kernel density estimation [ 13 ]. However, density estimation is often an inefficient method since it requires us to estimate the data behavior over all regions of the data. In high dimensionality, most of the regions in the data are sparse, and the estimation will need to be performed over a very large number of data points (which is exponentially increasing with dimensionality) in order to provide a comprehensive overview of the data behavior. This can rapidly become untenable for non-uniform data distributions of even modestly high dimensionality. In order to substitute for using density distributions directly, we will use very fine grained micro-clusters in the data. Micro-clustering is a concept which is used to track very detailed level of statistics of clusters with high granularity. This is a desirable approach when the data sets are received in the form of massive data streams. The distribution of the data for different speakers over these fine-grained clusters are used as a surrogate for the actual densities in the underlying data. We will see that this turns out to be a practical and scalable approach in most applications, and also simulates the underlying densities quite well. In order to design the voice recognition system, we will build upon some micro-clustering machinery developed in [ 2 ]. The micro-clustering framework discusses some summary statistics which are used to maintain the statistical information about the clusters. We assume that the dimensionality of the data stream is d . The definition of a micro-cluster is as follows: Definition 2.1 A micro-cluster for a set of d -dimensional points C ={ X i 1 ... X i n } with time wherein CF 2 x ( C ) and CF 1 x ( C ) each correspond to a vector of d entries. The definition of each of these entries is as follows:  X  For each dimension, the sum of the squares of the data values is maintained in CF 2 x ( C ) .  X  For each dimension, the sum of the data values is maintained in CF 1 x ( C ) .The p -th entry  X  The last update time (which is max { T i  X  The number of data points is maintained in n ( C ) .
 The design of micro-cluster statistics is chosen so as to make some important predictions about the data points in them. We make the following two observations about the statistics [ 3 ] stored in the micro-clusters: Observation 2.1 The mean and variance of the data points in a cluster can be determined from the micro-cluster statistics.
 In addition, the micro-clusters satisfy the additivity property . We omit the details of the proofs since they can be found in [ 16 ]. Observation 2.2 The micro-cluster statistics satisfy the additivity property. The micro-cluster statistics for the union of two sets of data points is the sum of the micro-cluster statistics of the individual sets of points.
 As discussed later, the above observations are used during the clustering process. The clus-tering process is used to create and store summary frequency information. This summary information is used in order to perform effective classification. A set of a clusters can be used to create a signature summary of the data. This signature summary is defined in terms of the frequencies of the different data points drawn from the segment S , in terms of their distribution over the clusters C 1 ... C k . The signature summary is used as a surrogate for the probability density of the data points in the stream. As we will observe later, this is not an unreasonable assumption when a fine granularity of clustering is maintained. Let us denote the data in the last segment of length S by D ( S ) .Wedefinethe signature summary of the data set D ( S ) over the segment S with respect to the clusters C 1 ... C k as follows: Definition 2.2 The signature summary  X ( C 1 ... C k , S ) for a set of k clusters C 1 ... C k and segment of data points S is defined as the k -dimensional vector ( f 1 ... f k ) ,where f i is defined as follows: It is important to note that the signature summary essentially defines the relative distribution of the data points across the different clusters. When the individual clusters have very small variance, they can be used as a surrogate for the true density distribution. In order to explain the relationship between the probability density and the frequencies of the data points across different clusters, we make the following observations.

Let X ( C i ) and h ( C i ) 2 be the centroid and variance of cluster C i . Then, the density estimate  X ( x ) at any point x in the space can be constructed as follows: We note that Eq. 2 is a modification to the standard density function which is often used in kernel density estimation of individual data points. The primary difference is the cluster-specific value of the bandwidth h ( C i ) .Here h is an additive bandwidth which is defined in the same way as standard kernel density estimation, except that we use the number of clusters rather than the number of points to define h . Specifically, the exact value of h is defined by the Silverman X  X  approximation rule [ 13 ]. According to this rule, for a data distribution with n points (clusters) and variance  X  of the data points (cluster centroids), the value of h is chosen to be 1 . 06  X   X   X  n  X  1 / 5 . We note that lim n  X  X  X  h  X  0. In effect, the density estimate is equal to the sum of Gaussian kernels which are centered at different clusters, and have bandwidth which is defined by the variance of the data points in the cluster. For very fine grained clusters, such an approach provides a very good estimate to the process of kernel density estimation. This is because this limiting case defines a situation in which the value of h ( C i ) tends to zero. On substituting the value of h ( C i ) = 0inEq. 2 , we obtain the same formula [ 13 ] used for standard kernel density estimation. We summarize this observation as follows: Observation 2.3 In the limiting case, when each cluster contains only one data point, the value  X ( x ) is equal to the standard kernel density estimate.
The essential idea behind this exercise was to illustrate that the signature summary can encode very detailed information about the probability distribution of the data even for very fine grained clustering. We note that the difference in probability density between two distributions  X  1 (  X  ) and  X  2 (  X  ) may be defined as follows: This difference is essentially equal to the integral of the difference of the two distributions over the entire space. Intuitively, we would like to use this difference in density distribution as a measure for the fit between two density distributions. Note that even when probability densities can be estimated accurately, this difference can be difficult to compute in practice. Therefore, as the surrogate, we compute the difference in signature summaries between the two data streams.
 Definition 2.3 The distance Dist ( H 1 (  X  ), H 2 (  X  )) between two signature summaries H 1 (  X  ) = ( f 1 ... f k ) and H 2 (  X  ) = ( f 1 ... f k ) is defined as follows: This distance is thus defined in terms of the L 1 -norm. We note that this distance is essentially a discrete analogue of the difference in density distributions. In this case, we are summing the discrete differences in probabilities that a voice packet belongs to a particular micro-cluster. 3 Generating signature summaries for speech segments In this section, we will discuss the micro-clustering algorithm for speech recognition. The micro-clustering algorithm is used in order to construct profiles from the speaker data. These profiles are essentially the signatures in the data stream. The micro-clustering algorithm uses a nearest neighbor clustering algorithm in which each data point is assigned to the mean of the closest cluster. As discussed in Observation 2.1 , the mean of the cluster can be computed from the micro-cluster statistics. Once the closest micro-cluster has been computed, we add the statistics for that data point to the micro-cluster statistics. This is possible to achieve because of the micro-cluster statistics discussed in Observation 2.2 . The overall process for signature construction is discussed in Fig. 2 .

One problem which may arise in a real application is that of cluster centroid drift. Cluster centroids can drift when the new data points which are added to the clusters have a different distribution from the original set of data points. Such a drift may affect the significance of the signatures over time, since different voice streams may be received one after another, and may have slightly different cluster centroids. This situation is also quite possible in real applications since the data distribution may vary over time. This is an undesirable situation, since it is difficult to fit the test data accurately. We note that the key function of cluster centroids is to ensure that the most relevant (dense) regions in the data are represented by these anchors. The exact location of these clusters is not very important as long as they remain fixed over time, and represent most of the dense regions. Furthermore, we note that the only statistic which is used during the actual speaker identification process is the relative frequencies of the data points in the different clusters. Therefore, it is acceptable to fix the cluster centroids once each micro-cluster is sufficiently populated. Therefore, we pick a small threshold (say 100 voice packets) for each micro-cluster, and apply the micro-cluster update algorithm in a normal way till this limit. However, when the number of data points in the micro-cluster exceed this threshold, we do not add the assigned data point to the micro-cluster, but only update the count of the number of data points in it. The other statistics are updated by the corresponding multiplicative factor in order to reflect a larger number of data points. This ensures that the centroid of the micro-cluster remains fixed, but the frequency statistics are appropriately maintained. The reason that the fixing of centroid positions continues to be effective is that we are interested only in picking certain anchor points which provide us with discriminatory signatures which identify speakers. As long as the anchors are picked from the different dense regions in the data, the exact positions of the anchors does not matter, since the signatures are unique for a speaker for many different choice of anchors. Fixing the centroids ensures that the same set of anchors are used over time, and therefore the statistics for the different speakers over different time-periods are directly comparable.
 During the training phase, we also maintain the signatures for the different speaker labels. These signatures are used for the speaker classification process. Specifically, we assume that the k -dimensional vector H i is used in order to track the micro-cluster frequency behavior of the speaker i . Whenever a new data point is received, we add to the frequency for the corresponding micro-cluster in the signature for speaker i .

We note that the great flexibility of the scheme is that the testing phase is essentially no different from the training phase, except that the micro-cluster statistics do not need to be updated. As in the training phase, we construct the signature for the test segment in order to create the summary signatures. This test segment is matched with the training segments using the relationship discussed in Eq. 4 . The closest matching signature is returned as the speaker identification. 3.1 Tradeoffs A key tradeoff is the choice of the number of micro-clusters. We note that a larger number of micro-clusters increase the amount of data required for training and also slow down the training and testing process for the data stream. However, when a larger amount of training data are available, and there are a large number of speakers to be distinguished, it is desirable to use a larger number of micro-clusters. In such cases, the accuracy of the speaker identification process can be improved at the expense of higher computational costs.

We note that the efficiency of the approach is inversely proportional to the number of micro-clusters. This is because, the number of comparisons of an incoming data point is directly proportional to the number of micro-clusters. Clearly, it is desirable to have as few micro-clusters as possible in order to have the greatest efficiency. So a natural question arises as to how the number of micro-clusters should be picked in relation to the total number of speakers.

In order to analyze this, let us try to compute a lower bound on the amount of information which is encoded in a given number of micro-clusters. Let us simplify each signature to a binary signal in which we have 1-bit for each micro-cluster. A bit takes on the value of 0, if the number of data points in that micro-cluster is less than the average per cluster; otherwise the bit takes on the value of 1. Thus, when there are a total of k clusters, the number of possible bit combinations is equal to 2 k . Clearly, if there are a total of S speakers, then the value of 2 should be at least S in order for the speakers to be well distinguished from each other. Conversely, the number of micro-clusters used should be proportional to log 2 ( S ) ,where S is the total number of speakers used in that application. We note that this only provides us with an idea of how the total number of micro-clusters should scale with increasing complexity of the underlying application. 3.2 Speech segmentation The method discussed in this paper can also be used for speech segmentation. The essential idea in speech segmentation is to partition the conversations between one and more speakers in an unsupervised way. We note that this is often required as a pre-processing step to speaker identification in a real time application in which one does not have the time to perform the segmentation manually after using the content of the speech. In this context, a number of interesting questions arise:  X  For a given speech segment, partition it into segments of contiguous speech patterns.  X  For a given speech segment, find the distinct (and possibly non-contiguous) speech We note that our speaker identification methodologies can be easily extended to these cases by using a windowing approach. In order to extend the methodology to these cases, we perform the micro-clustering continuously as in the previous case, except that we save the signatures in each window at intervals which are equivalent to the window size. For each window, we determine the distance between the signatures for the current window and the window just before it. This leads to a continuous alarm function over the data stream. This alarm function can be used in order to track sudden changes in the trends of speaker behavior. This can create a clear segmentation between the different speakers in a conversation. The size of the window should be chosen to be large enough to have statistical robustness, but at the same time, it should be significantly smaller than the average conversation length in the speech segment. In general, statistical robustness is obtained when a significant number of the micro-clusters are populated. For example, if we are using k micro-clusters, then a total of C  X  k packets should be used, where C is the constant of proportionality greater than 1. We picked C = 5asthe constant of proportionality, so that most micro-clusters could be safely populated. If S is the sampling rate in milli-seconds, then the number of seconds of speech required in the window is given by C  X  k  X  S  X  10  X  3 . Therefore, for a sampling rate of 8 ms, and 100 micro-clusters, this corresponds to a window size of 4 X 5 s. In general, if the number of micro-clusters increases, then the window size needs to increase as well. We have illustrated the overall process for speech segmentation in Fig. 3 . As illustrated in the figure, the speech segmentation process constructs a set of distinct signatures SIGH using the distances between the different signatures. We retain all the signatures in the data whose distances from one another are above a user defined threshold. In the event that the number of distinct speakers are known in advance, it is further possible to cluster the sets of signatures in SIGH into the corresponding number of clusters in order to determine the segmentation into distinct speakers. 3.3 Determining outlier speech segments In many cases, it may be desirable to determine outlier speech segments, which are signi-ficantly different from the other portions of the data stream. Such segments are useful in identifying anomalous patterns of activity in particular portions of the data stream. We note that the outliers are specific to the particular time in the data stream, at which they are reported. Therefore, a given data signature may be an outlier, the first time that it is encountered, but it may subsequently become a non-outlier when other similar stream segments are received. In order to determine the outlier speech segments, we use the speech segmentation process in order to construct the set of distinct signatures SIGH . In order to construct these signatures, we use the same process as Fig. 3 . The main difference is in how the distances to other seg-ments from the signatures in SIGH are tracked. For each signature in SIGH , we maintain the distance to the closest segment in the data stream received so far (excluding the segment itself from which the signature was constructed). We assume that the distance associated with the i th signature in SIGH is denoted by d i . Initially, when the signature is added to SIGH , this distance is set to the closest segment among all other signatures in SIGH . Subsequently, for each incoming stream segment, we compute its distance to all the signatures in SIGH . Let this value for the i th stream segment is denoted by e i .Thevalueof d i is then reset to min { d i , e i } . Thus, at any given moment of time, we have a set of values for d i which can be used in order to determine the outlier segments in the data. Let  X  and  X  denote the mean and standard deviation for the different values of d i . Then, all those signatures in SIGH for which the value of d i is greater than  X  + t  X   X  are reported as outliers. The value of t is picked based on the statistical level of confidence required. For example, using the normal distribution assumption for 95% level of confidence, one may pick t = 1 . 96. 4 Experimental results In this section, we will discuss some empirical results illustrating the effectiveness and efficiency of the method on a variety of voice data sets. For the purpose of comparison, we will use a standard Gaussian Mixture model, which was derived from a software called netlab [ 8 ]. The actual implementation was devised as a modification of an implementation from a music content analysis course available from [ 5 ]. For each speaker, we first constructed a GMM on the training data set, and calculated the log-likelihood of each speaker in the training data on the test data segments. The maximum likelihood speaker was reported as the speaker for the test data set. We note that the use of GMMs is considered as state of the art for text independent speech recognition [ 11 ]. While such models often cannot be used easily for online training and detection, the accuracy provides a idea of the desired accuracy of an online system.

The data set used is the HUB-64 data set, which contains the voice signal of 64 different public personalities such as Wolf Blitzer, Bill Clinton, Al Gore, Candy Crowley etc. This voice signal is then converted into three different formats: (1) A 12-dimensional LPCC format, (2) A 12-dimensional MFCC format (3) An 8-dimensional LPCC format derived from the compressed domain. In each case, a training data set and test data set were constructed from the data. We note that in most real time applications, the size of the test data can be quite small and cannot be controlled. Furthermore, it is desirable to use as small a test segment as possible to perform the classification, since this affects the latency of speaker identification. On the other hand, very large sets of training data can often be made available in most applications for well known speakers by compiling data from multiple sources. Therefore, we chose to divide the training data such that the training data size was twice the test data in each case. In each case, we will also test the accuracy of identification for different sizes of the (test) data set. 4.1 Effectiveness In this section, we will discuss the effectiveness of the micro-clustering technique. First, we will discuss some examples of signatures which were obtained by using micro-clustering on the different data sets. In Figs. 4 , 5 , 6 , 7 , 8 ,and 9 , we have illustrated some examples of the signatures obtained from the different personalities corresponding to Aaron Brown, Al Gore, Ann Kellan, Anthony Keith, Betsy Stark, and Bill Clinton, respectively. In each case, we have used 120 micro-clusters in order to construct the signatures. In each case, the cluster-id is illustrated on the X -axis, whereas the relative frequency of the corresponding cluster is illustrated on the Y -axis. It is clear that in each case, the corresponding signatures are quite distinct. The distinct natures of these signatures are very useful in performing an exact classification process on different test segments. In Figs. 10 and 11 , we have illustrated the signatures obtained on test segments of different sizes for the signatures corresponding to Aaron Brown. It is clear that the signature in Fig. 11 from the test segment of larger size is closer to the signature on the training data set. As a result, the accuracy of classification increases with increasing size of the test segment. In Figs. 12 , 13 ,and 14 , we have illustrated the accuracy on test segments of different sizes for the MFCC, LPCC, and GPCC formats, respectively. In each case, we trained for all 64 speakers simultaneously, and classified a test segment into one of these 64 speakers. This is significantly more difficult than a problem in which we try to distinguish a particular speaker from a control or mixed signal. This is because many speakers may have inherent similarity in their voice patterns, and it often becomes difficult to distinguish between a very large number of speakers using a single model. In each of the Figs. 12 , 13 ,and 14 , we have illustrated the number of records on the X -axis, and the classification accuracy over the 64 speakers on the Y -axis. In the same figures, we have illustrated the accuracy using Gaussian mixture models on test segments of different sizes. The accuracy of classification increases considerably with increasing test segment size because it is easier to build more accurate models on larger test segments. It is interesting to see that the accuracy of the micro-clustering process was significantly higher than the more computationally intensive (and offline) GMM approach. Our initial goals in designing this system were only to construct a system which could work in a one-pass approach for an online data stream, and we did not expect the micro-clustering approach to outperform the GMM model in terms of accuracy. Therefore, the (substantial) qualitative advantage of the micro-clustering approach over the GMM model was particularly surprising. We believe that the higher accuracy is because of the more compact representation of the micro-clustering approach. We note that the GMM approach required the estimation of a large number of model parameters which are often difficult to achieve accurately when training segments of only modest size are available. A larger number of model parameters naturally lead to overtraining, since the adjustable weights can often fit to the noise in the data [ 9 , 15 ]. On the other hand, the compact representation of the micro-clustering approach is less susceptible to overtraining because of the careful choice of a compact (but discriminative) representation of the training characteristics of the different speakers. This is a classic example of the  X  X ess is more X  paradigm in machine learning [ 9 , 15 ].

One observation from our tests was that the LPCC representation provided the best results (followed very closely by the MFCC representation), whereas the compressed LPCC method provided the least accuracy for the micro-clustering approach. However, this order was dif-ferent for the GMM model. In this case, the MFCC approach provided the best results, whereas the compressed LPCC representation provided better results than the LPCC method. The latter result is more surprising, since the compressed representation contained the least amount of information in the data. The effectiveness of the MFCC method for both the micro-clustering method and the GMM model is not particularly surprising, and is consistent with other results in the literature on the relative effectiveness of different data formats. 4.2 Real-time segmentation In this subsection, we will discuss the results for real-time segmentation of data streams. For this purpose, we used a segment of the stream which contained two speakers whose voice patterns followed one another. For this purpose we encapsulated a 13-s speech segment of Al Gore between two speech segments of Bill Clinton. We also assume that no training data were available for supervision purposes. In order to compute this alarm level at each point in the stream, we compute the difference in signature profiles over the contiguous windows. This is done using a 3-second segment over a 20-micro-cluster signature. In Fig. 15 ,wehave illustrated the alarm level for this contiguous segment. It is interesting to see that the alarm level peaks at certain points in the data. In the same figure, we have used an asterisked line to mark the positions on the X -axis at which the speakers change from one to the other. It is easy to see that the alarm level peaks at precisely the positions at which the speakers change from one to the other. This shows that the use of the alarm level can be used in order to perform effective real time segmentation of the data stream (without any training data). In order to illustrate this point better, we use the unsupervised methodology described earlier to enumerate the distinct histograms in the data in order to create a unique speaker id for each distinct histogram. In Fig. 16 , we have illustrated the speaker identification (on the same data set) using this method at various points in the stream. It is interesting to see that the speech segments for Bill Clinton correspond to speaker id 1, whereas the speech segments for Al Gore correspond to speaker id 4. However, the transition points were often classified as different speaker ids since the corresponding windows containing speech segments from both speakers. However, the overview provided by the method creates the ability to perform (unsupervised) speaker segmentation. 4.3 Outlier detection We also tested the outlier detection problem by running it with the MFCC format of the training data. The training data were organized in such a way that the segments for the different speakers were organized one after another in a contiguous way. We used a 95% level of confidence,and therefore the value of t was set at 1.96 using the normal distribution assumption. In most cases, the first time a speaker is encountered, it is tagged as an outlier. However, as subsequent segments of this speaker arrive, this speaker is no longer tagged as an outlier, since other segments which are close enough to the current data point are received. From the 64-speakers, 61 are tagged as outliers when they are encountered for the first time. All of these 61 speakers are no longer tagged as outliers when three more segments from the same speaker are received. Furthermore, 43 of the 61 segments are no longer tagged as outliers after receiving one more segment of the corresponding speaker, and 57 of the 61 segments were no longer tagged as outliers after receiving two more segments. This shows that the approach is not only quick at detecting outlier segments, but it is also quick at re-classifying an outlier as an actual pattern of speech, once subsequent data segments are received which show a consistent pattern of behavior. 4.4 Efficiency results In this subsection, we will discuss the efficiency results for the micro-clustering method for voice recognition. All results were tested on a simple laptop running the Windows XP operating system with 1.6 GHz, and 1 GB of main memory. We note that the GMM method was extremely computationally intensive because of the use of the iterative EM algorithm and could not be directly compared with the micro-clustering approach. The raw running times were several orders of magnitude higher than the micro-clustering approach. Furthermore, since the GMM model is not a one-pass online approach, it cannot be compared to the micro-clustering system in terms of stream progression. Therefore, we have illustrated only the results for the micro-clustering method. In Fig. 17 , we have illustrated the efficiency of the training process with progress of the data stream. We have illustrated the rate of processing for the compressed LPCC and the LPCC formats. We have omitted the results for the MFCC format since the two methods had exactly the same accuracy. It is easy to see that we processed thousands of data points per second for both the data formats. Furthermore, the rate of processing was higher for the compressed LPCC format because of its lower dimensionality. We note that this high rate of processing is because of the simple and efficient algorithms for constructing the signature from the online data stream. In Fig. 18 , we have illustrated the processing rate with progress of the data stream. We note that the testing process needs to perform the additional step of comparing the different signature profiles beyond the process of constructing them. This reduces the rate of processing from the training phase, but still continues to be over a thousand data points per second. 5 Conclusions and summary In this paper, we discussed an online system for voice recognition in data streams. We dis-cussed a micro-clustering approach which is not only efficient, but is significantly more accurate than the state-of-the-art GMM model. The greater accuracy of the micro-clustering approach is particularly surprising considering the fact that the GMM model is designed using the iterative EM-approach which does not have the constraints of the one-pass stream based micro-clustering model. While our system was originally designed with an intention of achieving greater online stream processing flexibility, and we did not intend to match the (qualitative) results of the GMM model, the final results greatly exceeded these initial goals. The reason for the surprising accuracy of the micro-clustering approach is the compact signature representation of the speakers . On the other hand, the GMM model turned out to be overly complex, and had a large number of adjustable weights which were susceptible to overtraining. Thus, the large number of parameters in the GMM model often fitted to the noise in the data. While the simplicity and compactness of the micro-clustering signature representation was originally designed only for speed, we found that it achieves the dual pur-pose of avoiding the overtraining of the parameter-heavy GMM model X  X  classic example of the  X  X ess is more X  paradigm in machine learning [ 9 , 15 ]. Furthermore, the system can perform both the training and testing simultaneously in online fashion. As a result when new training data are available, it can be incorporated quickly into the learning models of the system in order to adapt to the changes in the data. Furthermore, the system can also be used for a variety of other unsupervised applications such as speech and conversational segmentation in real time. Thus, the micro-clustering framework provides a real time, adaptable and accurate model for both unsupervised and supervised applications in speaker recognition. Our future work will extend this approach for a variety of related applications. Notes  X  A preliminary version of this paper appeared in the ACM KDD Conference, 2007 [ 1 ].  X  Research was sponsored in part by the US Army Research laboratory and the UK ministry References Author Biography
