 While multi-class categorization of documents has been of research interest for over a decade, relatively fewer approaches have been proposed for large scale taxonomies in which the number of classes range from hundreds of thousand as in Di-rectory Mozilla to over a million in Wikipedia. As a result of ever increasing number of text documents and images from various sources, there is an immense need for auto-matic classification of documents in such large hierarchies. In this paper, we analyze the tradeoffs between the impor-tant characteristics of different classifiers employed in the top down fashion. The properties for relative comparison of these classifiers include, (i) accuracy on test instance, (ii) training time (iii) size of the model and (iv) test time re-quired for prediction. Our analysis is motivated by the well known error bounds from learning theory, which is also fur-ther reinforced by the empirical observations on the publicly available data from the Large Scale Hierarchical Text Class-fication Challenge. We show that by exploiting the data het-erogenity across the large scale hierarchies, one can build an overall classification system which is approximately 4 times faster for prediction, 3 times faster to train, while sacrificing only 1% point in accuracy.
 I.5.2 [ Pattern Recognition ]: Design Methodology X  Clas-sifier design and evaluation ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Infor-mation filtering Hierarchical classification, Empirical Tradeoffs
With an increasing amount of data from various sources such as web advertizing, social media and images, automatic classification of unseen data to one of tens of thousand target classes has caught the attention of the research community. In flat classification, no relationship is assumed between the target classes and O ( K ) classifiers are learnt, one for each of the K classes. If some semantic structure exists among the classes, such as hierarchical, as in a rooted tree (Figure 1), a multi-class classifier is trained on each of the non-leaf node in the tree to distinguish between each of its children. For large scale classification, hierarchical strategies have two main advantages over flat classification: (i) to classify a test instance, one needs to evaluate only O (lg( K )) classifiers, as against O ( K ) for flat classification, and (ii) hierarchi-cal classification may lead to better (in general comparable) predictive performance as compared to flat techniques [4].
In the context of large scale hierarchical classification, open challenges like the Pascal Large Scale Hierarchical Text Classification (LSHTC) 1 and Imagenet Large Scale Visual Recognition Challenge (ILSVRC) 2 have been orgranized. In LSHTC for instance, the classes from the DMOZ and Wikipedia taxonomies are arranged in a rooted tree and di-rected acyclic graph respectively. The taxonomy thereby im-plicitly defines the semantic relationship among the classes. The publicly available DMOZ dataset contains around 400k training documents from the 27,875 target classes on the leaf nodes of the hierarchy tree with an extremely sparse repre-sentation involving 594,158 features. Outside of the LSHTC, various other approaches have also been proposed for large scale hierarchical classification, which have met with varying degrees of success (e.g., [1, 7]).

Previous approaches to large scale hierarchical categoriza-tion have mainly focused on the overall accuracy of the clas-sifiers without taking into account other important factors such as: (i) training time to build the model, (ii) size of the model generated by fitting the parameters, and (iii) test time to predict the target class of a given test example.
We study here the tradeoffs between using generative mod-els such as multinomial Naive Bayes, on one hand, and dis-criminative models such as Support Vector Machines (SVM) or Logistic Regression, on the other. In particular, we dis-cuss the variation of training sample size from the root of hierarchy towards the leaves, which further determines the choice of model one might want to fit.

Another contribution of this work is to highlight a useful scenario in which one could combine both types of models in the larger hierarchy to get the best of both worlds. Large scale category hierarchies which occur in most practical and commercial applications, such as DMOZ used in our experi-h ttp://lshtc.iit.demokritos.gr/ http://www.image-net.org/challenges/LSVRC/2011/ Figure 1: Example of a simple tree hierarchy, leaves a re represented by squares ments, are non-uniform across their entire structure. There-fore, to build an overall classification scheme, it is imperative to use classifiers which suit that particular local regime of operation. Empirical observations further demonstrate the interplay between various metrics of interest as we go from a fully discriminative setting to a fully generative framework.
We would also like to point out that the scope of this work is orthogonal to the large scale learning analysis by applying stochastic gradient descent [2] which essentially deals with binary classification in the context of large number of train-ing examples. They stress on the fact that, in order to attain better training performance, one need not fully solve the op-timization problem in learning the parameters and can stop the optimization process long before its convergence.
In single-label multi-class hierarchical classification, the training set can be represented by S = { ( x ( i ) , y ( i ) the context of text classification, x ( i )  X  X denotes the vector representation of document i in the input space X  X  R d . Assuming that there are K classes denoted by the set Y = { 1 . . . K } , the label y ( i )  X  Y represents the class associated with the instance x ( i ) . The hierarchy in the form of rooted tree is given by G = ( V , E ) where V  X  Y denotes the set of nodes of G , and E denotes the set of edges with parent-to-child orientation. The leaves of the tree which usually forms the set of target classes is given by Y = { u  X  V :  X  v  X  V , ( u, v )  X  E} .

In the above setup, given a new test instance x , the goal is to predict the class b y . This is typically done by making a sequence of predictions iteratively in a top-down fashion starting from the root until a leaf node is reached. At each non-leaf node v  X  V , a score f c ( x )  X  R is computed for each child c and the child b c with the maximum score is predicted i.e. b c = argmax For our analysis, we focus on SVM and Multinomial Naive Bayes (NB) representing discriminative and generative mod-els respectively. In SVM, f c ( x ) is modeled as a linear clas-sifier such that f c ( x ) = w t c x . To learn an SVM-based dis-criminative classifier for node v , we solve the following opti-mization problem for each child c of v The indices i above are such that  X  i, 1  X  i  X  n v , y i  X  L were L v denotes the set of leaves in the subtree rooted at node v and n v denotes the number of training examples for which the root-to-leaf path passes through the node v . Furthermore, if y i  X  L c and ( v, c )  X  E , then the constraints for the above optimization problem are given by,  X  i w x i  X  w t c  X  x i  X   X  i ,  X  c  X  6 = c s.t. ( v, c )  X  E , ( v, c We use standard multinomial NB model in which predicted class is the one with maximum posterior probability, i.e. and the probabilities are replaced by their maximum likeli-hood estimates, taking Laplace smoothing into account.
For a multi-class classification problem at node v of the hierarchy, let d v denote the dimensionality of the feature space and n v denote the number of training documents for which the root-to-leaf path goes through node v . Let their ratio for node v be denoted by r v , i.e. r v = d v n
I n the context of large scale hierarchical classification, such as DMOZ, there is a wide spectrum over which r v varies. For the classification problem corresponding to a node v at the top levels of the hierarchy tree, the ratio r is much higher as compared to its value for nodes at lower levels. Figure 2 shows the variation of average value of r for DMOZ dataset when plotted against the hierarchy levels. Each piece-wise linear curve in the plot corresponds to the class size range of the multi-class problem. Two important properties of the dataset, one of which follows from Figure 2, are: (i) The ratio r v increases towards the leaves, and (ii) Almost 97% of the multi-class problems involve 2-15 classes. Figure 2: Variation in ratio of feature set size to t raining sample size with the hierarchy level. Level 2 corresponds to the children of root node and level 5 to the level that leads to leaves.

This shows that the nature of the learning problem posed is different in different parts of the hierarchy tree. We now present relevant results from statistical learning the-ory which are perfectly suited to address these problems [6]. Let f G and f D represent the classifiers learnt by fit-ting generative and discriminative model respectively and f
G,  X  and f D,  X  be their corresponding asymptotic versions i.e. functions learnt when the sample size approaches infin-ity. Let  X  ( . ) be the function representing the generalization error of its argument. For a binary classification problem in d -dimensional feature space with n training examples, these results can essentially be summarized as follows: 2.  X  ( f G )  X   X  ( f G,  X  ) +  X  0 if n =  X  (ln( d )); 3.  X  ( f D )  X   X  ( f D,  X  )+  X   X  0 if n =  X  ( d ), for any fixed  X ,  X  Argument 1 implies that in the regime of aymptotic oper-ation, discriminative models should be preferred over gen-erative models. Argument 2 and 3 suggest that generative classifiers approach their asymptotic performance with much lesser training data as compared to discriminative classifiers.
As a consequence of the above arguments, this implies the following design choices to build component classifiers for large scale hierarchical classification. We also briefly men-tion our observation for each of them in case of DMOZ data: This indicates that, for lower levels in large hierarchy, NB is competetive to SVM and one can still employ NB instead of SVM, provided it can excel on metrics other than accuracy.
From above observations for the DMOZ dataset, if pre-diction accuracy is the only criterion, then employing SVM over the entire hierarchy seems to be the classifier of choice. However, this comes with a few cons as well, which include: (i) more training time to train the classifiers, (ii) large size of the models built from the training data, (iii) due to which the models need to be read from hard disk every time for hierarchical predictions which leads to significant slowdown for prediction time. The NB classifier, on the other hand, does not suffer from these disadvantages. Moreover, due to compact models in this case, one can load all the classifiers of the hierarchy in the physical memory and can get massive speedup for prediction.

This leads us to the conclusion that, depending on the relative priority to satisfy the conflicting constraints of ac-curacy and run-time, we can get best of both models by combining SVM and NB classifiers in an adaptive way. For node v in the hierarchy, this can be achieved by using a threshold  X  v for the feature set size to sample size ratio r The threshold value  X  v determines the choice of the classifier in the following way Property Name Value Total number of training examples 394,756 S ize of the Overall Feature Space 594,158 Number of Target Classes ( |Y| ) 27,875 Number of Nodes in the Hierarchy ( |V| ) 35,449 Size of training file on Disk 586.3 MB Depth of Hierarchy Tree 6 Total number of multiclass classifiers 7,574 Number of classifiers at depth 5 5,055
T he parameter  X  = {  X  v } ,  X  v  X  V , thus controls the trade-off between accuracy of the overall classification system and the response time for training and prediction. Even though the above thresholding strategy is a simplification of the classifier selection criterion in section 2.1, it works well in practice as shown in our experiments and presented in more detail in section 4.
The experiments were performed on a Linux system with 24GB physical memory and 1TB hard-disk. We use the pub-licly available DMOZ data set from the LSHTC, 2011. The dataset, after having been preprocessed by stemming and stopword removal, appears in the LibSVM format. Table 1 presents the numeric values corresponding to the impor-tant properties of the dataset. Since the average number of labels per document is 1.02, we consider it as single-label classification problem for our purpose.
 We use Liblinear [3] to train the models for L2-regularized L2-loss support vector classification. The optimization prob-lem was solved in the primal, since the dual formulation failed to converge for training classifier at the root node. The models are trained for all 7,574 non-leaf nodes in the hierarchy for One-Vs-All classification. For NB classifier, we implement the standard multinomial Naive Bayes us-ing Laplace smoothing. Predictions are done in a top-down manner starting at the root node till the class corresponding to a leaf node is finally predicted.

Table 2 shows the different classification mechanisms to build the overall classifier, which include, (i) SVM classi-fier for the entire hierarchy, (ii) Adaptive classifier selection strategy based on threshold value, (iii) Static classifier se-lection by deploying NB classifier at lower levels, and fi-nally (iv) NB classifier for the entire hierarchy. By employ-ing SVM-only classification system, the accuracy (35.6%) is comparable to the best participant (38.8%) in LSHTC for the DMOZ track. However, we would like to point out that the objective of our work does not coincide with the participants X  in the LSHTC challenge since the major fo-cus of the challenge is on accuracy related metrics. As a result, some of the participants do not necessarily utilize the hierarchy completely as in [5] or may employ some post-processing for higher accuracy. On the other hand, we take a more principled approach leading to a more robust and inter-pretable analysis which is also applicable to other large scale hierarchical classification problems involving more complex topologies such as directed acyclic graphs. Moreover, we aim to study the tradeoffs involving various constraints which
Model employed Accuracy SVM for entire hierarchy 35.6 35 20 A daptive Selection,  X  = 60 35.2 22 12 Adaptive Selection,  X  = 30 34.7 12 5 SVM with NB for last level 32.4 14 4 NB for entire hierarchy 22.2 0.25 0.5 Table 2: Tradeoff between Prediction Accuracy in % , Total Training for entire dataset in hours, and Average Test Time per Instance in seconds could be used to tune the desired behavior for a large scale hierarchical classification system.
Table 2 shows the tradeoffs as we go from a fully discrimi-native framework to a fully generative one. When replacing the SVM classifiers (row 1) at the outer-most periphery of the hierarchy by NB (row 4), there is a 10% decrease in accu-racy while the gain in prediction speed is close to 500%. This property could be leveraged to make robust real-time pre-dictions such as for large scale Question-Answering systems or data stream environments which need real-time response for acceptable behavior. Also, there is an almost 3-fold im-provement in training time as a result of this adaptation.
The gain in speed-up for training and test time is achieved as a result of more compact models built by NB as compared to SVM from same training data. All the NB models can, therefore, be loaded in the physical memory for predictions. For SVM, the total size of all the models is almost twice the physical memory size and hence the models for only the top two levels can be loaded in the physical memory.

The adaptive classifier selection as shown in row 2 and 3 of Table 2 was computed based on a uniform threshold value of  X  v = 60 and  X  v = 30 ,  X  v  X  V . Increasing the threshold value would select more SVM classifiers and thereby leading to better accuracy but slower training and test time. De-creasing it would correspond to more NB classifiers in the hierarchical framework, which leads to better run-time per-formance but lower accuracy.

Comparison between the adaptive classifier selection strat-egy and the static rule of applying NB classifier for the last level, rows 3 and 4 of Table 2, reveals another interesting observation. The prediction accuracy is noticeably higher by employing the adaptive strategy, for comparable values of training and prediction time.
 Figure 3 shows the variation of difference in accuracy of SVM and NB classifiers when plotted against levels in the hierarchy. As per the arguments given in section 2.1, SVM outperforms NB at the levels near the root node of the hier-archy. However, NB catches up with SVM for the classifiers at level 4 and level 5 of the hierarchy but it is not able to surpass SVM accuracy. This could be due to argument (1), i.e.  X  ( f D,  X  )  X   X  ( f G,  X  ), which implies that asymptotic gen-eralization performance of SVM is better than that of NB.
In this paper, we presented tradeoffs between conflicting constraints of prediction accuracy and computing resources Figure 3: Difference of SVM and NB accuracy, ( SVM -NB), in % for each hierarchy level. Level 1 corresponds to the root and level 5 to the level leading to leaves. which are crucial for the design of large scale hierarchical classification systems. Our analysis was based on utiliz-ing the heterogeneity in large scale web directories, such as DMOZ, for designing effective local classifiers. We also pre-sented an adaptive classifier selection strategy which can be employed to tune the extent of tradeoff. There are numer-ous avenues of further investigation, such as, (i) exploring more complex hierarchies such as graphs with cycles, (ii) ad-dressing the data imbalance problems among classes more effectively, and (iii) extension to multi-label predictions. This work was supported by the French National Research Agency(ANR). Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of ANR. [1] P. N. Bennett and N. Nguyen. Refined experts: [2] L. Bottou and O. Bousquet. The tradeoffs of large scale [3] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and [4] T.-Y. Liu, Y. Yang, H. Wan, H.-J. Zeng, Z. Chen, and [5] O. Madani and J. Huang. Large-scale many-class [6] A. Y. Ng and M. I. Jordan. On discriminative vs. [7] G.-R. Xue, D. Xing, Q. Yang, and Y. Yu. Deep
