 The advent of the Linked Open Data ( LOD ) initiative gave birth to a variety of open knowledge bases freely accessible on the Web. They provide a valuable source of informa-tion that can improve conventional recommender systems, if properly exploited. In this paper we present SPrank , a novel hybrid recommendation algorithm able to compute top-N item recommendations from implicit feedback exploit-ing the information available in the so called Web of Data. We leverage DBpedia , a well-known knowledge base in the LOD compass, to extract semantic path-based features and to eventually compute recommendations using a learning to rank algorithm.
 Experiments with datasets on two different domains show that the proposed approach outperforms in terms of predic-tion accuracy several state-of-the-art top-N recommenda-tion algorithms for implicit feedback in situations affected by different degrees of data sparsity.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval Hybrid Recommender System; Top-N Recommendations; Im-plicit Feedback; Learning to Rank; Linked Data; DBpedia
Information overload in the current Web challenges users in their decision-making tasks. Recommender systems have become essential tools in assisting users to find what is rel-evant for them in increasingly complex information spaces. The Linking Open Data project [3] started as a community effort in 2007, and helped to produce billions of RDF 1 state-ments that are now published on the Web. The result of this http://www.w3.org/TR/rdf-concepts/ initiative is a huge decentralized knowledge base, commonly known as the Linked Open Data ( LOD ) cloud, wherein each  X  X iece of little knowledge X  is enriched by links to related data. The development of a global information space con-sisting not only of linked documents but also of linked data has resulted in the emergence of the Web of Data as a subset of the World Wide Web.
 With the increased availability of this freely available knowl-edge, there is a great interest in taking advantage of such information to improve the quality of conventional recom-mender systems. Although recommender systems leverage well established technologies and tools, new challenges arise when they exploit the huge amount of interlinked data com-ing from the Web of Data.
 In the past, several works on ontological recommender sys-tems have been proposed. These works introduced the usage of ontologies and semantic technologies to boost collabora-tive filtering (CF) systems [2, 5, 16] or to build smarter content-based (CB) systems [21]. In particular they have been shown to be very effective in solving some drawbacks of collaborative methods such as cold start and data sparsity. Most of the works on ontological recommender systems are related to the rating prediction task. However, in the last few years a significant interest has grown towards ranking-oriented approaches as they seem to better approximate the top-N recommendation task [7, 23]. Differently from rating prediction, in top-N recommendations the goal of the sys-tem is to find a few specific items which are supposed to be the most appealing to the user instead of accurately predict all the missing ratings.
 Together with the top-N recommendation problem, great at-tention has been gained by implicit feedback scenarios and many recent works have addressed both these issues [20, 22]. Even though the case of explicit feedback where users express their preferences through ratings is the most known in the literature, the implicit feedback case has attracted in-creasing interest because in many real-world situations ex-plicit ratings are not available and implicit feedback requires no extra feedback on the user side.

In this paper we present SPrank ( S emantic P ath-based rank ing ), a novel hybrid recommendation algorithm able to compute top-N item recommendations from implicit feed-back that effectively incorporates ontological knowledge be-longing to the Web of Data with collaborative user prefer-ences in a graph-based setting. While several works have been proposed in the last recent years to address top-N recommendations and implicit feedback in the literature of collaborative filtering, for ontological recommender systems these issues mostly have not been investigated yet. In SPrank , the ontological knowledge describing the items has been ex-tracted from DBpedia 2 , a well-known encyclopedic knowl-edge base belonging to the LOD cloud. From the analysis of the DBpedia semantic graph we extract path-based fea-tures and use a learning to rank algorithm for computing the top-N recommendations as a ranking problem. We re-mark that previous work on semantic-aware and ontological recommender systems neither addresses the top-N item rec-ommendation task nor deals with implicit feedback datasets. Here we show how SPrank is able to compute accurate rec-ommendations in scenarios where collaborative filtering al-gorithms notoriously are not very effective, such as the ones affected by data sparsity. To the best of our knowledge, this is the first work proposed to address the top-N recom-mendation task as a ranking problem from implicit feedback by leveraging the Web Of Data. Main contributions of this paper are:  X  combination of semantic item descriptions from the Web of Data and implicit feedback for the top-N recommenda-tion task;  X  formulation of a hybrid recommendation problem in a learning to rank setting;  X  mining of the semantic graph of LOD datasets through path-based features to capture complex and not trivial relationships between items;  X  evaluation of the proposed approach in terms of accuracy of the top-N recommendations on real data from Movie-Lens and Last.fm .
 The remainder of this work is structured as follows. In Sec-tion 2 we discuss related work. We present our approach for top-N recommendation in Section 3. The experimental evaluation is carried out in Section 4. Conclusion closes the paper.
Several approaches have been proposed to incorporate on-tological knowledge in recommender systems. In the follow-ing we review some of them and more recent literature on LOD -based approaches. In addition, since we propose an on-tological top-N recommendation algorithm for implicit feed-back, we present related work in the same area.
 Ontological RSs . In [15] Quickstep and Foxtrot are pre-sented, two ontological recommender systems that make use of semantic user profiles to compute collaborative recom-mendations. A hybrid recommendation system is proposed in [5] where user preferences and item features are described by semantic concepts to obtain users X  clusters correspond-ing to implicit Communities of Interest . In [16] the authors introduce the so called semantically enhanced collaborative filtering where structured semantic knowledge about items is used in conjunction with user-item ratings to create a combined similarity measure for item comparisons. In [2] an approach is presented that integrates user rating vectors with an item ontology. In all of these works, the exper-iments prove an accuracy improvement over collaborative approaches especially in presence of sparse datasets. LOD-based RSs . Most of the works described so far have been produced before the LOD initiative was officially launched. In [8, 9] a model-based approach and a memory-based one to compute content-based recommendations are presented http://dbpedia.org leveraging LOD datasets. In [10] the authors present a knowledge-based framework leveraging DBpedia for computing cross-domain recommendations.
 Top-N RSs with implicit feedback . The rating predic-tion task is the main focus of all the ontological approaches presented so far. Instead, referring to the most recent top-N recommendation problem in the context of collaborative filtering, several works have been proposed in the last few years. SLIM [17] adopts a Sparse Linear method for learn-ing a sparse aggregation coefficient matrix that is used for computing top-N recommendations. In [18] the authors pro-pose an extension of SLIM to incorporate both users and side information about items thus showing an improvement of the performance associated to the usage of such informa-tion.
 Other works represent the top-N recommendation task as a ranking problem using learning to rank. In [22] CLiMF the authors present a collaborative-filtering algorithm able to directly optimize the Mean Reciprocal Rank. The authors of [20] propose a Bayesian Personalized Ranking (BPR) cri-terion for optimizing a ranking loss. Following this, in [12] a hybrid extension of BPR is presented that learns a linear mapping on the user/item features from the factorization and auxiliary user/item-attribute matrix. This extension of BPR is able to compute useful recommendations in cold-start scenarios. All these approaches deal with binary rele-vance data or only positive implicit feedback.
The main idea behind SPrank is exploring paths in a se-mantic graph in order to find items that are related to the ones the user is interested in. From the analysis of these paths we extract path-based features and apply a learning to rank algorithm for getting a ranking function able to rec-ommend the most relevant items to the user. However, ap-plying learning to rank to hybrid recommender systems is not as straightforward as in Information Retrieval for docu-ment ranking since we need to conciliate content-based and collaborative features in the same feature space. In the fol-lowing we detail the data model and the formulation of the recommendation problem, the path-based feature extraction and the algorithm for learning the ranking function.
The standard language to semantically describe resources in the Web of Data  X  and in the Semantic Web  X  is RDF . The RDF data model is a labeled directed graph where nodes correspond to entities and edges are properties connecting them. The semantics of such properties is explicitly modeled by means of an ontological schema represented in RDFS 3 or OWL 4 . Indeed, LOD datasets can be seen as semantic graphs where the knowledge related to an entity, e.g., a movie, a song or an artist, is encoded by linking different nodes/entities with each other via semantic-enabled edges. Semantic datasets can be used as the input for content-based recommender sys-tems. In fact, given a node representing an item, we can use the knowledge associated to the corresponding entity to dis-cover similar items available in the graph.
 Also the data model behind collaborative filtering problems http://www.w3.org/TR/rdf-schema/ http://www.w3.org/TR/owl2-overview/ Figure 1: Graph-based representation of the data model. can be seen as a graph as well  X  in this case a bipartite graph  X  where users and items are the nodes and users X  feedback are the links.
 The common graph-based nature of the data models for the two problems  X  content-based exploiting LOD and collabora-tive filtering  X  suggests interesting ways to model a hybrid recommendation engine. We can merge these two graphs ob-taining a new graph G = ( V, R ) as shown in Figure 1, where V denotes the set of vertices and R the set of relationships. Due to the nature of the problem we identify three relevant subsets of V : U , I and E representing users , items and enti-ties , respectively. Moreover, in our model the two following relations hold: I  X  E and V = U  X  E . Similarly, R contains two categories of relationships. In fact, we have R = S  X  P where S = U  X  I and P  X  E  X  E . More precisely, an edge s  X  S links a user u  X  U to his/her relevant items i  X  I while an edge p  X  P connects either an item i to another entity e  X  E in the graph or an entity e j  X  E \ I to another entity e k  X  E . In the rest of the paper we will use u , i , e and v to represent a node belonging to U , I , E and V , respectively. Analogously, we will denote with s , p and r the edges in S , P and R . Thanks to this graph-based for-mulation of the problem we consider both collaborative and content aspects in a unified representation and hence a uni-fied feature space. The purpose is recommending relevant items i to users u leveraging the knowledge encoded in the graph G . In the rest of the paper, in our data model we will always consider G as undirected.
Following the notation introduced by [20] for implicit feed-back scenarios, let  X  S be the matrix of implicit feedback, where  X  s ui = 1 if item i is relevant for user u (i.e., there is an edge of type s between u and i ), 0 otherwise. Looking at the graph in Figure 1, for user u 1 we have  X  s u 1 i 1 = 1,  X  s Starting from  X  S we define I + u = { i  X  I |  X  s ui = 1 } as the set of relevant items for u and I  X  u = { i  X  I |  X  s ui = 0 } as the set of unknown items for u . We call I + u the user profile of u . In Figure 1, with reference to user u 1 , we have I + u 1 = { i and I  X  u 1 = { i 3 , i 4 } .
 The main assumptions behind our approach are the follow-ing two: (I) only binary data of the user X  X  interactions can be observed through implicit feedback such as purchases, friendships, clicks, etc.; (II) most of the items in I  X  u with no observed interactions) are irrelevant, but some of them could actually be relevant. The unobserved items are exactly the items that have to be ranked. The ultimate goal of the system is to rank in the top-N positions items likely to be relevant for the user.
 We formulate the problem of computing the top-N recom-mendations in a learning to rank fashion similar to the doc-ument ranking problem adopted in Web search [14]. In par-ticular we adopt a regression based point-wise method. For each user-item pair ( u, i ) , we encode the features able to characterize the interaction between user u and item i in the vector x ui  X  R D where D is the dimension of the fea-ture space. Each component in x ui represents the relevance score between user u and item i with respect to a specific feature 5 . For each user u we assume to have information on the set of relevant items I + u , the set of unknown items I , the implicit binary feedback  X  s ui and the feature vector x ui . Finally, we introduce I  X  X  X  u  X  I  X  u computed by sampling, with a uniform probability distribution, a fixed number of unobserved items from I  X  u equal to K times the size of I being K a constant. In other words, I  X  X  X  u is the set of the K  X | I + u | uniformly sampled items from I  X  u . In Section 4.3.1 we will motivate the choice of K by means of experimental results.
 Now we have all the elements to formally define the training set T R as: Given the training set T R , computing the top-N recommen-dations for user u can be formulated as the task of generat-ing a ranking function f : R D  X  R such that f ( x ui )  X   X  s Eventually, we use f (  X  ) to rank the items in I  X  u and getting the top-N recommendation list for u .
Given a graph G as the one represented in Figure 1, we want to extract features able to characterize the interac-tions between users, items and entities capturing the com-plex relationships between them. The aim is to recommend items exploiting their underlying properties and attributes expressed in the semantic graph. The basic idea is to con-sider all the paths that connect the user to an item in order to have a relevance score for that item. The more paths be-tween user and item, the more the item is relevant for the user. However, in this formulation of the problem there are several types of paths and not all of them have the same rele-vance. Moreover, some paths that involve useless properties can be noisy for the purpose of recommendation. Based on these assumptions, we leverage a supervised approach and we delegate to the learning to rank algorithm the task of finding what paths are most relevant for computing top-N recommendations. In the previous section we introduced the feature vector x ui encoding the interest of the user u in the item i . In the following we detail how the vector values are computed.
 Given an undirected graph G as defined in Section 3.1, we define a path as the acylic sequence of edges of the form ( s, . . . , r l , . . . , r L ) where s = ( u, i ) and r
In SPrank we rely on path-based features as we will detail in Section 3.3. i 6 = i 0 . We also define the length of a path as the num-ber of edges contained within such path. We consider paths having length greater than 1 and less than or equal than a given L . We collect all the possible paths in G to build a P ath index. P ath ( j ) represents the j -th component in the index and it corresponds to a specific sequence of edge labels (i.e., to a path disregarding the actual nodes). Considering a user-item pair ( u, i ), we denote # path ui ( j ) as the number of paths between u and i corresponding to the specific P ath ( j ) entry in the index. In other words, it represents how many paths of type P ath ( j ) connect u and i . This aggregate in-formation corresponds to the frequency of P ath ( j ) in the sub-graph composed by all paths between u and i . We are now ready to define the path-based features. We define the j -th component in the feature vector x ui as: Equation (1) represents the importance of the specific se-quence of edge labels P ath ( j ) between u and i in the sub-graph constituted by all the associations between these two nodes. Specifically, it is the frequency of the specific path P ath ( j ) normalized with respect to the frequencies of all the existing paths between u and i .
 In order to clarify how to compute the feature vector x we show an example with reference to the graph in Fig-ure 1. For L = 4 we have the following paths: ( s, s, s ), ( s, p 1 , p 2 ), ( s, p 2 , p 1 ), ( s, p 1 , p 3 , p 2 ), ( s, p ( s, p 4 ), ( s, s, s, p 4 ), ( s, p 1 , p 2 , p 4 ), ( s, p respectively: path 1 ,  X  X  X  , path 10 and build the index P ath = { path 1 , . . . , path 10 } such that P ath (1) corresponds to path and so on. Between user u 3 and item i 1 , there are only paths P ath (1), P ath (3) and P ath (5). In particular, # path 0 for j = 2 , 4 , 6 , 7 , 8 , 9 , 10, and # path u 3 i 1 (1) = 2, # path 2 and # path u 3 i 1 (5) = 1. We can now compute the feature vector x u 3 i 1 for the pair ( u 3 , i 1 ). Following Equation (1), at the denominator we have the sum of the number of all the paths connecting u 3 and i 1 . This sum is equal to 5. Then, x 3 i 1 = (2 / 5 , 0 , 2 / 5 , 0 , 1 / 5 , 0 , 0 , 0 , 0 , 0). Path types . Depending on the type of links composing a path there are different types of paths. In particular, such paths can be: (I) collaborative if only links in S are involved as for ( s, s, s ); (II) content-based if there are only r l = 2 , . . . , L as for ( s, p 1 , p 2 ) or ( s, p 4 , p there is more than one link in S and at least one link in P as for ( s, p 4 , s, s ) or ( s, s, s, p 4 ). In Figure 2 we represent several examples of path types, referring to the music do-main. In particular, musical artists are items (red nodes) to be recommended to users (blue nodes). The green nodes are the entities, coming from DBpedia . Artists and entities are connected via DBpedia properties. In these paths there are user feedback edges ( likes ) and content-based RDF proper-ties ( dcterm:subject , skos:broader , dbprop:writer , dbprop:title ). In Figure 2, the paths connect the user An-drew to the artist Craig David 6 through the singer Adele liked by Andrew . Given that Andrew has shown interest for Adele , the task of the recommender system is to find other artists that are related to Adele . In this case we want to know if Craig David is a good candidate to be recommended to Andrew . A possible way for doing this is by exploiting the http://dbpedia.org/resource/Craig_David http://dbpedia.org/resource/Adele_(singer) Figure 2: Various examples of content, collaborative and hybrid paths. tastes of the crowd to find if users who like Adele also like Craig David . The path (a) of Figure 2 is an example of col-laborative path because it shows that there is another user ( Alex ) who likes both Adele and Craig David . We can also have longer chains of people with similar tastes, as shown in path (b) . Another way of recommending artists to An-drew is to find singers with similar characteristics to Adele (e.g., the genre of her songs, the prizes she won). These are content-based paths, as represented in Figure 2 by the paths (c) , (d) , (e) . We note that the usage of a LOD knowledge base such as DBpedia gives us the advantage of leveraging a valuable source of structured information. In fact, we can catch fine grained and not obvious relationships that in a non-ontological system we would otherwise miss. The last type of path is the hybrid one and it is shown in Figure 2 by path (f ) . In this case both collaborative and content-based information is combined.
In order to predict the ranking and form the top-N recom-mendation lists we deal with the learning to rank problem by adopting a point-wise approach. Point-wise methods have shown to be very effective in Web search ranking [14]. There are two point-wise algorithms that have proven particularly successful: Random Forests [4] and Gradient Boosted Re-gression Trees [11]. In fact, all of the top placed teams in the recent Yahoo! Learning to Rank Challenge used variants of these two algorithms coping with regression trees [6]. The fundamental concept underlying Random Forests is bag-ging . Bagging  X  or bootstrap aggregation  X  is a technique for reducing the variance of an estimated prediction func-tion. It works especially well for high-variance, low-bias procedures, such as trees. The idea behind this technique is to apply multiple times the same learning algorithm to bootstrap sampled versions of the training set. At the end, all the resulting models are averaged to reduce overfitting. Random Forest is essentially bagging applied to Classifica-tion And Regression Trees ( CART ) with full depth, where at each split only a subset of features is uniformly chosen and evaluated to find the best splitting point.
 Similar to Random Forests, Gradient Boosted Regression Trees ( GBRT ) is a state-of-the-art regression model, which is a combination of regression trees constructed using the boosting approach. Instead of training many full high vari-ance trees and average them to avoid overfitting, GBRT se-quentially adds small trees (weak learners), each of them with high bias. During each iteration, the new tree to be added focuses explicitly on the data points that are respon-sible for the current remaining regression error.
 We formulate the learning to rank problem as a combina-tion of both Random Forest and GBRT following the idea of BagBoo introduced by [19]. BagBoo combines the high accuracy of gradient boosting with resistance to overfitting and variance reduction of random forests. The basic idea is replacing simple tree models that are at the base of random forests with powerful and accurate gradient boosted trees. For a better understanding of BagBoo let us discuss the pseudo-code listed in Algorithm 1. The input of the learn-ing algorithm is the training data T R as defined in Section 3.2, on which learning the ranking function. Q , T , B are the parameters of the algorithm. Q specifies the number of features to be considered for each node in order to find the best split in the CART used in GBRT. T is the number of bags used in Random Forests and B is the number of itera-tions required by GBRT. The final model f returned by the algorithm is basically a Random forests of T  X  B trees. We have T GBRTs each one composed by B regression trees. These T GBRTs are learned in the for-loop at line 1. At line 2 T R t is sub-sampled with replacement from T R . At line 3 the f t GBRT is learned. At the end all the GBRTs learned in the loop are combined in the forest to form our final ranking function f .
 Algorithm 1 : BagBoo
In this section, we detail the results of the experiments ac-complished to evaluate the effectiveness of SPrank in terms of accuracy for top-N recommendations. The evaluation has been carried out on two real world datasets belonging to two different domains: MovieLens (movies) and Last.fm (mu-sic).
The first dataset is a subset of the MovieLens 1M dataset The original dataset contains 1,000,209 ratings for 3,883 http://www.grouplens.org/node/73 movies by 6,040 users. Since our recommendation approach is based on positive implicit feedback, we chose 5-star ratings as relevant for the user and we ignored all the other ratings. Hence, for each user u we set  X  s ui = 1 iff rating ui = 5. In this way we can reasonably assert that I + u contains only items relevant to u [7]. The second dataset comes from recent ini-tiatives on information heterogeneity and fusion in recom-mender systems 9 [1]. In particular, we used the dataset col-lected from the Last.fm music system 10 . This is an implicit feedback dataset consisting of user-artist listening data, in-dicating the frequency a user listened to an artist X  X  song. This dataset contains 1,892 users, 17,632 artists and 92,834 relations between a user and a listened artist together with their corresponding listening counts. In this case we chose the users X  average listening count as threshold to identify the relevant artists for each user. Then, for each user u we set  X  s ui = 1 iff count ui &gt; avg u , with the obvious meaning for count ui and avg u . For the purpose of our experiments in both datasets we removed users with less than twenty rele-vant items. In the following we will denote the two datasets MovieLens and Last.fm with ML and LF, respectively. Be-ing our approach based on LOD knowledge bases, we need to map items in ML and LF to resources in LOD . In this work, the LOD knowledge base we leverage is DBpedia . It is one of the main projects in the Linked Open Data cloud. It currently describes more than 3.77 million things and all this information is stored in RDF triples. We can extract sub-graphs related to the movie and the music domain by querying its SPARQL endpoint 11 . In the current 3.8 release there are about 71,715 movies and 34,186 artists. In the following we detail the procedure we used to map items in ML and LF to the correspondent DBpedia URIs and extract the semantic sub-graphs of interest.
As the initial step for the mapping, we extracted from DB-pedia the title and the year of production for all the movies in ML, by the following SPARQL query: We used a similar query to extract music artists from DB-pedia . Then, we performed a one-to-one mapping between the obtained sets of labels and the name of the movies and artists respectively in ML and LF by using the Levenshtein distance and checking also the year of production in case of ML. For ML we found a positive correspondence for 3,148 out of a total of 3,883 movies. For LF we found a match for 9,490 out of a total of 17,632 artists. The dump of the map-pings is available here 12 . At the end of this mapping phase we removed the unmapped items from the two datasets and we replaced the item IDs in the two datasets with the cor-responding DBpedia URIs. http://ir.ii.uam.es/hetrec2011/datasets.html http://www.lastfm.com http://dbpedia.org/sparql http://sisinflab.poliba.it/ mappingdatasets2dbpedia.zip
For each URI we extracted from DBpedia all the RDF triples containing it. For example the following SPARQL query re-turns all the triples corresponding to the songs written by Adele : An example of a returned triple is: dbpedia:Chasing_Pavements dbpedia-owl:writer dbpedia:Adele_(singer) .
 This triple states that Chasing Pavements has been written by Adele . At the end of this step we have an initial ver-sion of our graph of interest, consisting of entities directly linked to items. Starting from this set of entities we fur-ther query DBpedia to find other entities linked to them. Iteratively, we obtain a graph of increasing size increment-ing the distance from the original items. In the queries, we consider the RDF properties belonging to the DBpedia On-tology 13 plus two more properties: dcterms:subject and skos:broader . The former relates a resource to its cate-gories. They are used in Wikipedia to organize the entire project, and to help users to give a structure to the knowl-edge base, by grouping together pages on the same sub-ject. The latter models the hierarchical structure of the cat-egories. An example of these two properties is the path (e) in Figure 2. We decided to leverage the properties belonging to the DBpedia Ontology, because they represent high-quality, clean and well-structured information. The list of all the properties related to the Film class in the DBpedia ontol-ogy is available at http://mappings.dbpedia.org/server/ ontology/classes/Film . The list related to the Musical Artist class is available at http://mappings.dbpedia.org/ server/ontology/classes/MusicalArtist . At the end of the process, the final graph for ML contains 3,792 users, 2,795 movies and 104,351 entities (actors, directors, cate-gories, etc.) while the one for LF it contains 852 users, 6,256 artists and 150,925 entities (songs, genres, categories, etc.). We considered entities within paths of length L = 4.
For the evaluation of our approach we adopted a method similar to the one described in [7]. From the original matrix  X  S , we built two new matrices:  X  S train and  X  S test the former for producing the sets I + u , I  X  u and T R (used for training the model), as detailed in Section 3.2, the latter for evaluating the trained model. To create  X  S test we randomly selected ten positive feedback for each user from the initial matrix  X  S . In order to assess the performance of SPrank in situations affected by different level of data sparsity, we eval-uated our algorithm considering different sizes of user pro-files as done by [22]. Specifically, for each user we randomly considered at most m positive feedback from the original matrix  X  S (denoted with  X  given m  X  in Tables 1, 2 and 4) to form  X  S train , and we discarded all the others. We say at most m because some users can actually have less than m positive feedback. Different values of m correspond to different ma-sets T R . In Table 1 we show some statistics about the num-ber of non-zero entries in  X  S train ( nnz ), the average number http://wiki.dbpedia.org/Downloads38# dbpedia-ontology of non-zero entries for each user ( avg nnz ) and the sparse-ness ( spars ) of  X  S train for the different conditions ( given 5 , given 10 , etc.). For each condition we learned the model on the training set T R and we applied the learned model to predict the unknown values (0-entries) in  X  S train . We got the full recommendation lists by sorting the predicted values for each user and then we evaluated the accuracy for the top-N items. We repeated the procedure 5 times for each condition by randomly drawing new training/test sets in each round and at the end we averaged the results. To evaluate the accuracy of the system we measured the recall @ N , widely used for evaluating top-N recommender systems [7, 17]. The computation of recall @ N goes through a procedure similar to the one introduced in [7], as detailed in the following. For each  X  s ui in  X  S test , from the full recommendation list com-puted for u , we randomly selected 100 items appearing nei-ther in the test set related to that user nor in the user profile. We got a ranked list consisting of these 101 items. The top-N recommendation list is obtained by considering just the first N items ( N = 5 , 10 , 20) in this ranked list. Being pos the position of the test item i within the ranked list, we have a hit if pos  X  N , otherwise we have a miss. We note that for any single test case, we have just one relevant item (i.e., the tested item i ). The recall for a single test case is either 0 (in case of a miss) or 1 (in case of a hit). The overall recall on all users is defined by averaging over all test cases: The formula for precision@N differs from Equation 2 just by a multiplicative term N appearing at the denominator [7]. For this reason, in our results we do not report it. Table 1: Statistics of the ML and LF training ma-trices under different conditions of user profile size.
In the following, we present the results of the experiments that have been carried out to answer to the following ques-tions: 1. Is the chosen learning to rank algorithm effective? 2. Does the proposed approach improve, in situations af-fected by different degree of data sparsity, the recommen-dation accuracy with respect to existing state-of-the-art ranking-oriented approaches for positive implicit feedback?
To answer the first question we compared BagBoo , the learning to rank algorithm used in SPrank , with two other algorithms: Sum and GBRT . In Sum , the ranking function f ( x ui ) is the arithmetic sum of all the path-based feature values. On the one side, the comparison with Sum gives us a baseline for semantic-based recommendation algorithm where all associations are equally considered.This allows us to evaluate our learning to rank algorithm against a basic not ranking-oriented semantic recommender. On the other side, the comparison with GBRT is useful to prove the ef-fectiveness of combining bagging and boosting. We recall that BagBoo is an extension of GBRT as it is an ensemble of gradient boosting regression trees.
 Table 2 summarizes the accuracy results obtained on the two datasets. For the ML dataset we observe that Bag-Boo outperforms both GBRT and Sum in all the different conditions of sparsity degree, even when there are few pos-itive examples for each user. For example, if we analyze the recall@5 , the improvement of BagBoo over Sum goes from +6 . 6% to +11% respectively for the two limit condi-tions ( given 5 and given All ). We also see that for the condition given 5 the improvement with respect to GBRT is very marked (+15 . 8%), but it decreases with the increas-ing of positive examples (+2% for given 30 and +3 . 2% for given All ). For this dataset we observe that when there are only a few positive training examples for each user, GBRT is not able to learn an effective ranking function. This is not the case for the bagging of several GBRT s. Looking at the results for LF we observe again BagBoo outperforms the other algorithms but for the condition given 5 .
 From the results on the two datasets we can draw the follow-ing conclusions: SPrank benefits from learning to rank, both GBRT and BagBoo show substantial improvements with re-spect to the Sum baseline, particularly when the number of positive examples, and then the training data, increases; due to bagging, BagBoo outperforms GBRT in all the analyzed situations. Hence, BagBoo is a valid candidate for learning the ranking function in SPrank .
 Table 2: Results for BagBoo , GBRT and Sum given different user profile size.
 Impact of irrelevant item sampling . In Table 3 we show how different values of K , that is the factor that influences the size of I  X  X  X  u (cf. Section 3.2), affects the accuracy of SPrank . We can observe that increasing K and hence the number of unknown examples in the training data, the ac-curacy does not increase. An evident advantage in selecting a small K is the reduction of the training set size and con-sequently of the time required to build the model. Based on these observations, we chose K = 2 in all our experiments. Table 3: Accuracy results for different values of K (used to create I  X  X  X  u ).
In order to evaluate SPrank we compared it both with a hybrid algorithm proposed to address cold-start scenarios and with ranking oriented collaborative filtering algorithms. All of these approaches are state-of-the-art methods for posi-tive implicit feedback scenarios. BPRLinearMap ( BPRLin ), BPRMF and SLIM have been presented in Section 2. For BPRLinearMap we built the item-attribute matrix using the same content data used for SPrank . SoftMarginRankingMF ( SMRMF ) is a matrix factorization model for item predic-tion optimized for a soft margin ranking loss using stochastic gradient descent inspired by [23] [20].The computation of the recommendations for all these comparative algorithms has been done with the publicly available software library My-MediaLite [13].
 Results discussion . Table 4 shows the results obtained for SPrank and all the other comparative methods on both ML and LF. We observe that on the ML dataset our algorithm outperforms the others under all the different user profile conditions but given All where BPRMF achieves the best recall values, and SPrank gets the second best place. We can note that SPrank outperforms significantly the other methods when  X  S is very sparse. Referring to the SLIM method, for the conditions given 5 and given 10 , the im-provements in terms of recall@5 are respectively +20 . 2% and +23 . 3%.
 For the LF dataset, which is slightly sparser than ML, SPrank is always the best performing algorithm. In this case, BPRLin  X  the most suited approach for dealing with data sparsity  X  is the second best performing. Also in this case the improve-ments are substantial especially for the conditions of higher sparseness.
 From these experimental results, we can conclude that SPrank is able to compute accurate top-N recommendations even when there are few positive feedback where instead collabo-rative filtering algorithms have showed lower accuracy. On both datasets SPrank has also outperformed BPRLin , the other hybrid recommendation method proposed to address cold start and sparsity problems.
In this paper we have presented SPrank , a novel hybrid top-N item recommendation algorithm from implicit feed-back able to exploit LOD knowledge bases to compute ac-curate recommendations. In SPrank , positive implicit feed-back and semantic item descriptions are merged in a unique graph-based representation that allows us to extract path-based features describing complex relationships between items preferred by the user and items to be recommended. Then, Table 4: Comparison of SPrank with other ap-proaches under different conditions of the user pro-file size. the recommendation problem is cast in a learning to rank fashion to compute top-N recommendations.
 We have demonstrated in our experiments that SPrank out-performs several state-of-the-art approaches for implicit feed-back in two datasets belonging to two different domains: MovieLens for movie and Last.fm for music. The experi-ments have been conducted varying the sparseness of the im-plicit feedback matrix for analyzing how SPrank deals with sparse data with respect to other competitive approaches. We have observed significant improvements over collabora-tive filtering methods especially in case of high sparsity.
