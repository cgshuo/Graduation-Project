 We address the task of separating personal from non-personal blogs, and report on a set of baseline experiments where we compare the performance on a small set of features across a set of five classifiers. We show that with a limited set of features a performance of up to 90% can be obtained. H.3 [ Information Storage and Retrieval ]: H.3.1 Con-tent Analysis and Indexing; H.3.3 Information Search and Retrieval; H.3.4 Systems and Software Algorithms, Measurement, Performance, Experimentation Blog classification, language modeling
Reliable blog classification is an important task in the bl-ogosphere as it allows researchers, ping feeds (used to broad-cast blog updates), trend analysis tools and many others to separate, e.g., real blog content from blog-like content such as bulletin boards, newsgroups or trade market reports [1], to isolate spam blogs [3], to track developments in the blo-gosphere [5], or to identify specific blog genres as in [6]. We address the task of distinguishing between personal blogs and non-personal blogs, a type of classification that is use-ful, inter alia, for media analysis, reputation tracking, and for tasks such as the  X  X log distillation X  task considered at TREC 2007 [4]. We take a blog to be personal if it is an on-line journal, diary-like, in which the blogger keeps a running account of his or her daily life and shares intimate thoughts and feelings with the reader.

We report on a set of initial baseline experiments aimed at determining how basic classification and features sets per-form on this task. Starting with a basic feature set (consist-ing of frequent uni-grams), and we add more blog features and find that with limited feature engineering standard text classifiers are able to achieve up to 90% accuracy scores.
Below, we detail our experimental setup, describe the fea-tures used, and then report on our classification results, both for individual features and for sets of features.

We hand labeled a set of 152 blogs (76 personal and 76 non-personal) randomly sampled from a blog collection that we created for earlier blog classification work; see [1] for de-tails on the collection; we used the definition of personal blog as given in the introduction: an online diary-like jour-nal, in which the blogger keeps an account of her daily life and shares intimate thoughts and feelings.

We compared 5 machine learners implemented in the Weka toolkit [7]: Naive Bayes, SVM, kNN, decision trees, decision tables, and used all of them with default settings. Evalua-tion was done using 10-fold cross-validation, using  X  X ercent-age correct X  and precision and recall as the metrics on which we report.

As features for our classification experiments, we consid-ered the following.
 LM Following the popularity of features derived from uni-Pronouns We also consider a simple variation on this idea InLinks We assume that non-personal blogs are more likely OutLinks Acting on the observation that personal blogs Hosts For three hosts X  X logDrive, BlogSpot, and LiveJour-
Obtained from The Tongue Untied, A Guide to grammar, punctuation and style , URL: http://grammar.uoregon. edu/pronouns/pronouns.html http://technorati.com/developers/api/cosomos.html . We ran the following classification experiments: all features separately, all features combined, and all features minus the language modeling feature (LM) combined.
Table 1 lists the results of our classification experiments, listing the percentage correct scores. We see that, by it-self, and independent of the learner used, the LM feature performs rather poorly, below the 50% baseline for most classifiers, indicating that personal and non-personal blogs are not separable in terms of general language usage.
However, if we look at the language usage of specific parts of speech, i.e., of pronouns, we do see noticeable improve-ments over the 50% baseline, with scores up to 77%, showing that there is a marked difference in the usage of this partic-ular type of  X  X anguage. X 
Next we look at the InLinks and OutLinks feature. Here, we again see a marked improvement over the 50% baseline, but we do not see much of a difference in performance be-tween the two features.

The three hosts features behave differently. Hosts-BD (in-dicating whether a blog is hosted by BlogDrive) is unhelpful, Hosts-BS (indicating whether a blog is hosted by BlogSpot) consistently improves over the baseline, Hosts-LJ (indicating whether a blog is hosted by LiveJournal) helps even more, leading to a performance of over 80% correctly classified.
Finally, we look at two sets of features: one in which all features are included, and one in which all features but the LM feature is used. We see that the best performance is achieved by leaving out the LM feature X  X pparently, it is simply too noisy to be of any use, especially for the Naive-Bayes classifier. The performance of the Decision tree and Decision table classifier are comparable, and somewhat higher than the performance of the SVM and kNN classifiers, which in turn outperform the NaiveBayes classifier.
 Table 2: Precision and recall figures for two groups of features NaiveBayes 0.57/0.87 0.96/0.26 0.58/0.80 0.93/0.26
SVM 0.98/0.76 0.68/0.99 0.98/0.76 0.68/0.99 kNN 0.84/0.82 0.82/0.84 0.85/0.81 0.80/0.86 Decision tree 0.95/0.83 0.82/0.96 0.86/0.83 0.82/0.87 Decision table 0.94/0.87 0.86/0.95 0.94/0.87 0.86/0.95 In Table 2 we take a closer look at the precision and recall figures for the two groups of features ( All and All \{ LM } ). We see that, on the whole, and except for NaiveBayes, the precision numbers are mostly higher than the recall num-bers, and that the LM feature has a slightly negative impact on both recall and precision (for the Decision tree learner).
We addressed the task of separating personal from non-personal blogs and reported on the outcomes of a set of initial baseline experiments aimed at this task. Off-the-shelf learners, with a small set of well-chosen features are able to achieve up to 90% correctly classified scores.

We also found that a standard language modeling-based feature set is not helpful in distinguishing between personal and non-personal blogs, although narrowing the feature set down to pronouns only does lead to substantial improve-ments over the baseline.

In future work we want to extend the set of labeled blogs used in our experiments, and examine additional features. Moreover, we aim to integrate the classification scores into our retrieval engine for both blog post and blog search [2], on the assumption that for many professional users, non-personal blogs should receive a boost in ranking.
This research was supported by the E.U. IST programme of the 6th FP for RTD under project MultiMATCH contract IST-033104, and by the Netherlands Organisation for Scien-tific Research (NWO) under project numbers 220-80-001, 017.001.190, 640.001.501, 640.002.501, STE-07-012.
