 Keyword extraction for documents such as research papers and news articles is widely used in digital library and information retrieval. Content-based tag recommendation for web resources such as blogs and product reviews is an important application in Web 2.0, which can ease the process of social tagging for users. Since both keyword extraction and content-based tag recommendation seek to identify most representative terms from document contents, ranking terms thus plays a crucial role in the both applications.
Previous methods simply rank terms by frequency measures such as tf idf or  X  2 statistics, which are found to lead to poor results. In recent years, there is a surge of studies on graph-based methods for term ra nkings. These methods apply graph-based ranking algorithms, such as PageRank [4] and HITS [15], to rank terms in given docu-ment and select those with the highest ranking values as keywords or tags [20].
Domain knowledge is the knowledge of some specialized disciplines. In practice, there is usually domain information in addition to documents, which indicates the do-main knowledge shared by the document and other documents in the same domain. The domain of a document can be either large or small. Here are two examples of do-main information of documents. For news websites such as CNN.com , news articles are classified into different categories such as sports , science , business and politics .These category-like domains are large. Meanwhile, these news articles are also organized ac-cording to various popular themes, such as financial crisis , air pollution and world cup football match . These theme-like domains are small. Similar to news articles, for online bookstores such as Amazon.com , book reviews are divided into categories such as arts , literature , philosophy and history . The reviews under the same category share a large category-like domain knowledge. M eanwhile, according to s ome popular themes, various books on the same themes are collected together and their reviews share a small theme-like domain.

Generally, for a document under a specific domain, we are usually more interested in the part that is related to the domain. Domain knowledge of a document may thus play an important role in keyword extraction and tag recommendation, which can help focus on the important part of documents and filter out noise. In order to apply domain knowledge, we have to find a method to represent both terms and domains, and then rank terms by measuring their relatedness with given domains. In this paper, we use latent topic models to represent terms and domains, and then perform domain-specific term rankings.

The key idea of latent topic models is to represent terms and document as a mixture over latent topics. In a pioneer work [6], a topic model, i.e., probabilistic latent semantic analysis (pLSA), is proposed to rank documents in a corpus. Latent Dirichlet allocation (LDA) [3] was further proposed by adding Dirichlet priors on pLSA to avoid over-fitting problem. The success of latent topic models for modeling documents motivates us to propose a new latent topic model, referred to as Domain-Topic Model (DTM), for modeling domain knowledge of documents. Given a set of documents where each doc-ument has one or more domain labels, either category-like or theme-like, DTM learns topic distributions of words as well as topic distributions of domains. Using a learned DTM, we can rank term w in domain c by comparing their topic distributions. In this paper we investigate various measures of co mputing relatedness between domains and terms using their topic distributions. Existing methods for keyword extraction can be categorized into supervised classification-based approach and unsupervised ranking-based approach. For the for-mer approach, some researchers adopted supervised learning methods to build two-class (is a keyword or not) classifiers to identify keywords, which is first proposed by [27] and the following supervise-based methods mostly considered more linguistic fea-tures of terms for developing classification system [12]. Since the supervised approach needs manually annotated training set, it is sometimes not practical under web circum-stance. Starting from TextRank [20], graph-based ranking methods are becoming the most widely used ranking approach for keywo rd extraction. In recent years, many exten-sions of TextRank have been proposed for keyword extraction [17,29,28,18]. Besides, clustering methods on word graphs are also proposed for keyword extraction [19,10]. Unsupervised ranking terms is a practical approach for keyword extraction.

Some researchers have noticed the importance of domain knowledge [8,13]. In these work, however, human annotations are required to reflect domain knowledge in key-word extraction, either by building separate t raining set of different domains for classi-fiers [8] or using human-defined domain specific thesaurus as external knowledge [13]. The method in this paper, in contrast, can extract domain knowledge in an unsupervised manner.

Social tagging, as known as folksonomy, is a popular approach to organize online resources like documents, bookmarks and photos. Tag recommendation systems are usually designed to ease the process of social tagging, which can suggest tags to a new object based on previous tagged objects, user preferences or keyword extraction from the text content of the object. Most tag recommendation methods focus on ana-lyzing the relations between object, tags and users. For some special online resources such as blogs and product reviews, it is may be practical to recommend tags based on contents. Many supervised methods have been proposed for content-based tag recom-mendation [21,14,26]. None of these methods, however, have taken domain knowledge into account for content-based tag recommendation. Since we focus on investigating the usefulness of domain knowledge for term r ankings, our method is thus only compared with TextRank, without considering the supervised methods mentioned above. 3.1 Domain-Topic Model DTM models documents composed of words and domain labels. Each document d consists of N d words w d = { w d, 1 ,...,w d,N d } and L d domain labels y d = { y the domain labels are selected from a set of C unique labels.

Under the assumption that most words in a document describe the domain informa-tion of the document, we define DTM as a generative process as follows: where Dir (  X  ) , Uni (  X  ) and Mul (  X  ) indicate the Dirichlet distribution, Uniform distri-bution and Multinomial distribution, respectively. In the generative process,  X  c is the topic distributions of domain c , drawn from a symmetric Dirichlet prior  X  ;  X  k is the word distributions of topic k , drawn from a symmetric Dirichlet prior  X  .  X  and  X  are predefined as prior knowledge. Empirically we set  X  =50 /T and  X  =0 . 01 where T is the topic number [9].

Figure 1 shows the graphical representation of DTM in comparison with LDA. DTM is identical with Author-Topic Model (ATM) [25] in form, while ATM was proposed for modeling documents with authors.

Let w , z and u be the vectors of all words and their topic and domain label assign-ments of the whole document collection D . Given observed words and domain labels of a set of documents, the problem is inferring the hidden topics z . Since estimating posterior is intractable, various approximate methods could be used to estimate DTM. In this paper, we use Gibbs Sampling [9] to learn DTM by sampling u i and z i for each word w i . The topic assignment for a particular word depends on the current topic as-signments of all the other words. That is, the domain and topic of a particular word w i in document d with domain labels y d is sampled from the following distribution:
P( u i = c, z i = k | w , z  X  i , u  X  i , y d , X , X  )= where w  X  i , z  X  i and u  X  i are all other words in w except current word w i and their corresponding topic and domain label assignments, n ( w i )  X  i,k is the number of times that to domain c .The  X  i indicates the counts are taken by not including the value of w i .
When finishing Gibbs Sampling, we obtain the model consisting of both topic distri-The probabilities of word w and domain c given topic k are computed as follows: the total number of times that topic k is assigned to domain c . Correspondingly, we can also obtain the probabilities of topic k given word w ,i.e., P( k | w ) and given domain c , for domain-specific term rankings, which is introduced in the following section. 3.2 Distributed Gibbs Sampling of DTM To handle large-scale learning tasks, in this paper we implement a parallel version of DTM using the MapReduce parallel programming model [7], namely PDTM, where training documents are distributed over distinct processors for distributed Gibbs Sam-pling. The basic idea of PDTM is motivated by [22]. Here is an overview of PDTM algorithm. Given P processors, we partition documen ts and corresponding assignments into P disjoint subsets. Then simultaneous Gibbs Sampling is performed independently on each processor, as each processor thinks it is the only processor and updates it own copy of DTM. After each Gibbs Sampling iteration, each processor outputs its update to the model. Then an operation is performed to collect and merge the outputs from all processors, and broadcast the new model to all processors.

Our experiments consistently showed that the convergence rate for the distributed algorithms is as rapid as for the single pro cessor case. As an example, Figure 2 shows test perplexity versus iteration number of Gibbs Sampling (NIPS data, T =50 and P =10 ). Despite having no guaranteed formal convergence, PDTM works very well empirically. 3.3 Ranking Terms Using DTM To investigate the performance of DTM for domain-specific term ranking, we focus two important applications, keyword extraction and content-based tag recommendation.
A term for rankings usually contains more than one words. For a given term t ,we compute and where the fraction P( k ) P( t ) is approximated by the number of times that topic k occurs in training corpus, i.e., n k , divided by the number of words in term t , i.e., n t .
After obtaining P( t | k ) and P( k | t ) , using DTM we can rank term t given domain c by characteristics measure [6]: This measure can identify what terms are characteristic of a domain c . A rarely-used term that is mainly used in domain c is not characteristic of c ; neither is a term with high frequency in domain c , if it is also heavily-used by all other domains. The idea is similar to the measure of tf idf . That is, the former factor is controlled by P( t | c ) and the latter is by P( c | t ) .

Given a domain, we can also rank terms by KL-divergence between the topic dis-tributions of terms and the domain. KL-divergence is a asymmetric measure of the difference between two probability distributions by computing the expected extra in-formation of one distribution compared to another distribution. By representing both terms and domains using topic distributions, we can use KL-divergence to measure the semantic diversity between terms and domains: The third method to rank terms is predictive likelihood [11]: This is a part of the formula (Eq. 5) of char acteristics, which indicates how likely term t occurs under domain c . In this section, we evaluate DTM on both keyword extraction and content-based tag recommendation. Since we focus on investigating the usefulness of domain-specific rankings, we only compare our methods with other content-based methods, i.e., Tex-tRank and LDA for evaluation. 4.1 Keyword Extraction The experiments of keyword extraction using DTM are carried out on a dataset of En-glish news articles. However, we should not e that the method is language independent. We first introduce the dataset and the training process of DTM.
 Dataset. The dataset of news articles is annotated by Wan and Xiao [29], based on 308 news articles in DUC2001 [23]. The news articles are divided into 30 document sets. Each set is on an event or theme, which is regarded as a specific domain in experiments.
The news articles are too few to learn DTM. We construct a corpus consisting of both the news articles and English Wikipedia to learn DTM. Since the articles in Wikipedia are supposed to compile all human knowledge , high quality topics can thus be learned by taking Wikipedia as background. In experiments, Wikipedia articles come from the March 2008 snapshot. After removing non-article pages and removing articles shorter than 100 words, we collected 2 , 122 , 618 articles. After tokenization, stop word removal and word stemming, we build the vocabulary by selecting 20 , 000 words with top doc-ument frequency value. We learn DTM on the corpus by taking the set of each news article as its domain label, as well as taking the title of each Wikipedia article as its unique domain label. In this paper, we use the learned DTM with the number of topics T =1 , 000 selected by cross validation.
 Results and Evaluation. Keyword is a term which may be a single word or a multi-word phrase. Not all words or phrases in document are possible to be selected as keywords. In order to filter out some noisy words and phrases in advance, we se-lect candidate keywords using some heuris tic rules. This step pr oceeds as follows. Firstly, the document is tokenized for English or segmented into words for Chinese and other languages without word-separators. As reported in [12], most manually as-signed keywords turn out to be noun phrases. Therefore, we annotate the document with POS tags using Stanford Log-Linear Tagger 1 . Then we extract the noun phrases whose pattern is zero or more adjectives followed by one or more nouns, represented as (adjective) * (noun)+ . These noun phrases are regarded as the candidate key-words of the document.

Using DTM, for each candidate keyword, we compute its relatedness with the do-main using characteristics, KL-divergence and predictive likelihood. With the related-ness, we carry out domain-specific rankings for keyword extraction. In contrast with DTM, using LDA, we are only able to measure the relatedness between candidate key-words and the document according to their t opic distributions. For TextRank, we follow the implementation in [29].

For evaluation, the keywords extracted by different methods are compared with man-ually labelled keywords. All words in a keyword are first reduced to their base forms for comparison. In this paper, we use Porter Stemmer 2 to complete the process. The precision, recall and F-measure are used as ev aluation metrics, which are widely used in keyword extraction task.

The experiment results of TextRank, LDA and DTM when extracting 10 keywords are shown in Table 1, where  X  X HAR X ,  X  X L X  and  X  X SC X  indicate characteristics, KL-divergence and predictive likelihood for measuring relatedness, respectively. It is clear that LDA outperforms TextRank and DTM outperforms both TextRank and LDA, which indicates the effect of domain knowledge. We also note that KL-divergence outperforms other measures in both LDA and DTM. In Figur e 3, we demonstrate the precision, recall and F-measure with different number of keywords from 1 to 20 for TextRank, LDA and DTM (using KL-divergence). We can see that DTM always outperforms TextRank and LDA especially on precision when the number of keywords are small.
 We further demonstrate an example of extracted keywords from a news article by TextRank, LDA and DTM. The title of this article is Commodities and Agriculture: Investors sought for Zimbabwe diamond mine . The domain of the article is on diamond mines and diamond trading . As shown in Table 2, top five keywords extracted by the three methods is listed in descending order of ranking values. Compared to standard answers, these keywo rds are identified with + and  X  marks.

Because TextRank only uses the cooccurrenc e information within the article for rank-ing terms, it can not properly measure the relatedness between terms and the article. TextRank thus can not identify most representative terms of the article. As shown in Table 2, TextRank selects the heavily-connected de beers in word graph as a keyword, which in fact does not match the theme of the ar ticle. By representing terms and the ar-ticle using their topic distributions, LDA easily identifies the most theme-relevant terms of the article. Nevertheless, since there are some  X  X oisy X  parts in the article which may have nothing to do with the domain of this article, LDA selects gem quality as a keyword by mistake. DTM, however, can avoid the mistake by taking the domain knowledge of the article into consideration and make all of top five extracted keywords correct. We also show top five topics of article FT933-8941 and its domain in Table 3 and Table 4 for com-parison. These topics are represented by their top three characteristic words. We find that both the domain and the article focus on Topic-1307 on diamond . The domain, however, pays more concentration of Topic-1307 with probability 0 . 1261 compared to 0 . 0648 of the article on this topic. This makes sure that DTM is more robust against noises.
From the evaluation results and examples, compared to TextRank and LDA, we show the robust advantages of domain-specific term rankings for keyword extraction using DTM in the news dataset. In the following section, we will further investigate the per-formance of DTM for content-based tag recommendation. 4.2 Content-Based Tag Recommendation In this section, we try to recommend tags for restaurant reviews based on their con-tents. The reviews were crawled from Dianping ( http://www.dianping.com ), the largest Web review service website in China.
 Dataset. The review dataset contains 108 , 161 restaurant reviews in Chinese. The dataset itself is also too small to learn DTM. We thus combine more web articles with the review dataset together as the corpus for learning DTM, where the web article dataset contains more than 2 million articles. In this corpus, all restaurant reviews are labeled with do-main label restaurant , and each web article takes its ID as its unique domain label. After word segmentation and stop word removal, we select 50 , 000 words with top document frequency as the vocabulary. We set the number of topics T = 800 to learn DTM. Results and Evaluation. As described in Section 3.3, given the trained DTM, we rank each term in the review given the domain of restaurant . In the experiment using Tex-tRank, we follow the approach described by [20] to build a word graph for each review and rank terms using their PageRank values.

Most Dianping reviews have user-labeled tags. For experiments, we only keep the tags that occur in the corresponding reviews. The 108 , 161 reviews used here are all selected with one or more tags that occur in the corresponding reviews. Among the reviews, 103 , 068 are labeled with one tag, 4 , 856 with two keywords and 237 with threeormoretags.

We select top-m words from review using DTM and TextRank respectively. Here we do not list the result obtained by LDA due to its poor performance, whose max F-measure value is only 14 . 2% for m from 1 to 20 . This also indicates the impor-tance of modeling domain information for ranking. Similar to the results in Section 4.1, KL-divergence also outperforms other measures in domain-specific term rankings using DTM. In the following results, we only demonstrate the results of DTM using KL-divergence. Figure 4 (Top) compares DTM and TextRank with respect to various number of keywords. From this figure, we can see that DTM outperforms TextRank in all three measures. When m is small, this advantage is especially salient. We also examine the effectiveness of DTM and Tex tRank with respect to document length. The distribution of document length in Dianping dataset is shown in Figure 4 (Middle), and most reviews have 20 to 100 words. As shown in Figure 4 (Bottom), when m =10 , DTM outperforms TextRank completely in range of document length from 20 to 400 .
In Table 5, we show top four topics with the highest P( k | c ) values in reviews and their characteristic words. Note that we translate original Chinese words in English here. Top 10 characteristic words of reviews computed using Equation 5 are translated as follows: delicious, hot pot, tofu, beef, pepper, snack, taste, flavor, Sichuan-food and wine shop. We can see that using DTM to model domain knowledge for content-based tag recommendation is reasonable.

Comparing the performance of LDA on keyword extraction and tag recommenda-tion, we find that LDA performs better than TextRank on news articles and worse on restaurant reviews. This may be because news ar ticles are better-structured than restau-rant reviews. On the other hand, restaurant reviews are generated by millions of users and there are thus more noises. Since LDA ranks terms by comparing their topic dis-tributions with the topic distribution of the document, it is sensitive to the noises in the document. Therefore, LDA performs poorly on the documents with many noises. In contrast, by considering domain information, DTM performs the best on both news articles and restaurant reviews. This indicat es that domain information can effectively prevent term rankings from the influence of document noises. In other words, the more noises that a document has, the more necessarily we should take domain knowledge into consideration for term rankings. In this paper we present a novel method, referred to as Domain-Topic Model (DTM), to model domain knowledge of documents. Using DTM, we further perform domain-specific term rankings. By introducing the domain information as a crucial ranking factor in keyword extraction and content-based tag recommendation, DTM outperforms TextRank and LDA.

In this paper, DTM only considers the importance of a term in a specific domain, with-out taking the importance of the term in the corresponding document. We plan to com-bine both measures together for keyword extraction. Considering that in many cases, we do not have explicit domain information, instead, we may have a query. An interesting future work is to extend DTM to query-focused term rankings. In these years, several su-pervised topic models have been proposed [5,1,2,16,24]. We plan to try these supervised topic models as possible alternatives to DTM for domain-specific term rankings. We want to thank Dr. Yi Wang for helpful discussions and comments. This work is supported by the National Natural Science Foundation of China (NSFC) under Grant No. 60873174.

