 One of the promising directions in research on learning to rank concerns the problem of appropriate choice of the ob-jective function to maximize by means of machine learn-ing algorithms. We describe a novel technique of smooth-ing an arbitrary ranking metric and demonstrate how to utilize it to maximize the retrieval quality in terms of the NDCG metric. The idea behind our listwise ranking model called TieRank is the artificial probabilistic tying of pre-dicted relevance scores at each iteration of the learning pro-cess, which defines a distribution on the set of all permuta-tions of retrieved documents. Such distribution provides us with a desired smoothed version of the target retrieval qual-ity metric, which is possible to maximize using a gradient descent method. Experiments on LETOR collections show that TieRank outperforms most of the existing learning to rank algorithms.
 Categories and Subject Descriptions: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval General Terms: Algorithm, Experimentation, Perfor-mance Keywords: learning to rank, ranking function, information retrieval measures
Learning to rank is one of the most challenging problems in the field of Information Retrieval. A general learning to rank problem is usually defined as the problem of construct-ing a ranking function given a set of query-document pairs with their relevance labels and extracted features. Such a function assigns retrieval scores to documents, so that they could be sorted by their actual relevance to the given query using these scores. This set-up does not allow to apply stan-dard gradient descent methods directly to the retrieval qual-ity measures, since those measures are typically discontin-uous functions of predicted retrieval scores. One class of approaches proposed to cope with this problem suggests to optimize not the quality measure itself, but its smooth mod-ification, what still leads to the optimization in terms of the initial measure.

A number of proposed smooth modifications of retrieval quality metrics corresponds to certain distributions on the set S m of all permutations of m retrieved documents. One of the first methods based on this idea is ListNet algorithm [2] which aims to minimize the cross-entropy between two Luce-Plackett probability distributions: one based on relevance labels and another one based on retrieval scores. Computa-tional complexity of ListNet is considerably high, so authors focus on inferring the probability of retrieving a document at top positions only. SoftRank method [5] is based on the corrupting of the predicted scores s j with Gaussian noise with standard deviation  X  . This randomization produces a smooth probability distribution on S m . However, in general case, this distribution is infeasible to compute, so authors implement a smoothed metric using a pairwise approach to estimate the distribution. Another distribution over permu-tations, motivated by Boltzmann distribution was studied in the scope of BoltzRank algorithm [4]. This distribution was used to better handle the estimation of the target distri-bution in SoftRank. SmoothRank algorithm, which is very similar to SoftRank, relies on a simplified version of Gaus-sian noise function [3] and focuses on making an appropriate choice of the smoothing parameter  X  . To be more precise, this method heuristically defines probabilities h i,j of rank-ing the i -th document at j -th position after corrupting the ranking function with noise.

In this paper, we introduce a learning to rank method which is somewhat close in spirit to the above-mentioned methods, as it optimizes a smoothed variant of the NDCG -metric. We assume that each predicted score s j is a Bernoulli random variable with two integer values b s j c and d s j e and a parameter that depends on s j . Each possible combination of these variables results into a ranking func-tion producing tied scores. A ranking produced by such a function, which we call a partial ordering , is the core element of our approach. After we define a distribution on the set of partial orderings, we consider the expectation of NDCG @ k as the smooth objective function. In order to calculate the NDCG @ k metric on a partial ordering, we use the method proposed by McSherry and Najork [6]. By applying gradi-ent boosting tree-based algorithm [1] to the problem of ob-jective function maximization, we learn a ranking function. Since our algorithm is based on artificial tying of retrieval scores, we call it TieRank.
The crucial point in such methods is the choice of the appropriate distribution, so we list the major advances of the distribution introduced in our TieRank algorithm.
The remainder of this paper is organized as follows. The next section describes our approach in details. First, Sec-tion 2.1 provides a high-level description of our method. Then we proceed with the definition of tied NDCG @ k met-ric in Section 2.2. In Section 2.3 we provide a detailed intro-duction into the distribution implemented in TieRank and define a smooth objective function. Section 3 contains the experimental results. Conclusions and possible ways to ex-tend the presented work are discussed in the final section.
Let D i = { d i 1 ,...,d i m } be the set of documents retrieved for the query q i and { rel i (1) ,...,rel i ( m ) } be their rele-vance labels. Each query-document pair is represented by a vector of features and our goal is to rank the documents in D i according to their relevance to the query q i . Given the training data consisting of above-described queries and document sets, we learn a function f of query-document features, which assigns a score f ( q i ,d i j ) = s ( q ,d i j ), and then we sort the set of documents D i according to these scores (from now on, we omit i indices).
 To measure the effectiveness of the ranking model usually Precision,AP,DCG,NDCG metrics are used. We focus on optimizing the NDCG metric in this work. The value of the DCG @ k metric (discount cumulative gain at the position k ) of the ordering  X  = { v 1 ,...,v m } is: where v j is the identifier of the document retrieved at the function. Typically G ( r ) = 2 r  X  1 and D ( j ) = 1 / log(1 + j ). The NDCG @ k metric (normalized discount cumulative gain at the position k ) is NDCG @ k (  X  ) = DCG @ k (  X  ) /DCG @ k where DCG @ k p is a discount cumulative gain of the perfect ordering according to true relevance labels rel ( i ).
All of the mentioned metrics depend only on the final or-dering of the set of documents and human relevance labels and cannot be optimized directly by the gradient descent, since objective quality measure is locally constant discontin-uous function of the predicted scores s j .

Now we explicitly describe the class of the smoothed IR metrics, mentioned in the introduction, which are used in most of the listwise approaches, and, in particular, in Soft-Rank and SmoothRank algorithms. Let M be any ranking metric considered as a function on the set of all permu-tations S m of the documents retrieved for a given query, M : S m  X  R . Let X  X  fix any family of probability distri-butions P on the set S m , parameterized by scores { s such that for any exact ordering  X   X  S m the probability P (  X  ; s 1 ,...,s m ) is a smooth function of s j . The new ranking metric M s is the expectation value of the random variable M :
M s ( s 1 ,...,s m ) := E ( M ) = X Since M (  X  ) are constants and P (  X  ; s 1 ,...,s m ) are smooth functions of s j , the proposed metric is a smooth variant of the initial metric M and thus it can be directly maximized by a standard gradient boosting method.
 In the next section we explain how to generalize the NDCG @ k metric to the ranking functions with tied scores.
The problem of tied scores in performance evaluation was considered in [6]. We want to compute retrieval quality met-rics not only for exact orderings  X   X  S m , but also for partial orderings as well. Under partial ordering  X  we assume a partition of the set of all documents D = { d 1 ...,d m } into an ordered set of relevance groups of the sizes n n 1 +  X  X  X  + n l = m . We say that the exact ordering  X  is obtained from the partial ordering  X  , if there exists a per-mutation of documents in every group such that the overall ordering is  X  .

It is essential to define the value of the metric M for the partial ordering  X  as an average of n 1 !  X  n 2 !  X  ...  X  n of all exact orderings  X  obtained from the  X  . In general, the corresponding sum is very computationally expensive. However, for many IR metrics the naive expression of the averaged metric, which contains n 1 !  X  n 2 !  X  ...  X  n l can be reduced to a very simple one and computed directly. Below is the equation for the averaged DCG , which was in-troduced by McSherry and Najork [6]. Its NDCG analogue will be used further in our method. Let t i be the end of i -th group of the partial ordering  X  , i.e. t i = n 1 +  X  X  X  + n then the value of the DCG @ k metric for the partial order-details): DCG @ k (  X  ) = where G ( r ) = 2 r  X  1 and D ( j ) = 1 / log(1 + j ).
Further we explain how we arrive from the predicted scores s j to the distribution on the set of partial orderings and to compute the expectation of the NDCG @ k metric using the above-mentioned equation. The key idea of our approach is to define the distribution P (  X  ; s 1 ,...,s m ) on the set of partial orderings and compute the corresponding expectation value of the tied NDCG -metric introduced in the previous section. Roughly speak-ing, we round each of the predicted scores s j up or down with some probability.

Let X  X  assume that at a new iteration of the learning pro-cess we obtain scores s 1 ,...,s m . We replace each s j Bernoulli random variable  X  ( q,d j ) with two values b s d s j e and a parameter p =  X  ( s j  X  X  s j c ): where  X  ( x ) is the monotone decreasing function on [0; 1] satisfying the following conditions:  X  (0) = 1;  X  ( x )  X  0;  X  ( x ) +  X  (1  X  x ) = 1;  X  0 (0) = 0 . This set of m random variables defines the distribution on the set of 2 m predicted score lists with ties and thus on partial orderings of the set of all documents retrieved for the query q . The corresponding objective function is
M s ( s 1 ,...,s m ) = where  X  j is 0 if  X  ( q,d j ) = b s j c and 1 if  X  ( q,d j  X  =  X  (  X  1 ,..., X  m ) is a partial ordering, which corresponds to the particular outcome of m Bernoulli trials  X  ( q,d j 1 ,...,m .

Let us discuss in detail the conditions on the function  X  ( x ). First of them,  X  (0) = 1, just means that we do not round s j , if it is already integer. The following two condi-tions ensure that P (  X  ( q,d j )) is a true probability function. The latter condition guarantees the smoothness of the ob-jective function M s at integer points, as could be seen from the next equation for the gradient of M s . We have evaluated two possible functions  X  : the linear function  X  l ( x ) = 1  X  x and the spline function  X  s ( x ) = 2 x 3  X  3 x 2 + 1. The first one does not satisfy the last condition, but it still defines a reasonable distribution on the set of all partial orderings. The second one is a simple polynomial function which meets all four conditions. It is important to note, that the perfor-mance of the spline function has turned out to be far better. This observation indicates that in some cases continuous, but not everywhere differentiable functions of s j , cannot be effectively optimized by gradient descent algorithms.
The gradient of M s is defined as:  X  X  s ( s 1 ,...,s m ) = X where p 0  X  j ( s j ) is  X  0 ( s j  X  X  s j c ) if  X  j = 0 and  X   X  if  X  j = 1.

The computation of the gradient of the objective function for a query q requires O ( m 2 m ) operations, so its complex-ity is considerably high. However, as long as we define the initial performance metric as M = NDCG @ k , k  X  10, or if the number of retrieved documents per query is not high, the algorithm runs in a reasonable time. In our learning process we take randomly up to d documents per query from each of the relevance groups. Such a way of sampling is similar to the sampling used in SoftRank algorithm. In a man-ner similar to the authors of SoftRank, we also do not use any cut-off after this sampling and compute the smoothed NDCG @ m , where m is the number of selected documents for the given query. This is not a very strong restriction since most search engines display only 10 results per page and users often look only at a few top ranked documents. Thus, it is reasonable to optimize the objective function re-lying on a relatively small subset of retrieved documents. The results on LETOR collection reported further in this paper confirm our intuitions.

In order to illustrate our method with a simple exam-ple, we describe how TieRank solves the following ranking problem. Let X  X  assume that at some iteration for the given query q we have two documents d 1 and d 2 with relevance labels rel (1) = 2, rel (2) = 1 and predicted scores s 1 = 0 . 3, s = 0 . 6. We further consider that each of the scores s 1 is a random variable and obtain 4 possible outcomes with probabilities: The NDCG @2 scores of the corresponding rankings are the case s 1 ,s 2  X  [0; 1], the smoothed metric is:
M s ( s 1 ,s 2 ) = 0 . 9  X  ( s 1 )  X  ( s 2 ) +  X  (1  X  s 1 According to the equation of the derivative of M s we have (here  X  ( x ) = 2 x 3  X  3 x 2 + 1): Predictably, at a new iteration we should increase the score of d 1 and decrease the score of d 2 .

Now we briefly describe the gradient boosting method [1] used for the optimization of the smooth function of predicted scores. Parameters of the algorithm are the depth of each tree, the number I of iterations in the learning process, the number d of documents for sampling and the regularization multiplier  X  . At each iteration, the algorithm learns a tree model that best approximates the gradient of the objective function and adds it to the current ranking function f ( q,d ). The following algorithm describes the learning process: 1. Initialize predicted scores s j = 0 . 5 2. For i = 1 to I do
NDCG @ k
NDCG @ k We have evaluated TieRank on two LETOR collections: TD2004 from LETOR3 and MQ2007 from LETOR4. Train-ing data in these collections consists of 5 pre-folded sets for cross-validation. TD2004 web collection, also known as TREC-2004, consists of 75 queries and 74146 documents with binary relevance labels for query-document pairs. MQ2007 collection consists of 784 queries and 15211 doc-uments with 3 types of relevance labels for query-document pairs. In Tables 1 and 2 we report the performance of TieR-ank on these collections in comparison with the baseline methods. Due to paper space constraints, we compare our performance only with the most competitive baselines. In general, the less is regularization multiplier  X  and the more documents we sample, the better model we learn, however, as long as we are restricted by the computational complex-ity of our model, we had to fix the regularization multiplier  X  = 0 . 001 and the set sample count d = 6. So, we sample m  X  18 documents per query for experiments with MQ2007 collection and m  X  12 documents per query for experiments with TD2004. We optimized the number I of trees in our model (the parameter, which controls overfitting) and the depth of trees relying on the ordinary NDCG @5 metric on the validation folds. Then we evaluated our models on the test sets and measured their average performance in terms of the NDCG @ K metric. It turns out that during the learn-ing process on these collections all predicted scores lie in the segment [0; 1], thus typically we obtain 2 groups in the corresponding partial orderings.

The results on MQ2007 show that TieRank outperforms all other methods for all truncation levels, including tree-based method RankBoost. On TD2004 collection TieR-ank outperforms the best baseline RankBoost only for small truncation levels. This is not surprising, since TD2004 collection has binary relevance labels (so optimization of NDCG @ k metrics is less appropriate) and contains  X  1000 documents per query vs.  X  20 documents in MQ2007 (so sampling is not as reasonable in this case). Comparison of TieRank with closely related SmoothRank method on TD2004 shows that our method performs better for all trun-cation levels.
In this paper, we have introduced a novel smoothing tech-nique, and applied it to the NDCG @ k ranking metric. Our method is based on a new distribution on the set of partial orderings. The advantages of our approach are the smooth-ness of the objective function, its direct dependence on the initial performance metric and the possibility of its exact computation. We applied a gradient boosting learning algo-rithm to optimization of the proposed smoothed metric and learned rankers on several open collections. The evaluation on MQ2007 and TD2004 LETOR collections demonstrated that TieRank outperforms the most competitive baseline learning to rank approaches. We believe that principles em-bodied in the proposed smoothing technique have the po-tential to advance the research on learning to rank.
Since one of the main disadvantages of our algorithm is its computational complexity, we plan to implement some analogue of the averaging technique from [6] to simplify the calculation of the gradient of the objective function. We are also going to study in detail the influence of document sampling on the quality of a ranking model. Also it is inter-esting to investigate TieRank application to optimization of other retrieval quality measures (i.e. cascade metrics, such as ERR).
