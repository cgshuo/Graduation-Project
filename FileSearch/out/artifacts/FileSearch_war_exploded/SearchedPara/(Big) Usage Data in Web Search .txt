 H.3.3 [Information Search and Retrieval] Algorithms, Human Factors Web Retrieval, User Interaction Web Search, which takes its root in the mature field of information retrieval, evolved tremendously ove r the last 15 years. The field encountered its first revolution when it started to deal with huge amounts of Web pages. Then, a major step was accomplished when engines started to consider the structure of the Web graph and leveraged link analysis in both crawling and ranking. Finally, a more discrete, but no less critical step, was made when search engines started to monitor and exploit the numerous (mostly implicit) signals provided by users while interacting with the search engine. In this tutorial we focus on this  X  X evolution X  of large scale usage data. In the first part of this tutori al, we focus on usage data, which typically refers to any type of information provided by the user while interacting with the search engine. It comes first under its raw form as a set of individual signals, but is typically mined after multiple signals have been aggregated and linked to the same interaction event. The two major types of such data are (1) query streams , which include the query string that the user issued, together with the time-stamp of the query, a us er identifier, possibly the IP of the machine on which the browser runs, and (2) click data , which include the reference to the element the user clicked on the page together with the timestamp, user identifier, possibly IP, the rank of the link if it is a result, etc. Exploiting usage data under its multiple forms brought an unprecedented wealth of implicit information to Web Search. We discuss in the second part of this tutorial some of the key Web search applications that it made possible. One such example is the query spelling correction feature embodied now in all search engines. In fact, after years of very sophisticated spell checking research, simply counting similar queries at a small edit distance would in most cases surface the mo st popular spelling as the correct one, a beautiful and simple demonstr ation of the wisdom of crowds principle. In practice, such a feature cl early uses more sophisticated techniques than direct counting, but this simple example illustrates how even trivial  X  X ata crunching X  over big real data brings more value than sophisticated technique s on small datasets. Query logs have also revolutionized query a ssistance tools such as related queries (recommended queries after the search was issued) or query completions (suggested queries as the query is being typed). While, in the past, query assistance tools would analyze the document corpus in order to identify phrases that could serve as alternate queries, the tremendous growth in Web search engine traffic allowed these tools to mostly rely on real user-issued queries. Using query logs as the source corpus significantly improved the quality of suggestions, at least as perceived by the user. In practice, query assistance tools are now deployed on all major Web search engines, and their quality improves as query logs grow. An additional revolutionary benefit of usage data is to consider clicks as a measure of satisfaction or at least of intere st from the user, as if the user, by clicking, had actually voted in favor of the clicked element. One major reason of the quick pace of innovation in Web search can be credited to these  X  X seudo-votes X . Instead of testing a new feature, or any sort of change, on a small samp le of beta-users in a controlled environment, search engines now use real users on a much larger scale. Various metrics are used to verify whether users react positively or not to the change, thus helping search engines to decide whether to deploy the change to all users. After deployment, user behavior is constantly monito red, not only at pre-launch time, and features for which clicks or other metrics are decreasing might be discontinued or retired as it often happens. In spite of its multiple benefits, adequately leveraging usage data is not always straightforward. We disc uss, in the third part of this tutorial, the effects of three major factors that often pull in opposite directions:  X  Size of the data : Large-scale or big usage data is a key pre- X  Personalization : In order for search engines to personalize  X  Privacy : One key demand of privacy-protecting activists These conflicting factors impose serious limitations on leveraging big usage data. We discuss some ways to tackle these limitations, in the last part of our tutorial. One solution that we focus on is to aggregate data in the right way, depending on the context, the task, the need, so as to increase the am ount of relevant data. We show that aggregated data can be generated in a variety of scenarios, as the bulk of user queries belong to a few tasks: users are after all not that different, and many tasks shar e similarities at some level, for example find a home page, look for information, perform a transaction or download a resour ce. The main differences among users are not with what they do, but when they do it, how long they do it and how well they do it. We expect to see many types of aggregations arising in the future. Indeed, even social search can be seen as an incarnation of aggregation, where the aggregation is social and formed by the user's fri ends and other connections rather than by a common need. We conclude by providing some research directions as well as discuss with the audience the influence of regulation current or future such as the recently proposed privacy  X  X ill of rights X  in the US. This tutorial is a sequel of  X  X eb Retrieval: The Role of Users X , a tutorial offered at SIGIR'2010 in Geneva and then at WSDM'2011 and ECIR'2011. Ricardo Baeza-Yates is VP of Yahoo! Research for Europe and Latin America, leading the labs at Barcelona, Spain and Santiago, Chile. Until 2005, he was the director of the Center for Web Research at the Department of Computer Science of the Engineering School of the University of Chile, and ICREA Professor at the Dept. of Technology of University Pompeu Fabra in Barcelona, Spain. He is co-author of the bestseller te xtbook Modern Information Retrieval by Addison-Wesley, first publishe d in 1999 with a second edition in 2011, as well as co-author of the second edition of the Handbook of Algorithms and Data Structures, Addison-Wesley, 1991; and co-editor of Information Retrieval: Algorithms and Data Structures, Prentice-Hall, 1992, among more th an 200 other publications. He has been PC-Chair of the most important conferences in the field of Web Search and Web Mining. He has given tutorials in most major conferences many times, including SIGIR, WWW and VLDB. He is, both, ACM and IEEE Fellow. Yoelle Maarek is the Senior Director of Yahoo! Research in Haifa, Israel, leading research activities for Yahoo! Mail and Yahoo! Answers since 2009. Prior to this, Yoelle was the Director of Google Haifa Engineering Center, which she opened in 2006. There, she led the development of  X  X uggest X , Google X  X  query completion feature deployed on google.com and YouTube worldwide. Before this, Yoelle had been with IBM Research, first in the US, and then in Israel, where she led the search and collaboration department and became a Distinguished Engineer. She graduated from the ENPC in Paris, France, and received her DEA in Computer Science from Paris VI University. Yoelle obtained her PhD in Computer Science from Tec hnion. She has served as senior PC member at several SIGIR, WWW and WSDM conferences, and as PC co-chair of WWW X 2009, WSDM X 2012 and SIGIR X 2012. Yoelle is a member of the Board of Governors of Technion, and was appointed ACM Distinguished Scientist in 2010. 
