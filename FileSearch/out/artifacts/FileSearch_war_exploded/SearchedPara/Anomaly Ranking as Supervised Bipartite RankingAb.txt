 St  X  ephan Cl  X  emenc  X on STEPHAN . CLEMENCON @ TELECOM CIMFAV-Facultad de Ingeniera, Universidad de Valparaso, Valparaso, Chile Motivated by a great range of applications such as the de-sign of search engines in information retrieval, credit-risk screening in finance or supervised anomaly detection in signal processing, the problem of learning how to rank data with ordinal labels has been the subject of a good deal of attention in machine-learning these last few years, see (Duchi et al., 2010; Cl  X  emenc  X on et al., 2008; Agarwal et al., 2005) among others. A wide variety of criteria have been considered so as to cast the task of ranking observa-tions in an order as close as possible to that induced by the ordinal output variable as a M-estimation problem, in-cluding the (area under the) receiver operator characteristic curve (ROC curve in short) and the precision-recall curve in the bipartite situation ( i.e. when the output variable is binary), the normalized discounted cumulative gain crite-rion or the ROC manifold in the general multipartite frame-work. Many practical ranking algorithms, supported by sound theoretical results extending the probabilistic theory of pattern recognition, are now documented in the litera-ture, see (Freund et al., 2003; Cl  X  emenc  X on &amp; Vayatis, 2009; Rakotomamonjy, 2004; Pahikkala et al., 2007) for instance. However, in many applications, which can be referred to as unsupervised anomaly/novelty detection and comprise the monitoring of complex systems such as the functioning of aircraft engines, system management in data centers ( cf (Viswanathan et al., 2012)), network intrusion surveillance or fraud detection, it would be desirable as well to rank multivariate data, so that top ranked observations should be ideally the likeliest  X  X utliers X , in absence of any output variable indicating the degree of  X  X bnormality X . Through-out the article, this problem shall be termed anomaly rank-ing or anomaly scoring , insofar as the most natural way to define a preorder on a general feature space X  X  R d , with d  X  1 , is to transport the natural order on the real half-line by means of a (measurable) scoring function s : X  X  R + . The ideal way of ordering all the elements of the feature space naturally corresponds to the reverse of the order in-duced by the (generally unknown) underlying density func-tion. Because density estimation should be avoided in a high dimensional setup, due to the curse of dimensional-ity phenomenon, a performance criterion of functional na-ture, just like the ROC curve in the supervised framework, has been recently introduced in (Cl  X  emenc  X on &amp; Jakubow-icz, 2013), which permits to evaluate the accuracy of any ranking rule, as regards the objective pursued. It has been termed the Mass Volume curve (MV curve) and the lower the MV curve of a scoring function, the more accurate the ranking it induces. But, in contrast to the supervised frame-work, no algorithm is readily available to build a scor-ing function with a nearly optimal MV curve from (unla-beled) training data. It should also be recalled that min-imum volume set estimation techniques (Scott &amp; Nowak, 2006), originally designed to solve unsupervised anomaly detection problems, are not appropriate for anomaly rank-ing, cast as MV curve minimization, since they consist in recovering a single density level set, corresponding thus to single point of the optimal MV curve (with the target mass level as abcissa).
 It is the major purpose of this paper to highlight the connec-tion between (supervised) bipartite ranking and anomaly ranking. Indeed, it is shown in the present article that, in the case where the underlying probability distribution F ( dx ) has compact support, included in [ 0,1 ] d say, the MV curve of any scoring function s ( x ) and its ROC curve with regard to the bipartite ranking problem, where the  X  X osi-tive distribution X  is the probability measure F ( dx ) which the observations are drawn according to and the  X  X egative distribution X  is uniform on [ 0,1 ] d , are symmetrical w.r.t. the first diagonal. Hence, minimization of the MV curve boils down to maximizing the corresponding ROC curve, which task can be achieved by various algorithms based on two independent data samples, one drawn from F ( dx ) and the other drawn from the uniform distribution. Build-ing on this crucial observation, we first propose to  X  X i-jack X  bipartite ranking algorithms by implementing them with the originally unlabeled sample as  X  X egative sample X  and a simulated  X  X ositive sample X  made of i.i.d. data uni-formly distributed on [ 0,1 ] d . Incidentally, we point out that sampling data from a reference measure in order to reveal properties of the density under study by means of super-vised techniques is well-known folklore in applied statis-tics, generalized association rules for instance are precisely based on this approach (see Chapter 14 in (Friedman et al., 2009)) and (Steinwart et al., 2005) proposed a method, in-volving the simulation of uniformly distributed data too, to turn (unsupervised) anomaly detection into a supervised binary classification problem. We next explain how to ex-tend the T REE R ANK approach, originally introduced in (Cl  X  emenc  X on &amp; Vayatis, 2009) to the unsupervised frame-work. Beyond the fact that it may produce interpretable ranking rules, visualizable by means of an oriented tree graphic, in contrast to other bipartite ranking algorithms, its implementation in the unsupervised context does not re-quire to sample any extra data uniformly distributed over [ 0,1 ] d . Numerical experiments have been also carried out in order to illustrate the performance of various bipartite ranking algorithms for anomaly ranking.
 The rest of the article is structured as follows. In section 2, notations are first set out and key notions of the anomaly ranking problem are recalled, together with basic concepts of bipartite ranking and ROC analysis. Section 3 explains at length the connection between the supervised and un-supervised ranking problems in the compact support case, while section 4 shows how to extend the use of certain bi-partite ranking algorithms to anomaly ranking from a prac-tical perspective. Finally, numerical results based on syn-thetic/real datasets are displayed in section 5 for illustration purpose. Here we essentially describe the issue of anomaly rank-ing and briefly recall the related key concepts of MV curve analysis. We also set out the notations that shall be needed throughout the paper. 2.1. The Statistical Framework In the anomaly ranking problem, the goal pursued is to learn how to order observations by degree of  X  X bnormal-ity X , on the basis of a training sample X 1 , ..., X n made of i.i.d. copies of a random variable X , taking its values in a (possibly high-dimensional) space X  X  R d with d  X  1 and distributed according to a continuous probability mea-sure F ( dx ) = f ( x ) dx . The preorder on X is defined by means of a (measurable) scoring function s : X  X  R + :  X  ( x,x 0 )  X  X 2 , x s x 0  X  s ( x )  X  s ( x 0 ) . We denote by S the set of all scoring functions on X integrable w.r.t. Lebesgue measure on X (see the next subsection for the explanation of the integrability constraint). Given the na-ture of the problem, the optimal ranking is naturally that determined by the density function f ( x ) . The set S  X  of optimal scoring functions is made of (  X  -integrable) non-negative strictly increasing transforms of the density func-tion.
 We point out that the nature of the problem considered is very different from that of (nonparametric) density estima-tion : there is no need to estimate the local values taken by the density function, only the preorder on X it induces is of interest here. We also emphasize that in many ap-plications, the very purpose of unsupervised anomaly de-tection is not to assign a label  X  X ormal X  vs.  X  X bnormal X  to any new observation, compared to the vast majority of the data previously observed ( i.e. the training data), but to rank any new set of observations ( i.e. test data) by de-gree of abnormality. The form of the output, an ordered list namely, may greatly facilitates the work of human op-erators. For instance, in the context of Distributed Fleet Monitoring (DFM) for Flight Operational Quality Assur-ance (FOQA) programs, an anomaly scoring function (tak-ing flight data and aircraft features as input variables in par-ticular) could permit to set priorities and help optimize the work of FOQA analysts who do not have time to look at the data for hundreds of thousands of flights: depending on op-erational constraints, the 10 most abnormal flights will be examined first, then the next 10 flights, etc. . Finally, we un-derline that the framework we develop in this paper is fully nonparametric. In particular, no parametric assumption on the tail behavior of the underlying multivariate distribution, permitting to rank new observations according the corre-sponding p -values, is made.
 The following assumptions shall be involved in the subse-quent analysis.

H 1 The random variable f ( X ) is continuous.

H 2 The density f is bounded: sup x  X  X  f ( x ) &lt; + Here we denote by  X  the Lebesgue measure on X , by I {
E } the indicator function of any event E . The general-ized inverse function of any cdf K ( t ) on R is denoted by K  X  1 ( u ) = inf { t  X  R : K ( t )  X  u } . 2.2. Mass Volume Curves In (Cl  X  emenc  X on &amp; Jakubowicz, 2013), a natural way of mea-suring the ranking performance of a given scoring function s  X  X  in the unsupervised setting has been introduced (see Definition 2 therein). It consists of plotting its Mass Vol-ume (MV) curve, namely the Probability Measure plot: With  X  s,t = { x  X  X : s ( x )  X  t } for any t  X  0 , the MV curve is the parametrized curve t &gt; 0 7  X  ( F (  X  s,t ) ,  X  (  X  s,t )) . Observe that, since s is supposed to be  X  -integrable, the measure  X  (  X  s,t )  X  (
R u  X  R + s ( u ) du ) /t is finite for any t &gt; 0 . Connecting points corresponding to possible jumps of the parametric curve, the curve can be seen as the plot of a continuous mapping MV s :  X   X  ( 0,1 ) 7  X  MV s (  X  ) , starting at ( 0,0 ) . Denoting by F s ( t ) the cdf of the r.v. s ( X ) , in the case where F  X  F  X  1 s (  X  ) =  X  , we have: Let  X   X  ( 0,1 ) . Under the Assumptions H 1  X  H 2 , the set  X  of the minimum volume set problem where B ( X ) denotes the ensemble made of all borelian subsets of X . For small values of the mass level  X  , min-imum volume sets are expected to contain the modes of the distribution, whereas their complementary sets correspond to  X  X bnormal observations X  when considering large values of  X  . Refer to (Einmahl &amp; Mason, 1992; Polonik, 1997) for an account of minimum volume set theory and to (Vert &amp; Vert, 2006; Scott &amp; Nowak, 2006) for related statistical learning results. As stated in Proposition 3 of (Cl  X  emenc  X on &amp; Jakubowicz, 2013), this implies that the MV curve of the scoring function f ( x ) , which plots the (minimum) vol-ume  X  (  X   X   X  ) against the mass F (  X   X   X  ) =  X  and which shall be denoted by MV  X  , is dominated by any other MV curve everywhere: It is noteworthy that MV  X  is a convex function and MV curves are invariant under strictly increasing transforms. A list of properties of MV curves is given in Proposition 5 in (Cl  X  emenc  X on &amp; Jakubowicz, 2013). A typical MV curve is depicted in Fig. 5.1. When the distribution F ( dx ) is much concentrated around its modes and exhibits a light tail be-havior, the optimal MV curve increases very slowly and rises near 1 . Of course, MV curves are generally unknown in practice, just like the distribution F ( dx ) , and must be es-timated by their empirical counterparts, see Theorem 8 in (Cl  X  emenc  X on &amp; Jakubowicz, 2013) for more details on sta-tistical estimation of MV curves.
 A partial order on S . The concept of MV curve in-duces a partial order on the set of scoring functions S . Let ( s 1 ,s 2 )  X  S 2 , we will say that the scoring function s 1 more accurate than s 2 if and only if its MV curve is below of s 2 everywhere, i.e.  X   X   X  ( 0,1 ) , MV s 1 (  X  )  X  MV for any fixed mass level, s 1 defines a subset of smaller vol-ume. Equipped with this functional performance criterion, the optimal scoring functions s  X  S are the elements of S  X  = { T  X  f : T : Imf ( X )  X  R + strictly increasing } , where Imf ( X ) denotes the image of the r.v. f ( X ) . The closer the MV curve of a scoring function candidate to MV  X  , the more accurate the ranking it defines. Of course, there a many ways of quantifying closeness in the MV space. One could naturally consider L p distances, 1  X  p  X  +  X  , as in (Cl  X  emenc  X on &amp; Jakubowicz, 2013).
 In this paper, focus is on the situation where the assumption below is fulfilled.

H 3 The probability distribution F ( dx ) has compact sup-In this case, the MV curve of any scoring function s  X  S ends at ( 1,1 ) . Let p  X  [ 1, +  X  ] , the performance of any s  X  X  can be measured through the quantity where || . || p denotes the L p -norm on [ 0,1 ] and s  X   X  X  goal of anomaly ranking can be then stated in a quantita-tive manner. Based on a training dataset { X 1 , ..., X n the objective is to build a scoring function s  X  S such that d ( s,s  X  ) is as small as possible with overwhelming proba-bility. Notice finally that, since we have the decomposition d ( s,s  X  ) = (4)), anomaly ranking reduces to minimization of the area under the MV curve in the case p = 1 .
 Anomaly ranking versus anomaly detection. Anomaly ranking is very different from (unsupervised) anomaly de-tection, cast as minimum volume set estimation. A mass level  X   X  ( 0,1 ) being preliminarily fixed, the latter con-sists in recovering from data a specific density level set  X   X  , while the former aims at building a scoring function s ( x ) whose collection of level sets {  X  s,t } t&gt;0 nearly corre-sponds to that of the underlying density f ( x ) , {  X   X   X  ( i.e. an increasing transform of f ( x ) ). Hence, anomaly ranking should be viewed as a continuum of anomaly de-tection problems: finding the observations forming the top 1 % the most abnormal, then those forming the top 2 %, etc. 2.3. Ranking Bipartite and ROC Analysis Consider now two probability distributions on the space X , G ( dx ) and H ( dx ) , absolutely continuous with respect to each other. The ROC curve of any scoring function s ( x ) is defined as the PP -plot t &gt; 0 7  X  ( 1  X  H s ( t ) ,1  X  G where H s ( dt ) and G s ( dt ) respectively denote the images of the distributions H and G by the mapping s : X  X  R + . Connecting by convention possible jumps by line seg-ments, the ROC curve of the scoring function s ( x ) can always be viewed as the plot of a continuous mapping ROC s :  X   X  ( 0,1 ) 7  X  ROC s (  X  ) . It starts at ( 0,0 ) and ends at ( 1,1 ) . At any point  X   X  ( 0,1 ) such that H s  X  H  X  1  X  , we have: ROC s (  X  ) = 1  X  G s  X  H  X  1 s ( 1  X   X  ) . The curve ROC s measures the capacity of s to discriminate between distributions H and G . It coincides with the first diagonal when H s = G s . Observe also that the stochastically larger than H s the distribution G s , the closer to the left upper cor-ner of the ROC space the curve ROC s . One may refer to (Fawcett, 2006) for an account of ROC analysis and its ap-plications.
 The notion of ROC curve defines a partial order on S . A scoring function s 1 is more accurate than s 2 iff:  X   X   X  ( 0,1 ) , ROC s 1 (  X  )  X  ROC s 2 (  X  ) . A Neyman-Pearson argu-ment shows that the optimal ROC curve, denoted by ROC  X  , is that of the likelihood ratio statistic  X  ( x ) = dG/dH ( x ) . It dominates any other ROC curve everywhere:  X  ( s, X  )  X  S  X  ( 0,1 ) , ROC s (  X  )  X  ROC  X  (  X  ) . The set S  X  {
T  X   X , T : Im X  ( X )  X  R + strictly increasing } is the set of optimal scoring functions regarding the bipartite problem considered.
 The goal of bipartite ranking is to build a scoring func-tion with a ROC curve as high as possible, based on two independent labeled datasets: ( X  X  1 , ..., X  X  m ) and ( X 1 , ..., X and G respectively, with m, q  X  1 . Assigning the la-bel Y = + 1 to observations drawn from G ( dx ) and label Y =  X  1 to those drawn from H ( dx ) , the objective can be also expressed as to rank/score any pooled set of observa-tions (in absence of label information) so that, ideally, the higher the score of an observation X , the likelier its (hid-den) label Y is positive.
 The accuracy of any s  X  X  can be measured by: where s  X   X  S  X  H,G and p  X  [ 1, +  X  ] . Observe that, in the case p = 1 , one may write D 1 ( s,s  X  ) = AUC  X   X  AUC ( s ) , where AUC ( s ) = ROC Curve (AUC in short) and AUC  X  = AUC (  X  ) is the maximum AUC. Hence, minimizing D 1 ( s,s  X  ) boils down to maximizing the ROC summary AUC ( s ) . The popularity of this quantity arises from the fact it can be interpreted, in a probabilistic manner, as the rate of concording pairs
AUC ( s ) = P { s ( X ) &lt; s ( X 0 ) } + where X and X 0 denote independent r.v. X  X  defined on the same probability space, drawn from H and G respectively. An empirical counterpart of AUC ( s ) can be straightfor-wardly derived from (7), paving the way for the imple-mentation of  X  X mpirical risk minimization X  strategies, see (Cl  X  emenc  X on et al., 2008).
 The algorithms proposed to optimize the AUC criterion or surrogate performance measures are too numerous to be listed in an exhaustive manner. In the present article, due to space limitations, we restrict our attention to the ex-tension of the following algorithms to the anomaly rank-ing problem: 1) the T REE R ANK method and its variants (see (Cl  X  emenc  X on &amp; Vayatis, 2009; Cl  X  emenc  X on et al., 2011; 2013)), which relies on recursive AUC maximization, see subsection 4.2, 2) the RankBoost algorithm, which imple-ments a boosting approach tailored for the ranking prob-lem (see (Freund et al., 2003)), 3) the SVMrank algorithm originally designed for ordinal regression (see (Herbrich et al., 2000)) and 4) the RankRLS procedure proposed in (Pahikkala et al., 2007). With the notations of subsection 2.3, we take H ( dx ) as the uniform distribution U ( dx ) on [ 0,1 ] d and G ( dx ) as F ( dx ) , the distribution of interest in the anomaly ranking problem. It follows immediately from the definitions and properties recalled in section 2 that, for any scoring function s  X  S , the curves MV s and ROC s are symmetrical with respect to the first diagnonal of the unit square [ 0,1 ] 2 . Hence, as stated in the next result, solving the anomaly ranking prob-lem related to distribution F ( dx ) is equivalent to solving the bipartite ranking problem related to the pair ( U,F ) . Theorem 1 Suppose that assumptions H 1 , H 2 and H 3 hold true. Let U ( dx ) be the uniform distribution on [ 0,1 ] For any ( s, X  )  X  S  X  ( 0,1 ) , we have: ROC  X  1 s (  X  ) = MV s (  X  ) . We also have S  X  = S  X  U,F , and for 1  X  p  X  +  X  . In particular, we have:  X  s  X  X  , 1  X  where W and X are independent r.v. X  X , drawn from U ( dx ) and F ( dx ) respectively.
 The proof is straightforward, it suffices to observe that  X  = dG/dH = f in this context. Details are thus left to the reader.
 Incidentally, we point out that, under the assumptions listed above, the minimal area under the MV curve may be thus interpreted as a measure of dissimilarity between the distri-bution F ( dx ) and the uniform distribution on [ 0,1 ] d closer distribution F ( dx ) .
 eral, the support of F ( dx ) is unknown, just like the distri-bution itself. However, the argument above remains valid in the case where suppF ( dx )  X  [ 0,1 ] d . The sole dif-ference lies in the fact that the curve MV  X  then ends at the point of mass-axis coordinate 1 and volume-axis co-ordinate  X  ( suppF )  X  1 , the corresponding curve ROC  X  exhibiting a plateau: it reaches 1 from the false positive rate  X  ( suppF ) . We point out that, when no information about the support is available, one may always carry out the analysis for the conditional distribution given X  X  C , where C denotes any compact set containing the observa-tions X 1 , ..., X n . Now that the connection between anomaly ranking and bi-partite ranking has been highlighted, we show how to ex-ploit it to extend efficient algorithms proposed in the super-vised framework to MV curve minimization. Learning pro-cedures are based on a training i.i.d. sample X 1 , ..., X distributed according to the unknown probability measure F ( dx ) with compact support, included in [ 0,1 ] d say. 4.1. Sampling One may extend the use of any bipartite ranking algorithm A to the unsupervised context by simulating extra data, uni-formly distributed on the unit hypercube, as follows. 1. Sample additional data X  X  1 , ..., X  X  m , uniformly dis-2. Assign a  X  X egative X  label to the sample D  X  m = 3. Run algorithm A based on the bipartite statistical Except the choice of the algorithm A and the selection of its hyperparameters, the sole tuning parameter which must be set is the size m of the uniformly distributed sample. In practice, it should be chosen as large as possible, depending on the current computational constraints. From a practical perspective, it should be noticed that the computational cost of the sampling stage is reduced. Indeed, the d components of a r.v. uniformly distributed on the hypercube [ 0,1 ] being independent and uniformly distributed according to the uniform distribution on the unit interval, the  X  X egative X  sample can be thus generated by means of pseudo-random number generators (PRNG X  X ), involving no complex sim-ulation algorithm. Furthermore, uniform distributions on any (borelian) subset of [ 0,1 ] d can be naturally simulated in a quite similar fashion, with an additional conditioning step.
 We point out that, in the context of density estimation, a similar sampling technique for transforming this unsu-pervised problem into one of supervised function approx-imation is discussed in section 14.2.4 in (Friedman et al., 2009), where it is used in particular to build generalized association rules . This idea is also exploited in (Stein-wart et al., 2005) for anomaly detection, see also (Scott &amp; Davenport, 2007). In this respect, it should be men-tioned that a variety of techniques, including that proposed in (Sch  X  olkopf et al., 2001) where the SVM machinery has been extended to the unsupervised framework and now re-ferred to as O NE CLASS SVM, have been proposed to re-cover the set  X   X   X  for a target mass level  X   X  ( 0,1 ) , fixed in advance. Therefore, even if the estimates produced of are of the form { x  X  X : b f ( x ) &gt; t  X  } and one could consider using the decision function b f ( x ) as scoring function, one should keep in mind that there is no statistical guarantee that the ensembles { x  X  X : b f ( x ) &gt; t } are good estimates of density level sets for t 6 = t  X  . This explains the poor performance of such a  X  X lug-in X  approach in practice, as exhibited in section 5.
 4.2. Unsupervised TreeRank The T REE R ANK algorithm, a bipartite ranking technique optimizing the ROC curve in a recursive fashion, has been introduced in (Cl  X  emenc  X on &amp; Vayatis, 2009) and its proper-ties have been investigated in detail in (Cl  X  emenc  X on et al., 2011). Its output consists of an ordered partition of the fea-ture space X (defining thus a ranking, for which elements of a same cell being viewed as ties). The ordered recursive partitioning process is described by a left-to-right oriented binary tree structure, referred to as ranking tree , with fixed maximum depth J  X  0 . At depth j  X  J , there are 2 j nodes, indexed by ( j,k ) with 0  X  k &lt; 2 j . The root node depicts the entire space C 0,0 = X and each internal node ( j,k ) with j &lt; J and k  X  { 0, ..., 2 j  X  1 } represents a subset C j,k  X  X , whose left and right siblings respectively corre-C a constant scoring function s 1 ( x ) = I { x  X  C 0,0 }  X  1 and after m = 2 j + k iterations, 0  X  k &lt; 2 j , the current scor-ing function is s m ( x ) = P l = k ( m  X  k  X  l )  X  I in order to form a refined version of the scoring function, s k  X  l )  X  I { x  X  C j,l } namely, with maximum (empirical) AUC. Therefore, it happens that this problem boils down to solve a cost-sensitive binary classification problem on the set C j,k , see subsection 3.3 in (Cl  X  emenc  X on et al., 2011) for further details. Indeed, one may write the AUC incre-ment as AUC ( s m + 1 )  X  AUC ( s m ) = 1 2 H ( C j,k ) G ( C ting p = G ( C j,k ) / ( H ( C j,k ) + G ( C j,k )) , the crucial point of the T REE R ANK approach is that the quantity 2p ( 1  X  p )  X  ( C j + 1,2k | C j,k ) can be interpreted as the cost-sensitive error of a classifier on C j,k predicting positive label on C spectively, 1  X  p ) assigned to the error consisting in predict-ing label + 1 given Y =  X  1 (resp., label  X  1 given Y = + 1 ), balancing thus the two types of error. Hence, at each iteration of the ranking tree growing stage, the T ANK algorithm calls a cost-sensitive binary classification algorithm, termed L EAF R ANK , in order to solve a statis-tical version of the problem above (replacing the theoreti-cal probabilities involved by their empirical counterparts) at length in (Cl  X  emenc  X on et al., 2011), one may use cost-sensitive versions of celebrated binary classification algo-rithms such as CART or SVM for instance as L EAF R ANK procedure, the performance depending on their ability to capture the geometry of the level sets of the likelihood ra-tio dG/dH ( x ) . In general, the growing stage is followed by a pruning procedure, where children of a same parent node are recursively merged in order to produce a rank-ing subtree that maximizes an estimate of the AUC cri-terion, based on cross-validation usually ( cf section 4 in (Cl  X  emenc  X on et al., 2011)). Under adequate assumptions, consistency results and rate bounds for the T REE R ANK ap-proach (in the sup norm sense and for the AUC deficit both at the same time) are established in (Cl  X  emenc  X on &amp; Vayatis, 2009) and (Cl  X  emenc  X on et al., 2011), an extensive experi-mental study can be found in (Cl  X  emenc  X on et al., 2012). In the anomaly ranking context, the  X  X egative distribution X  is U ( dx ) . Therefore, in the situation where L EAF is chosen as a cost-sensitive version of the CART algo-rithm with axis parallel splits (see (Breiman et al., 1984)), all the cells C j,k can be expressed as union of hypercubes. The exact computation of the volume U ( C j,k ) is then el-ementarily feasible, as a function of the threshold values involved in the decision tree describing the split and of the volume of the parent node. Hence, only empirical coun-terparts of the quantities F ( C ) for subset C  X  [ 0,1 ] didates, b F n ( C ) = ( 1/n ) estimate the cost-sensitive classification error and imple-ment the splitting stage (AUC maximization). Hence, this approach does not require to sample any additional data, in contrast to that proposed in subsection 4.1. This is a key advantage in practice, in contrast to  X  X imulation-based X  approaches: for high values of the dimension d , data are expected to lie very sparsely in [ 0,1 ] d and can be then very easily separated from those obtained by sampling a  X  X easonable X  number of uniform observations, leading bi-partite ranking algorithms to overfit. Similarly to the su-pervised case, the U NSUPERVISED T REE R ANK algorithm corresponds to a statistical version of an adaptive piecewise linear interpolation scheme of the optimal MV curve, see (Cl  X  emenc  X on &amp; Vayatis, 2009).
 Interpretation. From a practical angle, a crucial advantage of the approach describes above lies in the interpretability of the anomaly ranking rules produced. In contrast to alter-native techniques, they can be summarized by means of a left-to-right oriented binary tree graphic: observations are all the more considered as abnormal as they are located in terminal leaves at the right of the anomaly ranking tree . An arrow at the bottom of the tree indicates the direction in which the density decreases. Each splitting rule possibly involves the combination of elementary threshold rules of the type  X  X ( k ) &gt;  X   X  or  X  X ( k )  X   X   X  with  X   X  R erarchical manner. In addition, it is also possible to rank the X ( k )  X  X  depending on their relative importance , mea-sured through the empirical volume under the MV curve decrease induced by splits involving X ( k ) as split vari-able , just like in the supervised setup, see section 5.1 in (Cl  X  emenc  X on et al., 2011) for further details. This permits to identify the variables which have most relevance to de-tect anomalies.
 We now illustrate the points put forward in sections 3 and 4 by means of numerical experiments, based on un-labeled synthetic/real datasets. Precisely, we implemented the modification of the T REE R ANK procedure based on lo-cally weighted versions of the CART method (with axis parallel splits) described at length in subsection 4.2, using the package for R statistical software (see http://www.r-project.org), available at http://treerank.sourceforge.net (with parameters: minsplit = 1, maxdepth = 4, in the L
EAF R ANK ), see (Baskiotis et al., 2009). We have also used RankBoost (aggregating 30 stumps, see (Rudin et al., 2005)) and SVMRank (with linear and Gaussian ker-nels with cross-validated parameters, see (Herbrich et al., 2000)), using the SVM-light implementation available at http://svmlight.joachims.org/. The RankRLS method (http://www.tucs.fi/RLScore, see (Pahikkala et al., 2007)) that implements a regularized least square algorithm with linear kernel ( X  bias = 1  X ) and with Gaussian kernel (  X  = 0.01 ) has also been used, selection of the intercept on a grid being performed through a leave-one-out proce-dure. The anomaly ranking procedure based on the latter algorithms required to sample uniformly distributed  X  X ega-tive X  data, as explained in subsection 4.1. As said at the end of section 4, the decision function output by the 1-class SVM procedure can be used as a scoring function, improperly however because the objective function it op-timizes is related to a single point of the target MV curve (see the toy example below). We used the R-package Kern-lab with gaussian kernel, with parameters chosen automat-ically by cross-validation. In the tables displayed below, the anomaly scoring function produced by RankBoost is referred to as  X  X ankBoost X , those computed by means of SVMrank (respectively, by means of RankRLS) based on a linear and a Gaussian kernels as  X  X VMlin X  and  X  X VM-gauss X  (resp.  X  X LSlin X  and  X  X LSgauss X ) and that pro-duced by one-class SVM as  X 1cSVM X .
 In the following experiment, an estimate of the area under the MV-curve (AMV in short) is computed over 5 repli-cations of a 5-fold cross validation as well as the overall standard deviation (denoted by  X  ). 5.1. Toy Examples and Synthetic Data Let Z be a q -dimensional Gaussian r.v. with mean  X  and covariance matrix  X  , and consider a borelian subset C  X  R q with non zero Lebesgue measure. We denote by N C (  X , X  ) the conditional distribution of Z given Z  X  C . Equipped with this notation, we can write the probability distribution used as toy example here as: f ( x ) = The simulated dataset is plotted in Fig. 2a, while some level sets of the density f are represented in Fig. 2b. We have in-dependently sampled 5000 independent observations from distribution f ( x ) dx and 5000 independent uniformly dis-tributed points. The optimal AMV is denoted by AMV  X  (knowing the density, it can be estimated by a basic Monte-Carlo scheme). As expected, given the distribution of the data to be ranked, the linear methods perform worst. Notice in addition that T REE R ANK and RLSgauss yield compara-ble results and outperform RankBoost, SVMgauss on this example. Among nonlinear rules, 1cSVM yields the poor-est performance ( cf section 4). The MV curves produced by the T REE R ANK algorithm in Fig. 3. 5.2. A Real-World Example We also used a benchmark dataset in anomaly de-tection (computer network intrusion detection namely) proposed as a challenge for intrusion detection in the CMDC2013, see http://www.csmining.org/cdmc2013/ and (Song, 2013). In the present analysis, we kept the three fea-tures dst.host.rerror.rate, rerror.rate and serror.rate and re-moved degenerate features, yielding a training set of 6802 instances. Then, we simulated 10000 extra  X  X egative X  data, uniformly distributed over the cube [ 0,1 ] 3 . Estimates of the area under the MV curve (AMV) have been computed over five replications of a five-fold cross validation and the over-all standard deviation is reported in Table 2. The modified T
REE R ANK procedure outperforms all the other methods, illustrating the advantage of using a method avoiding any sampling stage. Given the clear superiority of the methods based on Gaussian kernels over linear techniques, one may also guess that the level sets of the underlying density are highly nonlinear. Here we shed light on the connection between anomaly ranking , cast as Mass Volume curve minimization, and bi-partite ranking when the distribution F ( dx ) of the (unla-beled) training data is compactly supported. Assuming (rather than rescaling the observations) that the support is included in [ 0,1 ] d , the related bipartite problem corre-sponds to the situation where F ( dx ) is the  X  X ositive X  distri-bution and the  X  X egative X  one is uniform on [ 0,1 ] d . We thus proved that, following the generation of uniformly distributed data, bipartite ranking algorithms can be read-ily used to build scoring functions which nearly solve MV curve minimization. We illustrated this through numerical experiments.
 Agarwal, S., Graepel, T., Herbrich, R., Har-Peled, S., and Roth, D. Generalization bounds for the area under the ROC curve. JMLR , 6:393 X 425, 2005.
 Baskiotis, N., Cl  X  emenc  X on, S., Depecker, M., and Vayatis,
N. R-implementation of the TreeRank algorithm. Sub-mitted for publication , 2009.
 Breiman, L., Friedman, J., Olshen, R., and Stone, C. Clas-sification and Regression Trees . Wadsworth and Brooks, 1984.
 Cl  X  emenc  X on, S. and Jakubowicz, J. Scoring anomalies: a
M-estimation formulation. In Proceedings of AISTATS , 2013.
 Cl  X  emenc  X on, S. and Vayatis, N. Tree-based ranking meth-ods. IEEE Trans. Inf. Theory , 55(9):4316 X 4336, 2009. Cl  X  emenc  X on, S., Lugosi, G., and Vayatis, N. Ranking and empirical risk minimization of U -statistics. Ann. Stat. , 36(2):844 X 874, 2008.
 Cl  X  emenc  X on, S., Depecker, M., and Vayatis, N. Adap-tive partitioning schemes for bipartite ranking. Machine Learning , 43(1):31 X 69, 2011.
 Cl  X  emenc  X on, S., Depecker, M., and Vayatis, N. An empiri-cal comparison of learning algorithms for nonparametric scoring: the treerank algorithm and other methods. Patt. Analys. Appl. , 2012.
 Cl  X  emenc  X on, S., Depecker, M., and Vayatis, N. Ranking Forests. J. Mach. Learn. Res. , 2013.
 Duchi, J., Mackey, L., and Jordan, M. On the consistency of ranking algorithms. In Proceedings of ICML , 2010. Einmahl, J.H.J. and Mason, D.M. Generalized quantile process. Ann. Stat. , 20:1062 X 1078, 1992.
 Fawcett, T. An Introduction to ROC Analysis. Letters in Pattern Recognition , 27(8):861 X 874, 2006.
 Freund, Y., Iyer, R., Schapire, R., and Singer, Y. An efficient boosting algorithm for combining preferences. JMLR , 4:933 X 969, 2003.
 Friedman, J., Hastie, T., and Tibshirani, R. The Elements of Statistical Learning . Springer, 2009.
 Herbrich, R., Graepel, T., and Obermayer, K. Advances in Large Margin Classifiers , chapter Large margin rank boundaries for ordinal regression, pp. 115 X 132. MIT Press, 2000.
 Pahikkala, T., Tsivtsivadze, E., Airola, A., Boberg, J., and
Salakoski, T. Learning to rank with pairwise regularized least-squares. In Proceedings of SIGIR , pp. 27 X 33, 2007. Polonik, W. Minimum volume sets and generalized quan-tile processes. Stochastic Processes and their Applica-tions , 69(1):1 X 24, 1997.
 Rakotomamonjy, A. Optimizing Area Under Roc Curve with SVMs. In Proceedings of the First Workshop on ROC Analysis in AI , 2004.
 Rudin, C., Cortes, C., Mohri, M., and Schapire, R. E. Margin-based ranking and boosting meet in the middle. In Proceedings of COLT , 2005.
 Sch  X  olkopf, B., Platt, J.C., Shawe-Taylor, J., Smola, A., and Williamson, R. Estimating the Support of a High-
Dimensional Distribution. Neural Computation , 13(7): 1443 X 1471, 2001.
 Scott, C. and Davenport, M. Regression level set estimation via cost-sensitive classification. IEEE Transactions on Signal Processing , 55, 2007.
 Scott, C. and Nowak, R. Learning minimum volume sets. JMLR , 7:665 X 704, 2006.
 Song, J. Cdmc2013 intrusion detection dataset, 2013. Steinwart, I., Hush, D., and Scovel, C. A classification framework for anomaly detection. J. Machine Learning Research , 6:211 X 232, 2005.
 Vert, R. and Vert, J.-P. Consistency and convergence rates of one-class svms and related algorithms. JMLR , 7:817 X  854, 2006.
 Viswanathan, K., Choudur, L., Talwar, V., Wang, C., Mac-donald, G., and Satterfield, W. Ranking anomalies in data centers. In R.D.James (ed.), Network Operations
