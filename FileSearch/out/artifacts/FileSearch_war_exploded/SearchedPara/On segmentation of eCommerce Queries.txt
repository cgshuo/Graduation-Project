 In this paper, we present QSEGMENT, a real-life query segmentation system for eCommerce queries. QSEGMENT uses frequency data from the query log which we call buyers data and also frequency data from product titles what we call sellers  X  data. We exploit the taxonomical structure of the marketplace to build domain specific frequency models. Using such an approach, QSEGMENT performs better than previously described baselines for query segmentation. Also, we perform a large scale evaluation by using an unsupervised IR metric which we refer to as user-intent-score . We discuss the overall architecture of QSEGMENT as well as various use cases and interesting observations around segmenting eCommerce queries.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  Information filtering; Retrieval models; Query formulation Design, Experimentation.
 eCommerce search, query segmentation, query re-write, query suggestion.
Segmenting queries into meaningful syntactical units is an important task for both Web and eCommerce applica-tions. In web applications, segmenting a query helps in dis-ambiguation and query reformulation, resulting in better re-trieval performance by improving precision. In eCommerce applications, the benefit is far-reaching; besides enabling a  X 
The author was engaged in this research while he was at eBay Research Labs.
 shopper to find the right product, it also enables the market-place to build various customer assistive applications; note-worthy among these are applications that handle zero-recall scenarios [34] and build query suggestion dictionaries [15]. Consider a long query, like new ac adapter and battery charger for hp pavilion notebook ; it often suffers from zero-recall on ebay , a large eCommerce marketplace but breaking the query into meaningful phrases, such as {new | ac adapter | and | battery charger | for | hp pavil-ion notebook} helps in reformulating the query as new bat-tery charger hp pavilion ; this shortened query retrieves also helps the system understand the intent of a shopper. This enables the marketplace to make suggestions for re-lated products. In this case, the query new battery for hp pavilion can be a suggestion. In short, the query seg-mentation task plays a more active role in an eCommerce domain than it does in a Web search domain.

Query segmentation is extensively addressed in research literature. The majority of the pioneering works are based on supervised learning [4], and NLP-based techniques [36, 9]. The cost of obtaining a labeled dataset deterred the prospect of supervised learning based methods and the complexity of the algorithms held back the NLP-based techniques. Be-cause large benchmark datasets were not available, these earlier works also lacked proper validation of the perfor-mance of this task. However, in recent years, query seg-mentation task has regained interest among the researchers. Majority of the recent techniques are simple scoring meth-ods that use query frequencies from search logs. In [13, 14], the authors show that a naive algorithm that normalizes the frequency of a query by an intelligent function and then ranks each possible segmentation based on the normalized frequency, works surprisingly well. Some recent efforts also use Wikipedia titles as an external source of information to find noun phrases [38, 14]. However, all the existing works consider the Web search application and use web n -gram fre-quencies [5], so it is not yet widely known how these methods would perform for segmenting queries from eCommerce do-main.

Popular segmentation methods that perform well in Web applications warrant reassessment when they are to be ap-plied for segmenting eCommerce queries. One of the rea-sons for that is, unlike web queries, eCommerce queries are mostly related to product names. In such queries, differ-be different on a different day, but the trend would remain the same ent phrases in a query are permuted more often; for exam-ple , to search for a 500 GB hard disk, shoppers use two variants, 500 gb hard disk and hard disk 500 gb , with almost equal likelihood. Such a practice corrupts the n -gram frequency for many queries. Another challenge with product queries is that they sometimes refer to newly in-troduced products in the market, so Wikipedia titles are not available for such queries. Even for many old products such as, thinkpad t400 , tmobile comet , exactly matching Wikipedia titles are missing. So, Wikipedia does not offer much improvement in segmenting eCommerce queries, as it does for segmenting Web queries.

There are also differences between Web domain and eCom-merce domain in terms of use cases for query segmentation. In eCommerce, query segmentation is particularly useful for substituting, extending or reformulating user queries, so that the search engine can retrieve the right products for the shoppers. Say, a shopper searches for new thinkpad t400 ; if that search does not retrieve sufficient number of products, the search engine may choose to surface additional products that match the query refurbished thinkpad t400 . To ap-ply this query reformulation, the search engine requires to consider the phrase thinkpad t400 in the query, and then replace the word  X  X ew X  with the word  X  X efurbished X . Such applications of query segmentation for recovering from low-recall are actually rare for Web domain, because a typical web query rarely suffers from low-recall, unless some words in the query are mis-spelled. But, low-recall or even zero-recall is a common occurrence in eCommerce domain mostly due to the dynamic nature of the inventory; however it is also possible that a shopper experiences a zero-recall for a product that is available in the marketplace in abundance. For an example, take the scenario that we discussed in the first paragraph of this section, where a shopper intends to purchase an ac adapter for an HP laptop; the desired item is available in the marketplace from a large number of sell-ers, yet the query suffered a zero-recall, because of its ver-bosity. The above differences between the use cases of Web and eCommerce queries also warrant domain-specific per-formance metrics for assessing the performance of various query segmentation methods.

In this paper, we discuss Qsegment , a query segmen-tation system built at ebay and used to segment queries from a corpora of millions of eCommerce queries. The al-gorithm is efficient enough to be used in a near real-time fashion. To the best of our knowledge, this is the first work that discusses the segmentation of eCommerce queries. Ad-ditionally, we report experimental results on large datasets consisting of 25 thousand queries; such large scale analysis has rarely been done in any of the earlier works on query segmentation. Qsegment uses n -gram frequencies similar to what is described in Hagen et al.[13], however there are various adaptations to make it perform better on eCom-merce queries. One of the major adaptations is that instead of using only one training corpus, we use multiple training corpora; each corpus in this set corresponds to one of the meta-categories of products. On ebay there are around 35 top level domains which we refer to as meta-categories. For e.g. some of these are  X  X ollectibles X  ,  X  X lothing, Shoes &amp; Ac-cessories X  ,  X  X ome &amp; Garden X  and so on. Thus, the frequen-cies of n -grams of a query are taken only from the most rele-vant corpus. This improves the results for the segmentation task. Besides query classification (an off-line component), the core component of Qsegment is simple and computa-tionally light. It mostly uses the n -gram frequencies, which we obtain from query log or product titles and process in a map-reduce[8] cluster.

Another important contribution of this work is that we propose an unsupervised metric, named user-intent-score , for assessing the performance of a query segmentation method. This is a useful contribution because unlike Web domain, a gold standard annotated query-set is not available for eCom-merce domain. Further it is not even possible to obtain a large gold standard set, because for many eCommerce queries, different human experts disagree on the best seg-mentation of that query. The user-intent-score metric uses an indirect approach to capture the user-intent of a query from user X  X  click patterns on the result set. Then, for each segmented form of a query, it provides a numerical score which represents the closeness between the query X  X  result set and the user X  X  intent set.

In section 5, we show results that compare the perfor-mance of Qsegment with Hagen X  X  [13] method, Mishra et al. [25] X  X  method, and a mutual information based method [14], on a large dataset. These results validate that Qseg-ment is superior than all of these three methods. The remaining part of the paper is organized as follows. In Section 2, we discuss different methodologies of query segmentation. In Section 3, we discuss Qsegment in detail, including architecture, methodology, maintenance, and eval-uation metrics. Section 4 highlights some of the use cases of segmenting eCommerce queries. The subsequent sections show experimental results followed by conclusion.
We breakdown the existing query segmentation methods into three different groups based on their methodologies: (a) statistical method, (b) supervised and NLP based approach, and (c) IR (information retrieval) based method.

Statistical methods use frequency data from the query log for building statistical measures that denote the likelihood of a query segment to be a phrase. The earliest among such methods are based on mutual information. One such work is presented by Risvik et. al.[29], which segments queries by computing connexity values that use mutual information within a segment along with the segment X  X  frequency in a query log. Jones et. al. [19] use point-wise mutual informa-tion (PMI) on query terms for segmenting query, however the main emphasis of their work is on generating query sub-stitutions for effective retrieval performance. Similar term based PMI was also used in [21] to find high quality sub-queries, and segment-based PMI is used in [17] for obtaining web-scale language models.

Bergsma and Wang [4] proposed a supervised learning method for query segmentation. For a k -word query, there are k  X  1 different positions where a segment boundary can be placed, the supervised learning method predicts the yes/no decision whether a specific segment boundary will be placed or not. Bergsma and Wang incorporate many features: POS-tag features, statistical features as well as context and de-pendency features. Many of these features are selected to impose a segment boundary around the beginning and end of a noun phrase. For supervised learning, they use an SVM classifier. They also establish a benchmark corpus of 500 queries, each segmented by three human experts. Another sup ervised method is proposed by Bendersky et al.[3], which uses a two stage-method; in the first stage the query is de-composed into noun phrase chunks, and in the second stage it uses external information (say, query frequency from query log) as features for breaking a chunk, if necessary. For the first stage, they use a CRF based phrase chunker, and for the second they use a sequential multi-purpose chunker, both are trained on a pre-segmented corpus. However, the main chal-lenge of a supervised method is obtaining a large training set. Also, such methods assume that queries are composed of noun phrases, which is mostly not true for many eCom-merce queries.

In a recent work, Hagen et al.[13] proposed a simple query segmentation method that they call naive query segmenta-tion. This method scores all segmentations of a given query by the weighted sum of the frequencies of contained n -grams, obtained from a large web corpus. The objective of weight-ing is to apply a word-length based normalization so that a longer segment has a chance to achieve a higher score than a shorter segment. Besides raw n -gram, they use no other features, justifying the name naive segmentation. A follow-up work by the same group of authors [14] augments the naive query segmentation work by giving an empirical jus-tification of why the naive segmentation method works well in practice. The follow-up work also uses information from Wikipedia to boost the scores of a phrase if that phrase ap-pears as a title in a Wikipedia article. In another follow-up work [12], they conduct the first large-scale study of human segmentation behavior based on more than 50000 segmen-tations.

Recently, Mishra et al.[25] proposed a method that uses bag-of-words as a null model, and using the null model finds the probability of a Multi-Word Expression (MWE) (say w = ( w 1 , w 2 ,  X   X   X  , w k ) to be a phrase. Then, given a set of n queries where each query contains each of the words ( w i : 1  X  i  X  k ) of w , the method finds the number of queries (say, m : m  X  n ) in this set, that contain the MWE m . Then, the MWE score of m is computed as  X  log  X  , where  X  is the Hoeffding X  X  upper bound on the probability [16] that using null model, m or more queries may contain w as MWE. The difference between this method and other methods is that this method does not consider the frequency value of a query, so all the queries that contain the words of the query contribute significantly to the MWE score m .
In recent years, there have also been diverse efforts on evaluation of query segmentation algorithms. In earlier works, quality of segmentation was measured based on a few met-rics on a set of queries in a small human-annotated corpora, however it is not known how good these human-annotated gold-standard segmentations are for improving retrieval per-formance. In a recent work [30], the authors emphasized on measuring query segmentation directly based on its impact on retrieval performance. In this paper, we also show various metrics of query segmentation that are strongly influenced by the practical uses of query segmentation.
In this section, we discuss Qsegment in detail.
At ebay marketplace, we have more than 100 millions of searches a day, and more than 200 million active items on the site for sale at any given time. The query phrases from the search are referred as buyer vocabulary , and the product titles of the items are referred as seller vocabulary . The search interface of ebay takes a query, and matches it against the titles of active items on the site; in this matching, a query is considered as a bag of words using white space as delimiter, and any active item whose title or description text contains all the words of the query is considered as a relevant item for that query. The relevant items are displayed as an ordered list after they are sorted using a ranking function. A user can view, click or buy items from the search result page. Relevant activities of a shopper on the site, such as, their query strings, clicks, and views are stored in the query log for data mining purposes.

A shopper can alter the bag of words retrieval model that ebay  X  X  search considers, by enforcing phrase constraints in the query string using quotation symbol. For example, if a shopper types 500 gb X  X ard disk X  X nstead of 500 gb hard disk, then the products in which the words hard and disk appear together and in the specific order will be retrieved. Thus a phrase query retrieves a selective subset of relevant prod-ucts that the corresponding non-phrase query would have retrieved, Using phrase query improves the precision of the result-set, by sacrificing the recall. ebay uses a hierarchical taxonomy tree to partition the products into various categories. The top level nodes of the taxonomy tree are called meta-categories, and the low-est level nodes are called leaf categories. Books, Cameras &amp; Photos, Motors, Consumer Electronics, Antiques, Trav-els, Musical Instruments, and Toys are some of the meta-categories. Sellers must choose at least one category when they list their item on the site. Thus, every active item on the site can be mapped to one or more categories in the taxonomy tree. Shoppers are allowed to restrict their search only to a particular category by choosing the ad-vanced search option.

Besides the bare-bone search interface that we discuss above, ebay provides many assistive applications on the site for both the sellers and the buyers. For buyers, it provides query suggestion, automatic spell correction, and zero-recall recovery applications. For sellers, it provides category sug-gestion, and title suggestion[18]. Performance of these fea-tures is important to buyers, and sellers, so data from query logs is used to improve the quality of these applications. Query suggestion task that we discuss later in this paper, is a fundamental task that is used in many of these above applications. All the query logs as well as corpus of product description data is processed using a large map-reduce clus-ter. Processing the daily feed of both buyer vocabulary, and seller vocabulary to count the frequency of various n -grams is one of the major tasks that runs on this cluster.
A large portion of Qsegment is deployed over a Hadoop 2 based map-reduce server, that has access to the daily feed of both buyer vocabulary and seller vocabulary. Our expe-rience suggests that seller vocabulary is more polished com-pared to buyer X  X  vocabulary, it probably makes sense as sell-ers put more effort to choose the right title for their items so that their items surface for most of the relevant search queries. However, one problem with the seller vocabulary is that product titles are longer than typical queries, so the htt p://hadoop.apache.org/ query segmentation methods that are sensitive to the length of the query sometimes fail, if we use only seller vocabulary as the corpus. So, as a learning corpus, Qsegment uses a combination of both seller vocabulary and buyer vocabulary, by using different filtering mechanisms. By default, Qseg-ment considers a rolling window of about 2 years of vocabu-lary data for building the query segmentation model. More details around differences between these two vocabularies, effect of varying time length and weights of these vocabu-laries on query segmentation performance can be found in [37]. The overall process on Hadoop has a number of stages, which run sequentially. The stages are shown in Figure 1.
In the first stage of Qsegment , it cleans-up and nor-malizes billions of n -grams. At present, it considers up to 6-grams only, which covers more than 90% of our queries, and 46% of the product titles. In the second stage, it counts the frequency of the n -grams both over seller vocabulary and buyer vocabulary for the given period of time. This stage also devises a composite score for an n -gram that uses the frequency values from the above two vocabularies. Then using a heuristically determined threshold for this compos-ite score, it discards n -grams whose scores fall short of this threshold. The remaining n -grams are processed in the off-line stage.

In the off-line stage, Qsegment uses a classifier to clas-sify a query string into one of the meta queries. If the query string is available in seller vocabulary with a minimum fre-quency, Qsegment uses the most frequent categories used by different sellers, when they list the item on the site. If the query string does not have sufficient frequency in the seller vocabulary, then its category is obtained as below. For such a query, Qsegment creates a list of items that the shoppers click after they have issued the query. Thus, the query is mapped to a set of products that are relevant to that query. Then, using the categories of these products[32, 31], Qsegment determines the category of that query. If a query does not have sufficient click data, then Qsegment uses a method similar to the one discussed in [35, 2].
After classification of queries, Qsegment builds a set of corpora consisting of queries for each of the categories. Qseg-ment then computes the frequencies of all possible n -grams in each of these corpora independently. Thus, for an n -gram, different frequency values can be stored that represent its frequencies in corpora belonging to different categories. As an example, consider the 2-gram,  X  X ew yorker X , it can ap-pear in many queries that belong to different categories: for instance, it appears in the query the new yorker maga-zine , which belongs to the  X  X ooks X  category, in the query chrysler new yorker which belongs to the  X  X otors X  cat-egory, in the query Michael kors new yorker bag which belongs to the  X  X lothing, Shoes &amp; Accessories X  category, in the query new yorker restoration which belongs to the Pottery &amp; Glass category, and so on. Thus, the 2-gram  X  X ew yorker X  X ill have different frequency values correspond-ing to different categories. Collectively, the corpora have more than 125 million n -grams that are stored in an effi-cient search index,
Qsegment has two modes of operation, first as an API over an HTTP-like protocol; hardware specification for this is provided in Figure 1. In this case, the main segmentation module runs on a high performance C++ server, using main memory data structure. The memory footprint is about 1.2 GB, after further cleaning of a portion of tail n -grams that do not improve the efficiency. The second mode of Qseg-ment is for batch use-cases. In this mode, the segmentation code is written in Java which runs over Hadoop in a batch-mode and can segment large lists of queries.
As we have mentioned earlier Qsegment uses a n -gram frequency based approach. The choice of this method is guided by the simplicity and scalability of the model. We avoided costly statistical models that are not scalable to large datasets, such as, those that use conditional random fields (CRF). Models that are based on supervised learning frameworks are also ignored due to the difficulty of build-ing a large labeled corpus for training. Segmentation ap-proaches that depend on language modeling are also ignored, as eCommerce queries are short and informal, and may not conform well with grammatical rules.

Instead of directly using n -gram frequencies from queries, we first classify a query to a category, and then use the n -gram frequency from the corpus corresponding to that cat-egory. In this model, each segmentation (say, S ) of a query is scored according to the following function: score ( S ) =
However, eCommerce queries exhibit a very long-tail[10, 1, 1 5], and frequency of many queries are small (less than 10). Small frequency values are unreliable, and sometimes yield poor segmentation in methods that mostly depend on the frequency values. So, we use various other metrics, such as MWE score [25] and mutual information, for finding the score of a segmentation. And if a segmentation score falls short of a threshold, we consider that segmentation unreli-able and use unquoted query instead.
Query Segmentation task involves tasks such as normaliz-ing queries, normalizing product titles and building an index of n -grams. These same sub-tasks are also useful for tasks other than query segmentation like query completion, query suggestion and query ranking. As these are routinely run-ning tasks on the company cluster, the maintenance of fresh n -gram frequency values that are desired by Qsegment is not expensive.
It is difficult to evaluate the quality of a query segmenta-tion method on eCommerce queries as the segmentation task is ambiguous, and the ground truth is not known. For eCom-merce queries, our internal experiments show that for about 20% of the queries, multiple segmentations are proposed by different human experts. So, following some of the recent works [23], we also evaluate a query segmentation method based on its performance on various information retrieval use cases.

Our main evaluation metric is called user-intent-score . It measures the extent by which a segmentation method im-proves the understanding of user intent over a simple bag of terms model which considers each query term indepen-dently. This metric requires the quantification of user intent, for which we use click-through data, i.e., when a user clicks or buys a product, we consider that product to be relevant for the given query. Below, we explain the metric in more detail.

On eCommerce sites, products are listed against a tax-onomy tree and thus each product is associated with one of the multiple leaves in that taxonomy tree; we call these the leaf categories of the product. For a given product, leaf categories are typically known, as the seller of the product assigns the leaf categories when she enlists the product on the site. Now, consider a query q , for which the full text search engine retrieves various products, say, it is the set S . Since each of the products in S is associated with some leaf categories, we can induce a multinomial probability dis-tribution,  X  s ( q ), over these leaf categories for the query q . We call  X  s ( q ) the recall distribution for the query q . For instance, for a query q if 70% of the products on the search result page belong to leaf category cat1 , the  X  s ( q ) will have a value 0.7 for the leaf category cat1 .
 Among the products in S , consider a subset of products R  X  S which site users have bought or have viewed (clicked on it). Using click-through assumption, these products can be considered relevant for the given query, q . Now, as before, we can induce a multinomial probability distribution of leaf categories, but only using the products in the set R ; we call this distribution user intent distribution ,  X  i ( q ). Note that, when all the products in S are relevant, i.e., R = S , then  X  ( q ) =  X  i ( q ), but more often that is not the case and the IR performance of a query, q , can be measured by the closeness of the distribution  X  s ( q ) and  X  i ( q ),
Now, for a query q , let q s be one of its segmented forms. If we force the search engine to retrieve products by satisfying the phrase constraint in the segmented form q s , the search result changes; consider that the product in the search re-sult is S s , and assume that the recall distribution for the query q s as computed over the set S s is  X  s ( q s ). Like we de-scribed earlier, the IR performance of the segmented query q s can be measured by the closeness of the distribution  X  ( q s ) and  X  i ( q ). For example, for the query hard drive ,  X  ( hard drive ) is a distribution over all taxonomy leaves in which the user purchased or clicked on items after issuing the query;  X  s ( hard drive ) is a distribution over all taxon-omy leaves using the result set for the unrestricted query hard drive , and  X  s ( Phrase(hard drive) ) is the same dis-tribution but obtained using the result set S s after issuing the phrase query, Phrase(hard drive) . For a query q , We want to check if forcing a segmentation brings us closer to the user intent distribution,  X  i ( q ).
 We can compare two distributions using KL -divergence[20]. Thus, if KL (  X  i ( q ) ,  X  s ( q s )) is smaller than KL (  X  then the segmented form of the query q s shows better IR per-formance by being closer to the user intent distribution. The user-intent-score of a segmented form (say q s ) of a query q is the segmentation has better retrieval performance.
In this section, we discuss various use cases of a query segmentation module from the perspective of an eCommerce marketplace.
In the web domain, the proximity of query terms as they appear in the retrieved documents has been used to measure the relevance of a document to the query [7, 24]. A docu-ment is more relevant, if various query terms appear in that document in close proximity. In the best case scenario, the entire query phrase appears verbatim in the retrieved docu-ments; however, for long queries, this rarely happens. Thus, enforcing the verbatim requirement may yield zero recall. So a feasible alternative is to break the query into differ-ent syntactical units, and then retrieve relevant documents that satisfy a relaxed constraint.  X  X n a retrieved document the terms belonging to a syntactical unit should appear to-gether, and different syntactical units should appear within close proximity X   X  Enforcing this constraint reduces recall but it may improve the precision of the result-set substan-tially. However, the key step for applying the above con-straint is to find different syntactic units of the query, which can be done through query segmentation.

Similar to web search, query segmentation is also effec-tive in improving the precision of product search in eCom-merce domain. At their core, most eCommerce search en-gines consider each term in the query independently and display all the products whose titles or descriptions contain all the words in the query. So, for a query like  X  X ichael Jackson X , the recall set might have products that possess the terms Michael and Jackson in their product descrip-tion, but not necessarily in that order and together as a phrase. Thus, the query will inaccurately match products (false positives) whose descriptions contain both the follow-ing phrases:  X  X ichael Jordan X  and  X  X anet Jackson X . These fal se positives negatively affect the precision metric. But, by considering the query  X  X ichael jackson X  as a syntactic unit, the false positive products can be excluded from the result-set. In summary, the intent of the user is more closely captured by looking at intent units (query segments) in the queries, rather than tokenizing on white space for individual term-based retrieval.
Another important aspect in web search or product search is the ranking of the retrieved items (a web page or a prod-uct). In web-search scenario, a predominant factor for rank-ing web documents is the PageRank[26] value of a web page, which is a score obtained from the underlying topology of the Web graph. Unfortunately, for eCommerce products, graph-based ranking is not available, which makes product rank-ing a more challenging task. In existing eCommerce systems, product ranking is performed using various factors that com-bine buyers X  preference, sellers X  reputation, and product X  X  relevance given the query term. One of the ways to measure a product X  X  relevance to a given query is to find whether ti-tle (or description) of the product identically matches with some of the syntactical units of a query. For that, we need to first segment a query to find various syntactical units.
Query suggestion is an integral part of most search en-gines[27]. For product search, it provides the users with an option to narrow down their search to the product of inter-est or explore related products [15]. Various approaches are used in the design of query suggestion systems but at the heart of all such systems are ways to find queries that are semantically related to a given query [28, 15].

Most industry solutions use an ensemble approach where collaborative filtering on user search data, click-through from query logs and content based similarity of queries are used to find Related Searches. For head and torso products and queries, rich session behavior for collaborative filtering and large number of click-throughs are available for mining and generating high quality suggestions. However for the long tail, these data-sets do not exist and hence most meth-ods fall-back to content based similarity based on terms in queries. Previous proposed similarity functions include Lev-enshtein distance[22, 33] or exponential distance [28] based on terms present in queries. Some approaches weight the terms based on idf (inverse document frequency) so that rare terms that are common between two queries lead to higher similarity than the cases of popular terms being common.
However, as all these functions look at terms after white space tokenization of queries, they fail to capture user X  X  no-tion of intent. Users tend to think of units. For example, for a user christina aguilera poster , and britney spears poster might be as close as say 007 poster and termina-tor poster . However, for a term based similarity function the first pair of queries are 2 terms away whereas the second pair of queries are one term away, making the second pair of queries more similar than the first pair of queries. If in-stead of tokenizing on space, we can tokenize on appropriate segments and then have a distance function based on differ-ences in segments(units) instead of terms then this notion of closeness can be captured. Query segmentation provides us Original One-hop transition
Query Query prada bag marc jacobs bag cricut gypsy cricut tool kit strawberry shortcake vintage vintage dolls strasburg dresses strasburg dresses size 4 stratocaster bodies stratocaster eric Johnson diamond semi mount rings white gold semi mount diamond princess princess diamond engagement Table 1: Original query and one-hop transition que ry using query segmentation the segment boundary so that we can use it for computing distances between two queries appropriately.
An important use case of a query segmentation method is query substitution [19, 6], which is also known as query re-write [11] in the web community. The main objective of query substitution is to replace an overly specific query with a more general one that yields higher recall. This is particu-larly important for the eCommerce domain to guard against zero-recall [34], that may frustrate a buyer and result in poor user experience. However, query substitution is deli-cate, and irrelevant results caused by a wrong substitution may annoy the user more than receiving a smaller or null result-set. An accurate query segmentation algorithm can help in the design of more optimal query rewrite engines. Table 2: Performance Comparison between different alg orithms
In this section, we show results for different experiments that we performed with Qsegment . In the first experiment we compare the performance of Qsegment with three of the existing methods. The first of three methods are Hagen et al. X  X  method which uses raw n -gram frequencies of a query [13], the second is Mishra et al. X  X  method that computes MWE score of a query [30] and the third is a baseline method that computes mutual informa-tion at different segment boundary and based on that finds the best segmentation. For the sake of brevity, we will refer to these three methods as Frequency-based method, MWE met hod, and MI method respectively. For this experiment, we took 25K random queries from a popular long query set; frequency of these queries is more than 500 in 2 days query log at ebay . The length of these queries is between 3 and 8 (both inclusive). We segment the queries using Qsegment and the above three methods. Note that, MWE method ac-cepts two user-defined parameters,  X  and  X  . We set  X  = 10 and  X  = 0 . 8 for this experiment. These values were chosen as they were the optimal values obtained through evaluation on a hypothesis set.

We compute user-intent-score for each of the queries using the above algorithms. A positive value for user-intent-score means that using that segmentation method the recall distri-bution is closer to the user intent distribution as compared to no segmentation, on the other hand a negative score means that we are better off if we leave the query as it is without performing any segmentation. If for a query, a segmentation method achieves a positive user-intent-score , we award the corresponding method one point. In case, multiple methods produce the same segmentation which is better than the no-segmentation case, none of the methods receives any point.
Table 2 shows the results. In this table, each row rep-resents a pair of methods that are being compared. There are 4 columns in the table. The second column shows the number of queries for which both the methods has the same segmentation, and hence their user-intent-score is the same. The third column and the fourth column show the number of queries for which user-intent-score of the first and sec-ond method are better, respectively. The numbers in a row sum to 25K, which is the total number of queries in this experiment. While comparing two algorithms, we also com-pare every algorithm with the scenario of no-segmentation. A no-segmentation scenario wins only if user-intent-score is negative. From this table, we see that Qsegment wins over all the algorithms, by winning for almost twice as many queries compared to its competitors. For example, Qseg-ment wins over frequency based method with score of 7828 vs 4413, it wins over MI with score 6309 vs 4138 and so on. Interestingly, the closest to Qsegment is the Mutual infor-mation (MI) based method. Earlier works on Web query seg-mentation reported that frequency based method and MWE methods are superior than MI based method. But, our ex-periment shows that MI is actually better than these two methods. One of the explanation for this is that frequency based methods depend mostly on the query frequency, which may not be a stable statistic for eCommerce queries. Nev-ertheless, Qsegment wins over MI even though it is a fre-quency based method. Probably, the reason for this is that the category based classification generates and uses corpora with queries or product titles that have homogeneous n -gram statistics. Thus the n -gram frequencies from the right corpora combined with appropriate weighting of buyer vs. seller vocabulary frequencies helps Qsegment work well.
Table 2 also shows that MWE is the worst performer as it wins only over the case of no-segmentation. The reason probably is that it does not use the query frequency at all, which is an important information for query segmentation. Another observation is that segmentation is always better than no segmentation case. This shows the importance of segmentation for improving IR performance in eCommerce domain.

In T able 3, we show a set of example queries. For each of the queries we also show the, KL (  X  i ( q ) ,  X  s ( q )) which repre-sents the deviation between the user intent distribution and search engine result distribution for unsegmented queries. If using segmented form of a query makes the above devi-ation smaller, then the segmentation is worth considering. In Table 4, we show the segmentation of the above queries using 4 different methods, including Qsegment . Each seg-ment of a query is separated by a vertical bar. If a query is not segmented by an algorithm, no bar is present in that query. We also show the KL divergence value between the user intent distribution and search engine result distribution for segmented queries using the corresponding segmentation method. If two methods result in the same segmentation then they will have identical value for the KL divergence. The lowest KL divergence values in each row are shown in bold.

As we can see from Table 4, for most of the queries, the segmentation methods lowered the KL divergence value, i.e., they have a positive user-intent-score . Qsegment wins in all the queries in the chosen set. One of the interesting fact about Qsegment is that it tends to choose longer phrase if available, which other methods fail to do. For example, for the query swiss army knife lots , only Qsegment consid-ered entire phrase swiss army knife as a phrase, whereas other methods only considered swiss army as a phrase. Same holds for the query hot air brush , and violin string set . Table 5: Performance Comparison between different alg orithms for various query lengths
We also compare the performance of Qsegment with other methods for queries of different lengths. The result is shown in Table 5. As we can see in this table, Qsegment wins over MWE and MI over all different lengths. One interesting ob-servation is that as the length of the queries increases, the agreement between different algorithms decreases, which can be seen by the value of the tie column. For example, when comparing Qsegment and MWE methods, the tie percent-ages are 46%, 42.5%, and 19% respectively, for queries with 3, 4 and 5 (or more) words. In a way this is intuitive be-cause with high number of words, there are more choices for segmenting the query.
We also perform experiments to show how query seg-mentation can help improve performance of some practical eCommerce product features. Here we show a result that shows that query segmentation can help design better dis-tance functions between queries for building query sugges-tion algorithms. In order to test our segmentation approach for this particular use case, we pick user behavioral transi-tions from search query logs. For this experiment, we ignore the tail queries and only look at queries that are at the head or torso part of the frequency distribution. Characteriza-tion of eCommerce queries into head, torso and tail buckets is described in more detail in [15]. We do so, because for tail queries, the query transition behavior is noisy and does not show any regular pattern. The intuition here is that the selected transitions are closely related queries as implic-itly reflected by user X  X  behavioral activity. A good distance function will capture this and consider these queries to be closely related and more similar. If queries q 1 and q 2 tokenized into units then we denote the set of units in q n 1 and set of units in q 2 as n 2 . If number of elements in n  X  n 2 is n i and number of elements in n 1  X  n 2 is n u , then we consider q 1 and q 2 to be one hop away if n u -n i  X  2. Then if we use the query n -gram segmentation model (considering distinct segment of a query as a unit), we get the following results: Out of total 4225160 query transitions, transitions that are one hop away is equal to 1417714; if we tokenize using white space. Transitions that are one hop away is equal to 1496493, if we tokenize using query segmentation model. So our model does do better in this case. Some ex-amples where the model does better than space tokenization are shown in Table 1. Thus, we see that considering distance based on segment units rather than terms can better capture the intent of the users.
Query segmentation is an important problem for eCom-merce search. In this paper, we described Qsegment a query segmentation system that we have built using query logs and product titles from ebay . As most eCommerce platforms have products organized into taxonomies, we used the taxonomy information to incorporate domain specific models in our system. We showed that such a domain aware model outperforms other popular query segmentation algo-rithms described in literature. Query segmentation is a sub-jective task. However, usually the purpose of performing query segmentation is to improve the performance of fea-tures such as search or recommendations. Hence, we also introduced an unsupervised metric user-intent-score which can measure the efficacy of query segmentation in terms of information retrieval effectiveness. We showed a large scale evaluation of our algorithm using this metric. We also dis-cussed how appropriate query segmentation can help better product search ranking, query rewriting and query sugges-tions more specifically in the tail.

To the best of our knowledge, this is the first paper that discusses a query segmentation system for eCommerce at a large scale. Our approach works well in practice. We also showed how the eCommerce query segmentation problem compares and contrasts with that of web search. The ap-proach of using domain specific data is generic enough to be applicable to any platforms which have an explicit or implicit taxonomy defined over documents.

As we saw, segmentation is useful for eCommerce appli-cations. Its utility is different in different contexts. As part of future work we would like to design a system which can optimize the query segmentation based on the context of the application, sensitivity of aggressiveness in segmentation to the application as well as the characteristics of the query. We would also like to study how using more and more his-torical data from the same vocabularies(buyer and seller) or adding information from other vocabularies like product catalogs or commerce blogs impacts the performance of the algorithm.
We would like to thank Anselm Baird Smith for inspiring this research, Neel Sundaresan for supporting this research and Gyanit Singh for useful observations and comments. [1] C. Anderson. The Long Tail: Why the Future of [2] P. Bailey, R. W. White, H. Liu, and G. Kumaran. [3] M. Bendersky, C. W. Bruce, and D. Smith. Two-stage [4] S. Bergsma and Q. I. Wang. Learning noun phrase [5] S. Brants and A. Franz. Web 1t 5-gram version 1. In [6] Y. Chen and Y.-Q. Zhang. A query [7] R. Cummins and C. O X  X iordan. Learning in a pairwise [8] J. Dean and S. Ghemawat. Mapreduce: simplified [9] J. Gao, J.-Y. Nie, G. Wu, and G. Cao. Dependence [10] S. Goel, A. Broder, E. Gabrilovich, and B. Pang. [11] S. Gollapudi, S. Ieong, A. Ntoulas, and S. Paparizos. [12] M. Hagen, M. Potthast, A. Beyer, and B. Stein. [13] M. Hagen, M. Potthast, B. Stein, and C. Brautigam. [14] M. Hagen, M. Potthast, B. Stein, and C. Brautigam. [15] M. A. Hasan, N. Parikh, G. Singh, and [16] W. Hoeffding. Probability inequalities for sums of [17] J. Huang, J. Gao, J. Miao, X. Li, K. Wang, F. Behr, [18] S. Huang, X. Wu, and A. Bolivar. The effect of title [19] R. Jones, B. Rey, O. Madani, and W. Freiner. [20] S. Kullback and R. A. Leibler. On information and [21] G. Kumaran and V. R. Carvalho. Reducing long [22] V. Levenshtein. Binary Codes Capable of Correcting [23] Y. Li, B.-J. P. Hsu, C. Zhai, and K. Wang.
 [24] Y. Li, B.-J. P. Hsu, C. Zhai, and K. Wang.
 [25] N. Mishra, R. Saha Roy, N. Ganguly, S. Laxman, and [26] L. Page, S. Brin, R. Motwani, and T. Winograd. The [27] N. Parikh, G. Singh, and N. Sundaresan. Query [28] N. Parikh and N. Sundaresan. Inferring semantic [29] K. Risvik, T. Mikolajewski, and P. Boros. Query [30] R. Saha Roy, N. Ganguly, M. Choudhury, and [31] D. Shen, J.-D. Ruvini, and B. Sarwar. Large-scale [32] D. Shen, J. D. Ruvini, M. Somaiya, and [33] X. Shi and C. C. Yang. Mining related queries from [34] G. Singh, N. Parikh, and N. Sundaresan. User [35] G. Singh, N. Parikh, and N. Sundaresan. Rewriting [36] M. Srikanth and R. Srihari. Biterm language models [37] P. Sriram and N. Parikh. Towards ideal segmentation [38] B. Tan and F. Peng. Unsupervised query segmentation
