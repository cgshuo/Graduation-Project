 Measuring pairwise document similarity is critical to various text retrieval and mining tasks, such as clustering, filtering and similarity search. It is thus im-portant to measure similarity as effectively as possible. To date, many similarity measures have been proposed and implemented, such as the Cosine measure [3], the Jaccard measure [8], the Dice Coefficient measure [13], the information-theoretic measure [2], the DIG-based measure [6], etc. Among these measures, the Cosine measure is the most popular one and has been successfully used in various tasks.
 feature vectors to represent the original documents and then calculate the simi-larity between the feature vectors, such as the Cosine measure and the Jaccard measure. These measures do not take into account the structural information of a document. The compressed feature vectors lose the word distribution over text segments in the documents. In fact, different text segments represent different subtopics [7]. For example, one dimension in a document feature vector can be the word  X  IBM  X , and its weight can be its frequency 3, but we do not know how the word  X  IBM  X  distributes in the document: Maybe these three instances of  X  IBM  X  appear in the same text segment discussing the WebSphere software, or each  X  IBM  X  may appear in a distinct text segment: one discussing the Lotus software, one discussing WebSphere software and the other discussing the Tivoli software. The different word distributions over text segments will influence the similarity between documents: the more similar the word distributions are, the more similar the documents will be.
 theory between documents. The proposed similarity measure takes into account the structural information of a document by considering the word distribution over different text segments. It first calculates the similarities for different pairs of text segments in the documents and then gets the total similarity between the documents optimally through optimal matching. Experiments and a user study are performed to demonstrate the effectiveness of the proposed similarity measure, which outperforms the popular Cosine measure. We also examine the approach of text segmentation and the similarity measure between segments, which are the key issues influencing the performance of the proposed measure significantly. the popular Cosine measure widely used for document similarity search. The optimal matching theory is explained in section 3. In Section 4, we propose a document similarity measure based on optimal matching. Experiments and results are described in Section 5. A preliminary user study is performed in Section 6. Section 7 gives our conclusions and future work. A variety of different retrieval models have been developed to represent docu-ments and measure the similarity between documents in the IR field, including the Boolean model, probabilistic model, Vector Space Model(VSM) [3, 15], and the more complicated Latent Semantic Analysis [5]. The Vector Space Model is one of the most effective models and has been widely used for filtering, clustering and retrieval in IR field.
 by vectors. For a fixed collection of documents, an m-dimensional vector is gen-erated for each document from sets of terms with associated weights, where m is the number of unique terms in the document collection. Then, a vector simi-larity function, such as the inner product, can be used to compute the similarity between vectors.
 lowing two numbers: 1. term frequency, f ij the number of occurrences of term t j in document d i ; 2. inverse document frequency, idf j = log( N /n j ),where N is the total number The similarity sim ( d 1 ,d 2 ), between two documents d 1 and d 2 , can be defined as the normalized inner product of the two vectors d 1 and d 2 : where m is the number of unique terms in the document collection. Document weight w ij is lar similarity measure for document similarity search. The Cosine measure can capture a scale invariant understanding of similarity. An even stronger property is that the Cosine similarity does not depend on the length: sim (  X d 1 ,d 2 )= sim ( d 1 ,d 2 )for  X &gt; 0. This allows documents with the same composition, but different totals to be treated identically. Also, due to this property, samples can be normalized to the unit sphere for more efficient processing.
 vector, which loses the structural information about term distributions over text segments. In the extreme case, two documents with identical vectors may be composed of different sentences. When compared with a given document using the Cosine measure, they get the same similarity values. But in fact, they should have different similarity values when judged manually. Optimal matching(OM) and maximal matching(MM) are classical problems in graph theory. Let G = { X, Y, E } be a bipartite graph, where X = { x 1 ,x 2 ,...,x n } and Y = { y 1 ,y 2 ,...,y m } are the partitions, V = X Y is the vertex set, and E = { e ij } is the edge set. A matching M of G is a subset of the edges with the property that no two edges of M share the same node. Given the unweighted bipartite graph G , as illustrated in Figure 1, MM is to find a matching M that has as many edges as possible. OM is basically an extension of MM, where a weight w ij is assigned to every edge e ij in G , as illustrated in Figure 1. OM is to find the matching M that has the largest total weight.
 employed to solve the OM problem. The algorithm is as follows: 1. Start with initial label of l ( x i )= max j e ij , l ( y j )=0; i, j =1 , 2 ,...,t ; 3. If M consists of all vertices in X , M is the optimal matching of G and the 4. Find a vertex x i  X  X where x i is not inside M .Let A  X  X  x i } and B  X  X } 5. If N G l = B , then go to step 9, otherwise go to next step. N G l  X  Y corre-6. Find a vertex y j  X  N G l ( A )  X  B . 7. If ( y j ,z )  X  M ,let A  X  A { z } , B  X  B { y j } ,thengotostep5.Otherwise 8. There exists an augmenting path P from x i to y j ,let M  X  M E ( P ), 10. Replace l  X  l , G l  X  G l , and go to step 6.
 t = max ( n ,m ).
 successfully employed to measure the similarity between video clips in content based video retrieval [10]. Inspired by this, we propose a novel similarity measure based on optimal matching theory to better measure the similarity between documents. 4.1 The Proposed Measure Based on optimal matching theory described in Section 3, we propose a measure for document similarity.
 any document Y in the document collection. Here, X = { x 1 ,x 2 ,...,x n } and Y = { y 1 ,y 2 ,...,y m } ,where x i represents a text segment in document X and y represents a text segment in document Y . We assign weight w ij to every edge e , measuring the similarity between x i and y j .
 the optimal matching in the graph. In order to balance the effect of the lengths of different documents, we normalize the total value as follows: where optmatc h ( d 1 ,d 2 ) represents the total value of the optimal matching for d 1 and d 2 . l e n gt h ( d ) represents the count of text segments in document d and mi n ( a, b ) returns the minimal value of a and b .
 documents.
 tion of a document by considering the term distribution over text segments, thus capturing the subtopic structure of the document. 4.2 Text Segmentation As described above, x i and y j represent text segments in documents. We expect that the text segment used in the proposed measure is cohesive and coherent and may map to a distinct subtopic as well. Naturally, single sentence is a good candidate for text segment. Overlapping adjacent sentences can be used as text segment in that adjacent sentences are usually linguistically related. The number of the adjacent sentences can vary in our experiments. Noting that the paragraph structure of a document is not available for our data, we do not consider using paragraphs as text segments.
 and can not discover the subtopic structure of document. Here, we employ the algorithm of TextTiling [5] to partition texts into coherent multi-paragraph seg-ments, which reflect the subtopic structure of the texts. For TextTiling, subtopic discussions are assumed to occur within the scope of one or more overarching main topics, which span the length of the text. Since the segments are adjacent and non-overlapping, they are called TextTiles.
 terns of lexical co-occurrence and distribution with the text. The main idea is that terms that describe a subtopic will co-occur locally, and a switch to a new subtopic will be signaled by the ending of co-occurrence of one set of terms and the beginning of the co-occurrence of a different set of terms. The algorithm has three parts: tokenization into terms and sentence-sized units, determination of a score for each sentence-sized unit, and detection of the subtopic boundaries, which are assumed to occur at the largest valleys in the graph resulting from plotting sentence-units against scores.
 segments as vertices in the bipartite graph. 4.3 The Edge Weighting Measures In the proposed approach, the edge weighting measure is a key issue and signif-icantly influences the final performance.
 the Jaccard measure to measure the similarity between them. Here, we also use x i and y j to represent the set of words in the text segments respectively. The Binary Jaccard measure measures the ratio of the number of shared attributes(words) of x i and y j to the number possessed by x i and y j : where | x i y j | denotes the number of the words shared by x i and y j ,and | x i y j | denotes the number of the words possessed by x i and y j .
 features as follows [14]: where x i and y j represent the corresponding feature vectors respectively. Jaccardmeasureasfollows: where x i y j denotes the words shared by x i and y j ,and x i y j denotes the words possessed by x i and y j .
 weight for every word in the vector. 5.1 Experimental Setup We design a simple document retrieval system to test the effectiveness of the proposed similarity measure in comparison with the popular Cosine measure. Given a query document, the retrieval system is to find the similar documents to the given document and return a ranked document list. We implement it just by comparing each document in the document collection and the query document and then sort the documents in the collection by their similarity values. our knowledge, there is no gold standard data set for evaluation of our system. So we build the ground truth data set from the TDT-3 corpus, which has been used for evaluation of the task of topic detection and tracking [1] in 1999 and 2000. TDT-3 corpus is annotated by LDC from 8 English sources and 3 Mandarin sources for the period of October through December 1998. 120 topics are defined and about 9000 stories are annotated over these topics with an  X  X n-topic X  table presenting all stories explicitly marked as relevant to a given topic. topic are similar and relevant. After removing the stories written in Chinese, we use 40 topics and more than 2500 stories as a test set, while the others are used as a training set. Sentence tokenization is firstly applied to all documents. The stop word list in SMART [12] is employed in order to remove stop words. Then we use Porter X  X  stemmer [11] to remove common morphological and inflectional endings from English words. The total stories are considered as the document collection for search, and for each topic we simulate a search as follows: The first document within the topic is considered as the query document and all the other documents within the same topic are the relevant documents, while all the documents within other topics are considered irrelevant to the query document. Then the system compares this document with all documents in the document collection, returning a ranked list of 100 documents. The higher the document is in the ranked list, the more similar it is with the query document. Thus we can use classical precision( P )attop N results to measure the performance: where R is the set of top N similar documents returned by our system, and C is the set of relevant documents defined above for a given query document. In most of our experiments, we use P @5, P @10 and p @20 for evaluation. For each search, we can get the corresponding P @5, P @10 and p @20. Then we calculate the average P @5, P @10 and p @20 over the 40 topics as the final precisions. topics contain less than 5 documents, so its corresponding precisions may be low. But these circumstances do not affect the comparison of the performance of different systems.
 larity measure for this document retrieval problem. We compare the performance of the proposed similarity measure with the baseline to show the effectiveness of the proposed approach.
 similarity measure between text segments respectively. For text segment, we can use single sentence (uni-sentence or uni-), adjacent two sentences (bi-sentence or bi-), adjacent three sentences (tri-sentence or tri-), adjacent four sentences (four-sentence or four-), adjacent five sentences (five-sentence or five-) or multi-paragraph segment (TextTile). We use the JTextTile [4], which is a Java imple-mentation of Marti Hearst X  X  text tiling algorithm, to segment texts into coher-ent topic segments with the recommended parameter settings. For the similarity measure between text segments, we can use the Cosine measure, Bi-Jaccard mea-sure, Continuous Jaccard measure, and Idf-Jaccard measure. Different settings result in different performance of the proposed approach. 5.2 Experimental Results Theresultsof P @5, P @10 and P @20 are shown in Figures 2-4, respectively. In Figures 2-4,  X  cosine  X  means the traditional Cosine measure is used to measure the similarity between documents.  X  optmatch(cosine)  X  means we employ the pro-posed measure with the Cosine measure measuring the similarity between text segments.  X  optmatch(bi-jaccard)  X ,  X  optmatch(idf-jaccard)  X  X nd X  optmatch(con-jaccard)  X  use the Bi-Jaccard measure, Idf-Jaccard measure and Continuous Jac-card measure respectively to measure the similarity between text segments. The uni-, bi-, tri-, four-, five-sentence and TextTile are various choices for text seg-ment in the proposed measure.
 posed measure is better than that of the Cosine measure. For precision at top 5 results, the proposed measures with most different settings outperform the Cosine measure. Table 1 gives the best values of P @5, P @10 and P @20 for the proposed measure and their corresponding settings(text segment and similarity measure for text segments). In Table 1, the upper bounds of P @5, p @10 and p @20 are given and these precisions are not 100% in that the number of relevant documents for a query document is not always larger than 5, 10 or 20. Seen from the figures and the table, we actually achieve a significant improvement on the P @5 and P @10 compared to the most popular Cosine measure.
 tences becomes larger, the performance of the proposed measure is improved, but this ascending trend stops when text segment contains adjacent five sentences. The measures using TextTile as text segment mostly get better performance of P @10 and P @20 than those using adjacent sentences as text segment. Given a similarity measure for text segments, the proposed measure with the setting of single sentence gets the worst results. measures using the Continuous Jaccard measure and the Cosine measure to measure text segment similarity get almost the same best performance. The Idf-Jaccard measure gets a little lower performance than the above two mea-sures. The Bi-Jaccard measure always gets the worst results compared to other measures. Inverse document frequency(IDF) does improve the performance. measure. In Section 5, experiments are performed to show the effectiveness of the proposed approach. But precision can not reflect the ordering of the relevant documents. When the precisions of two returned ranked lists for a query document are equal, the ordering of the relevant documents may be different. We should not treat the relevant documents identically. These relevant documents should have different similarities with the query document and we should place the most similar document in the front of the ranked list. The rank for each document in the ranked list represents the degree of similarity with the query document. Unfortunately, there is no ground truth ordering for the relevant documents, so we performed a user study to compare their orderings.
 first on-topic document as the query document and then compared it with other on-topic documents and get a ranked list.
 because they were within the same topic. Different similarity measures produced different ranked lists for these relevant documents. We used the Cosine measure and the proposed similarity measure with the best setting(text segment: Text-Tile; text segment similarity measure: Cosine measure) to produce the ranked lists for the 5 topics. tively. We had no detailed guideline for the users to evaluate the orderings. We just told them that they might consider text content, structure, length, writing style, etc. The subjects were required to express an option for each ranked list over a 3-point scale, where 1 stands for  X  bad ordering  X , 3 stands for  X  good order-ing  X . Then we averaged the points across topic and subject and Table 2 shows the result.
 a more satisfying ranked list than the Cosine measure. The proposed measure put the most similar documents in the front of the ranked list. In a sense, the pro-posed measure has a better understanding of  X  similarity  X  than Cosine measure. In this paper, we have proposed a new measure for document similarity. The pro-posed measure is based on optimal matching in graph theory. The proposed mea-sure is able to capture the structural information of a document by considering the word distributions over text segments. Experimental results and a prelimi-nary user study shows that the proposed measure outperforms the most popular Cosine measure. We have also discussed the two key issues in the proposed mea-sure: text segment choice and similarity measure between text segments. Results show that taking TextTile as text segment and the Cosine measure as similarity measure for segments can get the best performance.
 ment clustering, duplicates detection and story link detection. Though TextTil-ing is a popular approach to capture the subtopic structure of a document, we will try to explore better approaches to get the discourse structure suitable to measure document similarity.
 We thank John Chen for both his great suggestions and his careful amendments for this paper. Lastly, we thank those students for the user study.

