 Radio Frequency Identification (RFID) promises optimiza-tion of commodity flows in all industry segments. But due to physical constraints, RFID technology cannot detect all RFID tags from an assembly of items. This poses problems when integrating RFID data with enterprise-backend sys-tems for tasks like inventory management or shelf replen-ishment. In this paper we propose the TagMark method to accomplish this integration. TagMark targets at a re-tailer scenario, where it estimates the number of tagged items from samples like the sales history or the tags read by smart shelves. The problem is challenging because most existing estimation methods depend on assumptions that do not hold in typical RFID applications, e.g., static item sets, simple random samples, or the availability of samples with user-defined sizes. TagMark adapts mark-recapture-methods in order to provide guarantees for the accuracy of the estimation and bounds for the sample sizes. It can be implemented as a database extension, allowing seamless in-tegration into existing enterprise backend systems. A study with RFID-equipped goods acknowledges that our approach is effective in realistic scenarios, and database experiments with up to 1 , 000 , 000 items confirm that it can be efficiently implemented. Finally, we explore a broad range of extreme conditions that might stress TagMark, including a thief who knows the location of unread items.
 H.2.8 [ Database Management ]: Database Applications Algorithms, Experimentation, Performance, Reliability
With Radio Frequency Identification (RFID) [9], physical objects are tagged with globally unique IDs. It is possible to read several tagged objects at once, e.g., from commodities that pass the reader in a transport box. However, current and future technology cannot guarantee that all items in the range of the reader are read. For instance, when a re-tailer deploys RFID technology to optimize his commodity flows [11], the situation is as follows: RFID readings de-pend on inexpensive RFID tags with small antennas. Due to products containing metals or liquids, the number of tags read divided by the number of tags in the range of the reader for an assembly of items ( tag-identification rate ) usually lies below 100%. Table 1 shows some typical numbers [13]. This is a problem, as reliable RFID data is a prerequisite for data mining, business processes like inventory management or re-plenishment planning and other applications.

An RFID reader cannot observe its tag-identification rate, and unread tags cannot be recognized until changing phys-ical conditions cause the blind spots of the reader 1 to shift. Changing conditions in turn affect the tag-identification rates. For example, after a customer has taken an interfering item from a smart shelf, the reader might identify tags unread so far. In this paper we propose TagMark , a mechanism that estimates the number of tagged items with guaranteed ac-curacy. The estimation is based on samples from streams of RFID tags read successively, e.g., the items detected in smart shelves [7] or identified at a point of sale. Existing estimators (cf. [3]) cannot be applied to RFID data, for the following reasons: It is unlikely to obtain simple random samples for the estimation; instead, the size and the content of the samples depend on unpredictable physical conditions and have an unknown bias. Continuous in-and outflows re-sult in non-static stock populations. Stocks go empty and are replenished between sampling points. Further, most ex-isting estimators have not been tested against challenges like shoplifters trying to outsmart detection mechanisms.
We tackle these challenges by adapting mark-recapture methods ( MR , [24]) for RFID scenarios. In particular, we make the following contributions: when conductive objects scatter or absorb signals. See [10] for an overview of reasons for failed RFID readings. Table 3: Example of table  X  X tems X  with RFID data In the next section we specify our retail scenario. In Sec-tion 3 we describe mark-recapture methods and investigate their applicability to RFID scenarios. Section 4 introduces TagMark, followed by an experimental evaluation in Sec-tion 5. We then review related work and conclude.
With RFID-equipped items and smart shelves that track the present items in real time, a retailer can optimize ap-plications [14] like stocktaking, tracking out-of-stocks or the detection of shoplifting. The savings potential is large. For example, sales losses that occur when shelves go empty are estimated to be 3 . 9% of sales worldwide [12]. To introduce TagMark, we describe the following RFID scenario which we have devised together with a large retailer. The scenario is not confined to this retailer, but is rather general.
Tables 2 and 3 show examples of the inventory list and the list of items obtained from the RFID reader. The ta-bles describe when an item was first and last read in the store, and when it has been sold. The Electronic Product Code [8] ( EPC ) uniquely identifies the item and the product group. In the case of shoplifting or damaged goods, the in-ventory list contains more products than actually available in the shelves. It does not contain information on misplaced products or empty shelves. Due to tag-identification rates below 100%, the items table contains unreliable information as well. Thus, querying all items read in store will not in-clude the ones which cannot be read at this moment. On the other hand, querying all items currently unsold will not dis-tinguish between stolen items, items in the shopping carts, or products that cannot be read.

The item sets from the smart shelves and from the point of sale can be seen as samples of a base population. Thus, it should be possible to apply statistical methods to estimate the number of items in the store. In this context, the fol-lowing characteristics of RFID data have to be considered: C1: Unpredictable item sets In general, RFID readers C2: Continuous data streams In a retail store, RFID C3: Open populations In retail, the shelves go empty C4: Large data volume Applications of item-level tag-
MR methods are designed to provide reliable estimations in scenarios where the size of the base population is not known, i.e., where it is impossible to compute the number of items that have to be sampled in order to obtain a statis-tically significant share of the base population.
MR methods estimate the number of animals in a popu-lation of unknown size N . The size of the estimated popula-tion is  X  N . A sample of size n 1 of animals is taken from the population, these animals are marked for future identifica-tion and then returned to the herd. After allowing marked Symbol Description n 1 , n 2 Size of first, second sample and unmarked animals to mix, a second sample of n 2 ani-mals is taken, of which m 2 had already been captured and marked in the first sample (cf. Table 4). Assuming that the ratio of marked animals in the second sample is a reason-able estimate of the ratio in the unknown population, we can obtain an estimate  X  N as follows [24]:  X  N is a suitable estimate of N , if Thus, classical MR methods require two random samples. The accuracy of the estimation depends on their sizes. Let A and  X  describe a relative confidence interval, i.e.,  X  N  X  N is the relative accuracy, and (1  X   X  ) is the probability that the estimated population  X  N lies inside the relative accuracy A , i.e.,  X  N  X  N N &lt; A [21]. The following equation, where P () denotes the probability of a certain event, can express this:
We transform this equation above using the normal cumu-lative distribution function (CDF). The CDF  X  ( z ) calculates the probability that a standard normal random variable z is greater than a given value. Thus, the sample sizes n 1 , n pend on the base population N and the relative confidence interval as follows [21]: D is an auxiliary variable introduced for readability. There is no closed form for the CDF and the inverse CDF. Thus, an approximate D has to be obtained by interpreting Equa-tion 4 with numerical methods. One can calculate the sam-ple sizes by solving Equation 3 for n 1 and n 2 and inserting the value of D just calculated.
We now redefine the parameters of the algebraic frame-work for RFID scenarios and compare the requirements of our scenario to the characteristics of MR methods.
Let N be the number of items that actually are in the smart shelves. The first sample contains n 1 items obtained from the RFID reader. The second sample consists of n 2 products that have been sold in a certain time frame. Of all products sold, m 2 products have previously been read in the store. Checking if samples are of sufficient size requires a coarse estimate of the population N (cf. Equations 3 and 4). Since an underestimation results in sample sizes which are too small, one has to overestimate the base population to adhere to A and  X  . In our scenario the inventory list is a suitable estimation for N : It contains all items that have been placed in the store and are not sold yet. Because stolen or damaged goods are still part of the inventory, the number of items in the list is equal to or larger than N .
In the following we will list four requirements on stock es-timates which we have identified in cooperation with a large retailer. To find out which extensions to MR are needed, we compare these requirements to the characteristics of RFID data in retail (cf. Section 2).
 Confidence Intervals: A retailer requires different confi-dence intervals, e.g., the inventory needs to be more pre-cise for the year-end closing than for replenishment. This is problematic: First, classical MR methods depend on two true random samples, while RFID data usually has an un-known distribution (C1). Second, RFID readers produce data streams (C2), and a sample of RFID data consists of items read at different points in time. However, MR cannot specify at which time the estimation is valid.
 Commodity Flows: RFID technology in retail faces con-tinuous data streams (C2) and open base populations (C3). In contrast, existing MR methods depend on static item sets that do not change between the points of time when two samples are taken.
 Scalability: Since RFID-based applications in retail de-pend on huge amounts of data (C4), the time and space complexity of the estimation procedure matter. This is prob-lematic for MR. Given a certain accuracy, the sizes n 1 , n the samples depend linearly on the size of the base popula-tion N . Thus, an estimation of a huge set of items requires huge sample sizes as well.
 Robustness: RFID-enabled business processes must be ro-bust against attacks like theft by staff. For example, a thief might try to steal unread items, exploiting that the set of items identified cannot be predicted (C1). This is differ-ent from problems that have been investigated for MR, e.g., mortality. While thieves try to exploit weaknesses in the process, animals usually pass away randomly.
We now introduce TagMark, a reliable and scalable esti-mation technique for the number of items from RFID data. TagMark combines all readings in a certain period of time, the sliding window, to one sample: Once an RFID tag is read within the window, it will be marked as read inside the store.
 Assumptions. Our assumptions are motivated by the fact that samples obtained from retail scenarios may have an un-known bias. Because consumers can take away items in a systematic way, and the amount of items detected by the RFID reader depends on unpredictable physical character-istics [13], it cannot be guaranteed that samples are simple random samples. Accordingly, the correctness of the esti-mate provided by classical MR methods cannot be ensured. Input: Relative confidence interval ( A ,  X  ), readHistory , salesHistory , replenishHistory , inventory Output: Estimated size of the population  X  N // Determine window size w 1: for w = 1 to | readHistory | { 2: int n 1 = getCount(readHistory, w) 3: int n 2 = getCount(salesHistory, w) // Check if samples are large enough 4: if n 2  X  calculateSampleSize( n 1 , A ,  X  , | inventory | ) { 5: int m 2 = getCount(readHistory  X  salesHistory, w) 6: int  X  N = calculateEstimate( n 1 , n 2 , m 2 ) // Correct estimation if replenishment has occurred 7: for each r in getData(replenishHistory, w) 8:  X  N =  X  N + calculateCorrection(r, w) 9: break 10: } 11: } 12: return max(  X  N , n 1 ) However, we can ensure that TagMark provides correct es-timates if the following two assumptions hold: 1. All RFID tags have the same probability of being read 2. There is no correlation between  X  X lind spots X  of the Assumption 1 requires all RFID tags to have the same prob-ability of being read by the RFID device. Defect tags or tags which are intentionally placed on a blind spot are not part of the base population. Therefore the estimate of the present items does not contain such tags. In our retail scenario, all RFID tags are robust and have the same communication capabilities. Thus, the first assumption is realistic.
Assumption 2 requires the buying behavior of the con-sumer to be independent from all physical effects that influ-ence the tag identification. If the assumption does not hold, the proportion of read and unread tags in the first sample and the items from the point of sale in the second sample are not representative for the base population. The assumption is realistic, because each time a consumer removes an item from the shelf the reading field changes unpredictably, and consumers cannot know the blind spots of the reader. Data Structures. TagMark requires four data structures: Algorithm. Figure 1 shows an outline of the TagMark al-gorithm in pseudocode. At first, TagMark determines the size w of the sliding window. The samples depend on tag-identification rates and consumer buying behavior, and can-not be freely chosen or predicted in advance. Thus, Tag-Mark starts with the most recent data and the smallest pos-sible window size, and increases the sliding window (Line 1) until it approaches a size where the readHistory and the salesHistory contain sufficient items to fulfill the specified relative confidence interval (Line 4). getCount(list, w) re-turns the number of items in list which lie inside the window w . calculateSampleSize( n 1 , A,  X  , | inventory | ) uses Equa-tion 3 to calculate the required size of the second sample. Once the algorithm finds a window of sufficient size, Tag-Mark determines the samples and estimates the number of present items  X  N (Line 6). The function calculateEstimate( n n , m 2 ) uses Equation 1 to calculate the estimation. After that, TagMark checks if replenishment has occurred within the sliding window (Line 7). In this case, the algorithm corrects the estimation  X  N (Line 8). Function calculateCor-rection(r, w) is explained in Section 4.2. Finally, we do a plausibility check to ensure that we do not estimate fewer items than read in the first sample and return the estimation (Line 12).
The sliding window used in TagMark allows us to over-come the problem of varying tag-identification rates which might result in sample sizes that are too small to ensure the confidence interval required. TagMark combines read-ings from a certain period of time, the sliding window. It estimates the number of items present at the earliest point of time in the sliding window, i.e., the time when the oldest tag data in the window was read. This might be problem-atic with slow-selling products, e.g., items only sold once p er day. Depending on the tag-identification rate and the num-ber of items of this kind in a store, it may take several days to reach the required sample size at the point of sale. Slow-selling items also imply that TagMark predicts the number of items in stock from a long time ago. Although this is a problem, it does not limit the applicability of TagMark in most real-world scenarios. For example, a delay of a few days is acceptable for stocktaking, and slow-selling items o f-fer the least financial savings when optimizing replenishment processes. Another problem might arise if an item was read outside the sliding window, but sold within the window, e.g. if a consumer needs a long time from the shelf to the point of sale. To provide estimates valid for recent points of time, we do not consider such tags for the second sample.
In retail, the shelves are replenished irregularly when they go empty, and the point in time of the replenishment and the number of products replenished is recorded. Replenishment poses two problems: (1) It violates the requirement of classical MR methods that all items have the same probability of being part of both samples: The reader detects the replenished items im-mediately, but it requires some time until the replenished items arrive at the point of sale. Existing extensions for MR are limited to predictable changes at a small rate (cf. C3). (2) After replenishment the tag-identification rate might change. This means that the proportion of read and unread items changes while the sample at the point of sale remains unchanged, i.e., the samples will not be representative.
Thus, classical MR would have to gather new samples from scratch after replenishment. Because sampling at the point of sale takes some time, this results in periods of time where no estimation is available. TagMark avoids this by calculating a replenishment-correction value that is added to the estimated number of items, as follows: Let N , N  X  denote the population before and after the replenishment, and let R denote the number of items replenished. Recall that the sliding window contains items that have passed the point of sales recently. For a certain time interval after re-plenishment, the sliding window consists of two parts: The first one only contains items that are not part of the replen-ishment, in contrast to the second one. In the following,  X  is the length of the first part of the window divided by its en-tire length. For instance, immediately after replenishment,  X  = 1. In what follows, we derive  X  N corrected , our estimate of the number of items after replenishment while  X  &gt; 0. To do so, we compute two estimates  X  N ,  X  N  X  , one in the moment before and one exactly after replenishment happened using the base variant of TagMark in Figure 1, Lines 1-6. Specifi-cally, TagMark first estimates the population  X  N  X  N , then estimates  X  N  X   X  N + R . The next notion needed here is the one of the absolute error, c , defined as c = N  X   X   X  N  X  . An estimate of this error is as follows: Note that  X  N  X  is different from  X  N corrected : Namely, the es-timate of  X  N  X  assumes that the replenished items are ade-quately represented in both samples, but this is not the case. Instead, the window will contain a mix of samples taken be-fore and after replenishment. Each new sale removes an old sale from the end of the window and decreases the fraction  X  that represents the share of pre-replenishment data. Thus, we compute  X  N corrected as follows: TagMark corrects the estimation based on a previous one (cf. Equation 5). Thus, the correction has an impact on the relative confidence interval of the estimation. Equation 2 explains the relationship between the relative accuracy A and the probability 1  X   X  . Thus, it is sufficient to investigate the impact of the replenishment on either A or on  X  . In the following, we will focus on the relative accuracy A .
Lemma 4.1. If a replenishment occurs inside the sliding window, the estimation  X  N corrected has a relative confidence interval of A + AR N .

Proof. We base our proof on the accuracy A,  X  of clas-sical MR, as defined in Subsection 3.1. Immediately af-ter replenishment, the base population changes from N to N  X  = N + R . Since TagMark determines the absolute er-ror c from two estimations  X  N and  X  N  X  (cf. Equation 5), the correction affects our confidence bounds. In order to ob-tain the corrected relative accuracy A , we replace  X  N with  X  N corrected + R , and we replace N with N + R in Equation 2: 1  X   X   X  P  X  A &lt; Finally, we multiply with N + R N in order to obtain the new relative confidence interval: 1  X   X   X  P  X  A + AR
RFID scenarios cannot provide two true random samples (cf. Section 2). In this subsection we will show that it is sufficient for TagMark to have samples gathered indepen-dently . In addition, we will state why the samples in our retail scenario are independent.

Lemma 4.2. The estimation  X  N is correct if the items in the first and the second sample are gathered independently. Proof. Two events X and Y are independent, if: Sampling in MR is the result of two sequences of Bernoulli Trials [24]. Two events have to be considered: U is  X  X e-ing part of the first sample X , and V is  X  X eing part of the second sample X . As [24] shows, the conditional distribution f ( m 2 | n 1 , n 2 ) of m 2 , given n 1 and n 2 , is binomial, i.e.: where p is the probability for an item from the first sample to be part of the second sample. E [ ] denotes the expected value, and k is the expected value for the fraction of items from the base population that are part of the first sample (the numerator) divided by the fraction of marked items in the second sample (the denominator). [24] formally shows that MR provides a correct estimation  X  N iff k = 1, i.e., the frac-tion of marked items in the second sample is n 1 /N . In order to confirm Lemma 4.2, we now have to prove that indepen-dently gathered samples result in k = 1. Equations 9, 10 let us transform Equation 12 as follows: k = ( E [ P ( V | X  U )]  X  E [ P ( U )  X  P ( V | X  U )])  X  E [ P ( U )] We have shown that TagMark provides correct estimations even with non-random samples if the samples are gathered independently, i.e., if there is no correlation between the blind spots of the reader and the items bought (cf. Assump-tion 2). As discussed, this does not limit the applicability of TagMark: The blind spots change frequently and are the re-sult of physical processes that the consumer cannot observe. We will investigate this issue further in Section 5.
In classical MR, the required sample sizes depend on the size of the base population N . Let us consider sample size n : Equation 4 can be interpreted numerically to obtain an approximated D for a certain relative confidence interval, and Equation 3 can be solved for n 2 showing the dependence on the population size N : Large sample sizes are problematic for retail scenarios: Large base populations might result in huge efforts for sampling and computation. We will now show that the second sample size n 2 in TagMark converges to an upper bound that only depends on the tag-identification rate and on the relative confidence interval. This is important, as the second sample is obtained from the products sold. A large second sample might results in a large sliding window, i.e., an estimation valid at an old point in time.

Lemma 4.3. For a given relative confidence interval A,  X  and a tag-identification rate  X  , the sample size required con-verges to
Proof. In RFID scenarios, the value of n 1 is correlated with the size of N through the tag-identification rate  X  , i.e., n 1 =  X   X  N . Inserting n 1 =  X   X  N into Equation 14 results in: The proof is achieved by transforming Equation 16: n Note that if D  X   X  D  X  1, the limit will be an upper bound. Otherwise, the equation specifies an asymptotic limit.
In this section we conduct experiments to provide an intu-ition for the retail scenario and to show that TagMark per-forms well with real-world data in real-world settings. We confirm that the nature of RFID data prohibits straightfor-ward estimators, we study the impact of our assumptions, and we address scalability issues.

We have implemented TagMark as an extension of SQL in PC (Linux, 2.4GHz x64 CPU). For performance experiments we used the default MaxDB configuration. To obtain a real-world retail scenario, we equipped a shelf with an RFID Class 1 Gen2 [8] RFID tags. In a preliminary experiment, we found that our reader has the capacity to read at most 30 carefully placed tags. Thus, we decided to place 40 tags on our smart shelf in order to evaluate a challenging scenario where many items are located in the  X  X lind spots X . With this configuration, we measured 10 sequences of 40 consumer interactions each: We removed one item per minute from the shelf, marked it as sold in the inventory, and recorded the tags identified by the reader. The time corresponds to the number of items removed from the shelf, and the shelf is empty after 40 minutes. We then refilled the shelf and 3 http://epsfiles.intermec.com/eps files/eps spec/ IF5 spec web.pdf started a new sequence. In this way, we obtained 400 sets of RFID tags together with the number of tags read at the same time.

Note that our straightforward consumer model is sufficient to test the applicability of TagMark. Since TagMark scans the inventory and the items table for samples that meet the confidence bounds, buying and selling times in particu-lar do not influence the quality of the estimation. Further, 40 tags are adequate to investigate a retail scenario under realistic conditions. A large RFID installation consists of numerous RFID readers with multiple antennas to cover a large number of tagged products. However, having multiple readers increases the amount of data, but does not affect the proportion of read and unread items. Thus, a larger installation would provide larger samples and narrower con-fidence bounds, but would not lead to new insights. In addi-tion, many real-world queries address only a small number of products, e.g., with less than 40 items of any product group within a shelf, a query targeting at these products will only read a small number of tags as well.
 First we want to provide an intuition of the quality of RFID data, and we want to resolve any doubts that there is a straightforward method (e.g., linear regression) to estimate the number of items present with a given precision.
The gray area in Figure 2(a) is the range of tag-identifi-cation rates of all of our experiments. The graphs represent the tag-identification rates for three distinctive sequences of consumer interactions. In Experiments A and C we re-moved items from a shelf in a way similar to consumer be-havior, starting near the edge of the shelf. The difference between Experiments A and C is that the consumers bought the items in a slightly different order. In these experiments, the tag-identification rate is rather low when the shelf is full, around 50%, and increases as products are removed. In the last 13 minutes however, the tag-identification rate again decreased in Experiment C. This is because most products were located at  X  X lind spots X  by coincidence. Experiment B shows the tag-identification rate if an insider with access to the data stream of the reader removes only items which are not read. The tag-identification rate quickly reaches 100%, since only unread items are removed.

The experiments confirm what we had expected from lit-erature [10]: Small deviations in the removal sequence of the items can result in very different tag-identification rates. We conclude that there is no straightforward method to obtain the number of tags present with a given precision. Next we have a look at the quality of the estimation, leaving aside the replenishment process for the time being. We will show that TagMark meets the confidence bounds specified in a real installation with varying tag-identification rates and tags removed in different orders. Therefore, we use our 400 sets of RFID data as input values for TagMark. After each consumer interaction we estimate the number of products in the shelf with two different accuracies: The first estima-tion requires an accuracy of A = 0 . 25 with a probability of 1  X   X  = 0 . 95. According to Equations 3, 4, the minimal slid-ing window that meets this accuracy requirement contains 9 RFID tags. The second estimation uses the parameters 1  X   X  = 0 . 95 and A = 0 . 18, which requires a sliding window of 20 tags. TagMark estimates well as predicted if at least (d) A typical replenishment experiment 95% of all estimations have a relative accuracy of at least 18% and 25%, respectively.

Figure 2(b) presents one of our experiments in detail. The figure graphs the relative deviations of the number of RFID tags read from the actual number, as well as the relative deviation for estimated items. The dotted lines represent the relative confidence interval of 25%. The estimations are good if at least 95% of them fall within this interval. The x-axis show the experiment time (which corresponds to the number of items removed), the y-axis is the relative accu-racy. Since we estimate the number of items at the end of the sliding window, there are no estimations for the last 8 minutes. The figure already indicates that TagMark keeps the relative confidence interval envisioned: Even at the be-ginning, when the tag-identification rate is around 55%, Tag-Mark provides a correct estimation.
 We now study the statistical significance of our results. Figure 2(c) shows the cumulative distribution function for all of our experiments. We obtained the graph by sort-ing the relative deviations of all estimations of our exper-iments and summing them up. The x-axis of Figure 2(c) shows the relative accuracy, the y-axis denotes the frac-tion of all estimations. For example, the figure indicates that 50% of all estimations have a relative accuracy better than 5% with the first and better than 9% with the second sequence of estimations. The vertical dotted lines in Fig-ure 2(c) represent both of the specified relative accuracies A , and the horizontal dotted line represents the percentage of 1  X   X  = 95% of values that fulfill A . As our proofs have pre-dicted, TagMark fulfills the quality requirements: Both cu-mulative distribution functions for the relative confidence in-tervals ( A = 18% , 1  X   X  = 95%) and ( A = 25% , 1  X   X  = 95%) cross the 95%-probability before approaching the accuracy bounds allowed.
 We now want to check how well our estimation works in the presence of replenishment. As described in Section 4.2, when adding R items to a population of N items, TagMark has to increase the relative confidence interval by AR N . Thus, adding one item to an almost-full shelf would hardly impact the quality of the estimation, but refilling an empty shelf is the worst-case scenario for TagMark.

To evaluate a challenging scenario, we let TagMark esti-mate the number of items when the shelf is becoming empty and is replenished. More specifically, we start at a state when the shelf contains 20 items and replenish R = 40 items when the population size is N = 1. Again, we demand a rel-ative confidence interval of A = 0 . 25 with a probability of 1  X   X  = 0 . 95. Because we estimate the number of items at the end of the sliding window, the first estimation influenced by replenishment will occur when N = 9. The relative confi-dence interval will change from A = 0 . 25 to A + AR N = 1 . 36. Figure 2(d) shows a typical replenishment experiment. The figure graphs the number of tags present, detected and estimated over time. The box shows all estimations which are influenced by the refilling process, i.e., where the relative confidence interval is A + AR N . The dotted lines represent the bounds of the relative confidence interval of 25%, and the grey area represents the relative confidence of 136% during replenishment. As expected, the replenishment correction in TagMark guarantees the relative confidence bounds of 1 . 36.
Again, to present statistically significant results, we calcu -late the cumulative distribution function for all of our replen-ishment experiments. Figure 2(e) graphs the same relative confidence intervals as required for the last evaluations, i.e., ( A = 18% , 1  X   X  = 95%) and ( A = 25% , 1  X   X  = 95%). Due to replenishment, the accuracies are relaxed to A = 98% and A = 136%, respectively. The figure also shows that Tag-Mark keeps the confidence interval during replenishment. Note that the relaxed relative confidence interval during re-plenishment has little impact on the usability of TagMark. If replenishment occurs when the shelf is becoming empty, N will be small, and therefore the absolute error will also be small. On the other hand, if a nearly-full shelf is replenished, the relative confidence interval does not change significantly . The reliability of TagMark depends on the absence of a cor-relation between the blind spots of the RFID reader and the items that are removed from the shelf. With the sequence of consumer interactions studied next, we want to find out how loosing this assumption impacts the precision of the es-timation. Therefore, we assume an insider who has perfect knowledge of all read and unread tags. An insider might hope to go undetected by stealing products which cannot be identified when the RFID reader takes the samples.
We test this threat as follows: On a shelf with 40 items, an insider removes one unread item after each item bought by a consumer. We choose this setting to reflect detuning effects: Because detuning may change the blind spots every time an item is removed, an insider cannot steal several items at once, but has to re-identify the unread items after each theft. In total, 8 unread items were removed. We estimate the number of items with a window size of 9 items.
We expect TagMark to underestimate the number of items present because the samples from the point of sale will con-tain a smaller amount of unread items than supposed, since the attacker has removed them. On the other hand, he re-moves only the unread items. Thus, the tag-identification rates will improve with every item stolen, which will improve the estimation (cf. Experiment B in Figure 2(a)).
Figure 2(f) shows one typical example from our set of experiments. Again, the figure graphs the relative devia-tion of the items read and estimated. All other experiments yield similar results and are omitted to save space. We were pleased to see that TagMark kept the desired accuracy, even though it tends to underestimate. However, this heavily depends on physical characteristics of the installation and cannot be formally guaranteed. Thus, this kind of attack is a potential threat to the precision of TagMark.

However, perfect knowledge of unread items requires ac-cess to the raw RFID data, and due to detuning effects the attacker is forced to steal unread items one by one. Hence, the insider attack is a worst-case scenario. Thus, we have demonstrated that TagMark is robust at least against shoplifting at large scale, even though we cannot provide formal guarantees in the presence of a correlation between the items read and bought.
 To show that TagMark is applicable to real-world scenarios consisting of huge numbers of tagged products, we have to conduct performance experiments. Therefore we generated a number of tables like Tables 2 and 3 synthetically with different parameters. Parameters varied include the popu-lation size N , tag-identification rate  X  , accuracy A and  X  , percentage of items sold and the relation of read and unread items at the point of sale. To obtain statistically significa nt results, we ran 10 tests with a warm database cache. Note that TagMark is deterministic, i.e., for a warm database cache all performance experiments yield the same results.
TagMark is based on statistical calculations and on non-nested SQL counting/grouping operations. These database operations can be performed efficiently. Section 3 has shown that the number of samples which have to be processed by TagMark does not depend on the population size N . How-ever, our performance experiments require database table scans to determine samples from the base population in a preliminary step, so we expect a non-constant runtime per-formance.

Figure 3 shows the runtime over 10 experiments with the parameters 1  X   X  = 0 . 95 and A = 0 . 10 and a tag-identification rate  X  = 80% and n 2 = 0 . 6 N . The total size of the tables in these tests was 1.2GB. For each experiment, we varied the number of items in the database in 20 steps from 50,000 to 1,000,000 items. The figure shows that TagMark returns an estimation in less than 200ms on average even with 1,000,000 items. All other tests with different param-eter settings yield similar results. The experiments confirm that TagMark can be efficiently implemented on top of an RDBMS, and it supports very large databases of items.
To the best of our knowledge, TagMark is the first reli-able estimation method for RFID data for business appli-cations. While TagMark extends and adapts MR methods, other solutions based on MR extensions, parametric estima-tors, database research, characteristics of the RFID commu-nication protocol or data cleansing seem to be feasible as well, but we think that this is not the case.

Mark-Recapture Extensions: Many approaches to ex-tend the capabilities of classical MR methods have been pro-posed. However, they cannot be applied to RFID installa-tions. For example, Jolly-Seber Methods [17, 23] estimate open populations, but require estimations for all factors that bias the samples, e.g., shoplifting, consumer buying behavi or or the percentage of misplaced products. Jackknife [2] com-bines multiple samples to provide reliable estimations. But Jackknife depends on closed populations, and all samples have to be mutually independent. This cannot be guaran-teed in two consecutive RFID readings.

Parametric Estimators: This class of estimators uses historical data to calculate an estimate for activity param-eters. For example, Charikar et al. [3] predict the number of distinct values of an attribute in a database for query optimization. The estimation uses a set of random samples from the table according to a specified probability distribu-tion. [3] requires two assumptions which do not hold for RFID scenarios: Samples need to be random, and data has to follow a known probability distribution. This makes it difficult to apply this estimator to RFID scenarios. Other parametric estimators, e.g., [4, 15], face similar problems.
Statistical Databases: With statistical databases, each tuple is annotated with the probability that the tuple is part of the table. For example, a statistical database could store the probability for each product to be present in the shelf, and compute the sum of products with specified accuracy. A prominent example is the Trio project [1]. It proposes exten-sions of the relational model and SQL to support uncertainty of data and data lineage. The main problem of applying Trio and similar approaches [5, 6, 22] to RFID scenarios is to ob-tain the probabilities that annotate the tuples. In RFID scenarios in retail, the tag-identification rate is not known in advance and changes frequently with changing conditions. This invalidates the probabilities in the database.
RFID Communication Protocol: Vogt [25] estimates the amount of tags in the communication range of the RFID reader from the amount of collisions during communication, and uses this information to optimize the communication with the rest of the tags. However, [25] only estimates the number of tags that communicate with the reader. Thus, the approach cannot consider items in the blind spots of the RFID reader nor queries for specific product groups. This is a systematic problem that holds for other protocol-based estimators [19, 20] as well.

Data Cleansing: There are different kinds of algorithms to clean RFID data. E.g. [18, 26] incorporate fixed con-straints and statistical knowledge to compensate for missed RFID readings. Both methods return a quantification of all possible results, i.e. each result is associated with a differ-ent probability. This poses two problems in regard of our requirements: It is not possible to ensure confidence inter-vals, and integration into business applications is difficult , as current systems do not consider probabilities. Other data cleaning methods also fail to fulfill all requirements of a re-tailer, e.g. [16] requires all samples to be random.
RFID-based tagging to optimize commodity flows is im-portant in all industry segments. However, tag-identification rates below 100% are problematic when integrating RFID data into existing enterprise-backend systems. Physical in-terference and the demand for cheap and small RFID tags are reasons for poor tag-identification rates. Future techni-cal improvements will not solve this problem.

In this paper we presented TagMark, a method to esti-mate the number of items tagged with RFID using samples from different RFID readings. TagMark provides stochastic guarantees regarding the reliability of the estimation. It can cope with continuous data streams and with open popula-tions where replenishment processes take place while tak-ing samples. Furthermore, TagMark scales well and can be seamlessly integrated into existing enterprise-backend sys-tems. An analysis and extensive experiments with artificial data and an existing RFID installation confirm the applica-bility of our approach both in extreme settings and realistic scenarios.
