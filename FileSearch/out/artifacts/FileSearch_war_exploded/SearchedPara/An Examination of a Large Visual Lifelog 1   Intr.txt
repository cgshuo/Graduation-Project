 Lifelogging is the process of digitally capturing ones life experiences and the most popular form of this is to record a text description of some part of your day in a blog. Most blogging activities are text-only, though increasingly we are seeing bloggers include visual aspects such as deliberately taken digital photos or video clips. These are usually included to illustrate some aspect of the blog such as  X  Here is a picture of the place I visited  X  or  X  Here is a picture of my friend John  X . Such inclusion of delib-erately posed and deliberately taken photos/v ideos is distinct from passively taken photos/images which constantly record the wearer X  X  activities, visually. This is somewhat similar to a personal CCTV system, worn by the wearer, for the wearer X  X  own, exclusive use. We call this visual lifelogging. Despite its relative novelty, visual lifelogging is gaining much interest, due to projects such as the Microsoft SenseCam [1] and Reality Mining [2]. Such lifelog data can include text, visual information (video or photos), audio information, biometric data (heart rate, galvanic skin re-sponse, blood pressure, etc.), location data, co-presence information and more be-sides. This information can potentially allow users to revisit the events of their life. 
In this paper we examine a collection of photos gathered by the constant wearing of a visual lifelogging device (SenseCam [3]) for a period of more that one year. We explore the composition of these photos and compare how photos from visual lifelogs differ from conventional personal digital photo collections. The motivation for this work stems from fact that much research is ongoing into content analysis of digital photos, while in the absence of large-scale visual lifelogging efforts, there has been little research undertaken for similar analysis of visual lifelogs. Since the SenseCam captures around 3,000 photos during a typical day, the rapid rate at which enormous archives can be gathered means that the need for understanding the natures of the composition and automatic organization of these photo collections is compelling. 1.1 Visual Search and Retrieval of Photos There has been much research recently into the organization of personal photo ar-chives [4,5,6]. Some of this research aims to organize personal photos by exploiting the results of visual content analysis of the photos in order to extract some semantic meaning, with the goal of aiding the organization, search and retrieval of the photos. An example is facial analysis of photo content, to enumerate faces or to match faces across an individual X  X  entire photo archive [7]. In addition, photo retrieval research has exploited the context of photo capture, or in some cases both visual content and photo context [5] to aid organisation. Often content analysis of photos requires the development of sets of concept detector s (e.g. face, crowd, building) which are trained on a representative set of photos [8]. In this paper we compare and contrast passively-captured large-scale visual lifelog data with more traditional intentionally-captured personal photo collections. We do this in order to explore the nature of a visual lifelog and to aid our understanding of the contents and composition of such a collection. Consequently we hope this understanding will allow us to leverage and deploy existing knowledge and techniques from the management and content analysis of personal photos in order to aid in automatic organization of visual lifelogs. 1.2 Visual Lifelogging The device used in this research is a Microsoft SenseCam, which is a small wearable digital camera (worn around the neck) that is designed to take photos passively (with-out user intervention). Unlike a digital camera, the SenseCam has a fisheye lens, to maximize the field of view, and incorporates multiple sensors including; light sensors, a multi-axis accelerometer, a thermometer and a passive infra red sensor to detect the presence of a person. Used collectively these sensors can trigger the capture of a photo. If capture is not triggered by one of these sensors, by default the SenseCam will take a photo after 30 seconds. This means that a SenseCam will normally capture approximately 3,000 images per day, amounting to one million images per year. The potential benefits of using a SenseCam to generate a personal visual diary have been detailed by Hodges et al. [3] and include the maintenance of personal histories, secu-rity benefits, and healthcare benefits, both for healthcare professionals and patients. For this research a SenseCam was worn constantly over one year, amassing over a million images. The device was worn all day, from breakfast until sleep. Sample pho-tos are shown in Figure 1 to illustrate the nature of the visual lifelog data captured in this experiment. Typically in visual lifelo gging research, participants use a wearable camera only for short periods of time, to record single activities or significant events. Importantly and uniquely, our study is the first time that an individual has worn a SenseCam for such a prolonged period of time. The process of manually analysing all one million photos in the visual lifelog would be too time consuming, therefore one thousand photos were chosen at random for individual examination. The selected photos were examined for the presence of a range of concepts and compared to a conven tional digital photo collection of over ten thousand photos, captured using standard digital cameras. The analysis presented here does not focus on particulars of the capture device such as image size or lens quality, rather emphasis has been placed on visual content which has been captured passively compared to that captured intentionally by conventional digital camera. 2.1 General Observations on Visual Lifelog Data An observation of visual lifelog data captured using a wearable device such as a Sen-seCam, clearly illustrates the differences between such data and a conventionally gathered photo collection. First, there is the prominence of the wearer X  X  hands and arms (51% of examined images contained visible hands and/or arms, as in Fig 1b, c &amp; photo (people/objects are often in the pe riphery), whereas with a conventionally posed photo, there is normally an identifiable salient object typically focused in the center of the image. In addition, the author X  X  office/work environment amounted to 16% of photos (easily identified by the presence of a computer screen, see Fig 1d) while steering wheel photos (see Fig 1b) amounted to 15% of the total. Finally, it is important to note that as the lifelogging device was worn around the neck of the owner, and as a result, the photos noticeably appear to be captured from below eye level, often producing  X  X eadless X  shots of individuals and/or an unusual viewpoint. Since the user does not have to initiate capture we often see scenes where the user is actively using both hands and during conversations individuals are often captured mid-gesture adding to the conversational style and reinforcing the  X  X aturalness X  of the photos. This contrasts heavily from conventional photo capture where photos are often staged and individuals and objects  X  X rranged X  prior to capture. 2.2 Photo Quality Analysis The quality of a photo is important for both end-user viewing and for content analysis algorithms, and for the analysis of visual lifelogs this is no exception. Our assumption convey rich semantic meaning and will be of higher quality compared with the auto-matically captured photos from a wearable passive capture device which doesn X  X  pos-sess a flash or adjustable focus. Each of the randomly selected 1,000 photos were manually evaluated on a five-point scale which ranged from very low quality to excel-lent or  X  X hoto album X  quality. The results are summarized in Table 1. 
Very low and poor quality photos (40%) are likely to be of little use for people re-viewing the happenings of a day and therefore could be automatically removed from the collection prior to organizing the day, into, for example a sequence of distinct events [9] for presentation to the user. In addition, these photos are less likely to be of benefit to content analysis tools and their removal could save processing resources when analysing content. Typical very low and poor quality photos are likely to be dark or blurred 1 photos where the content of the photo is not obvious by casually examining the photo. Of the remaining 60% of photos, the good photos (22%) are ideal candidates for presentation to users or for content analysis (e.g. all photos in Figure 1) in that they are not blurred and visually excellent. The photo album quality photos are visually excellent, but also convey semantic meaning, just like a tradition-ally posed photo from a photo album and we estimate that almost seventy such photos would be captured in a typical day wearing a Sensecam 2 . Finally, the 35% of photos that are of reasonable quality will visually acceptable, and one could consider that they would also be suitable for content analysis. 2.3 Comparison to Digital Photo Collections In addition to understanding the quality of the visual lifelog photos, it is important to determine how similar lifelog photos are to personal photos. This is especially impor-tant if we plan to deploy existing semantic concept detection techniques to visual lifelogs. Table 2 presents findings from examining the 1,000 random lifelog photos and comparing these to 500 randomly chosen photos from the personal photo collec-tion of the author (2,869 photos) and an additional 500 photos randomly chosen from the photo collections of ten colleagues (10,523 photos). As can be seen, both conven-tional, photo collections are equivalent (with a small amount of variation), as expected. However, the visual lifelog photos are very different in nature to the con-ventional photo collections. There is only one similar concept between the lifelog and the conventional photo collections (photos co ntaining people). All other concepts are very different and clearly illustrate the differences between visual lifelogs and con-ventional photo collections. The typical con cept detectors that could be applied to personal photo collections such as buildin g detectors, cityscape and landscape detec-tors are less likely to be useful for visual lifelog data. Rather we are presented with a whole new set of concepts that are important for visual lifelogs. Concepts such as computer screens, conversations, vehicle s cenes and work scenarios are typical of common concepts found in visual lifelog collections, which if automatically identifi-able, can be used to help organise a large visual lifelog. 
Rows in bold are concepts that we know to be very specific to visual lifelogs and as expected, are virtually non-existent in more traditional photo co llections due to the fact that people would not often take conventional photos of work scenarios, driving scenarios or rear-views of people. Our findings suggest that the focus of semantic concept detectors for visual lifelog data will need to be tailored for the unique nature of visual life logs. In addition, the vast presence of almost redundant  X  X unk-content X  such as computer screens, steering wheels, gives scope for filtering and summarizing the lifelogs automatically. We have illustrated that the photos contained within a large-scale visual lifelog collec-tion are vastly different in visual content to conventional digital photos. It is important to note that the collection examined consists of continuously collected photos for a single user for a one year period, we have no reason to believe that this collection is not typical of what one would expect to find across many people X  X  lifelogs and we antici-pate that the major distinctions between traditional and lifelog photo collections high-lighted in this work will hold true. We are, however, currently working to collect large scale visual lifelogs from a range of users to confirm these initial findings. 
We have found that visual lifelog photos often don X  X  have salient objects, many photos are either low quality or redundant, and the types of scenes/objects captured differ greatly from conventional photo collections. These findings will affect the fo-cus of our future work in developing specific concept detectors appropriate to lifelogs (such as driving, eating, talking or working) and the results of this experiment will help us in the migration of pre-existing concept detection techniques from the domain of conventional photo collections to visual lifelogs. However, simply applying such concept detectors to visual lifelog data will not be sufficient to organize the enormous amounts of data involved. At Dublin City University we are researching new methods to help users organize these vast visual lifelog collections, to summarise and high-light, to filter, search and recommend from a content source that grows by up to 3,000 photos every day for a single user. Acknowledgements. We acknowledge and thank Microsoft for their support of our lifelogging research. This work was also supported by the Irish Research Council for Science Engineering and Technology and by Science Foundation Ireland under grant 03/IN.3/I361. 
