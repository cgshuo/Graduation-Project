 While the field of automated deception detection in English (and a handful of other European languages) is experiencing growth in Natural Language Processing (NLP) or Computational Linguistics (CL), it has received surprisingly little attention from NLP/CL researchers working with Asian 1 languages. In this editorial I articulate what may be the stumbling blocks in further development of deception detection research in Asian contexts and invite other researchers to continue this conversation.

My brief summary of the recent deception detection methodological advances focuses on the idea that it is possible to discriminate deceptive texts from truthful ones by identifying reliable markers in texts, traditionally called verbal cues or deception pre-dictors. Since the exact inventory, effectiveness, and reliability of the cues remain con-troversial, I turn to insights from interpersonal psychology and Computer-Mediated Communication (CMC).

Perceptions of what constitutes deception in and across Asian cultures are dis-cussed in the literature on cultural differences, sociolinguistics, psychology, philosophy, and anthropology, but the findings are hard to summarize in a short piece. Drawing on select English-language publications from diverse disciplines, I question the as-sumptions of universality of perceptions of deception and deceptive behaviors across cultures. Current deception research is predominantly driven by studies of Western individuals, culturally rooted in philosophies with a moral imperative of truth-telling. Moral judgements about deception and truth-telling might not be necessarily shared by Asian cultures. Ethical considerations in deciding to tell the truth or not might entail virtues of modesty and self-effacement, the need to save face, or the desire to avoid embarrassment and resolve conflicts without harmful truth-telling. It is unclear at this point whether the psychological findings that produced various sets of verbal deception predictors would still stand under different sets of moral justifications. I will return to this question after I provide a brief background for this discussion. Assum-ing the reader X  X  distant familiarity with the topic, I start with the introduction of the field of automated deception detection and its position in NLP/CL, stressing its novelty and importance. A specialized workshop  X  X n Computational Approaches to Deception Detection X  was first held in 2012 at the European Chapter of the Association for Computational Linguistics in Avignon, France. Automated deception detection was announced as  X  X  relatively new area of applied computational linguistics that has broad applica-tions in business fraud and online misrepresentation, as well as police and security work X  [EACL 2012]. The task has been acknowledged as extremely challenging for over 15 years [DePaulo et al. 1997] and has only recently been proven computationally feasible [Bachenko et al. 2008; Fuller et al. 2009; Hancock et al. 2008; Zhou et al. 2004]. In spite of deception detection X  X  historical roots in interpersonal psychology and communication, the field best connects to opinion mining, spam, and fraud de-tection within NLP/CL. Opinion mining (or sentiment analysis; see a recent overview in Liu [2012]) has previously absorbed other subjectivity-related work on modality and negation (e.g., Morante and Sporleder, [2012]), factuality (e.g., Sauri and Pustejovsky [2012]), attribution (e.g., Bergler et al. [2004]), and certainty analyses (e.g., Rubin [2007]). Opinion mining shifts emphasis in computational analyses from factual state-ments to expressed opinions. The nature and specifics of opinions are important for predictive analyses, for instance, which product features do consumers tend to dislike, collectively, and specifically why?
Deception detection offers the next logical step of verifying that opinions are truthful so that dishonest or fraudulent statements are filtered out. Novel deception detection tools are needed in predictive analyses, news filtering, and business intelligence. In personal CMC, information seekers and users can benefit from deception detection tools in situations that require credibility assessment or veracity evaluation. Text-based digital communication, social media, and mobile technologies are expanding globally, but very little is known about pragmatic use of language in the context of lie-or truth-telling across cultures and, specifically, within individual Asian societies. From the North American computer-mediated communication perspective, deception is typically defined as a message knowingly and intentionally intended to foster a false belief or conclusion [Buller and Burgoon 1996; Zhou et al. 2004]. It is a deliberate act that excludes honest errors (which are naturally unintentional) and self-deceptions (which are intrapersonal), yet may achieve both malevolent, antisocial, self-serving goals as well as benevolent, prosocial goals such as keeping others from harm, pre-venting hurt feelings, or genuinely meaning to do good for others (e.g., lies that conceal plans for a surprise party) [Rubin 2010; Walczyk et al. 2008]. The latter are often re-ferred to as  X  X hite lies X  which seem to be typically excluded from automated deception detection training corpora. Do definitions of deception differ across Western and Asian cultures? If so, to what extent? How do individual Asian cultures differ, if at all, in terms of perceiving what constitutes deception?
Several taxonomies of deception types exist ranging in number of categories from 2 to 46 (such as commission versus omission or falsification and concealment versus equivocation). Rubin and Chen [2012] provide further metaanalysis of deception and manipulation varieties by their salient features (e.g., intentionality to deceive, accu-racy of information, and social acceptability). Current automated techniques for de-ception detection deal exclusively with falsifications (i.e., lying or deceit). Are there circumstances under which specific Asian cultures would tend to value certain de-ception favorably, or at least tolerably? Do any socially acceptable pragmatic goals of communication conflict with the moral imperative of truth-telling (e.g., avoiding con-flict, saving one X  X  face, or producing an agreeable inaccurate answer)? Next, I will talk about how deception is detected in texts. Since deceiving others is believed to involve changes in emotional, psychological, or cognitive states, certain linguistic cues may indicate lying and can be detected using automated techniques [Hancock et al. 2004]. Systematic differences between truth-ful and deceptive messages have long been accounted for by the four-factor theory of deception widely accepted in North America [Zuckerman et al. 1981].  X  X elative to a truthful baseline, deception is characterized by greater arousal, increased emotionality (e.g., guilt, fear of detection), increased cognitive effort, and increased effort at behav-ioral control. Because message veracity affects these internal psychological states, and because each of these states is behaviorally  X  X eaked X , observable behavioral differences are expected X  [Ali and Levine 2008, page 83].

The automated deception detection task has been formulated as a binary text cat-egorization task: is a message deceptive or truthful? There is a substantial body of research that seeks to compile, test, and cluster predictive cues for deceptive messages (see a discussion of differing sets of predictors in Rubin and Conroy [2012]) but no con-sensus on one reliable set of verbal cues has been reached. Preexisting psycholinguistic lexicons (e.g., LWIC by Pennebaker and Francis [1999]) and statement validity anal-ysis techniques from law enforcement credibility assessments (as in Porter and Yuille [1996]) are often used to derive predictors. Standard binary classification algorithms applied to predictors achieve 70  X  74% accuracy rates (e.g., Fuller et al. [2009] and Mihalcea and Strapparava [2009]). These results are promising for the field since they supersede notoriously unreliable human abilities of a 54% mean accuracy [DePaulo et al. 1997]. Human judges achieve 50  X  63% success rates, depending on what is considered deceptive [Rubin and Conroy 2011], and extreme degrees of deception are more transparent to judges [Rubin and Vashchilko 2012]. An ongoing yearly symposium (e.g., Jensen et al. [2013]) debates new technologies and procedures for deception detection and credibility assessment in the context of law enforcement, intelligence work, and information security. Cross-cultural aspects are sometimes discussed (e.g., George and Gupta [2013] compare perceptions of deceptive Hindi and American English stimuli), but the research community from Asia is generally underrepresented. There is surprisingly little to say about NLP/CL efforts on deception detection in the context of the use of Asian languages. A few exceptions concentrate on Chinese CMC. Zhou and Sung [2008] focus on cue selection based on Chinese online group communication and find that deceivers tend to communicate less and show low com-plexity and high diversity in their messages as compared to truth-tellers. Hu et al. [2009] construct the first deceptive and nondeceptive Chinese corpora, use SVM, and reach precision and recall comparable to Western studies (78% and 72%, respectively). Acknowledging deception detection is in its initial stages for Chinese texts. Zhang et al. [2012] follow the traditional paradigm and improve on their feature selection method with 86% accuracy results. An analysis of the impressive jump in Zhang et al. X  X  [2012] success rates is in order, preferably by native speakers. Broader comparable research is needed in other Asian languages. In a recent editorial in Computational Linguistics , Krahmer [2010] suggests that we can learn a lot from psychologists (and vice versa). Similarly, I would argue that, for deception detection purposes, we can learn a lot from researchers working in the neigh-boring fields of social sciences and humanities. Anthropologists, psychologists, and so-ciolinguists can offer insights on differences and similarities among Western and Asian societies. Disassociated strands of literature deal with language pairs and effects on cross-cultural communication, whereas others focus on individual languages and their sociocultural milieu. Here are but a few examples of the much needed research in Asian context. Suzuki et al. [2006] review the use of psychophysiological detection of deception (polygraphy) in Japan where this technique and its results are generally accepted as valid, reliable, and admissible in Japanese courts. Research on verbal in-dicators appears to be neglected. Lewis and George [2008] rate American and Korean respondents on four cultural dimensions, namely, individualism/collectivism, power distance, uncertainty avoidance, and masculinity/femininity, and identify differences in deception between the two cultures. Yeh et al. [2013] compare deception beliefs and perceived detection cues in the Chinese and Japanese cultures, and find cross-cultural consistency in stereotypes across cultures and differences in gender stereotypes. Amer-ican, Jordanian, and Indian participants are able to detect deception across cultures that share a language and those that do not; they often show tendencies to judge for-eigners as more truthful than compatriots (contrary to the language-based ethnocen-trism idea) [Bond and Atoum 2000]. George and Gupta [2013] offer a few other suitable examples in their review of deception across cultures. I invite computational linguists and the broader interdisciplinary community to provide much needed expansion to this select literature overview. I will next turn to philosophy and cross-cultural psychology for a deeper appreciation of potential cultural norm differences. In philosophical traditions, lying is widely condemned and rarely permissible. Englehardt and Evans [1994] indicate philosophers have argued for centuries that lying is wrong.  X  X pictetus, the early Stoic, defended, above all, the principle  X  X ot to speak falsely X  ... Aristotle condemns falsehood as  X  X ad and reprehensible X  and explains that the truth is  X  X ine and praiseworthy X ... In more modern times, Emmanuel Kant took the prohi-bition against lying as his paradigm of a  X  X ategorical imperative X , the unconditional moral law. Nietzsche took honesty to be one of his four  X  X ardinal X  virtues, and the existentialist Jean-Paul Sartre insisted that deception is a vice, perhaps indeed the ultimate vice X  [Englehardt and Evans 1994; page 255].

Nevertheless, the virtues of truth-telling and honesty at all costs may not be uni-versal. The Confucian belief of sincerity mattered significantly more to Koreans than to Japanese students according to Tamai and Lee X  X  [2002] survey. Cross-cultural developmental psychology studies suggest that cultures may categorize untruthful statements differently depending on specific social contexts. Comparing Chinese and Canadian children X  X  and adults X  evaluations of lying and truth-telling, Fu et al. [2001] find that  X  X ie-and truth-telling have inconstant moral values: certain forms of lie-and truth-telling, though valued negatively in one culture, may be evaluated positively in another culture X  [Fu et al. 2001, page 726]. Lee et al. [1997] corroborate that  X  X n the realm of lying and truth-telling, a close relation between sociocultural practices and moral judgment exists X . For instance,  X  X he emphasis on modesty and self-effacement leads Chinese children to believe that lying for reason of modesty has positive moral value whereas truth-telling about good deeds is morally undesirable X  [Fu et al. 2001, page 721]. More research on beliefs, attitudes, and moral underpinning is needed, specifically with the goal of assessing the impact of culturally specific norms on de-ception detection methodologies and selection of deceptive cues.

What are the philosophical or religious roots and motivating factors truth-telling behaviors? Potential differences in socially acceptable moral norms mat-ter because morals and attitudes are often cited as explanations for verbal  X  X eak-age X  that creates observable cues to deception. For instance, in their Dutch study, Schelleman-Offermans and Merckelbach [2010] emphasize that liars typically do not want to take responsibility for their behavior, or they feel guilty or ashamed about lying and use relatively more negative emotion words and fewer self-references [Schelleman-Offermans and Merckelbach 2010; page 249]. Most deception detection mechanisms operate at the levels of lexico-semantic analysis in combination with machine learn-ing. At a pragmatic discourse level, automated methods have been attempted in very few studies thus far (see Bachenko et al. [2008], Rubin and Lukoianova [2014], and Rubin and Vashchilko [2012]). What does an alternative pragmatic use of language imply for successful deception detection? Do language-blind lexico-semantic machine learning approaches ignore cultural specificities of Asian languages? These questions remain to be answered. The Asian perspectives (such as Zhang et al. X  X  [2012] success) can inform and extend studies conducted with mostly Western participants. Several reasons may account for the lack of research interest in deception detection in Asian NLP/CL community 3 . First of all, it is possible there is more development in the area than what is visible in English-language publications. If true language barriers separate existing bodies of research and the task is extensively discussed in respec-tive Asian languages, I would encourage researchers to consider bringing their re-search to international computational linguistics venues. I would also humbly request keyword tagging or considering translations of titles and abstracts for the benefit of the researchers without Asian-language backgrounds.

Second, might there be a cultural clash or research ethics difficulty in studying de-ception? If it is culturally undesirable to speak of or identify deceivers, or the overall topic is shaded in negative terms for study participants, it might be avoided altogether. If it were the case, it would be most helpful to have an explicit record or discussion of the issues.

The third potential stumbling block was briefly discussed earlier. Is there a funda-mental lack of universal agreement as to what deception needs to be detected? Diffi-culties arise among dissimilar cultures and misunderstandings are liable to occur in digital environments. Sociocultural models and discussions of philosophical and psy-chological roots may invigorate the field. Practical implications of such theoretical work are in selecting and identifying appropriate reliable verbal indicators of unde-sirable deception varieties.

The last stumbling block might be the nature of the languages themselves. If the languages have high degrees of hedging, qualification, or mitigation (say, for politeness sake or out of respect to authority), deceptive verbal cues may be better masked and harder to interpret as compared to English. Pragmatic interpretation of the actual meaning will then be required 4 . This editorial provides an overview of automated deception detection in texts and raises several questions essential to performing the task of automated deception detec-tion in an Asian context. The scarcity of automated deception detection research in the Asian applied computational linguistics community is puzzling. I speculate about po-tential stumbling blocks, namely, research dissemination language barriers, cultural and ethical clashes, methodological challenges, and definitional and conceptual dif-ficulties arising from the context of Asian cultures. I encourage the computational linguistics and broader interdisciplinary research community to respond with appro-priate solutions and to engage in several profound aspects of this task, beyond the pure computational challenge. Sociolinguistic, cross-cultural, psychological, and philo-sophical differences across Asian languages require careful consideration and better international dissemination. More research on cultural norms, beliefs and attitudes can help justify selection of verbal markers of deception, appropriate for Asian socio-cultural norms. The overall significance of deception detection research is in its ability to inform development of automatic analytical methods that complement and enhance notoriously poor human abilities to discern deception from truth. Further assessment of the feasibility and development of automated deception detection is needed for various applications such as personal computer-mediated interaction, social media monitoring, information security, credibility assessment, and intelligence and law enforcement.
