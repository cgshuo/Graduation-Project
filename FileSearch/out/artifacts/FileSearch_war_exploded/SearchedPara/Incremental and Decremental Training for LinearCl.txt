 In classification, if a small number of instances is added or removed, incremental and decremental techniques can be applied to quickly update the model. However, the design of incremental and decremental algorithms involves many considerations. In this paper, we focus on linear classifiers including logistic regression and linear SVM because of their simplicity over kernel or other methods. By applying a warm start strategy, we investigate issues such as using primal or dual formulation, choosing optimization methods, and creat-ing practical implementations. Through theoretical analysis and practical experiments, we conclude that a warm start setting on a high-order optimization method for primal for-mulations is more suitable than others for incremental and decremental learning of linear classification.
 I.5.2 [ Pattern Recognition ]: Design Methodology X  Clas-sifier design and evaluation warm start; incremental learning; decremental learning; lin-ear classification
In supervised learning, when a small amount of data is added or removed, the classification model may not change much. Therefore, incremental and decremental algorithms are useful to update the model without re-training the prob-lem from scratch. However, the design of good incremental and decremental learning algorithms is never easy. First, they are often extended from a standard learning method, but the resulting procedure may become very complicated. Second, applying incremental and decremental algorithms is not guaranteed to be faster than re-training the data from scratch. Third, the scenarios to use incremental and decre-mental learning may significantly vary according to applica-tions, so designing software for general use is difficult.
In this paper, we study incremental and decremental algo-rithms for logistic regression (LR) and linear support vector machine (SVM). The decision to work on linear rather than kernel classifiers comes from a long journey of attempting to support incremental and decremental learning in our SVM software LIBSVM [4]. Although many users have requested this function and some studies have been conducted, we were hampered by two difficulties. First, extending the commonly used decomposition methods to flexibly enlarge or shrink the cached kernel elements during training is complicated. Note that adding or removing data causes a  X  X wo-dimensional X  change of rows and columns of the kernel matrix. Second, existing extensions of decomposition methods for incremen-tal or decremental learning may not effectively reduce the running time. Recently, in contrast to using kernels, linear classification has been shown to give comparable accuracy on some applications (see, e.g., a survey in [19]). The popu-larity of linear classification has motivated us to study incre-mental and decremental learning again. However, the goal becomes to support this functionality in another software LIBLINEAR [8] for large-scale linear classification.
We point out that the difficulties occurred in incremental and decremental learning for kernel classifiers may be al-leviated for linear classifiers because more optimization al-restrictive to design optimization algorithms because the model is represented by a linear combination of training in-stances. Therefore, the optimization problem must be de-contrast, as we will explain in Section 2, there are more op-tions in solving optimization problems for linear classifiers. We show that this difference between linear and kernel clas-sifiers strongly affects their extensions to incremental and decremental training.

In Section 3, we apply a warm start strategy for incre-mental and decremental training of linear classification. The optimal solution of training past data is modified as an ini-tial solution for solving the new problem after data addition or removal. We consider in Section 4 three representative optimization algorithms for linear classification. They differ in several aspects such as solving primal or dual formula-tion, and using first-order (i.e., gradient) or second-order information of the optimization problem. Our main find-ings are that the warm start setting is in general more ef-fective to improve the primal initial solution than the dual and that the warm start setting more effectively speeds up a high-order optimization method than a low-order one. Af-ter addressing some implementation issues, we have suc-cessfully finished an extension of the software LIBLINEAR for incremental and decremental learning. It is available at http://www.csie.ntu.edu.tw/~cjlin/papers/ws .

This paper is organized as follows. In Section 2, we show the formulations of SVM and LR, and discuss existing meth-ods for incremental and decremental learning. In Section 3, we propose a warm start setting, followed by analyzing the difference between using primal and dual forms. The comparison between high-order and low-order optimization methods is described in Section 4. In Section 5, we dis-cuss implementation issues for building a solid tool. Exper-iments are presented in Section 6. Section 7 concludes our work. Supplementary materials with additional results and programs for experiments are also available at the above-mentioned web site.
Assume we are given (label, feature-vector) pairs of train-fication involves the following optimization problem. min parameter. Common loss functions include (4) is used, then we have logistic regression. The three loss functions in (2)-(4) have different differentiability. L1 loss: not differentiable L2 loss: differentiable but not twice differentiable LR loss: twice differentiable Many convex optimization methods have been considered to find the optimal w . Alternatively, from optimization theory or the representer theorem [12], the optimal w is a linear combination of training instances with coefficients  X  . Then we can instead solve an optimization problem over  X  . A common way is to derive the dual problem of (1). max subject to 0  X   X  i  X  U,  X  i = 1 ,...,l, (6) where K ( i,j ) = y i y j x T i x j and Further, h (  X  i ,C ) = (  X  i for L1-loss and L2-loss SVM , We define 0 log 0 = 0, so for all three losses. Besides (6), the dual problem can also be represented by the following matrix form. where  X  Q = Q + D  X  R l  X  l , Q ij = K ( i,j ), and D is diagonal with D ii = d,  X  i . We refer to (1) as the primal problem.
We briefly discuss the difference between linear and kernel classifiers. A kernel classifier maps data to a high (maybe in-finite) dimensional space, so problem (1) cannot be directly solved. Instead, by kernel tricks we solve an optimization problem of  X  like (6). 1 In contrast, for linear classifiers, it is more flexible to design optimization algorithms because we can solve problems of w or  X  . We will show in Section 3 that this difference between linear and kernel classifiers has an impact on their incremental and decremental training.
Most existing studies on incremental or decremental train-ing focus on kernel rather than linear classifiers. By consid-ering the dual problem of kernel SVM, [3] and subsequent works [9, 11, 13, 16] investigate how to maintain the opti-mality condition when data are slightly changed. Note that at an optimum, all  X  i  X  (0 ,U ) correspond to the solution of a linear system. They propose methods to quickly identify these  X  i  X  X  for the new data and efficiently solve the linear system. A kernel sub-matrix is required to be enlarged or shrunk. Careful implementations are essential as we can see that [13] wrote  X  X ncremental SVM may not be so easy to implement. X  The only work known to us that solves the pri-mal problem is [14]. They propose a Newton method for both kernel and linear SVM. However, their method is not scalable because matrix inversions are needed.
We consider a warm start setting by adjusting the optimal solution before data change as the initial solution of the new optimization problem. Because optimization algorithms are iterative procedures, we hope that a good initial solution can reduce the number of iterations to save the training time. Let be the original training set, and w  X  and  X   X  be optimal so-lutions of the primal and the dual problems, respectively. For the primal problem with the variable w , the number of variables is independent of data change because w  X  X  size is the same as the number of features. Therefore, w  X  can be directly used such that is the new initial solution. In contrast, if a dual problem is used,  X   X  X  size is changed after data addition or removal. For incremental learning, we assume
Besides (6), other optimization problems over  X  may be considered; see, for example, [6]. are instances being added, and the following  X   X  is considered as the initial dual solution. sure the feasibility. Because it is unclear which value is the best, we simply consider the zero value. For decremental learning, we assume instances are removed, and consider the following feasible  X   X  as the initial dual solution.
We hope that an initial solution closer to the optimum helps to reduce the running time. Subsequently, we check the initial objective values of solving the primal and the dual problems. A finding is that the primal initial point is closer to the optimal point if the change of data is not significant.
The optimization problem after considering new data is The primal and dual initial values are, respectively, 1 2 and
X = 1 2 where (12) comes from (7), and the property of same primal and dual optimal values in training the original set. Then and dual problems, respectively.

We argue that the primal initial value is usually closer to the optimal objective value of the new problem than the dual. A scaled form of problem (1) is which minimizes the average loss with regularization. If the original and new data points follow a similar distribution, and the original optimal solution w  X  describes the average loss well, then the optimal w of (10) should be similar to w  X  . Therefore, (11) may be a good approximation of the new optimal objective value.

For the dual initial objective value, from (10)-(12), we suspect that it may be far away from the new optimal value because of lacking the following term
One may question the above conclusion on the superiority of the primal initial value by claiming that the regularization parameter C must be adjusted for a larger training set. That is, to keep the same amount of total training losses, the following optimization problem can be considered. where  X  I = l/ ( l + k ). The corresponding dual problem is max subject to 0  X   X  i  X  U,  X  i = 1 ,...,l + k. (14) For LR and L1-loss SVM, the upper bound U becomes We then consider the following initial solutions We must scale  X   X  because of the new upper bound in (15), but  X  w can still be used without modification. We have new optimal objective value  X  primal initial value (17) = 1 2 Further, dual initial value = X l + k  X  1 where details of deriving (18) are in Appendix. Because l ( l + 2 k ) 2( l + k ) 2 (18) tends to be too small. Thus, even if the parameter C has been adjusted, the dual initial solution may still be farther away from the optimum than the primal. In Section 6, we will conduct experiments to confirm our findings.
The optimization problem after data removal is The corresponding dual problem is max subject to 0  X   X  i  X  U,  X  i = k + 1 ,...,l. (21) Using the initial points defined in (9), the primal and dual initial objective values are, respectively, and
X = 1 Details are in Appendix. Similar to (10), we have and dual problems, respectively.

For decremental learning, we can also argue that the pri-mal initial objective value is usually closer than the dual to the optimal objective value of the new problem. By (1), (20), and the same explanation for incremental learning, if not many data are removed, the optimal w should not change significantly. In contrast, because of the term in (23), the dual initial objective value should be less close to the new optimal value.

Like incremental learning, we discuss the situation of ad-justing the parameter C to maintain a similar total training loss. The following optimization problem is considered. where  X  D = l/ ( l  X  k ). The dual problem is the same as (21) except that C becomes  X  D C , d becomes d/  X  D , and U =  X  D C for L1-loss SVM and LR. Like (16), the following initial solutions can be used. For initial objective values, we have new optimal objective value (24)  X  primal initial value = 1 and dual initial value = X l 1 2 = 1  X   X  where the details of (25) are in supplementary materials because of space limitation. If not many data are removed,  X  D  X  1 and the last two terms in (25) are close to zero. Then the difference between (24) and (25) is similar to that between (22) and (23) without changing C . Therefore, even if the regularization parameter has been adjusted, the dual initial solution tends to be farther away from the optimum than the primal. Figure 1: An illustration on how optimization meth-ods may affect the effectiveness of a warm start set-ting. The y -axis is log-scaled.  X  : initial solution  X  : optimum. The dashed horizontal line indicates the initial distance to the optimum.
The effectiveness of a warm start strategy may be strongly related to the optimization method. We use Figure 1 to optimum, then a high-order optimization method may be advantageous because of the fast final convergence; see Fig-ure 1(b). Therefore, higher-order methods such as quasi Newton or Newton may be preferred for incremental and decremental learning.

Interestingly, for linear classification, lower-order methods such as stochastic gradient (SG) or coordinate descent are more commonly used than high-order methods. The reason is that low-order methods can quickly return a useful model. On the contrary, a high-order method like Newton methods may take considerable time to finish the first few iterations for obtaining an approximate solution.

To investigate if high-order methods become useful for incremental and decremental learning, in the rest of this section, we briefly describe three methods that will be de-tailedly compared in Section 6. -Newton method to solve the primal problem. -Coordinate descent method to solve the primal problem. -Coordinate descent method to solve the dual problem. The Newton method uses second-order information, while the coordinate descent method considers only gradient (i.e., first order) information.
We consider the Newton method in LIBLINEAR to solve the primal problem (1). It is a trust region Newton ( TRON ) method developed in [15]. Because differentiability is re-quired, this method is not applicable to L1-loss SVM.
At current iterate w , TRON obtains an approximate New-ton step d within the trust region by solving the following sub-problem. where q ( d )  X  X  X  f ( w ) T d + 1 is an approximation of f ( w + d )  X  f ( w ) and  X  is the size of the trust region. Afterward by checking the ratio between real function value reduction f ( w + d )  X  f ( w ) and the es-timated reduction q ( d ), TRON decides if w should be up-dated and then adjusts the current trust region  X . The sub-problem (26) is solved by the conjugate gradient method, so matrix inversion is not needed. For LR, whose objective function is twice differentiable, [15] shows that TRON has quadratic convergence.
We consider the coordinate descent method in [5] to solve the primal problem (1). This method updates one compo-nent w i of w at a time. ement. The work [5] applies a Newton method to approx-imately solve the one-variable sub-problem in (27), which does not have a closed-form solution. Their approach, ap-plicable to L2-loss SVM and LR, requires only  X  i f ( w ) and  X  ii f ( w ) at each step. Therefore, this method is a low-order one in compared with TRON that needs the whole Hessian matrix. The linear convergence is established in [5]. We refer to this method as PCD .
For solving dual problem (6), we consider the coordinate descent methods in [10, 18] that update  X  i at a time by  X  i  X  min max  X  i + arg min between (28) and (27) is that in (28) we must ensure the new  X  is in [0 ,U ]. The one-variable problem in (28) has a closed-form solution for L1-loss and L2-loss SVM, but for LR, we need an optimization procedure to obtain an approximate descent method linearly converges.
Although warm start is a simple strategy, its implementa-tion may be complicated. Recall in Section 1 we mentioned that the need to maintain the kernel cache is the main obsta-cle for us to support incremental and decremental learning in the kernel SVM software LIBSVM . Now for linear classifica-tion, although the implementation is more straightforward, many issues still need to be addressed in this section.
We begin with checking if additional information must be maintained in the model after training. If the primal prob-previously obtained w must be stored for prediction. In contrast, the dual solution  X  is not maintained in a linear is because we can generate and store w by (5) for predic-tion. Therefore, to employ a dual solver for incremental and decremental learning,  X  must be additionally stored. Un-fortunately, maintaining  X  is a complicated task because of the following concerns on the correspondence between  X  and data instances. -If new instances are randomly inserted into the existing set, it is difficult to maintain the mapping between  X  and Table 1: Data statistics: Density is the average ratio of non-zero features per instance.
 instances. Similarly, for decremental learning, the indices of removed instances must be known, though in practice this information may not be available. -The task of multi-class classification is often decomposed to several binary classification problems, so a set of  X  vec-tors must be maintained. The storage cost can be high if both numbers of instances and classes are large. Fur-ther, if each binary problem involves a subset of data (e.g., the one-against-one approach for multi-class classifi-cation), the above-mentioned problem of mapping  X  and data occurs.
 Therefore, the implementation of dual solvers with warm start is more complicated than that of primal solvers.
Stopping conditions of optimization algorithms are an-other implementation issues because some relative condi-tions depend on the initial point. For example, the TRON implementation in LIBLINEAR employs the following condi-tion. where w 0 is the initial point, w k is the current iterate, is the user-specified stopping tolerance, and l + and l  X  numbers of positive and negative data, respectively. For standard linear classification, in general w 0 = 0 is used. However, with a warm start setting, the initial w 0 is better than 0 , so a smaller k X  f ( w 0 ) k 2 appears in the denomina-tor in (29). Then the stopping condition becomes too strict under the same . To address this problem, in our imple-mentation, k X  f ( w 0 ) k 2 in (29) is fixed to be k X  f ( 0 ) k
In this section, we experimentally compare primal and dual solvers with the warm start strategy. We consider data sets ijcnn , webspam , news20 , rcv1 , real-sim and yahoo-japan , where details are shown in Table 1. All sets except yahoo-japan are available at LIBSVM data set. 2 All the experiments are conducted on a 2.50 GHz computer with 16 GB of RAM.
To evaluate methods for incremental learning, we ran-domly divide each data set to r parts so that Therefore, the solution of training the r  X  1 parts is used r parts. We consider r = 5 , 50 and 500 to investigate the effectiveness of the warm start method under different levels of data changes. Note that a larger r means a smaller in-crease of the data. Our setting ensures that the enlarged set remains the same regardless of different r values. We need http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/ datasets/ this property so in figures for comparison only one curve is drawn for the approach without a warm start setting. For decremental learning, we use the following setting to ensure that the reduced set is the same regardless of r . We split 1 / 5 data to r parts and have 4/5 data + 1 part of 1/5 data as the original data and 4/5 data as the reduced set.
 Our evaluation is by the relative difference to the optimal function value: for primal-and dual-based algorithms, respectively. Note that optimal w  X  and  X   X  are not available, so we obtain their approximations by running a huge number of iterations of optimization methods.
In Sections 3.1 and 3.2, we discuss properties of primal and dual initial solutions. To confirm our analysis, Table 2 shows the relative difference between initial and optimal function values for incremental and decremental learning. We check two values of the regularization parameter: C = 1 and C = 128. Because of space limitation, we consider only logistic regression, although results for l2-loss SVM (in Tables III and IV of supplementary materials) are similar. As a comparison, we include results without the warm start setting by using w = 0 and  X  = 0 as initial points for primal-and dual-based methods, respectively. Note that f ( 0 ) = 0, so In contrast, primal f ( 0 ) is larger. For example, for logistic loss, f ( 0 ) = Cl log(2) . Therefore, without a warm start set-ting, the primal initial point is far away from the optimal solution. This situation can be clearly seen in Table 2.
We further make the following observations. First, from results of each row of Table 2, the warm start setting signif-icantly reduces the distance from the primal initial solution to the optimum. In contrast, the improvement on the dual initial solution is only modest.

Second, with the warm start setting, if C = 1, the distance of the primal initial solution to the optimum is smaller than that of the dual. In particular, for data with a small number close to the optimum. This result confirms the calculation in Sections 3.1 and 3.2. However, the difference becomes smaller for some sparse data (e.g., news20 ). An explanation is that because of more features, more instances are needed to have a stable optimal w .

Third, if a larger C = 128 is used, the superiority of the primal initial solution becomes less clear. For sparse data, it is sometimes worse than the dual initial solution under the incremental learning scenario. This result is reasonable because a large C causes a better fitting of the original data. Then the solution w is sensitive to the increase of data. However, we notice that for these data sets, a large C is often not needed. Interestingly, for decremental learning
We did not consider L1-loss SVM here because our primal-based optimization methods require the differentiability of the objective function. sparse data. The reason might be that the remained data have been used in training the original set. In contrast, for incremental learning, some unseen instances are added to form the new training set.

Finally, we observe that under a larger r both primal and dual initial solutions are closer to the optimum. This result follows from our setting that a larger r implies a smaller the initial solution  X  w or  X   X  is almost good enough to be a model for the modified problem. For example, even under r = 5, if C = 1 and the primal-based algorithm TRON is used for incremental learning, the default stopping condition of LIBLINEAR is reached within two Newton iterations for all data sets except webspam .
In Figures 2 and 3, we compare the three optimization methods discussed in Section 4. Each sub-figure shows the relationship between the training time and the relative dif-ference to the optimal function value; see (30). Because of space limitation, we present results of only logistic regres-sion and leave the results of L2-loss SVM in supplementary materials. We can make the following observations.
First, the warm start strategy is useful regardless of op-timization methods. If data are not significantly changed (i.e., larger r ), the improvement is dramatic.

If without applying warm start, DCD is the fastest among the three optimization methods. This situation has been know from earlier works such as [10]. However, with warm start settings TRON becomes competitive. Generally TRON benefits more from warm start than DCD . For example, in the warm start strategy reduces the DCD  X  X  training time from 4.5 to 3 seconds, while TRON  X  X  training time from 40 to around 10 seconds. This result confirms our conjecture in Figure 1 that warm start strategies are more helpful for high-order optimization methods.

Although the warm start setting significantly improves the training speed of TRON for solving the primal problem, from Figures 2 and 3, DCD is still faster in general. Past works (e.g., [10]) have shown that DCD may become inferior to TRON if C is larger or feature values are in a large numerical range. In Figures I and II of supplementary materials, we present results of using C = 128. For data such as ijcnn , webspam , rcv1 and real-sim , we can clearly see that TRON is generally faster than DCD .

The two primal-based methods ( PCD and TRON ) share the same initial point. PCD quickly decreases the function value, but becomes slow in the end. In contrast, TRON is overall superior because of fast final convergence.
This research has lead to an extension of LIBLINEAR for incremental and decremental learning. Currently we choose TRON as the underlying solver because of the following re-sults obtained in this research work. -The warm start setting generally gives a better primal initial solution than the dual (Section 3). -The warm start setting more effectively speeds up a high-order optimization method such as TRON (Section 4). -For implementation, a primal-based method is more straight-forward than a dual-based method (Section 5). With the release of the software, we hope feedbacks from real applications can lead us to refine the methods for incre-mental and decremental learning. This work was supported in part by the National Science Council of Taiwan via the grant 101-2221-E-002-199-MY3. The authors thank Chia-Hua Ho for fruitful discussion. [1] B. E. Boser, I. Guyon, and V. Vapnik. A training [2] L. Bottou and C.-J. Lin. Support vector machine [3] G. Cauwenberghs and T. Poggio. Incremental and [4] C.-C. Chang and C.-J. Lin. LIBSVM: A library for [5] K.-W. Chang, C.-J. Hsieh, and C.-J. Lin. Coordinate [6] O. Chapelle. Training a support vector machine in the [7] C. Cortes and V. Vapnik. Support-vector network. [8] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, [9] S. Fine and K. Scheinberg. Incremental learning and [10] C.-J. Hsieh, K.-W. Chang, C.-J. Lin, S. S. Keerthi, [11] M. Karasuyama and I. Takeuchi. Multiple incremental [12] G. S. Kimeldorf and G. Wahba. A correspondence [13] P. Laskov, C. Gehl, S. Kr  X  uger, and K.-R. M  X  uller. [14] Z. Liang and Y. Li. Incremental support vector [15] C.-J. Lin, R. C. Weng, and S. S. Keerthi. Trust region [16] A. Shilton, M. Palaniswami, D. Ralph, and A. C. [17] P.-W. Wang and C.-J. Lin. Iteration complexity of [18] H.-F. Yu, F.-L. Huang, and C.-J. Lin. Dual coordinate [19] G.-X. Yuan, C.-H. Ho, and C.-J. Lin. Recent advances To begin, we show that for any constant  X  &gt; 0, For L1 and L2 losses, h (  X ,C ) =  X  , so (31) obviously holds. For LR loss, h ( X   X ,  X  C ) = X  C log  X  C  X   X   X  log  X   X   X  ( X  C  X   X   X  ) log( X  C  X   X   X  ) = X  C (log  X  + log C )  X   X   X  (log  X  + log  X  ) = X ( C log C  X   X  log  X   X  ( C  X   X  ) log( C  X   X  )) =  X  h (  X ,C ) . With  X  I = l/ ( l + k ) defined in Section 3.1, we have 1 2 = 1 2 .
 Finally, we derive (18) in detail. dual initial value = X l + k  X  1 = X  I 1 + 1 The second equality is from (31) and  X   X  l +1 =  X  X  X  =  X   X  The third equality is from (7) and (12). The fourth equality is from (32). The last equality uses the property w  X  T w  X   X  T Q  X   X  of optimal solutions.
 To begin, we show that holds for L1, L2 and LR losses. For L1-loss SVM,  X  by the following optimality condition (e.g., Eq. (17) in [2]). For L2-loss SVM,  X  The last equality is from the optimality condition For LR, consider the following optimality condition in Section 3.4 of [18]. Then we have (33) by
C log C  X   X   X  i log  X   X  i  X  ( C  X   X   X  i ) log( C  X   X   X  i )  X  y = C log C Denote the optimal value of the original problem as V  X  .
V Next, we denote the initial value of the decremented problem as V init and extract the term V init from V  X  to have V  X  1 + 1 The second equality uses (5) and the last equality is from (33). By the definitions of  X  w and V  X  , and (12), = 1 rcv1 rcv1
