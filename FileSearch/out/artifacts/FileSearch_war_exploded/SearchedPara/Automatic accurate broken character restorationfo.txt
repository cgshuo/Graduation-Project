 ORIGINAL PAPER B  X  en  X  edicte Allier  X  Nadia Bali  X  Hubert Emptoz Abstract In this article, we are interested in the restoration of character shapes in antique document images. This partic-ular class of documents generally present a lot of involuntary historical information that have to be taken into account to get quality digital libraries. Actually, many document pro-cessing methods of all sorts have already been proposed to cope with degraded character images, but those techniques often consist in replacing the degraded shapes by a corre-sponding prototype which is not satisfying for lots of spe-cialists. For that, we decided to develop our own method for accurate character restoration, basing our study on generic image processing tools (namely: Gabor filtering and the ac-tive contours model) completed with some specific automat-ically extracted structural information. The principle of our method is to make an active contour recover the lost infor-mation using an external energy term based on the use of an automatically built and selected reference character im-age. Results are presented for real case examples taken from printed and handwritten documents.
 Keywords Symbol recognition  X  Machine print  X  Document image processing  X  Digital libraries 1 Introduction Thanks to the development of digital technologies for mass media, the number of digital libraries projects all over the world grows up year after year. New on-line services are proposed everywhere to share knowledge with everyone in a kind of  X  X econd Gutenberg revolution X  [ 1 ]. Actually, these kinds of services are particularly interesting in the case of antique documents since they enable the access and the spreading of rare manuscripts usually hardly available for consultation.
 needs the application of a lot of treatments on each page of the library which will be then first indexable, then testable, and finally navigable [ 2 ]. There are two kinds of techniques to achieve such results (cf. Fig. 1 ). The first one consists in extracting the full text from the images of the pages using an OCR process and then in analysing the extracted ASCII code to get the editable version of the logical elements compos-ing the document [ 3 ]. The second one directly works on the image at a pixel level. It first consists in localising the infor-mation (physical segmentation) then in identifying it (logical labelling). The OCR system is further applied to each logical element to get the final digital document.
 belling are made at a pixel level, using particular document image techniques that are often very sensitive to a lot of pa-rameters such as the amount of noise in the digitised images. Moreover, OCR systems are hardly applicable to a lot of an-tique document images as they are generally composed of numerous very particular characters (cf. Fig. 2 ). For these reasons, the problem of degraded character restoration is a commonly addressed subject in the literature.
 document images. Some are quite general, using image pro-cessing techniques such as morphological or median filter-ing to eliminate local degradations [ 4 , 5 ]orarebasedon shape redundancy to build ideal characters that will replace the degraded ones in the original document so as to improve OCR recognition rates [ 6 , 7 ]. Further methods are particu-larly addressed to the problem of broken characters in doc-ument images: This is the case of the techniques proposed in [8 X 11], most of which work on binary images, where the aim is to extend the boundaries of the character using masks, morphological operators, region-growing, etc. (e.g. Fig. 3 ). In those methods, the accuracy of the restoration process is function of the size of the degradation and of the size of the structuring element. The latter methods are based on the use of degradation models [ 12 , 13 ] (for which a state of the art is proposed in [ 14 ]): They are not directly our purpose here, but these processes are interesting since they enable the cre-ation of degraded character databases that should be used to validate any technique.
 restoration aim at improving the recognition rates of OCR systems. In principle, they work locally in the neighbour-hood of a current pixel and are then powerful in only a few cases where degradations are relatively  X  X mall X  (e.g. the size of the structuring element or of the neighbourhood). about the accuracy of the rebuilding, which is indeed fun-damental in antique document images: By analogy with an-tique furniture, one could not imagine restoring the leg of a Louis XV style armchair by replacing it with any woodcut only because it is convenient. Printing has evolved slowly since its invention in the early fifteenth century. Contrary to the general thought, Gutenberg is not the one who invented it but he had the genius to bring together many new tech-niques. It finally involves a lot of specialists like engravers, founders, etc. Many methods have since been proposed all over the years to automate this task and produce more and more regular character shapes. As a matter of fact, the ma-terials used for the production of the raised letters, the ink, the mechanization of certain phases in the global process, the design of the letters (as presented in Fig. 4 ;[ 15 ]) induce significant marks on printed documents of all time. A care-ful study of these details by books specialists enables the drawing of the social, cultural, political, economical history of one (or more) country. As Y. Sordet says:  X  X he (economi-cal, social, political, ideal) history is always behind the book, explains it and is explained by it X .
 est details printed characters may present. The purpose of our study is then to go one step ahead of all the methods proposed so far offering a new  X  X istorical X  character restora-tion method aimed at preserving the original shape of the observed characters, i.e. we want to restore the very origi-nal details coming from the history of the printing technique that are considered as  X  X nvoluntary X  printing details. This cannot be done using any method but it requires powerful and reusable tools capable of extrapolating the information as precisely as possible: This is done using active contours (and their topological properties).
 diagram of Fig. 5 . It consists in restoring a given character image using an active contour algorithm that works on data coming simultaneously from the degraded initial image and from an automatically chosen reference image. The refer-ence character image is chosen among a set of automatically built reference characters using a matching process based on a bank of Gabor filters. The set of reference characters is obtained using consecutively a non-supervised classification method and a prototyping algorithm on each class. More de-tails will be given in the following sections.
 needs the page to be segmented into characters: This is done using the classical RLSA method combined to projections. tion, we will introduce the image-processing tools used to rebuild characters justifying our choice. Section 4 will be dedicated to the restoration method. The paper ends with a discussion on the results obtained at this stage and with propositions for future work. 2 Tools for the degraded character restoration method As said before, the proposed degraded character restoration method consists in finding the  X  X nvoluntary X  data lost dur-ing the acquisition phase. This has to be done using very powerful tools that will help us extrapolate the remaining information in as accurate a way as possible. The topologi-cal properties of the active contour model will then be used to extend the broken edges (especially in the case of huge degradations where the classical methods, evocated before, fail).
 from a reference image that has to be chosen as the most ap-propriate among a set of potential character shapes. This ob-viously needs the extraction and comparison of relevant fea-tures in each character image. The process has to be precise enough to avoid confusions between font types and it also has to be permissive enough to match degraded and sound characters. This is done using the well-known Gabor filters as they work on a global signal level more than at a pixel level. 2.1 Active contours The activecontours model is a widely used tool in artificial vision since its introduction in 1988 by Kass et al. [ 16 ]. It is used to solve a lot of problems in natural image processing such as object segmentation, video tracking, 3D reconstruc-tion, etc. In practice active contours, also called  X  X nakes X , are continuous curves (closed or not) initiated in the image containing data to detect (e.g. the boundaries of an object). Their evolution from time to time is controlled by an itera-tive energy functional minimization process so that the final contour (i.e. the one with minimal energy) corresponds to the data. The energies are analysable in terms of physical forces applied to the contour. 2.1.1 Classical model From a mathematical point of view, an active contour is a curve C function of the time t and the curvilinear abscissa s , such as:
C ={ v( s , t ) = ( x ( s , t ) ; y ( s , t ))/ s  X  X  a ; b the number of iterations.
 kinds of energies corresponding to three types of constraints on the curve: Intrinsic to the curve ( E int ), coming from the image ( E image ), or exclusively user-defined ( E ext ), leading to the following energy to minimize: trols the physical aspect of the snake. It is usually composed of two terms, function of the first derivative and of the sec-ond derivative of the curve, acting respectively on its length ( smoothing term in Eq. (3)) and curvature ( rigidity term in Eq. (3)). Their contribution in the global internal energy term is controlled by two real positive weighting parameters and  X  ,sothat: age. It ensures the convergence of the active contour, attract-ing it towards the desired data. Usually, these are the ob-ject boundaries defined as the regions with maximal gradient (the curve can also be attracted by light zones, terminations points, etc. [ 16 ]). In that way: where  X  I is the gradient operator applied to the image I and  X  is a real positive constant.
 contours classical formulation: E =  X  Nevertheless, we need it to make the active contours model work on the particular case of character images as seen later.
 potential energy in the classical formulation proposed in (5). This task is done using a gradient descent method over the Euler X  X agrange formulation (see [ 17 ] for de-tails). In spite of a lot of advantages, the active contours model yields a few problems like the sensitivity to initi-ation, and difficulties progressing into concave boundary regions.
 in the literature to overcome them, such as: Pre-smoothing [ 16 ] where the gradient effect is extended by thickening the edges of the image, the introduction of distance potential forces [ 18 ], balloon forces [ 19 ] to make the snake move along its normal, gradient vector flow (GVF) fields [ 20 ]that are particularly efficient as they preserve the gradient prop-erties near the edges and spread them in the homogeneous regions of the image. All these improvements lead to a pow-erful interactive tool allowing us to test it in the particular case of character images.
 tation of a wide variety of images without apriori knowl-edge on the geometry of the objects. To simplify, we could say that an active contour only has to be initiated and that it is then autonomous in finding the minimal energy state. This property is particularly interesting in our study even if we have to use some special formulations to cope with con-cavities that are frequent in character shapes (the classical formulation is not efficient in this case as the snake remains out of the concavity X  X f. Fig. 6 ).
 taken into account and what seems to be an important draw-back of the method is turned to account here. 2.1.2 Adaptation to character images As we said before, as concavities are frequently present in character images, the classical formulation (5) has to be adapted to that kind of shapes. For that, we have decided [ 17 ] to use a particular energy functional based on the GVF field proposed in [ 20 ]. The main idea of this energy func-tional is to use the classical gradient information near the boundaries and to diffuse it into the homogeneous regions around: F image I ,and  X  is a regularization parameter (set according to the amount of noise in the image) empirically fixed to 0.2. This formulation creates a vector flow g ( g x ; g y towards the concavities (i.e. attracting the active contour into the concave regions) as shown in Fig. 7 .
 in Fig. 8 (for 150 iterations). It represents the gradient image with the evolution of the contour (Fig. 8 a) and the final result superimposed to the original grey-level image (Fig. 8 b). 2.2 Gabor filters The second tool used in this paper is multi-channel filter-ing as we have already proved that it could be of particular interest for the characterization of font types at a character level [ 21 ]. In our approach, the typographical zones com-posing the entire document image were considered as being juxtapositions of small textured regions at a character level, basing our theory on the fact that characters  X  X  X  and  X  X  X  or  X  X  X  and  X  a  X , obviously cannot show the same orientations nor the same apparent frequencies (e.g. italics are strongly inclined whereas classical font types are straight). fined by a sinusoid plane wave modulated by a Gaussian en-velope oriented with angle  X  from the x -axis. In the spatial domain, for a fundamental frequency u 0 along the x -axis (i.e.  X  = 0  X  ), we get: where  X  x and  X  y are the Gaussian standard deviations along the x -andthe y -axis. Filters with orientation  X  (  X  = 0 obtained by rotating the latter equation, i.e. using: tation is clearer in the frequency domain where the signal is represented by two Gaussians along the x -axis, at a dis-tance + u 0 from the origin, as shown on Fig. 9 . Applying the Fourier transform to Eq. (7) yields: H ( u ,v) = TF ( h ( x , y )) 30  X  30 window, in the spatial and in the frequency domains for ( u 0 = 0 . 125;  X  = 0  X  )(Fig. 9 a) and for ( u 0 = 0  X  = 45  X  )(Fig. 9 b).
 uniformly cover the spatial-frequency domain, and since there is little overlapping between filters, they form a nearly orthogonal basis resulting in a powerful texture characteriza-tion tool [ 22 ]. An example of Gabor filter bank is proposed in Fig. 10 where we consider 24 filters (six frequency ranges and four orientations), the origin ( u ; v) = ( 0 ; 0 ) is taken at the centre of the image.
 12 Gabor filters defined in a 128  X  128 window with two radial frequencies ( u 0 = 0 . 05, 0.1) and six values of orien-tation  X  (  X  = 0,  X  /6,  X  /3,  X  /2, 2  X  /3, 5  X  /6) to characterize font types, styles and sizes. This configuration has been cho-sen because it corresponds well with the orientations classi-cally met in document images: Italics are generally closer to  X  /3 or  X  /6 skew angles than to  X  /4.
 the literature to recognize font styles in document images; among them: Zramdini [ 23 ] proposes an optical font recog-nition (OFR) system based on the study of digital typogra-phy; Chaudhuri and Garain [ 24 ] detect italics and bold at a character level, analyzing character widths in a few given directions; Wong et al. [ 25 ] use geometrical and statistical properties of text blocks at different levels (e.g. total amount of black pixels composing the block, block height, eccen-tricity, etc.); Duffy [ 26 ] uses shape redundancies to group to-gether characters written in a same font, based on the calcu-lation of symmetrical differences and Doermann et al. [ 27 ], presenting a more global method at a word level, use mor-phological mathematics for bold detection, and the orienta-tion of surrounding blocks for italics.
 ment images at a pixel level, thus suffering from every kind of noise images may be present. To avoid this, we decided to pay attention to more global methods classically used in natural images processing, considering machine-printed text images as textured images. Gabor filtering is a good method to analyse texture since it has been designed to simulate the human visual system, and it may be worth testing at a char-acter level as this has never been done so far (Gabor filters have only been used in a few very particular document im-age applications [28 X 31]). 2.3 Discussion As we have said before, our aim is the accurate reconstruc-tion of broken characters in antique document images. To achieve it, we have decided to develop our own method based on the use of active contours and structural informa-tion extracted using Gabor filters. The preceding tools are particularly interesting as they come from the field of im-age processing (instead of classical document image pro-cessing). As a matter of fact, they provide powerful and ro-bust solutions to our restoration problem as we will see in the next section. 3 Character restoration method Our restoration method works at a character level, that is, we must have a set of already segmented document images at this level. Each character is then considered as embedded in a 128  X  128 image (to enable the application of the Gabor filters). 3.1 Principle The global principle of our method is proposed in Fig. 5 .The restoration process takes two inputs: An automatically built set of reference character images and a character identified as degraded. Then, we find the reference character image that best matches the broken one which will be used in the restoration process based on the active contours model. and the active contours model whose topological properties are exploited to extend the broken frontiers. 3.2 Character restoration process The active contour model can be used for segmentation in non-degraded character images using a gradient-based information. The classical formulation using the GVF field is not usable as it is on broken characters as the boundary information is missing in the degraded areas (cf. Fig. 11 ). The classical active contours formulation (5) would produce a particular vector field attracting the curve into the degra-dations as if they were concavities of the character shape. knowledge in the active contour model to compensate the divergent vector field in the degraded area in order to recover the character width there. This can be done using a localized external energy to compensate the GVF field: Our proposi-tion is to complete the basic energy formulation in (5) using a new localized GVF attraction field F GVF ref brought via an external reference image I ref ,suchas: with E image I ref ,and  X  ref is the regularization parameter. This for-mulation creates the reference vector flow g ( g ref x ; g culated once and for all.
 the next subsection) and its contribution in the global energy formulation is weighed by the introduction of a real positive constant. The active contour process can then be launched. Fig. 12 , where we have presented a degraded character im-age (Fig. 12 a) and its associate reference image (Fig. 12 b), voluntarily manually chosen different, to clearly show its contribution in the convergence process (Fig. 12 c). The original degraded and the localized reference gradient vector flows are respectively shown in Fig. 12 e and f. The result obtained after a 150-iteration segmentation process is presented in Fig. 12 d, where the degraded zone has been automatically localized with the red crosses and the range of the field is represented by the blue rectangle.This image shows that the active contour is attracted by the original character in the non-degraded zones and by the reference image in the broken area. This process ensures an accurate and continuous reconstructed contour. The case of multiple boundaries in character images will be discussed in the later sections.
 done manually, like the choice of the reference images in function of its similarity to the original character shape. This task has to be automated in reality; this is what we explain now. 3.3 Matching process Matching is a fastidious task since we have to match broken character images to reference images that are non-degraded character shapes. It has to be both accurate and flexible enough to enable the selection of a similar but non-identical shape. This is done using a special partial prototyping sys-tem based on the use of Gabor filters at a character level as we have proved that they can provide good results [ 21 ]. mented and embedded in a 128  X  128 image. The bank of 12 Gabor filters can then be applied directly separately on the degraded character and each reference character image. The process used to compare each couple of shapes is presented in Fig. 13 .
 graded character image and each reference image of the set is done using statistical calculations (mean  X  and standard deviation  X  ) on the 12 filtered images (this method has been inspired from [ 32 ]). There, for two response images i and distance of the two images d ij is given by: d where norm(  X  ) (resp. norm(  X  )) is the standard deviation of  X  (resp.  X  ) over the entire set of input images, used to nor-malize the two features.
 (mean) was sufficient to discriminate between the different character shapes [ 33 ]. This can easily be shown on the fol-lowing charts (Fig. 14 ) where we have represented the mean grey-level value over each normalized Gabor filtered image for different character shapes. This leads to a kind of  X  X ro-file X . Figure 14 a and b show the profiles obtained respec-tively for a set of  X  X  X  shapes and a set of  X  X  X  shapes. Fig-ure 14 c shows the profiles obtained for different character shapes chosen for their frequency of apparition in the French language.
 sumed to the calculation of a distance between two proba-bility distributions. For that, we can use any classical dis-tance measure among the one proposed in [ 34 ] like the Bhattacharyya, Hellinger or Kullback X  X ielbler distances. Each one of these measures is efficient in a particular ap-plication, so there is no rule for choosing one or the other. Nevertheless, we chose the latter one, and more precisely the Kullback divergence (12) as it is scale invariant and enables the distinction of even very similar profiles without diver-gence. d ( p 1 , p 2 ) = K ( p 1 , p 2 ) + K ( p 2 , p 1 ) ability distribution X at the point of intensity k (with: X or 2) and K is the Kullback X  X ielbler distance such as: of respective features  X  k i and  X  k j over the k th filter has to be increased by a factor of 10 3 to improve the legibility of the representation. It is given by: images over 14 different shapes gives a 97.0% recognition rate without a prior knowledge, which is really convincing [ 35 ]. 3.4 Building the set of reference images 3.4.1 General principle The set of reference image is built using the same automatic principle as before (Fig. 13 ) that must be generalised: We are no more using single character shapes at one time, but we are now working simultaneously on a huge set of ( M + N ) character images extracted from the original document image. The process can then be divided into five parts: 1. We pick up one character image of each shape in the 2. The ( M + N ) character images are filled in the algorithm 3. Statistical measures, such as mean and standard devi-4. A distance measure is calculated between each sample 5. The distances are carried to an M -dimension space on cation process is applied. The algorithm used is AutoClass software (presented in [ 36 ]), which involves the Bayesian classification theory. It aims at automatically determining the maximal probable number of classes, using the classi-cal finite mixture distribution as fundamental model. This classifier has been chosen because it is easy to use and it rapidly provides good results. We should have tested other classifiers but it was not our purpose here.
 different clusters almost each one containing a single char-acter shape, the final prototype for each class is obtained using a simple pattern matching method, inspired from [ 37 ], which consists in calculating a symmetrical difference be-tween a current image and an updated resulting prototype image(see[ 21 ] for details).
 a set of 560 character images over 14 character shapes (ar-bitrarily chosen prototypes are shown on Fig. 15 a) has been used. The classification algorithm is processed 500 times on the same dataset, since the search includes a random com-ponent (AutoClass recommends at least 50 trials), and we obtain 17 classes without apriori knowledge. Examining the results, we notice that the classifier has managed to sep-arate well 10 very particular patterns, storing them into in-dependent classes (prototypes: Fig. 15 b). This is the case of characters  X  X  X ,  X  X  X ,  X  X  X ,  X  X  X ,  X  X  X ,  X  X  X ,  X  X  X ,  X  X  X ,  X  X  X  and  X  X  X , ex-cept a few isolated mistakes (classes R 0 , R 2 to R 8 , R R 11 ). Two other classes are composed of mixed characters namely  X  X  X  and  X  X  X  on the one hand, and  X  X  X  and  X  X  X  on the other. These are not explicitly classification errors since Ga-bor filtering has been designed to be orientation and transla-tion invariant. Thus, as  X  X  X  and  X  X  X  are a same pattern rotated with angle 180  X  , Gabor analysis logically characterizes them the same way, and so does it for  X  X  X  and  X  X  X . Other classes are rejection classes, containing at the most five test images each (classes R 13 to R 17 ). Finally, the error rate is evaluated to  X  3.6%, that is, we get a 96.4% recognition rate. Our idea is then to complete our characterization process using a very simple non-time-consuming distance measure.
 of more than one character shape: The first one is composed of characters  X  X  X  and  X  X  X , the dominance of n s resulting in a prototype of shape  X  X  X , the others are composed of charac-ters  X  X  X  and  X  X  X , resulting in prototypes #9 and #12 of shape  X  X  X  (as d s are more numerous than p s). In fact, these are not classification errors since Gabor filtering has been designed to be neither symmetry nor translation invariant, and since  X  X  X  and  X  X  X  are same patterns rotated with angle 180  X  .As a matter of fact, the Gabor analysis logically characterizes them the same way (and so does it for  X  X  X  and  X  X  X ). This appears clearly if we plot the distances between the sample images and ambiguous prototype images, for example, char-acters  X  X  X  and  X  X  X , as seen in Fig. 16 .
 try and translation, the character images clustering method based on Gabor filters can generate ambiguous cases that have further to be treated. This is what we explain in the following subsection. 3.4.2 Ambiguous cases As we have said before, because of the robustness of some parameters, the Gabor filters do not allow the recognition of character shapes rotated with angle 180  X  (like  X  X  X  and  X  X  X ). Nevertheless, we want to hold on with this method since it enables the distinction between even very similar character shapes. Thus, the global method has to be improved using a priori knowledge on the type of images we are working on (we have not used any until now).
 syntactical or stochastic analysis (like grammars or Markov fields) in which the image is described as a sentence. In our proposition, we have decided to use a simple and non-time-consuming method, basing our work on [ 38 ]. In this method, the aim is to calculate characteristic features based on the ob-servation of the statistical properties of the characters such as vertical and horizontal transitions, density calculations, etc. [ 35 ]. This enables the elaboration of a specific algorithm that aims at separating lower-case characters from the one presenting ascenders, descenders, etc. A synopsis of this al-gorithm is proposed in Fig. 17 .
  X  X  X ,  X  X  X ,  X  X  X ,  X  X  X  and  X  X  X  randomly chosen gave a recognition rate of 100%. This method is simple, efficient, low-time-consuming, and it works whatever the font type. On the other hand, it is based on the use of heuristics that need the knowl-edge of every ambiguous case. 3.5 Determination of the degraded character and localization of the degradation In our process, we need to know which characters have to be restored and where (the reference gradient vector flow used for the restoration has to be localized in an area surrounding the degradation). This is done automatically using structural information from the reference image.
 the literature and for every type of image. We focus on the case of binary handwritten character images as we are working on particular ancient document images in which every detail has to be taken into account. In this way, Si-mon and Zerhoumi [ 39 ] extract a graph representation of handwritten characters using lines, edges and summits. In [ 40 ] the authors use a Block Adjacency Graph that avoid the skeletonization phase that can generate incomplete final graphs. The method presented in [ 41 ] breaks down the initial character image into curves and segments so that the final representation is as insensitive as possible to the writer. In [ 42 ]and[ 43 ] the authors extract the graph directly on grey-level images. In their methods, the different components of the graph are defined by imprecise zones of pixels. of the final graphs is complex and hard to interpret and not really adapted to our case as they are aimed at eras-ing the details of the shapes. For that, we have developed our own method, as explained in [ 44 ]. In this study, we have presented a method for the extraction of representative structural graphs from character images. This method counts four classical steps: Skeletonization, vectorization (via Freeman), analyse and polygonal approximation; providing structural graphs composed of sets of particular points called  X  X imple points X  and  X  X ranch points X  (which are particular simple points), almost centred on the character width (as shown in Fig. 18 ) and valued by the right and left widths of the character ( w R and w L ). Figure 18 a represents the binary character to process and Fig. 18 b is the extracted graph where simple points are represented in light grey and branch points are in black (corresponding to the termina-tions). Thanks to the polygonal approximation phase, the fi-nal graph is composed of a set of equidistant points. This distance between two points has been chosen empirically on a few examples and is then fixed in the program.
 ular simple points s d defined as the simple points of the ref-erence graph (Fig. 18 b) located on the background when su-perimposed to the degraded image (Fig. 18 c). The degraded characters are the ones having one or more s d points. The rectangles localizing the GVF field are defined in an area surrounding the degraded points s d . 3.6 Initiation of the active contour As said in the former paragraphs, the active contours model is very sensitive to the initiation phase depending on the po-sition of the initial curve, the number of iterations, etc. To automate this step, we thus have to take care of all these parameters using the reference character image just deter-mined before. The principle of our method is then to detect the contours in this reference image and to inflate them at a fixed distance r in a direction normal to the curve at each point (cf. Fig. 19 ), i.e.: and erence character image and P i ( x i ; y i ) is the corresponding point on the initial curve.
 contours: In the first case, the increasing of r makes the con-tour shrink; in the other case, it makes it inflate. Moreover, the obtained initial contour has got the same shape as the reference character. As a matter of fact, it enters the concav-ity in the non-degraded areas and stays away in the degraded ones. Finally, this initiation which is indeed close to the real boundaries of the object, minimizes the necessary number of iterations and then the calculation burden (50 instead of 350 in this example). In practice, r = 2 gives interesting results (cf. Fig. 20 ). 4 Results and discussion Our method has been run on antique document images com-ing from different sources (cf. Fig. 21 ): From the centre of the Archives of Savoy, which are printed documents from the nineteenth century (Fig. 21 a), from the French Institute on Research and History of Texts (IRHT) and the Municipal Library of Troyes (Fig. 21 b) that provided us with images of handwritten manuscripts of the sixteenth century.
 randomly chosen segmented character images for which the extracted prototypes are shown in Fig. 22 .Wenoticethat some of the obtained reference images are representative of same character shapes e.g. ref001 and ref017 or ref006 and ref016 . This is particularly interesting as it proves that our method enables simultaneously the distinction between character shapes and font styles (in our example, we au-tomatically separate bold-faced  X  X  X  from normal ones, and large  X  X  X  from small ones).
 images are the ones presented in Fig. 23 . The distances ob-tained between this shape and three most likely reference images are presented in Table 1, the chosen corresponding prototype is shown in bold once ambiguities (e.g.  X  X  X  and  X  X  X ) are raised.
 cases (with reference characters #1 and 14), the selected ref-erence image is ref001 (presented in Fig. 22 ) with distance 0.6907. The restoration process finally gives the results pre-sented in Fig. 24 . This figure shows the evolution and the results obtained for the external contour (Fig. 24 a and b) as well as for the internal contour (Fig. 24 c and d). Figure 24 e shows both the final contours and Fig. 24 f is the final filled reconstructed character shape. Note that on this example, the restoration has to be done in two steps since the active contours model does not enable topological changes (our method is based on this principle to get continuous bound-aries). Moreover, we said that there was an ambiguity be-tween the reference images number 1 and 14. This is due to the fact that the latter shape corresponds to character  X  X  X  which is very similar to a broken  X  X  X . All the ambiguous cases like this have to be listed and integrated to the algo-rithm via the calculation of personal features inspired from [ 38 ](see[ 35 ] for details).
 results obtained on printed or handwritten characters com-posed of one or more pieces. On these examples, the origi-nal character images have been enlarged to better show what happens. As a consequence, the restoration algorithm seems to work at a higher resolution (it is true!). 5 Conclusion and further work We have elaborated an automatic method for accurate char-acter reconstruction based on the active contour model (it has been tested on hundreds of characters even if only a few examples are shown in this paper). We have made it as robust and autonomous as possible, even if it still needs special pre-processing steps such as the physical segmentation of the original document image at a character level. Our technique has been developed to be adapted to every kind of document image on condition that it is regular enough (we have shown on some examples that it worked for printed as well as for very regular antique handwritten characters, called  X  X etite caroline X ).
 to identify them. As a consequence, segmented touching characters as on Fig. 2 are considered as  X  X lassical X  ones and the method still works (in particular if they are frequent in the document image, there certainly will be a corresponding prototype).
 a repair patch of non-degraded character in the degradation area. This method is not satisfying in reality since it needs the detection of the degradation, the selection of the right zone, and since it may introduce discontinuities in the re-constructed character boundaries.
 a list of points provides a vectorial description of each seg-mented character shape that is very useful. For example, we could imagine using this format to ensure the transcription of antique documents on computer. In this way, we should create new digital typographies very similar to antique ones that would improve the visual aspect of digitised indexable, queryable ... antique document images ( via XML, for exam-ple) avoiding the disk space consumed in the image format. to model the use of a mobile character by following the de-formation of an initial model taken as reference. Going still further, we could imagine the creation of new compression formats as studied in [ 45 ].
 are charged of the author X  X  intention that makes them hard to analyse. In these conditions, the adaptation and exploitation of generic tools like the one used here can bring robust solu-tions to many typical problems in document image analysis, and may be we could imagine adapting an entire set of tools specially dedicated to the case of document images (as it has already been done for satellite or medical images). References
