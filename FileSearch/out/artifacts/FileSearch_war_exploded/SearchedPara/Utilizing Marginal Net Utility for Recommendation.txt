 Traditional recommendation algorithms often select prod-ucts with the highest predic ted ratings to recommend. How-ever, earlier research in economics and marketing indicates that a consumer usually makes purchase decision(s) based on the product X  X  marginal net utility (i.e., the marginal utility minus the product price). Utility is defined as the satis-faction or pleasure user u gets when purchasing the corre-sponding product. A rational consumer chooses the product to purchase in order to maximize the total net utility. In con-trast to the predicted rating, the marginal utility of a prod-uct depends on the user X  X  purchase history and changes over time. According to the Law of Diminishing Marginal Utility, many products have the decreasing marginal utility with the increase of purchase count, such as cell phones, computers, and so on. Users are not likely to purchase the same or sim-ilar product again in a short time if they already purchased it before. On the other hand, some products, such as pet food, baby diapers, would be purchased again and again.
To better match users X  purchase decisions in the real world, this paper explores how to recommend products with the highest marginal net utility in e-commerce sites. Inspired by the Cobb-Douglas utility function in consumer behav-ior theory, we propose a novel utility-based recommendation framework. The framework can be utilized to revamp a fam-ily of existing recommendation algorithms. To demonstrate the idea, we use Singular Value Decomposition (SVD) as an example and revamp it with the framework. We evaluate the proposed algorithm on an e-commerce (shop.com) data set. The new algorithm significantly improves the base algo-rithm, largely due to its ability to recommend both products that are new to the user and products that the user is likely to re-purchase.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Design, Experimentation Recommender System, E-commerce, Consumer Utility Func-tion
With ever increasing e-commerce websites and online shop-pers, the recommender system is becoming popular among internet users. It helps consumers to make purchase deci-sions, mainly by gathering information from other users. In the short term, it saves users X  time and effort to find what they are looking for. In the long term, it helps to increase users X  satisfaction rate and loyalty to the site.
In the literature, the satisfaction or pleasure a user gets when purchasing/consuming a product is called the marginal utility. According to consumer behavior theory, a rational consumer chooses the product with the highest marginal net utility, i.e., a product X  X  marginal utility minus the price. A product X  X  marginal utility is dependent on the user X  X  previ-ous purchase history. A product with the higher marginal net utility is more likely to be purchased. Some products have the diminishing marginal utility. For example, the util-ity of purchasing a second computer is less than that of pur-chasing the first computer. For these products, users are not likely to purchase them again and again in a short time pe-riod. This is called the Law of Diminishing Marginal Utility in economics. On the other hand, some products (pet food, baby diapers, etc.) are likely to be purchased again and again. We call it the  X  X e-purchase X  behavior in this paper.
In order to match users X  purchase decision(s), the rec-ommender system should choose products with the high-est marginal net utilities to recommend. Such a system is able to capture characteristics of both types of products and makes recommendations accordingly. Unfortunately, most of existing recommendation algorithms are not based on the marginal net utility optimization and cannot model the above two different products well. Most existing algorithms select products with the highest predicted ratings to recom-mend, assuming that the value/utility of a product for a user does not change over time.

This paper introduces the concept of marginal net util-ity to develop recommendation algorithms. Inspired by the Cobb-Douglas function in consumer behavior theory, we pro-pose a utility function for the recommender system in e-commerce sites. The new function contains a factor to con-trol the product X  X  marginal utility diminishing rate. As-suming that a user X  X  purchasing decision depends on the marginal net utility, the rate can be learned from the pur-chase history of all users. The function can be applied on a family of existing recommender algorithms, which we call base algorithms. In this work, we choose SVD as our base algorithm. Applying our utility function to SVD leads to a new utility function SV D util in this paper.

We evaluate our algorithm on the purchase history from an e-commerce website shop.com. The experimental results show that our approach can improve the base algorithm sig-nificantly with better precision, recall and conversion rates. If the user purchased what he/she purchased before, the product is denoted as a re-purchase product .Otherwise, if the user purchased a product that he/she never purchased before, the product is denoted as a new product .The recommended list generated by our proposed algorithm con-tains both new products and re-purchase products. Or we can add a filter on top of the recommender system to rec-ommend only re-purchase products or only new products for specific recommendation tasks.

The major contributions of this paper include the follow-ing:
The rest of this paper is organized as follows: Section 2 discusses the related work. Section 3 introduces basic util-ity functions in economics and marketing research. Then we propose a new utility-based recommendation framework, motivated by these basic utility functions. Section 4 ap-plies the new framework to revamp the well-known SVD algorithm. Section 5 first introduces the experimental de-sign to evaluate and understand the new algorithm. Then it presents experimental results and further analysis. In the end, Section 6 concludes the work and discusses some future work.
A major task of the recommender system is to present rec-ommendations to the user. The task is usually conducted by first predicting a user X  X  ratings (or probability of purchas-ing) for each item and then ranking all items in descending order. There are different information sources to find the rel-evant recommendation, including item X  X  content, user X  X  be-havior history, user X  X  demographical information, so on and so forth. There are two major recommendation approaches: content-based filtering and collaborative filtering.
The content-based recommendation is based on the as-sumption that descriptive features of an item (meta data, words in description, price, tags, etc.) tell much about a user X  X  preferences to the item. Thus a recommender system makes a decision for a user based on the descriptive fea-tures of other items the user likes or dislikes. Usually, the system recommends items that are similar to what the user likes before. A user profile contains his/her previous trans-action history, such as what he/she viewed or purchased before. How to determine the similarity between a prod-uct and the profile is the key challenge. Cosine similarity with TF.IDF term weights, the language modeling approach, Bayesian classifiers, clustering, etc., have been proposed [23, 24]. Largely influenced by the TREC filtering track, most of the early research on content-based filtering is about filtering text documents. In e-commerce systems, products usually have very limited description (title, user reviews, etc.). The effectiveness of content-based approaches is limited. Thus a content-based approach is usually not used by itself in e-commerce sites. It is used as part of a hybrid recommen-dation strategy [6]. In this work, we do not assume that a user likes things similar to what he/she likes before. Instead, we utilize the product X  X  metadata to find similar products in order to determine the product X  X  marginal net utility. As a result, a user may like or dislike an item that is similar to what he/she purchased in our model.

In the collaborative filtering approach, user behavior his-tory is utilized to make recommendations. This approach is based on the assumption that users with similar tastes on some items may also have similar preferences on other items. Thus the main idea is to utilize the behavior history from other like-minded users to provide the current user with good recommendations. This approach usually operates on a user-item matrix, in which each row is a user vector and each column is an item vector. User-based methods find sim-ilar users to the current user, and fall into the category of memory-based approach in the literature [26, 5, 12]. How-ever, these methods suffer from the poor quality and scala-bility issues. Item-based methods directly find items that are similar to the items a user has rated/purchased [25, 10]. Var-ious similarity measures, such as cosine similarity, Pearson correlation coefficient, conditional probability-based similar-ity, have been proposed to find all neighbors. In addition, a group of model-based approaches have been developed in recent years. Model-based approaches use the collection of user behavior (ratings, purchases, etc.) to learn a model, and make predictions based on the learned model. Exam-ples are Probabilistic Latent Semantic Indexing (PLSI) [14], Flexible Mixture Models [30], Decoupled Models [16], Mul-tiple Multiplicative Factor Model [21], etc.

Research on collaborative filtering algorithms has reached a peak due to the 1 million dollar Netflix movie recommen-dation competition [4]. Factorization-based collaborative fil-tering approaches, such as the regularized Singular Value Decomposition, perform well on this competition, signifi-cantly better than the Netflix own well-tuned Pearson corre-lation coefficient (nearest neighbors) algorithm. A common characteristic of these models is to introduce user latent fac-tors or/and product latent factors to solve the data sparsity issue. In this paper, we use SVD as our base algorithm, since it represents a family of factorization-based methods that work well on the Netflix dataset [4]. There are many extensions (AsySVD, SVD++, etc.) to the basic SVD in the literature [9, 18]. The approach proposed in this work can be applied to all these methods in the future.
In contrast to our work, most of the existing collabora-tive filtering methods assume that the utility of a product for a user does not change over time. Utility is typically represented by the rating. Although some work captures the temporal variations of a user X  X  ratings [19], they cannot capture the economic behavior behind products X  diminishing return and re-purchase characteristic.

Besides content based filtering and collaborative filtering approaches, other approaches such as Graph-based meth-ods [1], Bayesian network [5], association rules [22], and MDP-based methods (Markov decision process) [29] were de-veloped. Though it is not straightforward to use our pro-posed technique to revamp these filtering approaches, the basic idea of considering the marginal net utility, the dimin-ishing return and the re-purchase behavior could be used to further improve these algorithms in the future.

Recommendation in the e-commerce domain is a topic that has been studied in the IR community [26, 28, 17, 11]. Several methods have been studied in this domain, including neighborhood-based method [26], graph models [15], MDP-based methods [29], multi attribute utility theory based meth-ods [20] and so on. Existing research in economics and marketing can also be applied to model user behavior in e-commerce sites. This paper focuses on modeling users X  pur-chase decisions based on the marginal net utility of products.
In this section, we first define some basic notations to be used in the rest of this paper. Then we review two repre-sentative consumer utility functions. After proposing a new utility function for our problem, we describe how it can be used in a general framework to revamp some existing rec-ommendation algorithms.
The following notations are used in the problem definition and analysis. u =1 , ..., M : the index of a user. M is the number of i or j =1 , ..., N : the index of a product. N is the number t :time. c : the price of product i . We assume that this value is P
M  X  N : user-product matrix. Depending on the context,
The goal of our system is to provide a ranked list of per-sonalized recommendations to user u . In this paper, each user X  X  budget is not taken into consideration. The optimal purchase rule [3] indicates that a rational consumer pur-chases the product to maximize the marginal net utility. Accordingly the algorithm should choose the product with the maximum marginal net utility at each recommendation time point. Since the product price is given, the core prob-lem of a recommender system is to determine the marginal utility for each product.
The utility of a product for a user depends on the user X  X  purchase history. Marginal utility is used in economics and marketing research to represent the additional utility the consumer gets when consuming an additional unit of a prod-uct. The Law Of Diminishing Marginal Utility states that the marginal utility of a product drops while the con-sumption of the product increases. For example, for user u , the utility of consuming the first  X  X Phone 4 X  might be 10, the utility of consuming the second one might be 5, while the utility of consuming a third one might be only 1. It is worth mentioning that the standard definition of the Law Of Diminishing Marginal Utility assumes conti-nuity. It means that all units of a product are purchased one after another, without time gaps between any two pur-chases. However this assumption might not hold in an e-commerce site, where there are time gaps and purchases of other products between most re-purchases. For example, the user might purchase some pet food on Friday evening, then some books on the following Monday morning, and some pet food again after two weeks. Although the continuity assumption no longer holds in our e-commerce domain, we can still use the concept of marginal utility. Utility func-tions in economics can be adapted to our problem. This enables us to make recommendations based on the different diminishing return rate of different products.
Linear utility function is one of the simplest functions in consumer behavior theory, as shown in Equation 1. where X is the set of products the user consumed, and x j is the consumption quantity of product j .  X  j is the basic utility of product j , indicating the purchasing intention for product j . U ( X ) is the utility of the entire purchase list X .
We can calculate the marginal utility  X  U ( X, i ) of pur-chasing one additional unit of product i in the following equation.
 purchase list with one additional product i . x i = x i +1is the updated quantity of product i .

The linear utility does not capture the diminishing return characteristic. From the deduction, we can see that the pre-vious purchase count x i of product i does not affect the marginal utility of purchasing one additional unit of prod-uct i . If product i  X  X  basic utility  X  i is high, the system will recommend it regardless of previous purchase(s) of the same product.

In most existing recommender systems, products with the highest predicted values are recommended to the users. If these products include both re-purchase ones and new prod-ucts, the approach follows the linear utility assumption. If only products that were never purchased are recommended, the following utility function is used: However, both of these two underlying utility functions do not match how users make purchase decisions in the real world.
Another representative utility function is the Cobb-Douglas utility function [8]. This function is widely used due to its attractive mathematical characteristic: the ability of mod-eling the diminishing marginal return. The functional form is: where the definitions of x j and  X  j are the same as before. The marginal utility of purchasing one additional unit of product i is:
 X  U ( X, i )= U ( X, i )  X  U ( X )=  X  i ( log ( x i )  X  log ( x
The above equation shows that the marginal utility of product i decreases as the consumption quantity of product i increases. The diminishing return rate is log ( x i +1)  X 
Diminishing marginal utility is a widely recognized con-sumer behavior which we intend to model in the design of a recommender system for e-commerce sites. This motivates us to utilize the Cobb-Douglas utility function in our algo-rithm design.
 However, Equation 4 shows two major drawbacks of the Cobb-Douglas utility function. First, the marginal utility of different products has the same diminishing return rate log ( x i +1)  X  log ( x i ). It does not differentiate two types of products: products that the user would not purchase many times vs. products that the user would purchase again and again. Second, the basic utility  X  i of a product i does not depend on the particular user, which contradicts with the goal of a personalized recommender system.

A real-world e-commerce system could collect a large amount of consumer purchase data. This enables us to handle these drawbacks of the Cobb-Douglas utility function. We can learn the product-specific diminishing return rate and the user-specific basic utility from the data. Now we describe how to modify the Cobb-Douglas utility function to achieve this goal.
 We propose a new marginal utility function as follows: where x u,i,t is user u  X  X  consumption quantity of product j by time t .
 There are four major differences between Equation 5 and Equation 4. First, we substitute log ( x j )with x j for the mathematical convenience. This simplification is motivated by the well-known Constant elasticity of substitution (CES) utility function in Equation 6 [31]:
Second, x i is substituted by x u,i,t , so that it depends on the product, the user and the time. Third,  X  i is substi-tuted by  X  u,i , so that it is personalized to each individual user. Fourth, we introduce  X  i as a parameter to capture the diminishing return rate of product i .

One important question is how to determine x u,i,t .The original definition of x u,i,t is user u  X  X  purchase count of prod-uct i by time t . We make two major modifications while cal-culating x u,i,t in the e-commerce domain. First, we define the purchase count as the number of purchase orders the current user made. Each order is counted once for the same product, regardless of the product quantity in the order. For example, if the user purchases 4 window panels in one or-der, the purchase count of window panel is 1. Second, we assume that the marginal utility is affected not only by pre-vious purchase(s) of the same product, but also by previous purchase(s) of similar products. For example, the previous purchase of  X  X Phone 3 X  has effect on the marginal utility of the current purchase of  X  X Phone 4 X . We first find products that are similar to product i based on the metadata, such as the product title. Then let x u,i,t be the total similarity between these similar products and the current product i for user u at time t . where C u,j,t is user u  X  X  purchase count of product j by time t , and sim ( i, j ) is the similarity between product i and product j .  X  is a similarity threshold, which will be estimated by the cross-validation in our experiments.

It is worth mentioning that the utility over a sequence of purchases can be calculated based on the definition of the above marginal utility (Equation 5). However, the utility of an unordered set of products is not defined. The only ex-ception is when  X  = 1, in which case only the same product will influence the marginal utility. Under such circumstance, the utility over a sequence is independent of the sequential order of products. Then the utility can be used for an un-ordered set of products. With some derivation, we can get the definition of a user u  X  X  utility over an unordered set of products X at time t in this special case as follows:
It is similar to the Constant Elasticity of Substitution util-ity function in Equation 6. However, the meaning of  X  i in Equation 7 is different from  X  in Equation 6.  X  is the param-eter to tune the elasticity of substitution 1 and is the same for different products. In our new utility function (Equation 7),  X  i is a parameter to tune the diminishing return rate. It is product-specific and can be learned based on the purchase history of each product. Linear and Cobb-Douglas utilities can be viewed as special cases of our utility function. That is, in the limit as all  X  i approach 1, we get the linear utility; as all  X  i approach 0, we get the Cobb-Douglas utility.
In most cases, we can view an existing recommendation algorithm as a function f ( u, i ) to estimate the value of prod-uct i for user u without considering the diminishing return or the cost of a product. To reflect a user X  X  true decision
More information of CES utility function can be found in the reference [31]. behavior in reality, we model v u,i,t , the marginal net utility of product i for user u at time t , as follows:
Whether product i is likely to be purchased is dependent on the product X  X  basic utility, its diminishing return rate, as well as the product X  X  price. Comparing Equation 8 and Equation 5, we notice that  X  u,i is replaced by f ( u, i ). In other words, we propose to use an existing recommendation algorithm f ( u, i )toestimate  X  u,i , the basic utility of prod-uct i for user u .

At each decision point t , a higher marginal net utility v indicates that user u is more likely to purchase product i . The following logistic function can be used to capture this intuition and model the conditional probability of making the purchase.
 where r u,i,t =1ifuser u purchases i at time t .Otherwise r
Assume that the cost c i of product i is given, the pa-rameters of the above model include  X  i and parameters of function f . To learn these parameters, we can order the entire user purchase history by the purchase time. At each time point t ,user u  X  X  purchase decision of product i is con-sidered as a training point. If user u purchased the product, it is a positive training point with r u,i,t =1. Otherwise,it is a negative training point with r u,i,t =  X  1.

When a new recommended list is needed, the system can estimate each product X  X  marginal net utility based on Equa-tion 8 and rank them accordingly. For email-based or message-based marketing/recommendation applications, the system can predict how likely a user will purchase an item using Equation 9 and decide whether to recommend an item to the user accordingly (as in TREC adaptive filtering tasks).
In this section, we choose a popular recommendation al-gorithm SVD as an example. The algorithm in Section 3.4 is used to revamp it. This leads to a new recommendation algorithm, which we call SV D util .
In this work, we choose SVD as an example because it is a popular recommendation algorithm with a decent perfor-mance. It is the basis of several recommendation algorithms based on latent factors, which have been proven to work well on benchmark recommendation datasets including the Netflix dataset [4].

Following [9, 18], we represent SVD as a matrix factor-ization approach. The basic SVD algorithm operates over a user-product matrix P M  X  N . Itassumesthateachentry P u,i in the matrix P can be estimated using the following form: where q i and p u are vectors, which are the hidden rep-resentation of product i and user u . These vectors can be estimated based on all given entries in P M  X  N .
The value of P u,i in the observed matrix P M  X  N is deter-mined by the user purchase history. In the e-commerce do-main, P u,i is usually set to be a unary value that indicates whether user u purchased product i or not [13]. Existing work finds that unary value is more suitable than numeri-cal value, i.e., the number of times the user purchased the product [27]. Our piloting experiment compares these two types of values and reaches the same conclusion.

When a recommender system ranks all products by their estimated  X  P u,i values and selects the top ones to recommend, it is equivalent to maximizing the linear utility.
In this section, we apply the technique in Section 3.4 to re-vamp SVD. To do so, we set the basic utility  X  u,i = f ( u, i )= q p u . Based on Equation 8, the marginal net utility is:
For simplicity and as commonly done in the literature, we assume that prior distributions of user vector p u and item vector q i are Gaussian distributions. Pr ( p u )and Pr ( q have mean zero and variance 1 / X  1 . We assume that the prior distribution of  X  i is a Gaussian distribution with mean  X  0 and variance 1 / X  2 . We treat each purchase order made by a user as a decision point. The purchase history of all users can be viewed as the training data D =( r u,i,t ,c i The joint probability (likelihood) of all parameters and the training data is:
L =
The model parameters can be found by maximizing the joint probability of all parameters and the training data. According to Equation 12 and Equation 9, this is equiva-lent to minimizing the negative log likelihood of the data as follows: ( p u ,q i , X  i )= argmin [  X  logL ] = argmin 1 +  X   X  can also be viewed as regularization factors to avoid the overfitting problem.

The first order derivatives are: where
Based on the above derivation, we can use the stochas-tic gradient descent method to find the optimal parameters. Following the standard stochastic gradient descent method, update rules at each iteration are shown in the following equations. The algorithm stops when the change in an iter-ation is small enough. where  X   X  controls the learning rate at each iteration.  X  and  X   X  can be set by the cross-validation.
Since this paper focuses on the recommendation in e-commerce sites, we collect a dataset from a typical e-commerce website, shop.com, for our experiments. This dataset con-tains the purchase history from 2004-01-01 to 2009-03-08. Since our algorithm is dependent on users X  previous pur-chase history, we sort all history by the purchase time. The first 90% of data is the training data, and the last 10% is the testing data. Tail users that made less than 5 unique product purchases are filtered out in the training data. The remaining training data contains 10,399 users and 65,551 products. There are 102,915 unique (user, product) pairs. As we can see, the user-product matrix for SVD is quite sparse, with only 0.015% density. There are 55,539 unique (user u ,ordertime t ) pairs and 119,322 unique (user u , product i ,ordertime t ) tuples. All products are kept in the training process. In the evaluation step, user n&gt; returning users with at least one purchase in the training data. product n&gt; 0 are products with at least one purchase in the training data. In following sections, we report the performance for returning users that purchased from: 1) all products and 2) product n&gt; 0 .

We first split the training data, using the last 10% of the training data as the validation data to set (  X   X  , X   X  , X  have  X  1 =0 . 015 , X  2 =0 . 035 , X  1 =0 . 05,  X  2 =0 . 01 for posi-tive training points,  X  2 =0 . 001 for negative training points,  X  0 =1,and  X  =0 . 7. Instead of using all negative training points, we randomly sampled 1% from missing entries as negative training points in SV D util .Thesamplepercent-age is determined by cross-validation. Both positive and negative training datas are used to learn model parameters. Finally the model is used to generate the recommendation list in the testing stage. For every decision point t in the testing data, all products are ranked by the marginal net utility v u,i,t (Equation 11). The top ranked products are recommended to the user.

We set the dimension of the user vector and the product vector to be 50. Product titles are used to calculate prod-ucts X  similarity. All stop words are removed. 2
Some researchers have tried to fit SVD model parame-ters to the entire matrix P by replacing the missing entries with a base value such as 0. They found that such meth-ods perform better for ranking metrics, such as recall and precision [9]. Their experiment results are performed on the movie data (Movielens and Netflix) with matrix density be-ing 4.26% and 1.18% respectively. The matrix density on an e-commerce data set is usually much lower [13] (0.015% in our dataset). To train SVD, we randomly sample 0 . 1% missing entries and set them to 0, where percentage is de-termined by the cross-validation. The method is denoted as
There are several metrics to evaluate recommender algo-rithms in the literature [13]. Considering the usage scenario in a typical e-commerce web site, the ranking of all recom-mendations is more important than the rating prediction. Instead of using some common rating prediction accuracy measures (Root Mean Square Error, etc.), we evaluate all algorithms in the context of a ranking task [9].
Then we have:
Conversion rate, a commonly-used metric in e-commerce, is used as an additional evaluation metric in our experi-ments. If the user purchased at least one product from the recommended top K list, we consider that the user has con-verted from a browser into a buyer. The calculation of con-version rate for one testing point is shown in the following equation. conversion rate @ K = 1 S purchased
Conversion rate reflects whether a user receives at least one good recommendation. The average value of all testing points will be used to compare among different algorithms. Statistical significant tests are used when comparing two methods.
In this section, we intend to answer the following questions with the general analysis:
Other metadata information, such as user X  X  review to the product, product X  X  limited description, can be used in the future. Table 1: Conversion rate performance for the gen-eral recommendation task. Value* is significantly better than the baseline SV D matrix and TopPop.

The conversion rate performance of all methods is shown in Table 1. It is clear that all personalized methods are sig-nificantly better than the non-personalized method TopPop . Although the precision and recall are not reported here, we have similar observations when evaluating with these two metrics.
 can see that our proposed marginal utility function helps. Both SV D 0 . 7 util and SV D same util are significantly better than SV D matrix for all evaluation metrics.

Between two methods with the new utility function, the performance of SV D same util is significantly better than SV D The method SV D same util only utilizes the same product to learn the diminishing return rate and estimate the marginal utility. Thus it might catch re-purchase behavior with the higher accuracy. This will be further analyzed in the next section.
In the previous section, we generate a recommended list by ranking all products, including both re-purchase prod-ucts and new products. Besides the general recommendation task, there are more specific tasks in e-commerce sites. Now we perform further analysis to compare these recommenda-tion algorithms in two different recommendation tasks. One task is to recommend products for a user to re-purchase. In the testing data, 13.79% of the purchase orders from re-turning users contain re-purchase products, i.e., products Figure 1: Histogram of the previous purchase count in the training data of all re-purchase products. If a product in the testing data was purchased before, it is a re-purchase product. that were purchased by the user before. To successfully rec-ommend products for the user to re-purchase could save a consumer much time and effort, and might be able to in-crease sales. 3 The challenge is how to rank products the user has purchased before. For all re-purchase products in the testing data, we plot the the histogram of their previous purchase count (Figure 1). We observe that the majority of re-purchase products were purchased only once or twice in the training data. Thus it is hard to use the previous purchase count to rank. In Section 5.3.1, we compare all methods X  performance in ranking products that were pur-chased before. Only re-purchase products in each testing order are used to evaluate all methods X  performance.
A second task is to recommend new products that a user has never purchased before. In the testing data, 90.64% in the dataset of all purchase orders from returning users con-tain new products. The new product recommendation task is much harder and more interesting than the re-purchase recommendation task. The recommendation candidates in-clude all products that were not purchased by the current user before. Only new products in each testing order are used to evaluate all methods X  performance.

In this section, we intend to answer the following ques-tions:
This is why amazon.com is providing subscribing service with discount to encourage re-purchase. Table 2: Conversion rate@K for the re-purchase rec-ommendation task. Value* is significantly better than the baseline SV D matrix and TopPop.

The conversion rate for the re-purchase product recom-mendation task is shown in Table 2.

Before the filter is applied, SV D 0 . 7 util and SV D same form significantly better than baseline methods. This is as expected, since the new algorithm is expected to capture the re-purchase behavior.

SV D same util is better than SV D 0 . 7 util before adding the filter, probably because using similar products introduces some noise into the model. However, it is worth mentioning that SV D 0 . 7 util is able to catch some re-purchase behavior ignored by SV D same util . Some product was not purchased again and again in the training data, yet it is similar to the user X  X  pre-vious purchase. If such product is purchased in the test-ing data, the re-purchase behavior can only be captured by SV D 0 . 7 util yet not SV D same util . For methods with filter, SV D 0 . 7 util .P revious performs the best.

Here is one example. Table 3 shows product 2426 X  X  entire order history in the training data. Table 4 shows the prod-uct title of product 2426 and some of its similar products. 2426 was purchased only once by each of the five users. In this case, SV D same util cannot learn that it is a potential re-purchase product. Yet user u 2613 purchased two products (2365 and 1329) before, which are similar to product 2426. With this information, SV D 0 . 7 util learns that product 2426 is likely to be purchased again after a user purchases a similar product or itself. In the testing data, SV D 0 . 7 util recommends product 2426 to user u 2857 at timestamp 12/1/08,17:52. It was purchased by user u 2857 at that time, which is a re-purchase behavior.
 Table 3: Product 2426  X  X  purchase history in the training data. The table is used in Section 5.3.1. Table 4: Product title of Product 2426 and two sim-ilar products. The table is used in Section 5.3.1.
Table 5 compares the conversion rate of all methods in recommending new products.

Before using the filter, SV D 0 . 7 util achieves better perfor-mance than the baseline SV D matrix and TopPop. On the other hand, SV D same util does not help recommending new products. In this task, SV D 0 . 7 util performs better than SV D since it learns from similar products X  purchase behavior with  X &lt; 1. Recommending good and new products makes SV D 0 . more attractive in e-commerce sites since it adds more serendip-ity to the user.
 To better understand how the proposed method works, Table 6 shows user u 3007  X  X  order and Table 7 shows the cor-responding recommended lists generated by different meth-ods.
 User u 3007 purchased product 915 in the training data. In the SV D same util method, only the marginal (net) utility of the exact same product 915 will be changed. Since product 915 was purchased by the other user(s) for many times, it is recommended to user u 3007 by SV D same util .Inthe SV D method, the marginal (net) utility of similar products will also be changed, including product 914. Its estimation shows that product 914 has a higher marginal net utility. Thus it appears in the top position of SV D 0 . 7 util recommended list, which was actually purchased by the user in the testing Table 5: Conversion rate@K for the new product recommendation task. Value* is significantly better than the baseline SV D matrix and TopPop.
 Table 7: Top 5 recommendation for user u 3007 at time 10/23/08 8:37 data. With these examples in the data, we discover that it is worthwhile to model the purchase decision based on the product X  X  marginal net utility. The utility function can capture much information from consumer behavior.

After a filter is applied, SV D 0 . 7 util .New performs better than the baseline SV D matrix and the difference is signifi-cant.
It is well known that the number of rated items follows a long-tail distribution, i.e., a small fraction of the most popular ones receive the majority of ratings (or purchase counts) [2]. Figure 2 plots the popularity (purchase count) of all products, reflecting that the majority of products were purchased by a few times (  X  5). The 80:20 rule [7] is com-monly used to divide between long-tail products and popu-lar ones. In shop.com dataset, the short-head (20%) involves 0.814% of popular products. All the rest are long-tail prod-ucts.

As mentioned in [9], to recommend popular products is easier yet more trivial. On the other hand, to recommend long-tail products adds more novelty yet it is also a harder task, due to the data sparsity issue. Though our algorithm is not targeted for recommending long-tail products, we would like to see how SV D 0 . 7 util and SV D same util perform from this perspective. 96.09% of purchase orders in the testing data contain long-tail products. Only long-tail products in these testing orders are used to evaluate all methods X  performance.
Table 8 shows the conversion rate of all methods for long-tail products. As expected, TopPop cannot recommend any long-tail products. By maximizing the marginal net util-icantly. As long as the marginal net utility factor can be learned, the improvement is achieved for long-tail products. Figure 2: Popularity (purchase count) of all prod-ucts in the training data Table 8: Conversion rate@K for the long-tail product recommendation task(96.09% of all testing points). Value* is significantly better than the base-line SV D matrix and TopPop.

Inspired by the utility function in consumer behavior the-ory, we design a general framework to revamp existing rec-ommendation algorithms for e-commerce sites. We apply it to SVD, which leads to a new algorithm SV D util .Weeval-uate two special cases of the new algorithm: SV D 0 . 7 util SV D same util . The former one utilizes similar products in esti-mating the marginal utility while the latter one utilizes only the same product. These two methods use each purchase decision point in the data sequentially for the parameter estimation. On shop.com data, the new methods perform significantly better than baselines because they can better capture the re-purchase behavior as well as the diminishing return of the marginal utility. When comparing between these two cases, we found that SV D same util performs better in the re-purchase product recommendation task. SV D 0 . 7 is more useful in recommending new products, which is a harder task and generates more interesting result to the user.
This is just the first step towards revamping recommenda-tion algorithms based on the concept of marginal net utility. In this work, the marginal utility diminishing rate only de-pends on each product. In the future, we plan to do more research to explore its dependency on each user, different time, or other features. Besides, the latent vectors and prod-ucts X  diminishing return rate are not updated online in the current work. In the future, online updating and online test-ing would be implemented to reflect real-world scenario. In addition, the rich implicit data can also be utilized to train our model better. We would like to thank shop.com for sharing the data. This work was funded by N ational Science Foundati on IIS-0713111 and IIS-0953908. An y opinions, findi ngs, conclusions or rec-ommendations expressed in this paper are the authors, and do not necessarily reflect those of the sponsors. [1] C. C. Aggarwal, J. L. Wolf, K. lung Wu, and P. S. Yu. [2] C. Anderson. The Long Tail: Why the Future of [3] W. J. Baumol and A. S. Blinder. Microeconomics: [4] J. Bennett and S. Lanning. The netflix prize. 2007. [5] J.S.Breese,D.Heckerman,andC.Kadie.Empirical [6] R. Burke. Hybrid recommender systems: Survey and [7] Y. Chen, P. P. Chong, and Y. Tong. Theoretical [8] C. Cobb and P. Douglas. A theory of production. [9] P. Cremonesi, Y. Koren, and R. Turrin. Performance [10] M. Deshpande and G. Karypis. Item-based top-n [11] D. Fleder and K. Hosanagar. Blockbuster culture X  X  [12] J. L. Herlocker, J. A. Konstan, A. Borchers, and [13] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and [14] T. Hofmann. Latent semantic models for collaborative [15] Z. Huang, W. Chung, and H. Chen. A graph model for [16] R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative [17] Y. S. Kim, B.-J. Yum, J. Song, and S. M. Kim. [18] Y. Koren. Factorization meets the neighborhood: a [19] Y. Koren. Collaborative filtering with temporal [20] S. li Huang. Designing utility-based recommender [21] B. Marlin and R. S. Zemel. The multiple [22] B. Mobasher, R. Cooley, and J. Srivastava. Automatic [23] R. J. Mooney and L. Roy. Content-based book [24] M. Pazzani, D. Billsus, S. Michalski, and J. Wnek. [25] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [26] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [27] B. M. Sarwar, G. Karypis, J. A. Konstan, and J. T. [28] J. B. Schafer, J. A. Konstan, and J. Riedl.
 [29] G. Shani, D. Heckerman, and R. I. Brafman. An [30] L. Si and R. Jin. Flexible mixture model for [31] H. Uzawa. Production functions with constant
