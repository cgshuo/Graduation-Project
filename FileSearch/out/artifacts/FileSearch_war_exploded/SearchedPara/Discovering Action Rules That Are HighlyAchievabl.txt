 Suppose a census data set of which positive and negative classes correspond to income no less than 50 K dollars per year and the rest, respectively (i.e. adult.data [2]). We try to discover action rules each of which suggests actions for changing the negative class into positive such as obtaining a bachelor degree and becoming an employee of the federal government.

Conventional methods [6,9,10,11,12,13,15,16] either neglect or unsatisfactorily deal with the achievability of an action rule i.e. how many examples are likely to succeed in making the class change. Firstly, the action rule is less useful if a condition  X  X ative-country = Trinadad and Tobago X  is added in the premise as there are only 25 negative examples which correspond to the rule among 37,154 negative examples. Secondly, the action rule is also less useful if most of the negative examples who can obtain a bachelor degree and become an employee of the federal government have many disadvantages which would prevent the class change. Thirdly, the action rule is less useful if most of the negative examples are 57 years old, it takes 4 years to obtain a bachelor degree, and the age of retirement for an employee of the federal government is 60. In short, negative examples associated with a promising action rule should be large in number, should become similar to the positive examples once the actions are accomplished, and should not violate the domain rules in their class change. From the viewpoint of rule discovery, a discovered rule suggesting actions for the class change is likely to be of little use if the number of examples which would succeed in the class change by taking the actions is small.

We argue that a discovered action rule should have enough achievability i.e. it should have a sufficient number of negative examples which can make the class change. We propose AARUDIA (Achievable Action RUle DIscovery Algo-rithm), which discovers a set of action r ules each of which is associated with a set of relevant examples, as a practical solution. To realize the motivation, we include a set of domain rules which describe the effect of actions and a minimum achievability threshold in the input, and associate a set of relevant examples to a discovered action rule in the output. Our method judges the relevance of an ex-ample based on the Naive Bayes classifier, which is associated to each candidate of a discovered action rule. 2.1 Action Rule A table format data T consists of n examples e 1 ,e 2 ,...,e n , each of which is de-scribed with m attributes f 1 ,f 2 ,...,f m . An attribute is either nominal, ordinary, or continuous and not necessary binary. An ordinary attribute assumes a total order among its values unlike a nominal attribute and its number of possible values is small unlike a continuous attribute. Unlike association rule discovery, we do not assume a specific type of distribution on attribute values.
An attribute is classified as either actionable or stable. One can change the value v 1 of an actionable attribute f to another value v 2 through action e.g.  X  X ales X  for  X  X ccupation X  can be changed to  X  X xec-managerial X . The value of a stable attribute remains the same e.g.  X  X ative-country = United-States X  remains the same for a person.

We assume that the table format data contains a class attribute and one of its values represents a positive class. Table 1 shows an example of the table format data, which consist of three examples and have five attributes. Age, Education, and Capital loss are ordinary attributes while Income is a class attribute and Income  X  5K is the positive class.

We call a condition in the form of  X  X n attribute = a value X  an atom and we define that a literal represents either a single atom or a conjunction of atoms. An atom is called actionable or stable if its attribute is actionable or stable, respectively. A literal which has no actionable attribute is called a stable literal. A non-stable literal is called an actionable literal.

An action rule is a rule Y  X  P where Y is an actionable literal and P repre-sents  X  X lass = positive X . For instance,  X  X ative country = US, education level = Bachelors  X  P  X  suggests that those who were born in the U.S. and belong to the negative class had better change their education level to bachelor to turn into the positive class. A negative example which has a good possibility to satisfy Y by changing its value(s) of actionable attribute(s) and become a positive example is called relevant to the action rule. Let the new state of a negative example e by performing such a change be e , we call the class change achievable with the action rule for e if e satisfies the stable atoms in Y , e satisfies the actionable atoms in Y , and the classifier  X  associated with the action rule predicts e as positive. In this case, we also call e to be relevant to Y  X  P .

We define that an action rule Y  X  P satisfies the minimum support condition (1) for a minimum support threshold  X  and the minimum confidence condition (2) for a minimum confidence threshold  X  as in association rule discovery [1], where n ( P ,Y )and n ( Y ) are the number of positive examples which satisfy Y and the number of examples which satisfy Y , respectively. The left-hand sides of (1) and (2) are called the support and the confidence of Y  X  P and are denoted with sup ( Y )and conf ( Y ), respectively. A crucial difference to association rule discovery is the minimum achievability condition (3) for a minimum achievability threshold  X  ,where a ( Y  X  P )representsthe number of relevant examples to Y  X  P . We call the left-hand side of (3) the achievability of an action rule Y  X  P and denote it with ach ( Y ). We call an action rule which satisfies (1), (2), and (3) highly achievable. [Action rule discovery problem]: given a table format data T ,thevalues of thresholds for the minimum support  X  , the minimum confidence  X  ,andthe minimum achievability  X  , find all action rules Y  X  P that satisfy (1), (2), (3). 2.2 Domain Rules A domain rule describes either the kin d of an attribute, the change of values of an actionable attribute, and the number of bins in discretizing a continuous attribute. The last kind of rules are obvious thus we explain the first two.
For the kind of an attribute, we consider  X  X rdered actionable X  and  X  X artially actionable X  in addition to  X  X ctionable X  and  X  X table X  in the previous section. The first two kinds are special types of actionable attributes and are invented to facilitate a specification of changes of an actionable attribute. By specifying that an attribute is an ordered actionable attribute, any change of values in the wrong direction is prohibited. For instance, the final education level is an ordered actionable attribute because its values follow a total order (e.g.  X 10th X  &lt;  X 11th X  &lt;  X 12th X  &lt;  X  X S-grad X ) and a value is only allowed to increase. On the other hand, by specifying that an attribute is a partially actionable attribute, any change of values not specified explicitly is prohibited. For instance, the marital status is a partially actionable attribute because some of the recommendations such as divorce to a married person are inappropriate and thus are not specified.
For a change of values of an actionable attribute, we specify the old value, the new value, the cost of the change, the effects of the change, and the condition of the change. We do not allow multiple possibilities for a change of values for the same condition. Conflicts between effects o f actions are handled by user-specified rules. For an old value or a new value, the user can specify either one value, a set of values, or a wild card which matches any value. For the cost of a change, we allow either  X  X asy X ,  X  X ormal X , or  X  X ifficult X  for ease of specification. These costs are ordinary and cannot be added. We admit that a quantitative index can be more accurate but believe that it is not available in most domains. For the effects of a change, the user can specify a list of (attribute, new value)s. Here a new value is either an attribute value, an addition/deletion of a value (e.g. age 5 years older), or an average value of the attribute (e.g. working hour = the average value of the successful executive manegerials). For the condition of a change, we allow a literal which specifies a set of examples.

We assume that an example follows the recommended action if the class change is achievable. The suggestion made by our discovered rule can be called individual since each example consults the classifier and domain rules before taking the suggested action. Most of previous research [6,9,10,11,12,13,15,16] as-sume that all examples that can take the suggested action (with affordable cost if any but consulting neither a classifier nor domain rules) follow the suggestion thus can be called total. We believe that our formalization fits the reality unlike total as one would not follow a suggestion if the class change seems impossible. 3.1 Motivation and Overview AARUDIA finds all actionable literals Y that satisfy (1) ` alaApriori[1]then outputs all Y  X  P that satisfy (2) and (3) from disk-resident data. AARUDIA employs the Naive Bayes classifier [4], which considers both positive examples and negative examples and is effective even for high-dimensional data, to each actionable literal, which represents a candidate of an action rule. The Naive Bayes classifier can be constructed with one scan of the data, requires only (2  X  + 2)-double-precision-number space where  X  represents the number of possible atoms, and is robust against noise. Many experiments show its high accuracy despite of its simplicity and its assumption on the independence of attributes [4].
It is well-known that the support of an itemset follows the anti-monotonicity property unlike the confidence [1]. The achievability on the other hand does not follow the anti-monotonicity property because adding an actionable atom  X  to apremise Y may add some of the examples each of which satisfies  X   X  Y into the set of relevant examples i.e. a (  X Y  X  P ) can be greater than a ( Y  X  P ).
The above analysis has led us invent an algorithm which handles the set of actionable literals and the set of stable literals separately. The set of actionable and stable literals with d atoms are denoted with arl [ d ]and nrl [ d ], respectively. The algorithm requires 2 + 2  X  scans of the disk-resident data where  X  represents the maximum length of investigated literals. The number of scans is nearly twice of Apriori but we will show its practical performance in the next section. algorithm AARUDIA
AARUDIA first performs a global discretization for each continuous attribute to obtain a discretized data set T then iterates loops in each of which the set of all action rules with a premise-length d is discovered and d is incremented. In each iteration of the loop, the sets of actionable and stable literals which correspond to arl [ d ]and nrl [ d ], respectively as well as the candidates res [ d ] of the premises of discovered rules are obtained with obtainRulesCandidates. Then AARUDIA outputs all action rules of which length of the premise is d with printAchievable-ActionRules. The iteration continues at least one of arl [ d ]and nrl [ d ]isnonempty and d&lt;m . We omit the details of the algorithm due to space constraint.
Figure 1 shows two examples of action rules, an example, the Naive Bayes clas-sifiers associated with the two action rules, and their predictions to the example. Laplace estimates [4] are used for the conditional probabilities. The Naive Bayes classifier associated with action rules 1 and 2 judges example 1 positive and negative, respectively. Let N represent  X  X lass = negative X . In the experiments in the next section, rule 1 had n Pr( P Y ) = 2,219, n Pr( N Y ) = 12,362, a ( Y  X  P )= 3,489 (including this example) while rule 2 had n Pr( P Y ) = 2,030, n Pr( N Y )= 9,747, a ( Y  X  P ) = 2,080 (not including this example) for n =1 , 000 , 000. As we used  X  =0 . 01 , X  =0 . 15 , X  =0 . 03, rule 1 satisfies (1), (2), (3) while rule 2 does not satisfy (3). Thus only rule 1 is output as the discovery result. 4.1 Conditions The Census data set (i.e. adult.data) [2] consists of 48,842 examples described with 15 attributes and the maximum number of values that an attribute can take is 42. We believe that the data is at the same time ideal and inadequate for testing AARUDIA because it is comprehensible but small. To circumvent this problem, we have  X  X nflated X  the data set by randomly generating  X  X easonable X  examples. A reasonable example is gen erated by choosing a specified number (i.e. 5) of examples randomly then adopting the most frequent value for each non-continuous attribute and the average value for each continuous attribute. We have generated three inflated data sets of 100,000, 500,000, and 1,000,000 examples and call them 100K, 500K, and 1M, respectively.

In the experiments, age, capital-gain, and capital-loss are considered as con-tinuous attributes. The attribute fnlwgt is ignored because it is determined by the sampling weight thus does not describe a property of the corresponding per-son. The attribute education-num was used to define the order of values for the education attribute then was deleted because it is just a numeric representation of the education attribute.

We specified workclass and occupation as actionable. Education and marital-status were specified as ordered actionable and partially actionable, respectively. Five domain rules for actions were provided based on a simple statistical analy-sis 1 . We neglected the cost information b ecause it is an open problem and is not the main focus of our research. For the number of discretized values, we specified 3 for age and 2 for others. We used a workstation Dell Precision 690 with double 3.0GHz-CPUs and 16G byte memory. In the implementation, we used gcc 3.4.6 under Linux OS 2.6.9 and an optimization flag -O. The maximum number of the Naive Bayes classifiers were set to 65,536 though the workstation can hold even 1,048,576 Naive Bayes classifiers. 4.2 Results and Discussions We show the results of the experiments for the data sets 1M, 500K, and 100K in the top, middle, and bottom rows of Figur e 2, respectively. The figure consists of three kinds of plots, in which  X  ,  X  ,and  X  are varied in the left, middle, and right plots, respectively. We have varied the range of  X  for the data sets as 0.015, 0.016, ..., 0.024 for 1M, 0.01, 0. 011, . . . , 0.019 for 500K, and 0.005, 0.006, ..., 0.014 for 100K to keep the execution time reasonable. The values of  X  and  X  were varied as 0.10, 0.11, ..., 0.19 and 0. 025, 0.026, . . . , 0.034, respectively. Note that  X  is not as small as it looks since for instance  X  =0 . 025 for 1M means that the class change is achievable for at least 25,000 persons with an action rule. A standard condition was chosen for each data set: (  X ,  X ,  X  )=(0 . 02 , 0 . 15 , 0 . 03) for 100K. In each plot, we fixed the values of the remaining two parameters to those of the respective standard condition.

From the figure, we see that AARUDIA runs in a reasonable time: for 1M, 500K, and 100K, the execution times are between 204 and 419, 150 and 345, and 48 and 155 seconds, respectively. These r esults are related with the number of examples, the number of disk scans, which is typically about 20, the distributions of values in the data, and the values of the thresholds.

Unlike a typical rule discovery algorithm, AARUDIA discovers at most 71 rules thus the inspection of the discovered rules by the user is easy. A higher threshold value yields in a reduced execution time but a smaller number of dis-covered action rules, which is natural due to a more strict constraint on the discovered action rules. Under several combinations of threshold values, no ac-tion rules were discovered, which means that the threshold values were too high. In practice, the values of the thresholds may be determined with trial and error, which is common in a KDD process [5]. Most of the discovered action rules rec-ommend actions in terms of education, workclass, and occupation, which seems reasonable. No action rules which recommend an action on marital status were discovered, which shows that AARUDIA allows inadequate domain rules 2 .
Figure 3 shows the result of our invest igation on the effectiveness of (3) in reducing the number of discovered action rules. The left and right plots show the results of varying  X  and  X  , respectively, where  X  = 0 and the fixed threshold takes the value of the standard condition. The reduction rate is defined as 1 -(the number of discovered action rules with  X  = (the standard value))/(the number of discovered action rules with  X  = 0). We see that (3) eliminates more than 95 % of discovered action rules and without it their numbers become hundreds or thousands. Clearly the achievability condition (3) is useful in reducing the workload of the user in inspecting the discovered action rules. Note that each of the eliminated action rules has a small number of relevant examples thus are less worth of inspection. Ra  X  s et al. X  X  are the pioneers of the action rule mining [9,10,11,12,13,15,16] though they neglect the effect of an action and the achievability. They mostly use a heuris-tic method to discover a set of rules then to make pairs of a rule which predicts the positive class and a related rule which predicts the negative class. Unlike an ex-haustive method such as ours, their method can miss important rules. [17] also aims at converting individuals from an undesirable class to a desirable class. The work is based on the case-base reasoning and it states to  X  X dentify typical positive cases to form a small and highly re presentative case base, then use the case base as  X  X ole models X  to formulate the ma rketing actions X . As it discovers recom-mended actions to individuals instead of action rules, the recommendation lacks of generality and are easily influenced by outliers. They use three classifiers for find-ing the role model: 1-nearest neighbor, 1-nearest cluster centroid 3 , and the support vector machines. The first and the second classifiers neglect negative examples and are ineffective for high-dimensional data due to the curse of dimensionality. The last classifier is prohibitive to disk-resident data and noisy data.

Though the discovered pattern of [7] is a deviation, the motivation of the work is related to ours as it states  X  X he interestingness of a finding is the estimated benefit from a possible action connected to it X . Consideration on the effects and the achievability of the class change are left to the user. It should be also noted that [7] relies on a DBMS system thus neglects inventing data mining algorithms for disk-resident data. [3] tries to obtain the set of products that yields the maximum cross-selling profits in the framework of association rule discovery. Though the work also considers the effects of actions and puts emphasis on decision making, it neglects the achievability, takes a totally different approach, and relies on accurate quantitative profits and costs. In a practical data mining application, the achievability of the objective and the effect of the actions suggested by a data m ining method are often crucial. Most of data mining methods leave the consideration on them to the user while this paper can be considered as an initial step toward supporting such activities. This work was partially supported by the grant-in-aid for scientific research on fundamental research (B ) 18300047 from the Japanese M inistry of Education, Culture, Sports, Science and Technology.

