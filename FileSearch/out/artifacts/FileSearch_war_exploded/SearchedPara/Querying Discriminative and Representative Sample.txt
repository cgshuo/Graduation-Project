 Empirical risk minimization (ERM) provides a useful guide-line for many machine learning and data mining algorithms. Under the ERM principle, one minimizes an upper bound of the true risk, which is approximated by the summation of empirical risk and the complexity of the candidate classifi-er class. To guarantee a satisfactory learning performance, ERM requires that the training data are i.i.d. sampled from the unknown source distribution. However, this may not be the case in active learning, where one selects the most informative samples to label and these data may not fol-low the source distribution. In this paper, we generalize the empirical risk minimization principle to the active learning setting. We derive a novel form of upper bound for the true risk in the active learning setting; by minimizing this upper bound we develop a practical batch mode active learning method. The proposed formulation involves a non-convex integer programming optimization problem. We solve it effi-ciently by an alternating optimization method. Our method is shown to query the most informative samples while pre-serving the source distribution as much as possible, thus identifying the most uncertain and representative queries. Experiments on benchmark data sets and real-world applica-tions demonstrate the superior performance of our proposed method in comparison with the state-of-the-art methods. H.2.8 [ Database Management ]: Database Applications X  Data Mining Algorithms Active learning, representative and discriminative, empirical risk minimization, maximum mean discrepancy
In many machine learning tasks, we need to collect the training data and manually annotate them by experts. This procedure is very expensive in most real world application-s, such as text classification [34], collaborative filtering [23], outlier detection [1], biomedicine and bioinformatics [33]. Active learning is a very useful tool in such situations when unlabeled data is cheap to collect but labeling them is ex-pensive. There are two main intuitions for querying the unlabeled samples and designing practical active learning algorithms [14]. The first one is to find the most informa-tive or discriminative samples for the current classifier. This mechanism will shrink the space of candidate classifiers as rapidly as possible. The most typical criteria of this kind in-clude expected error reduction [25], query by committee [17, 27] and the most uncertain rule [8, 26, 30]. In such method-s, the queried data are not guaranteed to be i.i.d. sampled from the original data distribution, as they are selectively sampled based on the active learning criterion [3]. When training the classifier using the empirical risk minimization principle, this sampling bias prevents active learning from finding a classifier with good performance on future unseen data, and will also degrade the following query efficiency [14, 29]. The second category of active learning aims to alleviate this problem by querying the most representative samples for the overall patterns of the unlabeled data and preserv-ing the data distribution or its statistics [11, 12, 35]. Such type of active learning methods gives better performance when there is few or no initial labeled data. However, their efficiency will degrade with the increase of queried labels, as they do not fully use the label information.

Since using either kind of criterion alone is not sufficien-t to get the optimal result, there are several works trying to query the unlabeled samples with both high informative-ness and high representativeness [24, 34]. Usually they are either heuristic in designing the specific query criterion or ad hoc in measuring the informativeness and representative-ness of the samples. Recently, Huang et al. [22] try to use both discriminative and representative information in one optimization formulation. They use the most uncertainty as the query criterion, and use unlabeled data in the semi-supervised learning setting for boosting the learning perfor-mance. However, the queried samples may not preserve the original data distribution. If the data structure does not satisfy the semi-supervised assumptions [10, 36], they may not achieve good performance.

In this paper, we extend the empirical risk minimization principle to the active learning case and present a novel ac-tive learning framework. In this framework, we adapt max-imum mean discrepancy (MMD) [5, 18, 28] to measure the distribution difference and derive an empirical upper bound for active learning risk. By minimizing this upper bound, we approximately minimize the true risk under the original data distribution. We propose a practical batch mode active learning algorithm under this framework. In our algorith-m, we seek to query a subset of unlabeled samples which help minimize the generalization risk, based on all available information. To achieve this goal, the samples we query not only help to rapidly reduce the empirical risk on the training data, but also preserve the original data distribu-tion, resulting in a good generalization ability for the unseen samples. This leads to a proper use of both discriminative information and representative information simultaneously. Moreover, using our active learning method, we can natu-rally handle the situations with or without initial labeled samples and achieve high active learning efficiency in either case. We have conducted experiments on benchmark data sets and real-world applications. Results demonstrate the ef-fectiveness of the proposed method in comparison with the state-of-the-art batch mode active learning methods.
The rest of this paper is organized as follows: Section 2 analyzes the empirical risk minimization principle in the active learning setting and presents the corresponding ac-tive learning framework; in Section 3 we propose a practical batch mode active learning algorithm under our novel frame-work; experimental results are reported in Section 4; Section 5 concludes this paper and discusses the future work.
In supervised learning, the target of learning is to find the optimal classifier which is expected to generalize well on the unseen data. The empirical risk minimization (ER-M) is a successful guideline for designing machine learning and data mining methods [7, 31]. It minimizes an upper bound of the true risk under the unknown data distribu-tion. This upper bound is approximated by the summation of empirical risk on the available data and a properly de-signed regularization term, which constrains the complexity of the candidate classifiers [31, 2]. Assume we are given a data source D , with unknown distribution p ( z )= p ( x ,y )for sample z = { x ,y } , and a finite data set S with n points, which are i.i.d. sampled from the same distribution, p ( z ). Using the Rademacher complexity to describe the complex-ity of the function class, we obtain the uniform convergence property between the true risk and the empirical risk [2]: which holds with probability at least 1  X   X  . In this inequali-classifier f ( x )  X  X  . The true risk is defined as the expecta-tion of the loss function: The empirical risk is the empirical average of the loss func-tion: The Rademacher complexity of the loss function class L is expressed as where  X  1 ,  X  X  X  , X  n are independent random variables uniform-ly chosen from { X  1 , 1 } , known as Rademacher variables.
In this framework, the empirical average (3) is under the same sample distribution as the expectation (2). This re-quires data in S to be i.i.d. sampled from the original data distribution p ( x ,y ). However, this assumption may not hold in the active learning setting. In active learning, we assume that the labeled data are selectively sampled from another data distribution q ( x ,y ), which is usually different from the distribution p ( x ,y ) for the original problem. To extend the ERM principle to active learning, we reformulate the risk bound inequality as:  X  E
Q ( l ( z )) is the empirical risk for the available labeled data, which may include initial labeled samples and query sam-ples. R q ( L ) is the Rademacher complexity based on these labeled samples. There is a new term in the upper bound, which is the difference between the true risk under different data distributions:
Though in active learning the data distribution for the la-beled samples q ( x ,y ) may be different from the original dis-tribution p ( x ,y ), they share the same conditional probabili-we rewrite the first term in the upper bound of (4) as where we define g ( x )= y l ( f ( x ) ,y ) p ( y | x ) dy .Inlearn-ing problems, the prediction functions have bounded norm || f || F . Thus, given a continues loss function, such as the hinge loss and the least squares loss [31], the function g is bounded. Since g is also measurable, there exists a bounded and continuous function  X  g which has the following property [15]: where  X  g belongs to the function class of bounded and con-tinuous functions C ( x )of x . From [5, 18, 28], we find that the right side of the inequality is the maximum mean dis-crepancy term defined as
MMD[ C ,p ( x ) ,q ( x )] = sup
Taking MMD as an upper bound of the expected risk d-ifference, the ERM risk bound for active learning can be written as E D ( l ( f ( x ) ,y ))  X   X  E Q ( l ( f ( x ) ,y )) + MMD [ Following [5, 18, 28], we could empirically restrict the M-MD on a reproducing kernel Hilbert space (RKHS) with a characteristic kernel, k ( x i , x j ), which is associated with a nonlinear feature mapping function  X  ( x ). Then the ERM principle in the active learning case is summarized in the following theorem. The proof is provided in the Appendix.
Theorem 2.1. Assume that the kernel function is upper bounded by a constant, 0  X  k ( x i , x j )  X  M ,  X  x j , x variables be defined as above. Under the ERM principle for active learning, the following holds with probability at least 1  X   X  , In this inequality, the empirical MMD term is The function class complexity term is where c is a constant.
Suppose we are given a data set with n samples S = { x 1 , x 2 ,  X  X  X  , x n } of d dimensions. Initially we have l labeled samples. Without loss of generality, we denote them as L = { ( x 1 ,y 1 ) , ( x 2 ,y 2 ) ,  X  X  X  , ( x l ,y l ) } ,withlabels y we only focus on binary problems. Note that l could be 0. The remaining u = n  X  l samples form the unlabeled set tive learning. In our batch mode active learning problem, we iteratively select the best subset Q  X  U with b samples to label, and put them to the labeled set L . In the following discussion, we use Q to denote the query sample set.
Based on Theorem 2.1, we propose a practical active learn-ing algorithm by minimizing the active learning risk bound in (5). Mathematically, it is formulated as an optimization problem w.r.t. the classifier f and the query set Q : where || f || 2 F is used to constrain the complexity of the clas-sifier class, which is equivalent to constraining C ( L ,b, X  )[2]. l ( y,f ( x )) in the objective function can be any popularly used loss function, such as the least squares loss, the hinge loss or the negative log likelihood of logistic regression. We choose the least squares loss for simplicity.

The optimization problem (6) is difficult to solve, as it involves a square root in the MMD term. Therefore, we substitute this term with its quadratic form, and obtain the following problem The optimal solution is not changed with a properly chosen parameter  X  [18, 31]. As we do not know the labels of the query samples before we get them manually labeled, we use the pseudo labels  X  y i in the objective, which are binary vari-ables from { X  1 , 1 } [13]. In this objective function, the first three terms correspond to the regularized risk for all labeled samples after query, which carries the discriminative infor-mation embedded in the current classifier. We call them the discriminative part. The last term describes the distribution difference between the labeled samples after query and all available samples, which captures the representative infor-mation embedded in the labeled samples. The objective in (7) balances the discriminative and representative informa-tion in a single formulation. In the remaining part of this section, we will analyze this objective in a specific form and propose a practical batch mode active learning algorithm to solve the resulting optimization problem.
First, we show how to determine the b unknown pseudo labels  X  y i . It is clear that the maximum possible regularized empirical risk after querying the b samples in Q is max If we solve (8) w.r.t.  X  y i with fixed Q and f , we minimize the worst-case risk introduced by the query samples. In this case, the pseudo labels are given by  X  y j =  X  sign( f ( x Accordingly, the related risk terms become min which is still an upper bound of the true risk. For any clas-sifier f , (9) identifies the samples with minimum margin summation, given by Intuitively, it looks for the most uncertain query samples.
We use the linear regression model in the kernel space as the classifier, which is in the form of f ( x )= w T  X  ( x ), with the feature mapping  X  ( x ). The discriminative part of our objective becomes
The representative part in objective (7) is the MMD term, which is used to constrain the distribution of the labeled and query samples, and make it similar to the overall sample dis-tribution as much as possible. It captures the representative information of the data structure. This part is empirically calculated as [5, 18, 28]: MMD 2  X  ( D,L  X  Q )= 1 Similar to [11], we transfer the MMD term into 1 2 where 1 l is a vector of length l , with all entries 1; 1 of length u ;  X  is the indicator vector with u elements and each element  X  i  X  X  0 , 1 } ,and  X  T 1 u = b . K is the kernel matrix with its element as K ij = k ( x i , x j )=  X  ( x i and K AB denotes its sub-matrix between the samples from set A and set B . The objective can be further simplified as where K 1 = 1 2 K UU , k = k 3  X  k 2 ,and  X  x i  X  U , k 2
Combining the discriminative and representative parts to-gether, we obtain the following formulation: This objective function approximates an upper bound of the generalization risk under the original data distribution. This problem is not convex, and we propose to employ the alter-nating optimization strategy [4].

If the query index  X  is fixed, the objective is to find the best classifier based on the current labeled and query sam-ples: We propose to solve (12) by the alternating direction method of multipliers (ADMM) [6].

If w is fixed, the objective becomes which can be rewritten as programming problem for the indicator vector  X  .Ifwerelax  X  to continuous values in [0 , 1] u , this can be solved using standard quadratic programming.
We provide the details for solving the optimization prob-lem (11), which is not convex. The alternating procedure includes two main steps: step 1 : for a fixed  X  ,employtheal-ternating direction method of multipliers (ADMM) to solve w ; step 2 : for a fixed w , employ the quadratic programming (QP) to solve  X  .
 Step 1: Computing w, for a fixed  X  :
Using the kernel form, the problem is to learn  X  for w =
By introducing the auxiliary variable z j = w T  X  ( x j ), the objective function becomes, min s.t. z i  X   X  T K L ( x i )=0 ,  X  x i  X  Q. We construct the augmented Lagrangian as Then we obtain the updating rules as Step 2: Computing  X  ,forafixedw:
With a fixed w , the objective function becomes where H =  X K 1 and d =  X  k + a .Thisproblemcanbesolved using standard QP toolboxes such as CVX 1 and MOSEK 2 . With the compute  X  , we set the largest b elements in  X  to 1 and set the remaining ones to 0.

The key steps are summarized in Algorithm 1. We can al-so generalize our method to the semi-supervised setting, by introducing estimated empirical risk for all unlabeled sam-ples as in [20, 22].
CVX:  X  X ttp://cvxr.com/cvx X .
MOSEK:  X  X ttp://www.mosek.com/ X . Algorithm 1 Discriminative and Representative Queries for Batch Mode Active Learning (BMDR)
Input: L = { ( x i ,y i ) } with l labeled samples, U = { with u unlabeled samples, parameters  X ,  X  ,batchsize b , tolerance  X  for convergence condition
Initialize: Set initial variables and parameters. repeat until Convergence condition is satisfied
Output: The query indicator vector  X  .
In our experiments, we compare our method with ran-dom selection and state-of-the-art batch mode active learn-ing methods. We list all methods we compared in the ex-periments as follows: 1. Random : randomly select the query samples. 2. Fbatch : batch mode active learning based on fisher 3. Dbatch : discriminative batch mode active learning [20]. 4. Tbatch : batch mode active learning using transductive 5. Mbatch : batch mode active learning by matrix com-6. BMDR : our batch mode active leaning with discrimi-
We conduct the experiments on fifteen data sets from UCI benchmarks 3 [16]: australian, banana, chess, crx, diabetis, heart, image, ionosphere, monk1, ringnorm, splice, thyroid, twonorm, vote and waveform. We summarize the character-istics of the data sets in Table 1.

In the experiments, for each data set, we use 60% data for training and 40% for testing, and the data set is randomly divided into training and test sets. We use the training set for active learning and compare the prediction accuracy for different methods on the test set. We assume there is no la-beled data available at the very beginning of active learning. For Fbatch and Dbatch methods which need initial labeled data, we randomly sample the initial labeled data until there are enough labeled samples to train an initial classifier. The number of these initial samples are usually smaller than 10 in our experiments. The experiment stops when 80% of the training set has been labeled, or the learning accuracy does not increase for any method. This stopping criterion guar-antees we show the whole active learning process, though practically the query process stops much earlier due to the limited labeling cost. We set the batch size b =5inall experiments. For the parameters involved in the compet-ing methods, we prefer to use the values recommended in
Some of the data sets have been preprocessed and released at  X  X ttp://theoval.cmp.uea.ac.uk/  X  gcc/matlab/ default.html#benchmarks X .
 Table 1: Characteristics of the data sets, including the numbers of the corresponding features and sam-ples.
 the original papers. In other cases, we set up a large candi-date set and select the best parameter value. In our BMDR method, we set the regularization weight  X  =0 . 1, and the trade-off parameter  X  is chosen from a candidate set by cross validation. For each data set, we use the same kernel for all methods, which is properly chosen from the linear kernel or RBF kernel with the optimal kernel width. For fairness, we use the same SVM classifier for all methods to evaluate the informativeness of the selected samples. We report the ac-curacy curve of the SVM classifier after each query. We use the SVM implementation provided by LIBSVM [9]. In these experiments, we use the CVX toolbox as the solver for the quadratic programming problems and the linear program-ming problems. Running the Mbatch method needs a large amount of memory for large data sets. Though we could use subsampling to save the memory, it will degrade the perfor-mance of this method. For this reasons, we only provide the result for this method on relatively small data sets.
For each data set, we run the experiment independently for 10 times, and present the average result in Figure 1. We also show the significance of the comparison results using the paired t-test. In active learning, we need to compare the performance during the entire query process. In our ex-periments, we compare the learning accuracy of our method versus each competing method after each query, at 95% con-fidence level, then count the times of our win/tie/loss. We show them in percentage for all data sets in Table 2.
From all these results, we can observe that our method outperforms the competitors in three aspects. First, our method seldom performs worse than random query. All the other active learning methods are dominated by ran-dom query in certain cases. Second, the performance of our method is always among the best ones on all data set-s. Third, in most cases, our method performs consistently better than the competitors during the whole active learning process. These results demonstrate that both discriminative and representative information are critical for active learn-ing, and a proper balance of these two sources of information will boost the active learning performance.
Our algorithm has a tunable parameter  X  . It balances the trade-off between the effect of discriminative informa-tion and representative information in our optimization ob-jective. In this experiment, we run our algorithm with pa-rameter values from a candidate set { 1 , 2 , 10 , 100 , 1000 show the active learning performance. We report results on two UCI benchmark data sets: breast cancer and german [16]. The experiment settings are the same as previous ones.
We present the results in Figure 2. From these results, we observe that the performance on german is not sensitive to the trade-off parameter. However, the performance on breast cancer is more sensitive to this parameter. The rea-son may be that the breast cancer data set may have more regular data structure. Therefore, using more representative information helps to boost the active learning performance. In german, the samples may have more complex distribu-tion, which is more difficult to capture. As a result, it does not help much to focus on the representative information. Though these two experiments show different sensitivity be-haviors of the parameter, we observe that it does not hurt to pay more attention to the representative information for both data sets. We conclude from these experiments that a relatively larger value of  X  is recommended, when there are scarce initial labeled samples. In this situation, we need to pay more attention to the data distribution.
In the active learning literature, both representative in-formation and discriminative information are important for the efficient query. However, they are usually contradictory in the active learning process. Several existing investigation-s [14, 26, 35, 20] show that the representative information is more useful when there is no or very few labeled data; and the discriminative information is more efficient to boost the learning accuracy when there are certain amounts of labeled data, which can train a classifier with good discrim-Figure 2: Performance comparison using different trade-off parameters on breast cancer and german data sets for our BMDR algorithm. Each curve rep-resents the average result of 10 runs. inative capability. Using either information alone may not obtain the best performance during the entire active learn-ing process. In the ideal case, the most efficient active learn-ing method should pay more attention to the representative samples when there are very few labeled samples, and focus on finding the most discriminative sample to label when the representativeness of the queries decays rapidly.
In this paper, our method accomplishes this goal by prop-erly using those two kinds of information. In the beginning phase, there is no or very few labeled samples, and the em-pirical risk for the labeled samples is negligible in the op-timization objective. In such situation, our method is very similar to the pure representative active learning methods [11, 35]. When the number of labeled samples increases, the discriminative information plays a more and more importan-t role during the queries. When there are sufficient labeled samples, the query of new samples has less effect on the la-beled data distribution. The discriminative information be-gins to play the dominant role. The method becomes more similar to the most discriminative active learning method [20]. With this mechanism, our method naturally balances the effect of the two kinds of information, and makes its queries more efficient.
In this paper, we generalize the empirical risk minimiza-tion principle to the active learning setting and propose a novel active learning method. In our method, we query the samples which are expected to rapidly reduce the empiri-cal risk, and preserve the original source distribution at the same time. This enables our method to achieve consistent good performance during the whole active learning process. We also propose a practical batch mode active learning al-gorithm which is solved by alternating optimization. The superior performance of our method is verified by our ex-tensive evaluations using benchmark data sets, compared with the state-of-the-art batch mode active learning meth-ods. We observe from our experiments that it is beneficial to update the trade-off parameter which balances the dis-criminative and representative information during the query process. We plan to develop an adaptive mechanism to tune this parameter automatically, similar to [32]. This could make our active learning framework more practical. In ad-dition, we plan to extend our method to the semi-supervised learning and multi-class learning settings. This research is sponsored in part by NSF CCF-1025177, NIH LM010730, and ONR N00014-11-1-0108. [1] N. Abe, B. Zadrozny, and J. Langford. Outlier [2] P. L. Bartlett and M. S. Rademacher and Gaussian [3] A. Beygelzimer, S. Dasgupta, and J. Langford. [4] J. C. Bezdek and R. J. Hathaway. Convergence of [5] K. M. Borgwardt, A. Gretton, M. J. Rasch, H.-P. [6] S.Boyd,N.Parikh,E.Chu,B.Peleato,and [7] C. J. C. Burges. A tutorial on support vector [8] C. Campbell, N. Cristianini, and A. J. Smola. Query [9] C.-C. Chang and C.-J. Lin. Libsvm: A library for [10] O. Chapelle, B. Sch  X  olkopf, and A. Zien, editors. [11] R. Chattopadhyay, Z. Wang, W. Fan, I. Davidson, [12] D. A. Cohn, Z. Ghahramani, and M. I. Jordan. Active [13] F. d X  X lch  X e Buc, Y. Grandvalet, and C. Ambroise. [14] S. Dasgupta. Two faces of active learning. Theoretical [15] R. M. Dudley. Real analysis and probability . [16] A. Frank and A. Asuncion. UCI machine learning [17] Y. Freund, H. S. Seung, E. Shamir, and N. Tishby. [18] A. Gretton, K. M. Borgwardt, M. J. Rasch, [19] Y. Guo. Active instance sampling via matrix [20] Y. Guo and D. Schuurmans. Discriminative batch [21] S. C. Hoi, R. Jin, J. Zhu, and M. R. Lyu. Batch mode [22] S.-J. Huang, R. Jin, and Z.-H. Zhou. Active learning [23] Y. Koren. Factorization meets the neighborhood: a [24] H. T. Nguyen and A. Smeulders. Active learning using [25] N. Roy and A. McCallum. Toward optimal active [26] B. Settles. Active learning literature survey. Computer [27] H. S. Seung, M. Opper, and H. Sompolinsky. Query by [28] B. K. Sriperumbudur, A. Gretton, K. Fukumizu, [29] M. Sugiyama. Active learning in approximately linear [30] S. Tong and D. Koller. Support vector machine active [31] V. Vapnik. Statistical learning theory . Wiley, 1998. [32] Z. Wang, S. Yan, and C. Zhang. Active learning with [33] M. K. Warmuth, G. R  X  atsch, M. Mathieson, J. Liao, [34] Z. Xu, K. Yu, V. Tresp, X. Xu, and J. Wang.
 [35] K. Yu, J. Bi, and V. Tresp. Active learning via [36] X. Zhu, J. Lafferty, and Z. Ghahramani. Combining
Proof. Following [18], we know that the relationship be-tween the true MMD and the empirical MMD is Pr MMD[ C ,p ( x ) ,q ( x )]  X  MMD  X  ( S, Q )  X  +2( M n +  X  2 e with the empirical MMD term given by
In the active leaning scenario, Q  X  S and q  X  n .Wehave and Then
Pr MMD[ C ,p ( x ) ,q ( x )]  X  MMD  X  ( S, Q )+ +4 M n
Let 2 e  X  From the analysis in Section 2, we know by the classic ERM principle that E D ( l ( f ( x ) ,y ))  X   X  E Q ( l ( f ( x ) ,y )) + MMD[ holds with probability at least 1  X   X / 2.

Combining all the results above, we show that with prob-ability at least 1  X   X  , the following holds: E The function complexity term is C (
L ,q, X  )=2 R q ( L )+ ln (2 / X  ) It can be rewritten as: where c is a constant.
