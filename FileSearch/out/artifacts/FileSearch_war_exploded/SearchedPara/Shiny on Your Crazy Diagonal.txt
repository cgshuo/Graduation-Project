 In this demo, we present a web application which allows users to interact with two retrieval models, namely the Bi-nary Independence Model (BIM) and the BM25 model, on a standard TREC collection. The goal of this demo is to give students deeper insight into the consequences of mod-eling assumptions (BIM vs. BM25) and the consequences of tuning parameter values by means of a two-dimensional rep-resentation of probabilities. The application was developed in R, and it is accessible at the following link: http://gmdn.shinyapps.io/shinyRF04 .
 H.3.3 [ [Information Search and Retrieval ]: Retrieval Models; D.2.8 [ Software Engineering ]: Metrics X  complex-ity measures, performance measures Theory, Algorithms, Experimentation Probabilistic Models, Bayesian Inference, Text Retrieval
The Binary Independence Model (BIM) has been one of the most influential models in the history of Information Retrieval [3]. It is a probabilistic model that considers doc-uments as binary vectors and ranks them in order of their probability of relevance given a query according to the Prob-ability Ranking Principle [2]. The Okapi BM25 model goes one step further by taking into account the frequencies of the terms and the length of the documents. These two models are easy to train and reach satisfactory results even with standard default parameters. The optimisation of the pa-rameters can be performed by means of machine learning approaches; nevertheless, this process may be computation-ally demanding and only lead to partial improvements [6].
In this demo, we want to study the problem of the optimi-sation of the parameters of the two BIM and BM25 models by means of an interactive visualisation approach based on the idea of Likelihood Spaces [5], a two-dimensional repre-sentation of probabilities. We have developed a web appli-cation which allows users to be directly involved into the process of the optimisation of the retrieval function in a real machine learning setting. The goal of this demo is to give students deeper insight in the consequences of modeling as-sumptions (BIM vs. BM25) and the consequences of tuning parameter values. As a showcase, we used the TREC2004 Robust test collection (528,155 documents and 250 topics). We added to the original collection a pseudo-relevance feed-back set constituted by the top 100 documents obtained by a  X  X tandard X  BM25 approach for each query. For the online version of this demo, we used a sample of the collection in order to make the application usable. In particular, we built the training/validation sets by using all the pseudo-relevant feedback documents of the BM25 and the test set with all the relevant documents of the pool.
The BIM ranks documents according to the probability of relevance ( R = 1) given a document d and a query q , P ( R = 1 | d,q ). The logarithm of this probability can be approximated by (see [4] for the details of all the passages): where w i is the relevance score of the term t i , defined as where p i is the probability that a relevant document contains the term t i , while q i is the probability that a non-relevant document contains the term t i . The estimates of p i and q are smoothed with two parameters  X  and  X  to avoid zero probabilities (by default,  X  =  X  = 0 . 5, see [1]). The BM25 model has the same form of Eq.1 by replacing w i with w 0 where tf i is the frequency of the term t i in the document, k 1 and b are two parameters (usually set to 1.2 and 0.75, respectively), dl is the length of document d , and  X  is the http://trec.nist.gov/data/t13_robust.html average document length. Eq. 3 derives from [4] (in this formulation, ( k 1 + 1) is not present in the numerator).
In the two-dimensional representation of probabilities, we keep P ( R = 1 | d,q ) distinct from the probability of a docu-ment being not relevant P ( R = 0 | d,q ), and we order docu-ments according to the difference: With two more parameters M and Q , we define a decision line y = Mx + Q (see the details in [1]): This formulation allows us to study the problem on a two-dimensional space where documents are represented by two coordinates x and y and ranking is performed by the line Mx + Q  X  y .
The application has been developed in R using the Shiny package, an R package that makes it easy to build interactive web applications straight from R. 2 The main window of the application is split into two parts, see Fig. 1: on the left side, the user can interact with the retrieval models and see the results on the right side in terms of both the performance of the retrieval and the visualisation of the coordinates. Interaction : (1) The user chooses the topic of interest from the drop-down menu, and the query is shown in the text area. (2) The user selects the retrieval model (if BM25 is not selected, the BIM is on), the pseudo-relevance feedback is used (default is on), and whether the sum of Eq. 5 of the probabilities is computed over the selected features (4) or over the query terms. If BM25 is selected, the parameters k and b can be adjusted. (3) The parameters  X  and  X  are used to smooth the probabilities p i and q i . (4) The fourth part focuses on the machine learning approach to the problem: select the number of folds k and the number of features we need to train the retrieval model. By default we have a five-cross validation and the top 50 features selected according to the difference p i  X  q i . The user can change the ranking line by adjusting the two sliders Angular coefficient M and Intercept Q . The default values are 1 and 0, respectively, which correspond to a zero-one loss function. When these parameters are changed, a green line remain fixed in the position of the zero-one loss function for comparison. Visualization : The right panel is divided into two columns: (6) shows the results on the validation set, (7) the results on the test set. Both columns contain the following pieces of in-formation (from top to bottom): (i) The text box shows the total number of objects used for validation and the number of positive examples (red points, the pseudo-relevant docu-ments of the chosen topic). The box in the validation column also tells the user in what fold we are validating. (ii) The table shows performance measures in terms of precision-at-j (j = 5, 10, 20, 100, 500, 1000). (iii) The two-dimensional plot shows in red the relevant documents of the chosen topic (pseudo-relevant for the validation fold, true relevant for test set) and in black all the other documents of the collection. http://shiny.rstudio.com/ 1 2 3 4 5 Figure 1: Web application developed in Shiny.
 The blue line changes according to the parameters selected in (5) while the green line remains fixed to the bisecting line of the third quadrant.
In this demo, we have presented a Web application devel-oped in R which allows users to interact with two retrieval models, the BIM and the BM25 models, on a standard TREC collection. The probabilistic models are visualised on a two-dimensional space based on the idea of Likelihood spaces. The interactive application shows, in a real machine learning setting, how the human pattern recognition capa-bilities can immediately detect whether the model is close to the optimal solution or not. In theory, a classical fully-automatic machine learning approach that searches the best combination of parameters can find the optimal solution [6]. However, the number of possible combinations of the val-ues of the parameters grows exponentially with the number of the parameters; consequently, this interactive approach may be a crucial step in setting the initial parameters of the function that optimises these parameters automatically. [1] Giorgio Maria Di Nunzio. A new decision to take for [2] S. E. Robertson. The Probability Ranking Principle in [3] Stephen E. Robertson and Karen Sparck Jones.
 [4] Stephen E. Robertson and Hugo Zaragoza. The [5] Rita Singh and Bhiksha Raj. Classification in likelihood [6] Andrew Trotman, Antti Puurula, and Blake Burgess.
