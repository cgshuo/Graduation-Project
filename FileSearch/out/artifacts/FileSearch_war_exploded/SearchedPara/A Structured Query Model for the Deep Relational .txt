 The deep web is very large and diverse and queries evaluated against the deep web can provide great value. While there have been attempts at accessing the data in the deep web, these are clever  X  X ne-of X  systems and techniques. In this pa-per, we describe an ongoing research of a generic structured query model that can be used against the deep web. Using this query model, the contributions of a community of re-searchers can be combined freely, leading to a system that can be improved incrementally each time someone develops a specific novel technique to improve a particular operator. H.2.3 [ Database Management ]: Languages X  Database se-mantics; Query languages Data model; Heterogeneous databases; Data integration Deep web; Schema mapping; Form filling; Recommender systems; Wrappers; Entity resolution; Declarative querying; Query processing; Extended operators
Recent research show that the deep web [9] is several hun-dred times larger [23] than the shallow web [16] (see [23] for a discussion on the distinction between the shallow and deep web databases). The bulk of recent research on query-ing structured web contents has focused on exploiting either the exposed tables in the form of indexable documents, or somehow exposing the contents first and then using a tradi-tional method to query them. Among them, the relational web approach [3] aims to locate, extract, and manage a large  X 
Researc h supported in part by US NSF grants IIS 0612203 (for Hasan Jamil) and IIS 1250880 (for H. V. Jagadish). number of tables contained in already indexed documents in shallow web. In approaches like this, searching [8, 17] and harvesting [1, 7] tables in shallow web are used as key mech-anisms. Algebraic query languages were also proposed to manipulate harvested tables in the context of data integra-tion [2]. A complementary approach in querying deep web contents has been devising methods to actively expose the tables (e.g., [25]) based on predicted use, and then querying the exposed contents using conventional techniques.
While such harvesting-based systems can be valuable in specific domains, they suffer from two major drawbacks. First, much deep web content has proprietary value for its owner, who may not be willing to have it harvested and ex-posed [26]. Second, the sheer scale of the deep web makes a generic harvest of all deep web data a truly daunting ven-ture. For these reasons, we do not consider harvesting-based systems further in this paper.

The alternative is to access the deep web contents that are  X  X elevant X  and  X  X ermissible X  in the context of a query in a dynamic fashion at run time so that we are not re-quired to harvest or index them ahead of time. While there have been notable attempts in this direction (e.g., [10, 15, 18]), these do not establish a reusable general framework with which a community can jointly advance the field. For example, MetaQuerier [10] uses interface clustering to facil-itate query mapping for data integration. In contrast, our vision is to have a decomposable deep web querying sys-tem framework capable of accepting the most capable im-plementations for each module. For example, the interface identification task could be performed by a recommender system. To enable such a clean modular approach, we de-velop a high level abstraction and express it in terms of a declarative language and foundation. Through these means, various independently developed deep web technologies can synergistically come together at the implementation level. While challenges remain, we show that such a model and architecture is entirely feasible today by suitable adaptation of recent research in this area.
By means of a running example, we establish the main intuitions behind our proposal in this section.
 Necessity of Structured Search Over the Deep Web. Search engines today use keyword based querying. This is insufficient for the deep web. To illustrate this, consider Nina, who is searching online for a car. She has a rough idea of what she wants to buy  X  a fairly new Honda Civic for a price less than $15,000, preferring red trim with aluminium allo y wheels. She formulates her query Q D in an SQL-like language, called d eep web q uery l angua ge (DQL), as follows: Notice in this query that although she prefers a red car, she did not mention it as a condition to avoid being overly re-strictive. If this query was issued against the view CarView defined over a structured database with a scheme as shown in figure 1 as the SQL query Q below, she would have had a concrete response, i.e.,  X  $ 14,850, blue, 2011, Lone Star, MI  X  . However, it is well known that had she submitted the DQL query Q D directly on any contempo-rary search engine, we would not actually get any meaningful response other than possibly links to a few top ranking car sales web sites including www.lemonfree.com for used car sales site and Wikipedia page for Honda Fit as top hits. Black-Box abstraction through Deep Web Interfaces. Consider a trivial deep web database comprising a single site, such as cars.com . Nina could issue her query through a web form provided by this web site. This web form would al-low her to express various query conditions over the scheme of CarView . For many reasons (including security concerns), the form entries and variable names are usually different from the scheme of the view. Upon submission of the form, a well-formed SQL query is created, reflecting user constraints over the view and executed against the back-end database, in this instance the view CarView . The response is returned possibly in the form of a table in an HTML document for presentation purposes in which the scheme is transformed and variables renamed. This black-box model essentially helps hide the database structure and details of the view, captures an input-output behavior, and though limiting, ob-viates the need for a query language.
The question we would like address in this paper is: Is it possible for Nina to submit her query Q D in some system that will scour the web to compute a response that will include the tuple  X  $ 14,850, blue, 2011, Lone Star, MI  X  the deep web  X  X atabase X  that includes the site cars.com ? Absence of an Explicit Schema for Querying. Nina is using her home computer and is interested in accessing multiple databases across the web. She does not know what schema any web site may have, and is not interested in such information. Instead, she  X  X magines X  a CarView table, and expresses her query against this imagined schema. Note that she does not have to express this schema explicitly anywhere. Rather, this schema is implicit in her mind as she writes the query. The query itself is semantically interpreted with respect to this imaginary schema.

In general, this implicit schema could be complex. In this paper, we restrict our attention to single table schema for two reasons. First, joins are very hard for naive users to think through  X  even if the actual database is decomposed, it is easiest for users to think in terms of a single-table view [14]. Second, the technical challenges in achieving this vi-sion are already significant for single table views, so it is reasonable to leave the more complex cases to future work. DQL as a subset of SQL. SQL is a powerful language with many valuable features. We model DQL after SQL. Since there is an implicit schema against which DQL queries are written, there is no FROM clause. Therefore, a basic DQL qery would only have a SELECT clause and a WHERE clause. To make DQL easy to distinguish from SQL, we use the keyword LIST rather than SELECT. Nina X  X  query Q
D above, is a LIST-WHERE query. Many important SQL features, such as grouping and aggregation, are easy to add to DQL as are most types of nesting. For lack of space, we do not consider these enhanced features in this paper. Rather we restrict ourselves to a single-block LIST-WHERE query. Respecting Site Autonomy. Many deep web databases have proprietary value and will only allow limited access through form-based query interfaces. Therefore, the job of the deep web query processing engine is to take the DQL query input (either directly by the user or through some facilitating interface), evaluate the query against multiple sites, using their exposed form-based interface, and then to return results, after suitable composition, back to the user. Figure 2 depicts the overall architecture of our model.
Algebraic operators customarily have defined input-output behavior over a crisp database scheme. The challenge is to defin e query operators that have defined input-output be-haviors but no  X  X xplicit X  database scheme. Since each site is a black-box, and the only behaviors visible are the input form conditions and scheme of the output table, the visible scheme of a site must at least be the union of all the at-tributes in the form and the returned table. The implicit database scheme R thus is the union of the set of deep web form schemes. Naturally, the attributes A  X  appearing in the where clause and A l in the list clause in query Q D , called the query scheme Q S , must be a subset of R , i.e, A  X   X  A l
We overcome this challenge by dynamically supplying a tentative scheme to an operator, and the query succeeds if the supplied scheme sufficiently matched the query scheme, i.e., A  X   X  A l  X  R is satisfied. In order to define operators we have in mind, we proceed in four intuitive steps. Site Selection. First, we make an educated guess and choose a set of query forms I that we believe adequately captures the conditions in the query Q D . We capture this process as a function  X  to model our recommender compo-nent in figure 2 such that  X  : 2 C  X  2 I  X  2 I where W is the set of indices of all shallow web pages, I  X  W is the set of indices for all web form pages, and C is a set of terms, tags or key words that can be used to identify a relevant set of web forms that are likely candidates to execute our query. Ideally we would like these forms to have entries cor-responding A  X  only and the pages they return to have tables with attributes A  X  A l . The research in the area of recom-mender systems (e.g., [12, 27]) is particularly relevant and we propose to choose  X  as an adaptation of one such system. Schema Mapping and Form Filling. Second, we map the query condition  X  on the form entries using an enhanced schema matching system (e.g., [21]), and if a match is estab-lished, we use an automatic form-filling system (e.g., [24]) to submit the query.
 Table Extraction. Third, the response table is extracted using a suitable wrapper (e.g., [6]), a match is established with the required fields using a schema matcher and only the needed sub-table is retained. We throw away the response if the combination of the form input and the output scheme does not adequately match the  X  X uery semantics. X 
The last two steps above are abstracted in the form of an operator in our language. We adapt the approach of Data Mapper [5] and parameterize relational operators with user selectable functions so that operator behavior can be tailored according to the functions supplied. Parameterization also help encapsulate the complex behavior needed for our first deep web operator called transform that submits the queries, and extracts responses from supplied web sites as described above. Formally,
Definition 1. Let  X   X   X  be a schema matching func-tion,  X   X   X  be a wrapper function,  X   X   X  be a form-filling function,  X   X  I be a deep web query form, and Q D be a DQL query with a query condition  X  over the query scheme A  X   X  A l . Then, the transform operator  X  is defined In the above definition, a query form is treated as a function, which is supplied to a form-filling function  X  along with a matcher  X  . The response of  X  and the matcher is then piped to the wrapper function  X  for the extraction of the target table. The extended projection operator  X   X  A [13]) is then applied to generate the query response. In-tuitively,  X  in  X  is the where clause condition, A l is the list clause attributes, and the scheme of  X  is the implicit scheme (say R ) of query Q D which becomes concrete once  X  estab-lishes the schema correspondence satisfying A  X   X  A l  X  R . Output Processing. Finally, we gather and return all  X  X alid responses X  X rom all the relevant sites in  X  (  X   X  A single table. However, the output scheme may vary from site to site even though the query forms are sufficiently similar, and sites may represent semantically similar objects differ-ently, requiring novel data integration. We use the combine operator  X  [13], introduced in the context of semantic data integration, discussed next for this purpose.
The nature of partial schema matching, and the heteroge-nous structure of the relations gathered are likely to render a straightforward union of the responses into a single table r impossible. To overcome this hurdle, we propose to adapt the binary operator combine (  X   X , X  ) [13] that takes two rela-tions with heterogeneous schemes, a schema matcher  X  and a key discovery function  X   X  X  [22] to return a outer union in which duplicates are removed based on object identifi-cation in addition to schema matching. Using this oper-ator, we combine the relations iteratively for all the sites  X   X   X  (  X   X  A l , I ).

The transform and combine operators, in conjunction with the recommender system modeled as the function  X  , are suf-ficient to assemble a query processing engine to process DQL queries using the high level architecture presented in figure 2. The transform operator (  X  ) uses functions for schema matching ( X ), wrapping ( X ), and form filling ( X ); the com-bine operator (  X  ) uses the key discovery ( K ) function.
Intuitively, Nina X  X  query Q D can now be computed, with the help of an iterator function sion r  X 
Even though technology exists today to construct a deep web querying system, it can benefit from renewed research on several different fronts, a few of which we suggest below. Form Recommendation and Query Splitting. When sufficient mapping cannot be established for a DQL query, it can be split to push constraints to the wrapper with the anticipation that the constraint can still be met on the re-sponse table. That is, we consider query relaxation where we return a response r  X | = Q D such that  X  r  X  ,r  X  | = Q Additional opportunities exist to model similarity as a func-tion of the user or DQL query context [20]. For these pur-poses, recommender systems and form filling functions can be enhanced to consider DQL-like structured queries to map query constraints to query forms with a notion of X  X dequacy X  along the line of [10].
 Query Subsumption. The black-box model and the pri-vacy concerns of sites requires that we always choose sites
Here, w e assume that the iteration starts with an empty table r and combined with each extracted table returned by  X  over all  X   X   X  (  X   X  A l , I ). Also, when the matcher, wrapper, form-filler and key discovery functions are fixed and known, we can write these two operators simply as  X   X   X ,A to execut e our queries whose interface constraints subsume the query constraints in the sense of constraint subsumption [19] and query rewriting. More research is needed to flesh this out.
 Table Extraction. While many wrapper systems work fine, they cannot be customized to extract only the required sub-tables. Often the heuristics used miss extracting in-tended tables. We believe the query scheme and schema matchers together can be used to better identify target ta-bles, even when objects are spread across multiple tables in the response page. Unannotated tables pose another dimen-sion of challenge that needs to be addressed as well. Schema Expansion. The combine operator has a potential to extend the response scheme when tables from disparate sites are consolidated. Although the query scheme should help guide the pruning, we would prefer to allow a degree of expansion to retain search engines X  characteristics of ex-ploration and unknown. Since this is an iterative process, new and more interesting attributes may appear. The chal-lenge is how to prioritize the selection of columns, and prune when needed. Research is needed to study possible ordering of query forms to avoid such pruning so that we monotoni-cally add more interesting columns, rather than take out. Query Optimization. Optimization of deep web queries is a nascent area of research (e.g., [4]). Having a clean ar-chitecture like ours makes this task less daunting, since all the functions in the proposed operators are independent of one another. The query processor can select the matching, wrapping, form-filling and key discovery functions most ap-propriate for the given query, from among the many possible implementations based on current research. In fact, differ-ent implementations can even be used for different parts of the same deep web query.
We have presented the vision of an ongoing research on the deep web as a virtual database, and proposed a simple query language, DQL, and an algebra for query evaluation. The evaluation algebra divides the task into a set of operators and functions, each of which has a well-specified interface and can be implemented as an independent module. While the black-box model of deep web database content poses sig-nificant barriers toward its declarative and structured query-ing, we proposed a system model with the belief that clever and novel adaptation of existing technologies can overcome this limitation. We have identified ongoing research as well as mature systems that can be leveraged and integrated to form the backbone of the envisioned system. Our hope is that the research community will contribute vigorously to-ward this larger vision of harvesting the enormous wealth of deep web information using a semantically rich, declarative and convenient query language.
