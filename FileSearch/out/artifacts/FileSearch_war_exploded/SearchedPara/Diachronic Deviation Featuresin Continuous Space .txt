 Representation of words as dense, real-valued vectors can be trained via a neu-ral network language model[1, 7]. It has been shown that these distributed rep-resentations of words can be used to improve the performance of many NLP systems[3].
 do not consider the concept of diachronicity, i.e. the change of the semantics of the words through different time periods is not taken into account. In this paper, we devised a feature vector that represents the semantic variation of a word in a diachronic corpus.
 jection between vector spaces of words that represent different languages. We adopt the idea to vector spaces of words that represents texts of different time periods. Word embeddings learned from different time periods are projected to the same vector space (target space). all the projections in the target space. The deviation feature vector drawn from this distribution reflects the stability of the semantic of this word in a diachronic corpus. Experiments showed that these deviation features can be used in mining hot topics in different ages.
 of the mapping of different vector spaces. Section 3 illustrates our diachronic de-viation feature vector, and its use in topic clustering. In Section 4, evaluations are presented to illustrate the effectiveness of the diachronic deviation feature, and the application of the topic cluster is also presented. The final section concludes this paper and discusses possible future work. Given a diachronic corpus, we seek to split it into diachronic sections, under the assumption that each section is synchronic. For each section a distributed representation of words is trained via the method proposed by Mikolov et al. [7]. Then, by analogy of the method proposed by Mikolov et al. [8], a linear serves as a transformation that transforms all spaces to a uniform one. The symbols used in this section are described below: 2.1 Splitting the Diachronic Corpus A sliding-window based scheme is used to split the diachronic corpus. The split-ting is dependent on two variables: window size and window increment. For example, in Figure 1, the window size is 5 years and the window increment is 1 year.
 be split into multiple (46 here) segments, in which each segment contains a time-consecutive portion of the original corpus, while large enough to train a re-liable distributed representation of words. Additionally, overlapping of the slices, instead of using disjoint slices, produces more samples. 2.2 Training the Linear Projection In order to observe the representation of words over different time periods, a liner transformation is used here to project all the different vector spaces into a target space.
 achronic corpus using the neural network model. We seek to transform each vector space of a time period ( source space ) to the target space. This problem is formulated below: representations in two time periods find a transformation matrix T st such that T st x ( w,s ) approximates x ( w,t ). in the source space to the target space by computing ent languages Mikolov et al. [8], and it performed effectively in our experiments as well. 2.3 Generating the Training Data Set One of the key problems that influence the result of the transformation matrix is the proper choice of the training set. In this section we focus on how to build an appropriate training set for the optimization problem stated above, i.e. a set of words with their associated vector representations in two spaces.
 desired. To avoid overfitting, the size of this set should be relatively small. In our experiments 100 words are selected for both Chinese and English corpus. First, we build this training set beginning from a randomly selected set. Initial transformation matrices are trained from this initial training set with the target space. Then word whose variances of the error between the actual representation and the predicted representation are lowest is selected. In Algorithm 1, the target space is numbered 0.
 two diachronic corpora: one in Chinese ( People X  X  Daily ) and one in English ( New York Times ).
 contains conjunctions and adverbs or some common concepts in both Chinese and English. The semantics of these words are mostly stable in diachronic cor-pora, thus serving as a good training set for the training of the linear transfor-mation model over time periods. From the linear transformation procedure described above, for each word w , we have a set of vector representations drawn from different time periods all projected to the same space, namely This set of vectors S ( w ) is fit to a multidimensional Gaussian distribution, namely the diachronic representation distribution N (  X  w ,  X  w ).
 the representation space are mutually independent. Thus, the covariance matrix  X  w is reduced to a diagonal matrix. We define the deviation features as the variance of each dimension: where D is the dimensionality of the vector space. A min-max scaling is per-formed on these features: diachronic deviation feature vector. In this section, we demonstrate that clustering result of words using the di-achronic deviation feature vectors is correlated with time-specific topics. 4.1 Corpus and Experiment Settings Experiments are conducted on one Chinese real-word corpora: People X  X  Daily of 50 years (from 1947 to 1996). ICTCLAS[9] is applied to segment the raw text. Window size is 5 years and window increment is set to be 1 year. Each text slice contains approximately 30 million words.
 Mikolov et al. [7]. The dimension of the vectors is set to be 50. The target vector space is trained by the entire corpus. The words used for clustering are words that are prevalent in every time slice; i.e. the number of occurrence of a specific word in any time slice is greater than a minimum threshold. The actual number of words for clustering is approximately 10000. 4.2 Clustering A diachronic deviation feature vector is generated for each word using the method described in Section 3. We use the cosine similarity measure as the similarity measure between the feature vectors. And we used the hierarchical word clustering scheme described by He et al. [4]. It uses the hyper-link induced topic search algorithm [5] to produce clusters of words. The number of clusters is determined after the completion of the algorithm, thus it is not necessary for the users to specify the number of clusters. The algorithm is shown below. seen that the produced clusters are largely correlated with topics instead of synonyms. Namely, The words in the same cluster have a tendency to occur in period. 4.3 Case Study on People X  X  Daily In this section we present the experimental results on the Chinese corpus People X  X  Daily (from 1947 to 1996). Table 4 is a cluster generated using the method described in Section 4.2.
 concerning with exploiting class and revolution. The normalized frequency of these terms in the entire diachronic corpus is illustrated in Figure 2, where the abrupt change of frequency can be noticed around 1967.
 the terms have a tendency to occur in a specific time period. Then we choose the year(1967) with the highest frequency of these terms, and run a latent Dirichlet allocation (LDA) [2] on it to observe the topic distribution of these terms. in LDA with the highest probability. We count the word number for each topic, and the relation between the frequencies of words with respect to the topics generated by LDA is shown in Figure 3. The terms in this cluster concentrates heavily on topic 17, 29, and 83. The words in those corresponding topics are shown in Table 5. we could obtain clusters of hot topics. In this experiment, we found out that a generated cluster may correlate with several inter-related topics in LDA. Topic 17 talks about the armed partisanship revolution in China, topic 29 is about a political trend of anti-capitalism ideologies and topic 83 is about the military operations in other countries besides China. And the topic 6, 27 and 42, which the cluster also concentrated, are similar to these political topics. All these topics reflect the specific social background in that age. 4.4 Topic based diachronic analysis of social change digitized texts containing about 4% of all books ever printed[6]. By tracking the usage frequency of words picked carefully in different years, they highlight that the cultural change guides the concepts we discuss (hot topics). An example is shown in Figure 4, in which they plotted the median frequency in German over time for five lists of names and a collection of Nazi party members(547 names) to probe the impact of censorship on a person X  X  cultural influence in Nazi Germany. age of peak celebrity of some topics and study the human culture. While these special words were chose manually in Michel X  X  work[6], by our deviation features and clustering method, the clusters with words belong to a same topic were generated automatically. With this method, the topic based diachronic analysis of social and culture change is more effective then.
 As this cluster of exploiting class and revolution was active before the founding of the People X  X  Republic, it had relatively high frequency. And the frequency of it peaked in 1967, which is the beginning of the Cultural Revolution. Since the Cultural Revolution eulogized revolutionary violence, and some claustrophobic restrictions was proposed, the political-related topic developed. After this pe-riod, with the reform and open policy carrying on, the revolution and military operations stepped down from the stage of history so that the frequency declined gradually.
 art. Its frequency was low during the war years but soared since the founding of PRC (1949), and retained high for nearly 20 years, but then underwent a rapid decay in 1967 reversely, dropping the bottom over 10 years. And returned to the average level before 1967. This is because the artistic creation was signifi-cantly influenced by ideological factors in the Cultural Revolution (1967-1977) but reached its peak accompanying economic development. culture change. This paper proposed deviation features of the diachronic word semantic distri-bution, which represents the stability of the word-meaning over time periods. The word semantic distribution can be learned via linear transformations of the word embedding results generated from the different time periods of text in the diachronic corpora. We demonstrated that the clustering result of words using these deviation vectors is correlated with time-specific topics. The frequency changes of these word clusters can indicate the social and culture changes in history.
 diachronic topic mining or semantic change mining, and it can be also applied to the social linguistics and historical linguistics.
 Acknowledgments. This work is supported by the NNSF of China (grant No. M1321005)
