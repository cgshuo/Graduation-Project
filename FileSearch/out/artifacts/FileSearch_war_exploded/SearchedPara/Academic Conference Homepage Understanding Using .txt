 We address the problem of academic conference homepage understanding for the Semantic Web. This problem consists of three labeling tasks -labeling c onference function pages, function blocks, and attributes. Different from traditional information extraction tasks, the data in academic conference homepages has complex structural dependencies across multiple Web pages. In addition, there are logical constraints in the data. In this paper, we propose a unified approach, Constrained Hierarchical Conditional Random Fields, to accomplish the three labeling tasks dependencies can be well described. Also, the constrained Viterbi algorithm in the inference process can avoid logical errors. Experimental results on real world conference data have demonstrated that this approach performs better than cascaded labeling methods by 3.6% in F1-m easure and that the constrained inference process can improve the accuracy by 14.3%. Based on the proposed approach, we develop a prototype system of use-oriented semantic academic conference calendar. The user simply needs to specify what conferences he/she is interested in. Subsequently, the system finds, ex tracts, and updates the semantic information from the Web, and then builds a calendar automatically for the user. The semantic conference data can be used in other applications, su ch as finding sponsors and finding experts. The proposed approach can be used in other information extraction tasks as well. I.5.1 [Pattern Recognition]: Models  X  Statistical Algorithms, Experimentation Constrained Hierarchical Conditi onal Random Fields, Information Extraction, Semantic Conference Information. The semantic information of academic conferences consists of conference details, such as conference names, paper submission deadlines, sponsors, etc. It play s an important role in academic social networks. Understanding such information by machines can bring interesting applications in the Semantic Web. For example, a user-oriented conference calendar can be built to automatically obtain conference information on the Web according to a specific conference list users are interested in. Also, from the information about sponsors and topics of diffe rent conferences over years, we can know the history of research interests of certain companies, which can be used to find sponsors for new conferences or to predict the development directions of the companies. Furthermore, memberships of program committees and topics of a conference can be used to help find paper reviewers or experts in certain areas. Unfortunately, conference information understanding is still an unsolved issue. Previous work ha s extracted some attributes from call-for-paper (CFP) texts. This approach suffers from the following disadvantages: 1) It is not always easy to find CFP text for every conference. Even though some Websites such as  X  X B-world X  (http://www.cs.wisc.edu/dbworld) provide conference CFPs, they usually cover only conferences of interest of the group. For instance, we could find textual CFPs for only 40% of the top (http://citeseer.ist.psu.edu/impact.html). 2) Plain texts of CFP lose the format and structural inform ation, which can highly improve information extraction result. 3) Not all the conference information is contained in C FP. In our statistics about 1000 conference CFP pages, less than 10% provide sponsor information; in addition, update d deadlines can not be timely reflected in CFP documents. In general, conference information is provided in conference homepages, which leads us to extract information directly from Websites. Based on our statistics about 293 conferences held from 2004 to 2008, over 96% of conferences have homepages, providing necessary information. All homepages contain format and structural information. Comp ared with previous Web data extraction tasks, extracting information from conference homepages has two new features: 1) Strong structural dependencies exist across multiple Web pages. For instance, program committee members are listed in the program committee block, and this block usually appears in the program committee page and sometimes also in the call-for-paper page. Figure 1 shows the ontology we have defined for conference homepages. Conference attributes are distributed in different function blocks and these blocks are distributed in different function pages 2) Some logical cons traints exis t in conference inform ation. F or example, paper deadlines should be earlier than conference dates. topics block.. Two ques tions aris e for academ ic conference hom epage understanding: 1) How to descri be the complex dependencies am ong multiple Web pages to help label different attributes in different function blocks from f unction pages? 2) How to make the inference results satisfy the logical constraints? This paper addresses these two problems by proposing a Constrained Hierarchical Cond itional Random Fields method. The contributions include: 1) We propose a new unified model -Constrained Hierarchical Conditional Random Fields (CH CRF) -to label conference hom epage inform ation. This approach com bines the ideas of Hierarchical Conditional Random Fields (HCRF) [29] and linear constrained Viterbi inference algorithm [14] . On one hand, it represents the hierarchical struct ure as probabilistic graph; on the other hand, it expands linear constrained Viterbi into a hierarchical structure, and us es the s tructure in the inference process. The model can label the three tasks of function pages labeling, function block labe ling and attribute labeling simultaneously based on comple x hierarchical dependencies am ong m ultiple pages, while satisfy ing the logical constraints. 2) Experimental results in real world conference data have dem onstrated that sim ultaneously labeling the three tasks with the help of hierarchical dependencies to each other perform s better than cascaded labeling using lin ear Conditional Random Fields (CRF) or Support Vector Machin e (SVM) methods by 3.6% in F1-m eas ure. At the same tim e, cons trained inference proces s can avoid logical error, thus im prove the accuracy by 14.3% in F1-meas ure. 3) Based on our approach, we design and implement an interesting Sem antic W eb appli cation prototy pe system -Sem antic Conference Calendar. In contrast to previous work that manually creates a list of upcoming/current and pas t conferences , to build a calendar us ing our s ystem , the us er s imply needs to s pecify what conferences he/s he is interes ted in. The s ystem finds , extracts , and updates the semantic information fro m the Web. We firstly train a SVM clas sifier to identify conference hom epage URLs from search engine (Google) results, given its name and y ear as key words, and then employ our approach to label conference inform ation. The sem antic data obtained by this sy stem can be used in other applications su ch as finding sponsors, etc. The rest of this paper is organi zed as follows : In s ection 2, we introduce related work. In section 3, we formalize the problem of academ ic conference hom epage understanding. In section 4 we describe our approach to the probl em and in section 5 we give the experimental results. Our desi gn and implementation of the semantic conference calendar application is pres ented in sections 6. Finally , we summarize this paper in section 7. Previous works of extracting s emantic conference data are m ainly from CFP texts. [16] used rule-b ased method to extract date and country in conference CFP dataset. [24] employ ed linear CRF another conference CF P datas et with average F 1-m eas ure of 66.4%. Pascal Challenge 2003 pr ovided a common platform for researchers to empirically asse ss methods and t echniques devised for information extraction from workshop CFPs [13] . Participants em ploy ed different m ethods to extract 11 attributes for each workshop. For example, [3] used LP 2 algorithm; [8] used CRF model; [17] used SVM classifiers. The best result is 69.8% in average F1-measure. As discusse d above, the limited CFP source, ignoring of format and structure, and lack of sponsor and updated information, have led it hard to obtain comprehensive and dy nam ic conference inform ation fro m CFP texts. In our work, we obtain conference information di rectly from Web pages, whose inform ation is m uch richer. Many information extraction methods have been proposed. LP [3] , Hidden Markov Model (HMM) [10] , Maximum Entropy Markov Model (MEMM) [19] , linear Conditional Random Field (CRF) [11] [15] , Support Vector Machines (SVM) [6] , and Voted Perceptron [5] are widely us ed inform ation extraction m odels. Some of the methods only model the distribution of contexts of target instances and do not model dependencies between the ins tances , for exam ple, S VM and Voted Perceptron. Some other methods can model the linear-chain dependencies, for example, HMM, MEMM, and linear CRF. In our work, we employ LP SVM, and linear CRF as our ba seline methods since these are most widely used in traditional inform ation extraction tasks. Conditional Random Fields is a state-of-the-art probabilistic model for information extraction. It is first proposed by [15] for segm ent and labeling sequences data. Due to effectively utilizing dependencies of elements, it is wide ly used and developed such as Multi-scale CRF [12] , Sem i-CRF [ 23] , 2D-CRF [28] , TCRF [26] , HCRF [29] . In this work, we have im plem ented a Hierarchical Conditional Random Fields (HCRF) tool, while combining constrained Viterbi algorithm in inference. Constraints exist in m any labeling tasks, adding which into the model will im prove labeling resu lts. Kristjansson proposed linear constrained Conditional Random Fields in [14] . By using a constrained Viterbi decoding in th e reference proces s, the optim al fields assignm ent, which is consis tent with som e fields explicitly specified or corrected by the us er, can be found. Both assignment and features can be cons trained in a local way . However, constraints can not be relation of two distant tokens. [22] proposed Integer Linear Programming Inference process for linear CRF, in which distant constraints of nodes can be dealt with. In [22] , constraints were relaxed to ones that can be described in a linear constraint equation with the assignm ent of each node as variants. However, features cannot be constrained in this method. In our approach, we have expa nded constrained Viterbi decoding from linear s tructure to hierarchical s tructure and s hown how to describe three kinds of constraints in this application. Several research efforts have been made so far for providing semantic calendar s ervices . F or example, [20] developed the RETS INA Calendar Agent (RCAL), which could collect event information from schedules like conference programs published on the Semantic Web. [1] deve loped OntoWiki. The sy stem provides different views on knowle dge database. Calendar is one of the major modules in their sy stem. [9] implemented a sy stem called  X  e-W allet X  aim ing at pr oviding Semantic Web Services including calendar. The main diffe rences of their works from us are that their s ystem s are bas ed on exis ting s emantic conference data. However, there is not much of semantic data on the Web. On the contrary , our sy stem focuses on using information extraction techniques to generate sem antic data autom atically from the Web. Previous works in Web data extraction [29] have shown that understanding. Version-tree is gene rated by a Vision-based Page Segm entation (VIPS) algorithm [2] , which utilizes form at and structure inform ation in htm l file to partition W eb pages into blocks. In a version-tree, inner nodes represent data blocks, leaf nodes represent atomic units (e.g. element), and root represents the whole page. For conference data, different fro m previous Web data extraction works, inform ation is distributed in m ultiple pages rather than a single page, and structure depende ncies occur acros s thes e pages . Figure 2 gives an example of c onference root hom epage and its linked function pages. To desc ribe such kind of complex dependence information, we propos e to combine version-trees of different pages together with the root page. Figure 3 gives conference data repres entation in a com bined vers ion-tree. Here, triangles denote function page nodes, rectangles denote inner data block nodes, and ellipses denote leaf nodes. Blocks denoted by dotted are not fully expanded. We do not expand links in function pages. Our statistic study shows less than 5% inform ation is in these pages. 
Figu re 3. Con f. rep res entation in comb ined vers ion -tree. To understand academ ic conference hom epage, three sub tasks are defined based on combined ve rsion-trees: 1) Function pages labeling: As many function page s exis t in conference W ebsites , classes. 2) Function blocks labeling: In conference Web page, detailed inform ation usually occurs in a structured data block. For exam ple, different deadlines occur in  X  X mportant Dates X  block. It is natural to label these blocks , and m eanwhile, these blocks will bring more structure dependence information to the model, improving the results. 3) Attributes labeling: Attributes labeling is labeling the elem ents in the W eb page. The label s paces of thes e three kinds of nodes are shown in Table 1. Blocks Attributes According to analy sis of conference hom epage data, three kinds of logical constraints among the information are defined. 1) Label space constraints: The label space of current node is constrained with the label of its parent. For example, if parent X  X  label is  X  DatePg X , the label space of current node is restricted to: if it is a block node, the label can be  X  X nnerDPg X ,  X  X ameB X ,  X  X ateB X , other labels like  X  X opicB  X ,  X  X cB X  should not be chosen; others like  X  X ocation X  or  X  X c X  can not be chosen. By doing this, it can enhance the dependence of structure from m ultiple pages into the model. In our work, this kind of constraints includes all parent-child relations generated from Figure 1. 2) Label occurrence frequency constraints: In a combined vers ion-tree, s ome inform ation can only occur once. For exam ple, there is only one call-for-paper page in a conference hom epage; or, in a  X  X ateB X  block,  X  X ubm it X  only occurs once. In our definition, all five function page s ( X  X atePg X ,  X  X cPg X ,  X  X opicPg X ,  X  X ponPg X ,  X  X fpPg X .) can occur once at most in one conference homepage, and all four dates in form ation ( X  Subm it X ,  X  Notify  X ,  X  X am era X ,  X  Date X ) can occur once at m ost in one  X  DateB X . 3) Tem poral cons traints : There are four attributes related to date inform ation:  X  X ubm it X ,  X  X otify  X ,  X  Cam era X , and  X  Date X . Logically , paper submission deadlin e is before notification date  X  X am era X  &lt;  X  Date X . Based on analy sis above, academ ic conference hom epage understanding can be described as labeling three kinds of nodes in com bined vers ion-tree with different labeling spaces , while making the inference satisfy the logical cons traints . W e can us e a unified probabilistic m odel to solve the three tasks above. Formally , referring to [29] , we define the problem as: Given a com bined vers ion-tree of conference data, let x= { x x } be the observations of nodes, and let y= { y possible corresponding labels. The goal is to compute maximum a posteriori (MAP) probability of y , which satisfies the logical cons traints , and extract the as signm ent y* : Relevant to this problem, [29] has proposed a HCRF to describe complex dependencies among Web page, though our case is more com plex as inform ation is distributed in m ultiple level pages rather than one page. However, no constraints are added in this model. [14] has proposed linear constrained CRF to add hierarchical structure. In our m odel, we propose to combine them together to a Constrained Hierar chical Conditional Random Fields model. We build a HCRF mode l to describe the com plex dependence; in addition, we com bine it with hierarchical structured constrained Viterbi decoding in inference to make inference results satisfy the logical constraints, which is expanded from linear constrained Viterbi dec oding. It will be described in detail in next s ection, together with how to em ploy it in academ ic conference homepage understanding. In this section, we firs t introduce how we im plem ent Hierarchical Conditional Random Fields. It is first proposed by [29] and we build a HCRF tool. Then, we explain how to expand linear cons trained Viterbi decoding into a hierarchical structured constrained Viterbi decoding, and how to im plem ent it to describe constraints in academ ic conference hom epage understanding. Finally , we give the features defined. Linear Conditional Random Fields is a conditional probability distribution of a sequence of labels given a sequence of observations, represented as P ( Y | X ), where X denotes the observation sequence and Y the label sequence [15] . The conditional probability is form ulized as: where F ( Y , X ) is feature function vectors defined on cliques of vertices and edges in the linear graph; parameter  X  is feature function weights vector corresponding to each feature function, normalization factor. Like linear CRF, HCRF is a conditional probability distribution of the set of labels given the set of [29] . The probabilistic graphical m odel of HCRF is a hierarchical three kinds of cliques as verti ces, edges, and triangles. Expanding cliques with triangles, conditional global probability can still be formulized as th e formula above. Param eters learning problem is to calculate param eter  X  by maximizing the log-likeli hood from training data D={( x k The optim izing objective function can be written in: 
L log p y | x F y , x log Z x The gradient of the objective function is: 
L Fy ,x E FY,x F y,x p y|x F y,x  X =  X  =  X   X  X  X   X  X  X   X  X  X  In hierarchical graph, according to [7] , for one training s ample, we should first convert the graph to a junction tree, shown in Figure 4 (right). Then, the expectation part can be calculated in: where i denotes clique index,  X  i ( c i ,x k ) denotes clique energy function value corresponding to clique i , including vertex function value, edge function value, a nd triangle function value. Here, clique i is consisted of node i 1 , i 2 , and i Propagation [27] to calculate m arginal probabilities. For a given x ,  X  X essage X  from clique i to j is defined as: wh e r e 1 m c ,x c ,x c ,c ,x m c ,x Then, the m arginal probabilities can be described as following formulas: 
Z x c, x m c, x c  X   X  where w is the norm alization factor, m ij is m essage transferred in reduce over fitting, we define a s pherical Gaussian weight prior over parameters, and penalize l og-likelihood object function as: with gradient: where const is a constant. We us ed gradient-bas ed L-BF GS [18] , which has previous outperformed other optimization algorithms for linear CRF [25] . Kristjansson et al. [14] have shown how to use constrained Viterbi algorithm in linear CRF. We extend this algorithm into hierarchical structure and we show how three kinds of constraints can be solved in this expanded constrained Viterbi algorithm. Viterbi inference process of junction tree is to m axim um messages sending from leaf to root. Here,  X  i ( c i , x k ) can be calculated by feature function, In hierarchical structured constrained Viterbi algorithm, both thes e energy function can be s et zero (or a very small number) if assignment encounters constraints. It can be formulized as: In this way , the inference result will be an assignm ent fitting constraints with the largest probability . The three ty pes of constraints above can be described as follows. dis obey s label s pace cons traints ,  X  i ( c i , x avoid as signm ent. If for every cli que, parent and child satisfy the constraints, in the whole graph, it m ust also satisfy these constraints. 2) Label occurrence frequency cons traints: In Viterbi algorithm , assignment of one clique is only de termined by its neighbors, so it is hard to constrain the occurrence frequency of a label in one Viterbi proces s. However, we can s imply us e two-s tep inference iterations to solve this problem . Cons ider  X  CfpP g X  for exam ple, in the first round, we run a Viterbi algorithm to find the most likely  X  X fpPg X  and tag the node. And in the second round, we add a local constraint that tagged node is the one and the only one having the label of  X  X fpPg X . We can find the most likely  X  X fpPg X  by com paring the value of m arginal probability of cliques containing  X  X fpPg X  label, calcula ted again by Belief Propagation. 3) Temporal constraints: Date in form ation elem ents us ually occur together in conference pages . S o in two adjacent cliques with three continuous elements in  X  X  ateB X , it can cover two date attributes in m ost cases. In this way , if date attributes in one attributes acros s two adjacent cliques dis obey , set zero. We define some rule s to recognize whether current element contains date information and convert it into a format like  X 12/15/2008 X  for comparing. Features used in academ ic conference hom epage understanding include features of elem ents , featur es of inner blocks, and features of pages. Word Features: Include words in current elem ent and words in context elements. Th e window size is 1. Morp hology Featu res : The morphology of an element is divided into capitalized short term s, norm al short term s, capitalized short sentence, normal short sentence, and paragraph. Date Featu re: W hether current elem ent contains dates inform ation. We use rules to identify dates inform ation such as whether it contains key words like  X  X une X ,  X 2008 X , etc. Location Featu re: W hether current elem ent contains location information. We have built a location list from http://www.world-gazetteer.com /dataen.zip. If a word in current elem ent matches one item in the list, it is rec ognized as location information. Title Keyw ord s Featu res : W hether current elem ent contains key words occurring frequently in titles like  X  X t X ,  X  X d X ,  X  X d X ,  X  X h X ,  X  X onference X ,  X  workshop X ,  X  symposium  X , etc. Firs t Location Featu re: The first location in the root page. Usually , the first location in the root page is likely to be the location of the conference, referring to [16] . Latest Date Feature: W hether current elem ent contains lates t date among the homepage. Referring to [16] , latest date in a conference hom epage is likely to be the date of the conference. We use som e rules to identify date inform ation and com pare them between each other. Ch ild ren Nu mb er Featu re: Number of children of the block. Position Features: Center position of current block. The center can be calculated from features given by VIPS [2] . Area Featu res : Area of current block. The Area can be calculated from version-tree features given by VIPS [2] . Block Key words Features: W hether the firs t elem ent before this block contains key words like  X  Topics  X ,  X  Program Com mittee X , etc. This can help to recognize function blocks. Page Key words Features: Function pages usually have some hint words in the hy perlink. He re, we define  X  topic X ,  X  scale X ,  X  X cope X ,  X  them e X , etc, for  X  TopicP g X ;  X  X mportant X ,  X  X ey X ,  X  X ate X ,  X  X eadline X , etc, for  X  DateP g X ;  X  call X ,  X  paper X , etc, for  X  X fpP g X ;  X  X C X ,  X  X fficer X ,  X  X om mittee X ,  X  organization X , etc, for  X  PcPg X ;  X  X ponsor X , etc, for  X  X ponPg X . In total, we collected 570 conference homepages of 293 conferences during 2004-2008 containing the information defined in section 3, from top ranking conferences announced in conference sample, we downloaded the root page and all linked pages in it. Som e rules were defi ned to remove some linked pages which were sure not to be func tion pages to reduce the size of sam ple. Then, VIPS [2] was used to convert each page into a version-tree file, and then we jointed them into a com bined version-tree. Human annotator s conducted annotation on the combined version-trees. A spec was created to guide annotation process. All function pages, f unction blocks, and attributes defined in Figure 1 were labele d. For dis agreem ents in the annotation, we conducted  X  X ajor ity voting X . Table 2 shows the statistic of our dataset. W e us ed 3/4 of them for training and others for testing. Four-fold cross-validation was used in experiments. For all three labeling tasks, we us ed standard precision, recall and F1-measure (for definition of meas ures , see [21] ) to evaluate experim ental res ults. In addition, we used average F1-m eas ure to evaluate different methods. In par ticular, a block is considered as tolerant for one lay er difference. To com pare our m odel with traditional rule-based inform ation extraction methods, we firstly employ LP 2 as our baseline, which is the best method in previous works of conference information extraction in Pascal Challenge [13] . The algorithm tool we use is from Am ilcare [4] . To evaluate our model X  X  effectiveness of incorporating more hierarchical dependencies for la beling, we chos e two cas caded labeling methods, which firstly label function pages, based on the results, then label function blocks, and finally , label attributes. One is SVM m ethod, the other is Linear Conditional Random Fields (LCRF) method. Both methods are widely used in previous information extraction tasks. In these two methods, we converted Web page into a sequence while remaining their format and structure information as features. For SVM method, we trained a (http://crfpp.sourceforge.net) to do these experim ents. To evaluate our m odel X  X  effectiv eness of utilizing the constraints among conference labels in infere nce, we also used standard Viterbi algorithm s in infere nce (HCRF ) as bas eline. We have developed HCRF and CHCRF tools. Both HCRF and CHCRF experiments were done using our tools. As LP LCRF are difficult to use in labeling function blocks, we only did experiments with them in other two tasks. Pa ges Blocks Attributes pages blocks attri-butes Table 3 shows the four-fold cross-validation results for all three labeling tasks in different me thods. And Figure 5 shows the average F1-measure using different methods. From the results we can see that our proposed CHCRF can achieve the best result on average in all three labeling tasks. Based on F1-measure, in labe ling function pages, CHCRF outperforms LP 2 by 40.4%, SVM by 6.0%, LCRF by 4.3%, and HCRF by 10.7%; in labeling function blocks, CHCRF outperforms SVM by 28.4%, and HCRF by 16.4%; in labeling attributes, CHCRF outperforms LP 2 by 32.2%, SVM by 4.2%, LCRF by 2.8%, and HCRF by 15.9%. In total, CHCRF outperforms cascaded method (LCRF) by 3.6% (F1-measure) and non-constrained HCRF method by 14.3% (F1-measure). By com paring the results of CHCRF with the ones from SVM and LCRF, we can see sim ultaneously labeling the three tasks has received better res ults than labeling them in a cas caded way . It is mainly becaus e CHCRF takes m ore s tructure inform ation into the model, which helps to utilize com plex dependencies of all the inform ation. Bas ed on this , three s ub labeling tas ks can help each other, while cascaded m ethods pr opagate errors in each step. Our CHCRF outperforms HCRF, a nd the m ain reason is the constrained inference. The cons trained Viterbi decoding makes been improved. We found that HCRF performed worse than cascaded methods like SVM and LCRF. There are two reasons: One is that without constrained inference, the structure dependencies can not be correc tly described. Sometimes,  X  X c X  occurs in  X  X opicB X , or  X  X ocati on X  occurs in  X  X cB X . Without correctly describing the distant dependencies, HCRF lost its advantages. The other reason is that data representation is sim pler in cascaded methods. In cascaded methods, there is no inner node. All the sequence units are leaf nodes in the version-tree. The repres entation in a vers ion-tree has alm ost twice size as the sequence, making the labeling more complex. From experimental results, LCRF performed better than SVM. That is becaus e their data repres entations are in the s ame size, and LCRF can utilize label dependencies of adjacent contexts. This helped to im prove labeling results. Traditional rule-based LP 2 method did not receive good perform ance in this W eb page labeling tas k. That is becaus e rule-based methods mainly depend on contexts hints. In this task, structure and label dependences information are helpful. The LP algorithm , however, can not us e structure inform ation as features and can not take advantages of label dependences. Also, it can not utilize effective features defined m anually . In  X  location X  labeling, it can not recognize a location through a list, which leads to the low accuracy . We can see from the results in all methods, sponsor information labeling has received the wors t accuracy . This is mainly becaus e sponsor is usually presen ted with pictures in Web page rather than texts . In our building of com bined vers ion-tree, we replaced the im ages by the  X  alt X  attributes in the elem ent. 74% errors cam e from that  X  X lt X  attribute has no hint word for the sponsor or there recognize the content. Others are from errors of model. As we mentioned in our first section, s emantic conference information can bring many fascinating Sem antic W eb applications. Based on the sema ntic conference data obtained using our proposed Constrained Hierarchical Conditional Random Fields, we design and implement a prototy pe sy stem of semantic conference calendar. upcoming/current and past confer ences . It als o includes some im portant inform ation related to the conferences , for exam ple, conference date, conference full nam e, conference location, conference scope, paper submissi on date, and paper notification date. Such inform ation is very us eful for both academ ic and industrial researchers in their schedule decisions. Traditionally , conference calendar is viewed as an engineering issue and is constructed manually . F or exam ple, As sociation for Information Sy stems (http://www. isworld. org) provides a  X  X onference CFP Page X  that contains information about call-for-paper for conferences of interest to the global Information Sy stem community . DB-world (http://www. cs. wisc. edu/dbworld) provides a comprehensive and frequently updated list of events such as conferences and works hops in Computer Science (An ACM SIGMOD resource). Disadvantages of manual sty le are obvious: 1) Semantic informati on is limited. Much useful inform ation is presented in the unstr uctured plain text; 2) It is not eas y to im plem ent a cus tom izable conference calendar. M ost of users would not like to s ee the comprehensive list as AIS and DB-the conferences . In our work, we describe a Sema ntic W eb application that builds a cus tom izable conference calendar. In contras t to previous works aiming at manually providing a comprehensive list of upcoming/current and past conferences , in this work we engage in im plem enting a semantic conference calendar which can achieve to autom atically get inform ation from the Web using conference homepage understanding proposed in this paper. In this sy stem, to build one X  X  calendar, the us er s imply needs to specify what conferences he/s he is interes ted in. The s ystem finds and extracts the sem antic inform ation from the W eb autom atically . The conference information also can be updated (e.g., for different years) autom atically from the W eb. Our sy stem here aims at providing a user-oriented conference calendar. The s cenario is defined as follow: A user, for ins tance an academ ic res earcher, wants to be kept reminded of several conferences he /she is interested in. He/she inputs the conference names (acrony ms or full name) into our system . The s ystem autom atically identifies the hom epages of the conferences for every year; then extracts the s emantic conference inform ation from conference hom epage. The extracted conference inform ation is filled into a calendar and thus a personalized calendar is created. Figure 6 s hows an exam ple of conference calendar. The left-top part is the homepage identified by our system for ISWC X 2007; the right part is the extraction process; and the left-bottom part is the constructed calendar. Consequently , three problems need to be solved to build an autom atic calendar: 1) how to find the hom epage of a conference; 2) how to label the conference data from the pages; and 3) how to integrate the labeled data into our sy stem . For the second problem, we have proposed a Constrained Hierarchical Conditional Random Fi elds approach. The details are presented in previous sections. In this section, we focus on the other two problems. Finding relevant conference homepage is a precondition of obtaining conference inform ation. Naturally , exis ting search engine provides a good way to find conference homepages. We use Google as our search engine. Our statistics on 293 conferences during 2004 to 2008 with input of the acrony m of conference have s hown that over 96% conference hom epages can be returned in the first 10 items by Google, and 69.3% can be returned in the firs t item . Then, we form alize conference hom epage identification problem as a clas sification problem . Given the first 10 results from search engine based on acrony m the homepage of corresponding conference. Sometimes two academ ic conferences have the same acrony m, and in this cas e, both need to be identified. We proposed a SVM method to solve the problem. The relevant SVM algorithms are described in [6] . The process consists of training and identify ing. In the training, we trained a classifier from labeled dataset, and effec tive features were defined to improve the results including: URL Pattern Featu res : Whether the URL contains patterns like  X  X dd 2008 X ,  X  X rg X , and  X  X ndex X . Position Featu res : W hether the URL is the first, first three, or first five results returned by search engine. Page Title Feature : W hether the page X  X  title has patterns like  X  X IKM 2008 X ,  X  X IKM -2008 X ,  X  X IKM X  08 X , etc. Hy pe rlink F eatur es : Whether the page contains hy perlinks like  X  X mportant dates  X ,  X  X rogram com mittee X , etc. Our dataset contains 1046 confer ence homepages. We used the acrony m and y ear as key words to put into the search engine, the other results returned were seen as negative sam ples. Half of them were used for training and others for testing. Two-fold cross-validation experiments have show n that our methods can achieve 69.5% in precision, 79.3% in r ecall, and 74.1% in F1-measure. In inform ation integration, we norm alize the labeled inform ation. When the s ystem finds m ore than one ins tances of an attribute, and the values are different, we select the one that has the highest likelihood as the value of the attribute; 2) When the value of the ins tances are the s ame, but with different repres entations (e.g.,  X  X une 10, 2007 X  and  X 06/10/ 2007 X ), we normalize the representations (e.g. both  X  X une 10, 2007 X  and  X 06/10/2007 X  are normalized as  X 2007-06-10 X ), and store them in the database. Our calendar s ystem targets at pr oviding personalized services for users . The s ervices include: 1) Personalized Calendar. The user selects/inputs conference autom atically and keeps rem inds of the us er. 2) Conference Search. The user input the key words and the system returns the detailed conference inform ation that is extracted from the W eb autom atically . The processing of the sy stem is shown in Figure 7. When building corresponding conference will return. If results do not satisfy the inform ation manually , which will also be kept in database so that other users can share this, too. The extracted s emantic conference data is als o very useful for data mining tasks from the social network. Accurate extraction of the conference is es sential to expertis e conference finding and is greatly helpful for the other mining issues like finding sponsors, finding experts, etc. In this paper, we have inves tigated the problem of academ ic conference homepage understanding. Conference information has com plex structural dependencies across m ultiple pages, and has inherent logical constraints. Ba sed on these features, we have proposed a new unified approach, Constrained Hierarchical Conditional Random Fields, to so lve the problem by combining the ideas of Hierarchical Conditional Random Fields and Constrained Linear Conditional Random Fields. Experimental results on real world data have de mons trated that this approach perform s better than both the cas caded approach and Hierarchical Conditional Random Fields without constraints. Based on our conference homepage understanding technique, we have designed and implemente d a practical S emantic Web application, Semantic Conference Calendar. It can autom atically search and extract conference inform ation from the W eb and other Web applications such as finding sponsors, predicting com pany interes ts, and finding paper reviewers. As future work, we plan to com bine different m achine learning methods to im prove the accuracy . W e also want to build m ore Semantic Web applications based on the s emantic conference data. The work is supported by the National Natural Science Foundation of China (90604025, 60703059), Chinese National Key Foundation Research and Development Plan (2007CB310803), and Chinese Young Faculty Research Funding (20070003093). Thank Jun Zhu, Xiaobing Liu and Ali Daud for necessa ry disc ussions. [1] Auer, S., Dietzold, S., and Riechert, T. OntoWiki  X  A Tool [2] Cai , D., Yu , S., Wen , J., and Ma, W. Block-based Web [3] Ciravegna, F. (LP) 2 An Adaptive Algorithm for Information [4] Ciravegna, F., Dingli, A., Iria, J., and Wilks, Y. Multi-[5] Collins, M. Discrimina tive Training Methods for Hidden [6] Cortes, C. and Vapnik, V. Support Vector Networks. [7] Cowell, R., Dawid, A., Lauritzen, S., and Spiegelhalter, D. [8] Cox, C., Nicolson, J., Finke l, J., and Manning, C. Template [9] Gandon, F., and Sadeh, N. A Semantic eWallet to Reconcile [10] Ghahramani, Z. and Jordan, M.I. Factorial Hidden Markov [11] Hammersley, J. and Cliffo rd, P. Markov fields on Finite [12] He , X., Zemel , R., and Carreira-Perpi X  X n , M. Multiscale [13] Ireson, N., Ciravegna, F., Califf, M.E., Freitag, D., [14] Kristjansson, T., Culotta, A., Viola, P., and McCallum, A. [15] Lafferty, J., McCallum, A., and Pereira, F. Conditional [16] Lazarinis, F. Combining Information Retrieval with [17] Li, Y., Bontcheva, K., and Cunningham, H. Using Uneven [18] Liu, D. and Nocedal, J. On the Limited Memory BFGS [19] McCallum, A., Freitag, D., and Pereira, F. Maximum [20] Payne, T., Singh, R., and Sycara, K. Browsing Schedules  X  [21] Rijsbergen, C. Information Retrieval . 1979. [22] Roth , D. and Yih , W. Integer Linear Programming Inference [23] Sarawagi , S. and Cohen , W. Semi-markov Conditional [24] Schneider, K. Information Extraction from Calls for Papers [25] Sha , F. and Pereira , F. Shallow Parsing with Conditional [26] Tang , J., Hong , M., Li , J., and Liang , B. Tree-structured [27] Yedidia , J., Freeman , W., and Weiss , Y. Generalized Belief [28] Zhu , J., Nie , Z., Wen , J., Zhang , B., and Ma , W. 2D [29] Zhu , J., Nie, Z., Wen , J., Zhang, B., and Ma, W. 
