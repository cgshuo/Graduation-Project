 Protein interaction networks are one of the most promising types of biological data for the discovery of functional modules and the pre-diction of individual protein functions. However, it is known that these networks are both incomplete and inaccurate, i.e., they have spurious edges and lack biologically valid edges. One way to han-dle this problem is by transforming the original interaction graph into new graphs that remove spurious edges, add biologically valid ones, and assign reliability scores to the edges constituting the final network. We investigate currently existing methods, as well as pro-pose a robust association analysis-based method for this task. This method is based on the concept of h-confidence, which is a measure that can be used to extract groups of objects having high similarity with each other. Experimental evaluation on several protein inter-action data sets show that hyperclique-based transformations en-hance the performance of standard function prediction algorithms significantly, and thus have merit.
 H.2.8 [ Database Management ]: Database Applications X  Data min-ing ; J.3 [ Life and Medical Science ]: Biology and genetics; E.1 [ Data Structures ]: Graphs and networks Algorithms, Performance, Reliability, Experimentation Association analysis, h-confidence, protein interaction networks, noise reduction, protein function prediction
One of the most promising forms of biological data that are used to study the functions of proteins at a genomic scale are protein in-teraction networks. These networks are generated by collecting in-teractions between two or more proteins, which are in turn obtained from various sources such as metabolic or synthetic pathways, pro-tein complexes and ligand-receptor mechanisms [32]. These net-works provide a global view of the interactions between various proteins that are essential for the accomplishment of most protein functions. Due to the importance of the knowledge of these inter-actions, several high-throughput methods have been proposed for discovering them [14]. In fact, several standardized databases, such as DIP [33] and GRID [4] have now been set up to provide system-atic access to protein interaction data collected from a wide variety of experiments and sources.

It is easy to see that a protein interaction network can be rep-by nodes and protein-protein interactions as edges. Due to this systematic representation, several computational approaches have been proposed for the prediction of protein function from protein interaction graphs [18, 23, 25, 20, 30, 15, 16]. These approaches can be broadly categorized into four types, namely neighborhood-based, global optimization-based, clustering-based and association analysis-based [18]. Due to the rich functional information in these networks, several of these approaches have produced very good results, particularly those that use the entire interaction graph si-multaneously and use global optimization techniques to make pre-dictions [16, 30]. Indeed, recently, some studies have started using protein interaction networks as benchmarks for evaluating the func-tional relationships between two proteins [37].

However, despite the advantages of protein interaction networks, they have several significant weaknesses which affect the quality of the results obtained from their analysis. The most prominent of these problems is that of noise in the data, which manifests it-self primarily in the form of spurious or false positive edges [22]. Studies have shown that the presence of noise has significant ad-verse affects on the performance of protein function prediction al-the rest of this paper. Also, since a graph is the only representation of an interaction network that is used in our study, we use the terms network and graph interchangeably. gorithms [7]. Another important problem facing the use of the se networks is their incompleteness, i.e., the absence of biologically valid interactions even from large sets of interactions [30, 15]. This absence of interactions from the network prevents even the global optimization-based approaches from making effective use of the network beyond what is available, thus leading to a loss of poten-tially valid predictions. In this paper, we investigate techniques that try to address these two problems with the objective of improving function prediction results.

A possible approach to these problems is to transform the origi-nal interaction graph into a new weighted graph such that the weights assigned to the edges in the new graph more accurately indicate the reliability and strength of the corresponding interactions, and their utility for predicting protein function. In our study, a graph transformation converts an undirected graph G = &lt; V, E, W &gt; to a new graph G  X  = &lt; V, E  X  , W  X  &gt; . Interestingly, the alternate representation of the G as an adjacency matrix A | V | X | V | A ( p 1 , p 2 ) = 1 if p 1 and p 2 interact, allows the application of asso-ciation analysis techniques to the task of creating a new weighted adjacency matrix A  X  weighted graph may have some new edges (i.e., edges that had weight in the original graph) and may skip some edges that are present in the original network. This elimination of spurious edges can reduces the noise and the addition of viable edges can reduce the incompleteness of the original interaction network.

Association analysis is a field of data mining that is focused pri-marily on the analysis of objects that co-occur frequently in a data set, and are thus hypothesized to be associated to each other [28]. Several types of such frequent patterns and algorithms for deriving them have been proposed, the most common ones being frequent itemsets and the Apriori algorithm respectively [1, 3, 2]. Recently, a new type of frequent pattern known as hyperclique has been pro-posed for addressing the problem of skewed distributions of ob-ject frequencies in binary data [36]. This pattern is based on the h-confidence measure. This measure is just the number of times items appear together divided by the maximum number of times that one of the items occurs by itself. Thus, objects that are part of a hyperclique derived at a high h-confidence are tightly associated with each other, and those that are not a part of any hyperclique are often noisy objects.

Indeed, this idea has produced good results when applied to find-ing patterns in a number of situations, including those involving noisy data. In one study [35], hyperclique patterns were used to remove noise from document and gene expression data. In another study [34], hyperclique pattern discovery was applied to protein complex data to find functional modules. Specifically, the complex data was represented as a binary data set whose attributes corre-sponded to the presence or absence of proteins, while the hyper-clique patterns found in such data were treated as candidate func-tional modules, i.e., groups of proteins have related functions. Ex-amination of the hyperclique patterns showed that many of the hy-percliques did contain several functionally related proteins.
This success of hypercliques in noise removal from binary data, coupled with the representation of protein interaction graphs as a binary matrix to which association analysis techniques can be ap-plied, motivated us to address the graph transformation problem using an approach based on h-confidence. We perform this task in two ways. In the first, we compute new edge weights for pairs of proteins by computing the h-confidence between them based on the binary adjacency graph, A . This is equivalent to the process of find-ing size two hyperclique patterns in the adjacency graph. Second, if the weighted adjacency matrix of the original graph A w able, we employ a continuous version of h-confidence to compute new edge weights between all pairs of proteins. Thus, depending on whether the input graph was weighted or unweighted, we pro-duce one or two transformed graphs, both of which may have edges and weights different from the original graph. This transformation is expected to reduce noise in the network since the resultant edges that have a high weight are highly likely to connect proteins that have a strong association in the original interaction network.
In order to evaluate the efficacy of the resultant networks for protein function prediction, we provided the original and the trans-formed graphs as input to the FunctionalFlow algorithm [16]. Func-tionalFlow is a graph theory-based algorithm that enables insuffi-ciently connected proteins to obtain functional annotations from distant proteins in the network, and has produced much better re-sults than several other function prediction algorithms. The re-sults obtained from these experiments show that the transformed graphs are significantly more capable of accurately predicting pro-tein function as compared to the original network, as well as other recently proposed transformations methods that we evaluated. In addition, the improvement in performance was larger for networks for which the reliabilities for the edges were estimated indirectly using sources such as gene expression data, as compared to reliabil-ities computed using experimental means or functional annoations of the interacting protein.

An association analysis based approach to graph transformation is just one of the possible approaches. For comparison, we also consider a couple of other approaches as well. One such algo-rithm [23] computes the strength of the edge between two nodes in the transformed graph as the probability that they shared a given number of neighbors in the original graph by chance. Other studies have more directly used the number of common neighbors between two proteins, or a minor variation thereof, to estimate the reliabil-ity of an interaction between the two proteins in the transformed network [5, 15]. These approaches are detailed in Section 3.
This paper makes a contribution to the task of protein function prediction by proposing novel association analysis-based transfor-mation methods based on h-confidence for protein interaction net-works represented as graphs. This includes a technique for evalu-ating the reliabilities of the edges for unweighted networks, and a method to produce more noise-resistant weights for weighted networks. Through extensive evaluation, we show that the pro-posed transformations and weighting methods produce more accu-rate functional annotations for proteins in the network. This is due to the smaller amount of noise and a more complete set of biologi-cally viable interactions in the transformed network.

More generally, this work provides a novel example of an appli-cation where frequent patterns (hypercliques here) are extracted in the traditional market-basket setting from a symmetric binary ma-trix. In addition, we propose a new formulation for the h-confidence measure for pairs of vectors containing continuous values. Al-though the focus for both these techniques is on producing better graphs for protein function prediction, both approaches could be profitably applied to other data mining problems.

This paper builds upon our preliminary work on a related topic [11], that investigates the utility of association analysis for protein com-plex and interaction data to enhance SwissProt keyword recovery. Overview The remainder of the paper is organized as follows. Sections 2 and 3 provide the necessary background information for the rest of the paper by describing the function prediction and graph transformation techniques used. Sections 4 and 5 detail the infras-tructure of the study in the form of data sources and the evaluation methodology used respectively. Finally, we present the results of this evaluation in Section 6 and make concluding remarks in Se c-tion 7.
As mentioned earlier, due the richness of functional information in protein interaction networks and their systematic representation as a graph, several computation approaches have been proposed for inferring protein function from one or several interaction networks [15, 16]. These approaches can be broadly classified into four cat-egories [18]:
Due to their ability to gather predictions from the whole network and confidently assign them to unannotated proteins, approaches in the last category have generally produced the best results in pro-tein function prediction from interaction networks [18]. In partic-ular, the FunctionalFlow algorithm [16] was shown to outperform several other function prediction approaches in a comprehensive evaluation study by its authors. It also has the advantage of be-ing backed by well-founded graph theoretic concepts. Due to these merits, we chose FunctionalFlow as the base algorithm for evaluat-ing the effectiveness of various transformed graphs for the task of protein function prediction.

FunctionalFlow is based on the concept of network flow in graph theory [31]. However, since network flow is defined for directed graphs, FunctionalFlow uses an iterative algorithm for interaction networks, which are represented as undirected graphs. For each function a , the set of proteins annotated with a are treated as sources , the other proteins as sinks , and the weights are used as capacities of the corresponding edges in the graph. The algorithm then iter-atively "flows" the functional annotations from the sources to the sinks, using a downhill flow strategy. In this strategy, the anno-tations flow only from a more full node to a less full one directly connected to it, while maintaining the constraint that the flow on the edge does not exceed its capacity. At the end of the pre-specified number of iterations, all the nodes in the network have a certain functional score for a , from which annotations are made using a threshold on this score. Repeating this process for all the functions in the given set of annotations produces the required functional an-notations for the set of query proteins.

The above description indicates that the good results of Func-tionalFlow can be attributed to the use of annotations from both close and distant neighbors in the network, as well as the effective use of edge weights to control the flow of annotations from one protein to another. In other words, an interaction graph with more accurate edges and weights is expected to yield better function pre-dictions.
This section describes the various techniques that we used for graph transformation, i.e., to transform the original interaction graph G = &lt; V, E, W &gt; to a new graph G  X  = &lt; V, E  X  , W tioned, edges may be either deleted or added to address the prob-lems of the noisiness and incompleteness of the data, respectively. A number of recent techniques that have been developed for this purpose are described next. They employ a variety of approaches, but the goal is to transform the graph by adding or deleting edges in order to produce a new graph that is more suitable for protein function prediction.
The simplest technique is to treat the protein interaction network as an adjacency matrix for the set of proteins, i.e., to make the edge weights of all interacting pairs of proteins equal to 1. If the original matrix does not have weights, than this transformation does not change the graph. If the original graph has weights, then often a threshold is applied to eliminate weak edges. Thus, this approach is primarily used to show the value of weighted interaction graphs for function prediction.
This graph transformation technique is based on the observation that proteins that share a number of neighbors are more likely to have a function in common. Indeed, the evaluation of this approach on real interaction data sets [15] showed that predicting the func-tion of a protein based on the proteins with which it shares a number of common neighbors has better accuracy than predicting function based on proteins that are merely neighbors of the protein. Also, unlike the neighborhood approach, which typically sees accuracy rise and then decline as the number of neighbors increase, an ap-proach based on common neighbors attains a relatively stable level of accuracy as the number of common neighbors increases.

Using the common neighbor strategy for graph transformation is straightforward. Specifically, an edge is placed between two proteins only if those proteins have at least one neighbor, and the weight of that edge is the number of common neighbors. Note that some proteins that originally had an edge in the original graph can become disconnected, i.e., edges may be lost, while two proteins that did not originally have an edge, may be connected in the trans-formed graph.

This approach is closely related to the shared nearest neighbor approach for clustering [13, 8]. In the SNN approach, the nearest neighbors of the objects are determined from their similarity or dis-tance. Then, a new distance measure is defined based on the num-ber of neighbors that appear on both of the nearest neighbor lists of the objects [13]. This approach has been shown to have good per-formance for clustering in dealing with noisy and high-dimensional data [8].
The motivation for this graph transformation method is the same as the Common Neighbor approach, namely that those proteins that share many neighbors are more strongly connected, i.e., more likely to be functionally similar. However, this approach addresses the fact that the significance of two proteins sharing a particular num-ber of neighbors depends on the number of neighbors that each has. To illustrate, if two proteins, each having only two neighbors, share both these neighbors, then this is more significant, in terms of prob-ability, than two proteins, each having 20 neighbors, that sh are only two.
 The formula for the probability (p-value) of an edge is given by Equation 1, which is taken from Samanta and Liang [24]. Note that N is the number of proteins, n 1 is the number of neighbors of protein p 1 , n 2 is the number of neighbors of protein p the number of neighbors shared by the two proteins. In practice, the negative log of this probability is easier to work with and has the property that larger numbers imply stronger edges. In other words, typically we take w ( p 1 , p 2 ) =  X  log( prob ( N, n 1 , n
H-confidence [36], also known as all-confidence [17], is a mea-sure of the association of items (binary attributes). If a set of items has an h-confidence more than a user-specified threshold, the itemset is called a hyperclique. Definition 1 defines hyper-cliques and h-confidence more formally. The quantities of  X  X up-port X  and  X  X onfidence X  are as defined in standard association analy-sis [1, 28].
 D E FINIT ION 1. Hyperclique A set of items (binary attributes), X , forms a hyperclique with a particular level of h-confidence, where h-confidence is defined as
H-confidence is between 0 and 1, with a value of 0 indicating no association and a value of 1 indicating the strongest association between a group of items, i.e., the items always occur together. Thus, h-confidence can be used as a measure of similarity between the attributes in a binary data matrix.

Specifically, the adjacency matrix A of a protein interaction net-work is considered as a binary data matrix by treating its rows as transactions and columns as items. (Note that both correspond to protein). Then a weighted adjacency matrix A  X  of the same di-mensions as the original one can be generated using A  X  ( i, j ) = confidence ( i, j ) . Informally, the h-confidence of a pair of proteins, p and p 2 , will be high if p 1 tends to be a neighbor of a protein whenever p 2 is and, vice-versa. Using Equation 3 and the termi-nology introduced for the p-value transformation, h-confidence for a pair of proteins is given by the following equation:
Using the h-confidence of two proteins as the weight of the edge between the proteins, a new graph can be created. However, in addition to an h-confidence threshold, it is also necessary to take into account the absolute number of times two proteins appear to-gether ( m ) as well as the fraction of times that the occurrence of one protein as a neighbor implies the occurrence of the other pro-tein as a neighbor (min( n 1 /m, n 2 /m ) ). For example, if proteins p 1 and p 2 both have only one edge, which is to protein p their h-confidence will be one. On the other hand, proteins p , may have edges with 10 other proteins, 8 of which they share. They will have an h-confidence of 0.8 and thus, seem not to be as strongly connected as the first pair. To deal with such problems it is common to set a support threshold, i.e., to require that least some specified value.
As originally defined, h-confidence is only applicable to binary data or, in the context of protein interaction graphs, unweighted graphs [34]. However, the notion of h-confidence can be readily action networks, this amounts to replacing the counts, m , n 2 in Equation 4 by numbers based on the weights. In particular, n 1 and n 2 are the sum of the weights of all edges involving p , respectively, while m is defined to be the sum of the minimum of the edge weights of p 1 and p 2 on their shared edges. As with h-confidence defined on binary data, h-confidence on continuous data is between 0 and 1, with 1 indicating the strongest connec-tion. More specifically, the h  X  confidence of two vectors will be non-zero only if they both contain a non-zero value at the same position, while it will be high if both these values are high. Thus, in the domain of interaction networks, two proteins will be linked with an edge carrying a high weight only if they are connected to an overlapping set of proteins with highly reliable interactions.
To illustrate the difference between binary and continuous h-confidence, consider the following example of two proteins, p . In the weighted adjacency matrix, the two proteins occur to-gether in two rows and have weights 0.2 and 0.4, respectively, in the first row, and weights 0.3 and 0.1, respectively, in the second row. In addition, p 1 also occurs by itself in another row and has a weight of 0.5. Disregarding the weights, and considering only the number of edges, n 1 = 3, n 2 = 2, and m = 2. Using Equation 4, binary h-confidence = min(2 / 3 , 2 / 2) = 2 / 3 . However, using weights in the manner just described, n 1 = 0.2 + 0.3 + 0.5 = 1.0, n 0.4 = 0.5, and m = min(0 . 2 , 0 . 4)+min(0 . 3 , 0 . 1) = 0 . 3 plies that continuous h-confidence = min(0 . 3 / 1 . 0 , 0 . 3 / 0 . 5) = 0 . 3 Thus, for this example, continuous h-confidence is significantly smaller than binary h-confidence.
Pruning refers to the elimination of edges having a weight be-low a specified threshold. This approach is sometimes applied to the raw interaction graph to eliminate less reliable, i.e., lower weight edges. However, the transformed graphs produced by the techniques described above typically have substantially more edges than the original graphs since all potential pairwise protein-protein interactions are evaluated. Some of these interactions in the trans-formed graph may have small non-zero weights due to factors such as a random common neighbor in the original graph. Hence, prun-ing of the edges is conducted on the basis of the weights assigned in the transformed graph to remove unreliable edges.
In this section, we discuss the functional classification scheme and the interaction data sets used in our study.
Since our evaluation of the various graph transformations is based on the improvement provided by each of them over the raw network in the task of protein function prediction, it is important to define a set of reliable functional labels to be assigned to each protein. We chose the set of functional labels at a depth of two in the FunCat uous data [26], but in a manner slightly different from that given here. The previous approach addressed the general case which in-volved continuous attributes that could have widely different scales. The current formulation is better suited when all the attributes have similar scales. classification scheme of the MIPS database [21]. We made this s e-lection since this scheme has been widely used in function predic-tion literature [18], and the selected labels represent a good trade-off between the generality and specificity of the labels in this hier-archy. Also, all our experiments are performed on yeast proteins, and there are about 4500 proteins in yeast that can be annotated using the labels that we selected. Since we use a cross-validation-based evaluation methodology, we only consider this set of proteins in our study.
In order to be able to conduct a general evaluation study of the graph transformation methods, we selected the high-throughput protein-protein interaction networks of budding yeast ( S. cerevisiae ) listed in Table 2, since each of these data sets follows a different weighing scheme for the constitent interactions. Table 2 specifies the sizes of these networks in terms of the number of proteins and interactions constituting them, considering only the proteins annotated using our selection of functional labels. We removed any instances of re-dundant interactions, such as the interaction B  X  A when A  X  B already present in the data set, and self interactions, such as where A and B are proteins. A short description of each of the data sets and the weighing scheme adopted by them follows.
Deane et al [6] proposed two methods for assessing the reliabil-ity of high-throughput protein interactions, namely the paralogous verification method (PVM) and the expression profile reliability in-dex (EPRI). Using this method, they prepared the DIPCore data set, which is a set of highly reliable interactions selected from the Database of Interacting Proteins [33]. This set consists of teractions between 2526 yeast proteins. However, in its publicly sociated weights. Hence, in our study, we assumed these weights to be 1 for all interactions.
In order to illustrate the case of interaction data sets whose relia-bilities are estimated indirectly using other types of genomic data, we constructed a combination of three high-throughput yeast inter-action sets, namely those of Gavin et al [9], Uetz et al [29] and Ito et al [12], and refer to it as the combined data set. This data set consists of 7753 interactions between 3781 proteins, and the weights for these interactions are derived as follows. The reliabili-ties of each of the individual data sets was estimated using the EPR of a data set by comparing the distribution of gene expression dis-tances between the pairs of interacting proteins in the given data set, with that obtained from the DIPCore data set. The reliabili-ties computed for the above three data sets are tabulated in Table 1. Finally, the individual edge weights are calculated using the com-monly used formula of w ( e ) = 1  X  Q product runs over all the data sets i where edge e is found, and is the corresponding reliability of data set i . Overall, this method-ology provides us a set of indirectly derived weights for the edges constituting the combined data set.
Recently, Krogan et al [10] have reported a large high-throughput and reliable data set of 7123 interactions among 2708 yeast pro-teins. In addition, they have also assigned likelihood values for e ach interaction in their data set using various machine learning al-gorithms that tried to estimate the experimental reproducibility of these interactions. Thus, we treated these likelihood scores as the edge weights and used the entire set as an example of a data set whose edges are weighted directly using experimentally observed interaction data.

In summary, our selection of interaction data sets does indeed reflect a variety of weighing schemes used. Also, it can be seen that none of these data sets cover the entire yeast genome, and thus are highly likely to be incomplete.
The previous sections detailed the different data sets used in our study and the graph transformations that were used to process them and produce different transformed variants of the original interac-tion graph. These graphs were then input into the FunctionalFlow algorithm to produce predictions of functions for the constituent proteins. However, since it is hard to evaluate the predictions made for unannotated proteins, we restricted our evaluation to the pro-teins annotated with at least one functional label at depth two in the FunCat hierarchy. Table 2 details the number of proteins and interactions after imposing this restriction on each of the data sets used in this study.

U sing this set of annotations, we used the FunctionalFlow al-gorithm in a five-fold cross validation procedure, which produces a likelihood score for each protein being annotated with each la-bel (henceforth referred to as a protein-label pair). Now, in or-der to convert these scores into annotations, we follow a global scoring strategy. In this strategy, we sort the entire set of protein-label scores in descending order, and then selected the k the threshold for annotation, i.e., all protein-label pairs with scores greater than this threshold are predicted as annotations. Constantly increasing the value of k thus provided us a set of functional an-notation at different stringencies, and we used these annotation to calculate the following metrics for evaluating the performance of the algorithm.
In order to evaluate the overall performance, we used the precision-recall framework of evaluation [28]. However, since the traditional precision and recall metrics are defined only for binary classifica-tion problem, it needs to be modified for function prediction, given that a protein may ideally have multiple labels. Thus, we adopt the following definition of precision and recall used by other function prediction studies [7, 15].
Here, K is the total number of proteins with known functional labels, and for each protein i , m i is the number of labels predicted by the algorithm, n i is the actual number of labels possessed by the protein, and k i is the number of labels common to the actual and predicted set of labels. Sccording to these definitions, denotes the proportion of correctly predicted annotations out of all the functional predictions made, while Recall measures of the pro-portion of correctly predicted functions out of all the known anno-tations [28]. Thus, these measures are a suitable generalization of the original precision-recall framework to the multi-label scenario.
A biological researcher in the area of functional genomics may choose a number of predictions of protein function for experimen-tal investigation. Since the number of experiments that can be per-formed is quite limited, it is important to choose the most promising candidates for investigation, i.e., to focus on those functional pre-dictions most likely to be correct. Thus, for this situation, a list of the top k predictions is often more relevant than a precision-recall or ROC curve.
 The details of the top-k evaluation methodology are as follows. First, using the global scoring method, the k protein-label pairs with the highest functional score are identified, and are produced as the functional predictions of the algorithm. Next, the prediction accu-racy, or the precision, of this set of predictions is evaluated with respect to the known protein-label annotations. Then, a curve of prediction accuracy versus number of protein-label pairs predicted is produced by considering various values for k . We used values of k up to 500 or 1000 in our experiments.
 Note that these two metrics are related by the following equation:
P recision
Thus, they provide two related perspectives on the performance of a function prediction algorithm.
We evaluated several graph transformation methods using a wide variety of protein interaction data sets by testing the performance of the FunctionalFlow algorithm on the resultant interaction graph. Our data sets were selected to reflect the various types of interac-tion weighting schemes currently in use to estimate the reliabilities of protein-protein interactions. The following sections detail the results of our evaluation on each of these data sets. Note that all the results reported were obtained by a five-fold cross validation-based evaluation of the predictions produced by FunctionalFlow. Also, it was mentioned in Section 3.6 that the three transformations, namely p-value-based, common neighbor-based and h-confidence-based, may contain some spurious links in the tranformed graph. Hence, we tried several pruning thresholds for each of these meth-ods, the details of which are provided in Table 3. Note that the best value is the most commonly best performing value for the param-eter, and is used to report the evaluation results, unless some other value is specified.
 Common nbr Min(cmn nbrs) 1 , 2 , 3 2 Table 3: Paramater values tried for different transformatio ns
Finally, in order to make the discussion clearer, we use the fol-lowing notation in the rest of this section. The transformation of the binary adjacency matrix of an interaction graph to its trans-formed h-confidence-based adjacency matrix is referred to as the bin hconf (binary h-confidence) method, while the transformation of the weighted adjacency matrix of a graph to its transformed h-confidence-based adjacency matrix is referred to as the cont hconf (continuous h-confidence) method. The other notations are self-explanatory. Also, note that the plots in this section are best viewed in color.
In this experiment, we investigated the applicability of various graph transformation methods to enhance the weighted networks produced by indirect weighting methods such as EPRI [6]. The representative of this category was the combined data set described earlier in Section 4. We transformed this weighted network us-ing the continuous h-confidence-based method, and its unweighted version using three transformation methods, namely the binary h-confidence-based, the p-value-based and the common neighbor-based. Figure 1 shows the performance of the FunctionalFlow al-gorithm on the the original combined graph, its unweighted adja-cency matrix, and the four transformations computed above. It can be seen from Figure 1(a) that continuous h-confidence has better overall performance in terms of precision and recall. This improve-ment is shown much more clearly by Figure 1(b), which shows that the continuous h-confidence-based transformed graph produces the most accurate predictions when only the top 1000 predictions are considered, and outperforms the raw weighted network by nearly 10% throughout. For instance, if only the top 500 predictions are considered, the accuracy of the predictions made using the raw weighted network is only about 70% , while that of the predictions made using the continuous h-confidence-based transformations is over 80% . Also, for this data set, p-value-based transformation outperforms the raw network, though by a smaller margin than the h-confidence-based transformations.
Krogan et al  X  X  data set was discussed earlier in Section 4, and was used in their study [10] to discover overlapping protein com-plexes, which were subsequently categorized into cores, modules and isoforms. In addition to the good results obtained, a major com-ponent of this study was the use of machine learning algorithms to compute the likelihood of an observed interaction to be valid. In this experiment, we tested if the use of h-confidence could enhance these weights for effective function prediction. Thus, we used the continuous version of the h-confidence measure, defined in Section 3.5, to transform the original weighted interaction network and cal-culate the reliability of an edge connecting two proteins the basis of the strengths of their interactions with each other or with other proteins. Similar computations are carried out for the other transformation methods such as p-value and common neigh-bor.

The results of this experiment are shown in Figure 2. Figure 2(a) shows that h-confidence-based transformation was indeed able to Figure 1: Performance of graph transformation methods on the combined interaction set obtain better results under the precision-recall framework, as com-pared to the raw weighted graph and other transformations. This difference in performance between the various methods is accentu-ated by the relative performance of the different transformations of the original networks when only the top 500 predictions are considered. As shown by Figures 2(b), continuous h-confidence-and binary h-confidence-based transformations outperform the raw weighted graph by a large margin. For instance, for the top dictions, a margin of 5% and 10% is observed respectively. These results show the merits of using association analysis-based trans-formation methods for this data set.
The final category of protein interaction data sets that we con-sidered were those that did not contain the reliabilities of the edges explicitly, and since they form a single data set, it is difficult to weigh their edges using an approach such as the one used to es-timate the edge weights of the combined data set. Thus, we fo-cused this experiment on investigating the utility of graph transfor-mation methods for unweighted interaction networks. We selected Figure 2: Performance of graph transformation methods on Krogan et al  X  X  interaction set [10] the DIPCore [6] data set for this experiment, which is a set of about 6000 highly reliable unweighted interactions selected from within DIP. The interaction graph was represented as a binary adjacency matrix A , and was transformed using the binary h-confidence, p-value and common neighbor methods.

We executed the FunctionalFlow algorithm with the four graphs (one original and three transformed) as input, and obtained the overall precision-recall curves for each of them, which are shown in Figure 3(a). These curves show that the transformed graph ob-tained using binary h-confidence perform better than the original graph for a large part of the precision-recall range, while those pro-duced by the p-value and common neighbor methods performed worse throughout. It is important to point out that even though the improvement in performance may seem small, it is indeed signifi-cant when seen in the light of the fact that DIPCore is a very reliable data set [6], and is expected to be much richer in functional content than several other interaction data sets [15, 27].

As shown in Figure 3(b), even among these top predictions, where most methods are expected to produce good results due to the func-tional richness of the network, the binary h-confidence-based graph Figure 3: Performance of graph transformation methods on the DIPCore data set [6] performs significantly better than the raw network. More specifi-cally, there is a significant improvement of about 5% throughout the top 1000 predictions. Also, graphs produced by p-value-and combined neighbor-based transformations perform worse than the original adjacency matrix.

Finally, it should also be noted that we applied our evaluation methodology for weighted interaction networks to the data set used by Nabieva et al to compare FunctionalFlow against other function prediction algorithms [16]. Even here, the continuous h-confidence-based transformation is able to outperform the original raw net-work. However, the difference between the performance of the two graphs is very small, since the weights of Nabieva et al  X  X  data set are assigned using the functional labels of the interacting proteins. Thus, although it would be hard to outperform this network X  X  and its weights X  performance at the task of protein function prediction, the improvement achieved by the h-confidence-based transforma-tion demonstrates its ability to enhance the functional information even in very precise networks.

In summary, through the evaluation of several protein interaction data sets that use a wide variety of reliability estimation schemes for their interaction, we showed that the h-confidence-based graph transformation method produces the most precise network, which can be used to predict protein function accurately. We believe that the success of this method is due to the changes made by it to the original network, namely removal of noisy edges and addition of biologically viable ones, in combination with effective reliability estimation of the edges in the resultant data set. We tested the va-lidity of this hypothesis in the following final component of our study.
We designed the following test in order to test the effect of noisy interactions in the input interaction graph on the accuracy of the graph produced by transforming it using the binary h-confidence-based transformation method. Given an interaction graph G taining n edges, and a noise level of  X  % , we generated n  X   X  that are not already present in G , and added these "spurious" edges to
G to create a noisy interaction graph G  X  . However, it is diffi-cult to generate weights randomly to these new edges, since the edge weights in each data set follow some unknown distribution. Thus, we applied this test only to the DIPCore data set, since its edges do not carry weights. The spurious edges generated are added as they are to the original data set without assigning them any weights. Next, the function prediction algorithm Function-alFlow is executed using the raw and this noisy interaction graphs, as well as their transformed versions, which in this experiment are generated only using the binary h-confidence method. (Thus, the transformed graph in the following text refers only to the graph transformed using this method.) The results are compiled both in the precision-recall, as well the accuracy of the top-tions frameworks. The precision-recall results show the expected result that the precision-recall curves of the noisy versions of the raw graph and the transformed graph are inferior to their original counterparts (data not shown). However, the encouraging part of these results is that the gap between the performance of the noisy and the transformed noisy graphs is larger than that between the raw and the transformed raw graphs.
A more interesting result is presented by Figures 4 and 5, which illustrate the results of the accuracy of the top 500 predictions made using each of the noisy and original versions of the raw DIPCore network and their transformed counterparts which were further pruned using a minimum h-confidence threshold of 0 . 1 . These plots show that while the performance of FunctionalFlow deteriorates signifi-cantly when spurious edges are added to the original network, the corresponding loss in performance using the transformed graph is much less in comparison. For instance, it can be easily seen from Figure 4 that the performance of the transformed noisy graph is very close in performance to the transformed raw graph. On the other hand, the performance of the noisy network is significantly worse than that of the raw network. More specifically, in Figure 5, if only the first 300 predictions are considered, then the accuracy of the raw network is approximately 87% , which deteriorates to using the noisy raw network. On the other hand, the performance of both the binary h-confidence-based graphs is almost 93% though these precise values fluctuate throughout the first dictions, the general trend is that noise effects the raw interaction network much more adversely than the binary h-confidence-based network. This behavior of the binary h-confidence method can be explained on the basis of the noise resilience characteristic of hy-perclique patterns, as well as the incompleteness of the interaction data sets.

In an earlier study [35], we showed that hypercliques are very effective in identifying large number of noisy objects from binary data sets, i.e., objects that are expected to have been generated by processes other than that used for the regular objects. It was shown that this removal of noisy objects significantly improved the results of important data mining operations such as clustering and asso-ciation analysis. A similar phenomenon is expected to reduce the effect of the spurious edges added to the interaction graph. More specifically, protein interaction networks, particularly small ones such as DIPCore, are expected to be significantly incomplete [15, 30], and several interactions other than those already in the data set are expected to be biologically valid. Thus, among the set of noisy edges added to the original network, many are expected to be noisy, while a substantial number are also expected to be bio-logically valid. Now, due to their noise removal ability, the binary h-confidence-based transformation is able to identify the biologi-cally more viable edges, and use them for prediction. On the other hand, the performance of the raw noisy network suffers, since the positive contribution of these valid edges is negated significantly by the noisy edges.

In summary, this test shows that our hypothesis that the function prediction performance of the h-confidence-based graph transfor-mation is significantly better than that of the raw interaction net-work due to the three important changes made to the original net-work, namely the removal of spurious edges, the addition of bio-logically viable ones, and effective weighting of the resultant set of edges, is indeed highly likely to be true.
The previous sections detailed several experiments that we con-ducted to evaluate the use of the various methods for transforming a given protein interaction network. Several detailed conclusions can be derived from these results, which we discuss below: 1. Given a variety of interaction networks, such as the com-2. Throughout our extensive evaluation, we observe that the 3. Looking deeper into the results of the experiments on sev-4. Finally, through a test on the DIPCore data set, in which a
This detailed analysis of results indicates that associatio n analysis-based graph transformation methods are useful, both from a data mining, as well as a functional genomics perspective.
We thank Elena Nabieva and Mona Singh for providing us access to their interaction data and for several fruitful discussions. This work was supported by NSF grants #CRI-0551551, #IIS-0308264, and #ITR-0325949. Access to computing facilities was provided by the Minnesota Supercomputing Institute.
