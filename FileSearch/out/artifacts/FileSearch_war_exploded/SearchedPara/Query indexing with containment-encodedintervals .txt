 REGULAR PAPER Kun-Lung Wu  X  Shyh-Kwei Chen  X  Philip S. Yu Abstract Many continual range queries can be issued against data streams. To ef-ficiently evaluate continual queries against a stream, a main memory-based query index with a small storage cost and a fast search time is needed, especially if the stream is rapid. In this paper, we study a CEI-based query index that meets both criteria for efficient processing of continual interval queries. This new query in-dex is an indirect indexing approach. It centres around a set of predefined virtual containment-encoded intervals , or CEIs. The CEIs are used to first decompose query intervals and then perform efficient search operations. The CEIs are de-fined and labeled such that containment relationships among them are encoded in their IDs. The containment encoding makes decomposition and search operations efficient; from the encoding of the smallest CEI containing a data point, the encod-ings of other containing CEIs can be easily derived. Closed-form formulae for the bounds of the average index storage cost are derived. Simulations are conducted to evaluate the effectiveness of the CEI-based query index and to compare it with alternative approaches. The results show that the CEI-based query index signifi-cantly outperforms existing approaches in terms of both storage cost and search time.
 Keywords Continual queries  X  Data streams  X  Query indexing  X  Range indexing  X  Range queries  X  Stream processing 1 Introduction Recently, many data-stream applications have been recognised [ 1 , 10 ]. For ex-ample, financial applications, network monitoring, security, telecommunications data management, sensor networks and other applications can be modelled as with well-defined attributes, e.g. network measurements, call records, meta data records, Web page visits, sensor readings and so on. These data items flow in the network in the form of streams continually and perhaps rapidly.
 number of range queries or filtering predicates can be created and evaluated con-tinually against each data item in the incoming stream. For example, in a financial stream application, various continual range queries can be created to monitor the prices of stocks, bonds or interest rates. In a sensor network stream application, continual range queries can be used to monitor the temperatures, flows of traffic or other readings.
 query index. Each data value in the incoming stream is used to search the query index and identify those relevant queries that contain the data value. Though con-ceptually simple, it is quite challenging to design such an interval query index in a streaming environment, especially when the stream is rapid. The interval query in-dex is preferably main memory-based and it must have two important properties: low storage cost and excellent search performance. Low storage cost is important so that the entire query index can be loaded into main memory. Excellent search performance is critical so that the query index can handle a rapid stream. stabbing query problem [ 11 ], i.e. finding all the intervals that are stabbed by the data value. Figure 1 shows an example of a stabbing query problem, where various intervals are drawn as horizontal line segments. The intervals that intersect with the vertical line drawn at a data value are those that contain that data value. For and q 9 contain data value a j .
 bing query problem, such as segment trees, interval trees [ 2 ], R trees [ 5 ], interval binary search trees (IBS trees) [ 7 ] and interval skip lists (IS lists) [ 8 ]. However, they are generally not suitable for streams. Segment trees and interval trees gen-erally work well in a static environment but are not adequate when it is necessary to dynamically add or delete intervals. Originally designed to handle spatial data, such as rectangles, R trees can be used to index intervals. However, as indicated in [ 8 ], when there is heavy overlap among intervals, search performance degenerates quickly. Moreover, R trees are primarily disk-based indexes.
 indexing [ 7 , 8 ]. They were the first dynamic approaches that can handle a large number of overlapping intervals. As with other dynamic search trees, IBS trees and IS lists require O ( log ( n )) search time and O ( n log ( n )) storage cost, where achieve the O ( log ( n )) search time, a complex adjustment of the index structure is needed after an insertion or deletion. The adjustment is needed to rebalance the index structure. More important, the adjustment makes it difficult to reliably implement the algorithms in practice. Previous studies [ 8 ] indicated that IS lists perform better than IBS trees and are easier to implement, even though dynamic adjustments of the interval skip lists are still needed.
 cally for multidimensional spatial objects. In addition, they tend to be secondary storage-based indexes. In contrast, a main memory-based index is usually pre-ferred for stream processing, especially if the number of intervals indexed is large and the stream is rapid.
 query index is built directly with the query boundaries and search is conducted by comparing a data value with the query boundaries maintained in the index. Even with search time of O ( log ( n )) , such as the IS-lists approach, the search time may not be fast enough to handle a rapid stream, especially if n is large. cept of virtual constructs (VCs). A set of virtual constructs is predefined and prop-erly labeled. Each query is decomposed into one or more VCs and the query ID is inserted into the ID lists associated with the decomposed VCs. Search is con-query boundaries is needed during a search. Because of the query decomposition, the search result is contained in the ID lists associated with the covering VCs of a data value. We define VCs in such a way that there is only a small and fixed num-ber of VCs that can cover any data value. As a result, search time is independent of n , in terms of locating the covering VCs.
 tual construct intervals, v 1 ,...,v 5, which are used to decompose query intervals, Q 2 , Q 3and Q 4. After decomposition, query IDs are inserted into the associated ID lists. To perform a search on data value x , we first find the covering VCs for x . In this case, they are v 1and v 3. The search result is contained in the ID lists associated with v 1and v 3. From the VC-based query index, we find Q 2 , Q 3and Q 4.
 dex. These include the definition and proper labelling of the virtual constructs, the decomposition of query intervals and the computation of the covering VCs that contain any data value during a search. These issues must be carefully ad-dressed in order to have a query index that has both low storage cost and fast search time.
 lenging issues. It is memory based and has the properties of low storage cost and fast search operation, particularly suitable for stream processing. Unlike the IS-lists approach, no rebalancing is required. Hence, it is much easier to implement than IS lists. The new query index is centred around a set of predefined virtual containment-encoded intervals , or CEIs. We partition the range of interest of a numerical attribute into multiple segments. For each segment, a set of virtual CEIs are predefined. The CEIs are defined and labeled such that the containment rela-tionships among them are encoded in their IDs. The containment encoding makes decomposition and search operations efficient because integer additions and logi-cal shifts can be used to carry out most of the operations. Simulation studies show that the CEI-based query index outperforms the IS lists approach in terms of both storage cost and search time.
 struct intervals and their associated challenges. Section 3 describes the details of the CEI-based query index, including containment-encoded intervals, query de-composition and search algorithm. Section 4 analyses the average index storage costs for various VC-based query indexes. Section 5 presents performance studies based on simulations. Finally, Sect. 6 summarises the paper. 2 Virtual construct-based query indexes 2.1 System model There are two kinds of intervals discussed in this paper: (a) query or predicate intervals and (b) virtual construct intervals. Query intervals are real. They are de-fined by users over a numerical attribute to monitor a data stream. On the other hand, virtual construct intervals are created to decompose query intervals and per-form fast search operations. terval predicate on a numerical attribute. However, the result of this paper is ap-plicable to complex queries, where each query is specified with a conjunction of multiple interval predicates on various attributes. For example, a CEI-based query index can be maintained for each attribute in a two-phase algorithm involving complex queries, such as the ones presented in [ 3 , 13 ]. In the first phase, search operations against the CEI-based indexes are performed at individual attributes. The matched results are then merged in the second phase.
 tribute can be of integer or noninteger type. Query intervals have two integer end-points with an inclusive left endpoint and an exclusive right endpoint. 1 Namely, they can be specified as [ a , b ) ,where a and b are integers and a &lt; b .However, data values used for search can be any real numbers. Other design issues will be discussed on Sect. 3.4 for cases where both endpoints are inclusive or there is only one endpoint. 2.2 Alternative VCs and their challenges In a VC-based query index, a query ID q is replicated by d times, where d is the number of VCs used in the decomposition of q . For each VC, a pointer is needed to maintain the associated ID list. Hence, the storage cost of a VC-based query index depends on two parameters: the total number of VCs defined, N ,andthe total number of query IDs inserted due to decomposition, D . Assume C is the number of VCs that can possibly cover a data value. The search time of a VC-based query index depends on C . Different VC-based indexes have different N  X  X , D  X  X  and C  X  X , resulting in different storage costs and search times.
 vides a summarised comparison of the three. The first one is the simplest approach. It uses unit-length intervals ,orUI(seeFig. 3 a). The total number of VCs defined N equals r ,where r is the scope or range of the attribute. With UIs, labelling and decomposition are obvious. We simply label the unit-length intervals sequentially. The decomposition is by partitioning a query interval into one or more unit-length UIs. Search time is extremely fast because there is only a single VC that can cover any given data value x . However, the storage cost can be high. This is because we need to use  X  w UIs to decompose a query interval on average, where  X  w is the mean length of a query interval. Hence, the cost for storing the ID lists becomes large. If  X  w is large, the UI-based scheme cannot be scaled to a large n because the storage cost can be too large to fit into main memory.
 variable-length VCs. A larger sized VC can be used for decomposition, reducing the number of VCs in the decomposition. Because a query ID is inserted into all the decomposed VCs, the cost for the ID lists is reduced. In its simplest form, we define, for each integer attribute value, a set of L virtual intervals with length of 1 , 2 ,..., L ,where L is the maximal length of a VC. These L VCs all start at the same position but end at different positions. We call it a simple construct interval (SCI) approach (see Fig. 3 b). The total number of VCs defined N equals rL .More VCs increase the storage cost for maintaining the pointers to the ID lists, offsetting the benefit of low storage cost achieved due to fewer decomposed VCs.
 struct interval (LCI) approach (see Fig. 3 b). In LCI, the total number of VCs de-fined N equals ( 1 + log ( L )) r because we use 1 + log ( L ) variable-length VCs for each integer attribute value. For the rest of the paper, we use LCI as the repre-sentative for the variable-length interval approach. Both labelling and decompo-sition are simple under the LCI-based approach. One can sequentially label the ( 1 + log ( L )) VCs with the same left endpoints. The decomposition tries to use as few LCIs as possible by always choosing the largest available LCI for decompo-sition beginning from the left endpoint of the query interval. It can be proved that the number of LCIs that can cover any data value x is 2 L  X  1[ 12 ]. The storage cost is moderate for LCI. However, the search time becomes moderate or slow, especially if a large L is chosen in order to reduce the storage cost. containment-encoded intervals (see Fig. 3 c). It has the advantages of both low storage cost and fast search time. These advantages make CEI-based query index particularly suitable for a streaming environment. In CEI, the range of attribute values are partitioned into segments of length L ,where L is an integer that is a power of 2. Within each segment, we define 2 L  X  1 containment-encoded inter-vals. As a result, the total number of VCs defined is only 2 r  X  r / L , and the number of covering VCs for any data value x is 1 + log ( L ) . However, the labelling scheme and decomposition algorithm are nonobvious. They must be labelled carefully so that both decomposition and search operations can be carried out efficiently. In the rest of the paper, we will present our efficient solutions, which are also easy to implement. 3 CEI-based query indexing 3.1 Containment-encoded intervals Figure 4 shows an example of containment-encoded intervals and their local First, we partition r into r / L segments of length L , denoted as S i ,where i = 0 , 1 ,...,( r / L  X  1 ) , L = 2 k and k is an integer. Here, we assume r is a multiple of L . If not, we can simply expand it and make it so without impacting the sys-tem performance. Segment S i contains all the attribute values in [ iL ,( i + 1 ) L ) . Namely, S i ={ x | x  X  A  X  iL  X  x &lt;( i + 1 ) L } . Segment boundaries can be treated as guiding posts. Then, we define 2 L  X  1 CEIs for each segment as follows: (a) Define one CEI of length L , containing the entire segment; (b) De-fine two CEIs of length L / 2 by partitioning the segment; (c) Define four CEIs of length L / 4 by partitioning the segment; (d) Continue the process until L CEIs of unit length ( L / L = 1) are defined. For example, there is one CEI of length 8, two CEIs of length 4, four CEIs of length 2 and eight CEIs of length 1 in Fig. 4 . Property 3.1 The total number of CEIs in a segment is i = k i = 0 2 i = 2 L  X  1, where L = 2 k .
 in a special way. Every unit-length CEI is contained by a CEI of size 2, which is in turn contained by a CEI of size 4, which is in turn contained by a CEI of size 8, ...and so on.
 of a CEI has two parts: the segment ID and the local ID. For each segment, we assign 1 , 2 ,..., 2 L  X  1 to each of the 2 L  X  1 CEIs as their local IDs. The local ID assignment follows the labelling of a perfect binary tree (see Fig. 5 .) Local ID 1 is assigned to the CEI with length of L . Local ID 2 is assigned to the left CEI of length L / 2l while local ID 3 is assigned to the right CEI of length L / 2. Figure 4 shows the assignment of local IDs to CEIs within a segment.
 is simply computed as l + 2 iL ,where l is the local ID. Note that we assign 2 L local IDs for every segment, even though there are only 2 L  X  1 CEIs. Local ID 0 is not used.
 tree. The CEI with local ID 1 and length L is the root node, which contains two child CEIs of length L / 2 whose local IDs are 2 and 3, respectively. The leaf CEIs have unit length and local IDs L , L + 1 ,... to 2 L  X  1. Figures 4 and 5 show that, for L = 8, the leaf CEIs have local IDs from 8 , 9 ,..., to 15. The labelling of CEIs based on a perfect binary tree has many nice properties. These properties make possible efficient decomposition and search for the CEI-based query index. Due to containment encoding, almost all of the decomposition and search operations can be efficiently carried out. Property 3.2 There are k + 1 levels in the perfect binary tree formed with all the CEIs defined within a segment. Level i has 2 i CEIs, each with length L / 2 i ,for i = 0 , 1 ,..., k . The local IDs of CEIs at level i start from 2 i to 2 i + 1  X  1. Property 3.3 Any nonroot CEI is fully contained by its parent.
 Property 3.4 For any nonroot CEI with a local ID l , the local ID of its parent can be computed by l / 2 , or a logical right shift by 1 bit of the binary representation of l .
 Property 3.5 For any nonleaf CEI with a local ID l , the local IDs of its children are 2 l and 2 l + 1, respectively. Note that 2 l can be computed by a logical left shift by 1 bit of the binary representation of l .
 Property 3.6 For any data value x  X  A ,thereareexactly k + 1 CEIs that contain it because there are k + 1 levels of nonoverlapping CEIs in a segment.
 Property 3.7 For any data value x  X  A , the global ID of the unit-length CEI that contains x is l + 2 iL ,where i = x / L and l = x  X  iL + L .
 2 k = L to 2 L  X  1. Hence, the local ID of the CEI containing x is x  X  iL + L ,where i = x / L . Note that i can also be computed as x / L .However, it would involve a complex floating-point division because x is a noninteger. In contrast, x / L can be computed by first an integer conversion from a floating-point number, x , and then a logical right shift by k bits because L = 2 k . 3.2 Query insertion and deletion To insert a query interval, it is first decomposed into one or more CEIs, then its ID is inserted into the ID lists associated with the decomposed CEIs. The CEI-based query index maintains a set of query ID lists, one for each CEI. Similar to the inverted lists typically used in information retrieval, the query ID list associated with a CEI maintains all the query intervals that contain that CEI.
 of guiding posts and remnant intervals. We use segment boundaries as guiding posts. For each query q :[ a , b ) , we define two boundary guiding posts: P L and P
R . The left boundary guiding post, P L that is greater than or equal to a . The right boundary guiding post, P R = L b / L , is the rightmost guiding post that is smaller than or equal to b . These two boundary guiding posts are used to compute two remnant intervals, if any. The left remnant interval, R L ,isdefinedas [ a , P L ) .If P L equals a ,then R L is empty. The right remnant interval, R R ,isdefinedas [ P R , b ) .If P R equals b ,then R R is empty. compute the boundary guiding posts, P L and P R , and the remnant intervals, R L and R R . Then, we check if P L is greater than P R . If yes, it means that q com-pletely lies between two guiding posts without intersecting any. In this case, we call function BestPartition to decompose q . On the other hand, if P L &lt; P R ,then we insert the query ID q into the largest CEI of each segment that is completely contained by q between the two boundary guiding posts. This process repeats for ( P two remnant intervals, if there is any.
 ment or between two consecutive guiding posts. For example, we can always de-compose it using consecutive unit-length CEIs. As a query ID is inserted into all the ID lists associated with the decomposed CEIs, using more CEIs means more storage cost for the index. The goal of BestPartition algorithm is thus to min-imise the number of CEIs used in a decomposition. In other words, we want to use maximal-sized CEIs, if possible, for decomposition. BestPartition is based on the following property, which is derived from CEI labelling and can be easily observed from Fig. 4 .
 Property 3.8 Two C E I s a t l eve l i with consecutive local IDs can be replaced by a CEI at level i  X  1 of double length only if the smaller ID of the two CEIs at level i is even.
 unit-length CEI at level k toward the root CEI at level 0. For any interval of length m , where 0 &lt; m &lt; L , which lies between two consecutive guiding posts, it can be decomposed into m unit-length CEIs at level k . These unit-length CEIs have consecutive local IDs. The algorithm initialises a remnant interval R to be [ s , e ) , which is the interval to be decomposed. It starts with the local ID of the leftmost unit-length CEI. If the ID is an even number, then we try to replace two children CEIs with their parent CEI. Namely, we double the size of the CEI used in the decomposition. This is accomplished by dividing the ID by 2, or right shifting by 1 bit. Of course, if the right endpoint of the interval e is less than the right endpoint of the parent CEI, then we cannot use the parent CEI. In that case or if a local ID is an odd number, then we output a maximal CEI, remove the maximal CEI from R , and continue to decompose R from the local ID of the leftmost unit-length CEI for R . This process ends when R is empty.
 algorithm. The query interval has 6 unit-length CEIs with consecutive local IDs leftmost unit-length CEI for R , which has local ID 8, and successively tries to use its parent CEI by dividing the local ID by 2. The if condition that checks l is true when the local IDs are 8 and 4, but it is not true when the local ID is 2 because its parent CEI has a right endpoint exceeding 14. Therefore, it finds a maximal-sized CEI with local ID 2. This CEI is removed from R and the new remnant becomes [ 12 , 14 ) . Hence, the algorithm continues with the leftmost unit-length CEI for R , which now has local ID 12. This time the process stops when the local ID is 6 because its parent CEI (local ID 3) has a right endpoint exceeding 14. Hence, the second maximal-sized CEI is the one with local ID 6. After that, the algorithm stops because there is no more remnant interval, i.e., R =  X  .
 CEIs with local IDs from 11 to 14. Initially, R is [ 11 , 15 ) . The algorithm starts from the leftmost unit-length CEI whose local ID is 11. Because 11 is an odd number, it finds one maximal-sized CEI with local ID 11 and this CEI is removed from R . Hence, R becomes [ 12 , 15 ) . It continues with the leftmost unit-length CEI with local ID 12. It finds another maximal-sized CEI with local ID 6. Finally, it finds the third maximal-sized CEI with local ID 14.
 for ancestor CEIs and the leftmost unit-length CEI for the remnant interval R , if any. The computation involves only additions and logical shifts by 1 bit. Also note that decomposition means partitioning the query intervals into a set of CEIs. A decomposition is minimal when the number of CEIs in the decomposition is minimal among all the possible decompositions. We do not want the decomposed CEIs to be overlapping because it can result in duplicated query IDs in a search result. The storage cost would be higher as well because a query ID would be inserted into more ID lists.
 Lemma 1 Assume there is a decomposition, D i , that includes a CEI c i .Ifthereis another decomposition, D j , that includes a CEI c j and CEI c j is an ancestor of c ,then D i cannot be a minimal decomposition.
 Proof Assume decomposition D i is minimal. Figure 8 shows an example of two decompositions, D i and D j . D i contains CEI c i and D j contains CEI c j and c j is an ancestor of c i . From the definition of CEIs, there is no CEI of length less than | c j | that can cross the vertical lines at either endpoints of CEI c j due to containment property. As a result, there is more than one CEI besides c i that contradiction.
 Lemma 2 A minimal decomposition is unique.
 Proof Suppose there are two decompositions, D 1 and D 2 , that are different and are both minimal. If we sort both decompositions based on the left endpoints of the decomposed CEIs, there must exist a point where the first mismatch between D 1 and D 2 occurs if we scan the decompositions from left to right. The mismatch is due to different lengths because both have the same left endpoint. Hence, the small-sized CEI is a descendant of the large-sized CEI. From Lemma 1, the one with the small-sized CEI cannot be minimal. Therefore, there is only one unique minimal decomposition.
 Theorem 1 BestPartition decomposes any query interval of length less than L into a minimal number of CEIs.
 Proof Suppose D opt is the minimal decomposition. Let D bp be the decomposition generated by the BestPartition algorithm. Consider both decompositions as sorted based on the left endpoints of the decomposed CEIs. If CEIs c i and c j , where c i  X  D opt and c j  X  D bp , are the first CEIs that show a mismatch between the two decompositions, there are two cases to consider (see Fig. 9 a and b). For decomposition D opt cannot be minimal. A contradiction occurs. For the second have the same left endpoint, c j must have an even-numbered local ID, based descendant of CEI c i as shown in Fig. 9 b. If CEI c i has an even local ID, then its parent CEI must exceed the right endpoint of the query interval. Otherwise, D opt would not be minimal. Hence, CEI c i must either have an odd local ID or have a parent CEI whose length exceeds the right endpoint of the query interval. Under either condition, the BestPartition algorithm does not stop at CEI c j . It would continue skipping the ancestor of CEI c j until it reaches CEI c i . Therefore CEI c , instead of c j , should be in decomposition D bp . Hence, CEIs c i and c j cannot BestPartition indeed finds the minimal decomposition.
 position of four query intervals: Q 1 , Q 2 , Q 3and Q 4 within a specific segment containing CEIs of c 1 ,..., c 7. Q 1 completely covers the segment, and its ID is inserted into c 1. Q 2 lies within the segment and is decomposed into c 5and c 6, the largest CEIs that can be used. Q 3 also resides within the segment, but its right endpoint coincides with a guiding post. As a result, we can use c 3, instead of c 6 and c 7 for decomposition. Similarly, c 2isusedtodecompose Q 4. As shown in Fig. 10 , query IDs are inserted into the ID lists associated with the decomposed CEIs.
 the query ID is deleted from the ID lists associated with the decomposed CEIs.
 3.3 Searching the query index Figure 11 shows the pseudo-code for the search algorithm. It first computes the ID of the segment that contains a data value x . From Property 3.7 , this ID is computed via x / L . Then, it computes the local ID of the leaf CEI that contains x ,which is x  X  iL + L . Based on Property 3.6 , there are exactly k + 1 CEIs that contain any data value x . Hence, the search results are stored in the k + 1 ID lists associated with these CEIs. Because of the containment encoding (see Property 3.4 ), the local IDs of these k + 1 CEIs can be computed by successively dividing that of the leaf CEI by 2.
 teger conversion from a floating point number. The rest involves only integer ad-ditions and logical shifts. No complex floating point multiplications or divisions are needed. As a result, the search operation is extremely fast. The search time is independent of n ,where n is the total number of query intervals maintained, in terms of finding the k + 1 ID lists. However, if reporting time is also included, the search time increases as n increases. This is because there are more IDs stored in each ID list, on average, as n increases.
 local ID of the unit-length CEI that contains it. In this case, it is c 5. Then, from c 5, we can compute the local IDs of all its ancestors that contain c 5. In this case, they are c 2and c 1. As a result, the search result is contained in the 3 ID lists associated with c 1 , c 2and c 5. We can verify from Fig. 10 that the result indeed contains Q 1 , Q 2 , Q 3and Q 4. 3.4 Other system issues i.e. [ a , b ] , we need to use additional r point CEIs. These points are maintained separately. They will be useful only if the attribute is of integer data type. During decomposition, the query ID is additionally inserted into the ID list associated with the point CEI representing b . At search, we also report the IDs stored in the ID list associated with the integer data value.
 ID can be inserted into r / L CEIs in the worst case. If L is small, the storage cost can be high. Fortunately, we can choose a large L to reduce the storage cost. In fact, we can set L = r . In that case, the search time may degrade a bit because we need to collect the search result from exactly k + 1 ID lists, where k = log ( L ) = log ( r ) .
 ing. We can control both storage cost and search time by choosing a relatively large L and by properly separating r into partitions. One machine can then be used to process a partition. 4 Storage cost analysis Here, we analyse the average storage costs of the three VC-based query indexes. The storage cost can be expressed as 4 N + 8 n  X  bytes, where N is the total number of VCs defined, n is the total number of queries and  X  is the average number of de-composed VCs per query interval. We assume that a query ID and a pointer require 4 bytes each. N is available from Table 1 .However,  X  is dependent on the starting position and the length of a query interval. For the analysis, the query length w is uniformly distributed between 1 and W and the starting endpoint is also uniformly distributed. The first term represents the storage cost for the headers while the sec-ond term for the ID lists. For the UI-based query index, the average of unit-length intervals decomposed per query, denoted as  X  UI ,is ( 1 + W )/ 2 because each query interval is decomposed into w unit-length intervals and 1  X  w  X  W . We will now derive  X  CEI and  X  LCI as follows. 4.1 CEI storage cost Definition 1 Let B k w be the k -bit binary representation of w and | B k w | be the num-berof1 X  X in B k w .
 Lemma 3 If a query interval q , whose length w&lt; L , has either its left or right endpoint aligned to a guiding post, it will be decomposed into | B k w | CEIs by the BestPartition algorithm.
 Proof Because q is aligned to a guiding post, it must have an endpoint that is a multiple of L . Thus, q is either in the form of [ iL , iL + w) or [ iL  X  w, iL ) for 1  X  w&lt; L and i is an integer. It is easy to verify that the BestPartition algo-rithm finds CEIs of distinct lengths of 2 X  X  powers in decreasing order for the case of left-endpoint alignment and in increasing order for the case of right-endpoint alignment. Because every bit in B k w represents a distinct 2 X  X  power, there is a 1-to-1 mapping between the bit positions and lengths of decomposed CEIs. Therefore, q can be decomposed into | B k w | CEIs.
 binary representations. Because each bit position has 2 d  X  1 1 X  X  among all possible d -bit binary representations, there are d  X  2 d  X  1 1 X  X . When d = k = log ( L ) ,we per query interval. We enumerate all of the possible query intervals based on their left endpoints and lengths. More formally, where t ( p ,w) is the number of CEIs used in decomposing the interval with a left endpoint at p and a length w . Note that query intervals and left endpoints are represented with the style of [ a , b ) , while interval lengths are specified with the style of ( c , d ] .
 are within a specific common segment and whose lengths are between 1 and W . Without loss of generality, we pick two arbitrary successive guiding posts (say  X 
L and ( X  + 1 ) L ,where  X  is an integer) as the common segment. Namely, p  X  [  X  L ,( X  + 1 ) L ) . For simplicity, the common segment is chosen such that ( X  + 1 ) L + W &lt; r . There are L possible positions for the left endpoint of a query interval, and for each position, there are up to W query intervals to be decomposed. In other words, if W &lt; L , a smaller L can always be chosen.

L . Because we can categorise intervals of lengths from 1 to W into different we have Therefore, When 1  X  i  X   X   X  1, all of the enumerated intervals have lengths greater than L , which must cross the right guiding post of the common segment. If there are either one or two remnant intervals due to the decomposition process, they must be aligned with some guiding posts. Therefore, Lemmas 3 and 4 can be used to prove the following Lemma: Proof As shown in Fig. 12 , each integer point in the common segment is the left endpoint of L query intervals of lengths L + 1, L + 2, ... ,2 L respectively. These intervals must be decomposed into two or three subintervals by one or two guiding posts. These subintervals must have at least one endpoint aligned to some guiding posts. The number of decomposed CEIs inside the common segment is L + L | B k decomposed CEIs outside the common segment is L L  X  1 i = 1 | B k i |+ L i = 1 i ,where the second sum is for counting the number of decomposed CEIs with length L . Therefore, Proof The ( i  X  1 ) in the second term is due to additional i  X  1 segments, and each extra segment contributes L 2 more CEIs of length L .
 interval of length less than or equal to L may be totally contained within the com-mon segment without crossing any guiding post. Fortunately, we observed that intervals of lengths from 1 to L can be categorised further into intervals of lengths In other words, As there are L distinct CEIs of length 1 within the common segment, we have common segment into 2 j subsegments and apply the same counting method to the leftmost or first subsegment, i.e. [  X  L , X  L + L scaled-down version of T ( L , 2 L ] . However, instead of working with the full k bits, we are now using only the k  X  j least significant bits (LSBs). Because left end-points distribute evenly on all subsegments, we can multiply the number obtained using the first subsegment by the number of subsegments (2 j ). However, there are overcounts and we need to offset them.
 tioned into 2 subsegments [  X  L , X  L + L / 2 ) and [  X  L + L / 2 , X  L + L ) .Weevaluate the ( L 2 ) 2 intervals that have left endpoints in the first subsegment and with various in the second subsegment. Both groups of intervals share the same pattern, and therefore we can just count the first group. There are two CEIs of length L / 2in the subsegment, [  X  L , X  L + L / 2 ) and [  X  L + L / 2 , X  L + L ) . Consider the vertical dotted line at  X  L + L / 2. There are no CEIs of lengths smaller than L that can cross this vertical line. The number of CEIs decomposed from the left-hand side is and from the right-hand side is Because log ( L / 2 ) = k  X  1, only k  X  1 LSBs are involved. Adding both numbers second subsegment, and offsetting the overcount by 1, we get log ( L 2 ) . The overcount happens for interval [  X  L , X  L + L ) , which requires two CEIs of length L / 2 (from left and right) to decompose, while we can use just one CEIoflength L .
 half of them are overcounted by 1 each. This is because we use two CEIs of length L / 2 j  X  2 to decompose each of the 2 j CEIs within and outside of the sub-or com-mon segment. Therefore, we have Lemma 7 T L vals of various lengths.
 Theorem 2 4.2 LCI storage cost Similar to the CEI case, we enumerate all of the possible query intervals based decomposed LCIs for a query interval, denoted as  X  LCI . More formally, where t ( p ,w) is the number of LCIs used in decomposing the interval with a left endpoint p and a length w .
 1, 2, ... ,and W , respectively. Note that we exclude the boundary condition at the right-hand side to simplify the calculation. Therefore, we are actually computing with a length w . We can similarly define T ( 0 , W ] as a shorthand representation for w  X  ( 0 , W ] t (w) . Instead of looking at the left endpoints within a segment as in the CEI scheme, we look at left endpoints matching any arbitrary point.
 Lemma 8 T ( 0 , L ] = 1 + L 2 log L .
 Because the decomposing algorithm starts from the left-hand side and uses an LCI as large as possible, the number of LCIs decomposed for an interval of length w contributes L more LCIs of length L . Therefore, we have 4.3 Comparisons of three query indexes Ta b l e 2 summarises the closed-form formulae for the average number of decom-posed virtual constructs per query interval for the three VC-based query indexes. Both the lower and upper bounds for  X  CEI and  X  LCI are shown. To verify the accuracy of our analyses, we ran simulations and plotted the total number of de-composed virtual constructs. Figure 14 a and b show the upper and lower bounds and simulation results for the CEI-based and LCI-based indexes, respectively. Figure 14 c compares all three indexes. For this experiment, W = 200 , n = 100 , 000 and r = 1 , 048 , 576. These figures show that (1) the analyses are accu-rate, (2) the number of total decomposed virtual constructs is significantly larger for the UI-based index than the other two indexes and (3) the CEI-based index uses more virtual constructs than the LCI-based index in query decomposition. 5 Simulation studies Simulations were conducted to evaluate and compare the CEI-based index with the LCI-based index, the UI-based index and the IS-lists approach [ 8 ]. We focused on storage cost and search time because they are two of the most important metrics in determining the effectiveness of a query index for stream processing. A low storage cost is desirable so that the entire index can be loaded into main memory. A fast search time is important so that a rapid stream can be properly handled. The IS-lists approach represents the state of the art direct-indexing approach. It has O ( log ( n )) search time and O ( n log ( n )) storage cost. In contrast, the search times, in terms of finding the ID lists from the covering VCs, of the UI-based, LCI-based and CEI-based indexes are independent of n . However, in our simulations, the search time included the report time. As a result, it generally increases as n increases. This is because, on average, the ID lists contain more query IDs. We implemented the three alternative VC-based indexes. For the IS-lists approach, we downloaded from the Web an implementation from the authors [ 6 ] and used it to run the same sets of input data. The simulations were conducted on an RS6000 model 43P machine running AIX 5.1.
 the small r . The starting point of a query interval was randomly chosen between 1and r  X  1withalengthof w randomly chosen between 1 and W . Namely,  X  w = W / 2. Various W  X  X  were used, with a default 200. A total of n query intervals were generated and inserted. In the experiments, n was varied from 5,000 to 640,000. After insertion, we performed 50,000 random searches and computed the average search time and storage cost. The data value for search was a floating point number chosen randomly between 1 and r . The search time included the report time, which involves reporting the query IDs in the ID lists. If there are large numbers of IDs stored in the ID lists, the report time will be large as a result. 5.1 Impact of maximum interval length ( L ) We first examine the impact of the maximum interval length L on the three alter-native VC-based indexes in terms of storage cost and average search time. For this set of experiments, we compare the UI-based, LCI-based and CEI-based indexes. Figure 15 a and b show the storage cost and average search time, respectively, of ab the three indexes when r is large. In contrast, Fig. 16 a and b show storage cost and average search time, respectively, when r is small. For the entire set of exper-iments, a default W of 200 was used. The total number of query intervals inserted was 100,000.
 timeforalarge r and a small r . Moreover, the storage cost and search time are independent of L because it used unit-length virtual intervals. The CEI-based index has both low storage cost and fast search time for both r  X  X . In general, the average search time increases as L increases. This is particularly true for the LCI-based index because its search time increases much more quickly than the CEI-based index as L increases. This can be seen from the formula for C described in Table 1 . Hence, it argues for a small L for the LCI-based index from the search time perspective. However, if L is too small, the storage cost tends to increase for both schemes. This is because more query IDs are stored in the ID lists because the total number of decompositions D is larger with a smaller L (see Ta b l e 1 ). Moreover, when r is large, the storage cost of the LCI-based index also increases as L increases (see Fig. 15 a). However, under all cases, the storage cost of the CEI-based index decreases as L increases.
 the LCI-based index as L increases. This is because the report time is the same for all different L  X  X  because n remains the same for all the experiments. The difference is due to the computation of the IDs of the extra covering CEIs for a larger L . Because C = 1 + log ( L ) , it increases much slower than that of the LCI-based index, which is 2 L  X  1. Hence, for the CEI-based index, it argues for a larger L because the storage cost tends to decrease and the average search time increases only slightly as L increases. This result is important in practice. We can choose a larger L in order to minimise the storage cost without significantly degrading the average search time.
 in terms of both storage cost and average search time. The advantage in average search time is particularly dramatic when L is large (see Figs. 15 band 16 b). 5.2 Comparisons of CEI-based index with IS lists Now we compare the CEI-based scheme with the UI-based, the LCI-based and the IS-lists approaches. Figure 17 a and b show the impact of the maximal query interval width, W , on the performance of the four schemes. Figure 17 ashowsthe storage cost while Fig. 17 b shows the average search time. For this experiment, W was varied from 10 to 320 and L = 16, r = 65 , 536 and n = 50 , 000 were used. time for the entire range of W  X  X . The CEI-based has both low storage cost and fast search time. All three VC-based approaches outperform the IS-lists approach in terms of search time. For the smallest W = 10, the performance difference is almost 20 times. Namely, the average search time of the CEI-based index is only 1 / 20 that of the IS-based approach. The IS-lists approach also has a higher storage cost than both the LCI-based and CEI-based indexes. But it has a smaller storage cost than the UI-based index when W is large (see Fig. 17 a).
 time, respectively, when r is large. Figure 19 a and b shows the index storage cost and average search time, respectively, when r is small. For this set of experiments, W was 200 and n was varied from 5,000 to 640,000 and L = 16.
 performs both the LCI-based index and the IS-lists approach. Moreover, it is very close to the UI-based index, which has the best search time performance. The IS-lists approach, which is the best direct indexing approach, has the highest search time. Note that there are missing data points for the UI-based and the IS-lists ap-proaches. This is because, for those data points, n was too large for both schemes to be executed properly on our computer system, which is an AIX model 43P machine. Memory was exhausted by the indexes.
 n is relatively small. But, as n increases, this advantage disappears. This is because the UI-based, LCI-based and CEI-based indexes need to maintain pointers to the ID lists for every VC. When r is large and n is small, the storage cost for the pointers dominates the total storage cost, even though most of them are NULL. In contrast, the IS lists approach does not have to maintain those pointers. However, for a small r , the storage cost advantage of the IS-lists approach also disappears. 6 Summary We have presented a CEI-based query-indexing approach for efficient stream pro-cessing. It is a main memory-based approach and has both low storage cost and fast search time, ideally suited for stream processing. The CEI-based query in-dex is centred on a set of virtual containment-encoded intervals. The range of a numerical attribute is partitioned into segments. For each segment, a set of vir-tual containment-encoded intervals were carefully defined and properly labelled as a perfect binary tree. A query interval is first decomposed into one or more CEIs and the query ID is inserted into the ID lists associated with the decomposed CEIs. Search is carried out indirectly via these CEIs. There is no need to compare a data value with any of the query boundaries during a search. The containment encoding makes possible efficient decomposition and search operations. Almost all of the operations can be carried out with integer additions and logical shifts. Analyses and simulations were conducted to evaluate the performance of the CEI-based query index. The results show that, compared with other alternatives, the CEI-based query index does have low storage cost and fast search time and it outperforms other alternatives in both.
 References
