 In the main body of the paper, we assumed that global position estimates of at least four landmarks were known. When these landmarks are known, we can recover all of the estimated landmark positions and robot locations.
 In many cases, however, no global positions are known; the best we can hope to do is recover landmark and robot positions up to an orthogonal transform (trans-lation, rotation, and reflection). It turns out that Eqs. ( 7 ) provide enough geometric constraints to per-form this metric upgrade, as long as we have at least 8 landmarks and at least 8 time steps. The idea is to fit a quadratic surface to the rows of U or the columns of V , then change coordinates so that the surface be-comes the functions given in ( 7 ).
 To derive the metric upgrade, suppose that we start from an N  X  4 matrix U of learned landmark coor-dinates and an 4  X  N matrix V of learned robot co-ordinates from the algorithm of Sec. 3.1 . We would like to transform the learned coordinates into two new matrices C and X such that where c is a row of C and x is a column of X . At a high level, we first fit a quadratic surface to the rows of U , then transform this surface so that it satis-fies Eq. 14  X  15 , and scale the surface so that it satisfies Eq. 16 . Our surface will then automatically also sat-isfy Eq. 17 ,since X must be metrically correct if C is.
 In more detail, we first (step i) linearly transform each row of U into approximately the form (1 ,r i, 1 ,r i, 2 ,r we use linear regression to find a coe cient vector a 2 R 4 such that Ua  X  1 ,thenset R = UQ where Q 2 R 4  X  3 is an orthonormal basis for the nullspace of a . After this step, our factorization is ( UT 1 )( T 1 1 V ), where T 1 =( aQ ).
 Next (step ii) we fit an implicit quadratic surface to the rows of R by finding 9 coe cients b jk (for 0  X  j  X  k  X  3) such that To do so, we form a matrix S that has the same number of rows as U but 9 columns. The elements of row i of S are r i,j r i,k for 0  X  j  X  k  X  3 (in any fixed order; for conciseness, we take r i, 0 = 1 for all i ). Then we find a vector b 2 R 9 that is approximately in the nullspace of S T by taking a singular value decomposition of S and selecting the right singular vector corresponding to the smallest singular value. Using this vector, we can define our quadratic as 0  X  1 2 r T Hr + ` T r + b 00 where r is a row of R , and the Hessian matrix H and linear part ` are given by: Over the next few steps we will transform the coor-dinates in R to bring our quadratic into the form of Eq. 15 : that is, one coordinate will be a quadratic function of the other two, there will be no linear or constant terms, and the quadratic part will be spheri-cal with coe cient 1 2 .
 We start (step iii) by transforming coordinates so that our quadratic has no cross-terms, i.e., so that its Hessian matrix is diagonal. Using a 3  X  3 singu-lar value decomposition, we can factor H = MH 0 M T so that M is orthonormal and H 0 is diagonal. If we set R 0 = RM and ` 0 = M ` , and write r 0 for a row of R 0 , we can equivalently write our quadratic as Hessian as desired. After this step, our factorization is ( UT 1 T 2 )( T 1 2 T 1 1 V ), where Our next step (step iv) is to turn our implicit quadratic surface into an explicit quadratic function. For this purpose we pick one of the coordinates of R 0 and write it as a function of the other two. In order to do so, we must have zero as the corresponding diagonal element of the Hessian H 0  X  X lse we cannot guarantee that we can solve for a unique value of the chosen coordinate. So, we will take the index j such that H 0 jj is mini-mal, and set H 0 jj = 0. Suppose that we pick the last coordinate, j = 3. (We can always reorder columns to make this true; SVD software will typically do so automatically.) Then our quadratic becomes 0= r = Now (step v) we can shift and rescale our coordinates one more time to get our quadratic in the desired form: translate so that the linear and constant coe cients are 0, and rescale so that the quadratic coe cients are 1 2 . For the translation, we define new coordinates r 00 = r 0 + c for c 2 R 3 , so that our quadratic becomes By expanding and matching coe cients, we know c must satisfy The first two equations are linear in c 1 and c 2 (and don X  X  contain c 3 ). So, we can solve directly for c 1 and c ; then we can plug their values into the last equation to find c 3 . For the scaling, the coe cient of r 00 1 is now scale these two coordinates separately to bring their coe cients to 1 2 .
 After this step, our factorization is U 0 V 0 ,where U 0 = The left factor U 0 will now satisfy Eq. 14  X  15 .Westill have one last useful degree of freedom: if we set C = U T 4 ,where for any  X  2 R ,then C will still satisfy Eq. 14  X  15 .So (step vi), we will pick  X  to satisfy Eq. 16 : in particular, we set  X  = If we have 7 learned coordinates in U as in Sec. 3.2 , we need to find a subspace of 4 coordinates in order to perform metric upgrade. To do so, we take advan-tage of the special form of the correct answer, given in Eq. 10 : in the upper block of C in Eq. 10 ,three coordinates are identically zero. Since U is a linear transformation of C , there will be three linear func-tions of the top block of U that are identically zero (or approximately zero in the presence of noise). We can use SVD on the top block of U to find and remove these linear functions (by setting the smallest three singular values to zero), then proceed as above with the four remaining coordinates.
 Here we provide the details on how our estimation er-ror scales with the number T of training examples X  that is, the scaling of the di  X  erence between the esti-mated measurement model b U , which contains the loca-tion of the landmarks, and its population counterpart. Our bound has two parts. First we use standard con-centration bounds to show that each element of our estimated covariance c M = b Y b Y &gt; approaches its popu-lation value. We use the Azuma-Hoe  X  ding inequality to bound the probability that the sum of random vari-ables deviates from its mean. We start by rewriting the empirical covariance matrix as a vector summed over multiple samples: where  X  = ( b Y b Y ) &gt; is the matrix of column-wise Kronecker products of the observations b Y . We assume that each element of  X  minus its expectation E  X  i is bounded by a constant c ; we can derive c from bounds on anticipated errors in distance measurements and odometry measurements. Then the Azuma-Hoe  X  ding inequality bounds the probability that the empirical sum di  X  ers too much from its population value: If we pick  X  = probability in terms of T :
P " which means that the probability decreases as O ( 1 T ) and the threshold decreases as  X  O ( 1 p We can then use a union bound over all (2 N ) 2 covari-ance elements j (since b Y 2 R 2 N  X  T ): 8 That is, with high probability, the entire empirical co-variance matrix c M is going to be close (in max-norm) to its expectation.
 Next we use the continuity of the SVD to show that the learned subspace approaches its true value. Let c M = M + E ,where E is the perturbation (so the largest element of E is bounded). Let b U be the output of SVD, and let U be the population value (the top singular vectors of the true M ). Let be the matrix of canonical angles between range( U ) and range( b U ). Since we know the exact rank of the true M (either 4 or 7), the last (4th or 7th) singular value of M will be positive; call it &gt; 0. So, by Theorem 4.4 of Stewart and Sun (1998), This result uses a 2-norm bound on E , but the bound we showed above is in terms of the largest element of E . But, the 2-norm can be bounded in terms of the largest element: Finally, the result is that we can bound the canonical angle: In other words, the canonical angle shrinks at a rate of  X  Once we have learned an interpretable state space via the algorithm of Section 3.3 , we can simply write down the nominal robot dynamics in this space. The accu-racy of the resulting model will depend on how well our sensors and actuators follow the nominal dynamics, as well as how well we have learned the transformation S to the interpretable version of the state space. In more detail, we model the robot as a controlled non-linear dynamical system. The evolution is governed by the following state space equations, which general-ize ( 1 ): Here s t 2 R k denotes the hidden state, a t 2 R l denotes the control signal, o t 2 R m denotes the observation,  X  2 R k denotes the state noise, and  X  t 2 R m denotes the observation noise. For our range-only system, fol-lowing the decomposition of Section 3 ,wehave: Here v t and ! t are the translation and rotation calcu-lated from the robot X  X  odometry. A nice property of this model is that expected observations are a linear function of state: The dynamics, however, are nonlinear :seeEq. 22 , which can easily be derived from the basic kinematic motion model for a wheeled robot ( Thrun et al. , 2005 ). C.0.1. Robot System Identification To apply the model of Section C , it is essential that we maintain states in the physical coordinate frame, and not just the linearly transformed coordinate frame X  i.e., b C and not b U = b CS 1 . However, it is possible instead to use system identification to learn to filter directly in the raw state space b U . We conjecture that it may be more robust to do so, since we will not be sensitive to errors in the metric upgrade process (errors in learning S ), and since we can learn to compensate for some deviations from the nominal model of Sec-tion C .
 To derive our system identification algorithm, we can explicitly rewrite f ( s t ,a t ) as a nonlinear feature-expansion map followed by a linear projection. Our algorithm will then just be to use linear regression to learn the linear part of f .
 First, let X  X  look at the dynamics for the special case of S = I . Each additive term in Eq. 22 is the product of at most two terms in s t and at most two terms in a where  X  a t =[1 ,a t ] T and  X  is the Kronecker product. (Many of the dimensions of ( s t ,a t ) are duplicates; for e ciency we would delete these duplicates, but for simplicity of notation we keep them.) Each additive term in Eq. 22 is a multiple of an element of ( s t ,a t ), so we can write the dynamics as: where N is a linear function that picks out the correct entries to form Eq. 22 .
 Now, given an invertible matrix S , we can rewrite f ( s t ,a t ) as an equivalent function in the transformed state space: To do so, we use the identity ( Ax )  X  ( By )=( A  X  B )( x  X  y ). Repeated application yields where  X  S = S  X  S  X  I  X  I . Note that  X  S is invertible (since rank( A  X  B ) = rank( A ) rank( B )); so, we can write Using this representation, we can learn the linear part of f , SN  X  S 1 , directly from our state estimates: we just do a linear regression from ( Ss t ,a t )to Ss t +1 . Algorithm 2 Robot System Identification ment model for 4 landmarks C 1:4 (by e.g. GPS) Out : measurement model b C , motion model b N , robot states b X (the t th column is state s t ) 1: Collect observations and odometry into a matrix 2: Find the the top 7 singular values and vectors: 3: Find the transformed measurement matrix 4: Compute a matrix with columns t = 5: Compute dynamics: S b N  X  S 1 = S b X 2: T ( 1: T 1 ) 6: Compute the partial S 1 : b S 1 = C 1 1:4 ( b C 1:4 S 1 7: Given b X , we can compute the full S as S = 8: Finally, from steps 3,5, and 7, we find the inter-For convenience, we summarize the entire learning algorithm (state space discovery followed by system identification) as Algorithm 1 .
 C.0.2. Filtering with the Extended Kalman Whether we learn the dynamics through system identi-fication or simply write them down in the interpretable version of our state space, we will end up with a transi-tion model of the form ( 23 ) and an observation model of the form ( 21 ). Given these models, it is easy to write down an EKF which tracks the robot state. The measurement update is just a standard Kalman filter update (see, e.g., ( Thrun et al. , 2005 )), since the ob-servation model is linear. For the motion update, we need a Taylor approximation of the expected state at time t + 1 around the current MAP state  X  s t , given the current action a t : We simply plug this Taylor approximation into the standard Kalman filter motion update (e.g., ( Thrun et al. , 2005 )).
 Our simulator randomly places 6 landmarks in a 2-D environment. A robot then randomly moves through the environment for 500 time steps and receives a range reading to each one of the landmarks at each time step. The range readings are perturbed by noise sampled from a Gaussian distribution with variance equal to 1% of the range. Given this data, we apply the algo-rithm from Section 3.3 to solve the SLAM problem. We use the coordinates of 4 landmarks to learn the linear transform S and recover the true state space, as shown in Figure 1 A. The results indicate that we can accurately recover both the landmark locations and the robot path.
 We also investigated the empirical convergence rate of our observation model (and therefore the map) as the number of range readings increased. To do so, we generated 1000 di  X  erent random pairs of environ-ments and robot paths. For each pair, we repeatedly performed our spectral SLAM algorithm on increas-ingly large numbers of range readings and looked at the di  X  erence between our estimated measurement model (the robot X  X  map) and the true measurement model || b
C C || F . The results are shown in Figure 1 B, and show that our estimates steadily converge to the true model, corroborating our theoretical results (in Sec-
