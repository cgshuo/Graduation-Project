 The aggregation of search results from heterogeneous ver-ticals (news, videos, blogs, etc) has become an important consideration in search. When aiming to select suitable ver-ticals, from which items are selected to be shown along with the standard  X  X en blue links X , there exists the potential to both help (selecting relevant verticals) and harm (selecting irrelevant verticals) the existing result set.

In this paper, we present an approach that considers both reward and risk within the task of vertical selection (VS). We propose a novel risk-aware VS evaluation metric that in-corporates users X  risk-levels and users X  individual preference of verticals. Using the proposed metric, we present a de-tailed analysis of both reward and risk of current resource se-lection approaches within a multi-label classification frame-work. The results bring insights into the effectiveness and robustness of current vertical selection approaches. H.3.3 [ Information Systems ]: Information Search and Re-trieval Measurement, Experimentation aggregated search, vertical selection, evaluation
With the emergence of numerous vertical search engines, it is popular to present results from a set of verticals dispersed throughout the standard  X  X eneral web X  results (e.g. adding images results to queries about  X  X lowers X ). A key component of so-called aggregated search is vertical selection (VS), that is selecting multiple (zero to many) relevant verticals from which items are selected and presented on the search result page. Current work has focused on selecting a single relevant vertical [3], or on ranking vertical blocks that in turn are to be presented on the aggregated page [1].

When selecting suitable verticals, there exists the poten-tial to both help (selecting relevant verticals) and harm (se-lecting irrelevant verticals) the existing result set. A VS sys-tem should only select a vertical when it is confident that it will benefit most users while seldom frustrating others. Existing work ([2][3][13]) evaluates VS based solely on max-imising reward (e.g. the number of queries correctly classi-fied as relating to a vertical [3]), or the average correlation with the  X  X erfectly ranked X  reference page [2]. We argue that for VS, reward must be considered in conjunction with risk. We argue that maximising the reward alone is not suf-ficient, and that a robust VS approach and its evaluation should focus on maximising reward while minimising risk.
We propose a new risk-aware VS evaluation metric. Rather than treating a vertical as either relevant or irrelevant given a query, as mostly done in current work [3], we propose a general framework to evaluate the reward and risk for VS on a per user basis. This is motivated by the fact that current research [12] shows that the level of inter-annotator agree-ment for what constitutes a  X  X elevant X  vertical is low (users X  preferred verticals are diverse). Our proposed metric is flex-ible as it allows systems to be evaluated across a population of users, where users may have varying levels of risk (risk-averse vs. risk-seeking) and may have varying preferences across verticals (vertical relevance is user specific). In this paper, we perform an analysis of the effectiveness of differ-ent VS approaches across these different types of user [5]. Furthermore, we present an analysis of the robustness of VS approaches across all users with various levels of risk 1
We treat VS as a multi-label classification problem (mul-tiple verticals are relevant to a query) and we train a set of VS systems according to different controlled risk-levels (some systems are more risk-averse than others). We then analyse these trained VS systems with varying types of user (risk-averse and risk-seeking). We hypothesise that:
An analysis of the distribution of risk-levels in the user pop-ulation lies outside the scope of this work. This information could be estimated from query logs or through a survey of a sample of users. Section 2 outlines our proposed risk-aware VS metric. In Section 3, we formally describe the problem of multi-label vertical classification and list the features used. In Section 4, we empirically evaluate the effectiveness and robustness of those approaches using our proposed risk-aware metric. We conclude the paper in Section 5.
We present our risk-aware metric for VS, which considers an entire population of users X  vertical preferences for a query.
Let V = { v 1 ,v 2 , ...v n } be a set of verticals that can be selected to present along with  X  X eneral web X  results W ,fora given query q  X  Q .Let V u i q be a set of verticals that a user u  X  U would like to see in the result set with  X  X eneral web X  results for query q . These user-specific assessments can be obtained by either conducting a user study that explicitly asks users for their preferences [12] or be estimated by min-ing query logs [7]. We model this subjective view of vertical relevance where users X  vertical preferences can be different [12]. Therefore, V u i q  X  V and V u j q  X  V .

Furthermore, assume a vertical selection system s j selects a vertical set V s j q for q . Then, for a specific user u ity of vertical search system s j is based on both reward and risk . Reward is related to the number of verticals selected by s j that user u i deems relevant ( V s j q V u i q ). While risk is related to the number of verticals selected by s j that user u deems non-relevant ( V s j q ( V  X  V u i q )).

Furthermore, each user has his/her own estimated trade-off between reward and risk. For example, one user might be risk-seeking and prefers to have a page with some relevant verticals but does not mind viewing many non-relevant ones. On the contrary, another users might be risk-averse and prefers the page to only contain relevant verticals. There-fore, the main aim of the proposed metric is to model the trade-off between so-called reward and risk for each user u
For a given user u i and system s j that returns V s j q ,we define the reward and risk as user-specific vertical recall and vertical fallout respectively as follows:
To combine the above measure and also incorporate the user X  X  trade-off between reward and risk, we model the met-ric as a linear combination of reward and risk: where  X  u i q is a user-specific parameter that controls the trade-off between reward and risk. Setting  X  u i q =1leadstoa risk-averse metric where returning zero irrelevant verticals would be optimal, while setting  X  u i q = 0 leads to a risk-seeking metric where returning as many relevant verticals would be optimal.

The utility of the system s j is averaged over all q  X  Q , and within each q is averaged over all users U . We define the utility of the system as follows: This Util ( s j , X  ) function treats all (both popular and long-tailed) queries equally and is not biased to popular queries. Although other approaches to derive utility within this frame-work are possible, we will leave them for future work.
At this point we have one utility metric for evaluating a VS system, accounting for reward and risk. The metric depends on the user-specific and query-specific reward-risk tradeoff parameter  X  u i q , which we need to set. In this paper, we assume that for each query q , users have the same trade-off level (  X  ) between reward and risk. Furthermore, we assume a uniform distribution of  X  u i q across all users. We leave the work of discovering the distribution of risk-seeking and risk-averse for future work. Using our metric we can compare vertical selection approaches for both risk-seeking and risk-averse usersoverasetofqueries Q . Furthermore, we can measure the robustness of the VS approach over all types of users (assuming uniformity) by iterating over all values of  X  for all queries in Q .
We introduce the risk-aware multi-label classification ap-proach, followed by detailed descriptions of features used.
The approach to classification consists of two phases: test-ing and training. We separate 56 queries (conforming to a real-world distribution of verticals [3]) as a training set. This is used for determining a threshold  X  (see below). We use the remaining dataset (264 queries) for testing the approaches.
We use a thresholding approach to select verticals. For a set of verticals V = { v 1 ,v 2 , ...v n } with scores X { x 1 ,x 2 , ...x n } (generated by a vertical selection approach s and a threshold  X  ,wedenote V s j x i &gt; X  as the set of verticals with each vertical v i whose score x i &gt; X  . If no vertical has x &gt; X  ,then V s j x i &gt; X  =  X  . Note that each vertical score x obtained by normalising across all vertical scores.
In essence, the vertical scoring functions of each VS ap-proach is adapted to multi-label vertical selection by select-ing the top-k verticals where k is decided by a threshold  X  . The threshold is trained on the training set. If no verticals receive a score greater than the threshold, no verticals are deemed relevant for that query.

With respect to the risk-aware training, for a given verti-cal selection approach s j with scores over all verticals X { x 1 ,x 2 , ...x n } , we train a set of systems S j = { s  X  1 where each system varies in its reward-risk trade-off oper-ating point (by setting different training objective functions with different  X  , and obtaining corresponding  X  ), i.e. some of the systems are trained to be more risk-averse whereas others to be more risk-seeking. The optimal threshold  X   X  a given system s  X  j (with reward-risk trade-off  X  )istrained as follows: Therefore, for each feature (vertical selection approach s we iterate  X  and obtain a set of systems S j .
We investigate a number of resource selection approaches (CORI [4], Clarity [6], GAVG [8], ReDDE [10], CRCS(l) [9], CRCS(e) [9]) as features for multi-label VS approaches. We use each feature individually for training and aim to com-pare them. While these approaches derive evidence from the same source (sampled vertical representation), they model different aspects of the sources under consideration. CORI, Clarity and GAVG model the similarity between the query and the source, whereas ReDDE, CRCS(l) and CRCS(e) model the collection X  X  average document score in a full-dataset retrieval (all sources together).
CORI adapts INQUERY X  X  inference net document rank-ing approach to collection. Here, all statistics are derived from sampled documents rather than the full collection.
Clarity is a retrieval effectiveness prediction algorithm that measures the similarity between the language of the top ranked documents and the language of the collection, es-timated using the Kullback-Leibler divergence between the query  X  q and the collection language model  X  v i .
GAVG issues the query to a centralized sample index, one that combines document samples from every vertical, and scores vertical v i by the geometric average query likelihood from its top m sampled documents.

ReDDE scores a target collection based on its expected number documents relevant to the query. It derives this expectation from a retrieval of an index that combines doc-uments sampled from every target collection. Given this re-trieval, ReDDE accumulates a collection score ReDDE q ( v from its document scores P ( q |  X  d ), taking into account the difference between the size of the original collection N v i asampledsetsize N samp .
 where I ( . ) is a indicator function.
Like ReDDE , CRCS issues the query to a centralized sam-ple index and scores a collection according to an accumula-tion of a more refined estimation of document score. Specif-ically, the document score for CRCS(l) and CRCS(e) are estimated by a linear or a negative exponential weighting according to its presented position respectively.
 where  X  =1 . 2and  X  =2 . 8 in our setting.
Our experiments aim to investigate various resource selec-tion approaches under our risk-aware multi-label classifica-tion framework. We report the data used in the experiments first, followed by the main experimental results on both ef-fectiveness and robustness .
The user-specific preferred vertical ground-truth informa-tion of each query ( V u i q ) is obtained by only providing the vertical names (with a description of their characteristics) and asking a set of assessors to make pairwise preference as-sessments, comparing each vertical in turn to the reference  X  X eneral web X  vertical [12]. We used an existing web test collection [11] to obtain the vertical representations used for the vertical selection approaches. The verticals used and the distribution of majority user preferred verticals (more than 50% of the users preferred the vertical to  X  X eneral web X ) for all queries for the collection are described in Table 1.
A VS approach s j trained on a given user risk-level  X  is tested on the corresponding type of user (with same  X  ). An approach is effective if prediction of relevant verticals V can satisfy users of that type (i.e. high Util ( s j , X  )).
The main evaluation results on effectiveness for single-feature (each resource selection approach) classifier runs are shown in Figure 1. When only reward is considered (  X  = 0), all of the approaches perform comparably. However, when risk is considered (  X &gt; 0), we observe that in gen-eral, ReDDE performs consistently better than the other approaches. From a 2-tailed paired t-test ( p&lt; 0 . 05), we find that ReDDE is significantly better than GAVG and CRCS(e) at  X  =0 . 3 , 0 . 4, CRCS(l) at  X  =0 . 3, Clarity and CORI at  X  =0 . 2 , 0 . 3 , 0 . 4 , 0 . 5. Of the VS approaches tested CRCS(l) and ReDDE are more risk-aware (when  X &gt; 0 . 3for example). However, when favouring reward (low  X  ), GAVG and ReDDE achieve higher results. CORI and Clarity are, on average, the worst approaches across many values of  X  .
We also empirically observe that different approaches per-form differently for a range of queries whereas some of them hinder/increase the performance of more queries than the other when applying vertical selection. The percentage of benefited and hindered queries conforms to the training set-ting of the reward-risk trade-off. This demonstrates the need for current VS approaches to be more risk-aware.

In conclusion, comparably, ReDDE and CRCS(l) achieve the best performance on effectiveness in those settings, mostly with a large range of queries benefited and a small amount hindered.
Rather than evaluating on one single type of user, ro-bustness of VS approach is measured over all types of users (assuming uniformity) by iterating over risk-level  X  for all queries. Figure 1: Comparing Effectiveness for Various Ver-tical Selection Approaches The main evaluation results on robustness are shown in Figure 2. Firstly, we can observe a general trend that VS ap-proaches that balance the trade-off between reward and risk perform better than the ones that considers solely reward or solely risk. This is not surprising since VS approaches that solely maximise reward frustrate most of users that are risk-averse . On the contrary, only minimising risk could degrade user experience for users that are risk-seeking .

Secondly, it can be observed that in general, CRCS(l) perform more robust than other approaches. From a 2-tailed paired t-test ( p&lt; 0 . 05), we find that CRCS(l) is significantly more robust than all other approaches when  X &gt; =0 . 4. When  X &lt; 0 . 4, CRCS(l) is significantly better than CORI at  X  =0 . 0 , 0 . 1, GAVG, Clarity, CRCS(e) and Clarity at  X  =0 . 2 , 0 . 3, ReDDE at  X  =0 . 2. Of the VS ap-proaches tested, CRCS(l) and Clarity are more risk-aware (when  X &gt; 0 . 4 for example). However, when favouring re-ward (low  X  ), GAVG and ReDDE achieve higher results. CORI and CRCS(e) are, on average, the worst approaches across many values of  X  . We can conclude that CRCS(l) achieve the best performance on robustness in our settings.
This paper incorporates a risk-aware evaluation of verti-cal selection approaches in a multi-label classification frame-work. We propose a novel multi-label vertical selection eval-uation metric that incorporates both rewards and risks. We present a detailed empirical analysis of both effectiveness and robustness of current vertical selection approaches. We demonstrate that ReDDE is the most effective VS approach and CRCS(l) is the most robust.

Future work might include investigating more VS approaches (e.g. query-log based) in this multi-classification framework and study their robustness. Further investigations on real-world user risk-level distribution for this evaluation would provide more insights. A detailed analysis on how this novel risk-aware metric correlate with user satisfaction would fur-ther verify its fidelity.
 Acknowledgments This work was supported partially by Figure 2: Comparing Robustness for Various Verti-cal Selection Approaches the EU LiMoSINe project (288024). Any opinions, findings, and recommendations expressed in this paper are the au-thors X  and do not necessarily reflect those of the sponsors.
