 Data captured in OWL ontologies is generally considered to be more prone to changes than the schema in many situa-tions. Such changes often necessitate consistency checking over the resulting ontologies in order to maintain coherent knowledge, specifically in dynamic settings. In this paper, we present an approach to check the consistency over an evolving ontology resulting from data insertions and dele-tions, given by some expressive underlying Description Logic dialect. The approach, assuming an initially consistent on-tology, works by syntactically identifying  X  X elevant X  and rep-resentative parts of the data for the given updates, i.e., the part that may contribute to subsequent consistency check-ing. Our approach has demonstrated its efficacy in checking consistency over large and real-world ontologies and outper-forms existing approaches in several circumstances.
 I.2.4 [ Artificial Intelligence ]: Knowledge Representation Formalisms and Methods X  Representations ; H.4.0 [ Inform-ation Systems Applications ]: General Ontology evolution; consistency checking; description logic
The rise of big data poses many challenges for knowledge management over the Semantic Web. Scalable big data-based systems representation, integration, management and reasoning are all examples of such challenges. These chal-lenges call for novel semantics-aware technologies to solve practical real-world problems on a large scale, for instance, decision making over (dynamic) traffic, events, among oth-ers, for smart cities [24, 2] and data intensive infrastructures [8]. Knowledge management in such cases requires expres-sive modelling languages to represent the various dimensions of the data available from the application domains. OWL 2 , which provides a suite of features that are unavailable in RDF/S for modelling, has been extensively used for repre-senting knowledge as ontologies in the Semantic Web. Many industries advocate the expressivity of OWL 2 to run real-world semantics-aware applications. The BBC world archive [21] or the IBM Traffic system [17] are such examples.
Nevertheless, the ability to scale reasoning is essential for practical applications. One way to deal with scalabil-ity is by trading the expressivity of modelling languages for more desirable computational properties, for instance, the OWL 2 Profiles [20]. Additional techniques to address scalability have focused on optimizing reasoning over ex-pressive languages, e.g., [6, 9], which, compared to the for-mer, usually provides ad-hoc approaches for specific reason-ing tasks. Recent quests to tackling dynamic knowledge add another dimension to address scalable reasoning, for instance, stream reasoning. 2 Indeed, data collected from different sources about cities, such as sensors, social media, and so on, changes frequently over time. Conversely, the intensional knowledge is relatively static.

Changes of factual information in ontologies can occur on the syntactic or semantic level. Syntactic updates means the facts are directly inserted or deleted, as opposed to the for-mal semantic updates [18], where the semantics of each and every fact in the initial ontology needs to be carefully consid-ered. Since syntactic updates can introduce inconsistency, this work is motivated by the need to check consistency over evolving ontologies, in particular, the need to improve the performance of consistency checking over an ontology where the ABox is frequently updated.

In our context of an evolving ontology, the ABox is ex-posed through various high throughput sensors such as traf-fic sensors for measuring the intensity of congestion, weather stations, or water sensors to monitor water quality. Most of these updates are syntactic due to the nature of the sen-sors and the underlying domain knowledge. Determining the consistency of a dynamic ABox, possibly at various tempo-ral interval, is crucial in many applications since it supports (1) detection of abnormal updates, i.e., inconsistency in our context, which in turn can be used for (2) identifying rele-vant and noisy knowledge, (3) diagnosing noisy knowledge, and (4) maintaining consistent dynamic knowledge. Ensur-ing consistent, dynamic knowledge has been considered to be a basic requirement for reasoning over temporal knowl-edge [2, 3, 17, 24]. In a nutshell, we address the following problem in this paper: how to maintain consistency over dy-http://www.w3.org/TR/owl2-overview/ http://streamreasoning.org/ namic knowledge given by expressive languages in a scalable way? To formally present our approach, we adopt Description Logics (DL), a family of dialects that underlie OWL 2, in this paper [1]. This paper considers a fairly expressive dialect, namely SHIQ ( D ), that is beyond the expressivity of OWL 2 Profiles and under use in our applications. Notable features in this dialect include the corresponding OWL 2 class ex-pressions for maximum cardinality ObjectMaxCardinality , universal restrictions ObjectAllValuesFrom , among others (see Section 2).

The state-of-the-art for consistency checking in the pres-ence of updates in expressive DL dialects comes in different flavors. Pellet exploits the model-building tableaux algo-rithm for expressive DL dialects [13]. Compared to Pel-let, our approach is designed for tableaux-based DL reason-ers, but it does not rely on the tableaux algorithms per se. Summarization-based techniques for consistency checking, such as [9], deal with a less expressive dialect SHIN and are less efficient in case of inconsistency. Our current approach assumes the consistency of the ontology before insertions. In the extreme case where data is absent or considered to be updates, consistency of an ontology reduces to the schema satisfiability. In practice, consistency checking over massive data dominates reasoning time, while checking schema sat-isfiability is far more efficient. Note that the consistency assumption implies that deletions from a consistent ontol-ogy will not introduce inconsistency, so, the focus of this paper is on insertions.

Our contributions in the paper are summarized below.
The remainder of this paper is organized as follows. Sec-tion 2 briefly reviews the DL dialect we adopt to present our work. In Section 3 we introduce the core definitions of our approach. Section 4 presents our method for checking consistency over ontologies in the given dialect with syntac-tic insertions. Section 5 reports an empirical evaluation of our approach. Section 6 discusses the related work. Finally, Section 7 draws some conclusions and talks about possible future directions.
To formally present the approach, we use the underlying logic to represent an OWL ontology, namely, some descrip-tion logics dialect. In particular, the language under inves-tigation is a fairly expressive one in the DL family, called SHIQ ( D ), which can be found in many real-world ontolo-gies and is beyond the expressiveness of the three OWL 2 Profiles [20]. The selection of this DL fragment has been guided by the expressivity requirement of a language to model our application domain, in which various restrictions and data types are extensively used. To define a SHIQ ( D ) ontology, we first formalize the notion of data types.
Definition 1. A data type D consists of the domain of D , denoted  X  D , and a set of predicate names of D .

One example of data types is integers, in which the do-main is the set of all integers and the predicates include, for instance, binary predicates = ,  X  , among others. For simple exposition, this paper assumes some arbitrary data type D that is admissible (see [1] for details) and that has unary predicates = k , 6 = k for some k  X  D . SHIQ ( D ) concepts are defined using a set of constructs, including the assumed data type D .

Definition 2. Let NR , NF , NC and NI denote disjoint sets of named roles, named features, named concepts, and named individuals, respectively. A role S is either a named role R  X  NR or an inverse role R  X  . We write S  X  to denote R  X  if S = R and R if S = R  X  . A role box R is a set of role inclusions and transitivity axioms. A role inclusion is S S 2 for some roles S 1 and S 2 . A role transitivity axiom is of the form TR ( S ). Let v  X  b e the transitive-reflexive closure of v over the set { S 1 v S 2 , S  X  1 v S  X  2 | S 1 v S 2 role S p is called simple if TR ( S 0 ) 6 X  X  for every S 0
Let A  X  NC a nd n be a non-negative integer. A SHIQ ( D ) concept C is defined inductively as follows:
C := C b |  X  f. = k |  X  f. 6 = k | C 1 u C 2 | C 1 t C 2 L := A |  X  A | &gt;
C b := L |  X  , where  X  is the unsatisfiable concept, &gt; is the most general concept, f  X  NF is functional, C 1 , C 2 are concepts, k  X  D , S is a role, and S p is a simple role.

As an example, the concept describing an undergradu-ate course that is taught by a professor can be expressed as UGCourse u X  taughtBy . Prof . Abbreviated concepts are used throughout the paper. We write f = k for  X  f. = k , and f 6 = k for  X  f. 6 = k . Since f is functional, f 6 = k is equivalent to  X  ( f = k ). We assume all concepts are in negation normal form (NNF) and write  X  C to denote the NNF of  X  C . A SHIQ ( D ) ontology is defined based on SHIQ ( D ) concepts and a role box:
Definition 3. A SHIQ ( D ) ontology, denoted O , is a pair ( T , A ), where T , a TBox, is a finite set of constraints in the form of C 1 v C 2 , S 1 v S 2 , or TR ( S 1 ) for some SHIQ ( D ) concepts C 1 , C 2 and roles S 1 , S 2 , and where A , an ABox, is a finite set of assertions in the form of a : L , a 6' b , a : f = k , a : f 6 = k and S ( a, b ) for some concept L , f  X  NF , role S , k  X  X  , and a, b  X  NI .
In the remainder of this paper, C 1  X  C 2 is written as shorthand for the two constraints C 1 v C 2 and C 2 v C 1 Also, TBox constraints are called axioms, while ABox con-straints in the form of a : L ( a : f = k , a : f 6 = k ), a 6' b , and S ( a, b ) are called concept assertions , individual inequal-ity , role assertions , respectively.

The semantics of SHIQ ( D ) concepts is given by means of an interpretation I = ( X  I ,  X  I ), where the non-empty, ab-stract domain  X  I is disjoint from the concrete domain  X  D and the mapping  X  I maps every A  X  NC to a subset of  X  I , every a  X  NI to some o  X   X  I , every R  X  NR to a subset of  X  I  X   X  I , every f  X  NF to a function f I :  X  I  X   X  D every k  X  D to some d  X   X  D , and maps concept descrip-tions as follows:  X  A I =  X  I \ A I , &gt; I =  X  I ,  X  (  X  f. = k ) I = { x |  X  y. ( x, y )  X  f I and y = k I } (similarly for  X  f. 6 = k ), ( C 1 u C 2 ) I = C I 1  X  C I 2 , ( C 1 (  X  S.C ) I = { x |  X  y. ( x, y )  X  S I implies y  X  C I } , (  X  S.C ) { x |  X  y. ( x, y )  X  S I and y  X  C I } , (  X   X  n S p .C # { ( x, y )  X  S I p and y  X  C I }  X  n } , and (  X   X  n S p # { ( x, y )  X  S I p and y  X  C I }  X  n } , where # M denotes the cardinality of a set M .
 For TBox axioms, an interpretation I satisfies C 1 v C 2 iff C 1  X  C I 2 , S 1 v S 2 iff S I 1  X  S I 2 , and TR ( S ) iff { ( o o ) } X  S I implies ( o 1 , o 3 )  X  S I . If there is an interpretation I that satisfies every axiom in T , then T is satisfiable. For ABox constraints, I satisfies a : L iff a I  X  L I (analogously for a : f = k and a : f 6 = k ), a 6' b iff a I 6 = b I , and S ( a, b ) iff ( a I , b I )  X  S I . An interpretation I that satisfies all constraints in an ontology O = ( T , A ) is called a model of O , denoted I | = O . In this case, we say A is consistent w.r.t. T .
The syntactic approach for consistency checking requires that TBox constraints in ontologies be simplified so that certain types of constraints can be identified. This section defines a simplified version of any SHIQ ( D ) TBoxes and shows that the simplification transforms a SHIQ ( D ) TBox into an equi-satisfiable one.

Definition 4. A SHIQ ( D ) TBox T is simplified if (1) there is no TR ( S )  X  X  , and (2) universal restrictions (  X  S.C ) and maximum qualified number restrictions (  X   X  n S p .C ) appear in T only in the following forms: where S is a role and S p a simple role.

The rational behind simplification is to remove transitiv-ity axioms and to expose all universal restrictions and maxi-mum qualified number restrictions. As has been observed in [9, 29], universal restrictions and maximum qualified number restrictions are the sources of interaction between individ-uals in a tableaux algorithm for SHIQ ( D ). The simplifi-cation in Definition 4 preserves satisfiability of a TBox, as stipulated in Lemma 1.

Lemma 1. Every SHIQ ( D ) TBox T can be transformed into a simplified TBox T 0 , as defined in Definition 4; T is satisfiable iff T 0 is satisfiable.

Proof. First, transitivity axioms can be eliminated using the approach shown in [15]. Specifically, assuming all univer-sal restrictions are simplified and are of the form L 1 v X  S. L for every such axiom and every S 0 s.t. S 0 v  X  S a nd TR ( S T , add the following axioms to T : where A 1 is a fresh, named concept. With this method, all transitivity axioms can be eliminated from T , and this step preserves TBox satisfiability.

Following the first step, we can assume w.l.o.g. that TBox axioms are in the form of &gt; v C or S 1 v S 2 , where C is a SHIQ ( D ) concept in NNF. For every  X  S.C 1 (resp.  X   X  n S p .C 1 ) occurring in C , introduce two fresh, named con-cepts A 1 , A 2  X  NC not appearing in T , replace in C every occurrence of  X  S.C 1 (resp.  X   X  n S p .C 1 ) by A 1 , and add the following constraints to T : It is not difficult to see that the aforementioned steps pre-serve TBox satisfiability. Assuming I | = T , an interpreta-tion I 0 can be derived from I with A I 0 2 = C I 0 1 and A (  X  S.A 2 ) I 0 (resp. A I 0 1 = (  X   X  n S p .A 2 ) I 0 ), and I the other direction, if I 0 | = T 0 , then axioms of the form &gt; v C in T must be satisfied in I 0 . Otherwise, consider I 0 6| = &gt; v  X  S.C 1 . It contradicts with the fact that I &gt; v A 1 , I 0 | = A 1  X   X  S.A 2 , and I 0 | = A 2  X  C . The rest of the proof goes analogously.

Domain and range restrictions, as well as role character-istic constraints, such as functional roles, are assumed to be explicitly expressed as TBox axioms. In particular, a do-main (range, resp.) restriction in the form of Dom ( S ) = C ( Ran ( S ) = C , resp.) is expressed as the axiom &gt;v X  S ( &gt; v  X  S.C , resp.). Also observe that (1) can be simplified for the domain and range restrictions on transitive roles, in which case the second axiom in (1) is redundant because &gt;v X  S 0 .A 1 overrides A 1 v X  S 0 .A 1 . The simplification step is polynomially bounded by the size of T , and it needs to be done only once for any SHIQ ( D ) TBox. In the remainder of the paper we assume all TBoxes are simplified. In what follows an example is given to show how TBox axioms are simplified.
 Example 1. Given the following SHIQ ( D ) TBox: T 1 = { Stud v X  supervise  X  . Prof , the simplification of T 1 results in the following TBox: where A  X  NC is fresh in T 1 .
This section details our approach to checking consistency of an ontology, O = ( T , A ), in the presence of syntactic ABox updates. The approach works by presuming the con-sistency of O . An immediate consequence of this assump-tion is that deleting existing ABox constraints will not affect the consistency. Therefore, this section focuses on syntactic ABox insertions . Given a finite set of syntactic insertions A + that consists of any types of ABox constraints, the task is to find a subset of A  X  X  + that can be used for consis-tency checking with the simplified TBox. Such a set, de-noted A add , is not necessarily a minimal set of constraints for the purpose of checking consistency over A X  X  + . Our ap-proach is independent of the underlying tableaux algorithm or implementation for the dialect SHIQ ( D ), so, it can be used with any tableaux-based reasoners.

TBox axioms can cause two individuals a, b to interact with each other through the role assertion S ( a, b ), which affects consistency checking w.r.t. the TBox. We thus es-timate how individuals can be influenced by TBox axioms. Notably, universal restrictions of the form  X  S.C and maxi-mum qualified number restrictions of the form  X   X  n S p .C are the only sources for individual interaction through role as-sertions of the form S ( a, b ) [14]. We capture this notion formally in Definition 5.

Definition 5. A role S is said to be part-of universal re-strictions (maximum qualified number restrictions, resp.) w.r.t. a simplified SHIQ ( D ) TBox T , denoted u -part ( S, T ) ( m -part ( S, T ), resp.), if S v  X  S 0 a nd (1) L 1 v X  S 0 . L 2 ( L 1 v X   X  n S 0 . L 2 , resp.) or, (2) L 1 v X  S 0 X  . L 2 ( L 1 v X   X  n S 0 X  . L 2 , resp.). S is a part-of any qualified restrictions w.r.t. T , denoted part ( S, T ), if either u -part ( S, T ) or m -part ( S, T ) hold.
By Definition 5, it is easy to see that u -part ( S, T ) implies u -part ( S  X  , T ) and vice versa (analogously for m -part ( S, T )). This definition does not capture the exact circumstances un-der which TBox axioms cause interaction between individ-uals through a role assertion, rather it conservatively esti-mates when such interaction may occur.

To deal with data type assertions of the form a : f = k and a : f 6 = k , it is important to show how a feature interacts with other features. Let Fs ( T ) denote the set of features that appear in any axioms in T , for example, axioms of the form f = 5 v A or of the form f 1 v f 2 . Clearly, a feature interacts with another only if both of them are in Fs ( T ). Again, this definition of Fs ( T ) is an overestimation of the interaction between features.

Before delving into the details of computing a set of asser-tions, i.e., A add , for consistency checking, it is essential to consider when a role assertion S ( a, b ) is irrelevant for con-sistency checking w.r.t. T . If a role assertion is irrelevant for consistency checking, it should not be included in A add As shown in [9], a simple case is that, for a role assertion S ( a, b ), if S is not part-of any universal restrictions or maxi-mum qualified number restrictions, then S ( a, b ) is irrelevant. Definition 6 introduces the notion of remedy assertions for a role assertion, which is used to obtain a precise definition of  X  X rrelevancy X  for a role assertion in Definition 7. Definition 6. The remedy assertions of a role assertion S ( a, b ) w.r.t. an axiom of the form L 1 v X  S 0 . L 2  X  X  , S v  X  S in a consistent SHIQ ( D ) ontology O = ( T , A ), denoted S ( a, b ), is defined as follows: Definition 6 allows for syntactic inspections over the ABox to determine the remedy assertions: A syntactic occurrence of a : L 1 in A , as a consequence of our consistency assump-tion, implies b : L 2 . Moreover, remedy assertions for S ( a, b ) consider the inverse equivalence of S ( a, b ) and L 1 v  X  S. L namely, S  X  ( b, a ) and  X  L 2 v X  S.  X  L 1 .

This definition of remedy assertions is one of the many ways to specify how new concept assertions can be derived w.r.t. axioms of the form L 1 v X  S. L 2 . Indeed, this definition can be refined to reduce the likelihood of having S ( a, b ) =  X  . This topic is, however, beyond the scope of this paper, and we will revisit it in Section 7.

Definition 7. A role assertion of the form S ( a, b ) is irrele-vant for consistency checking w.r.t. a consistent SHIQ ( D ) ontology O = ( T , A ), if the following conditions are met: 1. m -part ( S, T ) does not hold, and 2. for every L 1 v X  S 0 . L 2  X  X  , Definition 7 extends the optimization proposed in [30, 9]. Intuitively, the purpose of the remedy assertions is to com-pensate for eliminating an  X  X rrelevant X  role assertion. Specif-ically, the first condition ensures that the role assertion is only affected by universal restrictions; the second condition ensures that a particular role assertion is irrelevant w.r.t. the given axiom, because of the existence of its remedy as-sertions.

Next comes the main procedure for computing a set of constraints, A add , from A  X  A + for consistency checking. Note that for any individual a in an ABox A , a : &gt;  X  A is assumed. To ease the presentation, we also write S T S ( a, b ) to denote the union of S ( a, b )  X  S  X  ( b, a ) w.r.t. all axioms in the form of L 1 v X  S 0 . L 2  X  X  , where S v  X  S 0 .
 1 . A add = A + \A ; 2. for a : L  X  X  add , mark a : L as processed, and update 3. for S ( a, b )  X  X  add , mark S ( a, b ) as processed. If S ( a, b ) 4. for a 6' b  X  X  add , mark a 6' b as processed, and update 5. repeats 2 to 4 until all constraints in A add are pro-6. for f 0  X  Fs ( T )  X  X  f | a : f = k or a : f 6 = k  X  A
To guarantee termination of the computation of A add , it is necessary to remember which constraints have already been processed. Only unprocessed constraints need to be added to A add , and this means every constraint is processed at most once. Also note that in step 3 if a role assertion is eliminated due to its irrelevancy, all remedy assertions have to be added in A add . This may seem ineffective for consistency checking, however, we believe that these remedy assertions are simpler for reasoning than role assertions in most cases because they tend to contain only  X  X solated X  individuals. Also, since the remedy assertions are marked as processed, they will not bring in new assertions to A add in subsequent computation.
We now give a step-by-step example showing how A add for a given insertion is computed.

Example 2. Consider the simplified SHIQ ( D ) TBox T 2 in Example 1 and the following ABox:
A 2 = { s : Stud , c 1 : UGradCourse , c 2 : GradCourse , It can be verified that the ontology O 2 = ( T 2 , A 2 ) is consis-tent. Suppose a new constraint c 1 6' c 2 needs to be added to A 2 (which will introduce inconsistency), we show how a new ABox A 0 add can be computed following the previous procedure.
 Initially, we have Because of step 4 and m -part ( teach , T 2 ), we have By step 3 and the fact that neither teach ( p, c 1 ) nor teach ( p, c can be eliminated (Definition 7), we augment A 0 add as fol-lows: Due to the newly added assertions c 1 : UGradCourse and c 2 : GradCourse , step 2, observing p : &gt;  X  A 0 add , adds supervise ( p, s ) to A 0 add .

To process supervise ( p, s ), the procedure first checks if, by Definition 7, supervise ( p, s ) is irrelevant. Given Stud v  X  supervise  X  . Prof  X  T 2 , the second condition in Definition 7 is applied to check if supervise  X  ( s, p ) is irrelevant. Since s : Stud  X  X  2 , it follows that A 0 add can eliminate supervise ( p, s ) and adds the remedy assertion p : Prof instead:
A 0 add = { c 1 6' c 2 , teach ( p, c 1 ) , teach ( p, c 2 It is easy to see that A 0 add , being much smaller than the ABox A 2  X  X  c 1 6' c 2 } that would have been used for consis-tency checking, is indeed inconsistent w.r.t. T 2 .

The computation of A add requires each assertion in A add (in the worst case A add = A  X  X  + ) to be checked for all referencing assertions in A that are part-of some restriction. Thus, this procedure runs in |A X  X  + | X |A| X |T| in the worst case. The main theorem that proves the correctness of the procedure for computing A add is given below.

Theorem 1. Let T , A , A + , A add be a SHIQ ( D ) TBox, an ABox, a given set of ABox insertions, and an ABox computed by the aforementioned procedure, respectively. If ( T , A ) is consistent, then
Proof. The proof of the only if direction, i.e., if ( T , A is inconsistent, then so is ( T , A X  X  + ), follows immediately from the fact that A add  X  X  X  X  + .

The proof of the other direction is similar to the proof presented in [29]. If ( T , A add )is consistent, we need to show so is ( T , A X  X  + ). We construct a model for ( T , A X  X  + arbitrary models for ( T , A ) and ( T , A add ). The construction of such a model, denoted I , is based on two models (the two models must exist because both ( T , A add ) and O = ( T , A ) are consistent and the models are in the shape of forests for the dialect SHIQ ( D )): I add such that I add | = ( T , A I O such that I O | = ( T , A ).

The domain of I ,  X , is given as follows.  X  =  X  add  X   X  O where  X  add consists of the set of objects e such that (1) a  X  A add and e = a I add ; or (2) e is an object in the tree rooted by the objects in (1), and analogously,  X  O is the set of objects e such that a  X  X \A add and e = a I O or an object in the tree rooted by such an object. The interpretation of an individual is copied from the appropriate interpretation when the domain is defined for I .

The interpretation of named concepts A is defined as fol-lows: e  X  A I if e  X   X  add and e  X  A I add or if e  X   X  O and e  X  A I O . The interpretation of concepts f = k is defined analogously to that of A . For individual inequality, e 1 if e 1 , e 2  X  I add and e 1 6 = e 2 , or e 1 , e 2  X  I O e = a I add , e 2 = b I O (or vice versa), and a 6' b  X  X  .
The interpretation of roles S is defined by the following cases: (1) if e 1 , e 2  X   X  add and ( e 1 , e 2 )  X  S I add , then ( e (2) if e 1 , e 2  X   X  O and ( e 1 , e 2 )  X  S I O , then ( e (3) if e 1  X  a I add , e 2  X  b I O , and S ( a, b )  X  X  , then ( e S (4) if e 1  X  a I O , e 2  X  b I add , and S ( a, b )  X  X  , then ( e S (5) if ( e 1 , e 2 )  X  S I and S v  X  S 0 , then ( e 1 , e
To show I | = ( T , A  X  X  + ), we need to ensure all ABox constraints are satisfied w.r.t. T in I . First, note that all minimum qualified number restrictions (including existential restrictions) can always be satisfied by creating the required number of different anonymous objects, which may be re-dundant in that named objects (those interpreting named individuals) could be used to satisfy such restrictions.
Now consider object pairs defined for S I . Observe that (1) and (2) simply replicate part of I add and I O , respectively, to construct I . Since the original interpretations satisfy all constraints, the duplicated part in I must also be consistent with the same constraints. (5) is an induction over (1)-(4); thus, it suffices to consider whether the object pairs defined by (3) and (4) are consistent w.r.t. T .

Intuitively, (3) and (4) define object pairs that travel across the two interpretations. Since minimum qualified number restrictions are satisfied as stated above, only maximum qualified number restrictions and universal restrictions need to be investigated. Let ( e 1 , e 2 ) be defined by (3), where in the form of L 1 v  X   X  n S p . L 2 , where n &gt; 0 , S v  X  S can show that e 1 6 X  L I 1 , since otherwise by definition, we have m -part ( S, T ), which, by step 2 in the procedure and a  X  A add , entails that S ( a, b )  X  A add , i.e., e 2 contradiction. For universal restrictions expressed in the form of L 1 v  X  S. L 2 , the same argument goes when S ( a, b ) is not irrelevant for consistency checking w.r.t. T . When S ( a, b ) is irrelevant w.r.t. T , Definition 7 already ensures that S ( a, b ) is consistent with L 1 v  X  S. L 2 or its equivalent form  X  L 2 v X  S.  X  L 1 . An analogous proof can be developed for the case of (4).

Note that for any individual in A add , all of its ABox con-straints that involve some features appearing in T and in A are included in A add by step 6. Thus,the feature-involving assertions of the form a : f = k or a : f 6 = k are inconsistent iff A add is inconsistent. Since A add is consistent, these con-straints are satisfied by I as well. For ABox assertions in the form of inequality a 6' b , it suffices to consider the case when e = a I add , e 2 = a I O (or vice versa), and a 6' b  X  A , be-cause in the other cases I replicates the interpretation from appropriate models. Note that inequality only affect maxi-mum or minimum number restrictions [14]. Since minimum restrictions can be satisfied without relying on existing ob-jects, we only need to consider maximum qualified number restrictions. Consider e 1 = a I add , e 2 = b I O , and a 6' b  X  X  . If neither a or b are referenced in any role assertions, or if either of them, say, a , is referenced by some S ( a, x ) but m -part ( S, T ) does not hold, then a 6' b must be consistent with other constraints. If a is referenced by S ( a, x ) and m -part ( S, T ) indeed holds, step 3 in the procedure ensures that a 6' b  X  X  add , contradictory to the fact that e 2 = b
Finally, all transitivity axioms are absent from T , while all object pairs are consistent with role inclusion axioms be-cause of (5). Thus, I | = ( T , A X  X  + ).
We implemented the approach outlined in Section 4 to evaluate the efficacy and performance. The experiments were carried out in a single core of a Linux server with Intel Xeon 3.47GHz CPU, and 16GB of memory was assigned to our Java implementation. Results reported in this section were averaged out of three independent runs. The datasets used include the LUBM [12] and UOBM [19] ontologies, the de facto benchmarks for ontology-based tasks, and the NPD ontology from the Optique project [23]. An overview of these ontologies is given in Table 1.

The UOBM TBox has the expressivity of SHOIN ( D ), and the one used in our experiments is free of nominals ( O ) and slightly modified for the expressiveness to SHIQ ( D ). The original NPD TBox has a set of general axioms in the form of f = k v A that adversely affect the performance of the underlying DL reasoner, thus, these general axioms were removed in the experiments. In addition, all individ-ual equality axioms were also removed since our approach currently does not consider them. Note that for LUBM and UOBM ontologies, the number of universities is indicated by the name, e.g., L5 means five universities. For NPD data, N1 is about one eighth of the total number of assertions of the NPD data, while N8 includes all. Table 1 also lists the number of concept assertions (ca), role assertions (ra), and concept assertions involving features (da) for each ontolo-gies, where  X  X  X  stands for thousand and  X  X  X  for million.
In the experiments, we chose to juxtapose our approach with Pellet X  X  incremental consistency checking mechanism, and we did not compare our approach with modularity based techniques for several reasons. For some existing techniques, such as [27, 9], our approach handles more expressive di-alects. In some other cases, such as [9], the technique has additional methods to reduce the size of ABox, which can also be used in our approach, hence, our approach is incom-parable to such techniques. For details, please refer to Sec-tion 6. We compared our approach with a highly optimized reasoner for consistency checking, Pellet v2.3.1, which sup-ports incremental consistency checking over expressive on-tologies (including extensive data type reasoning support) [22]. Other DL reasoners, such as HermiT 3 and FaCT++ 4 , are not included since there is no documented support for incremental consistency checking in these reasoners and/or they lack the support for extensive data type reasoning re-quired for the NPD ontology.

Our first set of experiments focuses on consistency check-ing of random insertions over well-known ontologies. The insertions, totalling 5% of the number of assertions in the original data, were randomly generated with different types of ABox assertions. The insertions are based on existing in-dividuals in the data and fresh individuals that account for 50% of the insertions, as indicated by the label  X (0.5) X  in the x-axis. Since Pellet has built-in support for incremental consistency checking, we did an initial consistency checking of the original ontologies, and recorded the time spent in the subsequent consistency checking after insertions were added. Our approach takes an ontology and insertions as input and generates a new ontology. We recorded the time of this gen-eration phase, as well as the time for consistency checking of the resulting ontology.

Figures 1 and 2 depict the comparison between Pellet X  X  incremental consistency checking approach (denoted INC) and our approach presented in this paper (denoted SYN). It can be observed that our approach needed twice to thrice the CPU time as Pellet did. Regarding the size of the result-ing new ontologies generated by our approach SYN, in the LUBM case, with insertions equivalent to 5% of the num-ber of assertions in LUBM ontologies, our SYN approach obtained new ontologies with size ranging from 12% to 21% of the original ontologies. For UOBM ontologies, the new http://hermit-reasoner.com https://code.google.com/p/factplusplus Figure 1: LUBM Ontologies with time (ms) in log-arithmic scale.
 F igure 2: UOBM ontologies with time (ms) in loga-rithmic scale.
 o ntologies generated by SYN vary little in the size: about 65% of the total assertions in U1-U10 were included in the new ontologies. We conjecture that the relatively slower time performance of our approach is due to the following reasons. First, because both LUBM and UOBM impose a significant number of constraints on object properties, par-ticularly domain and range constraints, most of the CPU time in our approach accounted for the generation of new ontologies. The UOBM TBox has more constraints on prop-erties than LUBM, so, the resulting ontologies for UOBM were dramatically larger than those in the LUBM case. Sec-ond, similar to other reasoners, Pellet spends a considerable amount of time in the ontology loading phase. In the in-cremental consistency checking setting, Pellet exploited the precomputed information saved from the initial consistency checking, whereas our approach generates new ontologies that have to be reloaded into reasoner. Although the size of the new ontologies is a small fraction of the original ones, the sheer number of assertions still requires a significant amount time for loading (and pre-processing). In this sense, Pel-let trades memory for computation time. Last, it is known that many reasoning systems were optimized for LUBM and UOBM [28], and it is not surprising Pellet performs partic-ularly well for these ontologies.
 NPD is a real-world ontology, which, unlike LUBM or UOBM, has a large number of properties with a moderate number of constraints cast on these properties. Figure 3 Figure 3: NPD ontologies with time (ms) in loga-rithmic scale.
 F igure 4: Original data used as insertions with time (ms) in logarithmic scale.
 c ompares Pellet X  X  approach with ours X  over varying NPD ontologies. For insertions in the size of 5% of the data, the new ontologies generated by our approach is no greater than 5% of the data, for example, in cases where half of the inser-tions involve new individuals, the new ontologies are only 4% of the data. As can be seen from Figure 3, for NPD ontologies, our approach for consistency checking is at least one order of magnitude faster than Pellet. Observe that Pellet ran out of memory to perform an initial consistency check of N8. It is reasonable to assume that Pellet, were it able to successfully check the consistency of N8, will likely have difficulty in maintaining the data structure required for incremental consistency checking; this suggests that our approach is more memory-efficient. Indeed, our initial ex-periments also showed that, for the original NPD ontologies that include all the general axioms, i.e., no elimination of axioms, our approach could still obtain very small new on-tologies of which Pellet was able to check the consistency in a few seconds, nevertheless, Pellet timed out after an hour for consistency checking over the original NPD ontology.
We also performed another set of experiments, in which the original data is assumed to be insertions. In this situa-tion, our approach presumes the satisfiability of the TBoxes, and the initial data consistency is validated against the TBox schema. As shown in Figure 4, our SYN approach per-formed better than Pellet; specifically, the improvement was about 30% for LUBM, 20% for UOBM, and 50% for NPD. Note that both approaches threw  X  X ut of memory X  excep-tions when reasoning with N8: the SYN approach obtained a new ontology over 90% of the original data, which was still difficult to reason with for Pellet. The results in Fig-ure 4 suggested that our approach can be used as an efficient method to check the consistency of original ABox data as well as insertions.
Incremental consistency checking over OWL ontologies has been investigated in Pellet [13] for expressive DLs. In Pellet, incremental consistency checking is achieved by incor-porating the updates directly in the model-resembling struc-ture obtained from previous consistency checking. There are several differences between the Pellet approach and ours. First, our approach is purely syntactic, which means any tableau-based reasoners can take advantage of it without modifying the tableaux algorithm. Second, our approach as-sumes the consistency of the original ontologies, while Pellet requires an initial consistency checking for subsequent rea-soning with insertions, which may consume a substantial amount of available memory. Nevertheless, Pellet supports incremental consistency reasoning with nominals, which is not considered in our current approach.

Another related line of research is on ABox modularity in ontologies. For example, an approach that split an ABox into small modules for instance checking (not consistency checking) is shown in [27]. Similar to our approach, initial consistency of an ontology is assumed in [27], while it only deals with ontologies expressed in SHI . For more expres-sive dialects, the authors of [11] proposed an ABox parti-tion method for the dialect SHIF . First, the given on-tology is transformed into a set of inference rules and the rules are used to estimate what ABox constraints should be grouped together. Note that in [11] if u -part ( S, T ) holds, then reasoning with b has to include the assertion S ( a, b ), whereas our approach can potentially eliminate S ( a, b ). The approach detailed in [7] is aimed at SHIQ ontologies by con-verting the ontology to a plain Datalog program; however, the data complexity of partition is polynomial in the the ABox size, and the approach is not incremental.

Our approach can be considered as an extension to that presented in [29], which was developed for efficient instance checking over SHIQ ( D ) ontologies. The technique devel-oped in [29] cannot be directly used for consistency checking and it requires a special absorption technique to be imple-mented for tableaux reasoners. Also related is the summa-rization techniques in [9] developed for SHIN ontologies, rather than SHIQ ( D ) ontologies. Particularly, the summa-rization techniques present one of the four sub-conditions presented earlier in Definition 7 (2.2) for role assertion elim-ination. The summarization techniques also abstract the ac-tual data with a summary for efficient consistency checking. However, inconsistency of the summary requires a reasoner to investigate the relevant part of the original data. Our approach is both sound and complete for consistency check-ing in presence of insertions. The summarization techniques were later extended in [5] to deal with the inconsistency case through semantic justifications, yet justifications require in-tricate modifications to the underlying tableaux algorithm and computing justifications is expensive.

As stated in the introduction, our approach considers only syntactic updates, while instance-level semantic update has been formally analyzed in [18, 10]. Updates over DL-Lite ontologies have also been studied in [4], in which the key observation is that ABox inconsistency is caused by no more than two ABox constraints in DL-Lite ontologies. This ob-servation, however, is not applicable to ontologies with more expressive underlying dialects. For RDFS data sets, updates are handled by maintaining materialized data incrementally [26, 3]. [16] also presents a method for incremental reasoning over ontologies in EL .
This work addressed the problem of maintaining consis-tency over dynamic knowledge with an underlying, expres-sive DL in a scalable way. In particular we present an ap-proach to checking consistency of any SHIQ ( D ) ontology O with a set of syntactic updates over O . By assuming the consistency of O our approach progressively builds a set of assertions from the ABox and the insertions, and it can iden-tify and eliminate role assertions that do not contribute to the final consistency checking. This approach is syntactic in that it does not rely on the underlying tableaux algorithms or implementation as the incremental reasoning approach in Pellet does, nor does it require justifications or specific absorption techniques. The advantages of our approach are manifold.
This paper focuses on an expressive DL dialect SHIQ ( D ), while the presented techniques are applicable to any DL di-alects up to SHIQ ( D ). Indeed, for less expressive dialects, the procedure given in Section 4 would be easier to imple-ment, e.g., for SHI , m -part (  X  ,  X  ) needs not to be considered. The techniques, however, require the use of inverse roles ( I ) due to the two-way interpretation of a role assertion S ( a, b ). Note that the techniques in this paper, developed for the tableaux-based DL reasoners, may not work correctly for tailored languages that employ non-tableau algorithms for reasoning, for instance, DL dialects underlying the OWL 2 Profiles.

One of our future extensions to the approach in this paper is to support more expressive dialects, for example, dialects that use role disjointness . Given two disjoint roles S 1 and a syntactic insertion S 1 ( a, b ), it is necessary to identify assertions that can infer S 2 ( a, b ) and consider them to be a part of A add . We believe the conditions established in Section 4 can be used to identify such assertions, together with axioms in the role box R . Negative role assertions in the form of  X  S ( a, b ), if permitted in a SHIQ ( D ) ABox, can be dealt with in a similar manner to that for role disjointness.
We observed from the empirical evaluation that the com-putation of A add accounts for most of the CPU time, since in many cases our approach can compute a new ontology that is far smaller than the original one, which makes consistency checking less time-consuming. We plan to optimize the pro-cedure for more efficient A add computation. One possible way to achieve this goal is to obtain more information about the TBox. For example, similar to [9], a closure can be con-structed to provide a finer way for estimating the universal restrictions and maximum qualified number restrictions that may affect a specific role assertion, based on how axioms are absorbed in a particular DL reasoner. The technique in [9] for removing role assertions that are part of maximum un-qualified number restrictions (i.e., for concept construct N ) may be extended to deal with maximum qualified number restrictions (for Q ) in our case.

Recall that remedy assertions for a role assertion of the form S ( a, b ), as shown in Definition 6, are used to deter-mine the relevance of a role assertion w.r.t. an axiom of the form L 1 v  X  S 0 . L 2 , S v  X  S 0 . From the materialization perspective, Definition 6 gives an incomplete materializa-tion of all the available concept assertions that can be de-rived syntactically. We sketch an example to illustrate the problem related to this definition. Given a TBox: A  X  S.A 2 , A 2 v X  S.A 3 and an ABox: S ( a, b ) , S ( b, a ) , a : A can derive b : A 2 , a : A 3 , which can be obtained only by ap-plying Definition 6 in a specific order. A simple refinement of Definition 6 is to iterate the materialization until a fixed point is reached. However, multiple iterations are likely to be costly in practice, thus, more efficient methods need to be developed to balance the materialization cost and the ac-tual benefits we receive (i.e., an increase in the likelihood of identifying irrelevant role assertions).

Another interesting problem is regarding the size of A add Currently our approach does not compute a minimal ontol-ogy for consistency checking, instead, it provides an over-estimation that is both sound and complete for checking consistency, due to its syntactic nature. We can, however, exploit existing optimization techniques developed for DL reasoning, e.g., see [25], to get more insights about which assertions can be eliminated for consistency checking. As an extension, our approach can be modified to partition ABox into smaller modules for specific reasoning tasks, for exam-ple, query answering. It is yet unclear if a modularity tech-nique based on our approach offers significant advantages over existing ones.
The research leading to these results has received funding from the European Unions Seventh Framework Programme (FP7/2007-2013) under grant agreement ID 318201(SIMPLI-CITY). We would like to thank Achille Fokoue for his helpful comments on the draft of this paper. [1] F. Baader, D. Calvanese, D. L. McGuinness, D. Nardi, [2] M. Balduini, E. Della Valle, D. Dell X  X glio, [3] D. Barbieri, D. Braga, S. Ceri, E. Valle, and [4] D. Calvanese, E. Kharlamov, W. Nutt, and [5] J. Dolby, A. Fokoue, A. Kalyanpur, A. Kershenbaum, [6] J. Dolby, A. Fokoue, A. Kalyanpur, L. Ma, [7] J. Du and Y.-D. Shen. Partitioning aboxes based on [8] W. Fan, F. Geerts, and F. Neven. Making queries [9] A. Fokoue, A. Kershenbaum, L. Ma, E. Schonberg, [10] U. Furbach and C. Schon. Semantically guided [11] Y. Guo and J. Heflin. A scalable approach for [12] Y. Guo, Z. Pan, and J. Heflin. Lubm: A benchmark [13] C. Halashek-Wiener, B. Parsia, and E. Sirin.
 [14] I. Horrocks, U. Sattler, and S. Tobies. Reasoning with [15] Y. Kazakov. Consequence-driven reasoning for Horn [16] Y. Kazakov and P. Klinov. Incremental reasoning in [17] F. L  X ecu  X e, A. Schumann, and M. L. Sbodio. Applying [18] H. Liu, C. Lutz, M. Mili X ci  X c, and F. Wolter. [19] L. Ma, Y. Yang, Z. Qiu, G. Xie, Y. Pan, and S. Liu. [20] B. Motik, B. C. Grau, I. Horrocks, Z. Wu, A. Fokoue, [21] Y. Raimond, M. Smethurst, A. McParland, and [22] E. Sirin, B. Parsia, B. C. Grau, A. Kalyanpur, and [23] M. G. Skj X veland, E. H. Lian, and I. Horrocks. [24] S. Tallevi-Diotallevi, S. Kotoulas, L. Foschini, [25] D. Tsarkov, I. Horrocks, and P. F. Patel-Schneider. [26] R. Volz, S. Staab, and B. Motik. Incrementally [27] S. Wandelt and R. M  X  oller. Towards ABox [28] T. Weith  X  oner, T. Liebig, M. Luther, and S. B  X  ohm. [29] J. Wu, A. Hudek, D. Toman, and G. Weddell.
 [30] J. Wu, T. Kinash, D. Toman, and G. E. Weddell.
