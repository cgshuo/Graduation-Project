 In recent years, the number of freely available online reviews is in-creasing at a high speed. Aspect-based opinion mining technique has been employed to find out reviewers X  opinions toward different product aspects. Such finer-grained opinion mining is valuable for the potential customers to make their purchase decisions. Product-feature extraction and categorization is very important for better mining aspect-oriented opinions. Since people usually use different words to describe the same aspect in the reviews, product-feature extraction and categorization becomes more challenging. Manu-ally product-feature extraction and categorization is tedious and time consuming, and practically infeasible for the massive amount of products. In this paper, we propose an unsupervised product-feature categorization method with multilevel latent semantic asso-ciation. After extracting product-features from the semi-structured reviews, we construct the first latent semantic association (LaSA) model to group words into a set of concepts according to their vir-tual context documents. It generates the latent semantic structure for each product-feature. The second LaSA model is constructed to categorize the product-features according to their latent seman-tic structures and context snippets in the reviews. Experimental results demonstrate that our method achieves better performance compared with the existing approaches. Moreover, the proposed method is language-and domain-independent.
 I.2.7 [ Artificial Intelligence ]: Natural language processing X  text analysis ; H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Linguistic processing Algorithms, Experimentation opinion mining, product feature categorization, latent semantic as-sociation
With the dramatic growth of web X  X  popularity, the number of freely available online reviews is increasing at a high speed. Amounts of websites, blogs and forums today allow users to post reviews or comments for various products or services. For many applications, simply judging the overall sentiment orientation (i.e. positive or negative) of a review unit is not sufficient. Reviewers usually praise some aspects of the product and bemoan it in other aspects. It is important to find out reviewers X  opinions toward different product-features instead of the overall opinion in those reviews. In recent years, some aspect-based opinion mining methods [8, 9, 11, 13, 17, 18, 19] have been presented to capture reviewers X  opinions to-ward different product aspects. Such finer-grained opinion min-ing are valuable for the potential customers to make their purchase decisions. Product-feature extraction and categorization is always a bottleneck for aspect-based opinion mining in real applications. The quality of aspect-based opinion mining can be considerably en-hanced by extracting and categorizing product-features correctly.
Product-feature extraction and categorization is a very challeng-ing task since people usually use different words to describe the same aspect in the reviews. Some product specifications are pro-vided by the merchants. However, customers and merchants may use different words to refer to the same aspect. For example, " photo ", " picture "and" image " all refer to the same aspect in digital camera reviews. Moreover, some product-features (e.g. " value ", " style ") can not be found in the specifications. For non-product domains (e.g. local service reviews , book stores , etc.), finding features here is more difficult due to the lack of specifications. Manually product-feature extraction and categorization is tedious and time consum-ing, and practically infeasible for the massive amount of products. Thus, it raises the need for automatically extracting and categoriz-ing product-features from customer reviews. The existing statisti-cal methods use high-frequency noun phrases as produc t-features. They may produce too many non product-features and miss many low-frequency terms and their variations, and terms with only one word [8]. Although supervised methods [11] work better, they re-quire much more human efforts for labeling training data.
In recent years, lots of web sites (e.g. CNET.com and Epin-ions.com ) support a semi-structured customer review format (see Figure 1). The reviewer is asked to briefly enumerate his/her con-cerned product-features and opinion words in Pros and Cons sep-arately, and also write a detailed review. Such semi-structured re-views provide useful clues for product-feature extraction.
In this paper, we propose an unsupervised product-feature ex-traction and categorization method with multilevel latent semantic association. We first extract product-feature candidates from the semi-structured Pros and Cons parts, and further verify the valid product-features by checking their re-occurrence in the detailed re-views. Second, we empl oy a multilevel latent s emantic association (LaSA) method to categorize the product-features. The first LaSA model is constructed to capture latent semantic association among words. It groups words into a set of concepts according to their vir-tual context documents in the reviews. This model generates the la-tent semantic structure for each product-feature. The second LaSA model categorizes all the product-features according to their latent semantic structures and context snippets in the review corpus. The intuition behind our method is that words in one concept set will have similar semantic features or latent semantic association, and share syntactic and semantic context in the corpus. They can be considered as behaving in the same way in the product-feature cat-egorization. The proposed multi-level LaSA method categorizes product-features on a semantic level rather than by shallow lexical comparison. It can better approximate the true underlying seman-tic category distribution in the domain without any labeled sam-ples. Experimental results show that our method achieves better performance compared with the existing approaches. The proposed method is language-and domain-independent.

The remainder of the paper is organized as follows. Section 2 introduces some related work. Section 3 illustrates how to extract product-features from semi-structured reviews. Section 4 presents latent semantic association method. Section 5 presents a product-feature categorization method with multilevel latent semantic asso-ciation. The experimental results are discussed in Section 6. The conclusion is given in Section 7.
Product-feature extraction and categorization is a key task for opinion mining. Liu et al. [11] and Hu et al. [8, 9] identify product-features using association rule mining. Liu et al. [11] also present a supervised association rule mining method for detecting product-features in the semi-structured reviews. This method works better through manually labeling training data. Popescu and Etzioni [13] identify product-features using PMI-based feature assessor. Scffidi et al. [15] employ probability-based heuristics and baseline statis-tics of words in English to identify product-features. Symbolic ap-proaches and statistical approaches are basically two techniques for terminology finding. Symbolic approaches [6, 5] focus on finding terms from noun phrases. They produce too many non product-features. Statistical approaches [16] exploit the co-occurrence fre-quency of words to predict terms. They miss many low frequency terms, variations and single-word terms. Although high-frequent features are the "hot" features that people are most interested in for a given product, There are some features that only a small num-ber of people talked about. These low frequency ones, which are mentioned by some reviewers, can also be interesting to some cus-tomers. Thus, it is a big challenge to effectively extract these infre-quent features in the reviews.
 Liu et al. [11] group product-features by the synonym set in WordNet and the semi-automated tagging of reviews. Titov and McDonald [18, 19] employ multi-grain topic model and rating in-formation to identify coherent aspects in the reviews. We present a multilevel latent seman tic association method for product-feature categorization without using rating information.

Some work also examined the importance of such semi-structured review format [11, 22, 10, 2]. Brananvan et al [2]. leverage free keyphrases annotation (i.e. all the phrases in Pros and Cons )toin-fer document-level semantic properties. Their goal is to predict the semantic properties supported by a previously unseen document. They cluster all the keyphrases based on the lexical comparison and the distribution similarity. The lexical comparison is based on the cosine similarity among the phrase words while the distributional similarity is quantified in terms of the co-occurrence of keyphrases across review texts. Different from their method, we present a mul-tilevel LaSA method for product-feat ure categoriza tion in opinion mining. The first LaSA model captures lexical semantic association among words according to their virtual context documents. It gen-erates the latent semantic structure for each product-feature. The second LaSA model categorizes all the product-features according to their latent semantic structures and context snippets in the cor-pus. In addition, Wong et al. [22] extract and normalize product at-tributes from the structured product descriptions provided by mer-chants in multiple web sites. However, merchants and customers may use different words to refer to the same feature. In this pa-per, we focus on extracting and categorizing product-features from customer reviews for opinion mining. Kaji et al. [10] also employ statistical method to build opinion lexicon from the layout struc-tures.
Product-feature extraction is very important for aspect-based opin-ion mining. However, few product-feature lists are available. In this section, we present an unsupervised method to extract product-features from the semi-structured reviews.
 In recent years, some popular web sites (e.g. CNET.com and Epinions.com) support a semi-structured customer review format (see Figure 1 in Section 1). Semi-structured reviews provide useful clues for extracting product-features. Since reviewers often briefly enumerate their concerned product-features and opinions in Pros and Cons , we may obtain many typical product-feature candidates from these short sentence segments.

We extract product-features from the review corpus using the fol-lowing three steps. All the reviews are tokenized and tagged part of speech automatically in the preprocess. 1. Extract product-feature candidates from Pros and Cons . 2. Verify all the candidates by detecting their re-occurrence in 3. Expand the product-featur e list by recalling compound terms
Algorithm 1 illustrates our unsupe rvised product-feature (PF) extraction method in detail.
 Algorithm 1 : Product-Feature Extraction Method
Figure 2 shows an example of product-feature extraction. Given areview r k , we first get the product-feature candidates {" LCD ", " touch screen ", " longer battery life ", " picture quality "} from Pros and Cons parts by removing opinion words " nice "and" horrible ". Second, we check their re-occurrence in the detail reviews and get the valid product-feature list {" LCD ", " touch screen ", " battery life "," picture quality "}. Finally, a new compound term " LCD touch screen " is recalled by merging the continuous terms " LCD ", and " touch screen ". This proposed method can automatically extract product-features from the reviews without any labeled training data and hand-craft rules.

In order to filter opinion words in the sentence segments, we au-tomatically build a list of opinion words from the corpus. Given a high frequency word x i (e.g. the count of occurrence  X  10 in our experiments). Let F pros ( x i ) and F cons ( x i ) be the frequency of x in Pros and Cons corpus, respectively. We calculate the distribu-tion difference between F pros ( x i ) and F cons ( x i ) using the similar method presented by Zagibalov et al. [23]. The distribution differ-ence is calculated using Equation 1.
If difference &gt; 1, then the frequencies are not similar . Hence, x has enough distinguishing power. We consider x i as an opinion word.
 Figure 2: Example of product-feature extraction from cus-tomer reviews
The challenge in product-feature categorization is how to cap-ture latent semantic association among product-features from the reviews. In this section, we present a latent semantic association (LaSA) model to find the latent semantic association structures of "words" according to their virtual context documents in the cus-tomer reviews.
Each product aspect often has various term representations. For example, " photo ", " picture "and" image " all refer to the same as-pect in the digital camera domain. It is a big challenge for product-feature categorization to effective capture latent semantic associ-ation among various product-features and their variants from the reviews. In this section, we present LaSA model to find the latent semantic association structures of "terms" according to their con-text snippets in the customer reviews.

Product-feature categorization focuses on grouping all the product-feature terms into semantic categories. We consider it as a concept group problem. Let X be a feature space to represent the observed word instances, and let Y be the set of semantic category labels. Let p s ( x, y ) and p t ( x, y ) be the predicted underlying category dis-tribution and the true underlying target category distribution, re-spectively. In order to minimize the human efforts, we expect to p ( x, y ) better approximate p t ( x, y ) without any labeled data.
Product-feature categorization based on lexical comparison usu-ally is not comprehensive enough to capture the underlying seman-tic distribution of various product-features. Product-features in the same semantic category usually have various term representations. For example, " screen ", " display ", " monitor "and" viewfinder "all refer to the same aspect in the digital camera domain. Many product-feature terms in the same category are not similar on the lexical level. However, these terms often appear in the similar syntac-tic and semantic context. For instance, product-feature terms in the category " appearance " often occur around the indicates " beau-tiful ", " fashion ", " popular " etc. Such latent semantic association among words provides useful hints for capture the underlying se-mantic category distribution in the domain.

Hence, we present LaSA model  X  s,t to capture latent semantic association among words in the domain.  X  s,t is learned from the unlabeled domain data. Each instance is characterized by its co-occurred context distribution in the learning. Semantic association feature in  X  s,t is a hidden random variable that is inferred from data. Even though word instances do not have the lexical similarity, but are in similar context, they still might have relatively high proba-bility in the same semantic concept set. Obviously, LaSA model can better capture the latent semantic association among words. It can enhance the estimate of the semantic category distribution p ( y | x ;  X  s,t ) to better approximate the real semantic category dis-tribution p t ( y | x ;  X  s,t ) in the domain.

In the product-feature categorization, we construct the first la-tent semantic association (LaSA) model to group words into a set of concepts according to their virtual context documents. Instances in the same concept set are considered as behaving in the same way for product-feature categorization. Thus, we employ the first LaSA model to generate the latent semantic structure for each product-feature. The second LaSA model is constructed to categorize the product-features according to their latent semantic structures and context snippets in the reviews. With the present multi-level LaSA method, we may better approximate the real semantic category dis-tribution without any labeled data.
In order to learn latent relationships among words from the un-labeled review corpus, each word candidate is characterized by a virtual context document as follows.

Given a word x i , its virtual context document (denoted by vd is composed of all the context units around x i in the corpus, that is, where, F ( x s k i ) denotes the context feature set of x sentence s k , n is the total number of the sentences which contain x in the corpus.

Given the context window size {-t, t} (i.e. previous t words and next t words around x i in s k , t=3 in our experiments). F ( x usually consists of the following features. 1. Anchor unit A x i C : the current focused word unit x i 2. Left opinion set O x i L : two left adjacent adjective units { adj 3. Right opinion set O x i R : two right adjacent adjective units 4. Left adjacent unit A x i L : the nearest left adjacent unit x 5. Right adjacent unit A x i R : the nearest right adjacent unit x 6. Left context set C x i L : the other left adjacent units { x 7. Right context set C x i R : the other right adjacent units { x
For example, given x i = "screen" , s k = "My new thinkpad is very good because its LCD screen is very large and nice" . Let the con-text window size be {-3,3}. F ( screen ) ={ screen , O L ( good ), O L ( new ), O R ( large ), O R ( nice ), A L ( LCD ), A R ( is ), C ( because ), C R ( very ), C R ( large )}. vd x i actually describes the semantic and syntactic feature distri-bution of x i in the domain. We construct the feature vector of x with all the observed context features in vd x i . Given the feature vector of vd x i , Vector( vd x i )= { f i 1 , ..., f i j jth context feature related to x i , m is the total number of features in vd x i . The weight of each context word f i j in vd x by Mutual Information [4] between x i and f i j .
 where, P ( f i j ,x i ) is the joint probability of x i and f in the corpus, P ( f i j ) is the probability of f i j occurred in the corpus. P ( x i ) is the probability of x i occurred in the corpus. The weight is normalized to non-negative in the model training.
LaSA model actually can be considered as a general probabilis-tic topic model. It can be learned from the unlabeled review corpus using the popular hidden topic models such as Latent Dirichlet Al-location (LDA) [1], probabilistic Latent Semantic Indexing (pLSI) [7].

Topic models are statistical models of text that posit a hidden space of topics in which the corpus is embedded [1]. LDA is a probabilistic model that can be us ed to model and discover under-lying topic structures of documents. LDA assumes that there are K "topics", multinomial distributions over words, which describes a collection. Each document exhibits multiple topics, and each word in the document is associated with one of the topics. LDA imposes a Dirichlet distribution on the topic mixture weights corresponding to the documents in the corpus. The topics derived by LDA seem to possess semantic coherence. Those words with similar seman-tics are likely to occur in the same topic. Since the number of LDA model parameters depends only on the number of topic mixtures and vocabulary size, LDA is less prone to over-fitting and is capable of estimating the pr obability of unobserved test documents. LDA can be used to estimate the multinomial observations by unsuper-vised learning. LDA is already applied to enhance document rep-resentations in text classification [1] and information retrieval [21].
In the following, we illustrate how to construct LDA-style LaSA model  X  on the virtual context documents. Algorithm 2 describes LaSA model training method in detail, where, Function AddT o ( data, Set ) denotes that data is added to Set . Given a large-scale unlabeled review data set D r , virtual context document for each word in the candidate word set CandWordSet is extracted from D r at first, and the weight of each context word in vd x i puted using Mutual Information (see Equation 2 in Section 4.2.1). Then, LaSA model  X  with Dirichlet distribution is generated on the virtual context document set VDSet using the algorithm presented by Blei et al [1]. In our experiments,  X  =0.1, and the number of it-erations is 1000.

LaSA model learns the posterior distribution to decompose words and their virtual context documents into topics. It extends the tra-ditional bag-of-words topic models to context-dependence concept association model. It has potential use for concept grouping. Algorithm 2 : LaSA Model Training
Since people often use various terms to refer to the same feature, it is important to group product-features into semantic categories in opinion mining. In this section, we present a multilevel LaSA method to categorize the product-features. The first LaSA model is constructed for the words in the product-feature terms. It groups these words into a set of concepts according to their virtual con-text documents. This model generates the latent topic structure for each product-feature. The second LaSA model is constructed to categorize all the product-features according to their latent topic structures and context clues in the corpus.
Component words in the product-feature terms are important in-dicators for semantic categorization. In order to better categorize the product-features, we build LaSA model to generate the latent topic structures for product-features as follows.

LaSA model  X  W is constructed for the words in the product-features using Algorithm 2 (see Section 4.2.2). Virtual context doc-uments of these words are constructed from the reviews using the method described in Section 4.2.1. LaSA model  X  W learns the posterior distribution to decompose these words and their virtual context documents into topics. Each word is assigned to a topic category by  X  W . Table 1 lists some content words from a random selection of 4 topics computed on the digital camera reviews. As shown, words in the same topic actually are grouped into broad concept sets. For example, topic 4, 8, 12 and 16 are related to the concepts media , battery , photograph and screen , respectively.  X  W can effectively capture latent semantic association among the words. We employ  X  W to further generate the latent topic structures for product-features. The latent topic structure of a given product-feature pf i is composed of the topic label sequence of all the words in pf i ,thatis, Table 1: Samples from 4 randomly selected topics computed in digital camera domain where, w j denotes the jth word in pf i . ts ( w j ) denotes w topic assigned by  X  W . Table 2 shows the latent topic structures of some product-features generated by  X  W . By projecting the product-features into latent topic structures, we may capture more latent se-mantic similarity among those product-features with the same topic structure.
 Table 2: Product-feature terms and their latent topic structures
The product-features with the similar latent topic structures usu-ally have some semantic similarity. We categorize product-features according to their latent topic structures and context clues in the re-view corpus. In the following, we illustrate how to construct LaSA-based product-feature categorization model  X  P .

Given an unlabeled review corpus and the list of product-features, we first construct the LaSA model  X  W (see Section 5.1) to gen-erate the latent topic structure for each product-feature. Second, the virtual context documents of all the latent topic structures are constructed from the review corpus. Finally, product-feature cate-gorization model  X  P with Dirichlet distribution is generated from these virtual context documents using the algorithm presented by Blei et al [1].  X  P learns the posterior distribution to decompose the latent topic structures of product-features and their context docu-ments into topics. Hence, each product-feature is assigned to a topic category by  X  P . Algorithm 3 describes this method in de-tail, where, Function TS ( pf i ,  X  W ) denotes that  X  W generates the latent topic structure for the product-feature pf i . Function AddT o ( data , Set ) denotes that data is added to Set .

In LaSA-based product-feature categorization model building, given a latent topic structure ts j , its context document CtxDoc is composed of the context units of all the product-features with ts in the corpus, that is, where, pf i denotes the ith product-feature with ts j . n is the total number of the product-features with ts j . Ctx ( pf i ,s k context units of pf i in the kth sentence s k . m is the total number of the sentences which contain pf i in the corpus. In our experiments, Ctx ( pf i ,s k ) is composed of a bag of all the non-stop words in s For example, given pf i = "LCD screen" , s k = "Its LCD screen is very
Algorithm 3 : Product-feature Cate gorization Using Multi-level LaSA Method nice" .Ctx(" LCD screen ", s k )={" LCD ", " screen ", " nice "}.
CtxDoc ts j actually describes the latent semantic distribution of all the product-features with ts j in the corpus. We construct the feature vector of ts j with all the observed context features in CtxDoc ts j . Given the feature vector of CtxDoc ts j , Vector ( CtxDoc ts j ) ={ cf j 1 , ..., cf j i , ..., cf j M }, cf text feature related to ts j , M is the total number of context features in CtxDoc ts j . The weight of cf j i is calculated as follows. where, tf denotes the occurrence frequency of cf j i in CtxDoc idf denotes inverse document frequency which is the inverse of the percentage of the context documents in which cf j i occurs.
In this section, we evaluate the proposed approach using the cus-tomer reviews of three electronics product domains. Two data sets are English reviews in digital camera and laptop domains. One data set is Chinese reviews in cell phone domain. We analyze the per-formance of product-feature extraction and categorization in detail. We build three domain-specific review data sets (see Table 3). The English digital camera and laptop data sets respectively con-sist of 4,694 customer reviews (totally 1.90M words ) and 2,348 customer reviews (totally 0.74M words). The Chinese cell phone data set consists of 8,181 customer reviews (totally 5.07M Chinese characters). The English reviews are collected from several En-glish product review web sites while the Chinese reviews are col-lected from a specialized cell phone review web site. Products in these sites have a large number of reviews. In the preprocess, these review documents are first cleaned to remove HTML tags. After that, a Maximum Entropy part-of-speech (POS) tagger is used to generate POS tags for English data. Meanwhile, Chinese data are segmented into words and tagged with POS using HMM.
In the experiments, we extract and categorize the domain-specific product-features from the above three data sets. In the following, we will analyze these experimental results in detail.
We evaluate the quality of the produc t-feature extraction in this section. Three product-feature lists are respectively extracted from the above data sets.

We use the standard Precision (P) as the major performance met-rics. To evaluation precision, we use each algorithm to generate list of outputs (product-features). All the output product-features are reviewed manually and then mark each as correct or incorrect. An output product-feature is correct if it refers to an attribute or com-ponent of the product in the domai n. The quality is ensured by cross-validation checking.
 Since noun phrase (NP) based statistical method (denoted as NPStc ) is a popular unsupervised term extraction method, we com-pare our extraction method with it. NPStc method automatically extracts NP (i.e. two or more continuous nouns in a sentence) from the corpus, and outputs thos e high-frequency NPs as product-feature terms. In the following comparison experiments, NPStc(Full) method extracts all the NPs from all the full text in the data set, and outputs only high-frequency NPs (i.e. frequency  X  3) as product-features. NPStc(Pros+Cons) method extracts all the NPs from Pros and Cons parts in the data set, and outputs all the NPs as product-features.

Our product-feature extraction method consists of three steps, including candidate extraction , verification and expansion .Inor-der to investigate the contribution of each step, we also compare our method (denoted as Extract-Verify-Expand ) with the simplified Extract-Verify method. Extract-Verify method first extracts all the candidates from Pros and Cons , then verifies them in the detail re-views (see Step 1 and 2 described in Section 3). Finally, it outputs those verified valid candidates as product-features without any ex-pansion.
 Table 4 shows the accuracy of these methods in each domain. Experimental results show that NPStc(Full) and NPStc(Pros+Cons) produce too many non product-feature terms. Moreover, NPStc(Full) method misses many low-frequency ones. Extract-Verify-Expand outperforms NPStc and Extract-Verify in all the domains. Its accu-racy is 0.8010, 0.7860 and 0.8269 in digital camera, laptop and cell phone domains, respectively. Furthermore, it recalls more correct product-feature terms than the other methods in each domain.
On the English digital camera data set, Extract-Verify-Expand yields an accuracy of 0.8010, and extracts 7,247 correct product-feature terms. Compared with NPStc (Pros+Cons) (P=0.7391), Extract-Verify-Expand significantly enhances the precision by 6.19 percent points. Especially, it recalls 5.08 times correct terms of Methods Digital Camera (English) NPStc(Full) 4,359 1,747 0.4008 NPStc(Pros+Cons) 1,690 1,249 0.7391 Extract-Verify 1,275 1,124 0.8816 Extract-Verify-Expand 9,048 7,247 0.8010 Methods Laptops (English) NPStc(Full) 1,554 811 0.5219 NPStc(Pros+Cons) 1,621 616 0.3800 Extract-Verify 1,095 743 0.6785 Extract-Verify-Expand 4,065 3,195 0.7860 Methods Cell phone (Chinese) NPStc(Full) 5,079 1,061 0.2089 NPStc(Pros+Cons) 363 259 0.7135 Extract-Verify 973 755 0.7760 Extract-Verify-Expand 5,512 4,558 0.8269 Table 4: Performance of product-feature extraction in the dif-ference domains NPStc (Pros+Cons) (1,249 correct terms). Compared with NPStc(Full) method (P=0.4008), Extract-Verify-Expand significantly enhances the precision by 40.02 percent points. Moreover, it recalls 4.15 times correct terms of NPStc(Full) method (1,747 correct terms). Experimental results on the English laptop review data set also show the similar trends.

On the Chinese cell phone data set, Extract-Verify-Expand method yields a precision of 0.8269, and extracts 4,558 correct product-feature terms. Compared with NPStc(Pros+Cons) (P=0.7135), it significantly enhances the precision by 11.34 percent points. Fur-thermore, it recalls 17.60 times correct terms of NPStc(Pros+Cons) method (259 correct terms). Compared with NPStc(Full) method (P=0.2089), Extract-Verify-Expand significantly improves the pre-cision by 61.80 percent points. Meanwhile, it recalls 4.30 times correct terms of NPStc(Full) method (1,061 correct terms). Figure 3: Precision curves of product-feature extraction in dig-ital camera domain
Figure 3, 4 and 5 show precision curves of these methods in dig-ital camera, laptop and cell phone domains. All the output candi-dates are ranked according to their frequency in the corpus. Given top n ranked outputs, Extract-Verify-Expand method achieves much better precision than the other methods at most of the cut-points. Moreover, its precision curve is more stable. On both digital cam-era and cell phone data sets, the precision of Extract-Verify-Expand method is above 80% at most of the cut-points while that one of the other methods ranges 80%  X  20% at most of the cut-points. On the laptop data set, the precision of Extract-Verify-Expand method is above 75% at most of the cut-points while that one of the other methods ranges 75%  X  40% at most of the cut-points. These exper-imental results show that Extract-Verify-Expand method effectively captures low-frequency terms. For example, it outputs 4,726 cor-rect low-frequency terms (Frequency &lt; 3) from the digital camera data set.
 Figure 4: Precision curves of product-feature extraction in lap-top domain Figure 5: Precision curves of product-feature extraction in cell phone domain
All the experimental results show that our method achieves better performance. Our method effectively removes invalid candidates by reoccurring verification, and recalls more compound terms. It also captures more low-frequency p roduct-features . Moreover, our method is language-and domain-independent.

Of course, our method still br ings some noises in the product-feature extraction. The errors come from two aspects:1) Some can-didates may not be the integrated phrases; 2) Not all fragments ending with nouns could be product-feature terms.
In this section, we evaluate the performance of product-feature categorization in the given three domains. In the experiments, the domain-specific product-feature lists extracted by Extract-Verify-Expand method (see Section 6.2.1) are further grouped into seman-tic categories, respectively.

With the limited of human efforts and time, we pre-constructed evaluation sets on several hot product-feature categories in each domain (see Table 5). All the product-features are checked man-ually. If a product-feature (PF) term satisfies the specification of product-feature categories, we give it the relevant label. The qual-ity is ensured by cross-validation checking.

The performance of product-feature categorization is evaluated using Rand Index [14], a measure of cluster similarity [2, 3, 20]. In equation 4, P 1 and P 2 respectively represents the partition of an algorithm and manual labeling. The agreement of P 1 and P checked on their n  X  ( n  X  1) / 2 pairs of instances, where n is the size of data set D. For each two instances in D, P 1 and P assigns them to the same cluster or to different groups. Let a be the frequency where pairs belong to the same group of both partitions. Let b be the frequency where pairs belong to the different group of both partitions. Then Rand Index is calculated by the proportion of total agreement.

We used this measure to calculate the accuracy of product-feature categorization in the experiments. The parts of product-feature terms in the pre-constructed evaluation set are used to represent the data set D. Partition agreements between the pairs of any two terms in the parts and in the grouping results are checked automatically. This measure varies from zero to one. Higher scores are better. We compared our multilevel LaSA method (denoted as Multi-LaSA , see Algorithm 3 in Section 5.2) with k-means clustering [12] and LDA-based categorization method (denoted as LDA-based ). k-means is a standard clustering algorithm. In k-means clustering, each product-feature term is characterized by a bag of non-stop words in the sentences which contain this term. In LDA-based cate-gorization method, the virtual context documents of all the product-features are constructed, and LDA -based categorization model for the product-features is learned from these virtual context docu-ments using Blei X  X  algorithm [1]. Finally, each product-feature is assigned to a category using this model.

In the experiments, the product-feature terms in each domain are categorized using these methods, respectively. Experimental re-sults show that Multi-LaSA effectively groups the product-features into semantic categories. Figure 6, 7 and 8 list some categorization samples of Multi-LaSA in digital camera, laptop and cell phone do-mains, respectively. As shown, terms in each category are repre-sentative. Especially, although so me terms have little similarity on the lexical level, they are also correctly grouped into the same cate-gory according to their semantic similarity. For example, on digital camera domain (see Figure 6), although terms " screen ", " LCD ", " display ", " viewfinder " are not similar on the lexical level, they are correctly assigned to the same category " Screen ". This shows that Multi-LaSA can effectively capture the latent semantic association among product-feature terms.

Selecting the right number of topics is also an important problem in the product-feature categorization. A range of 50 to 300 topics is typically used in the topic modeling literature. 50 topics are often Figure 6: Product-feature categorization samples of Multi-LaSA in digital camera domain Figure 7: Product-feature categorization samples of Multi-LaSA in laptop domain Figure 8: Product-feature categorization samples of Multi-LaSA in cell phone domain used for small collections and 300 for relatively large collections [21]. However, in the product-feature categorization, the number of topics might be set in a different range. It is confirmed here by our experiments with different v alues of K (10, 20, ..., 100) on the three review data sets.
 Figure 9: Product-feature categor ization evaluation on digital camera domain with different number of topics (K) Figure 10: Product-feature categorization evaluation on laptop domain with different number of topics (K)
We evaluate the accuracy curves of these methods with different number of topics in each domain. Experimental results show that Multi-LaSA and LDA-based methods achieve better accuracy than k-means in each domain, as shown in Figure 9, 10 and 11. The ma-jor reason for significant performance enhancement is that Multi-LaSA and LDA-based methods effectively capture the latent seman-tic association among words from their virtual context documents. Moreover, Multi-LaSA also outperforms LDA-based method at the most of the operation points in each domain. Especially, at the number of topics K=20, the scores of Multi-LaSA method achieve 0.8154, 0.8537 and 0.8218 in digital camera, laptop and cell phone domains, respectively. Compared with K-means , Multi-LaSA sig-nificantly enhances the accuracy by 10.33%, 14.08% and 29.90%, respectively. Compared with LDA-based method, Multi-LaSA sig-nificantly improves the accuracy by 7.41%, 12.50% and 25.29%, respectively.

We perform t-tests on all the comparison experiments in all the three domains (see Figure 9, 10 and 11). On the 30 comparison experiments of k-means and Multi-LaSA , p-value is 4.93754E-07, which shows that the performance improvement is statistically sig-nificant. Meanwhile, p-value &lt; 0.001 on the 30 comparison exper-iments of LDA-based method and Multi-LaSA , which shows that Figure 11: Product-feature categorization evaluation on cell phone domain with different number of topics (K) the enhancement is also statistically significant. Table 6 shows the performance comparison of these methods with different num-ber of topics ( K ). The evaluation measure is average precision of each method on all the three domains with a predefined number-of-topics K . Multi-LaSA always obtains much better average pre-cision than k-means and LDA-based methods at each predefined number-of-topics. Moreover, Multi-LaSA method gives the best av-erage precision at K=20.
 Table 6: Comparison of k-means clustering, LDA-based method and Multi-LaSA with di fferent number of topics (K). The evaluation measure is average precision of each method on all the three domains with a pre defined num ber-of-topics (K).  X  P denotes the percentage change in performance (measured in average precision) of Multi-LaSA over k-means or LDA-based method.

All the above experimental results demonstrate that Multi-LaSA produces better categorizations than LDA-based method and K-means . The major reason for the significant enhancement is that Multi-LaSA better captures deeper latent semantic association among the product-features using latent topic structures. Multi-LaSA bet-ter approximates the underlying semantic distribution of the product-feature categories with a large-scale unlabeled customer review cor-pus.

Product-feature extraction and categorization is always a big chal-lenge for opinion mining and other related real applications. This proposed method has been integrated into our existing opinion min-ing system. By grouping product-features into categories, our opin-ion mining system effectively provides non-trivial and more sound sentiment analysis and opinion summarization in several customer cases. We will further explore how to enhance the performance stability across domains in the real applications.
Fine-grained aspect-based opinion mining provides more use-ful information for users to make their purchase decision. It is very important to extract and categorize various product-features for opinion mining and other related real applications. However, few product-feature lists are available in practice. Although super-vised extraction and categorization methods work better, they re-quire lots of human efforts for labeling training data. In this paper, we propose an unsupervised product-feature extraction and cate-gorization method with multilevel latent semantic association. We first extract the product-features from the semi-structured customer reviews. Second, we categorize t he product-features using multi-level LaSA method. The first LaSA model captures latent semantic association among words in the product-features. It groups words into a set of concepts according to their virtual context documents. We employ this model to generate the latent semantic structure for each product-feature. The second LaSA model categorizes all the product-features according to their latent semantic structures and context snippets in the corpus. Experimental results show that our method achieves better performance than the existing approaches. Moreover, our method is language-and domain-independent. [1] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. [2] S. Branavan, H. Chen, J. Eisenstein, and R. Barzilay. [3] C. Cardie and K. Wagstaff. Noun phrase coreference as [4] K. W. Church and P. Hanks. Word association norms, mutual [5] P. Deane. A nonparametric method for extraction of [6] S. Evert and B. Krenn. Methods for the qualitative evaluation [7] T. Hofmann. Probabilistic latent semantic indexing. In [8] M. Hu and B. Liu. Mining and summarizing customer [9] M. Hu and B. Liu. Mining opinion features in customer [10] N. Kaji and M. Kitsuregawa. Building lexicon for sentiment [11] B. Liu, M. Hu, and J. Cheng. Opinion observer: analyzing [12] J. B. MacQueen. Some methods for classification and [13] A.-M. Popescu and O. Etzioni. Extracting product features [14] W. M. Rand. Objective criteria for the evaluation of [15] C. Scaffidi, K. Bierhoff, E. Chang, M. Felker, H. Ng, and [16] P. Schone and D. Jurafsky. Is knowledge-free induction of [17] Q. Su, X. Xu, H. Guo, Z. Guo, X. Wu, X. Zhang, B. Swen, [18] I. Titov and R. McDonald. A joint model of text and aspect [19] I. Titov and R. McDonald. Modeling online reviews with [20] K. Wagstaff, C. Cardie, S. Rogers, and S. Schroedl. [21] X. Wei and B. Croft. Lda-based document models for ad-hoc [22] T.-L. Wong, W. Lam, and T.-S. Wong. An unsupervised [23] T. Zagibalov and J. Carroll. Automatic seed word selection
