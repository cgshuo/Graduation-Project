 We often refer to information retrieval techniques to find information from a vast dataset or Internet. Ranking is an important part of information retrieval. Nowadays, more and more features used to construct ranking functions have been proposed e.g. content-based features such as TFIDF , BM 25 ; link-based features such as PageRank , HITS ; user behavior features based on clickthrough data. There are hundreds of pa-rameters to tune when constructing a ranking function and it is unpractical to tune these parameters manually. So  X  X earning to Rank X  (shown as LT R for simplicity in the rest of the paper), an interdisciplinary field o f information retrieval and machine learning, has gained increasing attention. The LT R method optimizes loss function to tune the parameters for each weak ranking functions and fuses them into a final ranking func-tion, such as the linear ranking function. The final linear ranking function is what this paper focuses on.

Almost all LT R methods, which output the linear ranking functions, need construct-ing the weak ranking functions by normalizing the ranking features before the training process. And the Min  X  Max Normalization is almost the only method considered by the field of LT R for the best of our knowledge. The differences among the ranking features are neglected when constructing the weak ranking functions. Min  X  Max Nor-malization performs a linear transformation on the original data values and preserves the relationships among the original data values.

However, ranking features are different from each other in many aspects, such as data value distribution. For example, we conduct the statistics on the dataset used in Section 4.1. The ranges of BM 25 and PageRank are divided into 10 equal intervals re-spectively, and the proportion of the unique-feat ure-value number in each interval to the unique-feature-value number in the range is calculated, shown in the Figure 1. The re-sults show: (1) the proportion is 99% and 10% respectively for BM 25 and PageRank in the first interval; (2) there is only 1% of the unique values for BM 25 in the last 9 intervals; (3) the differences among the number of unique values for PageRank in each interval could be almost ignored. When u sed to construct the weak ranking func-tions from BM 25 and PageRank ,the Min  X  Max normalization method does not change the distribution showed in the Figure 1. And 99% of the unique BM 25 values are located in the interval of [0 , 0 . 1) when the range is [0 , 1] after the normalization.
Is it appropriate to just apply the Min  X  Max normalization method when construct-ing the weak ranking functions from the ranking features for the final linear ranking functions? This question is the motivation of this paper, and the main contributions of this work are: (1) three typical normalization methods are analyzed and compared to construct the weak ranking functions: Min  X  Max , Log and Arctan normalization methods. The experiments show that for some ranking features, the final ranking func-tions could achieve significant improvements by using Log and Arctan normalization instead of Min  X  Max normalization. (2) two intuitive normalization selection methods are proposed to handel the question above: Feature Distribution Selection Method and One-Switch Selection Method. The experimental results show that final ranking func-tions based on normalization selection methods significantly outperform the original one.
 The rest of the paper is organized as follows. In section 2, related work is presented. Section 3 introduces the normalization methods and normalization selection methods. In section 4, experimental results are reported and discussed. In the last section, the conclusion and future work are briefly discussed. The field of LT R is related to our work. In the LT R task, the data is composed of queries, the retrieved documents for every query, and the relevance levels labeled by human for the document and query pairs. The LT R methods proposed now could be LT R models using linear ranking functions and LT R models using nonlinear rank-ing functions. For LT R models using nonlinear ranking functions, the formation of the weak ranking function is nonlinear, such as RankBoost [2], the formation is bipartite. For LT R models using linear ranking functions, the formation of weak ranking func-tions is linear, such as Ranking SV M [3, 9], SV MMap [14, 12] and listMLE [13]. Ranking SV M [3, 9](shown as RankSV M for simplicity in the rest of the paper) is a very effective algorithm proved by many previous studies [15, 10]. The optimization formulation of RankSV M is as follows:
This paper focuses on the LT R model using linear ranking functions and RankSV M is used to verify the effectiveness of different methods to construct the weak ranking functions from specific ranking features. 3.1 Normalization Methods There are three typical normalization methods used to normalize the data into same range: Min  X  Max Normalization, Log Normalization and Arctan Normalization Method.

Min  X  Max Normalization performs a linear transformation on the original data values and preserves the relationships among the original data values, showing as Equa-tion 1 where x i is the value of i th ranking feature; the range of i th ranking feature is [ X ranking feature respectively; f i,M M is regarded as the value of the i th weak ranking function constructed from the i th ranking feature.
Log Normalization and Arctan Normalization perform a nonlinear transformation on the original data values, shown as Equation 2 Equation 3 respectively where f i,LOG and f i A TAN depict the value of i th weak ranking function after the Log Normalization and Arctan Normalization respectively.
Three Normalization Methods map the original data into the same range and the comparison is shown in Figure 2. The comparison result shows: (1) the Log and Arctan Normalization methods could scatter the small values of the ranking feature and cluster the large values; (2) the Log and Arctan normalization methods are useful to uniformly distribute the original data when values are clustered around small values with few large values. 3.2 Normalization Selection Method There are three normalization methods: Min  X  Max , Log and Arctan normalization methods. In this section, two intuitive normalization selection methods are proposed based on the feature value distribution: Feature Distribution Selection Method( FDM ) and One-Switch Selection Method( OSM ) summarized in Figure 3 and Figure 4 respectively.

FDM selects the features of which data val ues are clustered around small/large value with few large/small values, while OSM selects the features with better perfor-mances through evaluation measure MAP . After the feature selection with FDM or Procedure. Feature Distribution Selection Method Procedure. One-Switch Selection Method OSM , the weak ranking functions are constructed through LOG or AT AN normal-ization from selected ranking features, and through Min  X  Max normalization from other ranking features. 4.1 Experimental Setting Data Information. The experiment dataset is Microsoft Learning to Rank Datasets [4, 6, 11] which are latest and one of the largest benchmark datasets in the field of LT R . There are two large scale datasets: MSLR  X  WEB 30 k with more than 30 , 000 queries and MSLR  X  WEB 10 K with 10 , 000 queries, and the queries in latter dataset are ran-domly sampled from the ones in the former dataset. The relevance judgments, depicting the relevance degree between a query and a document, are obtained from a labeling set of Microsoft Bing search engine, which take 5 values from 0 (irrelevant) to 4 (perfectly relevant). And the larger the judgement value is, the more relevant the document is with respect to a specific query. 136 ranking features, widely used in the research com-munity, are extracted such as BM 25 , PageRank , HITS and Language M odel [5]. MSLR  X  WEB 30 k is applied in the experiment.

Five-fold cross validation is adopted to train and test the ranking models with three sets for training, one set for validation and one set for test. The evaluation measure value means the average among five test sets in the rest of this paper.
 Evaluation Measure. We u s e P @ N , NDCG @ N , MAP and ERR as our evaluation measures.
 P @ N is the precision at top N returned results, which is defined as:
NDCG @ N (Normalized Discounted Cumulative Gain) [7, 8], considering the posi-tion (rank) of the document with different relevance degrees in the returned result list, is quite an useful and popular measure for evaluating web search and related tasks. The NDCG score at top n returned results is defined as: where R ( i ) is the relevance degree which equals to the relevance judgement in this paper; Z N is the normalization constant that makes the perfect list get a NDCG score of 1.In this paper, N =1 , 2 , ..., 10 .

MAP is the mean average precision for the queries. It is a comprehensive measure which takes both precision and recall into consideration. The definition can be shown as: where m is the total number of queries, R j is the total number of relevant documents for the j th query, k is the total number of returned documents for the query, rel j ( d i ) and ( P @ i ) j are the rel ( d i ) and P @ i scores for the j th query respectively.
ERR (Expected Reciprocal Rank) [1], calculates the gain and discount for a docu-ment in a position considering the documents shown above it. And the definition could be shown as: where R MAX is the largest value of the relevance degree, and R MAX =4 in this paper. 4.2 Dataset Statistics Information The statistics is conducted on the dataset, an d we obtain following information for each ranking feature(e.g. i th ranking feature): 1. the maximum of minimum values for i th ranking feature: MAX i and MIN i ; 2. the number of unique values for i th ranking feature: N i ; 3. the range of i th ranking feature is equally divided into 10 intervals, and the number The ranking features could be classified into four categories based on the differences of the proportion distribution: (1) the first category, there does not exist an interval of which the proportion is larger than 20% . the ranking features belonging to this category: 6  X  10 , 130  X  133 . (2) the second category, the sum of first five intervals is larger than 80% . the ranking features belonging to this category: 1  X  5 , 11  X  95 , 106  X  110 , 126 , 127 , 129 , 134  X  136 . (3) the third category, the sum of last five intervals is larger than 80% . the ranking features belonging to this category: 101  X  105 , 111  X  125 , 128 . (4) the fourth category, the number of unique values is smaller than 3. the ranking features belonging to this category: 96  X  100 .

The intuitive idea is that: for the first category, the Min  X  Max normalization is more useful; for second and third categories, the Log and Arctan normalization are more useful, and the feature value should be reversed first before normalization for the third category; for the last category, all normalization methods perform the same as each other. Is this intuitive idea correct? The experiments as follows will give the answer to this question. 4.3 Experiments Results Two experiments are conducted in this section: normalization methods comparison without selection, and the experiment with normalization selection. The former exper-iment is to verify that other normalization methods, such as Log and Arctan normal-ization methods, could enhance the performan ce of the final ranking function. And it is unappropriate to just use Min  X  Max normalization method to construct the weak ranking functions. The latter experiment is to verify the effectiveness of the normaliza-tion selection method. Normalization Methods Comparison Without Selection. Three normalization meth-ods are applied to construct the weak ranking function, and we just apply the normaliza-tion methods to construct the weak ranking function without considering which one is more appropriate for a specific ranking feature. Then four ranking functions are trained in the new datasets: MM , the ranking function trained on the weak ranking functions normalized from the ranking features through the Min  X  Max normalization method; LOG , the ranking function through the Log normalization method; AT AN , the rank-ing function through the Arctan normalization method; MERGE , the ranking func-tion trained on the datasets which are composed of three datasets used by MM , LOG and AT AN . The comparison of these four ranking functions shows in Table 1 and the experimental results show in Figure 5. T-Test is conducted among four ranking func-tions with NDCG @1 , and the result is shown in Table 2( p  X  value &lt; 0 . 05 means the difference is significant);
From the results, we could see that: (1) four ranking functions conduct significantly different performances from each other except for MERGE and LOG with p  X  value 0 . 49 .(2) MERGE and LOG significantly outperform the other two ranking functions; (3) MM performs the poorest in the four ranking functions; (4) AT AN performs better than MM and worse than LOG ,so Arctan normalization is ignored in the normaliza-tion selection method in the next section.

Min  X  Max normalization is the poorest method to construct the weak ranking functions from the ranking features, and it is unappropriate to just apply the Min  X  Max normalization when the ranking features are quite different from each other in many aspects such as the number distribution of the unique ranking feature values. Log normalization method is the best method, which means that Log normalization method could fit the distribution of most ranking features and normalize them to construct the weak ranking functions better than Min  X  Max and Arctan normalization methods. The Experiment with Norm alization Selection. Which normalization method should be used for a specific ranking feature? In this section, two normalization selection meth-ods are applied to choose an appropriate normalization method for a ranking feature: FDM and OSM . After normalization selection with either selection method, the Log normalization method is used to construct the weak ranking functions from the selected ranking features and the Min  X  Max normalization method from the other ranking features. Then four final ranking functions based on different weak ranking functions are trained and tested: MM , LOG , RF FDM and RF OSM showninTable3. MM and LOG are the same ranking functions used in Section 4.3.

Arctan and Log normalization methods are useful when the data values are clus-tered around small values with few large values, and Log normalization is better than Arctan normalization according to the re sults in Section 4.3. So only Min  X  Max and Log normalization methods are used to verify the effectiveness of the normalization selection methods.
After the normalization selection, the ranking feature set, not chosen by FDM , con-tains all the ranking features which are the second and third categories in Section 4.2; the ranking feature set, chosen by OSM ,is: { 5 , 12 , 14 , 25 , 27 , 28 , 35 , 41 , 46 , 61 , 62 , 64 , 79 , 82 , 86 , 87 , 90 , 106 , 109 , 115 , 116 , 118 , 127 , 133 , 134 , 135 } ,in which 133 belongs to the first category and all others belong to the second or third cat-egory. OSM applies the MAP values to measure whether to choose a ranking feature, and the improvement percent of map i over map 0 in Figure 4 for i th ranking shows in Figure 6. T-Test is conducted among four ranking functions with NDCG @1 ,andthe result shows in Table 4.

The comparison results among four final ranking functions show in Figure 7. From the results, we could see that: (1) four ra nking functions perform differently from each other significantly, except for LOG and RF FDM with p  X  value 0 . 15 .(2) LOG and RF FDM significantly outperform the other two ranking functions; (3) MM per-forms the poorest in the four ranking functions; (4) RF OSM performs significantly better than MM and worse than LOG and RF FDM .

After normalization selection with FDM , RF FDM performs similarly to LOG and better than MM , which means that: (1) the ra nking features, selected by FDM ,are normalized with Log normalization in RF FDM and with Min  X  Max normalization in MM ,and Log normalization is more useful for them than Min  X  Max normaliza-tion. So, FDM is effective and could distinguish the ranking features whether Log or Min  X  Max normalization is more useful. (2) the ranking features, not chosen by FDM , are normalized with Log normalization in LOG and with Min  X  Max normal-ization in RF FDM ,and Log normalization performs almost the same as Min  X  Max normalization for these ranking features.

After normalization selection with OSM , RF OSM performs better than MM , but significantly worse than LOG and RF FDM . The reasons we analyze are that: ranking features are not i ndependent from each other, so the weak ranking functions affect the performances of the final ranking functions as a sub feature set instead of an individual ranking feature. That makes the OSM not so useful as FDM .

According to the experimental results in this section, we could answer the question in Section 4.2: the intuitive idea is almost correct except that: Min  X  Max and Log normalization are both useful for the first category. Based on the proportion distribution, we could choose an appropriate normalization method to construct the weak ranking function for a specific ranking feature. The weak ranking functions are mostly constructed through Min  X  Max normalization method for the final linear ranking functions in the field of LT R without considering the differences among the ranking features. There do exist differences among the rank-ing features from many aspects. In this paper, we analyze the ranking features and apply three normalization methods to construct the weak ranking functions: Min  X  Max , Log and Arctan normalization methods, and find that Log normalization could significant improve the performances of the final ranking functions. Then two intuitive normaliza-tion selection methods are proposed to try to handle the problem which normalization is appropriate to construct the weak ranking function for a specific ranking feature. The experimental results show that the ra nking functions based on the normalization selection methods significantly outperform the original one.

Future study could follow these aspects: (1) other normalization methods could be attempted to constructed the weak ranking functions based on the specific distribution of the ranking features; (2) a ranking featur e depicts a special aspect of the relevance between a query and a document, and how to design a normalization selection method considering this to choose the best normalization method.

