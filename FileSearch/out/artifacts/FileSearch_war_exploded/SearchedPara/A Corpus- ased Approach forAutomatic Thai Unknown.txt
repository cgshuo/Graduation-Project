 Unknown word recognition plays an important role in Natural Language Pro-cessing (NLP) since a word is a fundamental unit of language that provides meaning. Most NLP applications need to identify words in sentences before fur-ther manipulation. Word recognition can be basically done by using a lexicon collected beforehand. The lexicon may include almost all widely-used words in the language. However, it is impossible to construct the lexicon that includes all available words. Therefore, a technique that efficiently identifies boundaries of unknown words in text would help increase the overall of word recognition system performance. Identifying unknown words is even more difficult in lan-guages which have no explicit word boundary including Thai [1]. This is because unknown words contain known substrings may interfere word segmentation alyzed unknown words from a collection of randomly selected documents from Thai newspapers, scientific reports and non-fiction texts. They found that, on average, about 15% of words in Thai text are unknown. The result shows the necessity of an efficient unknown word recognition technique for Thai text. The processtorecognizeunknownwordcanbeseparatedintotwosteps:(1)unknown word candidate generation, and (2) unknown word boundary identification. In this paper, unknown word candidates are firstly generated by detecting unregis-tered portions in the input text. Then, various combinations of character clusters surrounding the unregistered portion are constructed as a set of unknown word candidates. After that, boundaries of unknown words are identified by using a supervisedlearningalgorithmwithfeaturesbasedonstatisticsfromthecollected text. Based on our preliminary investigation, we however found that an ordinary learning algorithm is unable to work well on this problem since the number of positive and negative generated candidates are unbalanced in the training set. There are a few number of positive candidates comparing to the number of neg-ative ones because various combinations of surrounding character clusters can be generated and most of them are negative.
 data set by grouping the candidates that are generated from the same unregis-tered portion into a group. Each group may contain almost 100 candidates but only one (or a few) candidate is labeled as positive. Candidates from all groups are then fed to the learning algorithm in order to generate a classifier. A candi-date is classified as positive based on its strength to be positive comparing to the other candidate in the same group. Moreover, we present a technique improving the prediction of a classifier by applying a boosting technique with voting un-der group-based evaluation by ranking. This paper presents an approach using a different subset of training data with a same algorithm learning method i.e., na X ve Bayes classifier as a base classifier. The research on unknown word recognition in Thai language has not been widely conducted as in other languages. A few researches has studied this problem since the past decades. The unknown words are viewed as the problematic source in the NLP system. Kawtrakul et al. [2] used the combination of a statistical se-mantic segmentaion model and a set of context sensitive rules to detect unknown words. Charoenpornsawat et al. [1] considered the unknown word recognition as a classification problem. They proposed a feature-based approach to identify Thai unknown word boundaries. Features used in the approach are built from the specific information in context surrounding the target unknown words. pro
Most word segmentation algorithms use a lexicon or dictionary to parse a text at the character level. Based on such algorithm, three possible results can be outputted when they face with an unknown word. The first one is to obtain one or more sequence of known words from the unknown (out-of-dictionary) word, for example, a compound word  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  (meaning: a kind of mango) can be segmented into  X   X  X  X  X  X  X  X  X  X   X  (mango),  X   X  X   X  (meaning: breast), and  X   X  X  X  X  X   X  (meaning: crack). All of these subwords are found in the lexicon. This kind of unknown words is called hidden unknown word. The second one is to gain a sequence of unknown segments which all are undefined in the lexicon. For example, we cannot detect any subword from an out-of-dictionary word  X   X  X  X  X  X  X  X  X  X  X   X  (meaning:
Anesthetic) since all of its substrings do not exist in the dictionary. The last one is to get a sequence of known words mixing with unknown segments. For instance, an unknown word  X   X  X  X  X  X  X  X  X  X  X  X   X  (meaning: leukemia) can be segmented into two portions: an unknown segment ( X   X  X  X  X  X  X   X ) and a known word ( X   X  X  X  X  X   X , meaning: wife).
 the existence of the unknown word. In this paper, we only focus on the recogni-tion of an unknown word in these two types, later called a detectable unknown word.
The proposed method contains three processes: (1) unregistered portion detec-tion, (2) unknown word candidate generation and reduction, (3) unknown word identificationandevaluation.Thedetailsoftheseprocessesaregiveninsequence. 4.1 Unregistered Portions Detection
Practically, it is difficult to define a word in the language that does not have explicit word boundary. To cope with ambiguities more efficiently, we apply the concept of Thai Character Cluster (TCC) [6]. TCC is an inseparable group of
Thai characters based on the Thai writing system. Unlike word segmentation that usually includes ambiguity, segmenting a text into TCCs is easily done by applying a set of rules. These morphological rules guarantee grammatically cor-rect for word boundaries in Thai writing system. Moreover, almost transliterated words in Thai is normally comprised of several short words. With this charac-teristic, TCC is suitable for unknown word detection approach, and improves the chance to discover a new word. Since a TCC is a group of characters smaller than a word, we therefore called a TCC that could not be found in a lexicon as an unregistered portion.
 dictionary [8] to facilitate word segmentation. In this work, the longest word segmentation [9] is applied by considering of minimum number of unregistered portions that were produced from both left-to-right and right-to-left longest matching. Whenever the number of unregistered portions from both directions are the same the left-to-right longest matching is selected. 4.2 Unknown Word Candidate Generation and Reduction Similar to [1], [2], a candidate is generated from merging  X  K TCCS around the consideringunregisteredportion,andtheportionitself.Forexample,thenumber of possible candidates is 100 when K is set to 9 . Furthermore, we present two basic rules to filter out the generated candidates. Since it is clear that a Thai word cannot comprise of any special characters, we do not generate a candidate that includes such special characters. The second rule is to employ a set of marker words, such as  X   X  X  X  X  X  X  X  X  X  X  X  X  X   X  (Besides this),  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  (comprised with) etc. These marker words are considered word separators. 4.3 Unknown Word Identification and Evaluation The existing works on Thai unknown word recognition [1,2,4] consider unknown wordcandidatesseparately.Eachcandidateisindependentlylabeledasapositive or negative instance. However, several candidates can be generated from an unregistered portion, and typically only one candidate is an actual unknown word.Wethereforeputmultiplecandidatesgeneratedfromthesameportioninto a group, and only the most likely candidate is classified as a positive instance. Features Extraction. We use a sequence of TCCs instead of a sequence of characters to denote an unknown word candidate. Then, statistical-based fea-tures for each unknown word candidate are computed. In order to fasten the process of n -gram calculation, we apply the algorithm in [12] that utilizes the sorted sistring to enable the simultaneous calculation of ( n -gram of) alphabetical sorted TCCs of a text string. For each sistring (i.e., unknown word candidate), eight types of features (F1-F8) are extracted as follows: (F1) Number of TCC : A technical words in Thai language tends to be long. Therefore, the number of TCCs in a word is an important factor to discriminate unknown words; (F2) Number of known words : Like several languages, some unknown words in Thai language can be viewed as a compound word that contains a number of known words. Therefore, the number of known words in a candidate can be used as a clue to identify whether the candidate is an unknown word or not; (F3) TCC varieties on the left and right-hand side : Since an isolated word is often used together with various words, the high varieties of distinct TCCs on the left and right-hand side of the considering candidate indicate that the candidate is likely to be a word; (F4) Probability of special character on the left and right-hand side : The probabiblity that special characters occur on the left and right-hand side of the considering candidate indicates that the candidate is located near de-limiters and likely to be a word; (F5) Number of Characters : A long candidate is likely to be an unknown word; (F6) Frequency : It is obvious that the number of occurrences of the word sistring is higher than that of non-word sistring; (F7)
IDF : An unknown word is generally a word that does not happen frequently in several documents, but it appears frequently in only some specific documents; and (F8) TFIDF : A weight is often used in information retrieval and text min-ing to measure the importance of a word in a corpus. The importance increases proportionally to the number of times a word appears in the document but is offseted by the frequency of the word in the corpus.

Classification Techniques From the features extracted from the training cor-pus, three techniques (T1-T3) are applied to learn classifier for identifying un-known word boundaries. (T1) Base Classifier : na X ve Bayes classifier is a machine learning technique that generates a classifier based on Bayes X  X  theorem with independence assumptions. where ^ c is the predicted class, P ( C = c ) is the prior probability that the class is c ,and P ( F i = f i | C = c ) isthe probabilitythat the feature F i hasa value f i when the class is c . For continuous attributes, Gaussian distribution with smoothing technique can be applied as where  X  is a small positive constant that is set to 0.000001 in the experiments,  X  is the mean, and  X  is the standard deviation. (T2) Group-based Evaluation by Ranking :Unliketheevaluationmodelinnormal classifiers, we propose a technique called  X  X roup-based evaluation by ranking (GER) X . It categorizes all candidates produced by the same unregistered portion location into the same group. This technique ranks all candidates with respect to their group based on its probability to be the positive class and select the top-k candidates of that group as the prediction for unknown words. where C j is the set of top-k candidates of j -th group when k is a number of preferred answer. G j is a candidate group which were generated from an unreg-istered portion location j , P ( c | x ) is the probability that the class is c when the candidate is x .
 as follows: where ACC k is the accuracy when top-k ranking is considered, N is the number of detected unregistered portions, each of which forms a group. The set of correct answers for group j is defined as A ( G j ) = { x ij | x ij is the i -th potential unknown word in the j -th group}. The set of k ranked answers from the system for group j is defined as P ( G j , k ) = { y ij | y ij is the i -th candidates ranked by the system for the j -th group when i  X  k }. (T3) Voting under Group-based Evaluation by Ranking : For additional im-provement of the prediction of a classifier, we propose a technique called  X  X oting under group-based evaluation by ranking (V-GER) X . Unlike the voting technique in ordinal ensemble methods, this technique ranks all candidates belonging to the group based on the summation of its probability to be the positive class on eachsub-ensembleandselectthetop-k candidatesofthatgroupastheprediction for unknown words.
 where C j is the set of top-k candidates when k is a number of preferred answer, G j is a candidate group which were generated from an unregistered portion location j ,  X  i is a weight of i -th sub-ensemble, P M the class is c in the i -th sub-ensemble when the candidate is x and i is number of sub-ensemble. In the experiment, we occupy a corpus of 16,703 medical-related documents gathered from WWW [13] with a size of 8.4 MB for evaluation. The corpus is first preprocessed by removing HTML tags and all undesirable punctuations. To construct a set of features, we apply TCCs and the sorted sistring technique. After applying word segmentation on the running text, we have detected 55,127 unregistered portions. Based on these unregistered portions, 3,209,306 unknown wordcandidates are generated according to the process shownin Sect. 4.2. More-over, these 55,127 unregistered portions came from only 3,763 distinct words. In practice, each group of candidates may contain one or two positive labels. Therefore, 62,489 unknown candidates were assigned as positive and 3,146,819 unknown candidates were assigned as negative. The average number of unknown candidates in a group is around 58.
 number of TCCs in a word is around 4.5. To generate unknown word candidates, we set K , the maximum number of TCCs surrounding an unregistered portion, to nine in our experiment. This number is twice of the average number of TCCs in a word. With K =9, the number of generated unknown word candidates is 100. Na X ve Bayes classifier is used as the base classifier. The experiments were con-ductedusing10-foldcrossvalidation.Toidentifyanunknownword,weemployed our proposed method (group-based evaluation by ranking). We investigate the performance of our method when the top-k candidates are considered as correct answers. Here, the k ranges from 1 to 10. The experimental results showed that the classifier gained the accuracy of 84.14%  X  0.19 to 97.25%  X  0.17 as shown in Table 1.
 under group-based evaluation by ranking technique by using 10 committees. The average accuracy with standard deviation are shown in Table 1. The results showed that the proposed ensemble method can achieve an increase in accuracy of 6.79% to 8.45% at the first rank when compared to the original and GER technique. In this paper, we presented an automated method to recognize unknown words from a Thai running text. We described how to map the problem to a classifica-tion task. The na X ve Bayes with a smoothing technique classifier is investigated using eight features for evaluation the model. In practice, the unknown word candidates actually have relationship among them. To reduce the complexity in unknown word boundary identification, reduction approaches are employed to decrease a number of generated unknown word candidates to 49%. This paper also proposed the group-based evaluation by ranking technique. This technique considered the unknown word candidates as groups that can solved the unbal-anced data sets problem. To further improve the prediction of a classifier, we applyaboostingtechniquewithvotingundergroup-basedevaluationbyranking. We have conducted a set of experiments on real-world data to evaluate the per-formance of the proposed approach. From the experiment results, the proposed technique achieves the accuracy of the order of 90.93%  X  0.50 to 97.90%  X  0.26 at the first rank and tenth rank. Our proposed ensemble method can achieve an increase in classification accuracy of the order of 6.79% to 8.45% at the first rank when compared to the original na X ve Bayes evaluation and GER technique, respectively.
 Acknowledgment This work has been supported by The Thailand Research Fund (TRF) of Thai-land via reseach grant BRG5080013. The authors would like to thank all mem-bers at KINDML laboratory at Sirindhorn International Institute of Technology for fruitful discussions and comments.

