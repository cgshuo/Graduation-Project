 Bayesian network (BN) [1] is a type of statistical models that efficiently represent the joint probability distribution of a domain. It is a directed acyclic graph where nodes rep-resent domain variables of a subject of matter, and arcs between the nodes describe the probabilistic relationship of variables. One problem that naturally arises is the learning of such a model from data. Most of the existing algorithms fail to construct a network of hundreds of variables in size. A reasonable strategy for learning a large BN is to firstly discover the Markov blanket of variables, and then to guide the construction of the full BN [2,3,4,5].

Markov blanket indeed is an important concept and possesses potential uses in nu-merous applications. For every variable of interest T , the Markov blanket contains a set of parents, children, and spouses (i.e., parents of common children) of T in a BN [1]. The parents and child ren reflect the direct cause and direct effect of T respectively while the spouses represent the direct cause of T  X  X  direct effect. Such causal knowledge is essential if domain experts desire to manipulate the data process, e.g. to perform a troubleshooting on a faulty device, or to test the body reaction to a medicine, or to study the symptom of a disease, etc. Furthermore, conditioned on its Markov blanket variables, the variable T is probabilistically independent of all other variables in the domain. Given this important property, the Markov blanket is inextricably connected to the feature selection problems. Koller and Sahami [6] showed the Markov blanket of T is the theoretically optimal set of features to predict T  X  X  values. We show an instance of Markov blanket within a small BN in Fig. 1. The goal of this paper is to identify the Markov blanket of a target variable from d ata in an efficient and reliable manner.
Research on Markov blanket discovery is traced back to the Grow-Shrink algo-rithm (GS) in Margaritis and Thrun X  X  work [7]. The Grow-Shrink algorithm is the first Markov blanket discovery algorithm proved to be correct. Tsamardinos et. al. [8,9] pro-posed several variants of GS, like the increm ental association Markov blanket (IAMB) and Interleaved IAMB that aim at the improved speed and reliability. However, the algorithms are still limited on achieving data efficiency. To overcome this limitation, at-tempts have been made including the Max-Min Parents and Children (MMPC) [10] and HITON-PC [11] algorithms for Markov blank et discovery. Neither of them is shown to be correct. This motivates a new generation of algorithms like the Parent-Child based search of Markov blanket (PCMB) [12] and the improved one -Iterative PCMB (IPC-MB) [13]. Besides the proved soundness, IPC-MB inherits the searching strategy from the MMPC and HITON-PC algorithms: it starts to learn both parents and children of the target variable and then proceeds to identif y spouses of the target variable. It results in the Markov blanket from which we are able to d ifferentiate direct causes (effects) from indirect relation to the target variable. The differentiation on Markov blanket variables is rather useful when the Markov blanket will be further analyzed to recover the causal structure, e.g., providing a partial order to speed up the learning of the full BN. In a similar vein, we will base the new algorithm on the IPC-MB and provide improvement on both time and data efficiency.

In this paper, we propose a novel Markov blanket discovery algorithm, called Dy-namic Ordering-based Search (DOS) algorithm. Akin to the existing algorithms, the DOS takes an independence  X  based search to find a Markov blanket by assuming that data were generated from a faithful BN modeling the domain. It conducts a series of statistical conditional independence tests toward the goal of identifying a number of Markov blanket variables (parents and children as well as spouses). Our main contri-bution on developing the DOS is on two aspects. Firstly, we arrange the sequence of independence tests by ordering variables not only in the candidate set, but also in the conditioning sets. We order the candidates using the independence measurement like the mutual information [14], the p -value returned by the G 2 tests [15], etc. Meanwhile, we order the conditioning variables in terms of the frequency that the variables enter into the conditioning set in the known independence tests. We re-order the variables im-mediately when an independence test is completed. By ordering both types of variables, we are able to detect true negatives effect ively within a small amount of conditional in-dependence tests.

Secondly, we exploi t the known conditional independence tests to remove true neg-atives from the candidate set at the earliest time. By doing so, we need test only a small number of the conditioning sets (generated from the candidate set) thereby improving time efficiency. In addition, we can limit the conditioning set into a small size in the new independence tests, which achieves data efficiency. We further provide the proof on the correctness of the new DOS algorithm. Experimental results show the benefit of dynamically ordering independence tests and demonstrate the superior performance over the IPC-MB algorithm. In the present paper we use uppercase letters (e.g., X , Y , Z ) to denote random variables and boldface uppercase letters (e.g., X , Y , Z ) to represent sets of variables. We use U to denote the set of variables in the domain. A  X  X arget X  variable is denoted as T unless stated otherwise.  X  X odes X  and  X  X ariables X  will be used interchangeably.

We u s e I ( X, Y | Z ) to denote the fact that two nodes X and Y are conditionally independent given the set of nodes Z . Using conditional independence, we may define the Markov blanket of the target variable T , denoted by MB ( T ) , as follows. Definition 1 (Markov Blanket). The Markov blanket of T is a minimal set of vari-ables conditioned on which all other variables are independent of T , i.e.,  X  X  X  U  X  { MB ( T )  X  T } I ( X, T | MB ( T )) .
 Bayesian network (BN) [1] is a directed acyclic graph G where each node is annotated with a conditional probability distribution (CPD) given any instantiation of its parents. The multiplication of all CPDs constitutes a joint probability distribution P modeling the domain. In a BN, a node is independent of its non-descendants conditioned on its parents.
 Definition 2 (Faithfulness). ABN G and a joint pr obability distribution P is faithful to one another iff every conditional inde pendence entailed by the graph G is also present in P [1,15]. A BN is faithful if it is faithful to its corresponding distribution P , i.e., I ( X, Y | Z ) = I P ( X, Y | Z ) .
 A graphical criterion for entailed c onditional independence is that of d -separation [1] in a BN. It is defined as follows.
 Definition 3 ( d -separation). Node X is d -separated from node Y conditioned on Z in the graph G if, for all paths between X and Y , either of the following two conditions holds: 1. The connection is serial or diverging and Z is instantiated. 2. The connection is converging, and neither Z nor any of Z  X  X  descendants is instanti-ated.
 Due to the faithfulness assumption and d -separation criterion, we are able to learn a BN from the data generated from the domain. We may utilize statistical tests to establish conditional independence between variable s that is structured in the BN. This moti-vates the main idea of an independence-based (or constraint-based) search for learning BN [15]. Most of current BN or Markov blanket learning algorithms are based on the following theorem [15].
 Theorem 1. If a BN G is faithful to a joint probability distribution P then: 1. Nodes X and Y are adjacent iff X and Y are conditionally dependent given any other set of nodes. 2. For each triplet of nodes X , Y and Z in G such that X and Y are adjacent to Z , but X and Y are not adjacent, X  X  Y  X  Z is a sub-graph of G iff X and Y are dependent conditioned on every other set of nodes that contains Z .
 A faithful BN allows the Markov blanket to be graphically represented in G .Further-more, Tsamardinos et. al. [9] shows the uniqueness of Markov blanket in Theorem 2. Theorem 2. If a BN G is faithful, then for every variable T , the Markov blanket of T is unique and is the set of parents, children, and spouses of T .
 We observe that the first part of Theorem 1 a llows one to find parents and children of the target node T , denoted by PC ( T ) , since there shall be an edge between PC ( T ) and T ; the second part provides possi bility on identifying a spouse of T , denoted by SP ( T ) . Hence Theorem 1 together with Theorem 2 provide a foundation for the Markov blanket discovery. The Dynamic Ordering-based Search algor ithm (DOS) discovers the Markov blanket MB ( T ) through two procedures. In the first procedure, the algorithm finds a candidate set of parents and children of the target node T , called CPC ( T ) . It starts with the whole set of domain variables and gradually excludes those that are independent of T conditioned on a subset of the remained set. In the second procedure, the algorithm identifies spouses of the target node, called SP ( T ) , and removes the false positives from CPC ( T ) . The resulted CPC ( T ) is the output MB ( T ) .

Prior to presenting the DOS algorithm, we introduce three functions. The first func-tion, called Indep ( X, T | S ) , measures the independence between the variable X and the target variable T conditioned on a set of variables S . In our algorithm, we use G 2 tests to compute the conditional independence and take the p -value (returned by G 2 test) for the independence measurement [15]. The smaller the p -value, the higher the dependence. In practice, we compare the p -value to a confidence threshold 1- X  .More precisely, we let Indep ( X, T | S ) be equivalent to the p -value so that we are able to con-nect the independence measurement to conditional independence, i.e., I ( X, T | S ) = true iff Indep ( X, T | S )  X  1  X   X  . Notice that we assume independence tests are correct.
The second function, called Freq ( Y ) , is a counter that measures how frequent a variable Y enters into the conditioning set S in the previous conditional independence tests Indep ( X, T | S ) .Alarge Freq ( Y ) value implies a large probability of d -separating X from T using Y in the conditioning set S . In general, the variables belonging to PC ( T ) have a large Freq ( Y ) value.

The third function, called GenSubset ( V ,k ) , generates all subsets of size k from the set of variables V in the Banker  X  X  sequence [16]. The Banker  X  X  sequence is one way of enumerating all subsets of a set. It examines subsets in monotonically increasing order by size. For all subsets of size k , it constructs the subset by sequentially picking up k elements from the set. We denote the resulted set by SS , i.e., SS = GenSubset ( V ,k ) . Notice that SS contains a set of ordered subsets of identical size. For example, we may have SS = GenSubset ( { A, B, C } , 2) = {{ A, B } , { A, C } , { B, C }} . 3.1 Algorithm Formulation We present details of the DOS algorithm in Fig 2. As mentioned above, the new algo-rithm uses two procedures, called GenCP C and Ref CP C respectively, to discover the Markov blanket of the target variable T . It starts with the GenCP C procedure that aims to find a candidate set of parents and children of T .The GenCP C procedure searches the CPC ( T ) by shrinking the set of T  X  X  adjacent variables called ADJ ( T ) . The initial ADJ ( T ) is the whole set of domain variables except T , i.e., ADJ ( T )= U  X  X  T } . The procedure then removes an Non-PC (non-parent and child) variable from ADJ ( T ) if the variable is conditionally independent of T given a subset of the adjacent set (lines 7-9). We use G 2 estimation in the conditional independence tests (line 7), and check the independence for each adjacent variable ( line 4) by examining all empty condition-ing sets ( cutsize =0) first, then all conditioning sets of size 1, later all those of size 2 and so on, until cutsize  X  X  ADJ ( T ) | (lines 1 and 15). Recall that the number of data instances to reliable G 2 tests is exponential to the size of the conditioning set S . Hence the strategy of monotonically increasing size of S contributes to the improvement on data efficiency.

We observe that the plain algorithm needs to iterate every T  X  X  adjacent variable and test the conditional independence possi bly given all subsets of the adjacent set ADJ ( T ) . Clearly we may speed up the procedure by reducing ADJ ( T ) at the earli-est time. In other words, we shall remove Non-PC variables from ADJ ( T ) as early as possible using effective conditional independence tests. This is relevant to two is-sues: 1) Selection of an adjacent variable ( X  X  ADJ ( T ) ) that is most likely to be-come the Non-PC variable; 2) Selection of the conditioning set S that can effectively d -separate the adjacent variable X from T . We solve the first issue by choosing the variable that has the minimum relevance with T measured by the p -values (line 4), i.e., X =argmax probability of claiming conditional i ndependence. The selected variable X is the one that has not been visited and has the largest p -value among all un-visited adjacent vari-ables. Notice that we use the known p -values in the previous independence tests where the size of S is 1 smaller than that in the new tests (line 7).
 We solve the second issue by setting a counter function Freq ( Y ) to each variable Y . The function records how often the variable Y (in the conditioning set) d -separates an Non-PC variable from T . We update the counter immediately after an effective test is executed, and order the adjacent variabl es in the descending order of counters (lines 12-13). We generate the conditioning sets SS , each of which has the size cutesize , from ADJ ( T ) using the GenSubSet function (line 5). Since we order ADJ ( T ) variables and generate the subsets in the Banker X  X  sequence, the conditioning set S (  X  SS ) firstly selected will have a large probability of being PC ( T ) or its subset. Consequently, we may detect an Non-PC variable within few tests. Once we identify the Non-PC variable we immediately remove it from ADJ ( T ) (lines 8-9). The reduced ADJ ( T ) avoids to generate a large number of the conditioning sets as well as a big size of the conditioning set in the new tests.

The GenCP C procedure returns the candidate set of T  X  X  parents and children that excludes false negatives. However, it may include possible false positives. For instance, in Fig. 1, the variable M still remains in the output CPC ( T ) because M is d -separated from T only conditioned on the set { R, I } . However, the variable R is removed early since it is independent from T given the empty set. Hence the tests will not condition on both R and I simultaneously. The problem is fixed by checking the symmetric re-lation between T and T  X  X  PC, i.e., T shall be in the PC set of T  X  X  PC variable and vice versa [2,12]. For example, we may find the candidate set of M  X  X  parents and chil-dren CPC ( M ) .If T does not belong to CPC ( M ) we could safely remove M from CPC ( T ) . We present this solution in the procedure Ref CP C .

In the procedure Ref CP C , we start to search the par ent and children set for each variable in CPC ( T ) (line 2). If the candidate PC variable violates the symmetry (e.g., T  X  CPC ( X ) ) it will be removed from CPC ( T ) (line 4). If T  X  CPC ( X ) ,we know that X is a true PC of T and CPC ( X ) may contain T  X  X  spouse candidates. A spouse is not within CPC ( T ) , but shares common children with T . We again use G 2 tests to detect the dependence between the spouse and T , and identify the true spouse set SP ( T ) (lines 7-9). We refine the CPC ( T ) by removing the false positives and retrieving the spouses, and finally return the true MB ( T ) . 3.2 Theoretical Analysis The new algorithm DOS bases the searching s cheme on the state-of-the-art algorithm IPC-MB. It embeds three functions ( Indep , Freq and GenSubSet ) for the improve-ment on both the time and data efficiency. Its correctness stands on the two procedures, namely GenCP C and Ref CP C . The procedure GenCP C removes the Non-PC vari-able X if X is independent of T conditioned on any subset of ADJ ( T )  X  X  X } .On the removal of false positives, the algorithm resorts to a check on the symmetric rela-tion between T and each of T  X  X  PC. The additional check ensures a correct PC set of T . Besides removing the false positives, the procedure Ref CP C adds T  X  X  spouses to complete the MB ( T ) . Its correctness lies in the inference: the spouse Y is not a candi-date of T  X  X  PC, but dependent of T conditioned on common children. We conclude the correctness of the DOS algorithm below. More technical proof is found in [13]. Theorem 3 (Correctness). The Markov blanket MB ( T ) returned by the DOS algo-rithm is correct and complete given two assumptions: 1) the data D are faithful to a BN; and 2) the independence tests are correct.
 The primary complexity of the DOS algorithm is due to the procedure GenCP C in Fig. 2. Similar to the performance evaluation of BN learning algorithms, the complex-ity is measured in the number of conditional independence tests executed [15]. The procedure needs to calculate the independence function Indep ( X, T | S ) for each do-main variable given all subsets of ADJ ( T ) in the worst case. Hence the number of tests is bounded by O ( | U | X  2 | ADJ ( T ) | ) . Our strategy of selecting both the candidate variable X and the conditioning set S will quickly reduce the ADJ ( T ) by removing Non-PC variables and test only the subsets of PC ( T ) in most times. Ideally, we may on the complexity since | PC ( T ) || ADJ ( T ) | in most cases. We evaluate the DOS algorithm performance over triple benchmark networks and com-pare it with the state-of-the-art algorithm IPC-MB. To be best of our knowledge, the IPC-MB is the best algorithm for Markov blanket discovery in the current study. Both algorithms are implemented in Java and the experiments are run on a WindowsXP plat-form with Pentium(R) Dual-core (2.60 GHz) with 2G memory.

We describe the used networks in Table 1. The networks range from 20+ to 50+ variables in the domain and differ in the connectivity measured by both in/out-degree and PC numbers. They provide useful tools in a wide range of practical applications and have been proposed as benchmarks for evaluating both BN and Markov blanket learning algorithms [2]. For each of the networks w e randomly sample data from the probability distribution of these networks. We use both the DOS and IPC-MB algorithms to re-construct Markov blanket of every variable from the data.

We compare the algorithms in terms of sp eed measured by both times and the num-ber of conditional independence (CI) tests executed, and accuracy measured by both precision and recall . P recision is the ratio of true positives in the output (returned by the algorithms) while recall is the ratio of returned true positives in the true MB ( T ) . In addition, we use a combined measure that is the proximity of precision and recall of the algorithm to perfect precision and recall expressed as the Euclidean distance: Distance = the algorithm output is to the true Markov blanket.

For a single experiment on a particular dataset we ran the algorithms using as targets all variables in a network and computed the a verage values for each measurement. For a particular size of dataset we randomly generated 10 sets and measured the average performance of each algorithm. We set  X  = 0.05. Tables 2 reports the experimental re-sults for datasets of different sizes. Each entry in the tables shows average and standard deviation values over 10 datasets of a particul ar size. In the table,  X  X nsts. X  refers to data instances and  X  X lgs. X  to both algorithms. For the speed comparison purpose,  X  # CI tests X  denotes the total number of conditiona l independence tests. Reduction shows the percentage by which the DOS algorithm reduces the times and number of CI tests over the IPC-MB algorithm. For the accuracy comp arison purpose,  X  X mprovement X  refers to the improvement of the DOS algorithm ove r the IPC-MB algorithm in terms of accuracy measurements like precision , recall and distance .
 In the middle part of Table 2, we show th e speed comparison between the DOS and IPC-MB algorithms over four different datasets on three networks. The DOS algorithm executes much faster than the I-PCMB for discovering the Markov blanket. This re-sults from a significant reduction on the required CI tests in the DOS algorithm. As Table 2 shows, the DOS requires average 40% of CI tests less than that done by the IPC-MB. In some case (like ALARM network on 5000 data instances) the reduction is up to 49.94% . The improved time efficiency is mainly due to our ordering strategy that enables the DOS algorithm to quickly spot true negatives and reduce T  X  X  adajcent set thereby avoiding uncessary CI tests.

In the right part of Table 2, we shows the accuracy of both algorithms on discovering the Markov blanket. As expected, both algorithms perform better (smaller distance ) with a larger number of data instances. In most cases, the DOS algorithm has better performance than the IPC-MB algorithms. It has around 8% improvement in terms of the distance measurement compared with the IPC-MB algorithm. The improvement is mainly due to more true positives found in the DOS algorithm (shown by more im-provement on the recall measurement).

More importantly, the DOS demonstrates a larger improvement on the distance over a smaller number of data instances. For the example of Insurance network, the distance improvement is 13.95% over 300 data instances while it is 7.41% over 2000 data in-stances. This implies more reliable CI tests in the DOS algorithm. The significant re-duction of CI tests (shown in Table 2) also indicates improved test reliability for the DOS algorithm. The reliability advantage appears because the DOS algorithm always conditions on the conditioning set of small size by removing as early as possible true negatives. Margaritis and Thrun [7] proposed the first probably correct Markov blanket discovery algorithm -the Grow-Shrink algorithm. As implied by its name, the GS algorithm con-tains two phases: a growing phase and a shrinking phase. It attempts to firstly add po-tential variables into the Markov blanket and then remove false positives in the followed phase. As the GS conducts statistical indepe ndence tests conditioned on the superset of Markov blanket and many false positives may be included in the growing phase, it turns out to be inefficient and cannot be scaled to a large application. However, its soundness makes it a proved subject for future research.

The IAMB [8] was proposed to improve the GS on the time and data efficiency. It orders the set of variables each time when a new variable is included into the Markov blanket in the growing phase. By doing so, the IAMB is able to add fewer false positives the first phase. However the independence tests are still conditioned on the whole (even large) set of Markov blanket, which does not really improve the data efficiency. More-over, the computation of conditional informatio n values for sorting the variables in each iteration is rather expensive in the IAMB. Yaramakala and Margaritis [17] proposed a new heuristic function to determine the independence tests and order the variables. However, as reported, there is no fundamental difference from the IAMB.

Later, several IAMB X  X  variants appeared to improve the IAMB X  X  limit on data ef-ficiency like the Max-Min Parents and Children (MMPC) [10], HITON-PC [11] and so on. Unfortunately, both algorithms (MMPC and HITON-PC) were proved incor-rect [12], but they do introduce a new approach on identifying the Markov blanket. The algorithms find the Markov blanket by searching T  X  X  parents and children first, and then discover T  X  X  spouses. This novel strategy allows independence tests to be conditioned on a subset of T  X  X  neighboring or adjacent nodes ins tead of the whole set of Markov blanket.
 Following the same idea of MMPC and HITON-PC, Pena et. al. [12] proposed the PCMB to conquer the data efficiency problem of the IAMB. More importantly, the PCMB is proved correct in a theoretical way. Recently, Fu and Desmarais [13] pro-posed the IPC-MB that always conducts statistical independence tests conditioned on the minimum set of T  X  X  neighbors, which improves the PCMB on both the time and data efficiency. However, both algorithms need to iterate a large number of subsets of T  X  X  neighboring nodes in most cases and do not update the set of neighboring nodes immediately after a true negative is detect ed. This allows our improvement as presented in this paper. We presented a new algorithm for Markov blanket discovery, called Dynamic Ordering-based Search (DOS). The DOS algorithm orders conditional independence tests through a strategic selection of both the candidate variable and the conditioning set. The selec-tion is achieved by exploiting the known independence tests to order the variables. By doing so, the new algorithm can efficiently remove true negatives so that it avoids un-necessary conditional independence tests and the tests condition on a small set in size. We analyzed the correctness of the DOS algorithm as well as its complexity in terms of the number of conditional independence tests. Our empirical results show that the DOS algorithm performs much faster and more reliably than the state-of-the-art al-gorithm IPC-MB. The reliability advantage is more evident with a small number of data instances. A potential research direction is investigating the utility of our ordering scheme in independence-based algorithms for BN learning.
 The first author acknowledges partial support from National Natural Science Founda-tion of China (No. 60974089 and No. 60975052). Yanping Xiang thanks the support from National Natural Science Foundation of China (No. 60974089).

