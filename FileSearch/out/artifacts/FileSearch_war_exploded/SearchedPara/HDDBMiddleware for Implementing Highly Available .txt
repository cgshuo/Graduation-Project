 Our demo presents HDDB RS , a middle tier offering to clients a highly available distributed database interface using Reed Solomon codes to compute parity data. Parity data is stored in dedicated parity DB backends, is synchronously updated and allows recovering from multiple DB backend unavailability. HDDB RS middle tier is implemented in JAVA using standard technology, and is designed to be interoperable with any database engine that provides a JDBC dr iver and implements X/open XA protocol. H.2.4 [Systems]: Distributed Databases, H.2.2.[Database Management]: Physical Design -Recovery and Restart Management, Performance, De sign, Experimentation. Reed Solomon codes, Distributed databases, High availability. Data unavailability can be very costly; numbers can be checked in the study conducted by the Contingency Planning Research [1]. In 2001, 46% of the companies participating to the study said each hour of downtime would cost up to $50K. Many approaches to build highly available distributed data storage systems have been calculus. The latter approach uses erasure-correcting codes. The simplest codes, e.g. in RAID systems, use XOR calculus for the tolerance of a single site failure. Multiple failures need more complex codes. These can be the binary codes [4] for double or triple failure, or character codes. Examples of character codes are array codes such as the EVENODD code [2], the X-code [3] or Reed Solomon codes. The latter appear at present to be the best to deal with multiple failures [5]. Theoretical proofs demonstrating superiority of erasure resilient systems to replicated systems can be found in [6]. Indeed, the information theoretical minimum storage overhead for k -availability of m data servers is k/m , while it X  X  k  X  m for replicated systems. Solomon codes for distributed DBs over a shared nothing architecture. The two systems that are most closely related to our work are Clustered JDBC and LH* RS . Cecchet et al. designed and implemented a middleware Clustered JDBC , which uses replication [7] . Litwin et al. implemented high availability using Reed Solomon codes for LH* RS : an in-memory distributed data structure [5]. implementation. Section 3 presents performance measurements of the insert, record recovery and fragments X  recovery scenarios. Section 4 presents the demons tration outline. Finally, we conclude and we open new work perspectives. Our system follows a 3-tier architecture: client, middleware and DB backends. The client simp ly submits queries to the middleware. Indeed, parity data management and table fragmentation are transparent to the client. The middleware ensures high availability of dist ributed databases using Reed Solomon erasure codes to compute parity data. Below, Figure 1 illustrates the gross architecture. parity database backends. Where m denotes the data group size and k is the level of availability of the group. The group can survive to the failure of up to k source/parity database backends. The middleware has a multithreaded architecture. In the functions:  X  DB connection Thread(s): (abrev. DBCT), each DBCT is  X  Transaction Owner Thread: (abrev. TOT) each TOT is  X  Query Handler Thread: (abrev. QHT) this thread handles  X  Recovery Thread: (abrev. RT), this thread handles DB group The middleware is coded in JAVA using standard technology to connect, query and update the DB backends. The middleware is designed to be interoperable with any DBMS providing a JDBC driver and implementing X/open XA standard for distributed transaction processing. well as table fragments X  recovery scenario. The source code can be downloaded from [8]. We set data records size to 3KB, and we used GF(2 data. We built a multiplication table for fast Galois Field elements multiplication processing. Each Oracle DB backends runs on a 1.7 GHz clock-rate PCs with 512MB of RAM. The middleware tie r runs on 2.7GHz clock-rate dual core PC with 2GB of RAM. different levels of availability, namely k = 0,1,2. We recorded 67.5ms for k = 0, 140ms for k = 1 and 160ms for k = 2. The time to recover a record of 3KB is in average 130ms. Decoding is negligible and is 0.18ms. 720KBps and two fragments of 15. 04MB at a rate of 690KBps. The demonstration shows the use of HDDB RS middleware for implementing highly available distri buted databases. The focus is to show record insert at s ource DB fragment and subsequent parity update operations at k parity DB fragments and how the middleware recovers from up to k DB backends unavailability. Along the demonstration, we s how the following operations and their respective performance factors: (a) Creation of a k -available horizontally fragmented table. We (b) Recovery of k table fragments, into which we introduce (c) Key search directed to an unavailable fragment and recovery We have implemented and evaluated record insert, record recovery and fragments X  recovery scenarios for a group of four DB backends tolerating up to two DBs failures. The overhead of parity calculus is negligible at the middleware-tier, compared to communication cost. We expect having better performances using in-memory distributed database s and high-speed network for experimentation. [1] Contingency Planning Research, [2] Blaum, M., Brady, J., Bruck, J., Menon J.: EVENODD: An [3] Xu, L., Bruck, J.: Highly Available Distributed Storage [4] Hellerstein, L, Gibson, G.A., Karp, R.M., Katz, R.H., [5] Litwin, W., Moussa, R., Schwarz, T.J.E.: LH* RS -a highly-[6] Weatherspoon, H., Kubiatowicz, J.D.: Erasure Coding vs. [7] Cecchet, E., Marguerite, J., Zwaenepoel, W.: C-JDBC [8] Moussa, R.: HDDB RS , -A middleware for implementing 
