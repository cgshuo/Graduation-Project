 Graph reachability is a fundamental research problem that finds its use in many applications such as geographic navi-gation, bioinformatics, web ontologies and XML databases, etc. Given two vertices, u and v , in a directed graph, a reachability query asks if there is a directed path from u to v . Over the last two decades, many indexing schemes have been proposed to support reachability queries on large graphs. Typically, those schemes based on chain or tree cov-ers work well when the graph is sparse. For dense graphs, they still have fast query time but require large storage for their indices. In contrast, the 2-Hop cover and its vari-ations/extensions produce compact indices even for dense graphs but have slower query time than those chain/tree covers. In this paper, we propose a new indexing scheme, called Path-Hop, which is even more space-efficient than those schemes based on 2-Hop cover and yet has query pro-cessing speed comparable to those chain/tree covers. We conduct extensive experiments to illustrate the effectiven ess of our approach relative to other state-of-the-art methods . H.2.8 [ Database Management ]: Database Applications X  Graph Indexing and Querying ; H.3.1 [ Information Stor-age and Retrieval ]: Content Analysis and Indexing X  In-dexing Methods Algorithms, Design, Performance Graph Indexing, Path-Hop labeling, Reachability Query
The work described in this paper was fully supported by a grant from City University of Hong Kong (Project No.7002371).

There has been a proliferation of graph structured data across a variety of disciplines (e.g. social networks, bioi nfor-matics, geographic information systems) owing to its abili ty to represent complex relations among data objects. Many standard algorithms for processing and querying graphs are becoming inadequate in face of the growing size of the un-derlying graphs in many modern applications. How to ef-ficiently index and query on large graph structured data is becoming a pressing issue.

Among the various fundamental operations on graphs, reachability query has attracted a lot of attention. Given two vertices u and v in a directed graph, the reachability query asks if there exists a directed path from u to v . Reach-ability query is among the core operations in many applica-tions. Thus, efficient processing of reachability queries is critical to the success of these applications.
An XML document is typically modeled as a tree. There are many labeling schemes for trees, such as interval-based labeling and prefix-based labeling, that facilitate the pro -cessing of XML queries. For example, using the interval-based labeling, the ancestors-descendant axis ( X // X ) simp ly corresponds to an interval containment check. However, with the recent widespread use of ID/REFID tags for rep-resenting referenced information among the XML elements, directed graph is gradually replacing tree as the more ap-propriate model for an XML document. More general la-beling/indexing schemes are needed to support queries on a directed graph.

The interest in reachability query is also rekindled by re-cent advances in bioinformatics. Several well-known bioin -[15], make use of directed graphs to model bioinformatic data such as the metabolic pathways, protein interactions and gene regulations, etc. Each vertex in the graphs stands for an entity and the edges among them specify how the en-tities are related. Researchers are interested in finding ou t whether a reactant is indirectly activated or regulated by another gene, etc. and reachability queries are frequently invoked.

Reachability query is also used in the field of semantic web where two key standards, the RDF (Resource Descrip-tion Framework) and OWL (Ontology Web Language), are proposed with the aim of representing graph structured data efficiently and intuitively. Reasoning on such ontology can be formulated as reachability queries.
Let G = ( V, E ) be the input graph. Denote by n and m , the number of vertices and edges in G respectively. We define the edge density (or simply density ) of graph G as the ratio of the number of edges to number of vertices, m/n .
Since vertices in the same strongly connected component (SCC) are mutually reachable, they have identical reachabi l-ity information. Therefore, it suffices to solve the reachabi l-ity problem on the directed acyclic graph (DAG) obtained by collapsing each SCC into a single representative vertex. This takes only O ( n + m ) time using the algorithm of Paige and Tarjan [10]. Hence in the sequel, we assume that our input graph G is a DAG unless otherwise stated.

To facilitate our discussion, we call a pair of vertices ( u, v ) a reachable pair if there is a path from u to v . We denote by m  X  , the size of the transitive closure of G . That is, m is the number of reachable pairs in G .

Given two vertices u and v in the graph G , one can per-form a standard depth-first search (DFS) or breadth-first search (BFS) to test if u can reach v . In the worst case, this requires O ( m ) time, which is unacceptable when the graph is large. Another naive method is to precompute and store the transitive closure of the whole graph. Then a query in-volves only a single lookup in the closure and takes O (1) time. However the storage requirement is prohibitive, tak-ing O ( n 2 ) bits of space if we store the closure in a binary matrix, or O ( m  X  ) space if some form of adjacency lists is used. (Note that m  X  , the size of transitive closure, is  X ( n 2 ) in the worst case). Over the years, various indexing schemes have been developed that try to strike a balance between the index size and the query processing time. They roughly fall into two categories, namely, the Chain/Tree Cover Approach and 2-Hop Cover Approach.
 In this approach, a subgraph H with simple structure is ex-tracted from the input graph G so that reachability with respect to H can be represented compactly and checked quickly. Usually H is a cover (i.e., includes all vertices) of G .
 Jagadish [6] pioneered the chain cover approach in which H is a collection of pairwise disjoint chains covering G , i.e., H is a chain decomposition of G . Each vertex is labeled with a chain ID and a sequence number on its chain. Clearly, reachability between vertices within the same chain can be checked easily by comparing their sequence numbers. Fur-thermore, reachability between vertices on different chain s can also be compressed: For each vertex u and chain C , if u can reach some vertices in C , we just need to store the earliest such vertex, say v . It is clear that u can also reach all vertices that follow v on chain C . If k is the number of chains in the decomposition, this approach will have a worst case index size of O ( nk ) and query time 3 of O (log k ). Jagadish [6] designed an O ( n 3 ) algorithm that computes an optimal chain decomposition (i.e., one that minimizes k ) and proposed several more efficient heuristics for finding a good chain decomposition. 3 The query time can be improved to O (1) if we assume a computation model that supports hashing.

Agarwal et al. [1] formally introduced the tree cover ap-proach in which H is a spanning tree (also called tree cover) of G : A spanning tree (or forest) of G is computed and the vertices are labeled with an interval labeling scheme. This scheme allows us to determine if a vertex is a tree ancestor of another using their labels only. Thus, reachability inform a-tion within the spanning tree is captured succinctly by the interval labels. For the remaining reachability informati on, we just need to store with each vertex u , the roots of the subtrees reachable by u . (Note that if u can reach a root r , u can also reach any vertex in the subtree of r ). Agarwal et al. designed an algorithm to extract an optimal tree cover of G , i.e., a spanning tree of G that minimizes the total number of reachable subtree roots.

Wang et al. [14] proposed the Dual Labeling scheme which extracts a spanning tree from the input graph G and com-presses the closure information among the remaining non-tree edges using the so called TLC matrix. The query pro-cessing complexity is O (1) and the index size is O ( n + t 2 ) where t = O ( m  X  n ) is the number of non-tree edges. Note that the index size grows quadratically with respect to t and hence the method is not effective for dense graphs.
The Path-Tree Cover proposed by Jin et. al. [7] combines both the tree cover [1] and chain cover [6]. Their indexing scheme computes a chain decomposition of G and collapses each chain into a vertex to form a path-graph, G P . Then a spanning tree T is extracted from G P . This tree T defines a spanning subgraph, H , of G that has richer connections than a spanning tree of G . In particular, a vertex in H can have two parents and multiple children. Finally, the vertic es of G are labeled by an interval labeling scheme (according to T ) and a post-order numbering on H . Due to the richer connection of the spanning subgraph H , a path-tree cover can cover at least as many reachable pairs as a tree cover and a chain cover. However, this scheme is still not very space-efficient when the graph is dense.

There are other indexing schemes, such as Label+SSPI [3] and GRIPP [13], that produce a small index but require online graph searching during a query. Thus, the query time varies from query to query and can be as large as O ( m  X  n ) in the worst case. Cohen et al. [5] introduced the 2-Hop Cover in which each vertex, u , is associated with two sets of vertices, L out and L in ( u ), where L out ( u ) contains certain vertices that u can reach and L in ( u ) contains some vertices that can reach u . The L in  X  X  and L out  X  X  of all the vertices are chosen in a coordinated manner such that for any pair of vertices ( u, v ), u reaches v iff L out ( u ) and L in ( v ) have at least one common vertex, c . This vertex c serves as a  X  X itness X  to the reacha-bility of v from u and breaks down a path from u to v into two hops, the first from u to c and the second from c to v ; hence the name  X 2-Hop cover X . Note that if a vertex serves as witness for many reachable pairs simultaneously, storag e saving is achieved. The index size of the 2-Hop cover is de-fined as P u  X  V | L in ( u ) | + | L out ( u ) | and the minimum index size is conjectured to be O ( nm 1 / 2 ).

The biggest drawback of 2-Hop cover is the large construc-tion time. The problem of finding an optimal 2-Hop cover is equivalent to the set-cover problem, which is NP-hard. Cohen et al. proposed a greedy algorithm that computes a 2-Hop cover with size no more than an optimal one by a multiplicative factor of O (log n ). For large graphs, the construction time is still prohibitive. Several heuristic s were proposed to reduce the construction time. For example, the HOPI indexing scheme of Schenkel et al. [12] employed a divide-and-conquer strategy and reduced the construction time complexity from O ( n 4 ) to O ( n 3 ), which is still slow for large graphs.

Recently, Jin et al. [8] proposed the 3-Hop Cover, which combines the idea of both the chain cover and 2-Hop cover. First, it uses a chain decomposition to reduce the number of reachable pairs that need to be stored. The resultant set, called transitive closure contour (TC contour) is further compressed using a generalized 2-Hop cover technique: In-stead of using single vertices as witnesses for the reachabl e pairs present in the TC contour, it uses sub-chains. More specifically, each vertex u involved in the TC contour is as-sociated with two sets of vertices, L in ( u ) and L out ( u ). The L in  X  X  and L out  X  X  are chosen such that ( u, v ) is present in the TC contour iff there is a vertex x in L out ( u ) and a vertex y in L in ( v ) such that x precedes y on a certain chain. Hence the path from u to v witnessed by the sub-chain from x to y consists of three hops.
The 3-Hop Cover has, by far, the most compact index among those schemes having reasonable query time in prac-tice. Clearly, the chain decomposition has an important effect on the size of the TC contour and hence the size of the final index. For example, if the decomposition consists of many long chains, many reachable pairs (i.e., those along the chains) can be covered. However, we found that the chain decomposition often produces short chains. Specific data will be given in the next section.

In this paper, we explore the use of a spanning tree, in place of a chain decomposition, as the underlying graph structure. We found that a spanning tree can cover more reachable pairs than a chain decomposition. A discussion is given in the next section. We then designed an algorithm for constructing a generalized 2-Hop index and a correspond -ing query algorithm. They are presented in Section 3 and 4 respectively. Finally, our experimental evaluation in Se c-tion 5 shows that our index has even smaller storage the 3-Hop Cover. Moreover, our query processing time and index construction time are comparable to that of the path/chain cover approach; and are also faster than those of the 3-Hop Cover.
In this section, we provide some intuition on our proposed indexing scheme and show experimentally that a spanning tree can cover more reachable pairs than a chain decompo-sition.
We first take a closer look at how a chain decomposition can be used to cover reachable pairs. As mentioned in Sec-tion 1.2, reachability information between vertices on the same chain is captured by the sequence numbers of the ver-tices. For a chain C , with length denoted as | C | , there are | C | ( | C | X  1) / 2 reachable pairs covered in this way. Thus, the longer a chain is, the more reachable pairs are covered.
There are other reachable pairs that can be covered. View-ing a chain C as a highway, a vertex u just needs to remem-
Figure 1: Chain Decomposition and TC Contour ber its entrance to this highway, i.e., the smallest vertex in C that u can reach. This is exactly what is done in [6]. The 3-Hop cover compresses further by considering the reacha-bility information between a pair of highways, C and C  X  . In particular, for a segment of vertices on a chain C  X  that share the same entrance to another chain C , only the last vertex in that segment needs to remember the entrance . This last vertex is an exit of C  X  and the collection of all these exit-entrance pairs in the whole graph forms the TC contour.
For example, consider the chain decomposition in Figure 1(a). The original graph is decomposed into three pairwise disjoint chains, with 3, 3 and 2 vertices respectively. Fig-ure 1(b) shows the transitive closure of the graph in Figure 1(a). Those 1-cells represent the reachable pairs while the unreachable pairs are not shown. The four circled cells cor-respond to the four exit-entrance pairs in the TC contour. Observe that between an arbitrary pair of chains, C and C , there are at most min {| C | , | C  X  |} reachable pairs in the TC contour. For example, there are only two reachable pairs in the TC contour between C 1 and C 2 (refer to the top-middle block corresponding to the transitive closure b e-tween C 1 and C 2 in Figure 1(b)). If there were more than min {| C 1 | , | C 2 |} = 3 reachable pairs, at least one of them would be  X  X ominated X  by some of the others. E.g., in Figure 1(a), the reachable pairs (1, 5) and (2, 6) (i.e., in dotted line) are dominated by the pairs (1, 4) and (3, 6) respec-tively. Therefore, the number of reachable pairs in the TC contour between a pair of chains is linear w.r.t. the length of the chain. However, the number of pairs of chains is quadratic w.r.t. the number of chains. Thus the size of the TC contour can be large if there are many chains.

However, for most of the real data sets we have tested, the chain decomposition produces a large number of chains. For example, the HumanCyc [11] dataset, a bioinformatic database that describes the human metabolic pathways and human genome, has 40051 vertices and 38172 chains after chain decomposition. Eco O157Cyc [9], a database that con-sists of annotated genome sequences of Escherichia coli, ha s 13800 vertices and 12016 chains after chain decomposition.
Moreover, most of the chains decomposed are short. E.g., for the CiteSeer 4 dataset, which is a popular citation database for academic papers, about 50% of chains are single vertices , 87% of chains have a length no more than two. For the organizations, cities, etc.) and the semantic relations am ong them, 87% of chains are single vertices and more than 96% of the chains have a length no more than two.
Now, we turn to the use of a spanning tree in covering reachable pairs. To avoid complicating our discussion with unnecessary details, we assume that a single spanning tree H for G can be obtained. (If more than one tree is needed to cover G , we can add a virtual root with edges to all the roots of the trees and form a single spanning tree.) Also, we assume that H is labeled with an interval labeling scheme.
Given the spanning tree H , we classify edges of G into tree edges and non-tree edges , which are those edges in H and not in H respectively.

Consider an arbitrary vertex u . We also classify the ver-tices that are reachable from u into two types, namely, those in the subtree rooted at u and the others. For vertices of the former type, their reachability from u is captured by the interval labeling. For vertices of the latter type, note that they are grouped into subtrees, T 1 , T 2 , . . . , with roots r , r 2 , . . . respectively. If a vertex v is reachable from u in G , v must be a descendant of either u or one of the r i  X  X . There-fore, it suffices to remember, for each vertex u , those roots r , r 2 , . . . . This is essentially what the optimal tree cover of Agarwal et al. [1] stores. In the following, we give a formal definition to the collection of the corresponding reachable pairs.

Definition 1. Let G be a directed acyclic graph and H be a spanning tree of G . The residual transitive closure of G with respect to H is the set of all reachable pairs ( u, v ) in G where u cannot reach v using only edges in H and u cannot reach any ancestor of v even using edges in G . We denote the residual TC by RT C H ( G ) , or simply RT C ( G ) if H is clear from the context.

Thus, if ( u, v )  X  RT C H ( G ), every path from u to v con-tains at least one non-tree edge.

We illustrate the concept using Figures 1 and 2. First, suppose we form a spanning tree by adding to the chain decomposition in Figure 1(a), the edges (1 , 4) and (5 , 7). The resultant tree is shown in Figure 2(a). In Figure 2(b), we see that there are two reachable pairs (the circled cells) in the residual transitive closure with respect to the spannin g tree.

It is interesting to compare the size of the residual transi-tive closure with that of the TC contour for arbitrary graphs . Unfortunately, a direct comparison with analytical formul ae seems very difficult. Although Agarwal et al. [1] pointed out that their optimal tree cover scheme can cover more reach-able pairs than the optimal chain cover [6], this does not automatically imply that the size of the residual transitiv e closure is no more than that of the TC contour, which is more compact than the chain cover.

Nevertheless, we compute their sizes for a number of data sets and the results are shown in Table 1. For all the data sets, the size of the residual transitive closure is smaller than that of the TC contour. In fact, it is much smaller for most of the cases. Thus, using a spanning tree seems to give a much better starting point than a chain decomposition before we apply a 2-Hop-like technique to compress the re-maining transitive closure information. On the other hand, different algorithms need to be developed due to the change in the underlying graph structure. These will be described in the next two sections.
In this section, we explain our index construction process, which consists of the following steps: (1) constructing the residual transitive closure, and (2) constructing a Path-H op cover for the residual TC. We remark that before executing these algorithms, one could perform a transitive reduction (see [2]) to remove those superfluous edges from G , i.e., those edges whose removal do not affect the transitive closure. In practice, we observe that having this step or not does not have much effect on the final index size. Therefore, we do not elaborate on this.
To compute the residual TC, we apply the multi-interval labeling algorithm in [1] and then perform a certain post-processing.

The algorithm in [1] (shown in Algorithm 1) first computes a spanning tree, H , for G and labels the tree with an interval labeling scheme. Thus, each vertex u is associated with an interval I u so that a vertex u is an ancestor (according to H ) of another vertex v iff interval I u contains interval I v call this interval, I u , the tree interval of vertex u . Then the algorithm processes all vertices in reverse topological or der: At vertex u and for each out-going edge ( u, v ) of u , merge the set of intervals associated with v , including I v , into the current set of intervals associated with u . When merging, any interval contained in another interval is discarded.
After this processing, each vertex u is associated with a tree-interval, I u , and a set of non-tree intervals correspond-ing to the roots of all subtrees reachable by u via at least one non-tree edge. The correctness of this algorithm is proved in [1].

We now extract and represent the residual TC using ad-jacency lists: Each vertex u is assigned a list of successors , Succ ( u ), which corresponds exactly to the set of non-tree in-tervals associated with u . Symmetrically, we also associate with each vertex u a list of predecessors , P red ( u ), which contains all vertices v such that u is in Succ ( v ). Algorithm 1 : Multi-Interval Labeling Input : A Directed Acyclic Graph G Output : A Multi-Interval Labeling of G
Extract an optimal Tree Cover H of G
Traverse H in post-order and assign each vertex u a tree interval label I u foreach vertex u in reverse topological order do end
Note that both the collection of all Succ ( u ) X  X  and the col-lection of all P red ( u ) X  X  represent the residual TC but in different forms. Also, only the vertices with more than one incoming edges in G may have a non-empty list of predeces-sors. On the other hand, a list of successors can only contain vertices having more than one incoming edges. Our Path-Hop cover generalizes the 2-Hop and 3-Hop cover. In a 2-Hop cover, u reaches v iff L out ( u ) and L in ( v ) have a common vertex c . Figure 3(a) shows a reachable pair ( u, v ) covered by a vertex c . In a 3-Hop cover, the witness is a sub-chain in the chain cover. In Figure 3(b), a reachable pair ( u, v ) in the TC contour is covered by the sub-chain from x to y on chain C i : x is stored in L out ( u ) and y is stored in L in ( v ). In our Path-Hop cover, the witness is a path within the spanning tree H : To cover a reachable pair ( u, v ) in the residual TC, we store a vertex x in L out ( u ) and a vertex y in L in ( v ) such that x is an ancestor of y in the spanning tree H . See Figure 3(c). We call the tree path from x to y a Path-Hop and denote it as x ; y .

The formal requirement of our Path-Hop labeling is as follows:
Definition 2. Path-Hop Labeling: Given the residual transitive closure, RT C H ( G ) , of a graph G with respect to a spanning tree H , a Path-Hop labeling assigns two sets L in and L out ( u ) to each vertex u such that 1. for each u , L in ( u ) , L out ( u )  X  V ; 2. for each ( u, v )  X  RT C H ( G ) ,  X  x  X  L out ( u )  X  X  u } and 3. for each ( u, v ) , if  X  x  X  L out ( u )  X  X  u } and y  X  L
We define the size of Path-Hop labels as the total size of all the L in and L out labels: Furthermore, we define the size of Path-Hop index as the sum of the size of Path-Hop labels, the size of the tree inter-val labels, and the size  X  of any auxiliary index for facilitating query processing.

IndexSize ( G ) = The term 2 n in the right-hand side is the size of the tree intervals because each vertex has a tree interval which is defined by two endpoints. The last term  X  will be discussed in the section of query processing (Section 4). Note that after constructing the L in  X  X  and L out  X  X , those Succ () X  X  and P red () X  X , which represent the original residual TC, are no longer needed and can be discarded.

Our problem now is to find a Path-Hop labeling with mini-mum size. Since Path-Hop cover is a generalization of 2-Hop cover, our problem is NP-hard. Therefore, we aim at approx-imation algorithms.
Given RT C ( G ), our problem of finding a Path-Hop la-beling can be re-phrased as the classical set cover problem: Given a ground set U and a set S of subsets of U , where each candidate S  X  S has a weight w ( S ), select a subset C of S of minimum weight to cover U , i.e.,  X  S  X  X  S = U and P
S  X  X  w ( S ) is minimized. A greedy algorithm to find a good cover C is to maintain a set, U  X  , of currently uncovered ele-ments of U and select the candidate S  X  S that maximizes the ratio | S  X  U  X  | /w ( S ). This process is repeated until U empty. It is well-known that the algorithm computes a cover C with weight no more than a ln n factor of the optimal set cover (see [4]).

Consider an arbitrary path-hop x ; y in the spanning tree. Define E ( x ; y ) to be the set of all reachable pairs ( u, v ) in RT C ( G ) such that either 1. u  X  P red ( x )  X  X  x, y } and v  X  Succ ( y ); or 2. u  X  P red ( x ) and v = x .
 Thus, E ( x ; y ) is the set of reachable pairs in RT C ( G )  X  X overed X  by the path-hop x ; y . See Figure 4 for an illus-tration. In (a), x and y are two vertices in G and x reaches y by a path-hop x ; y in the spanning tree. In (b), the hop degenerates into a single vertex c .

Furthermore, for any subset, X , of P red ( x ) and subset, Y , of Succ ( y ), define E ( x ; y, X, Y ) to be the set of reachable pairs ( u, v )  X  E ( x ; y ), where either (1) u  X  X  X  X  x, y } and v  X  Y ; or (2) u  X  X and v = x .

Given an instance of the Path-Hop labeling problem, we construct an instance of the set cover problem as follows. The ground set U is the set of reachable pairs in RT C ( G ). The set S contains the E ( x ; y, X, Y ) X  X  for all path-hops x ; y and all subsets X and Y . Each set E ( x ; y, X, Y ) has weight | X | + | Y | to reflect the cost for the labeling when adding x to the L out of all vertices in X and adding y to the L in of all vertices in Y .
 Our approximation algorithm is as follows (conceptually): It maintains, R , the set of reachable pairs in RT C ( G ) that are not covered yet. Initially, R = RT C ( G ). Then in each iteration, the algorithm finds a candidate E ( x ; y, X, Y ) with the highest density, which is defined as:
The greedy algorithm removes the selected candidate from the candidate set after updating the corresponding L in  X  X  and L out  X  X . It also updates R by marking those reachable pairs in E ( x ; y, X, Y ) as covered. The algorithm iterates this processing until all entries in R are marked as covered.
The above algorithm guarantees that the final labeling is no worse than the optimal Path-Hop labeling by a factor of ln( | RT C ( G ) | ) + 1. However, the practical problem is that there are exponentially many possible X  X  X  and Y  X  X . To make the construction time smaller, one can run a linear time algorithm that selects a candidate with density at least hal f of the maximum one.

This is still slow, however. Therefore, we propose to con-sider a simplified problem and use a simplified greedy algo-rithm which produces similarly compact labels. The sim-plified problem is the same as the original problem except that the set S of candidates consists of only E ( x ; y ) X  X  for all path-hops x ; y . The simplified algorithm selects the candidate hop by the following formula:
In other words, the algorithm simply calculates the den-sity of the whole E ( x ; y ), instead of considering all possi-ble X  X  X  and Y  X  X . Our experiments show that the simplified algorithm runs much faster and surprisingly, produces even smaller index. We conjecture that it is due to the  X  single edge connection  X  phenomenon, which will be discussed in the experimental study section.

The pseudo-code for Path-Hop labeling is outlined in Al-gorithm 2. The algorithm starts by extracting a tree cover H , labeling it with Agarwal X  X  algorithm [1] (line 1) and then extracting the residual TC as Succ () X  X  and P red () X  X  (line 2). These have been explained in Section 3.1.

In each iteration of the while-loop (line 5  X  16), our al-gorithm selects the path-hop x ; y that delivers the best ratio among all candidate path-hops, according to Equation (4). Then R is updated accordingly after each path-hop is selected (line 15).

After that, we add x to the appropriate L out  X  X  and y to the appropriate L in  X  X . Note that our algorithm will check for the presence of any redundancy.
 Algorithm 2 : Path-Hop Labeling Input : A DAG G Output : Path-Hop Labels of G
Apply Algorithm 1 to extract a tree cover H of G and assign multi-interval labels to vertices in G
Construct RT C ( G )
R  X  RT C ( G )
Construct Succ ( v i ) and P red ( v i ) where i = 1 , 2 , 3 ...n while R is not empty do end Algorithm 3 : Densest-Hop() Input : Succ ( v i ) , P red ( v i ) , i = 1 , 2 , 3 , ...n
Output : Densest Hop foreach v i with non-empty P red ( v i ) where i = 1 , 2 , 3 , ...n do end foreach v i with non-empty Succ ( v i ) where i = 1 , 2 , 3 , ...n do end return the hop from { s max , p max , d max } with the largest density
Consider Figure 5(a). If L in ( u ) contains two elements a and b where a is a tree ancestor of b , then we say a is redundant since the reachability from a to u is dominated by the reachability from a to b and from b to u . Keeping b only in L in ( u ) is sufficient and complete.

The symmetric case shown in Figure 5(b), however, will not happen. The pair ( v, f ) cannot be in the residual tran-sitive closure since the tree interval of f is already contained in the tree interval of e . Thus f will not be propagated to node v . See line 3  X  14 in Algorithm 2. In the previous sections, we show how to construct the Path-Hop labels based on the residual transitive closure. After the index construction phase, each vertex u will be assigned (1) a tree interval, I u , which tells the reachabil-ity within the spanning tree H , and (2) L out ( u ) and L which compactly encode the reachability information in the residual transitive closure RT C ( G ). Note that, some of the L out  X  X  and L in  X  X  may be empty.

In this section, we present an algorithm that efficiently processes reachability queries using the above index. Give n two vertices u and v , we first use the tree interval labels to check whether u reaches v by only traversing edges in the tree cover H . This only involves checking if I u contains I . If so, the query returns true successfully. Otherwise, we further check if the RT C ( G ) contains reachable pair ( u, v ). This involves checking the L out and L in labels.

To understand this part of the query processing, let us recall the query procedure when the original residual TC information is available, say in the form of Succ ( u ) for all u in G . Suppose we are to check whether u can reach v and we know that I u does not contain I v . Then if v is reachable from u , v must lie in one of the subtrees reachable from u via at least one non-tree edge. Hence we just check, for each z in Succ ( u ), whether I v is contained in I z . Now, we do not have the Succ () X  X  and P red () X  X  but only L in  X  X  and L out  X  X . By construction of the Path-Hop labels (Definition 2, to be specific), we can recover the residual TC information in the following sense: Given a vertex z in Succ ( u ), i.e., ( u, z )  X  RT C ( G ), we can find an x in L { u } and a y in L in ( z )  X  X  z } such that I y  X  I x (according to condition (2) of Definition 2). Thus, if v is reachable from u but I v is not contained in I u , v must be a descendant of some vertex z in Succ ( u ). In other words, v must have an ancestor z such that there is some x in L out ( u )  X  X  u } and some y in L in ( z )  X  X  z } satisfying I y  X  I x . The query procedure is outlined in Algorithm 4.

Note that we actually need not consider choosing y = z for any proper tree-ancestor, z , of v (line 6): Suppose z is a proper tree-ancestor of v and there is an x in L out ( u ) and y = z such that I y  X  I x . We claim that x = y = z . Otherwise, x is a proper tree-ancestor of z . By construction of Algorithm 1, I z will be subsumed by I x and hence z will not appear in Succ ( u ). This contradicts the condition that ( u, z )  X  RT C ( G ) and the claim follows. Now, we can conclude that there is some x = z in L out ( u )  X  X  u } and y = v in L in such that I y  X  I x .

To summarize, to check if u can reach v given that I u does not contain I v , we retrieve all the ancestors of v . Denote by Anc v , the set of ancestors of v in the tree cover H . Then we check if there exists x in L out ( u )  X  X  u } and y in L in some z in Anc v such that I y  X  I x .

Note that in line 4 of Algorithm 4 reach ( u, v ), we need to retrieve the ancestors of v and collect the corresponding L in  X  X . To speed up the process, we notice that if L in ( z ) is empty for some ancestor z , of v , we need not process the vertex z . Therefore, we assign each vertex a back tracing pointer which points to its lowest ancestor z where L in ( z ) is non-empty. When processing a query on ( u, v ), we start from v , traverse along the ancestry path upwards towards the root by following this pointer and collect the elements in L in each vertex z we encounter. These back tracing pointers will introduce an additional term of n in the index size, which corresponds to the  X  in equation 4. We will show in the next section that this construction strikes a good balance between the index size and the query processing time and both performance measures are superior to 3-Hop cover. Algorithm 4 : reach(u, v) Input : Two query vertices u, v
Output : True/False (Reachable/Unreachable) if I v  X  I u then end
Anc v  X  the set of ancestors of v in H
Out u  X  X  u } X  L out ( u ) foreach x  X  Out u do end return false In this section, we perform empirical evaluation of our Path-Hop indexing scheme. We compare our approach with other state-of-the-art techniques from representative in dex-ing families mentioned in Section 1.2. Specifically, we com-pare our approach with the (1) Dual-II labeling scheme pro-posed in [14], denoted as Dual II ; (2) Path-Tree I scheme proposed in [7], denoted as PTree I ; and (3) 3-Hop Contour scheme proposed in [8], denoted as 3-Hop Contour .
The Dual labeling approach is from the tree cover family and it improves upon the optimal tree cover of Agarwal et al. by compressing the left-over edges not covered by the spanning tree. It has two variants, Dual I and Dual II re-spectively. Dual II is more space-efficient while Dual I is faster in processing queries. Since our major objective is t o reduce the index size, we compare with Dual II only.
The Path-Tree approach combines the tree cover tech-nique and the chain cover technique together. The index size is generally smaller than the original tree cover appro ach and chain cover approach while still maintaining a very fast query processing speed.
 The 3-Hop approach combines the chain cover and the 2-Hop technique. It has smaller index size as well as faster query processing compared with 2-Hop.

We implemented our Path-Hop indexing algorithm in C++ The experiments are conducted on an Intel 3.4GHz x86 ma-chine, with 2GB main memory. The machine is running Open Solaris (release 2009.06) and using GCC compiler (ver-sion 3.4.3).

To provide a fair comparison, the data sets used in our ex-periments are all obtained from the 3-Hop and the PathTree which has 2000 vertices and edge densities (i.e. | E | / | V | ) varying from 8 to 12, and an XML document generated by the XMark tool. The real life data sets are extracted from some large projects including Citeseer which contains aca-demic publication citations, Go which contains genetic en-tities and their relations, PubMed which contains citations for biomedical literatures and Yago which contains various entities (like persons, organizations, cities, etc.) and t he semantic relations among them. Table 2 shows some char-acteristics of the data sets. The index sizes of various approaches are presented in Table 3. For Path-Hop, each vertex receives an interval (2 integers) and a back tracing pointer. Therefore, the index size of Path-Hop scheme is defined as: the total number of integers in L in and L out , plus the number of integers for interval labels and back tracing pointers . Note that here  X  = n .

IndexSize ( G ) =
For the 3-Hop approach, each vertex receives a chain ID and a sequence ID (i.e., 2 n ). During query processing, 3-Hop 7 Available at http://www.cs.kent.edu/  X  nruan/soft.html Data Set Dual II PTree I 3-Hop rand2k 8 781458 88968 32811 30529 rand2k 10 978782 82161 33535 30246 rand2k 12 1119310 75809 33440 28897 Xmark 12278 21805 27241 19187 Citeseer 313618 91820 61755 54207 Go 47180 37729 34557 26823 PubMed 393540 107915 63531 52997 Yago 52093 39181 33680 32984 cover needs to collect the L out labels along the chain in which the source vertex u resides and collect the L in labels along the chain in which the destination vertex v resides. To speed up the query, each chain is stored explicitly (using storage n ) so that one can traverse a chain and retrieve its vertices in order of their sequence IDs efficiently. Therefore, the index size of 3-Hop approach is defined as: the total number of in-tegers in L in and L out , plus 3 n . Jin. et al. [8] proposed two versions of the 3-Hop scheme, the 3-Hop Segment and the 3-Hop Contour. As indicated by the experiments conducted by Jin. et al., 3-Hop Contour has better performance among the two, in terms of index size and query processing time. Therefore, we compare our results with 3-Hop Contour only.
For the Path-Tree approach, the index size is defined as the size of transitive closure not covered by Path-Tree plus 3 n (refer to [7]). For the Dual II approach, the index size is defined as the number of TLC search tree entries (refer to [14]).

It can be observed from Table 3 that for almost all data sets, synthetic and real, Path-Hop approach achieves the smallest index size among all indexing schemes. There is only one data set, namely, Xmark, in which Dual II has a smaller index size than Path-Hop. This is because Dual II is particularly suitable for very sparse graphs like XMark (XMark has edge density of 1.144).
In this experiment, we generate 100,000 random reachabil-ity queries for each indexing scheme and measure the time (in milliseconds) used for answering the queries. Figure 6 shows the processing time for 100,000 random queries.
We observe that the query processing speed of the pro-posed approach is comparable with the Path-Tree I approach. The time used for answering 100,000 queries are in the same order for the real life graphs. However, Path-Tree I has a much larger index (as indicated in Table 3) although its query processing speed is fast.

For Dual II, we do not plot it on the figure since its query processing is too slow and it is several order of magnitude slower than the proposed Path-Hop approach.

When compared with the 3-Hop approach, Path-Hop is much faster in answering queries. Notice that for all syn-thetic graph or real graph data sets, Path-Hop persistently answers queries faster than 3-Hop. On average, Path-Hop is about 3 times faster than 3-Hop in our experiments.
To understand why Path-Hop answers queries faster than the 3-Hop approach, we analyze the major operations in-volved in processing a query and show why the proposed ap-proach is faster than 3-Hop Contour. Recall that in 3-Hop,
Figure 6: Processing Time for 100,000 Queries the major operations involved in answering a single query u  X  v include: (1) collect the L out labels into Out u while traversing the chain in which the source vertex u resides, and (2) collect the L in labels into In v while traversing the chain in which the destination vertex v resides, and (3) check if there is any combination of vertices ( x, y ) where x  X  Out and y  X  In v such that x and y reside on the same chain and x precedes y (i.e. x. chainID = y. chainID and x. sequenceID  X  y. sequenceID). Note that the last step which examines the chain ID and sequence ID of each combination is very fast since only the most primitive arithmetic computation is involved. From our experiments, the last step takes less than 1/3 of the total processing time on average. The first and second steps have dominant effect in deciding the query processing speed since they involve traversing the backbon e structure (i.e. chains), which is expensive.

Similarly, Path-Hop scheme also involves 3 steps in pro-cessing a query u  X  v : (1) collect the L out label of the source vertex u into Out u , and (2) collect the L in labels of the tree ancestors of the destination vertex v , into In v (3) check if there is any combination of vertices ( x, y ) where x  X  Out u and y  X  In v , such that x is y  X  s tree ancestor (i.e., I  X  I x ). Note that the third step is computationally equiv-alent with that of 3-Hop in that checking a tree ancestor means a containment checking, which merely involves the most primitive operations.
 The main difference between the query algorithms of 3-Hop and Path-Hop is that Path-Hop only traverses the back-bone tree on the destination vertex side (i.e. v ) while the 3-Hop approach needs to traverse on both the source and destination vertex sides (i.e. u and v ). Since traversing the backbone structure is expensive, the amount of traver-sal could have a significant impact on the speed of query processing. We quantify the amount of traversal occurred during processing a query by the number of vertices we need to visit. That is, in 3-Hop, we count the number of visited vertices along the chains in which u and v reside. Similarly, in Path-Hop, we count the number of visited vertices which are tree ancestors of v and have non-empty L in labels. To measure how many vertices we need to traverse in 100,000 random queries, we simply sum them up.

Table 4 shows the measured number of vertices visited in 100,000 random queries for 3-Hop and Path-Hop approaches in one experiment. It is easy to see that Path-Hop X  X  query al-gorithm visits significantly fewer vertices, especially fo r real life graphs. This indicates that the proposed algorithm can
Data Set 3-Hop Contour Path-Hop Improvement rand2k 8 950896 622572 52.7% rand2k 10 1082507 911667 18.7% rand2k 12 1195411 1062016 12.5% Xmark 319570 193175 65.4% Citeseer 389805 48237 708.1% Go 372807 108282 244.3% PubMed 321981 31456 923.6% Yago 249069 5620 4331.2% Table 4: Number of Vertices Traversed in 100,000 Queries process queries faster by reducing the backbone traversal, which is expensive as evidenced in our experiments.
In this subsection, we study the construction time of our proposed indexing scheme. Figure 7 shows the time used for constructing the reachability index using different scheme s. Approaches from the tree/chain cover family, i.e. Dual II and Path-Tree I, generally have much faster construction speed than the approach from the 2-Hop family, i.e. 3-Hop. On the other hand, the construction speed of Path-Hop is usually faster than that of 3-Hop. This is due to our simpli-fied labeling algorithm. As illustrated in by Equation 4, our schemes start from a smaller residual TC and only calculates the density of the whole E ( x ; y ) instead of considering all possible subsets of E ( x ; y ) while choosing the hop.
Recall that in ref. [5] Cohen et al. suggested that choos-ing the densest hop is equivalent to choosing the densest subgraph in a certain bipartite graph.

However, an interesting phenomenon we discovered in our experiments is that choosing the best (densest) subgraph does not always produce the most compact index. We have tested two variants of our labeling algorithm, one employs the heuristic described by Equation 3 (variant 1) while the other uses the heuristic describe by Equation 4 (variant 2). We found that variant 2 produces a slightly smaller index than variant 1. To understand this, we insert a plug-in to our implementation which calculates the overall compressi on ratio after each hop is selected. The compression ratio is defined as the size of residual transitive closure covered so far divided by the size of labels produced :
With such a plug-in, we are able to monitor how the over-all compression ratio evolves as more and more hops are selected. Figure 8 shows the curves about how the overall compression ratio changes over time for variant 1 (i.e. Equa -tion 3) and variant 2 (i.e. Equation 4) using the PubMed data set. Variant 1 does a better job at the beginning stage and produces a higher compression ratio. However, it also leaves behind a lot of single edge connections where the con-nection does not pass through any intermediate vertex be-tween the two query vertices u and v . With such single edge connections, no compression could be made and the overall compression ratio is brought down. For example, variant 1 achieves an overall compression ratio of 4.88 before the algorithm starts to cover the remaining 28127 single edge connections while variant 2 achieves an overall compressio n ratio of 4.12 before starting to cover the remaining 16698 si n-gle edge connections. Variant 1 has significantly more singl e edge connections that need to be taken care of. When the algorithm finishes, variant 2 instead achieves a larger over all compression ratio and produces a smaller index. Thus being  X  X oo greedy X  at the beginning does not necessarily achieve the overall best. For the other data sets, we observed simila r trend. Due to space limitation, we do not show all of the experimental results here.
Graph reachability query is an important research prob-lem and much attention is devoted to it in recent years. In this paper, we propose a space-efficient indexing scheme, re-ferred to as Path-Hop, which has even smaller index than the 2-Hop based techniques while maintaining a comparable query speed with the chain/tree based methods. Experi-ments show that our indexing scheme produces smaller in-dex and processes reachability queries faster than 3-Hop ap -proach due to much less traversal on the backbone structure. The speed is also very close to that of Path-Tree for many real life graphs we have tested. In the future, we would like to investigate into the single edge connection phenomenon presented in section 5.4. Whether one can further compress those single edge connections still remains an open problem .
We would like to thank Haixun Wang for providing the implementations of their Dual labeling paper. [1] R. Agarwal, A. Borgida, and H.V. Jagadish. Efficient [2] A. Aho, M. Garey, and J. Ullman. The transitive [3] L. Chen, A. Gupta, and M.E. Kurul. Stack-based [4] V. Chvatal. A greedy heuristic for the set-covering [5] E. Cohen, E. Halperin, H. Kaplan, and U. Zwick. [6] H.V. Jagadish. A compression technique to materialize [7] R. Jin, Y. Xiang, N. Ruan, and H. Wang. Efficiently [8] R. Jin, Y. Xiang, N. Ruan, and D. Fuhry. 3-HOP: a [9] I.M. Keseler, J. Collado-Vides, S. Gama-Castro, [10] R. Paige and R. Tarjan. Three partition refinement [11] P. Romero, J. Wagg, M.L. Green, D. Kaiser, [12] R. Schenkel, A. Theobald, and G. Weikum. HOPI: an [13] S. Tri X l and L. Leser. Fast and practical indexing and [14] H. Wang, H. He, J. Yang, P.S. Yu, and J.X. Yu. Dual [15] E. Zimanyi and S. Gabouje. Semantic visualization of
