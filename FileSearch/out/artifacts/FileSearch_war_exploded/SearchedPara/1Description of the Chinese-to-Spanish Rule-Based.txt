 Chinese and Spanish are two of the most widely spoken languages in the world and they are gaining importance in today X  X  information society. For example, in the ranking of usage of content languages for websites, Spanish is in the fourth position and Chinese ranks fifth [Q-SuccessConsulting 2013].

Although communication between the two communities is challenging on both cultural and linguistic levels, there are many shared economic interests. China X  X  trade with Latin America grew in 2011, with the top five nations involved being Brazil, Mexico, Chile, Venezuela, and Argentina [IndoAsianNews 2013]. In this sense, Machine Translation (MT) between the two languages is of clear interest for compa-nies, tourists, students, and politicians. Even though the necessity is obvious, there are not many Chinese-to-Spanish MT systems available on the Internet. Systems available in Google Translate and Bing are corpus based, and these seem to produce transla-tions through English pivoting to compensate for the lack of Chinese X  X panish parallel corpora.

When it comes to academic research, there have not been many studies on this language pair; the studies are mainly reviewed in Costa-juss ` a et al. [2012] and Bertoldi et al. [2008], and they also rely on the pivoting procedure. Results of such approaches do not improve the direct system (for the same quantity of data) unless there is a combination of pivot systems. The main drawback of the combination is that the final system is not efficient. Therefore, corpus-based approaches have been applied to this language pair, but results are not comparable to other language pairs (such as English X  Spanish) because of the limited data available. Furthermore, the linguistic differences (mainly at the morphological level) between these two languages make the training of data-driven systems rather difficult. In fact, Chinese and Spanish are languages with multiple linguistic differences.
At the morphological level, Chinese is an analytical (or  X  X solating X ) language, which means that it shows a low ratio of morphemes to words; in fact, the correspondence is nearly one to one. Spanish, on the other hand, is a fusional language, meaning that morphemes (at least one independent morpheme per word) are mixed together in words with no clear limits.

At the level of syntax, Chinese and Spanish tend to follow the Subject-Verb-Object pattern and, theoretically, there are not as many long reorderings as would be expected for language pairs such as Japanese X  X panish. As stated in Cuza et al. [2013], the Chinese X  X panish contrast is particularly evident in anaphorical elements and the nominal domain. For example, the Spanish clitic/null object alternation is regulated by features of definiteness and specificity. In contrast, Chinese is a radical pro-drop, topic-oriented language that does not productively use pronouns and does not mark for definiteness and specificity in the nominal system, and null objects are identified by linking to discourse antecedents. Therefore, moving from Chinese to Spanish may depend more on the abstract meaning of the text than on the words and structure within it. Additionally, Chinese is a language with a massive number of homonyms at the lexical and morphemic level [Zhang et al. 2006], making the lexical semantic disambiguation toward Spanish even harder. We have shown that there is a need for translation between Chinese and Spanish (mo-tivated by the global market). We have also mentioned that there are no reliable MT systems that can help communication between different parties and that translating from Chinese to Spanish is challenging due to the linguistic differences. Given this situation, we decided to build a Chinese-to-Spanish Rule-Based Machine Translation (RBMT) system. This type of system provides a translation based on linguistic knowl-edge, in contrast to the existing and popular corpus-based approaches. The translation process is divided into analysis, transfer, and generation. Analysis and generation mainly cover the morphological variation of the languages, while the transfer phase is in charge of the syntactic aspects [Hutchins and Sommers 1992]. The main advantages of RBMT systems are that errors are traceable to the corresponding linguistic rules.
Our linguistic motivations for constructing a Chinese-to-Spanish RBMT are as follows: (1) The proposed system can directly tackle the differences in morphology between (2) Reordering from Chinese and Spanish can benefit from the use of manually poste-(3) The RBMT approach is able to exploit the use of linguistic tools that are separately
The main drawbacks of an RBMT system are that it requires a lot of human dedica-tion and years of development [Costa-Juss ` a et al. 2012] and that this type of system exhibits weaknesses in lexical selection, something that is quite relevant for this lan-guage pair. To overcome these drawbacks, we used the Apertium platform [Forcada et al. 2011], which makes the process of constructing an RBMT system easier. More-over, when applying the proposed RBMT approach, we used automatic techniques at different stages of analysis, generation, and lexical and structural transfer to feed the system from parallel corpora. This article describes how the Chinese-to-Spanish RBMT system has been devel-oped under the Apertium open-source platform. The integration was undertaken using the General Public License (GPU) tools available for the analysis and gener-ation steps of the languages at hand. Monolingual and bilingual dictionaries have been created combining human effort together with statistical lexical extraction from parallel corpora. For the transfer phase, rules have been automatically generated from a parallel corpus using recently developed algorithms [S  X  anchez-Mart  X   X nez and Forcada 2009a]. These rules have been experimentally validated. This new freely available online language pair is the first RBMT approach developed for Chinese to Spanish.

The rest of the article is organized as follows. Section 2 presents a detailed de-scription of the Chinese-to-Spanish RBMT architecture including the procedure of compiling monolingual and bilingual dictionary procedures as well as the inference of lexical and structural transfer rules. Section 3 provides a complete evaluation of the system including a comparison with a standard Statistical Machine Trans-lation (SMT) system. Finally, Section 4 discusses the results and draws the final conclusions. The general architecture of an RBMT system has been defined previously [Hutchins and Sommers 1992; Forcada et al. 2011]. However, in most cases, RBMTs have been developed by private companies. Therefore, the inner workings, strategies, and func-tioning of RBMTs have not been revealed because the private companies commercialize licenses to closed-source systems.

In this section, we describe in detail how we have developed our RBMT system using the Apertium platform [Forcada et al. 2011] and following similar procedures to those used in previous studies [Cort  X  es et al. 2012]. Novel aspects of our work include (1) a particularly challenging language pair with few bilingual speakers capable of developing the resources required to compile the target system and (2) combining statistical techniques with human annotation.
 Figure 1 shows the representative block diagram modules of the RBMT system.
Human annotation was supported by two bilingual English-Spanish annotators and one trilingual Chinese-English-Spanish annotator, who was in charge of checking each step.
 The system is based on the Apertium platform [Forcada et al. 2011], which is a free/open-source platform for shallow transfer MT. As well as the platform, the lin-guistic data for the MT systems are also available under the terms of the GNU-GPL.
The platform was originally designed for the Romance languages of Spain, so the targeted language pair deviates from the original objectives. However, in practice, statistical techniques were used to build our system, and we have not changed its architecture.

Development to date has consisted of  X  X eeding monolingual and bilingual dictionaries, to extend coverage, with statistical methods;  X  X eeding monolingual and bilingual dictionaries, to extend coverage, with human annotation;  X  X iltering and cleaning monolingual and bilingual dictionaries to make them consistent;  X  X omputing lexical selection rules by automatically extracting them from parallel corpora; and  X  X omputing structural transfer rules by combining manual and automatic procedures.
Coverage (i.e., the percentage of translated words versus the total number of words used) is defined as the primary measure to evaluate the system.

This first development track took place over the course of just 6 months, in contrast to the length of time required to develop classical RBMT systems. Most of the effort (around 80%) revolved around feeding the monolingual and bilingual dictionaries with human annotation. The key point here is that our system has been developed using a hybrid approach. Although the system achieves competitive results in terms of cov-erage, it is still under construction. The latest version of the system is available for downloading at the Apertium development site. 1 The bilingual dictionary was computed and principally constructed following two dif-ferent methods.

The first involves the Yellow Bridge resource. 2 This website, as mentioned by the authors, is the premier guide to Chinese language and culture for English speakers and provides comprehensive tools for learning the Chinese language. In particular, it gives a list of Chinese words classified following grammatical categories (i.e., adjectives, adverbs, conjunctions, interjections, measure words, nouns, numerals, onomatopoeia, particles, prefixes, prepositions, pronouns, question words, suffixes, time words, and different types of verbs). For each category, the words have corresponding translations into English. Our work consisted of translating English into Spanish and this was done by an English-Spanish expert. To double-check the translations provided, each word was translated using another online dictionary 3 and Google Translate. After this, the bilingual Chinese X  X panish entries were added to the bilingual dictionary. This procedure allowed several hundreds of numerals, conjunctions, adverbs, pronouns, determinants, adjectives, 3,000 nouns, and 2,000 verbs to be added.
 The second procedure is statistical. The parallel corpus of the United Nations General Assembly Resolutions (UN) [Rafalovitch and Dale 2009] was aligned at the word level by using the standard GIZA++ [Och and Ney 2003] software. Alignment was performed from source to target and target to source. Symmetrization was done using intersection because this is expected to provide the most reliable links. Then we extracted phrases of length one, meaning that we extracted translation from word to word. The dictionary was manually filtered to eliminate incorrect entries. This procedure allowed around 3,500 words to be added to the dictionaries. As a result of the two procedures, the bilingual dictionary now contains approximately 9,000 words. The Chinese monolingual dictionary was extracted from the source part of the bilin-gual dictionary. Additionally, it was filtered with regular expressions to avoid repeated entries.

From a morphological point of view, as mentioned earlier, Chinese is an isolating language. In practice, this means that words (or symbols) cannot be segmented in submorphemes. In this sense, no morphological analysis is required. However, the main challenge of Chinese at this level is that most of the time symbols appear concatenated and sentences are not segmented into words as is typical in other languages. Therefore, Chinese must be segmented. We considered using popular tools, such as the Stanford Segmenter [Chang et al. 2008], but this is written in Java, so it was difficult to integrate into Apertium. For this reason, we used the ZhSeg 4 programmed in C++. We evaluated the performance of this segmenter in comparison to the left-to-right longest-match (LRLM) strategy, which is the parsing strategy used by Apertium in analysis mode. This procedure reads tokens from left to right, matching the longest sequence that is in the dictionary (like  X  X reedy X  matching of regular expressions). Both ZhSeg and LRLM were compared using a manually constructed segmented test set of 456 words as a reference. The Word Error Rate (WER) measured [McCowan et al. 2004] for the ZhSeg was 16.56% and was 16.89% for LRLM. Given that results were comparable, we decided to use the Apertium morphological analyzer, which applies the LRLM strategy. All finite-state tools in Apertium use the LRLM strategy.
It is mandatory that the monolingual and bilingual dictionaries are coherent, mean-ing that they should have the same entries. Both dictionaries were cleaned up with different regular expressions. It is therefore necessary to ensure that there are no situ-ations where a word appears in the monolingual dictionary that is not in the bilingual dictionary, and vice versa. In order to check this out, we used a testvoc. As mentioned in the Apertium documentation, 5 a testvoc is literally a test of vocabulary. At the most basic level, this just expands the monolingual dictionary and runs each possibly ana-lyzed lexical form through all the translation stages to see that for each possible input, a sensible translation is generated in the target language. The generation of Spanish was taken directly from the Apertium repository. Given that this has been developed over several years, examples of earlier publications explaining Spanish generation can be found in Armentano-Oller et al. [2006] and Corb  X   X -Bellot et al. [2005]. Basically, it consists of two Apertium modules: the morphological generator and the postgenerator. The morphological generator delivers a surface (inflected) form for each transferred word and for each lemma and part-of-speech tag it is able to generate the final form. The postgenerator performs orthographic operations such as contractions. Lexical selection is very important in any type of MT system. If the lexical module is not implemented, Apertium deals with translation ambiguity by using multiword ex-pressions encoded in the system X  X  dictionaries as described in previous studies [Brandt et al. 2011]. In most systems, for any given source word, the most frequent or most general translation is presented. Obviously, this is not a desirable situation as it poses a translation problem: in most cases the correct translation depends on the context.
In this work, we used the procedure proposed in Tyers [2013], which tries to learn lexical selection rules directly from a parallel corpus. The procedure is as follows: the source and target corpus are morphologically analyzed. Then, the parallel corpus is aligned at the word level. The source corpus is run through the lexical-transfer stage, which generates three outputs: the source and target tagged corpus and the possible translations of the source words. At the same time, sentence pairs for which at least one lexically ambiguous source word is aligned to a word in the target (also found in the bilingual dictionary) are extracted from the parallel corpus. For each of these extracted sentence pairs, n-grams of context around the ambiguous source word(s), belonging to the categories of adjective, noun, and verb, are extracted. From these n-grams we extract relative frequencies by counting. If a possible given translation appears aligned to a word in a given context more frequently than other possible translations, then a rule is extracted. The rule basically selects the most frequently aligned translation in that same context over other translations. This method enabled 3,400 lexical rules to be extracted. Structural transfer rules were extracted by combining two procedures: manual and statistical.

The manual procedure consisted of translating a source text and contrasting the out-put translation, the source and the reference. From this observation, manual patterns were extracted in order to design a rule that could cover any necessary modifications. Following this procedure, 28 intrasyntagm and 34 intersyntagm rules were extracted. The main difference is that the former rules modify within a syntagm and the latter rules modify between different syntagms. An example of a handwritten rule for the first level is as follows:
This rule reorders adjective + noun into noun + adjective . Moreover, it ensures that the number and gender of the noun and the adjective agree. In order to do the latter, we call the f concord2 macro function. This allows forced agreement in terms of gender and number. Notice that these are first-level rules (t1x), meaning that they work within syntagms.

For a statistical procedure, we can use the example of S  X  anchez-Mart  X   X nez and For-cada [2009b]. This consists of aligning parallel corpora at the word level, extracting alignment templates and applying a set of restrictions derived from the bilingual dic-tionary of the RBMT system. Word alignment is done using standard statistical meth-ods, in particular GIZA++, in the source-to-target and target-to-source direction and symmetrizing using the refined intersection method [Och and Ney 2003]. Alignment templates are extracted as detailed in Och and Ney [2004]. Finally, restrictions are ob-tained from the RBMT system X  X  bilingual dictionary, where the inferred transfer rules are integrated. These restrictions explicitly ensure that the inflection information of the translation that is changed from one language to the other is coded.

A more recent statistical procedure is the extension of the first procedure mentioned earlier [S  X  anchez-Cartagena 2014]. In this case, the study allows more general rules and exploits the information contained in the bilingual phrases to decide, in a context-dependent manner, the level of generalization, that is, the morphological attributes to be removed from the word classes and the lexical words. This approach is the one we have used in this study and which allowed us to extract 100 rules.

Finally, manual and automatic rules are combined together by giving preference to the manual rules. In case no manual rule is applicable, the system uses an automatic rule (when available). This section explains the evaluation framework for analyzing the quality of the de-scribed Chinese-to-Spanish RBMT system. We present the data used for both training statistical techniques and testing. Then, we detail how the baseline SMT system was built. Finally, we report figures for coverage and other relevant MT quality measures. Note that coverage was computed using the available Apertium script. 6 As far as we know, and as discussed in Costa-juss ` a et al. [2012], four parallel corpora are available for the Chinese X  X panish language pair: BTEC (Basic Travel Expression Corpus), the Holy Bible , the KDE (K Desktop Environment, which is available from the OPUS project 7 ), and the UN. The first was used in the 2008 IWSLT, and complete experiments of pivot strategies are reported in works such as Bertoldi et al. [2008]. The Holy Bible was used for similar purposes in Henr  X   X quez et al. [2010]. In this study, we decided to use the UN corpus because it is freely accessible, it uses a more general vocabulary, and it is the largest one.

Table I shows the main statistics for all the corpora used once divided for experimen-tation. Additionally, we had another development corpus called NEWS (extracted from the web 8 , 9 ) for checking the evolution of the RBMT system. This corpus was monolin-gual, which is enough when checking the coverage. Finally, we utilized a small corpus developed in-house for the transportation and hospitality domains. In order to compare our system, we built a standard phrase-based SMT system. The basic idea was to segment the given source sentences s into segments of one or more words, then translate each source segment using a bilingual phrase obtained from the training corpus, and finally, compose the target sentence from these phrase transla-tions. Further description of the theory behind the baseline system can be found in previous works [Koehn et al. 2003].
 Our system was built using revision 4075 of the MOSES system [Koehn et al. 2007]. We used the default MOSES parameters, which include the grow-diagonal-final-and word alignment symmetrization, the lexicalized reordering, relative frequencies, lexical weights and the phrase bonus for the translation model (with phrases up to length 10), a 5-gram language model using Kneser-Ney smoothing, and a word penalty model. Therefore, 14 different features are combined. The language model was built using SRILM [Stolcke 2002]. Optimization was carried out using MERT [Och 2003]. For word alignment we used GIZA++, as mentioned earlier in this article. MT systems (and particularly RBMT ones) may be evaluated in terms of coverage. We used texts from different domains to perform the coverage evaluation. Table II shows the coverage results of the RBMT system for the development and test datasets described in Section 3.1. The coverage of the SMT system is also shown. The coverage of the SMT system is higher in the UN corpus because this test corpus is from the same domain (in-domain) as the training corpus. For the other corpora (NEWS and IN-HOUSE), which are out-of-domain, the RBMT system doubles the coverage of the SMT system.

In addition to evaluating the coverage, we also wanted to show the quality of the translation in terms of BLEU [Papineni et al. 2002], WER and PER [McCowan et al. 2004], ROUGE [Lin and Och 2004], and METEOR [Lavie and Agarwal 2007], which are standard measures used to evaluate SMT. Evaluation was undertaken using the ASIYA toolkit [Gonz ` alez et al. 2012].

Table III shows the results for the different systems. RBMT is the baseline system, it does not include lexical rules, and it only uses manually written structural rules. The next system (+LexicalTransfer) adds statistically extracted lexical rules, as ex-plained in Section 2.5. The system in the third row adds the automatic structural rules extracted to the manual structural rules, as explained in Section 2.6. Finally, the results for the SMT system are also shown.

We see that adding both lexical and structural rules extracted statistically from parallel corpora increases the performance of the RBMT system in all measures in the UN test set, which makes sense since automatic rules were extracted with the UN training corpus from Table I.

When testing the improvements in the out-of-domain test sets, we see that the automatically extracted lexical and structural rules improve the performance of the translation system in terms of PER, METEOR, and ROUGE. Although the translation quality is quite low, in this case, the rule-based method is capable of outperforming the statistical system.

Table IV shows some examples of the translation outputs when using statistically extracted lexical transfer rules, and without these rules.

Table V presents some examples of the translation outputs when using statistically extracted structural transfer rules and without them. Finally, a linguistic annotator evaluated 100 random sentences from the in-house test set using a human linguistic analysis that classified all the translation errors into one of the five following linguistic levels: orthographic, morphological, lexical, semantic, and syntactic. Linguistic guidelines for the target language are those presented in error subtypes was provided. For the RBMT system, we used the best automatic output from Table III.

Table VI shows the results of the linguistic analysis, and the RBMT system outper-forms the SMT system at all linguistic levels with the exception of syntax. However, the differences are not very large apart from at the lexical level. The coverage of both systems is very different in the out-of-domain test set. Table VII shows some examples of the outputs. The novel aspects covered in this article include (1) a detailed description of the first Chinese-to-Spanish open-source RBMT system and (2) an RBMT system built using hybrid techniques, combining human knowledge and statistical techniques.

In particular, human expertise has been used to create exhaustive monolingual and bilingual dictionaries as well as define structural transfer rules. Additional statistical knowledge complements all the steps mentioned. Moreover, statistical information has been the only source for the lexical transfer rules. The improvement in the RBMT system provided by the use of statistical knowledge in the RBMT system has been evaluated, and it has been shown to enhance translation output. In this sense, we present effective techniques for constructing an RBMT system using hybrid techniques. Moreover, the RBMT system outperforms the statistical system in the out-of-domain test.

The new RBMT system and the methods for constructing it have been evaluated both automatically and through a linguistic human analysis. Moreover, the output of the latest version of the RBMT system has been contrasted with a statistical state-of-the-art system for the out-of-domain test set. The RBMT system outperforms the SMT system at all linguistic levels except at the syntax level. Clear outperformance is shown in terms of lexical coverage.

Future work includes improving the RBMT system with new dictionary entries and more complex transfer rules. Both enhancements can be made combining human and statistical knowledge. Also, the fact of having two systems based on different principles in such a challenging language pair may be useful for research in the active field of hybrid MT. Finally, another RBMT toolkit, such as Matxin [Mayor et al. 2011], could be applied to solve reordering problems.

