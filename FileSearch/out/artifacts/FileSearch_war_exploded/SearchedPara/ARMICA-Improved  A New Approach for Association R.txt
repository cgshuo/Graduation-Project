 Association Rules Mining (ARM) is a data mining technique to extract frequent rules and patterns from a database. Many challenges are still remained in ARM techniques. Being a single dimension solution and focusing only on one aspect of ARM problems is the main drawback of these methods. For instance, many of them tend to be a fast approach and do not consider other parameters like the number of genera ted rules or accuracy; or only focus on accuracy of generated rules and do not investigate other factors like being a fast approach or having the least number of database scans. In conclusion, an efficient ARM approach should consider all these parameters at the same time. One of the main parameters that have been frequently considered in many ARM approaches is having low execution time. Generating frequent and interesting rules in a short period of time is one of the primary goals of many ARM approaches. To be a fast approach, many researchers have worked on other parameters that may affect the execution qualify, is in higher priority compared to having low execution time. Finally, an automatic ARM method could be independent from user knowledge and can be applied on any databases. For this reason, some researchers have worked on making their approaches automatic. In this paper, we focused on different aspects of ARM at the same time. We proposed a new ARM approach, named ARMICA -Improved, which extracts frequent rules accurately and in a short period of time. This approach is based on a heuristic algorithm called Imperialism Competitive Algorithm (ICA) [1]. ARMICA -Improved scans the database any of these frequent items. Finally, our approach is an automatic approach and set the minimum support automatically a nd does not need minimum confidence to extract frequent rules. The experimental results indicate that ARMICA -Improved has lower execution time, less number of database scans, less number of generated rules, set the minimum support automatically and does no t need minimum confidence value ; also its generated rules are accurate, and gener-ating more qualify rules compared to the Apri o ri [2][3] and FP -growth [4]. The rest of this paper is organized as follows. Section 2 reviews the literature. Section 3 briefl y introduces the ICA algorithm. Description of our proposed method and our experimental results could be found in section 4 and 5, re-spectively. Section 6 discusses the experiment al results and there would be a conclusion statement in section 6. approaches compared to Apriori. Apriori X  X  mechanism is as follows: The algorithm tries to find all {X,Y} that both X and Y may contain at least one item. The extracted rule may be like: X  X  Y This rule means that if we find X in a transaction, then with a probab ility (Confidence) we also find Y in that transac-tion. The important thing is X and Y should not have any item in common: X  X  Y =  X  Most of ARM algorithms have two steps: first, finding the frequent itemsets. Frequent itemsets are sets of items that freque ntly occur together in the database. Secondly, generate frequent rules from the frequent itemsets. In Apriori, there is a parameter, named minimum support that items and itemsets with frequency of more than mini-mum support are frequent. Support of each it em is the number of occurrence of that item in the database. In each level, Apriori generates candidate list of frequent items and itemsets. Then, it removes the items and itemsets with support of lower than minimum support. In this step, the algorithm emp loys a technique, named pruning to check that is there any itemsets, which has an item that was not on the candidate list in the previous levels; if it find one, so it removes this itemset. After pruning, it joins all the items and itemsets in the candidat e list with each other and produces new mention that, in this algorithm user should set the minimum support in advance and manually. generates rules. In this step, Apriori needs another user defined parameter, named Minimum Confidence. Based on that, the algorithm rem oves the weak rules. Confidence of each rule could be calculated by: In the literature, many heuristic approaches have been proposed. One of heuristic approaches in ARM is [5]. Authors have proposed two new ARM algorithm based on GA, n amed IARMGA and Memetic algorithm, named IARMMA. They claim that most of bio -inspired -based algorithms have two main drawbacks: Generating false rules and consid-ering some rules with low support and confidence as high qualify rules. They considered two par ameters to evaluate their approaches and compared them with each other: Execution time and Accuracy of generated rules. Accuracy in this approached has been considered as value of their fitness function. For this reason, they propose a new method, named  X  X  elete and decomposition strategy X  to have better accuracy. Finally, their experimental results indicate that IARMMA has higher execution time compared to IARMGA especially in a big dataset. However, IARMMA has Apriori.
 Yan et al. have proposed a novel approach based on Genetic algorith ms for ARM [6]. In their method, they did not use any fixed minimum support threshold. Instead, they employ relative minimum confidence term as fitness function to select only the best rules. At the beginning, they propose an algorithm, named ARMGA, which is designed to deal with Boolean association rule mining. However, since they also want to deal with quantitative association rule dis-covery, they propose another Genetic algorithm based method, named EARMGA which is an expansion of ARMGA. They also design ed a FP -tree approach based on FP -growth for implementing EARMGA. Experimental results illus-trate that their algorithms reduces computation costs and generates interesting association rules only. In our previous work [7], we proposed an ARM approach, named ARMICA. Our main focus was on proposing a fast algorithm that extract frequent rules in short fraction of time. For this reason, we employ Imperialism Competitive Algorithm (ICA ), which is a fast heuristic approach. Another focus was extracting frequent r ules automatically and without any predefined minimum support and confidence. ARMICA does not require any predefined minimum sup-port and it also does not require minimum confidence at all. Our experimental results indicate that ARMICA is faster primary comparisons illustrate that ARMICA is faster than FP -growth, so we could consider it as fast approach. How-ever, ARMICA has three drawbacks. Firstly, it requires a predefined parameter, named Number of Imperialists. Alt-hough setting this parameter is much easier than setting minimum support and minimum confidence, it would be great that in newer version of ARMICA we define this parameter automa tically. Secondly, as we mentioned for some of other heuristic approaches, it is not enough to compare ARM approach only with Apriori or even FP -growth. Hence, we should compare ARMICA with other recently approaches. Finally, to have a comprehensive ARM ap proach, we should consider more parameters like memory usage, number of database scans or interestingness. Applying Ant Colony Algorithm (ACO) is also one of popular solutions for ARM. In [8], authors have proposed a new ARM algorithm based on a Meta he uristic algorithm, named Ant Colony System (ACS). ACS is based on behav-ior of ants. However, in this algorithm ants have memory and they are not blind. They also have mentioned another research on ACS in ARM. They discus that in that research demonstrates that using ACS in ARM is time consuming. In addition, they claim that ACS needs some parameter that should be pre -determined. As a result, they propose a method that uses some limitations and also define most of parameters before running the model to decre ase the com-putational time. They tested their approach by National Health Insurance Research Database of Taiwanese government and compare their approach with Apriori. The experimental results indicate that proposed method scans the database only once which results in having less computational time compared to Apriori. This could make proposed method suitable for big data analysis. However, their experimental results show that many similar rules are generated by this method, which is an important challenge t hat should be addressed. In Kuo [9], authors have proposed a new approach based on Particle swarm optimization (PSO) algorithm. Their goal is to determine minimum support and minimum confidence automatically in a more accurate way. For this purpose, they change type of the data set to b inary format and with the help of PSO algorithm they extract rules. In the end, the best Particle is found. At that point, Minimum Support and Minimum Confidence of the best particle will be consid-ered for further associati on rules mining. To evaluate their approach, they compared their method with Genetic Algo-rithms. The experimental results indicate that PSO has lower computation time and it is faster. In addition, since PSO sets minimum support and confidence automaticall y, there is no need to set them by trial and error, which is a time consuming process. They also applied this method on investors X  stock purchase behavior in real world, but since they only had access to 50 individual brokerage accounts, their result canno t be representative for every investor in Taiwan. Another ARM algorithm which is based on Parallel Genetic Algorithm (PGA) is presented in Dash [10]. They demon-strate that the problem of Apriori and similar ARM algorithms is process of setting minimum supp ort and minimum confidence manually. For instance, in large datasets it is hard to predict value of these parameter s manually. They believe that in most of ARM approaches, user -defined min support and min confidence plays the main role to find interesting rules. However, in their approach, interestingness is determined by fitness function, automatically. They many researcher to apply heuristics . However, some heuristic methods like GA suffer from long computation time. As a result, they apply PGA as a solution. Moreover, they denote that fitness evaluation process for all frequent item-function, which results in decreasing computation time. Their Experimental results indicate that their approach has 85% accuracy when detecting interesting rules. However, they did not evaluat e on computational time of their ap-proach and they did not compare it with other approaches. There is another use of PSO algorithm in Nandhini [11]. In this paper, authors propose a new ARM method which includes two steps. First, they transform data to bi nary format. Then they apply PSO to define minimum support and minimum confidence automatically. They consider support and confidence of the best particle as minimum support and minimum confidence. At that point, their approach mines association rules and extracts rules. At the final stage, they use a post mining technique, named Domain Ontology to reduce the number of rules. They also employ a rule schema which defines user expectation of mined rules. Finally, they compared their proposed method with Aprio ri. Their approach at first place generates about 1000 rules, which has not any knowledge about user expectation. Then with applying domain ontology and taking user expectation, they were faced with a dramatic decrease in the number of extracted rules. As a result, their approach has less rules but does not have any negative impact on interestingness of the rules. However, they did not study computation time of their approach. ICA is a powerful heuristic algorithm. It includes some countries, which some of them are Imperialist and the others are colony. The concept of the algorithm is the competition between these imperialists to building the most powerful empire [1]. ICA involves key as follows:  X  Country: the variables that should be optimiz ed  X  Imperialist: A country with lots of power that controls some colonies.  X  Colony: A weak country that is controlled by an imperialist.  X  Empire: a group of countries that include an imperialist and some colonies.  X  Cost: This parameter is different in any problem domain. In this paper, we consider it as the number of occurrence of each item in the database.  X  Normalized cost: We calculate the cost of each country based on formula (3).  X  Power: This is the main parameter in the ICA competitions. It is b ased on the cost of each country. In this paper, a country w it h more cost is more powerful.  X  Total empire Power: The power of the imperialist plus the power of its colonies in one empire.  X  NCountry: the number of all countries (items)  X  Nimp: It is a free parameter in the original ICA and it represents the number of Imperialists [12].  X  Ncol: the number of colonies, which is Number of all countries  X  number of Imperialists. In ICA, all the variable s that should be optimized are a country. In this pap er, each item in the database indicates a country in ICA. At the beginning, ICA selects some of these countries as the imperialist. These countries are chosen among the most powerful countries. The power of each country is calculated by the cost of that co untry. In this paper, the cost of each country represents the number of occurrences of that country in all the transactions. Countries with more cost have more power. Based on the power of each imperialist, the algorithm distributes the colonies between th e imperialists. In this step, each imperialist and its colonies represent an empire. Next, the power of each empire will be calculated based on the power of its colonies. Then, ICA establishes a compe-tition between the empires. According to that, the most powerful empire takes the colonies of the weakest empires. At that point, if there is only one colony left in the weaker empire, that colony and its imperialist become colonies of the powerful empire. This competition continues until there is only one emp ire left. 3.1 Creating the Initial Empires In this algorithm, there is an array of variables that are known as countries and ICA tries to optimize them. Based on formula 2, the algorithm calculates the cost by a function f at variables [1]: Firstly, ICA Npop as the size of countries and selects Nimp of them as the imperialists. The remaining cou ntries (Ncol) are the colonies. Normalized Cost of each country could be calculated by formula 3 [12]. where cn is the cost of the nth imperialist and Cn is its normalized cost. With having the normalized cost, the normal-ized power of each imperialist can be computed by formula 4 [1]: 3.2 Total Empire Power The total power of each empire is based on sum of power of its imperialist and the mean power of its co lonies [1]. 1) Initialize the empires 2) Calculate the total Power of the empires. 3) Competition between empires. Select a colony from the weakest empires and assign it to the most powerful one. 4) Eliminate the weakest empires. 5) If there is only one empire left, stop the process. Otherwise, go to step2 We propose new ARM approach based on ICA algorithm called ARMICA -Improved, which is a heuristic approach. This approach is an improved version of our previous method ARMICA [7]. ARMICA -Improved has some significant improvements compared to the ARMIC A. One of the parameters that has impact on execution time is the number of database scans. Having higher number of database scans may increase the execution time. For this reason, ARMICA -Improved scans the database only once and at the same time calculate the frequency of each item in the database. In this algorithm, we consider the frequency of each item as cost of that item in ICA and each item is a country. In addition, we assume that a country with more cost has more power. In the other worlds, a coun try (item) with high calculated in the database scan stage) to the ICA. ICA selects some of the most powerful countries as imperialists and more colonies. In this stage, the empires are built. At that point, ICA establishes competition between the empires. colony become one the new colonies of the powerful empire, but like ARMICA, in ARMICA -Improved, this colony would be removed and added to a list, named Reserve List. Mor eover, the stolen colony should be the weakest colony of the weaker empire. This process continues until there is only one colony left for the weaker empire. In this occasion, the colony and imperialist of the weaker empire become colonies of the powerful empire. This completion continues has more power than any colony in the final empire and exchange them. Finally, the members of the f inal empire are our frequent itemset. It is noticeable that since ICA selects the most powerful countries as imperialists and because we working on offline databases and the items have fix frequency, there is no chance for a colony to become more powerful than its imperialist; as a result, there is no need for Revolution process. Next, the algorithm sorts the frequent rules based on their costs and calculates the median cost of them as the universal minimum support. Hence, ARMICA -Improved determines the mi nimum support automatically and it does not require any user knowledge to set this parameter in advance. One of the differences between ARMICA and ARMICA -Improved is that at this stage ARMICA -Improved removes each items that has frequency less than minimum support. (itemset, which their support value is less than minimum support). This could reduce the number of generated itemsets, significantly . At that point, the algorithm removes each transaction of the database that does not contain any of the frequent items. It also removes the columns of infrequent items. This process could dramatically decrease the size of the database. Just like Apriori, FP -growth and ARMICA, ARMICA -Improved tries generate all the possible k -length frequent item-set that k is 1,2,...,n. However, in contrast to ARMICA, it in each stage, it stores all the generated frequent item sets compared to the ARMICA. In the other worlds, one of the biggest difference between ARMICA and ARMICA -Improved is that in ARMICA -Improved we calculate the cost of frequent itemsets few t imes. We store all the costs of all itemsets in previous steps. This save us lots of time compared to ARMICA, which requires calculating costs of all frequent items and itemsets repeatedly. To familiarize the readers with ARMICA -Improved, here we made an example. Assume that we have transactional database like table 2. This database has 17 items and 7 transactions. ARMICA -Improved scans this dataset and calcu-late the frequency of each items at the same time. At this stage, it sends the items and t heir frequency to the ICA. ICA selects some of them as imperialist. As it was mentioned before, the number of imperialists is a free parameter in the original ICA. As a result, since here we only have 17 countries, we can not consider 10 percent of them as imperialist power. At this time, we the empires are built. Then the algorithm calculates the power of each empire based on power stage. Empire 1 tries to steal the I12 from the empire 4. The algorithm removes this colony from empire 4 and adds it references. them in the Save list. This process continues until all the possible frequent itemsets be produced. Then, ARMICA -Improved extract the frequent rules from these itemsets. Since the al gorithms stores all the possible items and temsets and their costs in the Save list, in contrast to the ARMICA, there is no need to calculate the support of different parts frequent rules like other ARM approaches.
 T1 t t t t t t t t T2 t t t t t t t t t t T3 t t t t t t T4 t t t t t t t t T5 t t t t t t t T6 t t t t t t t T7 t t t t t t T Frequency 6 4 3 3 1 4 6 3 4 3 2 1 2 1 3 4 3
