 Sponsored search is one of the major sources of revenue for search engines on the World Wide Web. It has been observed that while showing ads for every query maximizes short-term revenue, irrelevant ads lead to poor user experience and less revenue in the long-term. Hence, it is in search engines X  interest to place ads only for queries that are likely to attract ad-clicks. Many algorithms for estimating query advertisability exist in literature, but most of these methods have been proposed for and tested on the frequent or  X  X ead X  queries. Since query frequencies on search engine are known to be distributed as a power-law, this leaves a huge fraction of the queries uncovered.

In this paper we focus on the more challenging problem of estimating query advertisability for infrequent or  X  X ail X  queries. These require fundamentally different methods than head queries: for e.g., tail queries are almost all unique and require the estimation method to be online and inexpensive. We show that previously proposed methods do not apply to tail queries, and when modified for our scenario they do not work well. Further, we give a simple, yet effective, approach, which estimates query advertisability using only the words present in the queries. We evaluate our approach on a real-world dataset consisting of search engine queries and user clicks. Our results show that our simple approach outper-forms a more complex one based on regularized regression. H.3.m [ Information Storage and Retrieval ]: Miscella-neous Algorithms, Design, Experimentation sponsored search, click estimation, tail queries
Sponsored search is the dominant form of textual adver-tising on the Web in terms of revenue. It involves display-ing advertisements (ads) alongside the results returned by search engines. Under the pay-per-click mechanism, search engines get paid every time a user clicks on a displayed ad. Clearly, sponsored search is useful for search engines since it is a source of revenue for them. Moreover, it is beneficial for users as well since it helps them in finding relevant prod-ucts/services, especially for queries with commercial intent. It also aids advertisers in reaching the right set of users.
The success of sponsored search heavily relies on display-ing relevant ads for appropriate queries. Previous studies [6], have shown that irrelevant or unwanted ads are useless to search engines since they do not attract clicks. They may even be harmful since they degrade the quality of search experience driving users away. Even users who continue us-ing the search engine despite seeing irrelevant ads might get  X  X rained X  to ignore the sponsored sections of the search re-sult page, impacting the long term revenue of the search engine. Hence, estimating the following two properties are of key importance for an advertising engine: Estimating Advertisability for Tail Queries.

In this paper we focus on the first task above, that of es-timating Query Advertisability . There is past work on iden-tifying whether user queries have an underlying commercial intent, the intention to purchase a product or a service [2, 6, 10]. However, in addition to the underlying intent, adverti-sability should also capture other factors that influence the likelihood of engaging the user; the suitability of the current ad supply, the ability of the ad selection algorithms to select good ads, and even business rules. Therefore, we consider the ad clicks obtained in response to a query as a proxy for its advertisability. Specifically, in this paper we define ad-vertisability of a query as the probability of seeing a click on any sponsored search ads displayed on the result page of the query.

Past work on modeling advertisability of queries have fo-cused on using features derived from a plethora of informa-tion about them; the set of all retrieved ads in [6] and the set of all retrieved search results in [10]. Moreover, these approaches determine advertisability from an offline analy-sis of the historical click data. These methods have only been tested and shown to work well on frequently occur-ring queries. However, in this paper we focus on the more challenging problem of estimating advertisability of infre-quent or tail queries , so called because they form the  X  X eavy tail X  of the power-law distribution of query frequencies on a search engine. The above mentioned approaches are not applicable to these tail queries as they are too rare to have significant historical data. Furthermore, tail queries are al-most always unique, thus requiring an online estimation pro-cedure (i.e., estimation is performed when users issue the queries). Since search users are very sensitive to any latency in the results presentation, under any reasonable system in-frastructure the online procedure must be inexpensive and cannot employ complex query expansion methods. Hence we study the problem of estimating query advertisability using the query keywords only, similar to [2, 22].
 Technical Challenges and Solutions.

Most of the queries in the datasets used in this study con-sist of 3-4 words and have occurred 1-2 times. This results in the two principal challenges of the problem: noisy ground truth due to the rarity of the queries, and sparseness of fea-tures due to the short query lengths.

The noise in the ground truth, i.e. the estimates of query advertisability, results from the low number of impressions for each query. This makes not only the learning difficult, but also affects the testing methodology. For instance, an oracle is also unlikely to match the advertisability estimates of individual queries derived using our data. One of our key insights is that though the advertisability of each indi-vidual query is noisy, when many queries are put together they provide a fairly stable advertisability estimate. Hence, given an estimation policy we evaluate it by looking at the aggregate advertisability of the top-ranked queries (instead of their individual advertisability).

In order to learn in the presence of noisy ground truth, we propose a word-based advertisability model that employs the above X  X rouping X  X nsight (in Section 2). We estimate the parameters of this model via a maximum likelihood based method. As a competitive baseline we also present a regres-sion based methodology that combines state-of-art elements from machine learning literature (in Section 3). Finally, or-thogonal to these two methodologies we study an additional way of dealing with noise: learning from the head queries (which have reliable advertisability estimates) and then ap-plying the model on the tail queries (see Section 2.2.1). From our experiments we found that this does not work well, since tail queries exhibit fairly different vocabulary and character-istics than the head queries.

We handle the sparsity of features in different ways for the two learning methodologies. For the maximum likelihood estimation method, we show that simplifying assumptions to remove interactions among the features result in improved accuracy. In the regression methodology, we handle sparsity using two methods. One way is to perform regression under a L 1 -regularization (also known as Lasso). A second way is to make the features denser by clustering them [8, 22, 27]. In Section 3.3, we give an LDA-based method of clustering tail queries and a learning method that maps queries into latent clusters and learns a model using these cluster-based features.
 Contributions.

We make the following contributions in the paper: 1) We investigate and formalize the problem of estimating advertisability of tail queries using its keywords only. The problem is challenging due to the inherent noise and sparsity present in the data. 2) We propose a simple, yet effective, word-based model to estimate query advertisability. Our estimation method is robust to noisy ground truth as well as sparse features. 3) We put together a competitive baseline regression-based approach that deals with sparsity by: (a) incorporating reg-ularization in the model and (b) using LDA-derived latent topics. 4) We give an evaluation framework for the problem using a large scale dataset from a real-world search engine. Our ex-tensive empirical results show that our word-based model outperforms the more expensive and complex regression-based approach. Our goal in this work is to make predictions for Query Advertisability, which is the probability of the event when one or more ads displayed for a query are clicked. In this section, we give a model to accomplish this.
In Section 1 we discussed the challenges of learning and evaluation in the presence of noisy ground truth and sparse features. Further, we used these to motivate our use of a word-based model. In this section, we start with a discussion of the additional properties that we want our word-based query advertisability model to have.

A basic desired property would determine the influence each word exerts on the advertisability of the query it is part of. Some words indicate that the user is looking for a cer-tain product, e.g.,  X  X ownload X ,  X  X uy X  and  X  X ompare X , while other words like  X  X nsurance X ,  X  X light X  and  X  X otel X , are associ-ated with products/services that are known to be amenable to advertising. When we look at the queries that contain these words and their corresponding ad-clicks, we observe that these words have heavy positive influence on the query advertisability. Similar observations have been made in [2]. Hence, a useful basic property to have is, P1 : a single  X  X d-vertisable word X  should be capable of ensuring high adverti-sability for a query containing it. On the flip side, consider some words from [2] that lead to low ad-clicks on queries, such as  X  X eather X ,  X  X ree X ,  X  X niversity X  etc. From our data, we find that queries containing these words could poten-tially still be highly advertisable; for example,  X  X eather in fiji X ,  X  X ree download X , and  X  X niversity admissions X . Hence, a useful second property to have is, P2 : while some words do not contribute to a query X  X  advertisability, no one word X  X  presence should reduce the advertisability. Finally, the effect of a word on a query advertisability might depend on other words present, like effect of  X  X usic X  in the queries  X  X usic ringtones X  and  X  X usic lyrics X . However, because the word occurrences in tail queries are extremely sparse we do not incorporate such dependencies into the model.

Conforming to these desirable characteristics we give the following query advertisability model. In the model we say that each word in a query has a certain propensity of at-tracting a click on an ad, say c ( w ). Let us denote the ad-vertisability of query q by c ( q ). Say, the query q consists of the words w 1 , w 2 . . . w n . Thus, under the independence assumption, each word in the query independently attracts an ad-click for the query (with probability c ( w )). Hence, the advertisability (i.e., the probability of the ads displayed for query q to be clicked) can be written as:
A key property of this formulation is that, all things be-ing equal, it favors longer queries (e.g., if all c ( w i same, c ( q ) gets larger as n gets larger). While this makes sense in most cases, it can score longer queries containing words with mediocre click propensities higher than shorter ones with few good terms. To avoid this shortcoming, we in-troduce parameter k where k denotes the maximum number of words from the query that can take part in the clicking process. Under this constraint: where S X  q and |S| X  k .
In Equation 1 we presented the model to combine each query word X  X  contribution to the query advertisability. 1 can estimate the parameters of this model by computing the maximum likelihood estimate of the training data. The training data consists of queries and their associated click or impression events. Say, s ( q ) denotes the number of instances when query q received an ad-click, while n ( q ) denotes the number of instances when it did not. Given a dataset of queries Q and click events, its likelihood can be written as:
In Equation 2 we use the k  X  X est X  terms to compute query advertisability, but we will use Equation 1 to estimate the model parameters.

On taking the logarithm of the both sides: log L ( s ( q ) , n ( q ); c ( w )) = X Taking derivatives with respect to c ( w ) results in:
Here q 3 w is the set of queries that contain the key-word w . Solving this complex set of equations is difficult, especially since the feature combinations used in queries are sparse and the ground truth is unreliable. Hence, we ap-proximate this solution by assuming that each instance of a click or not click is a referendum on the advertisability of each keyword in the query independently. This has the same effect as replicating each query once for each term con-tained in it, with each such replication having just one of the keywords. Under this assumption we obtain:
In other words, the contribution of a word to advertisabil-ity is the fraction of times it is present in a query instance which attracted an ad-click.
As mentioned earlier, tail queries have very few impres-sions, the words combinations are extremely sparse, and thus their advertisability estimates tend to be very noisy. Clearly, learning from such a dataset is difficult and may lead to a poor model estimation.

An alternative approach is to learn the model from the head queries, which tend to have significant number of oc-currences in the historical data. For these queries we can compute advertisability estimate with confidence. The dis-advantage of learning from such a dataset is that it is very different from the test set of tail queries in terms of vocabu-lary, word combinations, and maybe even word advertisabil-ity scores. This difference could counteract the advantages gained from reliable ground truth when learning on the head queries.

Each training set has its own advantages and disadvan-tages. While the training set of tail queries is noisy, the training set of head queries may exhibit different behavior and not generalize well on the test set. In Section 4.5 we evaluate our model while training on both the head and tail set of queries.
In Section 2, we proposed a simple word-based model for predicting query advertisability. In this section, we present alternative approach that combines state of the art elements from machine learning literature. First, we will formulate the task of predicting query advertisability as a regression problem. Then we will present a few ideas to help the regres-sion model handle sparsity: regularization and clustering.
Just as in the word-based model in Section 2, we say that each word in a query has a certain propensity of attracting a click on an ad; we denote this with c ( w ). The advertis-ability of query q , denoted by c ( q ), can then be computed quite naturally by summing of the individual word adverti-sability values [19, 20]. Under this model we consider words in queries as binary features and the weight of each word is given by its advertisability. Say, the query q consists of the words w 1 , w 2 . . . w n , then c ( q )  X  P w  X  q c ( w ).
Hence, we can write the following set of linear equations: where q  X  X  are the error terms.

Under the squared loss function this problem can be for-mulated as:
This set of linear equations can be solved using existing methods. However, we face another challenge here which is that due to the sparsity in word occurrences. A tail query consists of 3-4 words on average, which is a very lit-tle amount of text. Moreover, tail queries significantly dif-fer from each other, thus resulting in a large vocabulary of words. For instance, in our experiments we noted that the number of unique words is more than half of the number of unique queries. In other words, if we represent a query in this feature space, it will consist of a couple of non-zero entries for the words present in the query, while the rest of the thousands of dimensions will be all zero. This is likely to make this set of equations under-determined. Next we consider a couple of ways to handle this issue of sparsity.
When the number of parameters is large, the estimates of linear regression exhibit high variance which is undesir-able. One way of controlling this by incorporating regular-ization while training. Under L1 regularization (also known as Lasso [12, 26]) this can be written as: subject to: where  X  is a given constant. This is also written as: where  X  is the shrinkage parameter. When  X  is close to 0, this behaves like regular linear regression, while as  X  goes to infinity it forces many c ( w ) X  X  to be zero. Hence, this performs feature selection for us, though unlike traditional feature selection methods this is not limited to completely picking or dropping a feature.
An alternative method of dealing with sparsity is by map-ping the sparse high-dimensional feature space to a dense low-dimensional space. Principal component analysis is of-ten used in doing so while maximizing the variance of the data captured in the low-dimensional space [17]. Latent se-mantic analysis is also used for dimension reduction [11, 16]. It transforms the sparse word-document matrix to a more dense topic-document matrix, where each topic is a latent concept that is derived using the co-occurrence information.
In this paper, we use Latent Dirichlet Allocation to ob-tain topics from queries. This is a generative model for the documents where the topic distribution is assumed to have a Dirichlet prior [5]. We describe it in more details next.
In this model a document is assumed to be generated from a mixture of topics, where each topic has its own word dis-tribution. In particular, we can write the probability of the i th word in the document as (given in [13]): where T is the number of topics. Variable z i denotes the latent topic from which word w i is generated. It is equal to topic j with prior probability P ( z i = j ), in which case the word has P ( w i | z i = j ) of being generated given the word distribution of the j th topic.

Let T denote the number of topics and D denote the num-ber of documents. In the LDA model P ( w | z ) is modeled using a set of T multinomial distributions  X  over the vocab-ulary W (one multinomial  X  per topic). The  X  distribution of a topic gives the distribution of words under the topic. P ( z ) is modeled using a set of D multinomial distributions, denoted by  X  d , over T topics (one multinomial  X  per docu-ment). The multinomial distribution  X  d gives the mixture of T topics present in the document d , i.e.,  X  ( d ) j = P ( z = j ). Both  X  and  X  distributions have Dirichlet priors [13]. In brief, the model can be written as: where  X  and  X  are the hyperparameters.
We use LDA to find a low dimensional representation of a query. In particular, we run LDA over a training set of queries for T number of topics. After the end of run, we have a topic distribution of each query q , P ( z | q ). Each topic makes a latent concept and the topic distribution of query P ( z | q ) gives a representation of the query in this low-dimensional concept space. For each query, these posterior topic-membership values can be used in two ways: they can be added to the query words as additional binary features, or used as a sole representation of a query. In this paper we experiment with both methods. We can use these query representations in our model from Section 3.1. In particu-lar, we find the advertisability of each topic using regularized regression and use them to compute the advertisability of a query.

The advantage of this method is that it is able to relate query keywords with each other in an intelligent manner. For example, we found that in our experiments a topic con-sisted of words like  X  X pod X ,  X  X phone X ,  X  X amsung X  etc. So, using just the co-occurrence information of data, LDA was able to connect these words together which are clearly very related. This helps significantly since new queries that fall into this cluster will be able to use the advertisability in-formation estimated for all queries that fall into the cluster, hopefully leading to robust results. In Section 4.3 we empir-ically evaluate this approach.
In this section we evaluate the word-based model we pro-posed for query advertisability with the state-of-art regres-sion based methodology. Dataset.

We train and evaluate our approach on a real-life search engine data. We collected a sample of queries issued to a major search engine over a period of 7 days. The dataset consists of more than 5 million query impressions. We also recorded the ad clicks for these queries during this period. Of these queries we put those queries into the tail set which have less than 2 impressions per day on average. The goal of this study is to predict the advertisability on these tail queries. The aforementioned tail set consists of more than 2 million unique queries. For our experiments we placed half of the queries in the training set and the rest in the test set.
The average query length is 3.3 which shows the amount of sparsity in the data. The average number of impressions per query is 1.55. As mentioned earlier, given such a few impressions for a query it is difficult to estimate its adver-tisability with any certainty. This presents challenges while learning as well as evaluation. In view of this, we propose our evaluation metric next.
 Evaluation Metric.

A conventional way of evaluating our advertisability esti-mation methods would be to take the L 1 -error or L 2 -error of the predicted ( X  c ( q )) and  X  X rue X  advertisability of queries ( c ( q )). However, since our focus is on tail queries which have very few impressions (as shown above), it is not possible to estimate their true advertisability. In other words, given the noise in  X  X rue X  advertisability estimated from our data an oracle is also unlikely to match them.

To deal with this problem, we opt to evaluate the predic-tion of a method with respect to a group of queries instead of the individual queries. In particular, given method  X  we rank the queries in order of their decreasing predicted ad-vertisability values  X  c ( q ) X  X . Starting from the top, let S ( r,  X  )) and F ( r,  X  ) be the cumulative total of number of ad-clicks and the total number of all impressions till rank r . Due to aggregation over a group of queries, S ( r,  X  ) and F ( r,  X  ) are fairly stable for large values of r and amenable for conduct-ing analysis. Clearly, the best method is the one which maxi-mizes S ( r,  X  ) for all values of F ( r,  X  ). In case there is no clear best method, we can plot S ( r,  X  ) on the y-axis and F ( r,  X  ) on the x-axis and compute area under the curve (AUC) to succinctly summarize the performance of a method. The best policy for a given impression threshold, say  X  , is the one which maximizes S ( r,  X  ) for F ( r,  X  ) =  X  .
Another reason this evaluation method is suitable is that launch criteria in real-world systems are likely to be framed w.r.t. to the relationship between S ( r,  X  ) and F ( r,  X  ). In order to preserve the user X  X  search experience, an advertising Figure 1: Performance of the word-based advertis-ability model for different values of k . system controller will likely limit the number of instances of queries in which ads are shown. The controller would then be interested in determining the algorithm that yields the most clicks in the fixed number of impressions. On the flip side, the number of clicks might be fixed in order to make revenue numbers.
In this experiment we evaluate the performance of our word-based advertisability model presented in Section 2. We tokenize each query into words by treating whitespace for word boundaries. Since many of our queries are URLs, we tokenize these queries at punctuation characters. We remove the stop-words and stem the remaining words.

For this experiment we learn word advertisability scores ( c ( w ) X  X ) from the training set using the approximate method (Equation 3) of Section 2.2. Then we evaluate the method on the test set. Figure 1 shows the performance of our method for different values of k . Recall that k is a parameter in our method which limits the number of words from a query that can contribute towards its advertisability. The x-axis in the figure is the cumulative fraction number of impressions till a given rank ( F ( r,  X  )), while the y-axis is the cumulative fraction of clicks ( S ( r,  X  )).

Note that all of our model variants are significantly above the straight line which denotes the random method (i.e., predict the advertisability at random). This is encouraging since it shows that the advertisability can be estimated quite well using the query keywords only. As expected the curves in the figure are convex. This happens because when the number of impressions is small (x-axis), the clicked impres-sions (y-axis) are aggregated over queries present on the top of the ranked list. These queries are predicted to have high advertisability, thus resulting in a high average click per im-pression (i.e., the slope of the curve). However, as the num-ber of impressions increases, queries with low advertisability start getting accounted for and hence, they bring down the average click per impression.
 From the figure it is clear that k = 2 performs the best. Intuitively, this makes sense because when k is too small, the method does not give due credit to queries with more advertisable words. On the other hand, when k is too large, long queries get an unfair advantage. Still, the model looks fairly stable when k is in a reasonable range (i.e., 1 to 3).
In Section 3 we gave a regression-based approach to pre-dict query advertisability. Due to sparsity the simple linear regression is unlikely to work, hence we experiment with the L -regularized regression. We perform L 1 -regularization us-ing the SMIDAS software [25] where SMIDAS stands for  X  X tochastic Mirror Descent made Sparse X .

Furthermore, as discussed in Section 3.3.2, we use LDA to derive dense topic-based features. In particular, we rep-resent each query as a mixture of latent topics derived using LDA and the query words. We then learn the model over this hybrid low-dimensional query representations using the SMIDAS software as above. In Table 2 we show some topics and the top words in them as derived using LDA. Clearly, the topics are fairly coherent and meaningful. We experimented with constructing a 100 and a 1000 topics; the results were very similar and we present the ones with 100 topics. We also experimented with using just the low-dimensional rep-resentations of a query in the regression formulation, but the results were much worse; we do not present those results here.

In Figure 2 we plot the performance of the regression-based approach with and without the topic-based features. As we can see adding the topic-based features has so signif-icant effect on the accuracy of the prediction task. This is in contrast to the results obtained in [22], where keyword cluster based features were shown to have significant im-pact on accuracy. We posit that this is because our focus is on tail queries; while the topics constructed by LDA are themselves meaningful, the uniqueness of tail queries means that inferring the topics for each tail query is extremely dif-ficult. Hence, the knowledge contained in sparse word-based features subsumes the contribution of dense topic-based fea-tures. We leave further investigation of this phenomena for future work.
Above we evaluated the two different methods for estimat-ing query advertisability. In Table 1 we show the popular words with top advertisability under the two methods. Note that both methods are doing a reasonably good job of find-ing highly advertisable words such as rental, vacation, travel etc. Even though the top features from the two estimation methods look fairly similar, the weights of many other fea-tures show differences.

In particular, we plot the performance of the two ap-proaches, word-based approach and L 1 -regularized regres-sion, in Figure 3. It is clear that the word-based method performs better in comparison to its state-of-art counter-part. This shows that careful modeling of the properties of the problem can result in a simple, yet effective, approach that can outperform a method based on much more complex machine learning primitives.
So far we have been learning the model from the training set of tail queries. Another data set that can be employed for training is the head set which consists of all the head queries. The advantage of this set is that it consists of fre-Figure 2: Performance of the regression-based ap-proach with and without LDA-derived topic fea-tures. Figure 3: Performance comparison of the word-based model and regression-based approach. quent queries and has relatively stable query advertisability values ( c ( q )). The disadvantage is that it is not similar to the test set which consists of tail queries only.
We perform learning from these training sets using model-based method for k = 2. Figure 4 shows the performance for different training sets. Note that the training set of head queries performs worse. This shows that the naive approach of learning from head queries and applying the learned model on tail queries does not work well since they exhibit different characteristics than the head queries. This does not imply that head queries are useless for our task; in-stead, it means that head queries are not sufficient by them-selves and must be used in conjunction with tail queries to aid the learning.
Sponsored search is an active area of research. Several studies have been published recently that focus on the spon-sored search advertising [1, 6, 7, 21, 22, 24]. We classify the related work along the following aspects and distinguish our work from them.
 Modeling Ad-specific CTR.

Most prior art [7, 21, 22, 24] in sponsored search deals with estimating the CTR of a given query-ad pair; this es-Figure 4: Performance of word-based model under different training sets.
 Table 1: Words with high advertisability estimates under the two prediction methods.
 Table 2: Some LDA-derived topics and their top words. timate is often used to display the ads with the highest pre-dicted CTR for a given query. In this work, we are inter-ested in predicting the advertisability of queries, which we define as the probability of seeing an event in which one of the ads displayed for the query gets clicked. Gauging the query advertisability correctly helps the advertising engine decide whether to show ads or not (or how many ads to display), and thus only showing ads to which the user will react. Moreover, this reduces the computation cost of ad selection for queries that should not display ads. Modeling Commercial Intent of User Queries.

Another line of related work has focused on identifying queries with commercial intent. An approach for detect-ing the commercial intent is proposed in [10]. They define the term OCI (Online Commercial Intention) and present a framework of building machine learning models to learn OCI based on the Web page content. They use that framework to detect the commercial intent of queries, which is related to the problem we solve in this paper. In [3] the authors an-alyze the click-through behavior of ads to characterize and predict query intent. An analysis of the contributions of the different query terms and their corresponding click rates on commercial intent queries is presented in [2]. In a follow-up work [1] the authors examine detecting commercial intent by building a classifier based on editorial judgments of the com-mercial intent of the queries. They show that those queries that are characterized as commercial have higher CTR than the others.
 Our work differs form this set of works in a few ways. First, we focus on modeling query advertisability, which in addition to the underlying intent, also captures all the fac-tors that influence the likelihood of engaging the user; the suitability of the current ad supply, the ability of the ad selection algorithms to select good ads, and even business rules. Because of this we consider the ad clicks obtained in response to a query as a proxy for its advertisability. Hence, unlike past work that has relied on using human judgments for learning, in our approach we use the click data directly, without using a human understandable defini-tion of the property of interest. Thus we identify directly the queries for which the users would be inclined to click on ads. Last, we focus specifically on the more challenging problem of modeling for tail queries. These queries, due to their rar-ity and the sparseness of their term combinations present very different problems than considered in past work. In this paper we give some solutions to these problems. Modeling using Rich Query Features.

In most past work, modeling of commercial intent behind queries has focused on using features derived from a plethora of information about them; the set of all retrieved ads in [6] and the set of all retrieved search results in [10]. Moreover, these approaches determine advertisability from an offline analysis of the historical click data. These methods have only been tested and shown to work well on frequently oc-curring queries. However, in this paper we focus on the more challenging problem of estimating advertisability of tail queries. The above mentioned approaches are not appli-cable to these tail queries since they are too rare to have sig-nificant historical data. Furthermore, tail queries are almost always unique, thus requiring an online estimation procedure (i.e., perform the estimation when users issue the queries). Since search users are very sensitive to any latency in the re-sults presentation, under a reasonable system infrastructure the online procedure must be inexpensive and cannot em-ploy complex query expansion methods. Hence we study the problem of estimating query advertisability using the query keywords only.
 Regression with Cluster-based Features.

Our work is most close to the work in [22], where the au-thors propose to the clustering of the bid phrases of ads in estimating CTRs. Both top-down and bottom up hierarchi-cal clustering are applied. The CTR of a bid phrase is then calculated as a linear combination of the predicted CTR and the CTR of its cluster. The results show that the smoothing helps the estimates for rare bid phrases and it slightly de-creases the precision for common bid phrases. In this paper we update this approach by performing a more sophisticated topic modeling using LDA, and feeding the results of it into a state of the art learner based on regularized regression. We show that our our simple, yet effective, word-based model outperforms this regression/clustering based approach via empirical results in Section 4.
In this paper we focused on the problem of estimating the advertisability of tail queries. Furthermore, due to some exogenous practical constraints, we performed the estima-tion using the query keywords only. We discussed how noisy ground truth and sparsity in the data make this problem dif-ficult and techniques from past work do not apply well to our scenario. We showed how to deal with problems associated with tail queries by proposing a words-based query adver-tisability model. We gave a maximum likelihood method of learning the model. We also gave a competitive baseline methodology based on a regression formulation of the prob-lem that used state-of-art machine learning approaches to deal with sparsity of data: (a) incorporating L 1 -regularization in the model training and (b) finding latent topics using LDA. We conducted extensive experiments on real data to evaluate our model. Our results are encouraging and show that the advertisability of queries can be estimated pretty accurately using their keywords only. We also compared different model estimation methods and study the effect of regularization, clustering, and training set selection. [1] A. Ashkan and C. Clarke. Characterizing commercial [2] A. Ashkan and C. Clarke. Term-based commercial [3] A. Ashkan, C. Clarke, E. Agichtein, and Q. Guo. [4] A. Ashkan, C. Clarke, E. Agichtein, and Q. Guo. [5] D. Blei, A. Ng, and M. Jordan. Latent dirichlet [6] A. Broder, M. Ciaramita, M. Fontoura, [7] A. Broder, P. Ciccolo, E. Gabrilovich, V. Josifovski, [8] J. Carrasco, D. Fain, K. Lang, and L. Zhukov. [9] D. Chakrabarti, D. Agarwal, and V. Josifovski. [10] H. Dai, L. Zhao, Z. Nie, J.-R. Wen, L. Wang, and [11] S. Deerwester. Improving information retrieval with [12] B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani. [13] T. Griffiths and M. Steyvers. Finding scientific topics. [14] W. Guo and G. Li. Predicting click rates by consistent [15] M. Gupta. Predicting click through rate for job [16] T. Hofmann. Probabilistic latent semantic indexing. In [17] I. Jolliffe. Principal Component Analysis .
 [18] A. Lacerda, M. Cristo, M. Goncalves, W. Fan, [19] W. Mendenhall and T. Sincich. A Second Course in [20] D. Montgomery, E. Peck, and G. Vining. Introduction [21] F. Radlinski, A. Broder, P. Ciccolo, E. Gabrilovich, [22] M. Regelson and D. Fain. Predicting click-through [23] B. Ribeiro-Neto, M. Cristo, P. Golgher, and [24] M. Richardson, E. Dominowska, and R. Ragno.
 [25] S. Shalev-Shwartz and A. Tewari. Stochastic methods [26] R. Tibshirani. Regression shrinkage and selection via [27] J. Yi and F. Maghoul. Query clustering using
