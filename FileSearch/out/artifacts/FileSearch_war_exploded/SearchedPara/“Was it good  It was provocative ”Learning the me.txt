 An important challenge for natural language pro-cessing is how to learn not only basic linguistic meanings but also how those meanings are system-atically enriched when expressed in context. For instance, answers to polar (yes / no) questions do not always explicitly contain a  X  X es X  or  X  X o X , but rather give information that the hearer can use to infer such an answer in a context with some degree of certainty. Hockey et al. (1997) find that 27% of answers to polar questions do not contain a direct  X  X es X  or  X  X o X  word, 44% of which they regard as failing to convey a clear  X  X es X  or  X  X o X  response. In some cases, interpreting the answer is straightfor-ward ( Was it bad? It was terrible. ), but in others, what to infer from the answer is unclear ( Was it good? It was provocative. ). It is even common for the speaker to explicitly convey his own uncer-tainty with such answers.

In this paper, we focus on the interpretation of answers to a particular class of polar ques-tions: ones in which the main predication in-volves a gradable modifier (e.g., highly unusual , not good , little ) and the answer either involves an-other gradable modifier or a numerical expression (e.g., seven years old , twenty acres of land ). Inter-preting such question X  X nswer pairs requires deal-ing with modifier meanings, specifically, learning context-dependent scales of expressions (Horn, 1972; Fauconnier, 1975) that determine how, and to what extent, the answer as a whole resolves the issue raised by the question.

We propose two methods for learning the knowledge necessary for interpreting indirect an-swers to questions involving gradable adjectives, depending on the type of predications in the ques-tion and the answer. The first technique deals with pairs of modifiers: we hypothesized that on-line, informal review corpora in which people X  X  comments have associated ratings would provide a general-purpose database for mining scales be-tween modifiers. We thus use a large collection of online reviews to learn orderings between adjec-tives based on contextual entailment ( good &lt; ex-cellent ), and employ this scalar relationship to in-fer a yes / no answer (subject to negation and other qualifiers). The second strategy targets numeri-cal answers. Since it is unclear what kind of cor-pora would contain the relevant information, we turn to the Web in general: we use distributional information retrieved via Web searches to assess whether the numerical measure counts as a posi-tive or negative instance of the adjective in ques-tion. Both techniques exploit the same approach: using texts (the Web) to learn meanings that can drive pragmatic inference in dialogue. This paper demonstrates to some extent that meaning can be grounded from text in this way. Indirect speech acts are studied by Clark (1979), Perrault and Allen (1980), Allen and Perrault (1980) and Asher and Lascarides (2003), who identify a wide range of factors that govern how speakers convey their intended messages and how hearers seek to uncover those messages from uncertain and conflicting signals. In the com-putational literature, Green and Carberry (1994, 1999) provide an extensive model that interprets and generates indirect answers to polar questions. They propose a logical inference model which makes use of discourse plans and coherence rela-tions to infer categorical answers. However, to ad-equately interpret indirect answers, the uncertainty inherent in some answers needs to be captured (de Marne ff e et al., 2009). While a straightforward  X  X es X  or  X  X o X  response is clear in some indirect an-swers, such as in (1), the intended answer is less certain in other cases (2): 1 (1) A: Do you think that X  X  a good idea, that we (2) A: Is he qualified?
In (2), it might be that the answerer does not know about qualifications or does not want to talk about these directly, and therefore shifts the topic slightly. As proposed by Zeevat (1994) in his work on partial answers, the speaker X  X  indirect answer might indicate that he is deliberately leaving the original question only partially addressed, while giving a fully resolving answer to another one. The hearer must then interpret the answer to work out the other question. In (2) in context, we get a sense that the speaker would resolve the issue to  X  X o X , but that he is definitely not committed to that in any strong sense. Uncertainty can thus reside both on the speaker and the hearer sides, and the four following scenarios are attested in conversa-tion: a. The speaker is certain of  X  X es X  or  X  X o X  and b. The speaker is certain of  X  X es X  or  X  X o X  but c. The speaker is uncertain of  X  X es X  or  X  X o X  and d. The speaker is uncertain of  X  X es X  or  X  X o X ,
The uncertainty is especially pressing for pred-ications built around scalar modifiers, which are inherently vague and highly context-dependent (Kamp and Partee, 1995; Kennedy and McNally, 2005; Kennedy, 2007). For example, even if we fix the basic sense for little to mean  X  X oung for a human X , there is a substantial amount of gray area between the clear instances (babies) and the clear non-instances (adults). This is the source of un-certainty in (3), in which B X  X  children fall into the gray area. (3) A: Are your kids little? Since indirect answers are likely to arise in in-terviews, to gather instances of question X  X nswer pairs involving gradable modifiers (which will serve to evaluate the learning techniques), we use online CNN interview transcripts from five dif-ferent shows aired between 2000 and 2008 (An-derson Cooper, Larry King Live, Late Edition, Lou Dobbs Tonight, The Situation Room). We also searched the Switchboard Dialog Act corpus (Jurafsky et al., 1997). We used regular expres-sions and manual filtering to find examples of two-utterance dialogues in which the question and the reply contain some kind of gradable modifier. 3.1 Types of question X  X nswer pairs In total, we ended up with 224 question X  X nswer pairs involving gradable adjectives. However our collection contains di ff erent types of answers, which naturally fall into two categories: (I) in 205 dialogues, both the question and the answer contain a gradable modifier; (II) in 19 dialogues, the reply contains a numerical measure (as in (3) above and (4)). Table 1: Types of question X  X nswer pairs, and counts in the corpus.
 Table 2: Mean entropy values and standard devi-ation obtained in the Mechanical Turk experiment for each question X  X nswer pair category. (4) A: Have you been living there very long?
Category I, which consists of pairs of modifiers, can be further divided. In most dialogues, the an-swer contains another adjective than the one used in the question, such as in (1). In others, the an-swer contains the same adjective as in the ques-tion, but modified by an adverb (e.g., very , basi-cally , quite ) as in (5) or a negation as in (6). (5) A: That seems to be the biggest sign of (6) A: Are you bitter? The negation can be present in the main clause when the adjectival predication is embedded, as in example (7). (7) A: [. . . ] Is that fair? In a few cases, when the question contains an ad-jective modifying a noun, the adjective is omitted in the answer: (8) A: Is that a huge gap in the system?
Table 1 gives the distribution of the types ap-pearing in the corpus. 3.2 Answer assignment To assess the degree to which each answer con-veys  X  X es X  or  X  X o X  in context, we use response dis-tributions from Mechanical Turk workers. Given a written dialogue between speakers A and B, Turk-ers were asked to judge what B X  X  answer conveys:  X  X efinite yes X ,  X  X robable yes X ,  X  X ncertain X ,  X  X roba-ble no X ,  X  X efinite no X . Within each of the two  X  X es X  and  X  X o X  pairs, there is a scalar relationship, but the pairs themselves are not in a scalar relationship with each other, and  X  X ncertain X  is arguably a sep-arate judgment. Figure 1 shows the exact formu-lation used in the experiment. For each dialogue, we got answers from 30 Turkers, and we took the dominant response as the correct one though we make extensive use of the full response distribu-tions in evaluating our approach. 2 We also com-puted entropy values for the distribution of an-swers for each item. Overall, the agreement was good: 21 items have total agreement (entropy of 0.0  X  11 in the  X  X djective X  category, 9 in the  X  X dverb-adjective X  category and 1 in the  X  X ega-tion X  category), and 80 items are such that a single response got chosen 20 or more times (entropy &lt; 0.9). The dialogues in (1) and (9) are examples of total agreement. In contrast, (10) has response en-tropy of 1.1, and item (11) has the highest entropy of 2.2. (9) A: Advertisements can be good or bad.
 (10) A: Am I clear? (11) A: 91 percent of the American people still Figure 1: Design of the Mechanical Turk experi-ment.

Table 2 shows the mean entropy values for the di ff erent categories identified in the corpus. Inter-estingly, the pairs involving an adverbial modifi-cation in the answer all received a positive answer ( X  X es X  or  X  X robable yes X ) as dominant response. All 19 dialogues involving a numerical measure had either  X  X robable yes X  or  X  X ncertain X  as domi-nant response. There is thus a significant bias for positive answers: 70% of the category I items and 74% of the category II items have a positive an-swer as dominant response. Examining a subset of the Dialog Act corpus, we found that 38% of the yes / no questions receive a direct positive an-swers, whereas 21% have a direct negative answer. This bias probably stems from the fact that people are more likely to use an overt denial expression where they need to disagree, whether or not they are responding indirectly. In this section, we present the methods we propose for grounding the meanings of scalar modifiers. 4.1 Learning modifier scales and inferring The first technique targets items such as the ones in category I of our corpus. Our central hypothesis is that, in polar question dialogues, the semantic relationship between the main predication P Q in the question and the main predication P A in the an-swer is the primary factor in determining whether, and to what extent,  X  X es X  or  X  X o X  was intended. If P
A is at least as strong as P Q , the intended answer is  X  X es X ; if P A is weaker than P Q , the intended an-swer is  X  X o X ; and, where no reliable entailment re-lationship exists between P A and P Q , the result is uncertainty.

For example, good is weaker (lower on the rel-evant scale) than excellent , and thus speakers in-fer that the reply in example (1) above is meant to convey  X  X es X . In contrast, if we reverse the order of the modifiers  X  roughly, Is it a great idea? ; It X  X  a good idea  X  then speakers infer that the answer conveys  X  X o X . Had B replied with It X  X  a complicated idea in (1), then uncertainty would likely have resulted, since good and complicated are not in a reliable scalar relationship. Negation reverses scales (Horn, 1972; Levinson, 2000), so it flips  X  X es X  and  X  X o X  in these cases, leaving  X  X ncer-tain X  unchanged. When both the question and the answer contain a modifier (such as in (9 X 11)), the yes / no response should correlate with the extent to which the pair of modifiers can be put into a scale based on contextual entailment.

To ground such scales from text, we collected a large corpus of online reviews from IMDB. Each of the reviews in this collection has an associated star rating: one star (most negative) to ten stars (most positive). Table 3 summarizes the distribu-tion of reviews as well as the number of words and vocabulary across the ten rating categories.
As is evident from table 3, there is a signif-icant bias for ten-star reviews. This is a com-mon feature of such corpora of informal, user-provided reviews (Chevalier and Mayzlin, 2006; Hu et al., 2006; Pang and Lee, 2008). However, since we do not want to incorporate the linguis-tically uninteresting fact that people tend to write a lot of ten-star reviews, we assume uniform pri-ors for the rating categories. Let count( w, r ) be the number of tokens of word w in reviews in rat-ing category r , and let count( r ) be the total word count for all words in rating category r . The prob-ability of w given a rating category r is simply Pr( w | r ) = count( w, r ) / count( r ). Then under the assumption of uniform priors, we get Pr( r | w ) = Pr( w | r ) / P r 0  X  R Pr( w | r 0 ).

In reasoning about our dialogues, we rescale the rating categories by subtracting 5 . 5 from each, to center them at 0. This yields the scale R = Figure 3: Decision procedure for using the word frequencies across rating categories in the review corpus to decide what a given answer conveys. described in figure 3. 4.2 Interpreting numerical answers The second technique aims at determining whether a numerical answer counts as a positive or negative instance of the adjective in the ques-tion (category II in our corpus).

Adjectives that can receive a conventional unit of measure, such as little or long , inherently pos-sess a degree of vagueness (Kamp and Partee, 1995; Kennedy, 2007): while in the extreme cases, judgments are strong (e.g., a six foot tall woman can clearly be called  X  X  tall woman X  whereas a five foot tall woman cannot), there are borderline cases for which it is di ffi cult to say whether the adjectival predication can truthfully be ascribed to them. A logistic regression model can capture these facts. To build this model, we gather distri-butional information from the Web.

For instance, in the case of (3), we can retrieve from the Web positive and negative examples of age in relation to the adjective and the modified en-tity  X  X ittle kids X . The question contains the adjec-tive and the modified entity. The reply contains the unit of measure (here  X  X ear-old X ) and the numer-ical answer. Specifically we query the Web using Yahoo! BOSS (Academic) for  X  X ittle kids X  year-old (positive instances) as well as for  X  X ot little kids X  year-old (negative instances). Yahoo! BOSS is an open search services platform that provides a query API for Yahoo! Web search. We then ex-tract ages from the positive and negative snippets obtained, and we fit a logistic regression to these data. To remove noise, we discard low counts (positive and negative instances for a given unit &lt; 5). Also, for some adjectives, such as little or young , there is an inherent ambiguity between ab-solute and relative uses. Ideally, a word sense dis-ambiguation system would be used to filter these cases. For now, we extract the largest contiguous range for which the data counts are over the noise threshold. 3 When not enough data is retrieved for the negative examples, we expand the query by moving the negation outside the search phrase. We also replace the negation and the adjective by the antonyms given in WordNet (using the first sense).
The logistic regression thus has only one fac-tor  X  the unit of measure (age in the case of lit-tle kids ). For a given answer, the model assigns a probability indicating the extent to which the ad-jectival property applies to that answer. If the fac-tor is a significant predictor, we can use the prob-abilities from the model to decide whether the an-swer qualifies as a positive or negative instance of the adjective in the question, and thus interpret the indirect response as a  X  X es X  or a  X  X o X . The prob-abilistic nature of this technique adheres perfectly to the fact that indirect answers are intimately tied up with uncertainty. Our primary goal is to evaluate how well we can learn the relevant scalar and entailment relation-ships from the Web. In the evaluation, we thus ap-plied our techniques to a manually coded corpus version. For the adjectival scales, we annotated each example for its main predication (modifier, or adverb X  X odifier bigram), including whether that predication was negated. For the numerical cases, we manually constructed the initial queries: we identified the adjective and the modified entity in the question, and the unit of measure in the answer. However, we believe that identifying the requisite predications and recognizing the presence of nega-tion or embedding could be done automatically us-ing dependency graphs. 4 Table 4: Summary of precision and recall (%) by type.
 Table 5: Precision, recall, and F1 (%) per response category. In the case of the scalar modifiers exper-iment, there were just two examples whose dom-inant response from the Turkers was  X  X ncertain X , so we have left that category out of the results. In the case of the numerical experiment, there were not any  X  X o X  answers.

To evaluate the techniques, we pool the Me-chanical Turk  X  X efinite yes X  and  X  X robable yes X  categories into a single category  X  X es X , and we do the same for  X  X efinite no X  and  X  X robable no X . Together with  X  X ncertain X , this makes for three-response categories. We count an inference as successful if it matches the dominant Turker re-sponse category. To use the three-response scheme in the numerical experiment, we simply catego-rize the probabilities as follows: 0 X 0.33 =  X  X o X , 0.33 X 0.66 =  X  X ncertain X , 0.66 X 1.00 =  X  X es X .
Table 4 gives a breakdown of our system X  X  per-formance on the various category subtypes. The overall accuracy level is 71% (159 out of 224 in-ferences correct). Table 5 summarizes the results per response category, for the examples in which both the question and answer contain a gradable modifier (category I), and for the numerical cases (category II). Performance is extremely good on the  X  X dverb  X  same adjective X  and  X  X egation  X  same adjective X  cases because the  X  X es X  answer is fairly direct for them (though adverbs like basically introduce an interesting level of uncertainty). The results are Table 6: Precision, recall, and F1 (%) per response category for the WordNet-based approach. somewhat mixed for the  X  X ther adjective X  cate-gory.

Inferring the relation between scalar adjectives has some connection with work in sentiment de-tection. Even though most of the research in that domain focuses on the orientation of one term us-ing seed sets, techniques which provide the ori-entation strength could be used to infer a scalar relation between adjectives. For instance, Blair-Goldensohn et al. (2008) use WordNet to develop sentiment lexicons in which each word has a posi-tive or negative value associated with it, represent-ing its strength. The algorithm begins with seed sets of positive, negative, and neutral terms, and then uses the synonym and antonym structure of WordNet to expand those initial sets and refine the relative strength values. Using our own seed sets, we built a lexicon using Blair-Goldensohn et al. (2008) X  X  method and applied it as in figure 3 (changing the ER values to sentiment scores). Both approaches achieve similar results: for the  X  X ther adjective X  category, the WordNet-based approach yields 56% accuracy, which is not signif-icantly di ff erent from our performance (60%); for the other types in category I, there is no di ff erence in results between the two methods. Table 6 sum-marizes the results per response category for the WordNet-based approach (which can thus be com-pared to the category I results in table 5). However in contrast to the WordNet-based approach, we re-quire no hand-built resources: the synonym and antonym structures, as well as the strength values, are learned from Web data alone. In addition, the WordNet-based approach must be supplemented with a separate method for the numerical cases.
In the  X  X ther adjective X  category, 31 items involve oppositional terms: canonical antonyms (e.g., right / wrong , good / bad ) as well as terms that are  X  X tatistically oppositional X  (e.g., ready / premature , true / preposterous , confident / nervous ).  X  X tatistically oppositional X  terms are not opposi-tional by definition, but as a matter of contingent fact. Our technique accurately deals with most of the canonical antonyms, and also finds some contingent oppositions ( qualified / young , wise / neurotic ) that are lacking in antonymy resources or automatically generated antonymy lists (Moham-mad et al., 2008). Out of these 31 items, our tech-nique correctly marks 18, whereas Mohammad et al. X  X  list of antonyms only contains 5 and Blair-Goldensohn et al. (2008) X  X  technique finds 11. Our technique is solely based on unigrams, and could be improved by adding context: making use of de-pendency information, as well as moving beyond unigrams.

In the numerical cases, precision is high but re-call is low. For roughly half of the items, not enough negative instances can be gathered from the Web and the model lacks predictive power (as for items (4) or (12)). (12) A: Do you happen to be working for a
Looking at the negative hits for item (12), one sees that few give an indication about the num-ber of people in the firm, but rather qualifications about colleagues or employees ( great people , peo-ple X  X  productivity ), or the hits are less relevant:  X  X ost of the people I talked to were actually pretty optimistic. They were rosy on the job market and many had jobs, although most were not large firm jobs X . The lack of data comes from the fact that the queries are very specific, since the adjec-tive depends on the product (e.g.,  X  X xpensive ex-ercise bike X ,  X  X eep pond X ). However when we do get a predictive model, the probabilities corre-Figure 5: Correlation between agreement among Turkers and whether the system gets the correct answer. For each dialogue, we plot a circle at Turker response entropy and either 1 = correct inference or 0 = incorrect inference, except the points are jittered a little vertically to show where the mass of data lies. As the entropy rises (i.e., as agreement levels fall), the system X  X  inferences be-come less accurate. The fitted logistic regression model (black line) has a statistically significant co-e ffi cient for response entropy (p &lt; 0 . 001). late almost perfectly with the Turkers X  responses. This happens for 8 items:  X  X xpensive to call (50 cents a minute) X ,  X  X ittle kids (7 and 10 year-old) X ,  X  X ong growing season (3 months) X ,  X  X ot of land (80 acres) X ,  X  X arm weather (80 degrees) X ,  X  X oung kids (5 and 2 year-old) X ,  X  X oung person (31 year-old) X  and  X  X arge house (2450 square feet) X . In the latter case only, the system output (uncer-tain) doesn X  X  correlate with the Turkers X  judgment (where the dominant answer is  X  X robable yes X  with 15 responses, and 11 answers are  X  X ncertain X ).
The logistic curves in figure 4 capture nicely the intuitions that people have about the relation be-tween age and  X  X ittle kids X  or  X  X oung kids X , as well as between Fahrenheit degrees and  X  X arm weather X . For  X  X ittle kids X , the probabilities of be-ing little or not are clear-cut for ages below 7 and above 15, but there is a region of vagueness in be-tween. In the case of  X  X oung kids X , the probabil-ities drop less quickly with age increasing (an 18 year-old can indeed still be qualified as a  X  X oung kid X ). In sum, when the data is available, this method delivers models which fit humans X  intu-itions about the relation between numerical mea-sure and adjective, and can handle pragmatic in-ference.

If we restrict attention to the 66 examples on which the Turkers completely agreed about which of these three categories was intended (again pool-ing  X  X robable X  and  X  X efinite X ), then the percent-age of correct inferences rises to 89% (59 cor-rect inferences). Figure 5 plots the relation-ship between the response entropy and the accu-racy of our decision procedure, along with a fit-ted logistic regression model using response en-tropy to predict whether our system X  X  inference was correct. The handful of empirical points in the lower left of the figure show cases of high agreement between Turkers but incorrect infer-ence from the system. The few points in the up-per right indicate low agreement between Turk-ers and correct inference from the system. Three of the high-agreement / incorrect-inference cases involve the adjectives right  X  correct . For low-agreement / correct-inference, the disparity could trace to context dependency: the ordering is clear in the context of product reviews, but unclear in a television interview. The analysis suggests that overall agreement is positively correlated with our system X  X  chances of making a correct inference: our system X  X  accuracy drops as human agreement levels drop. We set out to find techniques for grounding ba-sic meanings from text and enriching those mean-ings based on information from the immediate lin-guistic context. We focus on gradable modifiers, seeking to learn scalar relationships between their meanings and to obtain an empirically grounded, probabilistic understanding of the clear and fuzzy cases that they often give rise to (Kamp and Partee, 1995). We show that it is possible to learn the req-uisite scales between modifiers using review cor-pora, and to use that knowledge to drive inference in indirect responses. When the relation in ques-tion is not too specific, we show that it is also pos-sible to learn the strength of the relation between an adjective and a numerical measure.
 This paper is based on work funded in part by ONR award N00014-10-1-0109 and ARO MURI award 548106, as well as by the Air Force Re-search Laboratory (AFRL) under prime contract no. FA8750-09-C-0181. Any opinions, findings, and conclusion or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of the Air Force Re-search Laboratory (AFRL), ARO or ONR.

