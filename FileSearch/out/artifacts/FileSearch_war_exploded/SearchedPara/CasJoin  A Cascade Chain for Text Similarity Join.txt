 We are concerned with the problem of similarity joins of text data, where the task is to find all pair s of documents above an expected similarity. Such a problem often serves as an indispensable step in many web applications. A crucial issue is to preclude unnecessary candidate pairs as many as possibl e ahead of expensive similarity evaluation. In this paper, we in itiate an idea of adopting a cascade structure in text joins for a large speedup, where a latter stage can exclude a considerable number of i nvalid pairs survived in former stages. The proposed algorithm is shortly referred to as CasJoin . We further adopt a prefix filter to build the stage of CasJoin by introducing a novel vision to the dynamic generation of document vector. Specifically, a vector is partitioned into a chain of multiple prefixes that are appended one by one for cascade joining. We evaluate our CasJoin on a typical web corpus, ODP . Experiments indicate that, comparing to the state-of-the-art prefix algorithms, CasJoin can achieve a drastic reduction of candidates by as much as 98.15% and a dramatic speedup of joining by up to 13.34x. [ Database Management ]: Database Applications  X  Data Mining ; General Terms : Algorithms, Experimentation Keywords : Similarity search, Similarity joins, Prefix filtering, Cascade filtering, Duplicate detection Many web applications involve the problem of similarity joins as an important intermediate step, where they need to find all pairs of objects with the similarity above a given threshold [1, 2, 3]. The applications that rely on similarity joins need to deal with a great variant of free text. A text documen t is in most cases represented as a real-valued vector resided in a high dimensional space. As such, the problem on similarity joins of text data amounts to joining all pairs of vectors above a specified similarity threshold. In this paper, we initiate an idea of applying a cascade structure to similarity joins of text data for a large speedup. In such a structure, a positive decision from a former stage triggers the evaluation of a latter stage, while a negative decision made at any stage leads to the immediate rejection of the pair. An effective stage-wise filter could exclude a considerable number of invalid pairs survived in previous stages. The resulting algorithm is termed as CasJoin for short. In order to build the stage filter of CasJoin , we choose a prefix-based method by introducing a novel vision to a document vector in prefix conjunction. Specifically, a vector is iteratively segmented into a chain of consecutive prefixes, each of which is appended one by one for cascade joining in their turns. Prefix filtering . We choose prefixed-based processor as the stage filter of CasJoin . In essence, prefix filtering is an indexing-based method, but it only builds a partial indexing for all vectors. The exactness is guaranteed by a prefix principle [2]: if the similarity between two vectors could surpass a given threshold, they must agree at least one element in their prefixes; otherwise their similarity is by no means large enough . An immediate advantage of prefix filtering over full indexing is that it could further purge all pairs without any common elemen ts in prefixes even if they have many agreeing elements in suffixes. Some work followed up to raise the speed of prefix filtering. First, the metric symmetry [4] is exploited to build a dynamic i ndexing of prefix elements. Such a dynamic indexing allows a vector to hit the candidates only from the  X  already indexed  X  ones. Second, an upper bound [4] called remscore is utilized to abandon the pairs sharing none of  X  already processed  X  elements. Cascade Structure . To our knowledge, our work is the first effort to apply a cascade chain to the problem of similarity joins. In fact, our idea is largely inspired by its great success in the community of face detection [5, 6]. In earlier work [7], we also present a FloatCascade algorithm for fast classification in imbalanced web mining by developing a cascade ch ain for citation matching and web page categorization. In essen ce, similarity joins is also a typical unbalanced problem in that there are usually a very small number of valid pairs among all possible ones. Considering the analogy between the learning and joining problem in the sense of imbalance nature, we are motivated to pursue a new algorithm for similarity joins of text data based on the cascade principle, where a vast number of false candidates are discarded stage by stage. In order to apply a cascade chain to the task of similarity joins, we introduce a dynamic vision to document vector in terms of prefix conjunction. The prefix of a vector particularly refers to its first several elements. (At this time, the elements are usually sorted in order of their weights or frequencie s). In pervious research [4, 8], the prefix has demonstrated its dis tinct value to similarity joins for the purpose of throwing away invalid candidates sharing no prefix elements. Yet, prefix filtering is ha rdly scalable to a large dataset on the web [8]. It is mainly due to the fact that one round of prefix filtering could only rule out a decent number of false pairs. In this work, we exert the value of prefix filtering maximally by means of encapsulating it in a cascade chain of stage processors. Figure 1. A dynamic vision to a pl urality of prefixes in vectors. For that, a vector can be iteratively segmented into a sequence of multiple prefixes for similarity joins. For illustration, a set of n vectors with their prefixes are depicted in Figure 1. Take a look at the first vector; p 11 is its first prefix relativ e to all of its elements. Assume that p 11 were removed from the vector, p 12 could then be taken as the prefix of all remaining elements. The process repeats until the last one p 1a , which is inclusive of several tailing elements. With such a segmentation process, a vector could now be seen to be composed of a certain number of prefixes instead of elements themselves. It is important to em phasize that: 1) there would be an unequal number of prefixes in each vector; and 2) there would be an unequal number of elements in each prefix. As will be shown, both the number of prefixes and the length of each prefix are determined in CasJoin automatically. We show how a prefix filtering c ould be integrated into a cascade chain exactly, and how a cascade chain could speed up joins greatly based only on simple stage filters. The algorithm of CasJoin is described in Figure 2, where two specializations are initially made for simplicity. Specifically, we adopt the cosine distance as similarity metric a nd develop only a two-level cascade structure. On the whole, CasJoin consists of two indispensable processes including matching and indexing . The former verifies the candidacy of all pairs for a current vector x and only returns the qualified ones in O . The latter divides x into a sequence of prefixes and stores each of them into the respective inverted list, namely A or CA . Prefix conjunction . In CasJoin , the building of cascade chain is fully automatic over a large set of vectors. For a vector, it could adaptively determine which elements fall into the 1 st prefix, which ones fall into the 2 nd prefix, and so on. As can be seen in Figure 4, the indexing loop iterates over the elements of x from most to least frequent, and avoids indexing any elements until reaching a particular condition b  X  tr . b is the upper bound maintained on the score attainable by matching the processed elements of x against the prefixes of the vectors that have already been indexed. tr is the similarity threshold t * r for the 2 nd stage. During the process of indexing, the elements indexed for x first constitute its 2 further, if b  X  t , the elements switch to the 1 st prefix. The length of the prefixes for a vector is determ ined just in this automatic way. Note that those stop elements in vectors are discarded or reserved automatically during the course of prefix conjunction. Cascade indexing . In CasJoin , the indexing of vector elements follows a stage-wise manner, wher e a specific inverted list is built for a specific stage on top of the corresponding prefixes. In Figure 4, there are actually two inverted lists, including { I 1 { p 11 , p 21 , ..., p n1 } and { CI 1 , CI 2 , ..., CI Although it is possible to integrate the two lists into a unique one using some tricks (say, marking each element to designate that it the sake of a direct prefix access and a clear algorithm structure. Figure 2. The algorithm of cascad e joining for similarity joins. Candidate merging . In CasJoin , a false pair might pass a former stage by luck; but it stands a good chance of being exposed by the latter stage. In principle, in a cascade chain, there is always a stage to exclude a false pair, so expensive similarity evaluation on it is avoided. The results of filtering th e pairs at all stages ought to be merged together to discern the candidacy of each pair. In Figure 4, there are only two stages and their joining results are incorporated into the 1 st stage. In the end, CasJoin could remove significantly more pairs from A with the clues from CA than those discarded by the 1 st stage per se. The merging of th e joining results is as below. For two vectors, say x and y , CasJoin gets their partial scores from A CasJoin investigates whether two conditions are met. If s it means that the similarity between x and y is impossible to be above tr by having their first prefixes removed. It follows that the similarity between them has no way to exceed t if s 1 &lt; t-tr . At this time, the pair candidacy of x and y can be rejected safely from A . It is this form of cas cade filtering that drives CasJoin to efficiently eliminate a great number of false pairs survived in former stages. Notably, if any of the two conditions fail (i.e., s 1  X  t -tr or s All of these pairs are reserved for the subsequent stages and their partial scores in A should be instantly updated as s 1 For experiment, we use a ty pical web dataset, namely ODP [9] by considering the fact that web page is probably the most popular text type on the web. An efficient similarity joins of web pages is very promising in many web appli cations for further development. Such applications typically include duplicate detection, clustering and classification, to name a few. The details of ODP dataset are summarized in Table 1, n denotes the number of vectors while m denotes the dimension of the vector space; all_l denotes the total length of all vectors while ave_l denotes the average length. For comparison, two state-of-the-art variants of prefix filtering are implemented. The first va riant is referred to as P1 for short, which integrates prefix filtering and dynamic indexing. The second is P2 , which further maintains the upper bound of remscore in P1 [4]. After that, P1 and P2 are used as the stage filter for CasJoin , and the corresponding variants are named as C1 and C2 respectively. In this section, we conduct a series of trend analysis for CasJoin , and study the effect of data size, similarity threshold and cascade level on its efficiency. Figure 3. The number of pairs to the ratio of data size (t=0.9). We first study the effect of data size on the joining efficiency. For that, the ODP dataset is uniformly scal ed down with an increasing ratio from 0.1 to 1. With uniform data sampling, each sub-dataset could remain approximately the sa me distribution to the original data. As will be discussed in S ection 4.3.3, such a uniform down-sampling is also prepared for searching a proper cascade ratio. Figure 4. The time of joining to the ratio of data size (t=0.9). P1 , P2 , C1 and C2 are implemented on the 10 sub-datasets in turn. Figure 3 reports the number of candidate pairs on each sub-dataset at the threshold of 0.9. We can find that: 1) The P2 curve always locates on top of the P1 curve. The same situation also happens for C2 versus C1 . It hints that remscore really aids in discarding more candidates in both cascade-based and non-cascade methods. The refinement from such small tricks is favorably reserved in the cascade structure. 2) P2 and P1 are very close to each other in their curves. It indicates that only a limited number of pairs share no  X  X lready processed X  elements. 3) C2 and C1 almost overlap each other in their curves. It again indicates that the improvement from the cascade structure plays an overwhelming role and the refinement from remscore is too trivial to make sense. It is not surprising that all 4 me thods produce more candidates as the data size increases since there are generally more valid pairs on a larger data. However, the cascad e methods distinguish from their non-cascade counterparts in the increase speed of yielding the candidates. The candidates in P1 and P2 grow at an explosive rate (almost quadratically). As a resu lt, the non-cascade methods are hard much slower growth (almost linear ly). Figure 4 reports the running time of P1 , P2 , C1 and C2 on the 10 sub-datasets of ODP . As can be seen, the increasing trend of joini ng time keeps much consistent to that of candidate pairs for each algorithm. In general, on each subset of ODP , C1 and C2 requires significantly less time than P1 and P2 to obtain all qualified pairs. CasJoin demonstrates its distinct capability for the task of similarity joins in comparison to the non-cascade methods. Next, we compare all four algorithms at the threshold of 0.5. The curves of candidate number and jo ining time are plotted in Figure 7 and 8 respectively. This time, we could draw similar conclusion to the previous trials for 0.9. Th e trend consistency between two groups of trails lends credible evidence that, for an algorithm of similarity joins, its efficiency indeed depends much on how many false pairs are precluded before dir ect cosine computation. In the following, we thus focus more on the reduction of candidate pairs when comparing the joining efficiency of all four algorithms. In this section, we study the effect of similarity threshold on the joining efficiency. Very often, diffe rent applications need to make use of similar pairs with different degrees. For the applications of duplicate detection, the threshold might be 0.9 and even higher. For the applications of classifi cation and clustering, however, the threshold might be merely 0.5 or even lower, since they mostly build their models based only on re levant documents. We are just interested in whether CasJoin could retain its efficiency across a wide range of similarity thresholds. Figure 5. The number of pairs to the similarity threshold. For experiment, the similarity thre shold is tuned from 0.50 to 0.95, increased by 0.05 each time. We then perform P1 , P2 , C1 and C2 under these 10 thresholds. Figure 5 de picts the results of 40 trials. It is not surprised that all four algorithms generate more candidate pairs as the threshold decreases gradually since there are generally more valid pairs for a smaller th reshold. Nevertheless, the cascade methods of C1 and C2 could consistently throw away a very large number of false candidates in the non-cascade methods of P1 and P2 . CasJoin demonstrates its distinct power in removing invalid candidates using a cascade structure of prefix filtering. In the end, the overall joining time is reduced dr astically and the efficiency of similarity joins is increased greatly. Finally, we study the effect of cascade level on the efficiency of CasJoin . For this, we further develop three-level, four-level and five-level cascade chain of prefix filtering based on stage filters of P1 . The cascade ratio for the three latte r stages is simply set to be the same as the 2 nd stage. The merging process of all stages is just conducted as follows: the results at the 1 st and 2 merged into the 1 st one, the 1 st and 3 rd stages into the 1 so on. Finally, the results from all stages are fused into the 1 stage alone. Note that the optimal number of levels in the cascade chain could also be learned by building a small training data. Table 2. The number of candidate pairs to the cascade level. We first conduct two groups of trails, with t equal to 0.9 and 0.5 respectively. The experiment resu lts are reported in Table 2. We can see that: 1) a large majority of candidate pairs are removed by multiple-level cascade structure of prefix filtering. The number of invalid candidates is reduced by up to 39.11x and 53.93x. 2) The efficiency of CasJoin is increased more aggressively. The time of joining all pairs is reduced by as much as 10.57x and 13.34x. 3) We also compare the number of candidates in a latter stage to that in a former stage in the s econd column. As seen, the 2 nd rid of the most unnecessary candida tes than all subsequent stages. In many cases, a two-level cascade structure suffices to achieve a satisfactory efficiency for the task of similarity joins. Further, we compare the size of inverted lists at all stages in Table 3. It can be seen that the size generally renders a decreasing trend. But, the three latter stages build an approximately the same size of indexing. It is mainly because the prefixes indexed by them have about the same TFIDF weights. As a whole, the latter four stages require much less memory for indexing the prefixes than the 1 CasJoin does not sacrifice too much extra memory, but it improves the joining efficiency substantially. In this paper, we introduce a dyna mic vision to vector generation in prefix conjunction and present a cascad e chain of prefix filters for an efficient and scalable similarity joins of text data. The new algorithm is referred to as CasJoin , which is a general framework in that it can admit any variant method based on prefix filtering as stage filter for building a cascade chain to join all e xpected pairs. In such a chain, prefix filtering is iteratively performed at multiple rounds, and a latter stage could exclude a considerable number of invalid pairs survived in former stages. A pair of two vect ors is determined to be a candidate only if it escapes the filtering of all st ages. In the end, a large majority of false pairs are excluded and dir ect similarity computation on them is avoided. We evaluate the efficiency of CasJoin on a variety of text datasets. Experimental results indicate that, comparing to prefix filtering, CasJoin could achieve a great reduction of candidates by as much as 98.15% and a large speedup of joining by up to 13.34x. 
