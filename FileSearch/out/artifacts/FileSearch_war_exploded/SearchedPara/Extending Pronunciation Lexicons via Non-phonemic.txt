 Speech recognition (SR) systems use pronunci a-tion lexicons to map words into the phoneme -like units used for acoustic modeling. Text -to -speech (TTS) systems also make use of pronunciation lexicons, both internally and as  X  X xception dictio n-aries X  meant to override the systems X  internal grapheme -to -phoneme (G2P) convertors. There are many situations where users might want to au g-ment the pronunciation lexicons of SR and TTS sys tems, ranging from minor fixes, such as adding a few new words or alternate pronunciations for existing words, to significant development efforts, such as adapting a speech syste m to a specialized domain, or developing speech systems for new languages by bootstrapping from small amounts of data (Kominek et al. , 2008).

Unfortunately, extending the pronunciation lex i-con (PL) is not an easy task . Getting e xpe rt help is usually impractical, yet users have little or no su p-port if they want to tackle the job themselves. Where available, the user has to either know how to transcribe a word X  X  pronunciation into the appl i-ca tion X  X  underlying phone set, or, in rare cases, use pronuncia tion -by -orthography, whereby word pr o-nunciations are respelled using other words (e.g.,  X  Thailand X  is pronounced like  X  tie land X  ) . The former method requires a certain skill that is clearly beyond the capabilities of the average user; the latter is extreme ly limited in scope.

What is needed is a method that would make it easy for the users to specify pronunciations the m-selves, without re quiring them to be or become expert phoneticians. In this paper we will argue  X  with backing from some preliminary experime nts  X  that non -phonemic respell lings might be an acce s-sible intermediate representation that will allow speech systems to learn pronunciations directly from user input faster and more accurately. A utomatic G2P conversion seems the ideal tool to help users with PL expansion . The user would be shown a ranked list of automatically derived pr o-nunciations and would have to pick the correct one . To make such a system more user -friendly, a synthesized wave form could al so be presented (Davel and Barnard, 2004; also Kominek et al. , 2008). This approach has a major drawback: if the system X  X  choices are all wrong  X  which is, in fact, to be expected, if the number of choices is small  X  the user would have to provide their ow n pronu n-ciation by using the system X  X  phonetic alphabet. In our opinion this precludes the approach from being used by non -specialists.

Other systems try to learn pronunciations only from user -provided audio samples , via speech re c-ognition/alignment (Beaufays et al ., 2003; see also Bansal et al ., 2009 and Chung et al. , 2004) . In such systems G2P conversion may be used to constrain choices , thereby overcoming the notoriously poor phone -level recognition performance . For example, Beaufays et al . (2003) focused on a directory assi s-tance SR task, with many out -of -vocabulary proper names. Their procedure works by initializing a h y-pothesis by G2P conversion, and thereafter refi n-ing it with hypotheses from the joint alignment of phone lattices obtained from a udio samples and the current best hypothesis. Several transformation rules were employed to expand the search space of alternative pronunciations. 
While audio -based pronunciation learning may appear to be more user -friendly, it actually suffers from being a slow approach, with many audio sample s being needed to achieve reasonable pe r-formance (the studies cited used up to 15 samples). It is also unclear whether the pronunciations learned are in fact correct, since the approach was mostly used to help increa se the performance of a SR system . The SR performance improvements ( ranging from 40% to 74%) must be due to better pronunciations, but we are not aware of the exi s-tence of any correctness evaluations . The method proposed here is a imed at allowing users to directly indicate the pronunciation of a word via non -phonemic respellings (NPRs). With NPRs, a word X  X  pronunciation is represented a c-cording to the ordinary spelling rules of English, without attempting to represent each sound wi th a unique symbol. For example, the pronunciation of the word phoneme could be indicated as \ FO -neem \ , where capitalization indicates stress (boldface, u n-derlining, and the apostrophe are also used as stress markers). It is often possible to come up with different respellings, and, indeed, systematicity is not a goal here; rather, the goal is to convey info r-mation about pronunciation using familiar spel l-ing -to -sound rules, with no special training or tables of unfamiliar symbols.

NPRs are used to indicate the pronunciation of unfamiliar or difficult words by news organizations (mostly for foreign names), the United States Phar -macopoeia (for drug names), as well as countless interest groups (astronomy, horticulture, philos o-phy , etc.). Lately, Merriam -Webster Online 1 has started using NPRs in their popular Word of the Day 2 feature. Here is a recent example: While NPRs seem to be used by a fairly wide range of audiences, we must n X  X  assume that most people are familiar with them. What we do know, however, is that people can learn new pronunci a-tions faster and with fewer errors from NPRs than from phonemic transcriptions and this holds true whether they are linguistically -trained or not (Fraser, 1997). We contend, based o n preliminary observations, that not only are NPRs easily d e-coded, but people seem to be able to produce rel a-tively accurate NPRs, too. Our vision is that speech applications would e m-ploy user -provided NPRs as an additional source of informat ion besides orthography, and use ded i-cated NPR -to -pronunciation (N2P) models to d e-rive hypotheses about the correct pronunciation. 
However, before embarking on this project, we ought to answer three questions: 1. Is generic knowledge about grapheme -to -2. Are pronunciation respellings useful in obtai n-3. Since we don X  X  require that average users learn In the following we try to answer experimentally the technical counterparts of the first two que s-tions, and report results of a small study designed to answer the third one. 4.1 Data and models
We collected a corpus of 2730 words with a t o-tal of 2847 NPR transcriptions (some words have multiple NPRs) from National Cancer Institute X  X  Dictionary of Cancer Terms. 3 The dictionary co n-tains over 4000 medical terms. Here are a couple of entries (without the definitions):
Of the 2730 words, 1183 appear in the CMU dictionary (Weide, 1998)  X  w e X  X l call this the ID set. Of note, about 180 words were not truly in -dictionary; for example, Versed (a drug brand name), pronounced \ V ER0 S EH1 D \ , is different from the in -dictionary word versed , pronounced \ V ER1 S T \ . We manually aligned all NPRs in the ID set wit h the phonetic transcriptions.

We transcribed phonetically another 928 of the words  X  we X  X l call this the OOD set  X  not found in the CMU dictionary; we verified the phonetic tra n-scriptions against the Merriam -Webster Online Medical Dictionary and the New O xford American Dictionary (McKean, 2005). 
For G2P conversion we used a joint 4 -gram model (Galescu, 2001) trained on automatic align ments for all entries in the CMU dictiona ry. We note that joint n -gram models seem to be among the best G2P models availabl e (Polyakova and Bonafonte, 2006; Bisani and Ney, 2008). 4.2 Adequacy of generic G2P models To answer the first question above, we looked at whether the generic joint 4 -gram G2P model is adequate for converting NPRs into phonemes. 
At first, it appeared that the answer would be negative. We found out that NPRs use GP corr e-spondences that do not exist or are extremely rare in the CMU dictionary. For example, the &lt;[ ih ], \ IH \ &gt; correspondence is very infrequent in the CMU dictionary (and appears only in proper names, e.g., Stihl ) , but is very frequently used in NPRs. Therefore, for the [ ih ] grapheme the G2P converter prefers \ IH HH \ to the intended \ IH \ . Similar problems happen because of the way some diphones are t ranscri bed. T wo other peculiarities of the transcription accounted for other errors : a) always preferring / S / in plurals where / Z / would be required , and b) using [ ayr ] to transcribe \ EH R \ , which use s the very rare &lt;[ ay ], \ EH \ &gt; mapping . These deviations from ordinary GP corre spo n-dences occur with regularity and therefore we were able to fix them with four post -processing rules. We are confident that these rules capture specific choices made during the compilation of the Di c-tionary of Cancer Terms, to reduce ambiguity, and incr ease consistency, with the expectation that readers would learn to make the correct phonological choices when reading the respellings.
Another issue was that the set of GP mappings used in NPRs was extremely small (111) compared to the GP correspondence set obtained automat i-cally from the CMU dictionary (1130, many of them occurring only in proper names). However, it turns out that 47524 entries in the CMU dictionary (about 45%) use exclusively GP mappings found in NPRs! This suggests that , while the generic G2P model may not be adequate for the N2P task, the GP mappings used in NPRs are sufficiently co m-mon that a more adequate N2P model c ould be built from generic dictionary entries by selecting only relevant entries for training. Unfortunately we don X  X  have a full account of all  X  X xotic X  entries in the CMU dictionary, but we expect that by simply removing from the training data the approx imately 54K known proper names will yield a reasonable starting point for building N2P models. 4.3 NPR -to -pronunciation conversion To assess the contribution of NPR information to pronunciation prediction, we compare the perfor m-ance of spelling -to -pronunciatio n conversion (the baseline) to that of NPR -to -pronunciation conve r-sion, as well as to that of a combined spelling and NPR -based conversion, which is our end goal.
For the N2P task, we trained two j oint 4 -gram model s: one based on the aligned NPRs , and a se c-ond based on the 47K CMU dictionary entries that use only GP mappings found in NPRs. Then , we interpolated the two models to obtain an NPR -specific model (the weights were not optimized for the se experiments ), which we X  X l call the N2P model. The combined, spelling and NPR -based model was an oracle combination of the G2P and the N2P model. Phone error rates (PER) and word error rates (WER) for both the ID set and the OOD set are shown in Figures 1 and 2, respectively. We obtained n -best pronunciations with n from 1 to 10 for the three models considered.

As expected, G2P performance is very good on the ID set , since the test data was used in training the G2P model. Significantly, even though the N2P model is not as good itself, the combined model shows marke d error rate reductions: for the top hypothesis it cuts the PER by over 57%, and the WER by over 47% when compared to the G2P pe r-formance on spelling alone.

Since the OOD set represents data unseen by e i-ther the spelling -based model or the NPR -based model, all models X  performance is severely d e-graded compared to that on the ID set. But here we see that NPR -based pronunciations are already be t-ter than spelling -based ones. For the top hypoth e-sis, compared to the performance of the G2P model alone, the N2P mod el shows almost 19% better PER, and almost 5% better WER, whereas the combined model achieves 49% better PER and close to 31% better WER. 4.4 User -generated NPRs To answer the third question, we collected user -generated NPRs from five subjects. The subjects were all computer -savvy, with at least a BS c d e-gree. Only one subject expressed some familiarity with NPRs (but didn X  X  generate better NPRs than other subjects).
 The subjects were shown four examples of NPRs; two of them were recent Word of the Day en tries, and had audio attached to them. The other two were selected from the OOD set. With only four words and two different sources we wanted to en sure that users would not be able to train the m-selves to a specific system. Subjects understood the problem e asily and rarely if ever looked back at the examples during the actual test. 
The test involved generating NPRs for 20 of the most difficult words for our generic GP model from the OOD set (e.g., bronchoscope , pare n-chyma , etc.). These words turned out to be mostly unfamiliar to users as well (the average familiarity score was just under 1.9 on a 4 -point scale. No audio and no feedback were given .
 Users varied greatly in the choices they made. For the word acupressure , the first two syllables were transcrib ed as AK -YOO in the Dictionary of Cancer Terms, and users came up with ACK -YOU, AK -U, and AK -YOU. This underscores that a good N2P model would have to account for far more GP mappings than the 111 found in our data.
Sometimes users had trouble assigning co ns o-nants to syllables (syllabification wasn X  X  required, but subjects tried anyway), on occasion splitting them across syllable boundaries (e.g., \ BIL -LIH -RUE -BEN \ for bilirubin ) , which guarantees an i n-sertion error . It is quite likely that some error model might be required to deal with such issues.
Nonetheless, even though imperfect, the re sulting NPRs showed excellent promise. Looking just at the top hypothesis, whereas the average PER on those 20 words was about 45% for the G2P model, pronunciations obtained from NPRs using the same G2P model (new GP mappings pr e-cluded the use of the N2P model described in the previous section) had only around 36% (+/ -5%) phone error rate. The combined model showe d an even better performance of about 33% (+/ -5%) PER. Full results for n -best lists up to n=10 are shown in Figure 3. The experiments we conducted are preliminary, and most of the work remains to be done. More data need to b e collected and analyzed before good NPR -to -pronunciation models can be trained. Fu r-ther investigations need to be conducted to assess the average users X  ability to generate NPRs and how they tend to deviate from the general grap h-eme -to -phoneme rules of En glish.

Nonetheless , we believe these experiments give strong indications that NPRs would be an excellent source of information to improve the quality of pronunciation hypotheses generated from spelling. Moreover, it appears that novice users don X  X  have mu ch difficulty generating useful NPRs on their own; we expect that their skill would increase with use. Particularly useful would be for the system to be able to provide feedb ack, including generating NPRs; we have started investigating this reverse problem , of obtaining NPRs from pronunciations, and are encouraged by the initial results.

