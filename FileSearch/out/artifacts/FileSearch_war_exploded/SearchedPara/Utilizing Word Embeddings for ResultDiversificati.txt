 Kezban Dilek Onal, Ismail Sengor Altingovde ( In the last few years, microblogging  X  X nd being its most prominent platform, Twitter X  has gained tremendous popularity. Users of Twitter do not only post tweets and browse those in their own feed, but also submit queries to discover the posts about events or people (i.e., mostly celebrities) of their interest [ 26]. According to a recent study, more than 2 billion queries are submitted to Twitter per day [ 5], making microblog retrieval an important and active research area. Diversifying tweet search results is an emerging post-retrieval optimization that aims to cover different aspects of a given query in the top-ranked results, and hence provide the user a better overview of the searched topic [ 18]. Recent studies show that the vocabulary mismatch problem that has been identified for microblog retrieval also affects the diversification performance adversely. The vocabulary mismatch problem arises due to the short (i.e., typically 140 char-acters) and informal nature of tweets (e.g., see [ 1, 20, 21]), and causes highly relevant query-tweet (or, tweet-tweet) pairs yield very low similarity scores. In the context of result diversification, Ozsoy et al. [18 ] have shown that explicit methods with prior knowledge of the aspects of a given query are not as suc-cessful at diversifying tweet search results as they are at diversifying web search results, since the terms describing the query aspects do not usually occur in the tweet content. fication for tweet search, and as a remedy, we propose to expand queries and/or tweets using word embeddings as an external knowledge base. The vocabulary of a language is mapped into a vector space such that words that occur in simi-lar contexts have similar vector representations, so-called word embeddings [ 2]. Word embedding space is a convenient source as an external knowledge base because of the following reasons. First, word embeddings are obtained by unsu-pervised learning on raw textual data; and recent methods in the literature enable learning embedding vectors from a corpus of billion words in an hour on a personal computer. In contrast, most of the other knowledge bases are con-structed by some sort of human intervention [ 3, 12]. Second, word embeddings learned from raw textual data can encode both the linguistic knowledge that can be obtained from resources like WordNet and real-life knowledge such as the relationships between entities. Owing to this property, it can be more useful in searching highly dynamic and informal datasets, like microblogs.
 word embeddings. To the best of our knowledge, while query expansion is applied for microblog retrieval in some recent works (using pseudo-random feedback [1, 21], or external resources such as a community-curated knowledge base, namely, Freebase [20 ]), we are the first to adopt both query and tweet expansion based on the automatically-generated word embeddings for the result diversifi-cation problem in tweet search.
 sentative diversification methods from the literature; namely, Sy and MMR as implicit and xQuAD as explicit diversification methods. We find that query and tweet expansion using word embeddings is a promising idea and can yield some moderate improvements in most cases. As a further experiment, we employ ConceptNet, a crowd-sourced knowledge base, as an external resource for query/tweet expansion; and show that the performance is comparable to that obtained via word embeddings, while the latter requires no human effort for its construction. This last finding again implies the potential of utilizing word embeddings in tweet diversification in a realistic scenario.
 underlying theory for the word embeddings and discuss related work for retriev-ing and diversifying tweets. Section 3 presents our query and tweet expansion approach based on the word embeddings. Section 4 is devoted to the experi-mental setup and evaluation. Finally, we conclude and point to future research directions in Sect. 5. 2.1 Word Embeddings Word embeddings are real-valued vector representations for words. The idea behind word embeddings is to map the whole vocabulary of a language into a vector space such that syntactically and semantically close words are represented with similar vectors. The similarity of two words can be quantified by the simi-larity of their embedding vectors. The concept of word embeddings is employed within the context of the Neural Network Language Model (NNLM) by Bengio et al. [ 2]. The NNLM is trained to predict the next word given a sequence of words. The model is designed to learn word embeddings and parameters of the language model that predicts the next word given a sequence, simultaneously. Following the latter study, several other neural network models for learning word embeddings have been proposed. The very recent models Skip-Gram [ 16] and Glove [ 19] lean on simpler and scalable models that enable learning word embeddings from a corpus of a billion words on a personal computer in an hour. In this work, we utilized the Glove model for embedding learning model since it exploits global context besides the local context in training, differently from other embedding learning models. 2.2 Microblog Retrieval and Diversification Microblog retrieval has become an active research area in the last few years as it is addressed in several works as well as the TREC Microblog Track orga-nized since 2011 to date. A number of these previous works identify the vocab-ulary mismatch problem for microblog retrieval, and propose solutions based on the query and/or tweet expansion. Massoudi et al. [ 14] employ a tradi-tional pseudo-relevance feedback (PRF) strategy, where the expansion terms are scored based on their temporal closeness to the submission time of the query. Miyanishi et al. [ 17] again employs PRF by taking into account the temporal evidence, however their model is preceded by an initial PRF stage where a single relevant tweet for a given query has to be manually picked by the query poser. Rodriguez Perez et al. [21 ] apply a clustering of tweets based on the named enti-ties appearing in the tweet body and utilize these clusters for PRF. In contrast to all the latter approaches, some other works rely on the external corpora for query or tweet expansion. In the work of Bandyopadhyay et al. [ 1], the expan-sion terms for a query are based on the result document titles obtained via Google search API for each query. Gurini et al. [ 8] and Qiang et al. [ 20] employ Wikipedia and Freebase as an external resource for query expansion, respectively. Finally, there are also works that make tweet expansion, e.g., using hyperlinks in the tweets [9, 11, 15] or using the tweets themselves as pseudo-queries over the collection [7]. Clearly, all of these earlier works aim to enhance the retrieval performance; whereas our goal in this paper is to improve the performance of the result diversification in tweet search. To this end, we employ representative diversification methods that may require query expansion, tweet expansion, or both; and investigate to what extent our expansion strategies based on the word embeddings can help.
 Search result diversification is an emerging trend that is actively investigated in various areas such as the web search engines and recommender systems. Espe-cially for the result diversification in web search, a large number of methods are proposed, including those that utilize query expansion techniques. For instance, in [ 4], the authors employ ConceptNet to obtain diverse expansion terms for a given query. In a follow up work, a vector embeddings space is used to discover the diverse aspects of the query [ 13]. While inspiring for us, these works are not directly related as they do not address the microblog diversification. Further-more, their approaches expand the original query with diverse terms (i.e., diver-sification is applied over the expansion terms ) and then execute the expanded query to obtain the final result; whereas we apply the diversification over the results once the queries and/or tweets are expanded.
 the diversity of the top-ranked tweets. In [ 22], an approach based on the MMR method [ 6] and clustering of tweets is proposed. However, they do not evaluate the proposed approach using diversity-aware evaluation metrics, as we do here. In another study, Tao et al. introduce a data set, Tweets 2013 Corpus , for eval-uating microblog diversification, and they also propose a diversification method, Sy [24]. Koniaris et al. [ 10] consider the tweet diversification with respect to sev-eral criteria, such as the sentiment, time, location, and readability of the tweets. Finally, Ozsoy et al. [ 18] investigate the performance of various diversification methods on the Tweets 2013 Corpus . This study concluded that explicit meth-ods perform worse than the implicit methods, a finding that contradicts to the web search literature. The failure of the explicit methods is attributed to the vocabulary gap between the query aspects and tweets. In our work, we aim to remedy the vocabulary mismatch problem using expansion strategies for both implicit and explicit result diversification methods. 3.1 Preliminaries of the Result Diversification for Tweet Search The result diversification problem for tweet search is formally defined as fol-lows [18 ]. Let X  X  assume a query q that retrieves a candidate ranking C (where |
C | = N ) of tweets over a collection. The aim of the result diversification is obtaining a top-k ranking S (where k&lt;N ) that maximizes the total relevance and diversity among all possible size-k rankings S of C .
 gorized as implicit and explicit , based on the source of knowledge exploited for the diversification purposes. The methods in the former category rely only on the candidate ranking C , and attempt to construct the ranking S basedonsome intrinsic features of the tweets (such as their pairwise similarities) in the can-didate set. In contrast, the explicit methods assume the prior knowledge of the query aspects that is obtained from some external resource (e.g., from a query log in [ 23]) and try to diversify the candidate ranking accordingly. In this study, we employ MMR and Sy as representatives of the implicit methods, and xQuAD as a representative of the explicit methods. In what follows, we briefly review these three methods as they are adopted in [ 18].
 MMR. The MMR [ 6] method employs a greedy strategy to iteratively construct a diversified ranking S . In the first iteration, the tweet with the highest relevance to the query is inserted into the set S . In the following iterations, the score of each remaining tweet t i is computed by taking into account its relevance to q , which is denoted as rel ( t i ,q ), and its similarity to already selected tweets in S (asshowninEq. 1); and the tweet with the highest score is removed from C and added to S .InEq. 1, the trade-off parameter  X  is used to balance the relevance against diversity in the final result set. Sy. This is a simple yet effective method described in a framework for detecting duplicate and near-duplicate tweets in [ 24]. In a nutshell, Sy makes a scan of the candidate tweet ranking C in a top-down fashion. For a given tweet t its near duplicates (i.e., those that have a similarity score greater than a pre-defined threshold) succeeding t i in the ranking C (i.e., appearing at a lower rank position) are removed from C . xQuAD. xQuAD [ 23] assumes the prior knowledge of the query aspects and constructs a diversified ranking by a greedy approach that selects the tweet that essentially covers the aspects that are least covered in the current set S . More formally, in each iteration, this method selects the tweet that maximizes Eq. 2, where P ( t i | q ) denotes the relevance of t i to query q , P ( q likelihood of the aspect q i for the query q , P ( t i | q to the query aspect q i , and the product term represents the probability of the aspect q i not being satisfied by the tweets that are already selected into S . f xQuAD ( t i )=(1  X   X  ) P ( t i | q )+  X  Our work includes xQuAD as a representative explicit diversification method since it has been the top performer in the Diversification Track of the TREC evaluation campaigns between 2009 and 2012. For the implicit methods, we include MMR for being a traditional and one of the earliest methods, and Sy for being the best-performing approach for tweet diversification in [ 18]. 3.2 Expansion with K-Nearest Neighbours (KNN) The aforementioned diversification methods can operate on three different types of textual units, namely, queries, query aspects or tweets. In particular, the Sy method considers only tweet-tweet similarities for constructing the diversified ranking, while MMR computes both the query-tweet and tweet-tweet similarities (see Eq. 1), and xQuAD needs to compute the query-tweet and aspect-tweet similarities as shown in Eq. 2. Hence, for different methods, it is possible to expand some or all types of these textual units.
 In this work, we adopt the K-Nearest Neighbour (KNN) expansion method for expanding any textual unit. KNN follows the simple idea of collecting K-neighbours of each term from an external knowledge base. A textual unit is viewed as a set of terms, and the expansion term set is composed by merging the K-Nearest neighbour sets of unique terms in the textual unit. Formally, given a textual unit (i.e., a query, aspect or tweet) u that contains m terms, u = { w 1 ,w 2 , ..w m } , the expanded unit u e with the K-Nearest Neighbours expansion method is computed as follows: where E ( w i ,K ) is the set of K nearest neighbours of the term w knowledge base. The computation strategy of E ( w i ,K ) depends on the external knowledge base and discussed in depth in the following section. 3.3 Computing the K-Nearest Neighbours We utilize two external resources to compute E ( w i ,K ) as follows. Word Embeddings: In the word embedding space, each word is associated with a real-valued D dimensional vector. Since semantically similar words are likely to have similar embedding vectors, we treated K-nearest neighbours of a term w in the embedding space as the set of terms that maximize semantic similarity to w . In other words, the set of K-Nearest neighbours of a term w is determined by ranking all the words in the embedding space with respect to their similarity to w . The similarity of two words in the embedding space is computed by the Cosine similarity of their embedding vectors.
 (extracted from our query set) in the Glove embedding space. Each column lists the neighbors of the target term given in the header row. Remarkably, the neighbor terms are quite relevant to the target ones.
 ConceptNet: The ConceptNet API 1 provides the top-K similar concepts to a given concept. A crucial point to note about ConceptNet is that concepts in ConceptNet may be sentences or phrases in which the words are separated by underscores. For these types of concepts, although the concept cannot be matched to a textual unit exactly, one of the words in the concept can be found in the textual unit and provide an important information for the similarity com-putation. Therefore, we split such concepts and expanded the corresponding textual unit by the words instead of the whole concept. For instance, assume that head of state is the concept at hand, which is actually the second nearest neighbor to the query term president . In this case, we add three terms head, of, state to the expanded query for this single concept. 4.1 Experimental Setup Dataset. For our evaluations, we use the Tweets2013 corpus [ 25] that is specif-ically built for the tweet search result diversification problem. The dataset includes forty seven query topics and each topic has, on the average, 9 sub-topics. The tweets in the data set are dated between Feb. 1, 2013 and March 31, 2013.
 The owners of the Tweets2013 corpus only share the tweet identification numbers since the Twitter API licence does not allow users to share the content of the tweets. We attempted to obtain the top-100 tweets per query but failed to do so, since some of these tweets were erased or their sharing status were changed. Consequently, we ended up with 81 tweets per topic on the average. Furthermore, following the practice in the earlier works, we decided to remove the topics that have at most 2 relevant tweets among their top-100 results (with ids 5, 9, 22, 28, 7, 8, 14, 43, 46 and 47) from our query set, as they would deviate our measurements.
 Preprocessing. Prior to the application of the diversification methods, we removed all the mentions and URLs from the tweets and reduced each tweet to a set of terms and a set of hashtags. We performed tokenization and stem-ming with the Stanford CoreNLP library (version 3.5.1). At last, we removed all the terms that appear in the default stopword list of the Indri search tool (http://www.lemurproject.org/ ).
 Knowledge Bases. We used the 50-dimensional word embeddings obtained with the Glove algorithm from a corpus of 6 billion tokens that includes Wikipedia and Gigaword. The embeddings are published in http://nlp.stanford. edu/projects/glove/ . We also employed ConceptNet, a crowd-sourced knowledge base, as a further baseline.
 Evaluation Metrics. For evaluation, we used the ndeval software ( http://trec. nist.gov/data/web10.html) employed in the TREC Diversity Tasks. The results are reported using three widely-used effectiveness metrics, namely,  X  -nDCG, Precision-IA, and Subtopic-Recall at the cut-off values of 10 and 20. Parameters of the Diversification Methods. We measure the performance of our expansion strategy using the word embeddings and ConceptNet on three different diversification methods, namely, Sy, MMR, xQuAD. In all the diver-sification methods, we utilized the KNN expansion method. Depending on the method, we applied expansion to different textual unit types included in diversi-fication. For the Sy method, we performed only tweet expansion since the query is neglected by this method. For MMR, we performed two sets of experiments. In the first set, we expanded only queries. In the second set of MMR experi-ments, we expanded both queries and tweets. Finally, the xQuAD diversification method relies on the queries, query aspects and tweets for diversification. We performed two sets of experiments for xQuAD. In the first set of experiments, we only expanded the queries and query aspects, whilst in the second set, we expanded queries, aspects and tweets. Note that, following the practice in the lit-erature (e.g., [ 18, 23]), we used the official query aspects provided in the dataset to represent an ideal scenario. For all diversification methods, we report the results for the best-performing  X  value.
 relevance and/or tweet-tweet similarity scores. In this work, we employed Jaccard Similarity metric for both purposes. Each textual unit is viewed as a set of words and the similarity between two textual units T 1 and T 2 is computed by Finally, we obtain a diversified ranking of size 30 from a candidate ranking of size 100. 4.2 Experimental Results In the results, we compare the performance of diversification methods with KNN-based expansion to two baselines. The No-div Baseline is the performance over the initial retrieval results (i.e., without any diversification) obtained by a sys-tem employing the query-likelihood (QL) retrieval model. These initial retrieval results were provided in the Tweets2013 corpus. However, since it is impossible to retrieve exactly 100 tweets per query due to API issues (as discussed in the previous section), we re-computed the evaluation metrics for this initial ranking based on only those tweets that could be retrieved in top-100, for the sake of fair comparison. Consequently, the effectiveness of the baseline QL run slightly differs from what is reported in [ 25]. As a second baseline, for each diversification method, we also provide the effectiveness scores without doing any expansion. In the following results, we denote this baseline as No-exp Baseline , and those results that exceed the latter baseline are shown in bold.
 Results for Sy. In Table 2, we present results of the tweet expansion experi-ments for the Sy method. The Sy method was found to outperform all the other explicit and implicit diversification methods experimented in [ 18] when used with a hybrid metric that combines the Jaccard Similarity for content and the timestamp similarity. In this work, we focused only on content similarity and ignored the time attribute of tweets. The field K in the table denotes the num-ber of neighbors in the KNN strategy. The  X  parameter represents the similarity threshold used in the Sy method. Our findings reveal that the performance of Sy can be improved via tweet expan-sion using both types of knowledge bases. The improvements are relatively higher at the cut-off value of 10 and for the ST-Recall metric; and they tend to increase with the larger number of expansion terms. This is a moderate yet encouraging finding, as Sy is reported to be the best-performing method in [ 18, 23], and the expansion method has the potential to improve even this case.
 Results for MMR. In Table 3, we present the results of the query expansion experiments for MMR. Surprisingly, MMR fails to diversify the results, as even No-exp Baseline performs worse than the No-div baseline. Effectiveness improves with increasing number of neighbors using both knowledge bases, and expansion with Glove word embeddings seems to be better than ConceptNet, especially for certain metrics, such as ST-Recall@20. Actually, the latter metric is the only one for which the diversification performance can exceed both of the baselines. In Table 4, we present the results of the experiments in which both queries and tweets are expanded. The columns KQ and KT denote the number of neighbours used for query and tweet expansion, respectively. The trends are similar to the previous case, but the actual effectiveness scores are even worse, implying that tweet expansion does not help improving the diversification performance for MMR.
 Results for xQuAD. In Table 5, we present the results of xQuAD experiments with query and aspect expansion. In this case, expansions based on both types of the external resources are again useful, and in certain cases, they can yield an absolute improvement of more than 1 %. ConceptNet is slightly better than the word embeddings. Finally, in Table 6, we present the results of the xQuAD exper-iments where we expand the queries, aspects and tweets. We see that expanding tweets further improve the results (cf. Table 5) especially for the cut-off value of 10 and using a few (i.e., up to 3) expansion terms. In this case, expansions based on the word embeddings are slightly more useful than those based on the ConceptNet. In this work, we addressed the vocabulary mismatch problem in result diversifica-tion for microblog search. For the first time in the literature, we employed query and tweet expansion based on the automatically-generated word embeddings to improve the diversification performance. We evaluated the adopted expansion strategy using three diversification methods, namely, MMR and Sy for implicit and xQuAD for explicit diversification. Our findings revealed that while MMR is not a competitive method for diversification in this context; both xQuAD and Sy benefit from the expansion strategy, though the improvements are moderate. We further showed that the expansions based on the automatically-generated word embeddings may serve as useful as those based on the ConceptNet knowl-edge base, of which construction requires considerable manual effort. This is an encouraging finding for improving diversification by leveraging word embeddings in real life microblog retrieval scenarios. In our future work, we plan to generate word embeddings on a tweet corpus for further experimentation. We also aim to extend our experimental framework to analyze the impact of the other features, such as URLs, extracted from the tweets in addition to their textual content.
