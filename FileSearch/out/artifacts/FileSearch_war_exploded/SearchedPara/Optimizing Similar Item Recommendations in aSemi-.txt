 This paper tackles the problem of recommendations in eBay X  X  large semi-structured marketplace. eBay X  X  variable inven-tory and lack of structured information about listings makes traditional collaborative filtering algorithms difficult to use. We discuss how to overcome these data limitations to pro-duce high quality recommendations in real time with a com-bination of a customized scalable architecture as well as a widely applicable machine learned ranking model. A point-wise ranking approach is utilized to reduce the ranking prob-lem to a binary classification problem optimized on past user purchase behavior. We present details of a sampling strategy and feature engineering that have been critical to achieve a lift in both purchase through rate (PTR) and revenue. e-commerce; recommender systems; machine learning; learn-ing to rank
Recommender systems in e-commerce have been exten-sively studied over the last few decades. Recommendations drive a considerable portion of site revenue, and ensure that users stay engaged with content for as long as possible. Un-like general marketplaces such as Amazon and Walmart, which offer warehouse products in a documented catalog, the eBay marketplace offers more diverse listings ranging anywhere from a new iPhone (a specific product with struc-tured data attributes) to offhand antique items with no known characteristics. With over 800 million active listings at any given time as well as over 150 million active buyers, this semi-structured marketplace exhibits a heavy-tailed dis-tribution of items  X  a large number of listings are unique, unidentifiable items that are popular among niche buyers. In addition, multiple item conditions and selling formats make serving relevant recommendations significantly harder. been implemented in LinkedIn [2]. The engineering details of the system architecture are discussed in Section 2.
The second stage of the system involves ranking the rec-ommendations to decide which top 5 items to surface to the user. The topic of learning to rank has been widely studied in the field of Information Retrieval (IR) [9, 7] as it applies to ranking results based on a search query. More recently, machine learned ranking (MLR) techniques have been ap-plied directly to recommender systems at Google [12], Net-flix [11], and Amazon [4]. The pointwise learning to rank problem in the IR context can be reduced to a classifica-tion problem using x i = { query,URL } i pairs as well as a binary or multi-class relevance label y i as training input. Assigning the relevance labels to query-URL pairs is typi-cally done with crowdsourcing methods which can be time consuming and cost prohibitive. In the context of recom-mender systems for this work, the classification problem uses x i = { seed item,recommended item } i pairs and im-plicit user feedback (clicks/purchases) as the binary class label. This way, data collection is continuous and uses real-world conditions. The details of our ranking approach as well as experimental results are presented in Section 3.
We note that although our marketplace is unique, our ranking model is general enough for any domain employing recommender systems that uses a seed item, and can track click and purchase metrics. The model is widely applicable and is not limited to any one product category.
Our backend platform serves approximately 400 million requests every day and is optimized to have a response time of under 200 ms end-to-end. The backend architecture for the recommendation engine is divided into offline and online systems  X  the offline components indexes incoming eBay data, mines behavioral data and click logs, as well as trains a clas-sifier on historical data to determine likelihood of purchase.
The overall recommendation process follows the paradigm of a search problem, which consists of two stages: Recall , which requires retrieving candidate items that might be sim-ilar to the given seed item, and Ranking , which sorts the candidates according to their probability of being purchased. An overview of the backend architecture can be seen in Fig-ure 2. The input to the algorithm comes as an HTTP request to the merchandising backend (MBE) system with a given seed item. This initiates parallel calls to several services which return candidate recommendations that are similar in some way to the seed. The set of candidate recommenda-tions are then ranked in real time. The output of the system is the top 5 ranked items, which are surfaced to the user.
With a rather sparse inventory of known products, eBay X  X  internal product catalog serves only a small portion of sim-ilar item recommendations on the item page ( &lt; 10%). This sparsity led to a variety of techniques in generating candi-date recommendations for a given seed item.
 Product catalog: Although the majority of items on eBay are not tagged with a specific product ID, the distribution of product coverage tends to vary significantly across different categories. Books, for instance, usually has a high percent-age of items which are known products due to identifiers such as ISBNs. If the seed item is tagged with a particular Table 1: Class label options for binary classifier and KL divergence for price feature. clicked not purchased purchased 0.07 (ETL) where the user logs are joined with item details and the data is subsampled. The trained offline MLR model parameters are passed to the runtime ranking application where predictions are made in real time.
The pointwise learning to rank problem, in the context of serving item recommendations, is reduced to a binary classification problem where we rank the recommendations on the probability of being purchased (positive class), ef-fectively maximizing conversion. The training and testing data sets are generated with features derived from { seed item , recommended item } pairs and binary class labels be-ing { 0=non-clicked, 1=purchased } from recommendations shown in the past. At runtime in production, the Recall stage produces candidates for possible { seed item , recom-mended item } pairs, and then in the Ranking stage the model assigns a probability score to each such pair, with the 5 highest scoring pairs resulting in recommendations to be shown to the user. The sampling strategy as well as the engineering of specific features are critical to the success of any classifier.
We train a binary classifier on user browsing and pur-chase logs. Initially, we considered using  X  X on-clicked X  and  X  X licked X  as the class labels for the model and rank the rec-ommendations by the probability of click. To investigate the effectiveness of this strategy, we looked at the class separa-bility of each feature. Figure 3a shows a histogram of the price feature score (described in the next section) for the non-clicked / clicked sampling strategy. User click patterns tend to be noisy as users browse items in a marketplace for a variety of reasons. This leads to the classes not separat-ing well. We used the KL divergence to get a quantitative measure of the overlap of the probability distributions for the 2 classes. Table 1 shows several potential approaches to choose classes, as well as the resulting KL divergences for the price feature. Figure 3b shows the histogram for the non-clicked / purchased sampling strategy. We ran this type of analysis, looking at the KL divergence, for all of the features in our model to validate that the non-clicked / purchased strategy is optimal for class separation. This reflects user in-tention  X  non-clicked recommendations show absolutely no user interest while the purchased recommendations indicate complete user intention (conversion). Clicked recommenda-tions are in the middle of this spectrum and cannot be used as effectively for classification.

Purchased recommendations occur an order of magnitude less often than clicked recommendations, which themselves occur in a relatively low portion of impressions. Due to this extreme class imbalance, we subsample the negative class to be balanced with the positive class in order to improve classifier performance. Logistic Regression 0.77 0.353 0.689
Gradient Boosting 0.81 0.370 0.697 highest global score, G = P N j =1 w j  X  s j , where w j and s j are the weight and feature score, respectively. We define nor-malizations on the weights P N j =1 w j = 1 and feature scores 0  X  s j  X  1 which results in a constraint on the global score 0  X  G  X  1. We launched this model to live user traffic to validate effectiveness of the features.
We evaluated the performance of several classifiers on the balanced dataset with the non-clicked / purchased class la-bels. The dataset contained 352,070 examples gathered over 10 days of user logs and was randomly split into training (60%) and validation (40%) sets. Table 2 shows the ROC AUC scores from the validation data set demonstrating im-proved performance over the baseline model (Section 3.3). The hyperparameters for the tree based classifiers ware op-timized using grid search. The accuracy (0.70) as well as the positive class precision (0.70) and recall (0.70) for the logistic regression indicated reasonable classification perfor-mance.

To evaluate ranking performance, we took the raw un-sampled recommendations (1,177,117 examples) from im-pressions that contained a purchase, excluding impressions used for training. To gauge the quality of the ranking, we used the normalized discounted cumulative gain truncated at rank k (NDCG@k) metric which is typically used for eval-uating ranking performance [7, 4]. We defined the relevance function to be { non-clicked = 0, clicked = 0, purchased = 1 } . The model was evaluated on 10 datasets with eBay user log data from different time frames and countries. Classifica-tion and ranking performance was comparable to the results shown in Table 2.
As typically done in the ad tech industry, we segment the model by product category and country. An individual classifier was trained in every major category as users tend to shop differently in different domains (for example, prices may be more important in clothing than in antiques).
We implemented a logistic regression model for our pro-duction platform due to its scalability and reasonable of-fline classification and ranking performance compared to the tree based classifiers. The country and category segmented MLR model was A/B tested in live production traffic with the control being the baseline model defined in Section 3.3. Table 3 shows positive lift in critical operational metrics: click through rate (CTR), purchase through rate (PTR), and revenue. The model was optimized to maximize conver-sion which can be seen in the increase in PTR (+6.6%) and revenue (+6.0%). While the A/B test results were corre-lated with the improvement in offline performance between the logistic regression classifier and the baseline model, we are investigating how well this holds for the other classi-fiers. This machine learned ranking model was launched to
