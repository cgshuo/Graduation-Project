 For the past decade, the studies of sentimen t classification in natural language process-ing, due to its extensive applications [1], have been increasingly drawing attention from the researchers around the world. The aim of sentiment classification is to identify the subjectivity of texts and recognize the polarity ( X  X ositive X  or  X  X egative X ).
Sentiment classification mainly falls into three levels: document-level, sentence-level and word-level, among which word-level sentiment classification serves as the basis for the other two. The polarity of some words remains stable despite the context variation while the polarity of others depends on the context. The former can be referred to as context-free words and the latter as context-dependent words. Sentiment classification of context-dependent words is more challenging in that it requires deeper and more thorough understanding of natural language in corporating many syntactic, semantic and pragmatic factors. For example, the word  X  X igh X  conveys a negative polarity in  X  X igh cost X , but indicates a positive polarity in  X  X igh quality X . In fact, such context-dependent sentiment words can not be discarded in sentiment classification [2].

It is worth mentioning that antonyms can help inferring the polarity in natural lan-( X  X igh X , X  X ow X ) and ( X  X ig X , X  X mall X ) are helpful in sentiment detection [3]. However, no previous work has attempted to utilize such antonym pairs for context-dependent sentiment classification.

Figure 1 portrays a toy model of context-dependent sentiment classification with antonym pairs. It is often the case that two words in an antonym pair share the same context yet opposite polarity, as in the example of  X  ( ) | high(low) quality X . To recognize the polarity of context-dependent sentiment words, we begin with choosing a seed set of antonym pairs such as ( X  | high X , X  | low X ) and ( X  | big X , X  | small X ) , which are frequently used in opinionated tex ts. Next, we improve the scalability through double expansion, i.e., Context Expansion and Target Expansion, which is similar to double propagation [4]. Context Expansion refers to the process of expanding neighbor-ing nouns with synonymy identification [5], e.g.,  X  | quality X   X   X  | quality X  (as shown in Figure 1). Target Expansion refers to the process of expanding seed sentiment words to synonymous adjectives [6], e.g.,  X  | big X   X   X  | huge X , or semantically cor-related verbs, e.g.,  X  | big X   X   X  | improve X  (as shown in Figure 1).

In the most relevant work [2], the task of disambiguating dynamic sentiment ambigu-ous adjectives is transformed to sentiment expectation of noun. However, the impact of polarity detection with antonym pairs is ignored. We focus on context-dependent senti-ment classification using antonym pairs.

The rest of this paper is organized as follows: In Section 2 we describe the polar-ity classification method for antonym pair s. Section 3 illustrates the double expansion method in detail. The evaluation results of our approach through sentiment classifica-tion experiments are presented in Section 4. Finally, we conclude and discuss the future work in Section 5.
 2.1 Context Information Extraction Context information can be more accurately represented by aspects, which can be ob-tained from domain experts, or automatic methods[7]. However, aspect extraction of sentiment words is beyond the scope of this paper. The task of disambiguating am-biguous adjectives is simplified into sentiment classification of neighboring nouns [2]. Similarly, we extract the context information from neighboring nouns of ambiguous adjectives within a predefined distance.
 we assume that w i is an ambiguous adjective from antonym pairs. Neighboring nouns, denoted as nn , can be matched by templates shown in Table 1.
 2.2 Polar Posterior Probability Definition 1 (Antonym Pair). An antonym pair is formalized as a tuple pair =( u, v ) , where u and v are ambiguous and antonymous adjectives. Two antonymous adjectives with the same context generally have the opposite polarities, i.e.,
In this paper, we only discuss eight antonym pairs listed in Table 2. They are all one-character words and frequently used in opinionated texts [2].

The collocations of ambiguous adjectives and neighboring nouns are saved in a po-larity decision table. Definition 2 (Polarity Decision Table). A polarity decision table is formalized as a quad PDT =( U, C  X  D,V,f ) ,where, U : a finite nonempty set of objects, e.g., { e 1 ,e 2 ,  X  X  X  ,e 12 } in Table 3; C : a finite nonempty set of condition attributes, C = { nn, sw } in this paper, sw = u D : a finite nonempty set of decision attributes, D = { label } in this paper, label labels V : V =  X  V a , V a is a nonempty set of values of a  X  C  X  D . Thus, V = V nn  X  V sw  X  f : f = { f a | f a : U  X  V a } , f a is an information function that maps an object in U to
In general, it is hard to annotate the polar ity label for each context-dependent word for training. It is not necessary for our method which is on the basis of the following assumption.
 Assumption 1. The polarity label of one word in a sentence is consistent with the polar-ity label of the sentence, i.e., the same if the sentence is affirmative, while the opposite is the case if the word is in the scope of negation.
 Definition 3 (Polar Posterior Probability). A polar posterior probability is a proba-bility that a sentiment word sw is positive or negative given a neighboring noun nn , denoted as P ( sw =1 | nn ) and P ( sw =  X  1 | nn ) respectively.
 The polar posterior probabilities for antonym pairs can be computed according to Bayes X  theorem [8].
 where,
In Eqs. (4) and (5), the function  X  count ( X )  X  returns the number of objects in U that the condition X is met. To eliminate zero probabilities, we use add-one smoothing, which simply adds one to each count.

We can determine the polarity of sentiment words by the following two rules: Bidi-rectional Rule and Unidirectional Rule.
 Bidirectional Rule. If two sentiment words from an antonym pair both have the polar posterior probabilities given the same context, a bidirectional rule is made. The polarity of u from an antonym pair pair =( u, v ) given a neighboring noun nn is obtained: We compute the Z -score statistic with one-tailed test to perform the significant test. whose corresponding Z -score is -1.64. If Z -score is greater than -1.64, the difference of two posterior probabilities is significant.
 Unidirectional Rule. If only one sentiment word from an antonym pair has the polar posterior probabilities given the same context, a unidirectional rule is made. 2.3 An Example of Polarity Decision Table An example of polarity decision table is given in Table 3. The fourth column is the polarity label inferred from the training data. According to Assumption 1 ,if sw is in the scope of negation, label is opposite to the polarity of the sentence, otherwise the same. Table 4 lists the results of context-dependent polarity classification, which are satisfying.
 3.1 Context Expansion Context expansion is equivalent to finding synonyms of the contextual word. A syn-onym dictionary can be used directly, but its coverage is limited. Automatically finding synonyms is transformed to semantic similarity measure.

HowNet is widely used in semantic similar ity measure for Chinese words. Each word is described by several concepts. The similarity between w i and w j is equal to the maximum similarity of all concepts of the two words [10], denoted by Sim h ( w i ,w j ) . If w i or w j is out of HowNet lexicon, Sim h ( w i ,w j ) equals 0. We utilize a modified similarity measure from the perspective of edit distance [11].
 where EditCost ( w i ,w j ) is the minimum cost of character insertion and deletion op-erations needed to transform one word to another. The cost of inserting or deleting an character ch is set as in [12], where NEG is a set of negation characters, such as  X  | not X  and  X  | none X .

In context expansion, we combine the above two similarity measures. We give a higher weight to Sim h , i.e., 0 . 5 &lt; X   X  1 .If Sim of two words is greater than a predefined threshold  X  (  X  =0 . 6 in the following examples), they are considered to be synonymous.
 Property 1. 0  X  Sim ( w i ,w j )  X  1 .
 Property 2. If w i or w j is out of HowNet lexicon, Sim ( w i ,w j )= Sim e ( w i ,w j ) . Example 1 ( X  | quality X  and  X  | quality X ). Sim h =0 . 93 , Sim e =0 . 48 ,let  X  =0 . 6 , Sim =0 . 77 &gt; 0 . 6 . Thus,  X  | quality X   X   X  | quality X .
 3.2 Target Expansion sentiment words.
 Polar Adjective Expansion. Find adjectives, each of wh ich has the high similarity with the target sentiment word. The expansion is the same with context expansion. A higher weight to Sim h is given, i.e., 0 . 5 &lt; X   X  1 .
 Example 2 ( X  | big X  and  X  | huge X ). Sim h =1 . 00 , Sim e =0 . 91 ,let  X  =0 . 6 , Sim =0 . 96 &gt; 0 . 6 . Thus,  X  | big X   X   X  | huge X .
 Polar Verb Expansion. Find verbs, each of which has the same trend as the target sentiment word. The semantic similarity between  X  | high X  and  X  | high X  (0.13) is less than that between  X  | high X  and  X  | high X  (0.24), which is obviously wrong. Hence, a higher weight to Sim e is given, i.e., 0  X   X &lt; 0 . 5 .
 Example 3 ( X  | high X  and  X  | improve X ). Sim h =0 . 13 , Sim e =0 . 91 ,let  X  = 0 . 4 , Sim =0 . 92 &gt; 0 . 6 . Thus,  X  | high X   X   X  | improve X .

With the help of polar verb expansion, we can obtain verbs expressing the same trend as the corresponding adjective. We define a verb list for one adjective. Definition 4 (Verb Set for Adjective). Given an ambiguous adjective sw , a verb for sw satisfies that the similarity is greater than  X  . All such words comprise a verb set for adjective sw , denoted by VSA ( sw ) .
 Polar Verb Re-Expansion. VSA ( sw ) can also provide help for polar verb expansion. If the minimum Sim (computed with the similarity measure in context expansion) be-tween a new word and all words in VSA ( sw ) is greater than  X  , the new word is con-sidered to express the same meaning with sw .
 Example 4 ( X  | high X  and  X  | increase X ). VSA ( X  | high X )= {  X  | improve X ,  X  Sim ( X  | improve X , X  | increase X )=0.79, the similarity directly, Sim =0 . 53 &lt; 0 . 6 . 4.1 Data Sets We conduct experiments on two real-world data sets. One data set is from Task 1 of Chinese Opinion Analysis Evaluation 2012, denoted as COAE [13], and the other is from Task 18 of Evaluation Exercises on Semantic Evaluation 2010, denoted as SE-MEVAL [2]. Their statistics are listed in Table 5.

The distribution of sentiment words from 8 antonym pairs is shown in Figure 2. The total of 960 sentiment words appear in 709 sentences on COAE data set, and 4991 sentiment words appear in 2846 sentences on SEMEVAL data set. These words are often used in opinionated texts, especially  X  | high X , X  | low X ,  X  | big X , X  | small X ,  X  | many X , X  | few X , and  X  | heavy X .
 4.2 Experiment Settings  X  Preprocessing: All texts are automatica lly word-segmented and POS-tagged with  X  Sentiment Lexicon: We construct a sentiment lexicon with Affective Lexicon On- X  Sentiment Classification Method:  X  Evaluation: The evaluation criteria is micro-average F -measure micro -F 1 . 4.3 Performance of Sentiment Classification for Antonym Pairs The comparative results between three bas elines and Approach-1 are demonstrated in Figure 3. The improvement on SEMEVAL data set is obvious, because the data set is designed to disambiguate sentiment ambi guous adjectives per se, and almost each sen-tence contains ambiguous adjectives. After executing polarity classification for antonym pairs, many sentences can be truly labeled th e polarity. The performance of Approach-1 on COAE data set is slightly improved due to the small percentage of sentences con-taining such adjectives. We also find that Approach-1 is better than NB and SVM.
Table 6 shows the behavior analysis of the selected 16 words. Among all the selected words, 35% are positive, 40% are negative and the remainder are neutral due to the lacking of contextual information or matching rules. The number of other context-free polar words is nearly twice that of the select ed words. The number of the selected words is about three times that of other context-dependent polar words. 4.4 Performance of Double Expansion There are two important parameters,  X  and  X  , in double expansion.  X  measures the different weight of Sim h and Sim e ,  X  is a similarity cut-off. According to several experiment results, the optimal parameter settings are given in Table 7. The similarity cut-off of different expansion on a certain data set is the same. The performance of double expansion is shown in Figure 4.

Because more contextual polarities are disc overed, double expansion further improve the performance of sentiment classifica tion. The improvement on SEMEVAL data set is greater than that on COAE data set. 4.5 Annotation Consistence Analysis As mentioned above, we assume that the polarity annotation of a word is consistent with the sentence. To validate the rationality, Cohen X  X  kappa coefficient [18] is used as a statistical measure of inter-annotator agreement. where, Pr ( a ) is the relative observed agreement among annotators, and Pr ( e ) the hy-pothetical probability of chance agreement.

In this paper, there are two annotators: Assumption 1 and our proposed method. The contingence table is shown in Table 8: Pr ( a ) and Pr ( e ) in Eq. (13) are computed respectively: We can figure out Pr ( a )=0 . 86 and  X  =0 . 73 . Two annotators are consistent enough, and the assumption is reasonable. In this paper, we propose a novel approach to automatically determine the polarity of context-dependent words with antonym pai rs. To the best of our knowledge, this is the first context-dependent sentiment classification scheme which utilizes antonym pairs. According to Bayes X  theorem, two polar posterior probabilities are obtained. We also initiate two kinds of rules, i.e., Bidirectional Rule and Unidirectional Rule, and assign the polarity to sentiment words. In addition, we define a new similarity measure which combines semantic distance with edit distance for Context Expansion and Target Ex-pansion. Our approach is effective in improving the overall performance of sentiment classification.

In the future, we would like to dive into m ore accurate context information extrac-tion which can help to filter noisy neighboring nouns. We consider that antonym pairs deserve further research.
 Acknowledgments. This work is partially supported by the National Natural Science Foundation of China (No. 61273304, and No. 61202170), the Specialized Research Fund for the Doctoral Program of Higher Education of China (No. 20130072130004) and the Fundamental Research F unds for the Central Universities.

