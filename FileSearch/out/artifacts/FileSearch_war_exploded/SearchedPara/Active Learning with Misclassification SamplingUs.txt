 The standard setting of supervised learning assumes that a previously labeled set of instances is available. However, in a large number of real world applications, obtaining labeled instances may be expen sive or time-consuming. Therefore, re-ducing the number of labeled instances that are necessary to learn a classification function becomes important. Active lea rning methods [1] allow classifiers choose the most informative instances and ask the experts to label them. Thus the burden of labeling large number of instances could be alleviated.

The whole process of the pool-based ac tive learning can be described as fol-lows. Initially, the active learner has access to a pool of unlab eled instances and owns a set of labeled instances. Then, the active learner trains a base classifier on the set of labeled instances. Afterwards, an instance is sampled for labeling according to a certain criterion and is added into the labeled set. Then the active learner trains a new base classifier on the updated labeled set. The whole pro-cess runs repeatedly until the error rating of the current base classifier is below apresetvalue.

Depending on the criterion used to select instances for labeling, the current re-search falls under several categories: uncertainty reduction, expected-error min-imization and version space reduction [2]. The uncertainty reduction approach [1,3] selects the instances on which the cu rrent classifier has the least certainty of prediction. The expected-error minimization approach [4] samples the instances that minimize the future expected error r ate on the test set. The version space reduction approach [5,6], including QBC [5], QBag [7], QBoost [7] and Active DECORATE [8], tries to select the ins tances that can reduce the volume of version space by half which based on the idea of binary searching. Query-by-Committee is a representative method of this approach that constructs a com-mittee consisting of randomly selected hypotheses from the version space and selects the instances on which the di sagreement within the committee is the greatest.

Choosing an efficient criterion for ins tance selection is the most important step in active learning. Most existing methods use the idea of binary searching in version space reduction process [5,7]. The binary searching idea assumes that all hypotheses in the version space have equal probability to be the target function. However, the assumption can not hold in most tasks.

We aim to accelerate the version space reduction process more than what binary searching does. We propose a sampling criterion which tries to keep only the most accurate hypotheses in the version space when sampling. Thus we propose a sampling method MSDEEUI(Misclassification Sampling Using Diverse Ensembles Enhanced by Unlabeled Instances) that tends to select the instances with the largest prediction difference between a strong classifier and the current base classifier. In this paper, the strong classifier is generated by the ensemble method DECORATE trained on the current labeled set and enhanced by the unlabeled instances with high certainty pr edicted by the current base classifier. The experiments show that the proposed method outperforms the traditional sampling methods on most selected datasets.

The rest of the paper is organized as fo llows. Section 2 introduces the basic notations. Section 3 presentes the proposed active learning method MSDEEUI in details. Section 4 shows the experimental results of the MSDEEUI method as well as other methods on selected data sets. Section 5 draws the conclusion. 2.1 Notations The instance space X is a nonempty set containing several instances. Each in-For simplification, we focus on 2-value classification problems in the paper. Thus Y = { 0 , 1 } . The target function c to be learned is a function c : X  X  Y that classifies any x  X  X as a member of Y . The notion &lt;x,c ( x ) &gt; denotes a labeled instance, &lt;x, ? &gt; denotes an unlabeled instance where ?  X  Y and D denotes a set of labeled instances for tra ining. The hypothesis space H is a nonempty set containing functions that map from X to Y . Providing a set of labeled instances, the task of learning is searching a function f such that  X  x  X  X, f ( x )= c ( x )in the the hypothesis space H . The version space VS HD denotes the largest subset of hypotheses in H that satisfies  X  h  X  VS HD ,  X  x  X  D, h ( x )= c ( x ). 3.1 Efficiency of Instances for Version Space Reduction To visualize the process of version space reduction, we define hypothesis-instance matrix HIM mn as a binary matrix whose rows are indexed by the hypotheses h ,h the instances x 1 ,x 2 ,  X  X  X  ,x m from the instance space X ,andwhose( i, j )entry is 1 if h i ( x j )= c ( x j ) and otherwise 0. We define an operation TRN ( x j )onthe hypothesis-instance matrix HIM mn as follows: when the operation TRN ( x j )is executed, HIM mn removes all the i th rows that satisfy the entry ( i, j )being0.
Then the process of active learning can be viewed as that providing a sequence  X  X  X  , TRN ( x t ) one by one. Furthermore, the cu rrent version space can be denoted by the rows of the current HIM mn (after executed several TRN operations).
When HIM mn executes TRN ( x i ), many rows would be removed. The more rows are removed, the faster the versi on space size is reduced. Therefore we define the efficiency of TRN ( x i )as space VS HD and can also be viewed as the probability of the instance x i being misclassified by the version space.
 from the hypotheses with low accuracy. An instance x with high E x implies that x is hard to be classified correctly and m ost of the hypotheses may misclassify x . Therefore if we choose the instance x with the highest E x for labeling, the version space will decrease to several the most accurate hypotheses. Therefore E i is a more efficient criterion than the criterion based on binary searching (e.g. uncertain sampling, QBC etc.). 3.2 Constructing the Strong Classifier Based on Modified The criterion E x i can not be calculated directly .Thenweassumethebaseclas-sifier could represent the whole version space. Thus E x i can be rewritten as: E labeled set. Then E x i is the probability of the unequal decisions on x i made by h D and c .

The target function c is unknown yet. Then we estimate it by constructing a strong classifier by using ensemble methods and enhance the strong classifier by unlabeled instances on which the current base classifier has high certainty.
An ensemble of classifiers is a set of cl assifiers whose individual decisions are combined to classify new instances [9 ]. As Hansen and Salamon had pointed out, an ensemble can be more accurate th an its component classifiers when each component classifier outputs independently and has an accuracy over 1/2 [10]. An important property of a good ensemble for committee-based active learning is diversity [8].

We select DECORATE [11] to generate the ensemble. The DECORATE method generate the ensemble iteratively, learning one new classifier in each iteration and adding it to the current ensemble. It trains a classifier on the given data initially. In each iteration, artificial training instances called diversity instances are generated based on the data distribution. Class labels for these ar-tificial instances are chosen so as to differ maximally from the current ensemble X  X  predictions. Then it trains a new classifier on the union of the original training instances and the diversity instances. If adding this new classifier to the current ensemble increases the ensemble training error, then this classifier is rejected, else it is added to the current ensemble. This process repeated until the desired committee size is reached or a maximum number of iterations is exceeded.
However, errors would be introduced into the ensemble if the artificial in-stances are not consistent with the target function. In current research, unlabeled instances could augment classifiers trai ned on labeled instances. Such ideas in-spired the research on semi-supervised learning. Thus we modified the standard DECORATE method by incorporating the unlabeled instances into the artificial training instances. In each iteration of DECORATE, a few unlabeled instances on which the current ensemble has high cer tainty are chosen, prelabeled by the current ensemble, and added into diversi ty instances. Note tha t these prelabeled instances are just used to train the stronger classifier in the current iteration and still stay in the unlabeled set with no label waiting for active sampling. Those prelabeled instances could prevent the ensemble from overfitting problem and provide distribution information for the ensemble. Therefore, the DECORATE method could preserve its diversity and accuracy. 3.3 Sampling Criterion Based on the efficiency of instances for ver sion space reduction, we specify the sampling criterion as where P  X  D ( x i ) denotes the probability distribution of class label predicted by the modified DECORATE trained on unlabeled set D , P D ( x i ) denotes the proba-bility distribution of class label predicted by the current base classifier trained on D .Then R x i is the entropy of the difference between these two probability distributions.

Therefore, the process of MSDEEUI method is given in Algorithm 1. To evaluate the performance of our M SDEEUI method, we ran a series of ex-periments. Five different active learning algorithms were tested: the Random Algorithm 1. the MSDEEUI method sampling, the Uncertainty sampling [1], QBC [5], Active DECORATE [8] and the MSDEEUI sampling. The experiments were done on 16 representative datasets from machine learning repository provided by UCI [12]. The committee size were set to 5. Naive bayes was selected to be the base classifier. 10-fold cross-validation was used to obtain the target accuracy of the base classifier on the 16 datasets. The target accuracy is defined as the accu racy obtained by the base learning method trained on the whole dataset. All results presented were averages of ten runs. For each dataset, we divided it into 10 equal partitions at random and each in turn is used for testing and the remainder was used as the sampling set. Before the test started, the sampling set was divided into two parts: one is the labeled set and another is the unlabeled set. The labeled set contains only one instance selected randomly and the unl abeled set contains all the rest. When the test started, the active learner sampled 1 instance from the unlabeled set for labeling in each iteration. While the activ e learner reached the target accuracy, the test stopped.
 We summarized the data utilization of the different active learners in Table 1. We define data utilization as the number of instances an active learner requires to reach the target accurate rate. In Table 1, the least data utilization is marked in bold in each row and the number of wins is presented in the last row. In the head of Table 1, the Uncertainty method is denoted by UC, the Active DECORATE method is denoted by AD and Target Accuracy is denoted by TA.

According to Table 1, it shows that our MSDEEUI method has a superior performance than other sampling methods on most datasets. Based on these results, we may conclude that MSDEEUI is more likely to reduce the size of version space as much as possible.

Figure 1 and Figure 2 show the results on the datasets of car and vowel , respectively. In all these figures, the ve rtical axis shows the accuracy of the classifier and the horizontal axis shows the number of labels.
 accuracy(%)
In Figure 1, the Active DECORATE met hod achieves its maximal accuracy 83.67% at about the 291th sampling. Our MSDEEUI method requires 251 sam-pling to obtain the same accuracy. In Figure 2, the Active DECORATE method gets its highest accuracy, about 64.23%, after 291 sampling while the MSDEEUI method reaches the same accuracy at the 161th sampling. Furthermore, the other methods even can not get the accuracy of 64.23% before the 300th sampling. Focusing on the sampling question in pool-based active learning, we visualize the process of version space reduction by prop osing the Hypothesis-Instance matrix and its operation TRN ( x ). Then we propose the MSDEEUI method, which sam-ples the instances with the largest pred iction difference between a strong clas-sifier, generated by the DECORATE method enhanced by unlabeled instances with high prediction certainty, and the current base classifier. Experiments show that the MSDEEUI method is efficient and practical.

We would like to pursue following directions: finding a better function to ob-tain a more precise estimate of the target function and providing the theoretical proof of the converging speed of the version space using the MSDEEUI method. Acknowledgments. This research was supported by the National Natural Sci-ence Foundation of Ch ina (No. 60603015, 60603062).

