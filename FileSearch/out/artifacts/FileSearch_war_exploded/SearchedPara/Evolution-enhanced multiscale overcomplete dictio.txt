 1. Introduction
Overcomplete (or redundancy) is important in transformation-based image denoising methods to have the shift invariance property ( Coifman and Donoho, 1994 ; Bui and Chen, 1998 ). For example, with the growing realization of deficiencies of orthogonal wavelets in denoising images, some redundant multiscale trans-forms have been introduced, inc luding undecimated Wavelets ( Lang et al., 1996 ), Curvelet ( Starck et al., 2002 ), Contourlet ( Do and
Vetterli, 2002 ), Wedgelet ( Demaretetal.,2005 ), Bandelet ( Zhang decade, using spatial overcomplete representation and sparsity for images denoising has drawn much attention of researches ( Elad idea is that the sparse representation (SR) of images will help in automatically selecting the primary components in images while reducing the noise components, a s long as the dictionary can well describe the characteristics of images. In more recent works ( Aharon
Turek et al., 2010 ; Dong et al., 2011 ), image patches prove to well represent the statistical propert ies of the whole image, so a large number of image patches are tak en as the examples from which a dictionary can be learned. The patches are taken from the noisy image and then sparsely represented and restored, which lead to state-of-the-art denoising result.
 well on the natural images ( Aharon et al., 2006 ; Protter and Elad, it has been aware that making avail of the multiscale properties of images will obtain better denoising result ( Bui and Chen, 1998 ; Lang study we take both the overcomplete representations of images in spatial domain and transformation domain into account, and propose a multiscale dictionaries learning approach for image denoising.
Some multiscale overcomplete dictionaries are learned from example scales of images. We reduce the image denoising to an l 0 minimization problem with multiple variables. The available optimi-zation schemes for this NP-hard problem can be mainly divided into two catalogs: approximation method and relaxation method. The approximation method includes greedy algorithms and shrinkage algorithms. A greedy strategy abandons exhaustive search in favor of a series of locally optimal single-term updates. Its basic idea is to represent a signal as a weighted sum of atoms taken from a dictionary, such as matching pursuit ( Mallat and Zhang, 1993 ), orthogonal matching pursuit ( Tropp and Gilbert, 2007 )andtheir variants ( Donoho et al., 2006 ; Needell, 2009 ). The approximation method can correctly pick up atoms in the case of existing sparse characteristics of heavy computation, slow convergence, and can only work well in the noiseless case. T he shrinkage strategy iterates between shrinkage/thresholding operation and projection onto perfect reconstruction, so they are c haracteristic of low computation complexity ( Chen et al., 2001 ; Bioucas-Dias and Figueiredo, 2007 ).
However, they commonly require much iteration when the support of the solutions cannot be determined. The relaxation method includes l 1 -norm and l p -norm methods. Basis pursuit (BP) ( Blumensath and Davies, 2008 ) approximate the solution that mini-mizes l 1 -norm and reduce the problem to a linear programming (LP) structure, which is solvable comparing to the l 0 -norm minimization and is easy to be integrated into other variational model. However, it is a difficult optimization task a nd the tuning of parameter is not straightforward. Moreover, the equivalence of l 0 -norm and l minimization can only achieve under very strict assumption of the sparsity of signals ( Cand es and Wakin, 2008 ). Gradient based methods are discussed in paper ( Figueiredo et al., 2007 )and ( Blumensath and Davies, 2008 ) to solve this problem. The l by the mathematical analysis community, so it is used to serve as a non-convex,itisalmostequivalentto l 0 -norm and can be represented as a weighted l 1 -norm form by the iterative-reweighed-least-squares (IRLS) method. However, this algorithm is very sensitive to the initialization of solution. Moreover, it is guaranteed to converge to a fixed-point that is not necessarily the optimal one.

Evolutionary algorithms (EAs) provide a general and global searching approach for solving combinational and NP-hard opti-mization tasks( De Jong, 2006 ), so in this paper we use EAs to solve the l 0 -norm minimization problem discussed above. Genetic
Algorithm (GA) is one of the effective EAs that simulate natural evolution (crossover, mutation and selection) over populations of candidate solution ( Goldberg, 1989 ). However, GA is character-istic of slow convergence ( Alberto and Carlos, 2003 ). The memetic algorithm (MA) ( Alberto and Carlos, 2003 ; Badillo et al., 2011 ;
Amaya et al., 2010 ; Krasnogor and Smith 2005 ) makes an improvement on GA by combining GA with a local searching operation, and proves to perform much better than GA in terms of the quality of solution and computational cost. In the MA, GA is used for coarse search, while the subsequent local improvement is then used to refine the GA. Its superior performance over GA has been found for various applications, such as combinatorial optimization problems ( Tang et al., 2007 ), control design ( Caponio et al., 2007 ), VLSI design ( Tang and Yao, 2007 ), image segmenta-tion ( Jiao et al., 2010 ) and so on.

In order to tune multiple variables in the optimization pro-blem discussed above, in our study a MA based alternate optimi-zation strategy is employed to optimize the dictionaries and denoise the multiscale images. In the algorithm, two-dimensional individual is adopted to represent a dictionary. The individuals are used to perform a global search, followed by a local search operator, singular value decomposition (SVD), to further reduce the objective function. The dictionaries and sparse coefficients are alternately updated until the stop condition is satisfied. Some experiments are taken on some benchmark natural images to investigate the performance of our proposed method.

The rest of this paper is organized as follows. In Section 2 ,we addressed the classic image denoising problem, and depicted the memetic algorithm-enhanced multiscale dictionaries learning algo-rithm. In Section 3 , some simulation experiments are taken to illustrate the efficiency and superiority of our proposed method to its counterparts. Finally some conclusions are drawn in Section 4 . 2. Evolution-enhanced multiscale dictionaries learning
Considering the classic image denoising problem: an image is measured in the presence of an additive zero-mean white and homogeneous Gaussian noise, with standard deviation s . Thus the measured image is Y  X  X  X  n , and the goal of image denoising is to recover the clean image X from the noisy image Y . 2.1. A. Multiscale overcomplete dictionaries learning
Consider a redundant transformation on the noisy image, and denote R as the transformation dictionary. The noisy image can be written as, Y  X  R b 0  X  R b  X  n  X  1  X  where b 0 and b are the transformation coefficients of the noisy image Y and clean image X , respectively. When the transformation has the redundancy and multiscale property, R is often determined by the frame theory, such as undecimated wavelets frame, or some frame composed by cascade orthogonal bases.

Considering the multiscale property of R , we can reformulate (1) as, Y  X  R b 0  X  R 1 , ... , R N  X  b 0 1 , ... , b 0 N T  X  R 1 where R 1 , y , R N are the N multiscale dictionaries and b the corresponding coefficients. Inspired by the example-based denoising scheme ( Chatterjee and Milanfar, 2009 ), we extract right and top to bottom). Then we use these patches to train a dictionary that is representative of all the image patches and used to recover b j from b 0 j .
 extracted from the multiscale coefficients matrix b j at the spatial patch in b j with its coefficients being ordered lexicographically as column vector. Assume each patch vector b i , j belongs to the under a redundant dictionary D j A R p K that contains K prototype signal-atoms for columns f ~ d m , j g K m  X  1 , that is, b : i : j : 0 5 K , the MAP estimator for denoising this coefficient patch is built by solving ( Elad, 2010 ), f ^ a where P i is a patch extraction operator, Q j is the number of patches extracted from b j , and e and d are dictated by s .
Assume the number of the example patches at each scale take the same value: Q 1  X  y  X  Q N  X  Q , and denote the sparse coeffi-cients of patches in b j under the j th multiscale dictionary D tion problem can then be reduced to, s : t : : R b Y : 2 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : where : a j : 0 , 1 is the l 0 / l 1  X  norm of the matrix summarization of the l 0  X  norm of the columns in the matrix , determined. To simplify the problem, we assume that W is an orthonormal matrix (such as standard orthogonal wavelet trans-form) and R is composed of the shifted version of matrix W : operation. So the formula (4) can be rewritten as, min
KSVD algorithm has been used to solve this form of optimization problem. However, it performs a l ocal searching and cannot assure proposed a memetic algorithm-based optimization method for (5).
We use the individuals to code the multiscale dictionaries { D variables are tuned using the steps shown in the Pseudocode of the proposed algorithm. In the initialization, we randomly generate the dictionary population POP {0}  X  { I 1 (0), I 2 (0), y we randomly generate a number between 0 and 1, if it is smaller than the mutation probability P m , then perform a mutation opera-tion on the population using
I  X  t  X  1  X  X  c 1 I i  X  t  X  X  c 2 Best  X  t  X  0 r c 1 , c 2 r 1 , c where the parameter c 2 controls the degree of the individual moving towards the best individual; else perform the following random mutation,
I  X  t  X  1  X  X  I i  X  t  X  X  g rand  X  7  X  where g controls the mutation intensity. The mutation in (6) emphasizes the guidance of population by the best individual, and the mutation in (7) emphasizes the randomness of evolution.
Experimentally we found that a combination of these two schemes outperforms the sole one. For combing the global searching of evolutionary optimization with the local searching of SVD and
OMP algorithm, the optimized multiscale dictionaries can produce more sparse representation of images and better denoising result.
The flowchart of the algorithm is shown in Fig. 1 . 3. Experimental results performance of our proposed method. All experiments are exe-cuted on a 2.4-GHz Pentium-IV PC with 1-GB RAM. The test natural images are all of size 512 512 and the test SAR images are of size 256 256. 3.1. Experiment 1: denoised result of our method on Lena image ( Elad, 2010 )) to denoise the Lena image with additive zero-mean
Gaussian noise (the variance s  X  20). In our experiment, we let N  X  10, p  X  64, K  X  150, M  X  20, c 1  X  0.3, c 2  X  0.7, 10000, l  X  0.1, P m  X  0.7. Fig. 2 compares the multiscale coefficients b 1 , y , b N of the image recovered by our proposed method. horizontal high-frequency, vertical high-frequency and diagonally high-frequency components at the first scale, respectively. From these we can see that the noises in the four components are all reduced remarkably by our method, especially the D1 component. When the noises existed in the high-frequency and low-frequency components of the noisy image are efficiently removed by the learned dictionaries, the b 1 , ... , b N can be correctly recovered. 3.2. Experiment 2: Comparisons on benchmark natural images
In this experiment, we change the noise level and the perfor-mance of our proposed method is compared with that of Lee filtering, Bayesian Soft threshold (BST)( Abramovich et al., 1998 ), Non-local means (NLM)( Buades and Morela, 2005 ), redundant DCT (RDCT) dictionary and KSVD dictionary learning based methods ( Aharon et al., 2006 ). The number of atoms in RDCT dictionary and KSVD dictionary are the same with that of our method, and the number of training samples in KSVD and our method are the same. The code of KSVD algorithm and RDCT dictionary based denoising algorithm came from http://www.cs.technion.ac.il/ elad/software. The denoised result of Lena image when s  X  20 is shown in Fig. 3 .
Fig. 3 (a) X (f) give the denoised images by Lee, BST, NLM, RDCT, KSVD dictionary learning method ( Aharon et al., 2006 )andourproposed method respectively. From the result we can see that Lee filtering outputs the worst result, and BST cannot reduce the noise com-pletely. The denoised image by NLM is too smooth. RDCT, KSVD dictionary learning and our proposed methods can achieve better result than NLM. Compared with RDCT and KSVD, our proposed method can utilize both the advantages of multiscale denoising and sparse representation based spati al denoising schemes, so resulting higher quality images that well preserve the edges, contours and textures. The amplifications of the local regions in the denoised images are shown in Fig. 4 .

Fig. 4 (a) X (d) show the original image, the recovered images recovered by RDCT, KSVD and our method respectively. From it we can see our proposed method outperforms the other methods in preserving the details and textures. The edges of the hat, the contours of the eye, and the texture of the hair in the image recovered by our method are clearer than that of other methods. The Barbara image and Peppers image are also tested, and the
PSNRs (dB) of the denoised images are shown in Table 1 , with the bold indicated the best result among the four methods. From it we can see that our proposed method has an improvement over
KSVD dictionary learning algorithm Table 2 . 3.3. Experiment 3: comparison result of MA with GA
In this test, we take the Lena image as an example to investigate the efficiency of the memetic algorithm optimization in our method. We let the population size M  X  1, 20, 50, respec-tively, and compare the performance of memetic algorithm with
GA. The mutation and crossover probabilities are set as 0.3 and 0.7, respectively. Both the denoised result and the consumed time are considered. Considering the randomness of the initialization, ten independent experiments are taken and the average result is shown in Table 3 . From it we can see that MA outperforms GA in
PSNRs because GA is often trapped into local minimums. More-over, MA combines the local searching operator with the global searching of EAs, so achieving rapider convergence than GA.
Moreover, experimentally we found that when M is larger than 50, no remarkable improvement can be observed for MA and GA. the performance of our proposed method with different muta-tions. We compare our proposed mutation scheme with two sole ones, which are denoted as best strategy and random strategy, respectively. The denoised result after some iteration is shown in Table 3 . From the result we can see that the  X  X  X est strategy X  X  converge rapidly but is reliable to be trapped into local minimum,  X  X  X andom strategy X  X  is good at exploiting the possible solution space. A combination of the two schemes will be helpful in obtaining a stable and rapid convergence in the evolution. 4. Conclusions
In this paper we proposed a new evolution-enhanced multi-scale overcomplete dictionary learning method for image denois-ing. The main contribution of the paper can be summarized as, 1) We combined the multiscale image denoising method with the recent developed SR-based spatial denois ing approach, and pro-posed a multiscale overcomplete dictionaries learning approach for image denoising. Then we reduce the dictionary learning to a
NP-hard l 0 -norm minimization problem with multiple variables. 2) In order to solve the NP-hard optimization problem, we proposed a memetic algorithm-enhanced me thod to alternately optimize the variables. The algorithm has the capability of global searching, so outperforms the available optimization problems in reducing the noise existed in images. 3) Some experiments are taken on investigating our proposed method using some benchmark images, and the denoised images are better than the state-of-the-art result in PSNR. Acknowledgments
The authors would like to thank the anonymous reviewers for their constructive comments. This work was supported by the
National Science Foundation of China under Grant nos. 61072108, 60601029 and 60971112, the Program of NCET-10-0668, the
Basic Science Research Fund in Xidian University under Grant no. JY10000902041, the Science Foundation of Shaanxi Province under Grant no. 2006F25 and the Scientific Research Project Funded by Baoji University of Arts and Sciences (Grant no. ZK09167).
 References
