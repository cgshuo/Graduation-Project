 Logistic average misclassification percentage (lam%) is a key demonstrates that a spam filter can achieve a perfect 0.00% in lam%, the minimal value in theory, by simply setting a biased threshold during the classifier m odeling. At the same time, the overall classification performance reaches only a low accuracy. The result suggests that the role of lam% for spam filtering evaluation should be re-examined. H.3.3 [Information Storage and Re trieval]: Information Search and Retrieval -Information filtering Algorithms, Measurement, Performance, Theory Spam Filtering; Lam%; Measurement The spam filtering is generally rega rded as a binary classification task to identify spams from normal e-mails (i.e. hams). To evaluate the performance of spam filters, the overall classification accuracy (or the total proportion of misclassified messages) is not a good choice because all errors are treated on equal footing. Nevertheless, the logistic average misclassification percentage (lam%), a single quality measure based only on the filter X  X  binary which hm % is ham misclassification percentage, and sm% is spam misclassification percentage[1]. As the geometric mean of the odds of ham and spam miscla ssification[1], lam% is widely adopted together with 1-AUC by open spam filtering competitions including TREC Spam Filtering Track and CEAS(Conference on Email and Anti-Spam) Spam-filter Challenge. The lam% is or spam misclassification, reward ing equally an improvement in the odds of either. However, this paper demonstrates that lam% is inherently defected in allowing a 0.00% by a biased threshold, reliable enough to observe only la m% as the measure for spam filtering evaluation. (y spam | x ) exp(x w)/(1+exp(x w)) p == X   X  rrrrr  X  1  X  where i x Equation 1, the prediction value is converted between 0 and 1 following presents the pseudo code of LR. Algorithm 1: Logistic Regression (1) w r = 0 ; //initialize weights to 0 (3) (4) if ( p &gt;0.5 ) predict spam; (5) else predict ham; (7) w (8) else w where TRAIN_RATE is the learning rate, i.e. the learning speed, y in Line 2 and Line 6 is the golden judgment of x i . Line 4 and 5). As mentioned in Section 2, lam% can be optimized by setting the biased threshold. Th e threshold can be set nearly to 1 or 0, which can decrease hm% or sm% to 0. LR with the biased threshold is referred as biased LR . For biased LR, pseudo codes prediction scores of messages are not biased (i.e. not changed). TONE (Train On or Near Error) is adopted to train the spam filter in the actually modeling process. Two types of samples are classified samples if falling with in a predefined classification boundary. Character 4-grams, the first 3,200 features of each message and binary feature scoring are used similar to ref. [2]. We evaluated the lam% optimization method on TREC public shown in Table 1. Table 2 shows the experimental results which are acquired by TREC Spam Filter Evaluation Toolkit. hm%, sm% and 1-AUC are also reported . The parameters of LR and the biased LR are the same except the threshold: TRAIN_RATE = 0.002, TONE = 0.45, and threshold = 0.999999 for biased LR. proposed method decreases lam% to 0.00%, i.e. the minimal value in theory, across all datase ts. Although lam% is perfect, the accuracy of the filters for most cases is below 50%, i.e. the performance of random guess. Therefore, there is an obvious defect in lam% as the measure for spam filtering evaluation. It is very interesting that 1-AUC (area under the ROC curve), the other measure of spam filtering, is left untouched when biasing the threshold. This means that optimizing lam% method proposed 
