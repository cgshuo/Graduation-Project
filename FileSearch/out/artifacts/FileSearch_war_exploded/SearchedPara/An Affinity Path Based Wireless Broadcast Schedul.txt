 The rapid development of wireless communica tion technology leads to the increasing ment. Due to the asymmetry in the wireless communication environment and the a large number of clients, the data broadcasting has become an attractive and efficient solution for data dissemination [1, 2]. 
Lots of researchers have proposed their methods on designing broadcast schedules called QEM. The measure Query Distance (QD) is defined, which shows the coher-their referencing together in a query. Secondly, combine the pair with the highest data with the highest segment affinity in sequence. 
In this paper, we investigate an efficient broadcast scheduling approach called the root rule [6]. The experiment results show that the affinity path approach could attain a considerable improvement. 
The organization of the rest part is as follows. We first present a formal definition describe the affinity path approach in section 3. The performance evaluation is illus-trated in Section 4, and finally all of the above comes to a conclusion in section 5. We first introduce some notations which will be used in the rest of the paper. d i : a data item in the database. N : the number of data in the database. 
D : the set of database, where D ={ d 1 , d 2 , ...... d N }. q i : a query issued by a mobile client which access at least two data items. M : the number of queries in Q . Q : the set of all queries, where Q ={ q 1 , q 2 , ...... q M }. 
QDS ( qi ) : the set of data items that q i accesses (Query Data Set). freq ( q i ) : the reference frequency of the query q i .  X  : the broadcast schedule. The problem of data scheduling in this paper is to find a broadcast schedule  X  which minimizes total access time ( TAT ) [7], denoted by Where ) , (  X  items d i and d j , which is defined in [5]: Where 1 ) , ( =
Actually, the affinity of two data items is the sum of frequencies of queries that ac-cess both of them. The affinity of a pair of data items will be high if they are required together by many queries. 3.1 Motivation plex because we must consider the access frequency of both data item and request. If accessed by a query, there may exist many half-satisfied queries, which means some of the data items they require are satisfied while some are not. As a result, the average access time is prolonged greatly. On the other hand, if we focus mainly on the access frequency of queries and satisfy the query with all the data items it requires at a time, large QDS . We can see the consideration of both data items and requests in the defini-tion of data affinity. So it is a reason able parameter used in our approach. 
In most of previous studies of broadcast scheduling for multi-item queries, re-searchers do not consider data replication which means each data item appears exactly consideration. 3.2 An Example that there are 12 data items and 11 queries, and the frequency values and data sets of queries are as Table 1. 
We first construct a weighted graph that contains 12 vertexes, each vertex denotes a data item. There is an edge between two data items if the data affinity between the with edges, which is selected in E . It must satisfy the following tow conditions: 1) it in the same way from the endpoint of the edge with the larger weight until the other d tending the current path, delete all the edge between any two vertexes in the path from other path in the same way. For the above example, we can create seven paths which are listed in Table 2. 
At last, we consider each path as a whole data item with the same size, and then we broadcast the path base on the square root rule, where the probability of a path refers we have considered the affect of length in calculating average weight of path. 3.3 Algorithm We describe the affinity path approach by three steps as follows: Step 1: construct graph denote a data item, every pair of vertexes have a edge with a weight which equals to the affinity of the corresponding pair of data items. The algorithm is described as follows. Input: The set of data items D = { d 1 , d 2 , ...... d N }. Output : a graph G = ( V , E ). Algorithm: 1. for each data item d i , create a corresponding vertex v i in the graph; 2. if( aff ( d i , d j ) &gt; 0){ 3. create a edge e ( d i , d j ) between v i and v j ; 4. weight ( e ( v i , v j )) = a ff ( d i , d j ); 5. } Step 2: create paths must be the one with largest weight among all the candidates and will be deleted from path in the similar way until the two vertexes of the selected edge are both included in between the vertexes that selected to the path and calculate the average weight for the next step. We continue to create other paths until no edge exists in G . The algorithm is described as follows. Input: the weighted graph G . Output: the PathSet containing sets of affinity paths with average weight. Algorithm: 1. initiate PathSet = empty; 2. while( E is not empty){ 3. find edge e ( v a , v b ) in E with largest weight; 4. initiate Plist = { v a , v b }; 5. delete e ( v a , v b ) from E ; 6. set v t = the vertex with larger value of frequency between v a and v b ; 7. while( E is not empty){ 8. find the edge e ( v t , v s ) in E with largest weight; 9. if( v s already exist in Plist ) break; 10. else extend Plist with e ( v t , v s ); 11. delete e ( v t , v s ) in E ; 12. set v t = the endpoint of the edge with the larger weight between the head 13. } 14. add Plist into PathSet ; 15. calculate the average weight of Plist ; 16. } Step 3: broadcast path We consider each path as a whole data item with the same size, and then we broadcast the path based on the square root rule [6], where the probability of a path refers to its average weight. proach proposed in [5]. In our experiment, the parameter of Zipf distribution X  X  default value is 1. The default value of both number of query types and data items is 500. The quently in the affinity path approach, while in the data clustering approach all the data have a broadcast interval equal to the length of periodic cycle, that is each data items cially suitable for scheduling multi-item queries with skewed access probability. 
The effect of number of data items is showed in our second experiment. The result Fig.2. With the increase of number of data items for the data clustering approach, the length of periodic cycle is increasing linearly and the average access time is increas-periodic cycle. While in the affinity path approach, the performance of average access time is less affect by increase of number of data items because of data replication. ries. Most previous works are based on th e consumption that each data item appears users X  access and brings poor performance. 
To find an efficient solution, we loosen the restriction that each data item appears exactly once in a periodic cycle. In the affinity path approach, we create affinity paths based on the affinity between different data items and broadcast these paths according access possibility of data items is skewed. 
