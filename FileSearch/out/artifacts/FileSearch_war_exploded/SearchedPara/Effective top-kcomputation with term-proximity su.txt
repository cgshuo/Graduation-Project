 1. Introduction
Major commercial web search engines (Google, 1 Yahoo!, 2 Live Search, 3 etc.) have grown to index billions of pages. In spite of such large amount of data, end users expect search results being retrieved quickly with high accuracy. In web search, as the the relevance computation of some documents. Efficient top-k computation, which aims to return the correct top-k results as 2006a,b; Fagin, 2002; Long &amp; Suel, 2003 ) have been proposed for this purpose.
 In most papers studying efficient top-k computation, ranking functions in the following form are usually assumed cient top-k algorithm exists.

In addition to those factors in Formula (1.1), the search quality of modern search engines depends heavily on some other evidence, such as document structure and term-proximity . Document structure means that a web page often comprises multi-ple fields (title, URL, body text, etc). It has been proved that an appropriate usage of document field structure can improve search results effectively. Term-proximity demonstrates how close query terms appear in a document. Intuitively, one doc-ument with high term-proximity values (i.e. query terms are near in the document) should be more relevant to the query than another document in which query terms are far away from one another, given that other factors are the same for the two documents. Take query  X  X  X nowledge management X  as an example. It is clear that quite a lot of pages on the web con-taining both  X  X  X nowledge X  and  X  X  X anagement X  are actually irrelevant to knowledge management. On the other hand, a doc-ument, in which term  X  X  X nowledge X  is always followed by term  X  X  X anagement X , is much probably related to  X  X  X nowledge management X .

Due to the importance of term-proximity and document structure in modern commercial search engines, efficient top-k computation approaches should be studied by considering these factors. Unfortunately, although quite a few indexing prun-ing strategies have been proposed, few of them consider term-proximity in the ranking functions. With term-proximity and document structure information being considered, the ranking functions would become more complex (see the analysis in Zhu, Shi, Li, &amp; Wen, 2007 ). More importantly, term-proximity makes a ranking function NOT monotonic (w.r.t. query term scores) any more. Since term-proximity is determined by the relationship between all query terms rather than one single query term, a document with low term score values may have a high term-proximity score (and therefore a high overall rel-evance score), and vice versa. This adds additional challenges to the efficient top-k computation problem.
In our recent work ( Zhu et al. 2007 ) we addressed the problem of efficient top-k computation with term-proximity sup-port. According to our study, most existing top-k strategies become quite inefficient with term-proximity information being included, partially due to the non-monotonicity of the new ranking functions. We then propose two index structures and their corresponding pruning strategies, which efficiently address the top-k problem by utilizing web page structure information.

In this paper, we make a more comprehensive study on this problem in addition to our previous work. First, we study the possibility of adopting additional techniques to further improve top-k computation efficiency. We propose the Proximity-Probe Heuristic to further improve the performance. Experimental results show that some ineffective top-k algorithms can get back to work with this heuristic. Second, we study the problem on more settings. In terms of ranking functions, we test and compare the efficiency of different approaches using a non-linear ranking function as well as a linear one. In terms of result quality, we conduct experiments in the case of accurate top-k and approximate top-k, respectively.
The rest of this paper is organized as follows. Section 2 introduces the preliminary knowledge and related efforts. In Sec-tion 3, we first introduce how to adopt the Proximity-Probe Heuristic upon the work in Zhu et al. (2007) for more efficient top-k processing; then we exploit the top-k problem with more settings like non-linear ranking function and the approxi-mate top-k results. The experiment results are presented in Section 4. Finally we draw the conclusion in Section 5 . 2. Backgrou nd and related work
In this section, we first give some background concepts related to top-k computation. Then we briefly introduce the tra-ditional top-k approaches for web search and other related work. 2.1. Background
Indexing and ranking are two key components of a web search engine. To support efficient retrieval, a web collection needs to be offline indexed. Given a query, one ranking function is adopted to compute a relevance score for each document based on the information stored in the index. The documents are then sorted by their scores and the top-k documents with the highest scores are returned to end users.

One primary way of indexing large scale web documents is the inverted index, which organizes document collection (DocIds, occurring positions, etc.) of all documents containing the term. Zobel and Moffat (2006) give a comprehensive intro-duction to inverted index for text search engines. 2.2. Efficient top-k processing without term-proximity
Various dynamic index pruning techniques have been proposed for efficient top-k computation. They aim to correctly identify the top-k results without completely scanning inverted lists and/or computing the relevance scores of all docu-ments. One common idea shared among most existing efficient query processing approaches is score upper-bound estimation and early stopping , which are derived from Fagin X  X  TA algorithm (Fagin, 1996; Fagin, 2002; Fagin, Lotem, &amp; Naor, 2001 ).
During processing a query, the maximal possible score of all unseen (i.e. un-evaluated) documents is estimated. When the maximal possible score is not greater than the score of the k th document in current top-k list, we can skip processing the remaining documents and return the current top-k results to users. Let S k be the score of the k th document (in terms of relevance scores) in processing a query, and S T be the maximum possible score of all un-evaluated documents. Then the early-stopping condition is
How to organize inverted indexes is the key to index pruning. For example, if documents are naturally ordered by DocIds ing factors of unseen documents. The primary idea of optimizing the index structures is to put documents with higher scor-ing factors at the top of an inverted list. So S T can be lowered down quickly.
 For ranking function 1.1, S T is composed by two parts: the upper bound of static rank and term score.

Order by static rank : By sorting inverted index in the descending order of static rank, G upper can be constrained when we access the index as we can expect the subsequent documents have smaller static rank. However, most likely the a value crease of G upper cannot significantly lower down S T accordingly. In our previous study, this index structure hardly achieves any performance gain.
 1996) a more advanced index structure is proposed. This structure divides an inverted list into multiple segments according to one type of specific term impact values, with documents in each segment ordered by DocIds or static rank. The phrase  X  X  X erm impact X  here may refer term scores, term frequency or other factors related to the relevance score of a document to a term. Generally the segment containing high term impact documents is accessed first. So we can have a lower estimation of T upper ( t ) in the lower segment. While within each segment the descending order of static rank helps decrease G upper . This strategy is popular in web search as it X  X  effective with not too many complex additional efforts. 2.3. Related work
In database community, Fagin (1996, 2002) and Fagin et al. (2001) have a series of fundamental work on efficient top-k computation. As Fagin (2002) states, if multiple inverted lists are sorted by the attributes value, and the combination func-tion is monotonic, an efficient top-k algorithm exists.

In information retrieval area, the work of index pruning could go back to 1980s. Some earlier works are described in 1995). Their main idea is to sort the entries by their contribution to the score of the document and put the important entries in the front of inverted index for early termination. Anh and Moffat (2006a), Kaushik, Krishnamurthy, Naughton, and Rama-krishnan, (2004) have attempted to optimize the index structure in various ways. Persin et al. (1996) propose to partition the inverted list into several parts. When PageRank shows its power in web search, pruning techniques considering PageRank are studied in Long and Suel (2003) . Ntoulas and Cho (2007) study the keyword locality and document locality to get an opti-mized ratio between small index and full index in the parallel processing scenario.
 index size by keeping only relatively important information of the inverted index. Particularly, Blanco (2008) gives a com-prehensive study on the index optimization of information retrieval systems. However, in this paper, we focus on the dynamic index pruning problem which skips the computation of some document scores at query execution time.

We noticed a very interesting study of efficient text proximity search (Schenkel, Broschart, Hwang, Theobald, &amp; Weikum, 2007). In this paper, pre-computed and materialized index structures are proposed to boost the top-k processing perfor-mance. However, their work is more like a database style implementation and not applicable in real commercial web search scenarios.

Broder, Carmel, Herscovici, Soffer and Zien (2003) treat query evaluation as a two-stage process. In the first stage they retrieve and score the documents containing every query term. If the number of scored documents is greater than k , the process stops; otherwise they continue to look for documents contains only part of the query terms. The principle of giving documents containing all query terms the high priority inspires us to study the similar properties in our proposed Proximity-Probe Heuristic.

Approximate ( Fagin, 2002 ) and probabilistic (Theobald, Weikum, &amp; Schenkel, 2004 ) top-k computation are also important to web search. By relaxing result quality requirements, query processing efficiency has more space to be improved. Many work in Database area like Theobald et al. (2004) analyze the probabilistic top-k computation based on the property distri-bution over inverted lists. However, they are based on the conventional scoring functions without considering proximity and web page structure. With more factors involved, it becomes much more complex to make such estimations. Then we give the experimental study of approximate top-k processing approaches under the new settings in Section 4.
 3. Term-proximity-enabled top-k computation
In this section, we first review our previous work in Zhu et al. (2007) which discusses how to compute top-k results effi-ciently for a typical ranking function where the score of a document is the linear combination of static rank, term-weights, and term-proximity scores. Then we introduce our Proximity-Probe rules and demonstrate how they work together with our existing strategies to further improve search performance. Finally we exploit more factors for top-k processing, including the situations with non-linear ranking functions and approximate top-k processing. 3.1. Efficient top-k processing by exploiting document structure
In our previous work (Zhu et al. 2007 ), we mainly consider the following typical ranking function which supports term-proximity and document structure pressed as follows, following constraints,
In order to adopt the early-stopping rule (Formula (2.1)) to generate the top-k results efficiently, the maximal possible score S T of all unseen documents has to be properly estimated. For the ranking function in Formula (3.1), S T can typically be estimated as, where X max is the estimated maximum possible term-proximity score.

As term-proximity scores are determined by the distance between query terms, it is not anymore a monotonic function of term weighting scores. Therefore small term weighting scores do not imply a low term-proximity score. It is hard for tradi-tional approaches to find an accurate estimation of the maximum possible term-proximity score X max , because the index structures they adopted are mainly for lowering down the estimation of G upper (i.e., the score upper-bound of static-rank) X max = 1.0.

Our experiments in Zhu et al. (2007) showed that traditional top-k algorithms become quite ineffective for the ranking function in Formula (3.1) when the c value is larger than a threshold. In that paper, we proposed an effective approach by organizing each inverted list into two segments: a fancy segment and a body segment. The body segment contains all the term hits which appear in the body field of documents. While the fancy segment contains the hits of other document fields (title, URL, and anchor text). The documents in each segment are sorted by static rank. We call such an index format pute accurate top-k results efficiently using such an index structure. In addition, they sort documents by DocId rather than static-rank. We are motivated to investigate such an index format by the observation that the body text of a web page is typically longer than other fields (e.g., title, URL, and anchor-text) but relatively less important in ranking functions. With such an index structure, a three-phase strategy is adopted to process queries. In the first phase, all documents in the first segment (i.e., the fancy segment) is loaded and evaluated. Because the body scores of documents have not been available in this phase, a candidate documents accumulator A is maintained to record the minimal and maximal score of the docu-ments which have the possibility of being in top-k . Then in the second phase, documents in the body segment are sequen-tially evaluated and the early-stopping condition (Formula (2.1)) is periodically checked. Once the early-stopping condition is satisfied, we know it is safe to skip evaluating all the documents which are not in the accumulator A ; and then we enter into the third phase. In the third (and last) phase, the body segment is continually scanned and the documents which are in the pseudo-codes of query processing. One important operation is to estimate the minimal and maximal score of a document d . When we are in the fancy segments, d .minscore can be estimated by assuming a zero body score (i.e., no query terms appearing in d  X  X  body text). Similarly, we estimate d .maxscore by assuming the maximal possible body score a document could have. When come to the body segments, we have enough information to compute the accurate score of a document: d .minscore = d .maxscore = d .score. Once we get the estimated minimal and maximal scores of a document, we check or if the minimal score of d is larger than the smallest score in the list. S K may be updated (to become larger) after a new document is added into R .

In our settings, the fancy segment contains three fields: title, URL, and anchor text. The title of a web page is the small page is mentioned in other pages. Since the fancy segments are relatively small in size (compared with their corresponding body segments), we could process them very quickly when processing a query. When we come to the body segments, only the term-proximity upper bound of the body segment needs to be estimated. Therefore one main advantage of this index structure is that we are able to get a more precise estimation of X max when scanning the body segment, as follows,
As l body is much less than 1.0 (recall that P F
In addition to dividing the inverted lists by document structure, we can further split the body segment into two segments: body_high , and body_low . The body_high segment contains documents with relatively high term weighting scores (i.e.
T ( F body , t ) is larger than a threshold). And the documents with low term weighting scores are in the segment body_low .
The documents in each segment are still sorted in descending order by static rank. The hybrid index structure is expected to combine the merits of two index structures: structured , and multi-impact .

Experimental results showed that the query processing strategies based on the above two index structures are able to achieve up to one order of magnitude of performance improvement for typically settings. Please refer to Zhu et al. (2007) for more details of the proposed index structures and their corresponding query processing strategies. 3.2. The Proximity-Probe Heuristic The approaches in the previous subsection aim to achieve early stopping by adopting document structure information. With early stopping, we are able to reduce the number of documents being accessed or processed. When term-proximity is included in ranking functions, we observed that it is much more time-consuming to compute the term-proximity score of a document than its term-score, because term-proximity score computation needs to access all hits of the query terms in the document and to calculate the distance between hits. If we can avoid the term-proximity score calculation of some documents whose term-scores have been computed, we can save more query processing time. We call a document is fully evaluated if both the term score and the term-proximity score of the document is computed. In contrast, if the term score of a document is computed while its term-proximity score computation is skipped, we call this document is partially evaluated. Here we study in this subsection a top-k enhancement technique which improves top-k processing efficiency by reducing the number of documents being fully evaluated.
 Thus we have the following heuristic for accelerating top-k computation, gated term score (over all the query terms and fields), and X max ( D ) is the estimated maximal term-proximity score of the document. Assume G ( D ) and T ( D ) is available, it is safe to skip the term-proximity score computation of document D if the following formula is satisfied,
The correctness of the above heuristic is straightforward. The satisfaction of Formula (3.6) means the maximal possible calculating the term-proximity score of the document. Please pay attention that the above estimations are document-dependent.

According to the above heuristic, we can speed up top-k computation by the following way. For a document D in the doc-performing the term-proximity score calculation, we first combine the estimated maximal term-proximity score of the doc-ument with the actually computed term scores to get an estimated maximal overall score. If the estimated overall score is less than the minimal score of the k th document, we skip the document without actually computing its term-proximity score. Now the problem is how to precisely compute X max ( D ), the maximal possible term-proximity score of document D . Assuming the Structured index format (referring to Section 3.1) is adopted, we have, of document D in field i . Refer to Formula (3.3), the proximity score is made up of the individual term-proximity scores in each fields. So the maximal term-proximity score is determined by which fields the index segment contains. For the Struc-tured index format, we first access the fancy segment and use the combination of the maximal possible term-proximity scores of all fields as the estimated maximal term-proximity score of the document; then after we processed the fancy seg-ment and come to the body segment, X max ( D , Q ) can be estimated as the combination of the maximal possible term-proximity subsection, the Structured index also helps when we adopt the Proximity-Probe heuristic to estimate the maximal proximity score.
 term-proximity score of field i in document D . Here we propose two term-proximity score estimation (TPE) rules: TPE Rule-1: X max ( D , F i , Q ) = 1.0
By rule-1, we set the maximal possible score as 1.0 (the maximal possible term-proximity score for all documents) for each field of the document. This is a loose and coarse-grained estimation which does not consider the information about the document we have in hand at the moment.
 TPE Rule-2: X max ( D , F i , Q )= r (| Q |, m ) 1.0
In the above rule, | Q | is the query length (i.e., number of query terms), m is the number of distinct query terms occurred in the characteristics of term-proximity, we find that the maximal possible term-proximity score of a document D can be esti-mated to be less than 1.0 if we have some knowledge about the document. Intuitively, if we have already known that not all the query terms appear in one specific field of one document, the term-proximity score of the field should be smaller than the maximal possible term-proximity score. Here we take one simple term-proximity function to illustrate the TPE rule-2.
 aggregatingtheinversesquare ofthedistancebetweenquery termsforevery termpair. Givenaquery Q containingthreequery terms Q = {t1,t2,t3},assumeonlytwoofthethreequerytermsappearinthefield F i ofdocument D 1 .AccordingtoFormula (3.8),
For different term-proximity functions, function r ( n , m ) may be different. However, for any reasonable term-proximity function, a document should not achieve the maximal term-proximity score if it does not contain all the query terms. There-fore r ( n , m ) should be less than 1.0 if m &lt; n . 3.3. More factors for performance comparison
There are different settings for the top-k problem we discussed. Here we exploit two popular variants. First we study the problem when the ranking function is non-linear; then we raise the problem of approximate top-k processing. 3.3.1. Non-linear ranking functions
Besides the popular linear ranking function like Formula (3.2), there could be also non-linear ranking functions. Here we propose a simple heuristic ranking function as Formula (3.5) to study the term-proximity problem,
It is not hard to verify that all of the top-k approaches already discussed can be adapted to support the above non-linear ranking function. With such a ranking function, the potential max score S T for unknown documents is like Formula (3.10) . Similar to the situations in the linear ranking function, the term-proximity score factor c x max prevents us from estimating S effectively in traditional top-k strategies.
 However, with the structured index, the expression of S T is changed from Formula (3.10) to
Then it is easier to lower down the estimated value of S T . We give the experimental study with such a non-linear ranking function in Section 4. 3.3.2. Approximate top-k vs. accurate top-k
It is good for a system to return  X  X  X ccurate X  top-k results efficiently. There are, however, many circumstances (especially in large scale web search) where approximate top-k (Burrows, 1999; Fagin et al., 2001 ) results are enough to meet the users X  information needs. For two items scored 0.914 and 0.915 respectively, users may not care about the relative order between them. Strictly speaking, item scores computed by most (if not all) ranking functions are actually just an approximate measure of the  X  X  real  X  score. Any top-k results ordered by such scores are therefore not strictly accurate.

According to Fagin et al. (2001) , k items r 1 , r 2 , ... , r k is an h -approximation to the top-k results if and only if where t ( r ) denotes the score of item r .

Here parameter h indicates how fuzzy the ranking results can be tolerated. When h = 1, we have the exact or accurate top-k results. We will compare, via experiments, the performance of different approaches by varying h values. 4. Experiments
We now describe the experimental setup and analyze the results. In Subsection 4.1, we discuss the experimental study of the top-k processing with our proposed index structure for different settings. In Subsection 4.2, we present and evaluate the performance of our proposed structure with the Proximity-Probe Heuristic.

Datasets : We use two TREC 4 test collections in the experiment. The GOV collection consists of about 1.25 million web pages crawled from web sites in the  X  X .gov X  domain in 2002; and the GOV2 corpus is a crawl of .gov sites in early 2004 with around 25 million web pages (Refer to http://www.ir.dcs.gla.ac.uk/test_collections/ for more information about the two collections). For corpus GOV, we only keep html pages (about 1 million), while documents of other types (such as pdf, doc, etc) are discarded. For the GOV corpus, we conduct our experiments on query sets 2004mixed. For the GOV2 corpus, we perform experiments on query set 2004tera which was used in the Terabyte track of TREC in 2004 and 2005. Details of the query sets are shown in Table 1. We choose data collections of different sizes and queries of different types. This allows us to test and compare the performance of various index structures and pruning strategies by various settings.

Hardware and Software Environment : For the GOV dataset, experiments are carried out on a single machine with Dual 3.06 GHz Intel Xeon CPU, 4G RAM and 600 GB local SATA disk. While for corpus GOV2, we distributed its documents to 5 machines (via URL hashing), with each machine having about 5 million documents indexed. The 5 nodes exchange link infor-mation by network communication, based on which each document X  X  static rank is computed and its anchor text is accumu-lated. Only one CPU per machine is used in the pruning experiments, i.e. we are running a single-thread program on each machine.
 Index Structures : We compare 4 kinds of index structures as follows.
 BASE: The documents in each inverted list are sorted by DocId and no pruning strategies are performed.
 PR-1: The documents in each inverted list are sorted by PageRank. In Subsection 2.2, it is the Order by Static Rank .
IMPACT-2: Each inverted list has two segments: a high score segment, and a low score segment. Documents in each seg-ment are sorted by PageRank. In Subsection 2.2, it is the Multi-segment Divided by Impact Values .

STRUCTURED: Each inverted list contains a fancy segment and a body segment, with documents in both segments sorted by PageRank.
 Algorithm and Parameters: Two ranking functions are adopted in the experiments: the linear ranking function expressed in Formula (3.1), and non-linear function in Formula (3.9). In both ranking functions, the term score for each field is computed via the BM25 formula ( Robertson et al., 1994 ) with parameters k 1 = 1.0 and b = 0.66. The field scores are aggregated like in Song et al. (2004) . We vary some key ranking function parameters (listed in Table 2 ) in experiments to compare the perfor-mance of different approaches.

Evaluation Metrics : There are basically two kinds of metrics for evaluating a top-k algorithm: search quality (P@10, aver-age precision, etc.), and processing performance (average query processing time, throughput, etc.). As the top-k processing concern and we focus on the measure of the query processing performance. However, we list a group of search quality results in Table 3 for reference purpose. Please be noticed that the parameters are not specifically optimized for the highest quality and we did not include some useful features like HostRank and advanced URL scoring in Song et al. (2004) .
 4.1. With and without term-proximity
We evaluate the performance of various index structures and pruning strategies before and after term-proximity infor-mation is considered in ranking functions. Figs. 2 and 3 show the average query processing time of various algorithms for some selected term-proximity weight values. The results are acquired by using query set 2004tera (corresponding to dataset GOV2), and 2004mixed (corresponding to the GOV dataset) respectively. Some observations can be made from these results.
First, although the IMPACT-2 approach behaves well without term-proximity, its performance drops rapidly when the weights of term-proximity get larger. When the term-proximity weight is large enough, IMPACT-2 even performs worse than the baseline. Second, the performance of STRUCTURED is significantly better than the others when term-proximity weight is bigger than a threshold (0.1 in the figures); it could save more than 80% query execution time for all term-proximity weights.
Third, no significant performance gains can be acquired with the PR-1 strategy. This is consistent with the statements in Long and Suel (2003) . PR-1 can improve performance only when the weight of static rank is extremely high.All experimental re-sults demonstrated in the above are for accurate top-k . To evaluate the efficiency of our proposed strategies for approximate top-k processing, we set different values for the approximate factor h (referring to Section 3.3.2). Generally, high h values make the stop condition easier to be satisfied, which will improve top-k efficiency. However, inaccurate results may be re-turned with large h values. Fig. 4 shows the performance of different top-k approaches using the linear ranking function, with our newly-proposed approaches are constantly superior to existing top-k strategies for all h values. 4.2. Evaluate the Proximity-Probe Heuristic
In Subsection 3.2, we propose the Proximity-Probe Heuristic specifically aiming to reduce the number of documents whose term-proximity scores are computed. Here we conduct experiments to verify whether the heuristic can give real per-formance gains.
 In Table 4 , we list the average query execution time with different index structures with or without the Proximity-Probe umns list the results after the heuristic being adopted. We can see from the table that the performance improvement is remarkable after the heuristic is utilized. It can also be observed that the Proximity-Probe Heuristic boosts more for the in-dex structures with poor performance before. Specifically, the average query execution time of PR-1 drops from around 0.508 s to less than 0.1 s. This makes a big difference as we can achieve significant improvement on the simple PR-1 struc-ture. For IMPACT-2, we can also achieve over 50% of advance in the performance. For previously well performed STRUC-TURED we can still save 20% of average query execution time with the Proximity-Probe Heuristic. We can see that TPE Rule-2 gives further improvement over TPE Rule-1. Please note that it X  X  hard to apply TPE rule-2 to the IMPACT-2 index structure. As for the IMPACT-2, one document appear in one term X  X  high term impact segment may appear in another term X  X  low segment. When processing one segment, we may have one document X  X  partial hit information and it is hard to know the m value in TPE Rule-2.

As the Proximity-Probe Heuristic is adopted to save the processing time by skipping unnecessary term-proximity com-putations, we list the average proximity calculation times in Table 5 . It is very clear that most term-proximity computations are skipped with the Proximity-Probe Heuristic. And TPE Rule-2 can save more proximity calculations than TPE Rule-1. The most representative case is in the second row, without the Proximity-Probe Heuristic, PR-1 has to compute the term-prox-imity score for almost every document like BASE. However, we find that actually more than 99% of the calculations can be avoided after the Proximity-Probe Heuristic is applied. That X  X  why PR-1 has the most significant performance improvement (even performs better than IMPACT-2). Another interesting observation is that, with TPE Rule-2, PR-1 does even less prox-imity calculations than STRUCTURED, while taking longer query execution time. This is because PR-1 still has to access much more documents for term score evaluation, although the time for proximity calculation is reduced.
 In Fig. 5 , we give the experimental results on the non-linear ranking function discussed in Section 3.3.1 with a G = 2.0. Fig. 5 shows the average query processing time of various algorithms for some selected term-proximity weight values. Un-like the linear ranking function, we can see that the performance of IMPACT-2 and STRUCTURED are comparable when the proximity score weight is smaller than 0.5. Besides, we find the Proximity-Probe Heuristic gives extra performance gain for egies are still effective.

The above results prove that we can save more computational efforts by adopting the Proximity-Probe Heuristic. And the significance is that we can make the traditional index structure which has no pruning effect get back to work with this heuristic. 5. Conclusions
In summary, when ranking functions are fortified with term-proximity factors, top-k problem becomes much more dif-ficult due to the fact that the ranking functions are not monotone any more. In our previous study, most traditional index structures (and their corresponding pruning strategies) had bad performance. And it is interesting that simply splitting index according to document structure can achieve good performance in most settings. Our additional study on non-linear ranking function and approximate top-k processing shows similar conclusions. In this paper, we make a further step to reduce unnec-essary proximity computations with the Proximity-Probe Heuristic. With this heuristic, we not only improve the perfor-mance of our strategies, but also make the traditional static rank ordered inverted index get back to work. References
