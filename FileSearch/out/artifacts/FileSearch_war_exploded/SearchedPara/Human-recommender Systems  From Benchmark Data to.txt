 We bring to the fore of the recommender system research community, an inconvenient truth about the current state of understanding how recommender system algorithms and humans influence one another, both computationally and cognitively. Unlike the great variety of supervised machine learning algorithms which traditionally rely on expert input labels and are typically used for decision making by an ex-pert, recommender systems specifically rely on data input from non-expert or casual users and are meant to be used directly by these same non-expert users on an every day basis. Furthermore, the advances in online machine learn-ing, data generation, and predictive model learning have be-come increasingly interdependent, such that each one feeds on the other in an iterative cycle. Research in psychology suggests that people X  X  choices are (1) contextually depen-dent, and (2) dependent on interaction history. Thus, while standard methods of training and assessing performance of recommender systems rely on benchmark datasets, we sug-gest that a critical step in the evolution of recommender systems is the development of benchmark models of human behavior that capture contextual and dynamic aspects of human behavior. It is important to emphasize that even extensive real life user-tests may not be sufficient to make up for this gap in benchmarking validity because user tests are typically done with either a focus on user satisfaction or engagement (clicks, sales, likes, etc) with whatever the rec-ommender algorithm suggests to the user, and thus ignore the human cognitive aspect. We conclude by highlighting the interdisciplinary implications of this endeavor.
In its pioneering years, machine learning drew significantly from cognitive psychology and human learning. Later, with the proliferation of online services, social media websites,  X 
This research was supported in part by NSF grant NSF-1549981 to O.N. and P.S.
 and more generally, the wide democratization of  X  X onsump-tion of algorithms X  output X  by general users, machine learn-ing algorithms started interacting with users at unprece-dented rates. While in the early years, most (supervised) machine learning algorithms relied on reliable expert labels to build predictions [23, 24, 25, 8], more recently the gates of data generation have been opened wide to the general popu-lation with everyday users X  interactions X  X abeling, rating, an-notating, etc X  X eing treated as training data for subsequent interactions and users [6, 19, 11].

A critical development in the field of machine learning, and recommender systems specifically, has been the cura-tion of benchmark datasets. Prominent recent examples in-clude the UCI respository [18], MNIST [17], as well as many others. Benchmark datasets facilitate advances in the field by promoting consensus regarding the scope of the problems to be solved and by offering standards by which all models can be assessed. Indeed, the importance of these datasets to the field is reflected in the high number of citations to these resources X  X ore than 1700 for UCI and more than 500 for MNIST, which almost certainly under-represent the frequency of their use and their importance to the field. Figure 1: Illustration of the interaction between hu-mans and algorithms through which data are gen-erated. The arrows indicate directions of influence. Traditional recommender systems research focuses on the links between algorithms and data through curated benchmark data sets. Increasingly, algo-rithms are deployed in the  X  X ild X  and iteratively refined based on uncurated data, forming human-recommender systems. This raise questions about the non-independence of data and context and the non-stationarity of behavior over time.

Benchmark datasets typically provide data in batch for-mat. This reflects the historical approach to machine learn-ing and recommendation in which an algorithm is trained on a batch of data and then deployed. It also reflects assump-tions about the nature of the problem to be solved; the tar-get distribution is stationary and that data are IID samples. These are fundamental assumptions of most standard learn-ing algorithms, and thus sensible simplifying assumptions for starting out. The success of these standard algorithms and approaches has, however, led to new, more ambitious applications including online information filtering and item recommendations, retraining of algorithms based on users X  input, and iteration of these interactions. Implicitly, itera-tive retraining with algorithms that assume stationarity and IID data leads to the potential for introduction of biases, which may be magnified through the interactions over time.
In light of these developments, we argue that it is nec-essary that the field reconsider how it trains and assesses algorithms. We propose the development of benchmark mod-els of human behavior. Analogous to benchmark data sets, benchmark models capture the generative process that un-derlies typical benchmark data, including time-varying as-pects. Benchmark models will accelerate progress by en-couraging consensus regarding the kinds of dynamics and non-independence that are important for recommendation, and minimize risk by formalizing the aspects human behav-ior that potentially introduce bias and allowing researchers to investigate implications for their own algorithms. We emphasize that while some previous research has consid-ered the dynamics of data into model evaluation [26], these have looked primarily at Benchmark data as a dynamic data stream, and not at the interactions between algorithms and humans.

We begin by stating minimal desiderata for a benchmark models vis-a-vis benchmark data. We then review key ele-ments of human behavior to be integrated into such a model: contextual dependence of choice behavior, non-stationarities of preference due to learning about the domain of recommen-dation, and non-stationarities of preference due to learning about the recommender system itself. We conclude by sum-marizing our interactive approach and implications for the development of true human-recommender systems.
There are two minimal desiderata for benchmark models of human behavior. The first aspect is, we expect, relatively uncontroversial. In-deed, the simplest version of this, which does not include temporal dynamics, is precisely the generative modeling ap-proaches that have been popular in probabilistic modeling.
The second aspect is, we expect, potentially more con-troversial along two dimensions: is this necessary and can this be done? We believe there is a very compelling reason for the necessity of models that capture dynamics of human behavior. If behavior is time varying, no batch method can capture the statistical structure of this behavior. This nec-essarily implies a deviation between the algorithms, which assume and are trained on data that does not possess inter-esting temporal structure, and people whose behavior is time varying. The iterated nature of interactions means that, un-der some circumstances, this gap may grow over time, sug-gesting that it is possible to observe a divergence between algorithms and behavior that grows over time. Benchmark models that capture the dynamics of of human behavior would allow one to test algorithms for satisfactory behav-ior both on average and across time. In the next section, we address the second question, whether such benchmark models are feasible by considering the elements of a model of human behavior.
The main goal of the model of human behavior is to ab-stract away from benchmark datasets to generative mod-els for how people produce the data. This more abstract framework can allow the sorts of non-stationarity and non-independence that have been identified in research in cogni-tive science.

Research into human choice behavior in cognitive science dates back at least to Luce [20, 22, 35, 31]. Luce formalized human choice through the eponymous Luce choice rule, in which the probability of choosing an option from a set of pos-sibilities is proportional to its utility. Luce X  X  choice rule im-plicitly assumes a form of independence, independence from irrelevant alternatives. Since his proposal, researchers have identified numerous examples of how people X  X  choices do in fact depend on what one would reasonably consider irrele-vant alternatives. For example, several of the most famous examples stem from the work of Kahneman and Tversky [34, 29]. Consider the attraction effect, in which, people choose between, a nice pen or 6 dollars. At baseline, people favored the money over the pen; however, adding a second, much less attractive pen led more people to choose the nice pen. Adding an irrelevant pen increased participants preference for the nicer pen as compared to the money. This effect is a demonstration of the non-independence of choice in that the order of people X  X  preferences is not stable with respect to the addition of other options (as is required by independence). Moreover, inspired by this work, there are a large number of computational models of choice that have been proposed to account for these non-independence effects, which would provide candidate starting points for formalizing a bench-mark model of human behavior [22, 35, 33].

Increasingly, research in cognitive science has also inves-tigated avenues by which people X  X  choice behavior would be non-stationary over time. Two main mechanisms of non-stationarity are the active learning about the information they are searching for and learning about the system it-self. For active learning, non-stationarities would arise due to people X  X  beliefs changing over time. Thus, a choice at time t + 1 may differ from that at t  X  1 only because people learned more about the options at time t . Active learning has a large body of research in cognitive science dating back at least to Bruner [9]. Recent research has focused on devel-oping computational accounts of active learning [10, 3, 1, 2, 21], with recent work focusing on information gain (aka, KL divergence) as a model of human behavior in simple settings.
A second potential source of non-stationarity is people learning about the system with which they are interacting. These non-stationarities arise in that people may develop heuristics to influence the system toward their goals. Here non-stationarities arise because people are learning about the behavior of the system itself, in essence reverse engi-neering their input to influence the machine toward their desired goals. This notion has an analog in recent cognitive science investigating learning about, and from, other people [28]. These approaches extend models of choice to incorpo-rate simple models of other people X  X  actions in terms of plans [4] and through more abstract modeling of the individual X  X  goals and desires [13, 5, 28, 27, 12].

Although research continues, there are reasons to believe that development of a model of human behavior is reason-able. The first is that the basic empirical phenomena in choice theory are agreed upon. Second, the approaches based on learning are being developed within the broad choice theoretic framework [5, 28], suggesting a continuity in modeling.
We argue for a framework for investigating the implica-tions of interactions between human and algorithms that draws on diverse literature to provide algorithmic, mathe-matical, computational, and behavioral tools for investigat-ing human-algorithm interaction. Such an approach would draw on foundational algorithms for selecting and filtering of data from computer science, while also adapting mathemat-ical methods from the study of cultural evolution [14, 16, 7] to formalize the implications of iterative interactions. The basic feature of the algorithm application  X  X n the wild X  is it-erative interaction with people. In this sense, the evolution of algorithms is a special case of cultural evolution of the sort observed in human language [15] and human knowledge more broadly [32, 7]. Researchers in the behavioral sciences have developed formal and empirical frameworks for ana-lyzing and investigating the asymptotic effects of iterative interactions. Formally, iterative interactions with transmis-sion between adjacent iterations forms a Markov chain [14]. Markov chains provide a well-elaborated framework for an-alyzing the effects of local decisions on long-run behavior. For the current proposal, the key question regards the con-ditions under which algorithms X  behavior X  X n terms of the choice of data to present to people and the updated behav-ior in response to people X  X  observed actions X  X ill converge to more or less effective performance in the long run. Can we understand and compensate for these biases to ensure good performance?
Consider simple supervised machine learning where the goal is to learn to predict a discrete class label. Research on simple classifiers has historically paved the road for most formal analysis in machine learning and data mining, and had a significant impact on both information retrieval [30] as well as recommender systems [6]. It also provides a point of contact with the psychology of category learning.
We can extend iterated learning to provide a framework to analyze the evolution of the learned hypotheses with inter-actions between the user and the algorithm . We will account for the dependency between the current hypothesis and the next input because the model or hypothesis learned by the algorithm (learner) is used as a filter or gateway to the types of data that will later be seen by the user. This constitutes dependence between the current hypotheses h and the next inputs x (see Fig 2). It is interesting to con-trast the evolution of iterated learning without and with this dependency. Without the dependency, the algorithm at step n + 1 sees input x n +1 which is generated from a distribution p ( x ) that is independent of all other variables. Represent this independence with new notation q ( x ) ( q instead of p ), where q ( x ) represents an unbiased sample from the world, rather than a selection made by the algorithm. With the de-pendency, the algorithm at iteration n + 1 sees input x n +1 which is generated from a mixture between the objective distribution q ( x ) and another distribution that captures the dependency upon the previous hypothesis h n which biases the future inputs seen by the user. (a) (b) Figure 2: In iterated learning, information is passed
Recommender systems, and machine learning more broadly, have benefited greatly from benchmark datasets. However, recent successes in the field, and specifically applications  X  X n the wild X  have led to prolific use of data that are not cu-rated in the traditional sense, but instead arise from human-algorithm interaction. This cyclical flow is rarely taken into account in algorithm design and analysis; nor is its im-pact (or dependence) on algorithms and humans well un-derstood. We propose that the next generation of recom-mender systems be trained not on benchmark data, but on benchmark models. This approach is necessarily interdisci-plinary and involves building on cognitive science research to develop models of human behavior that formalize the non-stationarity and non-independence of human behavior that cannot be easily captured in data alone.

Key to our approach is the focus on the sources and con-sequences of bias in data collected  X  X n the wild X . The two primary sources of bias are from algorithms and from hu-mans. Recommender systems filter information with the goal of presenting humans with the most preferred content. This aspect of recommendation raises questions regarding the non-independence of choice behavior that have been doc-umented in cognitive science for decades. Our approach sug-gests that it may be important to not only study people X  X  choices, but also their beliefs about the domain in ques-tion and about the algorithm itself. The former has been a standard question in both human and machine learning for decades. The latter speaks to ways in which algorithms may not merely serve human goals, but that those goals may also be a consideration of the algorithm. We emphasize that even user-tests do not make up for the gap in benchmarking validity because they typically focus on user satisfaction or engagement with what the algorithm suggested, and thus ignore the human cognitive aspect. When algorithms are able to both recommend content and reason about when and why people prefer something, we will be moving toward truly human-recommender systems . [1] F. G. Ashby, L. A. Alfonso-Reese, and E. M. Waldron. [2] F. G. Ashby, W. T. Maddox, and C. J. Bohil.
 [3] F. G. Ashby, S. Queller, and P. T. Berretty. On the [4] C. L. Baker, R. Saxe, and J. B. Tenenbaum. Action [5] C. L. Baker, R. Saxe, and J. B. Tenenbaum. Bayesian [6] C. Basu, H. Hirsh, W. Cohen, et al. Recommendation [7] A. Beppu and T. L. Griffiths. Iterated learning and [8] C. M. . Bishop. Pattern recognition and machine [9] J. Bruner. The art of discovery. Harvard Educational [10] J. R. Bruner, J. J. Goodnow, and G. A. Austin. A [11] J. C. Caicedo, J. BenAbdallah, F. A. Gonz  X alez, and [12] B. S. Eaves and P. Shafto. Unifying pedagogical [13] N. D. Goodman, C. L. Baker, E. B. Bonawitz, V. K. [14] T. L. Griffiths and M. L. Kalish. A Bayesian view of [15] S. Kirby. Spontaneous evolution of linguistic structure: [16] S. Kirby, M. Dowman, and T. L. Griffiths. Innateness [17] Y. LeCun, C. Cortes, and C. J. Burges. The mnist [18] M. Lichman. UCI machine learning repository, 2013. [19] S. B. Y. J. Linden, G. Amazon. com [20] R. D. Luce. Individual choice behavior . John Wiley, [21] D. Markant and T. Gureckis. Is it better to select or [22] D. McFadden. Quantal choice analysis: A survey. [23] R. S. Michalski. Pattern recognition as rule-guided [24] R. S. Michalski, I. Bratko, and A. Bratko. Machine [25] T. M. Mitchell. Machine Learning . McGraw-Hill, Inc., [26] O. Nasraoui, J. Cerwinske, C. Rojas, and F. A. [27] P. Shafto and N. D. Goodman. Teaching games: [28] P. Shafto, N. D. Goodman, and M. C. Frank. Learning [29] I. Simonson and A. Tversky. Choice in context: [30] K. Sparck Jones. Some thoughts on classification for [31] R. S. Sutton and A. G. Barto. Reinforcement learning: [32] M. Tomasello. The Cultural Origins of Human [33] K. Train. Discrete choice models with simulation . [34] A. Tversky. Elimination by aspects: A theory of [35] J. I. Yellot. The relationship between luce X  X  choice
