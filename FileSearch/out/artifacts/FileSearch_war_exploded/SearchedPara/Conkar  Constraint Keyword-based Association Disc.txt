 In many domains, such as bioinformatics, cheminformatics, health informatics and social networks, data can be represented naturally as labeled graphs. To address the increasing needs in discovering interesting associations between entities in such data graphs, espe-cially under complicated keyword-based and structural constraints, we introduce Conkar ( Con strained K eyword-based A ssociation Dis-cove R y) System. Conkar is the first system for discovering con-strained acyclic paths (CAP) in graph data under sophisticated keyword-based constraints, with the highlight being the set of quan-titative constraint metrics t hat we proposed, including coverage and relevance . We will demonstrate the key features of Conkar: power-ful and user-friendly query specification, efficient query evaluation, flexible and on-demand result ranking, visual result display, as well as an insight tour on our novel CAP query evaluation algorithms. H.3.3 [ Information Systems ]: Information Storage and Retrieval X  Information Search and Retrieval (Search process) Algorithms Keyword-based Association Discovery, Search Algorithm, Cover-age, Relevance, Drug Discovery
In many domains, such as social networks, cheminformatics, bioinformatics, and health informatics, data can be represented nat-urally in graph model, with nodes b eing data entitie s and edges the relationships between them. RDF (Resource Description Frame-work) [11] is a W3C recommended language which describes linked data of the Semantic Web in the form of triples. Both RDF data and RDF schema can be represented by node and edge labeled graphs.
The graph nature of these data brings opportunities and chal-lenges to data storage and retrieval. In particular, it opens the doors to search problems such as semantic association discovery [3, 4] and keyword search [7].

We study the application requirements in various domains in-cluding cheminformatics and social networks and find that the prob-lem of discovering acyclic path s between data entities under con-straints such as appearance of nodes, edges and/or patterns and the length of paths is at the core of these applications.

One of the core research directions in cheminformatics is to study drugs X  affect on diseases via the interaction between proteins and genes [10]. To facilitate such study, drugs, diseases, proteins, genes, etc. are represented in an RDF graph, called Chem2Bio2RDF [5]. To assess the effectiveness of a drug before conducting chemical experiments, domain experts would like to first find and analyse paths from the drug to the target disease under constraints, e.g. the (partial) app earance of certain proteins/genes.
In social networks and research networks, such as VIVO [6], one of the most important functi onalities is to fi nd connections be-tween people that satisfy certain constraints [1, 8], for example, to find possible collaborations based on common interest, or to detect conflict of interest between authors and PCs based on the appear-ance of certain entities, such as professional institutions that both are affiliated with, and/or relationships, e.g. advise, co-author and co-PI. It is also critical to determine the degree of such conflict of interest further based on how frequent certain relationship and en-tities appear in the connection [1].

How to express and measure constraints and how to answer such constrained path discovery queries efficiently are critical problems, but are not yet fully studied in the literature. There are no generic systems that fulfill the demands. First, allow us to take social/re-search networks as example, to illustrate such demands.

E XAMPLE 1.1. Figure 1 shows the graph representation of a sample RDF data representing the relationships among people in the social networks. Let X  X  consider the following search requests: case1. Find how Azriel connects to Ben ; case2. Find the close ties (within 3 steps) between Azriel and Ben ; case3. Find how Azriel connects to Ben through Chris or Dan ; case4. Find how Azriel connects to Ben through at least two people from Chris , Dan and Ida within four steps. case5. Find Azriel  X  X  close (within 4 steps) professional connections (e.g. relationships such as workfor , coworker , coauthor )to Ben ; case6. Find Azriel  X  X  close (within 4 steps) semi-professional con-nections to Ben (i.e. half of the relationships in any tie should be professional);
Query languages have been proposed to query data on the Se-mantic Web. SPARQL [12], the de facto standard query language for RDF, relies on graph patterns to identify data entities and rela-tionships of interest. However, it lacks the ability to express arbi-trary paths between data entities, such as those shown in Ex. 1.1. The notion of label-constraint reachability (LCR) [8] was proposed to describe the problem of finding the connectivity between two given nodes in a labeled graph under the constraint that all the edge labels along the path are in a given set. The semantic keyword search problem was defined to find trees in a labeled directed graph where the tree nodes and edges cover all the keywords [7]. Com-bining these notions, several SPARQL extensions, with the intro-duction of path variables, were proposed [4, 9]. Such extensions are capable of expressing the search queries in cases 1-2 in Ex. 1.1, but not the other cases. There were also proposals for extending SPARQL with regular expressions [2] to express complex patterns that satisfy strictly defined constraints such as cases 1,2,3,5. How-ever, such SPARQL extensions s till cannot express more relaxed constraints such as those in cases 4,6.

To support the searches in Ex. 1.1, the two major challenges are: how to express these association discovery problems and how to answer them efficiently.

We introduce Conkar [14], the first system that can express and answer all these search queries. In Conkar, whose architecture is shown in Figure 2, we abstract the association discovery problem as the problem of finding constrained acyclic paths (CAP) in di-rected labeled graphs . We define a set of quantitative metrics, at the core of which are the notions of coverage and relevance of a path with respect to a set of keywords. Via the easy-to-use interface of Conkar, users can express CAP search queries by specifying key-word sets, the desired coverage and relevance of the resultant paths with respect to these keyword sets, as well as other constraints, such as path length. Users can also specify the relative importance of quantitative metrics. Then Conka r will rank the results based on their preference. Upon viewing the results, users can adjust (extend or refine) the constraints and ranking criteria to obtain the results that suit their needs.
 the constraints to eliminate unpromising search branches as early as possible. The important innovations of Conkar are to formally define the Constrained Acyclic Path Discovery problem and to provide a friendly interface for users to express CAP queries. Let L be an infinite set of literals and U be an infinite set of URIs disjoint with L . We represent RDF data as a node and edge labeled directed graph G =( V,E, X  ) where V is a set of nodes, E  X  V  X  V is a set of edges, and  X  is a labeling function that maps items in V  X  E into a finite set of labels and literals.

We call a sequence of interleaving nodes and edges of graph G a path fragment (or fragment ), represented by f ,if
We use nodes ( f ) ( edges ( f ) ) to represent the set of nodes (edges) in f ,and Length ( f ) (or | f | ) the length of f ,definedas We overload the mapping function  X  to map a set of nodes (edges) to their corresponding labels.

Given two nodes n s ,n d  X  V as the source and destination nodes, the paths that link n s to n d in G are fragments in the form f =( n s ,e 1 ,n 1 ...,n k  X  1 ,e k ,n d ) . In search queries that look for the paths between two nodes, frequently only acyclic paths are of interest to users. Therefore, as n s and n d are given, we are particularly interested in a special type of path fragment -acyclic e -fragment (denoted by f e ), which starts and ends with an edge, and no two nodes, including the end nodes, are the same. We use F ( n s ,n d ) to represent all acyclic e -fragments between n in G . Length Constraint : Among a possibly large number of resultant e -fragments of a search query, shorter e -fragments tend to express stronger and more meaningful relationship between the two end nodes than the longer ones do [3, 7]. Involving the length con-straint which restricts the length of the resultant e -fragments has been studied in [2, 4], and Conkar supports it as well.
 Set-based Constraints : When users search for paths between a pair of nodes, they are frequently interested in paths that contain certain keywords. Such constraints can be given in the form of a keyword set (denoted S ), where a keyword is a label in U
Certain constraints, such as presence constraints [4] on nodes and tight constraints on edges [8] were discussed in the existing works, but they are quite limited in terms of what can be in the key-word set and how the results are regulated by it, hence can express only some search queries, but not many others, such as cases 3-6 in Ex. 1.1.

We generalize the keyword-based constraints defined in [4, 8] in two directions: (1) we allow the keyword set to include keywords that can be mapped to labels of both nodes and edges; and (2) we extend how the results are confined by a keyword set.

D EFINITION 2.1. Given a finite keyword set S X  X  and an e -fragment f e  X  X  e ( n s ,n d ) , 1. if S X  (  X  ( nodes ( f e ))  X   X  ( edges ( f e ))) ,wesay f 2. if S X  (  X  ( nodes ( f e ))  X   X  ( edges ( f e ))) ,wesay f 3. if S X  (  X  ( nodes ( f e ))  X   X  ( edges ( f e ))) =  X  ,wesay f
Based on the definition above, we can express the search request in Ex. 1.1 case3 as "find e -fragments from Azriel to Ben that satisfy the intersection constraint w.r.t. keyword set { Chris,Dan Quantitative Metrics : To express the search requests in Ex. 1.1 cases 4-6, a more subtle description of the relationship between an e -fragment and a keyword set than the all-or-nothing set-based constraints described in Def. 2.1 is needed. For this purpose, we introduce quantitative metrics coverage and relevance .

Intuitively, coverage describes the fraction of the keyword set that appears in the label set of an e -fragment, while relevance de-scribes the fraction of the labels of an e -fragment that are in the keyword set. In an RDF graph, each node has its unique label, while more than one edge may have the same label. Therefore, we refine coverage and relevance further into node-coverage and node-relevance for keyword sets to be applied only on nodes, edge-coverage and edge-relevance for edges, and use coverage and rele-vance for the constraints in which keywords can be mapped to both nodes and edges. We use cntE ( l, f e ) to represent the number of appearance of a keyword l among the edges in an e -fragment f
We present the formula to calculate the coverage and relevance in Def. 2.2 while the formula to calculate node (edge) coverage and relevance can be easily deduced.

D EFINITION 2.2. Givenagraph G , two nodes n s ,n d  X  V and a finite keyword set S X  X  , for an e -fragment f e  X  X  e ( n
Taking advantage of the quantitative metrics, the search requests in Ex. 1.1 cases 4-6 can be expressed easily. For example, case 6 can be expressed as "find all e -fragments, f e , from Azriel to Ben such that EdgeRelevance( f e ,{ coworker , workfor , coauthor }) 0.5 and | f e | X  4 ".

All the constraints we defined in Def. 2.1 are special cases that can be expressed using the quantitative metrics defined in Def. 2.2. Similarly, we can define the node/edge version of these functions.
Formally, a CAP search query CAP ( n s ,n d , X  ) on RDF graph G involves source and destination nodes n s ,n d  X  V , and constraint  X  expressed using zero to many quantitative metrics functions that involve zero or many keyword sets, and returns the e -fragment(s) from n s to n d that satisfy  X  . Our Conkar provides a user-friendly interface for specifying a CAP query by composing the ingredients of the search, i.e. G, n s ,n d and an optional, potentially arbitrarily complicated  X  .
Asthedatagraph G and constraint  X  can both be large in size and complex in nature, designing algorithms that can efficiently answer CAP queries is at the heart of the design and implementation of Conkar.

Many graph searching algorithms [7] were proposed for answer-ing keyword searches in graph data. But they can not be applied directly to answer CAP queries, as they are designed to find tree instances covering all keywords in the graph. Traversal-based ap-proaches such as DFS, BFS and bidirectional search [2] can be adapted with a post-search filter to answer CAP queries. However, such Search-Filter appr oaches don X  X  scale well when the size and complexity of the graph increase. Algorithms [3, 4] with additional help from schema or indices were la ter proposed, but these facili-tating data and structures lack of either availability or scalability.
In Conkar, we implemented three algorithms to answer CAP queries: Search-Filte r approach utilizes algorithms proposed in the litera-ture to find all acyclic e -fragments in F e ( n s ,n d ) CAP ( n s ,n d ,  X  )( G ) ) , and then eliminates those not satisfying the constraints specified in  X  . This approach is most generic and can be easily adapted for all constraints introduced above. However it is not practically efficient because generating F e ( n time and space consuming, rendering the search phase costly, while frequently | CAP ( n s ,n d , X  )( G ) || CAP ( n s ,n d , the high cost of the search phase mostly wasted.

In Conkar, to answer CAP queries efficiently, we propose to take advantage of the constraints on length and keywords and push re-sult validation into the path discovery process, to prune unpromis-ing intermediate results as early as possible. In particular, we de-sign and implement the following two families of algorithms [13]. ConstraintDFS (cDFS) and Enhanced ConstraintDFS (ecDFS) al-gorithms are based on Depth First Search (DFS). To minimize the DFS search space in computing a CAP query CAP ( n s ,n d , X  minimize the total number of intermediate results, i.e. fragments, generated in the process by terminating expansion from fragments generated at search steps when we are certain that the expansion will not lead to any results. In order to do so, we introduce the notion of projected value range of the quantative metrics, and we design a set of formula to compute the projected value ranges of the constraint metrics in the CAP query in question, based on informa-tion, such as the length and keyword appearances, of the fragments generated so far in the DFS process. In the cDFS algorithm, at each DFS step, when the projected value ranges of a fragment do not overlap with the constraints in  X  , we can safely terminate the expansion of this fragment. The ecDFS algorithm further improves the performance by saving the validation of the fragments during the search steps of which we foresee the fragments guaranteed to be promising.
 Search-and-Join (S&amp;J) algorithm specifically targets at the set-based, rather than list-based, keyword constraint specification. The S&amp;J algorithm takes the local information around the nodes with key-words into consideration to calculate more precise projected value ranges, and thus conduct more efficient pruning. The S&amp;J algo-rithm issues mini-searches to find exclusive path fragments (i.e. paths that do not pass through any keyword nodes) between pairs of nodes that contain keywords, then use constrained sequence join to concatenate the fragments to produce the final results. Careful bookkeeping allows us to use the partial results in one mini-search to limit the search space of many other mini-searches, and effec-tively reduces the overall search cost.
We propose the demonstrational plan to welcome users to have a hand-on experience with Conkar. Especially users can (1) issue CAP queries, simple or complicated, via our user-friendly interface and view the resultant paths instantly; and (2) have an insight look at how our algorithms efficiently evaluate CAP queries. We will demonstrate Conkar on two applications: the drug discovery ap-plication for chemical informatics and the application on social/re-search networks. Following the running examples in Sec. 1, we will again use social/research networks data as our example here.
Users are welcome to use the CAP query interface of Conkar to specify and evaluate CAP queries. The required fields are (1) the data graph, which can be selected from our demo databases; and (2) the source and destination nodes, which can be specified by typing keyword(s) in a textbox, and selecting URIs that Conkar pulls from the database matching the keyword(s). The constraints are optional. Using the simple CAP query interface of Conkar, users can construct a set of keywords, and use scroll bars to set the desired values ranges of the quantitative metrics with respect to the keyword set. Users can also specify the importance of each con-straint, which Conkar will take into consideration while presenting the ranked results to reflect users X  preferences. Conkar visualizes the ranked results in list view as well as graph view. The simple search interface and result display are shown in Figure 3.
More sophisticated users are welcome to use the advanced CAP query interface to specify complex CAP search queries, consist-ing of constraints based on different keyword sets, linked via logi-cal operators (AND and OR). Conkar also offers the resultant CAP query generated from the click-and-drag interface in the CAP query box for users to inspect. Figure 4 shows a CAP query under con-struction using the advanced search of Conkar.
Besides demonstrating the key features of Conkar, e.g. CAP query specification and execution, we also provide a behind-the-scene tour for audiences who are interested in our CAP query eval-uation algorithms. Here, after composing a CAP query, we will welcome the audience to choose an algorithm to evaluate the query. Conkar will then illustrate how nodes/edges in the data graph are explored, the intermediate results, as well as our sophisticated book-keeping that facilitates the search. At the end, besides showing the query results, Conkar will also report the execution profile, includ-ing how many node/edges are explored, using which the users can compare the performance of different algorithms. Figure 5 illus-trates an intermediate step of using the S&amp;J algorithm to answer a CAP query. Here, nodes are color coded to distinguish source/des-tination nodes, query nodes, search frontiers, pruned branches, etc.
