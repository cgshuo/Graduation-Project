 Traditional clustering is a descriptive task that seeks to identify ho-mogeneous groups of objects based on the values of their attributes. While domain knowledge is always the best way to justify cluster-ing, few clustering algorithms have ever take domain knowledge into consideration. In this paper, the domain knowledge is rep-resented by hierarchical ontology. We develop a framework by directly incorporating domain knowledge into clustering process, yielding a set of clusters with strong ontology implication. Dur-ing the clustering process, ontology information is utilized to ef-ficiently prune the exponential search space of the subspace clus-tering algorithms. Meanwhile, the algorithm generates automati-cal interpretation of the clustering result by mapping the natural hierarchical organized subspace clusters with significant categori-cal enrichment onto the ontology hierarchy. Our experiments on a set of gene expression data using gene ontology demonstrate that our pruning technique driven by ontology significantly improve the clustering performance with minimal degradation of the clus-ter quality. Meanwhile, many hierarchical organizations of gene clusters corresponding to a sub-hierarchies in gene ontology were also successfully captured.
 Categories and Subject Descriptors: H.2.8 [Database Applica-tions]: Data Mining H.2.8 [Database Applications]: Data Mining. General Terms: Algorithms, Performance, Design.
 Keywords: Subspace clustering, Ontology, Tendency Preserving.
Clustering techniques have been studied extensively in statistics, pattern recognition, and machine learning. Clustering in high di-mensional space is often problematic as theoretical results [5] ques-tioned the meaning of closest matching in high dimensional spaces, which is known as the curse of dimensionality. Recent research work [16, 1, 2, 3, 6, 11] has focused on subspace clustering , dis-covering clusters embedded in the subspaces of a high dimensional data set.

Subspace clustering can be classified into two categories: partition-based algorithms and exhaustive enumeration algorithms, The PRO-CLUS [1] and the ORCLUS [2] algorithms partition the database into a given number of projected clusters based on representative Copyright 2004 ACM 1-58113-888-1/04/0008 ... $ 5.00. clusters centering in subspaces. The information-theoretic co-clust-ering [8] approach simultaneously clusters the rows and columns to maximize their mutual information. A common feature of partition-based algorithm is that one object can appear in one and only one cluster. The other branch of subspace clustering algorithms exhaus-tively go through all subspaces potentially containing clusters and cluster in each subspace in a bottom-up fashion [3, 16, 12]. Com-pared with partition-based algorithms, one drawback of exhaustive subspace clustering is that its complexity is exponentially asymp-totic to the dimensionality of the data space. In addition, it can gen-erate a huge set of overlapping clusters due to the exponential num-ber of unique subspaces. However, besides its capability of captur-ing all potential subspace clusters, the applicability of exhaustive approach to many areas can never be replaced by partition-based al-gorithm. The models of partition-based algorithms usually assume that one object only belongs to one cluster, which do not cater to the needs in many real-life applications. For example, a gene often par-ticipates in more than one gene activity and is often annotated with multiple function categories. Hence, the question with exhaustive subspace clustering algorithms is how to improve the scalability of the exhaustive subspace clustering algorithms while reducing the clusters into a small but relevant set.

Clustering analysis is purely syntactical in the sense that it does not take advantage of the existing knowledge in the learning pro-cess. Eventually, the most challenging problem is how to approach the matters of interpretability , i.e. why the objects in a cluster should be clustered together. In many applications, people may have significant amount of knowledge on the data set, which are usually utilized to measure the significance of a cluster. Tradition-ally, this knowledge is only used during the postprocessing step for validation of the clustering results. The following are some exam-ples.
In this paper, we assume that the domain knowledge is captured in the ontology. The ontology is flexible yet powerful to capture the various degrees of relationship among objects (or attributes). In addition, it is used in many real applications. For example, in the bioinformatics community, the GO Consortium was formed to converge the efforts to make the controlled vocabulary of various genomic databases about diverse species in such a way that it can show the essential features shared by all the organisms [10].
We propose a hierarchical framework to directly incorporate the ontology knowledge into subspace clustering process. Our partic-ular interest lies in searching subspace clusters that can be well explained by its ontology categories. However, is there a natural correspondence between the hierarchy of subspace clusters and the hierarchy of ontology? To answer this question, we give the fol-lowing example.
 E XAMPLE 1.1. Table 1 presents a subset of zoo data in UCI KDD repository. Figure 1: An animal ontology and subspace clusters corre-sponding to each category
A possible ontology for this small database is shown in Figure 1. Based on the ontology and the number of attributes shared by the animals at each ontology level, we observe that the higher level the category is in the hierarchy, the less attributes the objects in that category may share. For example, in each of  X  X at X  and  X  X ird X  cat-egories, the set of attributes { head, breaths , legs, milk } same values among all the animals belonging to its category respec-tively, while all the animals in  X  X errestrial X  category which includes both  X  X at X  and  X  X ird X  share less attributes, i.e, { head, breaths } The ontology can not only be used to guide the clustering process, but also can be used to validate the clustering results. If a cluster contains terms very far apart on the ontology hierarchy, then the cluster may not be very meaningful in that domain. Based on the above example, it is intuitive to see that Given an ontology hierar-chy, the objects in the higher level of the category might share less attribute sets than the objects in the lower level of the hierarchy, which is a natural correspondence of the arrangement of subspace clusters along the subspace hierarchy.

Based on the above observation, given a database with a set of objects featuring a set of attributes, it will be interesting to find out which subset of objects can be clustered together over which subset attributes that can be classified into the same category located in the ontology hierarchy. We also want to find out for each category, which subset of attributes might contribute to the split of the object sets into more detailed classification categories.

We create a general framework for ontology-driven subspace clustering. This framework can be most beneficial for the hierar-chically organized subspace clustering algorithm and ontology hi-erarchy, i.e., it is independent of the clustering algorithms and on-tology application domain. To demonstrate the usefulness of this framework, we choose TP-cluster algorithm [12] and the gene on-tology as two representatives of exhaustive subspace clustering and ontology respectively. Both of them have been proven useful in clustering gene expression profiles and gene function annotation. The remainder of the paper is organized as follows. Section 2 de-fines the model of Ontology and Tendency Preserving cluster. Sec-tion 3 presents the ontology-driven subspace clustering algorithm in detail. An extensive performance study on Microarray data is reported in Section 4. Section 5 concludes the paper and discusses some future work. We start with the formal definition of the ontology.

D EFINITION 2.1. An ontology is a sign system O :=( L , H , R ) which consists of A top term R  X  L . For all l  X  L , it holds: H ( l, R ) .
The ontology essentially defines a hierarchy where each node corresponds to a lexicon or a categorical term. Each categorical term contains a set of objects and the set of objects in a descen-dent term is always a subset of the objects in its ancestor category. Figure 1 presents an example of animal ontology. under the curve.
Let D be a database containing the object set O under a set of attributes A . The whole database can be represented in a data ma-trix M , where M ij is the entry value of object i under attributes ( 0 &lt; i  X  |O| , 0 &lt; j  X  |A| ).

We are interested in the TP-Clusters, in which the subset of ob-jects in O exhibits a coherent tendency on the subset of attributes T of A .
 D EFINITION 2.2. Let O be a subset of objects in the database D , O  X  D . Let T be a subset of attributes, T  X  X  . Let T  X  O  X  2 |A|  X  I be the function that assigns the rank of an object i  X  X  attribute j to be r , if the expression value of the ob-ject i under attributes j is the r th lowest value among that un-der all the conditions in T . ( O , T ) forms a TP-Cluster (Ten-dency Preserving Cluster) , if  X  i, j ( i, j  X  O ),  X  a R ( i, a, T ) = R ( j, a, T ) and  X  k ( k  X  D  X  O ) ,  X  l ( l  X  O ) ( b  X  T ), R ( k, b, T ) 6 = R ( l, b, T ) .

Definition 2.2 first defines the rank function R . Based on the rank function, a TP-Cluster is defined as a maximum subset of ob-jects which have consistent ranks along a subset of attributes.
The TP-Cluster tree is generally analogous to a prefix tree of a predefined set of sequences. However, it is also different because of its unique interpretation of each node and the parent-child rela-tionship. Each node in a TP-Cluster tree represents a unique TP-Cluster. The root node corresponds to the null space. The nodes at level m correspond to m dimensional TP-Clusters. The TP-Cluster at a node is related to its immediate parent by being part of the cluster. Each TP-Cluster other than the null root is a 1-dimensional extension of its parent cluster. In order to elucidate the structure of TP-Cluster tree, we give a complete TP-Cluster tree of three con-ditions in Figure 2 (a), where each TP-Cluster is represented by a sequence.

D EFINITION 2.3. The TP-Cluster tree is a hierarchical arrange-ment of TP-Clusters with the following properties: 1) The tree is rooted at level 0 with  X  1 . 2) Each node at level m corresponds to an m-dimensional TP-Cluster represented by a length-m sequence. 3) Each node at level ( m + 1) is a 1-dimensional extension of its immediate ancestor, which corresponds to a length ( m + 1) quence.

What we are interested in is the hierarchical relationship among a set of TP-Clusters. Investigating the relationships may help us with the prediction of the behavior of higher dimensional clusters based on the lower dimensional ones.
The hypergeometric distribution is used to model the probability of observing at least k objects from a cluster of n objects by chance in a category containing f objects from a total database size of objects. The P-value is given by P = 1  X  P k measures whether a cluster is enriched with objects from a particu-lar category to a greater extent than that which would be expected by chance. If the majority of objects in a cluster belong to the same category, then it is unlikely that this happens by chance and the category X  X  P-value would be close to 0.

We use an appropriate subtree in the ontology hierarchy to anno-tate a cluster. The subtree is rooted at the node of the most signif-icant category and includes all of its significant reachable subcate-gories.
 D EFINITION 2.4. Given a cluster C , its significant categories V = { v 1 , v 2 , ...v t } , and the directed ontology tree the Ontology SubTree ( OST ) H = &lt; V 0 , E 0 &gt; representing clus-ter C is defined as the following: 1.The root of H is the function category v r , 0 &lt; r  X  t , where P ( v r , C ) = min 0 &lt;i  X  t  X  v 0  X  X   X , there exists a path L ( L  X  E ) leading from v r 3. e  X  E 0 .

Figure 2 (b) shows a set of significant GO function categories of a gene cluster organized in a tree structure. To determine the representing this cluster, we first find out the location of the most significant function group, which in this case is cell growth, with log (P-value)=-7. We then discard its parent category  X  X ellular process, and sibling X  X ell communication, which have higher P-value. The resulting OST is the subtree rooted at cell growth. D EFINITION 2.5. Given two OST s H 1 and H 2 , we call H 1 H 2 if the root node of H 1 appears as a node of H 2 .

For example, Figure 2 (c) contains two gene clusters X  OST call H 2 H 1 since we can find the root node cellular growth of H
Problem Statement: Let D be a database with object set O and attribute set A . Given a threshold  X  p for category enrichment and the ontology hierarchy, our goal is to extract a hierarchy of enriched TP-Clusters consistent with the whole or partial ontology hierarchy.
In this section, we present the algorithm to build an ontology relevant TP-Cluster tree.
The TP-clustering process can be summarized in two steps: 1. Preprocess the data . Each row in the data matrix will be 2. Depth-first traversal to develop ontology relevant TP-Cluster .
We use the dataset in Table 2 in the following example to il-lustrate the suffix concatenation step during the tree construction process.
E XAMPLE 3.1. For sequences in Table 2, the initial prefix tree representing the whole database is presented in Figure 3 (A) and the suffix concatenation upon visiting the first node  X -1 X  is illus-trated in Figure 3 (B).
 Let X  X  denote the node currently being visited as the active node. Given an active node in the TP-Cluster tree construction process, for example, at the root  X -1 X  in Figure 3 (B), the suffixes to be inserted to  X -1 X  X  X  subtree are those inside the rectangle box shown in Figure 3 (A). The concatenation of the suffixes to the current active node is done by merging the suffix tree of the active node with the corresponding subtree one level below the active node. For example, suffix tree  X -1cd X  in (A) is merged with  X -1d X . The generated subtree is shown as the  X -1d X  subtree in (B). (B) is the subsequent tree after the visit of the node  X -1 X . The same procedure will be applied recursively in the depth-first order to construct the TP-Cluster tree. For example, after the first node visit at the root  X   X  1  X , the next node to be visited is  X -1c X  and the suffixes inside the rectangle box in Figure 3(B) are the next set of suffixes to be inserted.
The ontology information serves the following two purposes: (1) the assessment of category enrichments of a cluster. (2) the guid-ance to select the subset of attributes critical to a category. These two functionalities of ontology information are transformed into two pruning techniques in the ONTP-clustering algorithm.

The first pruning technique is based on the distribution of ob-jects in different categories in a cluster. Since the first one focuses on the computation of P-value in each category, we omit the de-tailed description and only explain the second technique, which is to use OST extracted in a parent cluster to guide the selection of its descendent TP-Cluster clusters, by favoring ontology relevant children clusters defined in Definition 3.1. Our criterion is based on the hypothesis that, the TP-Clusters in the higher dimensional space are enriched in more specific categories.

D EFINITION 3.1. Let C be a TP-Cluster and C 0 be one of C descendants. Let H be C  X  X  OST , and let H 0 be C 0  X  X  OST ontology relevant descendent of C if H 0 H .

C RITERION 3.1. Let C be a TP-Cluster and C 0 be one of C descendants, we say the development of C 0 is not viable if it is not an ontology relevant descendent of C .

We present the ONTP-clustering algorithm of extracting ontol-ogy relevant TP-Clusters in Algorithm smartGrowTree .

Analysis of ONTP-clustering construction: For ONTP-Clus-tering, only one scan of the entire data matrix is needed during the clustering. Each row is first converted into a sequence of column labels. The sequences are then inserted into the prefix tree. In the initial tree structure, sequences with the same prefix naturally fall onto the same path from the root to the node corresponding to the end of prefix. To be memory efficient, the row/object IDs associated with each path are only recorded at the node marking the end of the longest common prefix shared by these sequences. The depth-first pre-order traversal is then applied to the prefix tree to generate a ONTP-clustering. The techniques based on ontol-ogy knowledge further prune the potential clusters. Both the time and space complexities of the two algorithms are exponential de-termined by the nature of being an NP-hard problem. The pruning effects are largely determined by the relationship between a TP-Cluster and the significance of its underlying functional categories.
Our experiments demonstrate the applicability of ONTP-clustering algorithm to clustering biologically related genes with effective pruning techniques based on GO. We denote the algorithm without ontology-based pruning as TP-clustering and the one with prunning as TP-Cluster tree. The results are evaluated through the compari-son of TP-clustering and TP-Cluster tree and the mapping between the TP-Cluster tree to the GO hierarchy. The algorithm was im-plemented in C and executed on a Linux machine with a 700 MHz CPU and 2G main memory.

Our algorithms are tested on the yeast cell cycle data of Spell-man et al. The study monitored the expression levels of 6,218 S. cerevisiae putative gene transcripts (genes) measured at 10-minute intervals over two cell cycles (160 minutes) with 18 time points. Spellman et al. identified 799 genes that are cell cycle regulated. We used the expression levels of the 799 genes across 18 time points as the original input matrix. The clustering procedure groups together genes on the basis of their common expression tendency across a subset of time points.
 To assess the biological relevance of the clusters, we use GO and P-value to evaluate whether the cluster has significant enrichment in one or more function groups. The ontology of the 799 yeast genes is downloaded from gene ontology consortium [10] in Feb, 2004. We use functions from the three categories: molecular func-tion(MF), cell component(CC) and biological process(BP). We ex-tract categories between ontology level 2 and level 5 with a family size of at least 5. The discovered TP-Clusters in each level of the hierarchy are evaluated for enrichment with any of those function categories.

The first set of experiments was done using the ONTP-clustering algorithm and cellular component ontology category to evaluate the performance by varying parameters n r and  X  p . As shown in Figure 4 a), the response time of the ONTP-clustering algorithm decreases as the significance threshold decreases and as the minimum number of rows increases. high significance threshold allows early drop of cluster with poor functional implication. More early pruning enables shorter response time. The n r helps to prune clusters with the size limitation. The application of the same algorithm to the other two categories exhibits the same trend when varying  X  .

Figure 4 b) presents the distribution of the generated clusters in three categories: not enriched cluster, enriched cluster, and en-riched cluster not following its parent X  X  OST according to Crite-rion 3.1. The percentage of not enriched cluster increases signif-icantly as  X  p decreases. It also explains the performance gain of ONTP-clustering at the same time. Also the percentage of clusters being pruned due to Criterion 3.1 drops significantly compared to the percentage of the enriched clusters as the significance thresh-old decreases. This may also indicate that the more significant the enrichment of the clusters, the higher the probability that its leads to the right direction of selecting the biologically appropriate biclusters.

The second set of experiments in Figure 4 c) is a comparison between ONTP-clustering algorithm and TP-clustering algorithm. For each algorithm, we have done two tests with different settings of n r . ONTP-clustering algorithm consistently outperforms TP-clustering especially when  X  p is relatively low. The response time of ONTP-clustering can be as short as 1/4 of that of the TP-clustering algorithm. The TP-clustering algorithm generates a large num-ber of TP-Clusters, of which only 10% are enriched when  X   X  5 . Compared with TP-clustering, ONTP-clustering generates less than half of the number of TP-Clusters and almost the same num-ber of enriched TP-Clusters. Overall, ONTP-clustering improves the performance with minimum loss of the enriched clusters.
Figure 4 d) gives the comparison of the response times vary-ing the three available ontology files, i.e, MF, CC, BF. We can observe a clear trend that the experiments using biological pro-cess category consistently spend more time than the rest two. This can be explained by the data in Table 3. The average number of categories that a gene might have is 5.7, which is much higher than that of either the cellular component or the molecular func-tion files. With fewer categories but more gene annotations, the distribution of function groups in a cluster has a higher probabil-ity being more concentrated in one or more function groups rather than being evenly distributed. As a result, fewer functional clusters might be pruned, and hence, the response time is longer. In addi-tion, this may also be coincident with the hypothesis that similar gene expression profiles may indicate a function relation in biolog-ical process As a result, more time will be taken for generating a larger number of significantly enriched clusters compared with the rest two ontology files.

Overall, our experiment shows that the ontology-based pruning is effective in reducing the search space of biclustering. In addition, the response time of our algorithm is influenced by the two input parameters and the distribution of genes in each category of the ontology.
We present a generic example of hierarchically organized clus-ters that map to a hierarchical substructure of GO.

In Figure 5, (A) presents a three-level hierarchy of TP-Clusters, while (B) shows the corresponding OST s. The gene ontology summarizing the relationships among all the function categories appearing in (B) is  X  X ecleoside  X  DNA metabolism  X  DNA re-pair X .
 The root cluster C 01 in (A) is the largest cluster with 71 genes. However, it has the smallest number of conditions shared by all genes in its cluster, i.e. (4 , 15 , 13 , 8) . Its OST shown at the top of the hierarchy in (B) is rooted at the category, Necleoside. As we go down the hierarchy of clusters in (A), clusters tend to contain a smaller number of genes but share a larger number of consistent conditions. In addition, the OST s is likely to exist in the subtree of the OST of its parent cluster. For example, the root cluster is split into two smaller overlapping clusters C 11 and C enriched function  X  X NA metabolism X , which is a subcategory of necleoside . OST C 11 and OST C 12 suggest that the two clusters in level one have more significant grouping at a deeper level in GO hierarchy than cluster C 01 . A further clustering of cluster C 21 with six conditions again signifies the a even deeper function group, i.e.  X  X NA repair X .

This example illustrates the connection between the ontology hi-erarchy and the TP-Cluster tree. Our experiments demonstrate that it is possible that only a subset of conditions matter for a ontology category. In addition, the deeper the level of a category within the GO hierarchy, the more the conditions under which the genes in that category have the similar expression profiles. a) Response Time b)Clusters Distribution c) Response time d) Figure 5: An example of mapping from a hierarchy of TP-Clusters to their the genes while the columns correspond to the conditions.
The clustering analysis is traditionally syntactical in the sense that it does not take advantage of the existing knowledge in the learning process. In the paper, we present a general framework by incorporating ontology hierarchy into the process of hierarchical subspace clustering. We extract the set of ontology explainable clusters during the clustering process in one run. Meanwhile, we also discuss an ontology pruning technique that enhances clustering algorithm and clustering result. Our experiments on yeast gene expression data demonstrates the effectiveness of ontology-based pruning. We also successfully extract the partial ontology hierarchy from the subspace clusters. Our future work will use clustering results and domain ontology for efficient and effective classification for the unknown objects.
