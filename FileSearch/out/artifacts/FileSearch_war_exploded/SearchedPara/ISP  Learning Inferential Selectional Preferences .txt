 Semantic inference is a key component for ad-vanced natural language understanding. Several important applications are already relying heavily on inference, including question answering (Moldovan et al. 2003; Harabagiu and Hickl 2006), information extraction (Romano et al. 2006), and textual entailment (Szpektor et al. 2004).

In response, several researchers have created re-sources for enabling semantic inference. Among manual resources used for this task are WordNet (Fellbaum 1998) and Cyc (Lenat 1995). Although important and useful, these resources primarily contain prescriptive inference rules such as  X  X di-vorces Y  X  X married Y  X . In practical NLP appli-cations, however, plausible inference rules such as  X  X married Y  X   X   X  X dated Y  X  are very useful. This, along with the difficulty and labor-intensiveness of generating exhaustive lists of rules, has led re-searchers to focus on automatic methods for build-ing inference resources such as inference rule collections (Lin and Pantel 2001; Szpektor et al. 2004) and paraphrase collections (Barzilay and McKeown 2001). 
Using these resources in applications has been hindered by the large amount of incorrect infer-ences they generate, either because of altogether incorrect rules or because of blind application of plausible rules without considering the context of the relations or the senses of the words. For exam-ple, consider the following sentence: and an inference rule such as: Using this rule, we can infer that  X  federal prosecu-tors announced the arrest of Terry Nichols X  . How-ever, given the sentence: the plausible inference ru le (1) would incorrectly infer that  X  CCM telemarketers announced the ar-rest of accounts  X . 
This example depicts a major obstacle to the ef-fective use of automatically learned inference rules. What is missing is knowledge about the ad-missible argument values for which an inference rule holds, which we call Inferential Selectional Preferences . For example, inference rule (1) Law Enforcement Agent or a Law Enforcement Agency . This knowledge does not guarantee that the inference rule will hold, but, as we show in this paper, goes a long way toward filtering out errone-ous applications of rules.

In this paper, we propose ISP , a collection of methods for learning inferential selectional prefer-ences and filtering out incorrect inferences. The presented algorithms apply to any collection of inference rules between binary semantic relations, such as example (1). ISP derives inferential selec-tional preferences by aggregating statistics of in-ference rule instantiations over a large corpus of text. Within ISP , we explore different probabilistic models of selectional preference to accept or reject specific inferences. We present empirical evidence to support the following main contribution: Claim : Inferential selectional preferences can be automatically learned and used for effectively fil-tering out incorrect inferences. Selectional preference (SP) as a foundation for computational semantics is one of the earliest top-ics in AI and NLP, and h as its roots in (Katz and Fodor 1963). Overviews of NLP research on this theme are (Wilks and Fass 1992), which includes the influential theory of Preference Semantics by Wilks, and more recently (Light and Greiff 2002). Rather than venture into learning inferential SPs, much previous work has focused on learning SPs for simpler structures. Resnik (1996), the seminal paper on this topic, introduced a statistical model for learning SPs for predicates using an un-supervised method. 
Learning SPs often relies on an underlying set of semantic classes , as in both Resnik X  X  and our ap-proach. Semantic classes can be specified manu-ally or derived automatically. Manual collections of semantic classes include the hierarchies of WordNet (Fellbaum 1998), Levin verb classes (Levin 1993), and FrameNet (Baker et al. 1998). Automatic derivation of semantic classes can take a variety of approaches, but often uses corpus methods and the Distributional Hypothesis (Harris 1964) to automatically cluster similar entities into classes, e.g. CBC (Pantel and Lin 2002). In this paper, we experiment with two sets of semantic classes, one from WordNet and one from CBC. 
Another thread related to our work includes ex-tracting from text corpora paraphrases (Barzilay and McKeown 2001) and inference rules, e.g. TEASE 1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001). While these systems differ in their approaches, neither provides for the extracted in-ference rules to hold or fa il based on SPs. Zanzotto et al. (2006) recently explored a different interplay between SPs and inferences. Rather than examine the role of SPs in inferen ces, they use SPs of a par-ticular type to derive inferences. For instance the preference of win for the subject player , a nomi-nalization of play , is used to derive that  X  X in play X . Our work can be viewed as complementary to the work on extracting semantic inferences and paraphrases, since we seek to refine when a given inference applies, filtering out incorrect inferences. The aim of this paper is to learn inferential selec-tional preferences for filtering inference rules. 
Let p i  X  p j be an inference rule where p is a bi-nary semantic relation between two entities x and y . Let  X  x , p , y  X  be an instance of relation p . Formal task definition : Given an inference rule p determine if  X  x, p j , y  X  is valid. 
Consider the example in Section 1 where we have the inference rule  X  X is charged by Y  X   X   X  Y announced the arrest of X  X . Our task is to auto-matically determine that  X  federal prosecutors an- X 
Terry Nichols , p j , federal prosecutors  X  ) is valid but that  X  CCM telemarketers announced the arrest of accounts  X  is invalid. 
Because the semantic relations p are binary, the selectional preferences on their two arguments may be either considered jointly or independently. For example, the relation p =  X  X is charged by Y  X  could have joint SPs: or independent SPs: This distinction between joint and independent selectional preferences constitutes the difference between the two models we present in this section. 
The remainder of this section describes the ISP approach. In Section 3.1, we describe methods for automatically determining the semantic contexts of each single relation X  X  selectional preferences. Sec-tion 3.2 uses these for developing our inferential selectional preference models. Finally, we propose inference filtering algorithms in Section 3.3. 3.1 Relational Selectional Preferences Resnik (1996) defined the selectional preferences of a predicate as the semantic classes of the words that appear as its arguments. Similarly, we define the relational selectional preferences of a binary semantic relation p i as the semantic classes C ( x ) of semantic classes C ( y ) of the words that can be in-stantiated for y . 
The semantic classes C ( x ) and C ( y ) can be ob-tained from a conceptual taxonomy as proposed in (Resnik 1996), such as WordNet, or from the classes extracted from a word clustering algorithm such as CBC (Pantel and Lin 2002). For example, given the relation  X  X is charged by Y  X , its rela-tional selection preferences from WordNet could be { social_group, organism, state... } for X and { authority, state, section... } for Y . 
Below we propose joint and independent mod-els, based on a corpus analysis, for automatically determining relational selectional preferences. Model 1: Joint Relational Model (JRM) Our joint model uses a corpus analysis to learn SPs for binary semantic relations by considering their arguments jointly, as in example (2). 
Given a large corpus of English text, we first find the occurrences of each semantic relation p . long to and accumulate the frequencies of the tri-c ( y )  X  C ( y ) 2 . tional preference for p . Candidates can be incorrect when: a ) they were generated from the incorrect sense of a polysemous word; or b ) p does not hold for the other words in the semantic class. 
Intuitively, we have more confidence in a par-ticular candidate if its semantic classes are closely associated given the relation p . Pointwise mutual information (Cover and Thomas 1991) is a com-monly used metric for measuring this association strength between two events e 1 and e 2 : 
We define our ranking function as the strength of association between two semantic classes, c x and c , given the relation p : 
Let | c x , p , c y | denote the frequency of observing abilities of Equation 3.2 using maximum likeli-hood estimates over our corpus: ()
Similarly to (Resnik 1996), we estimate the above frequencies using: where | x , p , y | denotes the frequency of observing the instance  X  x , p , y  X  and |C( w )| denotes the number of classes to which word w belongs. |C( w )| distrib-utes w  X  X  mass equally to all of its senses c w . Model 2 : Independent Relational Model (IRM) Because of sparse data, our joint model can miss some correct selectional preference pairs. For ex-ample, given the relation we may find occurrences from our corpus of the particular class  X  Money Handler  X  for X and  X  Law-yer  X  for Y , however we may never see both of these classes co-occurring ev en though they would form a valid relational selectional preference. 
To alleviate this problem, we propose a second model that is less strict by considering the argu-ments of the binary semantic relations independ-ently, as in example (3). 
Similarly to JRM, we extract each instance  X  x , p , y  X  of each semantic relation p and retrieve the belong to, accumulating the frequencies of the tri-ples  X  c ( x ), p , *  X  and  X  *, p , c ( y ) c ( x )  X  C ( x ) and c ( y )  X  C ( y ). 
All tuples  X  c ( x ), p , *  X  and  X  *, p , c ( y ) date selectional preferences for p . We rank candi-dates by the probability of the semantic class given the relation p , according to Equations 3.3. 3.2 Inferential Selectional Preferences Whereas in Section 3.1 we learned selectional preferences for the arguments of a relation p , in this section we learn selectional preferences for the arguments of an inference rule p i  X  p j . Model 1 : Joint Inferential Model (JIM) Given an inference rule p i  X  p j , our joint model defines the set of inferential SPs as the intersection of the relational SPs for p i and p j , as defined in the Joint Relational Model (JRM). For example, sup-pose relation p i =  X  X is charged by Y  X  gives the following SP scores under the JRM: the following SP scores under the JRM: The intersection of the two sets of SPs forms the candidate inferential SPs for the inference p i  X  p j : 
We rank the candidate inferential SPs according to three ways to combine their relational SP scores, using the minimum , maximum , and average of the SPs. For example, for  X  Law Enforcement Agent, Person  X  , the respective scores would be 1.45, 2.01, and 1.73. These different ranking strategies pro-duced nearly identical results in our experiments, as discussed in Section 5. Model 2 : Independent Inferential Model (IIM) Our independent model is the same as the joint model above except that it computes candidate in-ferential SPs using the Independent Relational Model (IRM) instead of the JRM. Consider the same example relations p i and p j from the joint model and suppose that the IRM gives the follow-ing relational SP scores for p i : and the following relational SP scores for p j : The intersection of the two sets of SPs forms the candidate inferential SPs for the inference p i  X  p j : 
We use the same minimum , maximum , and av-erage ranking strategies as in JIM. 3.3 Filtering Inferences Given an inference rule p i  X  p j and the instance  X  x , p i , y  X  , the system X  X  task is to determine whether  X  classes c ( w ) to which word w belongs. Below we present three filtering algorithms which range from the least to the most permissive: 
Joint Inferential Model for some c ( x )  X  C ( x ) and c ( y )  X  C ( y ).  X  ISP.IIM.  X  , accepts the inference  X  x , p j , y inferential SPs  X  c ( x ), p j , *  X  AND  X  *, p j , c ( y ) admitted by the Independent Inferential Model for some c ( x )  X  C ( x ) and c ( y )  X  C ( y ) .  X  ISP.IIM.  X  , accepts the inference  X  x , p j , y inferential SP  X  c ( x ), p j , *  X  OR  X  *, p j admitted by the Independent Inferential Model for some c ( x )  X  C ( x ) and c ( y )  X  C ( y ) . Since both JIM and IIM use a ranking score in their inferential SPs, each filtering algorithm can be tuned to be more or less strict by setting an ac-ceptance threshold on the ranking scores or by se-lecting only the top  X  percent highest ranking SPs. In our experiments, reported in Section 5, we tested each model using various values of  X  . This section describes the methodology for testing our claim that inferential selectional preferences can be learned to filter incorrect inferences. 
Given a collection of inference rules of the form p  X  p lar instance  X  x , p j , y  X  holds given that  X  holds 4 . In the next sections, we describe our collec-tion of inference rules, the semantic classes used for forming selectional preferences, and evaluation criteria for measuring the filtering quality. 4.1 Inference Rules Our models for learning inferential selectional preferences can be applied to any collection of in-ference rules between binary semantic relations. In this paper, we focus on the inference rules con-tained in the DIRT resource (Lin and Pantel 2001). DIRT consists of over 12 million rules which were extracted from a 1GB newspaper corpus (San Jose Mercury, Wall Street Journal and AP Newswire from the TREC-9 collection). For example, here are DIRT X  X  top 3 inference rules for  X  X solves Y  X : 4.2 Semantic Classes The choice of semantic classes is of great impor-tance for selectional preference. One important aspect is the granularity of the classes. Too general a class will provide no discriminatory power while too fine-grained a class will offer little generaliza-tion and apply in only extremely few cases. 
The absence of an attest ed high-quality set of semantic classes for this task makes discovering preferences difficult. Since many of the criteria for developing such a set are not even known, we de-cided to experiment with two very different sets of semantic classes, in the hope that in addition to learning semantic preferences, we might also un-cover some clues for the eventual decisions about what makes good semantic classes in general. 
Our first set of semantic classes was directly ex-tracted from the output of the CBC clustering algo-rithm (Pantel and Lin 2002). We applied CBC to the TREC-9 and TREC-2002 (Aquaint) newswire collections consisting of over 600 million words. CBC generated 1628 noun c oncepts and these were used as our semantic classes for SPs. Secondly, we extracted semantic classes from WordNet 2.1 (Fellbaum 1998). In the absence of any externally motivated distinguishing features (for example, the Basic Level categories from Pro-totype Theory, developed by Eleanor Rosch (1978)), we used the simple but effective method of manually truncating the noun synset hierarchy 5 and considering all synsets below each cut point as part of the semantic class at that node. To select the cut points, we inspected several different hier-archy levels and found the synsets at a depth of 4 to form the most natural semantic classes. Since the noun hierarchy in WordNet has an average depth of 12, our truncation created a set of con-cepts considerably coarse r-grained than WordNet itself. The cut produced 1287 semantic classes, a number similar to the classes in CBC. To properly test WordNet as a source of semantic classes for our selectional preferences, we would need to ex-periment with different extraction algorithms. 4.3 Evaluation Criteria The goal of the filtering task is to minimize false positives (incorrectly accepted inferences) and false negatives (incorrectly rejected inferences). A standard methodology for evaluating such tasks is to compare system filtering results with a gold standard using a confus ion matrix. A confusion matrix captures the filtering performance on both correct and incorrect inferences: where A represents the number of correct instances correctly identified by the system, D represents the number of incorrect instances correctly identified by the system, B represents the number of false positives and C represents the number of false negatives. To compare systems, three key meas-ures are used to summarize confusion matrices:  X  Sensitivity , defined as probability of accepting correct inferences;  X  Specificity , defined as probability of rejecting incorrect inferences;  X  Accuracy , defined as probability of a filter being correct. In this section, we provide empirical evidence to support the main claim of this paper. 
Given a collection of DIRT inference rules of the form p i  X  p j , our experiments, using the meth-odology of Section 4, evaluate the capability of our ISP models for determining if  X  x , p j , y  X  holds given that  X  x , p i , y  X  holds. 5.1 Experimental Setup Model Implementation For each filtering algorithm in Section 3.3, ISP.JIM , ISP.IIM.  X  , and ISP.IIM.  X  , we trained their probabil-istic models using corpus statistics extracted from the 1999 AP newswire collection (part of the TREC-2002 Aquaint collection) consisting of ap-proximately 31 million words. We used the Mini-par parser (Lin 1993) to match DIRT patterns in the text. This permits exact matches since DIRT inference rules are built fro m Minipar parse trees. 
For each system, we experimented with the dif-ferent ways of combining relational SP scores: minimum , maximum , and average (see Section 3.2). Also, we experimented with various values for the  X  parameter described in Section 3.3. Gold Standard Construction In order to compute the confusion matrices de-scribed in Section 4.3, we must first construct a representative set of inferences and manually anno-tate them as correct or incorrect. 
We randomly selected 100 inference rules of the form p i  X  p j from DIRT. For each pattern p i , we then extracted its inst ances from the Aquaint 1999 AP newswire collection (approximately 22 million words), and randomly selected 10 distinct in-stances, resulting in a total of 1000 instances. For each instance of p i , applying DIRT X  X  inference rule tests how well our models can filter these so that only correct inferences are made. 
To form the gold standard, two human judges were asked to tag each instance  X  x , p j , y  X  as correct or incorrect. For example, given a randomly se-lected inference rule  X  X is charged by Y  X  Y an-nounced the arrest of X  X  and the instance  X  Terry Nichols was charged by federal prosecutors  X , the judges must determine if the instance  X  federal prosecutors , Y announced the arrest of X , Terry Nichols  X  is correct. The judges were asked to con-sider the following two criteria for their decision:  X   X  x , p  X  The inference p i  X  p j holds for this instance. Judges found that annotation decisions can range from trivial to difficult. The differences often were in the instances for which one of the judges fails to see the right context under which the inference could hold. To minimize disagreements, the judges went through an extensive round of training. 
To that end, the 1000 instances  X  x , p j , y  X  were split into DEV and TEST sets, 500 in each. The two judges trained themselves by annotating DEV together. The TEST set was then annotated sepa-rately to verify the inter-annotator agreement and to verify whether the task is well-defined. The kappa statistic (Siegel a nd Castellan Jr. 1988) was  X  = 0.72. For the 70 disagreements between the judges, a third judge acted as an adjudicator. Baselines We compare our ISP algorithms to the following baselines:  X  B0 : Rejects all inferences;  X  B1 : Accepts all inferences;  X  Rand : Randomly accepts or rejects inferences. One alternative to our ap proach is admit instances on the Web using literal search queries. We inves-tigated this technique but discarded it due to subtle yet critical issues with pattern canonicalization that resulted in rejecting nearly all inferences. How-ever, we are investigating other ways of using Web corpora for this task. 5.2 Filtering Quality For each ISP algorithm and parameter combina-tion, we constructed a confusion matrix on the de-velopment set and computed the system sensitivity, specificity and accuracy as described in Section 4.3. This resulted in 180 experiments on the devel-opment set. For each ISP algorithm and semantic class source, we selected the best parameter com-binations according to the following criteria:  X  Accuracy : This system has the best overall abil-ity to correctly accept and reject inferences.  X  90%-Specificity : Several formal semantics and textual entailment resea rchers have commented that inference rule collections like DIRT are dif-ficult to use due to low precision. Many have asked for filtered versions that remove incorrect inferences even at the cost of removing correct inferences. In response, we show results for the system achieving the best sensitivity while main-taining at least 90% specificity on the DEV set. We evaluated the selected systems on the TEST set. Table 1 summarizes the quality of the systems selected according to the Accuracy criterion. The best performing system, ISP.IIM.  X  , performed sta-tistically significantly be tter than all three base-lines. The best system according to the 90%-Specificity criteria was ISP.JIM , which coinciden-tally has the highest accuracy for that model as shown in Table 1 6 . This result is very promising for researchers that require highly accurate infer-ence rules since they can use ISP.JIM and expect to recall 17% of the correct inferences by only ac-cepting false positives 12% of the time. Performance and Error Analysis Figures 1a) and 1b) present the full confusion ma-trices for the most accurate and highly specific sys-tems, with both systems selected on the DEV set. The most accurate system was ISP.IIM.  X  , which is the most permissive of the algorithms. This sug-gests that a larger corpus for learning SPs may be needed to support stronger performance on the more restrictive methods. The system in Figure 1b), selected for maximizing sensitivity while maintaining high specificity, was 70% correct in predicting correct inferences. 
Figure 2 illustrates the ROC curve for all our systems and parameter combinations on the TEST set. ROC curves plot the true positive rate against the false positive rate. The near-diagonal line plots the three baseline systems. Several trends can be observed from this figure. First, systems using the semantic classes from WordNet tend to perform less well than systems using CBC classes. As discussed in Section 4.2, we used a very simplistic extraction of semantic classes from WordNet. The results in Figure 2 serve as a lower bound on what could be achieved with a better extraction from WordNet. Upon in-spection of instances that WordNet got incorrect but CBC got correct, it seemed that CBC had a much higher lexical coverage than WordNet. For example, several of the instances contained proper names as either the X or Y argument (WordNet has poor proper name coverage). When an argument is not covered by any class, the inference is rejected. Figure 2 also illustrates how our three different ISP algorithms behave. The strictest filters, ISP.JIM and ISP.IIM.  X  , have the poorest overall perform-ance but, as expected, have a generally very low rate of false positives. ISP.IIM.  X  , which is a much more permissive filter because it does not require both arguments of a relation to match, has gener-ally many more false positives but has an overall better performance. 
We did not include in Figu re 2 an analysis of the minimum , maximum , and average ranking strate-gies presented in Section 3.2 since they generally produced nearly identical results. 
For the most accurate system, ISP.IIM.  X  , we ex-plored the impact of the cutoff threshold  X  on the sensitivity, specificity, and accuracy, as shown in Figure 3. Rather than step the values by 10% as we did on the DEV set, here we stepped the threshold value by 2% on the TEST set. The more permis-sive values of  X  increase sensitivity at the expense of specificity. Interestingly, the overall accuracy remained fairly constant across the entire range of  X  , staying within 0.05 of the maximum of 0.62 achieved at  X  =30%. 
Finally, we manually inspected several incorrect inferences that were missed by our filters. A com-mon source of errors was due to the many incorrect  X  X ntonymy X  inference rules generated by DIRT, such as  X  X is rejected in Y  X   X   X  X is accepted in Y  X . This recognized problem in DIRT occurs because of the distributional hypothesis assumption used to form the inference rules. Our ISP algorithms suffer from a similar quandary since, typically, antony-mous relations take the sa me sets of arguments for X (and Y ). For these cases, ISP algorithms learn many selectional preferences that accept the same types of entities as those that made DIRT learn the inference rule in the first place, hence ISP will not filter out many incorrect inferences. We presented algorithms for learning what we call inferential selectional preferences, and presented evidence that learning selectional preferences can be useful in filtering out incorrect inferences. Fu-ture work in this direction includes further explora-tion of the appropriate inventory of semantic classes used as SP X  X . This work constitutes a step towards better understanding of the interaction of selectional preferences and inferences, bridging these two aspects of semantics. 
