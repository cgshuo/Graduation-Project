 Sequences of events are an important type of data arising in various applications, including telecommunications, bio-statistics, web access analysis, etc. A basic approach to modeling such sequences is to find the underlying intensity functions describing the expected number of events per time unit. Typically, the intensity functions are assumed to be piecewise constant. We therefore consider different ways of fitting intensity models to event sequence data. We start by considering a Bayesian approach using Markov chain Monte Carlo (MCMC) methods with varying number of pieces. These methods can be used to produce posterior distribu-tions on the intensity functions and they can also accomo-date covariates. The drawback is that they are computation-ally intensive and thus are not very suitable for data mining applications in which large numbers of intensity functions have to be estimated. We consider dynamic programming approaches to finding the change points in the intensity func-tions. These methods can find the maximum likelihood in-tensity function in O(n2k) time for a sequence of n events and k different pieces of intensity. We show that simple heuristics can be used to prune the number of potential change points, yielding speedups of several orders of mag-nitude. The results of the improved dynamic programming method correspond very closely with the posterior averages produced by the MCMC methods. H.2.8 [Information Systems]: Data Mining; G.3 [Probability and Statistics]: Stochastic Processes event sequence, intensity modeling, MCMC requires prior specific permission and/or a fee. KDD 01 San Francisco CA USA 
Copyright ACM 2001 1-58113-391-x/01/08...$5.00 
Sequences of events are an important type of data arising in various applications, including telecommunications, bio-statistics, web access analysis, etc. Given a set E of possible where e E E is an event type and t is the occurrence time of the event. In telecommunication alarm analysis the set E is the set of possible error messages in the network, in web access analysis E can be the set of possible pages, and in biostatistics E encodes the biological effects of interest. 
A basic approach to modeling such sequences is to find the underlying intensity functions describing, for each event type, the expected number of events of that type per time unit; i.e., the different event types are modeled as Poisson processes. Typically, the intensity functions are assumed to be piecewise constant functions [2, 4]. Such functions are simple: arithmetic operations between the functions result piecewise constant functions. These operations as well as integration can be done easily and efficiently. On the other hand, piecewise constant functions are flexible; they can also be used in complex statistical modeling. 
We consider different ways of fitting intensity models to event sequence data. We start by looking at Bayesian ap-proach with Markov chain Monte Carlo (MCMC) methods, which can be used to produce posterior distributions on the intensity functions. The drawback is that they are compu-tationally intensive and thus are not very suitable for data mining applications in which large numbers of intensity func-tions have to be estimated. 
We consider dynamic programming approaches to finding the change points in the intensity functions. These meth-ods can find the maximum likelihood intensity function in O(n2k) time for a sequence of n events and k different pieces of intensity. We show that simple heuristics can be used to prune the number of potential change points, yielding speedups of several orders of magnitude. The results of the improved dynamic programming method correspond very closely with the posterior averages produced by the MCMC methods. We introduce the concept of intensity in Section 2 and MCMC based methods in Section 3. The change point de-tection problem is introduced, and the dynamic program-ming and hierarchical algorithms for solving the problem are presented in Section 4. In Section 5 we give simple heuris-tic methods for improving the performance of the dynamic programming approach, and report experimental results on real data sets. 
Consider an event sequence consisting of events of a single event type, and consider a fixed starting time for observing the process. Let T be the random variable indicating the waiting time for the next event. Denote by G(t) = Prob(T &lt; t) the distribution function of T. The interpretation of G is the probability that (after the starting time some time G) the waiting time before the next occurrence is not longer than t. Assume that the density function of G exists, and denote it by g(t). The function G(t) = 1-G(t) expresses the probability that the waiting time is longer than t; then defined as: 
The intensity function can be interpreted as the "immedi-ate" probability of occurrence at time t, given that no event occurred before t. [1] Thus X(t)dt expresses the probability of exactly one event during a "short" time interval the other hand, X(t) can also be interpreted as the expected number of occurrences per time unit. 
The intensity function uniquely determines the distribu-tion function G(t), since 
When the data contains several event types, we have to define an intensity function AA for each event type A. An in-teresting issue is then finding how the intensities of different types of events influence each other. 
In this paper we use piecewise constant functions for mod-eling intensities, i.e., the functions A(t) are assumed to have the following form: Here {T~, Te} E R are the start and end times of the ob-servation period, and the values {X1 .... ,),i} E R + are the the change points of the function. An example of a piecewise constant intensity function is shown in Fig. 1. Assume that an intensity function Ae(t) is defined in time range [Ts, T~], and a given event sequence S~ contains only events of a single event type e: Se = {(e, tl),...,(e, tn)}, tl E [To, T~], for all i = 1 .... , n. Then the Poisson likelihood of the data S~ can be written in the following form 
Figure 1: A piecewise constant intensity function. 
We next briefly describe the Bayesian modeling approach and apply it to finding piecewise constant intensity models. 
MCMC simulation methods are used to solve the computa-tional problems in the data analysis. 
Assume that a full probability model Me is constructed, and denote by O the vector 01,..., On of the model parame-ters, and by Y the data. The joint probability distribution determined by Me is given by lihood of the data. 
Bayes' rule follows by conditioning the joint probability distribution on the known data; it gives the posterior distri-
As the probability of the data P(Y) is not dependent on 0, the posterior distribution is proportional to the product of the prior distribution and the likelihood. 
Finding out the posterior distribution of the model param-eters is the core of the Bayesian data-analysis. The desired quantities can be presented as functions (g below) of the ex-pectation of the posterior distribution. To know the poste-rior expectation integration of the posterior density function is needed: 
In practical situations the analytical integration is not pos-sible, the posterior distribution can, however, be approxi-mated by using MCMC methods. 
If a sequence of random samples xi, i = 1, ...,N can be generated from a distribution f, and N is large, the sample set can be used to implicit (Monte Carlo) integration: 
Classical simulation methods (e.g., rejection sampling), which generate independent samples, fail when the target distribution has a high dimension combined with a com-plex dependence structure. By rejecting the independence 
MCMC methods can cope with a wider set of distributions than the classical methods. When applying Monte Carlo in-tegration dependent generated values can be accepted, pro-vided the distribution of sample values converges towards the target distribution f. The basic idea of the MCMC methods is to approximate the target distribution f by con-structing a Markov chain which has f as the equilibrium distribution. The state space of the chain is the set of pos-sible values x of f. dition can be used. The condition holds, when for all states x and y we have where T(x, y) is the probability of moving from state x to state y in the chain. Intuitively, this means that the flow from x to y will be the same as the flow from y to x. As-suming further that the chain is irreducible (all states com-municate) and aperiodic [8], then the reversibility condition implies that the equilibrium distribution of the chain is f; see, e.g., [6]. 
To use this idea, we must be able to compute f(x)/f(y) for all pairs x and y of states, i.e., the distribution must be known up to a constant. In the case of the Bayesian posterior distribution, the posterior density function is pro-portional to the product of the prior and likelihood densities. 
Thus Metropolis-Hastings algorithm can be applied, when these densities can be calculated. 
Denote by Q(x) the distribution from which a candidate value x r is drawn in state x and q(x, x ~) the corresponding density to propose x ' in state x. Consider the following al-gorithm: 1. set initial value xo 2. n~--0 3. while n &lt; MaxIterations begin 5. accept x p with probability a(xn, x ~) 6. if accepted then xn+, e-x ~ 7. else x,,+l ~ x,~ 9. end Here the acceptance ratio a(x,~, x') is: 
The last term, the jacobian, is only needed when the di-mension of the model is a variable. Here u is a random vector generated when proposing candidate state x r, and x ~ = x~(x,u) is the function determining the candidate, given x and u. 
For explanation why Metropolis-Hastings algorithm works, and detailed description of MCMC, see, e.g., [5],[9]. 
We now describe a simple model where the intensity of the occurrences of an event is modeled using a piecewise constant function. We show how a smooth intensity func-tion can be represented using averages of the piecewise con-stant function. The simple model can easily be extended, for instance, by accomodating covariates to the model. 
The intensity )~(t) is modeled by using a piecewise con-stant function as described above. The levels of the func-tion )~j, the change times cj and also the number of pieces k are random variables with the following prior specifica-tions. Here a,/3, and 7 are fixed constants, and Ts and T~ the start and end times of the observation period.  X  Number of pieces k ,,~ Geom(3')  X  Levels of functions Aj ,~ Uniform(a, ~)  X  Change times cj ,,~ Uniform(Ts, T~) 
The varying number of pieces causes the number of model parameters to change during an MCMC simulation run. 
Thus the intensity value at a given time point can stem from different pieces of the function. By dividing the observation period into a large number of segments and detecting the intensity value at each of these fixed time points, the pos-terior expectation and quantiles over the whole observation period can be approximated as the average of the intensity values in all the different realizations. The resulting poste-rior distribution is no longer piecewise constant although it was originally represented with a piecewise constant func-tion. 
We next describe the data we used in our experiments: two real data sets from telecommunication network man-agement applications. 
Modem telecommunication networks produce large amounts of data about the faults appearing in the network. This kind of alarm data is sequential in time and typically contain a large set of different event types. The structures of the net-works are changing often, and hence automatical analysis methods are needed to cope with the raw alarm data mass. 
For more detailed description of the telecommunication net-works and the alarm data, see [7]. 
The first data set we used contained 15 704 events, and the second one 46 662 events. These sets were also used in the experiments of the dynamic programming approaches below. 
We next illustrate the use of MCMC methods on a sub-set which contained 2 371 events. The priors used were 
Geom(0.9995) for the number of pieces, Uniform(0.001, 1500) for the level parameters, and Uniform(180000, 380000) for the change points. From an initial state with 20 pieces, 5 000 000 initial iterations were run, before collecting the parameter values. Then 1 000 000 sweeps were run, during which the parameter values were collected from every round. The total run time was 55 minutes (Pentium 700 MHz). 
The posterior average of the intensity and the 99 % per-centile values for 2000 time points are shown in Fig. 2 on the left. An interesting feature of the approach is the possibil-ity to view the posterior distribution conditioned on a fixed value of a parameter. The posterior average conditioned on the number of pieces k=10 is shown in the middle. The marginal posterior distribution of the number of the pieces is presented on the right side. The conditional distribution of the intensity at time t=300 000 seconds is shown in Fig. 3 on the left. 
Given a long sequence of events with many different event types it is useful to search for condensed representations of the sequence. One natural approach is to detect the time points, where the intensity substantially changes. The marginal distribution of the second change point is shown in Fig. 3 on the right. Figure 3: Conditional posterior distribution of in-tensity at time t=300 000 s (left). Marginal distri-bution of second change point (right). 
The MCMC methods supply interesting possibilities, but many problems may be encountered when applying the meth-ods in practice. The questions about convergence must be answered; how to be convinced that the distribution of the states of the constructed chain follows the target distribu-tion; and, if so, how to know that the chain covers the dis-tribution exhaustively? 
There are many heuristic methods available to test con-vergence. (see, e.g., [11]). The models described in this paper are relatively simple, and thus plausible guarantee about convergence can be reached relatively easily. Mostly difficulties seem to be encountered when dealing with the parameter indicating the number of pieces. 
For large data sets, the subtle Bayesian style of intensity modeling may be too slow. Thus, instead of trying to find out the posterior distribution of the intensity, we devised methods to find the best fitting piecewise constant function. In this section we describe a dynamic programming algo-rithm that always finds the optimal solution and show how its performance can be improved by using a novel heuristic. We show later that the results of the MCMC method, the dynamic programming algorithm producing optimal results, and the improved version of it are in excellent agreement. 
When the change points of the optimal function are known, computing the intensity values giving the maximum likeli-hood solution is easy: in each piece, the optimal intensity is the number of events divided by the length of the time period. 
The task of finding the optimal change points is not trivial, however. An important note is the observation that the change points of the optimal piecewise constant function are always at occurrence times of the event sequence. 
We next describe a greedy top-down algorithm first in-troduced by [3], here called the hierarchical algorithm. The presentation below is based on the version in [10]. 
The basic idea of the algorithm is to split time segments into two parts at the occurrence time giving the best gain in likelihood. A candidate set of potential change points is maintained; in each iteration round, the candidate giving the best gain is selected to be a new change point, the corre-sponding time segment is split and the candidate is removed from the candidate set. Two new candidates are added to the set by searching the best split points of the left-and right-side segments of the new change point. Splitting is continued until the stopping criterium is met. 
A weakness of the algorithm is that the greedy heuristic of the algorithm does not allow removing change points once selected. However, a change point of the optimal solution with m pieces is not necessarily a change point of the optimal solution with n pieces (m &lt; n). 
The time requirement of the algorithm in the worst case is 
O(nk), where n is the number of events and k the number of change points. The space needed is O(n). 
We now introduce an algorithm based on the dynamic programming idea. The algorithm always finds the optimal solution for the change point detection problem. 
Let the observation period be [Ts,Te] and the observed event sequence E = {ez,...,en}. Assume that the change points of an optimal piecewise constant function with k pieces are known, let them be cz,...,ck-z, and denote the corresponding likelihood L(k, :Is, T~). Then cz, ..., the change points of the optimal piecewise constant function with k -1 pieces in the subperiod ITs, ck-z]. 
Let us denote the last change point of a k-piece func-tion with ei as the end point C(k, ei). Assume now that change points of an optimal piecewise constant function with k pieces in [T~, ei] are known for all ei E E How to find the change points of an optimal function with k + 1 pieces? 
The maximum likelihood of the function with k + 1 pieces is given by 
The key idea of the dynamic programming algorithm is to compute the optimal division into k pieces in the time results according to (9) when computing the best divisions into k -t-1 pieces. The change points of the function can be detected backwards by recursively applying the following: 
Thus, the dynamic algorithm not only finds the optimal solution in the time range [Ts,T~], but also for all the sub-ranges [T~,ei],ei E E. The time requirement of the algo-rithm is O(n2k), and the space needed is O(nk). 
As a preliminary trial, we generated 20-piece intensity functions using the hierarchical and dynamic programming algorithms on an alarm dataset. 
There were big differences between the solutions: only five out of 19 change points were common to both algorithms, and 13 of them were clearly different. The corresponding loglikelihood values with different numbers of pieces are pre-sented below in Fig. 5 (left). The results show that the hier-archical method can produce clearly nonoptimal solutions. The execution times were less than ten seconds for the hier-archical algorithm and more than 10 hours for the dynamic programming algorithm. 5. SPEEDING UP DYNAMIC PROGRAM-
Because of unfeasible run times of the dynamic program-ming algorithm on large data sets, we modified the algorithm by allowing only a subset of all the events to be potential change points. 
In the first modified version the observation period was split regularly into k pieces with a set of 1,2,4,8,16,...,n possible change points, where n is the number of events in the sequence being investigated. 
A natural way to proceed is not to pick the change point candidates using pre-defined regular steps but to try to find some heuristic methods for evaluating the value of an occur-rence time as a potential change point. The basic intuition is that an occurrence time of an event is a good candidate left and right side of the occurrence time. 
Denote by t(n) the nth occurrence time, and let t~ = event n, and tr = t(n + k) -t(n) similarly to the right. We as an indication of the imbalance of density at point n. 
To obtain candidate points for the dynamic programming algorithm, the observation period was divided into k seg-ments and the occurrence time with the largest value of f in each segment was selected to the candidate set. The segmen-tation was done to avoid wide gaps between the candidates. 
We also used two or three different window sizes in the same run and selected the best value to represent the occur-rence time in comparison. 
We firstly ran the same trial as described above using now the modified dynamic programming algorithm that selected candidate values regularly. The algorithm resulted higher likelihood values compared with the values resulted by the hierarchical algorithm, when the candidate set of the poten-tial change points included at least every 128th event of the whole data set. The execution time in the case was reduced to about 15 seconds from 10 hours. Results very near the optimal solution were yielded when at least every 8th event was included (Fig. 4, top) . Figure 4: Loglikelihoods of the 20 piece divi-sions generated by the dynamic programming (DP), (MDP) algorithms with different regular step sizes (top), and the MDP algorithm using different win-dow sizes: -t-/ -10, 20, 50, and 100 events (bottom). 
We then ran the experiment using the modified dynamic programming algorithm that selected candidates using the heuristic function (10). The results shown in Fig. 4 (bot-tom) indicate that the algorithm using this heuristic pro-duced remarkably better results than the hierarchical algo-rithm even when less than 250 candidates (0.5 %) were used as potential change points. With more than 500 candidates the solutions were very near the optimal solution, the exe-cution times being only a few seconds. 
The results shown in Fig. 5 indicate that the solutions of the hierarchical algorithm are quite far from the optimum, especially with relatively low numbers of splits. Instead, the divisions generated by the heuristic dynamic program-ming algorithm with different sizes of candidate sets are very near the optimal solutions. In addition, the behaviour of the dynamic programming algorithm is smoother compared with the hierarchical algorithm in the sense that no sudden changes occur in the loglikelihood values, when the number of divisions is increased. 
Experiences from several trials showed that the results of the improved dynamic programming method correspond closely with the posterior averages produced by the MCMC method. Hence, the dynamic programming approaches can be used to approximate the posterior expectations. 
Figure 6 illustrates the correspondence. The posterior av-erage and 99 % percentiles are shown with the 200 piece algorithm with 994 candidates). division generated by the heuristic dynamic programming algorithm with 6.3 % of possible change points. The aver-age number of pieces during the MCMC simulation was 510. The solutions are very close to each other; the percentiles indicating the spread of the distributed intensity values, on the other hand, give information not supplied by the dy-namic programming method. Figure 6: Posterior average and 99 % percentiles (MCMC), and 200 piece intensity function (dynamic programming); first data set. 6. CONCLUSIONS 
Sequences of discrete events are a common type of data in many application areas. Often a natural approach to modeling such sequences is using time-dependent intensity functions, which tell the expected number of events per time unit. In this paper we show how piecewise constant func-tions can in several ways be used to produce representations of the intensities of event occurrences. Such functions can in a flexible way be used in complex statistical modeling, as well as in rough models when dealing with large amount of data. 
With large datasets MCMC based approaches are too slow. If the best fitting piecewise constant function only -instead of the distribution of functions -is to be detected, the optimal solution can be found in time O(n2k) by using dynamic programming. This approach may be too slow as well. Alternatively, heuristic greedy methods can be used, but the results, especially with relatively low number of change points, can give solutions that are quite far from the optimum. 
We introduced simple heuristics that can be used to prune the number of the potential change points of the functions, yielding speedups of several orders of magnitude in perfor-mance. The solutions are nearly optimal, however, and they also correspond very closely to the posterior averages pro-duced by the MCMC methods. 7. REFERENCES [1] E. Arjas. Survival models and martingale dynamics. [2] E. Arjas and J. Heikkinen. An Algorithm for [3] D. Hawkins. Point estimation of parameters of [4] M. Eerola, H. Mannila, and M. Salmenkivi. Frailty [5] P. Green. Reversible jump Marker chain Monte Carlo [6] P. Guttorp. Stochastic modeling of scientific data. [7] M. Klemettinen, H. Mannila, and H. Toivonen. [8] L. Tierney. Markov chains for exploring posterior [9] S. Chib and E. Greenberg. Understanding the [10] V. Guralnik and J. Srivastava. Event detection from [11] D. W.Gilks, S.Richardson. Marker chain Monte Carlo 
