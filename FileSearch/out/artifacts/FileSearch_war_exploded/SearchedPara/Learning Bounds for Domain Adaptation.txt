 different genres or styles [7, 6].
 measure between source and target domains and the number of t raining instances. of which may be drawn according to a different distribution a nd may contain a different number can outperform standard empirical risk minimization. a source domain hD A hypothesis is a function h : X  X  { 0 , 1 } . The probability according the distribution D When we want to refer to the risk of a hypothesis, we use the shorthand  X  write the empirical risk of a hypothesis on the source domain as  X   X   X  ( h, f ) ,  X  T ( h ) , and  X   X  T ( h ) for the target domain.
 tance measure. Let H be a hypothesis class for instance space X , and A of
X that are the support of some hypothesis in H . In other words, for every hypothesis h  X  H , { x : x  X  X , h ( x ) = 1 }  X  A H . We define the distance between two distributions as: For our purposes, the distance d paring distributions such as L we can compute a finite-sample approximation to d discriminates between (unlabeled) instances from D and D  X  [3].
 For a hypothesis space H , we define the symmetric difference hypothesis space H  X  H as given pair of hypotheses in H disagree. We can then define A above a distance d which is straight-forward to prove: ses in our class. The ideal hypothesis minimizes combined source and target risk: We denote the combined risk of the ideal hypothesis by  X  =  X  reasonably approximate target risk using source risk and th e distance between D in terms of the source risk, the difference between labeling functions f between the distributions D of Ben-David et al. [3], with a small correction to the statem ent of their theorem. Theorem 1 Let H be a hypothesis space of VC-dimension d and U size m  X  each, drawn from D U choice of the samples), for every h  X  H ,  X  H  X  H -distance are important quantities for computing target er ror. PAC-Bayes [15] or Rademacher complexity [2] in an analogous way.
 At train time a learner receives a sample S = ( S instances drawn independently from D from D We denote as  X  sured with respect to D We bound the target risk of a domain adaptation algorithm tha t minimizes  X   X  bound has two main components, which we state as lemmas below . First we bound the difference between the target risk  X  true and empirical weighted risks  X  of Theorem 2, are in Appendix B.
 Lemma 1 Let h be a hypothesis in class H . Then Lemma 2 Let H be a hypothesis space of VC-dimension d . If a random labeled sample of size m is generated by drawing  X m points from D according to f samples), for every h  X  H is weighted equally), our finite sample approximation to  X  Theorem 2 Let H be a hypothesis space of VC-dimension d . Let U of size m  X  each, drawn from D by drawing  X m points from D f , respectively. If  X  h  X  H is the empirical minimizer of  X   X  target risk minimizer, then with probability at least 1  X   X  (over the choice of the samples), target data against the large amount of less relevant source data.
 We remark that when it is known that  X  = 0 , the dependence on m in Theorem 2 can be improved; this corresponds to the restricted or realizable setting. could be directly compared with test error, this is not pract ical because  X  is unknown, d complexity. Instead, we develop a simple approximation of T heorem 2 that we can compute from ously good for both domains), so we ignore it here. We approxi mate d d data. For domains that can be perfectly separated with margi n,  X  ( U are indistinguishable,  X  ( U with a tighter constant C . The resulting approximation to the bound of Theorem 2 is instance by  X / X  and the loss of a source training instance by (1  X   X  ) / (1  X   X  ) . numbers of source instances.
 instances m Note that  X  = m single value of C =1600 for all 12 curves on the top part of Figure 1. mimics the shape of the bounds. Furthermore the value of  X  which minimizes the bound also has bound of Theorem 2 and subsequently training a classifier to m inimize the empirical error  X   X  work well in practice, provided we have a reasonable measure of complexity. 4 Figures 1a and 1b target data). The phase transition occurs when m and learning only from target data). We fix C = 1600 and  X  ( U than this, it is more effective to ignore even an infinite amou nt of source data. We now explore an extension of our theory to the case of multip le source domains. We are pre-sented with data from N distinct sources. Each source S distribution D are given m perform well on a target domain hD instance is its own source domain.
 training errors over the labeled examples from each source d omain. As before, we let m with P N define the empirical  X  -weighted error of function h as The true  X  -weighted error  X   X  -weighted error.
 Theorem 3 Suppose we are given m vector of weights  X  , let  X  h = argmin  X   X  (0 , 1) , with probability at least 1  X   X  (over the choice of samples from each source), (a) Source. More girls than boys (b) Target. Separator from (c) Weighting sources to match data and learn an optimal classifier.
 second is a uniform convergence bound for  X   X  we demand that there exists a hypothesis h  X  which has low error on both the  X  -weighted convex a mixture of sources, rather than between the target and a sin gle source. non-uniform weighting of sources accurately approximates the target domain. As a hypothetical the  X  X ales X  and  X  X emales X  components of the source to match t he target. bounds they give are no stronger than bounds which completel y ignore the source data. d is less general. They consider only including or discarding a source entirely. Li and Bilmes [13] give PAC-Bayesian learning bounds for ada ptation using  X  X ivergence priors X . model, though, we measure the divergence (and consequently the bias) of the source domain from ing data from a source domain but wish to apply a model in a targ et domain with a much smaller explain the success of recent empirical work in domain adapt ation.
 convex combination of multiple sources to minimize the boun d in Theorem 3. This material is based upon work partially supported by the D efense Advanced Research Projects Agency (DARPA) under Contract No. NBCHD030010. Any opinion s, findings, and conclusions or the views of the DARPA or Department of Interior-National Bu siness Center (DOI-NBC).
