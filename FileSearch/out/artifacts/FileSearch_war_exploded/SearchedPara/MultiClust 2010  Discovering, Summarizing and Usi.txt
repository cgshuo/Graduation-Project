 Traditional clustering focuses on finding a single best clus-tering solution from data. However, given a single data set, one could interpret it in different ways. This is particularly true with complex data that has become prevalent in the data mining community: text, video, images and biological data to name a few. It is thus of practical interest to find all possible alternative and interesting clustering solutions from data. Recently there has been increasing interest on developing algorithms to discover multiple clustering solu-tions from complex data. This report provides a description of the first international workshop on this emerging topic  X  SIGKDD MultiClust10: Discovering, Summarizing and Using Multiple Clusterings, which was held in Washington DC, on July 25th 2010. The workshop program consists of three invited talks and presentations of four full research papers and three short papers. Data is often multi-faceted by nature. Given a single data set, one can interpret it in several different ways. This is particularly true with complex data that has become preva-lent in the data mining community: examples of such data include text, video, images and biological data. Yet, many data mining and clustering algorithms in particular only ex-tract and present a single clustering/summarization even though multiple good alternatives exist. Practitioners of-tentimes find that the clustering solution provided by an algorithm is not what they are looking for. Why limit the output to one clustering solution? Why not provide all pos-sible alternative and interesting clustering solutions? Recently, there has developed an emerging interest on dis-covering multiple clustering solutions from complex data. To avoid redundancy and excessive burden on the data an-alyst, it is key to extract clustering solutions that are infor-mative yet non-redundant from one another. Toward this goal, important research issues include, how to define redun-dancy among clusterings, can existing algorithms be modi-fied to accommodate this goal, how many solutions should we extract, how to select among exponentially many possi-ble solutions which solutions to present to the data analyst, and how to most effectively help the data analyst find what he or she is searching for. Existing work approach this prob-lem by looking for non-redundant, alternative, disparate or Prof. James Bailey presents a summary of the existing re-search on alternative clusterings. He organizes the exist-ing techniques into different categories including sequential and simultaneous discovering of alternative clusterings and highlights the advantages/disadvantages of each type. He also notes two different styles in designing the algorithms X  projection based methods and methods based on complex objective functions. Finally, Prof. Bailey also discusses im-portant open issues in alternative clustering including chal-lenges we face in evaluation and model selection.
 Dr. Rich Caruana combines ensemble methods and the goal of generating multiple alternative clustering solutions in his work on meta clustering. In his talk, he compared two com-peting approaches for accomplishing the goal of efficiently finding multiple, significantly different, yet high quality clus-terings, and to allow users to efficiently find among these the clustering(s) that are most useful for them. One approach is clustering with side information and the other is multi/meta clustering. One surprising result from their experiments is that the clustering which is most useful often is not a very compact clustering using common definitions of compact-ness. We accepted four full research papers: 1.  X  X ariational Inference for Nonparametric Multiple Clus-2.  X  X ncovering Many Views of Biological Networks Using 3.  X  X ncorporating Spatial Similarity into Ensemble Clus-4.  X  X n Using Class-Labels in Evaluation of Clusterings X  Clustering is a difficult problem. This difficulty is com-pounded by that data may be multi-faceted. In addition, in high-dimensions, typically not all features are important. When designing feature selection algorithms for clustering, one needs to define a criterion for selecting which of two or more alternative feature subsets is the relevant/interesting subset. Why choose one feature subset, when all the al-ternative feature subset views might be interesting. Fea-tures irrelevant to one interpretation might be relevant to another interpretation. Guan, Dy, Niu and Ghahramani present a probabilistic nonparametric Bayesian model that can discover multiple clustering solutions and the feature subset views that generated each cluster partitioning simul-taneously. They provide a variational inference approach to learn the features and clustering partitions in each view and also automatically learn the number of views and the number of clusters in each view.
 Duggal, Navlakha, Girvan and Kingsford discuss finding multiple views of biological networks. This is one of the for evaluating and exploring subspace clusterings. They describe how their OpenSubSpace open source framework which contains implementations of various sub-space clus-tering algorithms also contains various measures of evaluat-ing subspace clustering and their extensions for alternative sub-space clustering.
 Kriegel and Zimek attempt to draw comparisons and sim-ilarities between the areas the workshop covers: subspace clustering, ensemble clustering, alternative clustering, and multiview clustering. They draw the conclusion that though superficially similar all are different approaches motivated by different problems and aiming at different goals. How-ever, they do explore some connections between the areas and pose several topics for discussion amongst the fields: G  X unnemann, F  X arber, Muller and Seidl present some of the earliest work on alternative sub-space clustering. This work differs from existing work, in that not only is the notion of alternativeness measured in terms of the cluster composition with respect to instances/objects but also to the sub-space the objects within the cluster occupy. An empirical analysis on several UCI data sets including the PenDigits data set shows the practicality of this work for even low dimensional data. Discovering multiple clusterings from data is an emerging new topic that is gaining increasing interests among both researchers and practitioners. The MultiClust10 workshop is the first workshop on this topic. It brought together re-searchers from different subfields of data mining including cluster ensemble, constraint-based clustering and subspace clustering. The workshop provided an opportunity for re-searchers who are excited about this research area to com-municate with one another and discuss different challenges in this emerging area. Significant interest has been ex-pressed during the workshop to continue this effort and have another workshop for next year. More information about the MultiClust 10 workshop can be found on the following website, http://eecs.oregonstate.edu/research/MultiClust/. We would like to thank all the authors of the workshop pa-pers, whose creative work made this workshop a success. We thank the invited speakers for sharing their insights on this important topic. We are greatly indebted to our excellent
