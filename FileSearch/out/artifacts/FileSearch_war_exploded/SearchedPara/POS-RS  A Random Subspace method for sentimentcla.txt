 1. Introduction
With the rise of Web 2.0 platforms, personal opinions, such as reviews, ratings, recommendations, and other forms of user-generated content, have attracted significant interest from the research community ( Pang &amp; Lee, 2008 ). The sheer volume and exponential growth of this information provides potential value to governments, businesses, and users themselves ( He &amp; Zhou, 2011 ). There is an inherent property called sentiment involved in the vast majority of online-generated content. Sentiment is an opinion or feeling you have about something ( Delacroix, 2007 ). In this study of sentiment classification, we focus on attempts to identify the sentiment polarity of a given text, which is traditionally classified as either positive or negative.

In reality, sentiment classification has many application scenarios, such as applications to review-related websites, applications as a sub-component technology, applications in business and government intelligence, applications across  X  different domains ( Pang &amp; Lee, 2008 ). Based on two surveys of more than two thousands American adults, it was found that people between 73% and 87% reported that online reviews had an important influence on their purchase among readers of reported that they were willing to pay more for a 5-star-rated goods than a 4-star-rated goods ( Horrigan, 2008; Pang &amp; technique for other systems ( Pang &amp; Lee, 2008 ). For example, sentiment classification is a supplement to recommendation systems, as it might be proper that a system recommend items that receive a lot of positive feedback. Moreover, sentiment hostile or negative communications ( Abbasi, 2007 ).
 Accordingly, sentiment classification has become a popular research topic in both academic and industry fields ( Abbasi,
Heuristic-based methods and machine learning approaches were frequently employed in previous research ( Abbasi et al., 2008a; Pang &amp; Lee, 2008 ). Heuristic-based methods were primarily used in conjunction with linguistic properties and semantic features. For example, Turney used mutual information with predefined sentiment words to score other phrase tags, therefore identifying the sentiment of documents ( Turney, 2002 ). In parallel, many studies focused on using machine learning algorithms to classify sentiment. For instance, Support Vector Machines (SVM) and Naive Bayes (NB) are commonly used to identity sentiment, due to their predictive power. Pang et al. conducted an empirical study in sentiment classifica-tion, concluding that SVM outperformed other classifiers such as NB ( Pang, Lee, &amp; Vaithyanathan, 2002 ). In recent years, there has been a growing interest in using ensemble learning techniques, which combine the outputs of several base clas-thermore, prior research have shown that Bagging, Boosting, and Stacking have performed better than singleton machine learning techniques for sentiment classification ( Abbasi, Chen, Thoms, &amp; Fu, 2008b; Wang et al., 2014; Whitehead &amp;
Yaeger, 2010; Xia, Zong, &amp; Li, 2011 ). However, Random Subspace, an important ensemble method that has been successfully applied in other text classification problems, has been under-examined.

In this research, a novel Random Subspace method, POS-RS, is proposed for sentiment classification based on part-of-speech analysis. Random Subspace mainly uses one parameter, i.e., subspace rate, to control the diversity of base learners.
However, the performance of ensemble learning methods is influenced not only by the diversity of base learners, but also by the accuracy of base learners. From the perspective of multi-objective optimization, a collaborative mechanism should be considered to balance the accuracy and the diversity of base learners. Accordingly, based on part-of-speech analysis, POS-
RS is proposed for sentiment classification, which uses two parameters, i.e., content lexicon subspace rate and function lex-icon subspace rate, to simultaneously control the accuracy and the diversity of base learners. Ten public sentiment analysis datasets are used to verify the effectiveness of proposed method. Empirical results show that POS-RS achieves the best results among the compared methods. Moreover, POS-RS can reduce bias and variance simultaneously compared to the base learner, i.e., SVM, and yields the lowest bias among all the ten datasets.

In summary, the main contributions of this paper are the following: (1) From the perspective of multi-objective optimization, a tradeoff mechanism is proposed to control the balance of the (2) Based on the proposed collaborative mechanism, a new Random Subspace method, POS-RS, is proposed for sentiment (3) A detailed comparison with the performance of other popular ensemble methods is provided.

The rest of this paper is organized as follows. Section 2 presents the related work on sentiment classification. The newly proposed method, POS-RS, is described in Section 3 . Next, Section 4 describes the experimental setup used for evaluating the proposed approach. Section 5 presents the results and discussions. Finally, Section 6 discusses conclusions and future research directions. 2. Literature review
Since the late 1990s, sentiment classification has been an important research topic in the areas of data mining, and nat-to capture the sentiment of individual words or phrases, a measure of the strength of sentiment polarity is often defined to
Subrahmanian &amp; Reforgiato, 2008; Turney, 2002 ). Furthermore, Thet, Na, and Khoo (2010) computed the sentiment of a clause from individual word sentiment scores, considering the grammatical dependency structure of the clause. Other stud-Niblack, 2003; Zhang, Zeng, Li, Wang, &amp; Zuo, 2009 ). The greatest amount of work has been done on document level polarity research can be classified into heuristic-based methods and machine learning methods. 2.1. Heuristic-based methods for sentiment classification
By means of predefined lexicons and calculation rules, heuristic-based methods generally classify text sentiments based on the counts of derived positive or negative sentiment features ( Pang &amp; Lee, 2008 ). For example, Hatzivassiloglou and
McKeown (1997) considered that adjectives are more predictive of sentiment classification and predicted the sentiment approach may overestimate the importance of adjectives and underestimate some predictive words of other parts-of-speech.
Along this line, Turney (2002) determined the semantic orientation of a phrase using its point-wise mutual information with predefined sentiment words, such as  X  X  X xcellent X  X  and  X  X  X oor X  X . Therefore, sentiment classification can be achieved by aggre-gating the overall sentiment information of phrases. The Adjective X  X erb X  X dverb (AVA) combinations were thoroughly ana-this line ( Hu &amp; Li, 2011; Yi et al., 2003 ).

The heuristic-based methods are by nature knowledge engineering methods. One of the problems of this approach is it this research, we focus on machine learning methods for sentiment classification. 2.2. Machine learning methods for sentiment classification
Machine learning approaches for sentiment classification have been extensively studied, due to their predominant clas-sets, these methods can model more features and adapt to changing inputs more robustly, than heuristic-based methods ( Pang &amp; Lee, 2008 ).

Many machine learning techniques have been investigated for sentiment classification in the literature. However, there is no consensus as to which methodology an algorithm developer should adopt for a given problem in a given domain ( Wolpert &amp; Macready, 1997 ). Recent studies suggest that ensemble learning methods may have potential applicability in sentiment previous studies dealing with sentiment classification using ensemble methods.

Prior studies have shown that such ensemble methods have performed better than singleton machine learning technique 2010 ). For example, Wilson et al. first used Boosting for sentiment classification and achieved 23 X 96% improvements in used to the integration process of single classifier. The proposed stacking method improved the accuracy as compared with the three singleton classifiers. Abbasi et al. proposed the support vector regression correlation ensemble (SVRCE) method for enhanced performance of sentiment classification ( Abbasi et al., 2008b ). The experimental results indicated that SVRCE out-performed comparison techniques. Lu and Tsou presented a novel approach to combine a large sentiment lexicon and machine learning techniques for sentiment classification ( Lu &amp; Tsou, 2010 ). The experiments with the NTCIR opinion data showed that the approach significantly outperformed the baselines. Whitehead and Yaeger compared Bagging, Boosting, and Random Subspace for sentiment classification and shown that ensemble learning methods can increase classification tiveness of Stacking for sentiment classification ( Xia et al., 2011 ). Experimental results demonstrated that using ensemble technique is an effective way to combine different feature sets and classification algorithms for better classification performance. Su et al. used Stacking for sentiment classification of reviews based on different methods and compared it with majority voting ( Su et al., 2013 ). Stacking has been proven to be consistently effective across multiple domains. Li et al. iments on Chinese benchmark datasets showed that Stacking outperformed any individual classifiers. Wang et al. conducted a comparative assessment of the performance of three popular ensemble methods (Bagging, Boosting, and Random Sub-space) based on five base learners (Naive Bayes, Maximum Entropy, Decision Tree, K Nearest Neighbor, and Support Vector
Machine) for sentiment classification ( Wang et al., 2014 ). Empirical results revealed that ensemble methods substantially improve the performance of individual base learners for sentiment classification.

Although many ensemble learning methods have been proposed for sentiment classification, Random Subspace, an important ensemble learning method that has been successfully applied in other text classification problems ( Zhang, 2008 ), is under-examined in the literature. To fill this research gap, this study proposes a new Random Subspace method,
POS-RS, for sentiment classification based on part-of-speech analysis. This research will give more insights into sentiment classification using ensemble learning methods. 3. A novel Random Subspace method for sentiment classification
Ensemble learning is a machine learning paradigm where multiple learners are trained to solve the same problem ( Polikar, 2006; Zhou, 2012 ). In contrast to ordinary machine learning approaches that try to learn one hypothesis from the training data, ensemble methods try to construct a set of hypotheses and combine them for use ( Liu &amp; Zsu, 2009 ). Learners which an ensemble is composed of are usually called base learners. One of the earliest studies on ensemble learning is Dasarathy
In 1990, Hansen and Salamon showed that the generalization performance of an Artificial Neural Network (ANN) can be improved using an ensemble of similarly configured ANNs ( Hansen &amp; Salamon, 1990 ). Schapire demonstrated that a strong classifier in Probably Approximately Correct (PAC) sense can be generated by combining weak classifiers through Boosting have expanded rapidly, appearing often in the literature under many creative names and ideas ( Polikar, 2006 ).
The generalization ability of an ensemble method is usually much stronger than that of a single learner, which makes ensemble methods very attractive. Dietterich (1997) gave three reasons based on viewing the nature of machine learning as searching in a hypothesis space for the most accurate hypothesis. Firstly, the training data might not provide sufficient information for choosing a single best learner. For example, there may be many base learners performing equally well on the training set. Thus, combining these learners may be a better choice. Secondly, the search processes of the learning algo-rithms might be imperfect. For example, even if there is a unique best hypothesis, it might be difficult to attain this goal, since running the algorithms results in sub-optimal hypotheses. Thus, ensembles can compensate for such imperfect search processes. Thirdly, the hypothesis space being searched might not contain the true target function, while ensembles can give some good approximation. For example, the classification boundaries of DTs are linear segments parallel to coordinate axes.
If the target classification boundary is a smooth diagonal line, using a single DT cannot lead to a good result. But a good approximation can be achieved by combining a set of DTs. Although these intuitive explanations are reasonable, they lack rigorous theoretical analyses.
 In practice, to achieve a good ensemble, two necessary conditions should be satisfied: accuracy and diversity ( Windeatt &amp;
Ardeshir, 2004 ). The base learner should be more accurate than random guessing, and each base learner should have its own knowledge about the problem, with a different pattern of errors than other base learners. In general, ensemble learning methods can be divided into three categories: instance partitioning methods, feature partitioning methods, and Stacking ( Polikar, 2006; Wang, Hao, Ma, &amp; Jiang, 2011 ). Bagging and Boosting are instance partitioning methods; Random Subspace is a feature partitioning method ( Polikar, 2006; Wang &amp; Ma, 2011 ). The Random Subspace method is an ensemble construc-tion technique proposed by Ho (1998) . In Random Subspace, the training dataset is modified as in Bagging. However, this modification is performed in the feature space rather than in the instance space. The Random Subspace method may benefit from using random subspaces for both constructing and aggregating the base learners ( Wang &amp; Ma, 2011; Zhang, 2008 ).
Compared with other ensemble methods, Random Subspace method is more suitable to the problem of sentiment clas-sification. The main reason is that sentiment classification is an instance of text classification problems, which has a large number of relevant and redundant features. Thus, good base learners can be obtained in random subspaces than in the ori-ginal feature space, when the dataset has many redundant or irrelevant features ( Ho, 1998 ). The combined decision of such base learners may be superior to a single learner constructed on the original training dataset in the complete feature sets.
Although Random Subspace has these superiorities, previous studies have not paid attention to it in the area of sentiment classification. Subsequently, in line with the characters of sentiment classification, a new Random Subspace method, POS-RS, is proposed for sentiment classification based on part-of-speech analysis. The framework of POS-RS is shown in Fig. 1 .
POS-RS has two major steps: extracting a set of features and constructing base learners. These steps are used to carry out sentiment classification. 3.1. Feature extraction
In ensemble learning, accuracy and diversity of base learners are two important factors for the performance of ensemble learning methods. However, like many multi-objective optimization problems, how to balance these two factors lacks theoretical guidance. Comparative studies have shown that on average AdaBoost is the best method although Random Sub-sity in Bagging is obtained by using bootstrapped replicas of the training data: different training data subsets are randomly drawn X  X ith replacement X  X rom the entire training dataset ( Breiman, 1996 ). Boosting creates different base learners by sequentially reweighting the instances in the training dataset. Each instance misclassified by the previous base learner will get a larger weight in the next round of training ( Schapire, 1990 ). Unlike instance partitioning methods, Random Subspace construct base learners through randomly selecting features. Randomized feature subsets is used to  X  X  X nject randomness X  X  into base learners in order to increase their diversity in the ensemble, while this method ignores another import factor, accuracy.
Accordingly, an interesting question emerges whether there exists a mechanism that is capable of considering accuracy and diversity simultaneously for sentiment classification.

For the sentiment classification problem, the goal is to distinguish reviews X  sentiment polarity, i.e. positive or nega-tive. To achieve this, reviews need to be linguistically analyzed. Based on linguistic theories, a sentence is composed of many relative words. In grammar, a word class is a linguistic category of words, which is generally defined by the syn-tactic or morphological behavior of the lexical item in a sentence ( Winkler, 2012 ). Words in English can be divided into content words and function words ( Winkler, 2012 ). Content words are words that refer to some object, action, or other non-linguistic meaning. Function words are words that have little lexical meaning, but instead serve to express gram-matical relationships. Content words mainly include nouns, verbs, adjectives, and adverbs. Function words mainly include articles, prepositions, conjunctions, and so on ( Winkler, 2012 ). Content words typically hold much more infor-mation than function words, while many functional words are used to make sentences fluent and integrated. Just for this reason, WordNet is constructed based on a lexical database for English including nouns, verbs, adjective and adverbs, while not including function words ( Miller, 1995 ). These functional words not only reduce the accuracy of clas-sifier, but also cause longer computing time in classification ( D X  X ondt, Verberne, Weber, Koster, &amp; Boves, 2012; Liu, Yu, Chen, Wang, &amp; Wu, 2010 ).

Based on the above analysis and justification, we design a mechanism to balance the accuracy and diversity based on part-of-speech analysis. We firstly separate reviews into content lexicons and function lexicons. Then, two parameters, i.e., content lexicon subspace rate and function lexicon subspace rate, are used to control the process of constructing sub datasets for POS-RS. Unlike the original Random Subspace, which uses only one parameter, i.e., subspace rate, to control the diversity of ensemble, POS-RS includes two parameters to simultaneously control the accuracy and the diversity of ensemble.
 tent lexicons and function lexicon from the reviews. The content lexicons consist with nouns, verbs, adjectives, and adverbs.
Nouns is a word or group of words used for referring to a person, thing, place, or quality, while, verbs is a type of word or phrase that shows an action or a state. Adjectives is a word used for describing a noun or pronoun, while, adverbs is a word used for describing a verb, an adjective, another adverb or a whole sentence. These four sets of content lexicons play a dom-inant role in classifying sentiment of reviews, as demonstrated by our experiments. Stanford POS Tagger is a piece of soft-ware that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb and are constructed separately. 3.2. Model construction
Random Subspace methods use the subspace rate (the ratio of selected features over total feature stock) to randomly select features to construct sub datasets. In POS-RS, two parameters, i.e. content lexicon subspace rate and function lexicon subspace rate, are proposed to construct sub datasets, which control the accuracy and the diversity of base learners simul-taneously. After construction of sub datasets, base learners are trained on the different sub datasets.

The purpose of the model construction module is to learn the pattern in every sub datasets. Although each base learner in the ensemble only has to satisfy the minimum requirement of being more accurate than random guessing, the more accurate base learners can achieve the better performance. SVM is one of the most widely used machine learning techniques. Pang et al. conducted an empirical study in sentiment classification, concluding that SVM outperformed other classifiers ( Pang et al., 2002 ). Therefore, SVM is selected as base learner in this study.

In SVM learning, the original input space is mapped into a high-dimensional dot product space called a feature space, and in the feature space the optimal hyperplane is determined to maximize the generalization ability of the classifier ( Vapnik, 2000; Wang &amp; Ma, 2012 ). The optimal hyperplane is found by exploiting the optimization theory, and respecting insights provide by the statistical learning theory.

Given a set of training data points TR k  X  x k 1 ; y k 1 ; ... ; x rate. A linear classifier f ( x ) is a hyperplane, and can be represented as f ( x ) = sgn( w
SVM is equivalent to solving a convex quadratic optimization problem in (1): on the training set TR k . This quadratic problem is generally solved through its dual formulation. Simply replacing the involved vector inner-product with a non-linear kernel function converts linear SVM into a more flexible non-linear SVM, which is the essence of the famous kernel trick. Any function satisfying Mercer X  X  condition can be used as the kernel function ( Vapnik, 2000 ).

After training of different base learners, another issue is to combine these results of different base learners. The goal of the fusion module is to aggregate different base learners X  results and reduce the detection errors of every SVM ble learning methods, majority voting is a popular aggregation method whose effectiveness has been proven empirically and theoretically ( Breiman, 1996; Polikar, 2006 ). Accordingly, majority voting rule is used to aggregate different based learners X  results in POS-RS. Given a series of base learners f C as follows: 3.3. The POS-RS algorithm: recap
The POS-RS algorithm works as follow. At first, it uses the Stanford POS Tagger to split the original feature space D into content lexicons D C and function lexicons D F . Then, POS-RS generate K sub datasets by randomly choosing and combining two subsets of features from D C and D F , controlled by the parameters r trained on K sub datasets. In this research we choose SVM as the base learner. Finally, the predictions of the base learners are combined via majority voting. The pseudo-code of the POS-RS algorithm is shown in Fig. 2 . Compared with the original
Random Subspace, POS-RS has two important parameters, i.e. content lexicon subspace rate and function lexicon subspace rate.
 4. Experimental setup 4.1. Experimental datasets
To verify the effectiveness of POS-RS for sentiment analysis, we investigated ten publicly available sentiment analysis datasets from a wide variety of domains. The Movie dataset was collected from the commonly-used Cornell movie-review tive or negative) or ratings on a scale from 1 to 5, and movie-review sentences labeled with subjectivity statuses (subjective or objective) or polarities. In our experiments, the documents labeled with polarities were chosen as the dataset, which con-tained 1000 positive and 1000 negative reviews. The other nine sentiment analysis datasets were provided by Whitehead and Yaeger (2009) . These datasets include reviews and corresponding ratings, in which the rating of  X  X 1 X  X  was a positive sen-timent and the rating of  X  X  1 X  X  was a negative sentiment. Except for the Camera dataset that contain 250 positive instances and 248 negative instances, the other eight datasets have the equal number of positive and negative instances. The summary descriptions of the datasets are shown in Table 2 . 4.2. Performance evaluation
The established standard measure in sentiment classification, average accuracy, was adopted to evaluate the performance of the proposed method. The definition of average accuracy can be explained with a confusion matrix as shown in Table 3 . Formally, average accuracy is defined as follows: 4.3. Experimental procedure
In order to examine the performance of the proposed method, some baseline methods are selected for comparison pur-poses. Although the Stacking method is often used for sentiment classification, the performance of Stacking is difficult to analyze theoretically ( Polikar, 2006; Zhou, 2012 ). Similarly, little guidance is available on how to select base learners ginal Random Subspace method, are used as benchmark techniques in the experiments. Like POS-RS, Bagging, Boosting, and
Random Subspace all used SVM as base learner. Besides above mentioned ensemble methods, another two popular senti-ment classification methods, i.e., Naive Bayes (NB) and Maximum entropy (ME), were selected as benchmark methods. To verify our contribution to sentiment analysis besides machine learning, we also compared our proposed method with three (denoted as SNLP) uses average sentence polarity to approximate document polarity. SentiStrength (denoted as SS) estimates the strength of positive and negative sentiment simultaneously, and uses the maximum of the two to label the document polarity. OpinionFinder (denoted as OF) provides document-level polarity labels as well as corresponding probability distributions.

Moreover, in order to minimize the influence of variability in the training set, 10-fold cross validation was performed ten the union of nine subsets was used as the training set while the remaining subset is used as the test set. The process was repeated ten times, such that every subset had been used as the test set once. The average test result was regarded as the result of the 10-fold cross validation. The process was repeated for 10 times with random partitions of the ten subsets, and the average results of these different partitions were recorded. The experimental procedure is shown in Fig. 3 . 5. Results and discussions
We used the data mining toolkit WEKA (Waikato Environment for Knowledge Analysis) version 3.7.0 for implementation of base learners. This open-source toolkit includes a collection of machine learning algorithms for solving data mining prob-lems ( Witten, Frank, &amp; Hall, 2011 ). Additionally, the Stanford POS Tagger (version stanford-postagger-2012-01-06) was employed to extract content lexicons and function lexicons.

In this study, we compared the performances of SVM, Bagging, Boosting, Random Subspace (RS), Na X ve Bayes (NB), Max-imum Entropy (ME), StanfordNLP (SNLP), SentiStrength (SS), OpinionFinder (OF), and the proposed POS-RS. Among these methods, the SVM algorithm, Bagging algorithm, Boosting algorithm, Random Subspace algorithm, NB algorithm, and ME algorithm were implement by the SMO module, the Bagging module, AdaBoostM1 module, the RandomSubSpace module, the NaiveBayes module and Logistic module (WEKA X  X  own version of multinomial logistic regression) in WEKA, respectively.
The ensemble modules used SVM as base learner. StanfordNLP 3.4, SentiStrengh X  X  Window version, and OpinionFinder 2.0 were used. As the original datasets were text forms, WEKA X  X  StringToWordVector filter was used to convert original texts into an N-Gram representation. The parameter of SetWrodsKeep is set to the maximum number of features of datasets. The content lexicon subspace rate r C and function lexicon subspace rate r space rate of Random Subspace varied from 0.1 to 0.9 with interval 0.1. Except when stated otherwise, all the default param-eters in WEKA were used. 5.1. Experimental results
Table 4 presents the average accuracy of all methods, where the values following  X  X  X  X  X  are standard deviations. The highest average accuracies of different datasets are boldfaced.

Generally speaking, the results in Table 4 show that the performance of proposed POS-RS method is better than that of other methods. Except on the Camera, Music and TV datasets, POS-RS achieves the highest average accuracies of 85.26% ( r = 0.5 and r F = 0.5) on Camp, 85.03% ( r C = 0.8 and r F = 0.7) on Doctor, 68.82% ( r ( r = 0.4 and r F = 0.9) on Laptop, 83.86% ( r C = 0.6 and r F 70.66% ( r C = 0.8 and r F = 0.3) on Radio. RS, OF, and SNLP each leads on performance in one dataset. Moreover, as expected, methods only using function lexicons (F2) yield the lowest average accuracies. 5.2. Discussions 5.2.1. Statistical analysis
To ensure that the assessment does not occur by chance, we tested the significance of these results. Following ( Dem X ar, there are significant differences among all methods. Then, pairwise differences were measured using a Wilcoxon test ( Dem X ar, 2006 ). The formulation of the test ( Wilcoxon, 1945 ) is as follows. Let d is assigned. Let R + be the sum of ranks for the data sets on which the second algorithm outperformed the first, and let R be the sum of ranks where the first algorithm outperformed the second. Ranks are split evenly among the sums and values for T . For a larger N , the statistics is distributed approximately according to N (0,1). We combined these two tests to assess the performance difference of the different algorithms. When the comparison was between two algorithms only the Wilcoxon test was used.

We also employed the statistics used in ( Webb, 2000 ) to compare two learning algorithms across all data sets, namely, the win/draw/loss record. The win/draw/loss record presents three values, the number of data sets for which algorithm A obtained better, equal, or worse performance than algorithm B with respect to classification accuracy. We also reported mined to be significant at the 0.05 level by a paired t -test.

As the results of methods only using function lexicons (F2) are obviously worse, we only compared the methods using F1 and F1 + F2 with POS-RS. Table 5 shows the comparison among the methods. Columns labeled s present the win/draw/loss the last is the number for which row &gt; col . Columns labeled p Iman X  X aveport test had a p -value of 0.000, showing significant differences among them.

As seen in the tables, POS-RS has significantly better win/draw/loss records than other methods. Compared with RS (F1) and RS (F1 + F2), POS-RS gets the records 7/2/1 and 5/3/2. Compared with Bagging (F1) and Bagging (F1 + F2), POS-RS gets the records 9/1/0 and 10/0/0. Compared with Boosting (F1) and Boosting (F1 + F2), POS-RS gets the records 10/0/0 and 10/0/0. Compared with SVM (F1) and SVM (F1 + F2), POS-RS get the records 10/0/0 and 10/0/0. Compared with NB (F1 + F2), ME (F1 + F2), SNLP, SS, and OF, POS-RS get the records 9/0/1, 10/0/0, 8/1/1, 10/0/0, and 8/1/1. In summary, we can confidently confirm the effectiveness of the new proposed POS-RS for sentiment classification.

Besides, some other interesting phenomena were observed in the experiments. The first interesting thing is that com-pared with SVM (F1), SVM (F1 + F2) gets a record 2/2/6. This result indicates that content lexicons have more discriminative formance of Random Subspace is determined by the diversity and the accuracy of base learners. Compared with content lex-icons (F1), the richer feature space (F1 + F2) can produce base learners with higher diversity, which can compensate the issue &amp; Rajkumar, 2008; Leopold &amp; Kindermann, 2002 ). Thus, only using content lexicons can reduce such influence. 5.2.2. Bias and variance analysis
Subsequently, we will attempt to explain why POS-RS works, using bias and variance decompositions of the classification error. Bias and variance analysis is typically used to guide the design of ensemble learning methods and also provides a tool to analyze learning algorithms. The classification error is the expected loss when classifying a new instance and can be decompose into bias and variance using Kohavi and Wolpert X  X  definition ( Kohavi &amp; Wolpert, 1996 ).

The third term r x relates to irreducible error. We follow Kohavi and Wolpert X  X  practice of aggregating this value with bias due to the difficulty of estimating it from observations of classification performance ( Kohavi &amp; Wolpert, 1996 ).
Tables 6 and 7 show the bias/variance decompositions for compared methods errors, biases, and variances of different datasets are boldfaced. As can be seen from Table 6 , POS-RS can reduce bias and variance simultaneously compared to the base learner, i.e., SVM.
Additionally, except on Camera, Music, and TV datasets, POS-RS all gets the lowest bias of 0.0872 on Camp, 0.0842 on Doctor, 0.1845 on Drug, 0.0997 on Laptop, 0.1006 on Lawyer, 0.0722 on Movie, 0.1655 on Radio. All above results can explain why POS-RS gets the highest average accuracy.
 Furthermore, it is interesting that POS-RS does not get any lowest variance. However, among ten lowest variances,
Bagging (F1) gets five lowest variances. This result is also consistent with prior research ( Breiman, 1998; Webb, 2000 ).
The reason, as Breiman argued, is that Bagging can be viewed as classifying by application of an estimate of the central ten-dency of base learners ( Breiman, 1998 ). 5.2.3. Sensitivity analysis
Random Subspace has an important parameter, i.e., subspace rate, to control the diversity of base learners. In our exper-iments, subspace rate varies from 0.1 to 0.9. Figs. 4 X 6 show the average accuracy curve when using different feature sets.
As shown in Figs. 4 X 6 , Random Subspace gets lower average accuracy when the subspace ratio is lower than 0.3. After that, average accuracy curves reach the peak and they are becoming smooth as the subspace rate increases. These results are consistent with previous research, which also can explain why subspace rate is recommended to be set to 0.5 ( Ho, 1998 ).
Unlike the original Random Subspace method, POS-RS uses two important parameters, i.e. content lexicon subspace rate and function lexicon subspace rate, to control the balance between accuracy and diversity. A sensible question might be: what are the optimal values of content lexicon subspace rate and function lexicon subspace rate? However, there is not a value of content lexicon subspace rate and function lexicon subspace rate that we can consider optimal. Thus, the impact of using different numbers of content lexicon subspace rate and function lexicon subspace rate are studied further. Figs. 7 X 16 display the classification accuracy surface under different content lexicon subspace rate and function lexicon subspace rate.
The X -axis is defined to be the content lexicon subspace rate and the Y -axis is defined to be the function lexicon subspace rate.

As shown in Figs. 7 X 16 , when getting the highest average accuracy, the values of content lexicon subspace rate and func-tion lexicon subspace rate are ( r C = 0.6 and r F = 0.2) on Camera, ( r tor, ( r C = 0.5 and r F = 0.6) on Drug, ( r C = 0.4 and r Movie, ( r C = 0.6 and r F = 0.6) on Music, ( r C = 0.8 and r we can see that for the content lexicon subspace rate, 0.4 X 0.9 is the more suitable value; it is difficult to specify a recom-mended value for function lexicon rate, and it will vary with the different content lexicon subspace rate. The reason is that the content lexicon subspace rate is the dominant factor for classification accuracy. However, this does not mean that the function lexicon subspace rate is not important. Just on the contrary, the function lexicon subspace rate has important influ-ence on the diversity of base learners. This has been proved in the experiment where RS (F1) and RS (F1 + F2) underperform
POS-RS. 6. Conclusions and future directions
The rise of social media has fueled interest in sentiment classification. Promptly and correctly classifying sentiment from the text has become an important task for individuals and companies. Many researchers have investigated sentiment clas-sification problem based on ensemble learning methods, but very few literature focus on the Random Subspace and its variations.

In this research, we proposed a new Random Subspace method, POS-RS, for sentiment analysis based on part-of-speech analysis. Two important parameters, i.e., content lexicon subspace rate and function lexicon subspace rate, are introduced to control the balance between the accuracy and the diversity of base learners. Ten publicly available sentiment analysis data-sets were investigated to verify the effectiveness of the proposed method. Empirical results showed that POS-RS can reduce a viable method for sentiment classification, and possibly other text classification problems.
 There are several future research directions for this study. First, although we proposed a new Random Subspace method,
POS-RS, for sentiment classification based on part-of-speech analysis, and evaluated the effectiveness on ten datasets, more detailed theoretical analysis are needed further. We introduced two parameters, i.e., content lexicon subspace rate and func-understand how these two parameters influence the accuracy of POS-RS. Second, in this research, as SVM is a state-of-the-art proposed POS-RS. Actually, like other ensemble methods, our proposed POS-RS is a framework, which can also employ other methods, i.e., DT, as base learner. Third, in this study, we use ten popular sentiment datasets to evaluate our proposed POS-RS. In the future research, large and more diverse datasets should be collected and examined for further investigation.
Fourth, as ensemble learning methods are typically computationally intensive, parallel computing techniques should be explored to tackle this problem in the future research.
 Acknowledgements 71471054), the National Basic Research Program of China (973 Program) (2013CB329603), the Specialized Research Fund for the Doctoral Program of Higher Education (20110111120014), the China Postdoctoral Science Foundation (2011M501041, 2013T60611), the Special Fund of AnHui Province Key Research Institute of Humanities and Social Sciences at Universities (SK2013B400) and the Special Fund of Political Theory Research Center of HeFei University of Technology (2012HGXJ0392). References
