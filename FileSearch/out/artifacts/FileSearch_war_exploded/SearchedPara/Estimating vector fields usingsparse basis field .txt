 Stefan Haufe 1, 2, * Vadim V. Nikulin 3, 4 Andreas Ziehe 1, 2 Klaus-Robert M  X  uller 1, 2, 4
Charit  X  e University Medicine, Dept. of Neurology, Campus Benjamin Franklin, Berlin, Germany Current machine learning is frequently concerned with the estimation of functions with multivariate output. While in many cases the outputs can be treated as mere collections of scalars (e.g. different color channels in image processing), in some contexts there might be a deeper interpretation of them as spatial vectors with a direction and a magnitude . Such  X  X ruly X  vectorial functions are called vector fields and become manifest for example in optical flow fields, electromagnetic fields and wind fields in meteorology. Vector field estimators have to take into account that the numerical representation of a vector depends on the coordinate system it is measured in. That is, the estimate should be invariant with respect to a rotation of the coordinate system.
 Let v : R P 7 X  R Q be a vector field. Mathematically speaking, we are seeking to approximate v by a field  X  v using empirical measurements. Here we consider two types of measurements. The first type are direct samples ( x n , y n ) , x n  X  R P , y n  X  R Q ,n = 1 ,...,N of v leading to a regression problem . The second case occurs, if only indirect measurements z m  X  R ,m = 1 ,...,M are available, which we assume to be generated by a known linear 1 transformation of the vector field outputs y n belonging to nodes x n ,n = 1 ,...,N . This kind of estimation problem is known as an inverse problem . Let z = ( z 1 ,...,z M ) T denote the vector of indirect measurements, Y = ( y 1 ,..., y the stacked transposed rows of Y . The linear relationship between Y and z can be written as z = F vec ( Y ) using the forward model F  X  R M  X  NQ . As an example of an inverse problem consider the way humans localize acoustic sources. Here z comprises the signal arriving at the ears, v is the spatial distribution of the sound sources and F is given by physical equations of sound propagation. Using information from two ears, humans do already very well in estimating the direction of incoming sounds. By further incorporating prior knowledge, e.g. on the loudness of the sources, v can usually be well approximated. The use of prior knowledge (a.k.a. regularization ) is indeed the most effective strategy for solving inverse problems [13], which are inherently ambiguous. Hence, the same mechanisms used to avoid overfitting in, e.g., regression may be applied to cope with the ambiguity of inverse problems.
 For the estimation of scalar functions, methods that utilize sparse linear combinations of basis func-tions have gained considerable attention recently (e.g. the  X  X asso X  [14]). Apart from the computa-tional tractability that comes with the sparsity of the learned model, the possibility of interpreting the estimates in terms of their basis functions is a particularly appealing feature of these methods. While sparse expansions are also desirable in vector field estimation, lasso and similar methods cannot be used for that purpose, as they break rotational invariance in the output space R Q . This is easily seen as sparse methods tend to select different basis functions in each of the Q dimensions. Only few attempts have been made on rotation-invariant sparse vector field expansions so far. In [8] a dense expansion is discussed, which could be modified to a sparse version maintaining rotational invariance. Unfortunately, this method is restricted to approximating curl-free fields. In contrast, we here propose a method that can be used to decompose any vector field. We will derive the general framework in section 2. In section 3 we will apply the (appropriately customized) method for solving the EEG/MEG inverse problem. Finally, we will draw a brief conclusion in section 4. Our model is based on the assumption that v can be well approximated by a linear combination of some basis fields . A basis field is defined here (unlike in [8]) as a vector field, in which all output vectors point in the same direction, while the magnitudes are proportional to a scalar (basis) function b : R P 7 X  R . As demonstrated in Fig. 1, this model has an expressive power which is comparable to a basis function expansion of scalar functions. Given a set ( dictionary ) of basis functions b l ( x ) ,l = 1 ,...,L , the basis field expansion is written as with coefficients c l  X  R Q ,l = 1 ,...,L to be estimated. Note that by including one coefficient for each output dimension, both orientations and proportionality factors are learned in this model (the term  X  X asis field X  thus refers to a basis function with learned coefficients). In order to select a small set of fields, most of the coefficient vectors c l have to vanish. This can be accomplished by solving a least-squares problem with an additional lasso-like ` 1 -norm penalty on the coefficients. However, care has to be taken in order to maintain rotational invariance of the solution. We here propose to use a regularizer that imposes sparsity and is invariant with respect to rotations, namely the ` 1 -norm of the magnitudes of the coefficient vectors. Let C = ( c 1 ,..., c L ) T  X  R L  X  Q contain the coefficients and the basis functions evaluated at the x n . The parameters are estimated using case and L ( C ) = k z  X  F vec ( BC ) k 2 2 in the inverse reconstruction case, and  X  is a positive constant. achieving sparsity of grouped predictors [18]. Besides vector field estimation, this concept has natural applications in, e.g, multiple kernel learning [1] and channel selection for brain computer interfacing [15]. It has also recently been considered in the general multiple output setting [17]. 2.1 Rotational Invariance Rotational invariance, in the sense that the estimates after rotation of the coordinates axes are equal to the rotated estimates, is a desirable property of an estimator. One has to distinguish invariance in input-from invariance in output space. The former requirement may arise in many estimation settings and can be fulfilled by the choice of appropriate basis functions b l ( x ) . The latter one is specific to vector field estimation and has to be assured by formulating a rotationally invariant cost function. Our proposed estimator Eq. 3 is rotationally invariant. This is due to the use of the ` 2 -norm in output space R Q , which does not change under rotation. I.e. for an orthogonal matrix For the same argument, additional regularizers R  X  ( C ) = k vec ( D  X  C ) k 2 2 (the well-known Tikhonov regularizer) or R + ( C ) = k D + C k 1 , 2 (promoting sparsity of the linearly transformed vectors) may be introduced without breaking the rotational invariance in R Q . 2.2 Optimization Eq. 3 is a convex problem, composed of the quadratic term L ( C ) and the convex nondifferentiable term R ( C ) . It is equivalent to the following program in which a linear function of the variables is minimized subject to quadratic and second-order cone constraints [6]. The latter constraints are obtained by introducing auxiliary variables u l  X  R ,l = 1 ,...,L encoding upper bounds of the magnitudes of the coefficient vectors. Problem Eq. 5 is an instance of second-order cone programming (SOCP), a standard class of convex programs, for which efficient interior-point based solvers are available. The problem stays inside the SOCP class even if the original formulation is modified in any of the following ways: Vector fields occur, for example, in form of electrical currents in the brain, which are produced by postsynaptic neuronal processes. Knowledge of the electrical fields during a certain experimental condition allows one to draw conclusions about the locations in which the cognitive processing takes place and is thus of high value for research and medical diagnosis. Invasive measurements allow very local assessment of neuronal activations, but such procedure in humans is only possible when electrodes are implanted for treatment/diagnosis of neurological diseases, e.g., epilepsy. In the majority of cases recordings of cortical activity are performed with non-invasive measures such as electro-and magnetoencephalography, EEG and MEG respectively. The reconstruction of the current density from such measurements is an inverse problem. 3.1 Method specification In the following the task is to infer the generating cerebral current density given an EEG measure-ment z  X  R M . The current density is a vector field v : R 3 7 X  R 3 assigning a vectorial current source to each location in the brain. We obtained a realistic head model from high-resolution MRI (mag-netic resonance imaging) slices of a human head [4]. Inside the brain, we arranged 2142 nodes in a regular grid of 1 cm distance. The forward mapping F  X  R M  X  2142  X  3 from these nodes to the elec-trodes was constructed according to [9]  X  taking into account the realistic geometry and conductive properties of brain, skull and skin.
 Dictionary In most applications the  X  X rue X  sources are expected to be small in number and spatial extent. How-ever, many commonly used methods estimate sources that almost cover the whole brain (e.g. [11]). Another group of methods delivers source estimates that are spatially sparse, but usually not ro-tationally invariant (e.g. [7]). Here often too many sources, which are scattered around the true sources, are estimated. Both the very smooth and the very sparse estimates are unrealistic from a physiological point of view. Only very recently, approaches capable of achieving a compromise be-tween these two extremes have been outlined [16, 3]. For achieving a similar effect we here propose a sparse basis field expansion using radial basis functions. More specifically we consider spherical Gaussians s = 1 ,..., 4 , having spatial standard deviations  X  1 = 0 . 5 cm , X  2 = 1 cm , X  3 = 1 . 5 cm , X  4 = 2 cm and being centered at nodes x n ,n = 1 ,...,N (see Fig. 2 for examples). Using this redundant dictionary our expectation is that sources of different spatial extent can be reconstructed by selecting the appropriate basis functions. Unlike the approaches taken in [16, 3] this approach does not require an additional hyperparameter for controlling the tradeoff between sparsity and smoothness. Normalization Our ` 1 , 2 -norm based regularization is a heuristic for selecting the smallest possible number of basis fields necessary to explain the measurement. Using this approach, however, not only the number important to normalize the basis functions in order not to a-priori prefer some of them. Let B s be the N  X  N matrix containing the basis functions with standard deviation  X  s . The large matrix By this means, no length scale is artificially prefered. An estimation bias is also introduced by the location of the sources. Due to volume conduction, the signal captured at the sensors is much stronger for superficial sources compared to deep sources. estimated sources, where  X  F = HF and H = I  X  11 T / 1 T 1  X  R M  X  M . We found that  X  S can be used for removing the location bias. This can be done by either penalizing activity at locations with high variance or by penalizing basis functions with high variance in the center. We here employ the former approach, as the latter may be problematic for basis functions with large extent. Using this approach, evaluation of  X  v ( x ) requires knowledge of the forward model for x . Therefore, we restrict ourselves here to nodes x n ,n = 1 ,...,N . Let W n  X  R 3  X  3 denote the inverse matrix square root of the part of  X  S belonging to node x n . Defining the coefficients are estimated using  X  C = arg min estimated current density at node x n is  X  v ( x n ) = W n P L l =1  X  c l b l ( x n ) . 3.2 Experiments Validation of methods for inverse reconstruction is generally difficult due to the lack of a  X  X round truth X . The measurements z cannot be used in this respect, as the main goal is not to predict the EEG/MEG measurements, but the vector field v ( x ) as accurately as possible. Therefore, the only way to evaluate inverse methods is to assess their ability to reconstruct known functions. We do this by reconstructing a) simulated current sources and b) sources of real EEG data that are already well-localized by other studies. For each EEG measurement, simulated or not, we conduct a 5  X  5 crossvalidation, i.e. we perform 25 inverse reconstructions based on different training sets contain-ing 80 % of the electrodes. In each crossvalidation run, we evaluate two criteria. Most important where  X  Y tr are the vector field outputs at nodes x n ,n = 1 ,...,N estimated using only the training set. This criterion can only be evaluated for the simulated data. For real and simulated data we also evaluate the generalization error , i.e. the error in the prediction of the remaining 20% (the test set ) the parts of z and F belonging to the test set.
 We compared the sparse basis field expansion (S-FLEX) approach using Gaussian basis functions (see section 3.1) to the commonly used approaches of LORETA [11] and Minimum Current Estimate (MCE) [7], and the recently proposed Focal Vectorfield Reconstruction (FVR) technique [3]. All three competitors correspond to using unit impulses as basis functions while employing different regularizers. The LORETA solution, e.g., is a Tikhonov regularized least-squares estimate while MCE is equivalent to applying lasso to each dimension separately, yielding current vectors that are biased towards being axes-parallel. We here used a variant of MCE, in which the original depth compensation approach was replaced by the approach outlined in section 3.1. Interestingly, FVR can be interpreted as a special case of S-FLEX employing the rotation-invariant regularizer R + ( C ) to enforce both sparsity and smoothness. The tradeoff parameter  X  of this method was chosen as suggested in [3]. All methods were formulated such that the fitness of the solution was ensured by the constraint k z  X  F vec (  X  Y tr ) k 2 2 &lt;  X  . The optimization was carried out using freely available packages for convex programming [12, 2].
 Simulated data We simulated current densities in the following way. First, we sampled outputs y n ,n = 1 ,...,N from a multivariate standard normal distribution. The function ( x n , y n ) was then spatially smoothed using a Gaussian lowpass filter with standard deviation 2.5 cm. Finally, each y n was shortened by the 90th percentile of the magnitudes of all y n  X  leaving only 10% of the current vectors active. Current densities obtained by this procedure usually feature 2-3 active patches (sources) with small to medium extent and smoothly varying magnitude and orientation (see Fig. 3 for an example). This behaviour was considered consistent with the general believe on the sources. We simulated five densities and computed respective pseudo-measurements for 118 channels using the forward model F . As no noise was injected in the system,  X  was set to zero in the following reconstruction. Real data We recorded 113-channel EEG of one healthy subject (male, 26 years) during electrical median nerve stimulation. The EEG electrodes were positioned according to the international 10-20 sys-tem. The exact positions were obtained using a 3D digitizer and mapped onto the surface of the head model. EEG data were recorded with sampling frequency of 2500 Hz and digitally bandpass-filtered between 15 Hz and 450 Hz. Left and right median nerves were stimulated in separate blocks by applying constant square 0.2 ms current pulses to the respective thenars. Current pulses had intensities above motor threshold (approx. 9 mA), inducing unintended twitches of the thumbs. The interstimulus interval varied randomly between 500 ms and 700 ms. About 1100 trials were recorded for each hand. Artifactual trials as well as artifactual electrodes were excluded from the analysis. For the remaining data, baseline correction was done based on the mean amplitude in the prestimulus interval (-100 ms to -10 ms). Finally, a single measurement vector was constructed by averaging the EEG amplitudes at 21 ms across 1946 trials (50% left hand, 50% right hand). By this means the EEG response to somatosensory input at the hands was captured with high signal-to-noise ratio (SNR). Based on that the brain areas representing left and right hand were to be reconstructed with  X  set according to the estimated SNR. 3.3 Results Fig. 3 shows a simulated current density along with reconstructions according to LORETA, MCE, FVR and S-FLEX. From the figure it becomes apparent, that LORETA and MCE do not approximate the true current density very well. While the LORETA solution is rather blurry, merging the two true sources, the MCE solution exhibits many spikes, which could easily be misinterpreted as different amplitudes are plotted. The estimates of FVR and S-FLEX approximately recover the shape of the sources. S-FLEX comes closest to the true shape, as its estimates are less focal than the ones of FVR. However, S-FLEX still slightly underestimate the extent of the sources.
 The localization results of left and right N20 generators are shown in Fig. 4. The solutions of FVR and S-FLEX are almost indistinguishable. Both show activity concentrated in two major patches, one in each contralateral somatosensory cortex. This is in good agreement with the localization of the hand areas reported in the literature (e.g. [5]). LORETA estimates only one large active region over the whole central area, with the maximum lying exactly in between the hand areas. The MCE solution consists of eight spikes scattered across the whole somatosensory area.
 Tab. 1 shows that S-FLEX generalizes better than its competitors, although insignificantly. More importantly S-FLEX outperforms its peers in terms of reconstruction accuracy. The distance to the runner-up FVR is, however, larger than expected from Fig. 3. This is due to the fact that the parameter of FVR controlling the tradeoff between sparsity and smoothness was fixed here to a value promoting  X  X aximally sparse sources which are still smooth X . While this might be a good assumption in practise, it was not rewarded in our validation setting. We here explicitly required reconstruction rather than shrinkage of the sources.
 Table 1: Ability of LORETA, FVR, S-FLEX and MCE to reconstruct simulated currents ( C y SIM) and generalization performance with respect to the EEG measurements ( C z SIM/REAL). Winning entries (reaching significance) are shown in bold face. SIM LORETA FVR S-FLEX MCE Figure 3: Simulated current density (SIM) and reconstruction according to LORETA, FVR, S-FLEX and MCE. Color encodes current magnitude.
 LORETA FVR S-FLEX MCE Figure 4: Localization of somatosensory evoked N20 generators according to LORETA, FVR, S-FLEX and MCE. Color encodes current magnitude. This paper contributes a novel and general methodology for obtaining sparse decompositions of vector fields. An important ingredient of our framework is the insight that the vector field estimate constraint together with sparsity leads to a second-order cone programming formulation. We have focussed here on solving the EEG/MEG inverse problem, where our proposed S-FLEX approach outperformed the state-of-the-art in approximating the true shape of the current sources. However, other fields might as well benefit from the use of S-FLEX: in meteorology for example, an improved decomposition of wind fields into their driving components might provide novel insights that could be useful for better weather forecasting.
 Acknowledgments This work was supported in part by the German BMBF grants BCCNB-A4 (FKZ 01GQ0415), BFNTB-A1 (FKZ 01GQ0850) and FaSor (FKZ 16SV2234). We thank Friederike Hohlefeld and Monika Weber for help in preparing the experiment, and Ryota Tomioka for fruitful discussions.
