 In real applications, a given user buys or rates an item based on his / her interests. Learning to leverage this interest information is often critical for recommender systems. However, in existing rec-ommender systems, the information about latent user interests are largely under-explored. To that end, in this paper, we propose an interest expansion strategy via personalized ranking based on the topic model, named iExpand, for building an interest-oriented col-laborative filtering framework. The iExpand method introduces a three-layer, user-interest-item, representation scheme, which leads to more interpretable recommendation results and helps the under-standing of the interactions among users, items, and user interests. Moreover, iExpand strategically deals with many issues, such as the overs pecialization and the cold-start problems. Finally, we evalu-ate iExpand on benchmark data sets, and experimental results show that iExpand outperforms state-of-the-art methods.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Algorithms, Experimentation Collaborative filtering, interests expansion, personalized ranking
Collaborative filtering techniques have broad applications and have been widely studied, since these techniques only require the information about user interactions. However, existing collabo-rative filtering methods often directly exploit the information of users X  interaction with the systems. In other words, they make recommendations by learning a "user-item" dualistic relationship. Therefore, existing methods neglect an important fact that there are many latent user interests which can influence users X  behaviors. To that end, in this paper, we propose a three-layer, user-interests-item, representation scheme. Specifically, we interpret an interest as a re-quirement from the user to items, while for the corresponding item, the interest can be considered as one of its characteristics. Indeed, it is necessary to leverage this three-layer representation, since this representation leads to more interpretable recommendation results and helps the understanding of the interactions among users, items and user interests.

Furthermore, when leveraging the information of user interests, we must be aware that users X  interests can change from time to time. Nevertheless, traditional collaborative filtering systems cannot cap-ture these changes, and thus are prone to the "overspecialization" problem. The key challenge is how to model latent user interests and their potential changes in collaborative filtering systems.
To address the above challenges, we propose an interest-oriented collaborative filtering system, named iExpand. Specifically, each user interest is first captured by a latent factor. Then, we extract users X  latent interests and learn the transition probabilities between di ff erent interests. Moreover, we model the possible expansion pro-cess of users X  interests by personalized ranking. In other words, we exploit a personalized ranking strategy to predict the next possi-ble interest for each user. There are three key advantages of iEx-pand. First, iExpand models the implicit relations between users and items through a set of latent interests, this representation leads to more interpretable recommendation results. Second, iExpand can save the computational cost and help to alleviate the sparseness problem by reducing the number of item dimensions. Third, iEx-pand enables diverse recommendations by the interests expansion. This can help to avoid the overspecialization problem.

Finally, iExpand makes recommendations by directly ranking the candidate items. Therefore, in the experiments, we report the ranking prediction accuracy. As collaborative filtering is often for-mulated as a regression or rating prediction problem, we also report the comparison results. In this section, we first introduce the framework of the iExpand. Then, we describe each step in detail. In addition, we address the parameters selection and computational complexity issues.
The iExpand model assumes that a user X  X  rating behavior de-pends on an underlying set of hidden interests. Inspired by the topic models, in iExpand, each user is represented as a probability distribution over interests, and each interest is a probability distri-bution over items. What X  X  more, the model assumes that the order of items in a user X  X  rating list can be neglected. In correspond to LDA, the users, items and latent interests are documents, words and topics respectively [2]. Figure 1 illustrates the framework of the iExpand model. Each step of the model is introduced in the fol-Figure 1: The Framework of the iExpand Model. Gray ar-rows shows the general process of the model, while blue arrows shows the procedure of online recommendations. lowing subsections. Table 1 lists all mathematical notations used in the paper.

In this subsection, we show how to extract the information about user latent interests from the LDA model. The information about latent interests includes the probability distribution of each user over each interest (i.e.,user U i  X  X  distribution over interest T the probability distribution of each interest over each item (i.e., the distribution of interest T j over item I i is  X  i j ), and the distribution of each interest ( ~  X  i ). In this paper, we choose the Gibbs sampling technique [6], which provides an e ffi cient method for extracting a set of interests from a large ratings data set.

It is worth distinguishing between our user interests and the la-tent topics in topic models. In iExpand, each user has a distribution on the spectrum of interests, whereas in PLSA / LDA a topic is a latent variable and the distributions are specified by the topic,i.e., they are class (topic)-conditional distributions. Thus the model rep-resentation of iExpand and PLSA / LDA are significantly di ff erent.
In this subsection, we describe how to compute the transition probabilities between latent interests. In order to construct the cor-relation graph of latent interests, we use the items as intermediary entities.  X  is created to estimate each item X  X  probability distribution over interests and  X  i j can be estimated by Equation (1):
In iExpand, we model the correlations between interests in the form of probabilities. At first, we use a bipartite graph G = &lt; X , E &gt; to represent the relationships between items and interests, with the vertice set X = I  X  T . In G , the weight of the edge from interest T to item I i is  X  i j , and the weight of the edge from I Then, by projecting G , we get the relationships between interests represented by  X  . Also,  X  i j indicates the recommending strength of interest T i for T j and it can be computed by Equation (2):
At last, the bipartite graph is transformed into a correlation graph which describes the interest relations, and  X  is the correlation ma-trix. In terms of correlation matrix,  X  i j means the coe ffi cient of correlation between T i and T j from T 0 i s view. In terms of random walk,  X  i j is the probability that current state jumps from T
In this subsection, we describe the solution for user interests ex-pansion, to which we use PageRank personalized ranking strategy on the user interests correlation graph. Given a users X  interest vec-tor, we do repeat PageRank iterations until convergence. The final converged vector contains the expanded user interests. One can also view this as predicting the next possible interest for each user. Thus, we can make diverse recommendations in a systematic way. The algorithmic approach here is the personalized ranking [7]. First, we represent U i  X  X  current interest model through vector ~  X  in which the j -th entry ~  X  i (0) ( j ) corresponds to latent interest T initialized as  X  i j , and ~  X  i (0) is the probability distribution when ran-dom walk starts. In the next, let ~  X  i (0) perform Random Walk with Restart (RWR) [5] on the correlation graph. Let us consider a ran-dom walk that starts from ~  X  i (0) , when arriving at T chooses T j  X  X  neighbors and keeps walking. In addition to making such decisions, the random walker goes back to the starting point with a certain probability c . For all the users, their one-step updates from step s to step ( s + 1) can be formalized as Equation (3):
In  X  ( s ) ,  X  ( s ) i j means the steady-state probability that a random walk starting from U i and stops at T j after s steps, meanwhile it implies the a ffi nity of T j with respect to U i . The personalized ranking is run for all users simultaneously, and it only takes several steps before (1  X  c ) represents how much relationship is lost in each step.
In this subsection, we describe the ranking of the items and the generation of recommendation lists. In iExpand, the items are ranked by their relevance with any given user. The user X  X  possible distri-bution on latent interests, serves as intermediary entities:
It is easy to obtain the top-K recommendations by ranking the candidate items. Thus, iExpand directly generates recommenda-tions without the step of predicting rating scores. iExpand can also be used as a rating prediction method. Here, Pearson Correlation can be used to compute user similarities. Then, the rating from user U i to item I j can be predicted by Equation (5):
What we discussed above is about how to make recommenda-tions in a general iExpand process. However, in real-world appli-cations, we face the challenge of online recommendations. Since users X  interest distributions may change quickly and the correlation of interests evolves slowly, we can update both the inference pro-cess and the correlation graph periodically o ffl ine, while renew the user X  X  interests whenever he / she rates.
In this subsection, we show the value selections for parameters: the hyperparameters  X  and  X  , and interest number K . At first, we select values for  X  and  X  . There are many ways for learning them, among which Minka X  X  fixed-point iteration is widely used [10]. In iExpand, each step of iteration is formalized as Equation (6):
Next, we choose the right value for the interest number K . Until now, one possible approach for setting this value is to compute the likelihood of the test data under di ff erent K , then the best one is chose by a grid search. In this paper, we refer to an approach named Chib-style estimation [9]. As the posterior probability depends on both  X  ,  X  and K , we combine these factors together and propose a parameter learning algorithm, as shown in Algorithm 1.

Algorithm 1 : Estimating Parameters ( a , b ) input : a , the initial value of  X  ; b , the initial value of  X  ; output : the best values for  X  ,  X  and K for all candidate K do
Return the best values for  X  ,  X  and K
In this subsection, we analyze the computational complexity is-sues for iExpand. Specifically, the time cost for the inference of LDA is O ( M  X  N  X  K  X  l ) , where l is the iteration number of Gibbs the total computational complexity for general iExpand process is cess and the correlation graph can be updated periodically o ffl ine, thus for online computing, we just need to run Gibbs sampling and personalized ranking or rating prediction for current user, both of which can be done e ffi ciently.
In this section, we present the experimental results, and we demon-strate: (1) a performance comparison between iExpand and many other methods, (2) the understanding of interests and the expansion.
Data Sets. All the experiments were performed on two real-world data sets: MovieLens and Book-Crossing. The former one [1] contains 100 , 000 ratings from 943 users for 1 , 682 movies. In the latter one [12], we choose the most rated 996 users and their 91 , 084 ratings on 1 , 696 books. The split named as x -(100-x ) means x per-cent ratings serve for training and the remaining ratings for test.
Benchmark Methods. For the ranking purpose, we compare iExpand with ItemRank [5], L u [3], as well as LDA and SVD. For the rating purpose, we implemented the user based collaborative filtering (UCF) [8], RSVD [4], LDA and ItemRank [5].

Evaluation Metrics. We adopted Degree of Agreement (DOA) and Hit Ratio (HR) to evaluate the ranking accuracies. DOA mea-sures the percentage of item pairs ranked in the correct order [5]. HR measures the ratio of the number of hits [11]. For the evalu-ation of the rating e ff ectiveness, we choose the widely used Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).

Parameters selection. Before the performance comparison, we investigate the learning of two parameters: hyperparameters and the interest number. Here, the first 893 users in MovieLens are used as training data and the rest users for test, while For Book-Crossing the first 900 users are treated as training samples. Finally, the results of parameters selection are summarized in Table 2.
In iExpand, there are two other parameters for personalized rank-ing: the restart probability c and the step s .In experiments, we let c lie in the range of [0 , 1), and iExpand achieves best performance by just a few steps of random walk (less than 10 steps).

Performance Comparison. The performances of their recom-mendations are illustrated in Table 3. In terms of ranking, iExpand outperforms the other algorithms with a significant margin in each split. Another observation is that when the training set becomes larger and denser, the improvement made by iExpand compared to LDA becomes less obvious. The reason is that, when there are enough interactions between a user and the system, the user X  X  pref-erence has been decided and there will be no much di ff erence from his current interest distribution to the next possible interest distri-bution. In terms of rating, iExpand performs best in the sparsest splits, while in general RSVD outperforms the other methods. On the sparse splits, the methods that can discover the indirect correla-tions (i.e., iExpand and ItemRank) get better results. While on the remaining splits, the rating oriented methods (i.e., RSVD and UCF) generally perform better. Another observation is that, the two types of evaluation metrics DOA / HR and MAE / RMSE lead to inconsis-tent judgements which have been discussed in previous works.
The Understanding of Interests and Interests Expansion. In the previous, we do not distinguish latent interests and explicit in-terests. The former is a latent factor extracted by topic model, while the latter is the one identified in the real world, and we use la-tent interests to simulate explicit interests. The researches on topic models have shown their one-to-one correspondence. The ques-tion is whether every latent interest has a real meaning for use in iExpand? To this end, we consider the first three latent interests ex-tracted from the MovieLens data set. Table 4 lists the top-5 movies for each latent interest identified. As can be seen, all five movies in the first latent interest have the same genres which can be tagged as Action , Adventure , and Fantasy or they can be labeled "Harrison Ford"(and contain one mistake). While movie in the second column all fall into Comedy and Drama . However, there are several types of movie genres for the third one. After a closer look, we find that all of these movies are generally recognized as classic movies and they all have won more than one Oscar award. Another observa-tion is that movie S tar wars is given high probability in both latent interests 1 and 3. This verifies that topic models can capture the multiple aspects of each movie, and each aspect can be resolved by other movies in the corresponding latent interest. The above anal-ysis means that, even for collaborative filtering, every latent factor extracted by topic models still has a real meaning, although the in-terpretation of each factor may not be as easy and precise as that in text applications based on topic models.

In the experiments, we can see that iExpand with interest ex-pansion can lead to a better performance than the LDA which only exploiting the current user interests. The reason is that interest ex-pansion can predict the next possible interest for each user in a properly controlled manner, and make diverse recommendations. Thus, this helps to avoid the overspecialization problem. In other words, the interest expansion is more appropriate to capture the di-versified interests and find potential interests for the users. While the problem of how these interests expands from one to another needs more detailed analysis and this is beyond the discussion of this paper. Meanwhile, we would like to point out that this advan-tage is meaningful to most of the users which can be seen from the results of the performance comparisons shown in Table 3, while this does not mean it will work for every single user, and there may exist users whose interest expansion is di ff erent from the majority.
In this paper, we exploited latent interests for developing an interest-oriented collaborative framework, named iExpand. Specifically, in iExpand, a topic model based method is first used to capture each user X  X  interests. Then, a personalized ranking strategy is developed for predicting user X  X  possible interests expansion. Moreover, a di-verse recommendation list is generated by using user latent inter-ests as an intermediate layer between the user layer and the item layer. Finally, an empirical study has been conducted on two bench-mark data sets, and the results demonstrate that iExpand can lead to better ranking performances than state-of-the-art methods. Acknowledgment. This work was supported by grants from Natural Science Foundation of China ( No . 60775037), the Key Pro-gram of Natural Science Foundation of China ( No . 60933013), the National High Technology Research and Development Program of China ( No . 2009 AA 01 Z 12), and the Research Fund for the Doctoral Program of Higher Education of China (20093402110017).
