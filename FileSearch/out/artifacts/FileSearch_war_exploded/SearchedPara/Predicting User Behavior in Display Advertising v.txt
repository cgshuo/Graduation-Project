 Conversion prediction and click prediction are two impor-tant and intertwined problems in display advertising, but existing approaches usually look at them in isolation. In this paper, we aim to predict the conversion response of users by jointly examining the past purchase behavior and the click response behavior. Additionally, we model the tem-poral dynamics between the click response and purchase ac-tivity into a unified framework. In particular, a novel ma-trix factorization approach named dynamic collective matrix factorization (DCMF) is proposed to address this problem. Ourmodelconsiderstemporaldynamicsofpost-clickcon-versions and also takes advantages of the side information of users, advertisements, and items. Experiments on a real-world marketing dataset show that our model achieves sig-nificant improvements over several baselines.
 H.3.3 [ Information Search and Retrieval ]: Information filtering Conversion prediction; matrix factorization; temporal dy-namic
With the proliferation of the Internet and online shopping websites, digital marketing has become an effective way to reach out to consumers. Typically consumers can be influ-enced via targeted advertisements (ads) on the web to make purchases. Display advertising is a popularly used medium for targeting users and allows advertisers to place graphi-cal ads on the publishers X  web pages. Most of the ads aim to create an impulse leading to a sale. Traditionally, the  X  This work was completed during Sheng Li X  X  internship at Adobe Research.
 c click-through rate (CTR) has been used as a central mea-sure for evaluating the performance of a direct response ad campaign. An alternate strategy that has gained attention in the recent past is to maximize the conversion rate (CVR) instead of just ad-clicks, as many advertisers would prefer not to pay for an ad impression unless it leads to a conver-sion. The conversion could either imply revenue generated via buying a product or could mean account creation. In both strategies it is critical to understand the user behavior and predict the response so as to have better targeting of the ads and as a result higher conversions.

So far, the problem of click prediction and conversion pre-diction has mainly been studied in isolation. Researchers have successfully applied novel strategies for click prediction and there has been significant work in the area [1]. Recently the problem of conversion prediction has been studied by [2] to analyze the ad campaigns. However, the objectives of the two problems are often intertwined together and there is a need to study the two problems in conjunction with each other. With the notable exception of [3], there is not much work analyzing the two objectives together to understand the user purchase behavior better. Jointly studying the two problems can help us understand the pathway leading to conversion and can provide answers to several questions. For example, What ads should be shown to a particular user so that he generates revenue? and Will a given user generate revenue?
In this paper, we propose a novel approach called as dy-namic collective matrix factorization (DCMF) to jointly ex-amine the user click behavior and the purchase activity. The DCMF model is a substantial extension of the collective ma-trix factorization model used to jointly factorize multiple matrices [4]. Apart from considering the two matrices of click and purchase behavior together as in a CMF model, our model also takes into account the temporal influence of an ad impression/click on conversion. We model the time dependency into the matrix factorization framework to ac-count for the decay in the influence of an ad. An efficient optimization algorithm is devised to solve the problem. Our approach is well suited for an interactive setting where the user preferences and behavior change over time.

Our key contributions can be summarized as follows:
Response Prediction. Response prediction in digital marketing has been widely studied in recent years. Most of the prior work focuses on predicting the click-through-rate (CTR) of online ads or other contents [1]. The ultimate goal of display advertising is conversion. However, there are only a few works that investigate the conversion prediction prob-lem [2]. For example, Lee et al. estimated the conversion rate by using the past performance observations along with user, publisher and advertiser data hierarchies [2]. Unlike the existing conversion prediction methods, our approach takes advantage of the click response and side information via the collective matrix factorization technique. The most relevant method in the literature is the hierarchical multi-task learning algorithm presented in [3]. It jointly models the conversion, click and unattributed-conversion problems. There are significant differences between [3] and our work. First, we make use of the explicit temporal relationship be-tween click and purchase events, which is ignored in [3]. Second, unlike the multi-task learning model used in [3], we develop a matrix factorization approach.

Temporal Prediction Models. The prediction model considering temporal dynamics was first developed for col-laborative filtering in [5]. The idea of using temporal dy-namics has been explored in online advertising. Barajas et al. proposed a time series approach for evaluating the effec-tiveness of display advertising [6]. Most recently, Oentaryo et al. designed a hierarchical importance-aware factoriza-tion machine (HIFM) for click response prediction in mobile advertising [7]. It is able to handle the temporal ad re-sponse data. Unlike HIFM, our approach aims to tackle the conversion prediction problem, and to model the temporal relationships between click and purchase events.
We deal with the conversion prediction problem using the collaborative filtering (CF) technique. The fundamental in-tuition behind CF is that the  X  X imilar X  users will have  X  X im-ilar X  preferences. There has been work on applying the CF technique to conversion prediction [8], but it models the in-teractions between pages and ads. In our paper, we directly model the relationships between users and ads/items, which enables us to predict the user behaviors. The intuition is that  X  X imilar X  users are very likely to click  X  X imilar X  ads and purchase  X  X imilar X  items. Figure 1 shows our framework.
First , we want to jointly analyze the relational data, i.e., the click response and purchase activities of users. Inspired by the collective matrix factorization (CMF) [4], we factor-ize the click response matrix (User  X  Ads) and the purchase activity matrix (User  X  Item) simultaneously.

Secondly , we aim to model the temporal information, which is critical in attributing the conversions to the ad clicks. A key observation is that, the behavior of users may change over time . For example, if a user has already purchased an item in the previous week, it is unlikely that he/she will purchase the same item again in the next week. Therefore, we incorporate temporal information into CMF.
Thirdly , we need to ensure that the latent features of users do not dramatically change in a short period of time, as in reality the user preferences would evolve smoothly. To address this concern, we leverage the latent features of the users learned in time t  X  1.
 Given T pre-defined time slices t  X  X  1 , 2 ,  X  X  X  ,T } ,weuse sponses and purchase activities from N u users to N a ads (or N p items) in the time slice t , respectively. By exploiting the temporal relationships between click response and purchase events, we notice that the purchase events in time t +1are mainly related to the click events in time t and hence our model needs to account for that. The objective function is: arg min where W Ct and W Dt are boolean matrices that indicate the training samples in C t and D t ,respectively. U t , V t and are latent factors; M is a transition matrix; denotes the entry-wise product;  X  ,  X  1 and  X  2 are trade-off parameters.
The first two terms in (1) denote the approximation errors, and the last four terms are regularizations used to prevent overfitting. In (1), the smooth transition of user latent factors are modeled based on the assumption: where U t  X  1 is the latent features of users learned from the previous time slice t  X  1. We assume that the latent features in time t are closely related to the feature in time t  X  1, which is reasonable in real applications. M is a transition matrix of users X  behavior, which tries to capture the mappings between users X  behavior in two successive time slices. The intuition is that users X  intention on purchasing items should be smoothly transited over time.
So far, we have seen that the model in (1) is not aware of side information, i.e., the features of users, ads, and items. We can further exploit the additional information to im-prove the prediction performance. The side information are also particularly useful as the data in conversion and click prediction problems are generally sparse. For example, we do not have any click responses or conversion responses of some new users, which lead to the cold-start problem. In this case, the latent features of new users estimated by (1) are not reliable anymore. However, side information provide useful cues from another perspective, and make it possible to learn robust latent features in the cold-start scenario. In this section, we incorporate the side information into (1), and present the DCMF method.

Let X , Y and Z denote the feature matrices for users, ads and items, respectively. We assume that the click response and purchase activity are generated by the inner product of latent factors, and the side information via linear regression. Thus, the matrix approximation can be written as: where  X  U t ,  X  V t and  X  P t are regression coefficients on user fea-tures, ad features and item features, respectively. We treat the three terms used to approximate C t (or D t ) equally for simplicity. The performance can be enhanced by assigning different weights for them.

By replacing the matrix approximations in (1) with (3), we can then rewrite the objective function as: arg min
With the learned latent factors, we can predict the con-version score of user m for item n at time t +1as: where u t m and  X  u t m are the m -th row of U t and  X  U t  X  n are the n -th row of P t and  X  P t , respectively.
As the stochastic gradient descent (SGD) algorithm is ef-ficient in practice, we utilize SGD to solve (4).
First, we fix M , and update other variables, U t = { u t ,  X  V t = {  X  v t 1 ,  X  X  X  ,  X  v t r } ,and  X  P t = {  X  p t 1 we use f to denote the objective in (4). After selecting a pair of random training points C t ij and D t ik , we only need to  X  where  X  is the learning rate. The detailed gradients for each variable are omitted here due to the space limit.
Next, we fix all the other variables, and update M .By ignoring all the irrelevant terms with respect to M , the ob-jective (4) reduces to: Wecanthenupdate M using:
The above process is repeated until convergence.
In this section, we evaluate the performance of our ap-proach and baselines on a marketing dataset.
To evaluate the performance on conversion prediction, we examine a subset of the marketing data from Oct. 1, 2013  X  Nov. 30, 2013. The dataset constitutes of behavioral char-acteristics of 448,158 number of users and 737 ads. Along with the impression records, we also have click and purchase activity information for all the users. We empirically choose one week as the time window t in our model. To construct the binary response tables, we denote the click events and purchase events as positive responses, and the impressions (without any following events) as negative responses. All the other entries are treated as missing values. As the click and purchase are rare events in reality, our data set is ex-tremely sparse. To collect the side information, we select some features of users, ads and items, respectively. For each user, we encode the demographic information (e.g., country, state, domain) into a binary valued vector. The attributes of ads (e.g., advertiser, ad size) and items (e.g., type, price) are also encoded into binary vectors, respectively. To con-duct fair comparisons, we set up 5 different training/test cases along the timeline. Each training set consists of a click events table and a purchase events table. Each test set only contains a table of purchase events, as our goal is to predict the conversions.
 We compare our approach with the following baselines: PMF [9], LIBMF [10], SVDFeature [11], HBMFSI [12], and CMF [4]. For PMF, LIBMF, SVDFeature and HBMFSI, we only use the purchase data for training, due to the intrinsic limitation of these methods. For CMF and our approach, we use both the click data and purchase data for training. In particular, we use the click events and purchase events at time t to predict the purchase events in time t + 1 (i.e., D t +1 ). Following [3], we use the ROC curve and the area under ROC (AUC-ROC) as our evaluation metrics.
 For SGD based matrix factorization methods (e.g., PMF, LIBMF, SVDFeature and CMF), the major parameters are the learning rate  X  and the trade-off parameter  X  for regu-larization terms. For Bayesian method HBMFSI, we follow the settings in [12]. We sample a validation set from the training data, and tune these parameters empirically. The parameters  X  ,  X  1 and  X  2 are set to 0.003, 0.001 and 0.02, respectively. In CMF and our approach, another important parameter is  X  . To understand its sensitivity, we observe the AUC-ROC of CMF and DCMF approach with various choices of  X  . Figure 2(a) shows the AUC-ROC values in Case-3. We can observe that our approach is not sensitive to the values of  X  . We achieve better performance when  X  falls into the range [0 . 5 , 0 . 8]. In the following experiments,  X  is set to 0.6. In addition, the dimension of latent features is set to 20 for each method. To initialize our approach in Case-1, we borrow the latent factors of CMF learned from Oct. 1  X  Oct. 7 as the input U t  X  1 .
We evaluate the performance of each compared method in 5 training/test splits. Figure 2(b) shows the ROC in Figure 2: (a): AUC-ROC of CMF and DCMF in Case-3 Table 1: AUC-ROC of each methods on marketing data. Case-1, and Table 1 lists the AUC-ROC of all cases. Form Figure 2 and Table 1, we make the following observations: (1) Incorporating side information improves the prediction results significantly. SVDFeature and HBMFSI employ the features of users and items, they achieve much better perfor-mance than PMF and LIBMF, which do not utilize any side information. Similarly, our DCMF approach performs very well by virtue of the side information. (2) Modeling click response is helpful in predicting purchase events. CMF and our approach take advantages of the click response informa-tion, and they outperform PMF and LIBMF in each case. (3) Temporal dynamics is critical in conversion prediction. Our approach obtains better results than CMF, indicating that the latent features learned from previous time slice are very useful. (4) Our DCMF approach achieves the best re-sults in each case, compared to the baselines. It demon-strates that the side information and temporal information could be complementary to each other in predicting user behaviors such as conversion.
In this paper, we presented a novel matrix factorization approach DCMF for conversion prediction in display adver-tising. DCMF jointly examines the click events and purchase events in an online learning fashion by leveraging the tempo-ral information and side information. Extensive experimen-tal results on a real-world marketing dataset demonstrate the superiority of our approach over existing methods. This research is supported in part by the NSF CNS award 1314484, ONR award N00014-12-1-1028, ONR Young Inves-tigator Award N00014-14-1-0484, and U.S. Army Research Office Young Investigator Award W911NF-14-1-0218. [1] Deepak Agarwal, Bo Long, Jonathan Traupman, Doris [2] Kuang chih Lee, Burkay Orten, Ali Dasdan, and [3] Amr Ahmed, Abhimanyu Das, and Alexander J.
 [4] Ajit Paul Singh and Geoffrey J. Gordon. Relational [5] Yehuda Koren. Collaborative filtering with temporal [6] Joel Barajas, Ram Akella, Marius Holtan, Jaimie [7] Richard Jayadi Oentaryo, Ee-Peng Lim, Jia-Wei Low, [8] Aditya Krishna Menon, Krishna Prasad Chitrapura, [9] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic [10] Yong Zhuang, Wei-Sheng Chin, Yu-Chin Juan, and [11] Tianqi Chen, Weinan Zhang, Qiuxia Lu, Kailong [12] Sunho Park, Yong-Deok Kim, and Seungjin Choi.
