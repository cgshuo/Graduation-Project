 It is accepted that neural activity self-regulates to preve nt neural circuits from becoming hyper-or hypoactive by means of homeostatic processes [14]. Closely related to this idea is the claim that optimal information processing in complex systems is attai ned at a critical point, near a transi-tion between an ordered and an unordered regime of dynamics [ 3, 11, 9]. Recently, Kinouchi and Copelli [8] provided a realization of this claim, showing th at sensitivity and dynamic range of a network are maximized at the critical point of a non-equilib rium phase transition. Their findings may explain how sensitivity over high dynamic ranges is achi eved by living organisms. Self-Organized Criticality (SOC) [1] has been proposed as a mechanism for neural systems which evolve naturally to a critical state without any tuning of external parameter s. In a critical state, typi-cal macroscopic quantities present structural or temporal scale-invariance. Experimental results [2] show the presence of neuronal avalanches of scale-free dist ributed sizes and durations, thus giv-ing evidence of SOC under suitable conditions. A possible re gulation mechanism may be provided by synaptic plasticity, as proposed in [10], where synaptic depression is shown to cause the mean synaptic strengths to approach a critical value for a range o f interaction parameters which grows with the system size.
 In this work we analytically derive a local synaptic rule tha t can drive and maintain a neural network near the critical state. According to the proposed rule, syn apses are either strengthened or weakened whenever a post-synaptic neuron receives either more or les s input from the population than the required to fire at its natural frequency. This simple principle is enough for the network t o self-organize at a critical region where the dynamic range is maxi mized. We illustrate this using a model of non-leaky spiking neurons with delayed coupling for whic h a phase transition was analyzed in [7]. The model under consideration was introduced in [12] and can be considered as an extension of [15, timesteps a random walk with positive drift towards an absor bing barrier L . This spontaneous evolution is modelled using a Bernoulli process with parame ter p . When the threshold L is reached, the states of the other units j in the network are increased after one timestep by the synapt ic efficacy  X  , a i is reset to 1 , and the unit i remains insensitive to incoming spikes during the followin g timestep. The evolution of a neuron i can be described by the following recursive rules: where H L ( x ) is the Heaviside step function: H L ( x ) = 1 if x  X  L , and 0 otherwise. Using the mean synaptic efficacy: h  X  i = P N i P N j,j 6 = i  X  ij / ( N ( N  X  1)) we describe the degree of interaction between the units with the following character istic parameter: which indicates whether the spontaneous dynamics (  X  &gt; 1 ) or the message interchange mechanism (  X   X  1 ) dominates the behavior of the system. As illustrated in the right raster-plot of Figure 1, at  X  &gt; 1 neurons fire irregularly as independent oscillators, where as at  X  = 1 (central raster-plot) they synchronize into several phase-locked clusters. The lower  X  , the less clusters can be observed. For  X  = 0 . 5 the network is fully synchronized (left raster-plot).
 In [7] it is shown that the system undergoes a phase transitio n around the critical value  X  = 1 . The study provides upper (  X  max ) and lower bounds (  X  min ) for the mean inter-spike-interval (ISI)  X  of the ensemble and shows that the range of possible ISIs taki ng the average network behavior (  X   X  =  X  max - X  min ) is maximized at  X  = 1 . This is illustrated in Figure 1 and has been observed as well in [8] for a similar neural model.
 The average of the mean ISI h  X  i is of order N x with exponent x = 1 for  X  &gt; 1 , x = 0 . 5 for  X  = 1 , and x = 0 for  X  &lt; 1 as N  X  X  X  , and can be approximated as shown in [7] with 1 : We now introduce synaptic dynamics in the model. We first pres ent the dissipated spontaneous evolution , a magnitude also maximized at  X  = 1 . The gradient of this magnitude turns to be simple analytically and leads to a plasticity rule that can be expre ssed using only local information encoded in the post-synaptic unit. 3.1 The dissipated spontaneous evolution During one ISI, we distinguish between the spontaneous evol ution carried out by a unit and the actual spontaneous evolution needed for a unit to reach the t hreshold L . The difference of both quantities can be regarded as a surplus of spontaneous evolu tion, which is dissipated during an ISI. Figure 1: Number of possible ISIs according to the bound  X   X  =  X  max  X   X  min derived in [7]. For  X  &gt; 1 the network presents sub-critical behavior and is dominate d by the noise. For  X  &lt; 1 it shows super-critical behavior. Criticality is produced at  X  = 1 , which coincides to the onset of sustained activity. At this point, the network is also broke n down in a maximal number of clusters of units which fire according to a periodic pattern.
 Figure 2a shows an example trajectory of a neuron X  X  state. Fi rst, we calculate the spontaneous evolu-tion of the given unit during one ISI, which it is just its numb er of stochastic state transitions during an ISI of length  X  (thick black lines in Figure 2a). These state transitions oc cur with probability p at every timestep except from the timestep directly after sp iking. Using the average ISI-length h  X  i over many spikes and all units we can calculate the average to tal spontaneous evolution: Since the state of a given unit can exceed the threshold becau se of the received messages from the rest of the population (blue dashed lines in Figure 2a), a fra ction of (4) is actually not required to induce a spike in that unit, and therefore is dissipated. We c an obtain this fraction by subtracting from (4) the actual number of state transitions that was requ ired to reach the threshold L . The latter quantity can be referred to as effective spontaneous evolution E eff and is on average L  X  1 minus ( N  X  1) h  X  i , the mean evolution caused by the messages received from the rest of the units during an ISI. For  X   X  1 , the activity is self-sustained and the messages from other units are enough to drive a unit above the threshold. In this case, all the spontaneous evolution is dissipated and E eff = 0 . Summarizing, we have that: If we subtract (5) from E total (4), we obtain the mean dissipated spontaneous evolution, w hich is visualized as red dimensioning in Figure 2a: Using (3) as an approximation of h  X  i we can get an analytic expression for E diss . Figures 2b and c show this analytic curve E diss in function of  X  together with the outcome of simulations. At  X  &gt; 1 the units reach the threshold L mainly because of their spontaneous evolution. Hence, E total  X  E eff and E diss  X  0 . The difference between E total and E eff increases as  X  approaches 1 because the message interchange progressively dominates t he dynamics. At  X  &lt; 1 , we have E eff = 0 . In this scenario E diss = E total , is mainly determined by the ISI h  X  i and thus decays again for decreasing  X  . The maximum can be found at  X  = 1 . 3.2 Synaptic dynamics After having presented our magnitude of interest we now deri ve a plasticity rule in the model. Our approach essentially assumes that updates of the individua l synapses  X  ij are made in the direction of Figure 2: (a) Example trajectory of the state of a neuron: the dissipated s pontaneous evolution E diss is the difference between the total spontaneous evolution E total (thick black lines) and the actual evolution required to reach the threshold E eff (dark gray dimensioning) in one ISI. (b) E diss is maximized at the critical point. (c) The three different evolutions involved in the analysis (pa -rameters for (b) and (c) are N = L = 1000 and p = 0 . 9 . For the mean ISI we used  X  app of Eq. (3)). the gradient of E diss . The analytical results are rather simple and allow a clear i nterpretation of the underlying mechanism governing the dynamics of the network under the proposed synaptic rule. We start approximating the terms N h  X  i and ( N  X  1) h  X  i by the sum of all pre-synaptic efficacies  X  ik : This can be done for large N and if we suppose that the distribution of  X  ik is the same for all i . E diss is now defined in terms of each individual neuron i as: An update of  X  ij occurs when a spike from the pre-synaptic unit j induces a spike in a post-synaptic unit i . Other schedulings are also possible. The results are robus t as long as synaptic updates are produced at the spike-time of the post-synaptic neuron. where the constant  X  scales the amount of change in the synapse. We can write the gr adient as: For a plasticity rule to be biologically plausible it must be local, so only information encoded in the states of the pre-synaptic j and the post-synaptic i neurons must be considered to update  X  ij . Figure 3: Plasticity rule. (a) First derivative of the dissipated spontaneous evolution E diss for  X  = 1 , L = 1000 and c = 0 . 9 . (b) The same rule for different values of c .
 We propagate P k 6 = i  X  ik to the state of the post-synaptic unit i by considering for every unit i , an ef-fective threshold L i which decreases deterministically every time an incoming p ulse is received [6]. Intuitively, L i indicates how the activity received from the population in t he last ISI differs from the activity required to induce and spike in i .
 The only term involving non-local information in (10) is the noise rate p . We replace it by a constant c and show later its limited influence on the synaptic rule. Wit h these modifications we can write the derivative of E i diss with respect to  X  ij as a function of only local terms: Note that, although the derivation based on the surplus spon taneous evolution (10) may involve information not locally accessible to the neuron, the deriv ed rule (11) only requires a mechanism to keep track of the difference between the natural ISI and the a ctual one.
 We can understand the mechanism involved in a particular syn aptic update by analyzing in detail Eq. (11). In the case of a negative effective threshold ( L i &lt; 0 ) unit i receives more input from the rest of the units than the required to spike, which transl ates into a weakening of the synapse. Conversely, if L i &gt; 0 some spontaneous evolution was required for the unit i to fire, Eq. (11) is positive and the synapse is strengthened. The intermediate case ( L i = 0 ), corresponds to  X  = 1 and no synaptic update is needed (nor is it defined). We will consi der it thus 0 for practical purposes. Figure 3a shows Eq. (11) in bold lines together with  X  X  i total / X  X  ij (dashed line, corresponding to L i of a given unit at the end on an ISI. E total indicates the amount of synaptic change and E eff determines whether the synapse is strengthened or weakened . The largest updates occur in the transition from a positive to a negative L i and tend to zero for larger absolute values of L i . Therefore, significant updates correspond to those synapses with post-synaptic neurons which during the last ISI have received a similar amount of activity from the whole network as the one required to fire. We remark the similarity between Figure 3b and the rule chara cterizing spike time dependent plas-ticity (STDP) [4, 13]. Although in STDP the change in the syna ptic conductances is determined by the relative spike timing of the pre-synaptic neuron and t he post-synaptic neuron and here it is determined by L i at the spiking time of the post-synaptic unit i , the largest changes in STDP occur also in an abrupt transition from strengthening to weakenin g corresponding to L i = 0 in Figure 3a. Figure 3b illustrates the role of c in the plasticity rule. For small c , updates are only significant in a tiny range of L i values near zero. For higher values of c , the interval of relevant updates is widened. The shape of the rule, however, is preserved, and the role of c is just to scale the change in the synapse. For the rest of this manuscript, we will use c = 1 . Figure 4: Empirical results of convergence toward  X  = 1 for three different initial states above (top four plots) and below (bottom four plots) the critical point . Horizontal axis denote number of ISIs of the same random unit during all the simulations. On the lef t, results using the constant  X  = 0 . 1 . Larger panels shows the full trajectory until 10 3 timesteps after convergence. Smaller panels are a zoom of the first trajectory  X  0 = 1 . 1 (top) and  X  = 0 . 87 (bottom). Right panels show the same type of results but using a smaller constant  X  = 0 . 01 . 3.3 Simulations In this section we show empirical results for the proposed pl asticity rule. We focus our analysis on the time  X  conv required for the system to converge toward the critical poin t. In particular, we analyze how  X  conv depends on the starting initial configuration and on the cons tant  X  .
 For the experiments we use a network composed of N = 500 units with homogeneous L = 500 and p = 0 . 9 . Synapses are initialized homogeneously and random initia l states are chosen for all units the homogeneity in the interaction strengths. The network s tarts with a certain initial condition  X  0 and evolves according to its original discrete dynamics, Eq . (1), together with plasticity rule (9). To measure the time  X  conv necessary to reach a value close to  X  = 1 for the first time, we select a neuron i randomly and compute  X  every time i fires. We assume convergence when  X   X  (1  X   X , 1+  X  ) for the first time. In these initial experiments,  X  is set to  X / 5 and  X  is either 0 . 1 or 0 . 01 . We performed 50 random experiments for different initial configurations. I n all cases, after an initial transient, the network settles close to  X  = 1 , presenting some fluctuations. These fluctuations did not grow even after 10 6 ISIs in all realizations. Figure 4 shows examples for  X  0  X  X  0 . 58 , 0 . 7 , 0 . 87 , 1 . 1 , 1 . 3 , 1 . 7 } .
 We can see that for larger updates of the synapses (  X  = 0 . 1 ) the network converges faster. How-ever, fluctuations around the reached state, slightly above  X  = 1 , are approximately one order of magnitude bigger than for  X  = 0 . 01 . We therefore can conclude that  X  determines the speed of convergence and the quality and stability of the dynamics at the critical state: high values of  X  cause fast convergence but turn the dynamics of the network less st able at the critical state. We study now how  X  conv depends on  X  0 in more detail. Given N, L, c and  X  , we can approximate the global change in  X  after one entire ISI of a random unit assuming that all neuron s change its afferent synapses uniformly. This gives us a recursive defin ition for the sequence of  X  t s generated by the synaptic plasticity rule: Figure 5: Number of ISIs (a) and timesteps (b) required to reach the critical state in function of the initial configuration  X  0 . Rounded dots indicate empirical results as averages over 10 different realizations starting from the same  X  0 . Continuous curves correspond to Eq. (12). Parameter value s are N = 500 , L = 500 , p = 0 . 9 , c = 1 ,  X  =  X / 5 .
Then the number of ISIs and the number of timesteps can be obta ined by 2 : Figure 5 shows empirical values of  X  conv and  X  conv steps for several values of  X  0 together with the approximations (12). Despite the inhomogeneous coupling s trengths, the analytical approximations (continuous lines) of the experiments (circles) are quite a ccurate. Typically, for  X  0 &lt; 1 more spikes are required for convergence than for  X  0 &gt; 1 . However, the opposite occurs if we consider timesteps as time units. A hysteresis effect (described in [7]) presen t in the system if  X  0 &lt; 1 , causes the system to be more resistant against synaptic changes, which increases the number of updates (spikes) necessary to achieve the same effect as for  X  0 &gt; 1 . Nevertheless, since the ISIs are much shorter for supercritical coupling the actual number of time steps is st ill lower than for subcritical coupling. Based on the amount of spontaneous evolution which is dissip ated during an ISI, we have derived a local synaptic mechanism which causes a network of spiking n eurons to self-organize near a critical state. Our motivation differs from those of similar studies , for instance [8], where the average branching ratio  X  of the network is used to characterize criticality. Briefly,  X  is defined as the average number of excitations created in the next time step b y a spike of a given neuron. The inverse of  X  plays the role of the branching ratio  X  in our model. If we initialize the units uniformly in [1 , L ] , we have approximately one unit in every subinterval of leng th  X  X  , and in conse-quence, the closest unit to the threshold spikes in 1 / X  cases if it receives a spike. For  X  &gt; 1 , a spike of a neuron rarely induces another neuron to spike, so  X  &lt; 1 . Conversely, for  X  &lt; 1 , the spike of a single neuron triggers more than one neuron to spike (  X  &gt; 1 ). Only for  X  = 1 the spike of a neuron elicits the order of one spike (  X  = 1 ). Our study thus represents a realization of a local synapti c mechanism which induces global homeostasis towards an opti mal branching factor.
 This idea is also related to the SOC rule proposed in [3], wher e a mechanism is defined for threshold gates (binary units) in terms of bit flip probabilities inste ad of spiking neurons. As in our model, criticality is achieved via synaptic scaling, where each ne uron adjusts its synaptic input according to an effective threshold called margin . When the network is operating at the critical regime, the dyna mics can be seen as balancing between a predictable pattern of activity and uncorrelated random b ehavior typically present in SOC. One would also expect to find macroscopic magnitudes distribute d according to scale-free distributions. Preliminary results indicate that, if the stochastic evolu tion is reset to zero ( p = 0 ) at the critical state, inducing an artificial spike on a randomly selected un it causes neuronal avalanches of sizes and lengths which span several orders of magnitude and follo w heavy tailed distributions. These results are in concordance with what is usually found for SOC and will be published elsewhere. The spontaneous evolution can be interpreted for instance a s activity from other brain areas not considered in the pool of the simulated units, or as stochast ic sensory input. Our results indicate that the amount of this stochastic activity that is absorbed by the system is maximized at an optimal state, which in a sense minimizes the possible effect of fluct uations due to noise on the behavior of the system.
 The application of the synaptic rule for information proces sing is left for future research. We ad-vance, however, that external perturbations when the netwo rk is critical would cause a transient activity. During the transient, synapses could be modified a ccording to some other form of learning to encode the proper values which drive the whole network to a ttain a characteristic synchronized pattern for the external stimuli presented. We conjecture t hat the hysteresis effect shown in the regime of  X  &lt; 1 may be suitable for such purposes, since the network then is a ble to keep the same pattern of activity until the critical state is reached agai n.
 Acknowledgments We thank Joaqu  X   X n J. Torres and Max Welling for useful suggestions and inter esting discussions.
