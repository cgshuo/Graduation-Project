 Medical insurance is an important area related to the vital interests of everyone. But some illegal patients defraud only for their own benefits [2]. In view of this, it is widely concerned that detecting fraud quickly and accurately. Traditional methods usually make fixed rules to judge whether there exist fraudulent be-haviors. However, it is not always useful because the rigid rule cannot take the special nature of medical domain into account, which may lead to false negatives and false positive. Besides, as time going on, there are many new fraud models, which cannot be found through normal statistical methods.
 and still continues to be produced quickly every day. Thus, researchers tend to detect fraud in the medical field by means of data mining. Some researchers have defined data mining as a key part of a broader term of Knowledge Discovery from Databases [11]. Compared to traditional methods, data mining fully utilizes the massive data and is able to find out the fraud hidden in the massive data. However, there are still many challenges: First, analysis methods in the medical field usually work on heterogeneous datasets, which is hard to analyze through normal methods. Second, due to the special nature of medical field, an abnormal record cannot be confirmed as a fraud easily. Finally, because of the large size of the medical insurance data, it is difficult to analyze all the medical situation of every patient specifically.
 based on patients X  correlation(ODPC) to detect fraud in the massive medical insurance data. The method consists of four steps. The first step is data pre-processing, including data cleaning and clustering. After this, we extract the information of patients, medicines and diseases from the data set to construct a heterogeneous information network [3]. In the step three, by analyzing the in-formation network, the correlation scores of different patients can be calculated [12]. Finally, we design a discrimination rule to distinguish the normal patients and the patients who have fraudulent behaviors. This paper carries out experi-ments using real medical insurance data sets. We select two parts of the data as the candidate set and the reference set separately. Depending on the presence or absence of the label in the reference set, experiments can be divided into semi-supervised experiments and unsupervised experiments.
 and adjusting the weight to make it fit for the medical insurance field. Based on the method, we calculate correlation scores of patients and design a discrimina-tion rule to detect fraud. results verify the effectiveness and accuracy of the method.
 work in Section 2. Section 3 introduces the basic concepts. The structure of our model and the main ideas are reported in Section 4. Section 5 introduces an empirical case and evaluates the performance of our approach for fraud detection. We make a conclusion in Section 6. Outlier detection. The outlier detection techniques have been studied for many years and several definitions of outliers have been proposed [15]. It is a common and effective method of data mining used in fraud detection [16]. In recent years, a variety of outlier detection methods have been proposed. For example, Perozzi et al.[5] developed outlier detection in attributed graphs, Gao et al. [7] stud-ied outliers deviating from their closely connected peers and Gupta et al. [6] studied outliers in terms of their abnormal dynamics among communities. But most of them play a role in homogeneous networks, which are not applicable for heterogeneous information networks. As for heterogeneous networks, Gup-ta et al. [8] proposed to measure outliers based on community distribution of each vertex in the network and studied outlier detection based on assumption of association-based cliques in networks. Besides, Kuck et al. [12] made an outlier detection framework and give users X  flexibility to specify their own definition of an outlier in heterogeneous networks. However, these methods cannot be used in the medical insurance field directly because of the special nature of medical. In this paper, we increase the process of data cleaning, data clustering and weight adjustment on the basis of the method of Kuck et al. to make their way be able to fit for our medical insurance data.
 ing methods. However, most of them cannot be used for medical domain directly because it is hard to analyze for each drug. In the medical field, there are too many kinds of drugs, in the meanwhile, the amount of data is too small. Accord-ingly, data clustering is an effective way to solve this problem. Clustering is one of the fundamental data mining tasks and has been studied for many years.[13] Agrawal et al. [1] proposed automatic subspace clustering of high dimensional data for data mining applications and Jain et al. [10] proposed an algorithm for clustering data of Pentice-Hall advanced reference series.
 of outlier detection. Common methods include setting the threshold, selecting top k outliers, confidence interval et. There have been a lot of work carried out around the threshold. For example, Mcclure[14] conducted a personalized thresh-old testmode and Deng et al. [4] carried out the management and authentication for Wireless Ad Hoc Networks based on threshold and identity key. However, the threshold is usually a fixed value, which is not appropriate in our work because there are many factors that can affect the final score. So in this paper, we com-bine threshold with confidence interval to determine a flexible critical value that can adjust itself with the change of data to distinguish fraudulent patients from normal patients. In this section, we introduce the basic concepts.
 information network is an information network consisting of multiple types of vertices. In real word, when a person gets disease, he usually goes to the doctor for a diagnosis, and use medicines to treat his disease. Then the information between patients, medicines and diseases is interconnected, forming a gigantic network. Based on the above, the heterogeneous information network in this paper is a network consisting of 3 types of vertices: patients(P), medicines(M), diseases(D). This network can be defined generality as a directed network G = ( V,E, X ,T ) where V is the set of vertices and E is the set of edges.  X  is the vertex type mapping function V  X  T and T is the set of type. A meta-path is an ordered sequence of vertex types, denoted as P = ( T 1 T 2 ...T n ) and the reversal of it can be denoted as P  X  1 = ( T n ...T 2 T 1 ) .In our work, P = ( PMD ) and P  X  1 = ( DMP ).
 degree of correlation between different patients. In this paper, we determine pa-tients X  correlation based on their diseases and medicines. To a certain extent, the correlation of one patient to others can be a reaction to the possibility of fraud. In general, a patient is very likely to be fraudulent if he has a low correlation degree with any other patients. For example, it is abnormal that a person using orthopaedic medicines if he is a hypertension patient. And other hypertension patients usually do not use medicines in the department of orthopedics, then the patient who is abnormal will have a low correlative degree with other patients. In our work, we use the correlation score to reflect the correlation degree of different patients.
 medical field but sometimes it is difficult to make sure it is due to random fluctuations or some determining factors. Therefore, it is not always effective to detect outliers directly in terms of money, population of medical visit, the number of medicines and so on. In this paper we find outliers by calculating the correlation score that can reflect patients X  correlation degree in definition 2. To a certain extent, the one who has a low correlation score can be considered as an outlier but it is not fully applicable to our approach. In our work, the number of patients in reference set is usually more than one because it is not accurate to use only one patient X  X  medication model as a standard. Then there is a problem that more than one patients means more than one treatment plans so that the patients in candidate set cannot have a high degree of correlation with everyone in reference set. Thus, sometimes the average correlation may not be a big value. On the basis of these considerations, we combine the correlation degree with the outlier. By finding outliers of correlation score, the accuracy will be greatly improved for the reason that a patient must have a high likelihood of fraud if he not only has a low correlation degree but also his score is an outlier. In this section, we introduce the main process of our method. 4.1 Data Preprocessing The real health insurance data has large potential value but it is difficult to be excavated directly because of patient X  X  privacy and the dirty data. Besides, the particle size of the drug is so fine that there are too many kinds of medicines meanwhile the number of record is small for each medicine. We solve these problems by data cleaning and clustering through semantic. In the first step we removed the data containing the personal information and the data with the high loss rate. In particular, we only extract the information of patients, medicines, disease and label. On this basis, to rule out the interference of incomplete in-formation, we delete the patients with less than three records. In the next step we get the correspondence between medicines and categories from The Canon of Medicine. According to the correspondence relationship, many similar medicines can be replaced with one category. It is not a universal way, but it is appropriate in the medical field. 4.2 Network Construction In our work, we extract the information of patients, medicines and diseases from a real medical insurance data set to construct a heterogeneous information network. The network has a structure similar to the example in Fig.1.
 putation of closeness, or relevance between two network objects.[9] According to the network, we calculate the correlation score based on an improved algorithm from Kuck et al. The connectivity of vertex a and vertex b can be expressed as the number of symmetric meta-path instantiations of P sym between the t-wo vertices, where P sym = PP  X  1 = ( PMDMP ). Expressed as a formula is K ( v a ,v b ) = |  X P sym ( v a ,v b ) | .
 4.3 Score Calculation Considering that if we calculate the correlation score only in the above way there will be a problem that the score increases with the increase of the amount of data, which is not reasonable. In order to solve this problem, we adjust by increasing insurance field, it is normal that one medicine used to treat a few diseases, but at the same time we can infer that the medicine is not a specific drug for the diseases. If a patient treats many diseases using the same drugs, we believe it X  X  abnormal and he will be deducted scores. In particular, we accumulate the frequency that one medicine treat more than one diseases that the patient suffering as the weight need to be removed. There still is the problem that the value increases with the increase of the number of data. So we take the number of diseases into account and for a patient the weight is W =  X  N k is the number of disease that using the k-th medicine and t is the number of his diseases.
 of correlation score between two patients can be expressed as patients in the reference set. Noted that the correlation score is an indicator that can reflect their relevance but it is not the real correlation degree. Because of the existing of weight the score even may be a negative number. The general algorithm is shown in algorithm 1.
 Algorithm 1 Score calculation 4.4 Outlier Detection After calculating the correlation scores of patients, we design a discrimination rule to detect outliers. Kuck et al. finally came up with a ranking of scores and believe the top-k are outliers. However, it is not suitable for medical insurance field because it X  X  difficult to determine the number of k with the change of data sets. In our work, we combine threshold with confidence interval to determine a flexible critical value to detect outlier. The critical value is not a fixed threshold for the reason that many factors can affect the choice of threshold, such as the difference of disease category and the difference of sample sets. We need the critical value automatically adjust to an appropriate value when other factors change. Through statistics, we find that the distribution of scores is similar to the normal distribution as shown in Fig.2. The confidence interval for the normal distribution is the mean minus the standard deviation to the mean plus the standard deviation. In the medical field, false positive is much worse than false negative. On the basis of these considerations, the critical value in our work can be expressed as: Y =  X  C  X  2 correlation score as  X  C = 1 n the critical value is the fraudulent one. of calculation of the critical value to exclude the effect of abnormal data. In particular, we first calculate the critical value for the first time and compare it with the correlation degree score. By doing this, some outliers can be found out, but they may be only part of all the outliers. So we delete them and use the remaining data to calculate the critical value again and delete the new outliers. Repeat this process until there is no new outlier can be found and the last critical value is the final value. In this section, we introduce the source of the data and show our experimental results to evaluate the performance of our method.
 Algorithm 2 Outlier detection 5.1 Experiment Setup Data Set. The data set used in this experiment is collected from a real medical insurance system in a certain area. The data set consists of 192634 records of medical insurance of 11490 patients between 2011 and 2015. By the way the diseases in this data set mainly consist of chronic disease. Therefore, a normal patient will own more than two records and it is abnormal that one patient X  X  record contains too many types of disease.
 is the candidate set and the another part is the reference set. According to the difference of reference set, experiments can be divided into two kinds. As we all known, it is difficult to determine whether a patient is fraudulent, so there are only a little patients own clear label that record a patient is fraudulent or not. When the patients in reference set own clear label and all of them are normal patients, we call the experiment is a semi-supervised experiment. And we call the experiment is an unsupervised experiment if the reference set is the same as all the candidate set. 5.2 Case Study In the first experiment, we carry out a semi-supervised experiment and focus on the patients with hypertension. In the data set, there are 460 patients suffering hypertension. The candidate set consists of all of them, including the 18 fraud-ulent patients and other 442 patients. And we select the patients with the label of normal as an reference set. As we can see from Table 1, the correlation scores of normal patients are always at the range of 0.3 to 0.7. After calculation, we get the critical value as 0.26, then we can mark the patients whose score is -0.63, -0.13 and -0.56 respectively as a fraud. Obviously, the result is same as the label of experts.
 expected results as shown in Table 2. The candidate set consists of 182 fraudulent patients and 2416 other patients. From Table 2 we know the correlation score of normal patients are always at the range of 0.2 to 0.6. By calculating, we know the critical value is -0.24. Then we can mark the patients whose score is -0.29 and -1.45 respectively as a fraud and the result is also same as the label. the patients with cerebral hemorrhage as the candidate set and the reference set is the same as the candidate set. In this experiment, the candidate set consist of 698 patients, in which 16 patients are labeled as fraud. After calculation, we mark 15 frauds, including 13 real fraudulent patients and 2 normal patients. Then we can calculate the recall as 0.81 and the precision as 0.87. Besides, we also apply this method to hypertension and coronary heart disease. The result is shown in Fig.3. 5.3 Comparison of Result After proving the validity of our method, we compare the accuracy of it with Kuck X  X  methods  X  NetOut . First, we use hypertension as an example to compare the final score between  X  NetOut and ODPC. The results can be seen in Fig.4. From it we can know  X  NetOut cannot distinguish the normal patients and the fraudulent patients distinctly, which can be explained. Without clustering, the medicine is fine-grained, so it is difficult for a prescription to be similar to others, which results in low scores and the indefinite distribution. Without weight, we cannot distinguish a medicine is suitable to the patient or not, which leads to abnormal patients X  scores are not be significantly reduced. In summary, the majority of score in  X  NetOut is on the low side and there is no obvious outliers. medical insurance. So precision is more important than the recall. We compare precision of ODPC and  X  NetOut in Fig.5. However, from Fig.4 we can know the amount of fraud detected by  X  NetOut is rarely or even zero in our discrimination rule. For the sake of fairness, we select k patients whose scores are the lowest as the result, in which k is the number of fraud detected in ODPC. The result shows that the precision of ODPC is much higher than  X  NetOut . From it we can know although  X  NetOut is a good way to detect outliers, it is not suitable for medical insurance field and our method has a better effect in this field. In this paper, we have developed an outlier-based fraudulent detection method in huge medical insurance data. We first extracted the useful information from massive medical insurance data by data preprocessing. After that we constructed a heterogeneous information network to bridge patients, diseases and medicines. Based on the network, we detected outliers, which consists of two stages. For the first stage, to calculate the correlation scores of different vertices in the net-work, we improved an existing method by clustering and adjusting weight. For the second stage, we design a discrimination rule combined threshold with con-fidence interval to distinguish fraudulent patients from normal patients. Finally, we carried out experiments on real medical insurance data set, and the result demonstrated the effectiveness of our method from various angles.
 This work is partially supported by the Science and Technology Development Plan Project of Shandong Province No.2014GGX101019, 2015GGX101007; the Fundamental Research Funds of Shandong University No.2015JC031; Shandong Province Independent Innovation Major Special Project No.2016ZDJS01A09.
