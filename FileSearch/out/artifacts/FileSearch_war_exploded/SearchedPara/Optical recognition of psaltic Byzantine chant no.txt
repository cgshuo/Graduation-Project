 ORIGINAL PAPER Christoph Dalitz  X  Georgios K. Michalakis  X  Christine Pranzas Abstract This paper describes a document recognition system for the modern neume based notation of Byzantine music. We propose algorithms for page segmentation, lyrics removal, syntactical symbol grouping and the determination of characteristic page dimensions. All algorithms are expe-rimentally evaluated on a variety of printed books for which we also give an optimal feature set for a nearest neighbour classifier. The system is based on the Gamera framework for document image analysis. Given that we cover all aspects of the recognition process, the paper can also serve as an illus-tration how a recognition system for a non standard document type can be designed from scratch.
 Keywords Optical music recognition (OMR)  X  Base line detection 1 Introduction Byzantine music is a neume based notation system which uses a modal organisation/restructuration of melodies. The sacred music of this repertory is more commonly known as Psaltiki ( Yaltik X  ). Its notation has for long been used to des-cribe the principal melodic line, although it can theoretically be used as well for polyphonic melodies (see [ 1 , p. 222] for an example). This notation system has gone through many stages, the most recent one having been developed in the early 1800s in Constantinople (today known as Istanbul). As it is still in use today, we shall call it contemporary psaltic notation (CPN).

As psaltic music is a very small niche in today X  X  music business, there is not yet much research done on its optical recognition. Most other approaches to early music recogni-tion like Pugin X  X  hidden Markov modeling [ 3 ]relyonthe presence of stafflines and are thus not applicable to adias-tematic neumatic notations. Barton et al. have developed an experimental OCR system for the recognition of Gregorian chant neumes within the context of the NEUMES project [ 4 ]. They give little details about the program except that it uti-lises neural network techniques and provide no performance evaluation, but conclude that OCR for early Gregorian chant notation is of limited practical use due the inconsistent use of symbols, which restricts shape and meaning of a symbol to a particular manuscript source [ 5 ].

This restriction does not apply to CPN, which has been standardised since about 1800. Concerning its optical recog-nition, there is only the pioneering work of Gezerlis who focused on the optical character recognition of individual neumes [ 6 ], but did not deal with page segmentation and layout analysis. The aim of our work is to provide algo-rithms not only for recognising individual neumes, but also for their syntactical grouping based on their grammatical function as well as for page layout analysis and page segmentation.

We make the source code of our system freely available [ 9 ] as a toolkit for the Gamera framework [ 7 ]. Gamera is not itself a recognition system, but, rather, a cross platform Python library for building custom recognition systems. It has already been used successfully not only for building recognition systems for historic music notations like renais-sance lute tablature [ 10 ] and historic text documents in the Navajo language [ 11 ] or early modern Latin [ 12 ], but also for building a segmentation evaluation framework for staff removal from music images [ 13 ].

This paper is organised as follows: Sect. 2 gives an over-view of the music notation and Sect. 3 describes all steps of our recognition system. All algorithms are described and evaluated on sample pages from a variety of printed books. In Sect. 4 , we present a summary of the main ideas and experi-mental results, and in the final section we make some critical comments and suggest starting points for future improve-ments. 2 The notational system for Psaltiki This notation is described quite extensively in the original literature [ 1 ]; for an introduction in English see [ 2 ]. The particularity of CPN is that only the skeleton of the melo-dic line is written out according to well defined orthography rules. During performance more notes ( embellishments )are added, which requires considerable training beside a com-petent master. More recent editions by twentieth century composers extend the orthography rules so as to write out melodies in more detail, yet always using the same CPN neumes. There are hundreds of manuscripts and post 1800 classic editions, some of which are listed in Table 1 . Twen-tieth century editions including written out embellishments are just as numerous, as they describe the same repertoire as the classic 1800s editions.

Some characteristics of CPN can be seen in Fig. 1 which shows musical neumes accompanied by Greek lyrics below. Unlike in common western music notation, there is no staff system for specifying absolute pitches, and melodic formulae are encoded using specific symbols ( neumes ). These convey information that may be classified as quantitative (relative pitch), qualitative (melismatic vocalisations), temporal (divi-ding and extending neume durations), modulative (fthora and chroa, indicating modulation from one type of tri-, tetra-or pentachord scale to another), intonative (giving information as to the mode and musical gender used: diatonic, chromatic or enharmonic), martyric (giving  X  X itness X  attestations as to the relative pitch and mode after several lines of neumes), metric (indicating the type of temporal counting), rhythmic (with diastoles and numbers indicating rhythmic changes), chronagogic (tempo) and, more recently, isokratematic (indi-cating the relative pitch of a second or even third voice).
There are about 100 different individual neumes, which can be combined to form new neume groups . In each group there is one primary neume , which typically lies upon the baseline; all the other neumes in the same group are consi-dered as secondary neumes. Some neumes can never be primary, while others can be either primary or secondary, depending on their relative position.

All neumes belong to at least one neume group, which can be classified as an  X  X rdinary X , martyria or chronagogic group. Even though  X  X rdinary X  groups actually can be further classified into melodic, pause, rhythmic and metric neume groups, this distinction is of no significance with respect to the neume grouping algorithm described in Sect. 3.5 . While all neume groups are independent of each other, there is a set of neumes called linking neumes which may span over several neume groups (typically not more than three) and connect them. Such linking neumes can be occasionally broken in classical editions due to line endings for justification reasons.
Martyria groups ( X  X itnesses X ) consist of at least two com-ponents: a Greek letter representing the note name, and a martyria  X  X ppendix X , representative of the scale and overall context within which the particular note evolves. These two constituents specify the relative pitch (with respect to the starting point of the melody). Depending on the edition, the uppermost of the two symbols may be found on or below the baseline. Yet, if other symbols are added as well (such as dias-toles and fthoras), the entire martyria group components may span both above and below the baseline. The particularity of martyrias lies in the fact that they extend into the lyrics text zone, therefore creating a special segmentation problem in separating lyrics from martyrias. The same applies to chrona-gogic (tempo) groups, which typically consist of the neume  X  X hi X  plus Gorgons and Argons.

Table 2 lists all neumes and their possible functions. Some of these are Greek letters that can also appear in lyrics lines. Several neumes can vary in width (Ison, Anatinagma) or height (Diastole). All neumes marked as P ( X  X an be primary X ) are primary neumes when they intersect the baseline, with the notable exception of Kendima and Bareia. A single Kendima is never primary, but belongs to the group before it, while a group of two Kendimata on the baseline is primary. A Bareia usually is a secondary neume belonging to the group to its right, except when it is followed by one or more dots, in which case it is a primary neume with the dots (Hapli or Stigmi) belonging to its neume group.

The peculiarity of CPN that secondary symbols can be attached to the left, right, top or bottom of other primary sym-bols lying on a baseline shows some similarity to the  X  X atras X  in Hindi script that can be attached to basic characters resul-ting in modified characters which in turn can be combined into words [ 14 ]. The role of the baseline in CPN corresponds to the header line in Hindi script, with the notable difference that the CPN baseline is imaginary (i.e. invisible), while the header line in Hindi script is explicitly visible as an integral part of the main characters. Concerning layout analysis, an important difference is that in Hindi script the groups (words) are easily identified as connected components while the parts need to be determined by some segmentation method [ 15 ]. In CPN, on the other hand, it is the parts that are easily detec-table as connected components while the groups need to be determined based on syntactic rules and class membership. Thus Hindi script typically requires a top-down approach as opposed to a bottom-up approach in CPN.

Psaltiki associates different melodic patterns to text accor-ding to the distribution of the accentuated syllables. All this information constitues sequences that can be encoded, classified, and searched much like biological gene sequences and linguistic patterns that are used in the transmission of memory: this forms an interesting area of research for musi-cal pattern analysis. 1 Furthermore, its relationship to the Gre-gorian and Roman chant repertories is an interesting area of research for modern techniques of music information retrie-val. In order to build a database of Psaltic chant in a machine readable format that can be used for such comparative inves-tigations, as well as for building a repository of traditionally authentic formulae, an optical recognition system for this type of notation would be of great help. 3 The recognition system Like most other document recognition systems, our recognition system sequentially performs the five steps preprocessing, segmentation, classification, neume layout analysis and output generation . The task of the individual steps is: 1. During preprocessing , image defects due to low printing 2. In the segmentation step, the individual symbols are iso-3. In the classification step, the individual neumes are reco-4. In the neume layout analysis , the mutual relationship of 5. Eventually, a machine readable output encoding is gene-In the subsequent sections we describe these steps in detail and report their performance on the prints from Table 1 . 3.1 Preprocessing and symbol segmentation As our primary method for detecting neume baselines and lyrics textlines uses horizontal projections (see Sect. 3.3 below) it is important that a skew angle introduced through scanning be corrected. This was achieved with Postl X  X  pro-jection profile method [ 16 ] which already has proven to be quite reliable for lute tablatures [ 10 ]. The method determines the rotation angle  X  as the angle with the highest variation of the skewed projection profile ( y ) = where f ( x , y ) is the document image pixel value at position ( round ( x ), round ( y )) and zero outside the document. The variation of this profile is defined as V ( X ) =|| h  X  || 2 = As a naive brute force search for the angle  X  that maximises V ( X ) would be rather slow, we did a brute force search for the angle only at a coarse angle resolution and then used the three points around the maximum among these values as a starting point for a golden section maximum search [ 17 ].
To improve the image quality, we removed noise consisting of white and black speckles. White speckles were typically small enough in our images to be removed with a median filter using a 3  X  3 window [ 18 ], which, for one-bit images, is incidentally the same as an averaging filter. Most black speckles, however, were too large to be erased by the median filter and we identified and removed them ins-tead as connected components (CCs) having a  X  X mall X  black area. Ideally,  X  X mall X  would mean  X  X mall with respect to the characteristic page dimension oligon_height  X  (see below). Unfortunately this dimension can only be detected reliably after despeckling because, when speckles are present, they can be so frequent as to dominate the runlength histogram. Hence, we used a hard coded speckle size of three black pixels.

As all symbols in CPN are well separated and usually do not touch, individual symbols can be isolated using a connec-ted component (CC) extraction [ 19 ]. 3.2 Characteristic dimensions To make all subsequent operations independent from the scanning resolution, we determined two characteristic dimen-sions for each page: oligon_height , which corresponds to the vertical stroke thickness of the wide, frequently encountered neume Oligon, and oligon_width , which corresponds to the horizontal width of this same neume.

In many diagram recognition problems, the stroke thick-ness can be measured from the histogram of black runlengths. For example, the staffline height in common western music notation corresponds to the most frequent black vertical run-length [ 13 ]. In the case of CPN however, this histogram is dominated by thinner strokes from lyrics, noise and different neumes (see Fig. 2 ). As the most characteristic feature of the Oligon is that it is significantly wider than high, we created filtered images in which CCs with a ratio width/height less than three had been removed. This filtering is independent of the scanning resolution because the aspect ratio is scale invariant.

The neume distribution among the remaining wide CCs is showninTable 3 : the most frequent wide neume is the Oli-gon, followed by the Ison. Both neumes together form the majority of all wide CCs on each page. As both the width and the vertical stroke thickness of Oligon and Ison are com-parable, we can determine the characteristic dimensions from the filtered image as follows:  X  oligon_height is the most frequent black vertical run- X  oligon_width is the median of the CC width.
 These values turned out to be quite stable in our experi-ments over different pages, as can be seen from the low stan-dard deviations in Table 4 : even the largest mean error for oligon_width in source HS-1825 is only about 5%. For all other sources the variances are much smaller. The robust-ness of these two values makes them appropriate base units for thresholds used in subsequent rule based decisions. 3.3 Page segmentation The page segmentation step consists of the following tasks, which we describe in detail in the corresponding subsections:  X  detection of the baselines around which the neumes are  X  detection of the text (lyrics) lines between the baselines  X  lyrics removal. 3.3.1 Page layout analysis and lyrics removal Neume baselines are the lines around which the frequent neumes Oligon and Ison are aggregated. Consequently, they can be detected by an analysis of the horizontal projection profile of the image containing CCs with a width/height ratio greater than three (see Fig. 3 ), because this projection profile is dominated by Isons and Oligons, as we have shown in the preceding section. Baselines correspond to maxima in the projection profile with a height greater than 0.8 times oligon_width . As this criterion can yield more maxima than corresponding baselines, we first applied a low-pass filter of width oligon_height to the projection profile. For each projection value greater than 0.8 times oligon_width found at height y , we only selected the largest maximum within a window [ y , y + oligon_width ) . As an additional constraint we demanded that the distance between two baselines be larger than one oligon_width . This threshold is based on the reasoning that baselines cannot be closer due to the height of neume groups and due to the lyrics line between adjacent baselines.

While searching for a maximum in the projection pro-file of the unfiltered image, textlines can be found between two baselines, close to the middle. Due to the characteris-tic shapes of the Greek characters, the largest maximum will always be at the upper or lower edge of the lower case letters. To make our textline more robust with respect to curvature, we interpolated between the two largest maxima near the centre between adjacent baselines.

The algorithm described above yields a single y -position for each baseline and textline. This implies that the image is not too strongly rotated or curved. Although we have found this condition to be met after applying the rotation correction (described in Sect. 3.1 )intheprintsonwhichwehaveworked (see Table 1 ), it should be noted that this does not hold in general, in particular when manuscripts are considered.
The simplest approach for lyrics removal would be to remove all CCs that cross the textline. This would, howe-ver, also remove part of martyria and chronos signs, both of which contain components that overlap with lyrics lines, as can be seen in Fig. 1 . To distinguish martyrias from lyrics we tested two different methods, one based on a trained classifier, and the other based on pre-defined rules.
The training based approach requires that lyric glyphs be trained as  X  X yrics X  and that all CCs on the image be classified (see Sect. 3.4 ). As some of these glyphs can also be part of neume groups, we cannot simply remove all glyphs recogni-sed as  X  X yrics X , but must first look for glyphs recognised as  X  X artyria X  (or  X  X artyria-fthora X  or  X  X hronos X ). Each glyph that touches the textline and is not itself a  X  X artyria X  and is not below or above a glyph recognised as a martyria is considered as being part of the lyrics and is removed.
In the rule based approach, we first determined the lyrics character height ( character_height ) as the median height of all glyphs touching the textlines. All glyphs touching the textline were removed, unless they met one of the following criteria:  X  there is no glyph on the baseline above  X  the glyph X  X  upper edge rises above the baseline more than  X  the glyph has a width/height ratio greater than 2.2. The last two criteria avoid that two types of neumes, that frequently extend into the lyrics region, are inadvertantly removed: the second criterion is for Bareias which generally cross the baseline and the third criterion is for linking neumes which can be distinguished from Greek characters by their width (see Table 2 ).

Theoretically, lyrics always need neumes on the baseline above, so that glyphs meeting the first criterion could not be lyrics. In our sources however, lyrics were often not well aligned with the neumes, and this required an additional cri-terion. We therefore utilised the fact that martyria groups always consist of two vertically stacked components (see Fig. 1 ); the same holds for chronos groups. Consequently, we only consider a neume meeting the first criterion a martyria or chronos neume when a second component is found above it with the following properties:  X  It is narrower than 0.75 * oligon_width . This rules out  X  It is less than a vertical distance of 1.5 * character_height  X  The total height of both glyphs is greater than 2 * The numerical threshold values have been chosen heuristi-cally so that a number of common decision errors on selected pages from the different prints could be minimised.
In our experiments described in the next section, the rule based approach was slightly better, though not significantly so. This does not mean however, that a training based approach generally performs poorer. It may as well be due to insufficient training data. Concerning deterministic approaches to lyrics removal, the adaption of other sophis-ticated page layout analysis algorithms originally developed for text documents might be a potentially promising area of future research [ 20 ]. 3.3.2 Results We tested the baseline and textline detection algorithm on 65 random pages from the six prints listed in Table 1 .Froma total of 764 baselines only 2 were missed and no non-existent baseline was falsely found. For each detected baseline the corresponding textline was correctly identified.

That baselines were missed was due to a systematic error that occurs when a baseline does not contain any ison or oligon at all, in which case no neumes from that line remain after filtering the wide CCs before baseline detection. This can occur when a melodic line is only partially filled with a melodic formula that coincidentally contains no ison or oligon.

To compare the quality of our alternative algorithms for lyrics removal, we first manually removed the lyrics from 10 random pages for each source of Table 1 , resulting in a total of 60 test pages. For both algorithms (training and rule based, respectively) we counted the number of non-removed connected components (CCs) that were lyrics ( X  X issed X  CCs) and the number of falsely removed CCs that were not lyrics ( X  X xcess X  CCs). As the images still contained considerable noise even after the preprocessing described in Sect. 3.1 ,we only counted CCs taller than oligon_height .

The results are listed in Table 5 together with the results for the simple algorithm of removing all CCs touching the text-line (  X  character _ height / 2 to allow for slight curvature). It can be seen that the latter algorithm removes many glyphs that are not lyrics. Even though the other two algorithms introduce additional errors by not removing some lyrics, they lead to a significant reduction of the error rate with the rule based approach having the fewest errors overall.

Nevertheless, when pages are compared individually, there are those for which the training based algorithm was better. To test whether the overall error rate difference is signifi-cant, we used the statistical paired model proposed by Mao and Kanungo [ 21 ]. For each of the n test pages ( n = 60 in our case), we computed the difference W of the error rates between both algorithms. Under the assumption that these observations are independent for different test images, Mao and Kanungo have argued that a confidence interval for the true mean difference  X  at a given confidence level  X  is given by  X   X  W  X  t  X / 2 , n  X  1 V  X  where W and V 2 are the sample mean and variance of the n observed W and t  X / 2 , n  X  1 is the percentile of the t distri-bution with n  X  1 degrees of freedom. As a condition for a statistically significant difference of the error rates at a given confidence level  X  , Mao and Kanungo give the following criterion P where T = W function of the t distribution with n  X  1 degrees of freedom.
The results of this statistical estimation for the  X  X issed X ,  X  X xcess X  and  X  X otal X  (missed + excess) error rate are shown in Table 6 . It turns out that, although our rule based approach is on average slightly better, this difference is not significant. 3.4 Individual neume classification As already shown by Gezerlis, the individual neumes can be recognised by a kNN classifier [ 6 ]. In designing the classifier, two goals need to be achieved:  X  The recognition system should be adaptable to a wide  X  The classifier error rate should be low: this strongly Both aspects are investigated in detail in the following subsections. 3.4.1 Training abstraction layer The kNN classifier requires that class names be trained on sample images before the classification phase. While it were possible to only rely on the class names from Table 2 and their particular meaning in CPN as specified in [ 1 ], this would make the system very inflexible with respect to nota-tional variants and to the introduction of additional neumes. We therefore not only trained neume names, but also neume functions (primary, linking,...) as optional attributes. These functions are specified as a set of optional keywords during training. The supported keywords are listed in Table 7 . In our implementation, the function keywords are conveyed through the class name as an optional list of dot-separated fields pre-ceding the actual class name, e.g. primary.oligon . 3.4.2 Feature selection Gezerlis [ 6 ] used some features which are not built into Gamera (Euler number, principal axis direction, discrete wavelet transform). As reported by Gezerlis, these features were not sufficient to distinguish a number of different, but similar neumes. To tackle these confusions, he used a post-classification scheme to handle the different cases of confu-sion individually. On the other hand, one of the authors has observed in his work on the recognition of lute tablature prints that a selection of features built into Gamera can lead to a hol-dout recognition rate of over 99% [ 10 ]. Hence, we have made extensive experiments with these latter features which show that they lead to a good recogniton rate for psaltic neumes as well.

For each of the sources from Table 8 , we created a training data set for the kNN classifier. Source HS-1825 is missing in Table 8 because it uses the same typeface as HA-1825, so that the same training data can be used for both sources. In all training data sets, the class population ratios are represen-tative for the sources from which they are drawn. According to Davies [ 22 ], this ensures that the a priori probabilities of the individual classes are correctly taken into account by a kNN classifier.
 Some properties of our training data are listed in Table 8 . The glyphs classified as  X  X rash X  are speckles that still remain after our preprocessing operations. Their frequency can be considered as a measure for degradations due to low print or scan quality. Each training data set only contains about one fourth of all possible symbols, because not every symbol occurs in every print and some symbols are very rare. Even among the symbols occurring in our training sets, a consi-derable number is represented with less than three glyphs. This has the consequence that we cannot choose the number k of neighbours in the kNN rule larger than one, leading effectively to a nearest neighbour classifier rather than a k NN classifier.

At the time of writing, Gamera provided 15 built in fea-tures (see the Gamera documentation [ 8 ] for details), of which the 14 features listed in Table 9 were useful for segmen-tation based recognition. For our recognition system, we chose the feature combination aspect_ratio, moments, nrows, volume64regions , because these had the best  X  X eave-one-out X  performance in the experiments described in the next section. It is interesting to note that this feature combination also had an excellent  X  X oldout X  performance on lute tablature prints [ 10 ], which leads us to the conjecture that these features gene-rally are a good choice for printed sources. 3.4.3 Experimental results We evaluated the performance of the individual features on each training set with the  X  X eave-one-out X  method, i.e. by classifying each training glyph against the other training glyphs. The results are listed in Table 9 , which also gives the dimension of each feature, as some features are actually vector values rather than a single value. For all features, the performance values are roughly comparable over all sources, with the notable exception of nholes and nholes_extended . These features count the number of black-white transitions per row or column and are thus very sensitive to white spe-ckles, resulting in a poor performance on the lowest qua-lity source PPAM-1952. The different values for the average runtime of the leave-one-out evaluation in the last column are not only due to the different feature dimensions, but also to the runtime complexity of the feature computation: e.g. the zernike_moments [ 23 ] have a longer runtime than volume64regions even though their dimension is lower.
The best performing feature is volume64regions with an average recognition rate above 98%. This feature simply counts the percentage of black pixels ( X  X olume X ) in each cell of an 8  X  8 grid. Although it is scale invariant, it is not invariant to rotation or changing stroke positions. The latter variations are less likely to be found in printed books than in manuscripts, and, by consequence, the good performance on our sources (exclusively printed books) is not surprising.
To further improve the recognition rate, we have evalua-ted the leave-one-out error rates for feature combinations. As brute force testing of all possible combinations is expo-nential in the number of features, we have only tested all combinations up to a feature set size of four, because in experiments on lute tablature prints the combination of more than four of Gamera X  X  builtin features did not increase the recognition rate any further [ 10 ]. Table 10 lists the eight best performing feature combinations on every training set. Each of these combinations contains the individually best perfor-ming volume64regions . It is interesting to note that in each of the best performing combinations there is nrows or ncols , which are the height or width of a glyph. This leads us to the conclusion that the absolute size of a symbol is also an important distinguishing feature in our training sets. This is easily understandable because speckles (classified as  X  X rash X  in our training sets) can have any shape, yet are typically small.

Based on these results, we have chosen the feature com-bination aspect_ratio, moments, nrows, volume64regions for our nearest neighbour classifier, because it is the best performing combination when Table 10 is sorted by Avg and Min .
 3.4.4 Compound neumes Some neumes in Table 2 consist of more than one connected component, some of which even have a different meaning when appearing in combination (e.g. Kendima versus Kendimata and Bareia versus Leima Chronou).

One approach would be to train the compound neumes as  X  X roups X  in Gamera and let Gamera X  X  grouping algorithm [ 24 ] deal with them. This, however, requires that the combi-nations appear sufficiently often in all possible variants in the training data. Moreover, the distance between their compo-nents must not be too large, because otherwise the grouping algorithm will have to test too many possible combinations, resulting not only in a long runtime, but also in falsely detec-ted groups.

We have therefore chosen a different approach and added a post-processing step that replaces certain neume combi-nations with a compound neume, based upon a translation table. Entries in the translation table are of the form neume1,neume2,maxdist: neume3 This means that the adjacent neumes neume1 and neume2 following each other in the horizontal direction with a boun-ding box distance of at most maxdist * oligon_height aretobe replaced with the single, pre-combined neume neume3 .All such newly, post-processing introduced compound neumes are treated like any other neume in the subsequent layout analysis. 3.5 Neume layout analysis and grouping Once the various individual symbols have been recognised, their mutual relationship needs to be determined. Essentially this means organising the symbols as a linear sequence of neume groups. For each neume group, a primary neume must be identified. Furthermore, each linking neume must be atta-ched to the appropriate neume groups. 3.5.1 Rules for neume grouping Neume groups are always separated by some space on the baseline . All neumes trained as primary and found on or near the baseline are considered as primary neumes: they form the core of a neume group. When there are two primary neumes that overlap horizontally, the larger one is considered as the primary neume.

Once the primary neumes have been identified, the neume groups are built as follows:  X  secondary neumes are attached to the primary neume with  X  non primary neumes on the baseline are attached to the
This grouping scheme cannot be used for the neumes Gor-gon (and its variants), the linking neumes and the Gorgon associated dots, because they often extend into the x -position of a neighbouring neume group (see Fig. 4 b, c). These neumes must therefore be ignored by the above grou-ping algorithm and must be post-processed as follows:  X  linking neumes are always associated to the rightmost  X  Gorgons are associated with the leftmost neume group  X  any dot following or preceding a Gorgon is associated
All neumes belonging to martyria and chronos groups fall through the grouping scheme described above because these neumes do not belong to any primary class and do not overlap horizontally with any primary neume. We can thus identify martyria or chronos groups by joining all neumes that overlap horizontally with neumes that are of a martyria or chronos class.

All neumes still falling through the grouping scheme (this may happen, e.g., for Diastoles) are considered as groups of their own without a primary neume.
 3.5.2 Results We have measured the error rates both for the recognition of the individual neumes and for the neume grouping on 65 pages from the sources of Table 1 . On all pages we had manually removed the lyrics so that we could investigate the recognition and grouping error rates independently from errors introduced through the automated lyrics removal des-cribed in Sect. 3.3 .

For the recognition of the individual neumes we used the nearest neighbour classifier with the feature set aspect_ratio, moments, nrows, volume64regions in combination with Gamera X  X  grouping algorithm [ 24 ] with a maximum group size of two components, i.e., only adjacent pairs of glyphs were tested whether they  X  X ook like X  a broken variant of a single connected glyph in the training set.

The results are listed in Table 11 . In contrast to the leave-one-out error rates of Table 10 , the error rates for the indi-vidual neume recognition are holdout error rates, i.e., they are measured on test data different from the training set. This means that the errors on the test set are independent Bernoulli trials with an error probability p for misclassifying a neume or misgrouping a group. As p is typically a low value, the classical ( 1  X   X ) confidence interval taught in introductory statistic textbooks can be expected to have a poor coverage property, and we use the Agresti X  X oull confidence interval instead, as recommended by Brown et al. [ 25 ]:  X  p  X  z where  X  n = n + z 2 1  X   X / 2 and  X  p = ( k + z 2 1  X   X / n being the number of neumes or groups, k the number of misclassified neumes or groups and z 1  X   X / 2 being the (  X / 2 ) percentile of the standard normal deviation. It should be noted that this confidence interval is not centred around the estimator k / n for the error rate, but around the slightly higher value  X  p .For  X  = 0 . 05, we have z 1  X   X / 2 = 1 so that  X  p  X  ( k + 2 )/( n + 4 ) , i.e., the Agresti X  X oull estimator for p adds four trials and two errors.

The holdout error rates in Table 11 are all higher than the optimistically biased leave-one-out error rates in Table 10 , because the test data also contains heavily distorted, broken or touching symbols, which are absent in the training set. To examine the actual reasons for the difference in more detail, we have also counted the number of errors due to touching or broken symbols and found that  X  46% of the neume recognition errors and  X  26% of the neume grouping errors were due to broken or touching symbols. This is an observation also made in other OCR applications, where a considerable part of the recognition errors is typically due to segmentation errors [ 26 ]. A technique commonly deployed in OCR is to post-correct the recognition results by looking for lexical or syntactic errors [ 32 ]. To estimate whether such a post-correction could also be useful for our recognition sys-tem, we have additionally counted which of the errors lead to a syntactically impossible neume combination and found that this was the case for  X  almost all of the neume recognition errors and  X  more than 90% of the neume grouping errors.
 Consequently, syntactical plausibility checks could automa-tically detect the major part of the recognition errors. The downside of such a post-processing would however be that certain notational rules had to be wired into the system, making it applicable to only a narrow range of neumatic nota-tional conventions. 3.6 Output encoding Recognition of the neumatic music results in a machine readable output code. Ideally, this would be represented in the form of a well documented open file format, for which commodity software is available, comparable to MusicXML as a widely deployed interchange format for common wes-tern music notation [ 27 ]. MusicXML does not, however, pro-vide any means by which to encode neumatic notations and there is no other widely accepted file format for psaltic music notation.

A development project for an XML based music enco-ding scheme particularly tailored to the needs of scholarly critical editions is the Music Encoding Initiative (MEI) [ 28 ]. While supporting common music notation out of the box, MEI also allows for the inclusion of user defined modules as extensions. Such a module has recently been developed by the T X Bingen project to encode late medieval diastematic neumes [ 29 ]. Both this module and the MEI specification are currently under development and still a moving target.
A different file format specification is currently developed by the NEUMES Project [ 4 ] as a universal XML encoding scheme for medieval chant notation. It aims at covering a wide range of neumatic notations and also addresses the uncertainty problem of yet poorly understood notation. This introduces more complexity than necessary for our very limi-ted scope of contemporary psaltic notation. Like the MEI neumes extensions, the NeumesXML specification is still under active development and thus subject to changes. A different option is to use the file format of a graphical Psaltiki editor like Melodos [ 30 ]. Apart from the problem that this format is undocumented, this would also mean that the output would be useless without this particular software or on platforms for which this software is not available. This would be particularly inappropriate for storing the results in a database, because no custom third party software (e.g. for further musical analysis) could be written.

Yet another way of entering and publishing psaltic music is the use of an ordinary word processing program in combi-nation with some special font. Ideally, the font encoding from the Unicode Standard [ 2 ] could be used, which specifies code numbers for the individual neumes, but does not cover their relative positions. Unfortunately, word processing programs are inappropriate for the two-dimensional CPN, because they are only designed for lines of characters in a one dimensional sequence. Hence two different crutches using custom fonts areinuse:  X  encoding neume groups using pre-combined neumes  X  using different characters for the same neume at different Generating such an output would also mean to opt for some special non standard font encoding, thereby limiting the usa-bility of the output considerably.

An interesting compromise between GUI systems and heavily-tagged XML input is currently developed by Haralambous in the Byzantine notation typesetting system QAM  X  RIS based on luaT E X. 2 He uses the Unicode characters from [ 2 ] combined with ASCII characters ( / , &gt; ) to represent a vertical relation, absence of base character, and offset of diacritic. This system is still under development and not yet ready for production use.

We therefore decided to create our own CPN code, which is both simple (so that converters to different formats can be written without much effort) and does not loose any layout information of the music print. The output is a simple ASCII text file where each line of text represents a line of neume groups in the input image and groups are enclosed in paren-theses. The primary neume (or the main martyria or chronos neume) in each group is marked by an appropriate prefix and to each neume its coordinates are attached in square brackets ( [x,y] ). These coordinates are measured in the following coordinate system:  X  y = 0 on the baseline, x = 0 at the right edge of the  X  the grid unit size is oligon_height  X  the given coordinate is the position of the lower right edge
Table 12 shows some examples for the encoding of indi-vidual neume groups in our code. 4 Summary Our recognition system covers the complete process from reading a raster image of CPN notation to generating a machine readable code. This includes the measurement of characteristic page dimensions, page and symbol segmentation, neume recognition and syntactical neume grouping.

Two characteristic dimensions ( oligon_width and oligon_ height ) are measured on a filtered image in which narrow connected components ( w idth / height &lt; 3) have been removed. Our experiments show that width and vertical stroke height of the frequent neume Oligon can be determined with good accuracy from the histogram of CC widths and black vertical runlengths, respectively. Neume baselines are deter-mined from maxima in the horizontal projection profile of the same filtered image.

An important page segmentation step is the separation of chant text ( X  X yrics X ) from neumes. The technical pro-blem of this step lies in the fact that certain neume groups (mostly martyrias ) extend into the lyrics zone and that they can contain ordinary Greek letters that also appear in the chant text. Our system does this in two stages: first it deter-mines text lines from the horizontal projection profile of the full (unfiltered) image, while utilizing the previously found baseline positions. Then it removes all CCs around the text lines, unless they  X  X eem to belong to a martyria X . For the lat-ter criterion, we have devised two different approaches, one purely rule based and one primarily based on trained recog-nition. Our experiments revealed that both of our approaches have their shortcomings, with the rule based approach being slightly better, though not significantly.

The individual symbols are separated with connected com-ponent labeling and their recognition is done with a nea-rest neighbour classifier. Our experiments on a variety of printed sources have shown that for these sources even sim-pler features than those proposed by Gezerlis [ 6 ] yield good recognition rates. While the leave-one-out performance of the chosen feature set was greater than 99% on all training sets, the final recognition rates for the individual neumes on the test images were lower (between 95 and 98.5%, depen-ding on the source). A considerable fraction of these errors was due to touching or broken characters.

The final neume layout analysis step builds neume groups based on horizontal overlaps. Additionally, our system uses a class naming convention by which not only classes can be specified during training, but also possible grammatical neume functions. This approach worked quite well and lead to grouping error rates between one and three percent, depen-ding on the source. 5 Conclusions and perspectives We have developed a prototype of the described system that is freely available [ 9 ] and works well on printed books. To fur-ther improve its recognition quality, we suggest three starting points: the automatic lyrics removal, the symbol segmenta-tion, and a syntactic post-correction.

Even though the reported error rates for lyrics removal might seem low at first sight, they can require tedious manual correction of the final recognition results. Hence we plan to add a graphical user interface for manually correcting the automatic lyrics removal as an optional interactive step bet-ween the page segmentation and recognition stages. Inde-pendent from this workaround, the lyrics removal leaves room for further improvement by trying to adapt general page layout analysis methods for complicated layouts, like the use of area Voronoi diagrams [ 31 ].

As a considerable fraction of the neume recognition errors was due to touching characters, these can hardly be dimini-shed by further optimising the feature set. Actually the chosen feature set already has a leave-one-out performance of over 99%. It thus seems more promising to have a look at clas-sification based strategies for character segmentation [ 26 ], rather than trying to further optimise the feature set.
Another means to improve the final recognition rate could be a lexical or syntactic post-correction, a technique com-monly used for improving OCR results [ 32 ]. As in our tests most errors made by our system lead to syntactically impos-sible neume combinations, many of the recognition errors could be automatically detected with the aid of a program for generating CPN notation that utilises the notational conven-tions of CPN which can be considered as some kind of diagram notation [ 33 ]. The recently published third party program Melodos [ 30 ] actually offers an automatic correc-tion module, which could provide a useful option to improve the recognition rates of our system.

An interesting area of further research could be the refor-mulation of the neume grouping as a constraint satisfaction problem [ 34 ]. The grouping can be considered as a labeling of the neumes under constraints imposed by the notational conventions. This would provide a general framework both to formulating syntactically impossible combinations and for their detection already during the neume layout analysis step.

Our recognition system is not limited to the particular neumes of CPN listed in Table 2 . Because of its training abs-traction layer, it can be adapted to other variants of psaltic chant notation, including notations in Rumanian and Slavo-nic as well as paleographic notations. With such an extension into the domain of handwritten manuscripts, we are to expect that some of our algorithms will require modifications due to a higher variance both in the shape of the neumes and in their positioning.

As a first step in the direction of psaltic chant manuscript recognition, we plan to investigate the manuscripts by Ange-los L. Boudouris, who was the disciple and First Domestichos of Iakovos Nafpliotis at the Patriarchate of Constantinople during the turn of the 20th century. These manuscripts, approximately 10,000 pages distributed in 18 volumes, use the same CPN as the prints discussed in the present paper.
We hope that our research will eventually help building a machine readable repository of this repertoire that can be used for further musicological research.
 References
