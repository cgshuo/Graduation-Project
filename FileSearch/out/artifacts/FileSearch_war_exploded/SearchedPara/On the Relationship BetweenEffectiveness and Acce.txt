 Typically the evaluation of Information Retrieval (IR) sys-tems is focused upon two main system attributes: efficiency and effectiveness. However, it has been argued that it is also important to consider accessibility, i.e. the extent to which the IR system makes information easily accessible. But, it is unclear how accessibility relates to typical IR eval-uation, and specifically whether there is a trade-off between accessibility and effectiveness. In this poster, we empirically explore the relationship between effectiveness and accessibil-ity to determine whether the two objectives i.e. maximizing effectiveness and maximizing accessibility, are compatible, or not. To this aim, we empirically examine this relation-ship using two popular IR models and explore the trade-off between access and performance as these models are tuned. Categories and Subject Descriptors: H.3.3 Information Storage and Retrieval -Retrieval Models General Terms: Theory, Experimentation Keywords: Information Retrieval, Accessibility, Findabil-ity, Retrievability, Evaluation
Historically, there have been two main ways to evaluate an Information Retrieval (IR) system: efficiency and effec-tiveness [7]. A complementary and so-called higher order evaluation has been recently proposed based on accessibil-ity [1]. Instead of assessing how well the system performs in terms of speed or performance, access-based measures pro-vide an indication of how easily documents within the collec-tion can be retrieved using a particular retrieval system [1]. Evaluations based on accessibility have been performed in a number of different contexts (see [2, 6, 3, 4]), but there has been little work examining the relationship between access-based measures and effectiveness measures.
The accessibility of information in a collection given a sys-tem has been considered from two points of view, the system side i.e. retrievability [2] and the user side findability [6]. Re-trievability measures provide an indication of how easily a Neither extreme is desirable, but to what extent do we need to trade-off retrievability for effectiveness. In this poster, we examine the relationship between the Gini measure (i.e. the summarized retrievability measure) and precision, by exam-ining the change in each measure as the parameter values of different retrieval models are varied.
 Experimental Setup Two TREC collections were used: Associated Press (AP) 1988-1989 and Wall Street Journal (WSJ) 1987-1992, both with TREC query sets 1, 2 and 3. Two popular IR models were selected: Multinomial Lan-guage Modelling with Bayes Smoothing and Okapi BM25. For Language modelling, the smoothing parameter  X  was BM25, the b parameter, which adjusts length normalisation, was varied from 0 . 1 to 1 . 0 in steps of 0 . 1. Effectiveness was measured using both precision at 10 (P@10) and mean av-erage precision (MAP). To estimate retrievability, the same methodology employed in [2] was applied, where we used 100,000 two-word queries derived from the most frequent collocations found in each corpus to estimate the retrievabil-ity values. Retrievability was measured using the cumulative measure (described above) where c = 10 and c = 100. The degree of equality was measured using the Gini coefficient denoted as Gini@10 and Gini@100, respectively.

Results In Figure 1, plots of the different measures are shown for each model (top: Language Model, bottom: BM25) and each collection (left: AP, right: WSJ) across the pa-rameter values. From these plots, the first point of inter-est is that Gini varies considerably across the parameter ranges for both models, where minimizing the Gini coeffi-cient translates into providing more access to documents in the collection (this is around  X  = 10  X  100 for the Language Model and b = 0 . 6  X  0 . 8 for BM25. Of note, is that the sug-gested/default value for b is usually 0.75, which is well within this range.). While this does not directly correspond to when performance is maximized, the difference in performance is quite small; in the range of (0.01-0.03 for both P@10 and MAP). While, these differences in performance were signifi-cantly difference ( p &lt; 0 . 05 using Student X  X  T-test) for all but BM25 on WSJ, there does appear to be a positive correlation between the two measures, and this opens up the possibil-ity of using access based measures to tune retrieval systems. These findings suggest that a systematic relationship ap-pears to exist between the gini measurements (representing Accessibility) and the precision measurements (representing Effectiveness).
This preliminary analysis of the relationship between ac-cessibility measures (specifically retrievability measures) and effectiveness measures shows that the two goals of maximiz-ing access and maximizing performance are quite compati-ble. In fact, reasonably good retrieval performance is still obtained by selecting parameters that maximize access (i.e. when there is the least inequality between documents ac-cording to Gini given the r ( d ) values). This motivates the hypothesis that retrieval models/systems can be effectively tuned using access based measures. If this holds, then it suggests that when relevance information is not available a sensible approach to configuring a system is to ensure that users can access all documents as easily as possible. How-ever, further research is needed to test this hypothesize more
