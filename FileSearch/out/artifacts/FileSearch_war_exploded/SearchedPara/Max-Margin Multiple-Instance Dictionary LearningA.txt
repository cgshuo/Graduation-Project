 Xinggang Wang  X  wxghust@gmail.com Baoyuan Wang  X  baoyuanw@microsoft.com Xiang Bai  X  xbai@hust.edu.cn Wenyu Liu  X  liuwy@hust.edu.cn Zhuowen Tu  X  ,  X  zhuowen.tu@gmail.com
Microsoft Research Asia Finding an effective and efficient representation re-mains as one of the most fundamental problems in ma-chine learning. A number of important developments in the recent machine learning literature (Blei et al., 2003; LeCun et al., 2004; Hinton et al., 2006; Serre &amp; Poggio, 2010) have an important dictionary learn-ing stage, either explicitly or implicitly. For example the bag of words (BoW) model (Blei et al., 2003), due to its simplicity and flexibility, has been adopted in a wide variety of applications, in document analysis in particular. In computer vision, the spatial pyramid matching algorithm (SPM) (Lazebnik et al., 2006) has demonstrated its success in image classification and categorization.
 In this paper, we propose a general dictionary learning method through weakly-supervised learning, in par-ticular multiple instance learning (Dietterich et al., 1997). Our method can be applied in many domains and here we focus on image-based codebook learning for classification. On one hand, visual patterns are giv-en as multi-variate variables and often live in high di-mensional spaces; on the other hand, there are intrinsic structural information in these patterns, which might be unfolded into lower dimensional manifolds. Dictio-nary (codebook) learning provides a way of knowledge abstraction upon which further architectures can be built.
 In computer vision applications, given a learned code-book, each image patch in an input image is either as-signed with a code or a distribution (on learned code-book); then image representation can be built based on the encoded image patches. In the experiments of this paper, each input sample is denoted by a feature vector, such as SIFT (Lowe, 2004) and LBP (Ojala et al., 1996), extracted from an image patch (say 48  X  48). Using codebook has several advantages: (1) explicit representations are often enforced; (2) dimen-sionality reduction is performed through quantization; (3) it facilitates hierarchical representations; (4) spa-tial configuration can be also imposed. A direct way to learning a codebook is by performing clustering, e.g. the k-means algorithm (Duda et al., 2000). Several approaches have been proposed (Jurie &amp; Triggs, 2005; Lazebnik &amp; Raginsky, 2009) and one often builds fur-ther models on top of a learned codebook (Fei-Fei &amp; Perona, 2005). However, a direct clustering approach is often sensitive to: (1) initialization, (2) number of codes, and (3) metric (distance) of the multi-channel features. In a supervised setting where the labels are available, several discriminative codebook learning ap-proaches have also been proposed (Moosmann et al., 2006; Yang et al., 2008; Moosmann et al., 2008). Instead of learning a dictionary in a fully unsupervised way (e.g. k-means) or supervised way (e.g. random forests (Moosmann et al., 2008)), we take a different path to dictionary learning through a multiple instance learning strategy. Given a set of training images with each image assigned with a class label, we treat one particular class of images as positive bags, and the rest images as the negative bags; dense image patches are collected as the instances in each bag. Our al-gorithm then tries to learn multiple linear SVMs for two purposes: (1) to identify those patches (instances) which are genuine to the class of interest; (2) to learn linear SVM classifiers to classify those identified patch-es. These linear SVMs naturally cluster the positive instances into different clusters. We repeat the pro-cess for all the image classes and collect the learned classifiers, which become our dictionary (codebook). Due to the difference to the codes learned in standard ways, we call each learned linear SVM as generalized code , or G-code . In this paper, we propose a learning framework to achieve the above goal, which has the following properties: (1) a multiple instance learning strategy is proposed for dictionary learning (an un-common direction); (2) each code is represented by a linear SVM which naturally performs metric fusion for multi-channel features; (3) we design a formulation to simultaneously learn mixtures of codes by maximizing classification margins in MIL. State-of-the-art results are observed in image classification benchmarks with significantly smaller dictionary (e.g. only 1 / 6) than the competing methods. Next, we briefly discuss the relations between our work and the existing literature in dictionary learning. Based on low-level descriptors (Lowe, 2004; Ojala et al., 1996), bag of words (BoW) model (Fei-Fei &amp; Perona, 2005) using codebooks is widely adapted for image classification and object detection. On one hand, unsupervised learning, such as K-means, is al-ready demonstrated its popularity for codebook learn-ing in many applications. On the other hand, people found that supervised learning methods tend to pro-duce more discriminative codebooks, as described in recent works (Moosmann et al., 2008; Yang et al., 2008; 2010; Jiang et al., 2012; Mairal et al., 2010; Winn et al., 2005). More recently, there are some attempts (Parizi et al., 2012; Singh et al., 2012; Zhu et al., 2012) tried to involve latent structures during both the learning and inference process for image classification, howev-er, their target is not for generic dictionary learning. Different from all the previous work, in this paper we try to explicitly perform the dictionary learning along the line of weakly-supervised learning.
 Strongly supervised methods like Attributes (Farha-di et al., 2009; Pechyony &amp; Vapnik, 2010; Parikh &amp; Grauman, 2011), Poselets (Bourdev &amp; Malik, 2009), and Object Bank (Li et al., 2010), have shown to be promising. In our approach, we only use the image-level labels with no additional human annota-tions to learn the codebook. In Classemes (Torresani et al., 2010), the emphasis was made on learning an image-level representation for image search. From the viewpoint of multiple instance learning, our proposed method is related to multiple component learning (M-CL) (Doll  X ar et al., 2008) and multiple clustered in-stance learning (MCIL) (Xu et al., 2012). Due to the lack of explicit competition among the clusters, however, both MCL and MCIL are hard to general-ize to solve the codebook learning problem. From the viewpoint of multiple instance clustering, our proposed method is related to M 3 MIML (Zhang &amp; Zhou, 2008) and M 3 IC (Zhang et al., 2009) methods. However, both M 3 MIML and M 3 IC try to maximize the bag-level margin, we instead maximize the instance-level margin with the MIL constrains, which is quite dif-ferent from (Zhang &amp; Zhou, 2008; Zhang et al., 2009) in problem formulation, research motivation, and task objective. 3.1. Notation and Motivation We first briefly give the general notations of MIL (Di-etterich et al., 1997). In MIL, we are given a set of bags X = { X 1 ,...,X n } , each of which contains a set of instances X i = { x i 1 ,..., x im } ; and each instance is denoted as a d -dimensional vector x ij  X  R d  X  1 . In addition, every bag is also associated with a bag la-bel Y i  X  { 0 , 1 } ; and every instance is associated with an instance label y ij  X  { 0 , 1 } as well. The relation between bag label and instance labels is interpreted in the following way: if Y i = 0, then y ij = 0 for all j  X  [1 ,...,m ], i.e ., no instance in the bag is positive. If Y i = 1, then at least one instance x ij  X  X i is a positive instance of the underlying concept.
 To use MIL for dictionary learning, we consider an im-age as a bag, and a patch (or region) within the image as an instance. Given a set of images from multiple classes with the corresponding class labels, we treat the images of one typical class as positive images, and the rest ones as negative images. Intuitively, for each image, if it is labelled as positive, then at least one patch within it should be treated as a positive patch; while if it is labelled as negative, then all patches with-in it should be labeled as negative patches. Take the images in 15 Scene dataset (Lazebnik et al., 2006) as an example, if highway class is the positive class, then the mountain class falls into the negative class; image patches of sky appear in both classes will be treated as negative patches. As shown in Fig. 1, we assume pos-itive patches are drawn from multiple clusters , and we view negative patches from a separate negative cluster. The goal of this paper is to learn max-margin classi-fiers to classify all patches into different clusters, and illustrate the learned classifiers (G-codes) for image categorization/classification. Our dictionary learning problem involves two subproblems: (1) discriminative mixture model learning and (2) automatic instance la-bel assignment (which cluster a patch might belong to). It seems that MIL is a natural way to address the above problem. Hence, in the following, we will first give a naive solution, and then provide detailed formulation and solution to our proposed max-margin multiple-instance dictionary learning (MMDL) prob-lem. 3.2. A Naive Solution A naive way to use MIL for dictionary learning is to first run the standard MIL (e.g. mi-SVM) to select positive instances, then run a clustering algorithm to build the dictionary. In Fig. 2, we show a naive solu-tion based on the mi-SVM (Andrews et al., 2002) and k-means algorithm. This method typically treats mul-tiple instance learning and mixture models learning as two independent steps, which is not necessarily the optimal solution. In the following, we will introduce our formulation to perform these two steps simulta-neously, which is called max-margin multiple-instance dictionary learning (MMDL). 3.3. Formulation of MMDL In MMDL, we explicitly maximize the margins be-tween different clusters. To achieve this goal, we build the MMDL based on multi-class SVM, e.g ., Crammer and Singer X  X  multi-class SVM in (Crammer &amp; Singer, 2002). Without loss of generality, we simply adapt the linear classifier, which is defined as f ( x ) = w T x . Each cluster is then associated with a specific linear classi-fier. Due to the flexibility introduced by the multi-class SVM formulation, it X  X  very natural to allow all the classifiers to compete with each other during the learning process. In this paper, we introduce a cluster label as latent variable, z ij  X  X  0 , 1 ,...,K } , for each in-stance. If z ij = k  X  { 1 ,...,K } , instance x ij is in the k th positive cluster. Otherwise, z ij = 0, x ij is in the negative cluster. Furthermore, we also define a weight-ing matrix W = [ w 0 , w 1 ,..., w K ] , w k  X  R d  X  1 ,k  X  { 0 , 1 ,...,K } as linear classifiers stacked in each colum-n, where w k represents the k -th cluster model. Note that, w 0 denotes the negative cluster model. Hence, instance x ij can be classified by: With the above definitions, the objective function be-comes min ) s.t. if Y i = 1 , X In Eq. (2), the first term, P K k =0 k w k k 2 is for the margin regularization, while the second term is the multi-class hinge-loss denoted as ` ( W ; ( x ij ,z ij )). ` ( W ; ( x ij ,z ij )) = X Parameter  X  controls the relative importance between the two terms. The loss function ` ( W ; ( x ij ,z ij )) ex-plicitly maximizes soft-margins between all K + 1 clus-ters. Constraints in Eq. (2) are equivalent to con-straints in MIL. Because P j z ij &gt; 0  X  P j y ij &gt; 0 and z ij = 0  X  y ij = 0.
 This MMDL formulation leads to a non-convex op-timization problem. However, this problem is semi-convex (Felzenszwalb et al., 2010) since optimization problem becomes convex once latent information is specified for the instances in the positive bags. In (Felzenszwalb et al., 2010), a  X  X oordinate descend X  method is proposed to address this kind of problem, which guarantees to give a local optimum. Our prob-lem is even harder, since we do not know the number of positive instances in each positive bag. 3.4. Learning Strategies of MMDL At first, we denote training set as D = { X 1 ,...,X n } including all positive and negative bags for training. Then we define instance weight as follows: p p ij shows  X  X ositiveness X  of the instance. It is deter-mined by the maximal difference of SVM decision func-tion value between a positive cluster and the negative moid function is used for mapping the difference of SVM decision function value into the range of (0 , 1).  X  is a parameter for normalization.
 In the next step, we solve the problem in (2) using coordinate descend in a stochastic way which is sum-marized in Fig. 3. We form a new training set D 0 out of the original D by sampling instances from each bag based on p ij . Because latent variables are only effec-tive for instances in positive bags, we take all instances in negative bags into D 0 . In addition, we only sample p s portion of the instances per positive bag. Initially, the instance weights are equal for all positives. After the sampling step, the data set D 0 0 is used to train a standard multi-class SVM classifier f 0 . This com-pletes the Optimize W step. Once we get f 0 , we can apply it to the original positive bags to perform Update p ij and z ij step. Then, we sample another p s portion of instances from each positive bag based on the classification results, forming a new dataset D 0 1 and then obtain f 1 . This process is repeated until the desired number of iterations N is reached. Sampling instances according to their  X  X ositiveness X  makes sure that a portion of instances in positive bag have pos-itive instance labels. This satisfies the constraint in Eq. (2). In addition, this sampling procedure can also increase the efficiency of our optimization algorithm. A learned dictionary consists of a set of linear clas-sifiers (G-code classifiers) for different patch clusters from different image classes. Similar to the way in ob-ject bank (Li et al., 2010), our image representation is constructed from the responses of G-code classifiers. Our MMDL framework is illustrated in Fig. 4. Sup-pose there are M categories in the dataset, for each image category, we use the training images in this cat-egory as positive examples, and the rest training im-ages as negative examples. Through MMDL, K + 1 G-code classifiers are learned. Given an input image, patch-level image features are densely extracted. Sup-pose x is a local feature vector, response of x given by the k th G-code is w T k x ,k  X  { 0 , 1 ,...,K } . Thus, we can obtain a response map for each G-code classifier. For each response map, a three-level spatial pyramid representation (Lazebnik et al., 2006) is used, resulting in (1 2 + 2 2 + 4 2 ) grids; the maximal response for each G-code classifier in each grid is computed, resulting in M  X  ( K +1) length feature vector for each grid. A con-catenation of features in all grids leads to a compact image descriptor of the input image.
 Note that the complexity of feature encoding using G-codes is very low. It involves no more than a dot product operation. The benefit of using G-codes of low complexity is evident, since feature encoding is a time-consuming process in many classification system-s (Chatfield et al., 2011). For the high-level image classification tasks, our image representation achieves the state-of-the-art performance on several benchmark datasets. Dataset We evaluate the proposed MMDL method for image classification on three widely used dataset-s, including scene image (15 Scene (Lazebnik et al., 2006), MIT 67 Indoor (Quattoni &amp; A.Torralba, 2009) datasets), activity images (UIUC Sports dataset (Li &amp; Fei-Fei, 2007)). Experimental setting for the three datasets are listed below:  X  15 Scene: It contains 4,485 images divided into 15  X  MIT 67 Indoor: This dataset contains images  X  UIUC Sports: This is a dataset of 8 event classes. For the 15 Scene and UIUC Sports datasets, we ran-domly run experiments for 5 times, and record average and standard deviation of image classification accura-cies over all image classes.
 Experiment Setup For each image, image patches are densely sampled by every 16 pixels on image, under three scales, 48  X  48, 72  X  72, and 96  X  96. For each im-age patch, we resize it to 48  X  48 and compute five kind-s of features for describing it. The features are HoG, LBP, GIST (Oliva &amp; Torralba, 2001), encoded SIFT and LAB color histogram. For the HoG and LBP fea-tures, we use the implementation in VLFeat (Vedaldi &amp; Fulkerson, 2008); their dimensions are 279 and 522, respectively. For the GIST feature, we use the imple-mentation provided by the authors of (Oliva &amp; Torral-ba, 2001); its dimension is 256. When computing the encoded SIFT feature, we densely compute SIFT fea-ture at the size of 16 by every 6 pixels; then the SIFTs are quantized by a 100 bins via k-means by assigning each SIFT feature to its nearest entry in the cluster; a histogram is built on the quantized SIFTs; dimen-sion of the encoded SIFT feature is 100. For the LAB color histogram feature, we compute a 16 dimension histogram for each of the three channels. These five diverse features are normalized separately, concatenat-ed into a 1205 dimensional vector, and normalized by its ` 2 norm as local patch representation. In MMDL, the weight parameter  X  is set to 1; the number of it-erations N in the optimization algorithm in Fig. 3 is set to 5; the sampling portion p s is set to 0.7; and the normalization parameter  X  is set to 0.5. In the step of  X  X ptimize W  X , we use LibLinear (Fan et al., 2008) to solve this multi-class SVM problem. Training images of each dataset are used for learning our dictionary. The overall image representation is based on the de-scription in Sec. 4. LibLinear is also used for image classification after image representation is computed. 5.1. Nature Scene Image Classification: A In experiments on the 15 Scene dataset, we compare MMDL to k-means codebook learning, extremely ran-domized clustering forests (ERC-Forests) (Moosmann et al., 2008), the naive solution in Sec. 3.2, and some of the existing methods.
 In Fig. 5, X-axis shows the number of codewords of k-means or G-codes; Y-axis shows average classification accuracy (in percentage) of different test. HoG, LBP, GIST and encoded SIFT are tested separately with MMDL (using 165 G-codes, 11 G-codes per-class); av-erage classification accuracy of LBP (81.23%) is much higher than HoG (75.7%), encoded SIFT (74.74%) and GIST (74.27%). Fusing these four descriptors, we can obtain an improved accuracy of 86.35%. Color descrip-tor is not used in this dataset, because all images in this dataset are grey.
 Using multiple features, we also test traditional k-means codebook learning, ERC-Forests codebook learning and our baseline method, mi-SVM + k-means, in Sec. 3.2. Codebooks learned by k-means, ERC-Forests, and mi-SVM + k-means are used for locality-constrained linear coding (LLC) in (Wang et al., 2010) which is a popular state-of-the-art feature encoding method. Then we follow the pipeline in (Wang et al., 2010) for image classification. In Fig. 5, we observe that ERC-Forests works even worse than k-means in this situation. Our baseline method (mi-SVM + k-means in Fig. 2) works better than raw k-means method, since it can explore discriminative image fea-ture for each scene class. However, it is still worse than MMDL. Mi-SVM + k-means obtains an average classification accuracy of 85.06% using 1500 codeword-s, while the average classification accuracy of MMDL is 86.35% when only using 165 G-codes.
 We compare MMDL with some previous methods in Table. 1. Notice that in (Lazebnik et al., 2006) and (Bo et al., 2010) non-linear SVM is used for image classification; (Li et al., 2010), (Yang et al., 2009) and our method adopt linear SVM. We observe that the performance of our method is very close to the best performance obtained by kernel descriptors, with very small number of codewords using linear SVM.
 Learning G-codes using MMDL is computationally ef-ficient. In this dataset, learning 11 G-codes for one category takes about 8 minutes on a 3.40GHz com-puter with an i7 multi-core processor. In the testing stage, it takes about 0.8 second for patch-level fea-ture extraction, and takes less than 0.015 second for computing the image representation. The conclusions drawn from experiments on this dataset are general: 1. MMDL can naturally learn a metric to take the 2. The max-margin formulation leads to very com-5.2. Indoor Scene Image Classification In the experiment on MIT 67 Indoor dataset, for each of the 67 classes, we learn 11 G-codes, 10 for positive cluster and 1 for negative cluster. Therefore, we have 737 G-codes in total. Fig. 6 shows some cluster models learned in buffet and computer-room category. Take the computer-room category as an example: cluster 2 corresponds to computers; and cluster 8 corresponds to desks. Clusters are learned given no more than image class labels. But it seems that they are very semantic meaningful.
 Table. 2 summarizes the performances of our method and some previously published methods. Our perfor-mance is much better than traditional scene recogni-tion methods, such as (Quattoni &amp; A.Torralba, 2009; Zhu et al., 2010; Wu &amp; Rehg, 2011). Here we fo-cus on comparisons with three mid-level image rep-resentations, DPM (Pandey &amp; Lazebnik, 2011), R-BoW (Parizi et al., 2012), and Discriminative Patch-es (Singh et al., 2012). DPM, RBoW and our methods have used labels of training images for learning. Dis-criminative Patches method learns mid-level represen-tation in an unsupervised way. In (Singh et al., 2012), they combine Discriminative Patches with DPM, Gist-color, and SP and obtained a classification accuracy of 49.4%. Our much better performance indicates the efficiency and effectiveness of MMDL. 5.3. UIUC Sports Image Classification In this experiment, we report the performance result of event recognition in the UIUC Sports dataset. For each event category, we only learn 11 different G-codes. This results in 88 codewords in total for image representation. However, our performance is consis-tently better than object bank (requires detailed hu-man annotations) and two very recent approaches, L-PR (Sadeghi &amp; Tappen, 2012) and SPMSM (Kwit-t et al., 2012) as shown in Table. 3. In addition, a codebook learning method (Wu &amp; Rehg, 2009) using histogram intersection kernel has also been compared. In this paper, we have proposed a dictionary learning strategy along the line of multiple instance learning. We demonstrate the effectiveness of our method, which is able to learn compact codewords and rich semantic information.
 Acknowledgment: The work was supported by NSF CAREER award IIS-0844566, NSF award IIS-1216528, and NIH R01 MH094343. Part of this work was done while the first author was an intern at Mi-crosoft Research Asia. It is also in part supported by the National Natural Science Foundation of Chi-na (NSFC) Grants 60903096, 61173120 and 61222308. Xinggang Wang was supported by Microsoft Research c o m p u t e r -r o o m c o m p u t e r -r o o m Asia Fellowship 2012. We thank Jun Zhu, Liwei Wang, and Quannan Li for helpful discussions.

