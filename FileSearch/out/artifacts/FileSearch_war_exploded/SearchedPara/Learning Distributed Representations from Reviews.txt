 Recent work has shown that collaborative filter-based rec-ommender systems can be improved by incorporating side information, such as natural language reviews, as a way of regularizing the derived product representations. Motivated by the success of this approach, we introduce two different models of reviews and study their effect on collaborative fil-tering performance. While the previous state-of-the-art ap-proach is based on a latent Dirichlet allocation (LDA) model of reviews, the models we explore are neural network based: a bag-of-words product-of-experts model and a recurrent neural network. We demonstrate that the increased flexi-bility offered by the product-of-experts model allowed it to achieve state-of-the-art performance on the Amazon review dataset, outperforming the LDA-based approach. However, interestingly, the greater modeling power offered by the re-current neural network appears to undermine the model X  X  ability to act as a regularizer of the product representations. H.3.3 [ Information Search and Retrieval ]: Information filtering Recommender Systems; Neural Networks; Deep Learning
Recommendation systems are a crucial component of many e-commerce enterprises, providing businesses with metrics to direct consumers to items they may find appealing. A gen-eral goal of these systems is to predict a user X  X  preference for a certain product, often represented as an integer-valued rating, e.g., between 1 (unsatisfied) and 5 (satisfied).
In order to predict the user X  X  preference for a product, it is often beneficial to consider as many sources of information as possible, including the preference of the user for other products, the preferences of other users, as well as any side c  X  information such as characteristics of each user and prod-uct. A data-driven approach based on this idea is called collaborative filtering .

Collaborative filtering has been successfully used for rec-ommendation systems (see, e.g., [17]). A typical approach to using collaborative filtering for recommendation systems is to consider all the observed ratings given by a set of users to a set of products as elements in a matrix, where the row and column of this matrix correspond to users and products, re-spectively. As the observed ratings is typically only a small subset of the possible ratings (all users rating all products), this matrix is sparse. The goal of collaborative filtering is to fill in the missing values of this matrix: to predict, for each user, the rating of products the user has not rated. In this setting, collaborative filtering is usually cast as a problem of matrix factorization with missing values [10, 16, 18]. The sparse matrix is factorized into a product of two matrices of lower rank representing a user matrix and a product matrix. Once these matrices are estimated, a missing observation can be trivially reconstructed by taking a dot product of a corresponding user vector (or representation) and a product vector (or representation).

In this formulation of collaborative filtering, an important issue of data sparsity arises. For instance, the dataset pro-vided as a part of the Netflix Challenge 1 had only 100,480,507 observed ratings out of more than 8 billion possible ratings (user / product pairs) meaning that 99% of the values were missing. This data sparsity easily leads to naive matrix fac-torization overfitting the training set of observed ratings [10].
In this paper, we are interested in regularizing the col-laborative filtering matrix factorization using an additional source of information: reviews written by users in natural language. Recent work has shown that better rating predic-tion can be obtained by incorporating this kind of text-based side information [13, 12, 1]. Motivated by these recent suc-cesses, here we explore alternative approaches to exploiting this side information. Specifically, we study how different models of reviews can impact the performance of the regu-larization.

We introduce two approaches to modeling reviews and compare these to the current state-of-the-art LDA-based ap-proaches [13, 12]. Both models have previously been studied as neural-network-based document models. One is based on the Bag-of-Words Paragraph Vector [11]. This model is sim-ilar to the existing LDA-based model, but, as we argue, it offers a more flexible natural language model. The other is http://www.netflixprize.com/ 480,189 users and 17,770 movies a recurrent neural network (RNN) based approach. RNNs have recently become very popular models of natural lan-guage for a wide array of tasks [11]. Here we will find that despite the considerable additional modelling power brought by the RNN, it does not offer better performance when used as a regularizer in this context.
 The proposed approaches are empirically evaluated on the Amazon Reviews Dataset [13]. We observe that the pro-posed bag-of-words language model outperforms the existing approach based on latent Dirichlet allocation (LDA, [4]). We also confirm the use of an RNN language model does not lead to improved performance. Overall, our experiments demon-strate that, in this particular application where we rely on the document model to regularize the collaborative filtering matrix factorization, controlling the model flexibility is very important.

We also make methodological contributions in studying the effect of the train / test splits used in experimentation. Previous works on this subject (e.g. [13], [12] and [1]), do not clearly identify how the data was split into train and test sets. Here we empirically demonstrate the importance of doing so. We show that for a given fixed split, conclusions regarding the relative performance of competing approaches do generalize to other splits, but comparing absolute perfor-mance across difference splits is highly problematic. Let us assume that we are given a set R = { r u,i } ( u,i )  X  O of observed ratings, where r u,i  X  { 1 , 2 ,  X  X  X  , 5 } is the rating given by the user u to the product i . Collaborative filtering aims at building a model that is able to predict the rating of an unobserved user-product pair, i.e., r u,i where ( u,i ) /  X  O
In collaborative filtering based on matrix factorization, we estimate each user-product rating as where  X  ,  X  i and  X  u are a global bias, a user-specific bias for the user u and a product-specific bias for the product i , respectively. The vectors  X  u and  X  i are the latent factors of the user u and the product i respectively.

We estimate all the parameters in the r.h.s of Eq. (1) by minimizing the mean-squared error between the predicted ratings and the observed, true ratings: where  X  = n  X , {  X  u } N u =1 , {  X  i } M i =1 , {  X  u } N
Once the parameters  X  are estimated by minimizing C R , it is straightforward to predict the rating of an unobserved user-product pair ( u,i ) using Eq. (1).
It has been observed earlier, for instance in [10], that this matrix factorization approach easily overfits the observed ratings, leading to poor generalization performance on the held-out set, or unseen user-product pairs. This issue is especially serious in the case of recommendation systems, as it is highly likely that each user purchases/watches only a fraction of all the available products. For instance, in the Amazon Reviews Dataset more than 99.999% of ratings, or elements in the rating matrix are missing.

The issue of overfitting is often addressed by adding a regularization term  X  to the cost C R in Eq. (2). One of the most widely used regularization term is a simple weight decay Hence parameters are estimated by minimizing C R (  X  ) +  X   X (  X  ), where  X  is a regularization coefficient.
Another approach is to interpret matrix factorization in a probabilistic framework [10, 16, 18]. In this approach, all the parameters such as the user and product represen-tations are considered as latent random variables on which the distribution of the rating, an observed random variable, is conditioned. This probabilistic matrix factorization can automatically regularize itself by maintaining the confidence of the estimates/predictions based on the observations.
On the other hand, we can improve generalization, hence reduce overfitting, by simultaneously estimating the param-eters  X  of the matrix factorization to perform well on another related task [5]. With a model predicting a rating by a user on a product, we can consider letting the model also try to account for the product review given by the user. This seems like a useful side task as users often write reviews that justify their ratings and describe features that affected their opinions.

In this paper, we explore this approach of exploiting extra tasks to improve generalization performance of collaborative filtering based on matrix factorization.
In many e-commerce systems, each rating is often accom-panied with a user X  X  review of the product. As mentioned earlier, it is natural to expect that the accompanying re-view is used by the user to justify her/his rating or opinion, which suggests the possibility of improving the generaliza-tion performance of the prediction model for ratings [13]. As an illustrating example, a user, who wrote  X  X his is a great adventure movie that children and adults alike would love! X  for the movie  X  X ree Willy X , is likely to give a higher rating to this movie. 3
In this section, we will propose two approaches to utilizing this type of review data for improving the generalization performance of a rating prediction model based on matrix factorization.
More technically, let us suppose that the set R of ratings (see Sec. 2) is accompanied with a set D of reviews D = { d piece of natural language text written by a user u about an item i , which we represent as a sequence of words.
Following the multitask learning framework [5], we build a model that jointly predicts the rating given by a user u to a product i and models the review written by the user u
This is an actual sample from the Amazon Reviews datat-set. on the product i . The model has two components; matrix factorization in Eq. (1) and review modeling, which shares some of the parameters  X  from the rating prediction model.
Here, we follow the approach from [13] by modeling the conditional probability of each review given the correspond-ing product  X  i : where  X  D is a set of parameters for this review model.
We estimate the parameters of this review model (  X  D and  X   X  X ) by minimizing the negative log-likelihood: where C
We jointly optimize the rating prediction model in Eq. (1) and the review model in Eq. (3) by minimizing the convex combination of C R in Eq. (2) and C D in Eq. (4): where the coefficient  X  is a hyperparmeter.
The first model we propose to use is a distributed bag-of-words prediction. In this case, we represent each review as a bag of words, meaning This leads to
We model p ( w ( t ) u,i |  X  i ) as an affine transformation of the product representation  X  i followed by, so-called softmax, normalization: where and V , W and b are the vocabulary, a weight matrix and a bias vector. The parameters  X  D of this review model include W and b .

When we use this distributed bag-of-words together with matrix factorization for predicting ratings, and we call this joint model the bag-of-words regularized latent factor model (BoWLF).
The second model of reviews we propose to use is a re-current neural network (RNN) language model (LM) [14]. Unlike the distributed bag-of-words model, this RNN-LM does not make any assumption on how each review is rep-resented, but takes a sequence of words as it is, preserving the order of the words.

In this case, we model the probability over a review which is a variable-length sequence of words by rewriting the prob-ability as
We approximate each conditional distribution with where and
There are a number of choices available for implementing the recurrent function  X  . Here, we use a long short-term memory (LSTM, [9]) which has recently been applied suc-cessfully to natural language-related tasks [7].

In the case of the LSTM, the recurrent function  X  returns, in addition to its hidden state h ( t ) , the memory cell c that where The output o , forget f and input i gates are computed by  X   X  and the new memory content  X  c ( t ) by where E , V g , W g , U g , b g , V c , W c , U c , b c , A the parameters of the RNN-LM. Note that E [ w ] denotes a row indexing by the word index w of the matrix E .
Similarly to the BoWLF, we call the joint model of matrix factorization and this RNN-LM the language model regular-ized latent factor model (LMLF).
Similar approaches of modeling reviews to regularize ma-trix factorization have recently been proposed, however, with different review models such as LDA [13, 12] and non-negative matrix factorization [1]. Here, we describe  X  X idden Factors as Topics X  (HFT) recently proposed in [13], and discuss it with respect to the proposed approaches.

The HFT model is based on latent Dirichlet allocation (LDA, [4]), and similarly to the distributed bag-of-word model in Sec. 3.2.1, considers each review as a bag of words (see Eq. (7).) Thus, we start by describing how LDA models a review d u,i .

LDA is a generative model of a review/document. It starts by sampling a so-called topic proportion  X  from a Dirichlet distribution.  X  is used as a parameter to a multinomial topic distribution from which a topic is sampled. The sam-pled topic defines a probability distribution over the words in a vocabulary. In other words, given a topic proportion, the LDA models a review with a mixture of multinomial distributions.

Instead of sampling the topic proportion from the top-level Dirichlet distribution in LDA, HFT replaces it with where  X  is a free parameter estimated along with all the other parameters of the model. In this case, the probability over a single review d u,i given a product  X  i becomes where z k is an indicator variable of the k -th topic out of dim(  X  i ), and  X  k is the k -th element of  X  . The conditional probability over words given a topic is modeled with a stochas-The conditional probability over words given a product  X  i can be written as The matrix W  X  is often parametrized by w  X  j,k = exp { q where Q = [ q j,k ] is an unconstrained matrix of the same size as W  X  . In practice, a bias term is added to the formulation above to handle frequent words.
From Eq. (8) and Eq. (12), we can see that the HFT and the proposed BoWLF (see Sec. 3.2.1) are closely re-lated. Most importantly, both of them consider a review as a bag of words and parametrize the conditional probability of a word given a product representation with a single affine transformation (weight matrix plus offset vector).
The main difference is in how the product representation and the weight matrix interact to form a point on the | V | -dimensional simplex. In the case of HFT, both the product representation  X  i and the projection matrix W  X  are sepa-rately stochastic (i.e. each  X  i and each column of W  X  are in-terpretable as a probability distribution), while the BoWLF projects the result of the matrix-vector product W  X  i onto the probability simplex.

This can be understood as the difference between a mix-ture of experts and a product of experts [8]. On a per word basis, the BoWLF in Eq. (8) can be re-written as a (condi-tional) product of experts by where w j,k and b j are the element at the j -th row and k -th column of W and the j -th element of b , respectively. On the other hand, an inspection of Eq. (11) reveals that, on a per word basis, the HFT model is clearly a mixture model, with the topics playing the role of the mixture components.
As argued in [8], a product of experts can more easily model a peaky distribution, especially, in a high-dimensional space. 4 The reviews of each product tend to contain a small common subset of the whole vocabulary, while those subsets vastly differ from each other depending on the product. In other words, the conditional distribution of words given a product puts most of its probability mass on only a few product-specific words, while leaving most other words with nearly zero probabilities. Product of experts are naturally better suited to modeling peaky distributions rather than mixture models.

A more concrete way of understanding the difference be-tween HFT and BoWLF may be to consider how the product representation and the weight matrix interact. In the case of the BoWLF, this is a simple matrix-vector product with no restrictions on the weight matrix. This means that both the product representation elements as well as the elements of the weight matrix are free to assume negative values. Thus, it is possible that an element of the product representation could exercise a strong influence suppressing the expression of a given set of words. Alternatively, with HFT model, as the model interprets the elements of the product representa-tion as mixture components, these elements have no mech-anism of suppressing probability mass assigned to words by the other elements of the product representation.

We suggest that this difference allows the BoWLF to bet-ter model reviews compared to the HFT, or any other LDA-based model by offering a mechanism for negative correla-tions between words to be explicitly expressed by elements of the product representation. By offering a more flexible and natural model of reviews, the BoWLF model can im-prove the rating prediction generalization performance. As we will see in Sec. 4, our experimental results support this proposition.

The proposed LMLF takes one step further by modeling each review with a chain of products of experts taking into account the order of words. This may seem an obvious ben-efit at the first sight. However, it is not clear whether the order of the words is specific to a product or is simply a feature of language itself. In the latter case, we expect that LMLF will model reviews very well, but may not improve rating prediction.
We evaluate the proposed approaches on the Amazon Re-views dataset [13]. 5 There are approximate 35 million rat-ings and accompanying reviews from 6,643,669 users and
Note that the size of a usual vocabulary of reviews is on the order of thousands. https://snap.stanford.edu/data/web-Amazon.html 2,441,053 products. The products are divided into 28 cate-gories such as music and books. The reviews are on average 110 words long. We refer the reader to [12] for more detailed statistics.
We closely follow the procedure from [13] and [12], where the evaluation is done per category. We randomly select 80% of ratings, up to two million samples, as a training set, and split the rest evenly into validation and test sets, for each category. We preprocess reviews only by tokenizing them using a script from Moses 6 , after which we build a vocabulary of 5000 most frequent words.

We use mean squared error (MSE) of the rating prediction to evaluate each approach. For assessing the performance on review modeling, we use the average negative log-likelihood. We compare the two proposed approaches, BoWLF (see Sec. 3.2.1) and LMLF (see Sec. 3.2.2), against three baseline methods; matrix factorization with L 2 regularization (MF, see Eqs. (1) X (2)), the HFT model from [13] (see Sec. 3.3) and the RMR model from [12]. In the case of HFT, we report the performance both by evaluating the model ourselves and by reporting the results from [13] directly. For RMR, we only report the results from [12].

Both user  X  u and product  X  i vectors in Eq. (1) are five dimensional for all the experiments in this section. This choice was made mainly to make the results comparable to the previously reported ones in [13] and [12].

We initialize all the user and product representations by sampling each element from a zero-mean Gaussian distri-bution with its standard deviation set to 0.01. The biases,  X  ,  X  u and  X  i are all initialized to 0. All the parameters in BoWLF and LMLF are initialized similarly except for the recurrent weights of the RNN-LM in LMLF which were ini-tialized to be orthogonal.
 When training MF, BoWLF and LMLF, we use minibatch RMSProp with the learning rate, momentum coefficient and the size of minibatch set to 0 . 01, 0 . 9 and 128, respectively. We trained each model at most 200 epochs, while monitoring the validation performance. For HFT, we follow [13] which uses the Expectation Maximization algorithm together with L-BFGS. In all cases, we early-stop each training run based on the validation set performance.

In the preliminary experiments, we found the choice of  X  in Eq. (6), which balances matrix factorization and review modeling, to be important. We searched for the  X  that max-imizes the validation performance, in the range of [0 . 1 , 0 . 01].
We used a CPU cluster of 16 nodes each with 8 cores and 8  X  16 GB of memory to run experiments on BoWLF, MF, https://github.com/moses-smt/mosesdecoder/
The code was kindly provided by the authors of [13]. and HFT. For LMLF, we used a cluster of K20 GPUs where we had up to 50 GPUs available.
We list results of the experiments in Table 1 for the 28 categories in terms of MSE with the standard error of mean shown in parentheses. From this table, we can see that ex-cept for a single category of  X  X ewelry X , the proposed BoWLF outperforms all the other models with an improvement of 20.29% over MF and 5.64% over HFT across all categories. 8 In general, we note better performance of BoWLF and LMLF models over other methods especially as the size of the dataset grows, which is evident from Figs. 1 and 2.
 Figure 1: Scatterplot showing performance improve-ment over the number of samples. We see a perfor-mance improvement of BoWLF over HFT as dataset size increases.
 Figure 2: Scatterplot showing performance improve-ment over the number of samples. We see a modest performance improvement of LMLF over HFT as dataset size increases.
Due to the use of different splits, the results by HFT re-ported in [13] and RMR in [12] are not directly comparable.
Interestingly, BoWLF always outperforms LMLF. These results indicate that the complex language model, which the LMLF learns using an LSTM network, does not seem to im-prove over a simple bag-of-word representation, which the BoWLF learns, in terms of the learned product representa-tions.

This can be understood from how the product representa-tion, which is used linearly by the rating prediction model, is handled by each model. The word distribution modeled by the BoWLF depends linearly on the product representation, which requires the product-related structure underlying re-views be encoded linearly as well. On the other hand, LMLF nonlinearly manipulates the product representation to ap-proximate the distribution over reviews. In other words, the LMLF does not necessarily encode the underlying product-related structure inside the product representation in the way the rating prediction model can easily decode [15].
Comparing the results of the original HFT paper with the results we get training over the same split, it becomes clear that models trained on different splits are not directly comparable. To further explore the importance of the chosen split for model selection, we perform experiments over five randomly selected folds and compare each model on every fold.
 One of the challenges in pursuing empirical work on the Amazon review dataset is the current absence of a standard Figure 3: Box and whisker plot showing K-fold ( K = 5 ) experiments. Point represents the mean over all folds. Center line represents median. Box extents represent 25 th and 75 th percentile. Whisker extents show minimum and maximum values. Figure 4: Bar chart showing showing K-fold ( K = 5 ) experiments. Although values across folds vary, relative performance is consistent. train / test split of the data. Here we evaluate the impor-tance of establishing a standard data split.

Fig. 3 shows the results of experiments comparing the per-formance of each model over different splits. We perform 5-fold validation. That is, each model is trained 5 times, each on 80% of the data and we report performance on the remaining 20%. The result on the test reveal several im-portant points. First, we note that the variance over splits can be large, meaning that comparing across different splits could be misleading when performing model selection. On the other hand, as shown in Fig 4, the relative performance of each model is consistent over the different splits. This implies that a single random split can be used for model se-lection and evaluation as long as this split is held constant over all evaluated models.

Taken together, Figs. 3 and 4 illustrate the importance of standardizing the dataset splits. Without standardization, performance measured between different research groups be-comes incomparable and the use of this dataset as a bench-mark is rendered difficult or even impossible.
One way to analyze models which use text information is to compare their negative log-likelihood (NLL) scores on the same test dataset. We find BoWLF has a stronger language model than HFT, which is reflected in the NLL results, and in this case it appears to contribute to a better rating predic-tion. As shown in Fig. 5, LMLF has a much better language model than both HFT and BoWLF, but as discussed ear-lier, LMLF does not lead to better rating predictions than BoWLF. LMLF appears to be largely equivalent to HFT in prediction strength, despite having a much better lan-guage model. As discussed above in Sec. 4.3, this suggests that the strong nonlinearity in the LSTM helps modeling Figure 5: Bar chart showing showing negative log-likelihood (NLL) on test data for several datasets. LMLF is superior in NLL but does not improve rat-ing prediction over BoWLF. reviews, but not necessarily result in the linearly-decodable product representation, leading to less improvement in rat-ing prediction.

Contrary to LDA-based approaches, the latent dimensions of the product representations learned by BoWLF do not necessarily have clear interpretations as topics. However, the neighborhoods learned by BoWLF are interpretable, where we use the cosine distance between two product representa-bors seem qualitatively superior to the neighbors given by HFT as seen in Table 2. Note in particular the association of  X  X TR Simply Tomato Soup X  with other soups by BoWLF, while HFT neighbors seem much broader, including crack-ers, noodles, and gummy bears. This observation is consis-tent with the interpretation of the differences in the math-ematical form of HFT and BoWLF (as argued in Sec. 3.4). The ability of BoWLF to form peakier distributions over words, given the product representation, allows the model to be more discriminating and more closely group similar products. Furthermore, we can see that the neighbors based on the product representations from the LMLF are qualita-tively worse than those from the BoWLF, which indirectly confirms that the underlying product-related structure en-coded by the LMLF is more difficult to extract linearly.
While drawing firm conclusions from this small set of neighbors is obviously ill-advised, the general trend appears to hold in more extensive testing. Broadly speaking, this further strengthens the idea that stronger product represen-tations lead to improvements in rating prediction.
We develop two new models (BoWLF and LMLF) which exploit text reviews to regularize rating prediction on the Amazon Reviews datasets. BoWLF achieves state of the art results on 27 of the 28 datasets, while LMLF outperforms HFT (but not BoWLF) as dataset size increases. Addition-ally, we explore the methodology behind the choice of data split, clearly demonstrating that models trained on differ-ent data subsets cannot be directly compared. Performing K-fold crossvalidation ( K = 5), we confirm that BoWLF achieves superior performance across dataset splits. The re-sulting product neighborhoods measured by cosine similar-ity between product representations are intuitive, and cor-respond with human analysis of the data. Overall we find that BoWLF has a 20 . 29% average improvement over basic matrix factorization and a 5 . 64% average improvement over HFT.

We found that the proposed LMLF slightly lagged behind the BoWLF. As we discuss above, we believe this could be due to the nonlinear nature of language model based on a recurrent neural network. This nonlinearity results in the product-related structure underlying reviews being nonlin-early encoded in the product representation, which cannot be easily extracted by the linear rating prediction model. However, this will need to be further investigated in addi-tion to analyzing the exact effect of language modeling on prediction performance.
 We would like to thank the developers of Theano [3, 2] and Pylearn2 [6], for developing such a powerful tool for scien-tific computing. We are grateful to Compute Canada and Calcul Qu  X ebec for providing us with powerful computational resources. [1] Y. Bao, H. Fang, and J. Zhang. TopicMF: [2] F. Bastien, P. Lamblin, R. Pascanu, J. Bergstra, I. J. [3] J. Bergstra, F. Bastien, O. Breuleux, P. Lamblin, [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [5] R. Caruana. Multitask learning. Machine learning , [6] I. J. Goodfellow, D. Warde-Farley, P. Lamblin, [7] A. Graves. Generating sequences with recurrent neural [8] G. E. Hinton. Products of experts. In Proceedings of [9] S. Hochreiter and J. Schmidhuber. Long short-term [10] A. Ilin and T. Raiko. Practical approaches to principal [11] Q. V. Le and T. Mikolov. Distributed representations [12] G. Ling, M. R. Lyu, and I. King. Ratings meet [13] J. McAuley and J. Leskovec. Hidden factors and [14] T. Mikolov. Statistical Language Models based on [15] T. Mikolov, K. Chen, G. Corrado, and J. Dean. [16] A. Mnih and R. Salakhutdinov. Probabilistic matrix [17] F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor. [18] R. Salakhutdinov and A. Mnih. Bayesian probabilistic
