 Information integration has been a subject of research for several decades and still remains a very active research area. Many new applications depend or benefit from large scale in-tegration. Examples include large research projects in life sciences, need for data sharing among government agencies, reliance of corporations on business intelligence (which re-quires data integration from many heterogeneous sources), and integration of information on the web. The impor-tance of information integration with uncertainty has been observed in recent years. Frequently, information from mul-tiple sources are uncertain and possibly inconsistent. Fur-ther the process of integration often depends on approxi-mate schema mappings, another source of uncertainty. An integration system is useful only to the extent that the in-formation it produces can be trusted. Hence, providing a measure of certainty for integrated information is of crucial importance in many important applications.

In this paper we study the problem of integration of un-certain information. We present a simple and intuitive ap-proach to the representation and integration of uncertain information from multiple sources, and show that our in-tegration approach coincides with a recent formalism for uncertain information integration. We extend the model to probabilistic possible-worlds, and show certain unintu-itive constraints are imposed upon probabilities of possible-worlds of sources. In particular, we show the probabilities of possible worlds of a source are not independent, rather, they are dependent on probabilities of other sources. We study the problem of determining the probabilities for the result of integration. Finally, we present a practical approach to relaxing probabilistic constraints in integration. H.2 [ Database Management ]: [Miscellaneous] Theory Information integration, uncertain data, probabilistic data.
Information integration has been a subject of research for several decades, and despite significant progress, in particu-lar in recent years, it still remains a very active research area [24, 28]. Many new applications depend or benefit from large scale integration. Examples include large research projects in life sciences (such as biological and astronomy research), need for data sharing among government agencies, reliance of corporations on business intelligence (which requires data integration from many heterogeneous sources), and integra-tion of information on the web [25]. The importance of in-formation integration with uncertainty has been observed in recent surveys on information integration [24, 28, 34, 35]. The following quote is from [28]: Frequently, information from multiple sources are uncertain and possibly inconsistent. Further the process of integra-tion often depends on approximate schema mappings, an-other source of uncertainty. An integration system is useful only to the extent that the information it produces can be trusted. Hence, providing a measure of certainty for inte-grated information is of crucial importance in many impor-tant applications.

In this paper we study the problem of integration of un-certain information. Our contributions include:
This paper is organized as follows. We start with a mo-tivating example in Section 2, and discuss issues involved in uncertain information integration. Then we revisit the well-known possible-worlds framework for uncertain infor-mation in Section 3. We introduce a simple and intuitive logical representation of possible worlds, and present an al-gorithm for information integration using this representa-tion (Sections 3.2 and 3.3), and show the correspondence of integration using logical representation with integration based on the concept of superset containment of [2] (Sec-tion 3.4). In Section 4 we extend the integration framework to probabilistic possible worlds model, and show that cer-tain restrictive constraints are imposed on the probabilities assigned by sources to their possible worlds. Then we study the problem of determining the probabilities for the result of integration, and present a practical approach to relaxing probabilistic constraints in integration (Section4.2). We re-view related work in Section 5 and present conclusions and future work in Section 6.
Example 1. Consider information sources S1 and S2 con-taining data about student registrations. Source S1 states that Bob is taking CS100 or CS101 (but not both). Source S2 states that Bob is taking CS101 or CS 102 (but not both). How do we integrate the information from S1 and S2?
This is a very simple example, yet, as we will see, certain questions arise when we attempt the integration. First, let us look at how the information in sources S1 and S2 are represented. The possible worlds model [1] has been widely accepted as the conceptual model of uncertain information. In this model, the information represented by each source is (conceptually) considered as a set of database instances, each instance being a possible state of the real world. In our example, each database instance for source S1 consists of a single relation. The possible worlds of S1 are shown in Figure 1. Possible worlds of S2 are similar and are shown in Figure 2.
In practice, a compact representation, such as probabilis-tic databases [11, 12] or U-Relational Model [3], is chosen that avoids enumerating all possible worlds, and, hopefully, permits efficient information integration and query process-ing. We will not address the issue of compact representa-tion in this paper. Rather, we concentrate our discussion on the fundamental problems of information integration. Inter-ested readers are referred to [44, 45] for a detailed discussion regarding representations of uncertain data and their prop-erties.
When integrating information from multiple sources with definite data, the usual approach is to form the union of corresponding relations from the sources. For example, if S3 stated that Bob is (definitely) taking CS100 and S4 stated that Bob is (definitely) taking CS102, then the integration would state that Bob is taking both CS100 and CS102. Let us apply the union approach to uncertain case. A pairwise union of possible worlds of S1 and S2 in our first example yields the following four possible worlds: Figure 3: A Possible Result of Integrating Sources S1 and S2
Is this the correct answer to integrating S1 and S2? As we will see, in some cases it is although there are many cases where it is not the correct answer.
Scenario 1. John and Jane are talking about fellow stu-dent Bob. John says  X  X  am taking CS100 and CS101 and Bob is in one of them, but I am not sure which one. X  Note that John X  X  statement coincides with source S1. Namely, Bob is taking CS100 or CS 101 (but not both).

Jane says  X  X  am taking CS101 and CSC102 and Bob is in one of them, but I am not sure which one. X  Jane X  X  statement coincides with source S2.

How do we integrate John X  X  and Jane X  X  statements? In-tuitively, the combination of John and Jane X  X  statements indicate that Bob is either taking CS101, or he is taking both CS100 and CS102. If we compare this with the four possible worlds of Figure 3 which were obtained by pairwise union operation, we note that the first and fourth possible worlds are ruled out. This is due to the fact that John X  X  statement implies Bob is not in both CS100 and CS101, rul-ing out the first possible world. Similarly, Jane X  X  statement implies Bob is not in both CS101 and CS102, ruling out the fourth possible world. Note that these observations, that John X  X  statement implies that Bob is not in both CS100 and CS101 and Jane X  X  statement implies that Bob is not in both CS101 and CS102 are evident from the possible worlds rep-resentations (Figures 1 and 2).

Scenario 2. Andy and Amy are talking about fellow stu-dent Bob. Andy says X  X  am taking CS100, CS101, and CS102 and Bob is in either CS100 or CS101 but not in both. X  Note that Andy X  X  statement coincides with source S1. Addition-ally, his statement implies that Bob is not taking CS102. This fact is not evident from the possible worlds represen-tation (Figure 1). Amy X  X  statement is the same as Jane X  X  statement. It coincides with source S2.

In this case, the integration is that Bob is in CS101. The first and last possible worlds in the pairwise union are ruled out as in the previous scenario. Additionally, the second possible world in the pairwise union is ruled out by Andy X  X  statement as well.
The examples of previous section, in particular Scenario 2, demonstrate that the  X  X ure X  possible worlds model is not sufficient for information integration applications. In this section we explore an extension to the possible worlds model that makes it better suited for integration.
The model used in [2] adds the set of all tuples to the pure possible worlds model. The following definition is taken from [2]. Note that, for simplicity, each database is assumed to contain a single relation scheme. We adopt the same assumption. Extension to the usual case is straightforward.
Definition 1. (Uncertain Database). An uncertain database U consists of a finite set of tuples T ( U ) and a nonempty set of possible worlds PW ( U )= { D 1 ,...,D m } where each D i  X  T ( U ) is a certain database.

The addition of the tuple-set makes it possible to represent some negative information that is not possible to represent in the pure possible-worlds model. For example, consider Sce-nario 2 in Section 2.2. Recall that Andy X  X  statement implies that Bob is not taking CS102. While this information can not be represented in the pure possible-worlds model (Fig-ure 1), adding that corresponding tuple-set contains (Bob, CS102) makes this information explicit (that Bob is not tak-ing CS 102). We explain this further below.
In this section we present a logical representation of possible-worlds with tuple-set model that helps clarify the semantics and expressive power of this model.

Given an uncertain database U , we assign a propositional variable x i to each tuple t i  X  T ( U ). We define the formula f corresponding to a possible world D j ,andtheformula f corresponding to the uncertain database U as follows:
Definition 2. (Formula Corresponding to an Un-certain Database). Let D j be a database in the possible worlds of uncertain Database U . Construct a formula as the conjunction of all variables x i where the corresponding tuple t is in D j , and the conjunction of  X  x i where the correspond-ing tuple t i is not in D j . That is, The formula corresponding to the uncertain database U is the disjunction of the formulas corresponding to the possible worlds of U . That is,
Example 2. (Formula Corresponding to an Uncer-tain Database). Consider our Scenario 1 in Section 2.2. John X  X  statement was captured in the possible-worlds repre-sentation of Figure 1. In this case, the tuple set for source S1 (John) consists of two tuples, { (Bob, CS100), (Bob, CS101) Let variable x 1 and x 2 correspond to each of these tuples, respectively. Then the formula for the first possible world, second possible world, and the database are, respectively, x  X  X  x 2 ,  X  x 1  X  x 2 ,and ( x 1  X  X  x 2 )  X  (  X  x 1  X  x 2 ) . Now consider Scenario 2. The difference in this case is Andy X  X  knowledge regarding CS102. Here, the tuple set for Andy X  X  information consists of three tuples, { (Bob, CS100), (Bob, CS101), (Bob, CS102) } .Let x 1 ,x 2 ,x 3 correspond to these three tuples. Then the formula corresponding to the uncertain database representing Andy X  X  statement is ( x 1  X  x 2  X  X  x 3 )  X  (  X  x 1  X  x 2  X  X  x 3 ) . This is despite the fact that the pure possible worlds representation of Andy X  X  statement is the same as the representation of John X  X  statement in Sce-nario 1 (Figure 1). Let S 1 ,...,S n be sources containing (uncertain) databases U ,...,U n . Let the propositional formulas corresponding to U ,...,U n be f 1 ,...,f n . We obtain the formula f corre-sponding to the uncertain database resulting from integrat-ing U 1 ,...,U n by conjuncting the formulas of the databases: f = f 1  X  X  X  X  X  f n .

Example 3. (Integration Using Logical Represen-tation). Consider Scenario 1 of Section 2.2. Uncertain database corresponding to John X  X  statement is represented by formula ( x 1  X  X  x 2 )  X  (  X  x 1  X  x 2 ) (see Example 2). Similarly, the uncertain database corresponding to Jane X  X  statement is represented by formula ( x 2  X  X  x 3 )  X  (  X  x 2  X  x 3 ) ,where responds to tuple (Bob, CS102). The integration is obtained as (( x 1  X  X  x 2 )  X  (  X  x 1  X  x 2 ))  X  (( x 2  X  X  x 3 )  X  (  X  x which corresponds to possible world databases of Figure 4. Note that the result is consistent with our intuition in Sce-nario 1: Based on statements by John and Jane, Bob is either taking CS101, or he is taking both CS100 and CS102.
In contrast, consider Scenario 2. The uncertain database corresponding to Andy X  X  statement is represented by ( x 1  X  x 2  X  X  x 3 )  X  (  X  x 1  X  x 2  X  X  x 3 ) (Example 2). The integration in this case is obtained as (( x 1  X  X  x 2  X  X  x 3 )  X  (  X  x 1  X  x 2  X  X  x 3 ))  X  (( x 2  X  X  x corresponding to the (in this case, definite) database consist-ing only of the first database in Figure 4. Again, the result is consistent with our intuition in Scenario 12: Based on statement by Andy and Amy, Bob is taking CS101.
In this section we show that our integration approach co-incides with a recent formalism for uncertain information integration [2]. First, we review some definitions from [2].
Definition 3. (Superset-Containment) Consider un-certain databases U 1 and U 2 . We say that U 2 superset-contains U 1 ,denoted U 1 S U 2 ,ifandonlyif:
The following definition is a simplified version of a defi-nition in [2]. We have restricted the definition to identity views and queries, and have concentrated on superset con-tainment.

Definition 4. (Consistent Mediated Database) The set of sources S = { S 1 ,...,S m } with (uncertain) databases U ,...,U n is consistent if and only if there exists an uncer-tain database M such that: M is called a consistent mediated database for S (under superset containment).

Intuitively, a consistent mediated database is a possible integration of the sources. Note that we are assuming each source database consists of a single uncertain relation, and the mediated database is also a single uncertain relation.
Example 4. (Consistent Mediated Database) Con-sider sources S1 and S2 of Figures 1 and 2. It is easy to verify that the database of Figure 4 is indeed a mediated database of S1 and S2 under scenario 1. Note that tuple sets for the sources and for the mediated database are, respec-tively, T 1 = { (Bob, CS100), (Bob, CS101) } , T 2 = { (Bob, CS101), (Bob, CS102) } ,and T M = { (Bob, CS100), (Bob, CS101), (Bob, CS102) } .

A set of uncertain sources can have many consistent me-diated databases. We are interested in a mediated database (which we call the integrated database) that contains all the information implied by sources and nothing more.

Definition 5. (Integrated Database) Given a set of sources S = { S 1 ,...,S m } ,their integrated database is a consistent mediated database M for S such that for every consistent mediated database M for S , M S M .

Now we will prove that the notions of integration using logical formulas and that of integration using superset con-tainment (Definition 5) coincide.

In the following, let S 1 ,...,S m be sources with (uncer-tain) databases U 1 ,...,U m . Let the propositional formulas corresponding to U 1 ,...,U m be f 1 ,...,f m . The logical in-tegration results in the uncertain database M with the for-mula f M = f 1  X  X  X  X  X  f m (Section 3.3). There is a special case where f M obtained as above is false . In this case the sources are inconsistent and no consistent mediated database exists. Henceforth, we concentrate on the case where f M = false .
Lemma 1. Let S = { S 1 ,...,S m } be a set of uncertain sources, and M their integration using logical formulas. Then M is a consistent mediated database for S .
 Proof. We need to show that PW ( M ) =  X  and U i S M for all i =1 ,...,m . The first condition is satisfied for consistent sources since f M represents at least one world. For the second condition, we should show
Consider the form of f M = f 1  X  X  X  X  X  f m .Each f k has the form It follows that f M , after expansion, is the disjunction of con-junctive terms that have the form Where D 1 j ,...,D m j are databases in the possible worlds of U ,...,U m , respectively. Each of these conjunctive terms will be false if for one variable x ,both x and  X  x appear in the term. Otherwise, it will have variables corresponding to all tuples in T ( U 1 )  X  X  X  X  X  T ( U m ) , and it represents one possible world in the logical integration. Since M is non-empty, it follows that T ( M )= T ( U 1 )  X  X  X  X  X  T ( U m ) .Hence, T ( U i )  X  T ( M ) for all i =1 ,...,m .

Further, if a conjunctive term as above is not false, then it is easy to verify that the possible world corresponding to the conjunction, when restricted to tuples in T ( U k ) ,isrep-resented exactly by the formula and hence is equal to D j  X  PW ( U k ) . It follows that PW ( U k )  X  S { W  X  T ( U k ) | W  X  PW ( M ) } for all k 1 ,...,m .

Theorem 1. Let S = { S 1 ,...,S m } be a set of uncer-tain sources, and M their integration using logical formulas. Then M is the integrated database for S .

Proof. By Lemma 1 M is a consistent mediated schema for S . We need to prove for every consistent mediated database M for S , M S M .
 Since M is a consistent mediated database, we have U i  X  S M for all i =1 ,...,m .Then T ( U i )  X  T ( M ) for all i 1 ,...,m ,and T ( U 1 )  X  X   X   X  X  T ( U m )  X  T ( M ) . But in Lemma 1 we showed that T ( M )= T ( U 1 )  X  X  X  X  X  T ( U m ) . It follows that T ( M )  X  T ( M ) .
 It remains to show that PW ( M )  X  X  W  X  T ( M ) | W  X  PW ( M ) } . Assume the contrary. That is, there exists W  X  PW ( M ) such that W  X  T ( M )  X  PW ( M ) . On the other hand, since M is a consistent mediate database, every un-certain database U i should have a (regular) relation D j that D j i = W  X  T ( U i ) . It is easy to see that the logical construction of the integrated database, when applied to the logical formulas of D j i , i =1 ,...,m , generates the logical formula for W  X  T ( M ) .Hence W  X  T ( M )  X  PW ( M ) ,con-tradiction.
We extend the possible-worlds model by associating a probability distribution with each uncertain database: Definition 6 (Probabilistic Uncertain database).
 A probabilistic uncertain database U consists of a finite set of tuples T ( U ) , a nonempty set of possible worlds PW ( { D 1 ,...,D m } ,whereeach D i  X  T ( U ) is a certain database with a probability p i , 0  X  p i  X  1 .Further, m i =1 p i
Given a probabilistic uncertain database U with PW ( U )= { D 1 ,...,D m } , it is convenient to associate a probabilistic event e i with each possible world D i .Intuitively, e i repre-sents the event where the value of the uncertain database is equal to D i . Then, the probability of e i , P ( e i )= can make the following observations:
We present an example to demonstrate that probabilities associated with possible worlds of different sources need to satisfy certain constraints. We will generalize this observa-tion in Section 4.1 further below.

Example 5. Consider Scenario 1 of Section 2.2. Possi-ble worlds of the sources are shown again for convenience (Figures 5 and 6). Possible worlds of the integration were shown in Figure 4 (see Example 3).
Let the events associated with possible worlds D 1 ,...,D be e 1 ,...,e 4 , respectively. We have the following equations: P ( e 1 )+ P ( e 2 )=1 P ( e 3 )+ P ( e 4 )=1 P ( e 1 | e 2 )= P ( e 2 | e 1 )=0 P ( e 3 | e 4 )= P ( e 4 | e 3 )=0
Further, by Example 3, we know e 1 and e 3 are inconsis-tent, and so are e 2 and e 4 .Hence P ( e 1 | e 3 )= P ( e 3 | e 1 )=0 P ( e 2 | e 4 )= P ( e 4 | e 2 )=0
Ourgoalistocompute P ( e 1  X  e 3 ) , P ( e 1  X  e 4 ) , P ( and P ( e 2  X  e 4 ) in terms of P ( e 1 ) , P ( e 2 ) , P
It is easy to verify that P ( e 1  X  e 3 )= P ( e 1 | e 3 ) Similarly, P ( e 2  X  e 4 )= P ( e 2 | e 4 )  X  P ( e 4 )=0 . The only possible worlds in the integration with nonzero probabilities correspond to e 1  X  e 4 and e 2  X  e 3 . These possible worlds were shown in Figure 4.
 Some Observations
First, we note that e 1 and e 2 are complementary events since they are mutually exclusive and P ( e 1 )+ P ( e 2 )=1 .So, we can write e 1 =  X  e 2 and vice-versa. Similarly, e 3 and are complementary. Hence, we have P ( e 3 )= P ( e 3  X  e 1 P ( e 3  X  e 2 ) .But P ( e 3  X  e 1 )=0 as discussed above. So, we get P ( e 3 )= P ( e 3  X  e 2 )= P ( e 2  X  e 3 )= P ( e 2 | e follows that P ( e 2 | e 3 )=1 . Similarly, we can show P e )=1 , P ( e 1 | e 4 )=1 ,and P ( e 4 | e 1 )=1 .

Finally, since P ( e 3 )= P ( e 3  X  e 2 )= P ( e 3 | e 2 ) and P ( e 3 | e 2 )=1 ,weobtain P ( e 2 )= P ( e 3 ) . We can also obtain P ( e 1 )= P ( e 4 ) in a similar fashion.
This is a very interesting result. It shows that probabilities associated with possible worlds D 1 and D 2 of source 1 have to be the same as probabilities associated with worlds D 4 D 3 of source 2. Let X  X  recall our Scenario 1: The information that Bob is taking CS100 or (xor) CSC101 was given by John, and the information that Bob is taking CS101 or (xor) CSC102 was given by Jane. The restriction that probabilities associated with possible worlds D 1 and D 2 of source 1 have to be the same as probabilities associated with worlds D 3 and D 4 of source 2 means that If John assigns probabilities, say, 40% and 60%, to his statements, then Jane also has to assign exactly the same probabilities to her two statements (40% that Bob is taking CS102, and 60% that Bob is taking CS101). This is highly counter intuitive. We will generalize this observation, which we will call probabilistic consistency constraint , in the next section.
 Let X  X  assume for now that indeed P ( e 1 )= P ( e 4 ) and P ( e 2 )= P ( e 3 ) . Then it becomes easy to obtain the prob-abilities of the possible worlds in the integration: P ( e 1  X  e 4 )= P ( e 1 | e 4 )  X  P ( e 4 )= P ( e 4 ) ,and P ( e 2  X  e 3 )= P ( e 2 | e 3 )  X  P ( e 3 )= P ( e 3 )
To summarize, For Scenario 1: P ( e 1  X  e 3 )=0 , P ( e 1 e )= P ( e 1 )= P ( e 4 ) , P ( e 2  X  e 3 )= P ( e 2 )= P ( P ( e 2  X  e 4 )=0 . Given the possible world sets of two information sources S and S , we use a bi-partite graph G to represent the con-sistency relation between the worlds of the sources. Let the possible world set of S be { D 1 ,...,D k } , and the possi-ble world set of S be { D 1 ,...,D k } .Graph G has k + k nodes corresponding to possible world sets { D 1 ,...,D k { D 1 ,...,D k } . There is an edge between D i and D j if the formulas f ( D i )and f ( D j ) corresponding to these worlds are mutually satisfiable. That is, f ( D i )  X  f ( D j ) = false . (See Section 3.2 regarding logical representation of possible worlds.) We call G the possible-worlds consistency graph (or consistency graph for short) of S and S .
 In the following, we overload possible world symbol D (or D ) to also represent the event corresponding to D (or D ) (Section 4) as well as the node corresponding to D (or D )in the consistency graph G . The actual meaning will be clear from context.

We will prove the following:
Theorem 2. Let G be the consistency graph of sources S and S .Let G 1 be a connected component of G .Then G 1 is a complete bi-partite graph.
 Proof: We will show that if there is a path between nodes D and D in G ,where D and D correspond to possible worlds of S and S , respectively, then there must be an edge between D and D .

Assume there is a path between D and D )butthereis no edge ( D,D ) .Sincethereisnoedge ( D,D ) ,then f ( D ) and f ( D ) are not mutually satisfiable. That means there is avariable t such that one formula has t and the other has  X  t in their conjuncts. Without loss of generality, assume f (
D ) has t . Hence, (1) there is a tuple t in D (recall that a variable represents a tuple), (2) t is not in D ,and(3) t in the tuple set of S .

The path between D and D consists of a sequence of al-ternating nodes D i sand D j s such that D = D 1 , D k = D and the following edges are in G :
Since t is in D = D 1 and edge ( D 1 ,D 1 ) exists, then t must also be in D 1 . Similarly, since edge ( D 1 ,D 2 ) exists, then t must also be in D 2 . In a similar way we can show must be in all possible worlds along this path, including This provides a contradiction to the assumption that  X  t is in f ( D ) .
 Theorem 3. Let G 1 be a connected component of G .Let N and N denote the nodes of G 1 corresponding to the worlds of sources S and S , respectively. Then Proof: Let k and k be the number of possible worlds for S and S , respectively. We have If
D i  X  N ,then P ( D i | D j ) and P ( D i  X  D j ) are both zero for D j  X  N . So, for a node D i  X  N , we have It follows that Similarly, we can show, for a node D j  X  N , and hence, Theorem follows.

Example 6. Consider the possible worlds of two sources shown in Figures 7 and 8. The consistency graph G for these sources is shown in Figure 9. Note that G has two connected components: G 1 consists of nodes D 1 ,D 2 ,D 1 ,D 2 and G 2 consists of nodes D ,D 3 ,D 4 . Note that these connected components are com-plete bipartite graphs. According to Theorem 3, we must have P ( D 1 )+ P ( D 2 )= P ( D 1 )+ P ( D 2 ) ,and P ( D P ( D 3 )+ P ( D 4 ) .

The result of integration will consist of 6 possible-worlds relations, corresponding to compatible pairs of possible worlds from the two sources, namely, ( D 1 ,D 1 ) , ( D 1 ,D 2 ) , ( (
D We will discuss the problem of determining probabilities of possible-worlds relations of the integration in the next sec-tion. Figure 10: Result of integration of sources One and Two
In the integration of probabilistic uncertain databases, the goal is to obtain the probabilities of the possible worlds of the integration in terms of the probabilities of individual would like to obtain in terms of P ( e i j ) X  X  for all possible values of i , k We discussed a simple case in Example 5. If worlds D and D are connected in the consistency graph, and not con-nected to any other nodes, then (1) P ( D )= P ( D )and(2) P (
D  X  D )= P ( D )= P ( D ) (note that we are overload-ing the symbol D to mean a possible world, the node in the consistency graph corresponding to the possible world D , and the event corresponding to the possible world D .) This case corresponds to simple connected components in the consistency graph, those with only two nodes.
We face two difficulties in determining the probabilities of possible worlds in the integration in the general case:
In this section we discuss approaches to address these diffi-culties. First, we concentrate on the case where probabilistic consistency constraints are satisfied. The following lemma follows the proof of Theorem 3.

Lemma 2. Let G be the consistency graph of sources S and S ,and G 1 be a connected component of G .Letthe nodes of G 1 consist of nodes N corresponding to source S and N corresponding to source S .Then
Note that each D i  X  D j corresponds to a possible world in the integration. In other words, we know the sum of the probabilities of possible worlds resulting from the integration corresponding to each connected component of the consis-tency graph.

It is easy to extend the observation from Example 5 re-garding connected components with only two nodes to the case where N or N (in Lemma 2) is a single node. For ex-ample, if N = { D } is a single node, then P ( D  X  D j )= for all D j  X  N . However, if neither N nor N is a single node, then, in the absence of additional information, there are multiple (infinite) possibilities for the probabilities of the possible worlds in the integration (see Example 7). We can use the following approaches to compute the probabilities of possible worlds in the integration.
Example 7. Consider Example 6. Let X  X  assume the prob-abilities of possible worlds of sources S and S are P ( D 0 . 3 , P ( D 2 )=0 . 5 , P ( D 3 )=0 . 2 , P ( D 1 )=0 . 35 , 0 . 45 , P ( D 3 )=0 . 05 ,and P ( D 4 )=0 . 15 . Note that these probabilities satisfy the probabilistic consistency constraints P ( D 1 )+ P ( D 2 )= P ( D 1 )+ P ( D 2 ) ,and P ( D 3 )= P ( P ( D 4 ) .
 The consistency graph for S and S was shown in Figure 9. It has two connected components. The second component satisfies the special case where N is a single node. So, we can easily determine the probabilities of two of the possible worlds in the integration: P ( D 3  X  D 3 )= P ( D 3 )=0 . P ( D 3  X  D 4 )= P ( D 4 )=0 . 15 .

The first connected component of the consistency graph gives rise to possible worlds corresponding to D 1  X  D 1 , D , D 2  X  D 1 ,and D 2  X  D 2 . We have four unknowns. We have four equations too but they are not independent: P ( D 1  X  D 1 )+ P ( D 1  X  D 2 )= P ( D 1 ) , P ( D 2  X  D 1 )+ P ( D 2  X  D 2 )= P ( D 2 ) , P ( D 1  X  D 1 )+ P ( D 2  X  D 1 )= P ( D 1 ) ,
P ( D 1  X  D 2 )+ P ( D 2  X  D 2 )= P ( D 2 ) .
Given one more equation, we will be able to determine the four probabilities. An attractive possibility is the knowledge of a conditional probability. For example, let P ( D 1 | D 0 . 6 . Then we get P ( D 1  X  D 1 )=0 . 21 , P ( D 1  X  D 2 )=0 P ( D 2  X  D 1 )=0 . 14 ,and P ( D 2  X  D 2 )=0 . 36 .

In the absence of any additional knowledge, we can incor-porate some heuristics to provide the probabilities of pos-sible worlds in the integration. One possibility is to dis-tribute the sum (0.8 in our example) according to the pair-wise product of probabilities of underlying possible worlds (0.105, 0.135, 0.175, and 0.225 in our example). We ob-tain the following values for our example: P ( D 1  X  D 1 )= 0 . 13125 , P ( D 1  X  D 2 )=0 . 16875 , P ( D 2  X  D 1 )=0 . 21875 ,and P (
D 2  X  D 2 )=0 . 28125 . Note that this distribution corre-sponds to the assumption
Next, we consider the second difficulty: How to cope with violations of probabilistic consistency constraints? A strict approach would be to declare the sources as inconsistent and deem integration impossible. But in many applications, probabilities associated with possible worlds are approxi-mate, and may represent some degree of belief rather than a strict mathematical probability. Rather than dismissing the sources X  assessment completely when their probabilities violate some probabilistic constraint, we should try to pro-vide approximate probabilities for possible worlds in the in-tegration. The following example demonstrates a promising approach.

Example 8. Consider Example 5 again. The consistency graph corresponding to this example has two connected com-ponents: ( D 1 ,D 4 ) and ( D 2 ,D 3 ) ,where D 1 and D 2 sible worlds of source 1 and D 3 and D 4 are possible worlds of source 2.

Assume probabilities 40% and 60% for possible worlds of source 1, and 70% and 30% for the possible worlds of source 2. That is P ( D 1 )=0 . 4 , P ( D 2 )=0 . 6 , P ( D 3 )=0 P (
D 4 )=0 . 3 . Note that probabilistic consistency constraints are violated. That is, P ( D 1 ) = P ( D 4 ) and P ( D 2 ) = We showed that P ( D 1  X  D 4 ) must be equal to P ( D 1 ) and P (
D 4 ) (and also P ( D 1 )= P ( D 4 ) ). But that is not satisfied here. So, intuitively , what is the best probability to asso-ciate with P ( D 1  X  D 4 ) ? Source 1 says it must be 40%, while source 2 says it is 30%. One possible choice is the average of the two values, 35%. This corresponds to the first possible world of the integration in Figure 4. Similarly, we use the average of 60% and 70%, namely 65%, for the probability of the second possible world of the integration in Figure 4. The following is the generalization of our heuristics:
Consider each connected component of the consistency graph independently. The probabilistic consistency constraint is that the sum of probabilities of the possible worlds cor-responding to the first source is equal to the sum of prob-abilities of the possible worlds corresponding to the second source. If they are not equal, we use the average of the two values. Then we will distribute this value into probabili-ties for each  X  X dge X  of the connected component (note that an edge represents the integrated possible world that is the union of the two possible worlds represented by the nodes of that edge).
Information integration and modeling and management of uncertain information have been active research areas for decades, with both areas receiving significant renewed inter-est in recent years (for example, some recent publications in these areas include [2, 3, 4, 7, 10, 12, 15, 16, 17, 19, 20, 23, 24, 26, 28, 31, 39, 41, 42, 44, 45, 46, 47] Research on infor-mation integration with uncertainty, on the other hand, is quite recent [2, 18, 19, 20, 21, 34, 35]. In the following we review some of related research in these areas.

We start with a fundamental work on information in-tegration with uncertainty [2]. The focus of this work is on the foundations for local-as-view information integration when the sources contain uncertain data. To our knowl-edge, this is the first work that enhances the well-known possible-worlds model with tuple sets, a concept that proves critical for information integration applications. They intro-duce fundamental concepts of equality and superset contain-ment, consistency, and correct and strongest correct answer to queries. They prove that for superset containment, an uncertain database instance exists that gives the strongest correct answer to any query. We have chosen this instance as the formalism for the integration of uncertain databases, and provide a conceptually simpler algorithm to compute it. [2] also contains studies of complexities of checking consis-tency and evaluating queries in this model.

Most of the other research on information integration with uncertainty deal with the issue of uncertain schema map-ping. Schema matching/mapping is a key step in informa-tion integration. Significant research has been spent on au-tomated schema mapping (for example, [5, 6, 13, 14, 27, 29, 32, 33, 36, 37, 40, 48]). Automated schema mapping gener-ates uncertain mappings and hence the study of uncertain mappings is important for information integration.
In [18, 19] authors argue that data integration systems should handle uncertainty at three levels: Semantic map-pings, translation of keyword queries to structured queries, and data. They introduce the concepts of by-table and by-tuple probabilistic schema mappings. In by-table semantics, all tuples of a given table use the same mapping to the me-diated schema, whereas in the by-tuple semantics, each tu-ple may use a different mapping. [9, 18, 19] present query complexity and algorithms for query processing over inex-act schema mappings, as well as algorithms for efficiently computing top-k answers to queries.

A study and survey of uncertainty in data integration is presented in [34, 35]. They introduce a generic data inte-gration process in terms of wrapping , matching and merging operations, and identify critical points for uncertain infor-mation integration. They demonstrate the importance of handling uncertainties produced by the matching process, and introduce approaches to improve the matching phase. They also present a survey of a number of data integration methods that explicitly deal with uncertainty.

The authors of [21] concentrate on another dimension of using probabilistic information in information integration. Their goal is  X  X o improve the performance of a mediator system by obtaining answers to queries as fast as possi-ble. X  They consider three types of probabilistic information: (1) degree of overlap between collections in the mediated schema, (2) degree of coverage of each information source, and (3) degree of overlap between information sources (such as when a source is a view of another source.) They pro-pose algorithms to order access to information sources using probabilistic information and study their performances.
Management of uncertainty in XML schema matching and efficient query processing in this context has been studied in [22]. Authors present approaches to improve the efficiency of generating, storing, and querying possible mappings.
Information integration from uncertain XML sources is studied in [20]. The underlying model for uncertain XML is the ProTDB probabilistic XML model of [38], and the inte-gration system uses the Semantic Model approach of [7, 8, 30, 43]. It introduces the lineage-encoding relational model for the mediated schema which makes it possible to capture the uncertainties in the ProTDB-style probabilistic XML sources, and presents query processing and probability cal-culation algorithms for this framework.
We studied the problem of information integration from multiple sources with uncertain data. We reviewed the possible-worlds approach to the modeling of uncertain information, presented an intuitive logical representation of possible-worlds information, and presented an algorithm for uncertain infor-mation integration using the logical representation. We also showed that our integration approach coincides with a re-cent formalism for uncertain information integration. Then we extended the approach to probabilistic possible-worlds, and showed certain probabilistic consistency constraints are imposed upon possible-worlds of information sources in the integration. We studied the problem of determining the probabilities for the result of integration, and presented a practical approach to probabilistic information integration based on relaxation of probabilistic constraints.
Our work has established a formal model for the integra-tion of information from sources containing uncertain data, including probabilistic information about sources contents. To be practical, uncertain information should be presented using a compact representation rather than an enumeration of the possible-worlds. Future work includes selecting an efficient representation (such as the probabilistic relation of [12]) and designing efficient algorithms for integration of un-certain information in the selected representation. [1] Serge Abiteboul, Paris C. Kanellakis, and G  X  osta [2] Parag Agrawal, Anish Das Sarma, Jeffrey D. Ullman, [3] Lyublena Antova, Thomas Jansen, Christoph Koch, [4] Lyublena Antova, Christoph Koch, and Dan Olteanu. [5] Zohra Bellahsene, Angela Bonifati, and Erhard Rahm, [6] Philip A. Bernstein and Sergey Melnik. Model [7] Dongfeng Chen, Rada Chirkova, Maxim Kormilitsin, [8] Dongfeng Chen, Rada Chirkova, Fereidoon Sadri, and [9] Reynold Cheng, Jian Gong, David W. Cheung, and [10] Nilesh N. Dalvi, Christopher R  X  e, and Dan Suciu. [11] Nilesh N. Dalvi and Dan Suciu. Efficient query [12] Nilesh N. Dalvi and Dan Suciu. Efficient query [13] Robin Dhamankar, Yoonkyong Lee, AnHai Doan, [14] Hong Hai Do and Erhard Rahm:. COMA -a system [15] AnHai Doan and Alon Y. Halevy. Semantic [16] AnHai Doan, Natalya F. Noy, and Alon Y. Halevy. [17] Xin Luna Dong, Laure Berti-Equille, and Divesh [18] Xin Luna Dong, Alon Halevy, and Cong Yu. Data [19] Xin Luna Dong, Alon Y. Halevy, and Cong Yu. Data [20] Ala A. Eshmawi and Fereidoon Sadri. Information [21] Daniela Florescu, Daphne Koller, and Alon Y. Levy. [22] Jian Gong, Reynold Cheng, and David W. Cheung. [23] Todd J. Green, Gregory Karvounarakis, Nicholas E. [24] Laura M. Haas. Beauty and the beast: The theory [25] Alon Halevy and Chen Li. Information integration [26] Alon Y. Halevy, Naveen Ashish, Dina Bitton, [27] Alon Y. Halevy, Zachary G. Ives, Dan Suciu, and Igor [28] Alon Y. Halevy, Anand Rajaraman, and Joann [29] Mauricio A. Hern  X andez, Paolo Papotti, and [30] Laks V. S. Lakshmanan and Fereidoon Sadri.
 [31] Chen Li, Jia Li, and Qi Zhong. Raccoon: A peer-based [32] Jayant Madhavan, Philip A. Bernstein, AnHai Doan, [33] Jayant Madhavan, Philip A. Bernstein, and Erhard [34] Matteo Magnani and Danilo Montesi. Uncertainty in [35] Matteo Magnani and Danilo Montesi. A survey on [36] Sergey Melnik, Atul Adya, and Philip A. Bernstein. [37] Sergey Melnik, Philip A. Bernstein, Alon Y. Halevy, [38] Andrew Nierman and H. V. Jagadish. ProTDB: [39] Dan Olteanu, Jiewen Huang, and Christoph Koch. [40] Erhard Rahm and Philip A. Bernstein. A survey of [41] Christopher Re, Nilesh N. Dalvi, and Dan Suciu. [42] Patricia Rodr  X  X guez-Gianolli, Maddalena Garzetti, Lei [43] Fereidoon Sadri. Local as view information integration [44] Anish Das Sarma, Omar Benjelloun, Alon Y. Halevy, [45] Anish Das Sarma, Omar Benjelloun, Alon Y. Halevy, [46] Prithviraj Sen and Amol Deshpande. Representing [47] Nicholas E. Taylor and Zachary G. Ives. Reliable [48] Ling-Ling Yan, Ren  X  ee J. Miller, Laura M. Haas, and
