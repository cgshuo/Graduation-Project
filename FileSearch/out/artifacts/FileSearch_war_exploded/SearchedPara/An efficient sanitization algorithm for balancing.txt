 1. Introduction
Rapid advances in network communications and software and hardware technologies enable users to col-lect huge amounts of data. At the same time, high-speed computation has made it feasible to analyze these data to extract valuable information contained therein. This so-called data mining plays an important role in many applications such as business management, marketing analysis, and science exploration. However, it also introduces some privacy concerns.

Consider the following scenario extended from [7] . Suppose a distributed system is composed of a server statistical information about associations among items from the union of their databases to provide recom-erated from their databases. A sensitive pattern is a frequent pattern with security implications, such as patterns according to some specific privacy policies, sharing only the modified databases.
Importance of privacy continues to increase in the data mining field, thus making the issue of privacy-pre-serving data mining (PPDM) to be arisen. The PPDM problems can be categorized into two types: data privacy broad approaches are practiced. The randomization approach emphasizes the individual privacy and sends the randomized data to prevent the original data from being revealed [5 X 7,18] . In the secure multiparty compu-on the union of their databases without revealing such unnecessary information as the individual records.
On the other hand, the information privacy problems focus on hiding the association rules or frequent pat-terns containing the sensitive information. The problem of information privacy has been proved to be a NP-hard problem [1] and a large number of heuristic methods have been proposed to solve this problem [9,11 X  16,19,21,22] .

Oliveira and Za X   X  ane propose a privacy preservation framework for hiding the sensitive patterns in transactions and how to choose the victim items from the sensitive transactions are the two most important issues in that approach.

Algorithm (SWA), for enforcing privacy in association rules mining. This approach hides association rules by decreasing their supports and has better performance than the framework proposed in [12] . However, the approaches proposed in [12 X 14,16] are all vulnerable to Forward-Inference Attacks first discussed in nally considered in the published pattern set problem [15,23,24] .

The published pattern set problem is to hide the sensitive patterns in a set of frequent patterns, which is monotone and the inclusion X  X xclusion principles. In reality, in the published database problem, we need them from the non-sensitive patterns mined from the modified databases. Atzori et al. also define another base problems, the users do not specify the sensitive patterns in [2,3] .

Distinct from the inference channels discussed in [24] , the Forward-Inference Attacks discussed in [15,16] published pattern set problem and the published database problem addressed in this paper both aim at hiding the sensitive knowledge, the Forward-Inference Attacks should also be considered while modifying the database.

It is reasonable to assume that the adversary can use any inference method to obtain more patterns than we want her/him to know. Consequently, the Forward-Inference Attacks can be regarded as a related parameter databases but cannot contain any association information of the items.
 the sensitive transactions, it is also vulnerable to the Forward-Inference Attacks. Another border-based approach named, Max X  X in approach, is proposed in [11] . The Max X  X in approach focuses on minimizing ward-Inference Attacks, since only the sensitive transactions are considered. Wang et al. propose a matrix-ence Attacks.

In this paper, a method extended from [22] to modify the databases for hiding sensitive patterns is pro-ance of the hiding failure, the level of conference can be given by the users.

Our contributions can be summarized as follows: First, instead of checking the entire database to identify problem of hiding sensitive patterns is transformed to how to define the sanitization matrix rather than how to find the sensitive transactions. Second, the probability policies with a level of confidence defined by the users are introduced for the first time to solve the information privacy problems. Third, the For-ward-Inference Attacks [15] can also be avoided in the sanitized database generated by our sanitization process.

The remainder of this paper is organized as follows: Section 2 introduces the basic concepts of this
Section 6 concludes this work. 2. Preliminaries 2.1. Problem definition
The problem of discovering association patterns is defined as finding relationships between the occurrences which means that 10% of the transactions contain both of the items. As displayed in the above example, sup-mous amounts of the combinations of the items, the users can define the minimum support as a minimum the minimum support.

In this approach, a transactional database is represented as a binary matrix D in which the rows represent patterns mined from D except the frequent patterns with a length of one (i.e., frequent items), P sensitive patterns, and P H be a set of the remaining frequent patterns (non-sensitive patterns), i.e., P
H [ P H = P . The idea of this approach is to transform D into a sanitized database D of two should be hidden. As mentioned above, the single frequent items are ignored. Only the frequent pat-in many databases. By only the single frequent items, it is almost impossible to import any associations of length over two, they may obtain almost all the patterns enumerated from the database. 2.2. Basic concepts of the sanitization matrix sanitized database D 0 is to multiply D by a sanitization matrix S . That is, D identity matrix (i.e., S ij =1if i = j , otherwise S ij = 0), D elements of S to appropriate values can yield a sanitized database. 2.2.1. New definition of matrix multiplication different definitions of matrix multiplication are given: the supports, we only need to concern about how and when an entry of 1 in D should be converted to 0 in cess terminates. 2. If the resulting value of 3. If the resulting value of 2.2.2. Observation 1: Setting entries to 1
In order to hide a pattern { i , j }, its support should be decreased. For example, if D to 1 for a row (transaction) k , the value of D ki or D kj
S is set to 1 ; D 0 21 and D 0 41 will become 0 (i.e., the support of item 1 is decreased); whereas if S
D decreased by setting S 21 or S 12 to 1. Moreover, if S ij equal to 1, D 0 tj will become 0 (i.e., the support of item j is decreased). 2.2.3. Observation 2: Setting entries to 1 ring to Fig. 4 , let the minimum support be 50%, and {1, 2} and {1, 3} be the sensitive and non-sensitive
D . However, if S 31 is set to 1 (as shown in the right-hand equation), for those entries where D are both equal to 1, D 0 t 1 will keep the same value as D between items i and j by enhancing the strength of item j .
 3. Sanitization process
Fig. 5 shows the flowchart of the whole sanitization process proposed in this paper. Each of the compo-nents included in the sanitization process are detailed in this section. 3.1. Setting the sanitization matrix The set containing all pair-subpatterns of F is called the pair-subset of F .
 infer the hidden pattern.
 S to 1. The Marked-Set Generation algorithm is listed in Fig. 6 .
 Since the patterns belonging to P H should be affected as little as possible, the patterns in P sitive patterns are calculated in Step 4. For example, if P 2}, {2, 3}, {3, 5}, and {1, 5} are 2, 1, 1, 1, and 1, respectively.
 If the frequency of a pair-subpattern generated from P H is low, the few patterns in P in the groups with a low frequency. Therefore, the fewer patterns in P hidden by hiding a common pair-subpattern. Moreover, the dissimilarity between D and D reduced. An example of applying the Marked-Set Generation algorithm is given in Tables 1 X 3 . pattern stored in Marked-Set. If the effects on the patterns in P the number of its occurrences in Marked-Set. This is because choosing a more frequent item can decrease the supports of more patterns that belong to Marked-Set at one time and reduce the dissimilarity between D and
D . In Step 3, the associations of the patterns that belong to P 3.2. Probability policies 3.2.1. Distortion probability q ing to P H . However, Fig. 8 indicates that these results may cause the following problem, named overhiding problem . In both the left-hand and right-hand equations in Fig. 8 , the support of {1, 2} in D items 1 and 2 never appear together  X  they are mutually exclusive! This situation almost does not happen in the database that does not hide any information. The attackers may detect this situation and infer that {1, 2} has been painstakingly hidden.
 contains only one entry equal to 1 (i.e., S jj = 1) and it works as follows: if 1 6 j 6 m , the probabilities of D 0 ij being 1 or 0 are q loss of generality, we assume that S ij = 1. If q satisfies n is not frequent in D 0 .

Proof. Suppose that the probability policies are not considered in the following case. While S while a row (transaction) t of D includes D ti = 1 and D tj multiplication discussed in the previous section, D 0 tj will be set to 0. We can consider the n to be D 0 t distributed random variables X 1 ; X 2 ; ... ; X n is defined as X i = 1 and failure is defined as X i =0, " i =1 to n success outcome and 1 q is attached to the failure outcome. Let X be a random variable that can be viewed as the number of transactions including { i , j }in D
Thus, X follows a binomial distribution, that is, X B ( n
Var( X )= n ij q (1 q ), respectively. If we want to hide { i , j }in D cesses should be higher than c . Therefore, q must satisfy is not frequent in D 0 . h
Since we only need to obtain a value of q satisfying the above formulas, the above inequality can be viewed the CLT, transposing and table-looking can be applied to reduce the complexity of computing the equation, making the sanitization process to be more efficient
Moreover, if several entries in column j of S are equal to 1, such as S several candidate Distortion Probabilities (e.g., q i , q fident with a probability of at least c that all corresponding pair-subpatterns are hidden in D 3.2.2. Conformity probability l
S equal to 1. It works as follows: if tiplied by the entry with value 1 in D , D 0 ij is set to 1 with probability l multiplication rules discussed in Section 2 are required.
 a pattern in Marked-Set, {k, j } be a pattern in {large-2 Marked-Set } , and n following rule: l we can say that we are confident with a probability of c that {i, j } is not frequent in D
Proof. Suppose that the probability policies are not considered in this case. While S
S = 1 [i.e., while a row (transaction) t of D includes D ti the n ikj original D 0 t independent identically distributed random variables Y 1 ; Y bution, B (1, l ). Success is defined as Y i = 1 and failure is defined as Y attached to the success outcome and 1 l is attached to the failure outcome. Let Y be a random variable that can be viewed as the number of transactions that contain { i , k , j }in D
Then, Y follows a binomial distribution, that is, Y B ( n 0 ; otherwise 8 &lt; : . The mean and variance of Y are E ( Y )= n ikj l and Var( Y )= n (1 l ), respectively. If we want to hide { i , j }in D 0 , we must let the support of { i , j }in D r . Therefore, the expected value of Y must be smaller than r j D j ; that is, n summation of the probabilities of all the successes should be higher than c . Thus, l must also satisfy
P set to 1 in this case. h The application of the CLT yields didate Conformity Probability l . By setting the Conformity Probability of j , l lue, we can guarantee that we are confident with a probability of at least c that all corresponding pair-subpatterns are hidden in D 0 . 3.2.3. Discussion on distortion probability and conformity probability
In the above subsections, the Distortion Probability and the Conformity Probability are introduced. In the above-mentioned matrix multiplication without the probability policy considerations, the overhiding problem may occur, which cause the hidden pair-subpatterns to be recovered. It can be avoided by taking the Distor-is, each column of sanitization matrix S only has at most one probability (either Distortion or Conformity
Probability), because the column only satisfies one of the conditions discussed above. Moreover, according to the degree of difference between the modified database and the original database and the tolerance of and find one that is acceptable to them. 3.3. Sanitization algorithm
According to the probability policies discussed above, the sanitization algorithm implements D
S m m as indicated in Fig. 10 . Notice that if the sanitization process causes all entries in row i of D from some k where D ik = 1 is chosen randomly and D 0 ik is set to 1. This movement guarantees that D of equal size. 4. Analyses of complexity and security 4.1. Time complexity Analysis that is, the time for obtaining the frequent patterns.

Theorem 1. The running time of our sanitization process is O  X  n is the number of items in D, n trans is the number of transactions in D ; n maximal length of the frequent patterns.

Proof. The sanitization process can be roughly decomposed into four parts: the Marked-Set generation, the yses described below are considered in the worse case.

In the Marked-Set Generation algorithm, searching for the patterns with length equaling two in the sensitive pattern set (Step 1) takes n P generating the groups (Step 2) take n P and L groups that have the same class label. Two nested for loops need to scan all groups, and this takes O  X  n Similar to Step 2, Step 4 takes O  X  n P any patterns generated in Step 4, and this takes n P maximum number of groups generated in Step 2 and n P subpatterns generated in Step 4. The groups are sorted in Step 6, which takes O  X  X  n compares the sensitive patterns stored in the current two groups, G O  X  n P the time complexity of the Marked-Set Generation is O  X  n
Setting all the diagonal entries to 1 in Step 1 of the sanitization matrix setting algorithm takes O( n to 1; this takes O  X  n P remaining entries are set to 0 in Step 4, which takes O  X  n
The time to compute the probabilities for each column is now discussed. For the Distortion Probability, suppose that each computation of a candidate Distortion Probability takes a constant time C entries equal to 1 in a column where k 6 n item 1. It takes O( n this column. On the other hand, suppose that each computation of a candidate Conformity Probability takes a constant time C 2 , and there are k 1 entries equal to 1 and k k + k 2 6 n item , then the number of candidate Conformity Probabilities for this column is k probability policies takes O  X  n 3 item  X  .

Matrix multiplication forms the kernel of the Sanitization algorithm, and hence the time complexity of this n 4.2. Security discussion a sensitive pattern in D.
 with a length of r are the subpatterns of e , with a length of r 1.
 r 2 1 subpatterns of e , with length equaling three, the probability of recovering all subpatterns of e , with length equaling three is p p four. Since the revealing of sube will affect r 2 2 subpatterns of e , with length equaling four, the probability of recovering all subpatterns of e , with length equaling four is p p
Therefore, we can infer that the probability of recovering e is p p subpatterns of e is hidden. However, due to the other hidden sensitive patterns, e maybe has more than one pair-subpattern to be hidden, making the probability of recovering e to be decreased. h ered, and make it be difficult to find which patterns are truly significant.
 the published database D 0 , she/he can doubtless gain all frequent patterns mined from D all possible problems of divulging some elements in Marked-Set. Suppose the number of frequent patterns setting S , possible situations of values of two symmetrical entries ( S with probability 1/4. As can be seen, the number of two symmetrical entries in S is difficult to conjecture S . It means that the adversary obtains the real S with probability 1 = 4 understand that the conjectural S is real or not even though she/he gets the real one. Moreover, since our ward-Inference Attacks. 5. Performance evaluation 5.1. Performance Quantifying
Three potential errors may occur in the problem of hiding sensitive patterns under a fixed minimum sup-mined from D 0 . Second, some non-sensitive patterns cannot be mined from D introduce the other two criteria, dissimilarity and weakness. All of the criteria are discussed as follows:
Criterion 1: Some sensitive patterns is still frequent in D database X .

Criterion 2: Some non-sensitive patterns are hidden in D 0 mined from database X .
 Criterion 3: Some artificial patterns are generated after the sanitization process. The error is denoted as terns mined from database X . AP of our approach and SWA are always 0%. Because both of SWA and our the transactions.

Criterion 4: The dissimilarity between the original and the sanitized database is also concerned, and it is measured by Dis  X 
Criterion 5: According to the previous section, the Forward-Inference Attacks are avoided while at least mined in D 0 but the sensitive pattern is hidden in D 0 , the Forward-Inference Attacks problem will occur.
Therefore, the Forward-Inference Attacks can be quantified by Weakness  X  WK  X  X 
PairS ( D 0 ) is the set of sensitive patterns whose pair-subsets can be completely mined from D
HF may make the values of MC high. This is because the existence of the associations between the sensitive patterns and the non-sensitive patterns. Another example, the low values of HF may make the values of bility policies and find the balance that is acceptable to them. 5.2. Experiment results level of confidence and the other criteria in this sanitization process. The second one is to compare this approach with SWA [14,16] which is so far the algorithm with the best performances as we know. All the experiments are performed on a PC with Intel Pentium4 2.8 GHz, 1 GB of main memory, and under Windows
XP operating system. In addition, the test dataset is generated by the IBM synthetic data generator, which
The apriori algorithm with the minimum support = 1% is used to mine the text dataset and 52,964 frequent factors are defined in Table 5 .

Two factors, namely RS and RL2, are used in the experiments. Since the time complexity of this approach relates to the number of sensitive patterns n P malized n P
Moreover, as shown in the procedure of the Marked-Set generation, the number of sensitive patterns with a cedure. Therefore, RL2 is used to show how the criteria change with the number of sensitive patterns gener-ated from the seeds with a length of two.
 increases. Moreover, the misses cost and dissimilarity increase as c increases.
Figs. 15 X 19 show the effect of RS by comparing our approach to SWA. Referring to Fig. 15 , because the level of confidence in our sanitization process takes the minimum support into account, no matter how the there is no correlation between the disclosure threshold in SWA and the minimum support. Under the same may cause the serious Forward-Inference Attacks problems.
 over, referring to the turning points of SWA under x = 0.0855 X 0.1006 in Figs. 17 and 18 , the reason of the mon item in SWA, decreasing the misses cost and the dissimilarity.
 Fig. 19 shows the execution time of SWA and our approach. As shown in the result, the execution time of
SWA increases as RS increases. On the other hand, our approach can be separated roughly into two parts, one cute the multiplication whose execution time is dependent on the numbers of transactions and items in the database. In the experiment, since the items and transactions are fixed, the execution time of our approach is decided by the setting of Marked-Set which makes the execution time changing slightly.
Figs. 20 X 24 show the effect of RL2. In Fig. 20 , the execution time of our approach decreases as RL2 increases. This is because when RL2 increases, our approach takes less time to generate Marked-Set ideally.
Referring to Figs. 21 and 22 , our approach outperforms SWA no matter what the RL2 is. Moreover our hiding failure occurs at the seeds of the sensitive patterns, a high weakness is produced.
As shown in Figs. 23 and 24 , the misses cost and dissimilarity of our approach decreases as RL2 increases but those for SWA seem to be independent of RL2. 6. Conclusion
A novel sanitization process to improve the balance between protecting sensitive information and discov-some conditions, it is safer than SWA in general. Unlike SWA, this sanitization process is immune from the Forward-Inference Attacks. Moreover, since the probability policies in this approach also take the min-imum support into account, the users only need to decide the level of confidence (which affects the hiding of patterns) and do not need to investigate the balance between the disclosure threshold and the minimum this method to hiding association rules with probabilities.

References
