
Shobha Venkataraman  X  , Avrim Blum  X  , Dawn Song  X  , Subhabrata Sen  X  , Oliver Spatscheck  X  It is widely acknowledged that identifying the regions that originate malicious traffic on the Internet is vital to network security and management, e.g., in thrott ling attack traffic for fast mitigation, iso-lating infected sub-networks, and predicting future attac ks [6, 18, 19, 24, 26]. In this paper, we show how this problem can be modeled as a version of a question stud ied by Helmbold and Schapire [11] of adaptively learning a good pruning of a known decision tre e, but with a number of additional chal-lenges and difficulties. These include a changing target fun ction and severe space requirements due to the enormity of the underlying IP address-space tree. We d evelop new algorithms able to address these difficulties that combine the underlying approach of [ 11] with the sleeping experts framework of [4, 10] and the online paging problem of [20]. We show how to deal with a number of practical issues that arise and demonstrate empirically on real-worl d datasets that this method substantially improves over existing approaches of /24 prefixes and networ k-aware clusters [6, 19, 24] in correctly identifying malicious traffic. Our experiments on data sets of 126 million IP addresses demonstrate that our algorithm is able to achieve a clustering that is bot h highly accurate and meaningful. 1.1 Background Multiple measurement studies have indicated that maliciou s traffic tends to cluster in a way that aligns with the structure of the IP address space, and that th is is true for many different kinds of malicious traffic  X  spam, scanning, botnets, and phishing [6 , 18, 19, 24]. Such clustered behaviour can be easily explained: most malicious traffic originates f rom hosts in poorly-managed networks, and networks are typically assigned contiguous blocks of th e IP address space. Thus, it is natural that malicious traffic is clustered in parts of the IP address space that belong to poorly-managed networks.
 From a machine learning perspective, the problem of identif ying regions of malicious activity can be viewed as one of finding a good pruning of a known decision tr ee  X  the IP address space may be naturally interpreted as a binary tree (see Fig.1(a)), and t he goal is to learn a pruning of this tree that is not too large and has low error in classifying IP addresses as malicious or non-malicious. The structure of the IP address space suggests that there may wel l be a pruning with only a modest num-ber of leaves that can classify most of the traffic accurately . Thus, identifying regions of malicious activity from an online stream of labeled data is much like th e problem considered by Helmbold and Schapire [11] of adaptively learning a good pruning of a know n decision tree. However, there are a number of real-world challenges, both conceptual and pract ical, that must be addressed in order to make this successful.
 One major challenge in our application comes from the scale o f the data and size of a complete decision tree over the IP address space. A full decision tree over the IPv4 address space would have 2 32 leaves, and over the IPv6 address space (which is slowly bein g rolled out), 2 128 leaves. With such large decision trees, it is critical to have algori thms that do not build the complete tree, but instead operate in space comparable to the size of a good p runing. These space constraints are also important because of the volume of traffic that may need t o be analyzed  X  ISPs often collect terabytes of data daily and an algorithm that needs to store a ll its data in memory simultaneously would be infeasible.
 A second challenge comes from the fact that the regions of mal icious activity may shift longitu-dinally over time [25]. This may happen for many reasons, e.g ., administrators may eventually discover and clean up already infected bots, and attackers m ay target new vulnerabilities and attack new hosts elsewhere. Such dynamic behaviour is a primary rea son why individual IP addresses tend to be such poor indicators of future malicious traffic [15, 26 ]. Thus, we cannot assume that the data comes from a fixed distribution over the IP address space; the algorithm needs to adapt to dynamic nature of the malicious activity, and track these changes ac curately and quickly. That is, we must consider not only an online sequence of examples but also a ch anging target function.
 While there have been a number of measurement studies [6, 18, 19, 24] that have examined the origin of malicious traffic from IP address blocks that are kept fixed apriori, none of these have focused on developing online algorithms that find the best predictive I P address tree. Our challenge is to develop an efficient high-accuracy online algorithm that handles th e severe space constraints inherent in this problem and accounts for the dynamically changing nature of malicious behavior. We show that we can indeed do this, both proving theoretical guarantees o n adaptive regret and demonstrating successful performance on real-world data. 1.2 Contributions In this paper, we formulate and address the problem of discov ering and tracking malicious regions of the IP address space from an online stream of data. We present an algorithm that adaptively prunes the IP address tree in a way that maintains at most m leaves and performs nearly as well as the optimum adaptive pruning of the IP address tree with a compar able size. Intuitively, we achieve the required adaptivity and the space constraints by combining several  X  X xperts X  algorithms together with a tree-based version of paging. Our theoretical result s prove that our algorithm can predict nearly as well as the best adaptive decision tree with k leaves when using O ( k log k ) leaves. Our experimental results demonstrate that our algorithm id entifies malicious regions of the IP ad-dress space accurately, with orders of magnitude improveme nt over previous approaches. Our ex-periments focus on classifying spammers and legitimate sen ders on two mail data sets, one with 126 million messages collected over 38 days from the mail server s of a tier-1 ISP, and a second with 28 million messages collected over 6 months from an enterpri se mail server. Our experiments also highlight the importance of allowing the IP address tree to b e dynamic, and the resulting view of the IP address space that we get is both compelling and meaningfu l. We now present some basic definitions as well as our formal pro blem statement.
 The IP address hierarchy can be naturally interpreted as a fu ll binary tree, as in Fig. 1: the leaves of the tree correspond to individual IP addresses, and the non-leaf nodes correspond to the remaining IP prefixes. Let P denote the set of all IP prefixes, and I denote the set of all IP addresses. We also use term clusters to denote the IP prefixes.
 We define an IPTree T prefixes P  X  P , and whose leaves are each associated with a label, i.e., mal icious or non-malicious. An IPtree can thus be interpreted as a classification functio n for the IP addresses I : an IP address i gets the label associated with its longest matching prefix in P . Fig. 1 shows an example of an IPtree. We define the size of an IPtree to be the number of leaves it has. For example, in F ig. 1(a), the size of the IPtree is 6.
 As described in Sec. 1, we focus on online learning in this pap er. A typical point of comparison used in the online learning model is the error of the optimal offline fixed algorithm. In this case, the optimal offline fixed algorithm is the IPtree of a given siz e k i.e., the tree of size k that makes Figure 1: IPTrees: example and real. Recall that an IP addres s is interpreted as a 32-bit string, read from left to right. This defines a path on the binary tree, goin g left for 0 and right for 1. An IP prefix is denoted by IP /n , where n indicates the number of bits relevant to the prefix. the fewest mistakes on the entire sequence. However, if the t rue underlying IPtree may change over time, a better point of comparison would allow the offline tre e to also change over time. To make such a comparison meaningful, the offline tree must pay an add itional penalty each time it changes (otherwise the offline tree would not be a meaningful point of comparison  X  it could change for each IP address in the sequence, and thus make no mistakes). We the refore limit the kinds of changes the offline tree can make, and compare the performance of our algo rithm to every IPtree with k leaves, as a function of the errors it makes and the changes it makes.
 We define an adaptive IPtree of size k to be an adaptive tree that can (a) grow nodes over time so long as it never has more than k leaves, (b) change the labels of its leaf nodes, and (c) occas ionally reconfigure itself completely. Our goal is to develop an onli ne algorithm T such that for any se-quence of IP addresses, (1) for every adaptive tree T  X  of size k , the number of mistakes made by T is bounded by a (small) function of the mistakes and the chang es of types (a), (b), and (c) made by , and (2) T uses no more than  X  O ( k ) space. In the next section, we describe an algorithm meeting these requirements. In this section, we describe our main algorithm TrackIPTree , and present theoretical guarantees on its performance. At a high-level, our approach keeps a numbe r of experts in each prefix of the IPtree, and combines their predictions to classify every IP address. The inherent structure in the IPtree allows us to decompose the problem into a number of exp ert problems, and provide lower memory bounds and better guarantees than earlier approache s.
 We begin with an overview. Define the path-nodes of an IP address to be the set of all prefixes of i in
T , and denote this set by P i,T . To predict the label of an IP i , the algorithm looks up all the path-nodes in P for i . To update the tree, the algorithm rewards the path-nodes th at predicted correctly, penalizes the incorrect ones, and modifies the tree structure if necessary .
 To fill out this overview, there are four technical questions that we need to address: (1) Of all the path-nodes in P correct label to predict at a particular path-node in P grow the IPtree appropriately, ensuring that it grows prima rily the prefixes needed to improve the classification accuracy? (4) How do we ensure that the size of the IPtree stays bounded by m ? We address these questions by treating them as separate subpro blems, and we show how they fit together to become the complete algorithm in Figure 3.1. 3.1 Subproblems of TrackIPTree We now describe our algorithm in detail. Since our algorithm decomposes naturally into the four subproblems mentioned above, we focus on each subproblem se parately to simplify the presentation. We use the following notation in our descriptions: Recall fr om Sec. 2 that m is the maximum number of leaves allowed to our algorithm, k is the size of the optimal offline tree, and P of path-nodes, i.e., the prefixes of IP i in the current IPtree T .
 Relative Importance of the Path Nodes First, we consider the problem of deciding which of the prefix nodes in the path P 10]. We set an expert in each node, and call them the path-node experts , and for an IP i , we consider the set of path-node experts in P sleeping experts algorithm makes predictions using the awa ke experts, and intuitively, has the goal of predicting nearly as well as the best awake expert on the in stance i 1 . In our context, the best awake expert on the IP i corresponds to the prefix of i in the optimal IPtree, which remains sleeping until the IPtree grows that prefix. Fig. 2(a) illustrates the sleeping experts framework in our context: the shaded nodes are  X  X wake X  and the rest are  X  X sleep X .
 Specifically, let x To predict on IP address i , the algorithm chooses the expert at node t with probability x update, the algorithm penalizes all incorrect experts in P  X  = 0 . 8 ). It then renormalizes the weights of all the experts in P i,T so that their sum S i,T does not change. (In our proof, we use a slightly different version of the sleeping experts algorithm [4]). Deciding Labels of Individual Nodes Next, we need to decide whether the path-node expert at a node n should predict positive or negative. We use a different expe rts algorithm to address this subproblem  X  the shifting experts algorithm [12]. Specifically, we allow each node n to have two additional experts  X  a positive expert, which always predic ts positive, and a negative expert, which always predicts negative. We call these experts node-label experts.
 Let y with y probability y increases the weight of the correct node-label expert by  X  , and decreases the weight of the incorrect node-label expert by  X  (upto a maximum of 1 and a minimum of 0). Note that this algorit hm naturally adapts when a leaf of the optimal IPtree switches labels  X  the relevant node in our IPtree will slowly shift weights from the incorrect node-label expert to the co rrect one, making an expected 1 in the process. Fig. 2(b) illustrates the shifting experts s etting on an IPtree: each node has two experts, a positive and a negative. Fig. 3 shows how it fits in w ith the sleeping experts algorithm. Building Tree Structure We next address the subproblem of building the appropriate s tructure for or the optimal IPtree must also make the same mistakes. Since TrackIPTree cannot distinguish between these two situations, it simply splits any node that makes sufficient mistakes. In particular, TrackIPTree starts with only the root node, and tracks the nu mber of mistakes made at every node. Every time a leaf makes 1 and initializes the relevant path-node experts and node-la bel experts of the children. In effect, it is as if the path-node experts of the children had been asleep ti ll this point, but will now be  X  X wake X  for the appropriate IP addresses.
 TrackIPTree waits for 1 with noisy data  X  otherwise, it would split a node every time t he optimal tree made a mistake, and the IPtree would grow very quickly. Note also that it naturally i ncorporates the optimal IPtree growing a leaf; our tree will grow the appropriate nodes when that lea f has made 1 Bounding Size of IPtree Since TrackIPTree splits any node after it makes 1 that the IPtree it builds is split much farther than the optim al IPtree  X  TrackIPTree does not know when to stop growing a subtree, and it splits even if the same m istakes are made by the optimal IPtree. While this excessive splitting does not impact the p redictions of the path-node experts or the node-label experts significantly, we still need to ensure th at the IPtree built by our algorithm does not become too large. We do this by framing it as a paging problem [20]: consider eac h node in the IPtree to be a page, and the maximum allowed nodes in the IPtree to be the size of th e cache. The offline IPtree, which has k leaves, needs a cache of size 2 k . The IPtree built by our algorithm may have at most m leaves (and thus, 2 m nodes, since it is a binary tree), and so the size of its cache i s 2 m and the offline cache is 2 k . We may then select nodes to be discarded as if they were pages in the cache once the IPtree grows beyond 2 m nodes; so, for example, we may choose the least recently used nodes in the IPtree, with LRU as the paging algorithm. Our analysis sh ows that setting m = O ( k suffices, when TrackIPTree uses F LUSH -W HEN -F ULL (FWF) as its paging algorithm  X  this is a simple paging algorithm that discards all the pages in the ca che when the cache is full, and restarts with an empty cache. We use FWF here for a clean analysis, and e specially since in simple paging models, many algorithms achieve no better guarantees [20]. For our experiments, we implement LRU, and our results show that this approach, while perhaps n ot sophisticated, still maintains an accurate predictive IPtree. 3.2 Analysis In this section, we present theoretical guarantees on Track IPTree X  X  performance. We show our algorithm performs nearly as well as best adaptive k -IPtree, bounding the number of mistakes made by our algorithm as a function of the number of mistakes, numb er of labels changes and number of complete reconfigurations of the optimal such tree in hindsi ght.
 Theorem 3.1 Fix k . Set the maximum number of leaves allowed to the TrackIPTree algorithm m to on the its leaves over the sequence z , and R reconfigured itself over z .
 The algorithm TrackIPTreeensures that on any sequence of in stances z , for each T , the number of mistakes made by TrackIPTree is at most (1 + 3  X  ) M probability at least 1  X  1 In other words, if there is an offline adaptive k -IPtree, that makes few changes and few mistakes on the input sequence of IP addresses, then TrackIPTree will also make only a small number of mistakes. Due to space constraints, we present the proof in t he technical report [23]. We now describe our evaluation set-up: data, practical chan ges to the algorithm, and baseline schemes that compare against. While there are many issues th at go into converting the algorithm in Sec. 3 for practical use, we describe here those most importa nt to our experiments, and defer the rest to the technical report [23]. Data We focus on IP addresses derived from mail data, since spamme rs represent a significant frac-tion of the malicious activity and compromised hosts on the I nternet [6], and labels are relatively easy to obtain from spam-filtering run by the mail servers. Fo r our evaluation, we consider labels from the mail servers X  spam-filtering to be ground truth. Any errors in the spam-filtering will influ-ence the tree that we construct and our experimental results are limited by this assumption. One data set consists of log extracts collected at the mail se rvers of a tier-1 ISP with 1 million active mailboxes. The extracts contain the IP addresses of t he mail servers that send mail to the ISP, the number of messages they sent, and the fraction of tho se messages that are classified as spam, aggregated over 10 minute intervals. The mail server X  s spam-filtering software consists of a combination of hand-crafted rules, DNS blacklists, and Bri ghtmail [1], and we take their results as labels for our experiments. The log extracts were collected over 38 days from December 2008 to January 2009, and contain 126 million IP addresses, of which 105 million are spam and 21 million are legitimate.
 The second data set consists of log extracts from the enterpr ise mail server of a large corporation with 1300 active mailboxes. These extracts also contain the IP ad dresses of mail servers that attempted to send mail, along with the number of messages they sent and the fraction of these messages that were classified spam by SpamAssassin [2], aggregated over 10 minu te intervals. The extracts contain 28 million IP addresses, of which around 1.2 million are legiti mate and the rest are spammers. Note that in both cases, our data only contains aggregate inf ormation about the IP addresses of the mail servers sending mail to the ISP and enterprise mail servers, and so we do not ha ve the ability to map any information back to individual users of the ISP or e nterprise mail servers. TrackIPTree For the experimental results, we use LRU as the paging algori thm when nodes need to be discarded from the IPtree (Sec. 3.1). In our implementa tion, we set TrackIPTree to discard 1% of m , the maximum leaves allowed, every time it needs to expire no des. The learning rate  X  is set to 0.05 and the penalty factor  X  for sleeping experts is set to 0.1 respectively. Our results are not affected if these parameters are changed by a factor of 2-3.
 While we have presented an online learning algorithm, in pra ctice, it will often need to predict on data without receiving labels of the instances right away . Therefore, we study TrackIPTree X  X  accuracy on the following day X  X  data, i.e., to compute predi ction accuracy of day i , TrackIPTree is allowed to update until day i  X  1 . We choose intervals of a day X  X  length to allow the tree X  X  pre dictions to be updated at least every day.
 Apriori Fixed Clusters We compare TrackIPTree to two sets of apriori fixed clusters : (1) network-aware clusters, which are a set of unique prefixes derived fro m BGP routing table snapshots [17], and (2) /24 prefixes. We choose these clusters as a baseline, as th ey have been the basis of measurement studies discussed earlier (Sec. 1), prior work in IP-based c lassification [19, 24], and are even used by popular DNS blacklists [3].
 We use the fixed clusters to predict the label of an IP in the usu al manner: we simply assign an IP the label of its longest matching prefix among the clusters .Of course, we first need to assign these clusters their own labels. To ensure that they classif y as well as possible, we assign them the optimal labeling over the data they need to classify; we do th is by allowing them to make multiple passes over the data. That is, for each day, we assign labels s o that the fixed clusters maximize their accuracy on spam for a given required accuracy on legitimate mail 2 . It is clear that this experimental set-up is favourable to the apriori fixed clusters.
 We do not directly compare against the algorithm in [11], as i t requires every unique IP address in the data set to be instantiated in the tree. In our experiment s (e.g., with the ISP logs), this means that it requires over 90 million leaves in the tree. We instead foc us on practical prior approaches with more cluster sizes in our experiments. We report three sets of experimental results regarding the p rediction accuracy of TrackIPTree using the experimental set-up of Section 4. While we do not provide an extensive evaluation of our al-gorithm X  X  computational efficiency, we note that our (unopt imized) implementation of TrackIPTree takes under a minute to learn over a million IP addresses, on a 2.4GHz Sparc64-VI core. Our results compare the fraction of spamming IPs that the clu sters classify correctly, subject to the constraint that they classify at least x % legitimate mail IPs correctly (we term this to be the coverage of the legitimate IPs required). Thus, we effectiv ely plot the true positive rate against the true negative rate. (This is just the ROC curve with the x -axis reversed, since we plot the true positive against the true negative, instead of plotting the true positive against the false positive.) Experiment 1: Comparisons with Apriori Fixed Clusters Our first set of experiments compares the performance of our algorithm with network-aware cluste rs and /24 IP prefixes. Figs. 4(a) &amp; 4(b) illustrate the accuracy tradeoff of the three sets of cluste rs on the two data sets. Clearly, the accuracy of TrackIPTree is a tremendous improvement on both sets of ap riori fixed clusters  X  for any choice of coverage on legitimate IPs, the accuracy of spam IPs by Tra ckIPTree is far higher than the apriori fixed clusters, even by as much as a factor of 2.5. In particula r, note that when the coverage required on legitimate IPs is 95% , TrackIPTree achieves 95% accuracy in classifying spam on both data sets, compared to the 35  X  45% achieved by the other clusters.
 In addition, TrackIPTree gains this classification accurac y using a far smaller tree. Table 1 shows the median number of leaves instantiated by the tree at the en d of each day. (To be fair to the fixed clusters, we only instantiate the prefixes required to class ify the day X  X  data, rather than all possible prefixes in the clustering scheme.) Table 1 shows that the tre e produced by TrackIPTree is a factor of 2.5-17 smaller with the ISP logs, and a factor of 20-100 sma ller with the enterprise logs. These numbers highlight that the apriori fixed clusters are perhap s too coarse to classify accurately in parts of the IP address space, and also are insufficiently aggregat ed in other parts of the address space. Experiment 2: Changing the Maximum Leaves Allowed Next, we explore the effect of changing m , the maximum number of leaves allowed to TrackIPTree. Fig. 4 (c) &amp; 4(d) show the accuracy-coverage tradeoff for TrackIPTree when m ranges between 20,000-200,000 leaves for the ISP logs, and 1,000-50,000 leaves for the enterprise logs. Clearly, i n both cases, the predictive accuracy increases with m only until m is  X  X ufficiently large X   X  once m is large enough to capture all the distinct subtrees in the underlying optimal IPtree, the pre dictive accuracy will not increase. While the actual values of m are specific to our data sets, the results highlight the impor tance of having a space-efficient and flexible algorithm  X  both 10,000 and 100, 000 are very modest sizes compared to the number of possible apriori fixed clusters, or the size of t he IPv4 address space, and this suggests that the underlying decision tree required is indeed of a mod est size.
 Experiment 3: Does a Dynamic Tree Help? In this experiment, we demonstrate empirically that our algorithm X  X  dynamic aspects do indeed significantly enh ance its accuracy over static clustering schemes. The static clustering that we compare to is a tree ge nerated by our algorithm, but one that learns over the first z days, and then stays unchanged. For ease of reference, we cal l such a tree a z -static tree; in our experiments, we set z = 5 and z = 10 . We compare these trees by examining separately the errors incurred on legitimate and spam IPs. Fig. 4(e) &amp; 4(f) compare the errors of the z -static trees and the dynamic tree on legitimate and spam IPs respectively, using the ISP logs. Clearly, both z -static trees degrade in accuracy over time, and they do so on both legitimate and spam IPs. On the other hand, t he accuracy of the dynamic tree does not degrade over this period. Further, the in error grow s with time; after 28 days, the 10-static tree has almost a factor of 2 higher error on both spam IPs and l egitimate IPs.
 Discussion and Implications Our experiments demonstrate that our algorithm is able to ac hieve high accuracy in predicting legitimate and spam IPs, e.g., i t can predict 95% of the spam IPs cor-rectly, when misclassifying only 5% of the legitimate IPs. However, it does not classify the IPs perfectly. This is unsurprising  X  achieving zero classifica tion error in these applications is practi-cally infeasible, given IP address dynamics [25]. Neverthe less, our IPtree still provides insight into the malicious activity on the Internet.
 As an example, we examine a high-level view of the Internet ob tained from our tree, and its impli-cations. Fig. 1(b) visualizes an IPtree on the ISP logs with 5 0,000 leaves. It is laid out so that the root prefix is near the center, and the prefixes grow their chil dren outwards. The nodes are coloured depending on their weights, as shown in Table 2: for node t , define w where Q is the set of prefixes of node t (including node t itself. Thus, the blue central nodes are the large prefixes (e.g., /8 prefixes), and the classification the y output is slightly malicious; this means that an IP address without a longer matching prefix in the tree is typically classified to be malicious. This suggests, for example, that an unseen IP address is typi cally classified as a spammer by our IPtree, which is consistent with the observations of networ k administrators. A second observation we can make is that the tree has many short branches as well as l ong branches, suggesting that some IP prefixes are grown to much greater depth than others. This m ight happen, for instance, if active IP addresses for this application are not distributed uniform ly in the address space (and so all prefixes do not need to be grown at uniform rates), which is also what we might expect to see based on prior work [16].
 Of course, these observations are only examples; a complete analysis of our IPtree X  X  implications is part of our future work. Nevertheless, these observations s uggest that our tree does indeed capture an appropriate picture of the malicious activity on the Inte rnet. In the networking and databases literature, there has been m uch interest in designing streaming algorithms to identify IP prefixes with significant network t raffic [7, 9, 27], but these algorithms do not explore how to predict malicious activity. Previous I P-based approaches to reduce spam particularly useful since they are so dynamic [15, 19, 25]. Z hang et al [26] also examine how to predict whether known malicious IP addresses may appear at a given network, by analyzing the co-occurence of all known malicious IP addresses at a number of different networks. More closely related is [21], who present algorithms to extract prefix-ba sed filtering rules for IP addresses that may be used in offline settings. There has also been work on comput ing decision trees over streaming data [8, 13], but this work assumes that data comes from a fixed distribution. We have addressed the problem of discovering dynamic malici ous regions on the Internet. We model this problem as one of adaptively pruning a known decision tr ee, but with the additional challenges coming from real-world settings  X  severe space requirement s and a changing target function. We developed new algorithms to address this problem, by combin ing  X  X xperts X  algorithms and online paging algorithms. We showed guarantees on our algorithm X  X  performance as a function of the best possible pruning of a similar size, and our experimental res ults on real-world datasets are orders of magnitude better than current approaches.
 Acknowledgements We are grateful to Alan Glasser and Gang Yao for their help wit h the data analysis efforts.
