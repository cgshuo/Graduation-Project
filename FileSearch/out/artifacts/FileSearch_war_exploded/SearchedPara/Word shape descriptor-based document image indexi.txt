 ORIGINAL PAPER Ehtesham Hassan  X  Santanu Chaudhury  X  M. Gopal Abstract In this paper, we propose a novel feature repre-sentation for binary patterns by exploiting the object shape information. Initial evaluation of the representation is per-formed for Bengali and Gujarati script character classifica-tion. The extension of the representation for word images is presented subsequently. The proposed feature representation in combination with distance-based hashing is applied for defining novel word image-based document image indexing and retrieval framework. The concept of hierarchical hashing is utilized to reduce the retrieval time complexity. In addi-tion, with the objective of reduction in the size of hashing data structure, the concept of multi-probe hashing is extended for binary mapping functions. The exhaustive experimental evaluation of the proposed framework on a collection of doc-uments belonging to Devanagari, Bengali and English scripts has yielded encouraging results.
 Keywords Shape descriptor  X  Document indexing  X  Multi-probe hashing 1 Introduction Digitization of documents across the world has created large collection of document images. Indexing of these docu-ment images poses a challenging problem. In the tradi-tional document image indexing systems, optical character recognition (OCR) is applied to convert the document image to electronic representation. The recognized charac-ters/words are further used to build indexing scheme for doc-uments. The precondition for this approach is availability of robust optical character recognizer for the script. However, for old and degraded documents, and for the scripts for which reliable OCR X  X  are not available, this approach cannot be fol-lowed. In such situations, we need to use image-based index-ing and retrieval schemes for the document collection. The indexing scheme then exploits the image properties of the document content. The word image-based document index-ing and retrieval provides a practical solution for the indexing of non-OCRed document collection. The textual contents in the document, that is word images, are used for generating indices. The primary challenges involved in defining a word image-based document indexing framework are (i) formu-lating a unique feature-based representation for word images and (ii) developing computationally inexpensive method for indexing large collection of document images. In this paper, we focus on both the issues related to word-based document indexing framework. Following are the major contributions in this paper: 1. We propose a novel feature representation scheme for 2. The paper presents a new word-based indexing and
This paper is organized as follows: Sect. 2 presents review of related works in the field of word image representation and document indexing. Section 3 introduces the proposed doc-ument indexing scheme. In Sect. 4 , the algorithmic frame-work for computation of proposed feature representation is described. Section 5 briefly reviews the LSH and presents discussion on DBH and its extension in the hierarchical framework. In Sect. 6 , we present novel approach for multi-probe hashing in DBH framework. The experimental results of proposed document indexing framework and multi-probe hashing are presented in Sect. 7 . The Sect. 8 concludes and presents the perspective of our work. 2 Related works Considering the large amount of existing work available on word image representation and document image indexing, our work relates with a large body of literature. In order to simplify the discussion, we discuss both the subjects sepa-rately. 2.1 Word image representation The available research in the area of word image represen-tation has discussed character-like coding and shape-based representation as two primary strategies. The character-like codingrepresentationisgeneratedbyextractingsomeobjects from the word image through classical or morphological seg-mentation. Each object is assigned a code based on shape similarity to labeled data. The codes are concatenated in respective order of objects to generate the word image code. In recent works, Shijian et al. [ 24 ] have proposed a word shape coding scheme considering a word as a single compo-nent that does not require character segmentation. It defines word image by a set of topological character shape features including character ascenders/descenders, character holes and reservoirs. Simone et al. [ 28 ] have defined a collec-tion specific character prototypes from the character objects. The set of character prototypes are further used for word image representation. Nakayama [ 33 ] have defined word shape tokens for printed word images by sequence of charac-ter shape codes. The character shape codes are defined by the set of graphical features. In [ 5 ], word shape code is generated based on standard features as ascenders, descenders, charac-ter holes, deep eastward and westward concavity and hori-zontal-line intersections. The character-like coding schemes for word images are very much script specific, and gener-alization of these schemes for different scripts is a difficult task. In addition, detection of various word image features (topological and morphological) is very sensitive to noise and document image quality.

The shape-based schemes utilize the appearance of word as an entity, using its features like outer boundary, horizontal and vertical lines, inner circles and sharp turns for represen-tations. The earliest work on word spotting presented in [ 10 ] has used word contours in addition with autocorrelation coef-ficients as features. Madhavanath et al. have followed holistic approach for handwritten word images representation [ 26 ]. In [ 6 ], envelope curve-based signatures of the handwritten word images are used for signature verification. The enve-lopes are derived as sequence of external points with respect to the principal axis of the signature. On the similar lines, contours of the handwritten word image have been used for representation in [ 2 ]. The recent development of shape con-text descriptor has performed excellently for various recogni-tion problems [ 7 ]. However, the computational complexity of similarity search using rich set of local descriptor represented by shape contexts is very high. In [ 23 ], the skeleton of word images has been used to represent word shape. The word shape signature is formulated by computing the shape con-text over the points sampled over the skeleton of word image. However, the skeletons are highly noise sensitive. In general, shape-based features define geometric relations between the set of points over the word object. The feature represents the visual characteristics of word shape by these geometric rela-tions. Therefore, the exploitation of these features provide more intuitive and flexible approach for defining script inde-pendent word image representation. However, in the case of degraded and low-quality document images, techniques such as contour detection and skeletonization for shape infor-mation extraction have serious limitations. In contrast, pro-posed feature extraction scheme has following advantages: We apply novel grid-based approach for shape information extraction which does not require edge, contour or skeleton detection. The approach implicitly handles general scenar-ios and can distinguish words having similar outer envelopes but different inner contours. In addition, the proposed feature represents word objects as constant dimensional vectors that give flexibility to use direct comparison methods for similar-ity matching. 2.2 Document indexing An efficient indexing scheme performs accurate grouping of similar objects and supports fast retrieval. In the context of document indexing, different techniques have been reported in literature [ 8 , 29 , 31 , 41 ]. The early work of Doermann dis-cussed some old techniques for content-based document image indexing and retrieval [ 13 ]. Conventionally latent semantic indexing (LSI) is considered effective for index-ing [ 12 ]. LSI detects the most representative features for document representation and discovers the global structure of document. Similarly in [ 41 ], locality preserving index-ing (LPI) is applied for detecting the discriminative features for document representation. LPI discovers the local geo-metrical structure of document space and obtains a compact document representation subspace that best detects the essen-tial semantic document structure. In the case of non-OCR X  X d documents,computationofvectorspacerepresentationposes a challenging problem. In [ 27 ], the indexing scheme is pro-posed by grouping the word images to equivalence classes. The equivalence classes are generated by performing the matching of word images. In [ 28 ], self-organizing map is applied for unsupervised character clustering. The words are represented by vector codes obtained by clustering. How-ever in general, the character segmentation from Indian script words is a challenging problem because of the complicated positioning of glyphs. In [ 23 ], word spotting-based method is presented for indexing of historical documents. The word representation is defined by thresholded shape context com-puted on word skeleton. These word shape vectors are used to maintain a lookup table. The retrieval is done by mapping the query onto lookup table. Saykol et al. [ 35 ]havepre-sented document retrieval systems for Ottoman documents, by maintaining codebook consisting of occurrences of dif-ferent symbols representing rectangular region containing words.

The hashing-based indexing for various applications is a popular research problem. Hashing-based schemes generate the object indices by projecting it to low-dimensional hash space. The process generates hash table containing multiple buckets. Each bucket represents group of objects correspond-ing to an unique index. The retrieval process includes query index generation by applying the same mapping function to query. The relevant documents are obtained by performing similarity search over the objects in bucket corresponding to query index. The work presented in [ 31 ] demonstrated one of the earliest application of Geometric hashing for handwritten document indexing. Locality sensitive hashing (LSH) intro-duced by Indyk and Motwani is state-of-the-art method for finding similar objects in large data collection [ 3 ]. The LSH solves approximate nearest neighbor search in O ( n 1 / 1 for  X  0, by projecting the high-dimensional data points to low-dimensional hash space with high probability that similar points are mapped to same location. In recent years, many applications have applied LSH for performing simi-larity search in high-dimensional spaces [ 18 , 30 , 36 , 40 ]. The LSH-based indexing assumes the uniform distribution of objects in feature space for hashing. In this case, the retrieval success probability is increased by generating multiple hash tables and collecting objects corresponding to query buckets of all hash tables for similarity search. However, the gener-ation of multiple hash tables increases space complexity of data structure containing the indexing information. Addition-ally, the assumption for uniform distribution does not satisfy for most of the practical applications. In recent effort toward reducing the size of LSH data structure, concept of multi-probe hashing has been proposed [ 25 ]. The multi-probing reduces the required number of hash tables by increasing the utilization of single hash table. The multi-probe hashing selects more than one bucket from each hash table for prob-ing, therefore increasing the usability of hash tables. In this way, the multi-probing considerably reduces the number of hash tables required for high success probability. However, the definition of locality sensitive hashing function requires information about object space. The distance-based hashing is a recent development in hashing methods, which preserves the distance between objects in hashing space [ 38 ]. The dis-tance-based hashing functions are defined over set of pivot objects using the line projection formula. The prerequisite for distance-based hashing is the availability of defined dis-tance measure for the object space. The applicability of DBH has not yet been widely explored for different practical appli-cations. Also, multi-probing framework can not be directly extended for DBH because of the different characteristic of the mapping functions. In this paper, we have used DBH for indexing document images because of its distance pre-serving property. A new approach for the selection of pivot objects for hashing functions has been explored for increas-ing the collision probability. A hierarchical scheme for the organization of hashing tables has been presented. We have also defined a novel framework for multi-probing in case of binary mapping function and have shown its applicability to distance-based hashing function. 3 Overview: document indexing framework In this section, we present an overview of the proposed document image retrieval system. Our document indexing scheme follows conventional hashing-based indexing frame-work (Fig. 1 ). Here, we apply distance-based hashing func-tions for generating the indices. The initial steps of off-line processing include document preprocessing (deskewing and binarization).Thesegmentationroutineextractswordimages from the document image collection. The meaningful word images for generating the document indices are selected using word length in terms of pixels as thresholding crite-rion, for example, most of the English words having less than four characters are not required for indexing. These words in addition with stop words, punctuation and typo-graphical marks are filtered out by applying conventional thresholds (aspect ratio and word length). The word images are represented by the proposed shape descriptor (discussed in Sect. 4 ). The next step of off-line process includes gen-eration of distance-based hash functions (discussed in Sect. 5 ). Each hashing function is defined for a pair of data points defined as pivots. Instead of conventional approach, we con-sider precomputed cluster centers obtained by clustering the word images, as pivot objects. These pivot objects are used to generate a family of hashing functions H . The hashing function generation complexity is O ( X  2 N 2 ) . Here, N is the word image count, and  X  is the ratio of cluster count to N . For L hash tables, we generate g i for i = 1 ,..., L by ran-dom selection of k functions from H . Using each function g the indices for word images belonging to complete collection are generated, and the procedure is repeated for all the hash tables. Each separable set obtained after the application of g over the set forms a bucket. In this respect, a bucket remains a metric region and organizes all word images from the met-ric domain falling into it. Each hash table requires O ( kN distance calculations (each calculation signifies one projec-tion operation). The storage architecture of the hash table is based on 2-D array of buckets used for storing data points. This requires O ( kLN ) space to record the k -bit coordinate values corresponding to N word images for L hash tables.
The online process includes retrieval by performing the similarity search based on query. This includes query image generation from the query text string. The next step computes shape descriptor for the query image. The query is indexed to all the hash tables using hashing function g i . The data points from the query bucket (bucket to which query is hashed) in all the hash tables are collected. The word images similar to query word are retrieved by performing similarity search over the group of collected data points. Theoretically, the DBH does not guarantee sublinear search complexity. Nev-ertheless in practice, it achieves good approximation ratio, and it is confirmed by our experimental results. 4 Feature representation for binary patterns The present section explains the proposed feature extraction and representation scheme. The feature defines a generic representation scheme applicable for different binary pat-terns including word, character and symbol images. Shape information is an important visual cue for object recogni-tion. In the available literature, various image descriptors utilizing the object shape information have been proposed [ 17 , 22 , 32 , 37 ]. These descriptors represent the shape infor-mation in various forms including chain code, polygonal approximations, curvature, Fourier and moment descriptors. Broadly, these methods are categorized as contour-based and region-based shape descriptors. The contour-based shape descriptors make use of only the boundary information of shape extracted by conventional edge or contour detection approach. The region-based shape descriptors exploit the pixel intensity information within shape region.

We consider the boundary-based shape descriptor for defining binary patterns, ensuring that the inner contours in complex shapes are also utilized for descriptor compu-tation. The information of the inner contours is utilized to give distinct representation to objects having similar outer boundary, for example, Devanagari character pairs {/sha, /pa} and {/ba, /va} in Fig. 2 . The conventional approach of edge or contour detection for boundary extraction is highly noise sensitive. To overcome the limitations of edge detec-tion-based boundary extraction, novel grid-based approach is followed. The computation process for feature representa-tion is divided as descriptor point extraction for shape repre-sentation and feature computation from the set of descriptor points.
 4.1 Descriptor point extraction The conventional approach to extract points for boundary-based descriptor is by detecting object contour and randomly sampling the points from the contour coordinate set. The object X  X  shape is represented by point set P ={ P i } for i { 1 ,..., l } .Theset P is further applied for descriptor com-putation. The contour extraction approaches have inherent limitation because of the involvement of edge detection. In addition, the random sampling does not guarantee uniform distribution of points on the boundary. In our approach, we convert the gray scale image to binary image by standard binarization routine. The preprocessing step includes object-bound detection and normalization of the bounded image using aspect ratio preserving scaling transform. We overlay a logical grid of constant size over the normalized image. The transition points while traversing over the grid lines are set of descriptor points P . In addition, points lying on the boundary and coinciding with grid lines are also selected as descrip-tor points. A transition point is marked based on intensity change, that is 0  X  1or1  X  0. The grid-based approach for descriptor point extraction gives better distribution with respect to distance and orientation for complex shapes having multiple inner contours. In addition, the shape information embedded in inner contours of complex shapes are also used efficiently. Figure 3 a shows the red dots as transition points on the horizontal and vertical grid lines. 4.2 Shape representation The density of shape descriptor points varies with the com-plexity of object shape in the image. The distribution of these points based on relative arrangement is represented by log polar histogram. For a point set P ={ P i } for i ={ 1 ,..., the log polar histogram is defined as H ( k ) =[ q = p The histogram H i ( k ) is the shape context of point P i Shape context represents count of points falling in each bin k , with log polar origin centered at P i . It represents the arrangements of descriptor points with respect to the point under consideration. The bins are uniform in log polar space, making it more sensitive to closely located points. Let D be the distance, and A be the angle matrix for point set [  X  and n are number of distance and angular bins used for histo-gram computation. For point P i , we represent the bi n ( as h ( p , q ) = Here Here, h i ( : , : ) represents the shape context corresponding to point P i . The relative arrangement of descriptor points is unique for each word shape. The integration of all shape contexts represents the global distribution of point-pairs. Let h sum is the integration of all shape contexts, that is, h sum the cumulative histogram that represents distribution of log distances and orientations between the points in P .In h sum each bi n ( p , q ) represents the count of points, which are rel-atively arranged within distance [ d p  X  1 , d p ] and orientation [  X  tion histogram ( pdh ). The point distribution histogram rep-resents the structural arrangement of a shape and provides easy access to inherent semantic information embedded in the object shape. Similar shapes give rise to similar point dis-tribution histograms. The local shape properties represented by closely positioned point-pairs are identified by the ris-ing gradient of normalized h sum as seen from the front in Fig. 4 a.

The global shape properties represented by distantly posi-tioned point-pairs are identified by the peak and falling sur-face of the normalized h sum . The normalized h sum is treated as image, and we take its Fourier transform. The Fourier transform represents the characteristic function of point dis-tribution histogram and captures the periodicity in h sum The amplitude information of Fourier coefficients define the shape descriptor for object feature representation (Fig. 4 b). The feature computation steps are summarized as:  X  Extraction of point set P and computation of shape con- X  Computation of h sum as l i = 1 h i  X  Shape descriptor F ( P ) is defined by the magnitude of
Initial empirical evaluation of the proposed feature repre-sentation is performed on two sample character image col-lection of Bengali (Fig. 5 a) and Gujarati (Fig. 5 b) scripts. The Bengali script collection consists of approx. 17,000 images belonging to 49 categories. The Gujarati script collection consists of approx. 13,100 images belonging to 240 catego-ries. In the Gujarati collection, large number of categories are generated because of the zone-wise character segmenta-tion [ 19 ]. These categories represent the symbols generated as unique characters, modifiers and primitives obtained by different combination of characters. The conventional parti-tioning approach of 70% of complete data as training set and remaining 30% as testing set is adopted. After preprocess-ing steps of bound detection and normalization to 32  X  32, the descriptor points have been extracted by placing 16  X  grid. The extension of SVM for multi-category classification of Bengali characters is done using one against all (OAA) framework. For Gujarati character classification, we adapted direct acyclic graph (DAG) framework [ 34 ]. The multi-class SVM results are with Gaussian kernels, and parameter tuning is performed by grid-based search. First, SVM-based classifi-cation accuracy over the training set is computed. For Bengali characters, accuracy of 98.43% is achieved for parameters ( m = 35 , n = 30). For Gujarati characters, accuracy of 98.72% is achieved for parameters ( m = 35 , n = 36). Next, test set classification using KNN and SVM classifier is per-formed. The results for different sets of descriptor param-eters are presented in Table 1 . These results clearly show that the feature representation has the ability to discrim-inate the binary patterns. In addition, the proposed shape descriptor is also used for MNIST image set representa-tion [ 21 ]. With 25,000 randomly selected training examples from the complete training set, the DAG-SVM-based classi-fication achieved 93.18% accuracy over the training exam-ples and 91.45% accuracy over the complete test set. The shape context-based feature, which is state of the art in the field, achieves much higher accuracy. However, the shape matching procedure involving shape context is computation-ally expensive, because the correspondence determination between the shapes is established by weighted bipartite graph matching [ 7 ]. The global nature of the proposed descriptor provideslessaccurateresultthangraphmatching-basedalgo-rithmsbutprovidesmorethan91%accuracyinmoreefficient fashion. 4.3 Extension for word image representation In case of word objects, the character sequence informa-tion in the descriptor suffers because of the global nature of h sum . The empirical evaluations have shown that char-acter sequence information can be incorporated by splitting the word image in constant number of partitions. However, segmenting a word image in predetermined number of par-titions is a challenging problem. In the context of Indian scripts, the problem is further compounded because of the modifiers above and below the characters in word formation (Fig. 6 shows use of modifiers for word formation). These problems make the character segmentation process highly error prone. Therefore, to make the shape descriptor invari-ant to symbol/character segments, we split the word image in partitions of equal width (e.g. the word image is partitioned in four parts in Fig. 7 ). For each partition, the h sum is computed independently with points corresponding to the partition. The final histogram h final is obtained by concatenating normal-ized h sum corresponding to all the partitions following their sequence. If there are num _ parts partitions, the dimension of final histogram h final is m  X  n  X  num _ parts . Such an arrangement helps in preserving the sequence information in a word image, that otherwise suffers in global distribution. In addition, the deformations in partitions of word image will not affect the pdh corresponding to other partitions. The isolated noisy bins from the histogram are filtered out by applying adaptive filtering. Small distortions in the word shape are handled by applying smoothing over an appropriate neighborhood over the final histogram.

The selection of number of partitions is based on heuristics by considering average number of characters in word forma-tion as guidance, for example, most of the Devanagari words are formed by combination of 3 X 5 characters; therefore, we can select 1  X  3 , 1  X  4or1  X  5 partition for splitting the word image. Every unique word is represented distinctly by a combination of global and local shape features. The global shape features define the overall shape of the histogram. The local shape features like internal contours, sharp curves and broken or faded characters contribute in the smoothness of the histogram. The feature representation for the word image is obtained by application of Fourier transform over h final The shape descriptor computation steps are summarized as:  X  Computation of h sum for all partitions w.r.t. points in the  X  Shape descriptor F ( P ) is defined by magnitude of Fou-
Since the final histogram is a sequence of independent his-tograms, the partially matching results can also be retrieved. The image sequence in Fig. 8 shows an example of retrieval based on shape descriptor computation following without and with 1  X  4 partitioning of word image. In case of simi-lar word having different font properties, variations in the outer envelope of word image are not major leaving the low-frequency components of shape descriptor unchanged. The Table 2 shows the average distance between five groups of word images by the proposed shape descriptor (Fig. 9 ). The descriptor parameters are { m = 40 , n = 40, 1  X  4 par-tition}. The number of examples in each group of words are {15, 3, 30, 8 10}.

The discriminative property of the feature is established by observing the diagonal of the distance matrix. The dis-tribution shows close match between the third and fourth word in the sequence because of the approximately similar outer boundary. Nevertheless, the inner contour information in both the words describes them distinctly. The rotation invariance in the shape context can be incorporated in two ways. The first method considers the tangent vector at the point as reference axis for shape context computation. In second method, the reference axis can be aligned with the principal axis of shape to incorporate rotation invariance. The computation process of shape context makes it robust under small geometrical distortions and presence of outliers. The proposed feature represents the object image by constant length vector that can be applied in different applications. In addition, the feature gives the freedom of application of var-ious vector-based methods for performing similarity search.
The initial results on Bengali, Gujarati and Devanagari script characters and words establish the effectiveness of the shape descriptor. The shape-based nature of the representa-tion extends its applicability for different scripts in general. In case of scripts having complex characters and modifiers, forexample,majorityofSouthIndianscripts,densesampling of descriptor points is required. South Indian scripts exhibit complex formation of word images having curly characters with no concept of horizontal line at the top. In this case, histogram parameter selection requires careful analysis, so that discriminative attributes of word shapes are discovered. Additionally, the South Indian words in general have more variation in terms of number of characters. Therefore, the selection of partitions should be such that deformations in word shapes are efficiently addressed at local level. Figure 10 shows Telugu script retrieval with word image representation definedbyproposedshapedescriptor.Thesampleddocument images are collection of old story book pages scanned at 300dpi [ 1 ]. The segmented word image collection consisted of 7,800 images. The descriptor is computed with { m = 38 , n = 30, 1  X  6 partition} with the logical grid placed at the interval of 4 pixels. The Euclidean distance is used for similarity measurement. The results establish that proposed descriptor provides robust representation for words of differ-ent scripts. 5 Distance-based hashing for indexing Index space formed with our feature descriptor is expected to be high dimensional. The inherent semantic structure of the object space can be explored by projecting the data on lower-dimensional space. We use the concept of hashing for defining the lower-dimensional representation of data. It is an efficient method to retrieve -approximate nearest neighbors, whose distance to query is utmost some factor c = 1 +  X  1 larger than the distance from query to actual nearest neighbor.
We begin the discussion with brief review of locality sensi-tive hashing. A short introduction to distance-based hashing is presented in order. The distance-based hashing function is defined over a pair of pivot objects [ 38 ]. We propose clus-tering-based method for the selection of pivot objects for distance-based hashing. Subsequently, the locality sensitiv-ity property of DBH is analyzed using Euclidean distance as similarity measure. Finally, we introduce the novel concept of hierarchical distance-based hashing. 5.1 Locality sensitive hashing (LSH): review The LSH provides a probabilistic solution for the approxi-matenearestneighborsearchproblem[ 20 ].Forsolving( c , R ) nearest neighbor searchproblem inthespace R d withdefined distance measure d , an locality sensitive hash function family is defined as  X  The family H ={ f : R d  X  U } of hashing functions is Here, c is a real number greater than 1.

The LSH function family would be useful, if it satisfies the inequality P 1  X  P 2 . Therefore, if point q is close to p , the hash value of p and q would be same, that is, both points would be hashed in same bucket, whereas if q is placed far from p , then p and q would be less likely to be hashed in the same bucket. The difference between P 1 and P 2 can fur-ther be increased by performing projection by combination of k functions selected randomly, that is, formulating hashing function g (  X  ) by concatenation of k hashing functions. Since (
P of separation. The k -bit real number obtained for each data point after projection is the corresponding hash index. The nearest neighbor search for the query point can be performed by mapping the query to hash space using k -bit function and then performing a linear search over the points falling into the same bucket as query. The search success rate in any projection is increased by generating multiple hash tables, that is, L independent hash tables, and collecting the neigh-bors from these tables to find the nearest neighbor. The large value of parameter k increases the precision of the retrieval; however, the recall rate decreases because of the exponen-tial decrease in collision probability. To ensure satisfactory recall, multiple hash tables are required. Large number of hash tables, that is large L , increases the recall at increased search complexity, but simultaneously precision decreases. Therefore, the selection of L and k should be optimal to dis-tribute the data points sparsely to maintain the advantage of approximate nearest neighbor search. 5.2 Distance-based hashing The LSH defines an indexing scheme: hashing data points using k hashing functions, and increasing the success proba-bility of similarity search by generating multiple hash tables. Following the idea, Vassilis et al. presented the concept of distance-based hashing in [ 38 ]. Fundamentally, the idea comes from the FastMap embedding method [ 15 ]. The DBH is an algorithm to map objects to points in k -dimensional space such that the interobject distances are preserved. The distances represent the dissimilarity between objects. The DBH assumes that the objects are basically points in hypo-thetical Euclidean space with defined distance measure. The heart of DBH is the projection of objects onto a care-fully selected line while maintaining their distances. The line projection function defines one such mapping [ 15 ]. For two objects ( x 1 , x 2 ) in space ( X , D ) having objects repre-sented as points of unknown dimension, the line projection F 1 , x 2 : X  X  L for object x is defined as
F L defines the line connecting points ( x 1 , x 2 ) . The only requirement of the function in Eq. ( 1 ) is availability of dis-tance D ; therefore, mapping F is also applicable for arbitrary spaces. The extension of mapping the objects to k dimen-sional space is performed by projection using k -mapping functions. For every mapping function, two pivot objects ( x as coordinate axis, and the coordinate value along this axis for each object is determined by ( 1 ). In case of X being a general non-Euclidean space, F x 1 , x 2 ( x ) is geometrically uninterpretable. However, if D is available for X , F x 1 be defined which provides a simple way to project x on the line defined by ( x 1 , x 2 ) . The mapping F is independent of the dimensionality of object representation as the interob-ject distances are the only requirement. The Eq. ( 1 ) defines a rich family of functions. For a collection of N objects in X , N ( N  X  1 )/ 2 unique functions can be defined by applying Eq. ( 1 ) to each pair of objects. It is always convenient to have a hashing function that maps objects to { 0 , 1 } . The functions defined using ( 1 ) are real valued, whereas we desire discrete-valued hashing functions. The binary hashing functions can be obtained from F x 1 , x 2 using thresholds t l , t 2  X  F The mapping defined in Eq. ( 2 ) can also be extended for step-wise projection. In practice, the selection of [ t 1 , t 2 in
X to 0 and remaining to 1, that is, F generates balanced hash tables. Formally for each pair ( x 1 , x 2 )  X  X ,theset V ( x 1 , x 2 ) of intervals [ t 1 , t 2 ] is defined such that F splits the hash space in half as V ( With the threshold parameter family V ( x 1 , x 2 ) , we define the family H DBH for an arbitrary space ( X , D ) as H
An indexing scheme is formulated by defining g by ran-domly selecting k functions from H DBH and using it to gen-erate hash table for word objects. The retrieval success rate is increased by generating L hash tables. Retrieval is performed by hashing the query and collecting objects from all tables for similarity search. The implication of hashing parameters (
L , k ) in DBH is same as for the LSH-based indexing. 5.3 Pivot object selection The selection of pivot objects ( x 1 , x 2 ) is an important issue forfunction F (Eq. 1 ).Inthissection,wediscusstheproposed scheme for pivot object selection. Ideally, the pivot objects should be such that the projection values are well separated on the connecting line. The underlying distance information between objects can be extracted more efficiently by greater spread between the pivot objects. The determination of far-thest pair of objects among given set of N objects needs O ( N 2 ) distance computations. To reduce the computation cost, Faloutsos and Lin proposed heuristics-based method for the computation of farthest pair of objects with O ( N distance computation [ 15 ]. For an object x 1 , farthest object x 2 is computed and again x 3 is searched which is farthest from x 2 . The step is repeated for predecided times to obtain the final pair, maintaining the linearity of heuristics. Vassilis et. al. have proposed random selection of N objects from the complete set and generation of hash functions based on these objects [ 38 ]. In the above heuristic methods, the certainty of dissimilarity of objects in a pair is not guaranteed.
In the proposed approach for pivot object selection, we cluster the training objects. Ideally, each cluster should have all the occurrences of an object in single cluster. The cluster-ing extracts the multi-modal distribution information of the objects. We select these modes as the set of pivot objects where cluster center is considered as the representation of mode. The clustering-based selection identifies distinct points as pivot objects where each point will represent a group of similar objects. Additionally, the selection of cluster centers as pivot objects will ensure maximum spread of the distance between pivot objects. We compute the cluster cen-ter as the mean of data points belonging to a cluster, which minimizes the effect of noisy objects grouped wrongly in the clusters. 5.4 Locality sensitivity analysis of the distance-based In the following discussion, we investigate the locality sensi-tivity of DBH with object representation defined in Euclidean space with Euclidean distance as the similarity measure. The discussion shows the applicability of clustering-based approach for pivot selection for locality sensitive hashing based on the distance-based hashing functions. This is not available in literature to the best of our knowledge. The definition of LSH function requires knowledge about the underlying embedding of data points. Some of the references defining LSH functions are discussed in [ 9 , 11 , 20 ]. Aristides et al. [ 20 ] have defined the hashing function that embeds the data points in a hamming cube. In [ 11 ], p -stable distribution-based hashing functions are defined as f a , b ( q ) = a . p is d -dimensional input vector. The parameter a is p -stable distributed d -dimensional random vector, and b is a uni-formly distributed real random number between [0, r ]. Chari-kar [ 9 ] has defined random hyperplane-based hash function that measures the probability of collision in terms of defined similarity measure. The hash value represents the signum of projection of data points on the hyperplane. In contrary to LSH functions, the DBH functions perform object mapping without requiring knowledge of the object space geometry. The only requirement for hashing function definition is the existence of distance measure D for the object space. How-ever, the study of locality sensitivity of the H DBH requires complete geometric information of the object space.
The analysis of LSH directly is not applicable for evalu-ating H DBH because of the characteristics of Eq. ( 4 ). Con-sidering two similar objects, represented by data points x and x b . The similarity of these objects is defined by the close positioning of x a and x b . The projection of these points on the line joined by ( x 1 , x 2 ) is computed by Eq. ( 1 ), {
F ( x = = For the similar objects, that is, x a x b , the expression shows with good probability the projection by Eq. ( 1 ) will be close . For an uniformly distributed object data space, the param-eters [ t 1 , t 2 ] estimated by ( 3 ) divide the line connected by ( x projection on line connected by ( x 1 , x 2 ) , the Pr [ F F ( of [ t the training set X . Clearly for given F , accuracy of [ t depends on the size of X , and the spread of ( x 1 , x 2 ) ing the size of X and the selection of objects ( x 1 , x 2 that maximum distance information is extracted, increases the probability of F ( x a ) x 1 , x 2 t rewritten as
F The form of above equation is similar to random hyperplane-based hashing function in [ 9 ]. The hashing function in [ 9 ] partitions the object space based on the signum of projection value on the randomly selected hyperplane from multi-vari-ate Gaussian N ( 0 , 1 ) . In the present case, Eq. ( 6 ) computes the inner product of random hyperplane ( x 2  X  x 1 ) with input x and partitions the object space based on ( t 1 , t 2 ) . Rewriting the expression for collision probability as = Pr { ( x In the simplification process, parameters t 1 , t 2 are modified to t 1 , t 2 . Let us consider the special case of upper threshold t  X  X  X  and lower threshold t we follow the result given by Goemans and Williamson in [ 16 ] to compute the probability in the ( 7 ).
 Pr [ sign ( x The special case discussed above is equivalent to signum of projection function in Eq. ( 6 ), which is locality sensi-tive. The clustering-based approach for pivot object selec-tion ( x 1 , x 2 ) helps in improving the accuracy of threshold parameters ( t 1 , t 2 ) . In such case, for the hashing function F defined over a large, uniformly distributed dataset X repre-sented by data points in Euclidean space, the estimate of t is close to 0 and t 2 is a large number. The hashing performed by distance-based hash function F , therefore, will follow the locality preserving property. 5.5 Hierarchical DBH In practice, most of the real datasets are non-uniformly dis-tributed. Though the DBH partitions the hash space consid-ering the inter object distance distribution, it may lead to few densely populated and remaining sparsely populated buck-ets. This considerably reduces the efficiency of DBH in terms of accuracy and reduction gain in average comparisons for nearest neighbor search. The performance of several learn-ing algorithms has been improved by maintaining hierarchy. We take this idea and build hierarchy of hash tables using data points in different buckets for improving the hashing performance (Fig. 11 ). We can have maximum 2 k buckets in a hash table. In practice, the bucket count is much less in number; however, implementing hierarchy for all the buck-ets is not justifiable. Therefore, for hierarchical hash table generation, selection of buckets should follow certain cri-terion. The bucket selection for successive hashing can be based on either the population criterion or the distribution information of objects in various buckets. We can consider constant or variable number of buckets for hierarchical hash table generation. The hierarchy generation process will be terminated after processing all selected buckets. In this case, hashing functions for hash table belonging to each bucket needs to be regenerated with objects hashed in the same bucket. In the proposed document indexing framework in Sect. 7 , buckets for rehashing have been selected based on population criterion. For DBH data structure with single hash table generated for k -bit hash functions, upper bound of retrieval time complexity will be O ( N + 1  X  2 k ) .Inthis case, the upper bound of retrieval time complexity for hier-archical DBH generated for most populated bucket will be O ( N + 2 ( 1  X  2 k )) . 6 Multi-probe hashing in DBH framework Thefollowingdiscussionpresentsanovelapproachformulti-probe hashing in DBH framework. In [ 25 ],QinLvetal. presented the concept of multi-probe hashing that aims at reducing the size of LSH data structure. In the conven-tional LSH, single bucket from each table is probed dur-ing retrieval. Instead of probing single bucket from each hash table for retrieval, the method intelligently selects more than one bucket which are likely to have similar objects to query and uses them for probing. The process subsequently reduces the requirement of large number of hash tables for achieving desired recall. Applying the LSH preamble, it is highly possible that similar objects are hashed in nearby, that is, adjacent buckets. Therefore, searching the buckets adjacent to query bucket in a hash table can retrieve simi-lar objects. The adjacent buckets are identified by applying a perturbation to the query bucket g ( q ) . The perturbation is defined as vector ={  X  1 ,  X  2 ,...,  X  k }, k is the length of function g .The  X  i define the perturbation corresponding to function f i . Qin Lv et al. proposed two different methods for multi-probe hashing [ 25 ]. The first method defines an step-wise probing; that is, the address for new buckets to probe is generated by applying perturbation over s hash val-ues in g ( q ) vector. Therefore, for k length hashing function using s -step probing, we can generate 2 s  X  k C s perturba-tion vectors and therefore 2 s  X  k C s buckets. The pertur-bation values  X  come from {+ 1 ,  X  1 } . The second method defines query directed multi-probing where the perturbation vectors to g ( q ) are generated based on their estimated query dependent scores. In practice, it is always desirable to have binary hashing functions. However, the existing methods for multi-probe hashing are for real hashing functions. The dis-tance-based hashing functions are binary in nature; there-fore, the direct extension of existing methods for DBH is not possible.

In the following discussion, we present a novel approach for multi-probe hashing using distance-based hashing func-tions. The step-wise perturbation has the advantage of giving equal importance to all the hashing functions { f 1 , f 2 in g . Therefore, we follow step-wise perturbation for identi-fying the buckets for multi-probing. 6.1 Step-wise multi-probing in distance-based hashing The application of step-wise perturbation at s places will invert the hash value at s coordinates of g ( q ) . Therefore, we can identify adjacent buckets to the query bucket g ( q whose indices differ at s coordinates. The set of bucket addressesobtainedafterperturbationareneighborhoodbuck-ets to query bucket. We can select buckets for succes-sive probing from this set. To apply s -step perturbation to g ( q ) , we generate k C s k -bit vectors such that each vec-tor has s 1 X  X  and remaining 0 X  X . The basic idea is to apply perturbations to s sides of the boundary of query bucket. This can be achieved by XORing the query bucket address with perturbation vectors. Therefore, we will get maxi-mum k C s valid bucket addresses. Considering 4-bit query bucket address 1101, the 1-step perturbation vectors will be 1000, 0100, 0010 and 0001 and the probable buckets in which the objects similar to query may be hashed are 0101, 1001, 1111 and 1100. Similarly for 2-step pertur-bation, the set of perturbation vectors will be 1100, 1010, 1001, 0110, 0101 and 0011. Therefore, the probable bucket will be 0001, 0111, 0100, 1011, 1000 and 1110. The steps to generate step-wise perturbation vector set is defined below (i) Enter k -length of query bucket address and perturba-(ii) Generate k C s k -bit perturbation vectors with each vec-
The set of bucket addresses are obtained by following steps (i) Enter k -bit query bucket address (ii) Generate k C s bucket addresses. The i  X  X h bucket
We select only valid bucket addresses from the generated set. These buckets represent the adjacent buckets to query bucket. The probability of hashing of similar objects to query q , in any of these buckets, will be equal. We can utilize the population density information of each valid bucket to final-ize the buckets for multi-probing. Ideally, each bucket in a hashtableisdominatedbygroupofsimilarobjects;therefore, alternately we can finalize the buckets for multi-probing by ranking them based on the distance between query q from the center of valid buckets. In this case, the mean of data points representing objects in a bucket can be considered as bucket center. 6.2 Success probability estimation The DBH function ( 2 ) does the object projection onto a line which is uniformly bi-partitioned by parameters ( t 1 , t q be the query object and p is one of the nearest neighbor. Let  X  be the probability of f i ( p ) = f i ( q ) ,for i = The probability of q to be hashed in adjacent bucket to g is Pr [ g ( p ) = g ( q )  X  ]= Here, ={  X  1 ,  X  2 ,...,  X  k } is the perturbation vector with { 0 , 1 } . Since for s -step perturbation, s  X  ing are 0 X  X , the likelihood equation presented above can be written as For s -step perturbation, we can simplify the above equation, Equation ( 9 ) represents the probability of p hashed in adja-cent bucket to g ( q ) , where the indices of adjacent buckets differ at s coordinates from g ( q ) . Theprobabilityis higher for small values of s which is acceptable since the bucket indices that differ from g ( q ) at less coordinates values are more nat-ural candidates for adjacent buckets. Even with high proba-bility of collision  X  , the success probability mentioned in Eq. ( 9 ) will be low in measure. The proposed approach can also be used for defining multi-probe hashing using other binary mapping functions. In the conventional hashing, the retrieval success rate is increased by pooling neighbors from multiple tables for performing similarity search. We can apply the same idea for increasing the Pr [ g ( p ) = g ( q )  X  ] by select-ing more buckets instead of single bucket (final bucket to be probed) from the addresses generated by step discussed in Sect. 6.1 , for example, for 4-bit address 1101, we can select more than one buckets from 0101, 1001, 1111 and 1100 for multi-probing. Here, we observe that the objective of random perturbation-based multi-probing is to reduce the number of hash tables, whereas hierarchical hashing aims to reduce the average retrieval time. In both the cases, trade-off has to be accepted in terms of accuracy and retrieval processing time. 7 Experimental results In this section, experimental results of the proposed docu-mentindexingandretrievalframeworkandmulti-probehash-ing in DBH framework are presented. We have performed both experiments on three document collection of Deva-nagari, Bengali and English scripts. Devanagari and Ben-gali belong to Alpha-syllabic writing system, and English belongs to Alphabetic writing system. These scripts display great structural variation and varying combination of differ-ent constituents (vowels and consonants) in word formation. Additionally, Devanagari and Bengali scripts include long list of modifiers. In such scenario, word shape representa-tion becomes difficult because of the complex composition of curved and straight character segments. The challenge is further compounded by varying typing styles. Therefore, it requires sufficient descriptor points to capture the shape char-acteristic and large set of angular and distance bins for accu-rate estimation of point-pair distribution. This increases the descriptor computation time and gives rise to high-dimen-sional feature space. The high-dimensional features incur high matching cost and increases memory storage require-ment that is proportional to O ( mn ) . The concepts presented inthispaperareimplementedinMatlab7.6environment.The simulations are performed on a 2GHz desktop computer with 1GBRAM.

Devanagari and Bengali document collection contains 503 pages scanned from 6 books and 226 pages scanned from 4 books respectively. 1 English document collection contains 212 pages from 6 books. The collection is compiled by sampling document images from the Google book dataset [ 39 ]. The dataset contains scanned images of old Latin script books. Sample of document images is shown in Fig. 12 . The images from the collections are of low quality, pri-marily because of degradation in original document pages. The preprocessing steps for Devanagari and Bengali docu-ments includedsmoothinganddeskewing. Englishdocument images have been used in original form without any pre-processing. The conversion of original gray scale images to binary images is performed by Otsu X  X  method. The word seg-mentation from the document images is done by horizontal and vertical profile-based technique. After initial filtering, Devanagari word dataset contains 23,145 words, Bengali word dataset consists of 18,632 words, and the English word dataset consists of 19,721 words. The filtering process removes stop words, punctuation marks and words having length less than the defined threshold. The feature represen-tation discussed in Sect. 4 is used for word image represen-tation. Section 7.1 presents the indexing and retrieval results using DBH. The evaluation of multi-probe hashing in DBH framework is presented in Sect. 7.2 . 7.1 Document retrieval The document indexing framework for Devanagari, Bengali and English document collection is tested for 481, 278 and 301 queries, respectively. The query words for Devanagari and Bengali document retrieval have 3 to 8 characters. In case of English documents, query word length varied from 4 to 11 characters. The retrieval experiment is performed for two categories of shape descriptors. In the first category, word image shape descriptors for different parameters ( m , n ) computed without partitioning the image, that is, the shape descriptor points are assumed belonging to single partition. In the second category, we split the word image in fixed number of partitions of uniform width and compute the shape descriptor as discussed in Sect. 4 . The selection of number of partitions is based on heuristics that in Devanagari and Ben-gali scripts, the maximum number words are formed with combinations of 3 to 5 characters. Therefore, for Devanagari and Bengali scripts word images, we selected 1  X  4 partition for splitting the word image. Similarly, most of the English words are formed combining 4 to 7 characters; therefore, two sets of shape descriptors using 1  X  4 and 1  X  6 partitions are selected for splitting the word images. The high complex-ity in word shape requires significant number of descriptor points to capture the shape information. The initial evaluation showed that very high number of descriptor points incorpo-rated noise in the set P (Sect. 4 ). To avoid that, for all the experiments, the logical grid for point extraction is placed at interval of 4 pixels in both horizontal and vertical direc-tion. The selection of descriptor parameters ( m , n ) is based on some preliminary observations. For very less number of bins, the uniqueness of point distribution histograms is lost. Therefore, we select sufficiently large number of angular and distance bins such that the descriptor accurately captures the discriminative pattern of the point distribution histograms. The experimental evaluation showed that with increase in shape descriptor parameters, the discriminative ability of fea-ture increases with increased word matching cost. However, for very large number of bins ( m , n ) , sparsely distributed point distribution histograms are highly noisy and very sen-sitive to the presence of different types of degradation and varying typing conditions in the document. The preliminary experiments are performed for precision-oriented retrieval usingnearestneighborsearch.Weselectedfivenearestneigh-bors for precision computation. For all the word datasets, the subset of query set having more than five similar examples are considered for evaluation. The precision with respect to descriptor parameter is presented in Table 3 .

In the experimental framework, the hierarchical hash tables are generated for two most populated buckets in base hash tables. The generation of hashing function family H is done using the cluster centers as pivot objects. The clus-tering over training set is performed by DBSCAN algorithm [ 14 ]. The search radius selection for computing the precision and recall scores is done using the estimate of within clus-ter distances. The descriptor parameters ( m , n ) and hashing parameters ( L , k ) are the adjustable parameters. The impli-cation of these parameters has been discussed earlier. A set of descriptor parameter values have been selected, and the best results are presented. The best results therefore correspond to the optimal descriptor parameters for our document image collection. In retrieval experiments, precision and recall have inverse relationship; therefore, F -score-based single-point measure is considered for the selection of best. For Devana-gari and Bengali document collection, range of parameters ( m , n ) has been set as { ( 45 , 30 ), ( 45 , 40 ), ( 50 , 45 and with 1  X  4 partition. The descriptor computation steps include point extraction, pdh and Fourier transform computa-tion. The time consumption for Fourier transform depends on { m , n , num _ parts }. Total computational time depends on the complexity of word shape with major part is spent on descriptor point extraction and pdh computation. Figure 13 shows the average descriptor computation time for Deva-nagari word collection with respect to different descriptor parameters.

The empirical observation showed that for the same hash-ing parameter, descriptor parameters ( m = 50, n = 45) are optimal for Devanagari and Bengali word images. The retrieval results corresponding to these parameters are pre-sented in Tables 4 , 5 . For the same set of descriptor parameter, LSH-based retrieval results on Devanagari word collection are also presented in Table 6 . To define LSH-based index-ing, random hyperplane-based hashing functions have been applied [ 9 ]. The comparison between Table 4 and 6 showed that DBH-based indexing achieved 3.36 X 4.65% improve-ment in F -score for different hashing parameters. The DBH achieved better precision and recall with LSH requiring less number of average computations for larger k . It is justified as random hyperplane-based projections are independent of data distribution; therefore, for smaller k , the hashing func-tion g shows poor discriminative power. However, in prac-tice, short hash functions (small value of parameter k )are preferred at acceptable retrieval performance to control the size of indexing data structure.

The proposed indexing and retrieval framework are also validated with respect to retrieval performance of a search engine that uses recognized characters OCR X  X d in the doc-ument image. The experiment is performed on Devanagari document images. The recognition is performed by Devana-gari OCR discussed in [ 4 ]. The character level recognition accuracy of 86.56% is achieved. Figure 14 shows sample document image from the collection and the recognized text. For the same query set, precision and recall rate of 82.84 and 81.55% are achieved. Table 4 shows that proposed frame-work achieves best F -score of 88.44% with precision and recall as 88.18 and 88.79% respectively. The blue boxes in the left-side images show the retrieved word image for query word , and red characters/symbols in right-side images are the wrong recognitions. The degradation in doc-ument images causes poor recognition. Evidently, the uni-code-based indexing of OCR X  X d image skips the words even with single recognition error that reduces the retrieval perfor-mance significantly. In this case, the query retrieval time var-ied from 0.49 to 0.67s. The Fourier transform computation is time consuming; however, the computation is performed once during online querying. Additionally, the DBH-based approximate nearest neighbor search significantly reduces the search complexity as shown by approximation ratio of 8.5 X 12.9% in average computations.

Following the similar evaluation methodology, the index-ing framework is applied for English script documents. A set of descriptor parameters ( m , n ) are selected as { ( 50 ( 38 , 36 ) } without and 1  X  4, 1  X  6 partition, respectively. Based on the F -score, ( m = 38 , n = 36 ) with 1  X  6 parti-tion achieved best result for the selected hashing parameters. The corresponding retrieval results are presented in Table 7 . The retrieval performance over the English script documents is compared with the word shape code-based retrieval pre-sented by Lu et al. in [ 24 ]. On our experimental dataset with similar set of queries, word shape coding-based approach achieved precision and recall rate of 82.47 and 78.54%. In this case, the shape descriptor representation achieves best F -score of 87.08% with precision and recall as 86.24 and 87.95%, respectively. The morphological operations applied for word code generation are sensitive to noise and docu-ment degradations. Therefore, the method requires applica-tion of strong document enhancement technique in case of old and degraded documents. Additionally, shape code-based approach is not extendible to other scripts.

Next, the proposed framework is evaluated for indexing a synthetic document image dataset prepared by Reuter-21578 text collection. The objective is to evaluate our framework with the method presented in [ 24 ] by performing retrieval on synthetically created document images. The dataset gen-eration and evaluation strategy are followed by [ 24 ]. The results in Table 7 showed the descriptor parameters { m = n = 36, 1  X  6 partition} achieved best results. Therefore, these parameters are selected for word image representation. The word image segmentation is done following the pro-jection profile-based strategy. The words having less than 3 characters are filtered out in the preprocessing stage. The fil-tered word image collection consists of 26,700 samples. The query set consists of 125 frequently used word. The retrieval performance with the proposed indexing framework for dif-ferent hashing parameters is presented in the Table 8 .Inthis case, the method presented in [ 24 ] achieved precision, recall and F -score of 94.12, 91.86 and 92.98% respectively. Table 8 shows that the proposed indexing framework achieved comparable performance. The shape descriptor-based rep-resentation is robust in case word shape deformations. The results establish that proposed framework provides an effi-cient solution for indexing the old documents where the degradationsarestochasticinnature.Additionally,theframe-work provides the option of adjustable parameters which can be tuned according to the performance requirement.
The experimental observation showed improvement in precision with increase in k , though sharp decrease in the collision probability decreases recall rate significantly. Therefore, multiple hash tables are required to improve recall. Using word shape coding scheme for English words, Bai et al. [ 5 ] have reported F -score of 0.926 for a decent quality document collection. The document images used for the evaluation of the proposed framework are low quality and contain significant amount of noise (Fig. 12 ). However, with the original images for English script, best F -score of 0.87 is achieved. The variations in parameters L and k change preci-sion and recall. Nevertheless, current hashing parameters are selected to achieve satisfactory F -score at reasonable search time complexity. The experimental results show that hierar-chical DBH achieves significant improvement in search time complexity with approximation ratios of 9.6 X 17.2%. 7.2 Performance evaluation multi-probe hashing The performance evaluation of the multi-probe hashing is done following the approach proposed in [ 25 ]. The true percentage of K -NN X  X  retrieved results, that is recall, is considered as performance measure. In addition, aver-age number of comparisons also present an estimate of performance improvement in terms of search complexity. Therefore, recall represents the quality factor, and number of comparisons represents the cost factor. Considering q as query object and I ( q ) are the K nearest neighbors represent-ing ideal result. Suppose A ( q ) are the K nearest neighbors obtained from the multi-probe hashing scheme. The recall is defined as Recall =
Here, precision and recall are same because the retrieved objects (collection of objects obtained from the queried buck-ets) are ranked based on their similarity with the query and. We consider 10 nearest objects, that is, K =10 for measurement. The evaluation of multi-probing in DBH is done on Devanagari, Bengali and English word image collection (details of the datasets are presented in the Sect. 7 ). The recall for Devanagari dataset is computed for 481 query words and for Bengali with 278 words. The word length for the query words varied from 3 to 8 characters. The recall for English dataset is computed for 301 query words with word length varying from 4 to 11 characters. The experi-ment is performed for different values of L with only base hash table without considering hierarchical hash tables. The bucket selection for the multi-probing is done based on the population criterion from the addresses generated from steps discussed in Sect. 6.1 . We have performed multi-probe hash-ingusing1-stepand1,2-stepperturbation.In1,2-steppertur-bation, we combine buckets obtained using 1, 2-step probing for similarity search.

The results in Sect. 7.1 show that descriptor parameters { m =50, n =45, 1  X  4} are optimal for Devanagari and Ben-gali script words because of excellent discriminating charac-teristics across different words. Similarly for English words, descriptor parameter { m =38, n =36, 1  X  6} is the optimal. The multi-probe hashing results on the different script docu-mentcollectionarepresentedforthesedescriptorparameters. The results are presented in Figs. 15 , 16 , 17 .
The recall score obtained by complete set of hash tables is compared with the recall score of multi-probe hashing con-sidering 1 / 5th of initial set of tables. The results show the recall score of 1, 2-step multi-probing matches closely with recall obtained by complete set of tables. In most cases, the difference between recall scores varies from 0.30 to 0.90%. However, the experiments show minor increment in num-ber of comparisons and average processing time which is primarily because of bucket selection based on population criterion. 8 Conclusions Anovelfeaturerepresentationforbinarypatternsispresented which represents the structural information of object in the image. The feature representation can be applied for differ-ent binary patterns, for example, character, symbol or trade-mark image. The feature representation has been adopted for encoding shape information of word images. A novel word image-based document indexing scheme is proposed that applies the concept of distance-based hashing for index-ing. The distance-based hashing projects the word images to low-dimensional hash space while preserving their distances. The complete document indexing is performed by hierar-chical distance-based hashing. The paper presents a novel feature-based indexing scheme for Indian script documents by applying DBH. The experimental results are presented for Devanagari, Bengali and English script document collec-tions. In spite of the low quality of document images used for experiments, the proposed framework achieves F -scores of 0.88, 0.89 and 0.87 for Devanagari, Bengali and English scripts, respectively. The paper presented a new method for multi-probe hashing in the case binary mapping function. The evaluation of approach is presented using distance-based hashing function as the true percentage of KNNs. The eval-uation of proposed indexing framework for other scripts is part of future work. The proposed framework can also be extended to define indexing scheme for a dynamic environ-ment having incremental update in document collection. References
