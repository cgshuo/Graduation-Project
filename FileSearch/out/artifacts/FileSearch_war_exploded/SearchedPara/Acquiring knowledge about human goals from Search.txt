 1. Introduction
Knowledge about human goals has been found to be an important kind of knowledge for a range of challenging research problems. These challenges include goal recognition from people X  X  actions, reasoning about people X  X  goals or the generation of action sequences that implement goals (planning) ( Schank &amp; Abelson, 1977 ). Goal knowledge appears advantageous in practical problem settings as well, for instance, to inform companies to adjust their range of products or services according to their customers X  desires.

Knowledge acquisition denotes a field of research concerned with gathering ontological constructs from experts or nat-ural language corpora. Knowledge about human goals has been found to be important for a range of research communities and problems, including work on intelligent user interfaces ( Smith &amp; Lieberman, 2010 ), commonsense-enabled applications and ConceptNet/Openmind ( Liu &amp; Singh, 2004; Singh et al., 2002 ), have been capturing commonsense knowledge, including knowledge about human goals, over the past years aiming to continuously refine, improve and extend their commonsense  X  knowledge with different strategies. While Cyc partly relies on human experts to develop and build their knowledge base, ConceptNet aggregates and processes contributions made by volunteers all over the world.

These existing attempts illustrate two main problems in the process of constructing a knowledge base about human goals: (1) the goal acquisition problem (or bottleneck), which refers to the costs associated with knowledge acquisition dous variety and range in the set of human goals ( Eslick, 2006 ). These problems have hindered progress in capturing broad knowledge about human goals. To address the goal acquisition problem, Search Query Logs referred by Battelle (2005) to as Databases of Intentions  X  appear to be an interesting candidate for this task.

In this work, we are interested in the extent to which we can tap into Search Query Logs, to extract expressions of human goals in an automated way. Intuitively, Search Query Logs appear to represent an appropriate corpus for this task because every query can be considered to be an expression of a person X  X  (search) intent. In recent years, considerable progress was made in approximating a person X  X  search intent for the purpose of improving web search. The focus of our work is different:
While previous research on search intent focused in part on categorizing queries into high-level goal taxonomies thereby serving a functional purpose (e.g. to improve search, cf. Baeza-Yates, Calderon-Benavides, &amp; Gonzalez-Caro, 2006; Jansen, 2007; Pasca, Van Durme, &amp; Garera, 2007 ), our goal is to contribute to the problem of commonsense knowledge acquisition. 1.1. Queries containing explicit goals
In most cases, a query submitted to a search engine expresses some user X  X  underlying goal or motivation. While some goals contained in search queries might be very explicit, other queries might contain more implicit goals, which would mean that they are more difficult to recognize by, for example, an external observer. To give an example: in terms of intentional explicitness, the query car Miami differs from the query buy a car in Miami suggests that it is useful to distinguish between at least two classes of queries: (1) queries that contain explicit goals and (2) queries which do not. Table 1 contrasts queries of both classes.

Results from a larger human subject study corroborate the existence of these two classes and furthermore hint towards a purposes, we propose to automatically identify and extract queries which contain explicit goals. Our algorithm learns char-acteristics of queries containing explicit goals in order to perform the classification task. By applying the algorithm to two large Search Query Logs recorded by AOL and Microsoft Research in 2006, we obtain a set of 110,000 unique queries that contain explicit goals.

To study the acquisition of knowledge about human goals extracted from Search Query Logs, we address following four research questions 1 : RQ 01: Do queries containing explicit goals exist in Search Query Logs? RQ 02: How accurately can we identify queries containing explicit goals? RQ 03: What are characteristics of queries containing explicit goals automatically extracted from Search Query Logs?
RQ 04: Do Search Query Logs contain commonsense goals, i.e. goals that are found in ConceptNet, a commonsense knowl-edge base? If they do, what is the nature of human goals shared by ConceptNet and Search Query Logs and how do they differ?
Our findings suggest (i) that Search Query Logs represent a viable source for extracting expressions of human goals, (ii) that Search Query Logs contain a great variety of human goals and (iii) that this variety has the potential to complement commonsense goals found in existing commonsense knowledge bases. To illustrate the benefits of acquiring goal knowledge, we employ this knowledge to following practical scenario: We outline how commonsense knowledge can be refined and ex-tended by using human goals from Search Query Logs.

The overall contribution of this paper is the introduction of Search Query Logs as a viable, yet largely untapped, source for the task of knowledge acquisition with regard to human goals. This work is particularly relevant (i) for knowledge engineers interested in constructing knowledge bases of human goals and (ii) for researchers interested in studying characteristics of human goals in Search Query Logs. In applications, goal knowledge can benefit various domains including text analysis, hu-man computer interaction or planning. The potential of goal knowledge to inform human computer interaction is already being investigated (cf. Lieberman, 2008 ). By equipping user interfaces with knowledge about human goals ( Faaborg &amp;
Lieberman, 2006; Smith &amp; Lieberman, 2010 ), a better understanding about users X  actions can be achieved to advance the vision of more intelligent user interfaces. 2. Related work
To the best of our knowledge, this work is novel in a sense that it studies the potential of Search Query Logs as source for goal knowledge acquisition. In the following, we first provide a brief survey of Information Extraction (IE) from textual re-sources since IE can be considered key technology to knowledge acquisition. Second, we review work from two related but previously unconnected fields of research, (i) commonsense knowledge acquisition (including human goals) and (ii) search intent detection and categorization. 2.1. Information extraction from text
Information Extraction (IE) refers to the automatic extraction of structured information from unstructured textual re-sources. It also refers to the process of making information explicit and thereby useable by both humans and machines; information that otherwise remains hidden in vast amounts of digital text documents, e.g. newspaper archives. Extracted information is often stored in relational databases where the information becomes accessible, e.g. to querying mechanisms. To better understand the functions IE systems should perform, consider following sentence: Vienna is the stylish capital of
Austria . An IE system takes this sentence as input and is expected to output a mapping to a relational tuple, for instance, i.e. a certain degree of human involvement. This condition has been termed knowledge engineering bottleneck .
The advent of the World Wide Web triggered a paradigm shift in IE due to changing requirements: lesser human involve-ment given the sheer amount of digital resources. Traditional IE approaches had to evolve towards automatic procedures. In the following, we will briefly survey this evolution; the chronological grouping was partly adopted from ( Etzioni, Banko,
Soderland, &amp; Weld, 2008 ). 2.1.1. Traditional information extraction
Traditional Information Extraction (IE) systems focused on locating instances of narrow, pre-specified relations, such as the time and place of events, from small, homogeneous corpora. The spectrum of relation types was continually enlarged to among the first who pioneered hand-crafted, textual patterns in the early 1990s. For their analyses, they took into account the surrounding context, e.g., syntactical and grammatical characteristics. While Hindle focused on predicate-argument structure, Hearst developed lexico-syntactic patterns, i.e. part-of-speech enriched regular expressions, to extract hyponymy ( X  X  X s-a X  X ) relations from text. Being hand-crafted, only instances of predefined relation types, e.g. hyponymy, were extracted.
Additional disadvantages of traditional IE included domain dependency as well as being heavily time-consuming which led to research in automatic IE techniques. 2.1.2. Automatic information extraction
The objective of automatic Information Extraction (IE) is to continuously reduce human involvement in the IE process. As it turned out, machine learning was among the preferred methods and ideally complemented pattern based approaches. Hu-man involvement was still key in order to provide learning algorithms with annotated training examples. Yet, instead of crafting patterns by hand, researchers attempted to automatically learn these patterns to reduce human efforts. First work in this direction included Soderland X  X  CRYSTAL system ( Soderland, Fisher, Aseltine, &amp; Lehnert, 1995 ), Kim X  X  PALKA system ( Kim &amp; Moldovan, 1995 ), and Riloff X  X  AutoSlog-TS system ( Riloff, 1996 ). In contrast to CRYSTAL and PALKA, the AutoSlog-TS system represented an unsupervised approach to IE, i.e., the system generated extraction patterns using untagged text.
The annotation process proved to be a major bottleneck to highly scalable IE systems. To minimize human involvement, ( Agichtein &amp; Gravano, 2000 ) presented the IE system Snowball which extracted structured data from plain-text documents.
The idea is to provide few but frequent training examples in combination with a regular expression the examples have to match. Snowball uses iteration cycles to repeatedly check the quality of the extracted instances. These cyclic quality checks reduce error propagation and therefore represent the main advancement compared to Brin X  X  Dual Iterative Pattern Expan-sion (DIPRE) algorithm ( Brin, 1999 ).

Self-supervised IE systems can be regarded as a subcategory of unsupervised methods. Yet, unlike classic unsupervised methods, self-supervised IE systems find and annotate examples on their own to train a classifier. Representatives include KnowItAll ( Etzioni et al., 2005 ), a domain-independent system, that automatically extracts information from the web.
KnowItAll is seeded with an extensible ontology and a small number of generic rule templates from which it creates text information on lessons-learnt towards the development of an Open Information Extraction (Open IE) system.
The term Open IE was coined by Banko, Cafarella, Soderland, Broadhead, and Etzioni (2007) and represents a novel extrac-tion paradigm; the paradigm is meant to address challenges of extracting information from web-scale corpora: Open IE does scalability due to massive data amounts. TextRunner ( Banko et al., 2007 ) represents a fully implemented Open IE system which features all previously introduced requirements. When compared to its predecessor KnowItAll ( Etzioni et al., 2005 ), TextRunner X  X  average error rate is significantly lower while identifying an almost identical number of correct extrac-tions. In addition, TextRunner extracts information from all relations at once thereby drastically reducing processing time. neously. It refers to a 24/7 effort to continuously extract information from the web. In comparison to Open IE, the emphasis et al., 2010 ) presented NELL , an implementation of a never-ending language learning system. The system consists of four sub-system components which utilize semi-supervised learning methods thereby simultaneously attempting to extract candidate facts. A component called knowledge integrator is then responsible for upgrading high-confidence candidates to the status of beliefs. First evaluations of NELL yielded promising precision results while constantly accumulating knowledge.
As is the case with recent IE methods, our work uses supervised machine learning to automatically extract expressions of human goals from Search Query Logs focusing on  X  X  X yponymy X  X  relations. Feature engineering provides us with discriminant features for the classification task. However, these features reflect merely query log characteristics and thus cannot simply be transferred to other textual corpora such as weblogs or tweets. 2.2. Commonsense knowledge acquisition
Knowledge acquisition from natural language text often focuses on gathering a specific kind of knowledge such as  X  X  X om-monsense knowledge X  X . Commonsense knowledge spans a broad spectrum of human experiences such as a lemon is sour or if you forget someone X  X  birthday, they may be unhappy with you . Since it is assumed that every person possesses commonsense, it is in general omitted from social conversations. Commonsense comprises fact-based knowledge as well as knowledge about other aspects including emotional aspects, temporal contexts or human goals.

To humans,  X  X  X ommonsense knowledge X  X  appears trivial since it states simple facts about the world and its people. Yet, to make knowledge about the world accessible to machines, it needs to be acquired and adequately represented. A common approach to storing and structuring knowledge is to construct a knowledge base. Knowledge in structured form represents a prerequisite so that reasoning and inference mechanism can be applied. Reasoning, for instance, helps to answer why ques-tions and can thus support, e.g. intelligent agents in their decision making processes.
 commonsense knowledge, including knowledge about human goals. ConceptNet was designed to make practical context-based inferences over real-world texts. ConceptNet X  X  internal structure can be described as set of triples where each triple consists of two concepts connected by a semantic relation. ConceptNet provides a set of over 20 semantic relations which cover various thematics such as affectionate (MotivationOf), causal (EffectOf) or events (SubeventOf). Table 2 shows a list of ConceptNet entries taken from Liu and Singh (2004) .

The knowledge acquisition process itself may adopt a number of different strategies, including human knowledge engi-2009 ) or semi-automatic approaches ( Eslick, 2006 ). In Singh et al. (2002) , the authors described the Open Mind Experiences (OMEX) system which aimed to gather descriptions and explanations of everyday,  X  X  X ommonsense X  X  experiences in form of stories. Telling stories represents a human trait to share knowledge, a circumstance the OMEX system took advantage of.
Knowledge about human goals has been found to be an important kind of knowledge for a range of challenging research problems, such as goal recognition from user actions, reasoning about human goals, or the generation of action sequences that implement goals (planning)( Schank &amp; Abelson, 1977 ). We refer to the task of acquiring goals from textual resources as Goal Mining . This problem covers a broad range of interesting aspects, including the acquisition of goals from scientific ( Liaskos, Lapouchnian, Yu, Yu, &amp; Mylopoulos, 2006 ), Search Query Logs ( Strohmaier et al., 2008 ) and others.
In the area of understanding natural language text, knowledge about human goals gains significance as a novel dimension by employing knowledge about peoples X  goals. Tatu (2005) analyzed human goals in natural language text to improve the task of question answering. Extracting expressions of human goals to complement social media monitoring tools has been recently explored by Kr X ll and Strohmaier (2009) . In this previous work, we studied political speeches from a goal-oriented perspective and classified human goals into a human goal taxonomy ( Chulef, Read, &amp; Walsh, 2001 ). Eventually, we were able to compare political speeches not only by traditional topic category distributions but also by human goal category distributions.

Knowledge about human goals has been found to play a fundamental role in explanation, justification, and rationalization as well. Understanding peoples X  goals can help to answer why questions about user behavior and user interactions ( Faaborg &amp; Lieberman, 2006; Lieberman et al., 2007; Smith &amp; Lieberman, 2010 ). In commonsense enabled applications ( Lieberman, 2008 ), explicit representations of goal knowledge are crucial for plan recognition and planning. In addition, they are an ena-bler for intelligent user interfaces which exhibit traits of commonsense understanding, such as goal-oriented search ( Liu et al., 2002 ) or goal-oriented event planning ( Smith, 2007 ). 2.3. Search intent detection and categorization
The main objective of research in this field is concerned with estimating a searcher X  X  intent to inform and improve the &amp; Horvitz, 2008 ), emerged each incorporating different aspects during search.

Broder (2002) introduced a high level taxonomy of search intent by categorizing search queries into three categories: nav-categorization. They repeatedly revised their goal categories based on empirical evidence. Their efforts resulted in a search intent hierarchy where high-level categories resembled Broder X  X  taxonomy. Follow up research led to evolutions of Broder X  X  work which included collapsing categories, adding categories ( Baeza-Yates et al., 2006 ) and/or focusing on subsets only ( Lee et al., 2005 ). In the context of goal knowledge acquisition, we can make two observations: First, definitions of search intent do not require a query X  X  intent to be made explicit. Second, the adopted abstraction level suggests that information about individual human goals, e.g. how to sell my car , is lost. In contrast to Broder X  X  understanding of search intent, we do not incorporate high-level categories of search intent but rather focus on individual human goals (e.g. informational vs. ing a car ). Downey et al. (2008) interpreted the information seeking process differently: They proposed to use subsequent actions that succeeded a query as characterizations of the searcher X  X  goal. The last URL visited in a search session served as proxy for the user X  X  search intent. While their approach is useful to study user behavior with regard to high-level search in-tent, it cannot easily be used for extracting plausible human goals.

Complementary research was conducted by Jansen et al. who investigated search and search intent as decision making analyzed the search process from a cognitive learning perspective. In their studies, they utilized a cognitive learning taxon-omy ( Anderson &amp; Krathwohl, 2001 ) consisting of six categories: Remembering, Understanding, Applying, Analyzing, Evalu-ating and Creating. This taxonomy represents another potential high-level categorization scheme of search intent, e.g. Does the user intend (i) to recall something from memory (Remembering) or (ii) to collect information for a decision (Evaluating).
A few publications in recent years were dedicated to algorithms that automatically categorized queries according to their tures of Search Query Logs, e.g. user-click behavior or part-of-speech information, to perform the categorization task. Beitzel et al. (2005) proposed a method for automatic query classification by leveraging unlabeled data within a semi-supervised learning framework. Their semi-supervised approach facilitated the augmentation of labeled training samples for the clas-sification task. Baeza-Yates et al. (2006) applied a combination of supervised and unsupervised learning to classify queries.
Besides categorizing queries according to their intent, the attempt was made to capture the user X  X  interest as well. This was accomplished by assigning queries to top-level categories of the Open Directory Project. Learning more about the relation between intent versus topic was the focus in Jansen and Booth (2010) . The authors showed that intent categories varied queries accordingly. Li, Wang, and Acero (2008) described a semi-supervised learning approach to query intent classification with the use of search click graphs. Based on the distances in this click graph, the authors infer intent classes of unlabeled queries from those of labeled ones. In Hu, Wang, Lochovsky, Sun, and Chen (2009) , the authors X  motivation for putting effort into understanding user intent was to identify an adequate vertical search engine. By mining Wikipedia X  X  link structure, they ture from statistical approaches, ( Guo &amp; Agichtein, 2010 ) investigated whether human computer interactions during search such as mouse movements supported search intent inference more accurately. Their work was motivated by the observation that similar queries exhibited different underlying search intents.
 Areas such as e-commerce and personalization also realized potential benefits of approximating a person X  X  search intent.
In e-commerce, ( Dai et al., 2006 ) proposed detecting commercial intent to determine whether a user expresses commercial the query  X  X  X isney world X  X . By taking into account geographic information during the search procedure, they showed that re-trieval performance could be improved.

In this paper, we aim to contribute to research on knowledge acquisition, in particular, acquiring knowledge about human goals. While we do not aim to contribute to search intent detection and categorization, our work might inspire new ways of employing knowledge of human goals in intelligent systems and intelligent user interfaces (cf. Strohmaier, Kr X ll, &amp; K X rner, 2009 ). We believe that tapping into Search Query Logs for knowledge acquisition purposes represents a unique problem in the context of goal knowledge acquisition, and  X  to the best of our knowledge  X  has not been studied before. 3. Research design
In this section, we provide a detailed description (i) of the datasets used in our experiments and (ii) of the research meth-odology we employ to address the research questions. 3.1. Datasets 3.1.1. Search Query Logs from AOL &amp; MS research
In this work, we employ two large Search Query Logs which were recorded by AOL and Microsoft Research in 2006. We combine these two Search Query Logs to (i) increase the number of queries as well as (ii) to decrease potential domain and population bias that is introduced by using only one Search Query Log. To give an example, queries such as count or how to delete the msn account reflect a certain degree of domain bias. The first query log, the MSN Search
Query Log 2 excerpt, contains 15 million queries (from US users) that were sampled over one month in May, 2006. The second tween March 1, 2006 and May 31, 2006. Search queries from both logs were extracted using the same method, and underwent several sanitization and pre-processing steps in order to reduce noise to an acceptable level: Empty queries : We removed blank queries and queries containing just a minus character.
 ent ambiguity of short queries and (ii) the lack of syntactical structure to express human goals. This restriction resulted in a removal of 65% of the queries contained in the original datasets.
 URL queries : We removed queries containing URLs or fragments of URLs using regular expressions.
 Queries containing lyrics or movie titles : In preliminary experiments, we observed that queries for music lyrics ( love lyrics ) often contained a verb, but refered to songs rather than actual human goals. This bears the risk of confus-ing our classification approach that is in part based on syntactic features. However, such queries can be identified, since they often contain keywords such as  X  X  X yrics X  X  or result in click-through to lyrics or movie related websites (e.g.  X  X  http:// www.seeklyrics.com  X  X ). We performed limited term and website blacklisting to heuristically reduce the number of such queries in the datasets.

Syntax check : We removed queries containing tokens, which are not numbers or sequences of letters. We used this filter to eliminate corrupted character encodings.

Removed misspellings : We removed misspelled queries. Whether or not a consecutive query represents a spelling correc-tion was determined by the Levenshtein distance ( Levenshtein, 1966 ) between two consecutive query strings. A query was removed if the Levenshtein distance between the query and its successor is through event attached.

By applying these filtering steps, we only use &lt;5% of queries in the query log. While this reduction appears rigorous, we point out that only this part of all search queries is of value to this work (from a knowledge acquisition as opposed to an information retrieval perspective).

In this work we had only access to two time-constrained Search Query Logs, i.e. from AOL and from Microsoft Research. As a consequence, we cannot assume that our findings generalize for Search Query Logs in general, across time and space. Query logs from other search engines, e.g. Google, might exhibit different properties which would need to be studied in future work. 3.1.2. Commonsense knowledge obtained from ConceptNet
In this work, we choose ConceptNet ( Liu &amp; Singh, 2004 ) as commonsense knowledge base because of its open availability, its natural language knowledge representation and its considerable size. Moreover, knowledge in ConceptNet is partly rep-resented in free-form text which facilitates the comparison with search queries. In this work, we regard knowledge which is contained within ConceptNet, as commonsense knowledge. We identify commonsense goals ( Lieberman et al., 2007 ) in Con-ceptNet by querying concepts (ConceptNet nodes) which are connected by relations such as MotivatedByGoal , UsedFor and
CapableOf . We compiled a subset of entries from ConceptNet that consists of commonsense goals and imposed the following restrictions on all entries: Commonsense goals had to contain at least one verb and at least one noun. To enforce this restric-tion, we examined corresponding part-of-speech tags. 3 For our experiments, we obtained a set of 68,000 commonsense goals from ConceptNet. 3.2. Research methodology
In the following, we briefly summarize how we address each research question: 3.2.1. RQ 01: Do queries containing explicit goals exist in Search Query Logs?
To address the first research question, we conduct a human subject study where human annotators manually classify 3000 search queries into two classes: queries containing an explicit goal and queries which do not. Similarly to previous of the class X  characteristic and their boundaries. This study corroborates our intuition that Search Query Logs contain a small percentage of human goal expressions; the distribution of the human subjects X  annotations hints towards a theoretical sep-arability of these two classes. 3.2.2. RQ 02: How accurately can we identify queries containing explicit goals?
We start by inspecting characteristics of both query classes that can serve as potential features for our classification ap-initially take a wide spectrum of feature types into account including click-through as well as part-of-speech information. We apply feature selection methods to decide on a final set of feature types that appear promising for the classification task.
Having identified these features, we apply two established classification models, i.e., Naive Bayes ( Friedman, 1997 ) and Sup-port Vector Machines ( Dumais, Platt, Heckerman, &amp; Sahami, 1998; Vapnik, 1998 ). To evaluate these models, we perform threefold cross validation and calculate standard metrics: precision, recall and F1 measure. 3.2.3. RQ 03: What are characteristics of queries containing explicit goals automatically extracted from Search Query Logs? We conduct quantitative as well as qualitative analyses to learn more about the nature of human goals acquired from ilar, the intention behind query log analysis often is to improve retrieval performance. Our findings provide us with insights into the nature of frequent and infrequent human goals. To learn more about their diversity, we analyze verbs in human goals by classifying them into selected Levin X  X  verb classes ( Levin, 1993 ). 3.2.4. RQ 04: Do Search Query Logs contain commonsense goals, i.e. goals that are found in ConceptNet, a commonsense knowledge base? If they do, what is the nature of human goals shared by ConceptNet and Search Query Logs and how do they differ?
By addressing these research questions, we aim to establish a connection between human goal expressions from two do-mains, i.e. commonsense and search; we regard connecting these two domains and corresponding insights, e.g. common and uncommon characteristics, as acquiring knowledge about human goals.

We approach these questions by first verifying the existence of commonsense goals in Search Query Logs. Second, we study characteristics of commonsense goals by generating verb class histograms of selected Levin X  X  verb classes ( Levin, 1993 ). By learning more about common and uncommon features, we develop a better understanding of how human goals from Search Query Logs could contribute to complementing commonsense knowledge. As motivation to enrich existing taxonomic structures with automatically extracted in stances, we selectively refer to Pantel and Pennacchiotti (2008) and ent YAGO, a light-weight and extensible ontology. For ontology creation, they use Wikipedia to automatically extract facts and attempt to unify them afterwards with WordNet. Similarly, we believe that human goals from Search Query Logs have the potential to contribute to commonsense knowledge. In Section 5 , we present an illustration scenario as a first step into this direction. 4. Results 4.1. RQ 01: Do queries containing explicit goals exist in Search Query Logs?
In this subsection, we introduce a practical definition to identify queries containing explicit goals. While a multitude of definitions for human goals exist in related literature, our definition seeks to be applicable in the context of Search Query
Logs, i.e., capable of distinguishing search queries that contain explicit goals from queries which do not. Based on work that taining explicit goals in the following way:
A search query is regarded to contain an explicit goal whenever the query (1) contains at least one verb and (2) describes a plausible state of affairs that the user may want to achieve or avoid (cf. Regev &amp; Wegmann, 2005 ) (3) in a recognizable way (cf. Strohmaier et al., 2008 ).  X  X  X ecognizable X  X  refers to what ( Kirsh, 1990 ) defines as  X  X  X rivial to identify X  X  by a subject within a given attention span. According to Kirsh,  X  X  X rivial to identify X  X  represents the ability to make a decision in constant time. To give an example:
The query passing a drug test recognizably reflects the searcher X  X  goal. In contrast, the query interpretations of the searcher X  X  underlying intent.  X  X  X lausible X  X  refers to an external observer X  X  assessment whether the hu-man goal contained in a query could likely represent the goal of a user who formulates the given query. With regard to the previous example, we can generally assume that passing a drug test represented by the query living on the moon . It is important to note that it would be rather difficult to completely verify this assessment solely based on data from an anonymous query log due to the inherent goal verification problem of such a task ( Strohmaier et al., 2008 ). However, the objectives of our work are more modest: we are interested in acquiring plausible human goals for knowledge acquisition purposes. An advantage of acquiring broad knowledge about plausible human goals is that it can put constraints on the space of possible human goals, which plays a role in, for example, goal recognition ( He, Chang, &amp; Lu, 2007 ) or query disambiguation ( Allan &amp; Raghavan, 2002 ).
 A query does not contain an explicit goal when it is difficult or extremely hard to elicit some specific goal from the query.
Examples include blank queries, or queries such as car or and mostly implicit level.

To explore the agreeability of our definition and the feasibility of an automatic approach, we conducted a human subject study in which 4 judges (Computer Science graduate students) were instructed to annotate a small query sample. In this task, the judges conducted a question answering task; they were required to independently answer a single question for each of 3000 queries randomly obtained from the AOL Search Query Log. who is performing the query X? Two examples should illustrate the process: Given query :  X  X  X ow to increase virtual memory X  X 
Question : Do you think that  X  X  X ncrease virtual memory X  X  is a plausible goal of a searcher who is performing the query Potential answer : Yes Given query :  X  X  X oys kissing girls X  X 
Question : Do you think that  X  X  X issing girls X  X  is a plausible goal of a searcher who is performing the query  X  X  X oys kissing Potential answer :No
After the question answering task, we assigned the answers for each query to the corresponding categories in the follow-3000 have been labeled as containing an explicit goal by all 4 subjects (8.1%, right most bar), and 134 queries have been la-beled as containing an explicit goal by 3 out of 4 subjects. This shows that (1) Search Query Logs contain human goals and (2) the number of queries containing human goals is expected to be small. and (ii) the potential for an automatic classification approach.

To further explore agreeability, we calculated the inter-rater agreement j ( Cohen, 1960 ) between all pairs of human sub-jects A, B, C and D. The j values in our human subject study range from 0.65 to 0.76 (see Fig. 1 ). The average inter-rater agreement j yields 0.72 which hints towards a principal (yet not optimal) agreeability of our definition. 4.2. RQ 02: How accurately can we identify queries containing explicit goals?
To devise an algorithm to automatically identify queries containing explicit goals, we compiled a training data set that was based on a majority vote among the participants of the human subject study presented in the previous subsection.
Out of the 3000 labeled queries, the negative examples were defined by the two bars on the left hand side of Fig. 1 (2525 total), and the positive examples were defined by the two bars on the right hand side (377). The bar in the middle represents controversial queries 6 which were removed. Altogether, our training set for the classification task comprised 2902 queries.
We considered several feature types for our automatic classification approach including  X  X  X lain Text X  X ,  X  X  X art-of-Speech Tri-grams X  X ,  X  X  X uery Length X  X ,  X  X  X lick-Through X  X  and  X  X  X anguage Modeling X  X . After preliminary evaluation cycles, we decided on using the first two feature types since they exhibited sufficient discriminative power for our classification task at hand:
Plain text: Queries are represented as binary word vectors or  X  X  X et of Words X  X  (SoW). The Porter stemming algorithm ( Porter, 1997 ) was used for word conflation and removing stop words.
 Part-of-speech trigrams : Each query is translated from a sequence of tokens into a sequence of part-of-speech (POS) tags.
For the part-of-speech tagging, we used a Maximum Entropy Tagger
Street Journal part of the Penn Treebank corpus. Trigrams were generated by moving a fixed sized window of length 3 over the POS sequence. The sequence boundaries were expanded by introducing a single marker ($) at the beginning and at the end allowing for length two POS features. The query  X  X  X uying/VBG a/DT car/NN X  X  would yield the following trigrams: $VBG DT; VBG DT NN; DT NN $
Our intuition behind introducing trigrams was to exploit the grammatical structure of explicit goal queries, i.e. putting emphasis on verb phrases.Throughout our experiments, we used WEKA ( Witten &amp; Frank, 2005 ) as data mining toolkit for feature pre-processing, feature selection, classification and evaluation of classification models. We experimented with sev-eral feature types such as word n-grams, part-of-speech n-grams or query length. By ranking these features according to the results of a chi-square feature selection we determined most discriminative features which eventually led to the decision to use only word unigrams and part-of-speech trigrams. Table 3 lists the 20 most discriminative features together with exam-ple queries for each feature and the number of occurrences of the feature in the positive class (#).

We would have expected that word features such as  X  X  X ow X  X  and  X  X  X here X  X  were amongst highranking features to identify queries containing human goals. We suspect a (probably too strict) stop word removal by the Porter stemmer to be respon-highly ranked part-of-speech trigrams, i.e.  X  X $ WRB TO X  X  or  X  X  X RB TO VB X  X . Moreover, we can observe that only a fifth of the features in Table 3 are unigram features, notably all of them verbs. Thus, it appears that the most discriminative features for identifying queries containing explicit goals are POS features complemented by verbs.

After having identified a set of discriminative features, we apply two common classification models for handling tex-tual data, i.e. a Naive Bayes (NB) classifier ( Friedman, 1997 ) and a linear Support Vector Machine (SVM) ( Dumais et al., the harmonic mean of precision and recall, for evaluation. Since we are mainly interested in achieving high values for the positive class, i.e. queries containing explicit goals, we only report precision, recall and F1 values for the positive class.

In conducting experiments with regard to the F1 score, we aim to identify configurations that balance precision and recall in a way that is useful for acquiring expressions of human goals. We evaluate the selected linear classification models with regard to varying feature set sizes (see Fig. 2 ). Feature sets are generated by applying WEKA X  X  chi-square feature selection i.e. the F1 scores of different feature set sizes and classification models.

These results indicate that the SVM appears to be better suited for our classification task, in particular with increasing number of features. The results also illustrate the NB classifier X  X  dependence on accurate feature selection prior to training and classification. For the NB classifier, the performance significantly deteriorates when more features are used. Informed by these results, we select the linear SVM as the classification model for our subsequent experiments.

Table 4 shows the precision, recall and F1 scores for the positive class, i.e. queries containing explicit goals. The values result from averaging 10 trials of threefold cross-validation keeping all features. A precision of 77% means that in 77% where the classification model believed the query contained a goal, the majority of human subjects agreed. This form of evaluation allows statements about the generalization capabilities of our algorithm: A precision of 77% is the quality to expect when applying our algorithm to Search Query Logs. While this precision score is comparable to other attempts to acquire common-sense knowledge (cf. ConceptNet), it reflects our approach X  X  limitations and requires further attention by future research.
Table 5 shows classification results from our automated method in form of a confusion matrix. It provides an overview of
In addition to frequency values, Table 5 provides corresponding query examples. Examining exemplary queries categorized as FP or FN can be beneficial to better understand the algorithm X  X  behavior as well as to improve its performance. As will be discussed in Section 4.3 , incorrectly classified entries are mainly due to incorrect part-of-speech tagging.
As simple baseline approach, we would guess that a query containing a verb always contains an explicit goal. Yet, such a baseline would perform significantly worse: While the baseline would excel on recall (= yielding a recall of 1,0 due to our definition of explicit goals requiring a query to contain a verb), it would perform worse with regard to the extraction task due to low precision. In our experiments, the baseline achieved a precision of 0,13 and a F1 score of 0,23. 4.3. RQ 03: What are characteristics of queries containing explicit goals automatically extracted from Search Query Logs?
To address this question, we conduct quantitative as well as qualitative analyses to gain more insights into the nature of human goals which we automatically extracted from Search Query Logs. We apply our automatic classification method (see
Section 4.2 )to 35 million queries, 8 i.e. the AOL and the MSN Search Query Log combined. The set of queries our system clas-sified as containing human goals, which we call the result set, comprises 142,000 queries,110,000 of which are unique. With a precision of 77%, this means an estimated 109,000 queries in the result set actually do contain goals. 109,000 queries might
Log, 20 million queries reportedly represent only 0.33% of the total number of queries served during that time. Considering the large numbers of queries served every day, the approach would be able to continuously extract human goal expressions on lar-ger datasets.

Stop word removal and stemming were applied to the result set to obtain a more accurate frequency ranking. Similar en-tries such as buy a new car and buying new cars are then merged into one entry enhance readability, all queries in our result figures and tables are manually post-processed: stems are manually extended to their base form and, if necessary, stop words are re-inserted to restore original meaning. 4.3.1. Quantitative analysis
The 40 most frequent queries from the result set are presented in Table 6 . Each example is accompanied by rank and fre-quency information. Queries containing the token http are filtered out and those queries containing expletives or sex-related content are replaced by deleted .

The information in this table reflects  X  to some extent  X  the needs and goals of the North-American web population, i.e. users of AOL/MS search during the period of the dataset recordings. Some of the most frequent queries containing human goals relate to commonsense goals such as lose weight , get pregnant
We refer to these goals as commonsense goal because of their relation to ConceptNet, a commonsense knowledge base. weight represents a ConceptNet node which is connected to other nodes by relations such as tence of commonsense goals among the most frequent queries in the result set provides some evidence that Search Query
Logs are suited for the task of commonsense knowledge acquisition. By combining the AOL and MSN Search Query Logs, we were able to partly decrease bias that would be introduced by using just one dataset. Yet, the remaining bias introduced by the corpus itself (search queries) and the population (i.e. AOL and MSN users) deserves attention: A fraction of frequent que-ries deals with web-related or AOL/MSN specific issues, such as the queries
Entries such as meaning of name , and buy buy baby likely represent false positives, revealing two kinds of shortcomings of our approach: First, the automatic classification approach relies on linguistic patterns generated by part-of-speech (POS) tag-ging. In case of the query meaning of name , the POS tagger mistakenly tagged incorrect decision. Other examples include enterprise rent car been mistakenly tagged as a verb. A part-of-speech tagger that is trained on a more suitable corpus might help alleviating such problems in the future. Second, certain queries containing explicit goals resemble book titles, TV shows or music themes such as buy buy baby . This problem could be addressed by including domain knowledge (for instance  X  X  X mdb.com X  X ) in the classification task or inspecting and analyzing click-through data and anchor text, which can be expected to improve the overall performance of our approach.

To better understand the nature of identified human goals, we conduct a term analysis by identifying the 10 most fre-quent nouns and verbs in the result set and analyzing verb/noun co-occurrences. The most popular verb/noun co-occur-rences in Table 7 seem to be indicative of typical human goals on the web, such as phone . Preliminary evaluations of the top verb/noun correlations reveal that many of these human goals are also contained in the ConceptNet commonsense knowledge base (marked with a  X  ). This can be understood as a further indicator of the usefulness of Search Query Logs for acquiring knowledge about human goals. It also suggests that Search Query Logs might be useful to automatically complement knowledge contained in existing commonsense knowledge bases, which has been attempted before ( Eslick, 2006 ).

If Search Query Logs would be utilized for such a purpose, a relevant question to ask is: How diverse is the set of human goals contained in Search Query Logs? The diversity of goals would ultimately constrain the utility of a given dataset for com-plementing existing knowledge bases. In order to explore this question, we classified explicit goal queries from the long tail distribution provides evidence that the majority of queries containing explicit goals are diverse in nature, i.e. covering a broad spectrum of goals. 4.3.2. Qualitative analysis
While the analyses conducted so far provide statistical insights into the nature of human goals contained in search que-ries, it is difficult to infer information about their quality. To address this issue, we perform limited qualitative analyses through inspection. We select four verbs and four nouns, manually chosen to represent a range of exemplary activities and topics typically addressed by web search users and inspect explicit goal queries which contain them. In Table 8 , the 10 most frequent goals in the result set are listed, which contain either the verbs to the occurrence in the result set. The human goals listed in Table 8 are the result of identifying the first verb in a query containing a goal, and truncating any tokens prior to this verb. Goals marked with a  X  represent goals that are contained in
ConceptNet. Many entries in Table 8 are related to existing commonsense goals, such as funny .

To gain further insights, we attempted to select interesting nouns which belong to Information Extraction classes: [economy], birth [event], home [location] and people [person]. The corresponding top 10 most frequent human goal expressions are depicted in Table 9 .

Tables 8 and 9 make an interesting case for using Search Query Logs to complement existing commonsense knowledge bases as we will demonstrate in Section 5 . 4.4. RQ 04: Do Search Query Logs contain commonsense goals, i.e. goals that are found in ConceptNet, a commonsense knowledge base? If they do, what is the nature of human goals shared by ConceptNet and Search Query Logs and how do they differ?
By addressing this research questions, we aim to establish a connection between human goal expressions from two do-mains, i.e. commonsense and search. We approached these questions by comparing human goals acquired from Search
Query Logs to commonsense goals (cf. Lieberman et al., 2007 ) from ConceptNet. We identified commonsense goals in Con-ceptNet by querying concepts (ConceptNet nodes) which were connected by relations such as UsedFor , CapableOf and Moti-vatedByGoal . We compiled a subset of entries from ConceptNet that consists of commonsense goals and imposed the following restrictions on all candidates to increase quality: Commonsense goal candidates had to contain at least one verb and at least one noun.

Using this approach, we obtained an overall number of 68,000 commonsense goals and compared them to the 110,000 unique human goals acquired from Search Query Logs. First, we were interested whether Search Query Logs contained com-monsense goals. As an approximation, we calculated the intersection between Search Query Log and ConceptNet goal sets with the following intuition: An adequate number of shared entries would indicate the presence of commonsense goals in Search Query Logs. To calculate the intersection, we devised a simple goal matching algorithm (similar to Lieberman et al., 2007 ) to identify matching pairs of human goals from the two goal sets. All entries were pre-processed: stop words were removed and all remaining tokens were stemmed using the Porter stemmer ( Porter, 1997 ). Table 10 shows examples of commonsense goal examples from ConceptNet before and after applying pre-processing steps.

For two goals to match, they had to contain an equal number of identical stems. Our algorithm focused on lexical char-acteristics only; semantic similarities were not taken into account. This idea is similar to Liu X  X  process of normalization to identify similar instances in ConceptNet ( Havasi, 2007 ). Table 11 illustrates some examples of matching and non-matching entries from ConceptNet and Search Query Logs.

Eventually, we obtained 2300 ConceptNet goals and 3100 Search Query Log goals (occurrences) that produced positive matches. While the number of shared goals appears small, our findings provide first evidence of the existence of common-sense goals in Search Query Logs.
 To answer the second question, we categorized the set of 3100 commonsense Search Query Log goals into a subset of
Levin X  X  verb class taxonomy ( Levin, 1993 ). From this taxonomy, we selected 15 verb classes (see Fig. 4 ) that we deemed rel-evant for reflecting human activities, e.g. Eat or Learn . Fig. 4 shows the resulting verb class histogram of commonsense goals from Search Query Logs.

Three dominant verb classes build , obtain and perform can be identified from Fig. 4 . Their dominance might be ex-plained by occurrences of verbs in frequently stated commonsense goals such as instrument . Classes build (verb make ), obtain (verb buy classes. An interesting observation is that the verb class underrepresented due to the fact that search engines already represent a means for searching the web, i.e. goals in search queries do not need to contain verbs expressing the goal to search itself. In the following, we will study to what extent com-monsense goals which are contained in Search Query Logs differ to those contained in ConceptNet.

To illustrate different characteristics between goals from Search Query Logs (QL) and ConceptNet (CN), we generate a verb class histogram for the complementary sets of goals. In set-theoretic terms, this reads as follows: CN X  X L and QL X  X N. Our initial intuition was that ConceptNet X  X  commonsense goals would be biased towards everyday situations and human char-acteristics such as eating , feeling and living . The results confirm our intuition:
The verb histogram in Fig. 5 shows that verb classes eat , set. Similarly, we expected classes such as obtain to be the dominating Search Query Log goals. This can be observed in our results: Levin X  X  verb class obtain dominates the human goals acquired from Search Query Logs, which contain frequently occurring verb instances such as get , buy and find .
 suggests that query logs could actually help increase coverage of commonsense knowledge bases , for example by focusing on types of goals that are more prevalent in Search Query Logs, such as
Search Query Logs are not suited to contribute to commonsense goals from verb classes such as
We conclude this subsection with the following observations: (1) Search Query Logs appear to be a potential source for commonsense goals. (2) Search Query Logs and ConceptNet each emphasize different goal classes. (3) Search Query Logs might represent a useful resource to complement existing commonsense knowledge bases such as ConceptNet which we will elaborate on in the next section. 5. Illustration scenario of applying goal knowledge: complementing a commonsense knowledge base
In this section, we aim to make use of our findings from Section 4.4 and sketch potentials of applying knowledge about human goals to complement ConceptNet, a commonsense knowledge base. We explore two methods for complementing
ConceptNet: (i) refinement and (ii) extension. The internal structure of ConceptNet facilitates refinements and extensions simply by adding novel triples consisting of two concepts connected by a semantic relation.
 First, we propose refining existing nodes by making them more specific, e.g. by adding adjectives or adverbs. The Concept-
Net goal finding friends can thus be refined by following selected Search Query Log goals lost friend or find free military friends . Table 12 provides potential refinements for a set of commonsense goals from ConceptNet.

In addition, Search Query Logs provide us with frequency information that is denoted in brackets for each potential refinement in Table 12 . A quality criterion for refinement candidates could, for instance, be to introduce a frequency threshold.
 Second, we demonstrate one possible way to extend commonsense knowledge by human goals acquired from Search
Query Logs. We start from ConceptNet triples which contain the MotivatedByGoal relation such as [ X  X  X ait tables X  X ,  X  X  X otivat-edByGoal X  X ,  X  X  X ake money X  X  X . The left concept wait tables corresponding goal make money in the right concept. For each ConceptNet goal, we extracted a list of actions from Concept-
Net. In case of the goal make money , the list of actions includes knowledge base with human goals from Search Query Logs, we compiled a list of candidate human goals which were similar to the ConceptNet goal. We used a simple bag-of-words metric to identify similar goals: If the Search Query Log goal con-tained all tokens of the ConceptNet goal, it was added to the candidate set of the corresponding ConceptNet goal. To give an example, make money quickly represent a candidate for the ConceptNet goal refinements as candidates and consequently as potential new ConceptNet entries. The following example should clarify the procedure: ConceptNet entry: Wait tables MotivatedByGoal Make money Potential new ConceptNet entry: Wait tables MotivatedByGoal Make money quickly
Table 13 shows potential new combinations of human goals from Search Query Logs and corresponding actions that were already contained in ConceptNet. The examples in Table 13 illustrate selected combinations that were rated positively by human judges. These combinations could be integrated into ConceptNet by using the MotivatedByGoal relation.
We conducted a human subject study to evaluate the compiled ( X  X  X earch query goal X  X / X  X  X onceptNet action X  X ) pairs which were annotated by two annotators. On the whole, 528 decisions had to be made. The human subjects were given a list of goals and corresponding actions. For every goal/action pair (G/A), they had to answer following question with yes or no:
Do you think that a person X  X  goal could be G when performing action A? We introduced a softer variant of the known precision metric, i.e. a human goal from Search Query Logs was considered a potential goal if at least one ConceptNet action had been positively annotated. In our human subject study, we achieved an average soft-precision of 64%, meaning that 77 out of 120 goals from Search Query Logs were regarded reasonable goals for the given actions.

These findings suggest that human goals from Search Query Logs can contribute to complement ConceptNet, a common-sense knowledge base. In this section, we outlined how to generate promising ConceptNet node candidates and how to inte-grate them into ConceptNet. 6. Discussion
In this section, we will discuss threats to validity of our results ( Yin, 2002 ). By examining our approach from a scientific perspective, we are capable of estimating the scientific value of our results, e.g. ensuring reproducibility. 6.1. Threats to validity Construct validity : The main construct we investigate in this research is the notion of explicit goals contained in Search
Query Logs . While our definition intentionally gives some room for variability, our human subject study yields reasonable scores for inter-rater agreement j ( Cohen, 1960 ) and a reasonable distribution of human annotators X  judgements, which can be interpreted as preliminary empirical evidence for the validity of our construct.

Internal validity : The subjects involved in our human subject studies were graduate students enrolled at Austrian univer-sities, who were not involved in the research of this paper. While all subjects were fluent in English, they did not share the same cultural context of the population that submitted those queries contained in the Search Query Logs (Austrian Grad-uate students vs. North-American web users). Although we could not find evidence of this problem in our human subject study, it could be the case that certain queries were mistakenly labeled as containing an explicit goal (such as  X  X  X aking the band X  X ). Our bias towards longer queries (n &gt; 2) prevents us from studying a large part of the Search Query Logs ( 65%).
Yet, the focus on longer queries was motivated by the observation that queries containing explicit goals mostly consist of more than two tokens.

External validity : In our definition of  X  X  X ueries containing explicit human goals X  X , we refer to existing work on goal defini-tions from other research areas including goal-oriented requirements engineering ( Regev &amp; Wegmann, 2005; Liaskos et al., 2006 ) and computational linguistics ( Tatu, 2005 ).

Reliability : In our experiments, we used existing toolkits such as WEKA ( Witten &amp; Frank, 2005 ) and NLTK methods such as the Stanford part-of-speech tagger 10 and the Porter stemmer ( Porter, 1997 ), so that reproducing our results should be possible. 7. Conclusions
Our work illustrates the potential of Search Query Logs to address challenges associated with acquiring knowledge about human goals from the web. Since Search Query Logs are a natural by-product of human activity on the web, they represent a largely untapped, renewable resource for the knowledge acquisition task. We present an automatic classification approach and demonstrate that human goals can be acquired from Search Query Logs with useful precision/recall values. Our results indicate that our presented automatic approach is a viable alternative to manual or semi-automatic approaches which are often costly and time-consuming. Our findings reveal that (i) human goals acquired from Search Query Logs in part represent commonsense goals which can be employed to refine and extend commonsense knowledge bases ( Strohmaier &amp; Kr X ll, 2009 ) and that (ii) they cover a vast range of topics and levels of granularity, which makes Search Query Logs a promising resource for addressing the goal coverage problem.

Our work is particularly relevant for knowledge engineers who seek to construct knowledge bases of human goals. In efit from additional knowledge about human goals, e.g. recognizing a sequence of related human goals. Planning tasks in-volve the generation of action sequences that implement goals. Human goals from Search Query Logs can be employed to complement commonsense knowledge (see Section 5 ), which then could be integrated into artificial intelligence systems to support tasks such as planning. The potential of goal knowledge to inform human computer interaction is already being a better understanding about users X  actions can be achieved contributing to advance the vision of more intelligent user interfaces.
 Acknowledgements
The authors thank Microsoft Research for providing the Search Query Log and Peter Prettenhofer for participating in com-pleting this work. Furthermore, we would like to thank the reviewers for very constructive and detailed comments. This work is funded by the FWF Austrian Science Fund Grant P20269 TransAgere. The Know-Center is funded within the Austrian
COMET Program under the auspices of the Austrian Ministry of Transport, Innovation and Technology, the Austrian Ministry of Economics and Labor and by the State of Styria. COMET is managed by the Austrian Research Promotion Agency FFG. References
