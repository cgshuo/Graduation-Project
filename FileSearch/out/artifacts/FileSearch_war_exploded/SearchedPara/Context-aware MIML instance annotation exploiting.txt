 Forrest Briggs  X  Xiaoli Z. Fern  X  Raviv Raich Abstract In multi-instance multi-label (MIML) instance annotation, the goal is to learn an instance classifier while training on a MIML dataset, which consists of bags of instances paired with label sets; instance labels are not provided in the training data. The MIML for-mulation can be applied in many domains. For example, in an image domain, bags are images, of objects or categories present in each image. Although many MIML algorithms have been to predict instance labels. We propose MIML-ECC (ensemble of classifier chains), which exploits bag-level context through label correlations to improve instance-level prediction accuracy. The proposed method is scalable in all dimensions of a problem (bags, instances, classes, and feature dimension) and has no parameters that require tuning (which is a problem for prior methods). In experiments on two image datasets, a bioacoustics dataset, and two artificial datasets, MIML-ECC achieves higher or comparable accuracy in comparison with several recent methods and baselines.
 Keywords Multiple instance  X  Multi-label  X  MIML  X  Instance annotation  X  Classifier chain 1 Introduction The most common formulation of supervised classification is single-instance single-label The goal is to predict the label for a new instance. SVMs, logistic regression, and decision trees are for SISL. Multi-instance multi-label (MIML) learning is a framework for supervised classification, where the dataset is represented as a collection of bags of instances, paired with sets of labels. For example, in an image domain, a bag is an image, the instances in the [ 5 ], and video [ 31 ] domains. There are many algorithms that train a classifier on a MIML
MIML instance annotation is a recent and little-studied problem for supervised classifi-cation. In contrast to most prior work on MIML, instance annotation aims to train a classifier on a MIML dataset to predict the instance labels. For example, we train a classifier on images paired with sets of objects they contain and then predict the class label for each region of a new image. The main advantage of MIML instance annotation compared with SISL is that it typically requires less human effort to provide bag label sets than to label instances. For example, images tagged with label sets are abundant, whereas SISL data are limited (there are not many images labeled at the pixel level).

MIML instance annotation differs from the traditional MIML problem of label set pre-particular, it is commonly assumed that each instance only belongs to one class; thus, the for MIML instance annotation is to maximize instance-level accuracy (the fraction of cor-accuracy on the training data, because instance labels are not available for training.
Instance annotation problems for images have been widely explored. For example, Yang and learned from image label sets. Sometimes, it is possible to modify a MIML or MLC algorithm that is designed for label set prediction, to predict instance labels. The problem with this approach is that the model is optimized for label set accuracy, not for instance accuracy. However, to our knowledge, only two prior studies have specifically considered proposed rank-loss support instance machines (SIM), a collection of SVM-style algorithms
Prior work [ 3 , 4 ] has observed that the rank-loss SIM algorithms, as well as several other baseline methods, achieve lower accuracy for inductive classification of instances (predicting instance labels for previously unseen bags) in comparison with transductive classifications (predicting instance labels for bags with known label sets). We hypothesize that one way to improve the performance of inductive classification is to exploit the contextual information provided by other instances in the same bag.

Figure 1 a illustrates the difficulty of instance annotation without context. The region of pixels inside the red box is an instance. A MIML instance annotation classifier might be asked to predict the class label of this instance. Without the context provided by the rest of the image, it is hard to classify, even for a human. Figure 1 b shows the rest of the image. inductive MIML instance annotation is posed in prior work [ 3 , 4 ]. It is not as important to use the context provided by other instances in the same bag for transductive classification, because the bag label set is already known and provides a similar kind of context. Consider the same example in Fig. 1 a. If we know that the image contains labels  X  X ow X  and  X  X rass, X  be  X  X ow. X 
This paper proposes a new algorithm for MIML instance annotation designed to improve inductive instance accuracy by exploiting the context provided by other instances in the same The proposed method (Sect. 4 ) is a multi-instance multi-label ensemble of classifier chains, called MIML-ECC. The classification algorithm selects the maximum a posteriori (MAP) instance label as estimated by the ensemble, and the training algorithm is closely related to EM and the constrained concave X  X onvex procedure (CCCP) [ 35 ]. Training is asymptotically datasets show that MIML-ECC achieves higher accuracy than several recent methods and baselines, including Hamming, rank, and ambiguous-loss SVMs, and comparable accuracy to a recent graphical model. Further experiments show that the chain structure outperforms binary relevance, and an ensemble of chains outperforms a single chain. To gain a better understanding of how MIML-ECC exploits correlation, we present experiments with artificial datasets where the degree of correlation between classes is controlled. 2 Problem statement For training, we are given a MIML dataset consisting of n bags paired with their corresponding { x i 1 ,..., x in i } , x  X  X = R d .

We assume that each instance x in B i has a single label y  X  Y . The instance labels are not available in the training data; and we only have ambiguous information about them provided training only on the bag-level label sets.

Instance annotation can be applied in both transductive and inductive modes, which differ defined as: f ( the class of a particular segment in the image.
The inductive mode classifies an instance without the bag label set given. For example, in the inductive mode, the prediction task could be: given an image, predict the class of a particular segment in the image. Prior work [ 3 ] on MIML instance annotation formulates the We instead formulate the inductive classifier as The difference is that when classifying an instance x , we know that it is part of a bag B and can use the contextual information of B to improve the prediction.

Related problems There are many other formulations of supervised classification that are related to MIML instance annotation. The main difference between these frameworks is the training data and inductive classifier in each framework.

The most common supervised classification formulation is single-instance single-label (SISL). Most standard methods such as support vector machines, decision trees, and logistic regression are for SISL. Multiple-instance learning (MIL) is a framework where the training data consists of bags of instances paired with a single binary label, and the classifier maps of labels, and the goal is to predict a label set given a new instance.

Ambiguous label classification (ALC) [ 8 ] and superset label learning (SLL) [ 19 ]havethe same structure of training data as MLC, but assume only one label in the set is correct and instance. MIML instance annotation can be reduced to ALC/SLL by pairing each instance with its bag label set. However, this reduction can be undesirable as it discards the context of the bag. 3 Background A key observation motivating our approach is that the context provided by a bag X  X  label set is image can help for predicting the label  X  X ow X  for the given instance, because the labels  X  X ow X  approach, which has been previously developed for MLC to exploit label correlation. Below we begin with a review of classifier chains for MLC. We then discuss some design patterns in MIL and MIML algorithms that learn an instance-level model from bag-level labels, which provide inspiration for our algorithm. 3.1 Classifier chains for multi-label classification Recall the setup for MLC: Given an instance x , we denote its label set Y as a binary vector: Y =[ Y 1 ,..., Y c ] ,where Y j = 1 if the label set for instance x contains class j .
Binary relevance is an algorithm for MLC, which builds one binary model for each class, and treats the classes independently. Binary relevance uses a binary SISL classifier to model P ( Y j | x ) ,for j = 1 ,..., c . Figure 2 shows the graphical model for binary relevance. distribution of Y : on x , and all of the preceding classes 1 ,..., j  X  1. Let  X  denote vector concatenation. The basic training algorithm is: MLC Probabilistic Classifier Chain X  X rain for j = 1 ,..., c : standard SISL problem, not an MLC problem). This 2-class problem has n instances like [ 2 ].
 for all 2 c possible label vectors Y , and pick one that minimizes a set-level loss function. However, this approach may be intractable unless c is small. An alternative is to greedily construct a single value of Y . A basic greedy algorithm [ 9 ]is: MLC Probabilistic Classifier Chain X  X lassify
Y =[] for j = 1 ,..., c : return Y
In ensembles of classifier chains (ECC) [ 25 ], there are multiple chains, each of which is learned as above, but factorizing the classes in a different random order. When classifying with ECC, each chain votes. ECC reduces the sensitivity to the specific order of the chain and is generally observed to improve accuracy over a single chain. 3.2 From instance to bag labels A central problem in MIL and MIML is that labels are only provided at the bag level. Learn-ing an instance classifier from bag label sets requires an assumption about the relationship between the observed label sets and the hidden instance labels. A common assumption in corresponding assumption in MIML is that the bag label set is equal to the union of instance labels. Prior algorithms approximate these assumptions using different formulations, e.g., the max model.

Let f ( x ) be an instance-level score function and F ( B ) be a bag-level score function. In the max over the instance-level scores f ( x ) on all instances in the bag.

For probabilistic MIL classifiers, the max model has also been called the  X  X ost-likely-cause estimator X  [ 20 ], formulation for MIML [ 3 , 37 ] applies the same principle for each class j = 1 ,..., c :
Given a model for connecting bag labels with instance labels, the output of a bag-level clas-the bag. For example, assuming the max model for MIL, we have: define support instances similarly for MIML, except that one support instance is defined for each class and each bag. Alternatives to the max model are discussed in Sect. 6 . Many existing algorithms for MIL (e.g., MI-SVM [ 1 ]andEM-DD[ 38 ]) and MIML (e.g., SIM [ 4 ]) alternate between computing support instances based on a current classifier, and training a SISL classifier on the support instances. Our proposed algorithm follows the same pattern. 4 Proposed methods vector x and the context provided by the bag B containing x . We propose the MIML-ECC algorithm, which is motivated by the observation that the prediction of whether an instance belongs to a particular class can be influenced by the presence/absence of some other classes in the bag. To capture the label correlation, we assume an ordered chain structure such that whether an instance belongs to a particular class depends on whether the bag contains classes earlier in the chain. First, we present a training algorithm to learn such a model from MIML data. Then, we discuss instance classification in transductive and inductive modes. Table 2 summarizes notation for the proposed method. 4.1 Training A classifier chain for MLC is a chain of SISL classifiers. At a high level, our method can be viewed as building an ensemble of L chains of MIL classifiers. Each chain l = 1 ,..., L in The training algorithm viewed in terms of MIL classifiers is: MIML-ECC X  X rain (Bag-Level View) Input: MIML dataset { ( B 1 , Y 1 ),...,( B n , Y n ) }
Output: MIL classifiers F jl for l = 1 ,..., L :  X  l = random X  X ermutation( [ 1 ,..., c ] ) for j = 1 ,..., c : Each MIL dataset D jl constructed in the algorithm pairs the bag B i (and the context Y i ) with one bit of the label vector Y in practice, we simply append this vector to the end of all of the instance features.
Because our goal is ultimately to predict instance labels, we instantiate this template with a MIL classifier that internally builds an instance-level model. The instance-level models are SISL probabilistic classifiers f jl for j = 1 ,..., c and l = 1 ,..., L . We assume f jl that Y ={ 1 ,..., c } ; we encode the label y  X  Y of instance x with c binary indica-Y
Similar to the MIL algorithm EM-DD, and rank-loss SIM for MIML, we define the bag-level model in terms of a support instance. In MIML-ECC, there is a different support instance for each bag, class, and chain . The bag-level model in terms of support instances is
The support instance  X  x ijl is the instance in bag B i that is most representative of class  X  ( j ) , according to the classifiers in chain l .

The MIML-ECC training algorithm alternates K times between updating support instances according to the max model, and then training SISL classifiers on binary datasets that pair f jl to compute support instances from, so we start by setting the support instances to the average of the instances in each bag, as in [ 3 , 4 ]. The instance-level view of the training algorithm is: MIML-ECC X  X rain (Instance-Level View) Input: MIML dataset { ( B 1 , Y 1 ),...,( B n , Y n ) }
Output: SISL classifiers f jl for l = 1 ,..., L :  X  l = random X  X ermutation( [ 1 ,..., c ] ) for k = 1 ,..., K :
Similarities with EM The proposed training algorithm is a heuristic and is not proven to converge over multiple support instances updates. However, empirically we observe work using support instances with expectation maximization (EM), which we discuss below.

EM-DD [ 38 ] is a widely used EM-style algorithm for MIL (single-labeled bags of instances). The  X  X -step X  consists of computing support instances, and the  X  X -step X  max-imizes likelihood in a model involving the support instances. EM-DD also uses the max model to define the support instances. The main difference in how support instances are treated in MIML-ECC is that each bag has a different support instance for each class and chain. Recall that MIML-ECC trains SISL classifiers f jl in each iteration. If the base SISL with the M-step of EM-DD. In our implementation of MIML-ECC, f jl is a RF using the Gini data [ 6 ]. If the entropy split criteria were used instead, the RF would greedily maximize likelihood. Gini and entropy are very similar for binary problems. 4.2 Classification We consider a probabilistic framework for instance classification based on the maximum a posteriori (MAP) approach. Our method can be viewed as approximately optimizing the Y so we generate samples of Y by conditioning on all instances in the bag. 4.2.1 Transductive mode according to This prediction rule assumes that bag label set Y provides all of the contextual information other instances in the bag B given Y .

During training, we introduced random orders  X  for the purpose of constructing an ensem-ble. Now, we take a Bayesian approach and assume that  X  is random variable from a uniform prior P ( X  ) , so each chain in the ensemble corresponds to one i.i.d. sample  X  l  X  P ( X  ) for l = 1 ,..., L . We estimate the probability for instance x to have label y = k as P ( The algorithm for classification in the transductive mode is: MIML-ECC X  X lassify (Transductive) Input: instance x , label set Y
Output: label y for j = 1 ,..., c : y j = 0 for l = 1 ,..., L : y = arg max j  X  Y y j 4.2.2 Inductive mode conditions only on the instances from bag B (and not the bag label set). Therefore, we predict the instance label as the class with the highest posterior probability Y . This process requires a probabilistic model for Y given B , which we develop below. We begin by stating the assumptions of this model.
 of any other instances in the same bag B ,giventhefirst j  X  1 bits of the bag-level label set Y reasonable in Sect. 4.3 .

For training, we defined the relation between instance labels and bag label sets according to the max model. The max model is also part of our assumptions for inference, although we will rewrite it in probability notation.
 Assumption 2 Bag label sets and instance labels are linked via the max model, Section 3.2 discusses the motivation for this assumption in depth.

Similar to a classifier chain for MLC, the conditional distribution of the bag label set is factored as a chain in the order  X  as
Recall that Assumption 2 defines the conditional probability for Y  X ( j ) in terms of the bilities for y  X ( j ) in terms of Y  X ( 1 ) :  X ( j  X  1 ) .

We estimate P ( y j | x , B ) by sampling as follows. For a given  X  ,weapplyAssumption1 to obtain
Because  X  is a permutation, computing P ( y  X ( j ) | x , B , X ) for j = 1 ,..., c implies com-puting P ( y j | x , B , X ) for all j .

Finally, we average the posterior estimates over multiple samples from a uniform prior on  X  : As in the transductive mode, each chain in the ensemble gives one sample of  X  l  X  P ( X  ) to estimate the expectation. The inductive classification algorithm is: MIML-ECC X  X lassify (Inductive) Input: bag B ={ x 1 ,..., x n i }
Output: instance labels y 1 ,..., y n i 01: for i = 1 ,..., n i : for j = 1 ,..., c : 02: y j i = 0 03: for l = 1 ,..., L : 04: Y =[] 05: for j = 1 ,..., c : 06: for i = 1 ,..., n i : 07: y 09: Y = Y  X  Bernoulli ( p j ) 10: for i = 1 ,..., n i : applies the max model (Assumption 2). In lines 4 through 8, the pseudocode variable Y stores Y a probability is above or below 0.5. Line 9 serves an analogous purpose in MIML-ECC, but instead the bits are generated randomly based on a probability. Specifically, line 9 samples Y l ( j ) from a Bernoulli ( p j ) distribution and appends it to the current label vector. 4.3 Example of inductive classification example of object recognition in an image domain. Suppose an image is segmented into simplify the example, we consider a single chain ordered so that  X ( 1 ) = grass,  X ( 2 ) = cow, and  X ( 3 ) = penguin. Classification might proceed as follows:
The steps above show how a single chain generates the class scores for each instance. With multiple chains, the scores from each chain are summed before picking the highest scoring class.
In this example, it is difficult to tell whether the instance x 1 belongs to the class cow on a similar situation where there are two correlated classes, one of which is easily confused with a third class in Sect. 5.5 . 4.4 Asymptotic complexity MIML-ECC implemented with RF as the base SISL classifier is asymptotically efficient in all important dimensions of the problem size. The size of a MIML dataset is determined by the instance feature dimension d . MIML-ECC has several parameters that affect its runtime: the number of chains L , the number of trees in each RF T , and the number of support instance updates K . Note that the runtime to train a RF on a SISL dataset of n instances with feature structure of the pseudocode that the training time for MIML-ECC is
An efficient implementation of MIML-ECC classifies all instances in a bag at once, rather we provide empirical runtime results. 5 Experiments Our experiments compare MIML-ECC to prior and baseline methods on two vision datasets, for cross-validation are used). Therefore, we report new results for MIML-ECC and baseline methods and compare to previously reported results from the afore-mentioned prior work. 5.1 Datasets The datasets used in our experiments are summarized in Table 3 . Datasets have been pre-processed through feature rescaling (which does not affect RF), to improve results for SVM-style classifiers, by the same process in [ 3 , 4 , 8 ].

Vision datasets We consider two vision datasets, Microsoft Research Cambridge v2 (MSRCv2) [ 29 ] and PASCAL Visual Object Recognition Challenge (2012  X  X egmenta-MSRCv2 provides a single class label for each pixel. VOC provides a segmentation of each image into objects and a label for each object. Here, bags are images labeled with a list of objects, and instances are objects (regions of pixels), described by a 48-D feature vector. Single-label images are removed to make the learning problem more challenging.
Bioacoustics dataset This dataset was introduced by [ 5 ], applying a MIML formulation conditions. Each bag is a 10-second audio recording labeled with the set of species it con-tains. Each instance is an utterance of bird sound obtained by an automatic segmentation algorithm. This dataset has also been used in work on MIML instance annotation and super-[ 19 ].

Artificial datasets We use the same artificial MIML datasets as [ 3 , 4 ], which are generated are generated based on the words in two poems,  X  X abberwocky X  by Lewis Carroll [ 7 ]and  X  X he Road Not Taken X  by Robert Frost [ 13 ]; hence, they are referred to as Carroll and Frost. Each bag is a word, its letters are instances, and the bag label set is the union of instance labels. The instance features are sampled randomly from the UCI Letter Recognition dataset [ 12 ]. 5.2 Prior methods We compare MIML-ECC with a number of prior methods that can be applied to MIML instance annotation.

M 3 MIML Originally intended for label set prediction, M 3 MIML is a MIML support vector machine algorithm, which builds one linear instance-level model per class by minimizing a heuristic relaxation of bag-level hinge loss, and connecting instance labels with bag label sets by the max model. Although not intended for this purpose, the learned instance-level models can be used for instance annotation.

Rank-loss SIM Rank-loss SIM was introduced by [ 3 ] and refers to a class of instance annotation algorithms which learn one linear instance-level model per class by minimizing a bag-level rank-loss objective. Different variants of rank-loss SIM consider different models for connecting bag-level output with instance-level outputs and apply different procedures for optimizing the rank-loss objective. We consider SIM-Heuristic using a softmax model and SIM-CCCP with the max model, with random Fourier kernel features [ 23 ] to achieve nonlin-ear classification by approximating an RBF kernel. These models are chosen for comparison because they achieved the best accuracy in [ 4 ].

CLPL Like the other SVM-style algorithms, convex learning from partial label (CLPL) [ 8 ] learns one linear instance-level model per class, but uses an ALC formulation instead of MIML. CLPL minimizes a loss function which can be seen as an upper bound to the 0/1 loss on the true-unknown label, which is part of the candidate label set.

LSB-CMM Logistic stick-breaking conditional multinomial model (LSB-CMM) [ 19 ]is a recent hybrid generative/discriminative graphical model for SLL that have been used (by reduction) to solve the instance annotation problem. In particular, the same Birdsong and MSRCv2 datasets were used in [ 19 ] to evaluate its instance annotation accuracy. We compare to the results reported in [ 19 ] on these two datasets. 5.3 Experimental setup Transductive and inductive In the transductive mode, there is no cross-validation (the whole dataset is used for training and testing). However, because MIML-ECC is a randomized algorithm, we run 10 repetitions and report the average accuracy  X  the standard deviation over repetitions. Most of the other algorithms we compare to are not randomized, so in the transductive mode there is no uncertainty associated with the accuracy result.
In the inductive mode, we use tenfold cross-validation, except for the VOC dataset, for validation are reported as average accuracy over all folds  X  standard deviation. A different random instantiation of MIML-ECC is used in each fold, so we do not run multiple repetitions on top of cross-validation. However, because there is only one fold for the VOC dataset, we report results  X  standard deviation over 10 repetitions for MIML-ECC (and the randomized baseline method SISL Random Forest) on VOC.

M 3 MIML, CLPL, and rank-loss SIM-Heuristic/CCCP all build one instance-level model f ( the instance-label predictions). This constraint provides some context for instance-label pre-diction, so one might not expect as much benefit to be had from looking at other instances in the transductive mode.
 Parameter selection All of the rank-loss SIM algorithms, CLPL, M 3 MIML, and SISL SVM have a regularization parameter (either  X  or C ). When random kernel features are used to approximate the RBF kernel, there is also a kernel parameter  X  , and a parameter D which controls the approximation accuracy. In prior work, these parameters are optimized post hoc by a grid search as described in [ 4 ]. This means that the experiment is run once for each parameter setting in a grid, and the best test accuracy over all parameters is reported. Post hoc selection is not feasible without using instance labels to compute which parameter setting has the best accuracy, but it has been accepted in prior work on MIML instance annotation because it is an unsolved problem. Results using post hoc selection can be interpreted as the highest accuracy that can be achieved using an oracle to select meta-parameters. Results listed in Table 4 that are marked with a  X  are obtained with post hoc parameter selection.
An important practical advantage of MIML-ECC compared with the above prior methods is that it does not have regularization parameters that must be tuned. Note that MIML-ECC has parameters L , K ,and T . The accuracy of the algorithm tends to increase as these parameters increase up to a limit. So the parameter choices primarily depend on the time budget for training and testing. Our experiments set L = 20 , K = 20 , T = 100, which provides a good trade-off between runtime and accuracy.

LSB-CMM [ 19 ] has some parameters which can affect accuracy, but in their experiments these parameters are set to standard values for all datasets. 5.4 Results Comparison with prior methods MIML instance annotation algorithms are evaluated based on accuracy, which is the fraction of correctly classified instances. These experiments compare summarize results using wins, ties, and losses, and average ranks. Table 4 lists the accuracy and average rank results in transductive and inductive modes. Average ranks are computed by sorting the accuracy of MIML-ECC, and the prior methods M 3 MIML, CLPL, SIM-Heuristic, and SIM-CCCP on each dataset, and then averaging the position in the sorted list over all datasets. We do not include LSB-CMM in the ranking because there are only 2 datasets with comparable results.
 In the inductive mode, MIML-ECC ties with SIM-CCCP max with RBF kernel on the Carroll dataset and wins in all other comparisons. Results are not as decisive in the trans-ductive mode, but MIML-ECC still achieves the best average rank over all datasets. This is consistent with our expectation because the known label sets provide a surrogate for context to the other algorithms.
 It should be noted that due to the use of post hoc selection in experiments for CLPL, M 3 MIML, SIM-Heuristic, and SIM-CCCP, they are actually given an unfair advantage com-pared to MIML-ECC, which does not use the test data ground truth in training or parameter selection.

The comparison with LSB-CMM on two datasets is less conclusive. MIML-ECC outper-forms LSB-CMM by a margin of 15.2 % on the MSRCv2 dataset, but LSB-CMM is slightly better (by a margin of 4 %) on the Birdsong dataset.

Ensemble of chains versus binary relevance (SIM-RF) MIML-ECC is motivated by the idea instance labels. However, it is possible that the improved performance we observe compared to prior linear/kernel algorithms is not due to exploiting label correlations, but instead to comparison against a baseline that we call SIM-RF, which is the same as MIML-ECC in all details except it does not use a chain or model correlations. SIM-RF is equivalent to running MIML-ECC with one chain ( L = 1) but omitting all of the concatenation of label set bits, MIL classifier which alternates between computing support instances and training an RF on them.

MIML-ECC achieves better accuracy than SIM-RF most of the time. The win-loss count is 4-1 in favor of MIML-ECC for both transductive and inductive modes. The comparison with SIM-RF suggests that the chain structure is actually critical, and the improved performance of MIML-ECC compared with prior methods cannot be attributed only to switching from a linear or kernel SVM classifier to RF.

Single chain versus ensemble of chains We want to know how much benefit the ensemble provides compared with a single chain. The results we reported so far are obtained with L = 20 , K = 20 , T = 100, i.e., 20 chains and 100 trees and 20 iterations of support instance updates. To understand the impact of using multiple chains with a fair comparison, we run MIML-ECC with one chain order ( L = 1), and K = 20 , T = 2 , 000, so the total number of MIML-ECC in the inductive mode (see Baseline Methods). In this comparison, MIML-ECC with multiple chains achieves higher accuracy on all datasets than MIML-ECC with a single scores for class j , each chain can only use the presence/absence of other classes which come before j in the chain. Using multiple chains with random orders increases the chance that relevant classes are available for use as context (at least in some of the chains).
Comparison with SISL We also consider SISL algorithms, which have an unfair advantage of learning directly from instance labels. Results with these SISL algorithms are presented for the inductive mode as an empirical upper bound on the accuracy that can be achieved on these datasets. For this comparison, we use a SISL RF (with 1 , 000 trees) and refer to prior results from [ 4 ] with a SISL multi-class linear SVM.
SISL methods achieve better accuracy in inductive experiments than MIML instance annotation, ALC and SLL (Table 4 b), which is expected because they are trained on unam-biguously labeled instances. This improved accuracy must be weighed against the greater human effort required to obtain instance labels compared with bag label sets.
 Empirical runtime Ta b l e 5 lists empirical runtimes for training plus classification with MIML-ECC (with L = 20 , K = 20 , T = 100), on each dataset, averaged over the number of repetitions or folds of cross-validation. The runtime is on the order of seconds or minutes is done sequentially. 2 5.5 Experiments with controlled correlation MIML-ECC is motivated by improving instance annotation accuracy by exploiting corre-both MIML-ECC and SIM-RF, we conduct additional experiments in which the correlation between classes is controlled.
 Similar to the Carroll and Frost datasets, we obtain instance feature vectors from the UCI experiments, however, we only use subsets of 3 or 4 classes from the original dataset, which distinguish, and a third class that is hard to distinguish from one of the correlated classes. In order to identify classes that meet these criteria from the 26 available in the UCI Letter Recognition dataset, we consider the confusion matrix for a SISL experiment with the full 26 classes. Training and test sets are formed by splitting the instances from each class randomly examples. A Random Forest with 100 trees is trained on one set and then used to predict the labels in the other.

From the confusion matrix, we find that H is the lowest-accuracy class, with only 0.389646 often confused with instances of class X, with probability 0.125341. However, H is easily distinguished from instances of class A; zero instances of H are misclassified as A, and instances of A are misclassified as H with probability 0.0027248. Therefore, we will set up a MIML instance annotation experiment with three classes: A, H, and X. The correlated classes will be A and H, and X will be uncorrelated. We hypothesize that MIML-ECC will achieve better accuracy when A and H are positively or negatively correlated in the label set, because the context provided by the presence or absence of A can help to differentiate between H and X.

The next step in setting up this experiment is to generate bag label sets in such a way that the occurrence of A and H has correlation related to a parameter  X  . Let the label set y
A and y X of P ( y A ) = 1 generate A proof of that this process generates y A and y H with correlation  X  is given in Appendix.
We are now ready to supply the remaining details of the experiment. For each value of instances from the corresponding class randomly. At each value of  X  ,wetrainMIML-ECC or SIM-RF on the 100-bag training set and then classify all instances in the 100-bag test set. The parameters for MIML-ECC are L = 10 , K = 10 , T = 10, and the parameters for SIM-RF are T = 100 , K = 100; hence, both algorithms generate the same total number of trees. Because this is a random experiment, we use 1,000 repetitions at each value of  X  to compute statistics about the results. These experiments are conducted in the inductive mode only.

One issue that can occur with the setup described above is that a bag may be generated with an empty label set, and consequently, it will have no instances. Such bags are not valid input for MIML-ECC or SIM-RF. We handle this issue with two different variants of the experiment. One approach is to discard any bag that is generated with an empty label set. This approach has the consequence that the sample correlation coefficient  X   X  between y A and y discarded, estimated by sampling 1,000,000 label sets at each value of  X  . Rejecting empty that  X   X   X  0. Furthermore, discarding empty label sets means that y X is not conditionally independent of ( y A , y H ) . For example, knowing y A = 0and y H = 0 implies y X = 1. This kind of relationship is not captured by pairwise correlation.

The second approach we use to address this issue is to inject  X  X oise X  instances into each bag, which come from an unknown class that is not accounted for by the label set. Such noise instances realistically occur in machine vision and audio datasets, because automatic randomly generated bag, we add 5 noise instances from the UCI Letter Recognition class W (there is 0 confusion between W and A, H, and X in in both directions). This approach y X is completely independent of y A and y H .

We evaluate the predictions in these experiments based on three measures as functions of  X  : accuracy over all classes, precision on H and recall on H. Precision and recall are only considered for class H because it plays a central role in this experiment, as it is correlated with A and easily confused with X. In the second variant of the experiment, noise instances are skipped for the purposes of computing these statistics, because it is not possible for the follows: where y is the true label for an instance and  X  y is the predicted label.

Controlled correlation results Figure 5 a X  X  show the results of the correlation experiments without and with noise, respectively. We highlight several conclusions based on these results.
First, MIML-ECC generally achieves better accuracy on all classes and better precision using the same total number of decision trees. Toward the extremes of  X  = X  1or  X  =+ 1, MIML-ECC still outperforms SIM-RF, even at  X  = 0or  X   X  = 0. This result may be explained by MIML-ECC producing a more diverse ensemble, e.g., because there is more variety in the support instances it selects for training. In the case where there is no noise and empty label sets are rejected, knowing any two bits of the label set provides information about the third, hence even if the pairwise correlation is 0, there is still some higher order correlation that MIML-ECC can exploit. In the case where there is noise and empty label sets are allowed, MIML-ECC may still have an advantage when  X  = 0 because knowing that one class is present implies not all instances can belong to the other classes. For example, if the chain between MIML-ECC and SIM-RF is more pronounced in the experiment with noise, which suggests that MIML-ECC is more robust to noise.

As  X  approaches 1, both classifiers have lower performance according to all three per-formance measures. The explanation for this result is simple: when  X  = 1, there are no unambiguous examples of A or H, because they always occur together, or not at all. Hence, there is a fundamental limit to the accuracy any classifier can achieve in this case. How-ever, there is a slight positive trend in the recall for MIML-ECC in Fig. 5 f, which suggests that MIML-ECC is gaining some benefit from positive correlation, although this effect is overpowered by the lack of unambiguous training examples.
 As  X  approaches  X 1, the accuracy and recall for MIML-ECC increase, whereas SIM-RF remains comparatively flat across the range of values for  X  . One effect that occurs as  X  approaches  X 1 is that there are more unambiguous examples of A and H, although there are no unambiguous examples of X (because either A or H is always present). However, the widen-ing gap between MIML-ECC and SIM-RF as  X  approaches  X 1 indicates that the improved performance of MIML-ECC cannot be attributed entirely to training with fewer unambiguous examples, and is instead caused by MIML-ECC exploiting negative label correlation. Another trend in the results is visible in Figs. 5 d, e: The accuracy and precision for SIM-RF slope slightly downward as  X  go from 1 to  X 1. In particular, as  X  approaches  X  1, there is a clear dip in both overall accuracy, and the precision on class H. This can be explained by the fact that as  X  decreases and approaches  X  1, it becomes less likely to see a training bag that contains only X. Note that when  X  = X  1, X never appears alone in a bag. Since X is already easily confused with H, this makes it progressively more difficult to correctly classify X, decreasing the overall accuracy as well as the precision on H.

In conclusion, we see that MIML-ECC benefits more from correlation than SIM-RF, these effects are intertwined with varying levels of ambiguity. 6 Related work Graphical models for MIML sometimes include instance labels as hidden variables. Inference over these hidden variables can be used for instance annotation. In addition to LSB-CMM, some recent examples of graphical models for MIML include Dirichlet X  X ernoulli alignment [ 33 ] and exponential multinomial mixture model [ 32 ]. Zha et al. [ 36 ] proposed MLMIL, a conditional random field for MIML which uses Gibbs sampling to infer instance labels.
Vijayanarasimhan and Grauman [ 28 ] developed a MIML SVM algorithm that uses a bag-level kernel. Their algorithm predicts instance labels by applying the bag-level classi-fier to a bag of one instance. Vezhnevets et al. [ 27 ] proposed a MIML instance annotation algorithm that alternates between sampling random instance labels and training a Semantic Texton Forest (a specialization of RF to images). Nguyen [ 22 ] proposed a MIML algorithm that alternates between assigning instance labels and training a maximum margin classifier. Li et al. [ 17 ] considers the problem of selecting a set of instances explaining each label, which is different from instance annotation, where the goal is to label all instances.
Several formulations besides the max model have been used for MIL and MIML to relate instance and bag labels. Different formulations encode different assumptions about instance labels. One version of the diverse density algorithm for MIL [ 21 ] used a Noisy-OR model P ( y = 1 | B , X ) = 1  X  x makes fewer independence assumptions than the Noisy-OR model, although both generate similar probabilities in many cases. In the later work, the EM-DD [ 38 ] algorithm replaced Noisy-OR with max. Ray and Craven [ 24 ] proposed multiple-instance logistic regression, which uses a smooth softmax approximation to max. Briggs et al. [ 3 , 4 ] used a multi-class softmax model. Xu and Frank [ 30 ] propose a model where the bag label probability is the average of the instance-label probabilities.

Prior work on context-aware learning considered multi-instance learning problems where within a bag, which is then used to help make more accurate bag-level predictions. This line of work differs from ours in two ways. First, they are primarily interested in improving bag-level predictions by considering the structure within bags. In contrast, we are interested in instance-level predictions. Second, these approaches model context as relationship among instances, whereas our work focuses on context provided by the bag label set. One possible direction for future work is to investigate how both types of context can be used to help with instance annotation. 7 Conclusion and future work We proposed MIML-ECC, an algorithm for context-aware MIML instance annotation. Exper-iments on image, audio, and artificial datasets show that MIML-ECC achieves better accuracy than other recent algorithms. MIML-ECC is asymptotically efficient and does not require parameter tuning. Further experiments provide runtime results and suggest that the improved accuracy cannot be attributed only to switching from an SVM-style base classifier to a RF, that ensemble is beneficial, and that MIML-ECC X  X  improved accuracy is related to exploiting correlation in the bag label sets.

MIML-ECC exploits context through correlations, which can be summarized by state-ments like  X  X f A is present, B is also likely to be present. X  However, MIML-ECC cannot exploit a different kind of context, which can be summarized as  X  X f one A is present, there are likely to be more A X  X . X  For example, consider Fig. 1 b. It might be easy to recognize some of the larger cows in the image, but harder to recognize the small ones. However, after recognizing one cow, we might expect to find more cows. MIML-ECC will not exploit this kind of context because it can only use information about the presence or absence of other classes to inform its prediction. A useful direction for future work is to develop algorithms for MIML instance annotation that can exploit both bag-level label correlations, and relation-in MLC using a collective classification/relational learning approach [ 14 ].

We made several assumptions in formulating MIML-ECC; it is interesting to explore related models with different assumptions. For example, we assumed that each instance has exactly one label. However, there are cases where instances have none of the labels in the set of known classes (e.g., clutter in an image) and also where an instance should have multiple labels.
 Appendix The correlation coefficient  X ( X , Y ) between two random variables X and Y is given by Let X be a Bernoulli RV with P ( X = 1 ) = 1 2 . Similarly, let Y conditioned on X be a The correlation coefficient  X ( X , Y ) =  X  .
 Proof we begin by noting the property that the expected value of an arbitrary Bernoulli RV T for k = 1 , 2 ,... and consequently E [ T k ]= p . The variance of T isgivenbyVar ( T ) = E [ E [ X ]= P ( X = 1 ) = 1 2 . The expectation of Y is computed as follows Since X and Y are Bernoulli RVs with P ( X = 1 ) = P ( Y = 1 ) = E [ X ]= E [ Y ]= 1 2 ,we also have Var ( X ) = Va r ( Y ) = 1 2 ( 1  X  1 2 ) = 1 4 . Next, we compute References Author Biographies
