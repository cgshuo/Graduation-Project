 In many Indo-European languages, such as French, German, or Hindi, there are two pronouns corre-sponding to the English you . This distinction is generally referred to as the T/V dichotomy, from the Latin pronouns tu (informal, T) and vos (formal, V) (Brown and Gilman, 1960). The V form can express neutrality or polite distance and is used to address socially superiors. The T form is employed for friends or addressees of lower social standing, and implies solidarity or lack of formality. Some examples for V pronouns in different languages are Sie (German), Vous (French), and aAp [ Aap ] (Hindi). The corresponding T pronouns are du , tu , and t m [ tum ].

English used to have a T/V distinction until the 18th century, using you as V and thou as T pronoun. However, in contemporary English, you has taken over both uses, and the T/V distinction is not marked morphosyntactically any more. This makes gener-ation in English and translation into English easy. Conversely, the extraction of social information from texts, and translation from English into languages with a T/V distinction is very difficult.

In this paper, we investigate the possibility to re-cover the T/V distinction based on monolingual En-glish text. We first demonstrate that annotators can assign T/V labels to English utterances fairly well (but not perfectly). To identify features that indicate T and V, we create a parallel English X  X erman corpus of literary texts and preliminarily identify features that correlate with formal address (like titles, and formulaic language) as well as informal address. Our results could be useful, for example, for MT from English into languages that distinguish T and V, al-though we did not test this prediction with the limits of a short paper.

From a Natural Language Processing point of view, the recovery of T/V information is an instance of a more general issue in cross-lingual NLP and ma-chine translation where for almost every language pair, there are distinctions that are not expressed overtly in the source language, but are in the target language, and must therefore be recovered in some way. Other examples from the literature include morphology (Fraser, 2009) and tense (Schiehlen, 1998). The particular problem of T/V address has been considered in the context of translation into Japanese (Hobbs and Kameyama, 1990; Kanayama, 2003) and generation (Bateman, 1988), but only on the context of knowledge-rich methods. As for data-driven studies, we are only aware of Li and Yarowsky X  X  (2008) work, who learn pairs of formal and informal constructions in Chinese where T/V is expressed mainly in construction choice.
Naturally, there is a large body of work on T/V in (socio-)linguistics and translation science, cover-ing in particular the conditions governing T/V use in different languages (Kretzenbacher et al., 2006; Sch X pbach et al., 2006) and on the difficulties in translating them (Ardila, 2003; K X nzli, 2010). How-ever, these studies are generally not computational in nature, and most of their observations and predictions are difficult to operationalize. 2.1 Data Selection We chose literary texts to build a parallel corpus for the investigation of the T/V distinction. The main reason is that commonly used non-literary collections like EUROPARL (Koehn, 2005) consist almost ex-clusively of formal interactions and are therefore of no use to us. Fortunately, many 18th and 19th century texts are freely available in several languages.
We identified 115 novels among the texts pro-vided by Project Gutenberg (English) and Project Gutenberg-DE (German) that were available in both languages, with a total of 0.5M sentences per lan-guage. 1 Examples include Dickens X  David Copper-field or Tolstoy X  X  Anna Karenina . We decided to exclude plays and poems as they often include partial sentences and structures that are difficult to align. 2.2 Data Preparation As the German and English novels come from two different websites, they were not coherent in their structure. They were first manually cleaned by delet-ing the index, prologue, epilogue and Gutenberg li-cense from the beginning and end of the files. To some extent the chapter numbers and titles occurring at the beginning of each chapter were cleared as well. The files were then formatted to contain one sentence per line and a blank line was inserted to preserve the segmentation information.
 The sentence splitter and tokenizer provided with EUROPARL (Koehn, 2005) were used. We ob-tained a comparable corpus of English and German novels using the above pre-processing. The files in the corpus were sentence-aligned using Gargan-tuan (Braune and Fraser, 2010), an aligner that sup-ports one-to-many alignments. After obtaining the sentence aligned corpus we computed word align-ments in both English to German and German to En-glish directions using Giza++ (Och and Ney, 2003). The corpus was lemmatized and POS-tagged using TreeTagger (Schmid, 1994). We did not apply a full parser to keep processing as efficient as possible. 2.3 T/V Gold Labels for English Utterances The goal of creating our corpus is to enable the in-vestigation of contextual correlates of T/V in English. In order to do this, we need to decide for as many English utterances in our corpus as possible whether they instantiate formal or informal address. Given that we have a parallel corpus where the German side overtly realizes T and V, this is a classical case of annotation projection (Yarowsky and Ngai, 2001): We transfer the German T/V information onto the English side to create an annotated English corpus. This allows us to train and evaluate a monolingual English classifier for this phenomenon. However, two problems arise on the way: Identification of T/V in German pronouns. Ger-man has three relevant personal pronouns: du , sie , and ihr . These pronouns indicate T and V, but due to their ambiguity, it is impossible to simply interpret their presence or absense as T or V. We developed four simple disambiguation rules based on position on the sentence and capitalization, shown in Table 1.
The only unambiguous pronoun is du , which ex-presses (singular) T (Rule 1). The V pronoun for singular, sie , doubles as the pronoun for third person (singular and plural), which is neutral with respect to T/V. Since TreeTagger does not provide person information, the only indicator that is available is capitalization: Sie is 2nd person V. However, since all words are capitalized in utterance-initial positions, we only assign the label V in non-initial positions (Rule 2). 2
Finally, ihr is also ambiguous: non-capitalized, it is used as T plural (Rule 3); capitalized, it is used as an archaic alternative to Sie for V plural (Rule 4).
These rules leave a substantial number of instances of German second person pronouns unlabeled; we cover somewhat more than half of all pronouns. In absolute numbers, from 0.5M German sentences we obtained about 15% labeled sentences (45K for V and 30K for T). However, this is not a fundamental problem, since we subsequently used the English data to train a classifier that is able to process any English sentence.
 Choice of English units to label. On the German side, we assign the T/V labels to pronouns, and the most straightforward way of setting up annotation projection would be to label their word-aligned En-glish pronouns as T/V. However, pronouns are not necessarily translated into pronouns; additionally, we found word alignment accuracy for pronouns, as a function of word class, to be far from perfect. For these reasons, we decided to treat complete sentences as either T or V. This means that sentence alignment is sufficient for projection, but English sentences can receive conflicting labels, if a German sentence con-tains both a T and a V label. However, this occurs very rarely: of the 76K German sentences with T or V pronouns, only 515, or less than 1%, contain both. Our projection on the English side results in 53K V and 35K T sentences, of which 731 are labeled as both T and V. 3 Finally, from the English labeled sentences we ex-tracted a training set with 72 novels (63K sentences) and a test set with 21 novels (15K sentences). 4 The purpose of our first experiment is to investigate how well the T/V distinction can be made in English by human raters, and on the basis of what information. We extracted 100 random sentences from the training set. Two annotators with advanced knowledge of No context 63 65 68 In context 70 69 81 English were asked to label these sentences as T or V. In a first round, the sentences were presented in isola-tion. In a second round, the sentences were presented with three sentences pre-context and three sentences post-context. The results in Table 2 show that it is fairly difficult to annotate the T/V distinction on indi-vidual sentences since it is not expressed systemati-cally. At the level of small discourses, the distinction can be made much more confidently: In context, av-erage agreement with the gold standard rises from 64% to 70%, and raw inter-annotator agreement goes up from 68% to 81%.

Concerning the interpretation of these findings, we note that the two taggers were both native speakers of languages which make an overt T/V distinction. Thus, our present findings cannot be construed as firm evidence that English speakers make a distinc-tion, even if implicitly. However, they demonstrate at least that native speakers of such languages can recover the distinction based solely on the clues in English text.

An analysis of the annotation errors showed that many individual sentences can be uttered in both T and V situations, making it impossible to label them in isolation: (1)  X  X nd perhaps sometime you may see her. X  This case (gold label: V) is however disambiguated by looking at the previous sentence, which indicates the social relation between speaker and addressee: (2)  X  X nd she is a sort of relation of your lord-Still, a three-sentence window is often not sufficient, since the surrounding sentences may be just as unin-formative. In these cases, global information about the situation would be necessary.

A second problem is the age of the texts. They are often difficult to label because they talk about social situations that are unfamiliar to modern speakers (as between aristocratic friends) or where the usage has changed (as in married couples). Task Setup. In this pilot modeling experiment, we explore a (limited) set of cues which can be used to predict the V vs. T dichotomy for English sentences. Specifically, we use local words (i.e. information present within the current sentence  X  similar to the information available to the human annotators in the  X  X o context X  condition of Experiment 1). We ap-proach the task by supervised classification, applying a model acquired from the training set on the test set. Note, however, that the labeled training data are acquired automatically through the parallel corpus, without the need for human annotation.
 Statistical Model. We train a Naive Bayes classi-fier, a simple but effective model for text categoriza-tion (Domingos and Pazzani, 1997). It predicts the class c for a sentence s by maximising the product of the probabilities for the features f given the class, multiplied by the class probability: We experiment with three sets of features. The first set consists of words, following the intuition that some words should be correlated with formal ad-dress (like titles), while others should indicate infor-mal address (like first names). The second set con-sists of part of speech bigrams, to explore whether this more coarse-grained, but at the same time less sparse, information can support the T/V decision. The third set consists of one feature that represents a semantic class, namely a set of 25 archaic verbs and pronouns (like hadst or thyself ), which we expect to correlate with old-fashioned T use. All features are computed by MLE with add-one smoothing as Results. Accuracies are shown in Table 3. A ran-dom baseline is at 50%, and the majority class (V) corresponds to 60%. The Naive Bayes models signif-icantly outperform the frequency baselines at up to 67.0%; however, only the difference between the best (Words+Archaic) and the worst (Words+POS) model is significant according to a  X  2 test. Thus, POS fea-tures tend to hurt, and the archaic feature helps, even though it technically overcounts evidence. 5
The Naive Bayes model notably performs at a roughly human level, better than human annotators on the same setup (no context sentences), but worse than humans that have more context at their disposal. Overall, however, the T/V distinction appears to be a fairly difficult one. An important part of the problem is the absence of strong indicators in many sentences, in particular short ones (cf. Example 1). In contrast to most text categorization tasks, there is no topi-cal difference between the two categories: T and V can both co-occur with words from practically any domain.
 Table 4, which lists the top ten words for T and V (ranked by the ratio of probabilities for the two classes), shows that among these indicators, many are furthermore names of persons from particular novels which are systematically addressed formally (like Phileas Fogg from Jules Vernes X  In eighty days around the world ) or informally (like Mowgli, Baloo, and Bagheera from Rudyard Kipling X  X  Jungle Book ).
Nevertheless, some features point towards more general patterns. In particular, we observe ti-tles among the V-indicators ( gentlemen , madam , ma+ X  X m ) as well as formulaic language ( Permit (me) ). Indicators for T seem to be much more general, with the expected exception of archaic thou forms. In this paper, we have reported on an ongoing study of the formal/informal (T/V) address distinction in modern English, where it is not determined through pronoun choice or other overt means. We see this task as an instance of the general problem of recovering  X  X idden X  information that is not expressed overtly.
We have created a parallel German-English cor-pus and have used the information provided by the German pronouns to induce T/V labels for English sentences. In a manual annotation study for English, annotators find the form of address very difficult to determine for individual sentences, but can draw this information from broader English discourse context. Since our annotators are not native speakers of En-glish, but of languages that make the T/V distinction, we can conclude that English provides lexical cues that can be interpreted as to the form of address, but cannot speak to the question whether English speak-ers in fact have a concept of this distinction.
In a first statistical analysis, we found that lexical cues from the sentence can be used to predict the form of address automatically, although not yet on a very satisfactory level.

Our analyses suggest a number of directions for future research. On the technical level, we would like to apply a sequence model to account for the depen-decies among sentences, and obtain more meaningful features for formal and informal address. In order to remove idiosyncratic features like names, we will only consider features that occur in several novels; furthermore, we will group words using distributional clustering methods (Clark, 2003) and predict T/V based on cluster probabilities.

The conceptually most promising direction, how-ever, is the induction of social networks in such nov-els (Elson et al., 2010): Information on the social re-lationship between a speaker and an addressee should provide global constraints on all instances of com-munications between them, and predict the form of address much more reliably than word features can. Manaal Faruqui has been partially supported by a Microsoft Research India Travel Grant.

