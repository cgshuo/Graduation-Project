 1. Introduction parently integrating such diverse data sources, underlying differences in database management systems (DBMSs), languages, and data models can be hidden and users can use a single data model and a single high-level query language to access the unified data through a global schema.

For example, many large insurance companies require access to distributed and often heterogeneous dat-abases for BI applications. By integrating distributed databases, these companies can enhance the insurance play performance information for management; and improve the database-intensive clearance process during which databases from multiple branches need to be searched. As a matter of fact, data warehouses and BI applications are the top two priorities for insurance CIO/CTOs in 2006 based on Celent report on December 14, 2005. 1
To support federation of such distributed databases, IBM has developed the WebSphere Information Inte-grator (WebSphere II) [1] which provides relational access to both relational DBMSs and nonrelational sources such as file systems and Web services. The remote data sources are registered within WebSphere II as nicknames and thereafter can be accessed via wrappers. Statistics about the remote data sources are col-lected and maintained in WebSphere II for later use by the query optimizer for estimating the cost of query backend servers. In principle, there is no limit on the number of backend servers.

BI applications involve data-intensive processes that usually require great computation power to aggregate a huge amount of data. A materialized view or Materialized Query Table (MQT) is an auxiliary table with precomputed data that can be used to significantly improve the performance of a database query. An
MQT Advisor (MQTA) is often used to recommend and create MQTs to reduce the query processing cost by replacing parts of queries appropriately with existing and matched MQTs. State-of-the-art MQT advisors in existence in commercial DBMSs including the IBM DB2 Design Advisor [2 X 4] , are used to recommend MQTs for a stand-alone database (e.g., Fig. 1 b). This configuration has two prominent limitations. First, to a federated system scenario in which MQTs need to be placed on one or more servers other than the server relation of access to the database servers is not exploited.
 To overcome the first limitation, Li et al. [5] proposed a Data Placement Advisor (DPA) for recommending
MQTs for distributed databases. DPA recommends and places MQTs on the federation server to improve the performance of complex federated queries to access multiple backend databases for BI applications. Fig. 1 c shows the configuration of such a DPA. 1.1. Motivations and proposed solution In this paper, we expand our work on data placement (from [5] ) and study the problem of recommending
MQTs for the backend servers by considering correlation between backend servers. We name our approach the Federated MQT Advisor (FMQTA), as shown in Fig. 1 d. Our motivation of recommending MQTs at load. Usually, only a subset of the queries utilize MQTs. Moreover, only a subset of the MQT candidates are data at the backend servers. FMQTA can further improve the performance of these federated queries. For example, assume frontend MQTs can improve the performance of the federated workload by 50%. FMQTA can recommend backend MQTs that can further improve the performance of the workload by 50%. Then the total improvement is 75%. On the other hand, as an alternative approach, caching MQTs at the backend serv-ers can improve the performance of the federated queries even when frontend MQTs are not present.
Besides the performance factors, other factors also come into play in deciding which system configuration in Fig. 1 cand Fig. 1 d is more preferable over the other, such as for the creation and refresh of the MQTs. Because creating and refreshing MQTs are expensive tasks, this approach is suitable only when the federation server is substantially more powerful than the backend serv-ers and the frontend server is not used as a production system when the data aggregation is performed; otherwise, if the frontend server is a production system and already has a heavy workload (such as resource-thirty data aggregation tasks), Fig. 1 d is a more viable option.

Data refreshment requirement .In Fig. 1 c, since the MQTs and the base tables used to derive the MQTs are in different servers, MQTs can only be refreshed periodically instead of being refreshed in real time. As a Fig. 1 d should be used.

Recommending MQTs at multiple backend servers raises some unique technical challenges that do not appear in recommending frontend MQTs:
Placing MQTs on multiple backend databases calls for intelligent coordination between these backend serv-ers. If we place MQTs for each backend server separately (like Fig. 1 b), these MQTs might not help fed-erated queries that access MQTs from multiple backend servers X  X ence, compromising the performance of BI applications.

Scalability becomes more an issue when we recommend MQTs for multiple backend servers. If we do not small number of backend servers.

Our algorithm recommends MQTs for all the backend servers in a coordinated way by using the correlation information about the MQTs (e.g., whether MQTs are used by the same federated query) so that we can max-imize the synergy among the recommended MQTs on different backend servers. We use the two federated que-ries in Fig. 2 as examples to show how.

In Fig. 2 a, the federated query q 1 needs to access data in three backend servers (BE ing subqueries to the corresponding backend servers, respectively. The vertical distance between q backend servers indicates the time to execute subqueries on each backend servers (Note that, subqueries may contain expensive join or aggregate operations from BI applications). In this example, the access time is t for each backend server. To reduce the total time for the federated query, we may use MQTA to recom-mend MQTs on backend servers, by materializing the results of subqueries.

For the example in Fig. 2 a, since all the subqueries have the same execution time, recommending MQTs for stand-alone MQTA may provide such partial and useless recommendation. In contrast, our federated MQTA takes into consideration the correlation and recommends MQTs either for all of the three backend servers or for none of them.

Fig. 2 b shows a general example in which the query times for the backend servers are different. For this case, we may recommend MQTs only for BE 3 to speed up to D t for BE 3 and BE 2 to same more overall time (up to an additional D t is still important to consider correlation among the subqueries. A stand-alone MQTA may mistakenly recom-mend MQTs for BE 1 or BE 2 but not for BE 3 , resulting in wasted MQT space. The federated MQTA we con-sider can gracefully handle such general cases too.

To avoid the exponential solution, we exploit the parallelism property in multi-backend systems to reduce the complexity of our algorithm. The experiment results show that our approaches are not only effective in
MQT recommendation but also scalable and efficient to run. 1.2. Paper organization
The rest of the paper is organized as follows. In Section 2 , we give some background knowledge on MQT placement and formally define the problem we study in the paper. Section 3 provides an overview of our pro-posed MQT-recommendation solution. We then describe, in Section 4 , how to exploit the parallelism property loads of various characteristics. We summarize related work and compare them with our approach in Section 6 . Finally, the concluding remarks are presented in Section 7 . 2. Problem statement
In this section, we give a formal definition of the problem that we are trying to solve. We start with the description of the system topology we assume (Section 2.1 ) and then state the problem within the context of the assumed system topology (Section 2.2 ). 2.1. Topology of distributed systems
We assume a system topology where a thin frontend server (such as one running WebSphere II) is sup-the frontend server does not cache any base-table data from the backend servers. Nicknames for the tables server may contain not only the base tables that contain operational data, but also MQTs to speed up the processing of queries routed from the frontend server.

Users can query the backend servers through the frontend server. A user query might be a federated query server executes a federated query (see, Fig. 3 ):
S1 The frontend server parses the federated query into query fragments (or subqueries) such that each query
S2 Query fragments are sent to their corresponding backend servers and the partial results are returned to S3 The frontend server integrates the partial results to generate the final answer to the federated query.
We can divide the total resource time for running a federated query into three components corresponding because, even for the same federated query, this time could be different as we place different MQTs on the erence, we define the following function t : frontend server to complete the step S2 for all the backend servers. Let q result depends on the MQT placement on backend servers. The function t can additionally take a set of MQTs are placed at corresponding backend servers.

The system topology and the execution model in Fig. 3 assume that a query fragment submitted to a back-some query fragments are dependent on other query fragments, where the partial result from one backend is the input of another backend. However, Our observation on TPC-H workload shows that only fewer than a quarter (5 out of 22) of queries have dependent subqueries. We believe the assumption of independent subqu-ing problem but is out of the scope of this paper. 2.2. The problem to be solved
Given a workload with K federated queries and space limit for each backend server for storing MQTs, we want to recommend MQTs for each backend server such that the total resource time for running the workload the frontend server are independent of the MQT placement at backend servers. So the goal of our algorithms is to minimize the total of t  X  q i  X  , for 1 6 i 6 K .
 2.3. Solution overview
We present our algorithm in Section 3 and Section 4 . Specifically, we describe a federated MQTA in Section 3 such that the correlation among the multiple backend servers is taken into consideration when it recom-mends MQTs for these backend servers. In Section 4 , we exploit the parallelism property of a multi-backend system and improve running complexity of the federated MQTA from exponential to linear in terms of the number of backend servers involved. We given an overview of our solution in the following.
A hill-climbing algorithm (adaptation of [5] ) is used in our approach for recommending MQTs. In each step of iteration, we pick an MQT or a group of MQTs that can provide the most return (i.e., the reduction in query time) on investment (the required disk space to store these MQTs) to the federated workload. To avoid overlooking the correlation between backend servers, we also consider groups of MQTs that come from multi-considers any subset of the set of MQTs from all the backend servers and used by the federated queries. We call such a subset an MQT group. For the query in Fig. 2 a, the MQT group from each individual backend ations are materialized in these MQTs. Therefore, the group of MQTs from all the backend servers should be recommended in this case. For Fig.2 b, the group of MQTs from BE
MQTs from BE 2 and BE 3 or from all the three backend servers. We use their return-on-investment values to decide which one to pick.

The aforementioned algorithm investigates any subset of the MQTs from all the backend servers to avoid losing the correlation between MQT usage. However the number of MQT groups is exponential in terms of the number of backend servers. Assume there are five backend servers and a federated query accesses one MQT from each backend server, then the total number of MQT groups to be considered is 2 allelism property and reduce the number of candidate MQT groups to be linear to the number of backend covery of dominance relationship allows us to favor the MQTs for the dominant subqueries over the MQTs for the dominated subqueries, and at the same time, reduce the number of candidate MQT groups to be inves-tigated during each step. 3. FMQTA: federated MQT advisor
In this section, we describe the Federated MQT Advisor (FMQTA). The main feature of the FMQTA is that it considers the usage correlation among the backend servers so that the MQTs recommended for the backend servers provide the maximum overall benefits for the federated queries.

We can easily craft a brute force algorithm (that is theoretically optimal) for the MQT recommendation by (1) inspecting the benefits of all the subsets of the set of candidate MQTs and (2) recommending the subset subsets is exponential to the number of candidate MQTs.

FMQTA adopts a greedy hill-climbing algorithm that picks the best candidate MQTs for recommendation efficient algorithms by addressing these key factors. 3.1. System architecture The system architecture of the FMQTA is shown in Fig. 4 . There are mainly three steps involved in FMQTA.

Given a workload containing federated queries, the FMQTA compiles these queries. The compiler returns the lists of query fragments to be sent to the corresponding backend servers. FMQTA then invokes the MQTA [3] on each backend server with the corresponding list of query fragments. The MQTA recommends a list of candidate MQTs along with useful information about MQTs including the estimated size and the synchroni-zation cost of each MQT. FMQTA can derive from the output the MQT dependency information such as how multiple MQTs are used together within a federated query. Finally, FMQTA performs a greedy what X  X f anal-ysis to determine which MQTs to be placed at the backend servers. The what X  X f process is described in the following text. 3.2. What X  X f analysis for MQT recommendation 3.2.1. Two concepts: VCU and ROI There are two important concepts for the what X  X f analysis: VCU and ROI.
 Definition 2 ( VCU: virtual caching unit ). A VCU is either a singleton candidate MQT or a set of candidate MQTs that are used together by a federated query.

A VCU is the primitive unit of consideration during the what X  X f analysis. The VCUs from each federated of the set of candidate MQTs.
 benefit additional overhead) for the workload when the MQTs in the VCU are placed on top of the already-placed MQTs. The investment is the total size of the MQTs in the VCU and their indexes, excluding the already-placed MQTs. The ROI of the VCU is the calculated net benefit divided by the calculated size.
The ROI is a priority value for each VCU. A VCU with the highest ROI value is chosen over those with lower ROI values.

The benefit is measured as the resource time with respect to the frontend server. For the VCU f MQT 1 ; MQT 3 g in Fig. 5 , its initial benefit for q 1
VCU for q 2 is t 2  X  t  X  q 2 ; ; X  t  X  q 2 ; f MQT 1 ; MQT mated time t  X  q 2 ; f MQT 1 ; MQT 3 g X  is equal to t  X  q of t 1 and t 2 .

The overhead of a VCU is the summation of the overhead values of the MQTs in the VCU, excluding already-placed MQTs. It includes factors such as the cost of refreshing an MQT and the cost of rebuilding indexes if present. 3.2.2. The what X  X f analysis
The what X  X f analysis for our FMQTA is a five-step process: 1. Create a ranked list for VCUs sorted by ROI values in descending order. 2. Remove all the leading VCUs whose MQTs do not fit in the backend servers due to space constraints. 3. Remove the head VCU from the ranked list and add the MQTs in it into the recommendation list, M . 4. Recalculate ROIs for all the remaining VCUs in the ranked list by considering possible impact of the selected MQTs to the candidate VCUs due to dependency on benefit, space and overhead (described later). 5. Go to step 1 until no VCU can be selected either because the space limit is reached or no VCU is available.

We emphasize that, after some MQTs are selected into the recommendation list M , the ROIs of the can-didate VCUs are the additional ROIs on top of M . For example, given a VCU v and the current recommen-dation list M , the benefit of v for a federated query q is t  X  q ; v size of v should not include those MQTs that are already in M . 3.2.3. Complexity analysis
The algorithmic complexity of the FMQTA and the number of calls to the cost estimator (through the func-VCUs considered. The following is a breakdown of the complexity:
Initializing ROI values of candidate VCUs. For each VCU v benefit (i.e., saving in time) to run each federated query q O  X j V jj W j X  .

Picking the VCU with the maximum ROI. The algorithmic complexity is O  X j V j X  . There are no calls to the cost estimator.

Updating ROI values of the rest of VCUs. Both the algorithmic complexity and the number of calls to the cost estimator are O  X j V jj W j X  .

All VCUs could be selected one after another through the what X  X f process. Therefore there could be j V j iterations in the whole what X  X f process. As a result, the algorithmic complexity and the number of calls to the cost estimator are both O  X j W jj V j 2  X  in the worst case. 3.3. Discussions
The FMQTA should work fairly well for a workload of queries that access a moderate number of backend servers. However, when the number of backend servers is large and each federated query requires data from many backend servers, the what X  X f analysis does not scale well because the number of candidate VCUs from each federated query is exponential to the number of MQTs used by the query.

Our solution to the scalability problem is to reduce the number of candidate VCUs in the what X  X f pro-solution. 4. Exploiting the parallelism property number of candidate VCUs. For clarification, we call the FMQTA in Section 3 the basic-FMQTA, and the
FMQTA to be presented in this section the full-FMQTA. 4.1. Overview of our ideas t  X  q results (i.e., t  X  q  X  ) is equal to max  X  t  X  q  X  1  X  ; t  X  q
The intuition behind Definition 4 is simple. Since the backend servers run their corresponding query frag-server.
 The following Example 1 uses Fig. 6 to illustrate how we can use the parallelism property to spot spurious front of the MQT passed to the t function. It means all candidate MQTs except for the one following : . For
Since q  X  1 only uses one MQT MQT 1 , t  X  q  X  1 ; :f MQT 1 running the three query fragments ( q  X  1 , q  X  2 and q  X  3 respectively. Based on these estimates, we can conclude that some VCUs need not be considered. For example, the VCU f MQT 2 g is useless by itself because, although MQT frontend server 35 time units to collect the result of q  X  1 know that only three VCUs need to be considered: f MQT 1 g ; f MQT
The parallelism property can be utilized to reduce the number of VCUs significantly (from exponential to linear). We proceed to explain how to find candidate VCUs by considering the parallelism property. 4.2. Applying parallelism property with restriction
Here, we study the application of the parallelism property under the one-MQT assumption : given a feder-relaxed in Section 4.3 .

For ease of exposition, we assume that each federated query in consideration needs to access all the back-end servers (i.e., there is one query fragment for each backend server). All the discussions under such an assumption can be easily applied to the cases where a federated query only accesses some of the backend servers.
 4.2.1. Finding candidate VCUs
Example 1 has demonstrated that a subset (such as f MQT 2 query does not help reduce the resource time of running a federated query if a dominating MQT (i.e., MQT 1 ) is not present. We formally define the dominance relationship between MQTs as follows:
Definition 5 ( Dominance relationship between MQTs ). Consider a federated query q against N backend servers. By convention, the query fragment to backend server i  X  1 6 i 6 N  X  is q
We say MQT  X  x dominates MQT  X  y if t  X  q  X  x ; :f MQT  X  x
Given that t  X  q  X  i ; f MQT  X  i g X  6 t  X  q  X  i ; :f MQT  X  i dominated MQT appears in some VCU v , the VCU must also contain the dominating MQT for it to have positive ROI value. This observation is the key to our algorithm for finding nontrivial VCUs: (1) we sort the MQTs used by a federated query according to their dominance relationship (each MQT in the sorted list is dominated by all the preceding MQTs in the list); and (2) for each MQT MQT candidate VCU that contains MQT i and its dominating MQTs (i.e., all the MQTs preceding MQT sorted list is called a dominance path .

Recall Example 1 . The sorted list of the MQTs should be in the order of MQT the three candidate VCUs are exactly f MQT 1 g , f MQT 1 ; MQT 4.2.2. Complexity analysis
The algorithmic complexity remains the same X  X hat is, O  X j W jj V j ear to the number of MQTs accessed by the federated query. So is the number of calls to the cost estimator. 4.3. Relaxing the one-MQT assumption
In reality, multiple MQTs can be used by each query fragment. As an example, Fig. 7 shows a federated query q such that its query fragment q  X  3 uses two MQTs on BE We could lose good candidate VCUs if we use the approach from Section 4.2 for finding candidate VCUs. For example, given the first four function-t values in Fig. 7 , we will have the dominance path
According to this dominance path, we can only find four candidate VCUs, not including f MQT not difficult to find that f MQT 3 ; MQT 4 g is a valid candidate VCU because we can speed up the federated query (from 50 to 35) just by using it. Note that although MQT f MQT 3 ; MQT 4 g as a candidate MQT for evaluation since the ROI of a MQT could change over time after some MQTs are selected for placement.

Dominance relationship does not exist for MQTs on the same backend server. Instead, MQTs used by the same query fragment can add up together to dominate MQTs on other backend servers, although each individ-ual MQT might not do so. For example, the fifth t value in Fig. 7 shows that when MQT bined, they dominate MQT 1 and MQT 2 although MQT 3 itself does not dominate either of them.
Our solution is to consider all the nonempty subsets of MQTs used by each query fragment. In Fig. 7 , since the query fragment q  X  3 uses both MQT 3 and MQT 4 , we have three (i.e., 2 f MQT 3 g , f MQT 4 g and f MQT 3 ; MQT 4 g . Together with f MQT dominance relationship does not hold for MQTs on the same backend server, we need to create multiple dom-end server. With the dominance paths created, we can find VCUs for each dominance path. Fig. 8 c shows the candidate VCUs created from the two dominance paths, with duplicates removed.
 Fig. 8 c shows that, when multiple MQTs are used by the same query fragment, the number of candidate
VCUs is no longer linear. In the worst case when each federated query only has one query fragment and the query fragment uses multiple MQTs, the candidate VCUs are the same as those created by the basic-
FMQTA. 5. Performance evaluation the experiments to show the benefits of exploiting the parallelism property in full-FMQTA over the basic-
FMQTA. We then proceed to Section 5.3 and compare the full-FMQTA with the approach that uses stand-alone MQTA for each backend server to recommend MQTs. 5.1. Experimental setup
Our experiments were conducted with synthetic workloads with a spectrum of parameters to model differ-a Pentium IV 2.80 GHz PC with 1 GB RAM and a 200 G hard disk, and installed with Windows XP.
Three algorithms are tested in our experiments: the basic-FMQTA, the full-FMQTA and the SMQTA (i.e., stand-alone MQTA). 5.1.1. Parameters for synthetic workloads
The simulation system contains one frontend server and five backend servers. We use synthetic workloads for our tests. There are apparently many ways to generate workloads. We fix the total number of federated queries in each workload to be 50, and focus on four parameters that we believe are useful to model a large number of real-world query workloads. The four parameters are shown in Table 1 .
 Each assignment of the first three parameters in Table 1 results in a unique workload, such as  X  DF  X  2 ;
MF  X  2 ; SS  X  0 : 2  X  . We explain these parameters by showing how we generate a workload W given one assignment: 1. using DF: Create a new federated query q i . Randomly pick DF backend servers (out of the five backend servers): BE j 2. We assume that each query fragment accesses one candidate MQT on the corresponding backend server. That is, there will be DF MQTs  X  MQT  X  j 1 i ; MQT  X  j 2 i ; ... ; MQT 3. The benefit value of an MQT X  X hat is, t  X  q  X  j 1 ; :f MQT between 1 and 10. We assume that the time (w.r.t. the frontend server) to run each query fragment with the presence of the corresponding MQT is almost close to zero X  X hat is, t  X  q f MQT  X  j 2 i g X  0, and so on. In other words, the time to run a query fragment without the MQT, such as the time to prepare the MQT on the backend server. In what follows, we use  X  X  X QT time  X  and  X  X  X QT ben-efit value  X  interchangeably. 4. using SS: We need to know the sizes of the MQTs because MQT sizes are necessary for calculating ROI values. It is known that the ratio between MQT benefit and size is the factor that ultimately affects the
ROI values. Therefore, instead of randomly picking size values for MQTs, we use the MQT benefit together with a size-skew factor SS to decide MQT sizes. By doing so, we can change the ratio between benefit and size by varying the SS value. Specifically, for each MQT, if its benefit is t when the MQT size skew is zero, the size is the same as the benefit. 5. using MF: If an MQT has a fanout of MF, it is used by MF subqueries. In each workload, all the MQTs have the same fanout value indicated by the workload assignment. otherwise, the generation of the workload is accomplished.

Using SP: since there are 275 unique assignments of the three parameters (DF, MF and SS), we obtain 275
SP is 10%, we run the workload under the constraint that the disk space (for materializing MQTs) allocated result, there are totally 1375 different runs in our experiments. 5.2. Effectiveness of applying parallelism property
We compare the two versions of the FMQTA: the basic-FMQTA and the full-FMQTA. Two metrics are used in the comparison: the number of candidate VCUs examined by the algorithms and the running time required by each algorithm. Both the basic-FMQTA and the full-FMQTA provide the same MQT recommen-dation. Therefore, we do not show the workload times given MQT recommendations. Among the four param-eters that model each workload, two of them, specifically DF and MF affect the number of VCUs examined by each algorithm and the running time. We analyze the impact of these two parameters to each algorithm. 5.2.1. Impact of DF
Fig. 9 a shows the average number of VCUs under different DF values. For a given DF value, there are 275 ple, when DF is 1, both the basic-FMQTA and the full-FMQTA have about 24 VCUs in average for the 150 runs. When the DF is 5, the basic-FMQTA has 1334 VCUs while the full-FMQTA only has 227 VCUs.
In general, for the full-FMQTA, the number of candidate VCUs from each federated query is linear to the degree of federation. Precisely speaking, each federated query results in at most DF VCUs (when the MF is one). In contrast, the number of candidate VCUs grows exponentially for the basic-FMQTA.
FMQTA is, compared to the basic-FMQTA. The difference in running time is due to the difference in the num-bers of VCUs examined by these two approaches (see, Fig. 9 a). The running time for the full-FMQTA grows almost linearly and is significantly shorter than that for the basic-FMQTA, while the basic-FMQTA does not scale well as DF increases.
The result clearly shows that, the more backend servers are involved in federated queries, the more bene-ficial it is to exploit the parallelism property in full-FMQTA. 5.2.2. Impact of MF Fig. 10 shows the breakdown of the number of VCUs and the running time for both algorithms for each MF value. Here, the y -axis is the ratio of basic-FMQTA over full-FMQTA.
 As MF increases, the ratio of the numbers of VCUs gets a little smaller ( Fig. 10 a). For example, when
DF  X  5andMF  X  1, the ratio is 6.2; when DF  X  5 and MF  X  5, the ratio becomes 5.5. Again, these ratio time (see, Section 4.2.2 ). 5.3. SMQTA vs. FMQTA We compare the better version of the FMQTA (i.e., full-FMQTA) with SMQTA. For simplicity, we use FMQTA to refer to the full-FMQTA unless explicitly specified.

The major comparison metrics is the quality of MQT recommendation (i.e., the total resource time for run-ning workloads using the recommended MQTs). In all the 750 runs of experiments, the MQT recommenda-tion by FMQTA always results in less workload time than does the recommendation by SMQTA. Therefore we use the performance gain as a measure of how much improvement FMQTA makes over SMQTA. For example, if the resource times for a workload are T fdpa and T
FMQTA and SMQTA, respectively, then the performance gain (of FMQTA) is  X  T Additionally, we may refer to the difference value ( T sdpa 5.3.1. Overall impression
FMQTA consistently suggests better MQTs than SMQTA such that the resource time for running the workload is significantly reduced. The main reason is that SMQTA does not consider the correlation between MQTs on different backend servers and as a result less effective MQT placement is suggested. In particular, FMQTA achieves the performance gain of up to 75% for some runs.

Fig. 11 shows the average and the maximum values of performance gain under different DF values. Each point in the figure is the average of all the 275 runs for a particular DF value.
 average performance gain reaches up to 27%.

We note that each of the average performance-gain values shown in Fig. 11 considers the whole workload of a given parameter assignment. Although FMQTA outperforms SMQTA under any workload assignment, the degree of advantage varies for different workload assignments. In what follows, we study the impact of each of the other three parameters: MF, SS and SP. 5.3.2. Impact of MF
Fig. 12 shows the results under varying DF and MF values. It is reconfirmed that when the DF increases, the performance gain of FMQTA increases, regardless of the MF values.

We observe from Fig. 12 that the largest performance gain occurs when the MF value is one. When MF gets larger, the performance gain becomes smaller. The main reason behind the observation is that a large
MF value implies less flexibility in the MQT recommendation process. For example, whenever we recommend it. We give more concrete explanation below: increases, the total workload time based on the recommendation always increases, for both algorithms. The reason is that, the larger the MF value, the less flexibility in recommending MQTs, resulting in a worse recommendation.
 Second and in contrast, the absolute performance gain of FMQTA decreases as the MF increases. Since our
FMQTA exploits the relationship between MQTs more than the SMQTA, we believe the higher degree of sharing among subqueries unavoidably hurts the FMQTA more than the SMQTA. As a result, a decreased absolute performance gain is resulted as the MF value increases.
Since the performance gain is the result of the total workload time divided by the absolute performance gain, according to the above analysis, apparently it decreases as the MF increases. Nevertheless, even when the MF is 5, we still see quite significant performance gain by FMQTA. 5.3.3. Impact of SS
The parameter SS influences the two algorithms in a subtle way. Fig. 13 plots the performance-gain values under different combinations of DF and nonnegative SS values.

The case when SS  X  0 seems very special because the performance gain does not increase as fast as for the other cases when the DF increases. To understand the phenomenon, we need to go back to how the SMQTA recommends MQTs. SMQTA assigns an ROI to each candidate VCU on the current backend server (for which it is suggesting MQTs) and then picks VCUs with biggest ROI values. In our workloads, each VCU of SMQTA contains only one MQT. The ROI of an MQT (i.e., singleton VCU) is mainly decided by the ratio of its benefit (or MQT time) and size X  X hat is, ROI MF time = time
When SS is zero, all the MQTs have the same ROI value (i.e., the constant MF). Since we pick VCUs with larger times are picked first. As a result, the suggested MQTs by SMQTA share more similarity with those suggested by FMQTA, in which MQTs with larger times are always picked first due to the parallelism property. When SS is larger than zero, MQTs with larger times actually have smaller ROI values (recall, ROI
MF = time SS ) as they are considered individually in SMQTA. As a result, SMQTA would pick MQTs with smaller times first, which is reverse of what FMQTA would do. As a result, when SS is larger than zero,
FMQTA shows good performance gain and the gain is consistent (see, all the lines in Fig. 13 except for the lowest one).

Fig. 14 shows the results for nonpositive SS values. A negative SS value means that, in SMQTA, an MQT clear advantage over SMQTA for negative SS values. 5.3.4. Impact of SP We found an interesting phenomenon that, as the SP increases, the performance gain first increases (see, that there is not enough space for FMQTA to work with and there is limited combinations of MQTs can be placed at the backend servers. As the SP increases to 50% and 70%, FMQTA outperfoms SMQTA by almost 35% since this is enough space for FMQTA to place MQTs and come up with more intelligent combinations of MQTs across multiple backend servers. When the SP is 90%, the average performance gain descreases because almost all MQTs are deployed. When the SP is 100%, the performance gain should be zero because both FMQTA and SMQTA will place all the candidate MQTs. 5.4. SMQTA vs. FMQTA: correlation of subquery times We have studied the impact of the four workload parameters: DF, MF, SS and SP to FMQTA and
SMQTA. In particular, the larger the degree of federation (DF), generally the lager the performance gain of FMQTA over SMQTA. When there is no sharing of MQTs among subqueries (i.e., MF  X  1), the FMQTA shows the best performance over SMQTA. A positive size skew (i.e., SS &gt; 0) affects SMQTA in a negative way, resulting in the larger performance gain of FMQTA.

We have generated the synthetic workloads in such a way that the ROI of an MQT is decided by its benefit value and the SS parameter for each workload assignment. The benefit of an MQT is a random number by a federated query.

In order to gain insights into how the correlation between MQT benefits within each federated query can affect the performance, we conducted two more sets of workloads with controlled MQT benefit values. In one trast to a random number between 1 and 10. In the other set of experiments, the benefit values of the DF
MQTs in a federated query form a geometry sequence starting from 1 with a factor of 2. For example, if
The assignment of these values to the MQTs is random. Again, each workload set contains 1375 workloads. 5.4.1. Overall impression
Fig. 16 a shows the maximum performance gain and Fig. 16 b shows the average performance gain. The leg-for the set of workloads with doubling MQT benefit values within each query. Lastly, the  X  X  X andom-time  X  is the set of workloads with random MQT benefit values. It is the set of workloads studied in Section 5.2 .
It can be observed from Fig. 16 b that SMQTA performs the worst for the same-time workloads. The reason the MQTs have the same ROI value and the same size. As a result, the recommendation process of SMQTA for each backend server is no better than a random selection!
When MQTs have different benefit values, in general, those with larger benefit values are more likely to be picked, resulting in a relatively better SMQTA performance. 5.4.2. Performance under varying MF
When there is no sharing of MQTs between subqueries, FMQTA achieves the best performance gain for all
Section 5.3.2 . In brief, no sharing of MQTs provides the most flexibility for algorithms to recommend MQTs the average performance gain of FMQTA is up to 45%. The random-time data set provides the second best performance gain. The performance gain is least for the double-time workloads.

To put the result in Fig. 17 a differently, SMQTA performs the best when the MQT benefit values have dras-tic differences within each federated query (i.e., the double-time workloads). The explanation is that MQTs ibility to the recommendation process, particularly to the FMQTA algorithm. We note that the performance ative effect of MQT sharing is less obvious to same-time workloads. 5.4.3. Performance under varying SS
We chose three representative SS values, 0.3, 0 and 0.3, to study how SS values affect the algorithms for the different workload sets. Fig. 18 shows the results.

First of all, the performance gain keeps almost invariant for the set of same-time workloads regardless of value. The algorithms recommend MQTs in the same way for all SS values.

Consistent with Section 5.3.3 , a positive SS yields more performance gain for FMQTA, while a zero or neg-the double-time workloads when SS is nonpositive (see Fig. 18 band Fig. 18 c). The performance gain can be feedback  X  for SMQTA to pick MQTs with larger MQT benefits. 5.5. Evaluation based on TPC-H Workload
In this section, we present the experimental results based on 2 GB TPC-H database [6] . Since TPC-H data-base and workload are designed for a single database. We horizontally partitioned two tables, line item and backends are aggregated as the final result of the federated query. We compare the performance of FMQTA and SMQTA for the federated database configurations with 2, 3, 4 and 5 backend servers. Fig. 19 shows the performance gain of FMQTA over SMQTA by considering parallelism and correlation among sub-queries. The results show that FMQTA consistently recommends better MQTs than SMQTA in all configurations.
The higher the degree of federation, the more FMQTA out-performs SMQTA. The performance gain is about 22% when there are five backends. The evaluation based on TPC-H validates the usefulness of our approach in real-world applications. 6. Related work that they can be used for the local refreshment of the MQTs recommended by our FMQTA on backend servers.
Oracle 10 g [22] and SQL Server [23] . All of these MQTAs provide recommendations for only single server configurations. Of these MQTAs, only the IBM DB2 Design Advisor provides recommendations for a feder-ation database server in which some tables are represented as nickname references.

DBPRoxy [24,25] and TimesTen [26] are middleware that provide caching functionality for query results in the main memory at the frontend database. The query results are cached and assigned with TTL (Time to
Live) for exploration. Incoming queries are compared with cached query results via containment checks. If results for the whole workload; instead the cache replacement management in DBProxy is based a LFU (Least Frequently Used) strategy.

Similarly, DBCache [27,28] provides database-caching functionality. Instead of caching individual query result, it caches database table fragments: database table schema and some tuples cached via prior query load and proactively caches MQTs for matching incoming queries rather than being triggered by incoming aims at reducing storage space and view maintenance costs. A dynamic materialized view selectively materi-cache manager is developed to dynamically change the dynamic materialized views based on usage patterns.
CachePortal [30] is a middleware product that caches Web content page and automatically derives the map-ping between the cached Web content pages and the database queries that generate the pages. It monitors database changes and upon detection, it derives the Web content pages that need to be invalidated. In this work, HTML pages are cached instead of query results.

MTCache [31] is a related project at Microsoft  X  Research. MTCache aims at providing transparent mid-tier database caching in SQL Server based on the query optimization technology using materialized views actional model that allows update transactions to read out-of-date copies. Each read operation carries a rectness for this model and present algorithms to ensure freshness constraints.

The work described in these papers does not support a data placement advisor to recommend what MQTs to place in the caches in the federation server or remote servers. Our approach is complementary to our the federation server.

Another closely related work is the IBM DB2 physical database design advisor [35,4] . It can be used for a shared-nothing parallel database system, in which data is horizontally partitioned among multiple indepen-system in [35] .

Given a workload of SQL statements, the partition advisor seeks to determine automatically how to par-benefit each query in the workload, and to evaluate various combinations of these candidates.
The partition advisor can also provide advice for partition and placement of MQTs by evaluating combi-cost-based. The work [4] assumes (1) each node has identical computation power and same database system; mendation until the MQT advisor applies the space constraint and makes the decision about which MQTs to recommend.

If we view the coordinator of the shared-nothing parallel database system as the federation server and the partition nodes as the remote servers, we can compare our work with the physical database design advisor well with the configuration where the remote servers are heterogeneous database systems and they could have servers. Our work can be applied to shared-nothing parallel database systems as well as the situation when a given partition, our algorithm can be used to adjust load distribution via MQT selection to ensure better load balance and parallelism across multiple nodes for shared-nothing parallel database systems addressed in [35,4] . 7. Conclusion
We have studied the problem of MQT recommendation for multiple backend servers that are connected to a production frontend server that may or may not allow MQTs. Unique challenges in such a problem setting include how to coordinate the MQT recommendation process for multiple backend servers and how to make the recommendation algorithm scale well with the number of backend servers. We addressed these challenges by taking into consideration the correlation between MQTs and also the parallelism property of multi-back-end distributed systems. Experimental evaluation demonstrated that our approach is significantly more effi-cient and effective in recommending MQTs than the existing state-of-the-art. As the future work, we are interested in studying the problem of recommending MQTs for both the frontend server and backend servers at the same time to achieve a complete MQT-recommendation solution.

References
