 Entity extraction and sentiment classification are among the most common types of information derived from doc-uments, but the problem of directly associating entities and sentiment has received less attention. We use TextRank on a graph linking entities and sentiment-laden words and phrases. We extract from the resulting eigenvector the final sentiment weights of the entities. We then explore the algo-rithm X  X  performance and accuracy, compared to a baseline. H.3.3 [ Information Storage and Retrieval ]: Text Min-ing Algorithms, Experimentation Entity extraction, sentiment classification
Entity extraction and sentiment classification are both the focus of extensive research and of numerous applications. However, there X  X  been less research into assigning sentiment to entities directly based on their context within documents. Most documents are neither uniformly positive or uniformly negative, nor are they usually about only one thing. Con-sider the following snippet (from [1]):
This document doesn X  X  have a strong, consistent senti-ment, but the entities iPhone and AT&amp;T do. Clearly, we X  X  like to be able to distinguish the article X  X  opinions about each entity, beyond the overall sentiment of the document or the mere presence of entities in it.

Before we extract entity sentiment, we need to be able to extract entities and to have a sentiment model that as-sociates tokens (and optionally phrases) with a positive or negative sentiment.

There are many approaches to entity extraction. Almost any type of entity extraction can be used with the algorithm presented in this paper. For the experiments reported here, we combined the results of a dictionary-based entity extrac-tor and a statistical entity extractor. For increased accuracy, entity mention tracking can be used, as well as pronoun res-olution. When multiple references to the same entity are discovered, we combine their sentiment contexts.

For the algorithm presented here, the sentiment model must be able to map words (and optionally longer n-grams) to a sentiment score. Any approach that yields such a model, like [3], will be satisfactory. In particular, we used a standard supervised document classifier trained on docu-ments labeled positive and negative to derive the sentiment weights.

To blend the sentiment scores in the neighborhood of en-tities, we use the TextRank algorithm described in [2]. In-spired by Page Rank and similar graph-based algorithms, it describes a general approach to any natural language task that can be reduced to a graph.

For the entity sentiment problem, we make the sentiment-bearing words and all the entities into graph vertices. When any sentiment-bearing word is with a configurable distance from a entity (or one of its mentions), an edge is added to the graph, with the sentiment weight being the edge weight. Then, we use a version of power iteration, which finds the eigenvector with the greatest eigenvalue. When power iter-ation has converged, we read the final sentiment weights off the entity vertices. [1] Cosette. Using my beloved iPhone in Australia. http://stumbledownunder.com/2012/01/07/ using-my-beloved-iphone-in-australia/ . [2] R. Mihalcea and P. Tarau. Textrank: Bringing order into texts. In D. Lin and D. Wu, editors, Proceedings of
EMNLP 2004 , 2004. [3] B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up?
Sentiment classification using machine learning techniques. In Proceedings of EMNLP 2002 , pages 79 X 86, 2002.
