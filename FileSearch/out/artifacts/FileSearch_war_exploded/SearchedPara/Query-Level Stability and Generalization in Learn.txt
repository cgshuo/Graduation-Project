 Yanyan Lan* lanyanyan@amss.ac.cn Tie-Yan Liu tyliu@microsoft.com Tao Qin* qinshitao99@mails.thu.edu.cn Zhiming Ma mazm@amt.ac.cn Hang Li hangli@microsoft.com Recently, learning to rank has gained increasing at-tention in machine learning and information retrieval (IR). When applied to IR, learning to rank is a task as follows. Given a set of training queries, their as-sociated documents, and the corresponding relevance judgments, a ranking model is created which best rep-resents the relevance of documents with respect to queries. When a user submits a query to the IR sys-tem, the trained model assigns a score to each docu-ment associated with the query, sorts the documents based on their scores, and presents the top ranked doc-uments to the user. Average ranking accuracy over a large number of queries is usually used to evaluate the effectiveness of a ranking model. Therefore, from the application X  X  perspective, both training and evaluation should be conducted at query level.
 Many learning to rank algorithms have been proposed in recent years. Examples include the pointwise rank-ing algorithms like MCRank (Li et al., 2007), the pair-wise ranking algorithms like Ranking SVM (Herbrich et al., 1999) and RankBoost (Freund et al., 2003), and the listwise ranking algorithms like ListNet (Cao et al., 2007). Analysis on the algorithms in the light of sta-tistical learning theory, however, was not sufficient, particularly that on the generalization ability of the proposed algorithms. The pointwise and pairwise ap-proaches transform the ranking problem to classifica-tion or regression, and thus existing theory on clas-sification and regression can be applied. However, it deviates from the direction of enhancing ranking accu-racy at query level. Furthermore, the listwise approach lacks of analysis on generalization ability.
 In this paper, we investigate the generalization ability of learning to rank algorithms, in particular from the viewpoint of query-level training and evaluation. We propose a new probabilistic formulation of learning to rank for IR. The formulation can naturally repre-sent the pointwise, pairwise and listwise approaches in a unified framework. Within the framework, we introduce the concepts of query-level loss, query-level risk, and particularly query-level stability. Query-level stability measures whether the output of a learning algorithm changes largely with small changes in the training queries. With query-level stability as a tool we can conduct analysis on query-level generalization bounds of learning algorithms. A query-level gener-alization bound indicates how well one can enhance the expected ranking accuracy (corresponding to the expected risk) by enhancing the average ranking accu-racy in training (corresponding to the empirical risk). We take the algorithms of Ranking SVM (Joachims, 2002; Herbrich et al., 1999) and IRSVM (Cao et al., 2006; Qin et al., 2007) as examples, and apply the pro-posed theory to them. Our theoretical result shows that the query-level generalization bound of Ranking SVM is not reasonably good, mainly because Rank-ing SVM is trained at document pair level, not query level. Furthermore, IRSVM does have a better gener-alization bound than Ranking SVM, due to its stronger query-level stability. We also conducted experiments and our experimental results agree with the theoretical findings.
 The contributions of this paper are listed as follows. (1) A proposal on conducting analysis on learning to rank algorithms at query level is made. (2) A new probabilistic formulation of learning to rank is pro-posed. (3) A new methodology for analyzing gener-alization ability of learning to rank algorithms on the basis of query-level stability is proposed. (4) The pro-posed theory is applied to learning to rank algorithms of Ranking SVM and IRSVM. The correctness of the theory has been verified by experiments. 2.1. Ranking in IR Ranking is a central issue for IR. Many methods for creating ranking models have been proposed, including heuristics and learning based methods, (Baeza-Yates &amp; Ribeiro-Neto, 1999; Herbrich et al., 1999; Joachims, 2002; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007). Typically a ranking model is defined as a function of features based on query-document pair, and is learned with training data containing a num-ber of queries, associated documents, and correspond-ing relevance judgments. Measures for evaluating the performance of a ranking model, such as Precision, MAP (Baeza-Yates &amp; Ribeiro-Neto, 1999), and NDCG (J  X arvelin &amp; Kek  X al  X ainen, 2002) have been defined and used. All the measures are query-based; if the evalu-ation measure for a query q is EV ( q ), then the aver-aged EV ( q ) on a number of queries is used. From the application X  X  perspective, both training and testing in learning to rank should be conducted at query level. 2.2. Learning to Rank So far learning to rank has been addressed by the pointwise, pairwise, and listwise approaches. In the pointwise approach (Li et al., 2007), ranking is trans-formed to regression or classification, and the loss func-tion in learning is defined as a function of a single docu-ment. In the pairwise approach (Herbrich et al., 1999; Joachims, 2002; Freund et al., 2003; Cao et al., 2006), ranking is transformed to pairwise classification, and the loss function is defined on a document pair. In the listwise approach (Cao et al., 2007; Qin et al., 2007), document lists are viewed as learning instances and the loss function is defined on that basis.
 Although many learning methods have been proposed, theoretical investigations on them were not sufficient. Since training and testing should be conducted at query level, studies on query-level generalization abil-ity of learning algorithms are really needed. Unfortu-nately, it was missing in the previous work. 2.3. Stability Theory The notion of stability (Devroye &amp; Wagner, 1979) has been proposed for analyzing the generalization bounds of learning algorithms.
 Bousquet et al. (Bousquet &amp; Elisseeff, 2002) propose the theory of uniform leave-one-out stability. Based on it, the generalization bounds of classification algo-rithms such as Support Vector Machines (SVM) can be derived. Agarwal et al. (Agarwal &amp; Niyogi, 2005) apply the stability tool to bipartite ranking. We can apply the existing stability theory to get doc-ument level and document pair level generalization bounds. However, they may be not suitable for the task of IR. In this paper, we propose query-level sta-bility and reveal the relation between query-level sta-bility and query-level generalization bound. As explained in Section 2, ranking in IR is evaluated at query level. Therefore, to design and evaluate a learn-ing to rank algorithm, we should also look at it from the query perspective. To this end, we give a novel probabilistic formulation of ranking for IR, which con-tains queries and their associates (documents, docu-ment pairs, or document sets) in two layers. We then introduce the notions of query-level loss and query-level risk.
 Assume that query q is a random sample from the query space Q according to a probability distribution P
Q . For query q , an associate  X  ( q ) and its ground-truth g (  X  ( q ) ) are sampled from space  X   X G accord-ing to a joint probability distribution D q , where  X  is the space of associates and G is the space of ground truth. Here the associate  X  ( q ) can be a single doc-ument, a pair of documents, or a set of documents, and correspondingly the ground truth g (  X  ( q ) ) can be a relevance score (or class label), an order on a pair of documents, or a permutation (list) of documents. associate-level loss ) defined on (  X  ( q ) , g (  X  ( q ) ranking function f .
 Expected query-level loss is defined as:
Empirical query-level loss is defined as: ciates of q , which are sampled i.i.d. according to D q . The empirical query-level loss can be an estimate of the expected query-level loss. It can be proven that the estimation is consistent.
 The goal of learning to rank is to select the ranking function f which can minimize the expected query-level risk defined as:
In practice, P Q is unknown. What we have are { n i is the number of associates for query q i . Here q ,  X  X  X  , q r can be viewed as data sampled i.i.d. ac-according to D q i , j = 1 ,  X  X  X  , n i , i = 1 ,  X  X  X  , r . Empirical query-level risk is defined as:
The empirical query-level risk is an estimate of the expected query-level risk. It can be proven that the estimation is consistent.
 This probabilistic formulation can cover most of exist-ing learning to rank algorithms. If we let the associate to be a single document, a document pair, or a doc-ument set, we can respectively define pointwise, pair-wise, or listwise losses, and develop pointwise, pair-wise, or listwise approaches to learning to rank. (a) Pointwise Case Let D denote the document space. We use a feature mapping function  X  : Q X D  X  X (= R d ) to create a d -dimensional feature vector for each query-document pair. For each query q , suppose that the feature vec-tor of a document is x ( q ) and its relevance score (or random sample from X X  R according to a probability (square loss for example), then the expected query-level loss becomes: S out to be: (b) Pairwise Case ument pair associated with it. Moreover, y ( q ) = 1 if x 1 is ranked above x Y dom sample from X 2  X Y according to a probability dis-loss for example, (Herbrich et al., 1999)), then the ex-pected query-level loss becomes: S out to be: (c) Listwise Case For each query q , let s ( q ) denote a set of m documents associated with it,  X  ( s ( q ) )  X   X  denote a permutation of documents in s ( q ) according to their relevance degrees to the query, where  X  is the space of all permutations on m documents. ( s ( q ) ,  X  ( s ( q ) )) can be viewed as a random sample from X m  X   X  according to a probability (cross entropy loss for example, (Cao et al., 2007)), then the expected query-level loss becomes: S the empirical query-level loss of query q i , ( i = 1 ,  X  X  X  turns out to be: Based on the probabilistic formulation, we propose a novel concept named query-level stability. We further discuss how to use query-level stability to analyze the generalization ability of a learning to rank algorithm. First, we give a definition to uniform leave-one-query-out associate-level loss stability. The stability of a learning algorithm represents the degree of change in the loss of prediction when randomly removing a query and its associates from the training data.
 Definition 1. Let A be a learning to rank algorithm, { ( q i , S i ) , i = 1 ,  X  X  X  , r } be the training set, l be the associate-level loss function, and  X  be a function map-ping an integer to a real number. We say that A has uniform leave-one-query-out associate-level loss stabil-ity with coefficient  X  with respect to l , if  X  q j  X  X  , S ( X   X G ) n j , j = 1 ,  X  X  X  , r, q  X  X  , (  X  ( q ) , g (  X  ( q ) the following inequality holds: ( q 1 , S 1 ) , where ( q j , S j ) is deleted. f f ( q use the notations hereafter.
 With the definition, we can obtain the following lemma. It states that, if an algorithm has uniform leave-one-query-out associate-level loss stability, it will be stable in terms of expected query-level loss and em-pirical query-level loss. For ease of explanation, we simply call the uniform leave-one-query-out associate-level loss stability query-level stability .
 Lemma 1. Let A be a learning to rank algorithm, { associate-level loss function. If A has leave-one-query-out associate-level loss stability with coefficient  X  with respect to l , then the following inequalities hold: Based on the concept of query-level stability, we can derive a query-level generalization bound, as shown in Theorem 1. The theorem states that if an algorithm has query-level stability, then with high probability over the samples, the expected query-level risk can be bounded by the empirical risk and a term which depends on the query number and parameters of the algorithm. Furthermore, the theorem quantifies the expected loss on new queries, which is exactly what we mean by query-level generalization.
 Theorem 1. Let A be a learning to rank algo-and let l be the associate-level loss function. If (1)  X  ( q 1 , S 1 ) ,  X  X  X  , ( q r , S r ) , q  X  Q , (  X  ( q )  X   X  G , has query-level stability with coefficient  X  , then  X   X   X  (0 , 1) with probability at least 1  X   X  over the samples of { ( q i , S i ) } r i =1 in the product space Q Proof. For clarity of the proof, we first give the follow-ing definitions:
We then prove the theorem in two steps. 1) Get the bound of
For this purpose, we get the upper bound of the fol-lowing term first: where { ( q i , S i ) } r,j,q ( w 1 , g ( w To utilize the query-level stability, we divide  X  into two terms:  X  =  X  1  X   X  2 , and discuss either of them separately, as follows.
Based on query-level stability, we can obtain that  X  q inequality holds:
With (3), as  X  1 is an integral function, the following inequality holds:
As for  X  2 , we have
By jointly considering (4) and (5), we obtain:
Based on McDiarmid X  X  inequality(McDiarmid, 1989), with probability at least 1  X   X  over the samples of { ( q i , S i ) } r i =1 in the product space Q 2) Get the bound of The reason that the last equality holds is as follows. Because the integral is conducted over all of the sam-ples, and the samples are i.i.d ., we can change the i th further using (3), we have:
Merging Eq. (6) and (7) yields the inequality in the theorem. Without loss of generality, we take existing algorithms of Ranking SVM (Joachims, 2002; Herbrich et al., 1999) and IRSVM (Cao et al., 2006; Qin et al., 2007) as examples to show how to analyze the query-level generalization bound of an algorithm, using the tool of query-level stability. Both of the two algorithms be-long to the pariwise case of our probabilistic formula-tion. It should be noted that the framework is neither limited to these two algorithms nor to the pair-wise case, we leave the discussions on other algorithms or other approaches to our future work. 5.1. Generalization Bound of Ranking SVM Ranking SVM is widely used in ranking for IR, which views document pair as associate of the query and min-imizes: where l h ( f ; z i , y i ) is the hinge loss, and K is a ker-nel function in the Reproducing Kernel Hilbert Space (RKHS).
 Using the conventional stability theory (Bousquet &amp; Elisseeff, 2002), we can get the following lemma which shows the query-level stability of Ranking SVM. Lemma 2. If  X  x  X  X , K ( x, x )  X   X  2 &lt;  X  , then Ranking SVM has query-level stability with coefficient As for this lemma, we have the following discussions. (1) When r approaches infinity, suppose the mean and variance of the distribution of n q are  X  and  X  2 re-spectively. Then by the Law of Large Numbers and Chebyshev X  X  inequality,  X  0 &lt;  X  &lt; 1 ,  X   X  &gt; 0 ,  X  r &gt; R (  X  ), with probability at least 1  X   X  , the following inequality holds: Therefore,  X  ( r )  X  4  X  2  X r proach zero, with a convergence rate of O ( 1 p r ), when r goes to infinity. (2) When r is finite (which is the case in practice), we have no reasonable statistical estimation of the term loose bound for  X  ( r ) as 4  X  2  X  . That is, when r increases but is still finite,  X  ( r ) does not necessarily decrease. Based on the above lemma, we can further derive the generalization bound of Ranking SVM. In particular, as the function f f ( q C , such that,  X  ( q 1 , S 1 ) ,  X  X  X  , ( q r , S r ), C . Then,  X  ( q 1 , S 1 ) ,  X  X  X  , ( q r , S r ) , z  X  Z l  X  ering Theorem 1, we obtain the following theorems. Theorem 2. If  X  x  X  X , K ( x, x )  X   X  2 &lt;  X  , then for Ranking SVM,  X   X   X  (0 , 1) ,  X   X  &gt; 0 ,  X  R (  X  ) , if r &gt; R (  X  ) , then with probability at least 1  X  2  X  Q Theorem 3. If  X  x  X  X , K ( x, x )  X   X  2 &lt;  X  and we have no constraint on r , then for Ranking SVM,  X   X   X  (0 , 1) , with probability at least 1  X   X  Q Theorem 2 states that when the number of training queries tends to be infinity, with high probability the empirical query-level risk of Ranking SVM will con-verge to its expected query-level risk. However, when the number of training queries is finite, the expected query-level risk and empirical query-level risk are not necessarily close to each other, and the bound in The-orem 3 quantifies the difference, which is an increasing function of the number of training queries. 5.2. Generalization Bound of IRSVM In IR application, the numbers of document pairs asso-ciated with different queries vary largely (See LETOR or other public dataset). In consideration of this, IRSVM, studied in (Cao et al., 2006) and (Qin et al., 2007), is an adaptive version of Ranking SVM to the IR applications, which minimizes:
We can prove the query-level stability of IRSVM as shown in Lemma 3. Due to space limitations, we omit the proof.
 Lemma 3. If  X  x  X  X , K ( x, x )  X   X  2 &lt;  X  , then IRSVM has query-level stability  X  ( r ) = 4  X  2  X r . With a similar analysis to that for Ranking SVM, we obtain the following theorem.
 Theorem 4. If  X  x  X  X , K ( x, x )  X   X  2 &lt;  X  , then for IRSVM,  X   X   X  (0 , 1) , with probability at least 1  X   X  Q The theorem states that when the number of train-ing queries tends to be infinity, with high probability the empirical query-level risk of IRSVM will converge to its expected query-level risk. When the number of queries is finite, the bound in the theorem quantifies the difference between the two risks, which is a de-creasing function of the number of training queries. Remark 1. By comparing Theorem 2 and Theorem 4, we can find that the convergence rates of the empiri-cal query-level risk to the expected query-level risk for Ranking SVM and IRSVM are the same, i.e. O ( 1 p r ) . However, by comparing Theorem 3 to Theorem 4, we can see that for the case of finite r , the bound of IRSVM is much tighter than that of Ranking SVM. We conducted experiments on Ranking SVM and IRSVM to verify our theoretical results. 6.1. Query-level Stability First, we conducted an experiment to compare the stabilities of Ranking SVM and IRSVM. We ran-domly sampled 1,200 queries from a search engine X  X  data repository, each query associated with hundreds of documents and their relevance labels. There are five labels:  X  X erfect X ,  X  X xcellent X ,  X  X ood X ,  X  X air X , and  X  X ad X . We split the queries into three sets: a training set with 200 queries, a validation set with 500 queries, and a test set with 500 queries (we denote the test set as T ). The validation set was used to select the regu-larization parameter  X  for Ranking SVM and IRSVM. We first trained two ranking models with Ranking SVM and IRSVM, denoted as f 0 and f 0 0 respectively. Then we randomly deleted one query from the training set, and trained two new models with Ranking SVM and IRSVM, denoted as f 1 and f 0 1 respectively. We repeated this process 30 times, and created the mod-els f 1 , f 2 ,  X  X  X  , f 30 an f 0 1 , f 0 2 ,  X  X  X  , f 0 30 set, we compared the associate-level loss for f 0 with that for f i , and obtained the difference  X  i for Rank-ing SVM. Similarly, we computed  X  0 i for IRSVM. According to Definition 1,  X  i can bound from be-low the query-level stability  X  ( r )( r = 200) of Ranking SVM. Similarly,  X  0 i can bound from below the query-level stability  X  ( r )( r = 200) of IRSVM. In this re-gard, we can compare stabilities of Ranking SVM and IRSVM by comparing  X  i and  X  0 i .
 We list all the 30 values of  X  i and  X  0 i in Table 1. From it, we can see that  X  i is always much larger than  X  0 i . The mean (or maximum) value of  X  i over the 30 trials is 1.23 (or 4.53). It is about more than ten times higher than the mean (or maximum) value of  X  0 i , which is only 0.12 (or 0.27). Furthermore, the variance of  X  i (i.e. 0.72) is also larger than that of  X  0 i (i.e. 0.003). These results indicate that the query-level stability of RankSVM is not so good as that of IRSVM. (Note that Lemmas 2 and 3 hold for any r , the number of training queries. We simply set r = 200.) 6.2. Query-level Generalization Bounds Next, we compared the performances of Ranking SVM and IRSVM, to verify the theoretical results on their query-level generalization bounds.
 From Theorems 3 and 4 we can see that the bound for Ranking SVM is much looser than that for IRSVM, especially when the number of training queries r is large but finite. We interpret the result as follow. The actual empirical risk and expected risk with re-spect to Ranking SVM are as follows.
In the definitions, only document pair but no query appears, and thus we call them the pair-level risks . For comparison, we also list the query-level risks for the learning to rank problem (See also Section 3) where hinge loss is used as associate-level loss.
By comparing the above formulas, we can clearly see that what is optimized in Ranking SVM (i.e. the pair-level risk) is not equal to what should be optimized (i.e. the query-level risks), unless every training query has the same number of document pairs, which is not true in practice. In contrast, it is easy to verify that what is optimized in IRSVM is exactly the query-level risk. Therefore, no surprisingly IRSVM has a better query-level generalization bound.
 In summary, the theoretical results indicate that the performance of Ranking SVM on the test set in terms of a query-level measure should not be so good as that of IRSVM. We have verified this through experiments. We tested the ranking performances of Ranking SVM (RankSVM for short) and IRSVM on the test set, in terms of Precision and NDCG. The results are shown in Figure 1. Furthermore, MAP 1 for Ranking SVM is 0.39 and MAP for IRSVM is 0.41. From the results, we can see that IRSVM achieves better ranking perfor-mance than RankSVM, in terms of all the query-level measures. This is also consistent with the results re-ported in (Cao et al., 2006) and (Qin et al., 2007). In this paper, we have studied the generalization abil-ity of learning to rank algorithms for IR. A probabilis-tic formulation for ranking has been proposed, which covers ranking algorithms belonging to the pointwise, pairwise and listwise approaches. The tool of query-level stability has been developed, which has been fur-ther used to analyze the generalization bound of a ranking algorithm. We have applied the tool to two ex-isting ranking algorithms (Ranking SVM and IRSVM) and obtained theoretical results. We have also verified the correctness of the results by experiments. As far as we know, this is the first work on query-level generalization bound of learning to rank algorithms. There are still many issues to investigate. (1) We have taken SVM based ranking algorithms as examples. We will try to obtain similar results for other algorithms, such as RankBoost. (2) We have focused on the pair-wise approach. The proposed formulation for ranking and the tool of query-level stability can also be used to analyze other approaches. (3) It is worth check-ing whether new learning to rank algorithms can be derived under the guide of the theoretical study.
