 A significant portion of information needs in web search target en-tities. These may come in different forms or flavours, ranging from short keyword queries to more verbose requests, expressed in nat-ural language. We address the task of automatically annotating queries with target types from an ontology. The identified types can subsequently be used, e.g., for creating semantically more in-formed query and retrieval models, filtering results, or directing the requests to specific verticals. Our study makes the following con-tributions. First, we formalise the task of hierarchical target type identification, argue that it is best viewed as a ranking problem, and propose multiple evaluation metrics. Second, we develop a purpose-built test collection by hand-annotating over 300 queries, from various recent entity search benchmarking campaigns, with target types from the DBpedia ontology. Finally, we introduce and examine two baseline models, inspired by federated search tech-niques. We show that these methods perform surprisingly well when target types are limited to a flat list of top level categories; finding the right level of granularity in the hierarchy, however, is particularly challenging and requires further investigation. H.3 [ Information Storage and Retrieval ]: H.3.3 Information Search and Retrieval Entity retrieval, semantic search, query classification
A better understanding and processing of user queries is of vi-tal interest to a number of information management and retrieval tasks. A good deal of effort has been invested in recent years into various aspects of this topic, including query segmentation [24], named-entity recognition [12, 19], semantic tagging [18], struc-tural annotation [6], intent discovery [16, 26], and topical classi-fication [5, 13].

In this paper, we focus on queries targeting entities. These typ-ically come in two flavours: (i) looking for a specific entity, or (ii) It has been shown that more than 50% of queries in web search fall into one of these categories [20]. Complementing keyword queries with explicit type information X  X  scenario studied at the TREC and INEX Entity Ranking tracks [4, 9] X  X as been shown to significantly improve retrieval performance. Target types could be used, among others, for building semantically more informed query and retrieval models [3, 15], filtering results [8, 21], or iden-tifying relevant verticals [1, 26]. In practice, however, the scenario assumed at the above benchmarking initiatives, i.e., the user speci-fying the target type, is a rather unrealistic one; common web users prefer simple interfaces with a single search box. This motivates the need for automatic methods for the target type identification of entity-oriented queries.

In this paper, we introduce the task of hierarchical target type identification : given a query, identify the type of relevant results with respect to a given ontology. Specifically, we aim to find the single most specific type within the ontology that is general enough to cover all relevant entities. There are two key differences between this task and prior work on the topic of classifying entity types of queries [15, 25]: (i) our types are not a flat list, but are organised into a hierarchical structure, and (ii) we require  X  X nstance of X  rela-tions between the target type and relevant entities, instead of mere  X  X elatedness. X  Finding types with the appropriate granularity or specificity opens up a number of novel application possibilities, for example, in faceted browsing or result presentation.

The hierarchical target type identification task can naturally be formulated as a ranking problem and evaluated using standard in-formation retrieval metrics. However, taking the correctness of re-sults to be a binary decision would not account for  X  X ear misses, X  such as returning items that are too general or too specific. There-fore, we also consider a lenient evaluation, in which types on the same path with the correct answer are also rewarded.

We develop a purpose-built test collection by taking a large num-ber of queries from various recent entity search benchmarking cam-paigns and hand-annotating them with target types from the DBpe-dia ontology. Finally, we propose and examine two baseline mod-els, inspired by federated search techniques. We find that even sim-ple baselines can perform very well on identifying types from a flat list, while the hierarchical case proves to be challenging.
In summary, this paper makes the following contributions: (1) we identify the task of hierarchical query type identification, (2) we develop a test set and evaluation methodology, (3) we introduce two baseline methods and perform an experimental evaluation. The resources we developed (query set and type annotations) are made publicly available at http://bit.ly/SdpbZh .
Query type classification has been studied for web document re-trieval to categorise searches according to their geographical local-ity [11], goal (such as informational or navigational) [14], vertical intent (e.g., product, image, video) [1, 16], or topicality [17]. Of these, vertical intent discovery is the closest to our task in spirit; however, intents are usually limited to a handful a categories (2 in [16] and 18 in [1]) and are not hierarchically organised. A re-lated task, question classification in a community-based question answering portal is presented in [23]. The authors use a three-level hierarchy of categories, however, questions are only associ-ated with leaf level categories.
 Little work has been done on classifying entity types of queries. Vallet and Zaragoza [25] introduce the entity type ranking task: find the most important types related to the query results. Their approach ranks passages, extracts entities from them, and use the types associated with these entities. There are two important differ-ences between the task in [25] and ours: (1) they consider multiple target types that are related to the query, but the query does not nec-essarily have to fall into any of them, and (2) they use a flat set of (64) types. Kaptein et al. [15] rank entities in Wikipedia and assign Wikipedia categories automatically to the query by considering the most frequent categories associated with the top 10 results. Again, they do not consider the hierarchical structure of categories (due to the fact that categorisation in Wikipedia is not a well-defined  X  X s-a X  hierarchy).
We formulate the problem of hierarchical target type identifica-tion as follows: By entity-oriented queries we mean information needs where the user X  X  intent is to find (i) a specific entity or (ii) a list of entities that are of a particular type or class. It has to be noted that, even for queries with a very clear entity intent, it may not be possible to identify a single common category, apart from the root concept ( X  X hing X  in the DBpedia ontology), as we will show in Section 4. For our task, however, we only consider queries for which there exists a clearly preferred target type; automatic identification of these queries is a non-trivial exercise, and an interesting problem for future research, but it is outside the scope of this work.
We cast the hierarchical target type identification task as a rank-ing problem (rather than a classification one) as this allows us to give credit for  X  X ear-misses, X  i.e., types that are too specific or too general, instead of merely treating them as incorrect. Moreover, this makes it possible for us to gain a better understanding of both the task and the developed models, as we are not focusing only on a single class label, but also consider the other types returned for the query.

Our task is then summarised as follows:
Our notion for an ontology here is simply taxonomic: a hierarchi-cal categorisation of types (or classes) of entities.
In this section we introduce the set collection we developed for our task.
We collected queries from a number of recent benchmarking evaluation efforts: As seen from the examples above, these queries cover a broad range of information needs related to entities and amount to a good num-ber of queries to experiment with (a total of 367 ). Moreover, these topic sets share a peculiarity with pragmatic importance: (a signifi-cant portion of) known relevant answers come either from DBpedia or can relatively easily be mapped to DBpedia. This could aid us in the type annotation process, as we will explain next.
Queries were labelled with types from the DBpedia ontology (version 3.7). The ontology contains 358 categories (out of which only 282 are actually used), organised into a hierarchy of 6 levels. The root category element of all types (on the 0 th level) is Thing ; this, we disregarded from the set of possible types, as it would have no practical value for an actual application. There are 32 categories on the first level of the hierarchy (including Person , Organisation , Work , Species , etc.); we refer to these as top-level types . Annotation was done manually by the two authors of the paper. For each query we looked at the known relevant results (and the topic narrative, where available) to clarify the intent. It is impor-tant to emphasise that the target type was chosen with respect to the query intent, not based on the qrels (which, occasionally, were found to contain errors). The guiding principle was to pick a sin-gle type that is as specific as possible, yet general enough to cover all correct answers. This was possible in 67 % of the cases. The remainder of the queries could not be used for three main reasons: Figure 1: Distribution of target types over the hierarchy. Table 1 contains a summary.

Figure 1 displays the distribution of target types over the levels of the hierarchy. Interestingly, for more than 70 % of the queries the target type lies beyond the top-level categories and can go as far as 4 levels deep.
We consider two types of evaluation: (i) strict , where judgments are binary, crediting only the correct answer, and (ii) lenient , where the relevance scores are graded and near-misses are also rewarded.
For strict evaluation we use mean reciprocal rank (MRR) and success rate at the top rank (S@1). For lenient evaluation we mea-sure the degree of misclassification, as opposed to merely measur-ing correctness, by considering the distance between the returned type ( t ) and the correct type ( t q ) in the hierarchy. We set the dis-tance function d ( t,t q ) to be the number of steps between two types in the hierarchy, if they lie on the same path (which is 0 if t = t and to  X  otherwise. We then turn this distance function into a gain measure G ( t ) by considering linear and exponential decay func-tions. If d ( t,t q ) =  X  we take G ( t ) to be 0 , otherwise: This way the correct type has G ( t q ) = 1 , more specific and more general types on the same path are rewarded proportional to their distance to the target type, and all other types get G ( t ) = 0 . Using the gain values defined above, we compute normalized discounted cumulative gain (nDCG) at two rank cutoff points: 1 and 5.
Types have no direct textual representation, apart from their la-bel. To be able to rank them with respect to their relevance to an input query, we rely on entities from a knowledge base that are as-sociated with the given type. A parallel can be drawn between this task and that of ranking resources (collections) in a federated search setting; each type can be considered as a collection of entities and our target is to provide a relevance ranking of these collections (rep-resenting types). Note that the same analogy can also be made to other well-studied information retrieval tasks, namely expert find-ing [2] and blog distillation [10, 22]. In all these cases, two prin-cipal approaches are used: (1) representing types as a single  X  X arge Model MRR S@1 MRR S@1 nDCG@1 nDCG@5 Type-centric 0.5275 0.3469 0.2987 0.1918 0.1918 0.3089
Entity-centric 0.6951 0.5020 0.3507 0.1633 0.1633 0.3967 document, X  by concatenating all entity descriptors associated with the type, and (2) treating entities as individual retrieval units and aggregating their retrieval scores into a type-level ranking.
We assume that each entity e in the knowledge base has a textual description, e d , and a set of types, e t = ( e 1 t ,...,e with it, where the types come from an ontology ( e i t  X  O ). Further, it is assumed that if an entity is assigned to a given type t then it is also assigned to all ancestors of t ; for example, if an entity is of type President , then it is also of types Politician and Person . In principle, an entity could be assigned to types that are on different paths within the hierarchy, but in practice that is rarely the case.
For each input query, consisting of a sequence of terms, q = ( w 1 ,...,w | q | ) , and for each possible type in the ontology, t  X  O , we estimate the probability that the query was generated by the given type, P ( q | t ) , and rank types in decreasing order of this prob-ability. Next, we formalise the two strategies discussed above using language modeling techniques.

Type-centric model. For each type we build a single large doc-ument by concatenating the descriptions of all entities that are la-belled with that type. Once such a pseudo-document is generated for each type, we can rank types much like documents. Following the standard language modeling approach, we put:
P ( q | t ) = where  X  t is the type language model, computed as a mixture of an empirical model, P ( w i | t ) , and a background language model, P ( w i ) . The latter is a standard maximum-likelihood estimate; the former is estimated by aggregating the term probabilities from all entities of that type: where P ( w | e d ) is the maximum likelihood estimate of term w in the document representation of entity e ; P ( e | t ) is the probability of an entity given a type. For the sake of simplicity, we take this to be uniform, i.e., P ( e | t ) = 1 / |{ e : t  X  e t }| .

Entity-centric model. Instead of creating a direct term-based representation of types, our second approach models and queries individual entities, then aggregates their relevance estimates: The probability of the query given the entity is estimated using a standard query likelihood scoring for document language model-ing: P ( q | e ) = Q | q | i =1 P ( t |  X  e d ) , where  X  model of the entity description. As before, P ( e | t ) is set uniformly across all entities labeled with t .
As a first step, we perform strict evaluation, where the judgments are binary and there is a single correct answer. Table 2 reports the results in terms of mean reciprocal rank (MRR) and success rate Model nDCG@1 nDCG@5 nDCG@1 nDCG@5 Type-centric 0.3265 0.3440 0.2612 0.3287
Entity-centric 0.4143 0.4542 0.2939 0.4173 at rank 1 (S@1). 2 In one set of experiments, we limit ourselves to finding the top-level type for each query (columns 2 X 3). The results show that even simple baselines can be successful in performing this task with high accuracy. Then, we address the hierarchical ver-sion of the type identification task. Not surprisingly, the numbers are much lower here (columns 3 X 7). One interesting finding is that the type-centric model can more often return the correct type at the top rank (S@1) than the entity-centric approach, while in overall the latter method is more effective.

Next, in Table 3, we present results for the lenient evaluation. We test two ways of accounting for near-misses: linear decay (columns 2 X 3) and exponential decay (columns 4 X 5). The latter one is in-creasingly less tolerant as the distance increases between the re-turned type and the correct type; therefore, absolute values are lower for this metric. The relative differences between the two runs, however, are found to be stable for both metrics and cutoff values. Compared to the strict case (Table 2), we observe substan-tial improvements in terms of nDCG@1, while the improvements for nDCG@5 are moderate. This indicates that the top ranked type is often on the same path with the correct answer, however it is not of the right granularity. When examining the types returned at the level of individual queries, we observe some interesting differ-ences between the two approaches. The type-centric model tends to return more specific categories, whereas the entity-centric model rather assigns more general types. This is is indeed the expected behaviour, considering the strategies underlying these methods.
The numbers indicate that the entity-centric model is a clearly preferred choice; this is also in line with findings on the resource selection task in federated search. Our query-level observations, however, suggest that the two approaches should be combined; one possibility for future work would be to use a discriminative frame-work that employs both entity-level and type-level features.
In this paper we introduced the task of hierarchical target type identification for entity-oriented queries. We outlined the relevance of the task to a range of IR problems, developed an evaluation methodology and a test set based on a number of query sets used in recent entity-oriented benchmarking initiatives. Building on ap-proaches from resource selection in federated search, we proposed two baseline approaches and performed an experimental evalua-tion. Our main finding is that even simple baselines can perform surprisingly well, when target types are limited to a flat list. The hierarchical case, however, has proven to be more difficult. Our analysis revealed that the top ranked type is often on the same path with the correct answer, but it is not of the right granularity.
Throughout this paper we focused on queries for which a clearly preferred target entity type was available. This was ensured through a manual selection of queries. In future work we will investigate automatic means of making this selection, i.e., deciding whether the query has a clearly defined target type or not.
Note that in case of a single relevant result S@1 is the same as nDCG@1. Nevertheless, we included both to help comparing the numbers in Tables 2 and 3.

