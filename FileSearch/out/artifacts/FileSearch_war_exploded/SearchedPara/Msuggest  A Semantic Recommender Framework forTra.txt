 Learning traditional Chinese medicine knowledge from the digital library is becoming more and more important these days in China. In medicine learning, many readers want to find out the intrinsic relation between two medicines or among thousands of medicines. A semantic recommender system is useful for readers to understand something quickl y by means of analogy which is a cognitive process of trans-ferring information from a particular subject to another if they are similar in some aspects. In view of these above, we present a novel recommender framework called Msuggest to give the diverse semantic recommended medicine terminolo-gies and book pages when a reader searching for medicine information in digital library. Users can choose various as -pects including medicine property, efficacy, clinical appli ca-tion, place of origin, book provenance and etc. to see dif-ferent recommended results. We evaluate Msuggest under the t-test on the samples from random sampling. The result shows that Msuggest is effective and efficient in giving the recommended words and book pages.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models; H.3.7 [ Digital Libraries ]: System Issues Algorithms, Experimentation Traditional Chinese Medicine, Digital Library, Recommend er Framework
Both ordinary Internet users (6% of American Internet users on an average day) and therapists are increasingly us-ing web search engines to search for medical information [1, 2], and many beginning learners want to draw traditional Chinese medicine knowledge from digital books too. How-ever, there is no book search engine for traditional Chinese medicine in the world.

There are a lot of traditional Chinese medicine books in our digital library. However, readers can not learn medicin e knowledge quickly and effectively because our book search engine only gives medicine books by book name now. Actu-ally, readers want to learn the detail description of a medic ine from the recommended pages, even more, they may concern with other terminologies which are intrinsic related with t he search medicine, so current book search engine dose not sat-isfy the reading cognitive model. Considering the aforemen -tioned factors, we develop a traditional Chinese medicine book search recommender framework called Msuggest which can give semantic recommended words and book pages in our digital library.

In fact, the intrinsic relationship between two medicines i s not merely depended on their original characters or letters , but is mainly depended on their meanings from different as-pects. We construct the intrinsic relationship between two medicines in follow steps. In the beginning, the medicine description in dictionary is divided into various property fields: medicine property, efficacy, clinical application, p lace of origin, book provenance and etc. Once contrasted the meanings between two medicines, we can get the extent of their similarity relationships from different aspects resp ec-tively by Textual Data Mining. Besides, we use a simply PMI co-occurrence word similarity method to find the con-textual relationship between two medicines in the common web search engine. We also give readers the prevalent words associated with the medicine at present time by crawling the recommended words from the web search engines. In the end, the book pages which contain the search medicine are sorted by a page value evaluated function to generate the recommended book pages. Even more, readers can get their continuously upgrading recommended words and pages by user log analyzing in the background. We anticipate readers can enter a whole new realm of experience when searching medicines in Msuggest.

The rest of the paper is organized as follows: section 2 briefly reviews some related work. The key component of our framework is depicted in section 3. In section 4, 5 and 6, we give the details of machine learning, book page pro-cessing and user cooperative updating module respectively . Experimental results and discussions are shown in section 7 . In the end, section 8 presents the conclusions.
Traditional book search engines can give readers the rec-ommended words and pages over the past several years. Some engines provide literally related words to the search text such as Google Book Search [3] and CADAL [4]. How-ever, the given recommended results are probably not what readers need because those results contain the search text merely. In the other hand, some engines provide contextual related words to the search word using PMI-IR algorithm [5]. However, the recommended results may vary consider-ably with the size of overlapping window and the content layout. At present, many engines use rating oriented collab -orative filtering method [6, 7, 8] to give the recommended words and pages.

The Memory-based and the Model-based approaches are the two main categories of the collaborative filtering tech-niques.

The Memory-based approaches make use of the entire user data to get predictions. User-based model is the most com-mon form in using, which predicts unknown ratings of items for a particular user, based on ratings given by a set of neigh -bor users who express the likeness of the common items pre-ferred by the particular user. The similarity between each two users is the principal component of User-based model, which is used to generate the neighborhood of the target user. A popular similarity measure between two users is Pearson Correlation. There are two troublesome problems existing in these approaches. One of them is the biases from different users who have different rating behaviors respec-tively. For example, some users rate the preferred item a high score, however, others may mark the item under the mean value. To distinguish the different biases from each other, a few approaches have been proposed to normalize the ratings data before computing the similarity between two users [9, 10]. They use the mean rating to correct the raw ratings from anomalies. It is shown that the predic-tion effective rate is improved [11]. The second problem is the sparseness of users X  ratings network. The problem is extremely common when there comes a new user or a new item, especially in the beginning phase of construct-ing the neighborhood, which makes it difficult to generate high quality neighborhood for making accurate predictions . To solve such problems, some methods have been proposed to fill the unknown ratings of users, such as dimensionality reduction [7] and data-smoothing methods [6, 12].
The Model-based approaches use a part of data to gen-erate a model that can expound the given training data set well. The model is then used to predict directly without do-ing any work on the original rating database. Those kinds of approaches use clustering methods [12], aspect models [8], Bayesian networks [13] and etc.

The approaches above however are mainly passive. In fact, many readers are unwillingly leaving even a word about the recommended results. So ratings oriented recommender systems do not work very well.
Msuggest mainly contains three modules: machine learn-ing, book page processing and user cooperative updating. As shown in Figure 1, we provide auto-complete function binding with search inputbox to enable users quickly to find and select the medicine what they want to search by en-tering a few front characters. By using hash function, the medicines whose names are as similar as the entering char-acters are quickly be sent to the web page without refreshing by using AJAX(Asynchronous JavaScript and XML). While entering more characters, users can filter down the list to better matches. When a search medicine is submitted by a reader, the recommended framework would send the recom-mended words and recommended pages to him.

The recommended words come from the machine learning module. On the other hand, the recommended pages come from the page processing module. User cooperative updat-ing module has two tasks. The first is maintaining the user word log which records the recommended word click times and the number of IP. Each recommended word in backup set is endowed with a specific probability to displace the recommended words which have lower click rates. The sec-ond is maintaining the user page log which records the total dwell time of each recommended page, page click times and the number of IP. Recommended pages in backup set may get a specific probability to displace the recommended pages which have lower read rates too.
The main task of this module is to find the recommended medicines from different aspects. For example, when a user inputs ginseng( &lt;  X  ) as his search word, and he wants to find some medicines which have similar clinical application or other characteristics similar with ginseng, then Msugge st can give these medicines in the recommended bar in the web page.

The key technology used in finding similarity medicine set of an appointed medicine is calculating the similarity between two description strings of the medicines. It is not precisely evaluating the similarity between two words tota lly by contrasting their original characters. For example, it i s totally different between  X  X ish X  and  X  X ooden fish X  because  X  X ish X  is a kind of animal but  X  X ooden fish X  is a kind of re-ligious article. We present a novel method to calculate the medicine similarity score called  X  X ictionary learning X .  X  Dic-tionary learning X  relies on the assumption that more simila r medicines have more words in common in their descriptions.
We crawl traditional Chinese medicine science terminolo-gies and their descriptions as the content of our dictionary from Chinese Medicine Net [14]. The dictionary includes 4443 traditional Chinese medicine science terminologies a nd their definitions, 11161 medicines and their detail descrip -tions, 1338 prescriptions with their compositions and ap-plications, 241 famous therapists and their specialty info r-mation in Traditional Chinese Medicine field. We segment the description fields of each medicine including medicine property, efficacy, clinical application, place of origin, b ook provenance by shortest-path Chinese segmentation algorit hm [15] which based on traditional Chinese medicine science terminology as an additional segmentation thesaurus. The shortest-path is the lowest weight of words combination. The weight is defined as below:
Formula 1 represents the negative logarithmic probability value in a specific context c when word w = w i . It is clearly that the higher probability in one context, the lower weight the word will be. By using NPOS model [16], we calculate the probability value as: P ( w = w i | c ) = X g denotes a specific POS (part of speech) in G (POS collec-tions). The POS probability of a word is depended on the POS of previous N-1 words( P ( g ( w i ) | g ( w i  X  1 i  X  N +1 probability of a word is depended on the POS of itself( P ( w = w | g ( w i ) = g j )). The sign of summation( P g derstood as the different POS of a word in the same context.
After segmentation, we preserve illness name, medicine name, book name, person name, healing efficacy as the fea-ture of the  X  X linical application X ; preserve medicine prop -erty adjectives such as pungent( " ), sweet( [ ), bitter(  X  ), acid(  X  ), salty( o ), and channel tropism nouns such as Lung Channel of Hand-Taiyin(  X   X   X   X  ), Stomach Channel of Foot-Yangming( v  X   X   X  ) and etcetera as the feature of the X  X edicine property X ; preserve treatment means and heal -ing efficacy as the feature of  X  X fficacy X ; preserve toponomy as the feature of  X  X lace of origin X ; preserve book name and therapist as the feature of  X  X ook provenance X . It is reason-able to think the features above determining the essential implication of the medicine terminology.

We contrast a medicine with another by the words in their features. The similarity degree between words can be calcu-lated only they are of the same POS, because analogy should not be carried out between different classes according to a famous philosopher called Mo-tse who lived in China during 468-376 B.C.

We use Aminul Islam X  X  three modified versions of longest common subsequence (LCS) [17, 18] for the word semantic similarity measurement: v 1 = NLCS ( r, s ) = Length ( LCS ( r, s )) v 2 = NMCLCS 1 ( r, s ) = Length ( MCLCS 1 ( r, s )) v 3 = NMCLCS n ( r, s ) = Length ( MCLCS n ( r, s )) In above formulas, r and s are words from each feature. Length function returns the length of the word. MCLCS 1 stands for maximal consecutive longest common subsequence starting at first character and MCLCS n stands for max-imal consecutive longest common subsequence starting at any character. Overall, the similarity score can be deter-mined by the weighted sum of these individual values v 1 , v , and v 3 where w 1 , w 2 , w 3 are weights and w 1 + w 2 Therefore, the similarity of the two words could be written as:
We set w 1 &gt;w 3 &gt;w 2 for below reasons. In Chinese, the word is very short after segmentation, so common subse-quence X  X  continuity is not the key factor taken into consid-eration. w 3 &gt;w 2 can increase similarity score disparity which is helpful to the progress of sorting.

For example, if r = X   X   X   X   X  (obtaining yang from yin), s = X   X   X  X   X (the yang aspect of yin), w 1 =0.7, w 2 =0.1, w =0.2, then: LCS(r,s)=  X   X   X   X  MCLCS 1 (r,s)=  X   X   X   X  MCLCS n (r,s)=  X   X   X   X  NLCS(r,s) =3 2 /(4*4)=0.5625 NMCLCS 1 (r,s)= 2 2 /(4*4)=0.25 NMCLCS n (r,s)= 2 2 /(4*4)=0.25 similarity(r,s)= 0.5625*0.7+0.25*0.2+0.25*0.1=0.46875
The feature of a medicine could be interpreted as a word array. So we design an algorithm using greedy strategy to get the semantic similarity between two word arrays. Every word is contrasted with other words in the antithesis array, and the maximum similarity value v is recorded and added into the feature similarity score s. At last, the normalizat ion value of s is returned as the array similarity score. The algorithm is shown in Algorithm 1.
 Algorithm 1 getSmilarity (get the similarity score of two word arrays) Input: A, B /*A and B are word arrays, the array size of Output: s /* s is the similarity score of two words arrays, 1: for all string itema  X  A do 2: v  X  the maximum similarity value between itema and 3: s  X  s + v 4: end for 5: length = P posset i max ( pos i ) 6: s  X  s/length
We can find all medicines their recommended medicine set by constructing a medicine similarity matrix M .
Obviously, M is a symmetric matrix. So we treat M as an upper triangular matrix and set diagonal=0. If the size of semantic recommended medicine set is k , then the elements of the medicine a i set are from the other k medicines whose similarity scores with a i are in the top k . It is very easy to calculate the top k value by sorting the scores in the column and row where a i is contained in. We set k = n + m , where n is the number of semantic medicines shown in the web page and m is the number of backup recommended medicines.
The semantic accuracy of the recommended medicines v (0  X  v  X  1) is evaluated by specialists when we setting different values to w 1 , w 2 , w 3 . Three specialists give their marks(0  X  mark  X  1) subjectively about the recommended medicines and v is the mean value of the marks. It is im-portant to find out whether the semantic accuracy of recom-mended medicines v is closely related with the setting of w and w 3 ( w 2 can be deduced from the formula w 1 + w 2 + w In order to confirm this, we use a method called  X  X he H-test of Kruskal and Wallis X  [19] which is in common use in the comparison of several independent samples in applied stati s-tics. We find out the accuracy v is not obviously affected by weights w 1 and w 3 when w 1 &gt;w 3 &gt;w 2 . By setting w and v as the fit points, the relationship among w 1 , w 3 can be shown in a fitting curve. Figure 2 shows the accuracy of ginseng( &lt;  X  ) varies according to the different setting of weights. We choose the vertex(0.7, 0.2, 0.94) which means w 1 = 0 . 7, w 2 = 0 . 1 and w 3 = 0 . 2 to get the maximal v in all medicines for simplification.
 To obtain contextual similarity between medicines, we use Google AJAX API [20] to get the number of documents when searching two specific medicines together in Google [21]. The contextual similarity score reflects the frequenc y when two medicines co-occurred in the same web document. The higher frequency it is, the closer relation their will be . We do query operations C 2 n times in Google which means we iterate every two different medicines in the medicine dictionary whose size is n . The search keyword is set as  X  medicine i  X  +  X  medicine j  X  which denotes we want to find the documents which contain both of two medicines. At last, we record the document number. By constructing matrix M as above, we set the element of M as the mutual documents number, and then we can get the contextual recommended medicine set.

We can get recommended words related to search word when searching in current search engine. Those recommended words reflect the prevalent words people concerned with at the present time. We set the medicines in dictionary as search text then crawl the recommended words from Baidu [22], Google, Yahoo [23] and save them as A 1 , A 2 and A respectively. Then, the word which can not be discovered in our book full-text database will be filtered out. At last, the words will be ranked by the criterion below: If a  X  ( A 1  X  A 2  X  A 3 ), then the rank value of a is 3; else if a  X  ( A the rank value of a is 1. Set A 4 = A 1  X  A 2  X  A 3 , the words in A 4 will be sorted from highness to lowness by the rank value. The web recommended words set will be got after the sorting operation.
In this module, we establish the book full-text inverted index by Lucene tool [24]. The full-text is segmented by CJKAnalyzer [25] which pairs characters in overlapping win -dows of two characters each. So the string X   X  m  X  u  X   X (The mouth is the body opening or window of the spleen) is di-vided into  X   X  m m  X   X  u u  X   X , then we can easily find  X   X  m  X   X  and  X  m  X   X  where their source text file are, from the inverted index file by splicing words using logic operato r AND.

Inverted index is a specially designed data structure. It keeps a list of words pointed to the text file pages which contain them. The pages are sorted by the formula as [25]: score ( q, d ) = X
The implication of each factor in formula is shown below:
We do a second search in those documents which contain the search term to find out some special sentence styles. Declarative sentences contain X  X earch word + (so) X , X  X earch word +  X  (is) X ,  X  X earch word +  X  (is) X  or  X  X earch word + k (have) X  X re considered more valuable than other sentences for they may give descriptions for search term. So we put the documents which contain these sentences into the front of the result pages set and treat them as the recommended pages.
In this module, we analyze the recommended sets click log and page log to get the score of user satisfaction.
The medicine click log records the medicine click times and the number of IP every day just like this (search medicine , recommended medicine, click times, number of IP). The sat-isfaction score of recommended medicine is defined below:
We gather the medicine click times ( clickT imes i ) and the number of IP ( numberIP i ) in 10 days, it reflects the tastes from different readers when they search a specific medicine. The higher f ( medicine ) it is, the more readers like this rec-ommended medicine. So we define a filter operator close behind: n is the size of recommended medicine set. If filter ( medicine ) &lt; 1 /n 2 , it is shown that the popularity of this recommended medicine is less than 1 /n of average popularity. However, we do not replace the medicine with recommended medicines in backup set unconditionally for we do not think medicines in backup have better performance than medicine i . So we only endow the medicines in backup a chance defined below: n represents the number of medicines in backup, and m is the medicine rank position. It is shown that there are 90% potential for medicines in backup to displace the medicines whose filter&lt; 1 /n 2 . The medicines be not accepted yester-day may be accepted tomorrow, so we move those medicines into the end of backup medicine set.
 Table 1: Top 10 recommended medicines efficacy related to ginseng The page log records the page click times, the number of IP and the page dwell time every day just like this (medicine, bookid, page index, click times, number of IP, dwell time). The recommended page satisfaction is defined below: f ( page ) =
We gather the recommended page click times( clickT imes i number of IP( numberIP i ) and page dwell time( dwelltime in 10 days. The higher f ( page ) is, the more readers like this recommended page. So we define a filter operator close behind: n is the size of recommended page set. If filter ( page i it is shown that the popularity of this recommended page is less than the 1 /n of average popularity. But we do not sim-ply replace the page with successor pages unconditionally for we do not think successor pages have better performance than page i . So we only endow the pages in backup a chance defined below: n represents the size of backup page set, and m is the page rank position. It is shown that there are 80% potential for pages in backup page set to displace the pages whose filter&lt; 1 /n 2 . The pages not be accepted yesterday may be accepted tomorrow, so we move those pages into the end of recommended page set.
In this section, we will present some experimental results by using Msuggest at the first and make out the analysis report at last.
We will take the medicine ginseng( &lt;  X  ) as an example to analyze the recommended words and book pages given by Msuggest.

Table 1 shows the top 10 recommended medicines efficacy related to ginseng.

One of the bonds among medicines in Table 1 is that they are all medicines for tonifying Qi and blood (  X   X   X   X  ). Table 2: Top 10 recommended medicines property related to ginseng Table 3: Top 10 recommended medicines contextual related to ginseng
Table 2 shows the top 10 recommended medicines prop-erty related to ginseng.

The medicines in Table 2 all belong to lung, heart or spleen channel and they are sweet or flat in natural taste.
Table 3 shows the top 10 recommended medicines contex-tual related to ginseng in Google web documents.
The medicines in Table 3 may reflect their applied fre-quencies in clinical application with ginseng. The context ual relationship is useful for doctors when they make a prescrip -tion.

Table 4 shows the top 10 prevalent recommended words related to ginseng from common search engines.

These words in Table 4 are all words concerned by netizens at present time. So they may interest the readers in digital library too.
 Table 4: Top 10 prevalent recommended words re-lated to ginseng &lt;  X   X   X  (Ginseng Spleen Strengthening Pill) 2 &lt;  X  8  X  (Ginseng Spleen Invigorating Bolus) 5
Table 5 shows the top 10 recommended book pages related to ginseng.

The book pages in Table 5 expatiate ginseng in different extents. And the rank position is decided by their detail levels.

We randomly select 10 traditional Chinese medicine books from the digital stack room, and record their frequencies of reading in a month in the situation of using Msuggest and without using Msuggest respectively. The comparison is shown in figure 3.

As it turned out, Msuggest greatly increases the frequency of reading in traditional Chinese medicine book in the digit al library.

We record their book read coverage rate in above 10 books respectively. Book read coverage rate is defined as the pro-portion of the read pages in the total pages of a book. The comparison is shown in figure 4 in a month in the situation of using Msuggest and without using Msuggest.
 As it turned out, Msuggest greatly enlarges the traditional Chinese medicine book page read coverage rate in the digital library.
The recommended items X  effective rate of a medicine is defined as:
The numerator of the formula represents the number of recommended words( numExistW ) and page( numExistP ) without be filtered out, the denominator represents the tota l number of recommended words( numRW ) and pages( numRP ). The effective rate can be deemed to a random variable X. Based on experiences, X subjects to the normal distribution N (  X ,  X  2 ), however,  X  and  X  2 are unknown. It is impractical to count all recommended effective rates of the medicines, so we randomly select 30 medicines in dictionary as samples and get their effective rates in a month in Msuggest. The statistical results are shown in Table 6.

We use 0.95 as the confidence level. It is shown the average effective rate  X  is more than 85% by the proof below:
Proof. To obtain an estimate of  X  , we use one sided t-test. Thus for testing H 0 :  X   X   X  0 = 85% against H 1 :  X  &gt; 85%, reject H 0 if t surpasses the critical value t  X  ( n  X  1). h ( t ) is defined as below: h ( t ) =  X [( n + 1 / 2)]  X 
The region of rejection of this problem is:
Now n=30, t 0 . 05 (29)=1.6991, x =88.3667%, s =7.2468%, so t = x  X   X  0 s/  X  n = 2.5446 &gt; 1.6991. Then we reject H H , that is to say the average effective rate of all medicines is more than 85% under the confidence level of 95%.
This paper gives an introduction of Msuggest, a seman-tic book search recommender framework for traditional Chi-nese medicine. The design of Msuggest takes into considera-tion the unique requirements of users in medicine searching . Msuggest uses a novel method called  X  X ictionary learning X  to find out the intrinsic relationship among thousands of medicines from different aspects. Besides, Msuggest return s updating recommended set by the cooperation of digital li-brary readers. These features are very attractive to the ma-jority of Internet users who have little medical background . With a wide range of medicine searching scenarios, the ex-perimental results demonstrate that Msuggest greatly im-proves user satisfaction by performing medicine searching effectively and efficiently.

There are a variety of directions for future work. It would be interesting to import other advanced retrieval techniqu es to medicine search. In fact, the lack of individuation is the biggest problem in Msuggest. To combine user rating oriented collaborative filtering techniques may enhance th e recommended effects. Though many patients want to find medicines by searching disease name and it is pretty sim-ple to do this work, however, there maybe some medical tangles. Some careless patients may take the medicines in recommended bar without considerations. This is a terrible thing. It is more valuable to consider how to establish an Cross-Semantic book search engine whose node is medicine, prescription, doctor, book or disease in the future. This work are supported by the National Natural Science Foundation of China 60673088 and Program for Changjiang Scholars and Innovative Research Team in University (IRT06 52, PCSIRT).We thank Zhang Yan and Lu Weiming for their advice on some recommendation algorithms at the both time. [1]  X  X oogling X  Aids Difficult Diagnoses. http://www.e-[2] Curing Medical Information Disorder. [3] Google Book Search. http://books.google.com . [4] China-America Digital Academic Library. [5] Turney, P. Mining the web for synonyms: PMI X  X R [6] H. Ma, I. King and M. R. Lyu. Effective missing data [7] K. Y. Goldberg, T. Roeder, D. Gupta and C. Perkins.
Medicine Motherwort Myrrh Calyxkaki Radix Notoginseng Sword Bean [8] T. Hofmann. Latent semantic models for collaborative [9] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom and [10] J. S. Breese, D. Heckerman, and C. M. Kadie. [11] R. Jin, L. Si, C. Zhai and J. P. Callan. Collaborative [12] G.-R. Xue, C. Lin, Q. Yang, W. Xi, H.-J. Zeng, Y. Yu [13] D. M. Pennock, E. Horvitz, S. Lawrence, and C. L. [14] Chinese Medicine net. [15] The Resource of ICTCLAS. [16] Wang Xiaolong and Guang Yi. Computer Nature [17] L.Allison and T.I.Dix. A bit-string [18] Aminul Islam and Diana Inkpen. Semantic Text [19] Lothar Sachs. Applied Statistics(2nd Edition). [20] Google Ajax Search API. [21] Google Search Engine. http://www.google.com . [22] Baidu Search Engine. http://www.baidu.com . [23] Yahoo Search Engine. http://www.yahoo.cn . [24] Welcome to Lucene. http://lucene.apache.org . [25] Erik Hatcher and Otis Gospodnetic. Lucene in Action .
