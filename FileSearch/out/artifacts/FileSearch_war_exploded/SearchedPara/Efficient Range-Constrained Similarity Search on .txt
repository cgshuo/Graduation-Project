 Due to the resource limitation in the data stream environ-ment, it has been reported that answering user queries ac-cording to the wavelet synopsis of a stream is an essential ability of a Data Stream Management System (DSMS). In this paper, motivated by the fact that a user may be in-terested in an arbitrary range of the data streams, we in-vestigate two important types of range-constrained queries in time series streaming environments: the distance queries (which aim at obtaining the Euclidean distance between two streams) and the n NN queries (which aim at discovering n nearest neighbors to a reference stream). To achieve high ef-fi ciency in processing these two types of queries, we propose procedure RED (standing for Range-constrained Euclidean Distance) and algorithm EKS (standing for Enhanced N NN Search). Compared to the existing methods in the prior re-search, the advantageous features of our approaches are in two folds. First, our approaches are capable of processing the queries directly from the wavelet synopses retained in the main memory without using IDWT to reconstruct the data cells. This feature allows us to save the complexity in both memory and time. Moreover, our approaches enable the users to query the DSMS within their range of interest. Unlike the conventional methods which only support the full-range query processing, this feature will enhance the fl exibility at the client side. We evaluate procedure RED and algorithm EKS on live and synthetic datasets empiri-cally and show that the proposed approaches are e ! cient in similarity search and n NN discovery within arbitrary ranges in the time series streaming environments.
 H.2.4 [ DATABASE MANAGEMENT ]: Systems-Query processing Algorithms, Management Data Stream, Similarity Search, Wavelet Synopses
Query processing in streaming applications is one of the emerging topics in the fi eldofmoderndatabasesystems. In general, due to the rapid evolving speed, a data stream management system (DSMS) is responsible for processing user queries in near real time. On the other hand, since the data streams evolve continuously without limit, it is im-practical to store complete details for each stream. Instead, the queries are usually processed from the limited memory in which the behaviors of the data streams are summarized. Among all kinds of sketching techniques, the wavelet-based approaches have been received the most research attention due to the property of dimensionality reduction and the sim-plicity of transforming the data cells. In view of the fact that di erent applications require di erent error metrics, many approaches are proposed to generate the wavelet synopses which minimize the O 2 -qrup average error [5][15], the max-imum absolute/relative error [7], or the weighted O s -norm error [6].

In the time series streaming environments, similarity search, which aims at retrieving the similarity between two streams, is an important issue. Consider a time series with length Q . Since the data value at one time is orthogonal to that at the other, this time series can be viewed as an Q -dimensional object. A prevalent measure of similarity is the Euclidean distance between two objects in the Q -dimensional space domain.Inmanyreal-worldapplicationssuchasstockmar-ket, weather forecasts, video databases, and network moni-toring, the Euclidean distance has become the most widely used similarity measure to retrieve important patterns. Also note that a DSMS usually monitors a massive numbers of data streams. Under this circumstance, in addition to the simple similarity search between two streams, discovering n nearest neighbors among multiple streams also becomes im-portant. Compared to the similarity search, processing such n NN queries usually cost much higher complexity. There-fore, various approaches [4], [8], [9], [12], [16] are proposed to improve the e ! ciency of searching nearest neighbors in the streaming environments.

In this paper, we study the problem of similarity search and nearest neighbor discovery within an arbitrary range from the wavelet synopses over multiple streams. The sys-tem model of the DSMS for these goals can be illustrated in Figure 1. Consider multiple evolving streams as the input Figure 1: System model for a DSMS in processing distance queries and n NN search within an arbitrary range of the DSMS. The length of each stream (denoted by Q )is beyond the storage capacity of the main memory. To ap-proximate the behavior each stream, a common approach is to transform the input data cells as wavelet coe ! cients and then retain the most E representative ones, where QAAE . At the client side, we consider the fact that di erent users may be interested in di erent ranges, and allow the DSMS to process the queries according to the range of interest [ {&gt; | ] , where 0 $ { $ | $ Q 3 1 . For example, given two compa-nies, one user may only be interested in the similarity be-tween the trends of their stock prices in the last hour, while another user would like to know the similarity in the last minute. Under such circumstances, the queries sent from theusersareviewedas range-constrained queries .These queries are of two types, distance queries (e.g., get Euclid-ean distance between two streams V x and V y within [ {&gt; | ] ), and n NN queries (e.g., select n nearest neighboring streams to V x within [ {&gt; | ] ). After receiving the queries, the query processor will compute the answers from the wavelet syn-opses in the main memory.

Since the wavelet coe ! cients sketch the behaviors of data streams in the frequency domain, it is challenging to retrieve the similarity according to the constraint in the time do-main. To process such range-constrained distance queries, a naive approach is using IDWT to reconstruct the orig-inal sequences. For each IDWT operation, it costs R ( Q ) to reconstruct the whole stream. Note that Q is much larger than the limited number of retained coe ! cients, i.e., E .The R ( Q ) complexity of IDWT will induce high over-head in memory and computing power. On the other hand, readers may suggest the conventional approach proposed in [2], which calculates the Euclidean distances from wavelet coe ! cients by using a recursive method. However, the re-cursive algorithm is designed to obtain the Euclidean dis-tance within the full range, i.e., [0 &gt;Q 3 1] , and thus cannot support the queries within an arbitrary range. Moreover, in advanced DSMSs, di erent thresholding methods [6], [7], [11] will be employed to minimize di erent error metrics. Since the conventional approach works only when the fi rst k f wavelet coe ! cients are retained, the issue of compatibil-ity will be encountered. Therefore, it is necessary to sophis-ticatedly design an e ! cient approach to satisfy the require-ments at both client side (arbitrary ranges) and server side (various thresholding techniques).

Consequently, we propose in this paper an e ! cient proce-dure RED (standing for Range-constrained Euclidean Dis-tance) to compute the Euclidean distances within an ar-bitrary range given arbitrary wavelet synopses. RED is basedontherede fi nition of the error tree and the proposed LJulg architecture. Speci fi cally, we fi rst propose a theorem to model the Euclidean distance within the full range. In contrast to [2], this theorem allows us to compute the full-ranged Euclidean distances directly from wavelet coe ! cients without recursion. After that, according to the concept of the complete subtree , we show that the proposed theorem alsoworksgivenaspeci fi c subset of an error tree. Finally, the Euclidean distance between two streams within an arbi-trary range can be computed by using a novel decomposition technique.

Moreover, to process the n NN queries within an arbi-trary range, we also propose algorithm EKS (standing for Enhanced N NN search). It is noted that most of the ex-isting approaches for n NN queries are designed to process data cells in the time domain. Since the wavelet coe ! cients monitors the behaviors of the streams in the frequency do-main, the IDWT should be applied to reconstruct the data cells. However, as we mentioned above, the IDWT-based ap-proach is ine ! cient in computing the Euclidean distances. It will take even more execution time in fi nding n nearest neighbors. On the other hand, although the direct exten-sion of the RED procedure can achieve e ! cient search, all of the relevant coe ! cients (de fi ned as the coe ! cients con-tributing to the range-constrained Euclidean distance) will be accessed before n nearest neighboring streams are found. The EKS algorithm, which is designed to further speed up the searching e ! ciency, is based on the following observa-tions: (a) the wavelet coe ! cients located in the higher level of an error tree tend to dominate the Euclidean distance, and (b) the Euclidean distance between two streams can be viewed as a monotonic aggregation function. In the design of algorithm EKS, we use the partial accumulation rather than the Euclidean distance to score each stream, and al-low the stream with smaller partial accumulation to have higher priority to access the coe ! cients. It is noted that the square root of the partial accumulation can be viewed as the lower bound of the Euclidean distance. When there are n streams with Euclidean distances smaller than the lower bound, the EKS algorithm will stop and return the identi-fi ers of n streams.

To the best of our knowledge, there is no prior research in either processing range-constrained distance queries or searching range-constrained nearest neighbors from the wavelet synopses. Overall, the contributions of this paper are as fol-lows. 1. We explore the issue of processing range-constrained dis-tance queries from wavelet synopses over multiple streams. Compared to the prior research, the proposed method allows arbitrary ranges and can be suitable for various thresholding techniques. 2. We investigate the problem of searching n nearest neigh-boring streams given a reference stream and an arbitrary
Table 1: Wavelet-based multiresolution analysis range. In addition to fi nding exact n nearest neighbors 1 algorithm can also be combined with the existing techniques for approximating nearest neighbors for further speedup. 3. We perform extensive experiments to validate the pro-posed approaches in di erent aspects including the e ! ciency of processing distance queries, the e ! ciency of searching nearest neighbors. The experimental results show that our approaches outperform the naive methods signi fi cantly.
The rest of this paper is outlined as follows. In Section 2, preliminaries including the wavelet basics, the related works and the objectives of this paper are given. In Section 3, we introduce the data structures to retain the wavelet coe ! -cients. In Section 4 and Section 5, the design of procedure RED and algorithm EKS is presented, respectively. The ex-perimental results are shown in Section 6, and fi nally, this paper is concluded with Section 7.
Theoretically, the wavelet transform represents a function in terms of a coarse overall approximation and a series of detail coe ! cients that revise the function from coarse to fi ne. Among all wavelet transform techniques, the Haar wavelet basis representation is the most usual way in decomposing a sequence of data values 2 . The concept of Haar wavelet transform can be best understood by the following example. Example 1: Suppose we have the numerical time series D = { 4,2,6,4,9,6,5,1 } . For multi-resolution analysis, we fi rst average the values pairwisely to get a low-resolution sig-nal. Therefore, we have average values { 3 , 5 , 7 = 5 , 3 } ,where the fi rst two values in D , i.e., 4 and 2 , are averaged to 3 , and so on. To avoid losing any information in the averaging process, the di erence values { 1 , 1 , 1 = 5 , 2 } are also stored. Recursively applying the above pairwise averaging and dif-ferencing process on the lower-resolution array containing the averages, we get the full decomposition shown in Table 1. The wavelet transform of D is the single coe ! cient rep-resenting the overall average of the data values followed by the detail coe ! cients in the order of increasing resolution. Thus, the one-dimensional Haar wavelet transform of D is
In the time series databases, transformations are usually applied so as to reduce the dimensionality of the feature vec-tors. Compared to other transforms, the discrete wavelet
We use the term "exact" to indicate that the nearest neigh-bors discovered by our algorithm are the same as the those by the IDWT-based approach.
For interest of space, the theorem of Haar wavelets is not included in this paper. Interested readers are referred to [15]. transform (DWT) is the most common approach to approx-imate the behavior of a time series due to its low complex-ity and high approximation quality. To search the simi-larity from the wavelet-based time series databases, in [2] and its preliminary version [3], the authors propose an e ! -cient approach to compute the Euclidean distance from Haar wavelet coe ! cients. In their approach, considering that two sequences retain the wavelet coe ! cients for fi rst k f dimen-sions, the Euclidean distance between two sequences can be computed according to a recursive approach from low res-olution to high resolution. In [13], the authors extend the existing similarity searching techniques from Haar wavelets to other wavelet classes. In [10], the authors propose a data structure X-Tree to facilitate the similarity search in the Haar wavelet domain. In [17], the authors implement a gen-eral framework for recent-biased similarity search suitable for various dimension-reduction techniques such as SVD, DFT, DWT, and so on.

On the other hand, searching nearest neighbors e ! ciently is also an important issue in a high-dimensional database. In general, there are two classes in processing n nearest neigh-bor queries. The fi rst class is based on the concept in [14], which applies a spatial data structure (such as R-Tree and its variants) in searching exact nearest neighbors. A rep-resentative of the other class is [1], in which the nearest neighbors are approximated within an error bound. In the time series streaming environments, since the data cells usu-ally come without limit, the conventional approaches for n NN queries cannot be applied directly. In [4], the au-thors combine the existing index structure with a prefetching technique in streaming environments to process continuous nearest neighbor queries, which are the requests for fi nding out the nearest neighbor in an Q -pattern time series data stream. In [8], the authors study the problems of processing reverse nearest neighbor queries in streaming aggregates. In [12], a conceptual partitioning technique is adopted to ef-fi ciently process the continuous aggregate nearest neighbor queries. In [9], the authors investigate the n nearest neigh-boring streams given a predetermined error bound h and propose the DISC technique in searching the neighbors with minimum Euclidean distances. In [16], given a speci fi ctime series, the authors aim at fi nding out the N nearest subseries with predetermined length o t . Although the n NN queries are also processed from the wavelet synopsis, di erent from the problem addressed in this paper, the method proposed in [16] cannot support multiple streams and arbitrary ranges.
In Table 2, the symbols used throughout this paper are listed. Consider P streams with length Q .Weuse g x&gt;l to identify the l -th data cell in the x -th stream. Due to the lim-ited memory, a DSMS transforms these data cells as wavelet synopses. For each stream V x ,letonly E wavelet coe ! cients be retained, where E??Q .Alloftheretainedcoe ! cients form a collection F E . The (full-ranged) Euclidean distance between V x and V y ,de fi ned as [ denoted by gvw ( x&gt; y ) . The range-constrained Euclidean dis-tance between V x and V y within the range [ {&gt; | ] ,de fi ned as [
For ease of exposition, several assumptions are made in this paper. (a) In general, allowing di erent streams to re-tain di erentnumbersofwaveletcoe ! cients will lead to the minimum global error in approximating the data streams. However, since minimizing the error metrics is orthogonal to the main theme of this paper, without loss of generality, we assume that for each stream, the number of retained co-e ! cients is the same. (b) We also assume that each stream is of the same length. The length is a power of 2 . i.e., Q =2 where e is a non-negative integer. To deal with the situation of arbitrary stream length, the proposed approaches in this paper can be extended by combining the frontline structure proposed in [7].

The objectives of this paper are addressed as follows. 1. Given the identi fi ers of two streams x&gt; y and the range of interest [ {&gt; | ] ,we fi rst focus on obtaining the Euclidean distance between V x and V y within [ {&gt; | ] from the wavelet synopses F E . 2. Given the range of interest [ {&gt; | ] ,theidenti fi er of the ref-erence stream x , and an integer n , we further aim at search-ing n nearest neighbors to V x within [ {&gt; | ] from F E
The error tree proposed in [11], is a widely-used structure for exploring and understanding the key properties of the Haar wavelet transform. Given 8 data cells for stream V x Figure 2(a) shows a typical example of the error tree struc-ture. Below the average node q x&gt; 1 are a set of error nodes { q x&gt;l &gt; 2 $ l $ 8 } . Each data cell is represented as a leaf node. The value of each leaf can be viewed as the weighted sum of the coe ! cients from the average node to the leaf, where each weighting factor is equal to either 1 or 3 1 .In the streaming environments, since the data cells are received continuously, the persistent identi fi cation approach shown in Figure 2(a) will not be suitable to represent each node. For example, when the number of leaves increases from 8 to 16 , the error node which was identi fi ed as q x&gt; 8 should be given
To avoid the drawbacks of persistent identi fi cation in the streaming environments, we propose a new de fi nition of each node. Instead of assigning a distinct identi fi er to each node, we use two attributes, the level number and the placement number, to represent the unique location. Speci fi cally, each the s -th placement of level o in the error tree correspond-ingtostream x . An illustrative example of this error tree representation is shown in Figure 2(b). The identi fi cation of the wavelet coe ! cients is based on the following rules. Figure 2: The comparison between the conventional de fi nition and our rede fi nition in an error tree (a) The placement number of the average node of an error tree is set to be 3 1 . (b) For the error node with leaves as direct descendants, the level number is set to be 1 .Forthe error node with level-o nodes as direct descendants, the level number is set to be o +1 . (c) The attribute placement of all nodes except the average nodes is used to record the number of the nodes which appear in a speci fi c level. Consider that there are s nodes in level o .The placement number of the next node appearing in level o is set to be s +1 .
Moreover, to facilitate the description of decomposing an error tree, we view the direct descendant of the average node as the root . Itisalsodi erent from the conventional de fi n-ition in which the average node is regarded as the root. In general, there are several important characteristics in our error tree representation.
Although the wavelet coe ! cients can be stored in mem-ory in an arbitrary order, a causal arrangement of these coe ! cients may cause all coe ! cients to be accessed before the answers to the queries are derived. To process distance queries and to search nearest neighbors more e ! ciently, we propose an interconnected grid structure (denoted by LJulg ) to retain the wavelet coe ! cients. Figure 3 illustrates an ex-ample of the LJulg structure. The LJulg data structure contains two types of indices for sorted access and random access. The horizontal indices connect the coe ! cients be-longing to an identical stream, whereas the vertical indices connect the coe ! cients belonging to an identical category .It is noted that a category is identi fi ed by ( o&gt;s ) ,where o repre-sents the level number and s denotes the placement number. Moreover, the coe ! cients belonging to the same category are sorted according to the stream identi fi ers, whereas the coef-fi cients belonging to the same stream are sorted according to the priority .Thepriorityofacoe ! cient will determine the order for the coe ! cient to be accessed when the distance queries or n NN queries are processed. We use the following rulestoprioritizethecoe ! cients. (a) For coe ! cients be-longingtodi erent levels, the coe ! cients with higher level have higher priority. (b) For coe ! cients belonging to the same level, the coe ! cients with smaller placement number have higher priority.
Given the synopses which contain the wavelet coe ! cients of multiple streams, one of the major objectives in this pa-peristodesignane ! cient approach which computes the Euclidean distance between two streams within the range of interest. An intuitive approach is to compute the Euclid-ean distance in the time domain from the data cells recon-structed by IDWT. However, for each IDWT operation, it costs R ( Q ) .Since Q is much larger than the limited number of retained coe ! cients, i.e., E , the IDWT-based approach su ers from high complexity in memory and time. On the other hand, in [2], the existing similarity searching approach from wavelet coe ! cients cannot handle the arbitrary query ranges. Therefore, in this section, we design an e ! cient procedure RED (standing for Range-constrained Euclidean Distance). We fi rst introduce the theorem behind the RED procedure. After that, the details of designing the RED procedure will be presented. Note that the proofs of all the-orems and lemmas in this paper are given in the appendix. Theorem 1: Let F E represent the coe ! cients retained in the wavelet synopses. The Euclidean distance gvw ( x&gt; y ) can be formulated below. where G
According to Theorem 1, we can obtain the Euclidean distance between two streams from the wavelet synopses without recursion. Moreover, since the wavelet coe ! cients are retained in the LJulg structure, the coe ! cients of each stream will be arranged according to the priority .There-fore, each coe ! cient belonging to V x and V y will be searched at most once. The complexity of computing the Euclidean distance is R ( E ) . Compared to the IDWT-based approach which requires R ( Q ) for inverse wavelet transform, we can signi fi cantly speed up the distance computation. Note that Theorem 1 is based on the assumption that the users are interested in the full range [0 &gt;Q 3 1] of the streams. To enable Theorem 1 to support arbitrary ranges, we introduce the concept of the complete subtree . Several de fi nitions and lemmas will be used to facilitate the description. De fi nition 1: A complete subtree whichisrootedat q ( x ) leaves. Figure 4(a) gives an example of W [ q ( x ) (2 &gt; 1) Lemma 1: Given a complete subtree W [ q ( x ) ( o&gt;s ) ] ,thevalue formulated as: where Example 2: Figure 4(b) shows an example of obtaining Lemma 2: Given the complete subtree W [ q ( x ) ( o&gt;s )  X 
It is noted that a complete subtree follows the character-istics of the whole error tree. Thus, Theorem 1 also holds for each complete subtree. According to Lemma 2, given Figure 4: The illustration of a complete substree and the corresponding average node.
 Figure 5: Algorithmic form of procedure RED V , we can use Theorem 1 to obtain the Euclidean distance between V x and V y within the range [2 o W s , 2 o W ( s +1) 3 1] . However,therangeofinterestmaynotalwaysbelongtoex-actly one complete subtree. Given an arbitrary range, sim-ply applying the complete subtree properties and Theorem 1maystillbeinsu ! cient to obtain the Euclidean distance. Therefore, in the RED procedure, we further design a novel technique to decompose the range into several subranges in such a way that each subrange will correspond to a complete subtree.
 De fi nition 2: Given two streams V x and V y and the range of the coe ! cients which contribute to the range-constrained Euclidean distance gvw ( x&gt; y ) | | { in F E .  X  Lemma 3: Let g x&gt;ohiw _ prvw be the leftmost leaf in a com-plete subtree. If we represent the index ohiw _ prvw as s W 2 where s is an odd non-negative integer and o is a non-negative integer, the maximum number of leaves in the same subtree will be 2 o .  X  Example 3: In Figure 4(a), let g x&gt; 4 be the leftmost leaf in a complete subtree. Since the index 4 can be represented as 1 W 2 2 ,wecan fi nd that the complete subtree W [ q ( x ) result in the maximum number of leaves given that g x&gt; 4 the leftmost leaf. Therefore, the maximum number of leaves is 4 . It is noted that the complete subtree W [ q ( x ) (1 &gt; 2) in fewer leaves, whereas the complete subtree W [ q ( x ) con fl ict with the fact that g x&gt; 4 is the leftmost leaf. The algorithmic form of procedure RED is outlined in Figure 5. Given an arbitrary range [ {&gt; | ] ,theinsightof procedure RED is to decompose the range into several sub-ranges in such a way that each subrange will correspond to a complete subtree. When we are decomposing the range [ {&gt; | ] , the challenge is to determine whether a set of leaves belong to the same complete subtree or not. A casual so-lution which examines the leaves one by one will lead to R ( Q ) complexity, and is thus impractical. To resolve this problem, based on Lemma 3, we design the function Pre-dictLength. Given the leftmost leaf in a complete subtree, we can fi nd all the other leaves belonging to the same com-plete subtree at the cost of R (log Q ) with the PredictLength function employed. During the execution of the RED pro-cedure, the index of leftmost leaf, denoted by ohiw _ prvw , is set to be { initially. Once the leaves belonging to the same subtree are determined, ohiw _ prvw will be updated. Procedure RED will be executed iteratively until all of the leaves in [ {&gt; | ] are decomposed into several subtrees. These subtrees form a WuhhVhw .The relevant coe ! cients will be obtained according to the WuhhVhw . Finally, the RED proce-dure will compute the range-constrained Euclidean distance accordingtotherelevantcoe ! cients.
In this section, we aim at developing an e ! cient approach in searching n nearest neighboring streams from the wavelet synopses. Given a reference stream V x and a predetermined range [ {&gt; | ] ,the n NN searching problem is the problem of e ! ciently retrieving n streams which have the minimum dis-tance from V x within [ {&gt; | ] . In the streaming environments, the issue of e ! ciency will be even critical due to the real-time requirement in many applications. In order to process n NN queries on wavelet synopses, a naive approach is to calculate the Euclidean distance from the reference stream to all the other streams using IDWT and select the n streams with smallest distance. However, as we mentioned earlier, using IDWT will incur high overhead in computing the Euclidean distance. To resolve this problem, we introduce two e ! cient n NN searching approaches based on the LJulg structure and the RED procedure.

The fi rst algorithm is named BASIC, standing for n NN search with basic quality. The algorithmic form of BASIC is outlined in Figure 6(a). The BASIC algorithm reme-dies the naive approach by using the RED procedure when the Euclidean distances are computed. Compared to the naive approach, the BASIC algorithm achieves better ef-fi ciency. The complexity of BASIC can be formulated as R ( P log P ( E +log 2 Q )) since it costs R ( P ( E +log 2 Q )) to compute the Euclidean distance of P 3 1 candidate streams and R (log P ) for the insertion operation in the heap struc-ture used in Figure 6(a).

It is noted that in the BASIC approach, all of the relevant coe ! cients will be accessed before n NN search is completed. However, under many circumstances, we can still derive the exact n nearest neighbors without reading all relevant co-e ! cients in wavelet synopses. The reasons are based on
Figure 6: Algorithmic form of BASIC and EKS the following observations. (a) As mentioned in Theorem 1, since the square of the di erence is multiplied by 2 o coe ! cients with high levels tend to dominate the Euclidean distance. (b) In Eq. (1), the Euclidean distance between two streams can be viewed as a monotonic aggregation function appropriate lower bound when accumulating the Euclidean distance. Once there are n streams with Euclidean distances smaller than the lower bound, we judge that these entities are n nearest neighbors even if the Euclidean distances of all the other streams are still unknown.
 De fi nition 3: The partial accumulation between V x and V coe ! cients.  X  Lemma 4: Given a set of candidate streams { V l } ,aref-erence stream V x and the range of interest [ {&gt; | ] , suppose that each candidate stream V l corresponds to a partial ac-cumulation sd ( l&gt; x ) | | { .Let Plq =min ( gvw ( l&gt; x ) | | { ) 2 D Plq for each V l .  X 
We propose the second algorithm EKS (standing for En-hanced N NN Search) based on Lemma 4. The algorithmic form of EKS is outlined in Figure 6(b). In algorithm EKS, we use partial accumulation to score each stream in order to achieve enhanced quality in e ! ciency. In the beginning, all of the streams except the reference stream V x are viewed as candidate streams .Inthe LJulg structure, all the average nodes of each stream will be computed so as to initialize the partial accumulation. After that, the EKS algorithm will proceed to access the next relevant coe ! cient of the candi-date stream with minimum score, i.e., V l _ min .Notethat once a new coe ! cient is accessed, the partial accumulation of V l _ min will be update accordingly. This procedure will be executed iteratively. During the execution, if all relevant co-e ! cients of a stream have been accessed, the partial accumu-lation is equal to the square of the Euclidean distance. This stream will be removed from the list of candidate streams and become one of the solution streams . Note that each solution stream is one of the n nearest neighbors to the ref-erence stream. The reason is addressed as follows. When one stream V l _ min becomes a solution stream, it implies that ( gvw ( l _ min &gt;x ) | | { ) 2 $ min { sd ( l&gt; x ) | to Lemma 4, we have gvw ( l _ min &gt;x ) | | { $ gvw ( l&gt; x ) | candidate stream V l .Since V l _ min leads to the minimum Euclidean distance among candidate streams, V l _ min is one of the n NN solutions as long as the number of existing so-lution streams is smaller than or equal to n .Oncethere are exactly n solution streams, the EKS algorithm will halt and return these n entities and the corresponding Euclidean distances.

The advantageous features of algorithm EKS are as fol-lows. (a) For solution streams, EKS will access all relevant coe ! cients to obtain the Euclidean distances. For candidate streams, EKS will only access part of relevant coe ! cients. Therefore, EKS searches n nearest neighbors without redun-dancy. (b) There is no approximation error between EKS and the IDWT-based approach in processing NN queries. (c) For further speedup, EKS can easily be combined with the existing techniques for approximating nearest neighbors. Due to the characteristics of the LJulg structure, the coef-fi cients which tend to dominate the Euclidean distance will have high priority to be accessed, which enables the partial accumulation to approximate the Euclidean distance very accurately.
To validate the proposed approaches for distance queries and n NN search, we have conducted extensive experiments. In this section, the experimental results will be shown. The simulation environment will be presented in Section 6.1. In Section 6.2, we will evaluate the performances of the RED procedure. In Section 6.3, we will compare algorithm EKS with other competitive approaches.
We use the real dataset, denoted by STOCK to evalu-ate the e ! ciency of RED and EKS. The STOCK dataset monitors the stock prices of 234 major companies in Taiwan from Jan. 3rd, 2005 to Mar. 31st, 2005. The stock prices of each company were sampled every 10 seconds. We im-plement the relevant approaches using Java language, and execute the programs on an IBM compatible PC with Pen-tium IV 3.2GHz processor and 1GB RAM. To select the rep-resentative wavelet coe ! cients, we employ the thresholding techniques in [5][15], which aim at minimizing the O 2 -qrup average error . During the experiments, since di erent ap-proaches will result in the same answers to the queries, we only report the execution time (in millisecond) in exponen-tial scale to re fl ect the e ! ciency of each approach.
To evaluate the performances of the RED procedure, we measure the aggregate execution time of processing 1000
Figure 10: Performances of EKS with n varied range-constrained distance queries which are generated ran-domly. We compare the RED procedure with the IDWT-based approach, denoted by IDWT, in which the Euclid-ean distances are computed in the time domain after using IDWT to reconstruct the data cells. Figure 7 shows the ex-perimental results of procedure RED with the parameter E varied from 100 to 500. We observe that procedure RED is about an order of magnitude faster than the IDWT-based approach. This phenomenon can be explained according to the complexity of each approach. For the IDWT-based ap-proach, it costs R ( Q ) to reconstruct the data cells and com-pute the Euclidean distance. On the other hand, the total complexity of procedure RED is R ( E +log 2 Q ) . Therefore, since E is much smaller than Q , procedure RED will out-perform the IDWT-based approach signi fi cantly.

To evaluate the capability for the RED procedure to de-compose the query range [ {&gt; | ] , we use a parameter U to denote the length of the query range. Speci fi cally, the range of the randomly generated queries are of di erent lengths at di erent values of the parameter U . Figure 8 depicts the performance of the RED procedure with the parameter U varied. We have several observations as follows. First, the execution time of the IDWT-based approach remains almost thesameevenifthevalueof U increases, which is di erent from our intuition that it will take more execution time to compute the Euclidean distance with a longer length. The reason behind this phenomenon is that the complexity of re-constructing the whole data cells (i.e., R ( Q ) ) is much larger than that of computing the Euclidean distance (i.e., R ( U ) ). Therefore, the e ! ciency will be dominated by the inverse discrete wavelet transform. Second, for the RED procedure, the e ! ciency will depend on the length of the query range. Since the range-constrained queries are generated randomly, di erent ranges may be decomposed into di erent numbers of complete subtrees. On the average, smaller ranges will result in fewer decompositions. Thus, it will take less exe-cution time under the circumstances of smaller U .
In the second experiment, we use di erent approaches to search range-constrained n nearest neighbors from the wavelet synopses. We compare the proposed approaches Figure 11: Performances of EKS with P varied BASIC and EKS with the IDWT-based approach, in which the n nearest neighbors are obtained after the Euclidean distances from all candidate streams to the reference stream are calculated in the time domain. During the experiments, several parameters including the number of retained coe ! -cients E , the number of solution streams n ,andthenumber of candidate streams P , are varied so as to evaluate the per-formances of the proposed approaches. The average execu-tion time is measured after processing 20 range-constrained n NN queries.

Figure 9 shows the performances of the proposed approaches with the parameter E varied. It is e ortlesstoexplainwhy the IDWT-based approach result in the longest execution time. On the other hand, since algorithm BASIC directly extends the concept of the RED procedure, the BASIC algo-rithm outperforms IDWT signi fi cantly. Among all searching approaches, the EKS algorithm achieves the best quality in e ! ciency. Moreover, as the number of retained coe ! cients increases, the execution time of EKS remains almost the same. It is because the EKS approach avoids the access to the redundant coe ! cients during the n NN search. Even if E increases, the Euclidean distance between two streams are still dominated by a small part of coe ! cients. Therefore, the advantage of EKS over BASIC will be more signi fi cant as E increases.

Figure 10 depicts the performances with the parameter n varied. For the IDWT-based approach and the BASIC algorithm, the searching policy is to access all relevant co-e ! cients. Therefore, the execution time remains the same no matter how many nearest neighbors are searched. As for algorithm EKS, the execution time will depend on how many nearest neighbors should be searched. The reasons are as follows. In the searching policy of the EKS algorithm, theEuclideandistancewillbecomputedonlyfor solution streams . For the remaining candidate streams , the partial accumulation will be maintained. As the number of solution streams increases, more coe ! cients will be accessed. There-fore, it will take more time for algorithm EKS to search more nearest neighbors.

In Figure 11, the impact of the parameter P is shown. We fi x the number of solution streams to be 10 , and measure the execution time with the number of candidate streams varied. We observe that for IDWT and BASIC, the exe-cution time increases linearly as the value of parameter P increases. This phenomenon agrees with our intuition since more candidate streams will lead to larger searching space. Unlike IDWT and BASIC, the EKS algorithm is insensitive to the variance of P .Speci fi cally, as the number of candi-date streams increases, it will take almost the same time for EKS to fi nd out the n nearest neighboring streams. This experiment shows that the proposed EKS algorithm is very scalable in searching nearest neighboring streams from the wavelet synopses.
In this paper, motivated by the fact that a user may be in-terested in an arbitrary range of the data streams, we initiate the study of range-constrained similarity search and explore theproblemsofprocessingtwotypesofqueriesintimese-ries streaming environments: the range-constrained distance queries and the range-constrained n NN queries. We fi rst propose procedure RED, which is capable of decomposing an arbitrary range into several subsequences corresponding to di erent complete subtrees, to perform similarity search. After that, we design an e ! cient algorithm EKS, in which we use the partial accumulation to evaluate the data streams during the n NN searching procedure. In the experimental results, we show that RED and EKS outperform the compet-itive methods signi fi cantly, which justi fi es the practicability of the proposed approaches in processing range-constrained distance queries and n NN queries from the wavelet synopses over multiple streams. Proof of Theorem 1: We prove this theorem by induction.
Base Case : Consider Q =2 . We can use an error tree to represent the data cells for each stream. The Euclidean Dis-tance between V x and V y canbeformulatedas gvw ( x&gt; y )= [( g for l M { x&gt; y } . We can rewrite the square of Euclidean dis-tance as Sincesomeofthewaveletcoe ! cients may not retained in the synopses, we obtain
Induction Step : Suppose that Theorem 1 holds for Q = 2 .When Q =2 O +1 ,we fi rst decompose each stream into two substreams with Q =2 O . We can obtain gvw ( x&gt; y ) ( gvw ( x&gt; y ) | 2 O 3 1 0 ) 2 +( gvw ( x&gt; y ) | 2 O +1 error trees. For each stream, we can use two error trees to represent the data cells within [0 &gt; 2 O 3 1] and [2 O respectively. Thus, gvw ( x&gt; y ) | 2 O 3 1 0 and gvw ( x&gt; y ) | be derived using Eq. (1). Let U ( l ) {&gt;| denote the average node of the error tree corresponding to the subsequence [ {&gt; | ] of stream l . Therefore, the square of Euclidean distance can be formulated as Since the two ranges are of equal length, the two error trees can be merged into a new one. During the mergence op-eration, the two average nodes will be merged as one new q on the concept similar to the base case, Eq. (3) can be rewritten as This completes the induction step, which shows that The-orem 1 holds for any Q =2 O ,where O is a non-negative integer. Q.E.D.
 The work was supported in part by the National Science Council of Taiwan, R.O.C., under Contracts NSC93-2752-E-002-006-PAE. [1] S.Arya,D.M.Mount,R.Silverman,andA.Y.Wu.
 [2] F.K.-P.Chan,A.W.-C.Fu,andC.Yu.Haar [3] K.-P. Chan and A. W.-C. Fu. E ! cient Time Series [4] L. Gao, Z. Yao, and X. S. Wang. Evaluating [5] A.C.Gilbert,Y.Kotidis,S.Muthukrishnan,and [6] S. Guha and B. Harb. Wavelet Synopsis for Data [7] P. Karras and N. Mamoulis. One-Pass Wavelet [8] F. Korn, S. Muthukrishnan, and D. Srivastava. [9] N. Koudas, B. C. Ooi, K.-L. Tan, and R. Zhang. [10] I. Liabotis, B. Theodoulidis, and M. Saraaee. [11] Y. Matias, J. S. Vitter, and M. Wang. Wavelet-Based [12] K. Mouratidis, M. Hadjieleftheriou, and D. Papadia. [13] I. Popivanov and R. J. Miller. Similarity Search Over [14] N. Roussopoulos and S. K. F. Vincent. Nearest [15] E. J. Stollnitz, T. D. Derose, and D. H. Salesin. [16] C. Wang and X. S. Wang. Supporting Subseries [17] Y. Zhao and S. Zhang. Generalized
