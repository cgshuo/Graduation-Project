 The use of terminological systems for the creation of ontologies raises several major issues (Garc  X   X a-Silva et al., 2008). Obviously, ontologies and ter-minologies play a similar normative role. They aim at establishing a common vocabulary and make use of shared representations and concepts to allow the documents interoperability and facili-tate knowledge building. However, ontologies and terminologies have clearly a different formal ap-proach on Semantics. Ontologies are concepts ar-chitectures and are not organized lists of terms . Unlike terms, the concepts are characterized by formal definitions . The formal aspect enables the computerized treatment of the information. To use an ontology to normalize a document is, in that sense, to encode it by bringing a characteristic al-lowing the automated treatment of the informa-tion.

However, the creation of ontologies involves sometimes the use of terminologies, or even more radically, the use of corpus of text. If the ontology is to be integrated within an automated informa-tion treatment system, as for example the informa-tion retrieval (IR), the concepts should match with the terms appearing on the documents to enable the information treatment. The ontology should ensure the coverage of the terminological domain . The conceptual representation would otherwise be unusable.

The Lerudi (emergency services) Project in-tends to develop an Information System (IS) offer-ing an overview of the Electronic Health Record (EHR) to the health professionals. Additionally, it aims at facilitating the quick reading of the EHR to allow quick medical decisions under tight time constraints. The field experimentation of that project is the reading of hospital files by an emer-gency regulating physician. Practically, Lerudi is IR system based on a Termino-Ontological Re-source (TOR) 1 named O NTOL U RGENCES . The TOR (a) plays the field model role by listing the relevant concepts; and (b) ensures the link be-tween the concepts and their name in the EHR documents. This double function should not only enable an easy annotation and indexation of the patient files, but also facilitate the retrieval of in-formation from the indexed records.

The O NTOL U RGENCES development included 6 phases: (i) the building of the TOR ontological skeleton based on a corpus analysis method; (ii) the use of existing terminological and ontological resources to manually complete the TOR concepts system; (iii) the automatic enhancement and (iv) semi-manual TOR enhancement at the terms level; (v) the TOR enhancement of concepts in relation to the medicines; and finally, (vi) the implementa-tion of validation and quality control procedures.
The first 2 phases of the TOR correspond to the usual ontology construction method, widely tried in our team and did not raise major issues. However, the 3 following phases that were spe-cific to the TOR development were much more problematic. Specifically, the TOR terminological enhancement required external resources: Knowl-edge Organization System (KOS). These external resources are only useable in an architecture sup-porting a complex modeling of the target TOR. In particular, the architecture should accommodate the terms, the concepts and their interrelation, and simultaneously, the KOS used for the enhance-ment. The last stage corresponding to the qual-ity control is also specific to this project and was necessary considering the various participants in-volved in the TOR construction.

Trough the detailed description of the pro-cess guiding this TOR construction and validation within a large team, we aim at showing that: (i) the sustainability of such a resource requires a concise articulation between terms and concepts; and (ii) such a requirement can be met via the implemen-tation of standardized procedures based on a meta-model architecture allowing the modeling of all necessary KOS and other knowledge structures. The rest of the paper is organized as follows: Section 2 briefly presents the advantages of us-ing ontologies for retrieving information. The first two steps of the TOR construction and its speci-ficities are presented in Section 3. Section 4 pro-vides an overview of the UniMoKR model that enables the implementation of the TOR termino-logical and conceptual enhancement procedures; and its uses. Section 5 describes the TOR different enhancement phases 2 . The validation and quality control are detailed in the section 6. Finally, the paper concludes with a summary and a discussion in Section 7. To begin with, we should ask ourselves what the point in using an ontology for an IR is. Specif-ically, the main advantage of an ontology is to allow an automated reasoning based on the con-ceptual structure and semantic relations between notions. Consequently, in addition to subsump-tion relations ( is-a formal relation ), we modeled the semantic relations between signs, diseases and medical specialties. These relationships enable an interface ( i.e. a cloud of words) to display the medical specialties that characterize a given EHR.
An ontology for IR has also de facto , as any ontology, a structure that depends on the task (Charlet et al., 1996; van Heijst et al., 1997). This structure is not a quality in itself for the IR, but it nevertheless has two advantages: (i) a well-structured ontology is easier to maintain than a poorly structured ontology, (ii) a well-structured ontology enables valid reasonings. This second point is obviously expected from any ontology, but it is clear that it is not always satisfied. Another important property that has to possess an ontol-ogy for IR is the coverage of the terms relevant to express the notions of the target-domain. The fol-lowing two examples will illustrate these points: Example of the importance of the formal structure Example of the importance of the terminological
It appears clearly that, the quality of the infor-mation displayed to the final user of the IR system crucially depends on the quality and richness of the TOR. The processes of annotation, indexing and inference rely on the formal structure and the terminological completeness ( i.e. its capacity to cover the terms of the domain). The figure 1 be-low illustrates the different uses of the TOR in the Lerudi project. 3.1 Domain of O NTOL U RGENCES O
NTOL U RGENCES has been built in several steps and by using different resources, and its tar-get knowledge field has been clarified gradually. From the very beginning of the project, we real-ized that the knowledge field that had been orig-inally set for the TOR (that is: the repertoire of concepts that had to be present in the TOR ) had to evolve. We had left with the idea of building an ontology representing only the specific concepts used by the emergency physicians. But it turned out that, from the perspective of information re-trieval in EHRs, such restriction a priori of the tar-get knowledge field was a mistake. Indeed, the information system aims to allow the emergency physician to quickly find medically relevant con-cepts in EHRs. But these concepts can not be re-duced to concepts specific to the medical emer-gency field, they can instead meet any medical specialty .

In the paragraphs below, we present the main phases of the development of O NTOL U RGENCES and the terminological and ontological resources we have used. We do not discuss the problem of the organization of these stages and cycles of development. For this question, we may refer to (Dhombres et al., 2010).Suffice it to say that during the development process of O NTOL U R -GENCES , we followed the A RCHONTE method de-veloped by B. Bachimont Bachimont et al. (2002). 3.2 The processing of textual data In the A RCHONTE method, the domain ontology is built on the analysis of documents generated during the activity to be modeled. In our case, we have encountered great difficulties in access-ing a corpus that could perform this function. The emergency services being not computerized, and the paper documents shorter and less numerous than in other services, it was difficult to find docu-ments in sufficient numbers to make up the corpus in question.

Consequently, we used two other kinds of docu-ments: the acts of the Urgences conference of the discipline and the Guides to Good Practice . Be-sides the difficulty we had to preprocess the cor-pus, the main problem was the coverage capac-ity of the corpus compared to the target. Indeed, the corpus of the conference proceedings, that was fully processed, has shown its limits in terms of scope. Conference papers are in many cases con-cerned with the  X  X are bird X , that is with questions that are not representative of the problems that emergency physicians are confronted daily. A spe-cific work has shown this clearly by comparing the terms most frequently detected in the corpus with the actual incidence of the emergency dis-eases (Gayet et al., 2010).

This issue of availability of the corpus should not be underestimated: in the areas where we can base the construction of the ontology on a corpus analyzed by tools of natural language processing (NLP), resorting to existing terminologies oper-ates in the validation process of the work having been done. In the case of interest here, they occur much earlier in the development process. 173 3.3 Reusing the specialty thesaurus For the PMSI 3 coding, the emergency physicians make use of an CIM-10 extract which contains about 1,000 terms. These terms covering an im-portant part of the terminological repertoire used by emergency physicians for coding, it appeared necessary to incorporate them in the ontology. Consequently, a concept was created and defined for each of them.

One of the major limitation of the project is the fact that the CIM-10 terms are suitable for cod-ing, but some of them are difficult to manage in an ontology because they encompass several het-erogeneous concepts. For example, one can find terms such as  X  X ubject waiting to be admitted else-where, in a suitable establishment X  or  X  X ymptoms and signs involving cognitive functions and con-sciousness, other and unspecified X . The concepts associated with such terms, because they articulate in a complex way a multitude of heterogeneous concepts, are difficult to model. 3.4 Reusing the CCAM The french CCAM classification (commune clas-sification of medical acts) has the benefit of having been designed by teams familiar with ontologies. Which means a priori that each concept of this classification has been validated by a formal rep-resentation (Rodrigues et al., 1999). The reuse of the CCAM thus enabled us to incorporate a clas-sification made up in accordance with consistent principles to our TOR.
 The problems rather came from the way the CCAM is organized and designations used for the acts, which are built for specified accounting poli-cies and not at all suitable for their expression in medical documents -our target. Much work has thus consisted in renaming the terms associated with concepts ( cf.  X  3.6). 3.5 Reusing the SNOMED V3.5 The creation of the branch of diseases concepts is always a major part in the constitution of medi-cal ontologies. As the necessary corpus for the design of such a branch were not available or did not cover the whole area, we decided to complete the work by integrating in O NTOL U RGENCES the diagnoses branch of the S NOMED V 3.5 4 . This procedure was mainly carried out by physicians and required more than 100 hours of work: The S
NOMED V 3.5 was notoriously too specific -what could be expected -but appeared also very badly organized -which was quite surprising. From the 25,000 diseases present in the The S NOMED V 3.5, 6 500 have been preserved. 3.6 Additional methodological comments To complete the description of the construction of O
NTOL U RGENCES , a few points of clarification are further needed: 1. O NTOL U RGENCES was developed with the 2. The SKOS 5 language was used for the for-3. The resources used in the construction of on-4. The concepts of the ontology can be distin-The O NTOL U RGENCES ontology provides a con-ceptualization of the emergency field with terms to designate its concepts. This conceptualization can benefit from (i) the terms present in the KOS of Health to increase the detection of concepts in documents processed and from (ii) specific con-cepts about drug molecules in the ATC classifi-cation. To develop this new resource, you must be able to represent the KOS and ontology at the same level of description. Indeed, these resources are available in different formats and languages. 4.1 The UniMoKR metamodel The diversity that exists in the nature, represen-tation, and organization of the knowledge can be explained by different pasts, objectives, and uses. However, these KOS always intend to grasp infor-mation, to share it, and to support the human and computised processing. Thus, it is possible to ex-tract a common model core from this obvious het-erogeneity (i.e. a model common to all knowledge structuring). In the field of knowledge organiza-tion system representation, some norms and stan-dards are in place and facilitate the interoperability (Miles, 2006; Clarke, 2008). Although SKOS and BS 8723 allow terminologies representation, none of them adress the issue of concepts group in a satisfactory manner 6 . We reuse in this project, the UniMoKR model designed in our previous work (Vandenbussche and Charlet, 2009) 7 . This model uses and extends modeling elements from SKOS, BS 8723 and is already used by research and com-mercial projects (Joubert et al., 2011; Vandenbuss-che et al., 2013).

The Termino-Conceptual part of UniMoKR model describes the relation between a Concept and its related Preferred Term and Simple non pre-ferred Terms (aka synonyms) in each language. The Group Part enables not only the representa-tion of a whole terminology, but also the repre-sentation of a terminology subset. It allows two different ways to characterize membership: by in-tension (concepts have to meet the restriction re-quirement to be part of a group; all concepts an-swering this request are implicitly members of the group) and by extension (concepts have to ex-plicitly refer to this group via the relationship in-Group ) Our modeling reified the SKOS original alignement relations and allows alignments repre-sentation generated by various sources as well as the representation of the associated metadata in-formation. Finally, meta-classes intend to guar-anty the UniMoKR model extensibility and to fa-cilitate its re-use and adaptation: some artifacts particular to some terminologies are not taken into account in UniMoKR; however, they need to be represented to avoid the loss of information. As mentioned above, for the Lerudi information system to be operational in situation, it is nec-essary that the TOR O NTOL U RGENCES covers almost all linguistic forms under which medical concepts relevant for emergency decisions appear in the EHR the system will have to deal with. Ultimately, the system must also be able to ac-commodate the  X  X hortcuts X  and  X  X mperfections X  of the language in which patient records are writ-ten, which for instance make use of abbreviations or may simply contain spelling errors.

The overall Lerudi system works as follows: the text of the various documents comprised in the EHR is processed by an algorithm that seeks to es-tablish a correspondence (if necessary, by integrat-ing NLP methods) between the phrases (treated as mere strings) and the system of concepts of the TOR. If a string has been matched with a concept, the concept will be used to index the document.
Now, medical records are usually written in nat-ural language (or at least in this semi-standardized language suitable for concrete medical activities), 175 for the semantic interpretation process to reach a satisfactory level (or an optimal one: the opti-mum being set by the performance attained by an emergency physicist), it is often necessary to have available all lexical variations (synonyms, short forms, etc.) that may present the textual form of the concept. If a form encountered in the EHR has not been specified in the ontology, the record will not be indexed with the corresponding con-cept. The medical term will not be displayed by the interface. The emergency physicist will then have to put up with an incomplete or incorrect in-formation.

To overcome this problem, two terminologi-cal enhancement processes of the TOR have been performed: (i) an automatic enhancement of the TOR by the adding of terms extracted from var-ious KOS; (ii) a semi-automatic enhancement of the TOR by the adding of noun phrases extracted from the EHRs. 5.1 Enhancement of the TOR through the A first version of the enhanced TOR is realized through the aligment of the emergency domain on-tology with few KOS relevant for the field, includ-ing CIM-10, SNOMED 3.5, MedDRA, ATC. By providing a controlled vocabulary, the KOS sup-port the functions of analysis (annotation) of the EHRs. But, du to the difficulty to validate align-ments, we decide to keep just the alignment to S
NOMED V 3.5. The alignment was performed with the alignment software O N AGUI (Mazuel and Charlet, 2010) 8 and by manually validating all the automatic alignments made.

Finally, during an export phase, the TOR, now optimized for annotation and indexation, is made available in the SKOS format. Once the concepts of the ontology enhanced with lexical forms from the KOS, the representation model of the TOR is converted to SKOS. This operation of conver-sion is performed with the model transformation method described at the section 4.1. 5.2 Enhancement of the TOR through the To improve the terminological completeness of O
NTOL U RGENCES TOR, a complementary semi-automatic enhancement procedure was intro-duced. This procedure incorporates the principles of the bottom-up methodology used by the design-ers of domain ontologies. It includes the follow-ing steps: (i) we first analyze with NLP tools the content of the documents produced by the oper-ating health professionals ( i.e. the EHRs), in or-der to extract (this time by mobilizing statistical methods) the noun phrases likely to be among the most structuring of the considered field of knowl-edge, that is the terms that are specific and essen-tial to the field; (ii) Once these terms are identi-fied, health professionals (emergency physicians): A) perform a filtering operation to retain only the terms actually belonging to the medical field and likely to be clinically relevant during the process of IR in EHRs and B) validate the relevance of the identified synonymous terms; (iii) these terms are then: A) added as synonyms ( skos:altLabel tag) when they meet medical concepts already present in O NTOL U RGENCES TOR, or B) con-verted into new concepts, when they refer to no-tions that do not yet have a conceptual representa-tion in the TOR (in that specific case these terms correspond to the so-called candidate-terms of the bottom-up methodology. This conceptual conver-sion step requires to produce a formal definition of the concept being considered, which means firstly positioning the concept in the existing ontological hierarchy. 6.1 Why using validation procedures? After one year of work, it appeared that the imple-mentation of control procedures was necessary to maintain the quality of O NTOL U RGENCES TOR, and that these procedures had to be replayed reg-ularly. Indeed, (i) many stakeholders, physicians as well as modelers, are working together on the ontology, and despite all our efforts, we have not always been able to correctly apply the guidelines for the maintenance of quality and the homogene-ity of the TOR. In addition, (ii) many instructions are binding and a person may apply them one day and forget them another.

In a first step, these procedures do not address the structure of the ontology. The main reason is that at this level of development of the TOR and given the skills of the team, the problems we encountered were first terminological problems. But it is clear that problems of structuration, also 176 present, call for future treatments ( cf. 7). Our procedures are based on patterns, or anti-patterns when managing mistakes to be avoided. This work falls under the current research area concerned with the control of the quality of ontologies, as can be read on more structural points in (Roussey et al., 2010) or (Rector et al., 2004). 6.2 Which meta-model? The quality control procedures were designed to ensure that the TOR meets the criteria of a spe-cific meta-model. As far as this part is concerned, the meta-model can be expressed by the list of fol-lowing rules:  X  Each concept must carry an annotation  X  ter- X  Each terminological concept ( cf. previ- X  Each terminological concept must have zero  X  Due to the IR algorithms functioning, 6.3 The procedures The procedures are implemented by uploading the ontology to a SESAME store, and via SPARQL requests. Consequently, the quality criteria are verified in the triplestore :  X  Each terminological class must have a pre- X  Each class must have one, and only one, pre- X  Each prefLabel must be associated with a  X  Each altLabel must be associated with a lan- X  Each class must carry a hiddenLabel.  X  Each class must carry only one hiddenLabel  X  Two classes must have the same prefLabel for  X  Two classes must not have the same altLabel  X  Two classes must not have the same hidden- X  Two classes must not have one identical pre- X  Tracking of multiple parent classes. The  X  Additional requests. Most of the additional Lerudi is a project that applies a specific method-ology to the requirements of the medical emer-gency environment. The goal of this project is to build a TOR capable of retrieving information ef-ficiently. Trough the complete description of the building process and the TOR validation in a large team, we have shown that: (i) concepts and terms must be precisely articulated within such a re-source; (ii) the developed meta-modeling architec-ture must allow the modeling of all necessary KOS and other knowledge structures; (iii) standardized procedures based on this architecture may be im-plemented to enable the modeling.

Finally, the integration of the KOS in the same format and the RDF transformation service (ca-pable of operating pre-treatments) allow to gener-ate a termino-ontological resource with a lexical-ization able to carry out the annotation, inference 177 and indexation actions of the patients files. This project demonstrates the possibility to accommo-date multiple KOS and to provide an efficient re-source based on different request and transforma-tion treatments.

