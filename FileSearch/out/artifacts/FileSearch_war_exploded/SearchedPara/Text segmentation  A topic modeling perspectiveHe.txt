 1. Introduction
On several occasions, information needs of a user can be reasonably satisfied by presenting only the relevant part(s) of a document, and presenting the whole document may result in information overload. In information retrieval (IR), passage a set of passages are retrieved. In this context, estimating passage boundaries reliably in an unsupervised manner is a key step in performing IR at the segment level.
 Linear text segmentation is the task of dividing a given text data into topically coherent segments ( Allan, Carbonell, very useful for browsing/retrieval. In a normal setting when no text segmentation is performed, if a user needs to access a segmented (either manually or automatically) into stories and labeled, the relevant story can be retrieved directly. Text segmentation can also improve a user X  X  retrieval experience by segmenting a document into topics and subtopics, and presenting only the relevant parts of the document during a search operation. Text segmentation assumes importance in text summarization and discourse analysis (the detection of topic changes) as well ( Hearst, 1997 ).  X 
Several approaches have been proposed in the past to perform this task. Most of the unsupervised approaches exploit lex-ical chain information, the fact that related or similar words tend to be repeated in topically coherent segments and segment boundaries are often linked to a change in the vocabulary ( Choi, 2000; Hearst, 1997; Kozima, 1993; Malioutov &amp; Barzilay, et al. (2004) , repetition being one among them. These approaches typically do not require a training phase (and data), and can be directly applied to any text from any domain, subject to the only constraint that word boundaries can be identified.
These approaches may fail to produce reliable segment boundaries if the word repetition is avoided by design. variation of these approaches (to overcome the issue of non-repetition because of words being replaced by synonyms or hyper-is that even when the segment boundaries are estimated correctly, the segments are not associated (labeled) with any topic information.

In order to overcome these limitations of the lexical chain approaches, this paper proposes a new methodology for text segmentation that builds upon unsupervised topic modeling techniques. The two topic models investigated in this paper are trained and then used to segment running texts. During training, the models learn the semantics information from the data-set and hence do not rely on mere word repetitions to segment the text. This is a departure from the lexical chain approaches that are typically knowledge-free. Our proposed approach for text segmentation using topic models also differs from the lexical chain approaches in that the proposed approaches  X  X  X ointly X  X  perform segmentation and topic labeling (outputs the topic distribution associated with each segment). An expected benefit of these approaches is their ability to identify of this topic estimation process is that it increases the computational cost of the entire process by several orders of magnitude.

The main objective of this study is to investigate whether text segmentation can be achieved from a topic modeling per-spective. The empirical contributions of this paper for text segmentation task are manyfold:
We demonstrate that the topic model based approaches proposed in this paper yield a better performance than the stan-dard baseline technique proposed in Utiyama and Isahara (2001) , provided that in-domain data is available for training the topic models. Our study also provides new insights into the strengths and weaknesses of the methods.
We also introduce a modification to the dynamic programming (DP) algorithm that results in a substantial reduction in computational cost associated with topic model based text segmentation approaches. This makes topic modeling a viable alternative even when the document needs to be segmented online. The proposed modification is not specific to the topic model based methods only; it can be straightaway applied to all other methods that use DP for text segmentation task.
The proposed methods are first evaluated on a standard dataset. Later, a bigger and more realistic dataset is designed to do an in-depth investigation of the issues associated with the text segmentation task. Finally, we validate and reconfirm the findings of this paper on a third dataset which was a part of TRECVid 2003 evaluations.

The rest of the paper is organized as follows: In Section 2 , we briefly review extant approaches to linear text segmentation and relate our methodology with state-of-the-art techniques. In Section 3.1 , we recall the main aspects of two topic models, first LDA and then MM, along with their training and testing procedures. In Section 4 , we recall the principles of dynamic programming (DP) for text segmentation, first reviewing the method proposed by Utiyama and Isahara (2001) , one of the most successful approaches to date, and then explaining how to adapt these principles when fragments are scored under the two topic models. In Section 5.3 , we compare the performance of the three methods on Choi X  X  benchmarks ( Choi, 2000 ). We then investigate these methods on a larger dataset derived from the Reuters News Corpus Volume 1 (RCV1) data-weaknesses of all the approaches. We revisit the (DP) algorithm and analyze it in Section 6 , proposing a solution which brings a significant reduction in the computational cost when using DP for text segmentation task. In Section 7 , results are presented on the dataset proposed for TRECVid 2003 news story segmentation evaluation to revalidate the main findings of this paper. Conclusions of this study are drawn and the future prospects are discussed in Section 8 . The proposed LDA based approach provides segment boundaries as well as the topic distribution associated with these segments. To show these two complementary outputs of the proposed approach, in Appendix A we show the top topic of the segments for a sample text. 2. Background
The approaches proposed for linear text segmentation can be primarily divided into two groups: (a) the ones that resort to linguistic information such as cue phrases, syntax or lexical features; (b) the ones that use the information regarding character, word or phrase repetition. Though a few studies did use the linguistic cues for the task, for example ( Beeferman 2001; Youmans, 1991 ), were motivated by the observation that coherent text usually contains repeating or similar vocab-ulary, an observation often attributed to Halliday and Hasan (1976) .

Linguistic information is typically a good indicator of a segment boundary or non boundary. For example, a pronoun in a a segment end ( Reynar, 1998 ). However, these cues may be specific to a particular type of data or media, news broadcast in the above discussion, and cannot be used across the board in all application domains. For each new application, one needs to analyze the data and define the appropriate cues.

Vocabulary repetition is usually linked with continuation of a segment, however all the words may not be equally impor-while counting the word repetition. Statistics regarding the relationship between changes in vocabulary size (number of un-ique words) with changes in word tokens (number of word occurrence) was used in Youmans (1991) to estimate the seg-ment boundaries; this study was based on the assumption that the vocabulary size increases more rapidly when a new segment starts as compared to when inside a segment. Attempts have also been made to use a broader definition of repe-tition, for instance taking into account repeated occurrences of synonyms. Along these lines, the effort of Morris and Hirst (1991) was to (manually) integrate a thesaurus, thus avoiding the problem of synonyms when identifying the lexical chains and subsequently finding the segment boundaries. In Kozima (1993) ,  X  X  X emantic similarity between words X  X  (called as Lexical
Cohesion Profile (LCP) ) was measured by manually designing a semantic network from a small English dictionary and spread-ing activation on this network. LCP was used for finding the segment boundaries. Though these earlier works were promis-ing, they were applied only to small text databases and were not backed by any measurable results.

In the TextTiling approach of Hearst (1997) , blocks of words were represented as word count vectors and similarity be-tween adjacent blocks was measured using dot-product in the vector space. It was asserted that a drop in similarity was typ-ically associated with a segment boundary. The proposed method was also compared with the method described in Youmans noting that in the TRECVid 2003 story segmentation task, TextTiling remained the most common method for segmenting to several important variants and extensions most of which incorporate two main ingredients: (i) a measure of similarity segment boundaries based on these similarity/cohesiveness patterns.

Various ways to compute these similarities have been put forward, for instance, Choi (2000) replaced the numerical sim-paper also introduced a synthetic database which was later used as a benchmark in several publications. Utiyama and
Isahara (2001) used a probabilistic measure of cohesiveness; this method is used as a baseline in this study and is further discussed in Section 4.2 . Another line of improvement was to compute the similarity in so-called latent semantic spaces so as to capture not only exact repetitions, but also repetitions of related words ( Bestgen, 2001; Brants et al., 2002; Choi have replaced the heuristic computation of the optimal segment boundary location with an exact computation based on dynamic programming (DP). In DP, similarity between each possible segment pair is computed, whereas in TextTiling , similarity is computed only between adjacent blocks. We will discuss DP and its computational complexity in Section 4 ; in Section 6 we investigate why computing similarity between all the segment pairs is not a necessity, and the information about similarity between the number of neighbouring segments that must be computed can be extracted in an unsupervised manner from the text data to be segmented.

Our work draws inspiration from these proposals, and relies on DP to locate segment boundaries. Where we depart from most of the previous work is in our assessment of the cohesiveness of a segment using probabilistic topic models. In our pro-earlier (text not used for training).

Different probabilistic models have been used in the past for automatically segmenting texts: for instance, probabilistic models in Utiyama and Isahara (2001) , hidden Markov model (HMM) in a fully supervised setting ( Blei &amp; Moreno, 2001; is used to train the LDA model which makes the approach unfit for segmenting running texts. After training LDA model on the data to be segmented, based on the Fisher kernel the likelihood score of each possible segment is used to estimate similarity score between contiguous chunks. The authors compared the performance of their LDA based method with the approaches suggested in Fragkou et al. (2004); Hearst (1997) on a synthetic dataset but failed to demonstrate an improvement over the much simpler TextTiling method of Hearst (1997) . The reason for this may be as follows: the data to be segmented is usually limited therefore the LDA parameters may not be estimated reliably in this kind of setup.
In contrast to the previous attempts using probabilistic models, our approach does not require any annotated data or an analysis of the test corpus in advance. Our approach requires building a model prior to segmentation on some similar data source; these models are our primary source of information when computing the cohesiveness of text segments. 3. Unsupervised topic models
In this section, we briefly explain two unsupervised topic models, LDA and MM, that are investigated in this paper for the task of text segmentation. 3.1. Latent dirichlet allocation model showed that the model can capture semantic information from a collection of documents, and demonstrated its superiority vis- X -vis several other models including multinomial mixture (MM) model ( Nigam et al., 2000; Rigouste et al., 2007 ) and where topic detection plays a key role, including, but not limited to, unsupervised language model adaptation for automatic ( Xing &amp; Girolami, 2007 ), and detecting semantically incoherent documents ( Misra, Capp X , &amp; Yvon, 2008 ).
This paper explores the use of topic modeling properties of LDA for yet another important application, the task of text segmentation. Our approach is based on the premise that using a topic model may allow better detection of segment bound-aries because a segment change should be associated with a significant change in the topic distribution. 3.1.1. LDA: basics
LDA adopts the traditional view that texts are represented as word count vectors, and relies upon a two step generation has an underlying word distribution .

The probabilistic generative story of a document is as follows: assuming a fixed and known number of topics, T , for each generating a document is to draw a topic distribution , H ={ h simplex. Next, assuming that the document length is fixed, for each word occurrence in the document a topic, z , is chosen from H and a word is drawn from the word distribution associated with the topic z . Given the topic distribution, each word is thus drawn independently from every other word using a document specific mixture model.
 Given H , the probability of w i , the i th word token in a document, is thus where P ( z i = t j H ) is the probability that the t th topic was chosen for the i th word token and P ( w w given topic t . The likelihood of a document, represented as a count vector C , is a mere product of terms such as (2) where C v is the count of word v in the document. 3.1.2. LDA: training
During training, the following two sets of parameters are estimated from a set of documents: the topic distribution in each document d ( h dt , t =1 ... T , d =1 ... D ) and the word distribution in each topic ( / are interpreted as the parameters of a multinomial distribution and indicate which topics are important for a particular doc-ument and which words are important for a particular topic respectively.

The task of estimating parameters can be accomplished using statistical techniques such as variational Bayes ( Blei et al., nique has been used in this study for training. In Gibbs sampling, two hyper-parameters a and b define the non-informative Dirichlet priors on H and U respectively.

The estimation procedure for LDA model using Gibbs sampling is detailed in Griffiths and Steyvers (2004) . In short, for assignments computed for all the word tokens in the training data constitutes a Gibbs sample. For a particular Gibbs sample, the estimates for H and U are derived from the counts of hypothesized topic assignments as where J t v is the number of times word v is assigned to topic t and K token in document d . 3.1.3. LDA: testing Training LDA on a text collection reveals the thematic structure of the collection, and has been the primary application of tions regarding novel documents ( assuming that they use the same vocabulary as the training corpus  X  vocabulary mismatch semantic dimensions, computing this distribution is important in many applications, including the present task of text segmentation.

This computation can be performed using the iterative procedure suggested in Heidel et al. (2007); Misra et al. (2008) , which relies on the following update rule where l d is the document length computed as the number of running words. As discussed in Misra et al. (2008) , this update rule converges monotonically towards a local optimum of the likelihood, and convergence is typically reached in less than a dozen iterations. Once the H has been obtained for a document, the likelihood of the document can be computed by (3) . This recently proposed method for computing H for unseen documents is key to computing the likelihood of a document. In this paper, we extend this idea to compute likelihood of a segment and use the estimated likelihood of segments as scores for performing the text segmentation task. 3.2. Multinomial mixture model
In an MM model, it is assumed that every word in a document belongs to the same topic and each document is thus rep-ability of a document is: This model can be trained through expectation maximization (EM) using the following re-estimation formulas: where (8) defines the E-step, and (9) and (10) define the M-step.
 As suggested in Rigouste et al. (2007) , we initialize the EM algorithm by drawing initial topic distributions from a prior Dirichlet distribution with hyper-parameters a = 1 and b = 0.1 in all the experiments.

During testing, the parameters of the MM models are used to estimate the posterior topic distribution in an unseen doc-ument using (8) . The likelihood of the unseen document is given by (7) . As in the case of LDA model, we extend this idea to compute likelihood of a segment and use the estimated likelihood of segments as scores for performing the text segmenta-tion task. 4. Algorithmics of segmentation 4.1. Dynamic Programming (DP) with probabilistic scores As discussed in Utiyama and Isahara (2001); Kehagia et al. (2003) , text segmentation can be efficiently implemented with
DP techniques. Assuming the text is represented as a linear graph, a segment is defined by two nodes, the begin (B) and the (including E = 5). Node 0 is treated as null node for convenience.

In the standard DP approach, scores for all the possible node pairs are computed. Therefore, if the graph contains N nodes, one has to consider N ( N + 1)/2 node pairs as shown in Fig. 2 .

Text segmentation thus proceeds as follows ( Utiyama &amp; Isahara, 2001 ): We denote d  X  w l ; and S = S 1 S 2 S m a particular segmentation S made up of m segments. The likelihood of S is thus alty factor. Assuming that S i contains n i word tokens, and that w therefore, d = W 1 W m with l d  X  P m i  X  1 n i . Under these assumptions, W assuming that segments are independent of each other, (11) can be rewritten as The most likely segmentation, b S , is defined as b S  X  argmax resolution of shortest path problems. During the forward-pass, for each pair of nodes ( B , E ), the score of Seg best start node B is stored. The information about the best start node is used during trace back to find the path that maxi-mizes the score, and in turn, the segment boundaries. 4.2. Scoring segments by baseline
The method proposed in Utiyama and Isahara (2001) consists of modeling each segment using the conventional multi-nomial model, assuming that segment specific parameters are estimated using the usual maximum-likelihood estimates with Laplace smoothing. This approach has often been used as a standard baseline in literature and shown to deliver com-in (12) are thus computed as where C j i is the frequency of word w j i in S i and V d written as tation algorithm incurs for every proposed segment change. In Utiyama and Isahara (2001) , it was optimized to log P ( S )= m log( l d ) to yield the best performance. 4.3. Scoring segments by LDA
The LDA based method proposed in this paper is based on the following premise: if a segment is made up of only one story, it will have only a few active topics, whereas if a segment is made up of more than one story, it will have a compar-atively higher number of active topics. In Misra et al. (2008) , the authors showed that documents with a few active topics have higher log-likelihood than documents that have several active topics. Extending this reasoning to segments, if a seg-ment is coherent (the topic distribution for a segment has only a few active topics), the log-likelihood for that segment is typically high as compared to the log-likelihood in the case when a segment is not coherent. This observation is of critical importance in the success of the proposed LDA based approach for text segmentation task, and has been left unexplored ex-cept for its original use in detecting coherence of a document ( Misra et al., 2008 ).

It is thus tempting to use the log-likelihood of each possible segment as a score in the DP algorithm and to recover the segmentation from the path that yields the highest log-likelihood. The information about topic distribution ( H ) for a text segment can be estimated by (6) , 3 assuming that the parameter U (distribution of words in each topic) of the LDA model has been learned on a training corpus. This in turns allows to compute the likelihood of the segment using (3) .
The proposed LDA based approach for text segmentation task works like this: 1. For each possible segment, S i , (a) Compute its H by performing 20 iterations of (6) : (b) Compute its log-likelihood using (3) : (c) The likelihood of the segment is treated as its score: 2. Substitute the scores of the segments in (12) , and use DP to find the segmentation which maximizes the score.
The penalty factor we have used is defined as log P ( S )= p m log( l performance on a held out condition (on Choi X  X  dataset with words as nodes) and has been used throughout. 4.4. Scoring segments with MM The MM topic model can be used to segment a text if in the algorithm described above the likelihood is estimated by an
MM model. The segmentation algorithm in this case proceeds like this: 1. For each possible segment, S i , (a) Compute its log-likelihood using (7) : (b) The likelihood of the segment is treated as its score: 2. Substitute the scores of the segments in (12) , and use DP to find the segmentation which maximizes the score.
Notice that in MM, unlike LDA, the topic distribution need not be estimated in order to estimate the likelihood. This makes the whole approach much faster than the LDA based approach (where an iterative procedure was needed to estimate the topic distribution before computing the log-likelihood); however, a drawback of this approach is that segments are not associated with a topic distribution. 5. Experimental results 5.1. Databases
The first dataset used in this study is the Choi X  X  dataset, algorithms. Choi X  X  dataset is derived from Brown corpus. This corpus consists of running text of edited English prose printed in US during the calendar year 1961 and has a small sample size of 500 proses of approximately 2000 words each ( http:// 129.177.24.52/icame/manuals/brown/ ; link active as on June 2010). Brown corpus contains  X  X  X nformative prose X  X  (374 docu-ments) as well as  X  X  X maginative prose X  X  (126 documents), including 44 documents from the  X  X  X ress reportage X  X  genre. lowed by selecting first N (a random number between X and Y ) sentences from that story. Exactly 10 such segments are con-catenated to make a document. Further, in each subset, there are 100 documents to be segmented. By design, the segments are not complete stories. As expected, because of the small coverage of Brown corpus, the coverage of Choi X  X  dataset is also quite limited.
 To study the performances on a more realistic dataset, we created a dataset similar to Choi X  X  dataset from the Reuters
Corpus Volume 1 (RCV1) ( Lewis et al., 2004 ). RCV1 is a collection of over 800,000 news items in English from August 1996 to August 1997. These news items belong to at least one of the following broad subject areas (topic codes): Corpo-rate/Industrial (CCAT), Economics (ECAT), Government/Social (GCAT) and Markets (MCAT). We selected a set of 23,326 news items from RCV1 for generating the Reuters dataset (RDS) for text segmentation which is more comprehensive than Choi X  X 
Choi X  X  dataset, there are 100 documents to be segmented in each subset of RDS , and each document has 10 segments ( Set 1 ) in it. However, with a realization that 10 segments in each document is too restrictive and may not be the only condition to occur in practice, we created two more sets varying the number of segments in a document. In RDS , Set 2 and Set 3 contain 50 and 100 segments respectively.

Though similar to Choi X  X  dataset, RDS covers more situations. The number of segments in a document is not fixed to 10; it is 10, 50 or 100. Further, subset  X  X  X ulltext X  X  in RDS has entire news items randomly chosen and then concatenated to form the documents.

From RCV1 collection, we selected another 27,672 news items for training the LDA model ( ReutersTrain ). The vocabulary size of this train set is approximately 93K and the number of word tokens, excluding stop words, are approximately 3.6M. In these experiments, number of topics ( T ) and Dirichlet priors ( a and b ) are set to the following values: T = 50, a = 1 and b = 0.01. These values were chosen for two main reasons: (a) in our previous work on coherence detection ( Misra et al., 2008 ), which was the initial motivation for using LDA for the task of text segmentation, these values yielded good perfor-mance, and (b) T = 50 is large enough to keep the model flexible but at the same time keep the computational complexity of the segmentation algorithm moderate; it may be recalled from (6) that theta estimation is an iterative procedure and its computational cost increases with an increase in T (though it was not a factor here, it may be noted that an increase in T also increases the computational cost associated with the training of LDA model). Similar values of these parameters were found to be a reasonable choice while training an LDA model on data of similar size in Griffiths and Steyvers (2004) .
RCV1 was used for the following reasons: (a) It is a large database so we can have separate train ( ReutersTrain ) and test ulary are less likely. (c) ReutersTrain had enough train documents to cover minimum vocabulary size and do reliable LDA parameters estimation. (d) In RDS , the subset  X  X  X ulltext X  X  simulated realistic conditions whereas other subsets were to emu-late Choi X  X  dataset. (e) In RDS , the number of segments in a document were varied (10, 50 and 100) in order to simulate a wider spectrum of the text segmentation problem. 5.2. Test conditions
Isahara, 2001 ), the information about the sentence end is used while performing segmentation. In such a case, each sentence start is a possible B node while each sentence end is a possible E node. The same setup is studied in this paper. 5.3. Choi X  X  data: results and analysis 5.3.1. Baseline experiments
In this section, we compare the results of the following segmentation systems (see Table 1 ) The results reported in Utiyama and Isahara (2001) (using Choi X  X  implementation of Porter stemmer) Our own implementation of Baseline method LDA based segmentation MM based segmentation
The results are presented in terms of P k value, the probabilistic error metrics introduced in Beeferman et al. (1999) . P is set to the average segment length in our experiments. A lower value of P
The results reported in Table 1 suggest that the performance of the Baseline and LDA based methods consistently im-proves with an increase in segment size. This is an expected result: longer segments allow a better estimation of the multi-nomial parameters for the baseline method and of the topic distribution for LDA. This trend is observed in the performance of the MM based method as well, but it is much weaker.

Out of the two topic models, the LDA based method gives a better performance as compared to that of the MM based method. This result shows that the underlying assumption of a topic distribution associated with each document (LDA mod-el) is able to represent the data better as compared to the assumption that each document is represented by a single topic (MM model).

Compared to the topic model based approaches, the baseline method is: (i) more accurate and (ii) an order of magnitude faster. An inspection of outputs (other than just the segment boundaries provided by the two methods) gives a possible explanation for (i): there is a serious mismatch in vocabulary between ReutersTrain dataset (used for LDA and MM models (stop words were removed before segmenting the text) for computing the score of a segment. In contrast, the vocabulary of the the training vocabulary are not used for computing the score of a segment. Comparing the baseline and topic model based methods, approximate loss in vocabulary and content words by topic models are 11.8% and 10.5% respectively.
Apart from this loss in vocabulary, the other aspect is the distribution of the content words present in the test set. We found that the high frequency content words of ReutersTrain set were mostly missing or under represented in the documents of Choi X  X  set, and these documents often consist of low frequency content words of ReutersTrain set. 5.3.2. Experiments with an adapted LDA model
To overcome this problem of vocabulary, domain and temporal mismatches, we conducted a second series of complemen-tary experiments using more appropriate training data. Given that Choi X  X  pseudo-documents are generated using (some of) the first 11 sentences of documents of the Brown corpus, we built a new training set containing documents both from the Reuter corpus (as before) and 500 pseudo-documents from the Brown corpus. The last 40 sentences of each document in the
Brown corpus were selected to generate these pseudo-documents. The new combined training set has a vocabulary size of approximately 109K and the number of content word tokens are approximately 3.9M, an increase of approximately 17.2% and 7.4% over ReutersTrain set respectively. Using this new dataset, we trained an  X  X  X dapted X  X  LDA model using the same value of hyper-parameters as before ( T = 50, a = 1 and b = 0.01) and used this adapted model to produce segmentations. These re-more closely allows to significantly improve the performance across all the conditions, the improvement being especially large for shorter segments. With this new training dataset, our results are more comparable with the baseline.
A part of this improvement is due to the reduction in vocabulary mismatch: with this new training data the average num-ber of content word tokens taken into account during test increases by approximately 2.5%. This however also means that in are not used. Therefore the main cause of this improvement can be attributed to the creation of topics that more appropri-ately describe the thematic content of the Brown corpus. Using these new topics, our algorithm is now in a position to iden-tify segments boundaries between documents which previously were thematically indistinguishable.

The main conclusion of this small study is the reiteration of the fact that topic models need to be trained on a dataset that is as similar as possible to the test documents to be segmented.

In the next section, we present the results on a bigger and more realistic dataset (RDS) to investigate other issues related uate all the algorithms on a dataset that was proposed for TRECVid 2003 news story segmentation evaluation task. The re-sults obtained on TRECVid dataset again show the limited coverage of Choi X  X  dataset. By using an adapted LDA model, an average improvement of approximately 4 X 7% absolute is obtained on Choi X  X  dataset whereas improvement on TRECVid 2003 dataset is a modest (though significant) 2% absolute.
 5.4. Reuters data: results and analysis
As explained earlier, RDS includes sets that contain a larger number of segments ( Set 2 and Set 3 contain 50 and 100 seg-ments per document respectively). In addition, a subset consisting of complete Reuters news stories was also considered
RDS , the performance of the baseline method drops significantly, especially when used to segment longer documents. In uments that could be segmented. This result shows that unsupervised topic model based approaches can produce segmen-test documents to be segmented.

As pointed out earlier on Choi X  X  dataset, out of the two model based approaches, the performance of the LDA based ap-proach is better than that of the MM based approach. On a complex dataset like RDS , better expressiveness of the LDA model is able to show its strength in data modeling. However, computational cost of the former is extremely high because of the iterative procedure for estimating the topic distribution.
 The poor performance of Utiyama X  X  method on longer pieces of text was also reported in Utiyama and Isahara (2001);
Malioutov and Barzilay (2006) . A possible explanation is as follows: The maximum-likelihood (ML) estimator in Utiyama and Isahara (2001) , even with smoothing, is not robust for small segments. Based on the observation of a handful of words,
Utiyama and Isahara (2001) claims to estimate a distribution over the entire vocabulary whose size increases rapidly as the number of segments in a document increase and could easily be a few thousand parameters for reasonably sized documents.
By comparison, the LDA based method only attempts to estimate the H distribution, which corresponds to a much smaller number of parameters, and can thus be performed more robustly, even for small segments.

In Appendix A , we show the segmentation estimated by the proposed LDA based approach for a sample document. Along with the segmentation, we also show the topic assigned (only the topic with the highest probability is printed) by the LDA model to each segment. A comparison of  X  X  X he top words in a topic X  X  and  X  X  X he topic assigned to a segment based on the words tions like discourse analysis and summarization.

Encouraged by these results, we analyzed the DP algorithm to alleviate the issue of high computation cost associated with the topic based segmentation algorithm. 6. Sparse path and modified DP
The main difficulty of DP based segmentation stems from its requirement to score all possible node pairs as segments, whose number grows quadratically with the number of sentences in a document. In LDA, scoring a segment requires an iter-ative estimation of its topic distribution. An obvious remedy to this problem is computing the score of only a subset of the ments that were too long (their B and E nodes were too far apart), a strategy that proved effective in reducing the compu-tational cost of their technique. Such distance thresholds were also used in Stokes et al. (2004) in order to reduce spurious chains and also to avoid very long segments.

Our proposed modification is based on the observation that during the forward-pass, most nodes are never active as B nodes. In other words, for most of the nodes, we cannot find a single E node whose best starting node is among these nodes.
As a consequence, these nodes are never on the maximum score path. This observation reflects in Fig. 3 , where we plot, for two different test files, the frequency count of active nodes during the forward-pass; more precisely, we display the number segment boundaries and the segment boundaries obtained by the baseline method after back-tracing. As shown in Fig. 3 , of many segments) are very often a good candidate for segment boundaries. This also means that the most likely candidates for once an active B node is crossed, the segments starting from before this B node are mostly not in the maximum score path.
Based on this observation, we suggest a solution to reduce the computational cost of DP: disregard the segments whose starting node lies before the last active B node.

This heuristic, which holds irrespective of the underlying probabilistic model, does not require defining a threshold for be significant if it is used wisely.
 for score computation.
 compute the scores for segments 2 X 5, 1 X 5, and 0 X 5 . As the DP progresses, the last active node keeps getting updated. For example, if towards the end of the document B = N 4 is an active node, scores of only a few segments need to be computed.
In order to make this algorithm more robust, a node is considered active only when it has been active for at least two con-
E =5.If B = 3 was an active node for at least 2 times, then for E = 6 the scores for segments 2 X 6, 1 X 6, and 0 X 6 need not be computed.
This simple scheme, which trades-off the exactness of search with speed, proves to be very efficient in terms of reducing by the results achieved by modified DP (MDP) algorithm ( Table 5 ).

The results in Table 5 reflect the effectiveness of this simple heuristics, both in terms of speed and accuracy. For all seg-ment sizes, the time needed to segment documents is divided by more than 10, with even larger gains for long documents. For test Set 1 that contains 10 segments per file, we can actually compare the performance of exact and approximate search.
We find that both the methods (DP and MDP) for both the topic models (LDA and MM) yield very comparable results. In fact, the modified algorithm proves slightly better in several cases as it discards solutions that are optimal for the model but would yield segments that are too long. For test Set 2 and Set 3 containing more segments (50 and 100 segments respec-tively), our topic model based methods outperform baseline by a wide margin. In fact, contrary to the baseline performance, the performance of the topic model based methods degrades very gracefully with an increase in the number of segments.
The performance of the two topic model based approaches can also be viewed from a different perspective. If time com-plexity is an important criterion for performance and one is willing to compromise the accuracy of the segmentation, it is reasonable to use MM based approach for the segmentation task. Nevertheless, LDA based method gives better performance than MM based method and in future we would like to focus on the iterative procedure of estimating the topic distribution in order to reduce the time complexity of the LDA based method. 7. A real application: news story segmentation task
In TRECVid 2003 ( TREC Video Retrieval Evaluation, 2003 ), news story segmentation was defined as a separate evaluation task. In this section, we present the performance of the proposed LDA based method on the dataset proposed for TRECVid 2003 news story segmentation evaluation task. The dataset consists of 120 h of video news story collected from ABC and
CNN news channels in the year 1998. Approximately 60 h of data was set aside for training or development ( TRECVidTrain ) were expected to utilize multi-modal features from text, audio and video streams to perform the segmentation task.
In the actual evaluation, the participants were allowed to use specific cues like  X  X  X ood evening X  X ,  X  X  xyz (person) reporting ated with news broadcasts and typically suggest a story change. These cues were obtained from the TRECVidTrain data. The TRECVid results are typically reported in terms of precision, recall and F1 measures. These measures are defined as:
In this paper, we approach news story segmentation task as a text segmentation problem. Only the close caption text was the task .

We show the performance of the baseline and two LDA based methods in Table 6 . In the first LDA based method, the mod-el is trained on ReutersTrain dataset while the second LDA based method utilizes ReutersTrain and TRECVidTrain datasets for training the LDA model. The results are presented in terms of two measures, P
P indicates a better performance, whereas a higher value of F1 measure indicates a better performance. A comparison of the results shows that the baseline and unadapted LDA methods yield similar performances, and the performance of the LDA method can be improved by adaptation. These results validate the earlier results obtained on Choi X  X  dataset that adaptation improves the performance of LDA based method.

These encouraging results on a real application by the unsupervised topic modeling approach (the proposed LDA based method in our case) suggest the following: text segmentation from unsupervised topic modeling perspective is an alterna-tive and a competitive tool which gives a reasonable performance on several different datasets.

Still, the text segmentation problem is far from being solved and below are some of the observations from TRECVid 2003 dataset: In this dataset, a typical news broadcast of CNN and ABC started with  X  X  X ain headlines X  X  followed by the actual news where the headlines were presented in detail. In the  X  X  X ain headlines X  X , each story was represented by a single sentence. In the problem of unsupervised approaches which need some minimum amount of data to perform reliable estimates of the score.

We expect our LDA based approach to be complementary to the existing approaches. In our last experiment we investi-gated the complementarity of the two approaches by combining the segment boundaries estimated by the baseline and the
LDA methods by simple OR operation. That is, if any one of the methods suggested a segment boundary, we accepted it as a segment boundary. This combination was performed because an analysis of the segment boundaries estimated by the two methods revealed that: (a) a boundary estimated by these methods was mostly an actual boundary, (b) both the methods do undersampling, that is, the number of boundaries estimated by individual methods is always less than the number of actual boundaries, and (c) the boundaries estimated by the two methods are not the same. These observations suggest that the out-puts provided by the two methods are complementary. This is expected because both the methods rely on different tech-niques to compute the segment scores and as a consequence have different estimates for segment boundaries. This simple combination yields an F1 measure of 0.52 and 0.55 for Baseline+unadapted LDA and Baseline+adapted LDA respectively. 8. Conclusions
In this study, we proposed an application of two well established unsupervised topic models (LDA and MM) for the task of text segmentation. Out of the two approaches proposed in this paper, the LDA based method was able to estimate the seg-ment boundaries with higher accuracy as compared to the boundaries estimated by the MM based method.

Another advantage of the proposed LDA based method is that it computes topic distributions ( Appendix A ) jointly with segmentation, thus allowing one to collect information about the thematic content of each segment. This information can be used to keep track of recurring topics.

We investigated and compared the performance of our methods with a standard approach often used as a baseline for the text segmentation task ( Utiyama &amp; Isahara, 2001 ), and analyzed their potential strengths and weaknesses. The LDA based method gave a better performance than that of the baseline in matched conditions (train and test data from the same do-main). As expected, when topic models are trained with data that substantially differs from the test set, the performance is less favorable; we show that the performance can be easily improved using a small amount of adaptation data. This trend was observed in all the adaptation experiments reported in this paper.
 One drawback of the proposed LDA based approach was its high computational cost. We proposed a modification to the
DP algorithm that effectively reduces the computational cost. The unsupervised method of discarding the unimportant seg-ments from the process of score computation brings a substantial reduction in computational cost without significantly affecting the performance. The proposed modification in the DP algorithm is not only useful for text segmentation task but can also be used in many other situations where a similar sparsity in data is encountered.

LDA based approach remains an order of magnitude slower than the baseline, indicating that there is scope for improve-ment. One possible solution is to combine both the techniques, that is, using the baseline method to locate the most prom-ising boundaries, and then rescoring them using the topic based methods. The second issue with the topic based approaches is related to mismatch between the train and the test domains. This could be alleviated, for instance, by adapting the param-eters of the LDA model via a first pass on the test data, during which the topic assignments for the whole document would be computed and used to revise the parameters.
 Acknowledgments
This research was partly supported by the European Commission under the Contracts FP6-027122-SALERO and FP7-231854-SYNC3 .
 Appendix A. Text segmentation by LDA: Sample output
The results previously published in the literature typically concentrated on the segmentation performance (either some error metric or time complexity). Though estimating the segment boundaries is important, yet if the segments can be iden-segment boundaries; this very aspect of the LDA model is shown in this section.
 A.1. An analysis of LDA output In this section, we show the following two complementary outputs of the LDA model:
Text segmentation phase output [Section A.2 ]: For a sample document segmented by LDA based approach, the top topic label assigned by LDA model to each segment. To save space, long sentences were terminated by  X  X  ...  X  X  to reflect continuity beyond the printed words.
 Training phase output [Section A.3 ]: Top ten words of the topics that are found in the example segmented document in Section A.2 .

A.2. Segmented text output indian finance minister p chidambaram said on friday india was concerned over the impact ... look at what happened over the last two or three ... what happens to our oil import bill MISSED BOUNDARY pakistani officials said on saturday in azad kashmir to ... at least one civilian was killed and two were wounded ... ESTIMATED BOUNDARY is CORRECT: TOPIC 46 has highest probability (0.28) shares in industrial conglomerate btr plc rose in early trading ... the stock was up 5p at two hundred sixty five ... british newspaper reports over the weekend had anticipated the sale ... ESTIMATED BOUNDARY is CORRECT: TOPIC 50 has highest probability (0.26) the washington post carried the following stories on its front ... dukan iraq government backed kurdish guerrillas overran sulaimaniya and captured ... washington more than hundred iraqi dis-sidents and military officers associated ... little rock a defiant susan mcdougal reported to jail this ... ESTIMATED BOUND-
ARY is CORRECT: TOPIC 35 has highest probability (0.44) south africa X  X  chamber of mines said on wednesday it had agreed wage increases ... the national union of mineworkers num said earlier it had ... minimum wage rates for different mining houses have been adjusted ... ESTIMATED BOUNDARY is CORRECT: TOPIC 32 has highest probability (0.41) the czech gov-ernment plans a balanced thousand nine hundred ninty ... the cabinet did not find bigger room for tax cuts ... the budget plan is expected to go to a final vote ... INSERTED BOUNDARY: TOPIC 25 has highest probability (0.54) the thousand nine hundred ninty seven budget assumes growth in gross domestic ... ESTIMATED BOUNDARY is CORRECT: TOPIC 42 has high-est probability (0.70) deutsche bahn chairman heinz duerr said on wednesday that the current building ... the construction number of investment challenges facing the german railway ... ESTIMATED BOUNDARY is CORRECT: TOPIC 19 has highest probability (0.19) california state treasurer matt fong has called on the securities and exchange commission ... fong called
ESTIMATED BOUNDARY is CORRECT: TOPIC 26 has highest probability (0.60) about fifty containers of aluminium phos-phate have been found on the ... we X  X e found about fifty small tubes with the chemical inside them none were open but there X  X  always a risk that some of the poison ... aluminium phosphate is used as rat poison and produces a toxic gas on ... ESTIMATED BOUNDARY is CORRECT: TOPIC 16 has highest probability (0.38) contract talks continued saturday be-tween ford motor co and the united auto workers ... bargainers were optimistic according to ford spokesman jon harmon but ... they X  X e not there yet on all the issues it X  X  going to take a while to get through harmon told reporters ... ESTIMATED BOUNDARY is CORRECT: TOPIC 32 has highest probability (0.29)
A quick analysis of the segmented output shows that the topic associated with a segment is mostly relevant to the words present in that segment. In particular, the MISSED BOUNDARY occurs because both the stories have a common theme india .
On the other hand, INSERTED BOUNDARY divides a story into two segments, one related to  X  X  X overnment economic policy (TOPIC 25) X  X  and the other related to  X  X  X dp growth (TOPIC 42) X  X .
 A.3. U Matrix: top 10 words of relevant topics TOPIC 46 :  X  X upees X   X  X ndia X   X  X ndian X   X  X akistan X   X  X ombay X   X  X ew X   X  X illion X   X  X ri X   X  X ndia X  X  X   X  X arket X  TOPIC 50 :  X  X lc X   X  X tg X   X  X roup X   X  X ondon X   X  X ounds X   X  X ritish X   X  X illion X   X  X lus X   X  X nvestment X   X  X k X  TOPIC 35 :  X  X raq X   X  X raqi X   X  X .s. X   X  X nited X   X  X urdish X   X  X orthern X   X  X ilitary X   X  X tates X   X  X ran X   X  X ulf X  TOPIC 32 :  X  X nion X   X  X orkers X   X  X trike X   X  X overnment X   X  X ercent X   X  X talian X   X  X age X   X  X tate X   X  X ay X   X  X ao X  TOPIC 25 :  X  X overnment X   X  X illion X   X  X udget X   X  X ax X   X  X tate X   X  X inister X   X  X ear X   X  X inance X   X  X conomic X   X  X inistry X  TOPIC 42 :  X  X ercent X   X  X oint X   X  X ear X   X  X uly X   X  X une X   X  X illion X   X  X onth X   X  X ose X   X  X rowth X   X  X ugust X  TOPIC 19 :  X  X erman X   X  X arks X   X  X obacco X   X  X ar X   X  X ermany X   X  X ndustry X   X  X ales X   X  X g X   X  X illion X   X  X ew X  TOPIC 26 :  X  X ourt X   X  X .s. X   X  X loyd X  X  X   X  X ase X   X  X lan X   X  X udge X   X  X ames X   X  X egal X   X  X aw X   X  X nvestors X  TOPIC 16 :  X  X eople X   X  X fficials X   X  X olice X   X  X lane X   X  X iles X   X  X illed X   X  X assengers X   X  X pokesman X   X  X light X   X  X irport X  References
