 With the increasing use of electronic health records, it becomes urgent to leverage this rich information resource about patients X  health condi-tions to transform research in health and medicine. As an example, when developing a cohort for a clinical trial, researchers need to identify pa-tients matching a set of clinical criteria based on their medical records during their hospital visits (Safran et al., 2007; Friedman et al., 2010). This selection process is clearly a domain-specific re-trieval problem, which searches for relevant medi-cal records that contain useful information about their corresponding patients X  qualification to the criteria specified in a query, e.g.,  X  X emale patient with breast cancer with mastectomies during ad-mission X .

Intuitively, to better solve this domain-specific retrieval problem, we need to understand the re-quirements specified in a query and identify the documents satisfying these requirements based on their semantic meanings. In the past decades, significant efforts have been put on constructing biomedical knowledge bases (Aronson and Lang, 2010; Lipscomb, 2000; Corporation, 1999) and developing natural language processing (NLP) tools, such as MetaMap, to utilize the informa-tion from the knowledge bases (Aronson, 2001; McInnes et al., 2009). These efforts make it pos-sible to map free text to concepts and use these concepts to represent queries and documents.
Indeed, concept-based representation is one of the commonly used approaches that leverage knowledge bases to improve the retrieval perfor-mance (Limsopatham et al., 2013d; Limsopatham et al., 2013b). The basic idea is to represent both queries and documents as  X  X ags of concepts X , where the concepts are identified based on the in-formation from the knowledge bases. This method has been shown to be more effective than tra-ditional term-based representation in the medical record retrieval because of its ability to handle the ambiguity in the medical terminology. However, this method also suffers the limitation that its ef-fectiveness depends on the accuracy of the concept mapping results. As a result, directly applying existing weighting strategies might lead to non-optimal retrieval performance.

In this paper, to address the limitation caused by the inaccurate concept mapping results, we pro-pose to regularize the weighting strategies in the concept-based representation methods. Specifi-cally, by applying the axiomatic approaches (Fang and Zhai, 2005), we analyze the retrieval func-tions with concept-based representation and find that they may violate some reasonable retrieval constraints. We then propose two concept-based weighting regularization methods so that the reg-ularized retrieval functions would satisfy the re-trieval constraints and achieve better retrieval per-formance. Experimental results over two TREC collections show that both proposed concept-based weighting regularization methods can im-prove the retrieval performance, and their perfor-mance is comparable with the best systems of the TREC Medical Records tracks (Voorhees and Tong, 2011; Voorhees and Hersh, 2012).

Many NLP techniques have been developed to understand the semantic meaning of textual in-formation, and are often applied to improve the search accuracy. However, due to the inherent am-biguity of natural languages, the results of NLP tools are not perfect. One of our contributions is to present a general methodology that can be used to adjust existing IR techniques based on the inac-curate NLP results. The Medical Records track of the Text REtrieval Conference (TREC) provides a common platform to study the medical records retrieval problem and evaluate the proposed methods (Voorhees and Tong, 2011; Voorhees and Hersh, 2012).

Concept-based representation has been studied for the medical record retrieval problem (Lim-sopatham et al., 2013d; Limsopatham et al., 2013b; Limsopatham et al., 2013a; Qi and La-querre, 2012; Koopman et al., 2011; Koopman et al., 2012). For example, Qi and Laquerre used MetaMap to generate the concept-based repre-sentation and then apply a vector space retrieval model for ranking, and their results are one of the top ranked runs in the TREC 2012 Medi-cal Records track (Qi and Laquerre, 2012). To further improve the performance, Limsopatham et al. proposed a task-specific representation, i.e., using only four types of concepts (symp-tom, diagnostic test, diagnosis and treatment) in the concept-based representation and a query ex-pansion method based on the relationships among the medical concepts (Limsopatham et al., 2013d; Limsopatham et al., 2013a). Moreover, they also proposed a learning approach to combine both term-based and concept-based representation to further improve the performance (Limsopatham et Figure 1: Example of MetaMap result for a query. al., 2013b).
 Our work is also related to domain-specific IR (Yan et al., 2011; Lin and Demner-Fushman, 2006; Zhou et al., 2007). For example, Yan et al. proposed a granularity-based document rank-ing model that utilizes ontologies to identify doc-ument concepts. However, none of the previous work has studied how to regularize the weight of concepts based on their relations.

It is well known that the effectiveness of a re-trieval function is closely related to the weight-ing strategies (Fang and Zhai, 2005; Singhal et al., 1996). Various term weighting strategies have been proposed and studied for the term-based representation (Amati and Van Rijsbergen, 2002; Singhal et al., 1996; Robertson et al., 1996). However, existing studies on concept-based rep-resentation still used weighting strategies devel-oped for term-based representation such as vector space models (Qi and Laquerre, 2012) and diver-gence from randomness (DFR) (Limsopatham et al., 2013a) and did not take the inaccurate con-cept mapping results into consideration. Com-pared with previous work, we focus on address-ing the limitation caused by the inaccurate con-cept mapping. Note that our efforts are orthogonal to existing work, and it is expected to bring addi-tional improvement to the retrieval performance. 3.1 Problem Formulation We follow the problem setup used in the TREC medical record track (Voorhees and Tong, 2011; Voorhees and Hersh, 2012). The task is to retrieve relevant patient visits with respect to a query. Since each visit can be associated with multiple medical records, the relevance of a visit is related to the relevance of individual associated medical records. Existing studies computed the relevance scores at either visit-level, where all the medical records of a visit are merged into a visit document (Demner-Fushman et al., 2012; Limsopatham et al., 2013c), or record-level, where we can first compute the relevance score of individual records and then aggregate their scores as the relevance score of a visit (Limsopatham et al., 2013c; Zhu and Carterette, 2012; Limsopatham et al., 2013d). In this paper, we focus on the visit-level relevance because of its simplicity. In particular, given a pa-tient X  X  visit, all the medical records generated from this visit are merged as a document. Note that our proposed concept-weighting strategies can also be easily applied to record-level relevance modeling.
Since the goal is to retrieve medical records of patients that satisfying requirements specified in a query, the relevance of medical records should be modeled based on how well they match all the re-quirements (i.e., aspects) specified in the queries. 3.2 Background: UMLS and MetaMap Unified Medical Language System (UMLS) is a metathesaurus containing information from more than 100 controlled medical terminologies such as the Systematized Nomenclature of Medicine Clin-ical Terms (SNOMED-CT) and Medical Subject Headings (MeSH). Specifically, it contains the in-formation about over 2.8 million biomedical con-cepts. Each concept is labeled with a Concept Unique Identifier (CUI) and has a preferred name and a semantic type.

Moreover, NLP tools for utilizing the informa-tion from UMLS have been developed. In partic-ular, MetaMap (Aronson, 2001) can take a text string as the input, segment it into phrases, and then map each phrase to multiple UMLS CUIs with confidence scores. The confidence score is an indicator of the quality of the phrase-to-concept mapping by MetaMap. It is computed by four met-rics: centrality, variation, coverage and cohesive-ness (Aronson, 2001). These four measures try to evaluate the mapping from different angles, such as the involvement of the central part, the distance of the concept to the original phrase, and how well the concept matches the phrase. The maximum confidence in MetaMap is 1000.

Figure 1 shows the MetaMap results for an ex-ample query  X  X hildren with dental caries X . Two query aspects , i.e.,  X  X hildren X  and  X  X ental caries X , are identified. Each of them is mapped to multiple concepts, and each concept is associated with the confidence score as well as more detailed informa-tion about this concept. 3.3 Concept-based Representation Traditional retrieval models are based on  X  X ag of terms X  representation. One limitation of this rep-resentation is that relevance scores are computed based on the matching of terms rather than the meanings. As a result, the system may fail to re-trieve the relevant documents that do not contain any query terms.

To overcome this limitation, concept-based rep-resentation has been proposed to bridge the vo-cabulary gap between documents and queries (Qi and Laquerre, 2012; Limsopatham et al., 2013b; Koopman et al., 2012). In particular, MetaMap is used to map terms from queries and documents (e.g., medical records) to the semantic concepts from biomedical knowledge bases such as UMLS. Within the concept-based representation, the query can then be repre-sented as a bag of all the generated CUIs in the MetaMap results. For example, the query from Figure 1 can be represented as { C 0008059 ,C 0680063 ,C 0011334 ,C 0333519 , C 0226984 } . Documents can be represented in a similar way.

After converting both queries and documents to concept-based representations using MetaMap, previous work applied existing retrieval functions such as vector space models (Singhal et al., 1996) to rank the documents. Note that when referring to existing retrieval functions in the paper, they include traditional keyword matching based func-tions such as pivoted normalization (Singhal et al., 1996), Okapi (Robertson et al., 1996), Dirich-let prior (Zhai and Lafferty, 2001) and basic ax-iomatic functions (Fang and Zhai, 2005). 4.1 Motivation Although existing retrieval functions can be di-rectly applied to concept-based representation, they may lead to non-optimal performance. This is mainly caused by the fact that MetaMap may generate more than one mapped concepts for an aspect, i.e., a semantic unit in the text.

Ideally, an aspect will be mapped to only one concept, and different concepts would represent different semantic meanings. Under such a situ-figures.). ation, traditional retrieval functions would likely work well and generate satisfying retrieval per-formance since the relations among concepts are independent which is consistent with the assump-tions made in traditional IR (Manning et al., 2008). However, the mapping results generated by MetaMap are not perfect. Although MetaMap is able to rank all the candidate concepts with the confidence score and pick the most likely one, the accuracy is not very high. In particular, our preliminary results show that turning on the dis-ambiguation functionality provided by MetaMap (i.e., returning only the most likely concept for each query) could lead to worse retrieval per-formance than using all the candidate mappings. Thus, we use the one-to-many mapping results generated by MetaMap, in which each aspect can be mapped to multiple concepts.

Unfortunately, such one-to-many concept map-pings could hinder the retrieval performance in the following two ways.  X  The multiple concepts generated from the  X  The one-to-many mapping results generated
To address the limitations caused by the inac-curate mapping results, we propose to apply ax-iomatic approaches (Fang and Zhai, 2005) to reg-ularize the weighting strategies for concept-based representation methods. In particular, we first formalize retrieval constraints that any reasonable concept-based representation methods should sat-isfy and then discuss how to regularize the existing weighting strategies to satisfy the constraints and improve the retrieval performance.

We first explain the notations used in this sec-tion. Q and D denote a query and a document with the concept-based representation. S ( Q,D ) is the relevance score of D with respect to Q . e i denotes a concept, and A ( e ) denotes the query aspect associated with e , i.e., a set of concepts that are mapped to the same phrases as e by us-ing MetaMap. i ( e ) is the normalized confidence score of the mapping for concept e generated by MetaMap. c ( e,D ) denotes the occurrences of concept e in document D , df ( e ) denotes the num-ber of documents containing e . | D | is the docu-ment length of D . Imp c ( e ) is the importance of the concept such as the concept IDF value, and Imp A ( A ) is the importance of the aspect. 4.2 Unified concept weighting regularization We now discuss how to address the first challenge, i.e,. how to regularize the weighting strategy so that we can take into consideration the fact that concepts associated with the same query aspect are not independent. We call a concept is a variant of another one if both of them are associated with the same aspect.

Intuitively, given a query with two aspects, a document covering both aspects should be ranked higher than those covering only one aspect. We can formalize the intuition in the concept-based representation as the following constraint.
Unified Constraint: Let query be Q = { e 1 ,e 2 ,e 3 } , and we know that e 2 is a variant of e . Assume we have two documents D 1 and D 2 with the same document length, i.e., | D 1 | = | D 2 | . If we know that c ( e 1 ,D 1 ) = c ( e 3 ,D 2 ) &gt; 0 , c ( e 1 ,D 2 ) = c ( e 3 ,D 1 ) = 0 and c ( e 2 ,D 1 ) = c ( e 2 ,D 2 ) &gt; 0 , then S ( Q,D 1 ) &gt; S ( Q,D 2 ) .
It is clear that existing retrieval functions would violate this constraint since they ignore the rela-tions among concepts.

One simple strategy to fix this problem is to merge all the concept variants as a single concept and select one representative concept to replace all occurrences of other variants in both queries and documents. By merging the concepts together, we are aiming to purify the concepts and make the similar concepts centralized so that the assumption that all the concepts are independent would hold.
Formally, the adjusted occurrences of a concept e in a document D is shown as follows: where c ( e,D ) is the original occurrence of con-cept e in document D , EC ( e ) denotes a set of all the variants of e including itself (i.e., all the concepts with the same preferred name as e ), and Rep ( EC ( e )) denotes the representative concept from EC ( e ) .

It is trivial to prove that, with such changes, ex-isting retrieval functions would satisfy the above constraint since the constraint implies TFC2 con-straint defined in the previous study (Fang et al., 2004).

Now the remaining question is how to select the representative concept from all the variants. There are three options: select the concept with the maxi-mum IDF, average IDF, or minimum IDF. We con-duct exploratory data analysis on these three op-tions. In particular, for each option, we generate a plot indicating the correlation between the IDF value of a concept and the relevance probability of the concept (i.e., the probability that a document containing the concept is relevant). Note that both original and replaced IDF values are shown in the plot for each option. Figure 2 shows the results. It is clear that the right plot (i.e., selecting the con-cept with the maximum IDF as the representative concept) is the best choice since the changes make the points less scattered. In fact, this can also be confirmed by experimental results as reported in Table 5. Thus, we use the concept with the max-imum IDF value as the representative concept of all the variants. 4.3 Balanced concept weighting We now discuss how to address the second chal-lenge, i.e., how to regularize the weighting strat-egy to deal with the arbitrarily inflated statistics caused by the one-to-many mappings.

The arbitrary inflation could impact the impor-tance of the query aspects. For example, as shown in Figure 1, one aspect is mapped to two con-cepts while the other is mapped to three. More-over, it could also impact the accuracy of the con-cept IDF values. Consider  X  X olonoscopies X  and  X  X dult X , it is clear that the first term is more im-portant than the second one, which is consistent with their term IDF values, i.e., 7.52 and 2.92, re-spectively. However, with the concept-based rep-resentation, the IDF value of the concept  X  X olono-scopies X (C0009378) is 2.72, which is even smaller than that of concept  X  X dult X  (C1706450), i.e., 2.92.
To fix the negative impact on query aspects, we could leverage the findings in the previous study (Zheng and Fang, 2010) and regularize the weight-ing strategy based on the length of query aspects to favor documents covering more query aspects. Since each concept mapping is associated with a confidence score, we can incorporate them into the regularization function as follows: f ( e,Q ) = (1  X   X  ) +  X   X  where i ( e ) is the normalized confidence score of concept e generated by MetaMap, and  X  is a pa-rameter between 0 and 1 to control the effect of the regularization. When  X  is set to 0, there is no reg-ularization. This regularization function aims to penalize the weight of concept e based on its vari-ants as well as the concepts from other aspects. In particular, a concept would receive more penalty (i.e., its weight will be decreased more) when it has more variants and the mappings of these vari-ants are more accurate.

To fix the negative impact on the concept IDF values, we propose to regularize the weighting based on the importance of the query aspect. This regularization can be formalized as the following constraint.

Balanced Constraint: Let Q be a query with two concepts and the concepts are associ-ated with different aspects, i.e., Q = { e 1 ,e 2 } , and A ( e 1 ) 6 = A ( e 2 ) . Assume D 1 and D 2 are two documents with the same length, i.e., | D 1 | = | D 2 | , and they cover different concepts with the same occurrences, i.e., c ( e 1 ,D 1 ) = c ( e 2 ,D 2 ) &gt; 0 and c ( e 2 ,D 1 ) = c ( e 1 ,D 2 ) = 0 . If we know Imp c ( e 1 ) = Imp c ( e 2 ) and Imp A ( A ( e 1 )) &lt; Imp A ( A ( e 2 )) , then we have S ( Q,D 1 ) &lt; S ( Q,D 2 ) .

This constraint requires that the relevance score of a document should be affected by not only the importance of the concepts but also the importance of the associated query aspect. In a way, the con-straint aims to counteract the arbitrary statistics in-flation caused by MetaMap results and balance the weight among concepts based on the importance of the associated query aspects. And it is not dif-ficult to show that existing retrieval functions vio-late this constraint.

Now the question is how to revise the retrieval functions to make them satisfy this constraint. We propose to incorporate the importance of query as-pect into the previous regularization function in Equation (2) as follows:
Note that Imp A ( A ( e )) is the importance of a query aspect and can be estimated based on the terms from the query aspect. In this paper, we use the maximum term IDF value from the aspect to estimate the importance, which performs better than using minimum and average IDF values as shown in the experiments (i.e., Table 6). We plan to study other options in the future work. 4.4 Discussions Both proposed regularization methods can be combined with any existing retrieval functions. In this paper, we focus on one of the state of the art weighting strategies, i.e., F2-EXP function de-rived from axiomatic retrieval model (Fang and Zhai, 2005), and explain how to incorporate the regularization methods into the function.

The original F2-EXP retrieval function is shown as follows: where b is a parameter control the weight of the document length normalization.

With the unified concept weighting regulariza-tion, the revised function based on F2-EXP func-tion, i.e., Unified , is shown as follows: where c mod ( e,D ) and c mod ( e,Q ) denote the modified occurrences as shown in Equation (1). It can be shown that this function satisfies the unified constraint but violates the balanced constraint.
Following the similar strategy used in the previ-ous study (Zheng and Fang, 2010), we can further incorporate the regularization function proposed in Equation (3) to the above function to make it satisfy the balanced constraint as follows: where f ( e,Q ) is the newly proposed regular-ization function as shown in Equation (3). This method is denoted as Balanced , and can be shown that it satisfies both constraints.
 5.1 Experiment Setup We conduct experiments using two data sets from the TREC Medical Records track 2011 and 2012. The data sets are denoted as Med11 and Med12 . Both data sets used the same document collection with 100,866 medical records, each of which is as-sociated with a unique patient visit to the hospi-tal or emergency department. Since the task is to retrieve relevant visits, we merged all the records from a visit to form a single document for the visit, which leads to 17,198 documents in the collection. There are 34 queries in Med11 and 47 in Med12 . These queries were developed by domain experts based on the  X  X nclusion criteria X  of a clinical study (Voorhees and Tong, 2011; Voorhees and Hersh, 2012).

After applying MetaMap to both documents and queries, we can construct a concept-based collec-tion. Since documents are often much longer, we can first segment them into sentences, get the map-ping results for each sentence, and then merge them together to generate the concept-based rep-resentation for the documents.

Table 1 compares the statistics of the term-based and the concept-based collections, including the number of unique tokens in the collection (i.e., the number of terms for term-based representa-tion and the number of concepts for concept-based representation), the average number of tokens in the documents (AvgDL) and the average number of tokens in the queries for these two collections (AvgQL11 and AvgQL12). It is interesting to see that the number of unique tokens is much smaller when using the concept-based indexing. This is expected since terms are semantically related and a group of related terms would be mapped to one semantic concept. Moreover, we observe that the document length and query length are similar for both collections. This is caused by the fact that concepts are related and the MetaMap would map an aspect to multiple related concepts.

Table 2 summarizes the methods that we com-pare in the experiments. Following the evalua-tion methodology used in the medical record track, we use MAP@1000 as the primary measure for Med11 and also report bpref. For Med12 , we take infNDCG@100 as the primary measure and also report infAP@100. Different measures were cho-sen for these two sets mainly because different pooling strategies were used to create the judg-ment pools (Voorhees and Hersh, 2012). 5.2 Performance Comparison Table 3 shows the performance under optimized parameter settings for all the methods over both data sets. The performance is optimized in terms of MAP in Med11 , and infNDCG in Med12 , re-spectively.  X  and b are tuned from 0 to 1 with the ment over Term-BL, Concept-BL and TSConcept-BL is statistically significant at 0.05 level based on Wilcoxon signed-rank test, respectively.

Results show that Balanced method can signifi-cantly improve the retrieval performance over both collections. Unified method outperforms the base-line methods in terms of the primary measure on both collections, although it fails to improve the infAP on Med12 for one baseline method. It is not surprising to see that Balanced method is more ef-fective than Unified since the former satisfies both of the proposed retrieval constraints while the lat-ter satisfies only one. Finally, we noticed that the performance difference between TSConcept-BL and Concept-BL is not as significant as the ones reported in the previous study (Limsopatham et al., 2013d), which is probably caused by the difference of problem set up (i.e., record-level vs. visit-level as discussed in Section 3.1).

We also conduct experiments to train parame-ters on one collection and compare the testing per-formance on the other collection. The results are summarized in Table 4. Clearly, Balanced is still the most effective regularization method. The test-ing performance is very close to the optimal per-formance, which indicates that the proposed meth-ods are robust with respect to the parameter set-ting.

Moreover, we would like to point out that the testing performance of Balanced is comparable to the top ranked runs from the TREC Medical records track. For example, the performance of the best automatic system in Med11 (e.g., Cen-gageM11R3) is 0.552 in terms of bpref, while the performance of the best automatic system in Med12 (e.g., udelSUM) is 0.578 in terms of infNDCG. Note that the top system of Med12 used multiple external resources such as Wikipedia and Web, while we did not use such resources. More-over, our performance might be further improved if we apply the result filtering methods used by many TREC participants (Leveling et al., 2012). 5.3 More Analysis In the Unified method, we chose the concept with the maximum IDF as the representative concept Table 6: Estimating query aspect importance Table 7: Regularization components in Balanced among all the variants. We now conduct experi-ments on Med11 to compare its performance with those of using average IDF and minimum IDF ones as the representative concept. The results are shown in Table 5. It is clear that using maximum IDF is the best choice, which is consistent with our observation from the data exploratory analysis shown in Figure 2.
 In the Balanced method, we used the maximum IDF value to estimate the query importance. We also conduct experiments to compare its perfor-mance with those using the minimum and aver-age IDF values. Table 6 summarizes the results, and shows that using the maximum IDF value per-forms better than the other choices.

As shown in Equation (3), the Balanced method regularizes the weights through two components: (1) normalized confidence score of each aspect, i.e., query aspect, i.e., Imp A ( A ( e )) . To examine the effectiveness of each component, we conduct ex-periments using the modified Balanced method with only one of the components. The results are shown in Table 7. It is clear that both components are essential to improve the retrieval performance.
Finally, we report the performance improve-ment of the proposed methods over the Concept-BL for each query in Figure 3. Clearly, both of the proposed methods can improve the effectiveness of most queries, and the Balanced method is more robust than the Unified method. Medical record retrieval is an important domain-specific IR problem. Concept-based representa-tion is an effective approach to dealing with am-biguity terminology in medical domain. How-ever, the results of the NLP tools used to gen-erate the concept-based representation are often not perfect. In this paper, we present a general methodology that can use axiomatic approaches as guidance to regularize the concept weighting strategies to address the limitations caused by the inaccurate concept mapping and improve the re-trieval performance. In particular, we proposed two weighting regularization methods based on the relations among concepts. Experimental re-sults show that the proposed methods can signif-icantly outperform existing retrieval functions.
There are many interesting directions for our fu-ture work. First, we plan to study how to automat-ically predict whether to use concept-based index-ing based on the quality of MetaMap results, and explore whether the proposed methods are appli-cable for other entity linking methods. Second, we will study how to leverage other information from knowledge bases to further improve the per-formance. Third, more experiments could be con-ducted to examine the effectiveness of the pro-posed methods when using other ranking strate-gies. Finally, it would be interesting to study how to follow the proposed methodology to study other domain-specific IR problems.

