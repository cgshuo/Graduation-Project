 Probability density function estimation is a fundamental component in several stream mining tasks such as outlier detection and classification. Th e nonparametric adaptive kernel density estimate (AKDE) provide s a robust and asymptotically consistent estimate for an arbitr ary distribution. However, its extensive computational requirements make it difficult to apply this technique to the stream environment. This paper tackles the issue of developing e fficient and asymptoti cally consistent AKDE over data streams while heeding th e stringent constraints imposed by the stream environment. We propose the concept of local regions to effectively synopsize local density features, design a suite of algorithms to maintain the AKDE under a time-based sliding window, and analyze the estimates X  asymptotic consistency and comput ational costs. In addition, extensive experiments were conducted with real-world and synthetic data sets to demonstrate the effectiveness and efficiency of our approach . G.3 [ Probability and Statistics ]: Nonparametric statistics Algorithms, Performance Data Mining, Data Streams, Kernel Density Estimation 
Advances in hardware and soft ware technologies have caused a surge in the growth and availability of voluminous information. Data streams are realizations of vast information that are fast, continuous, mutable, ordered, and unbounded [5]. Numerous data streams stem from the ubiquitous time series and span a wide range of applications such as finance, medicine, and sensor networks. Some well-known stream s are traded stock prices, electroencephalograms), and roadway performance metrics (e.g., speed). Applying analysis and mining techniques can help deepen knowledge in these fields and enhance their applications. Therefore, the development of stream analysis tools can provide far-reaching impacts to the general discipline of stream mining. 
Underpinning many stream mining tasks is the use of the probability density function (PDF) for the most recent data [3, 5, 11, 22]. However, in real-world situations, the PDFs are usually unknown and therefore must be es timated. Examples of stream mining tasks that employ estimated PDFs include: outlier detection by modeling a sensor X  X  sample distribution and selecting data points of low probability [ 21]; concept drift detection via comparison of current and past da ta streams X  probability density estimates [2]; and pattern discovery in Internet traffic by visualizing the estimated probabi lity density function of arriving packets [22]. One could further the efficacy of probability density estimates by enabling queries for an explicit time range [3]. The extension would be able to respond to questions such as,  X  X hat is the distribution of telnet connections within the last hour? X   X  X ow have the roadway X  X  speed and volume distributional patterns changed in the past two hours since the snow began? X  The extension of an explicit time range is naturally modeled by a time-based window. Hence, it can be s een that providing probability density estimates over a time-based sliding window will serve as a valuable tool in the study of da ta streams. Emphasis on the most recent data implies the need for the stream mining techniques to furnish results in real-time. A dditionally, practical constraints dictate that the techniques posse ss finite memory and perform at most a linear pass on the data elements [5, 16]. Meeting and balancing these requirements is a key goal in stream research. 
An effective technique to estimate an unknown probability density function is the nonparam etric kernel density estimate (KDE). KDE possesses several adva ntages that include: rigorous mathematical foundation; gene ralization to other density estimators such as orthogonal seri es and histograms; asymptotic consistency; and inheritance of the kernel function X  X  continuity and differentiability prop erties [19, 20]. The standard formulation of the univariate KDE is given as follows: for  X  independent and identically distributed sample points (i.e., kernel centers)  X  with corresponding weights  X   X  .. X   X  , bandwidth  X  , and a kernel function  X ( X ) , the kernel density estimate is The accuracy of the KDE does not significantly depend on the choice of kernel function  X ( X ) , but rather on the selection of  X  [19]. The bandwidth  X  is regarded as a smoothing parameter: a high  X  can generate a smooth shape density whereas a low  X  tends to provide an undersmoothed but potentially more accurate estimate. The drawback of the KDE formulation is the requirement of assigning a global bandwidth. Due to the existence of local features, a single global bandwidth may not be sufficient to model complex density st ructures (e.g., multimodal distributions). When the global ba ndwidth KDE technique is used as the core step in mining tasks (e.g., outlier detection), the generated results can be misleadi ng and potentially disastrous for mission critical applications (e.g., military sensor surveillance). To overcome this problem, this paper proposes the use of an adaptive KDE (AKDE) to improve the estimation accuracy of local features within data st reams. The AKDE is a variable bandwidth technique, which has been shown to be effective in capturing local density features [18-20]. The general formulation of the AKDE is as follows:  X  where  X ( X   X  ) is the bandwidth function that is inversely proportional to the true density  X ( X   X  ) . 
In essence, the AKDE increases its learning capacity (via smaller bandwidth) in regions of high density where the local features are likely to originate from the true distribution. This AKDE characteristic is consistent with the real-world observation: inherent local features tend to occur in regions of high probabilities whereas noise-induced local features occur in areas of low probabilities. This adapti ve scheme enables the AKDE to provide superior estimation accuracy over the classical KDE. 
Although the AKDE can produce superior estimation quality to the classical KDE, its computational cost (  X ( X   X  ) ) far exceeds the traditional KDE (  X ( X ) ). In the AKDE, the bandwidth,  X  (  X  ) , is computed from the true density,  X ( X ) . Because the true density is unknown, a pilot function is define d to provide an estimate for  X ( X ) . Generally, the pilot function is modeled by the classical KDE. This choice impl ies that evaluating  X ( X ) is an  X ( X ) process. Therefore, computing a query under the AKDE is an  X ( X   X  ) operation because  X ( X ) is computed at least once for each sample point. This evaluation appr oach cannot be applied to data Due to AKDE X  X  extensiv e computational cost, there are currently no works that provide adaptive ke rnel density estimates for the data stream e nvironment. 
A crucial property provided by the KDE is asymptotic consistency, that is, as the samp le size approaches infinity, the KDE converges to the true density. This KDE property is conducive to the data stream environment because the unbounded sample size provided by the data stream can improve the KDE X  X  accuracy. Therefore, to enable AKDE to be a viable tool in stream analysis, a new online technique mu st be developed that is both efficient and asymptotically consistent. 
This paper tackles the issue of developing efficient and asymptotically consiste nt AKDE over data stream s. To the best of our knowledge, this paper is the first attempt that addresses the issue of applying AKDE to the data stream se tting. To that end, we propose, the online Local Region KDE (LR-KDE), an adaptive kernel density estim ation framework for processing univariate data streams. The ma jor components of the proposed framework are (1) a new partition-based variable bandwidth strategy to capture local dens ity features and to improve maintain and compute kernel de nsity estimates, and (3) a fixed-size memory time-based slid ing window. We also analyze the asymptotic costs and consistency property of the proposed online LR-KDE. Extensive experiments were conducted to demonstrate the effectiveness and efficiency of the approach. 
The proceeding sections are orga nized as follows. Section 2 preliminary . Section 4 details our proposed framework. Section 5 presents the computational complexity and asymptotic consistency analysis. Se ction 6 demonstrates empirical results and validation. Section 7 gives the conclusion.
Early efforts in computationall y tractable KDEs can be found in the domain of offline analysis. Zhang et al. proposed a method to maintain a space efficient KDE by using the CF-tree [23] to cluster a set of kernels into a single kernel known as the CF-Kernel [24]. The CF-Kernel employs a global bandwidth which can lead to oversmoothing and loss of local density information. Gray et al. proposed a kernel space partitioning technique by utilizing a KD-Tree and bounded support kernels to offline data sets [9]. The KD-Tree reduces computations by effectively pruning kernels, which do not contribute to the density query. 
Several recent work s have been proposed for the online management of KDE. These online techniques can be classified into the following three categories: 1. Grid-based KDE  X  provides a uniform and discretized 2. Sample-based KDE  X  employs a sampling methodology on 3. Cluster-based KDE  X  utilizes kernel me rging techniques to 
Grid-based and sample-based: Aggarwal proposed a framework to capture the structural evolution of data streams by using a grid-based KDE [2]. The kernels are summarized in a multidimensional grid where a common bandwidth is employed for each dimension. Concepts of forward and reverse density profiles are introduced to discover the occurrences of concept drifts. Subramaniam et al . proposed an approach for outlier detection in sensor networks by modeling the densities of node observations [21]. Their scheme employs a uniformly sampled sequence-based sliding window to summarize the current set of kernels. A global bandwidth is applied to the sampled set of kernels. Wegman et al. introduced an online KDE for the analysis of Internet traffic [22]. They suggested the use of a sequence-based and exponentially aging sliding window to accommodate a fixed storage environment. To derive estimates, a single bandwidth KDE is employed on the sliding window. 
Cluster-based: Zhou et al. introduced the M-Kernel, a cluster-based KDE maintenanc e strategy which performs numerically-based kernel mergers under a fading window [25]. The merging algorithm combines two kernels which produces the minimum integrated absolute error between the original pair and the merged result. This scheme allows for a fixed memory representation of the kernels. However, under the M-Kernel, the cons istency of the estimate is not guaranteed and the approach can exhibit high update costs due to its numerical -based merging strategy. In a similar vein, Heinz et al. proposed a constant time pair-wise merging technique that guarantees consistency [12]. Their kernel method employs a single bandwidth that has been shown to be effective in approximating the classical KDE. 
Table 1. Summary of stream-based KDE techniques.  X  is the 
Table 1 provides a summary of the key characteristics of current stream-based KDEs. Most KDE approaches employ single a bandwidth strategy hence they cannot accurately estimate the stream X  X  local features. The M-Kernel, although it applies a asymptotically consistent. As a c onsequence, the M-Kernel is not guaranteed to converge as the sample size increases. The proposed LR-KDE differentiates itself from existing works in the following aspects: 1. Local feature estimation  X  models local de nsity features via 2. Consistency  X  assures asymptotic consistency under the 3. Linear pass processing  X  employs  X  (  X  ) algorithms to 4. Time-based window  X  provides a fixed-size time-based 
Online histograms have also been proposed in the field of database optimization to provide query selectivity estimates and approximate queries [13]. Some online histograms include dynamic quantiles [8], equidept h histograms [7], and V-optimal histograms [10]. Due to the histogr am X  X  inherent discontinuities and slower convergence, the hist ogram may not be suited for the tasks of stream analysis [20]. 
A formal description of the dens ity estimation problem is given as follows: Given a data stream,  X = X  X  X  ( X ) , X  ( X ) ,.., X  ( X )  X  associated with a timestamp,  X ( X  ( X ) )  X  [ X   X  X  X  X  , X   X  X  X  X  and maintain an adaptive kernel density estimator,  X  The storage, update, and query costs of  X   X   X  X  X  X  X  (  X  ) should be at most  X ( X ) , where  X  is a constant and  X  X   X   X   X  = X  .

With respect to stream appli cations, one of the fundamental issues of the AKDE is its high co mputational cost for determining the bandwidth,  X ( X ) (eq. 1). To reduce this computational requirement, a bandwidth approxi mation technique is proposed for the AKDE. Let  X = {  X   X  :  X   X   X  X  X   X  X  X  ,1 X  X  X  X  X  X , X   X   X  X  X  } be an ordered representation of the kernels in  X  . Define the relative density variance ,  X  (  X , X  ) , as the sample variance of the set of estimated densities at  X   X  .. X   X   X  X  X  , where 1 X  X  X  X  X  X  X  X  X  . The bandwidth approximation pro cedure is given as follows: 2. For each local region, assign a bandwidth that is unique to its The above scheme serves to captu re the local densities within the total span of the distribution. The obtained approximation is consistent with the structure of AKDE X  X  bandwidth i.e., similar bandwidth values are assigned to kernels of similar densities. Hence, the local regions can be seen as a piecewise constant representation of the structure of  X ( X ) . 
Two design challenges exist in applying the above approximation approach: (1) the efficient derivation of the relative density variance; and (2) the deve lopment of a technique for local region identification. In the following, the Pair-wise Adjacent Distance Uniformity theorem is introduced to provide an efficient venue for estimating the densit y variance. The theorem is followed by the definition of an optimization problem for the task of identifying the local regions. 
As previously defined, local regi ons provide a total and disjoint partitioning of the kernel domain which minimizes the intra-variance of the density estimates. A unique bandwidth is assigned to each local region based on the regional kernel characteristics. If each kernel is given its own unique local region, then the local region based KDE (with the appropriate bandwidth function) is a reformulation of the traditional AKDE. However, if the number of the local regions is less than the number of kernels, then the local region KDE is an approximation of the AKDE. The problem now is to derive a method which ca n efficiently deduce the density estimate variance for a given ra nge of kernels. One possible approach is to estimate the densities via the traditional KDE approach. However, this poses the same computational issue as the AKDE. An alternativ e and more viable solution is to employ the pair-wise and adjacent kernel distances to derive relevant properties of the density variance. To that endeavor, the Pair-wise Adjacent Distance Uniformity theorem is proposed. 
Let  X  be a set of ordered and id entically weighted kernels whose pair-wise and adja cent distance variance is zero, then under certain conditions, it can be shown that the densities at the kernel centers (under a global bandwidth KDE) in  X  are uniform. The estimating the density variance through information of the kernels X  pair-wise and adjacent distances (PAD). As a result, computationally tractable bandwidth approximations can be developed from the kernels X  PAD information. The proof of the Pair-wise Adjacent Distance Uniformity theorem is as follows: THEOREM 3.1 (Pair-wise Adjacent Distance Uniformity): Let  X = {  X   X  :  X   X   X  X  X   X  X  X   X  X  X  X  1 X  X  X   X  X  X  } be a set of sorted kernel centers associated to a bounded and radially-symmetric kernel function with uniform weight and bandwidth. Furthermore, let the sorted kernels be adjacently equidistant such that |  X   X  X  X   X  X  X   X   X   X  X , X  . Suppose  X = {  X   X  :  X   X  + X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  . Then for the kernel density estimate,  X  following property must hold:  X   X  (  X   X  ) = X   X  (  X   X  )  X   X  PROOF. Let  X   X  , X   X   X  X  X  be any two kernel centers and define a set  X  ={ X   X  : | X   X   X  X  X |&lt; X  X  X  X  X  X  X  X  X  X  X  X  X  X  .  X   X  is the set of kernel centers for which their corresponding bandwidths intersect  X  , thus  X  possess all the kernels that cont ribute non-zero values to the kernel densit y estimate,  X   X  (  X  ) . Consider  X   X  loss of generality choose a kernel center,  X  X  X  X   X  , from  X  Because all the kernel centers within  X  are adjacently equidistant, there must exist an element,  X  X  X  X   X  , from  X   X   X   X  X  X  . Since the kernels are radially-symmetric, equal bandwidth, and identically weighted, the contribution of  X  to  X   X  (  X   X  ) is equal to the contribution of  X  to  X   X  (  X   X  in  X   X  contributions are equal. This relationship also holds for any  X  in  X  corresponding to an  X  in  X   X  relationship between  X  in  X   X  sum of the kernel contributions of  X   X  are equal. Therefore,  X   X  (  X   X  ) = X   X  (  X   X  )  X   X   X  , X 
Leveraging upon Theorem 3.1, identification of the local regions can be achieved by minimizing the variance of the kernels X  pair-wise and adjacent distance values. In the following, an optimization problem is established to identify local regions based on the kernels X  PAD inform ation. Assume that a local region,  X  , possesses a set of kernels (centers),  X   X   X  X  X   X  X  X   X  X  X   X  for 1 X  X  X  X  X  X  X  X  X  , and  X  is the total number of kernels. Set  X   X  X   X   X  X  X  adjacent distance to be  X   X  ( X )= X  and define the variance of L  X  X  kernel pair-wise and adjacent distances as follows: where  X   X   X  is the number of kernels in  X  . 
In practice, the density estim ate makes use of arbitrarily weighted kernels. Henc e, consideration of varying weights must be made in the local region formulation. Let  X   X  sorted kernel centers assigned to a bounded, radially-symmetric, and equal bandwidth kernel function, such that |  X   X  X  X   X  X  X  |  X  X , X  . Let  X ( X   X  ) be the non-negative weight of kernel center  X  and  X   X  (  X   X  ) be the density estimate at  X   X  . From the KDE definition,  X  X  X  X  X  X  X   X  (  X  )  X  is equivalent to minimizing  X  X  X  X  X  X  X  (  X  )  X  . Let  X  the weight of kernel  X   X  X  X  X  in  X  , and define L  X  X  kernel weight variance,  X  X  X  X  (  X   X  X  ) , as follows: 
Using the local region PAD (eq. 2) and the kernel weight variance (eq. 3) formulae, partition the entire sample points  X  .. X   X  into  X  disjoint local regions by minimizing the aggregate variance of all  X   X  and  X   X  X  : where  X  is the weight assigned to L  X  X  kernel weight variance. 
In summary, the solution to the above local region optimization problem generates local region s with minimum overall intra-density variation. Moreover, the pr oblem is solved by exclusively employing the kernels X  PAD and weight information which are amenable to efficient implementations. 
The local region identification problem can be solved via dynamic programming techniques in time  X ( X   X   X ) where  X  is the number of local regions; however, this solution exceeds the constraints of the data stream problem. Therefore, an incremental local region identification tech nique is proposed. The technique employs a locally optimal decision strategy to reduce the identification task to  X ( X  X  X ) . As a result, the online Local Region KDE (LR-KDE) is proposed for the efficient generation of density estimates in data streams. 
The online LR-KDE is composed of the following two primary components: 1. Local region management  X  identifies and manages local 2. Kernel maintenance  X  updates the kernels with new data 
Figure 1 illustrates the LR-KDE approach. An online binning method is applied on the set of all kernels where each bin represents a local region. The bins are maintained in the data structure, bin list , which can store at most  X  number of bins. The kernel set manages and organizes all kernels in a sorted queue ordered by their cent ers. A maximum of  X  X  X  X  kernels is model a time-based sliding window (using the FIFO policy) and to support efficient operations of kernel expirations and insertions. The following is a summary of the main operations for inserting a new data point  X   X  X  X  X  : 1. Bin list update : Find the bin whose interval intersects  X  2. Kernel set insertion : Insert  X   X  X  X  X  into position by searching 3. Time list synchronization : After K new is added to the kernel 
The following proposes an incremental bin management approach for the identification of local regions. A formal definition of the bin and its property are given as follows: Bin Vector  X  X  bin vector,  X  , is defined as follows:  X  following feature definitions refer to set  X   X  X  .  X  squared sum of the kernel centers.  X   X  X  gives the sum of the kernel weights.  X   X  X  X  yields the squared sum of the kernel weights.  X  indicates the sum of the weighted kernel centers.  X  the weighted squared sum of the kernel centers. Let  X   X  sorted kernel centers in  X   X  X  , then the sum of adjacent kernel centers product is  X   X  X  =  X   X   X   X   X  X  X   X   X   X  X   X  X  X  X  . 
The bin vector possesses the additivity property [23]. This property allows the combining of bins in constant time. Let  X  and  X  ( X ) be a pair of disjoint bins, max X  X   X  X  ( X ) kernel in  X   X  X  ( X ) , and min X  X   X  X  ( X )  X  = minimum kernel in  X  max X  X   X  X  ( X )  X &lt; min X  X   X  X  ( X )  X  , then the sum of bin vectors  X  ( X ) +  X  ( X ) is:  X  Bin Creation and Merger: Bins are updated as new kernels enter  X   X  X  X  X  enters: (1) the number of bins in bin list is less than  X  ; and  X   X  X  X  X   X  X  center intersects any one of the bins, then a reference to  X  global kernel set . Suppose that the number of existing bins is less than  X  , and  X   X  X  X  X  does not intersect any bin. Since the number of bins is less than  X  , a new bin is created with  X   X  X  X  X  as its first and center point. The bin management algorithm continues in this manner until  X  bins have formed. Now assume that there are  X  scenario, a new bin is created for  X   X  X  X  X  and two bins (including one formed by  X   X  X  X  X  ) are merged to maintain  X  number of bins. 
The merger of two bins is defined by its additivity property (eq. 5). Because the bins represent lo cal regions, they must remain continuous and mutually disjoint. Therefore, the merger can only occur between adjacent bins. The merger candidates are selected based on the objective function of the local region optimization (eq. 4). The following is an expa nded expression of the uniformly weighted local region PAD variance (eq. 2) in terms of kernel centers  X   X  , X   X  ,.., X   X  : By utilizing the above form ula, the variance of the  X  wise adjacent kernel distance is determined to be as follows (for uniformly weighted kernels):  X  Similarly, the  X   X  X  X  bin X  X  kernel weight vari ance is given as follows which is a reformulation of (eq. 3) in terms of the bin vector components: Therefore, a merger will occur for the pair of adjacent bins which minimizes the following objective function: 
When  X   X  X  X  X  is added, updating all of the bin X  X  features (with the exception of  X   X  X  ) follows straight-forward algebraic calculations and incurs constant time execution. To efficiently update  X  following operations are employed: 2. Update  X   X  X  as follows:
In order to maintain the kernels in a fixed memory environment, a kernel clustering paradigm is employed. If the size of the kernel set is  X  , then the insertion of  X  overflow and invoke the merger of two kernels at the kernel merging approach as follows [12]:  X  ( X ) (  X  ) and  X  ( X ) (  X  ) are selected such that the following  X  distance is minimized: It can be shown that the  X   X  distance increases proportionally with the kernel distance, hence th e mergers only occur between adjacent kernels. It can be shown that minimizing  X   X  error can be done in constant time [11]. 
The remainder of this section pr esents the time-based sliding window algorithm which ensures that all elements in kernel set are within the time range, [ X   X  X  X  X  , X   X  X  X  X  ] . The algorithm is followed by a description of the densit y evaluation which leverages upon the bin list structure for efficient computation. Lastly, the selected kernel function and bandwidth form are provided. 
Time-based Sliding Window: Let  X   X  X  X  be the length of the time window. To produce a sliding window, set  X   X  X  X  X  to the current time and set  X   X  X  X  X  = X   X  X  X  X   X  X  X   X  X  X  . The time list is implemented as a First-In-First-Out queue with the head node being the oldest timestamp. When  X   X  X  X  X  is inserted into the kernel set , the time handling algorithm inserts the kernel X  X  arrival time,  X  kernel X  X  extended time span,  X   X  X  X  , (i.e., time to remain in window Assume that two kernels,  X  ( X ) and  X  ( X ) , are merged to become  X  ( X  X  X  X  X  X  X ) . The time list updating process proceeds as follows: 1. Remove the corresponding time list nodes of  X  ( X ) and  X  2. Define  X  ( X  X  X  X  X  X  X )  X  X  arrival time and time span as follows: 3. Insert  X  ( X  X  X  X  X  X  X )  X  X  arrival time into the time list 
Kernel expiration is performed by comparing the time list  X  X  head node, deleting all a ssociated kernels with  X   X   X  X  X  =0 from the kernel set , and updating the bin list . As for expiring a kernel with  X   X  X  X  &gt;0 , assume that the weight of the kernel is uniformly distributed across its time span . Therefore, the kernel will remain in the kernel set but its weight will be adjusted to the following: where  X   X  ( X ) is the weight of kernel  X  . 
Density Evaluation: For a query point  X  , the evaluation algorithm proceeds as follows: 1. Bin search and kernel filtering : Find the relevant set of bins 2. Kernel search : Scan the kernels within each relevant bin and 
The evaluation technique presen ted above capitalizes upon the bin list structure by effectively pruning kernels which do not contribute to the final estima tion result. Furthermore, the bandwidth is computed from the bi n features in constant time. Discussion on the exact bandwid th form is given below. 
Kernel Function and Bandwidth Form Selection: The class of admissible kernel functions must satisfy the conditions of Theorem 3.1 which requires that the kernels be (1) radially-symmetric and (2) compactly supported. The compact support property also eases the burden of computing the density estimates by eliminating kernels with  X   X  Epanechnikov kernels [20]. It has been shown that the Epanechnikov kernel minimizes the asymptotic mean integrated squared error (AMISE) and theref ore it is optim al amongst all other kernels [15]. The Epanechni kov kernel is given as follows: Due to Epanechnikov kernel X  X  compact support, radial-symmetry, and optimality w.r.t. the ASIME, this kernel is chosen for the proposed LR-KDE. 
Each bin of the LR-KDE describes a region of similar density, hence, the captured distribution w ithin each bin can be expected to be unimodal. Also recall th at the LR-KDE assigns a unique bandwidth to each bin. Therefor e, for each bin, the chosen bandwidth form is the normal rule which has been shown to perform well under a wide range of unimodal distributions [20]:  X  ( X ) is the number of kernels in bin  X  . Note that  X  ( X ) can be directly calculated from the bin features i.e., is achieved in  X (1) time. 
This section provides the consistency results and cost complexities of the LR-KDE. An important criterion for any KDE is its consistency, th at is, as the number of samples approaches infinity, the KDE converges to th e true density. The time/space complexities of the online main tenance technique and density evaluation approach are analyzed to guarantee that the LR-KDE heeds the constraints of the data stream environment. 
Assume that all  X  samples are uniquely accessible and continuously persistent. To prov e the consistency of the local region KDE, it suffices to show that the density estimate within a local region fulfills Parzen X  X  condition for the asymptotic convergence of a KDE [17]. Parzen provides a sufficient condition described as follows: If kernel  X ( X ) is a bounded Borel function with  X  |  X ( X ) |  X  X  X &lt; X  ,  X   X ( X ) X  X  X =1 and |  X  X  X ( X ) |  X 0 as |  X  |  X  X  X  and bandwidth  X   X  indexed on  X  sample points satisfies then for the KDE,  X   X  (  X  ) , and true density,  X ( X ) , 
Since a local region employs the Epanechnikov kernel, the kernel conditions given by Parzen are completely satisfied. Recall that the bandwidth selected for a local region is the normal rule:  X   X  =  X  5  X   X   X   X  X  X  . Hence, it can be seen that the following holds:  X   X   X 0 as  X  X  X  X  . Therefore, Parzen X  X  first bandwidth condition is satisfied. As for the second cond ition, note that a local region is continuous and has compact support, which implies which implies Therefore, 
Let  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  ( X   X  X  X  X  ) be the total cost of inserting  X  then the total cost of the insertion procedure is: sequential search over the bin list and merging a pair of bins. Hence the cost of inserting  X   X  X  X  X  into the bin list is: the kernel list is dominated by the kernel search and the  X  updates for each pair of adjacent kernels within the affected bin. cost of the kernel list insertion is: Time list cost : The dominant cost for inserting into the time list is the removal of all expired kern els. This operation involves updates on the  X   X  errors and bin statistics. Let  X  be the number of expired kernels and  X  be the total number of kernels within a bin of an expired kernel, then the cost of inserting  X   X  X  X  X  into the time list is: Since  X , X , X  X  X  X  , where  X  is the maximum size of the kernel list , the total cost of inserting  X   X  X  X  X  is: Total space cost : The total space cost of the online maintenance algorithm is derived from storing the three primary structures, bin list , kernel list , and time list in memory: The above analysis shows that the time and space complexities of the proposed online kernel maintenance algorithm are  X ( X ) . Since  X  is fixed, the proposed maintenance strategy provides constant runtime and space complexities which meet the linear-pass constraint. 
A single density evaluation compos es of a sequential search of the bin list and a scan of all kernels which provides a non-zero contribution to the query point. Let  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  (  X  ) be the total cost of determining the density at  X  ,  X  be the number of bins then the total evaluation cost is: Since  X  X  X  X   X  X  X  , the total evaluation runtime cost is: In practical applicati ons, only a fraction of the kernels contributes to  X  , which implies that  X + X  X  X  X  . Therefore, the total evaluation cost can be much less than the asymptotic cost described above. The space cost of the density evaluation is  X  ( 1 ) since the evaluation algorithm make s use of a single counter to store the current density sum. Similar to the time and space complexities of the maintenance algorithm, the evaluation runtime and space costs are also constant. 
A set of comprehensive experime nts have been conducted to validate the effectiveness and efficiency of the proposed online LR-KDE. The experiments focused on three core metrics: estimation quality, maintenance ti me, and density evaluation time. Other existing online KDE techniques were included for performance comparisons. The experiments applied a battery of synthetic and real-world data sets to study the effects of various streaming conditions on the LR -KDE. The experiments were conducted on a Windows Server 2003 Enterprise Edition (32-bit) operating system. The hardware platform was a 2.0 GHz Intel Pentium Dual with 3 GB of RAM. 
The data sets were comprised of 2 synthetic and 4 real-world time series data. The first 25K (if available) data samples were used for the experiments. A description of the data sets is shown in the table below: 
Table 3 provides all of the evaluated techniques and parameters: For all of the evaluated techniques in Table 3 (except for time sample KDE), the time windows were set to be the total length of the data stream. 
The first component of the experiments was to measure the estimation quality of the online KDE techniques. This was accomplished by establishing the ground truths for all data sets. In the synthetic case, the exact density structures are given in Table 2. For the real-world data sets, the true densities are defined to be the density estimates produced by the offline AKDE. For the AKDE, the nearest neighbor KDE was used as the pilot estimate [20]. The error measure used wa s the Root Mean Square Error (RMSE) which is defined as follows: where  X   X  (  X  ) ( X ) is the  X  density estimation technique and  X  are query points which uniformly divide the entire span of the distribution. 
The maintenance time of an online KDE is defined as the total points. This measures the efficiency of the online KDE in updating its kernel structures to match the current stream. The density evaluation time is defined as the average time to evaluate and compute a single density quer y. The density evaluation time was measured after all of the data points were processed. In these experiments, 10 trials were conducted for each evaluation component and the averaged results were reported. 
For each metric and data set, the LR-KDE was evaluated against the existing stream-based KDE techniques. The following provides the experiment results.

Estimation Quality: Figure 2 gives the estimation quality results of all data sets and KDE techniques. Each graph represents the number of processed sample points and the y-axis is the RMSE of the density estimates. The experiment showed that the LR-KDE provided lower RMSE than all competing techniques in the MIX2, MIX8, ROBOT, TRAFFIC, POWER, and EEG data sets. The LR-KDE produced significant RMSE reductions in MIX2 and MIX8 with errors that were at most half of the next best performing technique. Note that the time sample and sequence sample KDEs pr ovided almost identical performance in MIX2 and MIX8. The LR-KDE converged as more samples were processed in the MIX2, MIX8, POWER, and EEG data sets. However, for TRAFFIC and ROBOT, the RMSE of LR-KDE increased at 20K and 24.5K points, respectively. This behavior was similarly exhibited in other techniques such as M-Kernel KDE. In the TRAFFIC data set, the sequence sample KDE produced a drastic change in its RMSE at the 20K mark. All of these observations suggest the presence of concept drifts in the POWER and EEG data sets. 
Figures 3 and 4 show the plotte d estimates of MIX2 and MIX8 by two of the lowest error at taining techniques, LR-KDE and Heinz KDE. The x-axis represents the query points and the y-axis shows the density. MIX2 and MIX8 possess multiple isolated modes which can be difficult to estimate with a single bandwidth KDE. For example, the Heinz KDE tended to oversmooth the distributions as indicated by the underestimated peaks and overestimated valleys. The overs moothing can be attributed to Heinz KDE X  X  use of the normal rule bandwidth which is known to oversmooth multimodal distributions [20]. In an attempt to improve the accuracy of Heinz KDE, the only available parameter, kernel size, was increased from 1K to 100K. The increased kernel size produced  X  1% improvement in the RMSE and showed no observable difference in the plotted estimates. When the kernel size for LR-KDE was increased to 100K, it resulted in 5.5% (MIX2) and 7.8% (MIX8) improvements in the RMSE. Although the LR-KDE employs the normal rule bandwidth, it restricts uniform bandwidth assignment to regions of similar densities. As a result, the LR-KDE identified all of the modes and accurately captur ed the peaks and valleys. 
Maintenance Time: Figure 5 illustrates the impact of the various data streams on LR-KDE X  X  kernel maintenance times. The maintenance times for processing the entire data. The real-world POWER, TRAFFIC, and ROBOT da ta sets showed the most improvements for the LR-KDE. This observation is attributable to the data sets X  largely ordered samples which reduced the amount of scans the LR-KDE needed to perform. In the MIX8 and EEG data sets, the LR-KDE provided lower times than all of the non-sample-based approaches. Note that the sample-based techniques produced nearly identical results within the various data sets. 
Figure 6 shows the relationship between maintenance time and sample size. The x-axis is the number of samples processed and the y-axis is the maintenance time. Due to space constraint, only the POWER data set is shown but similar trends can be observed in the other data sets. All of the KDE techniques exhibited times that were linear to the sample size; however, LR-KDE and Heinz KDE provided the lowest cost ra tes in POWER, TRAFFIC, and ROBOT. The linear trend of LR-KDE is also consistent with the analyses of Section 5. Standard deviation for all trials was  X  5%.
Density Evaluation Time: Figure 7 shows the density query times of all data sets. The x-axis represents a specific data set and the y-axis gives the average evaluation time for a single density query. For MIX2, MIX8, EEG, and POWER data sets, the LR-KDE consistently produced lower ev aluation times than all of the competing techniques. For TRAFFIC and ROBOT, the LR-KDE performed equally to Heinz KDE but better than the other techniques. For the sample-based KDE, regardless of the kernel function employed, the entire kernel set must be scanned to generate a density estimate. This a pproach resulted in a consistent, but higher evaluation times than the LR-KDE and Heinz KDE. In summary, the results demonstrated that the LR-KDE evaluation performance was better than or at least equal to all of the competing techniques. Standard deviation for all trials was  X  10%. 
Application of the local regi on concept to kernel density estimates has shown to be effect ive in modeling the local density features in data stream. As a result, the LR-KDE provided superior estimation quality over th e competing techniques in both real-world and synthetic data sets. The LR-KDE was also able to improve the estimation accuracy in data sets which did not exhibit strong localities (e.g., predominantly unimodal data sets such as ROBOT). Since real-world data streams can exhibit strong local features (e.g., multiple random processes), it can be expected that stream mining applications woul d benefit from the use of the LR-KDE. 
A concrete mining task that would benefit from LR-KDE X  X  improved estimation quality is the density-based clustering. In particular, those density-based approaches that employ bump hunting algorithms for determining the cluster centers [20]. For example, Figures 3 and 4 show that the LR-KDE captures and differentiates all of the modes a lmost exactly which would allow the bump hunting method to optimall y isolate the cluster centers. In contrast, the next best pe rforming technique (Heinz KDE) could not capture some of these modes which would increase the likelihood for the bump hunting algorithm to dismiss some potentially vital clusters. In the context of a real-time surveillance application, such false dismissals could indicate missed emergent events. 
Density estimation can also be a pplied to the problem of outlier detection. An outlier can be defined as a sample point whose probability of occurrence falls below a predefined threshold [21]. Suppose that density es timates are employed to perform the above outlier detection scheme, then the rates of false dismissals are dependent on the accuracy of the estimated model. For instance, if the estimate is oversmoothed, then the rate of false dismissals may be increased in regions of low probability. In these regions, the true density of the sample points may be much smaller than their estimated values. Hence, a more accurate density estimation model, such as LR-KDE, can help reduce the false dismissals and improve the outlier detection performance. 
LR-KDE also improved the computational efficiency over the competing techniques. Local regi ons allow non-relevant kernels to be pruned from further processing which results in the simultaneous reduction of main tenance and query times. Furthermore, the LR-KDE retained the same order of space cost as the other online KDE techniques. These cost reductions are essential to stream mining tasks where results need to be furnished in real-time and pro cessed in a fixed-size memory environment. 
This paper addresses the issue of developing an efficient and asymptotically consistent onlin e adaptive density estimation technique to meet the stringent constraints of the data stream environment. In that endeavor, we propose an online and local region based AKDE framework (LR-KDE) for univariate streams. The contributions of this work include (1) the first approach of its kind to provide AKDE over data st reams, (2) the introduction of the local regions to effectiv ely approximate the AKDE with guaranteed asymptotic consistency, and (3) the design of linear-pass algorithms to maintain and co mpute kernel density estimates over a time-based sliding window . Theoretical analyses are computational complexities of the LR-KDE. Experiments demonstrated that the LR-KDE enhanced estimation quality, improved maintenance performance, and reduced density evaluation time over the existing techniques. Future work in developing a multivariate local region based KDE will be investigated. [1] "Freeway Performance Measurement System (PeMS) [2] C. Aggarwal, "A framework for diagnosing changes in evolving [3] C. Aggarwal and P. S. Yu, "A survey of synopsis construction in [4] A. Asuncion and D. J. Newman, "UCI Machine Learning [5] B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom, [6] B. Babcock, M. Datar, and R. Motwani, "Sampling from a [7] P. Gibbons, Y. Matias, and V. Poosala, "Fast incremental [8] A. Gilbert, Y. Kotidis, S. Mu thukrishan, and M. J. Strauss, [9] A. Gray and A. Moore, "Rap id evaluation of multiple density [10] S. Guha, N. Koudas, and K. Shim, "Approximation and [11] C. Heinz, "Density estimation over data streams," in [12] C. Heinz and B. Seeger, "Towards kernel density estimation [13] Y. Ioannidis, "The histor y of histograms (abridged)," in [14] E. Keogh, X. Xi, L. Wei, and C. A. Ratanamahatana, "The UCR [15] T. Ledl, "Kernel density estimation: theory and application in [16] L. O'Callaghan, N. Mishra, A. Meyerson, S. Guha, and R. [17] E. Parzen, "On estimation of a probability density function and [18] S. R. Sain and D. W. Sc ott, "On locally adaptive density [19] D. W. Scott, Multivariate Density Estimation . New York: Wiley [20] B. W. Silverman, Density estimation for statistics and data [21] S. Subramaniam, T. Palpan as, D. Papadopoulos, V. Kalogeraki, [22] E. J. Wegman and D. J. Marchette, "On some techniques for [23] T. Zhang, R. Ramakrishna n, and M. Livny, "BIRCH: an [24] T. Zhang, R. Ramakrishna n, and M. Livny, "Fast density [25] A. Zhou, Z. Cai, L. Wei, and W. Qian, "M-Kernel merging: 
