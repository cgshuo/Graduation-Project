 Traditional online learning for graph node classification adapt-s graph regularization into ridge regression, which may not be suitable when data is adversarially generated. To solve this issue, we propose a more general min-max optimization framework for online graph node classification. The derived online algorithm can achieve a min-max regret compared with the optimal linear model found offline. However, this algorithm assumes that the label is provided for every node, while label is scare and labeling is usually either too time-consuming or expensive in real-world applications. To save labeling effort, we propose a novel confidence-based query approach to prioritize the informative labels. Our theoreti-cal result shows that an online algorithm learning on these selected labels can achieve comparable mistake bound with the fully-supervised online counterpart. To take full advan-tage of these labels, we propose an aggressive algorithm, which can update the model even if no error occurs. The-oretical analysis shows that the mistake bound of the pro-posed method, thanks to the aggressive update trials, is bet-ter than conservative competitor in expectation. We finally empirically evaluate it on several real-world graph databas-es. Encouraging experimental results further demonstrate the effectiveness of our method.
 H.2.8 [ Database Management ]: Database applications X  Data mining ; I.2.6 [ Artificial Intelligence ]: Learning Learning Theory; Algorithm Min-Max Optimization; Online Learning; Sampling; Graph Node Classification
Graphs, such as Facebook 1 , Amazon network, and citation network, play an important role in many real-world appli-cations. In particular, graph node classification has drawn significant attention, for example, to identify the labels of comments on Twitter or to prioritize the potential customer-s in social networks [23, 27, 11]. To solve this problem, a classification model can be trained on a set of node-label pairs from the graph, in terms of both offline [8] and online settings [21]. Offline learning can query label whenever the nodes are stored, thus demanding a high memory space. In contract, online algorithm learns the nodes in a streaming order. In specific, online learning can only access the label of the current node. After processing the node, the current input is discarded and cannot be stored for further query. As a result, online algorithm is efficient and scalable, especially for the high dimensional and large-scale graph dataset [21].
In fact, most of the online learning algorithms [5, 26, 9] are designed for vector-based data. Unlike the vector da-ta setting, to build an algorithm on graph node, we have to consider the impact of graph structure on these nodes, for example, Gu et al. adapt the graph Laplacian regular-ization into online setting [18]. Although online learning is quite efficient, it assumes that all labels of nodes are pro-vided. It clearly limits its application to many real-world scenarios, in which labels are scare and labeling all nodes is very expensive. To address this issue, selective sampling is introduced [14, 7, 6, 25, 18], that is an active online learn-ing approach that accesses a fraction of labels to build a model. Its objective is to achieve a good trade-off between classification error and the number of queried labels. A pi-oneering work of selective sampling on graphs was proposed in [18]. However, it assumes an underline rule to generate a antee the performance in an adversarial setting where the actual labels (i.e. y t , t  X  1) are unknown and they may be chosen adversarially by  X  X ature X  for the unlabeled nodes (i.e. x t , t  X  1) [32, 21]. This called adversarial classification problem is closely related to intrusion detection in computer networks, weather forecast and biometric authentication, in which malicious instances may weaken the effectiveness of the classifier [16, 28].

To design a robust online classification model in adver-sarial environments, we propose a new framework for graph node classification, by exploiting a min-max optimization s-trategy [31]. In this framework, the derived online algorith-h ttp://www.facebook.com m, Min-max Optimization for Online Learning on Graph ( MOOLG), can bound the choices of an adversary under a stochastic setting of data generation [32, 1]. However, this algorithm will query every node during the learning pro-cess, making it inefficient for many real-world applications. To make it scalable on large graphs, we develop a novel confidence-based query method to query only a fraction of labels. This query method not only depends on the mar-gin, but also the prediction confidence on the current nodes, which will query a fraction of labels, on which the MOOLG can achieve a comparable mistake bound with the one of MOOLG that learns on all the labels. Moreover, MOOL-G updates the hypothesis only on error trials, thus wasting the correctly predicted labels that are useful to improve the model. To make full use of these labels, we propose another algorithm, Confidence-based randomized Query for Selec-tive Sampling on Graph (CQSSG), hybrids the conservative update with aggressive one, which can conduct updates ag-gressively even if no error occurs. Theoretical analysis shows that the mistake bound of CQSSG is better than the online model [5] and selective sampling algorithm [7], which can be considered as a theoretical guarantee for our aggressive learning method. Finally, extensive experiments on graph data show the proposed algorithms outperform the existing state-of-the-art online learning methods.

The remainder of this paper is organized as follows. Sec-tion 2 provides related work. Section 3 introduces the pre-liminaries and the setting of graph node classification. Sec-tion 4 develops an online learning algorithm on graph. The proposed selective sampling algorithm and its theoretical analysis are present in section 5. Section 6 empirically e-valuates the algorithm. Section 7 concludes this paper.
In this section, we briefly introduce the online learning algorithm and selective sampling algorithm in the setting of vector-based data and graph-based data.
Online learning has been extensively studied in the ma-chine learning community. Due to the sequential nature of online learning, it is very efficient and scalable to be applied to the large-scale datasets [36, 37, 38, 22]. Online learning algorithm can be categorized into conservative algorithms [5, 9, 36] and aggressive algorithms [15, 26]. An algorith-m is called conservative if it updates the hypothesis on only mistake trials, while an algorithm called aggressive conducts an update even if its prediction is correct.
 A pioneering work of online learning on graph data is Graph Percenptron Algorithm (GPA), which is a conserva-tive algorithm [20, 19]. Inspired by this work, Gu et al. pro-posed an online algorithm, namely OLLGC, which derived the online version of Laplacian regularization [18]. Howev-er, all these graph-based online algorithms mentioned above belong to conservative algorithms. In this work, we propose an aggressive online algorithm, which is proved better than the conservative algorithm in both theoretical and empirical results.
Standard selective sampling, designed for vector-based da-ta, combines the setting of online learning and active learn-ing [29, 17, 35]. These algorithms are generally categorized into first-order algorithms [9, 4, 7] and second-order algo-rithms [25, 6]. A first-order algorithm queries the labels based on a concept of  X  X argin X . More specifically, the al-gorithm is likely to query of a sample that lies close to the decision boundary. However, this kind of model is unable to optimize the direction and scale of the update. To ad-dress this issue, a second-order algorithm is proposed recent-ly, which issues a query based on a notion of  X  X ncertainty X . It usually chooses an update trial in the direction with little observed instances for current model. However, few method-s combine two quantities (margin and uncertainty) to make a query decision, while we will propose a strategy based on both them.

Different from vector-based setting assuming i.i.d. on da-ta, few algorithms are designed for graphs. SSLGC [18] are the most relevant to our work, which is a second-order al-gorithm that decides to query based on the  X  X ncertainty X . Several recent works focus on the active-transductive learn-ing [24, 34]. However, these methods are off-line setting where the observed instances are stored in a pool for fur-ther query, which consumes more memory than the online setting.

While extensive works are studied in both fields of selec-tive sampling algorithm under vector-based and graph-based setting, we are the first effort to combine min-max optimiza-tion and graph regularization to derive an online algorithm on graph. Moreover, we propose a novel selective sampling algorithm on graph that hybrids the conservative update with aggressive one, which can take full advantage of the queried labels to improve the model.
In this section, we first introduce our notations. Then we review a graph regularization framework for classification.
In this paper, lower case letter is used as scalar (e.g. x), lower case bold letter as vector (e.g. v ), upper case letter as element of a matrix (e.g. D ii ) and bold-face upper letter as matrice (e.g. A ). An identity matrix is denoted as I and zero vector as 0 with an appropriate size. We denote the transpose of a vector m as m  X  , the inverse of a matrix A as A  X  1 , and the pseudo inverse of L as L  X  . Finally, a elements  X  i , i  X  [1 , n ], and the  X  2 -norm of vector w  X  R
We define a graph as G = ( V , E ) with an vertex set V = { v i | i  X  [1 , n ] } , and an edge set E = { e ij = ( v i , v V } . An adjacency matrix for the graph is denoted as S  X  R n  X  n , where the element value S ij  X  R is computed by the edge affinity of a pair { v i , v j } . Graph Laplacian is defined as L = D  X  S , where D is the diagonal matrix with D ii = P k S ik while the remain elements are 0. Giv-en graph Laplacian L , we denote its eigenvectors as V = [ v 1 , . . . , v n ], and its eigenvalues as  X  = diag(  X  1 , . . . ,  X  =  X  1  X  . . .  X   X  n ). We assume graph G is connected and undi-rected in this paper.

Graph regularization [30] is built based on the concept of label smoothness over graph, formatted as 1 2 P n i ,j =1 f ) assigned labels for graph nodes (i.e. f i : v i  X  R ) . In this paper,we solve the following problem in the setting of binary classification, nodes, and b &gt; 0 is a parameter to control the balance of the squared loss and Laplacian regularization. In the classi-fication setting with labeled and unlabeled nodes on graph, this optimization is to learn the function f with following re-quirements: (1) the function values for labeled nodes should be close to the given labels for that nodes; (2) nodes should satisfy label smoothness on the whole graph, namely, the points nearby in the graph should have similar labels by f ; (3) function values should be regularized without overfitting (i.e. ill-posed problem).

To solve the problem in Eq. (1) with a linear model, we consider its dual form. According to the definition of graph kernel [30, 3], the function f is defined as, where L  X  is the pseudo inverse of L and  X  is a parameter vector. Motivated by the work [18], we assume L  X   X  M  X  M , rank matrix where d  X  n . According to Eckart-Young-Mirsky theorem [12], we claim that M  X  M is the best rank-d approximation of L  X  . Thus the kernel function f can be rewritten in a linear model form, where u = M  X   X  R d . Substituting Eq. (3) back into Eq. (1), we get In this way, we derive a formulation similar to ridge-regression, except it contains additional regularization, which makes it shrink the prediction. And Eq. (4) can be used to derive graph-based online learning with new data representation for graph node.
Now we are ready to derive the online learning algorithm on graph. We first introduce the problem setting of online learning. Then we exploit a min-max optimization problem [31] to derive the online model on graph.
The objective of online learning is to achieve a low re-gret compared with best linear model in hindsight. Let m 1 , . . . , m t m t  X  R d ( t  X  n ) be a sequence of nodes from columns of M , and y i  X  X  X  1 } with i &lt; t , the graph regular-ization in Eq. (4) can be represented as an online version: At round t , online learning algorithm receives an incoming node m t , and predicts its binary label  X  y t = m  X  t u  X  { X  1 } . After prediction, its actual label y t  X  R is revealed, and the algorithm uses it to update model and then proceeds to the next round. At each iteration, the performance of the online model is evaluated by the squared loss,  X  t ( alg ) =  X  ( y ( y t  X   X  y t ) 2 . The cumulative loss suffered by the algorithm taneous loss and by L T ( u ) = P T t  X  t ( u ) be its cumulative loss. The goal is to achieve low regret compared with the best linear function. Formally, we define the regret of an algorithm to be The objective is to let the loss of the online algorithm con-vergent to the loss of the best linear function u , that is, we have R T ( u ) = o ( T ). We will solve the problem in Eq. (6) as follows.
To minimize the regret above, we introduce a last-step minmax prediction, proposed by [13] and [31]. Following this optimization approach, the derived online learning out-puts a minmax prediction assuming the current iteration is the last one, and  X  y t and y t serve as min and max quanti-fiers over the optimization problem, that is, the goal of the learner is to minimize the regret while the goal of the ad-versary is to maximize it. Note that our objective function is different from [31], since the best model u is learned from graph regularization. Our motivation is also different from [13], because the derived output is for graph classification. Adapting online graph regularization Eq. (5) into the min-max algorithm, the graph-based online learning predicts,  X  y T = arg min  X  y We next compute the actual prediction via solving the min-max optimization in Eq. (7). We start with additional no-tation,
A t = b I + 2 Then we define the internal infimum function, and solve the internal infimum over u in the following lem-ma.

Lemma 1. For all T  X  1 , the function R ( u ) = P T t =1 ( m y ) u
T given by, We leave the proof in the Appendix. Algorithm 1 M OOLG: A Min-max Optimization for On-line Learning on Graph 1: I nput: Adjacency matrix S , rank d , and regularization 2: Output: w T 3: Compute L  X  and M  X  R d 4: Initialize: A 0 = b I , b 0 = 0 , w 0 = 0 5: for t = 1 , . . . , T do 6: Receive m t  X  R d 8: Predict  X  y t = sign ( b  X  t  X  1 A  X  1 t m t ) 9: Query the actual label y t 10: if  X  y t 6 = y t then 11: Update A t = A t  X  1 + 2 m t m  X  t 12: Update b t = b t  X  1 + y t m t . 13: else 15: end if 16: end for
By using lemma 1, we obtain the solution for internal i nfimum R ( u T ). Substituting (9) back in (7), we obtain the following form of the minmax problem,
The min-max optimization problem is defined that func-tion G ( X  y t , y t ) should be minimal in  X  y T and maximal in y Equipped with lemma 1, we derive the optimal solution for the min-max problem in Eq. (10) in the following theorem.
Theorem 1. For all T  X  1 and y t  X  { X  1 } , the optimal prediction for the function  X  y T = min  X  y T max y T G ( X  y We leave the proof in the Appendix.

Note that the predicted solution p T can turn to be a linear case, the form of the derived algorithm can be comparable to the best linear function u . We call the algorithm (defined using (11) and (8)) MOOLG, a Minmax Optimization for Online Learning on Graph. However, it is not efficient for MOOLG to perform update in each iteration. To make it scalable on large graphs, we adopt a mistake-driven update rule, motivated by [5], to let update issued only when an error ( X  y t 6 = y t ) occurs. Note that our update format is dif-ferent from [5], because it adds additional input-covariance m t m  X  t to matrix A t to avoid overfitting in classification. Moreover, MOOLG is different from OLLGC [18], since it adds the current node into the weight vector w t for label prediction. We summarize our proposed online algorithm on graph MOOLG in Algorithm 1.
In this section, we first introduce the setting of selec-tive sampling. Then we propose a confidence-based query method and theoretically evaluate the effectiveness of the queried labels.
Unlike the traditional online algorithm that queries al-l labels, selective sampling has to decide whether to query label or not for each coming node m t ( t &lt; T ). If label is queried of, the algorithm can update learner with m t and y otherwise, no action is performed and learner continues to proceed next one. Query and update decisions are denoted as binary variables Q t and Z t at time t . When Q t = 1 iif label y t is queried of; Q t = 0, no query conducted. The up-date decision Z t is similar setting. Note that selective sam-pling is an online version of active learning. Thus, its best predictor can be derived in a form of online learning with query/update choice on each node, w t  X  1 = A  X  1 t b t  X  1 A
The derived model can turn to be a recursive form in terms of A  X  1 t and b t . The recursive form for b t is: Using Sherman-Morrisan Identity [2], a non-inverted recur-sive form for A  X  1 t is derived: A s a result, matrix A  X  1 t can be calculated incrementally with time complexity of O ( d 2 ) whenever the update is in-voked (i.e. Q t Z t = 1).
The purpose of selective sampling algorithm is to make few mistakes with small amount of queries. To achieve this goal, we propose a randomized query tuning by a confidence score  X  t : a coin with bias 2 h/ (2 h + max(0 ,  X  t )) is flipped; if the coin turns up heads, then actual label y t is queried; otherwise Q t = 0 and no query performed. The randomized query has been considered in several works [7, 25]. Unlike these methods, we introduce a new confidence  X  t in a ran-domized query. We start with the notations below, Then an additional notation can be derived,
Definition 1. (Confidence-based Query) Given any in-put node m t , t  X  [1 , T ] , an algorithm predicts label with p be computed by a randomized method tuning by  X  t , where  X  t =  X ( p t , r t ) = p 2 t + 2 | p t | X  r t 1+2 r
T he  X  t is a function parameterized by the variables p t r , which have been used for label query in several works. The quantity p t , defined as  X  X argin X , is a distance of an input to the model boundary [5, 7], while the r t as  X  X ncer-tainty X  is a projection of current input into the spectrum of observed instances [6, 18, 10]. We observe that  X  t is pos-itively related to p t while negatively related to r t , that is, the query will be not issued only when a node is far from b oundary with a large margin (i.e. | p t | ) as well as the model has less uncertain (i.e. r t ) towards its prediction. In this condition, the algorithm has a high confidence  X  t toward its prediction, thus a label can be omitted safely with a low extensive works mentioned above were studied in both two variables, we proposed a new method to combine p t and r t to make a query decision. We will further study the effec-tiveness of our confidence query in the following theorem.
Intuitively, a query decision is effective iff it can control the probability of making a mistake when the algorithm does not query this label. To analyze the effectiveness of the query decision, we derive a mistake bound for an online al-gorithm that trains on only queried labels { t : Q t = 1 } . We start with the following lemma.

Lemma 2. For all t  X  1 , R t ( u ) is an online graph reg-ularization over u . An online algorithm predicts with p t b t  X  1 A  X  1 t m t , then the following equality folds,
P roof. We omit the proof due to the limited space. But similar proof can be found at [13] Theorem 3.

In our randomized query, the mistake trials can be parti-t ioned into two disjoint sets, set S = { t : 2 h 2 h +m ax(0 ,  X  includes indices on which a stochastic query is conduct, while is a deterministic query. We denote M = { t : y t p t  X  0 } as the set of mistake trials and let M = |M| . We let U t = { i  X  t : Z i Q i = 1 } be the set of updates. Finally, we denote  X  ( x ) is a hinge loss over x .

Theorem 2. Let an arbitrary node-label sequence ( m t , y where t &gt; 1 , an online learning (i.e. MOOLG) learns on on-then the following inequality holds for any u  X  R d ,
E [ M ]  X  h T he expectation of queried label is upper bound by E [ |D| + P
Proof. In lemma 2, if the trial is such that Z t Q t = 0, then U t = U t  X  1 with no update, which yields inf u R t inf u R t  X  1 ( u ). Hence the equality,
Z h olds for all trials t . We drop the term  X  Z t Q t r t p negative ( r t  X  0 and p 2 t  X  0), and sum over t = 1 , . . . , T . Note that inf u R 1 ( u ) = 0, Expanding the squares in both sides and performing manipulation, we obtain
X = inf  X  X holding for any u  X  R d . Since u is a random variable, we use h u to replace u where h &gt; 0. Using inequality 1  X  x  X  max { 1  X  x, 0 } yields hZ t Q t  X  hZ t Q t y t u hZ ror Z t Q t = 1, we simplify with the notations A t and  X  X When an error incurs at trial t  X  X  , the function  X  t can be positive ( t  X  X  X  X  ) or negative ( t  X  X  X  X  ): In the former subcase, Q t is random variable with expectation E [ Q t ] = In the later subcase, E [ Q t ] = 1. We bound T o summarize, E quipped with Eq. (16), we complete our proof. Note that labels are selected randomly. Thus, all expectations occur-ring are w.r.t this randomization.

Remark 1 . Online algorithm, i.e. MOOLG, run on these queried labels achieves a comparable mistake bound with the fully-supervised algorithm OLLGC ([18], Corollary 5), due P ues of matrix A t . Second, u  X  A U T u = P t  X  X  k u k 2 = f  X  Lf , assuming k m t k 2  X  B and = M B . In addition, this mistake bound on the queried labels is compa-rable with the bound of MOOLG learning on all labels. Sim-ilar with loss bound of min-max online algorithm learning on all labels in [13] Theorem 3, MOOLG run on all label-s is bound by the cumulative loss of optimal linear predic-tor and log | A T |  X  log T , which is comparable with mistake bound run on queried labels. In general, the MOOLG learn-ing on these queried labels performs not worse than OLLGC and MOOLG that queries all labels in expectation. In other word, our query method is effective to control the probability of making a mistake when it decides not to query this label.
Inspired by the confidence-based query, we propose a new selective sampling on graph. We call our algorithm CQSS-G, the Confidence-based Query for Selective Sampling on Graph, as present in Algorithm 2. It maintains two quanti-ties: A  X  1 t and b t with initial values A 0 = b I and b each round t , the algorithm observes a node m t and predicts its binary label with the learner w t = A  X  1 t b t  X  1 . Then its which yields to a stochastic query and deterministic query. Algorithm 2 C QSSG: Confidence-based randomized Query for Selective Sampling on Graph 1: I nput: Adjacency matrix S , rank d , regularization pa-2: Output: w T 3: Compute L  X  and M  X  R d 4: Initialize: A 0 = b I , b 0 = 0 5: for t = 1 , . . . , T do 6: Receive m t  X  R d 8: Compute  X  t = p 2 t + 2 | p t | X  r t 1+2 r 10: Set Q t = 1 and Z t = 1 11: Query label y t  X  X  X  1 } 12: else 14: if Q t = 1 then 15: Query label y t  X  X  X  1 } 16: Set Z t = 1 if y t 6 =  X  y t ( Z t = 0 otherwise) 17: end if 18: end if 19: Update b t = b t  X  1 + Q t Z t y t m t 2 1: end for en by mistake. If an error occurs ( X  y t 6 = y t ), the algorithm updates model in terms of A  X  1 t and b t in a recursive way; otherwise, no action takes place and we proceed the nex-t one with A t = A t  X  1 and b t = b t  X  1 . We observe that In this case, an aggressive update is performed, that is, we update model even if no error occurs.

To further understand the aggressive method, we compute under what condition a deterministic query will be issued. A query is issued with probability 1 when  X  t = | p t | 2 1+2 r t  X  0 . By solving for | p t | , we have If | p t | is less than  X  ( r t ), a deterministic query/update is will be issued with a probability strictly less than 1. And the upper bound of  X  ( r t ) increases with r t . If r t = 0 with a minimal uncertainty, a deterministic query is issued only when an input lies on the boundary (i.e. | p t |  X   X  (0) = 0). However, if r t = 1 with the largest value of uncertainty, this implies that an aggressive query is issued whenever margin | p | is no more than  X  (1)  X  0 . 16.

In the following theoretical analysis, we show the superior-ity of our aggressive learning algorithm. Besides stochastic query trials S and deterministic query trials D , we denote is an aggressive update without predicted mistake, and let C = | C | . We omit other trials since they do not affect the model. U t = { i  X  t : Z i Q i = 1 } is the update trials in Alg. 2.

Theorem 3. Let an arbitrary node-label pair sequence be sequence with h &gt; 0 and  X  is hinge loss, then for all u  X  R The expected number of queries is upper bounded by E [ |D| + P P roof. Due to limited space, we omit the theory proof.
Remark 2 . It is obvious that this upper mistake bound is strictly lower than the one of MOOLG in Theorem 2, due to the deduction of expectation trials E [ C ] . In addition, The the corresponding terms of [7] Thm. 3. The reason is that P our bound is subtracted by the update trials E [ C ] . Hence, we summarize that our mistake bound, thanks to the additional deduction of aggressive update trials E [ C ] , is better than the expectation version of mistake bound of MOOLG in Theo-rem 2 and one of conservative selective sampling algorithm ([7] Thm. 3), which is considered as a theoretical support for our aggressive learning algorithm.

Remark 3. h &gt; 0 is a parameter of the algorithm acting as a scaling actor in the randomized method. The parameter h is affected by structure of graph. If we would know in advance, by setting a proper choice w e would minimize the bound and get
E [ M ]  X  The first two terms of this optimized bound is same as an expectation version of the mistake bound for the standard second-order Perceptron (SOP) algorithm, proven in [5]. As it turns out, our bound in Eq. (19) would be sharper than the online algorithm SOP, since the set of updates U T is formed by a randomized sampling method, which is typically smaller than the mistake trials in the fully-supervised algorithm (as SOP queries all the labels, it has higher chance to update model). This tends to shrink the three terms 1 2 h u  X  E [ A nents of our proposed bound. Nonetheless, their bounds are not comparable since they depend on the exact update trials in U T .
 Remark 4. As the term P t  X  X  lative hinge loss over the trials in U T for all u  X  R d , the mistake bound in (18) can be re-written as one by which the total number of mistakes exceeds a cumulative loss of the best linear model u over the update trials, The u  X  A U T u a lways lies between min k  X  k and max k  X  particular, u  X  A U T u =  X  k when u is the eigenvector asso-ciated with  X  k . In addition, P t r t 1+2 r d log(1 + T ) is substantially smaller than d log T whenever the spectrum of matrix A T is decreased rapidly. Thus, we conclude that the bound in Eq. (20) can achieve a regret of O (log T ) w.r.t. the best linear model, where T is the number of trials.
In this section, we first introduce data sets and experi-mental evaluation metrics. Then we present the empirical results to evaluate the proposed algorithms.
Data Sets: We use four real-world graph data sets to evaluate the proposed algorithms.

Coauthor 2 is an undirected coauthor graph from DBLP dataset in four areas, data ming , machine learning , infor-mation retrieval and database . There are a total number of 1711 authors denoted as nodes, and the numbers of their coauthored papers as the weights of edges.
 Cora 2 contains 2485 scientific publications with their cita-tion links. Each publication is categorized into one of sev-en classes, they are Case based , Genetic Algorithms , Neu-ral Networks , Probabilistic Methods , Reinforcement Learn-ing , Rule Learning and Theory .
 IMDB 3 is a graph that contains up-to-date movie informa-tion. The graph is modeled by co-actor association from 17046 movies of four genres: Romance , Action , Animation and Thriller .
 PubMed 4 contains 19717 scientific publications pertaining to diabetes categorized by one of three types. Citation net-work in PubMed consists of 44338 links.

We assume that graphs are undirected and connected. If some edges are directed, they are transformed into undi-rected graphs.If they are disconnected, the biggest connect-ed subgraph is selected to study. Table 1 summarizes the statistic results of data sets above.
 Evaluation Matrics and Parameter Setting: W e evalu-ate the performance of selective sampling with two measures: (i) cumulative error rate, (ii) number of queried labels. Cir-culative error rate evaluates the prediction accuracy of on-line learning algorithm while queried label number shows the label efficiency of an algorithm. It indicates that the s-maller both two measures, the better the performance of an algorithm. We compare the proposed algorithms with three baselines that are discussed in Section 2. We next introduce the algorithms we study and their parameter settings as fol-lows: GPA [20] is the state-of-the-art first order nonparametric online learning algorithm on graph. Note that the Percep-tron algorithm is not affected by the step-size. h ttp://www.cs.umd.edu/ sen/lbc-proj/data/ http://www.imdb.com/ http://www.cs.umd.edu/projects/linqs/projects/lbc/ OLLGC and SSLGC [18] are two second-order active on-line learning algorithms on graph. All parameters are tuned with grid search on a held-out random shuffle.
 MOOLG and CQSSG : are the proposed second-order on-line learning and selective sampling on graph. For both two methods, the parameter d is set to 100 since these algorithms achieve low error rate with small queried number. We tune shuffle. In CQSSG, we set h = 0 . 01 for Cora and Coauthor, h = 0 . 001 for IMDB and PubMed due to graph structure variable.

In order to compare these algorithms fairly, we randomly shuffle the sample ordering for each dataset. We run algo-rithms 20 times for each dataset and compute the average result. Finally, the above algorithms are designed for bina-ry classification. In order to apply the algorithms to those data sets with multiple classes, we use one-vs-other scheme to adapt binary classifiers to the multi-class scenarios.
The experimental results are presented in Table 2. We found that CQSSG outperforms all baselines consistently across all four data sets. We also show the results with respect to the round of online learning in Fig.1. In all sub-figures, the horizontal-axis represents the rounds of online learning, while the vertical-axis is the cumulative error rate and queried nodes, averaging over 20 times of shuffling order.
We can see the our improvement over GPA are always significant on every data set. This is consistent with previous observations in online learning: second-order algorithms are generally better than first-order algorithm [33]. The reason is due to the matrix A t which has a spectral structure to correlate with a best estimator u for observed instances [5].
MOOLG achieves comparable results with other two algo-rithms OLLGC or SSLGC. It is because the MOOLG out-puts a minmax prediction with a low regret with optimal linear model. However, when graph nodes are adversarially generated, MOOLG can bound the choice of adversary and achieves a more robust performance than the ridge regres-sion model [32].

CQSSG always enjoys smaller error rates than SSLGC with much fewer queried nodes (P-value &lt; 0.001), which shows our algorithm can save the labeling while maintains the high quality of prediction result. Generally speaking, the good performance is due to two reasons. First, the confidence-based query improves the label-efficiency of al-gorithm. Second, thanks to the aggressive learning, CQSS-G can achieve a convergence stage quickly, thus the query rate is reduced further when the model has learned sufficient knowledge of data.
We study the impact of parameter h &gt; 0 in the query method. The selective sampling algorithm with a small h would perform few number of queries. In specific, we set query for each value of h over the 20 times of experiments. The comparison results is shown in Fig.2.

We observe that CQSSG achieves the best performance consistently under different ratios of queried nodes, which validates the label-efficiency of our method. SSLGC updates the model only when an error occurs, thus it wastes some Figure 1: Cumulative error rate and number of label q uery with respective to online learning rounds on four datasets. Figure 2: A comparison between CQSSG and S SLGC with respect to different ratios of queried nodes. correctly predicted labels which are useful to improve the accuracy. Moreover, SSLGC is unable to turn into a small ratio of query in Coauthor and Cora datasets, that cannot guarantee the running process efficiently.
The efficiency of the algorithm is also affected by the rank of nodes. To study the impact of low-rank graph nodes on algorithms, we set the parameter d with the grid { 10, 100, 250, 500, 750 } . Cora and Coauthor are used as case study since similar conclusions are obtained on IMDB and PubMed. The results in Fig.3 show that CQSSG achieves better performance than SSLGC consistently under different rank approximation.

It is observed that with a high rank, both algorithms need a high number of queries to achieve a low error rate. Howev-er, a high queried number yields to a high chance of update. It causes an additional computational cost for the algorithm-s which update a model with time complexity of O ( d 2 ). To achieve a balance, we choose d = 100 in the rest of exper-Figure 3: A case study of low rank impact on per-f ormance. iments since the algorithm achieves a good accuracy while the queried number is quite small.
In this paper, we present a novel online learning and a se-lective sampling algorithms for graph classification based on min-max optimization. To the best of our knowledge, this is the first effort to combine the graph regularization and min-max optimization for graph classification. The derived online learning algorithm can address online graph classifi-cation problem where the labels are adversarially generat-ed, which is realized via the min-max optimization strate-gy. The selective sampling algorithm can effectively reduce labeling efforts, by only querying a fraction of informative labels. Theoretical result shows that our bounds are better than other second-order online learning and selective sam-pling algorithms. Finally, we empirically evaluate the pro-posed algorithms on several real-world datasets. Promising experimental results further validate the effectiveness of the proposed algorithms compared with other baselines in terms of the cumulative error rate and the number of queried la-bels.
 We would like to thank the anonymous reviewers for their helpful comments, and Quanquan Gu for his suggestions. Proof of Lemma 1 Proof. From R ( u ) = we have  X  R ( u ) = 2 A T u  X  2 b T = 0 and  X  R ( u ) = 2 A 0. Thus R ( u ) is convex and it achieves a minimal point if u T = A  X  1 T b T back into R ( u T ), and we have Proof of Theory 1
P roof. The adversary can choose any y T , thus the algo-rithm predicts  X  y T via minimizing the following maximization problem over y T , We use the equation below to re-write the optimization prob-lem,
Omitting all terms that are not depending on  X  y T and y T max
We manipulate the equation to be the maximization of a polynomial form over y T , given that y T  X  X  X  1 } , max This is a convex function, since m  X  T A  X  1 T m T  X  0 given that A
T is positive definite. Thus, we only have to consider y
T = 1 or y T =  X  1, the convex function reaches maximal, as follows,
Omitting the term unrelated to y T and  X  y T , we thus have to find a  X  y T in the following minimization form, We consider two cases: 1. b  X  T  X  1 A  X  1 T m T  X   X  y T  X  0, and 2. b 1. For b  X  T  X  1 A  X  1 T m T  X   X  y T , that is  X  y T  X  [  X  X  X  , b an optimal solution. If b  X  T  X  1 A  X  1 T m T  X  1, it achieves op-timal at 1. The case b  X  T  X  1 A  X  1 T m T  X   X  1 is similar. In the binary classification setting where  X  y T  X   X  1, we set  X  y
T =sign( p T ) where we define p T = b  X  T  X  1 A  X  1 T m T [ 1] J. Abernethy, A. Agarwal, and P. L. Bartlett. A [2] M. S. Bartlett. An inverse matrix adjustment arising [3] M. Belkin, P. Niyogi, and V. Sindhwani. Manifold [4] G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. [5] N. Cesa-Bianchi, A. Conconi, and C. Gentile. A [6] N. Cesa-Bianchi, C. Gentile, and F. Orabona. Robust [7] N. Cesa-Bianchi, C. Gentile, and L. Zaniboni. [8] O. Chapelle, B. Sch  X  olkopf, A. Zien, et al. [9] K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, [10] K. Crammer, M. Dredze, and F. Pereira.
 [11] C. Desrosiers and G. Karypis. Within-network [12] C. Eckart and G. Young. The approximation of one [13] J. Forster. On relative loss bounds in generalized [14] Y. Freund, H. S. Seung, E. Shamir, and N. Tishby. [15] C. Gentile. The robustness of the p-norm algorithms. [16] G. Giacinto, F. Roli, and L. Didaci. Fusion of multiple [17] A. B. Goldberg, X. Zhu, A. Furger, and J.-M. Xu. [18] Q. Gu, C. Aggarwal, J. Liu, and J. Han. Selective [19] M. Herbster, G. Lever, and M. Pontil. Online [20] M. Herbster and M. Pontil. Prediction on a graph [21] M. Herbster, M. Pontil, and L. Wainer. Online [22] S. C. Hoi, J. Wang, and P. Zhao. Libol: A library for [23] M. Ji, J. Han, and M. Danilevsky. Ranking-based [24] D. Kushnir. Active-transductive learning with [25] F. Orabona and N. Cesa-Bianchi. Better algorithms [26] F. Orabona and K. Crammer. New adaptive [27] M. Pennacchiotti and A.-M. Popescu. A machine [28] A. A. Ross, K. Nandakumar, and A. K. Jain.
 [29] N. Slonim, E. Yom-Tov, and K. Crammer. Active [30] A. J. Smola and R. Kondor. Kernels and [31] E. Takimoto and M. K. Warmuth. The last-step [32] V. Vovk. Competitive on-line linear regression. [33] J. Wang, P. Zhao, and S. C. Hoi. Exact soft [34] Z. Yang, J. Tang, and Y. Zhang. Active learning for [35] P. Zhao and S. C. Hoi. Cost-sensitive online active [36] P. Zhao, S. C. Hoi, and R. Jin. Double updating [37] P. Zhao, S. C. H. Hoi, R. Jin, and T. Yang. Online [38] P. Zhao, S. C. H. Hoi, J. Wang, and B. Li. Online
