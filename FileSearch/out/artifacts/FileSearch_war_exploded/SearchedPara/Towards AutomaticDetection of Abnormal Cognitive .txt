 A lzheimer X  X  disease is p revalent and becoming more so as the world X  X  population ages (Prince et al., 2014). Since no cure is known, it is hoped that early detection and intervention might slow the on-set of symptomatic cognitive decline and dementia. Clinical methods to detect Alz heimer X  X  disease are typically applied well after symptoms have pro-gressed to a troubling degree, and may be costly. Families, however, often report earlier signs of the disease through their language interactions with their elders. This has led clinical r esearchers to study linguistic differences to detect the disease in conversational speech (Asp and de Villiers, 2010). One approach is to search for non -informative phrases or semantic incoherences, which was con-firmed to distinguish patients with Alzheime r X  X  disease from controls (Nicholas et al., 1985). A strong limitation for its automatic application is the need of a trained expert to annotate the incoher-ences and scoring by hand.

We propose in this study to use Natural Lan-guage Processing (NLP) to eval uate samples of a patient X  X  descriptive writing in order to attempt to discriminate decline due to normal aging from de-cline due to pre -demented conditions. The Arizona Alzheimer X  X  Disease Center (ADC) is a longitudi-nal study of patients with Alzheimer X  X  d isease and normal control subjects, who receive an annual battery of clinical and neuropsychological exams, to which we added the following brief and a simple task. Participants are asked to describe, in writing, a picture typically used within the speech -based Boston battery ( Nicholas and Brookshire, 1993 ). We collected 201 descriptions written by ADC participants by hand, which were scanned, tran-scribed , and later analyzed. We describe here a sta-tistical machine learn ing method relying on lexical, syntactical and semantical features to discriminate evidence of abnormal deterioration in the writings of the patients. Our results confirm a correlation between linguistic decline on this writing task and the cognitive decli ne revealed by the more time consuming neuropsychological test battery . A lzheimer X  X  disease (AD) is a highly prevalent neurodegenerative dementia that increases expo-nentially with age. It is the most common form of dementia in the United States. AD is characterized by a severe memory deficit and at least one of the following: aphasia ( an impairment of language, af-fecting the production or comprehension of speech and the ability to read or write) , apraxia ( loss of the ability to execute or carry out skilled movements and gestures) , agnosia ( inability to recognize and identify objects or persons), and a disturbance in the internal control of cognitive processes (such as reflection, planning, working memory, etc.) (American Psychiatric Association, 1994) . While clinical testing often leads to an accurate diagnosis during its middle and late stages, several signs may alert a patient X  X  family to much e arlier stages of the disease even in the absence of frank aphasia (Obler and de Santi, 2000). 
Given the repeated failures of experimental therapies targeting dementia stage AD, current strategies are targeting early intervention at pre-clinical and early symptomatic stages thereby ne-cessitating more accurate methods for earlier de-tection of AD. Mild Cognitive Impairment (MCI), is defined as abnormal cognitive decline relative to age -matched peers that does not impair normal ac-tivities of daily living (Gauthier et al., 2006). AD is a f requent but not invariant cause. Some MCI pa-tients may even recover, but all AD patients transi-tion through the MCI stage before developing frank dementia (Petersen et al., 2001). As a result, an increasing number of clinical studies are trying to define a nd predict each stage in the life of an AD patient: normal, MCI and Alzheimer (Drum-mond et al., 2015) . 2.1 Predicting Cognitive Decline with Lan-T est batteries commonly used to measure cognitive decline include tests to evaluate the language pro-duction of patients, but they are criticized for their simplicity. For example, the Mini -Mental State Examination (MMSE), a widely used screening tool, asks to name 2 objects, to repeat a phrase, write a sentence and obey a 3 -step instruction. Bucks et al. , 2000, citing Sabat, 1994 , assert that these structured tests break down language into ar-tificial components that fail to represent the psy-chological and sociological context involved in daily conversations. As a consequence, such tests may be insensitive to early linguistic decline, when anomalies are already detectable by patients X  fami-lies ( Key -DeLyria, 2013 ) .

More sophisticated exercises have been pro-posed to complement the existing linguistic test batteries (Asp and de Villiers, 2010). These exer-cises are centered around conversation and narra-tion abilities of patients. Conversation and narra-tion abilities are developed in the early age of chil-dren (around 2 -3 years for conversation and around 4 years for narration). Since they play a fundamen-tal role in cognitive and social development, they are intensively studied. Cognit ive tests addressing narration capabilities can probe memory, spontane-ity and the quality of interactions with the interloc-utor . Tests can be complex, like narrat ing through informal conversation a habitual task, a memorable day of their life, or an event they participated in during the last week or month . Typically, the exact utterances ar e not captured, but rather the examiner notes if the narrative was coherent, or if the ex-pected events were mentioned. Simpler tests ask patients to comment on an image, or a sequence of relat ed images or to narrate a movie previously displayed. The patients participating in our study are receiving an extensive battery of tests annually to which we added a linguistic task . We therefore opted for a simple exercise of image description to avoid exhausting our participants. While the ma-jority of the e xercises testing the narration abilities are spoken , w ith the exception of ( Hayashi et al., 2015 ) and (Hirst and Feng, 2012) , all studies work with a corpus of transcribed oral narratives . W e opted for a written version for a direct analysis of written language , a form that remains relatively unexplored ( Hayashi et al., 2015 ) . 2.2 Clinical Studies for Linguistic Decline A seminal longitudinal study (Snowdon et al., 1996) demonstrated that writing performance in young women correlated with development of AD in old age. Since then, clinical studies of cognitive decline have been scrutinizing all linguistic levels (Reilly et al., 2011), lexical, syntactical, semantical and pragmatic (Bolshakov and Ge lbukh, 2004), in order to detect elements deteriorating with normal aging, those commonly observed degraded in the MCI stage, and finally their disintegration during the continuous phases of dementia. Various prop-erties of language are studied, e.g. number of words, size of sentences, number and correctness of anaphoric references, number of propositions per sentence, number of relevant facts and the structure of the narration (Hier et al., 1985; Drum-mond et al., 2015). These properties are most often compu ted manually on samples of small size (usu-ally around 50 patients) and appropriate statistical tests are used to determine the properties which can discriminate controls, MCI and AD patients.
From these studies has emerged a general pat-tern of pathological language decline observed dur-ing the MCI and the early stage of dementia (Obler and de Santi, 2000). Phonology and morphology are conserved. Syntax is also mostly spared even if it tends to be simplified. Degradations are mainly found at the lexical and s emantical levels (Hier et al., 1985). At the lexical level, the vocabulary is reduced with fewer words and fewer occurrences. It becomes more abstract and vague with multiple phrasal repetitions (Xuan et al., 2011). At the se-mantic level , complex questions are reduced and, early in the dementia phase, patients have difficul-ty making exact and pertinent remarks (Nicholas and Brookshire, 1993). Empty words and incom-plete sentences are often observed in oral exercis-es.

These alterations of the language seem to allow caregivers and researchers to distinguish decline due to normal aging from pathological decline but, further studies with larger patient numbers are needed to confirm these initial results. A signifi-cant limitation in clinical environment has bee n the need for a trained language pathologist to annotate and evaluate all linguistic productions of each pa-tient examined. More recently, however, some ef-forts have been made to automate the annot ation process using NLP techniques. The next section reviews the progress made . 2.3 Automatic prediction of Linguistic De-A first hypothesis to detect the cognitive decline in an older person is to compare his/her writing at a young age with his/her writing at an old age . In (Hirst and Feng, 2012) sophisticated stylometric measures were tested to identify the differences caused by the disease in the style of three well -known authors (2 probable ADs and 1 healthy). However, not onl y were results not decisive given the small number of subjects, but this approach re-quired a large amount of writings from the same person in order to establish the shift in the style of that person, conditions rarely met with common subjects. A variant of this approach is to compute two distinct profiles by modeling separately nor-mal subjects and aphasic subjects from their writ-ings. The results reported in (Holmes and Singh, 1996) report 88% of subjects correctly predicted from a corpus of 100 conversatio ns. Few features were used and the computation of some of them still required a human intervention.

B igger set of features can be explored with the use of NLP and machine learning. A first attempt in (Thomas et al., 2005) was to combine stylo-metric feature s (Stamatatos, 2009) and language model within a classifier. Their classifier obtained reasonable performances with 70% accuracy when distinguishing cognitively impaired from normal subjects in 95 oral interviews. In (Jarrold et al., 2010), the authors eva luated 80 features from vari-ous categories computed using dictionaries and predefined rules: positive sentiments words, social-ly related words, use of the first person, among others. The perfor mance reported an accuracy of 82.6% in the prediction task in 4 5 interviews.
The most efficient features for discrimination are semantic features which capture the abilities of a subject to understand and convey a set of perti-nent information (Nicholas and Brookshire, 1993). Automatic computation of such features are still challenging for automatic systems. Therefore, sev-eral publications integrated heuristics for compu-ting such features. A prototype to approximate the density of idea has been released by (Brown et al., 2008). Idea density can be thought of as the tota l number of assertions or claims whether true or false, in a proposition. The number of claims is es-timated from the number of verbs, adjec-tives/adverbs and conjunctions given certain condi-tions. The integration of the idea density proved to be significant to separate AD subjects from con-trols in (Jarrold et al., 2010). 3.1 Corpus Description and Preprocessing In the context of the ADC study we created a cor-pus for our experiments. At the day of writing, the total number of subjects participating in th e ADC study was roughly 500 corresponding to about 200 normal controls, 100 with MCI and 200 with AD or other form of degenerative dementia. In the be-ginning of the year 2015, in collaboration with the five institutes participating on the ADC study, a cognitive test was added to the protocol of the study. Subjects were asked to describe an image at the end of their annual visit. This control image is the same for all subjects (Nicholas and Brookshire, 1993). The image (Figure 1) represents a family havi ng a picnic near a lake. Subjects were asked to write (by hand) a detailed description of the scene in the picture. No time limit is imposed, and the time it takes them to write their description is not-ed. The test giver is asked to read the description wh en the subject completes it, asking the subjects to clarify any unreadable words and to write them in the descriptions. We collected 201 descriptions for this study, 154 from healthy subjects and 47 from subjects in decline. The collection process is 
We developed a web site to centralize the col-lection of the scans of the descriptions from the different institutions. The web site offers a basic interface to display the scan s and to transcribe their contents. We trained a student (native English speaker) to transcribe the scans, preserv ing , as much as possible, the original presentation of the description ( i.e. punctuations, uppercase, indents and new lines) as well as misspellings and crossed words.

The descriptions are processed through an NLP pipeline composed of several off -the -shelf NLP mo dules. First, a homemade tokenizer and the as well as chunks are computed thanks to Genia the sentence splitter found in the ANNIE tools guage models we have integrated the character specific Perl module Text::NGrams (Keselj et al., 2003) for computing character Ngram frequencies. Finally, for computing the seman tic features de-scribe below (section 3.2 .3 ), we compute vectors of words which are semantically close to a selected set of words that correspond to a model descrip-tion . To generate these vectors we have selected on part of Google News dataset (about 100 billion words).

For each sample writing, we have access to all information acquired during the ADCC study about the subjects enrolled. T his includes personal information ( e.g. gender, sex or education), social and medical information ( e.g. social status, smok-ing habit, depression) as well as the subjects X  tests admin i stered during the visits. For our experi-ments, we u sed the primary diagnostic made dur-ing the last visit of a subject. If the subject was di-agnosed with any form of dementia, including p os-sible or probable Alzheimer X  X , or with MCI , the subject was labeled as Declined . If the subject was not diagn osed with dementia we checked the score measuring the cognitive status. This score is as-signed by a neuropsychologist and it summarizes the performance of the subject during the cognitive exams. If the neuropsychologist diagnosed the sub-ject as cognitively impaired or as demented, the subject is labeled as Declined . Finally, we checked the Clinical Dementia Rating (CDR) glo bal score (Morris et al., 1997) . The CDR is assigned using a semi -structured standardized interview completed with the subject's caregiver and the subject inde-pendently. The CDR score is used to help diag-nose dementia, indicating: Normal, MCI, Early Dementia, Moderate Dementia, and Severe De-mentia , depending on its value . Administrators of the CDR are trained i n a standardized fashion. If the score of the CDR indicated the subject as MCI or Dementia, then we labeled the subject as De-clined , otherwise the subject was NotInDecline . These labels were used as gold standard during our experi ments. 3.2 A Classifier for Detecting Linguistic De-In order to automate the analysis of the descrip-tions of our 201 subjects we created a classifier to discriminate subjects in abnormal decline from subjects with normal aging decline. Our classifier inc orporates various features proposed by us or found in the literature. The following sections de-tails the features and the motivations for their use. 3.2.1 Lexical Features Adjective/Noun/verb/Pronoun ratios (Thomas et al., 2005). Given an abnormal decline we ex pected an important impoverishment of the vocabulary. Our initial hypothesis was a sensitive diminution of the number of adjective and pronouns since they are indicative of a precise description and complex syntactic structures. These ratios were computed by taking the number of adjec-tives/nouns/verbs/pronouns divided by the total number of tokens contains in a description. We re-lied on the POS tags to determine if a word was a noun, adjective or verb. To find the pronouns we matched a list of 73 pronouns.
 Type Token Ratio (Thomas et al., 2005). The use of this ratio was supported by the idea that a subject presenting an abnormal decline will see his/her vo-cabulary reduced and would tend to repeat general words. This ratio was computed by taking the size of the vocabulary of a description over the total number of tokens. The vocabulary was found by adding up the lemmas occurring in the description. Documents, Sentences and Tokens length (Hirst and Feng, 2012). The length of the different com-ponents of a docum ent are often a good indicator of the quality of the writing and the ability to pro-duce long and complex descriptions. We expressed several statistics which describe the description. The description length is expressed in number of tokens and punctuations. The size of the longest and shortest sentences, min -max sentence length , were used as features as well as the average of the length of all sentences occurring in the description. The average length of the tokens occurring in the description was also added as feature.
 Misspelling Ratio (Proposed). For this ratio we considered only orthographic errors present in a description. Since longer descriptions are more likely to have more misspellings we normalized the metric by dividing the number of errors with th e total number of tokens in the description. To discover automatically the misspellings we used the rule -based spell checker languagetool -3.0 7 . As for the previous ratios we assumed that a higher percentage of misspellings would reflect an under-lying lexic al problems. 3.2.2 Stylometric Features Functional Words Ratio (Hirst and Feng, 2012). Functional words are known to be good indicators of a personal style (Stamatatos, 2009). We matched an extended dictionary of 337 entries to retrieve the functional words in our descriptions. The ratio was given by the number of functional words over the total number of tokens in a descrip-tion.
 Brun X t X  X  Index and Honor X  X  X  Statistic (Thomas et al., 2005). Both metrics are length insensitive ver-sions of the type token ratio and often reported as useful features for discriminating abnormal decline in the literature. They were computed by the fol-lowing equations: N the total number of tokens and V 1 the total num-ber of hapax.
 Character NGrams and Character NGram Fre-quencies (Thomas et al., 2005). Ngrams of words capture lexical regularities hidden in the writing style of an author as well as its syntactic complexi-ty. They also help to highlight synt actic errors. Since sparsity problems raise quickly when Ngrams of words are created from a small size corpus, we preferred to use Ngrams of characters. By taking the most frequent Ngrams for both pro-files Normal subjects and subjects in decline, we expect ed to capture the set of words which are the most indicative of each profile. We set the size of the Ngrams to 5 for the character NGrams and to 10 for the Character NGram Frequencies. We lim-ited to the 2000 most frequent Ngrams. Those pa-rameters were set manually and can be optimized in future experiments. 3.2.3 Semantic Features Idea Density (Brown et al., 2008) To compute the idea density detailed in section 2.3, a heuristic to estimate the quantity of information convey in the description, we integrated the s oftware CPIDR used by the software.
 Word2Vec Distance (Proposed). A characteristic of subjects in abnormal decline is their inability to convey pertinent information and to digress from the initial subject. To model this characteristic we propose a new feature which takes advantage of the specificity of our corpus: all subjects, normal and subjects in decline, are describing the same image. By taking only descriptions written by normal subjects we obtained a set of words de-scribing correctly the image. We named this set generative words . All functional words were re-moved from this set. Our hypothesis was that sub-jects in decline would use less words from genera-tive words and add more inappropriate words (giv-e n the context of the image). Since the size of our corpus is small, not all relevant words were present in generative words . We extended generative words into a set called Word2Vec clusters by add-ing for each word of generative words , the corre-sponding vector returned by Word2Vec. These vectors are composed by words semantically close to the generative words. This includes synonyms, meronyms, hyperonyms but also correlated words. At run time, when an unknown description was submitted to the syst em, we created a subset of Word2Vec clusters , called Filtered Word2Vec clus-ters , by taking all vectors V i in Word2Vec clusters related to the words W i occurring in the unknown description. We added V i in Filtered Word2Vec clusters if W i was the generating word of V i or if W was a word occurring in V i with W i belonging to the set generative words . If W i was found in a vector V  X 
Word2Vec clusters but V j was generated by a word w j not occurring in the unknown description, V j was not added in Filtered Word2V ec clusters . This filtering step is crucial to guarantee good per-formances when using this feature. Additional tests were performed without filtering Word2Vec clus-ters and a significant drop of performances was observed due to noise or ambiguity in the vec tor generated by Word2Vec, for example vectors gen-erated by go , be etc. The filtering step insures that the vectors of Filtered Word2Vec clusters contain only words semantically related with the content of the unknown description. Given the set of words in Filtered Word2Vec clusters the distance is the ratio of words W i in Filtered Word2Vec clusters and to-tal number of words in W i . 3.2.4 Subject Features All clinical information about the subjects partici-pating in the ADC study were available during our experiments. We retained only criteria known to affect linguistic competences or known to contrib-ute to the development of the disease. Age and gender are important factors for the Alzheimer X  X  disease as well as the version of the APOE gene of a subject. T he presence of an e4 allele increases significantly the risk of the disease. Education and primary language (native English speaker or not) are obvious attributes to consider to measure the linguistic abilities as well as the social status of the subject. A subject living alone, with relatives or spouse will not have the same opportunities to speak. We evaluated our classifier on the data mining platform Weka . This platform implements state -of -the art machine learning algorithms (Witten et al., 2011 ). The size of our corpus being small we opted for a leave -one -out cross validation. We chose the framework of a Bayesian Network (BN) (Koller and Friedman, 2009) to perform the evaluation of our classifier. For all following experiments we learned the str ucture of the network and its condi-tional probabilities automatically from our data. No Naive Bayes structure were a priori imposed during the training and the number of possible par-ents for a node were manually set to 20. We select-ed this machine learning algorithm because it learns complex decision functions, its decisions are interpretable by medical experts, it has very few global parameters to set up and it was fast to train on our problem.

Our first experiment evaluated the performances of our cl assif ier when all features were used (Table 2) . We confirmed the quality of our classifier by comparing its performances with a baseline classi-fier. The baseline classifier predicted the majority class label NotInDecline for all instances. The baseline system obtain ed 76.6% of accuracy (Acc). With this set-ting, our classifier obtained a better score with 80.6% Acc. and thus demonstrated i ts abilities to learn the difference between normal subjects from subjects in abnormal decline using linguistic fea-tures.

We proceeded to an ablation study to assess the benefits of each feature. We removed one at a time each feature, or complementary feat ures such as min -max length of sentence , and rerun the train-ing/testing of our classifier. The results are detailed in Table 3 . For brevity we did not report in the ta-ble the features which did not change the score of our classifier once removed.

In the light of the ablation study we performed a second experiment to determine the optimal per-formances of our classifier. We run several feature selection/reduction algorithms implemented in the W eka plat form. The Correlation -based Feature Se-lection algorithm (CFS) ( Hall, 199 9) found a set of features which maximized the performances of the classifier. Under this setting our classifier outper-formed the baseline system with a score of 86.1 Acc. against 76.6 Acc (Table 2) . Inspection of the confusion matrix shown that the classifier correctly recognized 24 patients in abnormal decline and 149 normal patients. Considering Decline as the targeted class, our classifier mistakenly predicted 7 False Positives (FP) and 21 False Negatives (FN). We reproduced comparable performances with other machine learning algorithms using this set of features. A multilayer perceptron got a score of 84.6 % Acc., a random forest 81.1 % Acc. and a bagging algorithm 83.6 % Acc. Five fea tures only were selected by the CFS algorithm: Ngrams, Honor  X  X  s Statistic, Misspelling Ratio, Age and the Word2Vec Distance. This set of features differs from the set indicated by the ablation study but ob-tained better performances on our task. When traine d and tested using only the four features which improved the classification during the abla-tion study, the score of the classifier reached 85.6 Acc. with 4 FP and 25 FN.

From these experiments we can conclude that our system showed promising performances w hen learning to discriminate subjects in abnormal cog-nitive decline from their writings. The ablation study and the set of optimal features found by the CFS algorithm seem to confirm the existence of the general pattern postulate d in the clinical litera-ture where lexical and semantical capacities are damaged during the cognitive decline. The most important features were the semantic features, Ngrams and Word2Vec, with a total drop of 2.7 points when they were removed. Both features cap-ture the tendency o f the subjects in decline to de-scribe few topics of the image, resulting in a low Word2Vec distance, and to digress from the de-scription task by mentioning several facts or state-ments that could not be inferred from the image or were not plausible with its content. These digres-sions caused the system to compute a higher prob-ability for the description written by a subject in decline to be generated by the profile of the ab-normal subject s and a low probability for being generated by the profile of the normal subject s . The profile of abnormal subject s contained more words than the profile of normal subject s , this lat-ter containing only words related to the image. The decline of the lexical capacities are suggested by the higher number of misspellings made by sub-ject s in decline as well as the positive role of the Brun  X  t  X  s Index or Honor  X  X  s Statistic Brunet during the classification. 4.1 Analysis of Errors The prediction of abnormal decline is a hard learn-ing problem. Since it is still difficult to clinically diagn ose the cognitive decline and potentially the following dementia, the labels of the target class in our corpus remains uncertain. Patients labeled normal can quickly show sign of decline and MCIs can recover over time. Therefore, for our analysis, we focus ed more on the capacity of our classifier to detect good descriptions rather than to strictly predict the target class. Additional analysis of our errors will be carried out by pathologists special-ized in aphasia.

The 7 FPs where all primary diagnosed norm al during their last visit. Their ages varied from 69 to 86 year old. Our manual inspection of their writ-ings revealed that 4 descriptions presented strong irregularities which may explain the decision of our classifier. In the first case we found short de-scriptions containing misspellings, repeated phrases, ungrammatical sentences and descriptions focused on small details of the image. In the sec-ond case, descriptions were longer but they all con-tained digressions such as  X  X he turtle is shuffling back to b e with the water. X  (no turtle is drawn in the image), or  X  X om is torn between the playtime there and being being with her friends back home X  (the woman seems perfectly relaxed). Additional analysis of such digressions on our corpus are needed to know how s trongly they are correlated with the decline. The reasons the classifier tagged the last 3 descriptions as Decline remained unclear. The Bayesian Networks learned for these instances are currently analyzed to understand which fea-tures deceived the classifi er. The BN classifier s learned are probabilistic directed acyclic graph s which represent causal relations between variables. They can be displayed in a dedicated Graphical User Interface where values for different variables observed can be manually imposed to see the changes on the likelihood of the others unseen var-iables.

Th e 21 FNs can be separated in 3 groups: 2 pa-tients whose pri mary diagnosis were AD, 11 whose primary diagnosis were MCIs and 8 normal pa-tients but whose cognitive exams results (3 pa-tie nts) or global CDR (5 patients) showed signs of decline.

Our corpus contains in total 7 cases of patients diagnosed with AD, 5 cases were correctly classi-fied by the system and 2 incorrectly, making it fair-ly sensitives to strong signs of decline. The majo ri-ty of the classifier's errors were made on light and mild impairments. In order to understand these er-rors we randomly selected 10 descriptions written by these patients and proceeded to a manual exam-ination. A clear difference with the descriptions of t he FPs is the absence of digressions. Only one de-scription mentioned some implausible facts, others strictly described the image with most of its topics commented. 6 descriptions presented anomalies like misspellings, phrases repeated, verbs/auxiliaries mi ssing, incomplete sentences or wrong choices of pronouns and, for 2 of them, a simplified syntax with unnatural constructions ( e.g.  X  X  coulle having a picnic, the man with a book the girl pouring a soda. X  ) . The 4 remaining descrip-tions exhibit a good quali ty and would be difficult to discriminate with linguistic features only. With the general aging of the population more at-tention has been given to Alzheimer X  X  disease. In this study we presented a NLP system to predict early signs of cognitive decline, which precedes the disease, based on the analysis of written de-scrip tions of an image. To perform our experi-ments we created a cor pus which is, to the best of our knowledge, unique by its nature and its size. With a final score of 86.1% Accuracy our system outperformed our baseline system and showed state -of -the -art performances with existing classifi-ers working on oral interviews. O ur results suggest a correlation between abnormal cognitive decline and the dislocation of the language ability. Our ab-lation study revealed that our system discriminates patients with abnormal decline using lexical and semantical irregularities found in their writings, consolidating the hypothesis of a general pattern in the linguistic impairment already postulated in the literature. The analysis of its classification errors showed the limitation of our approach: the pres-ence of linguistic irregularities are not always suf-ficient to diagnose abnormal decline and may not always be observed in writings of patients already diagnosed in abnormal decline. To overcome this limitation we are currently designing a classifier based on Conditional Random Fields. Thi s classi-fier will integrate all information available about our patients (i.e. medical, cognitive, linguistic, and imaging information) and will allow the represen-tation of the performances of the patients over the time.
 Research reported in this publication was partially suppor t ed by the NIH/NIA under g rant P30 AG019610 .

