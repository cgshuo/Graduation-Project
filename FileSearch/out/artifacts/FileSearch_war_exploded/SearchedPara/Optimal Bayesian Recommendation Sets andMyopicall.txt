 Utility elicitation is a key component in many decision supp ort applications and recommender sys-tems, since appropriate decisions or recommendations depe nd critically on the preferences of the user on whose behalf decisions are being made. Since full eli citation of user utility is prohibitively expensive in most cases (w.r.t. time, cognitive effort, etc .), we must often rely on partial utility in-formation. Thus in interactive preference elicitation , one must selectively decide which queries are most informative relative to the goal of making good or optim al recommendations. A variety of principled approaches have been proposed for this problem. A number of these focus directly on (myopically or heuristically) reducing uncertainty regar ding utility parameters as quickly as possi-ble, including max-margin [10], volumetric [12], polyhedr al [22] and entropy-based [1] methods. A different class of approaches does not attempt to reduce ut ility uncertainty for its own sake, but rather focuses on discovering utility information that imp roves the quality of the recommendation. These include regret-based [3, 23] and Bayesian [7, 6, 2, 11] models. We focus on Bayesian models in this work, assuming some prior distribution over user uti lity parameters and conditioning this distribution on information acquired from the user (e.g., q uery responses or behavioral observations). The most natural criterion for choosing queries is expected value of information (EVOI) , which can be optimized myopically [7] or sequentially [2]. However, o ptimization of EVOI for online query selection is not feasible except in the most simple cases. He nce, in practice, heuristics are used that offer no theoretical guarantees with respect to query quali ty.
 In this paper we consider the problem of myopic EVOI optimiza tion using choice queries . Such queries are commonly used in conjoint analysis and product d esign [15], requiring a user to indicate which choice/product is most preferred from a set of k options. We show that, under very general assumptions, optimization of choice queries reduces to the simpler problem of choosing the opti-mal recommendation set , i.e., the set of k products such that, if a user were forced to choose one, maximizes utility of that choice (in expectation). Not only is the optimal recommendation set prob-lem somewhat easier computationally, it is submodular, adm itting a greedy algorithm with approx-imation guarantees. Thus, it can be used to determine approx imately optimal choice queries. We develop this connection under several different (noisy) us er response models. Finally, we describe query iteration , a local search technique that, though it has no formal guara ntees, finds near-optimal recommendation sets and queries much faster than either exa ct or greedy optimization. We assume a system is charged with the task of recommending an option to a user in some multi-attribute space, for instance, the space of possible produc t configurations from some domain (e.g., computers, cars, rental apartments, etc.). Products are ch aracterized by a finite set of attributes X = { X 1 , ...X n } , each with finite domain Dom ( X i ) . Let X  X  Dom ( X ) denote the set of feasible configurations . For instance, attributes may correspond to the features of various cars, such as color, engine size, fuel economy, etc., with X defined either by constraints on attribute combinations (e. g., constraints on computer components that can be put together ) or by an explicit database of feasible configurations (e.g., a rental database). The user has a utility function u : Dom ( X )  X  R . The precise form of u is not critical, but in our experiments we assume that u ( x ; w ) is linear in the parameters (or weights) w (e.g., as in generalized additive independent (GAI) models [8, 5].) We often refer to w as the user X  X   X  X tility function X  for simplicity, assuming a fixed form for u . A simple additive model in the car domain might be: The optimal product x  X  w for a user with utility parameters w is the x  X  X that maximizes u ( x ; w ) . Generally, a user X  X  utility function w will not be known with certainty. Following recent models of Bayesian elicitation, the system X  X  uncertainty is reflecte d in a distribution, or beliefs , P ( w ;  X  ) over the space W of possible utility functions [7, 6, 2]. Here  X  denotes the parameterization of our model, and we often refer to  X  as our belief state . Given P ( ;  X  ) , we define the expected utility of an option x to be EU ( x ;  X  ) = the optimal option x  X  (  X  ) is that with greatest expected utility EU  X  (  X  ) = max x  X  X EU ( x ;  X  ) , with x (  X  ) = arg max x  X  X EU ( x ;  X  ) .
 In some settings, we are able to make set-based recommendations : rather than recommending a single option, a small set of k options can be presented, from which the user selects her mos t pre-ferred option [15, 20, 23]. We discuss the problem of constru cting an optimal recommendation set S further below. Given recommendation set S with x  X  S , let S  X  x denote that x has the greatest utility among those items in S (for a given utility function w ). Given feasible utility space W , we define W  X  S  X  x  X  { w  X  W : u ( x ; w )  X  u ( y ; w ) ,  X  y 6 = x, y  X  S } to be those utility functions satisfying S  X  x . Ignoring  X  X ies X  over full-dimensional subsets of W (which are easily dealt with, but complicate the presentation), the regions W  X  S  X  x i , x i  X  S , partition utility space. A recommender system can refine its belief state  X  by learning more about the user X  X  utility function w . A reduction in uncertainty will lead to better recommendat ions (in expectation). While many sources of information can be used to assess a user preferenc es X  X ncluding the preferences of related users, as in collaborative filtering [14], or observed user c hoice behavior [15, 19] X  X e focus on explicit utility elicitation , in which a user is asked questions about her preferences. There are a variety of query types that can be used to refine one  X  X  knowledge of a user X  X  utility function (we refer to [13, 3, 5] for further discussion). Comparison queries are especially natural, asking a user if she prefers one option x to another y . These comparisons can be localized to specific (subsets of) attributes in additive or GAI models, and such s tructured models allow responses w.r.t. specific options to  X  X eneralize, X  providing constraints on the utility of related options. In this work we consider the extension of comparions to choice sets of more than two options [23] as is common in conjoint analysis [15, 22]. Any set S can be interpreted as a query: the user states which of the k elements x i  X  S she prefers. We refer to S interchangeably as a query or a choice set . The user X  X  response to a choice set tells us something about h er preferences; but this depends on the user response model . In a noiseless model , the user correctly identifies the preferred item in the slate: the choice of x i  X  S refines the set of feasible utility functions W by imposing k  X  1 restricting  X  to have non-zero density only on W  X  S  X  x i and renormalizing. More generally, a noisy response model allows that a user may select an option that does not maximize her utility. For any choice set S with x i  X  S , let S x i denote the event of the user selecting x i . A response model R dictates, for any choice set S , the probability P R ( S x i ; w ) of any selection given utility function w . When the beliefs about a user X  X  utility are uncertain, we de fine P R ( S x i ;  X  ) = x ; w ) P ( w ;  X  ) dw . We discuss various response models below.
 When treating S as a query set (as opposed to a recommendation set), we are not interested in its expected utility, but rather in its expected value of information (EVOI) , or the (expected) degree to which a response will increase the quality of the system X  X  re commendation. We define: Definition 1 Given belief state  X  , the expected posterior utility ( EPU ) of query set S under R is EVOI ( S ;  X  ) is then EPU ( S ;  X  )  X  EU  X  (  X  ) , the expected improvement in decision quality given S . An optimal query (of fixed size k ) is any S with maximal EV OI , or equivalently, maximal EPU . In many settings, we may wish to present a set of options to a us er with the dual goals of offering a good set of recommendations and eliciting valuable inform ation about user utility. For instance, product navigation interfaces for e-commerce sites often d isplay a set of options from which a user can select, but also give the user a chance to critique the pro posed options [24]. This provides one motivation for exploring the connection between optimal re commendation sets and optimal query sets. Moreover, even in settings where queries and recommen dation are separated, we will see that query optimization can be made more efficient by exploiting t his relationship. We consider first the problem of computing optimal recommend ation sets given the system X  X  uncer-tainty about the user X  X  true utility function w . Given belief state  X  , if a single recommendation is to be made, then we should recommend the option x  X  (  X  ) that maximizes expected utility EU ( x,  X  ) . However, there is often value in suggesting a  X  X hortlist X  co ntaining multiple options and allowing the user to select her most preferred option. Intuitively, s uch a set should offer options that are diverse in the following sense: recommended options should be highl y preferred relative to a wide range of  X  X ikely X  user utility functions (relative to  X  ) [23, 20, 4]. This stands in contrast to some rec-ommender systems that define diversity relative to product a ttributes [21], with no direct reference to beliefs about user utility. It is not hard to see that  X  X op k  X  systems, those that present the k options with highest expected utility, do not generally result in go od recommendation sets [20]. In broad terms, we assume that the utility of a recommendatio n set S is the utility of its most preferred item. However, it is unrealistic to assume that us ers will select their most preferred item with complete accuracy [17, 15]. So as with choice queries, w e assume a response model R dictating the probability P R ( S x ;  X  ) of any choice x from S : Definition 2 The expected utility of selection (EUS) of recommendation set S given  X  and R is: We can expand the definition to rewrite EUS R ( S ;  X  ) as: User behavior is largely dictated by the response model R . In the ideal setting, users would always select the option with highest utility w.r.t. her true utili ty function w . This noiseless model is assumed in [20] for example. However, this is unrealistic in general . Noisy response models admit user  X  X istakes X  and the choice of optimal sets should reflect this possibility (just as belief update does, see Defn. 1). Possible constraints on response models inclu de: (i) preference bias : a more preferred outcome in the slate given w is selected with probability greater than a less preferred o utcome; and (ii) Luce X  X  choice axiom [17], a form of independence of irrelevant alternatives tha t requires that the relative probability (if not 0 or 1) of selecting any two item s x and y from S is not affected by the addition or deletion of other items from the set. We consider three different response models:  X  In the noiseless response model , R NL , we have P NL ( S x ; w ) = (with indicator function I ). Then EUS becomes
This is identical to the expected max criterion of [20]. Under R NL we have S x iff S  X  x .  X  The constant noise model R C assumes a multinomial distribution over choices or respons es where each option x , apart from the most preferred option x  X  w relative to w , is selected with (small) constant probability P C ( S x ; w ) =  X  , with  X  independent of w . We assume  X  &lt; 1 k , so the most preferred option is selected with probability P C ( S x  X  w ; w ) =  X  = 1  X  ( k  X  1)  X  &gt;  X  .
This generalizes the model used in [10, 2] to sets of any size. If x  X  w ( S ) the optimal element in S given w , and u  X  w ( S ) is its utility, then EUS is:  X  The logistic response model R L is commonly used in choice modeling, and is variously known a s the Luce-Sheppard [16], Bradley-Terry [11], or mixed multinomial logit model. Selection prob-
For comparison queries (i.e., | S | = 2 ), R L is the logistic function of the difference in utility between the two options.
 We now consider properties of the expected utility of select ion EUS under these various models. All three models satisfy preference bias, but only R NL and R L satisfy Luce X  X  choice axiom. EUS is monotone under the noiseless response model R NL : the addition of options to a recommendation set S cannot decrease its expected utility EUS NL ( S ;  X  ) . Moreover, say that option x i dominates x j dominated option x to S (i.e., an x dominated by some element of S ) does not change expected utility under R NL : EUS NL ( S  X  X  x } ;  X  ) = EUS NL ( S ;  X  ) . This stands in constrast to noisy response models, where adding dominated options might actually decrease expected utility.
 Importantly, EUS is submodular for both the noiseless and the constant response models R C : Theorem 1 For R  X  { R NL , R C } , EUS R is a submodular function of the set S . That is, given recommendation sets S  X  Q , option x 6 X  S , S  X  = S  X  { x } , and Q  X  = Q  X  { x } , we have: The proof is omitted, but simply shows that EUS has the requir ed property of diminishing returns. Submodularity serves as the basis for a greedy optimization algorithm (see Section 5 and worst-case results on query optimization below). EUS under the commonl y used logistic response model R L is not submodular, but can be related to EUS under the noiseless model X  X s we discuss next X  X llowing us to exploit submodularity of the noiseless model when opti mizing w.r.t. R L . We now develop the connection between optimal recommendati on sets (using EUS) and optimal choice queries (using EPU/EVOI). As discussed above, we X  X e often interested in sets that can serve as both good recommendations and good queries; and since EPU /EVOI can be computationally difficult, good methods for EUS-optimization can serve to ge nerate good queries as well if we have a tight relationship between the two. In the following, we make use of a transformation T  X ,R that modifies a set S in such a way that EUS usually increases (and in the case of R NL and R C cannot decrease). This transformation is used in two ways: (i) to prove the optimality (near-optimali ty in the case of R L ) of EUS-optimal recommendation sets when used as query sets; (ii) and direct ly as a computationally viable heuristic strategy for generating query sets.
 Definition 3 Let S = { x 1 , , x k } be a set of options. Define: where x  X  (  X  | S x i ; R ) is the optimal option (in expectation) when  X  is conditioned on S x i w.r.t. R .
 Intuitively, T (we drop the subscript when  X , R are clear from context) refines a recommendation set S of size k by producing k updated beliefs for each possible user choice, and replacin g each option in S with the optimal option under the corresponding update. Not e that T generally produces different sets under different response models. Indeed, on e could use T to construct a set using one response model, and measure EUS or EPU of the resulting set un der a different response model. Some of our theoretical results use this type of  X  X ross-eval uation. X  We first show that optimal recommendation sets under both R NL and R C are optimal (i.e., EPU/EVOI-maximizing) query sets.
 Lemma 1 EUS R ( T  X ,R ( S );  X  )  X  EPU R ( S ;  X  ) for R  X  { N L, C } From Lemma 1 and the fact that EUS R ( S ;  X  )  X  EP U R ( S,  X  ) , it follows that EUS R ( T ( S );  X  )  X  EUS R ( S ;  X  ) . We now state the main theorem (we assume the size k of S is fixed): Theorem 2 Assume response model R  X  { N L, C } and let S  X  be an optimal recommendation set. Then S  X  is an optimal query set: EPU ( S  X  ;  X  )  X  EPU ( S ;  X  ) ,  X  S  X  X k Another consequence of Lemma 1 is that posing a query S involving an infeasible option is pointless: there is always a set with only elements in X with EPU/EVOI at least as great. This is proved by observing the lemma still holds if T is redefined to allow sets containing infeasible options. It is not hard to see that admitting noisy responses under the logistic response model R L can decrease the value of a recommendation set, i.e., EUS L ( S ;  X  )  X  EUS NL ( S ;  X  ) . However, the loss in EUS under R L can in fact be bounded. The logistic response model is such th at, if the probability of incorrect selection of some option is high, then the utility of that option must be close to that of the best item, so the relative loss in utility is small. Converse ly, if the loss associated with some incorrect selection is great, its utility must be significantly less th an that of the best option, rendering such an event extremely unlikely. This allows us to bound the differ ence between EUS NL and EUS L at some value  X  max that depends only on the set cardinality k and on the temperature parameter  X  (we derive an expression for  X  max below): Theorem 3 EUS L ( S ;  X  )  X  EUS NL ( S ;  X  )  X   X  max .
 Under R L , our transformation T L does not, in general, improve the value EUS L ( S ) of a recom-mendation set S . However the set T L ( S ) is such that its value EUS NL , assuming selection under the noiseless model , is greater than the expected posterior utility EPU L ( S ) under R L : Lemma 2 EUS NL ( T L ( S );  X  )  X  EPU L ( S ;  X  ) We use this fact below to prove the optimal recommendation se t under R L is a near-optimal query under R L . It has two other consequences: First, from Thm. 3 it follows that EUS L ( T L ( S );  X  )  X  EPU L ( S ;  X  )  X   X  max . Second, EPU of the optimal query under the noiseless model i s at least as great that of the optimal query under the logistic model: EPU  X  NL (  X  )  X  EPU  X  L (  X  ) . 1 We now derive our main result for logistic responses: the EUS of the optima l recommendation set (and hence its EPU) is at most  X  max less than the EPU of the optimal query set.
 Theorem 4 EUS  X  L (  X  )  X  EPU  X  L (  X  )  X   X  max .
 The loss  X ( S ;  X  ) = EUS NL ( S ;  X  )  X  EUS L ( S ;  X  ) in the EUS of set S due to logistic noise can be characterized as a function of the utility difference z = u ( x 1 )  X  u ( x 2 ) between options x 1 and x 2 of S , and integrating over the possible values of z (weighted by  X  ). For a specific value of z  X  0 , EUS-loss is exactly the utility difference z times the probability of choosing the less preferred option under R L : 1  X  L (  X z ) = L (  X   X z ) where L is the logistic function. We have  X ( S ;  X  ) = for any S,  X  by maximizing f ( z ) = z 1 1+ e  X z with z  X  0 . The maximal loss  X  max = f ( z max ) for a set of two hypothetical items s 1 and s 2 is attained by having the same utility difference u ( s 1 , w )  X  u ( s 2 , w ) = z max for any w  X  W . By imposing  X  X   X  X  = 0 , we obtain e  X   X z  X   X z +1 = 0 . Numerically, this yields z max  X  1 . 279 1  X  and  X  max  X  0 . 2785 1  X  . This bound can be expressed on a scale that is independent of the temperature parameter  X  ; intuitively,  X  max corresponds to a utility difference so slight that the user identifies the best item only with probab ility 0 . 56 under R L with temperature  X  . In other words, the maximum loss is so small that the user is un able able to identify the preferred item 44% of the time when asked to compare the two items in S . This derivation can be generalized to sets of any size k , yielding  X  k max = 1  X  L W ( k  X  1 e ) , where L W ( ) is the Lambert W function. 2 We discuss several strategies for the optimization of query /recommendation sets in this section, and summarize their theoretical and computational propert ies. In what follows, n is the number of options | X | , k the size of the query/recommendation set, and l is the  X  X ost X  of Bayesian inference (e.g., the number of particles in a Monte Carlo sampling proc edure).
 Exact Methods The naive maximization of EPU is more computationally inten sive than EUS-optimization, and is generally impractical. Given a set S of k elements, computing EPU ( S,  X  ) requires Bayesian update of  X  for each possible response, and expected utility optimizat ion for each such posterior. Query optimization requires this be comput ed for n k possible query sets. Thus EPU maximization is O ( n k +1 kl ) . Exact EUS optimization, while still quite demanding, is on ly O ( n k kl ) as it does not require EU-maximization in updated distribut ions. Thm. 2 allows us to compute optimal query sets using EUS-maximization under R C and R NL , reducing complexity by a factor of n . Under R L , Thm. 4 allows us to use EUS-optimization to approximate the optimal query, with a quality guarantee of EPU  X   X   X  max .
 Greedy Optimization A simple greedy algorithm can be used construct a recommenda tion set of size k by iteratively adding the option offering the greatest impr ovement in value: arg max x EUS R ( S  X  { x } ;  X  ) . Under R NL and R C , since EUS is submodular (Thm. 1), the greedy algorithm determines a set with EUS that is within  X  = 1  X  ( k  X  1 k ) k of the optimal value EU S  X  = EP U  X  [9]. 3 Thm. 2 again allows us to use greedy maximization of EUS to determine a query set with similar gaurantees.
 Under R L , EUS L is no longer submodular. However, Lemma 2 and Thm. 3 allow us t o use EUS NL , which is submodular, as a proxy. Let S g the set determined by greedy optimization of EUS NL . By submodularity,  X  EUS  X  NL  X  EUS NL ( S g )  X  EUS  X  NL ; we also have EUS  X  L  X  EUS  X  NL . Applying Thm. 3 to S g gives: EUS L ( S g )  X  EUS NL ( S g )  X   X  . Thus, we derive Similarly, we derive a worst-case bound for EPU w.r.t. greedy EUS-optimization (using the fact that EUS is a lower bound for EPU, Thm. 3 and Thm. 2): Greedy maximization of S w.r.t. EUS is extremely fast, O ( k 2 ln ) , or linear in the number of options n : it requires O ( kn ) evaluations of EUS , each with cost kl . 4 Query Iteration The T transformation (Defn. 3) gives rise to a natural heuristic m ethod for com-puting, good query/recommendationsets. Query iteration (QI) starts with an initial set S , and locally optimizes S by repeatedly applying operator T ( S ) until EUS ( T ( S );  X  ) = EUS ( S ;  X  ) . QI is sensitive to the initial set S , which can lead to different fixed points. We consider severa l initialization strate-gies: random (randomly choose k options), sampling (include x  X  (  X  ) , and sample k  X  1 points w i from P ( w ;  X  ) , and for each of these add the optimal item to S , while forcing distinctness) and greedy (initialize with the greedy set S g ).
 We can bound the performance of QI relative to optimal query/ recommendation sets assuming R NL or R C . If QI is initialized with S g , performance is no worse than greedy optimization. If initi alized with an arbitrary set, we note that, because of submodularit y, EU  X   X  EUS  X   X  k EU  X  . The condition T ( S ) = S implies EUS ( S ) = EPU ( S ) . Also note that, for any set Q , EPU ( Q )  X  EU  X  . Thus, EUS ( S )  X  1 k EUS  X  . This means for comparison queries ( | S | = 2 ), QI achieves at least 50% of the optimal recommendation set value. This bound is tight and corresponds to the singleton and has EVOI of zero. However, under R NL , QI with sampling initialization avoids this fixed point provably by construction, always leading to a query set with positive EVOI.
 Complexity of one iteration of QI is O ( nk + lk ) , i.e., linear in the number of options, exactly like Greedy. However, in practice it is much faster than Greedy si nce typically k &lt;&lt; l . While we have no theoretical results that limit the iterations required b y QI to converge, in practice, a fixed point is reached in very quickly (see below).
 Evaluation We compare the strategies above empirically on choice probl ems with random user utility functions using both noiseless and noisy response m odels. 5 Bayesian inference is realized by a Monte Carlo method with i mportance sampling (particle weights are determined by applying the response model to observed re sponses). To overcome the problem of particle degeneration (most particles eventually have low or zero weight), we use slice-sampling [18] to regenerate particles w.r.t. to the response-updated bel ief state  X  whenever the effective number of samples drops significantly (50000 particles were used in the simula tions). Figure 1(a) shows the average loss of our strategies in an apartment rental datase t, with 187 outcomes, each character-ized by 10 attributes (either numeric or categorical with do main sizes 2 X 6), when asking pairwise comparison queries with noiseless responses. We note that g reedy performs almost as well as exact optimization, and the optimal item is found in roughly 10 X 15 queries. Query iteration performs reasonably well when initialized with sampling, but poorly with random seeds. In the second experiment, we consider the Boston Housing dataset with 506 items (1 binary and 13 continous attributes) and a logistic noise model for resp onses with  X  = 1 . We compare the greedy and QI strategies (exact methods are impractical on p roblems of this size) in Figure 1(b); we also consider a hybrid greedy(EUS,NL) strategy that optimizes  X  X ssuming X  noiseless responses, but is evaluated using the true response model R L . QI(sampling) is more efficient when using T NL instead of T L and this is the version plotted. Overall these experiments s how that (greedy or exact) maximization of EUS is able to find optimal X  X r near-optimal w hen responses are noisy X  X uery sets. Finally, we compare query optimization times on the tw o datasets in the following table: Among our strategies, QI is certainly most efficient computa tionally, and is best suited to large outcome spaces. Interestingly, QI is often faster with samp ling initialization than with random initialization because it needs fewer iteration on average before convergence (3.1 v.s. 4.0). We have provided a novel analysis of set-based recommendati ons in Bayesian recommender sys-tems, and have shown how it is offers a tractable means of gene rating myopically optimal or near-optimal choice queries for preference elicitation. We exam ined several user response models, show-ing that optimal recommendation sets are EVOI-optimal quer ies under noiseless and constant noise models; and that they are near-optimal under the logistic/L uce-Sheppard model (both theoretically and practically). We stress that our results are general and do not depend on the specific implemen-tation of Bayesian update, nor on the specific form of the util ity function. Our greedy strategies X  exploiting submodularity of EUS computation X  X erform very well in practice and have theoretical approximation guarantees. Finally our experimental resul ts demonstrate that query iteration, a sim-ple local search strategy, is especially well-situated to l arge decision spaces.
 A number of important directions for future research remain . Further theoretical and practical in-vestigation of local search strategies such as query iterat ion is important. Another direction is the development of strategies for Bayesian recommendation and elicitation in large-scale configuration problems, e.g., where outcomes are specified by a CSP, and for sequential decision problems (such as MDPs with uncertain rewards). Finally, we are interested in elicitation strategies that combine probabilistic and regret-based models.
 Acknowledgements The authors would like to thank Iain Murray and Cristina Manf redotti for helpful discussion on Monte Carlo methods, sampling techni ques and particle filters. This research was supported by NSERC.
