 People X  X  interests are dynamically evolving, often affected by ex-ternal factors such as trends promoted by the media or adopted by their friends. In this work, we model interest evolution through dy-namic interest cascades: we consid er a scenario where a user X  X  in-terests may be affected by (a) the interests of other users in her social circle, as well as (b) suggestions she receives from a recom-mender system. In the latter case, we model user reactions through either attraction or aversion towards past suggestions. We study this interest evolution process, and the utility accrued by recommenda-tions, as a function of the system X  X  recommendation strategy. We show that, in steady state, the optimal strategy can be computed as the solution of a semi-definite program (SDP). Using datasets of user ratings, we provide evidence for the existence of aversion and attraction in real-life data, and show that our optimal strategy can lead to significantly improved recommendations over systems that ignore aversion and attraction.
 H.2.8 [ Database Applications ]: Data Mining Recommender Systems; Interest Evolution; Attraction; Aversion
Users X  content consumption patterns evolve over time. For ex-ample, a user may be attracted towards content that is popular, content recommended to her by a service, or content being en-joyed by her friends. Alternatively, users may get tired of certain types of content, e.g., romantic comedy movies, and desire to con-sume something different and new. A key challenge for recom-mender systems is accurately modeling such user preferences as they evolve over time. Although trad itional matrix fact orization ap-proaches can be extended to incorporate temporal dynamics of user behavior [19,20], such extensions do not identify or explicitly ana-lyze the factors that influence the drift in interests.
A X  X lassic X  X actorinfluencinguserinterestsis attraction :users may be attracted to content they are exposed to repeatedly and often (such as, e.g., a song played often on the radio). This phe-nomenon, known in psychology as the  X  mere-exposure effect  X  X 33], is natural and intuitive, and is the main premise behind advertis-ing [10, 15]. Nonetheless, repe tition and/or overe xposure can also have the opposite effect, leading to aversion :recentresearchargues that users often desire serendipitous, novel, previously unseen con-tent [1,3,23,27]. This notion is also quite natural and intuitive, but is usually not taken into account by recommender systems, yielding over-specialized, predictable recommendations [3, 23].

Athirdfactoraffectingauser X  X interestsis social influence : users may feel attracted to content consumed and liked by their friends. Trend adoption through  X  X ord-of-mouth X  or  X  X iral X  mar-keting is also a well documented phenomenon [7, 9], and has been extensively studied since the seminal paper by Kempe et al. [17]. Nonetheless, to the best of our knowledge, the effect of social in-fluence on interests, and its implications for recommender systems, has received attention only recently [16,27].

Incorporating these influence factors in a recommender system raises several challenges. To begin with, under attraction and aver-sion, a recommender can no longer b etreatedasapassiveentity: recommendations it makes may alter user interests, pushing them either towards or away from certain topics. Hence, traditional meth-ods that merely profile a user and then cater to this specific profile may fall short of keeping up with these dynamics. Second, social influence implies that recommendation decisions to different users cannot be made in isolation anymore: as recommendations alter a user X  X  interests through attraction and aversion, social influence can spread these changes, resulting in an interest cascade .Therefore, optimal recommendation decisions across users need to be com-puted globally ,takingintoaccountthejointeffecttheyhaveover the user X  X  social network.

In this work, we make the following contributions:  X  We formulate a global recommendation problem in the pre- X  We show that, for a large recommender item catalog, obtain-Figure 1: Illustration of aversion and attraction in MovieLens, and gains from accounting for them in optimization.  X  We provide evidence for the existence of attraction and aver- X  We conduct extensive experiments on real world datasets, and
Our analysis indicates that (a) the above phenomena are present in real-life datasets and (b) accounting for them can lead to sig-nificant gains in the improvement of recommendations. Figure 1 provides a quick illustration of these two facts (see Section 6 for adetailedaccountonthederivationthesetwofigures).Figure1(a) presents the distribution of a score measuring aversion and attrac-tion among different users in MovieLens (with  X  1 indicating users with the strongest aversive behavior, and +1 indicating users with the strongest attractive behavior). About 7 . 0% of users are strongly aversive (score  X  X  X  0 . 5 )while 9 . 0% are strongly attractive (score  X  0 . 5 ). Accounting for such users can lead to a significant im-pact on recommendations: as shown in Figure 1(b), the user social welfare more than doubles when incorporating this knowledge in recommendation decisions. Though there are clearly many factors of user behavior that are not accounted for in our analysis, we be-lieve that these two facts, along with the SDP relaxation yielding optimal recommendations, indicate that investigating and accom-modating for such phenomena is both important and tractable.
There has been a significant interest in modeling the temporal dynamics of user interests for various settings close to ours [19, 26,27,30]. Early work on matrix factorization (MF) by Koren [19] incorporates time-variant user profiles, an approach that we also adopt. We depart from this line of work by modeling, and also in-cluding in the MF process (see Section 5), factors that impact these drifts, including attraction, aversion, and social influence.
Several studies have highlighted the need for serendipity and di-versity in the context of recommender systems, both of which relate to the notion of aversion we describe here. The need for serendip-ity was first identified by McNee et al. [23]. To address this, Yu et al. [32] and Abbassi et al. [1] propose algorithms for recommend-ing items that maximize a score that combines both relevance to auseraswellasdiversity.Geetal.[12]focusonevaluatingthe lack of serendipity and diversity, and how it hurts the quality of recommendations. We depart from these works by modeling how recommendations themselves may instigate aversion or attraction among users, through a dynamic evolution of user interests.
Our approach to aversion is closer to Das Sarma et al. [27], who consider users that iteratively consume items in one out of several categories. They incorporate  X  X oredom X  and social influence in a manner similar to us: inherent item values decrease as a function of a weighted frequency of past consumption, and a user X  X  util-ity is averaged among her friend X  X  utilities. The authors provide bounds of the steady state performance of different consumption strategies under such dynamics. W edepartbymodellinguserinter-ests as multi-dimensional vectors, and using a factor-based model for user utilities, w hose dynamics and steady state behavior cannot be captured by the (one-dimensional) model in [27].

The literature on social influence is vast, motivated by the vi-ral marketing applications introduced by Domingos and Richard-son [9] and further studied by Kempe et al. [17]. Our influence model is closer to gossiping [28], in that the interest/state of each user results from averaging the interests of her neighbors. Though we depart from classic gossiping protocols in that we incorporate additional dynamics (through attraction and aversion), similar tech-niques as in [28] could potentially be used to study our system in scenarios where interest evolution is asynchronous across users. In the context of matrix factorization, Jamali et al. [16] propose in-corporating the distance of a user X  X  profile to the average profile of users in their social circle as a regularization factor in MF. This is consistent with the social influence behavior we outline in Sec-tion 3.3. We depart from this work by modeling dynamic profiles, and studying the additional effect of recommendations on user pro-files through attraction and aversion.

Semi-definite programming (SDP) relaxation for quadratically-constrained quadratic programs (QCQP) lies at the core of our al-gorithmic contribution. Building on the seminal work by Goemans and Williamson [13], several papers have demonstrated classes of QCQPs for which an SDP relaxation gives a constant approxima-tion guarantee [24, 25, 31]. Moreover, exact solutions of rank 1 are known to be attainable for several classes of QCQP, including when the problem has one [6] or two quadratic constraints [5]. Of special interest is the case where the quadratic objective involves non-negative off-diagonal elements, and constraints involve only quadratic terms of one variable [34], as the attraction-dominant case of our problem falls into this class (see Section 4.3). We re-fer the interested reader to [29] for SDP in general, and to [22, 25] for applications to quadratic programming.
In what follows, we present our mathematical model of users interacting with a recommender system. We use bold script (e.g., x , y , u , v )todenotevectors,andcapitalscript(e.g., A, B, H denote matrices. For either matrices or vectors, we use  X  element-wise inequalities. For symmetric matrices, we use indicate dominance in the positive semidefinite sense; in particular, A  X  0 implies that A is positive semidefinite. For square matrices A ,wedenoteby tr( A ) , diag( A ) , rank( A ) the trace, diagonal and rank of A ,respectively.Finally,givenan n  X  m matrix A ,wedenote by A :i.e., col( A ) maps the elements of A to a vector, by stacking the m columns of A on top of each other.
Our model assumes that user interests are dynamic: they are af-fected both by recommendations users receive, as well as by how other users X  interests evolve. In particular, our model of user behav-ior takes into account the following factors: 1. Inherent interests. Our model accounts for an inherent pre-2. Attraction. As per the mere-exposure effect, users may ex-3. Aversion. Users may also exhibit aversive behavior: a user 4. Social influence. Auser X  X behaviorcanbeaffectedbywhat
Under the joint effect of the factors above, suggestions made by the recommender instigate an interest cascade over the users. Suggestions alter user interests through attraction or aversion; in turn, these changes affect neighboring users as well, on account of their social behavior. These effects propagate dynamically over the users X  social network. Next, we formally describe how each of these factors is incorporated in our model.
We consider n users receiving recommendations from an entity we call the recommender. We denote by [ n ]  X  { 1 , 2 ,...,n } set of all users. At each time step t  X  N ,therecommendersuggests an item to each user in [ n ] ,selectedfromacatalog C of available items. The user accrues a utility from the item recommended. As discussed below, the recommender X  X  goal is to suggest items that maximize the aggregate user utility, i.e., the social welfare.
Following the standard convention in recommender systems, we assume factor-based user u tilities. At each t  X  N ,eachuser [ n ] has an interest profile represented by a d -dimensional vector u ( t )  X  R d .Moreover,theitemrecommendedtouser i at time t represented by a d -dimensional feature profile v i ( t )  X  the expected rating 1 auser i would give to the item suggested to her at time t is given by F ( u i ( t ) , v i ( t )) ,where i.e. ,theinnerproductbetweentheinterestandfeatureprofiles [18,20]. Intuitively, each coordi nate of a feature profile can be per-ceived as an item-specific feature such as, e.g., a movie X  X  genre or an article X  X  topic. The corresponding coordinate in an interest pro-file captures the propensity of the user to react positively or nega-tively to this feature.
 item at time t .Withoutlossofgenerality 2 ,weassumethattheitem profiles v i  X  R d are normalized, i.e.:  X  v i ( t )  X  2 =1 t  X  N . Under this assumption, given that a user X  X  profile is 1 In practice, (1) best approximates centered ratings, i.e., ratings offset by a global average across users. 2 Note that F ( u , v )= F ( s u , 1 assume that either user or feature profiles have a bounded norm. best item to recommend to user i is the one that yields the highest expected rating; indeed, this is i.e., the item that maximizes the utility of a user i .Notethatiden-tifying items that maximize the aggregate utility across users (i.e., the sum of expected ratings to suggested items), is a natural goal for the recommender.
The evolution of user interests captures the four factors outlined in Section 3.1. At each time step t  X  N ,theinterestprofileofa user i  X  [ n ] is chosen alternately between either a personalized or a social behavior. If personalized, the behavior of a user is again selected among three possible outcomes, each corresponding to in-herent interests, attraction, and aversion, respectively.
The selection of which of these four behaviors takes place at a given time step is random, and occurs independently of selections at other users as well as selections at previous time slots. We denote with  X   X  [0 , 1] the probability that the user selects a social behavior at time slot t .Theprobabilityofselectingapersonalizedbehavior is thus 1  X   X  .Interestsatthesetwodistincteventsareasfollows: Personalized Behavior. If a user X  X  interest is selected through a personalized behavior, the user selects her profile through one of the three personalized factors outlined in Section 3.1. In particular, for every i  X  [ n ] ,thereexistprobabilities  X  i ,  X  i ,  X  that  X  i +  X  i +  X  i =1 ,and:
To gain some intuition on (2) and (3), recall that a user X  X  utility at time t is given by (1). Therefore, a profile generated under (2) im-plies that the suggestion that maximizes her utility at time be one that aligns perfectly (i.e., points in the same direction as) the weighted average g up to time t  X  1 .Incontrast,undertheaversive behavior (3), the same suggestion minimizes the user X  X  utility.
Note that the weighted average g is fully determined by the se-quence weights { w  X  }  X   X  N .Byselectingdecayingweights,ahigher importance can be placed on more recent suggestions.
 Social Behavior. User i  X  X  profile is selected through social behavior with probability  X  .Conditionedonthisevent: The probability P ij  X  [0 , 1] captures the influence that user on user i .Notethatusers j for which P ij =0 (i.e., outside circle) have no influence on i .Moreover,thesetofpairs ( i, j ) P ij  X  =0 ,definesthesocialnetworkamongusers.Wedenoteby we assume that P is ergodic (i.e., irreducible and aperiodic) [11].
Under these dynamics, interests evolve in the form of a dynamic cascade: suggestions made by the recommender act as a forcing function, altering interests either through attraction or aversion. Such changes propagate across users through the social network.
In practice, the recommender has access to a finite  X  X atalog X  of items. Recalling that feature profiles have norm 1, the rec-ommender X  X  catalog can be represented as a set C  X  B ,where B = { v  X  R d :  X  v  X  2 =1 } is the set of items of norm 1 (i.e., the d -dimensional unit ball).
 We assume that the recommender selects the items v j ( t )  X  suggested to user i  X  [ n ] by sampling them from a discrete distri-bution  X  i over B ,whosesupportis C .Notethattheexpectedfeature profile of a suggested item is a weighted average among the vectors in
C .Assuch,itbelongstothe convex hull of catalog C ;formally: Note that conv( C ) is a convex polytope included in B .
As we will see later in our analysis (c.f. Theorem 1), the steady state user utilities depend only on the expectations i  X  [ n ] ,ratherthantheentiredistributions  X  i .Wewillthusrefer to {  X  v i } i  X  [ n ] as the recommender strategy ;itisworthkeepingin mind that, given a  X  v i  X  conv( C ) ,findinga  X  i such that (5) holds can be computed in polynomial time in | C | (see also Section 4.4).
We further assume that the catalog C is large; in particular, for large catalog size | C | ,wehave: This would be true if, for example, each item in the catalog are gen-erated in an i.i.d. fashion from a distribution that covers the entire ball B ;thisdistributionneednotbeuniform 3 .Werevisittheissue of how to pick a distribution  X  i given  X  v i ,aswellashowtointerpret our results in the case of a finite catalog, in Section 4.4.
Observe that, under the above dynamics, the evolution of the sys-tem is a Markov chain, whose state comprises the interest and fea-ture profiles. We define the objective of the recommender as maxi-mizing the social welfare, i.e., the sum of expected user utilities, in steady state .Formally,wewishtodetermineastrategy {  X  v i (and, hence, distributions  X  i )thatmaximizes: lim 3 Formally, lim | C |  X  X  X  conv( C )= B w.p. 1 if, e.g., items in cat-alog C are sampled independently from a probability distribution absolutely continuous to the uniform distribution on B . where the equality above holds w.p. 1 by the renewal theorem [11]. It is important to note that, under the interest dynamics described in 3.3, optimal recommendations to a user i cannot be obtained independently of recommendations to other users: user i  X  X  profile depends on recommendations made not only directly to this user, but also to any user reachable through i  X  X  social network.
In this section, we discuss how the recommender selects which items to present to users to maximize the system X  X  social welfare. We begin by obtaining a closed-form formula for the social welfare in steady state, and then discuss algorithms for its optimization.
Recall that  X  0 i is the inherent profile distribution of user and let  X  i be the steady state distribution of the profile of user denote by  X  u i = $ profile of i  X  [ n ] under the steady state and inherent profile distri-butions, respectively. Moreover, denote by  X  U,  X  U 0 , matrices of dimensions n  X  d whose rows comprise the expected profiles  X  u i ,  X  u 0 i ,  X  v i , i  X  [ n ] ,respectively.Letalso be the n  X  n diagonal matrices whose diagonal elements are the coefficients (1  X   X  )  X  i , (1  X   X  )  X  i ,and (1  X   X  )  X  i
Then, the steady state social welfare can be expressed in closed form according to the following theorem.
 T HEOREM 1. The expected social welfare in steady state is:
G (  X  V )  X  tr where tr(  X  ) denotes the matrix trace.

P ROOF .Observethatatanytimestep t  X  [ n ] the profiles u and v i ( t ) are independent random variables. Hence, Observe that by the linearity of expectation E [ g ( V i ( t ))] =  X  v all t  X  N and i  X  [ n ] .Thus,for U ( t )=[ u i ( t )] i  X  [ n ] matrix of user profiles at time t ,wegetthat As  X  P is sub-stochastic and ergodic, the Perron-Frobenius theo-rem [11] implies that  X  U =lim t  X  X  X  E [ U ( t )] exists and Solving this linear system, and substituting the solution for  X  (8), yields the theorem.

An important consequence of Theorem 1 is that the steady state social welfare depends only on the expected profiles  X  V than the entire distributions  X  i , i  X  [ n ] .Hence,determiningthe optimal recommender strategy amounts to solving the following quadratically-constrained quadratic optimization problem (QCQP): subj. to:  X   X  v i  X  2 2  X  1 , for all i  X  [ n ] . where the norm constraint comes from (6). Note that this is indeed a global optimization: to solve it, recommendations across different users need to be taken into account jointly. This manifests in (9) through the quadratic term in the social welfare objective.
The QCQP (9) is not necessarily convex. It is thus not a priori clear whether it can be solved in polynomial time. However, there is awaytoreducetoasemi-definiteprogram(SDP)relaxation,which can be solved in polynomial time. Interestingly, in many cases, the solution obtained for the SDP relaxation turns out to be an optimal solution to our original problem (9), and there is a simple and effi-cient test that can verify whether the obtained solution is optimal. Finally, when the solution is not optimal, it can be transformed to yield a constant-factor approximation. We are thus able to obtain a strong and elegant theoretical result for solving the G LOBAL
It is important to note that the large-catalog assumption (6) is crucial to tractability: replacing the quadratic constraints with the linear constraints (5) does not lead to a problem that is amenable to an SDP relaxation. In fact, generic quadratic problems with linear constraints are known to be inapproximable, unless P = NP [25]. Deriving an SDP Relaxation .Webeginbydescribingfirsthowto express (9) as  X  X lmost X  an SDP, except for a rank constraint: T HEOREM 2. There exists a symmetric matrix H  X  such that G LOBAL R ECOMMENDATION (9) is equivalent to:
P ROOF .Let x =col(  X  V )  X  R nd be the column-major or-der vector representation of the recommender X  X  strategy, and term in (7). Moreover, for Q =( I  X   X  P )  X  1 (  X   X   X  )  X  is repeated d times: Under this notation, (9) can be written as of x ,and D 0 the set implied by the norm constraints:
D 0 = { x  X   X  R nd | / i  X  [ n ] , Note that D 0 is a convex polyhedral set defined by linear equality constraints. Moreover, (11) can be homogenized to a quadratic pro-gram without linear terms using the following standard trick (see also [22, 25, 29]). Introduc ing an auxiliary variable t ,theobjective can be replaced by t b T x + x T H 0 x ,where t satisfies the constraint t  X  1 .Setting y =( x ,t )  X  R nd +1 ,thisyields: where H is the following symmetric matrix: and To see that (12) and (11) are equivalent, observe that an optimal solution ( x ,t ) to (12) must be such that t =  X  1 or t =+1 t =+1 ,then x is an optimal solution to (11); if t =  X  1 ,then is an optimal solution to (11). Finally, (12) is equivalent to (10), by setting Y = yy T and using the fact that y T H y =tr( H yy
In particular, given an optimal solution Y to (10), an optimal solution to G LOBAL R ECOMMENDATION can be constructed as fol-lows. Since Y  X  0 and rank( Y )=1 ,thereexists y  X  R nd +1 such that Y = yy T .Morespecifically, Y has a unique positive eigen-value  X  .If e is the corresponding eigenvector, y =( x ,t )= An optimal solution to (9) is thus the matrix  X  V  X  R n  X  d with column-major order representation col(  X  V )= t  X  x .

Problem (10) is still not convex, o naccountoftherankconstraint on Y .However,inlightofTheorem2,anaturalrelaxationfor G
LOBAL R ECOMMENDATION is the following semi-definite pro-gram, resulting from droppi ng this rank constraint:
This is a relaxation, in the sense that it increases the feasible set: any solution to (10) will also be a solution to (13). Crucially, (13) is a convex SDP problem, and can be solved in polynomial time. Moreover, if it happens that the optimal solution Y has rank 1, this solution is also guaranteed to be an optimal solu-tion to (10), and can thus be used to construct an optimal solution to G LOBAL R ECOMMENDATION ,byTheorem2.If,ontheother hand, rank( Y ) &gt; 1 ,wearenotguaranteedtoretrieveanopti-mal solution to (10). However, a solution with a provable approxi-mation guarantee can still be constructed through a randomization technique, originally proposed by Goemans a nd Williams on [13]. Approximation Algorithm. Algorithm 1 summarizes the steps in the approach outlined above to solving G LOBAL R ECOMMENDA TION .First,thealgorithmobtainsanoptimalsolution Y to the SDP (13). It then tests if rank( Y )=1 ,i.e.,ifthissolutionhappensto have rank 1. If it does, then it is also a solution to (10), and an op-timal solution to (9) can be constructed as outlined in the proof of Theorem 2. In particular, Y can be written as Y = yy T ,where eigenvalue of Y and its corresponding eigenvector. The optimal so-lution to (9) can subsequently be obtained as the matrix  X  that has a column-major order representation col( V )= t  X  x
If, on the other hand, rank( Y ) &gt; 1 ,thealgorithmreturnsavec-tor ( x ,t ) constructed in a randomized fashion. In particular, the algorithm returns the vector Y  X  X  diagonal elements, with each coordinate multiplied by a ran-dom sign ( +1 or  X  1 ). The random sign vector  X   X  {  X  1 , +1 } used in this multiplication is constructed as follows. Given that Y  X  0 ,thereexistsamatrix Z  X  R n  X  n that factorizes Y ,i.e., Y = Z T Z .Suchamatrixcanbeobtainedinpolynomialtimefrom the eigendecomposition of Y .Having Z ,thealgorithmproceedsby sampling a random vector u  X  R nd +1 from a standard Gaussian distribution. Then,  X  is the binary vector computed by applying the sign operator on the coordinates of vector Z T u .

The resu lting random y =( x ,t )  X  R nd +1 is guaranteed to be afeasiblesolutionto(10).Mostimportantly,thefollowingapprox-imation guarantee for the quality of the corresponding solution to G
T HEOREM 3(Y E [25]). Let G  X  , G  X  be the maximal and minimal values of the social welfare G given by (7) ,evaluatedover the feasible domain of (9) .Letalso  X  V be the solution generated by Algorithm 1 when rank( Y ) &gt; 1 .Then where the expectation E u [  X  ] is over the Gaussian vector
The existence of a simple test (namely, rank( Y )=1 )verifying that the solution produced by Algorithm (1) is optimal is important. In fact, in Section 6, we study an extensive set of instances, involv-ing several social network topologies and combinations of aversive and attractive behavior. In each and every instance studied, Algo-rithm 1 yielded an optimal solution .Hence,althoughthequadratic program (9) is not known to be within the class of problems that can be solved exactly through an SDP relaxation, the experiments in Section 6 suggest that a stronger guarantee than the one provided by Theorem 3 is attained in practice.
Though for generic instances of (9) we cannot obtain a better theoretical guarantee than Theorem 3, there are specific instances of (9) for which optimality is always attained, and the approxima-tion through randomization is not necessary. As these cases are also of practical interest, we briefly review them below.
 Attraction Dominance .Considerascenariowhere(a)  X  i &gt;  X  for all i  X  [ n ] and (b)  X  U 0  X  0 .Intuitively,(a)impliesthatattrac-tion to proposed content is more dominant than aversion to content, while (b) implies that user profile features take only positive values. Hence, the matrix H in Theorem 2 has nonnegative off-diagonal elements. Although the QCQP (9) in this case is not convex, it is known that in this specific case Algorithm 1 provides an optimal, rank-1 solution [34].
 Uniform Aversion Dominance .Considerascenariowhere(a)all parameters are uniform across users, i.e.,  X  i =  X  and  X  i i  X  [ n ] ,and(b)  X  &lt;  X  ,i.e.,aversiondominatesuserbehavior.In this case, the QCQP (9) is convex and can thus be solved optimally by standard interior point methods in polynomial time [6]. No Personalization. Consider the scenario where the same item is recommended to all users , i.e. , v i ( t )= v ( t ) , / i  X  [ n ] . case, G LOBAL R ECOMMENDATION reduces to a quadratic objec-tive with a single quadratic constraint, in which case even though the problem may not be convex, Algorithm 1 is guaranteed to find arank-1,optimalsolution[6].
 No Social Network. In the case where  X  =0 ,andthereisno social component to the optimization, the social welfare (7) be-comes separable in  X  v i ,i.e., G (  X  V )= ! is a quadratic function. Then, the optimization is separable, and a solution to (9) can be obtained by solving max  X  v for each i  X  [ n ] ;theseareagainquadraticproblemswithasingle quadratic constraint, and can be solved exactly by Algorithm 1 [6].
Recall that our analysis assumes (6), which becomes applicable for a large catalog C covering the unit ball B .Wedescribebelow how a computed profile  X  v i , i  X  [ n ] can be used to construct a distribution  X  i over catalog C .

If  X  v i  X  conv( C ) ,therecommendercanselectprobabilities  X  ( v ) ,for v  X  C ,thatsatisfy(5);thisequality,alongwiththe positivity constraints, and the constraint ! adistribution),arelinear,anddefineafeasibleset.Thus,findinga probability distribution satisfying (5) (i.e., that lies in the feasible set) is a linear program, which can be solved in polynomial time.
If, on the other hand,  X  v i /  X  conv( C ) ,thesameprocedurecanbe applied to the projection of  X  v i to conv( C ) .Giventhat aconvexpolytope,thiscanagainbecomputedinpolynomialtime. Moreover, under (6), if the catalog C is large this projection will be close to the optimal value  X  v i .
In this section, we provide an algorithm for validating the ex-istence of attraction and aversion phenomena in real datasets. In short, our approach involves incorporating aversion and attraction parameters into Matrix Factorization (MF) [18, 20]; we treat pa-rameters  X  i ,  X  i and  X  i as regularization terms, which are learned through cross validation.
 Extending MF. We focus on datasets that comprise ratings gen-erated by users, at known times (such as the datasets used in Section 6). More specifically, we assume access to a dataset rep-resented by tuples of the form ( i, j, r ij ,t ) where i  X  [ n ]  X  { 1 ,...,n } is the id of a user, j  X  [ m ]  X  { 1 ,...,m } an item, r  X  R the feedback (rating) provided by user i to item j and t  X  [ T ] the time at which the rating took place. Denoting by
E  X  [ n ]  X  [ m ] the pairs appearing in tuples in this dataset, re-call that matrix factorization (MF) amounts to constructing profiles u min where  X  ,  X  &gt; 0 are regularization parameters to be learned through cross validation. Though this is not a convex problem, it is typically solved either through gradient descent or alternating least squares techniques, both of which perform well in practice [18,20].
We incorporate attraction and aversion in this formulation as fol-lows. First, at any time step t  X  [ T ] ,theprofileofauser by u i ( t )  X  R d .Let E i ( t )  X  [ m ] be the set of items rated by user at time t and be the set of items the user has interacted with up to time sive). As in Section 3, we denote by g ( V i ( t )) the weighted average Algorithm 2: Attraction-Aversion Learning Algorithm of items in V i ( t ) .Then,weproposeobtaining u i ( t ) as solutions to: where u 0 i , v j are computed through standard MF (14), and  X  ,  X  i , i  X  [ n ] and  X  are also treated as regularization parameters, to be learned through cross validation. Note that, in contrast to (14), (15) is a simple linear regression problem, and the profiles where i  X  [ n ] , t  X  [ T ] ,canbecomputedinclosedform. Learning Procedure. Based on this approach, our algorithm for learning the vectors  X  ,  X  ,and  X  is outlined in Algorithm 2. First, we learn the inherent profiles u 0 i and the item feature profiles by solving (14), through stochastic gradient descent. Then, we use ular, we split the ratings dataset in k folds, and use k  X  1 atrainingset,andonefoldasatestset.Inourevaluation,weset k =5 .Welearn u i ( t ) by solving (15) on this restricted dataset. Using these, we compute the square error on the test set as: We repeat this process across k folds and obtain an average  X  We compute vectors  X  ,  X  ,  X  that minimize the average  X  Note that this is a function of the regularization parameters of (15), solution, so does  X  SE test (  X  ,  X  ,  X  ,  X  ) .Usingthis,wefind through projected gradient descent, requiring that they sum to 1.
We perform experiments to evaluate our parameter learning and social welfare-maximizing algorithms on three real-world rating datasets: Flixster, FilmTipSet, and MovieLens, as well as several synthetically generated traces. The implementations are in Matlab and we use the CVX library [14] to solve the SDP in Algorithm 1. All experiments were run on a server with AMD Opteron 6272 CPUs (eight cores at 2.1GHz) and 128GB memory.
 Dataset Preparations. We first describe the three real-world rating datasets. Their statistics are summarized in Table 1.
 lected by Jamali et al. [16], comprises 1M users, 14M undirected friendship edges, and 8.2M timestamped ratings (ranging from 0.5 network. Further, we filter out users and movies with less than 100 ratings so that there is enough data to learn temporal profile vectors. This gives a core of 4.6K users, 44K edges, and 25K movies. originally published for a research competition in the CAMRa ings (on the scale of 1 to 5). We select users rating no less than 100 movies in both 2004 and 2005. This gives a core of 443 users, 4.3K movies, and 118K ratings.
 cus on users that have rated at least 20 movies in the year of 2000. Note that there is no social network in MovieLens. FilmTipSet con-tains some social networking information, which we were unable to use in our analysis due to its extreme sparsity (85 edges for the 443 core users). Learning on Synthetic Data. We first run Algorithm 2 on a syn-thetically generated dataset to examine its accuracy. We set 100 , T =100 ,and d =5 .Eachuser i  X  [ n ] consumes one ran-dom item at every time step t  X  [ T ] .Forallusers i ,wegenerate  X  X round-truth X   X  i ,  X  i ,and  X  i uniformly at random from normalize them so that  X  i +  X  i +  X  i =1 .Theexpectedinherent interest profiles and item profiles are generated uniformly at ran-ics in Section 3.3, with  X  =0 ,andweightedaverage g with equal weights. At each step, users generate ratings computed by taking the inner product of appropriate profile vectors.

The learning rate  X  and regularization parameter  X  in Algo-rithm 2 are both set to be 0 . 001 (determined by cross validation). The convergence condition of Algorithm 2 is set to be the change in  X  with different random starting points and report the results obtained in the repetition that gives the smallest  X  SE test .
 RMSE to define the learning error w.r.t.  X  i  X  X : RMSE  X  and RMSE  X  can thus be defined in the same way. Fig-ure 2a shows the decrease of these RMSEs as the number of iter-ations goes up. At convergence, they are 0 . 08 , 0 . 58 and spectively. In addition, Figure 2a also shows that the test RMSE (computed as ceeds, which finally converges to 0 . 02 in a total of 5300
In Figure 2b, we show a scatter plot of the ground-truth prob-abilities and the learned probabilities (at convergence). Each data point has one gr ound-truth probability value in x -coordinate and the corresponding learned value in y -coordinate. The y = x dicates points for whic hthelearnedandground truth probabilities are equal. As can be seen, the algorithm recovers  X  i  X  X  almost per-fectly, while the results for  X  i  X  X  and  X  i  X  X  are also reasonably good. http://www.flixster.com/ http://www.cs.utexas.edu/users/dml/ Software/graclus.html http://www.filmtipset.se/ http://www.dai-labor.de/camra2010/ http://grouplens.org/datasets/movielens/ (a) Test RMSE, RMSE  X  , RMSE  X  ,and
RMSE  X  over iterations on three real-world datasets on three real-world datasets This gives us confidence in deploying the algorithm on real-world rating data, in which ground-truth parameters are not known. Learning on Real Data. For each dataset, we sort the ratings in chronological order and split them into T =10 time steps. A single time step corresponds to 3, 1.2, and 2.5 calendar months in Flixster, MovieLens, and FilmTipSet, respectively. We then run Algorithm 2 with learning rate  X  =0 . 001 ,regularizationparameter  X  =0 . 001 and number of latent features d =10 .Figure3showsthedis-tributions of values learned for  X  i  X  X . Furthermore, to compare the number of attraction-dominant users and the number of aversion dominant users, in Figure 4 we display the distribution of along with a Gaussian distribution fitted by data within the interval [  X   X  1 . 8  X  ,  X  +1 . 8  X  ] (capturing 90% of a Gaussian distribution), be seen, the empirical distribution has tails that are heavier than the Gaussian (at about  X  0 . 5 and 0 . 5 ), indicating the existence of strongly aversive and strongly attracted users.

For reference, we also compare the average test RMSE on five-fold cross-validation achieved by our model and by standard MF. For standard MF, we implement the stochastic gradient descent method as in [20] with d =10 ,learningrate0.002,andregulariza-tion parameters determined by cross validation. As shown in Fig-ure 2c, profiles learned by Algorithm 2 outperform standard MF in rating prediction, lowering the test RMSE by 11.8%, 11.9%, 6.18% on Flixster, FilmTipSet, and MovieLens respectively.
Next, we evaluate Algorithm 1, hereafter referred to as GRA , and compare the social welfare it yields with a baseline that ig-nores interest evolution. This baseline recommends to each user  X  (c) Varying  X  i  X   X  i the item profile maximizing the user X  X  utility under the inherent profile computed by standard MF. For each user i  X  [ n ] ,this is v i = u 0 i / || u 0 i || 2 ,forall i  X  [ n ] .Itisthuseasytoseethat || v i || 2 =1 and it is in fact co-linear w.r.t. u 0 i .Wehereafterre-fer to this baseline as MF-Local .Inallexperiments,followingthe literature of social influence propagation and maximization [8,17], we set the influence probability of user j on user i to be where deg in ( i ) is the in-degree of node i in the network graph. We start by evaluating the social welfare achieved by GRA and MF-Local on three different of random networks that mimic the structure of a social network: Forest-Fire [4], Kronecker [21], and Power-Law [2]. For each type, we consider the following settings: Forest-Fire with forward and backward burning probability being 0 . 38 and 0 . 32 respectively, Kronecker with initiator matrix being [0 . 9 , 0 . 5; 0 . 5 , 0 . 3] ,andPower-Lawwithexponent 2 . 1
We vary the size of network graphs (i.e., number of users, value of  X  (i.e, users X  tendency of getting influenced by friends), and the difference between  X  i and  X  i ,toevaluatetheireffectsonthe performance of our GRA algorithm in comparison to MF-Local . Unless otherwise noted,  X  i  X  X ,  X  i  X  X ,  X  i  X  X , and inherent user profiles are sampled randomly and the process is repeated ten times, of which we take the average social welfare. Also, d is fixed to be 10 .Inallcases,weplotthe relative gap in social welfare, i.e., ( Social Welfare GRA  X  Social Welfare MF-Local ) / | Social Welfare Effect of Network Size. We test five different values for 10 , 50 , 100 , 150 ,and 200 for Forest-Fire and Power-Law, and 16 , 32 , 64 , 128 ,and 256 for Kronecker (b ydefinitionarandom Kronecker graph has 2 w nodes where w  X  N + is the number of it-erations of Kronecker product taken in the generation process [21]). As can be seen from Figure 5a, the gap between GRA and MF-Local is close to 10% for small graphs, but increases on all three networks for larger values of n : GRA achieves twice as much so-cial welfare as MF-Local ,for n =200 .
 Effect of  X  . In this test, we vary the value of  X  from 0 Network size is fixed at 100 for Forest-Fire and Power-Law, and 128 for Kronecker. Figure 5b shows that GRA significantly outper-forms MF-Local ,andmoreinterestingly,therelativegapincreases as  X  increases. This intuitively suggests that when the influence among users is higher, ignoring the joint effect of recommenda-tions becomes more detrimental to maximizing the social welfare. Effects of  X  i  X   X  i . Next, we test different values of  X  senting cases from extreme aversion dominance to attraction dom-inance. Network size is n =100 and  X  =0 . 25 ,while  X  i =  X  Figure 6: Social welfare achieved on: FX(0.1) and FX(0.5)  X  Flixster with  X  =0 . 1 and 0 . 5 ;FT X  X ilmTipSet;ML X  X ovieLens.  X  =  X  and  X  i =  X  for all i  X  [ n ] .Weset  X  s.t.  X  (1  X   X  )=0 . 25 and vary  X   X   X  ,where  X  +  X  +  X  =1 .Relativegapsareshownin Figure 5c. All in all, we see that gaps are far more pronounces in the strongly aversive regime, as targeting to the existing profiles of users leads to suboptimal recommendations. For values less than -0.3, the social welfare under MF-Local is actually negative; it goes up as  X   X   X  increases, i.e., users tend towards attractive behavior. In contrast, the social welfare of GRA is always positive, and always greater than the one under MF-Local .Asaresult,thereisalarge gap for values at less than  X  0 . 3 ;therelativegapbecomessmall (but still positive) near  X  0 . 1 ,andthensteadilyincreases.
It is important to note that in all evaluations of GRA over syn-thetic datasets, as well as the ones listed below on real datasets, GRA returned an optimal solution .Thatis,forallinputstested,the matrix Y computed had rank 1. Hence, although the QCQP prob-lem (9) is not known to be solvable in polynomial time, in practice, GRA outperforms the guarantee of Theorem 3. We next compare the social welfare attained on Flixster, FilmTipSet, and MovieLens by GRA and MF-Local .For FilmTipSet and MovieLens where there is no social network con-sidered, G LOBAL R ECOMMENDATION is separable and can thus be parallelized (see Section 4.3): we can divide users into arbitrary subsets, run GRA on each of them, and then combine the total so-cial welfare over all subsets as the final solution without any loss.
To improve the scalability of GPA over Flixster, and parallelize its execution, we adopt the following heuristic. First, we split the social graph into 50 subgraphs using Graclus. Then, we solve SDP on each subgraph separately. Note that, in effect, this optimization ignores the edges between subgraphs, and thus only yields an ap-proximation to the social welfare.

Figure 6 illustrates the performance of GRA and MF-Local on those datasets, where the values of  X  i ,  X  i ,and  X  i are all from the learning results in Section 6.1 and dimensionality d is set to 10. We can see that GRA is significantly superior to MF-Local :on FilmTipSet (1461 vs. 757) and MovieLens (11092 vs. 4926), it achieves approximately twice the social welfare. On Flixster, we test two cases for  X  :0.1and0.5,representingweakandstrongso-cial behavior respectively. For GRA ,weadopttheaforementioned clustering-based heuristic to compute  X  v i  X  X , and evaluate the wel-fare achieved by GRA in two ways: (i) simply calculating the wel-fare on the subgraph and taking the sum over all subgraphs (termed GRA -heuristic); (ii) taking the  X  v i  X  X  to calculate the social welfare on the entire graph (termed GRA ). The values computed by method (ii) are only slightly different from (i), indicating that our cluster-ing heuristic closely follows the true social welfare, while enabling parallelization. The relative gain of GRA -heuristic over MF-Local is 39.0% when  X  =0 . 1 and 13.4% when  X  =0 . 5 .Therunning time of GRA is reasonably good, e.g., on a subgraph of Flixster with 94 nodes and 276 edges, GRA finishes in 90 seconds.
In summary, through extensive empirical evaluation on both real and synthetic data, we have demonstrated that first, the phe-nomenon of interest evolution, especially attraction and aversion, can indeed by observed from real-world rating data, and second, both of our learning algorithm and global recommendation algo-rithm are highly effective in their respective tasks.
Our study of attraction, aversion, and social influence suggests that such phenomena can be incorporated in recommendation de-cisions, and that the SDP relaxation approach brings relevant op-timizations within the realm of tractability. The heuristic we ex-ploited in Section 6, namely, parallelizing execution over weakly connected partitions of the social graph, highlights an approach for scalable, parallelizable solutions to the SDP relaxation. Neverthe-less, further opportunities for improv ing efficiency exist: the sparse, block structure of the matrices in our SDP was not exploited by the generic solvers we employed. Investigating solutions that exploit this structure for higher efficiency is an interesting future direction. Moreover, although the QCQP that expresses our problem is not known to be exactly solvable through an SDP relaxation, all solu-tions we obtained through our experiments were actually optimal. Understanding if optimality holds for a wider class than the ones presented in Section 4.3 is also an important open problem. Finally, there are many phenomena beyond attraction, aversion and social influence that may affect a user X  X  interests. The quadratic nature of our problem arises from the standard factor-based model for util-ities: understanding if other phenomena inducing drift on profiles can also be cast in this framework is also an open question.
