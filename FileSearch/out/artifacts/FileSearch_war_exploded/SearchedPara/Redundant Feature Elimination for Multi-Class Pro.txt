 Annalisa Appice APPICE @ DI . UNIBA . IT Michelangelo Ceci CECI @ DI . UNIBA . IT Classification is one of the fundamental tasks in machine learning. In the usual classification setting, input or train-ing data consists of multiple examples, each having mul-tiple attributes or features X i . Each example is tagged with a class label c j . The goal is to learn the target concept as-sociated with each class by finding regularities in exam-ples of a class that characterize the class in question and discriminate it from the other classes. This problem has been extensively studied in machine learning. However, the growing importance of knowledge discovery and data mining in practical real world applications, where data consists of a large amount of records that may be stored in different tables of a relational database, requires increas-ingly sophisticated solutions for classification problems  X  X  X  X  X  such as multi-relational data mining or propositionalisa-tion. In particular, propositionalisation (Dzeroski &amp; Lavra , 2001; Krogel et al., 2003) is the process of trans-forming a multi-table representation of data into the form of a single table. The result can be used as input for at-tribute-value learning algorithms.
 Propositionalisation tends to produce large numbers of features, many of which are highly correlated or even logically redundant. A simple example of a redundant feature is one which is never (or always) satisfied: e.g.,  X  X  molecule having an atom which has a bond with itself X . While some forms of redundancy can be recognised at feature generation time, others can only come to light by examining the data. Pagallo &amp; Haussler (1990) investigate the problem of discovering a subset of Boolean features to describe two-class Boolean concepts. using three different algorithms. F RINGE induces decision trees in which Boo-lean features are adaptively constructed at each node whereas G REEDY 3 and G ROVE use greedy accuracy-based heuristics to build decision lists. These methods select Boolean features as part of learning rather than according to any definition of logical redundancy. In contrast, (Lavra et al., 1999) proposed a method to remove Boo-lean features that are logically redundant with respect to a two-class data set. They defined a feature f to be redun-least the same positive examples as f and false for at least the same negative examples as f . The R EDUCE algorithm operates by pairwise comparison of the features.
 In this paper we improve and extend the R EDUCE algo-rithm in two ways. First, we increase the number of re-dundant features detected, without losing the ability to find a complete and consistent theory with the reduced feature set. Secondly, we extend the method to multi-class problems. Central to our approach, which we call R (REdundant FEature Reduction) is the notion of a neigh- X  X  X  X  X  bourhood of examples: a set of examples of the same class where the number of different features between ex-amples is relatively small. Redundant features are elimi-nated by applying a revised version of the R EDUCE method to each pair of neighbourhoods of different class. The paper is organized as follows. In the next section we discuss the background to our work and some related work. The method is presented in Section 3. Experimental results are reported in Section 4 and conclusions are drawn in Section 5. It is useful to distinguish between feature selection and feature reduction. Feature selection is concerned with identifying a small subset of relevant features that are sufficient for learning the target concept. We define fea-ture reduction as eliminating logically redundant features. In a certain sense, the two approaches are orthogonal: feature selection aims at increasing correlation with the class (relevance), feature reduction aims at reducing cor-relation among features (redundancy). This different fo-cus may lead to different results: for instance, if we have several copies of a highly relevant feature, feature selec-tion will select all of them, while feature reduction will eliminate all but one. 2.1 Feature Selection The problem of feature selection has been widely ex-plored in machine learning. Reasons include that irrele-vant features may deteriorate the predictive performance of a learning algorithm (Langley, 1996; Rendell &amp; Seshu, 1990), as well as reduce the comprehensibility of the learned model (Dash &amp; Liu, 1997; Blum &amp; Langley, 1997). Feature selection approaches may be categorised into wrapper, filter and embedded approaches (Kohavi et al., 1994; Blum &amp; Langley, 1997), according to whether the method takes into account the characteristics of the data, the target concept or the learning algorithm.
 In the wrapper approaches, the goal is to find a subset of features that maximizes accuracy. The wrapper approach implies that the selection algorithm searches for a good subset of features using the induction algorithm itself as a part of the evaluation function, the same algorithm that will be used to learn the final target concept. In the filter approaches, the goal is to filter the irrelevant and/or re-dundant features on the basis of the characteristics of the training data without involving any learning algorithm. Finally, in the embedded approaches the feature selection process is done inside the learning algorithm. For exam-ple, partitioning and divide-and-conquer methods implic-itly select features for inclusion in a branch or rule in preference to other features that appear less relevant. Embedded approaches are intrinsic to some learning algo-rithms and so only those algorithms designed with this characteristic can be used. However, embedded ap-proaches such as Adaboost (Freund &amp; Schapire, 1997) can often be quicker than wrapper or filter ap proaches since they perform feature selection and induction at the same time. Filtering approaches ensure a fairly good computational complexity, but the wrapper approaches with their higher complexity tend to produce higher re-sulting accuracy. Filtering approaches are very flexible, since any target learning algorithm can be used, while the wrapper approach is strictly dependent on the learner. Among the filter approaches, it is also possible to distin-guish between approaches based on probabilistic distance measures, probabilistic dependence measures, interclass distance measures or information theoretic measures such as the entropy. For instance, R ELIEF (Kira &amp; Rendell, 1992) and its extension to multi-class problems R ELIEF (Kononenko, 1994) estimate the relevance of each feature according to the difference between the selected example and the nearest examples of the same and different classes. However, R ELIEF does not help with removing redundant features. As long as features are deemed rele-vant to the class concept, they will be selected even though many of them are highly correlated with each other (Kira &amp; Rendell, 1992).
 F
OCUS (Almuallim &amp; Dietterich, 1991) is a straightfor-ward filtering algorithm for noise-free, multi-class Boo-lean data. It exhaustively examines all subsets in order of size to find the minimal subset necessary for concept learning. F OCUS has a time complexity of O( n p ) for p relevant features among n total features and is therefore impractical for high-dimensional data sets.
 S
CRAP (Raman, 2003) implements a sequential search filter approach that is able to detect relevant features in multi-class problems. S CRAP divides the entire set of training examples into neighbourhoods that are groups of similar examples tagged with the same class label and identifies the features that are required to discriminate between adjacent neighbourhoods containing examples belonging to a different class. However, similarly to R
ELIEF , S CRAP does not consider dependencies among features. Furthermore, this method cannot guarantee that selected features are sufficient to discriminate among all classes (i.e., the completeness and consistency of the learned theory) since it analyses only the centres of pairs of adjacent neighbourhoods. 2.2 Feature Reduction Feature reduction and elimination of redundant features have been studied to a much lesser extent. A definition of redundancy follows from reducts in rough sets theory (Modrzejewski, 1993), in which Boolean features are re-dundant if their removal does not change the set of exam-ple-pairs having the same value for each feature. In this paper our main inspiration comes from (Lavra et al., 1999), who situate their work in the setting of inductive logic programming (ILP). The primary aim of their R
EDUCE algorithm is to detect which features (or literals, in the ILP setting) are redundant for learning and exclude them in order to reduce the hypothesis space. They prove that their method achieves this without compromising the existence of a complete and consistent theory for the tar-get concept, which is assumed to be Boolean. One of their conclusions is that  X  X he method is more effective when there are many literals and a small number of examples X . The method we propose in this paper addresses exactly this issue. By using neighbourhoods similar to those of S
CRAP , and calling a variant of R EDUCE on pairs of neighbourhoods of different class, we achieve further feature reduction (with a factor of more than two on dif-ferent propositionalised versions of the mutagenesis ILP benchmark). Furthermore, the use of pairwise comparison leads to a very natural upgrade to multi-class problems. In the next section we present our improved multi-class fea-ture reduction method R EFER . The multi-class concept learning problem can be defined as follows. Given (1) a set of training examples E = { e e , ..., e n }, each of which is tagged with a class label in C hypothesis language LH that defines the space of hy-potheses SH : find a theory T = { H 1 , ..., H hypotheses in SH describing a concept for each class in C , that is complete and consistent with respect to each class. This means that for each i , 1 i r , BK H i |= e each example e + of class i ( completeness property) and BK H i | e  X  for any example e  X  not of class i ( consis-tency property).
 In this paper we consider training examples e i E that are described by m Boolean features f i F where a feature is a mapping from examples to Booleans. R EFER (see Figure 1) is a two-stage process based on the iterative partition-ing of the example set into neighbourhoods (R EFER followed by the reduction of features among these parti-tioned examples (R EFER -R). We now describe these two stages in turn. 3.1 R EFER -N: Neighbourhood Construction R EFER -N produces a set of disjoint neighbourhoods E 1 , ..., E ( w n ), forming a set partition of the training set E , such that each neighbourhood E i contains a subset of ex-amples belonging to one class c i C only. Each neigh-bourhood is uniquely identified by two examples. The first example is where the neighbourhood construction started and the second one is the termination point. Let e
E be a random starting example for the construction of a neighbourhood. R EFER -N finds a corresponding termi-nation point, the closest example in e t E tagged with a different class label, referred to here as the point of class change . The neighbourhood E ( e s , e t ) contains the set of training examples where the distance between two examples is computed as the Hamming distance , that is, the number of features whose values differ between the two examples. The neighbourhood construction proceeds in E \ E ( e s considering the last point of class change as the current starting point and the process is repeated until the entire set of training examples is partitioned in neighbourhoods. This process is illustrated in Figure 2 on a two-dimensional continuous instance space. 3.2 R EFER -R: Coverage-Based Feature Reduction Let E l and E m be a pair of neighbourhoods in E of differ-ent classes ( c l c m ). The goal is to detect which features f
F describing examples in E l E m are redundant for discriminating between the classes c l and c m . The defini-tion of redundancy we use, following (Lavra et al., 1999), is based on coverage among features.
 Formally, a feature f F covers a feature g F with re-( T ( g )) is the set of all examples e i E l such that f ( g ) has the value true for e i and F ( f ) ( F ( g )) is the set of all exam-ple e j E m such that f ( g ) has the value false for e intuition is that a feature f is better than another feature g same c l examples as g , and false for at least the same c examples as g . The implicit assumption is that class c the positive class we are trying to describe.
 This suggests the notion of useless features , those for which T ( f ) = or F ( g ) = . Such features can be imme-diately removed from the set of features F regardless of the properties of other features. Furthermore, a feature g
F is defined to be redundant if there exists another feature f F ( f g ) such that f covers g . Therefore, redundant features can be eliminated in a preprocessing step without compromising the existence of a complete and consistent theory according to the theorem found in (Lavra et al., 1999), the basis of the algorithm R EDUCE R
EFER applies R EFER -R (see Figure 3), a revised version of the algorithm R EDUCE , to find a set of non-redundant features RF l,m between the neighbourhoods E l and E particular, R EFER -R takes into account the set of features R that have been already identified as non-redundant in previous neighbourhood-pair comparisons. This allows us to find a smaller set of non-redundant features by prefer-ring features among those that have been already selected, instead of introducing new ones. R EFER -R first identifies the non-redundant features between E l and E m , consider-ing only the features in F not yet selected as non-redundant in previous neighbourhood-pair comparisons. Afterwards, it prunes the resulting set considering R . 3.3 Finding Non-Redundant Features A neighbourhood decomposition E 1 , ..., E w of the example set E can be represented by a graph of neighbourhoods G = ( N, A ), where N is the set of nodes n i representing each neighbourhood E i and A is the set of arcs connecting nodes in N . Each node n i N is connected only to every other node n j N that corresponds to a neighbourhood of a different class (see Figure 4a). Consequently, for each arc between a pair of nodes ( n i , n j ) in N tagged with a dif-ferent class label, R EFER detects the set of all non-redundant features discriminating between examples in n i and n j , and vice-versa, according to the R EFER -R algo-rithm. We tag the arc with this set.
 Where the features represent only positive literals, such as in some propositionalised data, the implicit assumption is that any negation is eventually introduced in learning. Then, there is an effective comparison between f and g as well as not-f and not-g . If negated features are supplied explicitly, all possible combinations are evaluated. Example . Consider a pair of neighbourhoods, E 1 = { e e , e 3 } and E 2 = {e 4 , e 5 , e 6 , e 7 } as follows: By comparing E 1 against E 2 , R EFER -R discovers that only features f 5 and f 7 are non-redundant. In the opposite direc-tion, when R EFER -R compares E 2 against E 1 , it identifies the features f 1 , f 4 and f 6 as non-redundant. Therefore R
EFER -R discovers that features f 2 and f 3 are redundant in discriminating between E 1 and E 2 .
 In contrast, S CRAP builds a graph of neighbourhoods where each node is connected only to an adjacent node associated with a different class (see Figure 4b). Because of this, S CRAP does not guarantee that selected features are sufficient to discriminate among all classes. On the other hand, we can prove that given G = ( N , A ), the graph of neighbourhoods produced by R EFER -N from a training set E and F X  , the union of all non-redundant features de-tected by applying the R EFER -R algorithm to each pair of nodes in N with different class labels , we can learn a complete and consistent theory using only features in F X  . Theorem : Giv en L H , an hypothesis language rich enough to allow for a theory T , that is complete and consistent for a)
E each class, to be learned from a training set E , a set of features F and E 1 , ..., E w a neighbourhood decomposition of E . A complete and consistent theory T can be found using only features from the set F X  F if and only if for each possible pair of examples ( e i , e j ) ( E l , E m c , there exists at least one feature f X  F X  such that e T ( f X  ) and e j F ( f X  ).
 Proof . Necessity : Suppose that a pair of examples ( e i ( E l , E m ) with c l c m exists such that there is no feature f X  F for which e i T ( f X  ) and e j F ( f X  ). This implies that no rule involving features in F X  could discriminate be-tween e i and e j and a description which is complete and consistent with respect to the class c i cannot be found. Sufficiency : Let G = ( N , A ) be the graph corresponding to the neighbourhood decomposition of E . Consider an arbi-trary example e E . We can build a description of e from all those features F e appearing on all arcs of G connecting its containing node, since we have associated with these arcs the set of all features discriminating e against every other example of a different class, and vice-versa. This description is exactly the conjunction of all those features that are true for e with the negation of each of those fea-tures that are false for e . This description is then true for e and no other example. Now consider all those examples in the neighbourhood (and therefore of e  X  X  class). We build a description for those examples by constructing a disjunc-tion of the descriptions for each example. This description is true for each of these examples and no other example of a different class. Similarly, we can build a description of each class as a whole by taking a disjunction of such de-scriptions for each neighbourhood. We now have a com-plete and consistent hypothesis for each class. 3.4 Computational Complexity In this section we analyse the time complexity of the R
EFER algorithm. We consider the average case to be such that the example set E is decomposed into w equal disjoint subsets E 1 ... E w , assuming E is distributed appropri-ately with respect to class. First we consider the average-case computational complexity of R EFER -N for n training examples and m features. Consider the construction of the first neighbourhood E 1 with a random starting point e This requires the calculation of the Hamming distance (complexity O( m ) per example) between e s and each other example in E . This has a time complexity O( m ( n X  1)). R
EFER -N determines the changing class point e c , and, without further calculation, extracts the first neighbour-hood E 1 . The example set for the next iteration is there-new example set. Therefore, the entire R EFER -N process requires an average time complexity O( nmw ).
 R
EFER -R is an extension of the algorithm R EDUCE , but comparing each neighbourhood pair tagged with different class labels. For each comparison, R EFER -R has a average time complexity of O( m 2 n/w ). Therefore, R EFER has an average combined time complexity of O( nmw + m 2 hn/w ) with h w 2  X  w . R
EFER was implemented in Java and empirically evalu-ated in three different experimental settings. 4.1 Mutagenesis ILP dataset This dataset concerns the problem of identifying mutagenic compounds (Muggleton et al., 1989) and has been extensively used as an ILP benchmark. We consid-ered, following related experiments in the literature, the regression-friendly dataset of 188 molecules. The dataset consists of three relations, describing molecules, atoms and bonds, and the goal is to identify the mutagenic mole-cules. We preprocessed and propositionalised the dataset using S INUS (Krogel et al., 2003). We obtained four dif-ferent datasets varying the background knowledge (Srini-vasan et al., 1999) and S INUS parameters. The settings of the experiments are reported in Table 1.
 The results obtained by ten-fold cross-validation are re-ported in Table 2. We furthermore compared R EFER with R
EDUCE in order to show the advantages in the use of the neighbourhoods. Figure 5 presents a graphical compari-son between the systems in terms of the number of fea-tures that are considered non-redundant with respect to the original set of features. In addition, Table 3 reports the average predictive accuracy on the test set (not used by R
EFER or R EDUCE ) obtained running different learning systems, specifically, C4.5 (Quinlan, 1993), Na X ve Bayes, k -nearest neighbours, the R IPPER rule learner (Cohen, 1995) and a support vector machine (Keerthi et al. 2001). Results show that in general R EFER selects half the num-ber of features selected by R EDUCE without accuracy de-creasing. Not all the accuracy results are directly compa-rable with results reported in the literature. However, M2 is equivalent to the BK2 setting (see Table 4). Despite the significant reduction in the number of features, the accu-racy remains competitive with the performance of estab-lished multi-relational data mining algorithms for this domain.
 4.2 UCI Datasets In the second experimental setting, 13 UCI datasets have been considered. In particular, we selected the following datasets containing only discrete attributes: Audiology, Bridge, Car, Flare-1066 (class C), Flare-1066 (class M), Flare-323 (class C), Flare-323 (class M), Mushroom, Nursery, Post-operative and Tic-tac-toe. In addition, we considered PimaF and YeastF, with continuous attributes discretised using equal width bins. Each dataset was transformed into a binary representation and evaluated by means of a ten-fold cross-validation. All experiments were performed using the same folds. We chose three feature selection methods for comparison with R EFER namely R ELIEF F, the variant of R ELIEF for multi-class problems, CFS and LVF. CFS uses a correlation-based heuristic to evaluate features. This heuristic takes into account the utility of individual features for predicting the class along with the level of intercorrelation among them (Hall, 2000). LVF makes probabilistic choices to guide the search for the best subset of filtered features (Liu &amp; Setiono, 1996). For R ELIEF F, the parameter K is set to 5 (neighbours) and M is set to 30 (instances).
 Figure 6 shows the number of selected features against the original number of features (before feature selection). It demonstrates that in general R EFER is a conservative approach but is more selective than R ELIEF F. On the other hand, R EFER is considerably faster than any other feature selection method used in our comparison (see Table 5). In addition, we applied the same five learners used in the Mutagenesis experiment. We compared the percentage of correct classifications averaged over the ten folds in the cross-validation for each algorithm-dataset combination before and after feature selection or reduction. In Table 6 we report the accuracy results. We notice that the accu-racy obtained with R EFER  X  X  reduced feature sets is com-petitive with the feature selection approaches. Sec ondly, the accuracy of the algorithms on the feature sets pro-duced by R EFER is consistently close to that of the origi-nal feature set. These experiments have been condu cted using the Weka environment (Witten &amp; Frank, 2000). Finally, Figure 7 shows the number of both reduced fea-tures and neighbourhoods constructed by R EFER using varying starting points. We may observe that the number of reduced features as well as the number of neighbour-hoods is not greatly affected by a different starting point. 4.3 Reuters-21578 To evaluate the performance of R EFER on large-scale datasets, we executed it on the Reuters-21578 dataset (Lewis, 1997) consisting of a set of 21,578 articles pub-lished by Reuters. This is a well-known benchmark dataset in the field of Information Retrieval and Docu-ment Categorisation. We evaluated it using the Mod-Apte split (Yang and Liu, 1999), where the dataset is cleaned and split into a training set (7769 articles) and a test set (3019 articles). The resulting data contains articles each belonging to one or more of 90 classes. In our representa-tion, each feature represents a word in the article and each article has been represented in the form of a Boolean vector, recording for each word whether it occurs in the document. In order to adapt it to the single-label problem, we removed the articles with multiple classifications, as in (Schapire &amp; Singer, 2000). We thus obtained a training set of 6577 articles and a test set of 2583 articles. After preprocessing, the total number of features was 16,582. Although the dataset could be represented in a sparse ma-trix representation, we did not use this representation in order to prove the applicability of our method even to large-scale datasets where the dataset is not sparse. For this domain, the Boolean vector representation leads to a dataset of high dimensionality, giving a file size of hundreds of megabytes. One of the advantages of R is that it is possible to split a dataset into several smaller ones consisting of subsets of the features of the original set, run R EFER on the subsets (possibly in parallel on dif-ferent machines), combine them, and run R EFER on the combination, without compromising the discovery of a complete and consistent theory, described in Section 3. In this way, we identified more than 90% of 16,582 features as redundant, resulting in a set of 1450 reduced features. In this paper we presented R EFER , an efficient method for eliminating redundant Boolean features for multi-class classification tasks. The method is logically sound, in that it guarantees the existence of a complete and consistent theory using only the reduced feature set if it exists with the complete feature set. It also is efficient, requiring on average less time than the three feature selection methods we compared it with. We have demonstrated that the use of neighbourhoods increases the number of identified redundant features with more than a factor of two, in comparison with R EFER  X  X  predecessor R EDUCE . We have also shown that it is feasible to execute the method on a large and high-dimensional dataset, and that the method is amenable to parallel execution. R EFER  X  X  computational efficiency derives from its heuristic nature and sets it apart from exhaustive methods such as F OCUS , which do not scale up well to large sets of features.
 Feature reduction, i.e., eliminating redundant features, and feature selection, i.e., identifying relevant features, are in some sense complementary approaches. In future work, we plan to study the interaction between these two approaches to obtain even smaller feature sets. We also plan to incorporate noise-handling mechanisms by al-lowing non-pure neighbourhoods.
 Almuallim, H., &amp; Dietterich, T.G. (1991). Learning with many irrelevant features. Proc. 9th Nat. Conf. on Artifi-cial Intelligence (pp. 547-552). MIT Press.
 Blum, A., &amp; Langley, P. (1997). Selection of relevant features and examples in machine learning. Artificial Intelligence , 97 , 245-271.
 Ceci, M., Appice, A., &amp; Malerba, D. (2003). Mr-SBC: a Multi-Relational Naive Bayes Classifier . Proc. 7th Eur.
Conf. on Principles and Practice of Knowledge Discov-ery in Databases (pp. 95-106). Springer-Verlag.
 Cohen, W.W. (1995). Fast Ef fective Rule Induction.
Proc. 12th Int. Conf. on Machine Learning (pp. 115-123). Morgan Kaufmann.
 Dash, M., &amp; Liu, H. (1997). Feature selection for classifi-cation. Intelligent Data Analysis , 1 , 131-156.
 Dzeroski, S., &amp; Lavra , N., Eds. (2001). Relational Data Mining . Springer-Verlag.
 Freund, Y. &amp; Schapire, R. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. J. Computer and System Sciences , 55(1) , 119-139.
 Hall, M. (2000). Correlation-based feature selection for discrete and numeric class machine learning. Proc. 17th Int. Conf. on Machine Learning (pp. 359-366). Morgan Kaufmann.
 Keerthi, S.S., Shevade, S.K., Bhattacharyya, C., &amp;
Murthy, K.R.K. Improvements to Platt X  X  SMO Algo-rithm for SVM Classifier Design. Neural Computation , 13(3) , 637-649.
 Kira, K., &amp; Rendell, L.A. (1992). A practical approach to feature selection. Proc. 9th Int. Conf. on Machine Learning (pp. 249-256). Morgan Kaufmann.
 Kohavi, R., John, G., &amp; Pfleger, K. (1994). Irrelevant features and the subset selection problem. Proc. 11th Int. Conf. on Machine Learning (pp. 121 X 129). Morgan Kaufmann.
 Kononenko, I. (1994). Estimating attributes: Analysis and extensions of RELIEF. Proc. Eur. Conf. on Machine Learning (pp. 171-182). Springer-Verlag.
 Krogel, M., Rawles, S., Zelezny, F., Flach, P., Lavra , N., &amp; Wrobel S. (2003). Comparative evaluation of ap-proaches to propositionalization. Proc. 13th Int. Conf. on Inductive Logic Programming (pp. 197-214). Springer-Verlag.
 Langley, P. (1996). Elements of Machine Learning . Morgan Kaufmann.
 Lavra , N., Gamberger, D., &amp; Jovanoski V. (1999). A study of relevance for learning in deductive databases. J. Logic Programming , 16 , 215-249.
 Lewis, D.D. (1999). Reuters-21578 text categorization test collection distribution 1.0. Available at http://www.research.att.com/lewis.
 Liu, H., &amp; Setiono, R. (1996). A probabilistic approach to feature selection: A filter solution. Proc. 13th Int. Conf. on Machine Learning (pp. 319-327). Morgan Kauf-mann.
 Modrzejewski, M. (1993). Feature selection using rough sets theory. Proc. Eur. Conf. on Machine Learning (pp. 213-226). Springer-Verlag.
 Muggleton, S. H., Bain, M., Hayes-Michie J., &amp; Michie,
D. (1989). An experimental comparison of human and machine learning formalisms. Proc.. 6th Int. Workshop on Machine Learning . Morgan Kaufmann.
 Pagallo, G., &amp; Haussler, D. (1990). Boolean feature dis-covery in empirical learning. Machine learning , 5(1), 71-100.
 Quinlan, J. (1993). C4.5: Programs for machine learning . Morgan Kaufmann.
 Raman, B. (2003). Enhancing inductive learning with feature selection and example selection. Master thesis, Texas A &amp; M University.
 Rendell, A., &amp; Sheshu, R. (1990). Learning hard concepts through constructive induction: Framework and ration-ale. Computational Intelligence , 6 , 247-270.
 Schapire, R., &amp; Singer, Y. (2000). A boosting-based system for text categorization. Machine Learning , 39(2/3) , 135-168.
 Srinivasan, A., King, R.D., &amp; Muggleton, S. (1999). The role of background knowledge: using a problem from chemistry to examine the performance of an ILP pro-gram . Technical Report PRG-TR-08-99, Oxford Uni-versity Computing Laboratory.
 Yang, Y., &amp; Liu, X. (1999). A re-examination of text categorization methods. Proc. 20th ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval (pp. 42-49). ACM Press.
 Witten, I. &amp; Frank, E. (2000). Data mining: practical machine learning tools and techniques with Java
