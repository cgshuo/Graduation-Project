 The role of big data in addressing the needs of the present healthcare system in US and rest of the world has been echoed by government, private, and academic sectors. There has been a growing emphasis to explore the promise of big data analytics in tapping the potential of the massive health-care data emanating from private and government health insurance providers. While the domain implications of such collaboration are well known, this type of data has been explored to a limited extent in the data mining community. The objective of this paper is two fold: first , we introduce the emerging domain of  X  X ig X  healthcare claims data to the KDD community, and second , we describe the success and chal-lenges that we encountered in analyzing this data using state of art analytics for massive data. Specifically, we translate the problem of analyzing healthcare data into some of the most well-known analysis problems in the data mining com-munity, social network analysis , text mining , and temporal analysis and higher order feature construction , and describe how advances within each of these areas can be leveraged to understand the domain of healthcare. Each case study illustrates a unique intersection of data mining and health-care with a common objective of improving the cost-care ratio by mining for opportunities to improve healthcare op-erations and reducing what seems to fall under fraud, waste, and abuse.
 H.2.8 [ Database Management ]: Database Applications X  Data Mining Healthcare Analytics; Fraud Detection
Healthcare spending in United States is one of the key issues targeted by policy makers, owing to the fact that it is a major contributor to the high national debt levels that are projected for next two decades. In 2008, the total healthcare spending in US was 15.2% of its GDP (highest in the world) and is expected to reach as much as 19.5% by 2017 [2]. But while the healthcare costs have risen (by as much as 131% in the past decade), the quality of healthcare in the US has not seen comparable improvements (See Figure 1) [24]. Figure 1: Life expectancy compared to healthcare spending from 1970 to 2008, in the US and the next 19 most wealthy countries by total GDP [14].

Experts agree that inefficiencies in the current healthcare system, resulting in unprecedented amounts of waste, is the primary driver for the discrepancy between the spending and the returns in the healthcare domain [11]. Recent studies estimate that close to 30% (  X  $765 billion in 2009) of total healthcare spending in United States is wasted, which in turn is caused by many factors such as unnecessary services, fraud, excessive administrative costs, and inefficiencies in the healthcare delivery.

In recent years, several experts as well as the federal gov-ernment 1 have stressed on the role of big data analytics in addressing the issues with healthcare. The 2011 report by Mckinsey Global Institute [19] estimate that the potential value that can be extracted from data in the healthcare sec-tor in US could be more than $300 billion per year. The same report lists out several areas within the healthcare sec-tor which can benefit from using big data analytics. These include segmentation of patients based on their health pro-files to identify target groups for proactive care or lifestyle http://www.whitehouse.gov/sites/default/files/ microsites/ostp/big_data_press_release_final_2.pdf changes, development of fraud resistant payment models, creating information transparency and accessibility around healthcare data, and conducting comparative effectiveness research across providers, patients, and geographies.
Healthcare insurance claims have the potential of answer-ing many of the questions currently faced by the healthcare sector, In fact, until shareable electronic health records be-come a reality, healthcare claims, especially from organiza-tions with a large spatial and demographic coverage such, which is the case with many of the government run health insurance programs in the country, are the most reliable re-source for understanding the current healthcare landscape, from conditions, care, and cost perspective. But the trans-actional format of claims data is not amenable for advance analytics that the state of art KDD methodologies have to offer. In this paper we explore transformations of the health-care claims data which bridge this gap between the health-care domain and modern data analytics.

We present a study of big data analytics on health in-surance data collected by a large national social health in-surance program. While previous efforts have used data mining methods for analyzing healthcare claims data within small organizations, we believe that this is one of the first in-stances where advanced data analytics and healthcare have interacted at a national scale. In all, we approximately ana-lyzed 2 billion insurance claims for approximately 45 million beneficiaries and over 3 million healthcare providers.
In this paper, we make the following contributions: 1. We introduce the emerging domain of health care claims 2. We propose three transformations of the transactional 3. We present several approaches to identify and under-4. We highlight the unique nature of healthcare data when
The role of big data in healthcare has been well acknowl-edged across government and industrial sectors 23 . But only a few published studies have analyzed such data [12]. The primary reason is the data availability, given that the health-care claims data has strong proprietary and privacy require-ments 4 . Moreover, existing studies have considered claims data from a payment system perspective and have analyzed www.eweek.com/database/emc-says-big-data-is-essential-to-improving-health-outcomes/ www.intel.com/content/dam/www/public/us/en/ documents/white-papers/healthcare-leveraging-big-data-paper.pdf http://www.hhs.gov/ocr/privacy/ the data for payment errors [12]. Limited efforts exist that have analyzed the healthcare claims data to understand the inefficiencies in the healthcare system [6], but from the ana-lytics perspective they are limited to simple summary statis-tics such as population means for various demographics. In this paper we explore the application of three advanced KDD technologies, viz. , text mining [18], social network analysis [29], and time series analysis [20], all of which have been suc-cessful in a variety of applications but have not been applied at a large scale to healthcare claims data.

Domains such as credit card and property insurance have long studied the issue of fraud identification [4, 10]. But healthcare fraud detection has unique characteristics given that the actual beneficiary is typically not the fraud perpe-trator, which is not the case for other domains. So existing fraud detection methods cannot be directly applied to the healthcare domain. Most of the existing fraud detection so-lutions in the healthcare domain are not public, primarily because of the fact that the data is highly sensitive and is usually not made available for research and publishing.
Healthcare data can be broadly categorized into four groups (See Figure 2): Clinical data (patient health records, med-ical images, lab and surgery reports, etc.) and patient be-havior data (collected through monitors and wearable de-vices) provide an accurate and detailed view of the health of the population. But such data, which is increasingly being stored electronically, can be leveraged in a big data setting only when the owners (doctors, hospitals, and individuals) share, which, owing to privacy concerns is still limited to being analyzed within an organization such as a hospital or a network of hospitals. Pharmaceutical research data (clinical trial reports, high throughput screening results) of-ten face privacy concerns owing to business practices. In this paper, we focus on health insurance data , which has been collected and stored for several years by various health insurance agencies. While the primary justification for this data is to track payments and address fraud, such data also has great potential to address some of the other aforemen-tioned issues of the healthcare system. For United States, such data is extremely valuable, given that around 85% of Americans use some form of insurance (private or govern-ment). Moreover, insurance data is the only source of the cost associated with healthcare which is vital to address the economic challenges associated with modern healthcare sys-tem. The strong challenge presented by insurance data on the other hand is that it is not readily in the form to infer strong analytic insights into healthcare, besides the payment model. A key contribution of this paper is the transforma-tion of the insurance data into formats that allow application of existing analytic tools for knowledge discovery.
The typical health insurance payment model is a Fee-for-service (FFS) model in which the providers (doctors, hos-pitals, etc.) render services to the patients and are paid for each service by the payor or the insurance agency. The providers record the details of each service, including the cost and justification and submit the record to the payor. The payor decides to either pay or reject the claim based on the patient X  X  eligibility for the particular service which are determined by the policy guidelines.

The insurance agency typically maintains three types of data for their operations: 1. Claim information captures the information about the 2. Patient enrollment and eligibility data that captures 3. Provider enrollment data that captures the informa-
In the US, approximately 85% of the population has some of form of health insurance. Majority of these individuals (  X  60%) obtain insurance through their employer or employer of parent or spouse. Almost 28% of population (83 million individuals) is covered under government health insurance programs. These include programs such as Medicare , Medi-caid , Veterans Health Services , etc.

The data managed by each of these programs is at a mas-sive scale. Medicare alone provides health insurance to 48 million Americans and covers for hospitalization, out pa-tient, medical equipments, and drugs. There are a few mil-lion providers enrolled with the Medicare Provider Enroll-ment, Chain, and Ownership System (PECOS). In 2011, Medicare received close to 1.2 billion claims (4.8 million claims per day) for their fee for service programs. An almost equivalent number of claims were received in the prescrip-tion drugs program (also known as Part D ). Under Medi-caid, more than 60 million individuals received benefits in 2009 (one in every five). In the state of Texas alone, there are more than 0.5 million providers within Medicaid.
As mentioned in Section 1, fraud , waste , and abuse form a significant amount of healthcare spending. Fraud ranges from single providers billing the system for services that were not provided to large scale fraud carried out by organized criminals [27]. One form of waste happens due to improper payments , since organizations are mandated to process pay-ments in a short duration of time, resulting in authorization Providers Beneficiaries
Speciality Figure 3: Entities and relationships in healthcare claims data along with approximate number of en-tries in each entity set. of double payments for duplicate claims, payments using an outdated fee schedule, etc. A major cause for abuse is due to the fact that programs such as Medicare follow a prospective payment system for hospital care, which means that providers are paid for services at predetermined rates. Thus if the actual service costs more than the allowed cost, the provider has to cover its losses. If the actual service costs less than the allowed cost, the provider keeps the re-mainder. This drives the providers to charge unnecessary or more expensive services (also known as upcoding ) by making more severe diagnosis to safeguard against any losses and to make profit. Some of the examples listed above, e.g., double payment for duplicate claims, can be identified by applying business rules to the data. For others, such as upcoding or miscoding providers, there is need for advanced algorithms that can analyze the vast amounts of claims data.

In the subsequent sections we describe three case stud-ies that were conducted onhealthcare claims and associated data. The common thread among the studies is the analysis of the behavior and interaction between healthcare providers, which is highly important given that they are the primary drivers for the wasteful spending in the system.
The data used for the subsequent case studies captures three different aspects of healthcare. First is the claims data for close to 48 million beneficiaries for the entire US. Second is the provider enrollment data which can be obtained from several private organizations. The third is a list of fraudulent providers that have been sanctioned for fraudulent behavior in the state of Texas. The list of fraud-ulent providers was obtained from the Office of Inspector General X  X  exclusion database 5 . Note that in this paper we will treat the rest of the providers as non-fraudulent for eval-uation, even though it is evident that there are a significant number of fraudulent actors who have not been identified.
The claims and the provider enrollment data comes from transactional data warehouses. Each claim, consists of sev-eral data elements with information about the beneficiary, provider, the health condition (or diagnosis), the service pro-vided (procedure or drug), and the associated costs. Figure 3 shows the different entities and their relationships that are present in the healthcare claims data. Note that the providers typically are affiliated to each other through orga-https://oig.hhs.gov/exclusions/exclusions_list. asp nizations such as hospitals. This information and additional data about the providers is present in the provider data.
Simply stated, the two ultimate goals necessary to ad-dress rising healthcare costs are: 1). a healthy population, and 2). optimal healthcare in terms of cost and quality. To reach these goals, the first vital step is to understand the current landscape in terms of prevalent diseases and the re-sulting treatments and costs. Identifying the key disease profiles for patients will allow segmentation of the popula-tion into groups which can then be targeted for proactive care or lifestyle changes. For providers, typical treatment profiles used by doctors and hospitals will be instrumen-tal in identifying the costly areas which need to addressed through policy changes or medicinal research. Moreover, such profiles can also be used to compare providers across the country and potentially across organizations to identify fraudulent (upcoding) or wasteful providers.

In the first case study, we show how such profiles can be generated from the claims data (See Figure 3) using ad-vanced text analytic solutions [18]. Text data, especially from the web domain, has been the foremost target of the big data paradigm and a host of open-source solutions (Apache Hadoop based Mahout library [8], MADlib for parallel databases [9]) exist for deploying text mining algorithms on massive text data sets. The interaction between text mining and healthcare, for obvious reasons, has been in analyzing the text available within the patient health records (clinical data) [25]. But these solutions have never been applied in the con-text of healthcare claims data.
To capture the behavior profiles of the providers and ben-eficiaries we construct several sparse matrices from a tem-poral aggregate of claims data, as follows:
Let the set of providers be denoted as P , set of benefi-ciaries be denoted as B , set of procedures as C , set of di-agnoses as G , and set of drugs as D . Let the symbol XY denote a matrix with X  X  { B, P } representing rows and Y  X  X  G, C, D } representing columns. For example, the ma-trix PG (providers vs. diagnoses) captures the nature of diagnoses that a doctor assigns to patients. Each cell P C in the matrix PC denotes the number of times the provider P  X  P uses the procedure C i  X  C in the given time frame.
Each of matrices thus created can be viewed as a document-term matrix with providers/beneficiaries as documents and drugs/procedures/diagnoses as terms . Such representation opens up the claims data to a wide spectrum of existing text analysis methods [18]. Given that multiple document-term matrices can be generated for the same entity (providers), it also allows application of methods that deal with learning from multiple views [16].
In this study we used topic modeling using Latent Dirich-let Allocation (LDA) [5] as our text analysis tool. LDA is a probabilistic topic model which is widely used for determin-ing hidden topics in a set of documents. In the LDA model, each document (provider) is represented as a mixture of a fixed number of hidden topics and each topic is a probability distribution over a vocabulary of words (diagnosis codes). Figure 4: Relative proportion of fraudulent and non-fraudulent providers assigned to each topic of diag-nosis codes.

We applied the Mahout implementation of collapsed vari-ational Bayesian inference (cvb) algorithm [28] for LDA on the provider-diagnoses ( PG ) matrix constructed from a year of claims data (361,117 providers, 9,378 diagnosis codes, 43,331,004 tuples). The matrix was normalized using tfidf normalization. Using LDA we identified 20 hidden topics from the PG matrix.

From healthcare perspective, each topic can be thought of as a category for providers. While one would expect that topic driven categorization should closely match the actual specializations of the providers, we found out that this was not always the case. While some topics were dominated by diagnoses that belonged to same area of medicine (e.g. , on-cology, ophthalmology), there were other topics which were made up of diagnosis codes that are seemingly different from each other. For example, one topic consisted of diagnosis codes associated with Diabetes as well as dermatoses (skin condition). While this might appear surprising, further re-search revealed a medicinal connection between the two [17].
Another possible application of the topic modeling is to use the topic distributions as features or profiles for the providers. To validate the discriminatory potential of topic distributions we conducted the following analysis. For each provider, we chose the topic with highest probability as-signed by LDA. We then compared the proportion of fraudu-lent and the non-fraudulent providers (using the list of fraud-ulent providers as described in Section 5) that fall under each topic. The relative proportions are shown in Figure 4.
The non-fraudulent providers are evenly distributed across most topics, except for the topic 19. This particular topic is composed of  X  X eneric X  diagnoses such as follow-up surgery and benign tumor and hence is expected to represent a large number of providers. For the fraudulent providers, the dis-tribution follows the non-fraudulent providers, except for topic 5, which represents close to 25% of all fraudulent providers as opposed to only 7% of non-fraudulent providers. Topic 5 is dominated by very distinct diagnosis codes.

From the domain perspective, this discovery is valuable since it identifies the diagnosis codes that are used by same providers and have historically been targets of fraud. Given the fact that the codes in topic 5 are medicinally distinct from each other, such discovery can only be made by meth-ods that allow all diagnosis codes to be related to each other, i.e. , topic models.

The promising findings in Figure 4 show that analyzing claims data using text mining methods can reveal very in-teresting interactions and patterns. Similar analysis can be conducted for other matrices for additional insights.
As health insurance companies shift focus from fraud de-tection to fraud prevention, building a predictive model to estimate the risk of a provider before making any claims has been a challenging problem. Furthermore, sub-stantial amount of healthcare fraud is expected to be hidden in the relationships among providers and between providers and beneficiaries making insurance claims. In this case study, we present results of applying social network analysis meth-ods [21] to understand the relationships of providers in the healthcare system and visualizing features and patterns of fraudulent behaviors in such a network. We describe the construction of social-network features and the predictive model built on those features as a solution to assessing health-care fraud risk at the time of enrollment.
Providers in the US healthcare system are typically asso-ciated with multiple hospitals and health organizations. The information about the providers can be obtained from mul-tiple sources. Some of such data sources are public 6 while others may be purchased 7 . We use data from such sources to construct a social network in which providers (both in-dividual and organizations) are the nodes. The edges are between individual and organization nodes (See Figure 5). A graph when constructed for all providers in the United States is expected to have nearly 35 million nodes and more than 100 million edges. In this study we construct a graph for providers in the state of Texas with almost 1 million nodes and close to 3 million edges.
A snapshot of the provider network for the state of Texas is shown in Figure 6. This provider network is different from a typical  X  X ocial network X  in the following ways: (i) the networks consist of both organizations and individuals. This introduces a latent hierarchy in the network because several individual physicians work for organizations and can also own group practices, (ii) the network is a collection of https://nppes.cms.hhs.gov/NPPES/ http://www.healthmarketscience.com/ Figure 6: Snapshot of the provider network for Texas. The width of circle at each node denotes the number of affiliations. The large circles indicate organizations, such as hospitals. Nodes in red are fraudulent providers. disconnected graphs, the largest network being a network of a few 100,000 providers and the smallest as little as 3, and, (iii) the network is constructed based on self-reported data and inferred data based on subject matter expertise and may be subject to omissions, errors and quality issues.
For this particular study, we focus on analyzing the net-work properties with respect to the fraudulent providers de-scribed in Section 5. The objective is to extract multiple fea-tures for every node in the network and use them for discrim-inating between fraudulent and non-fraudulent providers. We investigated several network based features [21, 23] as listed in Table 1.
 Table 1: Network features studied for the provider network [21].
For each feature we estimated its capability to distinguish between fraudulent and non-fraudulent nodes using the In-formation Complexity (ICOMP) measure [15] which com-pares the distribution of the features for the fraudulent and non-fraudulent populations. The five network based features that we found to be most distinguishing were: Node de-gree , Number of fraudulent providers in 2-hop net-work , Page rank , Eigenvector centrality , and Current-flow closeness centrality . Figure 7 shows the distribu-tion of each feature with respect to the fraudulent and non-fraudulent populations.

For instance, the red line in 7(a) indicates the node degree distribution for providers previously identified as fraudulent. The blue lines are for a random sample of non-fraudulent providers. We observe that increase in degree of provider correlates to a higher risk of fraud. Similar conclusions can be drawn from analyzing the 2-hop network (See Fig-ure 7(b)). In fact, the chance of finding other fraudulent providers within the 2-hop network of a fraudulent provider is  X  40% compared to the chance of finding a fraudulent provider within the 2-hop network of a random provider (  X  2%).

Given the ability of the above features to distinguish be-tween fraudulent and non-fraudulent providers, we plan to utilize them within either an unsupervised multivariate anomaly detection algorithm [7] for automatic detection of such providers or in a binary classification algorithm that learns from the available labeled data.
In the context of identifying healthcare fraud perpetrated by providers, two generic response mechanisms are possible: 1). identify and prosecute providers after claims are submit-ted ( pay and chase ), and 2). timely denial of payment for a submitted claim based on the associated risk. Whereas legal prosecution is expensive, time-consuming and difficult to wage, a policy of selective denial of payment based on statistical risk factors is much easier to implement once the risk estimation algorithms have been developed.

In this case study we use temporal analytics to address the following two questions: i). How can we identify the transi-tion of a good provider into a bad actor in an online fashion using the temporal sequence of claims?, and ii). how can the temporal sequence be used to discriminate fraudulent providers from others?
We pose the first question as a change-point detection problem and employ a statistical process control methodol-ogy to identify the transition. The strength of this method is that it can be implemented online to examine each claim as it enters a processing queue for payment. For the second question we compare the temporal claim submittal patterns of every provider to estimated population norms for similar providers (e.g., by speciality and geographic location) and define features from these comparisons. Classifiers can sub-sequently be trained to learn the differences between known fraudsters and presumed normal providers.
The statistical process control (SPC) literature [20] has evolved into a fairly mature technology for implementation of a temporal approach to processing data sequences.
A number of methods have been proposed in SPC the-ory to monitor processes for exceedance of control limits. One popular metric is the cumulative sum (CUSUM) statis-tic [22]. Here we illustrate an application of CUSUM to iden-tify changes in the patient enrollment. A useful assumption in this approach is that a fraudulent providers often start  X  X aking X  more patients than usual [27].

Suppose we have a time-ordered sequence of claims X = x , x 2 , . . . , x n . This sequence could represent all insurance claims submitted by a single provider over a fixed time in-terval (e.g., one year). One of the simplest SPC statistics is the Bernoulli CUSUM [26], where X is simply a vector of zeros and ones. For example, we can define x i according to the following: x = 1 if the i This vector tracks the introduction of new beneficiaries in the stream of claims submitted by a specific claimant, and provides a basis for estimating whether a large number of new beneficiaries were seen by a provider during a particular time interval. The Bernoulli CUSUM statistics to analyze this vector are: where S 0 = 0 and the chart signals if S 0 &gt; h . The values of the log-likelihood scores are A more common form of fraud occurs when providers start taking patients with conditions different from their past pro-file. Given that the condition codes can have multiple cate-gories, the above method needs to be generalized to a multi-nomial case. The multinomial CUSUM statistic [13] can be applied here as follows: Where p i 1 is the i th alternative hypothesis, and p i 0 null hypothesis. A typical multinomial/categorical CUSUM for a  X  X resumed normal X  is shown in Figure 8(a). The CUSUM statistic spikes when the provider uses different condition codes than the typical, but falls back to 0 since the atypical behavior is sporadic. On the other hand, Figure 8(b) shows the CUSUM statistic for an unusual (potentially fraudulent) physician who uses many condition codes that are not typ-ical for his speciality; the CUSUM statistic captures this unusual behavior.

A complete set of out-of-control probabilities are selected for the multinomial CUSUM. In the absence of a specific alternative hypothesis, a simple method of formulating the out-of-control probabilities is to assume that every proba-bility reverses direction to become less extreme, i.e., prob-abilities migrate in the direction of the grand mean. We specify a proportional change constant to compute the ex-act probabilities. The alternative hypothesis p 0 is then p 1 = p 0 + c  X  ( m  X  p 0 ) where c is the proportional constant and the mean m is simply the reciprocal of the number of categories.
One promising metric for screening anomalies is the max-imum value of a CUSUM statistic over a fixed time interval. However, this statistic is biased by the number of claims submitted by a provider during that interval. Some out-lier providers exhibit continuously anomalous behavior, even (b) Potentially Fraudulent Provider over a large time interval, and their CUSUM statistics of-ten resemble a linear function. This pattern suggests an-other metric that is not similarly biased by the length of the claims sequence -the average CUSUM rate. Figure 9 shows a scatterplot using these metrics for a typical provider pop-ulation color-coded by speciality. The scatterplot displays a cornucopia-shaped pattern with the tail originating at the lowest CUSUM values, and the mouth arcing upward to-ward the highest CUSUM rates. Anomalies are separated from the main cluster near the top of the scatterplot. Fur-ther analysis is required to determine whether these anoma-lies are normal in a statistical sense, or whether they are more likely members of an anomalous cluster. A horizontal line boundary is drawn at a CUSUM rate of about 0.35 to suggest a possible division of outliers from normals.
The previous section explored the possibility that a provider presumed to be normal up to some position within a tempo-ral claims sequence is diverted either temporarily or perma-nently to anomalous behavior. Additionally we expect that some providers are either fraudsters from the moment they Figure 9: Distribution of CUSUM metrics for a provider population. enroll in an insurance program, or that they revert to fraudu-lent activity permanently at some time before the beginning of a limited claims sequence. In this case the availability of provider ground truth affords the analyst an opportunity to go beyond anomaly detection as a method of identifying potential bad actors. In particular, if every provider can be labeled as either  X  X ad actor X  or  X  X resumed normal X , we can discriminate between temporally stable characteristics of normal and bad actors. Here we assume that providers naturally cluster into a main normal group and a main bad actor group. This assumption may only be approximately correct, especially for the class of bad actors if multiple paths exist to fraudulent behaviors.

In this section we extract 10 temporal features for each provider based on their submitted claims. Given the fact that some of these features might  X  X elp X  real providers to adapt and avoid future identification, we are not disclosing the actual features in this paper . In general, we consider a set of temporally stable features are defined over observed fields in a claims sequence. Features may ei-ther be direct functions of elements of the claims sequence or goodness-of-fit statistics that compare empirical distribu-tions to normative distributions. While some features are conditioned on the provider speciality (denoted as Spec fea-tures) other are independent ( NonSpec features).

To assess the value of such features, we train two weighted binary logistic regression classifiers [3] for the Spec and Non-Spec feature sets, respectively. We use a labeled training set with 8557 instances constructed using several million Medi-caid claims. Less than 1% of the labeled set contained 1% of known fraudulent providers using the fraud data discussed in Section 5. Since the bad actor group was comparatively small, and because we had greater confidence in their la-bels, the logistic regression was weighted toward the bad actor group by a 10:1 ratio.

We calculated the sensitivity and specificity of both classi-fiers along with the area under the curve (AUC). Figure 10 shows that including speciality in the model significantly improved performance (DeLong X  X  test; Z=7.22, p &lt; .0001) of the Spec model over the NoSpec model, yielding an AUC of 0.814.
 Figure 10: ROC curves for Spec and NoSpec classi-fiers using weighted logistic regression
Thus we show that supervised learning methods can be effective in discriminating between bad actors and those pre-sumed normal if the features are well-designed and norma-tive data is available. An immediate next step is to try semi-supervised methods on provider feature vectors so that providers that are not labeled  X  X raudulent X  can be treated as unlabeled.
This paper showcases the relevance of advanced big data analytics in the emerging domain of healthcare analytics us-ing claims data. Our main contribution is the translation of some of key challenges faced by the healthcare industry as knowledge discovery tasks. The three case studies presented in this paper attack the problem of identifying fraudulent healthcare providers in three independent ways, using state of art KDD methodologies, which have never been previ-ously used in this context. Our results on real fraud data highlight the promise that advanced data analytics hold in this important domain. The analysis for these case studies was conducted using the Hadoop/Hive data platform and used open source software such as Mahout, R, and Python networkx 8 and hence are repeatable in other contexts.
In each case study we identified the potential and chal-lenges associated with the existing analytic solutions. Treat-ing providers and beneficiaries as text documents opens the possibility of using the vast text mining literature and the highly sophisticated text mining tools that have been devel-oped specifically for big text data, and can lead to valuable discoveries as shown in Section 6. Studying affiliations be-tween providers as social networks is valuable, given that organized fraud is rampant in the healthcare system, and can be identified by analyzing the relationships between the providers using network science methods. However, we iden-tified certain differences between the provider network and a traditional  X  X ocial network X  which researchers should bear in mind before applying these methods. Temporal analysis methods are also useful because they do not require trained classifiers to identify anomalies, and are sensitive enough to be employed as timely online techniques for detection of transient billing practices that are anomalous. In future, we intend to combine the features generated from each of the case studies in a multi-view learning framework to better identify fraudulent providers.

An important conclusion from these analyses is that while insurance claims data are typically considered as payment records, they contain valuable information that can be used to answer many other healthcare related questions. For in-stance, studying topics of diagnosis or drug codes (see Sec-tion 6) can be done in the context of beneficiaries to under-stand the major behavior modes of the population in terms of health indicators. Networks that capture interaction be-tween beneficiaries and providers can be constructed from claims data and can be used in conjunction with the provider network to better understand the healthcare system.
Prepared by Oak Ridge National Laboratory, P.O. Box 2008, Oak Ridge, Tennessee 37831-6285, managed by UT-Battelle, LLC for the U. S. Department of Energy under contract no. DEAC05-00OR22725. http://networkx.github.com/ [1] National health expenditure projections 2009 X 2019. [2] World health statistics. WHO Library [3] A. Agresti. Categorical Data Analysis , chapter 5. [4] E. Aleskerov, B. Freisleben, and B. Rao. Cardwatch: [5] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [6] Y. M. Chae, et al. Data mining approach to policy [7] V. Chandola, A. Banerjee, and V. Kumar. Anomaly [8] C. T. Chu, et al. Map-Reduce for Machine Learning [9] J. Cohen, et al. Mad skills: new analysis practices for [10] T. Fawcett and F. Provost. Activity monitoring: [11] A. M. Garber and J. Skinner. Is american health care [12] R. Ghani and M. Kumar. Interactive learning for [13] M. H  X  A  X uhle. Online change-point detection in [14] L. Kenworthy. America X a  X  A  X  Zs inefficient health-care [15] S. Konishi and G. Kitagawa. Information Criteria and [16] B. Long, P. S. Yu, and Z. Zhang. A General Model for [17] C. B. Lynde and M. D. Pratt. Acquired perforating [18] C. D. Manning, P. Raghavan, and H. Schtze.
 [19] J. Manyika, et al. Big data: The next frontier for [20] D. C. Montgomery. Introduction to Statistical Quality [21] M. Newman. Networks: An Introduction . Oxford [22] E. S. Page. On problems in which a change can occur [23] L. Page, S. Brin, R. Motwani, and T. Winograd. The [24] S. H. Preston and J. Ho. Low life expectancy in the [25] U. Raja, T. Mitchell, T. Day, and J. M. Hardin. Text [26] M. Reynolds and Z. Stoumbos. A cusum chart for [27] M. Sparrow. License to steal: how fraud bleeds [28] Y. W. Teh, D. Newman, and M. Welling. A collapsed [29] S. Wasserman and K. Faust. Social Network Analysis.
