 With the advances and increasing sophistication in data col-lection techniques, we are facing with large amounts of data collected from multiple heterogeneous sources in many ap-plications. For example, in the study of Alzheimer's Disease (AD), di erent types of measurements such as neuroimages, gene/protein expression data, genetic data etc. are often col-lected and analyzed together for improved predictive power. It is believed that a joint learning of multiple data sources is bene cial as di erent data sources may contain comple-mentary information, and feature-pruning and data source selection are critical for learning interpretable models from high-dimensional data. Very often the collected data comes with block-wise missing entries; for example, a patient with-out the MRI scan will have no information in the MRI data block, making his/her overall record incomplete. There has been a growing interest in the data mining community on expanding traditional techniques for single-source complete data analysis to the study of multi-source incomplete data. The key challenge is how to e ectively integrate informa-tion from multiple heterogeneous sources in the presence of block-wise missing data. In this paper we rst investigate the situation of complete data and present a uni ed \bi-level" learning model for multi-source data. Then we give a natural extension of this model to the more challenging case with incomplete data. Our major contributions are three-fold: (1) the proposed models handle both feature-level and source-level analysis in a uni ed formulation and include several existing feature learning approaches as special cases; (2) the model for incomplete data avoids direct imputation of the missing elements and thus provides superior perfor-mances. Moreover, it can be easily generalized to other ap-plications with block-wise missing data sources; (3) ecient optimization algorithms are presented for both the complete and incomplete models. We have performed comprehensive evaluations of the proposed models on the application of AD diagnosis. Our proposed models compare favorably against existing approaches.
 H.2.8 [ Database Management ]: Database Applications-Data Mining Algorithms Alzheimer's disease, multi-source, block-wise missing data, optimization
Recent advances in data collection technologies have made it possible to collect a large amount of data for many ap-plication domains. Very often, these data come from multi-ple sources. For instance, in the study of Alzheimer's Dis-ease (AD), di erent types of measurements such as mag-netic resonance imaging (MRI), positron emission tomogra-phy (PET), cerebrospinal uid (CSF), blood test, protein expression data, and genetic data have been collected as they provide complementary information for the diagnosis of AD [31, 34]. In bioinformatics, di erent types of biological data including protein-protein interactions, gene expression and amino sequences have been collected for protein classi-cation [19]. Extraction of the great wealth of information from such multi-source (a.k.a multi-modality) data has be-come a crucial step in knowledge discovery. Data mining and machine learning methods have been increasingly used to analyze multi-source data [26, 10, 29]. It is expected that the performance can be signi cantly improved if informa-tion from di erent sources can be properly integrated and leveraged. Multi-source learning has thus attracted great attentions in various application domains from biomedical informatics [17, 31] to web mining [1, 29]. It is closely re-lated to multi-view learning. However they di er in several important aspects. More speci cally, multi-view learning mainly focuses on semi-supervised learning and using un-labeled data to maximize the agreement between di erent views [2, 11]. In this paper, we focus on the multi-source learning in the supervised setting and we do not assume there are abundant unlabeled data available. In addition, we do not attempt to reduce the disagreement between mul-tiple sources but try to extract complementary information from them, as is often the case in biomedical applications such as AD study.

In many applications, the data are also of very high di-mension, e.g., medical images and gene/protein expression d ata. However, the high-dimensional data often contains re-dundant information or even noisy or corrupted entries and thus poses a potential challenge. In order to build a stable and comprehensible learning model with good generaliza-tion, it is critical to perform certain \feature-pruning". A simple approach is to pool data from multiple sources to-gether to create a single data matrix and apply traditional feature selection methods directly to the pooled data ma-trix. However, such an approach treats all sources equally important and ignores within-source and between-source re-lationship. Another popular approach is to adopt multiple kernel learning (MKL) to perform data fusion [19, 29, 31] which provides a principled method to perform source-level analysis, i.e., a particular source is considered relevant to the learning task only if its corresponding kernel is selected in MKL. However, MKL only performs source-level analysis, ignoring feature-level analysis. Such an approach is subopti-mal when the individual data sources are high-dimensional and an interpretable model is desired. To fully take ad-vantage of the multi-source data, it is desirable to build a model which performs both individual feature-level and source-level analysis. In this paper, we will use the term \bi-level analysis" (this was rst introduced in [8]) to refer to the simultaneous feature-level and source-level analysis.
Besides the multi-modality and the high-dimensionality, the existence of (block-wise) missing data source is another big challenge encountered in most biomedical applications. Figure 1 provides a typical situation in AD research. We have 245 participants in total and 3 types of measurements (PET, MRI and CSF) are taken for diagnosis. Therefore for a single participant, there are at most three di erent mea-surements, which are represented in di erent colors. The blank region means that data from the corresponding source is missing. In this example, participants 1 60 have records on PET and MRI but lack CSF information while partici-pants 149 245 have only MRI data. The block-wise miss-ing data issue could emerge in several scenarios: inaccurate data sources of certain sample may be discarded; some data-collecting mechanisms (like PET) may be too costly to be applied to every participant; participants may not be will-ing to take certain measurements for various reasons. Notice that the missing data emerges in a block-wise way, i.e., for a patient, certain data source is either available or lost com-pletely.
 Fi gure 1: An illustration of an incomplete multi-source data with three sources.
Considerable e orts have been made to deal with the miss-ing data, both in data mining and biomedical informatics. Some well-known missing value estimation techniques like EM [12], iteratively singular value decomposition (SVD) and matrix completion [21] have been extended to biomedical applications by performing imputation on the missing part of the data. Although these approaches have demonstrated their e ectiveness on handling random missing entries, they often deliver sub-optimal performance in AD research [32] for the following reasons: (1) these imputation approaches fail to capture the pattern of the missing data, i.e., the miss-ing elements are not randomly scattered across the data matrix but emerge block-wisely. However, such prior knowl-edge is completely discarded in imputation methods; (2) due to the high-dimensionality of the data, these methods of-ten have to estimate a signi cant amount of missing values, which would result in unstable performances.

To overcome the aforementioned drawbacks of standard imputation methods, Yuan et al. proposes an incomplete Multi-Source Feature learning method (iMSF) which avoids the direct imputation [32]. The iMSF method rst parti-tions the patients into disjoint groups such that patients from the same group possess identical data source combina-tions. Feature learning is then carried out independently in each group and nally the results from all the groups are properly combined to obtain a consistent feature learning result. Such a mechanism enables iMSF to perform feature selection without estimating the missing values, however, the resulting model is unable to provide source-level analy-sis, i.e., we cannot tell which data source is more important for the diagnosis or which data source should be discarded in a particular application. Such a drawback may limit the per-formance of iMSF in applications where noisy or corrupted data sources are frequently encountered.
Although the importance of bi-level analysis in bioinfor-matics has drawn increasing attention [8, 16, 28], how to e ectively extend these techniques to deal with block-wise missing data remains largely unexplored. In this paper, we ll in such a gap by proposing a bi-level feature learning model for both complete and block-wise missing data. Our contributions are three-fold: (1) we propose a uni ed feature learning model for multi-source data, which includes several existing feature learning approaches as special cases; (2) we further extend this model to t the block-wise missing data. The resulting model avoids direct imputation of the miss-ing data and is capable of bi-level feature learning; (3) the proposed models for both of the complete and incomplete data require solving non-convex optimization problems. We present ecient optimization algorithms which nd the so-lution by solving a sequence of convex sub-problems.
The rest of the paper is organized as follows. In Section 2, we present our uni ed framework for multi-source feature learning for complete data. The relationship between our model and existing works and the optimization algorithms are also discussed. In Section 3, we provide a natural exten-sion of this model to deal with the block-wise missing data sources and propose an alternating minimization algorithm for the optimization. Extensive empirical evaluations are carried out in Section 4. We conclude the paper and point out some future directions in Section 5.
Assume we are given a collection of m samples from S data sources: with each sample being a p i -dimensional vector, and y is the corresponding outcome for each sample. We consider the following linear model: where each column of X is normalized to be zero mean and standard deviation of 1 and  X  represents the noise term. is the underlying true model and is usually unknown in real-world applications. Based on ( X ; y ), we want to learn an estimator of , denoted as ^ , whose non-zero elements F = f j : ^ j  X  = 0 g correspond to the relevant features. In other words, features correspond to the zero elements of ^ are discarded. We consider the following regularization framework: where L ( ) represents the data-tting term and  X ( ) is the regularization term which encodes our prior knowledge about . Speci cally, the choice of  X ( ) should also enable us to perform both feature-level and source-level analysis simulta-neously. Towards this end, a natural approach is a two-stage model. First we learn di erent models for each data source and then combine these learned models properly. The reg-ularization should be imposed independently on each stage to provide the bi-level analysis. We formalize our intuition as follows: minimize where the minimization is taken with respect to ( ; ) jointly. According to the intuition above, i denotes the model learned on the i th data source and is the weight that combines those learned models together. The regularization is taken independently over and and therefore we have the exibility to choose di erent values of p and q to induce sparsity on either feature-level or source-level. Notice that model (2) is not jointly convex and direct optimization to-wards (2) would be dicult. We provide an equivalent but simpler formulation in the following theorem and discuss its optimization in the next section.

Theorem 1. The formulation (2) is equivalent to the fol-lowing optimization problem:
Proof. Without loss of generality, we assume that i  X  = 0 for all i = 1 ; 2 ; ; S . Since if i = 0 for some i , the optimal i must be 0 and therefore both i and i can be removed from (2). Let i = i i and replace i with  X  i  X  p  X  w e can obtain an equivalent formulation: minimize
Taking partial derivative with respect to i and setting it to zero leads to: Plugging (5) back into (4) with the change of variables, we get the formulation (3).
Formulation (2) (or its equivalent form (3)) is a very gen-eral model. Assigning di erent values to p and q leads to various kinds of regularization and feature learning models. Next, we show several widely-used convex models are actu-ally our special cases.

Let p = 1 and q = 1 . In this case, the regularization term in (3) becomes the  X  1 -regularization and the resulting model becomes Lasso [25]: It is well-known that the  X  1 -regularization leads to a sparse solution, which coincides with the goal of feature selection. However, it does not consider the source structure by treat-ing all features from di erent sources equally.

On the other hand, if both p and q equal 2, then the  X  2 -regularization is applied on each source. Letting i = lea ds to the group lasso [33]: Similarly, if p = 1 and q = 1, we obtain the  X  1 ; 1 -regularization model [27, 23], which penalizes the largest elements of i each source:
Besides these common convex formulations, our general model also includes a family of non-convex formulations which have not been fully explored in the literature. Par-ticularly, letting p = 1 and q = 2 leads to the following non-convex model: If p = 2 and q = 1, model (3) reduces to: For the convex models such as lasso, the optimization algo-rithms have received intensive studies [5, 7, 13, 4]. In order to fully explore the functionality of our general model, we shall provide further investigations on the non-convex for-mulations in terms of optimization.
We rst focus on formulation (10), which is clearly a non-convex optimization problem. Gasso et al. has shown in [15] that the  X  q -regularized least squares problem with q &lt; 1 can be eciently solved using the di erence of convex func-tions (DC) algorithm [24]. The DC decomposition presented in [15] requires the regularization term to be a concave func-tion with respect to the absolute value of the variable. How-ever this is not the case in our formulation according to the following proposition:
Proposition 1. Letf ( ) =  X   X  convex nor concave w.r.t. j j unless is a scalar, where jj denotes the absolute value.

Proof. The proof is carried out by computing the Hes-sian of f . Without loss of generality, we assume  X  = 0 . It can be shown that: wh ere 1 is the indicator function. It is clear that, unless is a scalar, in which case it is obvious that f is a concave words, the sign of the diagonal elements of the Hessian of f can be either positive or negative, which means that f is neither convex nor concave.

T o employ the DC algorithm, we need to avoid the non-concavity of the regularization item. We introduce new vari-ables t i ; i = 1 ; 2 ; ; S and transform (9) into the following formulation: It is clear that (11) is equivalent to the original formula-tion (9), however the regularization term in (11) is concave with respect to t i , as shown in Proposition 1. We apply the DC algorithm, i.e., for each t 2 3 i , we rewrite it as the di erence of two convex functions as follows: Th erefore, (11) becomes: minimize su bject to  X  i  X  1 t i ; i = 1 ; 2 ; ; S: Next we replace the second convex item t i t 2 3 i b y its ane minorant at the previous iteration. Speci cally, suppose at the previous iteration the value of t i is ^ t i ; now we approx-imate t i t 2 3 i b y its rst-order Talyor expansion at ^ follows: Plu gging the above expression back to (12) and dropping the constant, we get: Since i and ^ t i are nonnegative, all constraints in (13) must be active at the optimal points. Thus, (13) is equivalent to the following group lasso problem: Aft er is obtained, we update ^ t i with  X  i  X  2 and continue the iteration until convergence. Notice that ^ t i 1 3 c an be very large if  X  i  X  2 is small. For numerical stability, we add a smoothing term to each b t i as suggested by [15]. The overall procedure is summarized in Algorithm 1.
 Al gorithm 1 DC algorithm for solving (10) Inpu t: X , y , Output: solution to (10) 1: Initialize , (0) i ; i = 1 ; 2 ; ; S 2: for k = 1 ; 2 ; do 3: Update and i by: 4: if the objective stops decreasing then 5: return = ^ k 6: end if 7: end for
Re mark 1. Model (9) can be solved in exactly the same way as above. The only di erence is that in each iteration we need to solve a weighted lasso problem to get ^ (  X  ) .
Remark 2. Although we only consider the least squares loss function here, the above derivations can be easily ex-tended to other widely-used convex loss functions, such as the logistic function.
In this section, we consider the more challenging and more realistic situation with block-wise missing data, as shown in Figure 1. In such situation, most patients do not have com-plete data collected from every data source but lack one or more data blocks. To apply existing feature learning ap-proaches directly, we can either discard all samples that have missing entries or estimate the missing values based on the observed entries. However, the former approach may signi cantly reduce the size of the data set while the lat-ter approach heavily relies on our prior knowledge about the missing values. Moreover, both approaches neglect the block-wise missing patterns in the data and therefore could lead to sub-optimal performance.
As in the case of complete data, an ideal model performs both feature-level and source-level analysis simultaneously. Next, we show how to extend the model on complete data presented in the previous section to a more general setting with missing data. Our intuition of designing such Incom-plete Source-Feature Selection (iSFS) model is illustrated in Figure 2. We follow a similar strategy used in our com-plete model (2): individual model is learned on each data source and then all models are properly integrated via extra regularizations/constraints. As shown in Figure 2, we try to learn the model represented by 1 , 2 and 3 , corresponding to measurements from PET, MRI and CSF, respectively. A subtle issue is how to learn the coecients , since model (2) is not applicable due to the presence of missing data blocks. To address this issue, we partition the whole data set into multiple groups according to the availability of data sources, as illustrated in the red boxes in Figure 2. For this particu-lar case, we partition the data into 4 groups, where the rst group includes all the samples that have PET and MRI, the second group of patients possesses all three data sources, the third group of patients has MRI and CSF measurements, while the last group of patients only has MRI data. Note that within each group we have the complete data and the analysis from the previous section can be applied.
The proposed model is closely related to the iMSF model proposed in [32], however, they di er in several signi cant aspects: (1) the proposed method partitions the data into multiple groups according to the availability of data sources. The resulting groups are not disjoint compared to that of the iMSF. Generally, our partition method results in more samples for each group; (2) in the proposed approach, the model learned for each data source is consistent across dif-ferent data source combinations while iMSF does not; (3) in every data source combination, we learn the weights of each source from the data. The weights for a speci c data source may di er in di erent data source combinations. Un-like iMSF, the proposed method achieves source selection by discarding the data sources with a weight of 0. Thus, the proposed method is expected to outperform iMSF especially in the presence of noisy data sources.
Before presenting the formal description of our iSFS model, we rst introduce some notations which will simplify the dis-cussion. Suppose we have S data sources in total and each participant has at least one data source available. Then there are 2 S 1 possible missing patterns: the number of all possible combinations of S data sources except for the case that all data sources are missing. For each participant, based on whether a certain data source is present, we obtain a bi-nary indicator vector I [1 S ], where I [ i ] = 1 indicates the i th data source is available. For example in Figure 1, partici-pants 1 139 possess the same indicator vector [1 ; 1 ; 0] while the indicator vector of participants 149 245 is [0 ; 1 ; 0]. Us-ing such indicator vectors simpli es our analysis. Moreover, we do not even need to store the complete vector for each participant but just need to record a single decimal integer if we convert this binary vector to a binary number, i.e., the information in the indicator vector can be completely de-scribed by a decimal integer, called pro le . All these pro-les are stored in an n-dimensional vector pf [1 n ] where n is the number of participants.
 We are ready to give a concise description of our model. Following the aforementioned intuitions, we learn a consis-tent model (variable ) across di erent source combinations, while within each combination, the weights (variable ) for di erent sources are learned adaptively. Mathematically, the proposed model solves the following formulation: minimize subject to R ( m ) 1 8 m 2 pf ; where and R , R are regularizations on , respectively. The m subscript in (14) denotes the matrix/vector restricted to the samples that contain m in their pro les. X i and i in (15) represent the data matrix and and the model of the i th source, respectively. L can be any convex loss function such as the least squares loss function or the logistic loss function and n is number of rows of X .
One of the advantages of iMSF is its ecient optimization algorithm. In fact, iMSF can be solved by standard convex multi-task learning algorithms [3, 20]. The proposed iSFS model involves a more complicated optimization problem. In fact, (14) is not jointly-convex w.r.t and , posing a major challenge. We adapt the alternating minimization method to solve (14). More speci cally, we rst initialize and compute the optimal . Then is updated based on the computed . We keep this iterative procedure until convergence. For simplicity, we focus on the least squares loss function in the following discussion. The techniques can be easily extended to other loss functions, e.g., the logistic loss function.
As shown in Figure 2, we learn the weight for each source combination independently. Therefore, when is xed, the objective function of (14) is decoupled w.r.t m and the optimal m is given by the optimal solution of the following problem:
For many choices of the regularization term R , such as the ridge penalty, the  X  1 -norm penalty as well as other sparsity-induced penalties [4], the optimal solution of (16) can be eciently computed via the accelerated gradient al-gorithm [6].
When we keep xed and seek the optimal , (14) be-comes an unconstrained regularization problem:
X
X source, i remains identical while may vary across di erent groups. where a nd n m is number of rows of X m . We can observe that g ( ) is a quadratic function of and thus the overall formulation is to minimize the summation of a quadratic term and a regularization term: a typical formulation that can be solved eciently via accelerated gradient method provided that the following proximal operator [9]: ca n be computed eciently. Indeed, this is the case for many widely used regularization terms. In addition, in order to apply standard rst-order lasso solvers, we only need to provide the gradient of at any given point without knowing the explicit quadratic form. For each data source i , we can compute the gradient of the g ( ) w.r.t i as follows: where I ( ) is the indicator function which equals 1 when the condition is satis ed and 0 otherwise. The expression m &amp; 2 S i  X  = 0 ensures that the i th source exists in the combination m , where &amp; denotes the bit-wise AND opera-tion. Then we can obtain r g ( ) by stacking all the r g ( i = 1 ; 2 ; S and nally obtain a global solution of (17) via applying the accelerated gradient method. Algorithm 2 summarizes our alternating minimization scheme.
 Al gorithm 2 Iterative algorithm for solving (14) Inpu t: X , y , Output: solution , to (14) 1: Initialize ( i ) 0 by tting each source individually on the 2: for k = 1 ; 2 ; do 3: Compute each ( ) k via solving a constrained lasso 4: Update ( ) k via solving a regularized lasso prob-5: if the objective stops decreasing then 6: return = ( ) k 7: end if 8: end for
Re mark 3. Our model can be easily extended to the logis-tic loss function which is widely used in classi cation prob-lems. Computing in (16) amounts to solving a constrained logistic regression problem while computing in (17) re-quires solving a regularized logistic regression problem. In fact, any convex loss function can be applied to our model as long as the gradient information can be eciently obtained. Remark 4. We may apply di erent forms of R and R in order to capture more complex structures, as long as the associated proximal operator can be eciently computed. Particularly, we can employ the  X  1 -norm penalty to achieve simultaneous feature-level and source-level selection.
Remark 5. A special case of the proposed iSFS model can be obtained by setting m to 1 n is the number of samples that have pro le m . As a result, the optimization (14) only involves and becomes a convex pr ogramming problem. In fact, this is exactly an extension of the classical lasso method to the block-wise missing data. To the best of our knowledge, such an extension is not known in existing literature.
To examine the ecacy of the proposed bi-level feature learning models, we report the performance of the proposed models for the complete and block-wise missing data, on both synthetic data and real-world applications. Specif-ically, the following aspects are evaluated: (i) model (9) and (10) for complete data; (ii) model (14) for block-wise missing data; (iii) the capability of source-level analysis.
We rst evaluate the e ectiveness of the complete mod-els (9) and (10) on synthetic data generated by the lin-ear model (1). The parameter settings follow the similar strategy described in [14, 30]. Speci cally, we have S = 20 sources in total and the underlying true model = [ 1 ; T 2 ; ; T S ] T only takes non-zero values in the rst six sources, whose values are 10, 8, 6, 4, 2 and 1 respectively. The data matrix X = [ X 1 ; X 2 ; ; X S ] and the noise term  X  all follow the Gaussian distribution with zero mean and standard deviation of 0 : 5. To evaluate the performance of bi-level feature learning, we consider the following two situ-ations: (1) all features within the six sources are useful, i.e., the elements of i , i = 1 ; 2 ; ; 6 are all non-zero; (2) not all features within the six sources are useful, i.e., i is sparse for i , i = 1 ; 2 ; ; 6. Speci cally, only the rst 3 features within each i are nonzero. Figure 3 illustrates these two settings: Fi gure 3: Two scenarios of the underlying true model : the upper one corresponds to the situation of non-sparse features and the lower one represents the situation of sparse features. The white block represents zero elements while the non-zero values are represented by di erent colors, indicated in the rst row.

For each scenario, we partition the dataset into disjoint training set and test set, and compare models (9) and (10) with lasso, group lasso and sparse group lasso. 5-fold cross-validation is employed to tune the parameters for each model. Speci cally, the set of tuning parameters for lasso, group lasso, model (9) and model (10) are chosen from the interval M = [10 8 ; 10 2 ]. For sparse group lasso, its parameters are chosen from the product space of M M . We report the number of features and groups selected by each model and the mean squared error (MSE) on the testing set. In addi-tion, since we know the underlying true model , we also include the parameter estimation error:  X  ^  X  2 2 , where is the estimated model. All the results are averaged over 10 replications and are listed in Table 1. For simplicity, we use FRAC(1 ; 2) to denote model (9) ( p = 1 ; q = 2) and FRAC(2 ; 1) to denote model (10). The experimental results show that, in the situation of sparse features, model (9) achieves the least MSE and estimation error, while for the non-sparse feature case, model (10) outperforms the oth-ers. In addition, in both cases, models (9) and (10) demon-strate signi cant improvement over the lasso, group Lasso and sparse group lasso.
Next we consider the more realistic setting where block-wise missing data is present. We evaluate our models us-ing the classi cation of Alzheimer's disease. We utilize the Alzheimer's Disease Neuroimaging Initiative (ADNI) data set [22, 18] and choose 4 data sources for each patient: Pro-teomics, PET, MRI and CSF. We investigate the classi ca-tion between AD patient, normal control (NC) subjects, sta-ble MCI subjects (non-converter) and progressive MCI sub-jects (converter). Imputation methods such as Mean-value imputation, EM, KNN, iterative SVD and matrix comple-tion as well as the iMSF feature learning model are included for comparison. Notice that kernel learning algorithms are not applicable here since the data are incomplete. All the evaluations are done in a two-stage fashion. In the rst stage, we either apply the feature learning methods to select informative features or the imputation methods to ll in the missing entries in the data. Then in the second stage, the Random Forest classi er is applied to perform the classi ca-tion. We use 10% of the ADNI data for training and report the accuracy, sensitivity, speci city and the area under the ROC curve (AUC value) on the remaining test data. 5-fold cross-validation is used for selecting suitable parameters for iSFS, iMSF, KNN and SVD. Particularly, for iSFS, iMSF and matrix completion, we choose ve values from [10 5 ; 10] in the log scale as candidates. For KNN, the size of the neighborhood is selected from [1 ; 5 ; 10 ; 15 ; 20 ; 25]. The rank parameter in the SVD is chosen from [5 ; 10 ; 15 ; 20 ; 25 ; 30]. In addition, we employ the  X  1 -norm penalty for both R and R . The results are presented in Table 2 to Table 4. All the results are averaged over 10 repetitions. From the evaluation results, we can observe that: (1) among all imputation meth-ods, the mean-value imputation and EM demonstrate better performance in terms of accuracy. However, their results are not stable, as revealed by the low sensitivity/speci city value in some tasks; (2) feature learning models such as iSFS and iMSF provide superior results than the imputation methods and often achieve uniform improvement across all the mea-surements. This coincides with our intuition that estimating the missing blocks directly is usually dicult and unstable and approaches avoiding imputation are more preferred. In particular, iSFS clearly delivers the best performance among all approaches.
Motivated by the strategies used in [19], we add two ran-dom (noisy) data sources to the ADNI data set to verify the performance of source-level learning. We compare our iSFS model with iMSF and report their performance in Figure 4. Besides the previous tasks, two additional evaluations: AD T able 2: Classi cation results of AD patients and normal controls. All results are averaged over 10 replications.
 iSF S 0.8103 0.8077 0.8124 0.8101 iMSF 0.7857 0.7671 0.8005 0.7838 SVD 0.7756 0.7770 0.7746 0.7758 KNN 0.7668 0.7161 0.8072 0.7617 Mean 0.7789 0.7845 0.7744 0.7795 EM 0.8089 0.7963 0.8189 0.8076 MC 0.5957 0.5710 0.6155 0.5932 T able 3: Classi cation results of AD patients and stable MCI patients. All results are averaged over 10 replications.
 iSF S 0.7489 0.7032 0.7816 0.7424 iMSF 0.7172 0.6910 0.7359 0.7135 SVD 0.6942 0.6510 0.7250 0.6880 KNN 0.6774 0.6819 0.6742 0.6781 Mean 0.7338 0.6163 0.8177 0.7170 EM 0.7174 0.6323 0.7782 0.7052
MC 0.6234 0.6135 0.6304 0.6220 p atients vs. MCI and MCI vs. normal controls, are also in-cluded. We can see that our method outperforms the iMSF model in most of the cases. Such a result again justi es the importance of source-level analysis when noisy/corrupted data sources are present.
In this paper, we investigate the bi-level feature learning motivated by biomedical applications and propose system-atic approaches for both complete and block-wise missing data. Speci cally, we introduce a uni ed feature learning model for complete data, which contains several classical convex models as special cases. We further show that the model for complete data can be easily extended to handling the more challenging block-wise missing data. The e ec-Table 4: Classi cation results of progressive MCI patients and normal controls. All results are aver-aged over 10 replications.
 iSFS 0 .8754 0.9361 0.8297 0.8829 iMSF 0.8611 0.9190 0.8174 0.8682 SVD 0.7280 0.7222 0.7323 0.7273 KNN 0.7272 0.6381 0.7944 0.7162 Mean 0.7889 0.9531 0.6651 0.8091 EM 0.8027 0.8281 0.7836 0.8059
MC 0.7740 0.7728 0.7749 0.7738 tiv eness of the proposed models are veri ed through both synthetic data and the Alzheimer's disease study.
In future work, we plan to apply the proposed algorithms to other applications involving block-wise missing data. In addition, we plan to analyze the generalization performance of the proposed algorithms. [1] A. Aizawa and K. Oyama. A fast linkage detection [2] R. Ando and T. Zhang. Two-view feature generation [3] A. Argyriou, T. Evgeniou, and M. Pontil. Convex [4] F. Bach. Optimization with sparsity-inducing [5] J. Barzilai and J. M. Borwein. Two-point step size [6] A. Beck and M. Teboulle. A fast iterative [7] S. Boyd and L. Vandenberghe. Convex optimization . Fi gure 4: The classi cation results of iSFS and iMSF on ADNI data set with additional noisy data sources. [8] P. Breheny and J. Huang. Penalized methods for [9] P. Combettes and J. Pesquet. Proximal splitting [10] K. Crammer, M. Kearns, and J. Wortman. Learning [11] M. Culp, G. Michailidis, and K. Johnson. On [12] R. Duda, P. Hart, and D. Stork. Pattern [13] B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani. [14] J. Friedman, T. Hastie, and R. Tibshirani. A note on [15] G. Gasso, A. Rakotomamonjy, and S. Canu.
 [16] J. Huang, P. Breheny, and S. Ma. A selective review of [17] I. Huopaniemi, T. Suvitaival, J. Nikkil  X  a, M. Oresic, [18] C. R. Jack, M. A. Bernstein, N. C. Fox, P. Thompson, [19] G. Lanckriet, T. De Bie, N. Cristianini, M. Jordan, [20] J. Liu, S. Ji, and J. Ye. Multi-task feature learning via [21] R. Mazumder, T. Hastie, and R. Tibshirani. Spectral [22] S. G. Mueller, M. W. Weiner, L. J. Thal, R. C. [23] A. Quattoni, X. Carreras, M. Collins, and T. Darrell. [24] P. Tao and L. An. Convex analysis approach to dc [25] R. Tibshirani. Regression shrinkage and selection via [26] O. Troyanskaya, K. Dolinski, A. Owen, R. Altman, [27] B. Turlach, W. Venables, and S. Wright. Simultaneous [28] S. Xiang, X. Shen, and J. Ye. Ecient Sparse Group [29] Z. Xu, I. King, and M. Lyu. Web page classi cation [30] H. Yang, Z. Xu, I. King, and M. Lyu. Online learning [31] J. Ye, K. Chen, T. Wu, J. Li, Z. Zhao, R. Patel, [32] L. Yuan, Y. Wang, P. Thompson, V. Narayan, and [33] M. Yuan and Y. Lin. Model selection and estimation [34] D. Zhang and D. Shen. Multi-modal multi-task
