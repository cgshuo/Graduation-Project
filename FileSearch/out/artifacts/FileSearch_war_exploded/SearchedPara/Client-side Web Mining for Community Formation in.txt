 In this paper we present a framework for forming interests-based Peer-to-Peer communities using client-side web brow s-ing history. At the heart of this framework is the use of an order statistics-based approach to build communities with hierarchical structure. We have also carefully considered privacy concerns of the peers and adopted cryptographic protocols to measure similarity between them without dis-closing their personal profiles. We evaluated our framework on a distributed data mining platform we have developed. The experimental results show that our framework could effectively build interests-based communities.
 Peer-to-Peer community, Order Statistics, Privacy Preser v-ing Data Mining
According to Maslow X  X  theory [17], social motive, which drives people to seek contact with others and to build satis-fying relations with them, is one of the most basic needs of human beings. The tendency to have affiliations with oth-ers is visible even in virtual environments such as the World Wide Web. Many online communities like Google and Ya-hoo groups provide the user a place to share knowledge, and to request and offer services. These communities are usually implemented as forums or mailing lists and under certain central control. As the Web continues to grow in both contents and the number of connected devices, Peer-to-Peer (P2P) distributed computing is becoming increas-ingly popular. Applications like Napster, KaZaA, BitTor-rent, and SETI have already demonstrated the power of such computation. Peer-to-Peer technologies harness the CPUs and storage devices over the network to produce huge data stores, processing engines and communications sys- X  Hillol Kargupta is also affiliated with AGNIK, LLC, USA. tems. Each peer in the P2P environment acts as an au-tonomous and independent agent that shares knowledge by submitting queries and by replying with relevant informa-tion. Dynamically aggregating peers with similar interest s could greatly enhance the capability of each individual, fa -cilitate knowledge sharing, and reduce the network load. Fo r example, a peer community allows the establishment of an abstract region of specialization. When a peer needs some relevant resources, the query could be propagated to the community members first to avoid the flooding of the re-quest, and to maximize the quality of search results.
In this paper we address the problem of forming interest-based communities in a Peer-to-Peer environment. We de-fine a Peer-to-Peer community as a collection of nodes in the network that share common interests. Traditional web mining has spent lots of efforts on the web server side, e.g. to analyze the server log. Instead, in this paper, we pro-pose the usage of client-side information, namely, the web browsing cache, to model a peer X  X  personal interests and to build Peer-to-Peer communities. Compared with other related work, our framework has the following specific fea-tures:
The remainder of this paper is organized as follows. Sec-tion 2 offers an overview of the literature on Peer-to-Peer community formation, Peer-to-Peer data mining, and pri-vacy issues in Peer-to-Peer network. Section 3 presents som e basic features of our Peer-to-Peer community framework. Section 4 and 5 address the community formation process. Section 6 discusses the message complexity of some key steps of the formation process. Section 7 studies the performance of the proposed framework and provides the experimental results. Finally, Section 8 concludes this paper with sever al directions for future work.
This section presents a brief overview of the literature on the formation of Peer-to-Peer communities, Peer-to-Pee r data mining, and privacy in Peer-to-Peer network. Due to the large volume of the literature we do not attempt a com-prehensive citation listing. Instead we provide a sampling from a group of major categories.
Generally speaking, the research on self-formation of Peer -to-Peer communities can be grouped into four major cate-gories: 1) ontology matching-based approach; 2) attribute similarity-based approach; 3) trust-based approach; and 4 ) link analysis-based approach. We introduce each of them as follows.

Castano and Montanelli addressed the problem of forma-tion of semantic Peer-to-Peer communities [4]. Each peer is associated with an ontology which gives a semantically rich representation of the interests that the peer exposes t o the network, in terms of concepts, properties and seman-tic relations. Each peer interacts with others by submittin g discovery queries in order to identify the potential member s of an interest-based community, and by replying to incom-ing queries whether it can join a community. A semantic matchmaker is employed to check whether two peer share the same interests. The matchmaker performs dynamic on-tology matching by taking into account both linguistic and contextual features of the concepts to be compared. The ad-vantage of this approach is that peers do not have to agree on the same predefined ontology, and therefore they have lots of flexibility of describing their interests. However, the gain of flexibility comes at the price of accuracy because of the uncertainty of concepts. We refer the reader to [19] for a brief survey of existing ontology matching approaches. The other drawback of this approach is that a peer X  X  interests are inevitably revealed, even to the peers that do not be-long to the community, therefore the privacy of the peer is compromised.

Khambatti et al. proposed a Peer-to-Peer community dis-covery approach where each peer is associated with a set of attributes that represent the interests of that peer [15] . These attributes are chosen from a controlled vocabulary that each peer agrees with, which gets rid of the uncertainty of the fuzzy ontology matching. Peers whose attributes have non-empty intersection can be grouped together. A very ba-sic privacy policy is applied such that a peer does not dis-close attributes corresponding to its private interests. T his means that the smaller the number of claimed attributes, the smaller the number of communities or community mem-bers discovered by a peer. In this paper, we also assume each peer has a set of attributes, which we call as profile vector. The difference is that each interest in the profile vector can be given a weight to show its importance. More-over, we do not simply check the intersection of attributes, instead, we quantitatively compute the similarity between profile vectors (using scalar product), and we use an order statistics-based algorithm that can tell how similar a pair of peers are to each other in the whole network. Our pri-vacy management scheme enables each peer to measure the similarity with other peer without worrying about privacy breach.

Trust-based community formation is usually discussed in the scenario of file sharing and service providing. The nota-tion  X  X rust X  is a measure used by a peer to evaluate other peer X  X  capability of providing a good quality service or re-source. This trust is based on information about the peer X  X  past behavior. Once a peer finds trustworthy peers, it in-vites them to join its community. We refer the reader to [27, 1] as a starting point on this topic. In this paper, we are interested in forming a community based on peers X  interests without considering the past interactions of peers.
There exists another area of research that focuses on the link structure analysis of network to identify patterns of i n-teraction. For example, Scott identified the various clique s, components and circles into which networks are formed [22]. Flake et al. described an approach to identify web commu-nities [8]. Here a web community is a collection of web pages in which each member page has more hyperlinks within the community than outside it. Such communities help to cre-ate improved search engines, to perform content filtering, etc. The drawback of link analysis-based approach is that it depends on the stable link structure of the network, and therefore precludes a peer from being a member of more than one community simultaneously.
Peer-to-Peer data mining is a relatively new field. It pays careful attention to the distributed resources of data, com -puting, communication, and human factors in order to use them in a near optimal fashion. Wolff et al. proposed al-gorithms for association rule mining [29] and local L2 norm monitoring [28] over P2P networks. Datta et al. proposed an algorithm for K-Means clustering over large, dynamic networks [5].
The objective of large scale distributed network is to max-imize the availability and utilization of information. Thi s goal would be achieved if the free flow of information was ensured, and if the owners of different data resources were able to share the data with each other. However, this is frequently restricted by legal obligations or by commercia l and personal privacy concerns. Privacy, or lack of it, is becoming an increasingly important issue in many distrib-uted application scenarios including file sharing, coopera tive computation, etc. Previous research on privacy in Peer-to-Peer network can be roughly classified into two categories: 1) user anonymity; and 2) data privacy.

User anonymity aims at offering the users privacy protec-tion by letting them hide their identities from the commu-nicating peers or from malicious eavesdroppers. There are many uses of anonymous P2P technology that help inter-net users surf the web anonymously and shield their online activities from corporate or government eyes. Anonymous communication system is also used by government for intel-ligence gathering and politically sensitive negotiations . Usu-ally a special protocol for anonymous routing is applied in the network (see e.g. [2]). The anonymity comes from the idea that no one knows who requested the information as it is difficult  X  if not impossible  X  to determine whether a user requested the data for himself or simply requested the data on behalf o somebody else. The end result is that everybody on the network acts as a universal sender and universal re-ceiver to maintain anonymity. There are many decentralized anonymous and censorship-resistant P2P frameworks in the market such as the Freenet [9] and the GNUnet [11], to name a few.

The objective of protecting data privacy is to hide the sensitive information owned by a peer from being disclosed in a cooperative computation environment, where the rev-elation of a peer X  X  identity is unavoidable. For example, it may not be possible to hide the identity ( e.g. IP, port number, URI) of a peer in a Peer-to-Peer community since without this information, peers may not be able to commu-nicate with each other. To be more specific, the data privacy problem in a large scale cooperative computation environ-ment can be defined as follows. Assume that n participants P = { P 1 , P 2 , . . . , P n } , each owning a private input x to jointly compute the output f ( x 1 , x 2 , . . . , x n mon function f , without revealing anything but the output. Privacy preserving data mining (PPDM) [26] strives to pro-vide a solution to this problem. It aims to allow useful data patterns to be extracted without compromising privacy. For example, Gilburd et al. presented a privacy model called k -TTP for large-scale distributed environment [10]. The in-tuition is that at any time each participant can only learn a combined statistics of a group of at least k participants, and therefore any specific participant X  X  private input is hidde n among at least k  X  1 other participants X  input. In Section 5.3 we will revisit this problem and discuss how to compute the scalar product of two private vectors owned by two peers.
In this section, we present some features that characterize the formation of our Peer-to-Peer communities.
A crucial issue in forming Peer-to-Peer communities is to create peer profiles that accurately reflects a peer X  X  intere sts. These interests can be either explicitly claimed by a peer, or implicitly discovered from the peer X  X  behaviors. A peer X  s profile is usually represented by a keyword/concept vector. Trajkova and Gauch proposed techniques to implicitly build ontology-based user profiles by automatically monitoring t he user X  X  browsing habits [25]. The system classifies each web page the user has visited into the most similar concept in a predefined hierarchy of ontology. Each element of the user profile vector corresponds to the weight or the number of pages associated with that concept in the ontology. The Open Directory Project concept hierarchy 1 was used as the reference ontology. Figure 1 shows a sample ontology for user profile. Other sources of information have also been used in the literature to create profiles, such as using book-marks [24], using queries and search results [23], etc. We refer the reader to [25] for a brief overview on this topic.
We point out that any approach that represents a peer X  X  profile in a feature vector can be used in our framework. In this paper, we use the frequencies of the web domains a peer has visited during a period of time to construct the peer X  X  profile vector. Each web domain can be viewed as an interest or topic and hence the frequency represents the weight of the interest for that topic. Detailed explanation about dat a collection is given in Section 7. To avoid the uncertainty of ontology matching, we expect all peers to agree on the same ontology defined by a controlled vocabulary. In this paper, this means that all peers agree on a superset of web domain names. Open Directory Project  X  http://dmoz.org/
The goal of community formation is to find peers sharing similar interests. However, one of the important questions is how a peer can decide whether another peer is similar to him, to what extent? If we simply choose a similarity measurement  X  and setup a subjective threshold such that peers with similarities greater than this threshold can be grouped together, we can X  X  provide any statistical guarant ee. Furthermore, this approach is not able to reflect the essen-tial characteristics of a social community, namely, hierarchy . In a social network, a person may have multi-level friends, where the first level might be family members and closest friends, the second level might be some other colleagues. A person could also have indirect friends from his/her friend s X  social network. A Peer-to-Peer community from one peer X  X  perspective should also have such kind of hierarchical stru c-ture. That is, some peers share more interests with this peer, and some less, under some similarity measurement.
To achieve this goal, we propose an order statistics-based approach (to be described later in Section 5.1) that enables a peer to know how similar the other peer is to himself. In other words, our statistical measurement guarantees that i f the similarity between peer P i and P j is above a threshold, P i can determine with confidence level q that P j is among the top (1  X  p ) quantile most similar peers of P i  X  X . Here the quantile, denoted by  X  p with 0 &lt; p &lt; 1, of a continuous random variable X is defined by P r { x  X   X  p } = p , e.g.  X  is called the median of the distribution. We use the term  X  X op (1  X  p ) quantile X  to denote the area [  X  p ,  X  1 ), e.g. top (1-0.9) quantile means the largest 10% of data. As a running example, let us assume there are 5 peers { P 1 , P 2 , P 3 in the network, and the similarity measures between P 1 and all other peers are { 1 , 3 , 2 , 4 } , respectively, where the higher the value, the higher the similarity. If P 1 knows the similar-ity between him and P 5 is 4, our approach will enable P 1 know, with high confidence, that P 5 is among the top 25% most similar peers of P 1  X  X  in the network, without comput-ing all the similarity values.
 Now we formally define a Peer-to-Peer community based
Figure 2: Example of Peer-to-Peer communities. on our above discussion.
 Definition 3.1. [(  X  , p, q )-P2P Community] A (  X  , p, q )-P2P community from peer P i  X  X  view is a collection of peers in the network, denoted by C , such that the similarity mea-sures  X  between P i and all the members in C are among the top (1  X  p ) quantile of the population of similarity measures between P i and all the peers in the network, with confidence level q .
 Definition 3.2. [Extended (  X  , p, q )-P2P Community] An extended (  X  , p, q )-P2P community from peer P i  X  X  view is the union of C (defined by Definition 3.1) and all the peers from the (  X  , p, q )-P2P community of each member in C .
These two definitions implicitly capture the hierarchical characteristics of the community. When a peer finds a sim-ilar buddy, he could compute the quantile value and deter-mine which area this buddy belongs to. A peer could also specify a p value and only invite those belonging to top (1  X  p ) quantile area to be his community members. The commu-nity could be expanded to include members from members X  X  community. For example, in Figure 2, Peer A, P j , H are the first level members (with larger p ) of community initiated by P i . Peer C, F and G are the second level members (with smaller p ) of community. Note that P j is also a initiator of another community, and it has E as its first level commu-nity member. Peer A, P j , H, E compose an extended P2P community initiated by P i .

In this paper, we use the scalar product between two pro-file vectors to quantify the similarity between two peers. Other similarity metrics such as Euclidean distance can als o be applied in our framework without any hurdle. Details on how to determine the threshold for quantiles using order statistics theory are given in Section 5.1.
A major drawback of most existing community formation approaches is that none of them take serious consideration t o protect a peer X  X  privacy. For example, a peer may not want to reveal some of his interests, or the weights of his interes ts in his profile vector. Privacy becomes an extremely impor-tant issue especially when the profile is implicitly discove red from the peer X  X  personal activities.

In our framework, we provide the peer with two-level pri-vacy protection. The first level allows the peer to explicitl y filter out extremely private sensitive interests by assigni ng zero weights to the corresponding concepts in the profile vector. The second level protection relies on the notion of cryptographic secure multi-party computation (SMC) [31]. Loosely speaking, SMC considers the problem of evaluating a function of the private inputs from two or more parties, such that no party learns anything beyond what can be im-plied from the party X  X  own input and the designated output of the function. We adopt private protocols that are proved to be cryptographic secure such that any pair of peers can compute the similarity of their interests without knowing each other X  X  actual profile vector. Details about the privat e computation are given in Section 5.3.

We need to note that no protocols can build a similar interest-based community without revealing the informati on that these peers share the same interests . A high simi-larity value between two peers tells them they have a lot in common, and their profile vectors are close. Neverthe-less, SMC-based protocols can guarantee that neither party would know the other X  X  actual input, namely, the actual pro-file vector. Moreover, if the similarity value is low, no sign ifi-cant information about the other peer X  X  interest is disclos ed.
In this section, we address the Peer-to-Peer community formation process under the assumptions that: 1) each peer can be a member of multiple virtual communities; 2) peers interact with each other by submitting or replying queries to determine the potential members of a given community; and 3) there is no superpeer as a centralized authority.
The Peer-to-Peer community emerges as a peer, P i , called community initiator, invokes a community discovery proces s which consists of the following tasks: sample size computa-tion, quantiles estimation, member identification, member notification and acceptance, and community expansion.
In our framework, peers interact with each other by send-ing discovery queries, or by answering queries. If a peer P polls another peer P j but does not get a reply in a reason-able amount of time, P i simply assumes that P j has left the network. In this case, P i can resend query to other peers to get necessary information.
This section elaborates on some building blocks that are necessary to complete the Peer-to-Peer community forma-tion process.
Given x , a feature vector, and Y , a set of other feature vectors, we want to find out how similar x and a y  X  X  are to each other in comparison with the similarities of x and other y s in Y . A trivial approach to this problem would be to collect the entire set of Y and compare all the scalar prod-ucts of x and Y . This simple approach, however, does not work in a large-scale distributed P2P environment because the network state is not stable with frequent nodes arrivals and departures, and the overhead of communication would be extremely high. Theories from order statistics, however , could relieve us from this burden by considering only a small set of samples from Y and producing a solution with prob-abilistic performance guarantees. The following part of th is section discusses this possibility.

Let X be a continuous random variable with a strictly increasing cumulative density function (CDF) F X ( x ). Let  X  p be the population quantile of order p , i.e. F X (  X  p ) = P r { x  X   X  p } = p . Suppose we take N independent samples from the given population X and write the ordered samples as x 1 &lt; x 2 &lt; &lt; x N . We are interested in computing the value of N that guarantees Since we have
For example, for q = 0 . 95 and p = 0 . 80, the value of N obtained from the above expression is 14. That is, if we took 14 independent samples from any distribution, we can be 95% confident that 80% of the population would below the largest order statistic x 14 . In other words, any sample with value greater or equal to x 14 would be in the top 20 quantile of the population with 95% confidence. The smaller the p is, the smaller the N , e.g. when p = 0 . 70, N = 9. Therefore, given 14 samples, we can also determine the threshold for any quantile of order less than 0 . 80. Recall in the community formation process, if the initiator P i finds a peer P j with similarity value less the threshold, the initiator cannot s ay P j is among the top 1  X  p quantile most similar peers, but the initiator can still find out a smaller p  X  &lt; p and determine with the same confidence level that P j is among the top 1  X  p  X  quantile most similar peers. For detailed treatment of orde r statistics, we refer the reader to David X  X  book [6].
When X is discrete, the equation F X ( x ) = p does not have a unique solution. However,  X  p can still be defined by P r { x &lt;  X  p } X  p  X  P r { x  X   X  p } . This gives  X  p unless F X (  X  p ) equals p , in which case  X  p again lies in an in-terval. It can be shown that in this case, P r { x N &lt;  X  I ( N, 1) = p N , where I p ( N, 1) is the incomplete beta func-tion. Therefore, in the discrete scenario, we have This does not change the conclusion from Eq. 1.
Random sampling in the networks is a prerequisite to the estimation of population quantile. It can be performed by modeling the network as an undirected graph with transi-tion probability on each edge, and defining a corresponding Markov chain. Random walks of prescribed length on this graph produce a stationary state probability vector and the corresponding random sample. The simplest random walk algorithm chooses an outgoing edge at every node with equal probability, e.g. if a node has degree five, each of the edges is traversed with a probability 0.2. However, it can be shown that this approach does not yield a uniform sample of the network unless the degrees of all nodes are equal [16]. Since typical large-scale Peer-to-Peer network tends to have non -uniform degree distribution, this approach will generate a biased sample in most practical scenarios.

Fortunately, the elegant Metropolis-Hastings algorithm [18, 13] implies a simple way to modify the transition prob-ability so that it leads to a uniform stationary state dis-tribution, and therefore results in uniform sample. In this paper, we implement an adaptation of this classical algo-rithm. The work in [3] proposed a more efficient random walk algorithm, the Random Weight Distribution (RWD) algorithm, that allows uniform sampling while minimizing the length of the walk. We will experiment with that al-gorithm in our future work. Next we briefly introduce the Metropolis-Hastings algorithm for random walk.

Let G ( V, E ) be a connected undirected graph with | V | = n nodes and | E | = m edges. Let d i denote the degree of a node i , 1  X  i  X  n . The set of neighbors of node i is given by  X ( i ) where  X  j  X   X ( i ), edge ( i, j )  X  E . Let P = { p ij } represent the n  X  n transition probability matrix, where p ij is the probability of walking from node i to node j in one message hop. 0  X  p ij  X  1 and P j p ij = 1. Protocol 5.2.1 gives the basic algorithm.
 Protocol 5.2.1 Metropolis-Hastings Random Walk 1: FOR each node i, 1  X  i  X  n 2: IF receives a query q 3: Replies with d i 4: IF receives a random walk message 5: IF TTL == 0 6: Terminates the walk 7: ELSE 8: TTL = TTL -1 9: Sends out a query q to its neighbors  X ( i ) 10: IF receives all the replies from its  X ( i ) 11: Modifies transition probability p ij as follows: 12: p ij = 13: Walk to next node with probability p ij .

This algorithm generates a symmetric transition proba-bility matrix and is proved to produce uniform sampling via random walk [3]. As stated in [16], the length of ran-dom walk necessary to reach to stationary state has order O (log n ). Empirical results show that when the length of walk is 10  X  log n , this algorithm approaches uniform dis-tribution reasonably well. The network size n could be estimated using the localized estimation scheme proposed in [14]. Figure 3 shows the probability of selection using the Metropolis-Hastings algorithm over a simulated networ k with 5000 nodes. As can be easily seen, the probability of selection is almost uniform even for varying degree distrib -ution. The longer the simulation runs, the clearer the curve shows a uniform distribution.

To implement a random walk, the initiator sends out a message contains a time-to-live (TTL) parameter that indi-cates the length of the walk. Whenever a node receives the message, it checks the TTL parameter. If TTL is 0, then the walk terminates; otherwise, this node decreases TTL by 1 and forwards the message to the next node based on the transition probability matrix. Figure 3: Selection probability in a simulated net-work with 5000 nodes (nodes arranged by their de-grees).
Private scalar product computation serves as an impor-tant building block for privacy preserving data mining [26] . It considers the problem of computing the scalar product of two vectors owned by two different parties, respectively, so that neither party should learn anything beyond what is im-plied by the party X  X  own vector and the output of the compu-tation. Here the output for a party is either the scalar prod-uct or nothing, depending on what the party is supposed to learn. Many private scalar product protocols have been pro-posed in the literature. Generally speaking, these protoco ls can be classified into two categories: 1) cryptosystem-base d approaches, which offer strong privacy protection, but in-cur high communication and computational cost ( e.g. [30]); and 2) data perturbation-based approaches, which provide weaker privacy protection but allow more efficient solutions for more complicated data mining tasks ( e.g. [7]). We refer the reader to [12] for an overview on this topic.
In this paper, we adopt the protocol proposed in [12] for the private similarity computation. This protocol is prove d to be private in a strong cryptographic sense. To be more specific, no probabilistic polynomial time algorithm subst i-tuting one party can obtain a non-negligible amount of infor -mation about the other party X  X  private input, except what can be deduced from the input and output of this party. Protocol 5.3.1 describes the basic procedures.
 Protocol 5.3.1 Private Scalar Product Private Input of Alice: Vector x = ( x 1 , . . . , x d )  X  Z Private Input of Bob: Vector y = ( y 1 , . . . , y d )  X  Z Output of Alice: x y mod  X  1: Alice generates a private and public key pair (sk, pk), 2: For each i, i = 1 , . . . d , Alice generates a random number 4: Alice computes x y mod  X  = D sk ( w ).

To understand this protocol, let us first take a brief re-view of public-key cryptosystem. A public-key cryptosyste m P ( G, E, D ) is a collection of probabilistic polynomial time algorithms for key generation, encryption and decryption. The key generation algorithm G produces a private key sk and public key pk with specified key size. Anybody can en-crypt a message with the public key, but only the holder of a private key can actually decrypt the message and read it. The encryption algorithm E take as an input a plaintext m , a random value r and a public key pk and outputs the corresponding ciphertext E pk ( m, r ). The decryption algo-rithm D takes as an input a ciphertext c and a private key sk (corresponding to the public key pk ) and outputs a plain-text D sk ( c ). It is required that D sk ( E pk ( m, r )) = m . The plaintext is usually assumed to be from Z  X  , 2 where  X  is the product of two large primes. A public-key cryptosystem is homomorphic when D sk ( E pk ( m 1 , r 1 ) E sk ( m 2 , r 2 ) mod  X  2 ) = m This feature allows a party to add or multiply plaintexts by doing simple computations with ciphertexts, without hav-ing the secret key. That is why Bob could compute an encrypted scalar product without knowing Alice X  X  private inputs in Step 3 of the above protocols.

In our implementation, we use the Paillier cryptosystem [20] for public-key cryptography. Both encryption and de-cryption require modular exponentiations and modular mul-tiplications of large numbers. The bit complexity of these basic operations in Z  X  is O ( |  X  | 3 ), where |  X  | is the size of the public key in bits. In Protocol 5.3.1, Alice performs k encryptions and one decryption; and Bob does not perform any cryptographic operations. Therefore a great amount of computation is attributable to Alice, which becomes the bottleneck of the whole process. However, in our scenario, this protocol can be optimized since each feature vector con -tains lots of 0 X  X  because the peer has never visited the cor-responding web sites. Thus, each peer can pre-compute a large table of random encryptions of 0 X  X  (each encryption uses different r and therefore produces different ciphertext for 0). Then every encryption of 0 simply corresponds to fetching an element from the table, which can be very fast. The communication overhead of this protocol is 2 |  X  | / | m | , where | m | is the size of the original plaintext in bits.
This section discusses the message complexity of some key steps of our community formation process.
 Random walk to fetch samples: Let the size of the network be n , the number of samples necessary be N (refer to Equation 1) and the length of a single random walk be  X  . The community initiator needs to launch N parallel random walks. Each random walk message needs to carry a TTL token (which is initially set to the length of the walk), the I P address and port number of the initiator. If each of them are represented by a 32-bit integer, the total message complexi ty is 32  X  3  X  N  X   X  bits.
 Reply to initiator: Once a peer receives the TTL with value 0, it needs to send its IP address and port number back to the initiator node for doing the private scalar product
The integers modulo  X  , denoted Z  X  , is the set of (equiv-alence classes of) integers { 0 , 1 , . . . ,  X   X  1 } . Addition, sub-traction, and multiplication in Z  X  are performed modulo  X  . Figure 4: Snapshot of a peer X  X  profile. There are 722 such domains for each peer. computation. Since there are N samples to be collected, there are N such peers. The message complexity in this step will be 32  X  2  X  N bits.

Private scalar product computation: Alice encrypts each element of her vector with a public key of size |  X  | bits. The size of each ciphertext is 2  X |  X  | bits. Alice then sends the entire encrypted vector to the Bob for computation. The total message payload for a vector of dimension d is there-fore 2  X |  X  | X  d . After that Bob sends the encrypted scalar product (2  X |  X  | bits) back to Alice. Hence the total message complexity for N samples is 2  X |  X  | X  ( d + 1)  X  N bits.
Message complexity for member identification and invita-tion can be derived in a similar way using the above results. We omit the analysis due to the space constraints.
In this section, we study the effectiveness of the proposed framework for Peer-to-Peer community formation.
We use the web domains a peer has browsed to create the profile vector. Each element of the vector corresponds to the frequency that the domain has been visited by the peer during a period of time. The data was collected from the Internet Explorer (IE) history files of 5 volunteers from the DIADIC Research Lab at UMBC and 10 volunteers from the DSP Lab at Johns Hopkins University. There are in total 1387 KB of data accounting for 97050 browsing history records in our data set, and 722 unique web domains. These records are randomly split and distributed to peers in our network simulator so that each peer can compute its own profile vector. As we have stated previously, we assume all the peers agree on the same profile ontology, i.e. the same set of domain names, and therefore, all the profile vectors have the same size -722. Figure 4 shows a snapshot of a peer X  X  profile.
Our network topology was generated by using BarabasiAl-bert Model from BRITE 3 , a universal topology generator. BarabasiAlbert model interconnects the nodes according to a incremental growth approach, i.e., when a node i joins the network, the probability that it connects to a node j already BRITE -http://www.cs.bu.edu/brite/ belonging to the network is given by: where d j is the degree of the target node, V is the set of of out degrees of all nodes that previously joined the net-work. We choose this model because it does a fairly good job in reproducing the out degree properties of Internet topolo -gies.

We use the Distributed Data Mining Toolkit (DDMT) 4 developed by the DIADIC research lab at UMBC to simu-late the distributed computing environment. This toolkit i s build upon JADE (Java Agent DEvelopment Framework) 5 , a multi-agent systems platform. We implemented all of our algorithms in Java JDK 1.5, and performed the experiments on a dual-processor workstation running Windows XP with 3 . 00GHz and 2 . 99GHz Xeon CPUs and 3 . 00GB RAM.
Having discussed about the data and the simulator setup we are in a position to report the experimental results.
This experiment evaluates the accuracy of random sam-pling and quantile estimation. We chose three different p values -80% , 85% and 90%. In all the three cases, the confi-dence level q was set to 95%, and the size of the network was fixed at 100 nodes. According to Equation 1, the number of samples, denoted by N , necessary to guarantee that the highest order statistic is within the top (1  X  p ) percentile of population is given by 14 , 19 and 29, respectively. Let P the community initiator. The population can be defined as the set of all pairwise scalar products between P i and all the other peers. Now, if P i wants to find similar peers who are in the top (1  X  p ) quantile of the population, it launches N ran-dom walks. The terminal peer for each random walk refers to a sample and P i computes the private scalar product be-tween its own vector and the vector owned by the sample. P i sorts all the N scalar products and finds the largest one as the threshold of quantile of order p . Figure 5 shows esti-mated threshold in the distributed experiment. To compare the results with centralized sampling, P i first collects the pairwise scalar products between itself and all the peers in the network. P i then performs a random sampling of size N and finds the largest scalar product. The threshold found by this approach is illustrated by the stars in Figure 5. Figure 5 also shows the actual population quantile of order p . As is evident from these results, the threshold found through random sampling and order statistics theory is above the actual population quantile. Therefore any scalar product greater than this threshold can be recognized as among the top (1  X  p ) quantile population with high confidence, which validates our claim in Section 5.1.

The next experiment evaluates the accuracy of the ran-dom sampling and quantile estimation algorithm with re-spect to the number of peers -100 , 200 and 500. In each of these cases, the quantile of the population to monitor was set at 80%, and the confidence level was fixed to 95%. Fig-ure 6 shows similar results that in all the three cases the
DDMT -http://www.umbc.edu/ddm/wiki/software/DDMT/
JADE -http://jade.tilab.com/ Figure 5: Estimated and actual quantile value w.r.t. the order of quantile. The results are an average of 100 independent runs. Figure 6: Estimated and actual quantile value w.r.t. the number of peers for fixed p = 0 . 8 , q = 0 . 95 . The results are an average of 100 independent runs. average ordinal thresholds are greater than the actual quan -tiles of the population. Note that as we increase the size of the network the scalar product between any two peers decreases because the original data set is now divided into more partitions and hence each profile vector becomes more sparse.
This experiments measures the complexity of private scalar product protocol in terms of running time. We generated vectors with size from 500 to 2000. 85% of the vector en-tries were set to zeros, and the remaining ones took values uniformly distributed in [0 , 100]. We did this because most peers only visited a small subset of the domains, which made the profile vectors very sparse. Moreover, the complexity to encrypt zero is the same as to encrypt any other integers. As mentioned before, we implemented Paillier X  X  cryptosystem in Java JDK 1.5, and conducted the experiments on a dual-processor workstation running Windows XP with 3 . 00GHz Figure 7: Time required to compute private scalar product with varying dimension of the vector. The results are an average of 10 independent runs. and 2 . 99GHz Xeon CPUs and 3 . 00GB RAM. We tested the baseline protocol as well as its optimized version, i.e. pre-computing the encryption of 0. Figure 7 shows the running time to compute a single scalar product of vectors of varying dimension both with and without the optimization. It can be seen that there is a great reduction in the running time with optimization.

Using the private scalar product protocol and order sta-tistics theory, we can compute the threshold for quantile estimation. Table 1 presents the running time of threshold computation with fixed confidence level 95% and varying p . Table 1: Time required to compute the threshold w.r.t. different population quantile.
Once the threshold is detected, the next step is to form the communities. We experimented with two community forma-tion schemes. One is without community expansion and one is with expansion. The size of the network was fixed to be 100. Table 2 shows the average number of members found by a community initiator and the (simulated) running time with respect to different TTL values. Table 3 presents the results using the community expansion scheme. The inter-esting thing to note here is that peers can find more  X  X im-ilar X  peers without a significant increase in running time. Note that in these simulations, we didn X  X  consider the net-work latency. Since the private scalar product protocol is the most expensive computation, the increase in running time due to network delay in the actual scenario would be insignificant. As a future work, we would like to conduct the experiment in a real distributed environment, and evaluate the performance of our framework. TTL Ave Num of Community Members Time (in secs) 3 3 55.00 4 8 77.50 8 13 173.00 Table 2: Average number of community members found by the initiator without community expan-sion.
 TTL Ave Num of Community Members Time (in secs) 3 7 59.00 4 12 82.50 8 17 179.00 Table 3: Average number of community members found by the initiator with community expansion.

In this paper we have presented a framework for forming interest-based communities in a Peer-to-Peer environment . We proposed an order statistics-based approach to quantify similarities between peers, and to build hierarchical comm u-nities. We also adopted cryptographic protocols to measure similarity between peers without compromising the privacy of their personal profiles. We have conducted simulations on our distributed data mining platform, and the experimental results show that our algorithm can effectively build simila r interests-based communities.

As a future work, we are trying to develop a framework whereby the need for pre-specification of the global ontolog y is not required. For example, each peer can claim a set of interests and we can compute the set intersection size as a similarity index. In this case, no global set of ontology is required. Further we can explore a secure set intersection protocol to protect privacy. We are actively working to ex-tend this work where not only the web domain names are used for peer X  X  profile but also the contents of the web pages. We also plan to run experiments on a real-life peer-to-peer environment where we can simulate with tens of thousands of peers using a large-scale data and measure the actual net-work latency and message overhead.
 H. Kargupta acknowledges the support from the United States National Science Foundation CAREER award IIS-0093353. [1] A. Agostini and G. Moro. Identification of [2] J. Al-Muhtadi, R. Campbell, A. Kapadia, M. D. [3] A. Awan, R. A. Ferreira, S. Jagannathan, and [4] S. Castano and S. Montanelli. Semantic self-formation [5] S. Datta, C. Giannella, and H. Kargupta. K-Means [6] H. A. David. Order Statistics . Wiley-Interscience, 2 [7] W. Du, Y. S. Han, and S. Chen. Privacy-preserving [8] G. W. Flake, S. Lawrence, C. L. Giles, and F. M. [9] Freenet. http://freenetproject.org/. [10] B. Gilburd, A. Schuster, and R. Wolff. k-ttp: a new [11] GNUnet. http://gnunet.org/. [12] B. Goethals, S. Laur, H. Lipmaa, and T. Mielik  X ainen. [13] W. K. Hastings. Monte carlo sampling methods using [14] K. Horowitz and D. Malkhi. Estimating network size [15] M. Khambatti, K. D. Ryu, and P. Dasgupta. Efficient [16] L. Lov  X asz. Random walks on graphs: A survey. [17] A. H. Maslow. Motivation and Personality .
 [18] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, [19] N. Noy. Semantic integration: A survey of [20] P. Paillier. Public-key cryptosystems based on [21] S. Saroiu, P. K. Gummadi, and S. D. Gribble. A [22] J. P. Scott. Social Network Analysis: A Handbook . [23] F. Tanudjaja and L. Mui. Persona: A contextualized [24] C. Thomas and G. Fischer. Using agents to [25] J. Trajkova and S. Gauch. Improving ontology-based [26] J. Vaidya, C. Clifton, and M. Zhu. Privacy Preserving [27] Y. Wang and J. Vassileva. Trust-based community [28] R. Wolff, K. Bhaduri, and H. Kargupta. Local L2 [29] R. Wolff and A. Schuster. Association Rule Mining in [30] R. Wright and Z. Yang. Privacy-preserving bayesian [31] A. C. Yao. How to generate and exchange secrets. In
