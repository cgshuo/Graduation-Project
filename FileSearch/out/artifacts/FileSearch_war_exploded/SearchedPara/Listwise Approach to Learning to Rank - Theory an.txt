 Fen Xia* fen.xia@ia.ac.cn Tie-Yan Liu tyliu@microsoft.com Jue Wang jue.wang@ia.ac.cn Wensheng Zhang wensheng.zhang@ia.ac.cn Hang Li hangli@microsoft.com Ranking, which is to sort objects based on certain fac-tors, is the central problem of applications such as in-formation retrieval (IR) and information filtering. Re-cently machine learning technologies called  X  X earning to rank X  have been successfully applied to ranking, and several approaches have been proposed, including the pointwise, pairwise, and listwise approaches. The listwise approach addresses the ranking problem in the following way. In learning, it takes ranked lists of objects (e.g., ranked lists of documents in IR) as instances and trains a ranking function through the minimization of a listwise loss function defined on the predicted list and the ground truth list. The listwise approach captures the ranking problems, particularly those in IR in a conceptually more natural way than previous work. Several methods such as RankCosine and ListNet have been proposed. Previous experi-ments demonstrate that the listwise approach usually performs better than the other approaches (Cao et al., 2007)(Qin et al., 2007).
 Existing work on the listwise approach mainly fo-cused on the development of new algorithms, such as RankCosine and ListNet. However, there was no suf-ficient theoretical foundation laid down. Furthermore, the strength and limitation of the algorithms, and the relations between the proposed algorithms were still not clear. This largely prevented us from deeply un-derstanding the approach, more critically, from devis-ing more advanced algorithms.
 In this paper, we aim to conduct an investigation on the listwise approach.
 First, we give a formal definition of the listwise ap-proach. In ranking, the input is a set of objects, the output is a permutation of the objects 1 , and the model is a ranking function which maps a given input to an output. In learning, the training data is drawn i.i.d. according to an unknown but fixed joint probability distribution between input and output. Ideally we would minimize the expected 0  X  1 loss defined on the predicted list and the ground truth list. Practically we instead manage to minimize an empirical surrogate loss with respect to the training data.
 Second, we evaluate a surrogate loss function from four aspects: (a) consistency, (b) soundness, (c) mathemat-ical properties of continuity, differentiability, and con-vexity, and (d) computational efficiency in learning. We give analysis on three loss functions: likelihood loss, cosine loss, and cross entropy loss. The first one is newly proposed in this paper, and the last two were used in RankCosine and ListNet, respectively. Third, we propose a novel method for the listwise ap-proach, which we call ListMLE. ListMLE formalizes learning to rank as a problem of minimizing the likeli-hood loss function, equivalently maximizing the likeli-hood function of a probability model. Due to the nice properties of the loss function, ListMLE stands to be more effective than RankCosine and ListNet.
 Finally, we have experimentally verified the correct-ness of the theoretical findings. We have also found that ListMLE can significantly outperform RankCo-sine and ListNet.
 The rest of the paper is organized as follows. Section 2 introduces related work. Section 3 gives a formal definition to the listwise approach. Section 4 conducts theoretical analysis of listwise loss functions. Section 5 introduces the ListMLE method. Experimental results are reported in Section 6 and the conclusion and future work are given in the last section. Existing methods for learning to rank fall into three categories. The pointwise approach (Nallapati, 2004) transforms ranking into regression or classification on single objects. The pairwise approach (Herbrich et al., 1999) (Freund et al., 1998) (Burges et al., 2005) trans-forms ranking into classification on object pairs. The advantage for these two approaches is that existing theories and algorithms on regression or classification can be directly applied, but the problem is that they do not model the ranking problem in a straightforward fashion. The listwise approach can overcome the draw-back of the aforementioned two approaches by tackling the ranking problem directly, as explained below. For instance, Cao et al. (2007) proposed one of the first listwise methods, called ListNet. In ListNet, the list-wise loss function is defined as cross entropy between two parameterized probability distributions of permu-tations; one is obtained from the predicted result and the other is from the ground truth. Qin et al. (2007) proposed another method called RankCosine. In the method, the listwise loss function is defined on the ba-sis of cosine similarity between two score vectors from the predicted result and the ground truth 2 . Experi-mental results show that the listwise approach usually outperforms the pointwise and pariwise approaches. In this paper, we aim to investigate the listwise ap-proach to learning to rank, particularly from the view-point of loss functions. Actually similar investigations have also been conducted for classification. For in-stance, in classification, consistency and soundness of loss functions are well studied. Consistency forms the basis for the success of a loss function. It is known that if a loss function is consistent, then the learned classifier can achieve the optimal Bayes error rate in the large sample limit. Many well known loss func-tions such as hinge loss, exponential loss, and logis-tic loss are all consistent (cf., (Zhang, 2004)(Bartlett et al., 2003)(Lin, 2002)). Soundness of a loss func-tion guarantees that the loss can represent well the targeted learning problem. That is, an incorrect pre-diction should receive a larger penalty than a correct prediction, and the penalty should reflect the confi-dence of prediction. For example, hinge loss, exponen-tial loss, and logistic loss are sound for classification. In contrast, square loss is sound for regression but not for classification (Hastie et al., 2001). We give a formal definition of the listwise approach to learning to rank. Let X be the input space whose elements are sets of objects to be ranked, Y be the out-put space whose elements are permutations of objects, and P XY be an unknown but fixed joint probability distribution of X and Y . Let h : X ! Y be a ranking function, and H be the corresponding function space (i.e., h 2 H ). Let x 2 X and y 2 Y , and let y ( i ) be the index of object which is ranked at position i . The task is to learn a ranking function that can minimize the expected loss R ( h ), defined as: where l ( h ( x ) , y ) is the 0  X  1 loss function such that That is to say, we formalize the ranking problem as a new  X  X lassification X  problem on permutations. If the permutation of the predicted result is the same as the ground truth, then we have zero loss; otherwise we have one loss. In real ranking applications, the loss can be cost-sensitive, i.e., depending on the positions of the incorrectly ranked objects. We will leave this as our future work and focus on the 0  X  1 loss in this paper first. Actually, in the literature of classification, people also studied the 0  X  1 loss first, before they eventually moved onto the cost-sensitive case. It is easy to see that the optimal ranking func-tion which can minimize the expected loss R ( h B ) = inf R ( h ) is given by the Bayes rule, Since P XY is unknown, formula (1) cannot be directly solved and thus h B ( x ) cannot be easily obtained. In practice, we are given independently and identically distributed (i.i.d) samples S = f ( x ( i ) , y ( i ) ) g P
XY , we instead try to obtain a ranking function h 2 H that minimizes the empirical loss.
 Note that for efficiency consideration, in practice the ranking function usually works on individual objects. It assigns a score to each object (by employing a scor-ing function g ), sorts the objects in descending order of the scores, and finally creates the ranked list. That is to say, h ( x ( i ) ) is decomposable with respect to objects. It is defined as where x ( i ) j 2 x ( i ) , n i denotes the number of objects in x ( i ) , g (  X  ) denotes the scoring function, and sort ( denotes the sorting function. As a result, (4) becomes: R
S ( g ) = Due to the nature of the sorting function and the 0  X  1 loss function, the empirical loss in (6) is inher-ently non-differentiable with respect to g , which poses a challenge to the optimization of it. To tackle this problem, we can introduce a surrogate loss as an ap-proximation of (6), following a common practice in machine learning.
 where  X  is a surrogate loss function and g ( x ( i ) ) = the following sections, we sometimes write  X  y ( g ) for  X  ( g ( x ) , y ) and use bold symbols such as g to denote vectors since for a given x , g ( x ) becomes a vector. 4.1. Properties of Loss Function We analyze the listwise approach from the viewpoint of surrogate loss function. Specifically, we look at the following properties 3 of it: (a) consistency , (b) soundness, (c) continuity, differentiability, and convex-ity, and (d) computational efficiency in learning. Consistency is about whether the obtained ranking function can converge to the optimal one through the minimization of the empirical surrogate loss (7), when the training sample size goes to infinity. It is a nec-essary condition for a surrogate loss function to be a good one for a learning algorithm (cf., Zhang (2004)). Soundness is about whether the loss function can in-deed represent loss in ranking. For example, an in-correct ranking should receive a larger penalty than a correct ranking, and the penalty should reflect the confidence of the ranking. This property is particu-larly important when the size of training data is small, because it can directly affect the training results. 4.2. Consistency We conduct analysis on learning to rank algorithms from the viewpoint of consistency. As far as we know, this is the first work discussing the consistency issue for ranking.
 In the large sample limit, minimizing the empirical surrogate loss (7) amounts to minimizing the following expected surrogate loss Here we assume g ( x ) is chosen from a vector Borel measurable function set, whose elements can take any value from  X   X  R n .
 When the minimization of (8) can lead to the min-imization of the expected 0  X  1 loss (1), we say the surrogate loss function is consistent. A equivalent def-inition can be found in Definition 2. Actually this equivalence relationship has been discussed in related work on the consistency of classification (Zhang, 2004). Definition 1. We define  X  y as the space of all possible probabilities on the permutation space Y, i.e.,  X  Y , f Definition 2. The loss  X  y ( g ) is consistent on a set  X   X  R n with respect to the ranking loss (1), if the following conditions hold: 8 p 2  X  Y , assume y  X  = arg max y  X  Y p y and Y c y  X  denotes the space of permu-tations after removing y  X  , we have We next give sufficient conditions of consistency in ranking.
 Definition 3. A permutation probability space  X  Y is order preserving with respect to object i and j , if the following conditions hold: 8 y 2 Y i,j , f y 2 Y : y object i in y , denote  X   X  1 y as the permutation which exchanges the positions of object i and j while hold others unchanged for y , we have p y &gt; p  X   X  1 y . Definition 4. The loss  X  y ( g ) is order sensitive on a set  X   X  R n , if  X  y ( g ) is a non-negative differentiable function and the following two conditions hold: 1. 8 y 2 Y , 8 i &lt; j , denote  X  y as the permutation Theorem 5. Let  X  y ( g ) be an order sensitive loss func-tion on  X   X  R n . 8 n objects, if its permutation prob-ability space is order preserving with respect to n  X  1 objective pairs ( j 1 , j 2 ) , ( j 2 , j 3 ) ,  X  X  X  , ( j the loss  X  y ( g ) is consistent with respect to (1). Due to space limitations, we only give the proof sketch. First, we can show if the permutation probability space is order preserving with respect to n  X  1 objective pairs ( j 1 , j 2 ) , ( j 2 , j 3 ) , with the maximum probability is y  X  = ( j 1 , j 2 ,  X  X  X  , j Second, for an order sensitive loss function, for any or-der preserving object pairs ( j 1 , j 2 ), the vector g which minimizes Q ( g ) in (8) should assign a larger score to j than to j 2 . This can be proven by the change of loss due to exchanging the scores of j 1 and j 2 . Given all these results and Definition 2, we can prove Theorem 5 by means of contradiction.
 Theorem 5 gives sufficient conditions for a surrogate loss function to be consistent: the permutation prob-ability space should be order preserving and the func-tion should be order sensitive. Actually, the assump-tion of order preserving has already been made when we use the scoring function and sorting function for ranking. The property of order preserving has also been explicitly or implicitly used in previous work, such as Cossock and Zhang (2006). The property of order sensitive shows that starting with a ground truth permutation, the loss will increase if we exchange the positions of two objects in it, and the speed of increase in loss is sensitive to the positions of objects. 4.3. Case Studies We look at the four properties of three loss functions. 4.3.1. Likelihood Loss We introduce a new loss function for listwise approach, which we call likelihood loss. The likelihood loss func-tion is defined as: Note that we actually define a parameterized exponen-tial probability distribution over all the permutations given the predicted result (by the ranking function), and define the loss function as the negative log likeli-hood of the ground truth list. The probability distri-bution turns out to be a Plackett-Luce model (Marden, 1995).
 The likelihood loss function has the nice properties as below.
 First, the likelihood loss is consistent. The following proposition shows that the likelihood loss is order sen-sitive. Therefore, according to Theorem 5, it is consis-tent. Due to the space limitations, we omit the proof. Proposition 6. The likelihood loss (9) is order sen-sitive on  X   X  R n .
 Second, the likelihood loss function is sound. For sim-plicity, suppose that there are two objects to be ranked (similar argument can be made when there are more objects). The two objects receive scores of g 1 and g 2 from a ranking function. Figure 1(a) shows the scores, and the point g = ( g 1 , g 2 ). Suppose that the first ob-ject is ranked below the second object in the ground truth. Then the upper left area above line g 2 = g 1 cor-responds to correct ranking; and the lower right area incorrect ranking. According to the definition of likeli-hood loss, all the points on the line g 2 = g 1 + d has the same loss. Therefore, we say the likelihood loss only depends on d . Figure 1(b) shows the relation between the loss function and d . We can see the loss function decreases monotonously as d increases. It penalizes negative values of d more heavily than positive ones. This will make the learning algorithm focus more on avoiding incorrect rankings. In this regard, the loss function is a good approximation of the 0  X  1 loss. Third, it is easy to verify that the likelihood loss is continuous, differentiable, and convex (Boyd &amp; Van-denberghe, 2004). Furthermore, the loss can be com-puted efficiently, with time complexity of linear order to the number of objects.
 With the above good properties, a learning algorithm which optimizes the likelihood loss will become pow-erful for creating a ranking function. 4.3.2. Cosine Loss The cosine loss is the loss function used in RankCosine (Qin et al., 2007), a listwise method. It is defined on the basis of the cosine similarity between the score vector of the ground truth and that of the predicted result. The score vector of the ground truth is produced by a mapping  X  y (  X  ) : R d ! R , which retains the order in a permutation, i.e,  X  y ( x y (1) ) &gt;  X  X  X  &gt;  X  y ( x y ( n ) First, we can prove that the cosine loss is consistent, given the following proposition. Due to space limita-tions, we omit the proof.
 Proposition 7. The cosine loss (10) is order sensitive on  X   X  R n .
 Second, the cosine loss is not very sound. Let us again consider the case of ranking two objects. Figure 2(a) shows point g = ( g 1 , g 2 ) representing the scores of the predicted result and point g  X  representing the ground truth (which depends on the mapping function  X  ). We denote the angle from point g to line g 2 = g 1 as  X  , and the angle from g  X  to line g 2 = g 1 as  X  g tigate the relation between the loss and the angle  X  . Figure 2(b) shows the cosine loss as a function of  X  . From this figure, we can see that the cosine loss is not a monotonously decreasing function of  X  . When  X  &gt;  X  g can heavily penalize correct rankings. Furthermore, the mapping function and thus  X  g loss function. Specifically, the curve of the loss func-tion can shift from left to right with different values of  X  g tively satisfactory representation of loss for the learn-ing problem. Third, it is easy to see that the cosine loss is contin-uous, differentiable, but not convex. It can also be computed in an efficient manner with a time complex-ity linear to the number of objects.
 4.3.3. Cross Entropy Loss The cross entropy loss is the loss function used in List-Net (Cao et al., 2007), another listwise method. The cross entropy loss function is defined as: where P (  X  j x ;  X  y ) = where  X  is a mapping function whose definition is sim-ilar to that in RankCosine.
 First, we can prove that the cross entropy loss is con-sistent, given the following proposition. Due to space limitations, we omit the proof.
 Proposition 8. The cross entropy loss (11) is order sensitive on  X   X  R n .
 Second, the cross entropy loss is not very sound. Again, we look at the case of ranking two objects. g = ( g 1 , g 2 ) denotes the ranking scores of the predicted result. g  X  denotes the ranking scores of the ground truth (depending on the mapping function). Similar to the discussions in the likelihood loss, the cross en-tropy loss only depends on the quantity d . Figure 3(a) illustrates the relation between g , g  X  , and d . Figure 3(b) shows the cross entropy loss as a function of d . As can be seen that the loss function achieves its minimum at point d g means it can heavily penalize those correct rankings with higher confidence. Note that the mapping func-tion also affects the penalization. According to map-ping functions, the penalization on correct rankings can be even larger than that on incorrect rankings. Third, it is easy to see that the cross entropy loss is continuous and differentiable. It is also convex because the log of a convex function is still convex, and the Algorithm 1 ListMLE Algorithm set of convex function is closed under addition (Boyd &amp; Vandenberghe, 2004). However, it cannot be com-puted in an efficient manner. The time complexity is of exponential order to the number of objects. Table 1 gives a summary of the properties of the loss functions. All the three loss functions as aforemen-tioned are consistent, as well as continuous and differ-entiable. The likelihood loss is better than the cosine loss in terms of convexity and soundness, and is better than the cross entropy loss in terms of time complexity and soundness. We propose a novel listwise method referred to as ListMLE. In learning of ListMLE, we employ the like-lihood loss as the surrogate loss function, since it is proven to have all the nice properties as a surrogate loss. On the training data, we actually maximize the sum of the likelihood function with respect to all the training queries. We choose Stochastic Gradient Descent (SGD) as the algorithm for conducting the minimization. As rank-ing model, we choose linear Neural Network (param-eterized by  X  ). Algorithm 1 shows the learning algo-rithm based on SGD. We conducted two experiments to verify the correct-ness of the theoretical findings. One data set is syn-thetic data, and the other is the LETOR benchmark data for learning to rank (Liu et al., 2007). 6.1. Experiment on Synthetic Data We conducted an experiment using a synthetic data set. We created the data as follows. First, we ran-domly sample a point according to the uniform dis-tribution on the square area [0 , 1]  X  [0 , 1]. Then we assign to the point a score using the following rule, y = x 1 + 10 x 2 +  X  where  X  denotes a random variable normally distributed with mean of zero and standard deviation of 0 . 005. In total, we generate 15 points and their scores in this way, and create a permutation on the points based on their scores, which forms an in-stance of ranking. We repeat the process and make 100 training instances, 100 validation instances, and 100 testing instances. We applied RankCosine, List-Net 4 , and ListMLE to the data.
 We tried different score mapping functions for RankCosine and ListNet, and used five most represen-tative ones, i.e., log (15  X  r ), and exp(15  X  r ), where r denotes the positions of ob-jects. We denote the mapping functions as log , sqrt , l , q , and exp for simplicity. The experiments were re-peated 20 times with different initial values of param-eters in the Neural Network model. Table 2 shows the means and standard deviations of the accuracies and Mean Average Precision (MAP)(Baeza-Yates &amp; Ribeiro-Neto, 1999) of the three algorithms. The ac-curacy measures the proportion of correctly ranked in-stances and MAP 5 is a commonly used measure in IR. As shown in the table, ListMLE achieves the best per-formance among all the algorithms in terms of both accuracy and MAP, owing to good properties of its loss function. The accuracies of RankCosine and ListNet vary according to the mapping functions. Especially, RankCosine achieves an accuracy of only 0 . 047 when using the mapping function exp while 0 . 917 when using the mapping function l . This result indicates that the performances of the cosine loss and the cross entropy loss depend on the mapping functions, while finding a suitable mapping function is not easy. Furthermore, RankCosine has a larger variance than ListMLE and ListNet. The likely explanation is that RankCosine X  X  performance is sensitive to the initial values of param-eters due to the non-convexity of its loss function. 6.2. Experiment on OHSUMED Data We also conducted an experiment on OHSUMED, a benchmark data set for learning to rank provided in LETOR. There are in total 106 queries, and 16,140 query-document pairs upon which relevance judg-ments are made. The relevance judgments are either definitely relevant, possibly relevant, or not relevant. The data was in the form of feature vector and rele-vance label. There are in total 25 features. We used the data split provided in LETOR to conduct five-fold cross validation experiments. In evaluation, besides MAP, we adopted another measures commonly used in IR: Normalized Discounted Cumulative Gain (NDCG) (Jarvelin &amp; Kekanainen, 2000).
 Note that here the ground truth in the data is given as partial ranking, while the methods need to use total ranking (permutation) in training. To bridge the gap, for RankCosine and ListNet, we adopted the methods proposed in the papers (Cao et al., 2007) (Qin et al., 2007). For ListMLE we randomly selected one perfect permutation for each query from among the possible perfect permutations based on the ground truth. We applied RankCosine, ListNet, and ListMLE to the data. The results reported below are those aver-aged over five trials. As shown in Figure 4, ListMLE achieves the best performance among all the algo-rithms. Especially, on NDCG@1, it has more than 5-point gains over RankCosine which is at the sec-ond place. We also conducted the t-test on the im-provements of ListMLE over the other two algorithms. The results show that the improvements are statisti-cally significant for NDCG@5, NDCG@7, NDCG@8, NDCG@9, and NDCG@10 (p-value &lt; 0 . 05). In this paper, we have investigated the theory and al-gorithms of the listwise approach to learning to rank. We have pointed out that to understand the effective-ness of a learning to rank algorithm, it is necessary to conduct theoretical analysis on its loss function. We propose investigating a loss function from the view-points of (a) consistency, (b) soundness, (c) continu-ity, differentiability, convexity, and (d) efficiency. We have obtained some theoretical results on consistency of ranking. We have conducted analysis on the likeli-hood loss, cosine loss, and cross entropy loss. The re-sult indicates that the likelihood loss has better prop-erties than the other two losses. We have then de-veloped a new learning algorithm using the likelihood loss, called ListMLE and demonstrated its effective-ness through experiments.
 There are several directions which we can further ex-plore. (1) We want to conduct more theoretical anal-ysis on the properties of loss functions, for example, weaker conditions for consistency and the rates of con-vergence. (2) We plan to study the case where cost-sensitive loss function is used instead of the 0  X  1 loss function in defining the expected loss. (3) We plan to investigate other surrogate loss functions with the tools we have developed in this paper.

