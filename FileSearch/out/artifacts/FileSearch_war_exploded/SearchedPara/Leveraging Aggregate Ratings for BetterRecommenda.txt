 The paper presents a method that uses aggregate ratings provided by various segments of users for various categories of items to derive better estimations of unknown individual ratings. This is achieved by converting the aggregate ratings into constraints on the parameters of a rating estimation model presented in the paper. The paper also demonstrates theoretically that these additional constraints reduce rating estimation errors resulting in better rating predictions. Categories and Subject Descriptors: H.1.2 [Models and Principles]: User/Machine Systems -Human information processing. H.3.3 [Information Storage and Retrieval]: In-formation Search and Retrieval -Information filtering. General Terms: Algorithms, Design, Theory Keywords: Recommender systems, Hierarchical Bayesian models, predictive models, aggregate ratings, OLAP
Consider a movie recommender system, such as the one provided by Netflix, and assume that we know an aver-age rating that graduate students provide for action movies from a reliable external source . Can we use this type of aggregate rating information to improve quality of individ-ual recommendations? More generally, ratings of individual items provided by individual users can be aggregated into OLAP-based aggregation hierarchies [1], and various aggre-gate ratings for different groups of users and groups of items at different levels of the OLAP hierarchy can be known to the recommender system. For example, the IMDB database provides average ratings of movies by various categories of users, such as Male vs. Female ratings. In this paper, we describe how this aggregate rating information from external sources can be leveraged for providing better recommenda-tions of individual items to individual users.

We study this problem in the context of the hierarchical regression models, both Bayesian and frequentist, that were independently proposed by statisticians [5] and marketers [3] studying recommender systems. We decided to use this type of hierarchical regression models [12] for the following rea-sons. First, they constitute hybrid models integrating both user and item characteristics into a single recommendation model. Generally, hybrid models tend to outperform col-laborative and content-based recommendation methods in many cases [2]. In fact, the Hierarchical Bayesian model pre-sented in [3] outperformed a collaborative filtering model [3]. Second, these models are based on strong statistical theory and have nice statistical properties that can be analyzed theoretically, as is done in this paper. However, the gen-eral approach presented in this paper is not limited to this particular type of models and can be generalized to various other statistical and data mining models and approaches. For example, [4] presents a method for using aggregate in-formation about traversal of hypertext pages by a group of users in order to provide better recommendations of hyper-text pages to individual members of the group. In contrast to this top-down approach, [11] presents a bottom-up ap-proach in which the goal is to provide recommendations to a group of users. Then these group recommendations are based on the aggregate ratings that are computed based on the individual ratings of the members of the group.
In this paper we show theoretically that the extra knowl-edge of the external aggregate ratings indeed leads to more accurate recommendations. We also show how this aggre-gate rating information can be converted into additional con-straints on model parameters leading to better estimations of individual unknown ratings. Finally, we present a par-ticular semi-parametric frequentist method for estimating parameters of hierarchical regression models and show how the method incorporates aggregate information.

Before presenting the aggregate method, we first describe hierarchical regression models in Sections 2 and 3 and how they are used for estimating unknown individual ratings. Due to space limitations, we present a compressed version of our results. A complete description is presented in [13].
As explained in Section 1, [3] describes a hybrid approach to rating estimation that uses the following Hierarchical Bayesian (HB) linear regression model: ( r where observed values of the model are ratings r ij assigned by user i for item j , z i is a vector 1 of attributes of user i , such as age, gender, etc., w j is a vector of attributes 2 j , such as price, weight, etc., and vector x ij = z i  X  w where  X  is the Kronecker product. Intuitively, x ij is a long vector containing all possible cross-products between indi-vidual elements of z i and w j .

Vector  X  represents unobserved slope of the regression, vectors  X  j and  X  i represent unobserved item heterogene-ity and user heterogeneity effects respectively. Moreover, the model (1) assumes that vector  X  j  X  N ( 0 ,  X ) and  X  i N ( 0 ,  X ), where  X  and  X  are unobserved covariance matrices, and that each observation r ij has also an i.i.d. disturbance  X  ij  X  N (0 ,  X  2 ), where  X  is also an unobserved parameter.
Thus, vectors  X  , {  X  j } and {  X  i } , scalar  X  , covariance ma-trices  X  and  X  constitute the unknown parameters of model (1). Prior belief about these parameters is introduced in [3], and the parameters are estimated from the known ratings r and known user/item data using Markov Chain Monte Carlo (MCMC) method [6], which constitutes one of the Bayesian estimation techniques for finding the expected value of the posterior distributions of parameters.
 Moreover, [3] compared predictive performance of their Hierarchical Bayesian model (1) against the classical collab-orative filtering methods and demonstrated that model (1) outperformed the collaborative filtering considered in [3].
In most practical cases, the number of parameters to be estimated for model (1) is very large. For example, for 1000 users defined by 5 user attributes and 1000 movies defined by 20 movie attributes, we will need to estimate more than 25,000 free parameters in the model. In general, according to [7], constrained Bayesian estimation techniques are no-torious for their computational difficulty, especially in high-dimensional parameter spaces, as is the case with model (1).
To address this difficulty, we propose to use a frequentist semi-parametric approach that we present in the next sec-tion for solving the aggregate rating problem instead of the Bayesian parametric method defined by (1).
Consider the same model as in (1), but from a frequentist semi-parametric perspective 3 :
For a frequentist,  X  j and  X  i constitute random effects, so that the model (2) constitutes a mixed-effects model [8].
We introduce the notion of a compound disturbance  X  ij by
We typed vectors in bold font as opposed to matrices and scalars that are typed in regular font.
We also include constant term both in z i as a user attribute and in w j as an item attribute.
Semi-parametric perspective makes no assumptions about the shape of distributions. For example, we don X  X  assume that the residuals are normally distributed. Instead, we make assumptions only about the moments of the residual distribution, not about the shape of the distribution. grouping together all the random effects in (2) as follows thus making it a Generalized Least Squares linear regression model (GLS). Moreover,  X  can be consistently 4 estimated by using ordinary least squares estimator (OLS) if we assume that  X  j and  X  i are not correlated with x ij .

The covariance structure of residuals  X  ij can be deter-mined from equations (2) and (3) as follows: where expected value E (  X  ) is taken over  X  ij ,  X  i and  X 
Let  X  be the covariance matrix of a very long vector of residuals  X  = ||  X  ij || ; that is  X  = Var(  X  ). From (4), we conclude that  X  depends just on a few unknown parameters:  X  ,  X  and  X . Thus  X  ,  X  and  X  can be consistently estimated from OLS residuals. For example, we can use the following (overdetermined) system of linear equations: where e ij is the OLS residual corresponding to observa-tion r ij , N is the total number of observations and S U S I are some subsets of users and items respectively.
Parameter  X  of the model (2) can be estimated asymptot-ically efficiently using the Feasible GLS (FGLS) estimator approach [8] as follows: where r is a column-vector of observed scalars r ij stacked on top of each other, so the first element of the vector is a scalar r i 1 j 1 , the second element is r i 2 j 2 and so on. X is a matrix of row-vectors x 0 ij stacked on top of each other one-by-one; thus the first row of the matrix X is a row-vector x 1 j 1 corresponding to observation r i 1 j 1 , the second row of the matrix X is the row-vector x 0 i 2 j 2 and so on.  X   X  is an estimate of  X .

Once we estimated consistently parameters  X  ,  X  and  X , we can consistently estimate expressions X 0  X   X  1 X and X 0 using the estimates  X   X  ,  X   X ,  X   X  and expression (4), and then obtain consistent and asymptotically efficient estimate of  X  using expression (6).

As long as we assume that for each user N i  X   X  and for each item N j  X   X  as N  X   X  for asymptotic analysis, we are able to estimate consistently individual item hetero-geneities {  X  j } and {  X  i } from the following (overdetermined)
Although, not efficiently [8]. system of linear equations where  X   X  ij is a consistent estimator of  X  ij , for example, it can be an OLS residual  X   X  ij = e ij .

System (7) can be interpreted as an ordinary linear regres-sion with dependent variables  X   X  ij , regressors z i and w i.i.d. disturbances  X  ij . Since  X   X  ij is a consistent estimator of  X  , the OLS estimators  X   X  i and  X   X  j consistently estimate  X  and  X  j given our assumption about asymptotic behavior of the model. Thus, the frequentist model (2) gives as much of individual heterogeneity information as Bayesian model (1).
As it follows from (6), estimation of  X  requires inverting matrix  X   X  that is of size N  X  N , where N is the total number of observations. Matrix  X   X  is sparse, symmetric and positive-semidefinite and one can use Cholesky decomposition for sparse matrices  X   X  = LL 0 , where L is the lower-triangular matrix, in order to calculate and store the inverse.
Note that we don X  X  have to store  X   X   X  1 itself, we only need to calculate the X 0  X   X   X  1 X and X 0  X   X   X  1 r . We also notice that  X   X   X  1 = L  X  1 0 L  X  1 and L  X  1 is itself lower-triangular. Thus,
Unfortunately, matrix  X   X  is not a band matrix, so the re-quired storage for Cholesky decomposition matrix L can be as large as O ` N 2  X  of memory, that is too high for large problems. Computational complexity for naive algorithms can be as large as O ( N 3 ). However, the problem is paralleliz-able. For example, the inversion of triangular matrix takes O (log 2 N ) operations with O ( N 3 / log N ) processors [10].
Determination of how to invert the sparse matrix  X   X  more efficiently, and thus making the whole aggregate rating prob-lem scalable, constitutes one of our future research topics.
The main research question addressed in this paper is how to use the aggregate ratings in our statistical models to pro-vide better estimators of individual ratings.

Formally, assume that in addition to the classical indi-vidual ratings r ij , user data z i and item data w j used in equations (1) and (2), we also know the expected value 5 of an average rating across some segment S of user-item pairs. Also assume that there are k total possible user-item pairs in the segment S , thus where sum is taken over all user-item pairs ( i, j )  X  S . For example, assume that the expected average rating of some 100 action movies provided by 20 graduate CS students, based on k = 2000 possible user-item pairs, is a = 7 . 8.
Substituting the expression for r ij from our model equa-tions (1) or (2), we conclude that
E Here we take expected value only over  X  , not  X  j and  X  i
Note that both the Bayesian model (1) and the frequentist model (2) have the same expression for r ij , thus the equation (12) has the same form for both. However, interpretation of the equation (12) can be different for the two approaches.
For the Bayesian model (1), the new information from equation (12) about the expected average rating is inter-preted as a linear equality constraint on unknown parame-ters  X  , {  X  j } , {  X  i } . For the frequentist model (2), the new information from equation (12) about the expected average rating is interpreted as an additional observation. To see equation (12) is equivalent to having an additional observa-tion in the model where the residual  X   X  has a known covariation structure with other residuals  X  ij defined in (3):
Therefore, the constrained model still fits the GLS paradigm presented in Section 3. Note that for the FGLS estimator, equations (14) and (15) introduce an additional row and a column to matrix  X  corresponding to covariances (14) and (15). By including this additional observation we create the corresponding matrix  X   X  from the matrix  X .
In the previous section, we considered only one true ag-gregate rating a for one particular segment of ratings. In this section, we assume that there is a whole aggregation hi-erarchy defined for the ratings matrix. One example would be an OLAP-based hierarchy [9] of aggregate ratings.
Given an OLAP hierarchy for users and items, where rat-ings constitute measures defined for the OLAP cells [9], con-sider a particular category of items C p , a particular segment of users S q and the cell CELL pq in the OLAP hierarchy cor-responding to C p and S q . Also let D pq be all the ratings that users in segment S q provided for items in category C and let R aggr pq be the aggregate rating for CELL pq that was independently assigned by the expert to that cell. various aggregate cells CELL pq at different levels of the OLAP hierarchy. Using the results from Section 4, each aggregate rating R aggr pq produces a constraint of the form duce multiple constraints for different values of p and q and that these constraints come from various levels of aggrega-tion in the OLAP hierarchy.

In fact, we may introduce so many such constraints that the estimator itself will be largely determined by the con-straints and not the real observation data. The solution to this problem for the aggregation model presented in this pa-per is that we may have different levels of confidence in the aggregate ratings. For example, we may be more sure that the average rating provided by graduate CS students from University of XYZ for action movies is 6.5 than in that the average rating by physics students for drama movies is 7.8.
To model this  X  X egree of confidence X  in aggregate ratings, we assume that the aggregate ratings are  X  X oisy, X  which can be formally represented as: where  X  is an unknown noise component,  X  is an unknown true value, a is the observed value for the aggregate rating and  X  2  X  is some known parameter.

Including this noise into expression (10) results in the fol-lowing fuzzy constraint rather than the crisp constraint (12):
From the frequentist prospective, the model still can be interpreted as an additional observation of type (13). There-fore, the multiple aggregation model with different degrees of certainty in various aggregate ratings can still be defined with the GLS framework, and the same analysis presented in Sections 3 and 4 still holds. By including this additional observation (17), we create the corresponding matrix  X   X  from the matrix  X  defined in Section 4. It can be shown that  X  is not singular.

Parameter  X  2  X  in (16) has the following intuition: it can be interpreted as the weight that we place on the corresponding constraint. It can be shown that the larger  X  2  X  is, the less the FGLS method will try to satisfy the constraint. When we consider multiple constraints, we can put different weights on different constraints by assigning to each constraint i its own  X  X eight X   X  2  X  i . In this way, we can accommodate a real situation when some external rating information is more re-liable than the other.

The following proposition demonstrates that the constrained models using aggregate ratings, such as FGLS, provide bet-ter individual rating estimations than the unconstrained ones.
Proposition 1. The expected mean squared error (MSE) on a test set of the constrained FGLS estimator is smaller than the one of the unconstrained FGLS estimator.
Sketch of Proof . Complete proof is available in [13]. The proof is based on the idea that specifying an aggregate rating is equivalent to adding a new observation (17) and on the idea that the sample size matters, i.e., the expected MSE on the test set of the estimator trained on the bigger sample size will be smaller than the expected MSE on the test set of the estimator trained on the subset of the sample.
In this paper, we replaced the Bayesian approach pre-viously deployed in [3, 5] with a corresponding frequentist estimation method Feasible GLS (FGLS) and demonstrated how aggregate ratings can be used to produce additional constraints on the parameters of the FGLS model. We also showed that these additional constraints reduce rating esti-mation errors of the FGLS model resulting in theoretically better rating estimation methods, thus demonstrating how aggregate ratings can improve individual recommendations.
The main issue with the FGLS method is that it works mainly on small to medium-sized problems because of the difficulty with inversion of matrix  X   X  for large problems. Therefore, as a future research, we plan to work on devel-oping more scalable methods for estimating the FGLS and other types of frequentist estimation models that work well for large problems. Also, the next step in our research would be to test our theoretically-based conclusions about superior performance of the constrained models on real data and try to show that empirical results confirm our theoretical anal-ysis. Finally, we intend to extend Proposition 1 from the FGLS to more general types of estimators. [1] G. Adomavicius, R. Sankaranarayanan, S. Sen, and [2] G. Adomavicius and A. Tuzhilin. Toward the next [3] A. Ansari, S. Essegaier, and R. Kohli. Internet [4] J. Bollen. Group user models for personalized [5] M. Condliff, D. Lewis, D. Madigan, and C. Posse. [6] A. Gelfand and A. Smith. Sampling-based approaches [7] A. Gelfand, A. Smith, and T. Lee. Bayesian analysis [8] W. Greene. Econometric Analysis . Prentice Hall, 2002. [9] R. Kimball. The Data Warehouse Toolkit: The [10] Y. C. Kwong. Annual Review of Scalable Computing . [11] M. O X  X onnor, D. Cosley, J. A. Konstan, and J. Riedl. [12] S. W. Raudenbush and A. S. Bryk. Hierarchical [13] A. Umyarov and A. Tuzhilin. Leveraging aggregate
