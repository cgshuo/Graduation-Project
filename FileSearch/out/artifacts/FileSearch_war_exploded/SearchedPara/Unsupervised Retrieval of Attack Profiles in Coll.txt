 Trust, reputation and recommendation are key components of successful e-commerce systems. However, e-commerce systems are also vulnerable in this respect because there are opportunities for sellers to gain advantage through manip-ulation of reputation and recommendation. One such vul-nerability is the use of fraudulent user profiles to boost (or damage) the ratings of items in an online recommender sys-tem. In this paper we cast this problem as a problem of de-tecting anomalous structure in network analysis and propose a novel mechanism for detecting this anomalous structure. We present an evaluation that shows that this approach is effective at uncovering the types of recommender systems attack described in the literature.
 I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Experimentation, Security
In recent years there has been significant research inter-est in the problem of detecting attempts to inject bias into recommender systems [8, 12, 13, 5]. Many e-commerce sys-tems that make use of endorsement or positive ratings to rank products or sellers are vulnerable to the creation of fake profiles that bias the recommendation process. Here we cast this as the problem of detecting anomalous structure in net-work data and consider what can be borrowed from related research in this wider area to address the problem.
A popular theme in data analysis is the study of collections of entities and the links between these entities. In social net-work analysis the entities may be individuals and links are relationships between them. There is also a lot research on network analysis in bioinformatics where the nodes can rep-resent genes or proteins and the links indicate interactions between them. One of the dominant research themes in bi-ological network analysis is the discovery of network motifs that are in some way anomalous or remarkable [10, 16]. A motif is significant in a network if the probability of the observed incidence of the motif occurring by chance is less than some cutoff value, typically 0.01. Such motifs are worth studying as they can reveal something about the structural design principles of the network.

In social network analysis Boykin and Roychowdhury [2] have shown that a similar analysis of the structure of a net-work created from the headers of messages in a user X  X  email inbox can help identify spam. In this network the vertices are users (email addresses) and the edges are taken from the  X  X o X  and  X  X c X  fields in messages. The key insight in this work is that the network structure around spammers is different to that around legitimate users. There will be few links between addresses occurring in the  X  X o X  and  X  X c X  fields of spam email whereas there will be frequent triangular struc-tures around legitimate users. In the language of biological network analysis we can say that there are characteristic network motifs associated with spam email. Boykin and Roychowdhury analyse a clustering coefficient which quan-tifies the proportion of pairs of edges that actually form tri-angles from all possible connected pairs of edges. Because co-recipients of spam email will often not know each other, there will be very few links between these co-recipients and thus very few triangles. They show that this clustering coef-ficient is effective at identifying spam. Zinman and Donath [18] discuss how link analysis such as this can be applied to assess requests to join a person X  X  social network in a social networking service such as MySpace.

The starting point for the research reported in this paper is the observation that the task of identifying attack profiles in recommender systems is similar to the task of identifying biclusters in microarray gene expression data. The objective in biclustering gene expression data is to discover subsets of genes that are correlated across a subset of samples [6]. The research on attack profiles in recommender systems suggests that some important types of attack have a similar structure in that a set of attack profiles will be correlated across a subset of items. Our preliminary evaluation found that that bandwagon attacks (see section 2) could readily be identified by biclustering. However, biclustering was less effective at uncovering other types of attack. We found though that the H v -score that is an effective metric for biclustering expres-sion data [3] is also effective for uncovering a range of attack strategies. The main contribution of this paper is a compre-hensive evaluation of the H v -score for attack detection.
This approach has an advantage over alternative super-vised strategies [5] in that, by being unsupervised, it simply uncovers structure that is anomalous and thus is not re-stricted to discovering attack types known at design time.
The paper proceeds with an overview of the character-istics of recommender system attacks in section 2. In sec-tion 3 we review strategies for detecting attacks and present our H v -score strategy. Section 4 describes our evaluation methodology, the results of which are presented in section 5. The paper concludes with a summary and some plans for future work in section 6.
People are frequently required to make choices about items without having a significant knowledge of the range of choices available. Consequently, we often seek recommendations from others relating to which movies to see, which books to read or which car to buy etc. Collaborative recommen-dation algorithms operate in a similar fashion and can be used to filter information and recommend personalised con-tent that satisfy the particular needs and tastes of individ-ual users [15]. These algorithms have been successfully em-ployed in many online settings and work by gathering prefer-ence data and opinions from users and using this information to generate recommendations for others.

While people are relatively adept at assessing the reli-ability of friends and associates and valuing recommenda-tions from such sources accordingly, it is much more difficult to make judgments concerning users of online environments given their anonymous or pseudo-anonymous nature. Since it is practically impossible to determine in advance the moti-vations and integrity of those who use online systems, there is no guarantee that the preferences expressed for items re-flect the true opinions of users.

In addition, it is often feasible to create a number of identi-ties within a single system and thus the potential for shilling attacks or profile injection attacks to occur exists [8, 12]. These attacks involve the creation of multiple attack profiles which are typically designed to reflect the true preferences of genuine users for certain items, while the target item is assigned a biased rating with the intention of promoting or demoting recommendations made for the item in question. Such attacks are referred to as product push and product nuke attacks, respectively. Since it has been demonstrated that the presence of even small quantities of attack profiles can significantly bias recommendations [13], it is vital that online systems are protected against these kinds of attack.
A number of attack models have been proposed in the literature; we evaluate UnRAP in the context of the widely studied random, average and bandwagon attacks [5].
For each of the attack models, it is assumed the the ob-jective of the attack is to push or nuke the recommendations that are made for one particular target item, i t . This item is always included in attack profiles and is assigned the maxi-mum ( r max ) or minimum rating ( r min ) for product push or nuke attacks, respectively. The remaining items for attack profiles are selected via the following attack models. Random Attack . In this attack, a subset of filler items are simply selected uniformly at random from the set of items present in the system. These items are rated randomly ac-cording to a normal distribution with mean equal to the average rating of all items in the system and standard devi-ation equal to the standard deviation across all items. The advantage of this attack is the low degree of domain knowl-edge required, given that the overall mean and spread of ratings for many domains can be estimated or mined with-out too much difficulty.
 Average Attack . As with the random attack, filler items are selected uniformly at random from the system item set. Ratings for filler items, however, are assigned based on a more specific knowledge of the domain. In this case, filler items are rated randomly on a normal distribution with mean equal to the average rating of the item being rated and with the standard deviation computed as above. This attack has been found to outperform the random attack in the literature [5]. Note, however, that the domain knowledge required to implement this attack is significant and thus may be unfeasible to implement in practice.
 Bandwagon Attack . This attack can be viewed as an extension to the random attack, where an additional set of selected items are also included in attack profiles. These items are picked due to their popularity in the domain, both in terms of the number of ratings assigned to them by gen-uine users and also because they are generally liked. In practice, these items can easily be identified by examining box-office returns and best-seller lists, etc. In the attack profiles, selected items are assigned ratings of r max , thereby ensuring high degrees of similarity between attack and gen-uine profiles. As a result of including these items, it has been demonstrated that the bandwagon attack significantly outperforms both random and average attacks.
Attack detection can be viewed as a 2-player game be-tween attackers attempting to create more effective attack models and system administrators trying to devise new at-tack detection algorithms. As detection algorithms become adept at identifying profiles created according to particular attack models, attackers may attempt to obfuscate attack signatures in order to render them less visible to detection algorithms. Many approaches to obfuscation are possible; in this paper, we consider the models proposed in [17] which can be applied to the three attacks described above. Noise Injection . Noise is added to ratings according to a standard normal distribution multiplied by a constant,  X  , which governs the degree of obfuscation obtained. We set  X  = 0 . 2 in our evaluations and we apply noise to all filler and selected items.
 User Shifting . This approach involves shifting the ratings of a subset of items within a profile by a constant amount. Shifts can take the positive or negative form, where the amount of shift for each profile is governed by a standard normally distributed random number. In the evaluations, all filler and selected items in attack profiles are shifted. Target Shifting . As stated in Section 2.1.1, target items in attack profiles all receive ratings of either r max or r depending on attack intent. Thus, all attack profiles exhibit a particular signature in this regard. Target shifting involves setting the rating of the target item in a percentage of attack profiles to r max  X  1 for push attacks and to r min +1 for nuke attacks. Where applied in our evaluations, we choose to target shift 50% of attack profiles inserted into the system.
Given the vulnerability of collaborative recommender sys-tems to attack as described above, research activity in the field is now well-focused on the robustness issue. We be-gin this section with a review of some of the recent tech-niques that have been proposed to defend collaborative rec-ommender systems against attack.

In [14], signal processing theory was applied to the prob-lem of attack detection. Attack data, created according to a set of specific attack models, is deliberately inserted into a system in order to model the predictive accuracy distribu-tions of known genuine and attack ratings, thereby enabling the selection of thresholds that optimised hit and false alarm rates for such attacks.

In [11], a number of statistical measures to detect attack data were proposed to detect attack profiles. These include generic and model-specific measures, where the latter are derived from the characteristics of a set of known attack models. Classifiers based on these attributes were built us-ing supervised learning methods which are trained to dis-criminate between genuine and attack profiles. As with the previous technique, classification is tuned to the specific at-tack models under consideration, and consequently systems employing these approaches would be susceptible to new or unknown attack models that may be developed.

An unsupervised classification algorithm was introduced in [9] which considers the combined effect of attack pro-files, with the expectation that the correlation between such profiles would be high relative to that between genuine pro-files. The proposed algorithm, based on principal component analysis, achieved favourable attack detection performance when compared to [14, 11].
In this section we briefly describe some of the statistical measures which have been proposed in the literature to de-tect attack profiles. The motivation behind such measures is that the statistical signature for attack and genuine profiles will differ and thus offer a basis on which to perform classi-fication. We will compare the performance of the measures set out below to our proposed metric in Section 5.2. Rating Deviation from Mean Agreement (RDMA).
 This measure was initially introduced in [7] and measures a user X  X  rating disagreement with other users in the system, weighted by the inverse number of ratings assigned to the user X  X  rated items. It is defined as: where N u is the number of items rated by user u , r ui is the rating assigned by user u to item i and U i is the set of users who have rated item i .
 Weighted Degree of Agreement (WDA). Derived from RDMA, WDA is designed to capture the sum of the differ-ences of the user X  X  ratings from the item X  X  average rating, divided by each item X  X  rating frequency [11]. The measure is defined as: Weighted Deviation from Mean Agreement (WDMA).
 As before, this measure is derived from RDMA and places a higher weight on rating deviations that are observed for sparse items by squaring the denominator inside the sum [11]. It is given by: Length Variance (LengthVar). This measure is designed to detect profiles consisting of unusually small or large num-bers of items. The ability to accurately detect large-sized profiles can be seen to be of particular importance, given that such profiles would likely exert a significant influence on recommendations. This measure is defined as follows. where U is the set of all users, l u is the length of profile u and  X  l is the average profile length in the system. Note that, of all the measures described in this section, WDMA was found to provide the highest information gain [11].
The metrics introduced in this study have their origins within bioinformatics, namely the gene expression analysis domain. The mean square residue or H-score was introduced by Cheng and Church to aid location of biclusters , i.e. sub-sets of genes correlated over a subset of experimental con-ditions, in an attempt to better model the gene functional modules within expression data [6]. The H -score is a cumu-lative metric based on the residue score that can be assigned to an entry in a matrix: where a ij is the entry at position ij in the sub-matrix ( I, J ), a iJ is the mean of the i th row, a Ij is the mean of the j th column and a IJ mean of the whole matrix.

The mean squared residue or H -score for the matrix ( I, J ) is given by: Later, biases within this metric were identified [1] and sub-sequently remedied [3] giving rise to variance adjusted mean square residue or H v -score : where a ij is the entry at position ij in the matrix ( I, J ), a is the mean of the i th row. The added row variance as the denominator compensates for the bias inherent in the mean squared residue.

The H v has been used to detect highly correlated sub-matrices or biclusters within gene expression data [3, 4]. An analogous problem within the area of collaborative recom-mendation is that of the detection of certain types of fraud-ulent profiles that exhibit a high correlation over a subset of items. These types of attack are termed bandwagon attacks and occur when a standard random attack is augmented by the addition of k selected popular items, each of which are assigned the mean rating for that item. As the number of random filler items increases however the intra-correlation of the profiles is reduced and these profiles become less de-tectable by standard bicluster analysis. Random and aver-age attack profiles, mentioned in Section 2, also show less intra-correlation and exhibit an anomalous structure in the context of the larger data set, i.e. all genuine users.
Interestingly, further properties of the H v -score metric may be used to aid detection and retrieval of such attack profiles. The H v -score may also be used to assess how well each row and column fit into a data matrix. This is achieved in practice by analysing the partial H v -scores for the rows/columns in the matrix. In general, outlying or anomalous rows in a matrix incur higher H v -scores than well fitting rows. As a result this aspect of the H v -score would seem to suit the profile injection attack detection problem within the collaborative recommendation domain.

In the context of anomalous profile detection, using the notation consistent with Section 3.1, the partial H v -score for user u is given by: where r ui is the rating that user u has assigned to item i , r
Ui is the average rating that item i has received from all users U , r uI is the average rating that user u has given to all items, and r UI is the average rating the data matrix. We now describe the UnRAP (unsupervised retrieval of attack profiles) algorithm which employs the H v -score metric. Step 1: User Profile Scoring using the Hv-score: The first step in the UnRAP algorithm involves assigning H v -scores to all users in the database. Due to the large number of null values (rating zero) in the sparse recommender sys-tem data the standard scoring approach utilized in the gene expression data must be adjusted. The row, column and matrix means are calculated as normal, i.e. over all entries (including null values), however only the residues for each non-null value are summed to give the sum squared residue for the user. In general anomalous profiles, i.e. profiles that do not fit well into the data matrix, receive a higher H v than well fitting profiles. Therefore after sorting based on the partial H v -score the attack profiles tend to cluster in the upper range.
 Step 2: Retrieval of Target Item: In the second step the top-n highest scoring users from the sorted user list are ex-amined to identify the target item. In all cases, regardless of The UnRAP Algorithm: Figure 1: The sliding window assessment in Step 2. attack or filler size, we examine the top 10 users ( n =10).As the upper range tends to be enriched for attack profiles the target item ( i t ) can generally be detected by retrieving the item which deviates most from the mean user rating. In practice the profile mean is subtracted from each item rat-ing and summed over the n users. The item with the largest consistent deviation from its mean (positive deviation in the case of a pushed item and negative deviation in the case of a nuked item) is selected as target item ( i t ). Step 3: Retrieval of Attack Profiles: In Step 3 of the UnRAP algorithm a sliding window (of 10 users in size) is passed along the sorted user list, see Figure 1. In each iter-ation the window is shifted by one user and the sum of the rating deviation for the target item over the current 10 users is calculated. At some point the sliding window moves from a region enriched with attack profiles to a region enriched for normal users. This point is signified by a sharp change (a) (b) (c) Average Push (10%) (d) (e) (f) Average Push Obfuscated (10%) in the rating deviation for the target item. In practice the stopping point is reached when the deviation of the target item reaches or exceeds zero (  X  0 for a push and  X  0 for a nuke attack). A final filtering is then carried out on this reduced set in which individual users that have either no rat-ing for the target item or a rating deviation in the opposite direction from the attack (i.e. if the rating at i t is less than the user mean for pushed target item than it is removed). After this final filtering the remaining user set is returned as attack profiles for the target item i t .
In the first part of the evaluation we compare the H v -score against existing generic profile attributes as reported in [5], see Section 3.1. In Section 5.3 we investigate the ability of UnRAP to detect attack profiles employing various strategies and intents over a range of attack and filler sizes. In our evaluations we used the publicly available Movie-Lens 100K dataset 1 . The Movie-Lens dataset consists of 100,000 ratings on 1682 movies by 943 users. Ratings are integer values between 1 and 5 where 1 is the lowest (dis-liked) and 5 is the highest (most liked). Our data includes all the users who have rated at least 20 movies. In this study we generate both the standard and obfuscated attack strate-gies ( random , average and bandwagon ) described in Section 2.1.1. Attacks of sizes 1 % , 2 % , 5 % and 10 % and filler sizes of 1 % , 3 % , 5 % , 10 % , 25 % , 40 % and 60 % are generated. All reported results are based on the mean values over 100 ran-domly selected target items. http://www.cs.umn.edu/research/GroupLens/data/
Recently Burke et al. evaluated a number of  X  X eneric at-tack detection attributes X  [5]. It was found that RDMA, WDMA, WDA and Length variance (see Section 2) were the most distinguishing generic attributes of attack profiles. We compare the H v -score metric to these attributes and, like Burke et al. , use information gain as an evaluation cri-terion. In this procedure all user profiles are first scored with each metric. The maximum information gain (best split) be-tween attack profiles and genuine users is then calculated. All results presented in this section are mean results over 100 attacks on randomly selected items.

In Figure 2 (a), (b) and (c) we present the comparison of metrics for standard random , average and bandwagon push attacks of size 10%, over several filler sizes. We can see that H v -score performs well aganist the RDMA, WDMA, WDA and Length variance profile attributes over most filler sizes and attack strategies. The one exception seems to be with lowest filler sizes (1%-5%) for the bandwagon attack in which the H v -score is outerperformed by the RDMA and WDMA metrics. However, the H v -score still improves upon all metrics in the 10%-60% filler range of bandwagon attacks.
In Figure 2 (d), (e) and (f) we that similar performance is achieved in the case of the obfuscated versions of the above attacks. Lastly, similar results to those above are seen in the case of nuke attack intent. Burke et al. incorporated the above metrics as  X  X eneric attributes X  within a supervised attack detection approach. Given the results presented here such an approach may well benefit from the addition of a H v -score attribute. In the following section we evaluate the performance of the UnRAP algorithm, which incorporates the H v -score as its principal metric.
In this section we examine the efficacy of the UnRAP al-gorithm in detecting both standard and obfuscated random , average and bandwagon attacks of varying sizes, intents and filler sizes. All results represent average performance over 100 randomly selected items from the Movie-Lens database. We evaluate the retrieval of attack profiles in terms of the precision (P) and recall (R) for both standard and obfus-cated Random , Average and Bandwagon attacks. We exam-ine performance over attack sizes of 1 % , 2 % , 5 % and 10 filler sizes of 1 % , 3 % , 5 % , 10 % , 25 % , 40 % and 60 and nuke attack intentions are investigated. Where possi-ble, values are compared with previously reported results. In this study we use the standard stopping point value of zero i.e. retrieval ceases when zero target item rating deviation is first encountered 2 .

Results for standard attacks are presented in Tables 1, 2 and 3. The underlined values represent improvements upon results from the PCAVarSelect approach developed by Mehta et al. to detect push attacks [9] 3 .

PCAVarSelect also requires the total number attack pro-files present in the system as an input parameter, clearly this would be difficult to estimate in the real world. Un-RAP, which retrieves attacks of various sizes without the need for such a precise constraint, is thus in a sense a  X  X ore unsupervised X  approach.

In Tables 4, 5 and 6 precision and recall of obfuscated attack profiles are reported. This obfuscation involves Noise Injection , Target Shifting and User Shifting parameters (see Section 2.1.2). Comparison with results of Mehta et al. is not performed as their obfuscation parameters and values were not reported. It can be seen that UnRAP performs well despite obfuscation.

In the case of Bandwagon attacks of 1% filler size UnRAP filler sizes.
 sizes.
 filler sizes.
 performs poorly. This is as a result of a high ratio of selected item ratings as compared with randomly imputed item rat-ings which cause these profiles to become less conspicuous. However, as these attacks are highly intra-correlated, they can be detected by standard biclustering approaches as de-scribed in Section 3.2.

In the case of push attacks, precision seems to improve as attack size increases (down the table). This may be because as an item is pushed or nuked with increasing frequency the item mean shifts (up for a push attack and down for a nuke attack) in relation to the user and database mean. This fact has ramifications for the residue of the entry, see Equations 6 and 8 in Section 3.2, making profiles more ill-fitting. This improvement is also seen in the case of nuke attacks, however overall precision is lower. An explanation for this is that in nuke attacks both the mean user rating ( r uI ) and the mean item rating for the target item ( r Ui t ) are lower than push attacks. This serves to reduce the overall mean squared residue across the user profile, see the nominator in Equation 8, Section 3.2.
The UnRAP algorithm employs a sparse matrix variation of the H v -score metric, a metric originally developed in the area of gene expression data analysis. In this paper we show that this metric alone performs well in separating fraudulent attack profiles from genuine users. Given its performance when compared with standard metrics, the H v -score may be used to improve performance of existing attack detection methods, whether they be fully supervised or otherwise.
The UnRAP algorithm builds on the strength of the H v -score, incorporating additional steps to maximize retrieval of attack profiles. UnRAP shows good performance over a range of standard and obfuscated attack strategies and various attacks sizes and filler sizes. UnRAP also shows good performance against previous algorithms presented in the literature and also requires less supervision than pre-vious approaches, in terms of input parameters. Given its generic, unsupervised nature, UnRAP may be better able to detect future novel attack strategies that could confound supervised approaches built upon current problem models.
This research was supported by SFI Grant No. 05/IN.1/I24. [1] J. Aguilar-Ruiz. Shifting and scaling patterns from [2] P. O. Boykin and V. P. Roychowdhury. Leveraging [3] K. Bryan and P. Cunningham. Bottom-Up [4] K. Bryan and P. Cunningham. BALBOA: Extending [5] R. Burke, B. Mobasher, C. Williams, and [6] Y. Cheng and G. Church. Biclustering of expression [7] P. Chirita, W. Nejdl, and C. Zamfir. Preventing [8] S. Lam and J. Riedl. Shilling recommender systems [9] B. Mehta, T. Hofmann, and P. Fankhauser. Lies and [10] R. Milo, S. Shen-Orr, S. Itzkovitz, N. Kashtan, [11] B. Mobasher, R. Burke, R. Bhaumik, and C. Williams. [12] M. P. O X  X ahony, N. J. Hurley, N. Kushmerick, and [13] M. P. O X  X ahony, N. J. Hurley, and G. C. M. Silvestre. [14] M. P. O X  X ahony, N. J. Hurley, and G. C. M. Silvestre. [15] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [16] Z. Saul and V. Filkov. Exploring biological network [17] C. Williams, B. Mobasher, R. Burke, J. Sandvig, and [18] A. Zinman and J. S. Donath. Is Britney Spears spam?
