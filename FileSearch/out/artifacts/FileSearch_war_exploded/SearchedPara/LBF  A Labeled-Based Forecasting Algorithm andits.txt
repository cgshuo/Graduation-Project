 electricity prices and assessment of the risk of trusting in predicted prices.

The uncertainty of the evolution of the electricity prices is a widely studied topic. However, forecasting electricity prices is a specially difficult task because unlike demand time series, prices time series present nonconstant mean and variance and significant outliers. In that way, forecasting techniques are acquiring significant importance. Actually, several forecasting techniques have already been used to predict miscellaneous electricity time series.
 Indeed, Conejo et al. [5] used the wavelet transform and ARIMA models [2] to predict the day-ahead electricity price. The authors decompose the available historical price series in four constitutive series by using the wavelet transform [12]. Then, specific ARIMA models are applied to three of these series (the fourth one is the main component of the transform) and the results are anti-transformed, providing the final forecasting. In [11] two new mixed models were proposed to obtain the forecasts of the prices in two different prediction horizons. The first one, forecasts electricity prices for each of the 24 hours of the next day using ARIMA models. They used the model estimated for one hour with the whole previous weeks to make a prediction. The second model computes the predictions for either working days or weekends using Bayesian Information Criteria.

Equally noticeable was the approach proposed by Garc X a et al. [10] in which a forecasting technique based on a GARCH model [8] was presented. Hence, this paper focuses on day-ahead forecast of electricity prices with high volatility periods. First, they apply a logarithmic transformation in order to smooth the volatility effect. Secondly, the observation of the autocorrelation helped the authors to make the selection of a specific model that deals with the seasonality of the data and the time-varying nature of volatility.
 Recently, a mixing of Artificial Neural Networks [18] and Fuzzy Logic [14] was proposed in [1]. With reference to the neural network presented, it had an inter-layer and a feed-forward architecture consisting of three layers, where the hidden nodes of the proposed Fuzzy Neural Network perform the fuzzification process. Another neural network approach can be found in [3] where multiple combinations were evaluated. These combinations included networks with different number processing decrease. As soon as the clustering is applied, the algorithm only processes the number of cluster  X  X he label X  assigned to the samples, ignoring if they had more than one feature. On the other hand, the complexity of the algorithm is drastically reduced insofar as the computation process is directly proportional to the dimensionality of the data.
The LBF method allows predicting more than one sam-ple because it is implemented with a close loop that feeds the sample-ahead prediction back in the data set, in order to predict the following sample. This feature is especially useful when the horizon of prediction has to cover various samples. Figure 1 shows the basic idea behind the proposed methodology.
 A. Data normalization
The first task to be completed is the normalization of the data. It can be assumed that the prices increase all along the year following a tendency in accordance with the intra-annual inflation. That is, the original trend is suppressed from the initial data; otherwise it could muddle up the results. The transformation applied is: where p j is the price of the j  X  th hour of the day and N the number of samples considered per day. In this case, N =24 since each sample represents one hour of the day.
 B. Clustering technique
At this point the data has already been conveniently pre-processed and cleared. Clustering techniques are, now, going to be applied to label time series.

Given the data base of hourly prices the clustering problem consists of identifying K groups or clusters such that the prices curves of the days belonging to a cluster are similar between them and disimilar to the prices curves of the days belonging to other clusters, according to a distance measure.
As a consequence, the dimensionality of the data base is drastically reduced from its initial 24 features (equivalent to the 24 hours of the day) to only one dimension (the label of the cluster which the day belongs). This effect can be observed in Figure 2.

To achieved this challenge, two questions have to be an-swered: which clustering technique has to be chosen? and, if it is appropriate, how many clusters has to be created?
These two topics has widely been discussed in the literature [24]. Nevertheless, it seems that there is not an unique answer because it depends on many subtle factors.

Hard or fuzzy clustering are the two main branches of non-supervised classification techniques that can be used. Once the data are prepared, a clustering technique is applied in order to label each daily electricity price curve. The discussion of choosing one technique or another can be found in [17], in which the well-known K-means algorithm was the optimum method to classify this kind of data set. In an object i belonging to the cluster C k , the average dissimilarity of i to all other objects of C k is denoted by c ( i ) . Analogously, in cluster C m , the average dissimilarity of i to all objects of C m is called dis ( i, C m ) . After computing dis ( i, C m ) for all clusters C m = C k , the smallest one is selected as follows, This value represents the dissimilarity of the object i to its neighbor cluster. Thus, the silhouette values, silh ( i ) are given by the following equation:
The silh ( i ) can vary between  X  1 and +1 , where +1 denotes clear cluster separation and  X  1 marks points with questionable cluster assignment. If cluster C k is a singleton, then silh ( i ) is not defined and the most neutral choice is to set silh ( i )=0 . The objective function is the average of silh ( i ) over the number of objects to be classified, and the best clustering is reached when the above mentioned function is maximized. where size( ES ) is the number of elements belonging to the set ES . Afterwards, LBF algorithm outputs need to be de-normalized to generate the desired forecasted values. This procedure is detailed in Figure 3.

In case of a long-term prediction, in which more than one forecasted sample is required, the following tasks have to be carried out. First of all, the real values of the predicted sample are linked to the whole data set. Second, the clustering process is repeated with the enlarged data set and, finally, the window size is re-calculated and the prediction step is performed (to see Figure 1).
 D. Selecting the size of the window
The previous clustering generates a sequence of labels associated to every day. Now, a subsequence of labels is taken into consideration for further steps; concretely, if the day d +1 has to be predicted, the sequence of labels S d W = [
L set and it is used as a pattern of search, where W is the length of this subsequence or window.

This stage is, perhaps, the most critical of the whole process insofar as a wrong value for W may affect deeply in the rest of the forecasting. The selection of W depends on the case under study but it can be systematically tuned. Thus, it is compulsory to perform a training phase to find an adequate value for W before applying the LBF approach. This step is illustrated in Figure 4. make predictions. Table I summarizes the periods used in the three time series analyzed.

According to the methodology proposed in [17], the silhou-ette function is applied to these three time series. Figure 5 shows the variation of the mean silhouette value with relation to the number of clusters, K . When the curves reach their higher values, it can be stated that the corresponding K value (X axis) is the one that generates the best clusters possible, that is, the intra-cluster distance is minimized and the inter-cluster is maximized. As it can be appreciated, the number of clusters selected were K =4 , K =3 and K =5 for the Spanish, Australian and New York markets, respectively. The Figures 6, 7 and 8 illustrate the silhouette curves obtained when the Spanish, Australian and New York Markets are evaluated respectively with the above mentioned values of K .
As the number of clusters is already decided, the next step consists in selecting the optimal length of the window W . B. Parameters of quality.

To evaluate the accuracy of the LBF approach in forecasting time series different criteria could be used. However, the most relevant parameters which have to be taken into consideration are: C. Results of forecasting year 2006
In this subsection the results obtained when the LBF algo-rithm was applied into the three different markets is provided. Precisely, Tables IV, V and VI show the MRE, MSE and  X 
MRE produced in the Spanish, Australian and New York markets when the year 2006 was taken into consideration.
Figure 9 illustrates the best prediction curve obtained for the Spanish market in the year 2006 in cents of Euro per KWHr (cE/KWHr). It took place for 23 rd June and its MRE was 3.10%. On the contrary, Figure 10 references the worst prediction. It took place the 8 th May and its MRE was 9.39%.
It is important to remark that the Australian market shows their information structured in different areas. Thus the Na-tional Electricity Market in Australia is comprised of five jurisdictions: Queensland, New South Wales, Victoria, Tasma-nia and South Australia. The results in Table V refers to the Queensland Market.

Figure 11 illustrates the best prediction curve obtained for the Australian market in the year 2006 in dolars per MWHr ($/MWHr). It took place for 12 th May and its MRE
The Spanish electricity price market has been widely ana-lyzed. Many authors have proved their own novel approaches in the year 2002 and, as a consequence, the literature offers multiples results in this year. The LBF algorithm is compared with the four most recently approaches published: ARIMA [5], Neural Networks [3], Mixed Models [11] and Weighted Nearest Neighbors [23]. Finally, it is also compared with the Na X ve Bayes classifier [21]. As it can be appreciated in Table VII, the proposed method has improved all the MRE rates. The authors in [11] also forecasted a week of the year 2000. The comparative MRE rates are shown in Table VIII.
The prices in the Australia X  X  National Electricity Market have also been predicted in [26]. It is remarkable that this market presents an especial behavior since many spot prices are observed. Despite the authors in [26] have developed techniques based on support-vector machines in order to deal with this particular days, the LBF algorithm does not make any assumption about the nature of the days to be predicted, authors in [4] compared some forecasting algorithms with their own approach. They applied manifold-based dimensionality reduction to electricity price curve modeling. Hence, they demonstrated that it exists a low-dimensional manifold rep-resentation for the day-ahead price curve in the New York electricity market.
 The results in Table X stand for the MRE of one week-ahead
