 Abstrac t Learn ing microblog users X  interests has important significance for constructing more precise user profile, and can be useful for some co mmerc ia l applications such as personalized advertise ment, or potential customer analysis. However, most microblogging platforms can X  X  get users X  interest directly registration tags suffer fro m la rge diversity of word choices which leads to the semantic gap. To deal with these problems, this paper a ims to mine imp licit user interests from mic roblog contents, including posts, retweets and comments. We present a novel interest min ing me thod to extract and cluster users X  interest candidates based on phrase LDA mode l. Furthermore , we semi -auto matica lly construct a hierarchical interest knowledge base and utilize it to identify users X  interest category. As a result, we assign each microblo g user one or more interest labels (such as  X  X oving sports X ), which is different fro m prev ious approaches using non -uniform interest keywords (such as  X  X asketball X ,  X  X ennis X , etc.). Expe rimental results on SMP CUP 2016 dataset show that (a) phrase LDA gets good performance on mining reached 78% and 82% at best respectively.
 Keywords : M icroblog Analy sis , User Interests M ining , Phrase LDA , Knowled ge B ase thoughts , status and even their personal informat ion . As the continuously increasing of microblog user s, t he analysis o f user s  X  attribute s , relation s and behavior s has received more and mo re attention both in academic and industry. Specifically, microblog users X  interests can reflect users X  preference and also have a close relationship with users X  other attrib utes such as gender, age and occupation. Therefore , mode ling users  X  interests has important significance for getting more precise user profile , and can be useful for co mme rcia l applications such as personalized advertisement, or potential customer ana lysis. At present , the miss rate of user s  X  registration interest tag s is higher than 70% (Ding Yu xin et a l. , 2014) , wh ich means that most users X  implicit interest s should be learned . As an important data source, mic roblog content s involve personal preferences which di rect ly r e flect user interests. including Te xt Rank (T. Vu, 2013; Y. Tao, 2013; Mihalcea , 2004) and topic model (Zhao WX, 2011; Zhang Chenyi, 2011) . A lthough TextRan k is considered a state -of -the -art method for unsupervised keyword e xtraction, it ranks key words in a docu ment just using local features. In order to utilize global statistical characteristics in the document collection, and discover potential re lations between words describing the same topic, topic model has been widely used in user interest min ing recently. Co mpared to Te xt Rank, topic model can use potential topic structures in texts and handle high -sparsity short texts. And it would be helpful to take the most re lated topic of a user into consideration. However, these user interest min ing methods still face some challenges. On one hand, ext racted interest keywords may provide a a mbiguous representation of the topic. On the other hand, the topic model can obtain potential topics in texts, but e xplic it topic semantic labels are not given. microblog content s. Here, we use multi -wo rd phrases instead of keywords to represent user interest. Co mpared with words, phrases have clearer semantic information, and can e xpress a specific topic more intuitively and accurately. For examp le,  X  X ed apple X  an d  X  X pple 6 p lus X  respectively belong to different topics  X  X ood X  and  X  X lectronics X . This method contains two stages: (a) interest phrase mining algorith m a nd a phrase merging algorith m to mine candidate interest phrases. Microblog user interest phrases are clustered and further filtered by phrase -LDA. Secondly, we se mi -automat ically construct an interest knowledge base from open data sources, and identify us ers X  interest category combing topic distribution of their interest phrases and the world knowledge. microblog contents in Chinese. Expe rimental results show that the phrase LDA can achieve better results than traditional topic model on perple xity , and performs good on time co mple xity . The presision rate and the recall rate of user interest mining reached 78% and 82% at best respectively. TFIDF method, researchers e xtract the candidate words fr om mic ro blog content s and sort the wo rds according to the ir frequency , then pick out the Top -M words as the keywords to i ndicate user interest s (Salton et al., 1988) . Re searchers also try to use TextRank to build a word -based graph and use PageRank (Page et a l., 1998) to sort the candidat e keywords to e xtract the user s  X  in terest keywo rds, and get 31.2% p recision and recall rate of 43.1% ( M ihalcea et a l ., 2004) . So me resea rchers describe user s  X  interest s by using a set of tuple s of content directives (categories to which user interests belong) and action indicators (actions related to interest categories), wh ich can effect ively e xp lo it the re al -time interests of microblog u sers ( Banerjee et a l ., 2009) . Others consider the time distribution of micro blog content s and use th e time series to classify users X  content s ( Tao et a l ., 2013) . The prec ision rate of the classification is increased to 67%. These methods make use of the statisti cal properties or semantic informat ion of words in te xt . They have made some effects in min ing the inter est informat ion of microblog users, but they can  X  t make use of statistical features in documents and between documents , and can X  t solve the ambiguity pr oble m of interest word s either .
 space, and then use words  X  frequency to ex tract the hot topic, which ma k e s the hot t opic rank higher ( Zhang et al ., 2012) . Resea rchers also [15] use the aggregated info rmation to train the LDA model , and t he experimental results show that the model is mo r e suitable fo r the modeling of  X  aut hor -feature topic X  ( Ra mage et a l ., 2009) . So me researchers propose Twitter -LDA to filter the n on -hot topic words and compare the m with the distribution of hot topics in trad itional media ( Weng et al ., 2011) . They fin d t hat most of the topics in micro blog content s are ab out the daily life of users , which m ore reflect user s  X  personal interests. Others p ropose the MB -LDA model on the basis of LDA model, wh ich can extract hig her quality keywords from mic roblog content s to represent user s  X  interest s ( Z hang Chenyi et al ., 2011) . The above studies show that the top ic model can effic iently mine interest s from the sparse and short text such as microb log content s by using the distribution of words and topics in the text and the distribution of topics and documents. However, the e xisting work s only for the topic s of interest, but the semantic information of topics and t he categories of user interest s are not clearly identified. higher -quality interest p hrases from microblog content s and combine the mic roblog user interest knowledge b ase to identify the categories of microblog users X  interest s . segmented documents. The method is based on a ma in intuitive ass umption that  X  a high -quality interest phrase is composed of one or more frequent and continuous words. X  This metho d is divided minimu m support from the text as the initial set of candidate interest phrases ; then phrase filtering, name ly, using a phrase merge a lgorith m to filter these phrase s, and get the candidate interest phrases. Let w v v V  X  X  X  means that the i -th token in d -th document is the k -th word in the vocabulary. DEFINITION 1. A phrase is a sequence of one or more contiguous words: threshold. We draw upon two properties for efficiently min ing these frequent phrases. of our a lgorith m without searching through the prohibitively la rge candidate phrase space. We take an increasing -size slid ing window to generate candidate phrase s fro m documents, and count their frequency. In iteration k , for each document still in consideration, candidate phrases of length 1 k  X  are pruned if they do not satisfy the minim u m support threshold. Then the iteration is terminated and the document is re moved fro m the active indices. Th is condition provides a natural termination criterion for our algorithm. me rge algorith m to determine whether a candidate interest phrase sh ould be retained .
 occurrence of phrases, we consider a null hy pothesis, t hat the corpus is generated from a series of independent Bernoulli t ria ls. Under this hypot hesis, the presence or absence o f a phrase at a specific position in the corpus is a product of a Bernoulli random va riab le, and the e xpected number of occurrence of a phrase can be interpreted as a bino mia l random variable. Because the number of phrases L can be assumed to be fairly la rge, this binomial can be reasonably approximated by a norma l distribution. As such, the null hypothesis dist ribution for the rando m variab le () fP , the count of a phrase P within the corpus is: phrase in the corpus can be estimated as () () fP pP phrases phrases is: we can estimate the variance of the population using sample variance: phrase occurrence count.
 of two phrases. The significance score is as follo ws: occurrences under the null hypothesis . A high score means that th ese two phrases should be merg ed. sentence, we ad opt a bottom -up me rge method. For each iteration, a phras e pair with the h ighest score meet ing the threshold is merged, and the iteration terminates if a ll the phrases are merged together or the s ignificance scores between all the re ma ining t wo phrases do not meet the threshold. Merging occurs only in the same sentence, ma king the phrase is in line with the semantic ru les of the merger, so as to ensure the quality of the phrase after the merger. The phrase merge algorith m is shown in Ta bl e 1 . phrases that meet the threshold, so as to realize the phrase filtering function. which consist s of one or more wo rds that appear frequently, continuously and non -accidentally. Ne xt , on the basis of LDA model, we p ropose a phrase -based topic model for interest ph rase clustering . distribution over words in the vocabulary. The generative process is as follows: 1. Dra w ( ), 1, 2, , k Dir k K  X  X  X   X  2. For d -th document, where 1 2 , dD  X   X   X  : out { , }  X  X  X  , that is: collection of phrases, and we fo llo w the assumption that the wo rds in the sa me phrase are li ke ly to share the same topic , which we use a potential equ ation Fro m this we can define the joint distribution of a ll random variab les as: distribution. As with LDA, we can integrate out { , }  X  X  X  and get the simple form as follows: develop an effic ient gibbs sampling a lgorith m for this particula r choice. We sample a configuration for 
C fro m its posterior value k . Then we can get: users X  interest categories. It requires the support of external knowledge base. In order to acco mplish this goal more effective ly, we first construct the mic roblog user interest category knowledge base fro m open data source, then combine the topic phrase mining results to recognize users X  interests. an orthogonal and more co mplete microblog user interest ta xonomy . Based on a la rge nu mber of research, we construct a two -level interest taxonomy manually , as fa r as possible to cover microblog users X  main interests. The interest taxonomy is shown in Table 2.
 interest category knowledge base . In o rder to enrich our knowledge base, we co mbine two methods to build the knowledge base.
 websites ( such as douban, Sogou, etc. ) as the interest category keywords dire ctly in the knowledge base. S ome o ther key words t hat can represent a specific interest categor y, such as  X  X ce ball X ,  X  dunk  X , etc., are often needed to be further mined fro m the comp le x web content . For these keywords, we use the Text Rank to analyze the content of a sp ecific site, and select the top candidate word s as the interest category keywords. Through these two aspects of work, we can effectively build a mo re co mplete microblog user interest knowledge base. So me o f the keywords in the k nowledge b ase and the corres ponding target sites are shown in Table 3 .
 microblog users' interest phrases after clustering. We combine the distribution of phrases under the topic and the distribution of the phrases under the interest ca tegory to identify the categories of interest phrases.
 under topic z . F rom the microblog use r interest category knowledge base , we can get the probability distribution of phrase P under the inter est category , 0,1, , i i k  X  , we ma ke the fo llowing settings: microblog user interest category knowledge base, to achieve auto matic identificat ion of the categories of user interest phrase s .
 and 230000 microblog contents. T he data se t i s divided fro m a real Sina microblog data set in Ch inese , which containing about 46,000 users, more than 30 00000 0 mic roblog contents . interest phrase mining and interest phrase auto -identification in detail.
 method. Perple xity is an important measure o f the effectiveness of the topic model, the small er the category knowledge base the better. The expe rimental results are shown in Fig u re 1 .
 ou tperforms the standard LDA in the performance of perple xity . This indicates that the phrase based topic model performs better on the clustering eff ect of topic s . In addition, in order to verify the time efficiency of this algorith m, we conduct a time effic iency test for different scale of dataset. The runtime of candidate interest phrase mining and the phrase based topic model a re shown in Fig ure 2. method and the topic model method e xh ibit a nearly linear trend (log -leve l) at runtime, which indicat es that the algorith m has high time efficiency.
 to ensure precision of experimental results. We set the value of M a s 100 , a nd identify each topic which obtained fro m the phrase -LDA. By counting re cognition results of each topic, we can obtain the precision rate and the recall rate of mic roblog user interest category identif ication, as shown in the table 4 .
 recall rate of user interest category recognition, and has good perfor mance in film and television , music, g a me, entertain ment and shopping . This shows that our method can effectively identify the user interest categories. In addition, our method is not good in financia l, technological and social interest categor ies , ma inly due to that microblog user interest category knowledge b ase is not perfect . W e will improve it in our ne xt work . microblog user s . This method e xtrac ts high -quality interest phrase s fro m the user s  X  microb log contents by using the phrase based topic model, and realizes the automatic identification of the interest phrase s by constructing the microblog user interest category knowledge base. Through the e x perimental verification, we prove that our method has a good performance in the mic roblog user interest mining on precision and recall rate. In the ne xt step, in view o f the importance of microblog user interest category knowledge base for the accurate ide ntification of user interest categories, we consider to enrich the mic roblog user i nterest category knowledge base to further improve the performance of user interest mining.
 semi -supervised learning[J]. Journal on Co mmunication , 2014, 35(8): 15 -22.
 Francisco, CA, USA.
 interests using time series[C]. In : Proceedings of the 2013 IEEE/A CM International Conference on Advances in Social Networks and Mining. 2013: 684 -691.
 model[C]. China Co mmunicat ions, August 2014.
 on Emp irical Methods in Natural Language Processing . 2004 , 4 04 -41 1 .
 In: Advances in Information Retrieval, Springer. 2011:338 -349.
 Model[ J]. Journal of Co mputer Research and Develop ment, 2011, 48(10): 1795 -1802.
 Processint and Management, 1988, 24(5): 513 -523.
 web[J] . Technica l Report , Stanford Dig ital Libra ry Technologies Project , 1998.
 with mic ro -blogs[C]. In: Proce edings of the 18th ACM conference on Informat ion and knowledge manage ment. ACM , 2009: 1823 -1826.
 texts using world knowledge[C].In : Proceedings of the 18th ACM conference on In formation and knowledge manage ment. ACM, 2009: 919 -928.
 construction on the social web[C]. In : The Se mantic Wed: Research and Applications, Springer. 2011: 375 -389.
 knowledge[C]. In: Proceedings of the Twenty -Second international joint conference on Artifica l Intelligence -Volu me Vo lu me Three. 2011: 1866 -1871.
 Networking and Security(MINES), 2012 Fourth International Confe rence on IEEE. 2012: 922 -925. attribution in mu lti -labe led corpora [ C ] . In: Proceedings of the 2009 Conference on Emp irical Methods 
