 Models for the processes by which ideas and influence propagate through a social netw ork have been studied in a number of do-mains, including the dif fusion of medical and technological inno va-tions, the sudden and widespread adoption of various strate gies in game-theoretic settings, and the effects of  X  X  ord of mouth X  in the promotion of new products. Recently , moti vated by the design of viral mark eting strate gies, Domingos and Richardson posed a fun-damental algorithmic problem for such social netw ork processes: if we can try to con vince a subset of indi viduals to adopt a new product or inno vation, and the goal is to trigger a lar ge cascade of further adoptions, which set of indi viduals should we tar get?
We consider this problem in several of the most widely studied models in social netw ork analysis. The optimization problem of selecting the most influential nodes is NP-hard here, and we pro-vide the first pro vable approximation guarantees for efficient algo-rithms. Using an analysis frame work based on submodular func-tions, we sho w that a natural greedy strate gy obtains a solution that is pro vably within 63% of optimal for several classes of models; our frame work suggests a general approach for reasoning about the performance guarantees of algorithms for these types of influence problems in social netw orks.

We also pro vide computational experiments on lar ge collabora-tion netw orks, sho wing that in addition to their pro vable guaran-tees, our approximation algorithms significantly out-perform node-selection heuristics based on the well-studied notions of degree centrality and distance centrality from the field of social netw orks. F.2.2 [ Analysis of Algorithms and Pr oblem Complexity ]: Non-numerical Algorithms and Problems Supported by an Intel Graduate Fello wship and an NSF Graduate Research Fello wship. y
Supported in part by a Da vid and Lucile Packard Foundation Fel-lowship and NSF ITR/IM Grant IIS-0081334. z Supported in part by NSF ITR grant CCR-011337, and ONR grant N00014-98-1-0589.
 Cop yright 2003 ACM 1-58113-737-0/03/0008 ... $ 5.00.
 approximation algorithms, social netw orks, viral mark eting, dif fusion of inno vations
A social netw ork  X  the graph of relationships and interactions within a group of indi viduals  X  plays a fundamental role as a medium for the spread of information, ideas, and influence among its members. An idea or inno vation will appear  X  for example, the use of cell phones among colle ge students, the adoption of a new drug within the medical profession, or the rise of a political mo ve-ment in an unstable society  X  and it can either die out quickly or mak e significant inroads into the population. If we want to un-derstand the extent to which such ideas are adopted, it can be im-portant to understand how the dynamics of adoption are lik ely to unfold within the underlying social netw ork: the extent to which people are lik ely to be affected by decisions of their friends and colleagues, or the extent to which  X  X  ord-of-mouth X  effects will tak e hold. Such netw ork dif fusion processes have a long history of study in the social sciences. Some of the earliest systematic investigations focused on data pertaining to the adoption of medi-cal and agricultural inno vations in both developed and developing parts of the world [8, 27, 29]; in other conte xts, research has inves-tigated dif fusion processes for  X  X  ord-of-mouth X  and  X  X iral mark et-ing X  effects in the success of new products [4, 7, 10, 13, 14, 20, 26], the sudden and widespread adoption of various strate gies in game-theoretic settings [6, 12, 21, 32, 33], and the problem of cascading failures in power systems [2, 3].

In recent work, moti vated by applications to mark eting, Domin-gos and Richardson posed a fundamental algorithmic problem for such systems [10, 26]. Suppose that we have data on a social netw ork, with estimates for the extent to which indi viduals influ-ence one another , and we would lik e to mark et a new product that we hope will be adopted by a lar ge fraction of the netw ork. The premise of viral mark eting is that by initially tar geting a few  X  X nflu-ential X  members of the netw ork  X  say , giving them free samples of the product  X  we can trigger a cascade of influence by which friends will recommend the product to other friends, and man y in-dividuals will ultimately try it. But how should we choose the few key indi viduals to use for seeding this process? In [10, 26], this question was considered in a probabilistic model of interaction; heuristics were given for choosing customers with a lar ge overall effect on the netw ork, and methods were also developed to infer the influence data necessary for posing these types of problems.
In this paper , we consider the issue of choosing influential sets of indi viduals as a problem in discrete optimization. The optimal so-lution is NP-hard for most models that have been studied, including the model of [10]. The frame work proposed in [26], on the other hand, is based on a simple linear model where the solution to the optimization problem can be obtained by solving a system of linear equations. Here we focus on a collection of related, NP-hard mod-els that have been extensi vely studied in the social netw orks com-munity , and obtain the first pro vable approximation guarantees for efficient algorithms in a number of general cases. The generality of the models we consider lies between that of the polynomial-time solv able model of [26] and the very general model of [10], where the optimization problem cannot even be approximated to within a non-tri vial factor .

We begin by departing some what from the Domingos-Richardson frame work in the follo wing sense: where their models are essen-tially descriptive , specifying a joint distrib ution over all nodes X  be-havior in a global sense, we focus on more oper ational models from mathematical sociology [15, 28] and interacting particle sys-tems [11, 17] that explicitly represent the step-by-step dynamics of adoption. We sho w that approximation algorithms for maximiz-ing the spread of influence in these models can be developed in a general frame work based on submodular functions [9, 23]. We also pro vide computational experiments on lar ge collaboration net-works, sho wing that in addition to their pro vable guarantees, our al-gorithms significantly out-perform node-selection heuristics based on the well-studied notions of degree centr ality and distance cen-trality [30] from the field of social netw ork analysis. Two Basic Diffusion Models . In considering operational models for the spread of an idea or inno vation through a social netw ork G , represented by a directed graph, we will speak of each indi-vidual node as being either active (an adopter of the inno vation) or inactive . We will focus on settings, guided by the moti vation discussed abo ve, in which each node X  s tendenc y to become acti ve increases monotonically as more of its neighbors become acti ve. Also, we will focus for now on the progressive case in which nodes can switch from being inacti ve to being acti ve, but do not switch in the other direction; it turns out that this assumption can easily be lifted later . Thus, the process will look roughly as follo ws from the perspecti ve of an initially inacti ve node v : as time unfolds, more and more of v  X  X  neighbors become acti ve; at some point, this may cause v to become acti ve, and v  X  X  decision may in turn trigger fur -ther decisions by nodes to which v is connected.

Grano vetter and Schelling were among the first to propose mod-els that capture such a process; their approach was based on the use of node-specific thr esholds [15, 28]. Man y models of this flavor have since been investigated (see e.g. [5, 15, 18, 19, 21, 25, 28, 29, 31, 32, 33])b ut the follo wing Linear Thr eshold Model lies at the core of most subsequent generalizations. In this model, a node influenced by each neighbor w according to a weight b v;w as follo ws. Each node v chooses a thr eshold v uniformly at ran-dom from the interv al [0 ; 1] ; this represents the weighted fraction of v  X  X  neighbors that must become acti ve in order for v to become acti ve. Given a random choice of thresholds, and an initial set of acti ve nodes A 0 (with all other nodes inacti ve), the dif fusion pro-cess unfolds deterministically in discrete steps : in step that were acti ve in step t 1 remain acti ve, and we acti vate any node v for which the total weight of its acti ve neighbors is at least : Thus, the thresholds v intuiti vely represent the dif ferent latent ten-dencies of nodes to adopt the inno vation when their neighbors do; the fact that these are randomly selected is intended to model our lack of kno wledge of their values  X  we are in effect averaging over possible threshold values for all the nodes. (Another class of approaches hard-wires all thresholds at a kno wn value lik e for example work by Ber ger [5], Morris [21], and Pele g [25].)
Based on work in interacting particle systems [11, 17] from prob-ability theory , we can also consider dynamic cascade models for dif fusion processes. The conceptually simplest model of this type is what one could call the Independent Cascade Model , investi-gated recently in the conte xt of mark eting by Goldenber g, Libai, and Muller [13, 14]. We again start with an initial set of acti ve nodes A 0 , and the process unfolds in discrete steps according to the follo wing randomized rule. When node v first becomes acti ve in step t , it is given a single chance to acti vate each currently inac-tive neighbor w ; it succeeds with a probability p v;w  X  a parameter of the system  X  independently of the history thus far. (If multiple newly acti vated neighbors, their attempts are sequenced in an arbitrary order .) If v succeeds, then w will become acti ve in step t + 1 ; but whether or not v succeeds, it cannot mak e any further at-tempts to acti vate w in subsequent rounds. Again, the process runs until no more acti vations are possible.

The Linear Threshold and Independent Cascade Models are two of the most basic and widely-studied dif fusion models, but of course man y extensions can be considered. We will turn to this issue later in the paper , proposing a general frame work that simultaneously includes both of these models as special cases. For the sak e of con-creteness in the introduction, we will discuss our results in terms of these two models in particular .
 Appr oximation Algorithms for Influence Maximization . We are now in a position to formally express the Domingos-Richardson style of optimization problem  X  choosing a good initial set of nodes to tar get  X  in the conte xt of the abo ve models. Both the Linear Threshold and Independent Cascade Models (as well as the generalizations to follo w) involv e an initial set of acti ve nodes that start the dif fusion process. We define the influence of a set of nodes A , denoted ( A ) , to be the expected number of acti ve nodes at the end of the process, given that A is this initial acti ve set A 0 . The influence maximization problem asks, for a parameter k , to find a k -node set of maximum influence. (When dealing with algorithms for this problem, we will say that the chosen set k initial acti ve nodes has been tar geted for acti vation by the algo-rithm.) For the models we consider , it is NP-hard to determine the optimum for influence maximization, as we will sho w later .
Our first main result is that the optimal solution for influence maximization can be efficiently approximated to within a factor of (1 1 =e " ) , in both the Linear Threshold and Independent Cascade models; here e is the base of the natural logarithm and " is any positi ve real number . (Thus, this is a performance guar -antee slightly better than 63% .) The algorithm that achie ves this performance guarantee is a natural greedy hill-climbing strate gy related to the approach considered in [10], and so the main con-tent of this result is the analysis frame work needed for obtaining a pro vable performance guarantee, and the fairly surprising fact that hill-climbing is always within a factor of at least 63% of optimal for this problem. We pro ve this result in Section 2 using techniques from the theory of submodular functions [9, 23], which we describe in detail belo w, and which turn out to pro vide a natural conte xt for reasoning about both models and algorithms for influence maxi-mization.

In fact, this analysis frame work allo ws us to design and pro ve guarantees for approximation algorithms in much richer and more realistic models of the processes by which we mark et to nodes. The deterministic acti vation of indi vidual nodes is a highly simplified model; an issue also considered in [10, 26] is that we may in reality have a lar ge number of dif ferent mark eting actions available, each of which may influence nodes in dif ferent ways. The available bud-get can be divided arbitrarily between these actions. We sho w how to extend the analysis to this substantially more general frame work. Our main result here is that a generalization of the hill-climbing al-gorithm still pro vides approximation guarantees arbitrarily close to (1 1 =e ) .

It is worth briefly considering the general issue of performance guarantees for algorithms in these settings. For both the Linear Threshold and the Independent Cascade models, the influence max-imization problem is NP-complete, but it can be approximated well. In the linear model of Richardson and Domingos [26], on the other hand, both the propagation of influence as well as the effect of the initial tar geting are linear . Initial mark eting decisions here are thus limited in their effect on node acti vations; each node X  s probability of acti vation is obtained as a linear combination of the effect of tar -geting and the effect of the neighbors. In this fully linear model, the influence can be maximized by solving a system of linear equa-tions. In contrast, we can sho w that general models lik e that of Domingos and Richardson [10], and even simple models that build in a fix ed threshold (lik e 1 = 2 ) at all nodes [5, 21, 25], lead to influ-ence maximization problems that cannot be approximated to within any non-tri vial factor , assuming P 6 = NP. Our analysis of approx-imability thus suggests a way of tracing out a more delicate bound-ary of tractability through the set of possible models, by helping to distinguish among those for which simple heuristics pro vide strong performance guarantees and those for which the y can be arbitrarily far from optimal. This in turn can suggest the development of both more powerful algorithms, and the design of accurate models that simultaneously allo w for tractable optimization.

Follo wing the approximation and NP-hardness results, we de-scribe in Section 3 the results of computational experiments with both the Linear Threshold and Independent Cascade Models, sho w-ing that the hill-climbing algorithm significantly out-performs strate-gies based on tar geting high-de gree or  X  X entral X  nodes [30]. In Sec-tion 4 we then develop a general model of dif fusion processes in social netw orks that simultaneously generalizes the Linear Thresh-old and Independent Cascade Models, as well as a number of other natural cases, and we sho w how to obtain approximation guaran-tees for a lar ge sub-class of these models. In Sections 5 and 6, we also consider extensions of our approximation algorithms to mod-els with more realistic scenarios in mind: more comple x mark et-ing actions as discussed abo ve, and non-pr ogressive processes, in which acti ve nodes may become inacti ve in subsequent steps. The overall appr oach . We begin by describing our strate gy for pro ving approximation guarantees. Consider an arbitrary function f ( ) that maps subsets of a finite ground set U to non-ne gati ve real numbers. 1 We say that f is submodular if it satisfies a natural  X  X i-minishing returns X  property: the mar ginal gain from adding an ele-ment to a set S is at least as high as the mar ginal gain from adding 1 Note that the influence function ( ) defined abo ve has this form; it maps each subset A of the nodes of the social netw ork to a real number denoting the expected size of the acti vated set if geted for initial acti vation. the same element to a superset of S . Formally , a submodular func-tion satisfies for all elements v and all pairs of sets S T .

Submodular functions have a number of very nice tractability properties; the one that is rele vant to us here is the follo wing. Sup-pose we have a function f that is submodular , tak es only non-negati ve values, and is monotone in the sense that adding an ele-ment to a set cannot cause f to decrease: f ( S [ f v g ) f ( S ) for all elements v and sets S . We wish to find a k -element set for which f ( S ) is maximized. This is an NP-hard optimization problem (it can be sho wn to contain the Hitting Set problem as a simple special case), but a result of Nemhauser , Wolse y, and Fisher [9, 23] sho ws that the follo wing greedy hill-climbing algorithm ap-proximates the optimum to within a factor of (1 1 =e ) (where is the base of the natural logarithm): start with the empty set, and repeatedly add an element that gives the maximum mar ginal gain.
T HEOREM 2.1. [9, 23] For a non-ne gative , monotone submod-ular function f , let S be a set of size k obtained by selecting ele-ments one at a time , eac h time choosing an element that provides the lar gest mar ginal incr ease in the function value . Let set that maximizes the value of f over all k -element sets. Then f ( S ) (1 1 =e ) f ( S ) ; in other wor ds, S provides a appr oximation.

Due to its generality , this result has found applications in a num-ber of areas of discrete optimization (see e.g. [22]); the only direct use of it that we are aware of in the databases and data mining lit-erature is in a conte xt very dif ferent from ours, for the problem of selecting database vie ws to materialize [16].

Our strate gy will be to sho w that for the models we are consid-ering, the resulting influence function ( ) is submodular . A subtle dif ficulty lies in the fact that the result of Nemhauser et al. assumes that the greedy algorithm can evaluate the underlying function ex-actly , which may not be the case for the influence function Ho we ver, by simulating the dif fusion process and sampling the re-sulting acti ve sets, we are able to obtain arbitrarily close approxi-mations to ( A ) , with high probability . Furthermore, one can ex-tend the result of Nemhauser et al. to sho w that for any is a &gt; 0 such that by using (1 + ) -approximate values for the function to be optimized, we obtain a (1 1 =e " ) -approximation.
As mentioned in the introduction, we can extend this analysis to a general model with more comple x mark eting actions that can have a probabilistic effect on the initial acti vation of nodes. We sho w in Section 6 how, with a more careful hill-climbing algorithm and a generalization of Theorem 2.1, we can obtain comparable approximation guarantees in this setting.

A further extension is to assume that each node v has an asso-ciated non-ne gati ve weight w v , capturing how important it is that v be acti vated in the final outcome. (For instance, if we are mar -keting textbooks to colle ge teachers, then the weight could be the number of students in the teacher X  s class, resulting in a lar ger or smaller number of sales.) If we let B denote the (random) set ac-tivated by the process with initial acti vation A , then we can define the weighted influence function w ( A ) to be the expected value over outcomes B of the quantity P tion studied abo ve is the special case obtained by setting for all nodes v . The objecti ve function with weights is submodular whene ver the unweighted version is, so we can still use the greedy algorithm for obtaining a (1 1 =e " ) -approximation. Note, how-ever, that a sampling algorithm to approximately choose the next element may need time that depends on the sizes of the weights. In vie w of the abo ve discussion, an approximation guarantee for influence maximization in the Independent Cascade Model will be a consequence of the follo wing T HEOREM 2.2. For an arbitr ary instance of the Independent Cascade Model, the resulting influence function ( ) is submodu-lar .

In order to establish this result, we need to look, implicitly or explicitly , at the expression ( A [ f v g ) ( A ) , for arbitrary sets A and elements v . In other words, what increase do we get in the expected number of overall acti vations when we add v to the set A ? This increase is very dif ficult to analyze directly , because it is hard to work with quantities of the form ( A ) . For example, the Independent Cascade process is underspecified, since we have not prescribed the order in which newly acti vated nodes in a given step t will attempt to acti vate their neighbors. Thus, it is not initially obvious that the process is even well-defined, in the sense that it yields the same distrib ution over outcomes regardless of how we schedule the attempted acti vations.

Our proof deals with these dif ficulties by formulating an equi v-alent vie w of the process, which mak es it easier to see that there is an order -independent outcome, and which pro vides an alternate way to reason about the submodularity property .

Consider a point in the cascade process when node v has just be-come acti ve, and it attempts to acti vate its neighbor w with probability p v;w . We can vie w the outcome of this random event as being determined by flipping a coin of bias p v;w point of vie w of the process, it clearly does not matter whether the coin was flipped at the moment that v became acti ve, or whether it was flipped at the very beginning of the whole process and is only being revealed now. Continuing this reasoning, we can in fact as-sume that for eac h pair of neighbors ( v; w ) in the graph, a coin of bias p v;w is flipped at the very beginning of the process (indepen-dently of the coins for all other pairs of neighbors), and the result is stored so that it can be later check ed in the event that while w is still inacti ve.

With all the coins flipped in adv ance, the process can be vie wed as follo ws. The edges in G for which the coin flip indicated an acti vation will be successful are declared to be live ; the remaining edges are declared to be bloc ked . If we fix the outcomes of the coin flips and then initially acti vate a set A , it is clear how to determine the full set of acti ve nodes at the end of the cascade process:
C LAIM 2.3. A node x ends up active if and only if ther e is a path from some node in A to x consisting entir ely of live edg es. (W e will call suc h a path a live-edge path .)
Consider the probability space in which each sample point spec-ifies one possible set of outcomes for all the coin flips on the edges. Let X denote one sample point in this space, and define X be the total number of nodes acti vated by the process when the set initially tar geted, and X is the set of outcomes of all coin flips on edges. Because we have fix ed a choice for X , X fact a deterministic quantity , and there is a natural way to express its value, as follo ws. Let R ( v; X ) denote the set of all nodes that can be reached from v on a path consisting entirely of live edges. By Claim 2.3, X ( A ) is the number of nodes that can be reached on live-edge paths from any node in A , and so it is equal to the cardinality of the union [ v 2 A R ( v; X ) .
 Pr oof of Theor em 2.2. First, we claim that for each fix ed out-come X , the function X ( ) is submodular . To see this, let T be two sets of nodes such that S T , and consider the quantity X ( S [ f v g ) X ( S ) . This is the number of elements in as the number of elements in R ( v; X ) that are not in the (bigger) union [ u 2 T R ( u; X ) . It follo ws that X ( S [ f v g )
X ( T [ f v g ) X ( T ) , which is the defining inequality for sub-modularity . Finally , we have since the expected number of nodes acti vated is just the weighted average over all outcomes. But a non-ne gati ve linear combination of submodular functions is also submodular , and hence ( ) modular , which concludes the proof.
 Ne xt we sho w the hardness of influence maximization.

T HEOREM 2.4. The influence maximization problem is NP-har d for the Independent Cascade model.
 Pr oof . Consider an instance of the NP-complete Set Co ver prob-lem, defined by a collection of subsets S 1 ; S 2 ; : : : ; S set U = f u 1 ; u 2 ; : : : ; u n g ; we wish to kno w whether there exist k of the subsets whose union is equal to U . (W e can assume that k &lt; n &lt; m: ) We sho w that this can be vie wed as a special case of the influence maximization problem.

Given an arbitrary instance of the Set Co ver problem, we define a corresponding directed bipartite graph with n + m nodes: there is a node i corresponding to each set S i , a node j corresponding to each element u j , and a directed edge ( i; j ) with acti vation prob-ability p i;j = 1 whene ver u j 2 S i . The Set Co ver problem is equi valent to deciding if there is a set A of k nodes in this graph with ( A ) n + k . Note that for the instance we have defined, acti vation is a deterministic process, as all probabilities are 0 or 1. Initially acti vating the k nodes corresponding to sets in a Set Co ver solution results in acti vating all n nodes corresponding to the ground set U , and if any set A of k nodes has ( A ) n + k then the Set Co ver problem must be solv able.
 We now pro ve an analogous result for the Linear Threshold Model.
T HEOREM 2.5. For an arbitr ary instance of the Linear Thr esh-old Model, the resulting influence function ( ) is submodular . Pr oof . The analysis is a bit more intricate than in the proof of The-orem 2.2, but the overall argument has a similar structure. In the proof of Theorem 2.2, we constructed an equi valent process by ini-tially resolving the outcomes of some random choices, considering each outcome in isolation, and then averaging over all outcomes. For the Linear Threshold Model, the simplest analogue would be to consider the beha vior of the process after all node thresholds have been chosen. Unfortunately , for a fix ed choice of thresholds, the number of acti vated nodes is not in general a submodular function of the tar geted set; this fact necessitates a more subtle analysis.
Recall that each node v has an influence weight b v;w 0 from each of its neighbors w , subject to the constraint that P (W e can extend the notation by writing b v;w = 0 when w is not a neighbor of v .) Suppose that v picks at most one of its incoming edges at random, selecting the edge from w with probability and selecting no edge with probability 1 P edge is declared to be  X  X ive, X  and all other edges are declared to be  X  X lock ed.  X  (Note the contrast with the proof of Theorem 2.2: there, we determined whether an edge was live independently of the decision for each other edge; here, we negati vely correlate the decisions so that at most one live edge enters each node.)
The crux of the proof lies in establishing Claim 2.6 belo w, which asserts that the Linear Threshold model is equi valent to reachabil-ity via live-edge paths as defined abo ve. Once that equi valence is established, submodularity follo ws exactly as in the proof of The-orem 2.2. We can define R ( v; X ) as before to be the set of all nodes reachable from v on live-edge paths, subject to a choice of live/block ed designations for all edges; it follo ws that the cardinality of the union [ v 2 A R ( v; X ) , and hence a submodu-lar function of A ; finally , the function ( ) is a non-ne gati ve linear combination of the functions X ( ) and hence also submodular .
C LAIM 2.6. For a given tar geted set A , the following two dis-trib utions over sets of nodes are the same: (i) The distrib ution over active sets obtained by running the Lin-(ii) The distrib ution over sets reac hable from A via live-edg e paths, Pr oof . We need to pro ve that reachability under our random choice of live and block ed edges defines a process equi valent to that of the Linear Threshold Model. To obtain intuition about this equi v-alence, it is useful to first analyze the special case in which the underlying graph G is directed and acyclic. In this case, we can fix a topological ordering of the nodes v 1 ; v 2 ; : : : ; v go from earlier nodes to later nodes in the order), and build up the distrib ution of acti ve sets by follo wing this order . For each node suppose we already have determined the distrib ution over acti ve subsets of its neighbors. Then under the Linear Threshold process, the probability that v i will become acti ve, given that a subset of its neighbors is acti ve, is P probability that the live incoming edge selected by v i lies in and so inducti vely we see that the two processes define the same distrib ution over acti ve sets.

To pro ve the claim generally , consider a graph G that is not acyclic. It becomes trickier to sho w the equi valence, because there is no natural ordering of the nodes over which to perform induc-tion. Instead, we argue by induction over the iterations of the Lin-ear Threshold process. We define A t to be the set of acti ve nodes at the end of iteration t , for t = 0 ; 1 ; 2 ; : : : (note that initially tar geted). If node v has not become acti ve by the end of iteration t , then the probability that it becomes acti ve in iteration t + 1 is equal to the chance that the influence weights in push it over its threshold, given that its threshold was not exceeded already; this probability is
On the other hand, we can run the live-edge process by revealing the identities of the live edges gradually as follo ws. We start with the tar geted set A . For each node v with at least one edge from the set A , we determine whether v  X  X  live edge comes from A . If so, then v is reachable; but if not, we keep the source of v  X  X  live edge unkno wn, subject to the condition that it comes from outside Ha ving now exposed a new set of reachable nodes A 0 stage, we proceed to identify further reachable nodes by perform-ing the same process on edges from A 0 sets A 0 by the end of stage t , then the probability that it is determined to be reachable in stage t + 1 is equal to the chance that its live edge comes from A t n A t 1 , given that its live edge has not come from any of the earlier sets. But this is same as in the Linear Threshold process of the pre vious paragraph. Thus, by induction over these stages, we see that the live-edge pro-cess produces the same distrib ution over acti ve sets as the Linear Threshold process.
 Influence maximization is hard in this model as well.

T HEOREM 2.7. The influence maximization problem is NP-har d for the Linear Thr eshold model.
 Pr oof . Consider an instance of the NP-complete Verte x Co ver prob-lem defined by an undirected n -node graph G = ( V; E ) and an in-teger k ; we want to kno w if there is a set S of k nodes in every edge has at least one endpoint in S . We sho w that this can be vie wed as a special case of the influence maximization problem. Given an instance of the Verte x Co ver problem involving a graph G , we define a corresponding instance of the influence maximiza-tion problem by directing all edges of G in both directions. If there is a verte x cover S of size k in G , then one can deterministically mak e ( A ) = n by tar geting the nodes in the set A = S ; con-versely , this is the only way to get a set A with ( A ) = n
In the proofs of both the approximation theorems in this section, we established submodularity by considering an equi valent process in which each node  X  X ard-wired X  certain of its incident edges as transmitting influence from neighbors. This turns out to be a proof technique that can be formulated in general terms, and directly ap-plied to give approximability results for other models as well. We discuss this further in the conte xt of the general frame work pre-sented in Section 4.
In addition to obtaining worst-case guarantees on the perfor -mance of our approximation algorithm, we are interested in under -standing its beha vior in practice, and comparing its performance to other heuristics for identifying influential indi viduals. We find that our greedy algorithm achie ves significant performance gains over several widely-used structural measures of influence in social netw orks [30].
 The Netw ork Data . For evaluation, it is desirable to use a netw ork dataset that exhibits man y of the structural features of lar ge-scale social netw orks. At the same time, we do not address the issue of inferring actual influence parameters from netw ork observ ations (see e.g. [10, 26]). Thus, for our testbed, we emplo y a collabo-ration graph obtained from co-authorships in physics publications, with simple settings of the influence parameters. It has been argued extensi vely that co-authorship netw orks capture man y of the key features of social netw orks more generally [24]. The co-authorship data was compiled from the complete list of papers in the high-ener gy physics theory section of the e-print arXi v (www .arxi v.or g). 2
The collaboration graph contains a node for each researcher who has at least one paper with co-author(s) in the arXi v database. For each paper with two or more authors, we inserted an edge for each pair of authors (single-author papers were ignored). Notice that this results in parallel edges when two researchers have co-authored multiple papers  X  we kept these parallel edges as the y can be in-terpreted to indicate stronger social ties between the researchers involv ed. The resulting graph has 10748 nodes, and edges between about 53000 pairs of nodes. 2 We also ran experiments on the co-authorship graphs induced by theoretical computer science papers. We do not report on the results here, as the y are very similar to the ones for high-ener gy physics.
While processing the data, we corrected man y common types of mistak es automatically or manually . In order to deal with aliasing problems at least partially , we abbre viated first names, and unified spellings for foreign characters. We belie ve that the resulting graph is a good approximation to the actual collaboration graph (the sheer volume of data prohibits a complete manual cleaning pass). The Influence Models . We compared the algorithms in three dif-ferent models of influence. In the linear threshold model, we treated the multiplicity of edges as weights. If nodes u; v have c edges between them, and degrees d u and d v , then the edge
In the independent cascade model, we assigned a uniform proba-bility of p to each edge of the graph, choosing p to be 1% in separate trials. If nodes u and v have c u;v parallel edges, then we assume that for each of those c u;v edges, u has a chance of to acti vate v , i.e. u has a total probability of 1 (1 p ) acti vating v once it becomes acti ve.

The independent cascade model with uniform probabilities p the edges has the property that high-de gree nodes not only have a chance to influence man y other nodes, but also to be influenced by them. Whether or not this is a desirable interpretation of the influence data is an application-specific issue. Moti vated by this, we chose to also consider an alternati ve interpretation, where edges into high-de gree nodes are assigned smaller probabilities. We study a special case of the Independent Cascade Model that we term  X  X eighted cascade X , in which each edge from node u to v is as-signed probability 1 =d v of acti vating v . The weighted cascade model resembles the linear threshold model in that the expected number of neighbors who would succeed in acti vating a node 1 in both models.
 The algorithms and implementation . We compare our greedy algorithm with heuristics based on nodes X  degrees and centrality within the netw ork, as well as the crude baseline of choosing ran-dom nodes to tar get. The degree and centrality-based heuristics are commonly used in the sociology literature as estimates of a node X  s influence [30].

The high-de gree heuristic chooses nodes v in order of decreasing degrees d v . Considering high-de gree nodes as influential has long been a standard approach for social and other netw orks [30, 1], and is kno wn in the sociology literature as  X  X e gree centrality X .  X  X istance centrality X  is another commonly used influence mea-sure in sociology , building on the assumption that a node with short paths to other nodes in a netw ork will have a higher chance of influ-encing them. Hence, we select nodes in order of increasing average distance to other nodes in the netw ork. As the arXi v collaboration graph is not connected, we assigned a distance of n  X  the number of nodes in the graph  X  for any pair of unconnected nodes. This value is significantly lar ger than any actual distance, and thus can be considered to play the role of an infinite distance. In particu-lar , nodes in the lar gest connected component will have smallest average distance.

Finally , we consider , as a baseline, the result of choosing nodes uniformly at random. Notice that because the optimization problem is NP-hard, and the collaboration graph is prohibiti vely lar ge, we cannot compute the optimum value to verify the actual quality of approximations.

Both in choosing the nodes to tar get with the greedy algorithm, and in evaluating the performance of the algorithms, we need to compute the value ( A ) . It is an open question to compute this quantity exactly by an efficient method, but very good estimates can be obtained by simulating the random process. More specif-ically , we simulate the process 10000 times for each tar geted set, re-choosing thresholds or edge outcomes pseudo-randomly from [0 ; 1] every time. Pre vious runs indicate that the quality of approx-imation after 10000 iterations is comparable to that after 300000 or more iterations.
 The results . Figure 1 sho ws the performance of the algorithms in the linear threshold model. The greedy algorithm outperforms the high-de gree node heuristic by about 18% , and the central node heuristic by over 40% . (As expected, choosing random nodes is not a good idea.) This sho ws that significantly better mark eting results can be obtained by explicitly considering the dynamics of information in a netw ork, rather than relying solely on structural properties of the graph.
When investigating the reason why the high-de gree and central-ity heuristics do not perform as well, one sees that the y ignore such netw ork effects. In particular , neither of the heuristics incorporates the fact that man y of the most central (or highest-de gree) nodes may be clustered, so that tar geting all of them is unnecessary . In fact, the une ven nature of these curv es suggests that the netw ork influence of man y nodes is not accurately reflected by their degree or centrality .

Figure 2 sho ws the results for the weighted cascade model. No-tice the striking similarity to the linear threshold model. The scale is slightly dif ferent (all values are about 25% smaller), but the beha vior is qualitati vely the same, even with respect to the exact nodes whose netw ork influence is not reflected accurately by their degree or centrality . The reason is that in expectation, each node is influenced by the same number of other nodes in both models (see Section 2), and the degrees are relati vely concentrated around their expectation of 1 .

The graph for the independent cascade model with probability 1% , given in Figure 3, seems very similar to the pre vious two at first glance. Notice, howe ver, the very dif ferent scale: on average, each tar geted node only acti vates three additional nodes. Hence, the netw ork effects in the independent cascade model with very small probabilities are much weak er than in the other models. Sev-eral nodes have degrees well exceeding 100, so the probabilities on their incoming edges are even smaller than 1% in the weighted cascade model. This suggests that the netw ork effects observ ed for the linear threshold and weighted cascade models rely hea vily on low-de gree nodes as multipliers, even though tar geting high-de gree nodes is a reasonable heuristic. Also notice that in the independent cascade model, the heuristic of choosing random nodes performs significantly better than in the pre vious two models. Figur e 3: Independent cascade model with probability 1%
The impro vement in performance of the  X  X andom nodes X  heuris-tic is even more pronounced for the independent cascade model with probabilities equal to 10% , depicted in Figure 4. In that model, it starts to outperform both the high-de gree and the central nodes heuristics when more than 12 nodes are tar geted. It is initially sur -prising that random tar geting for this model should lead to more acti vations than centrality-based tar geting, but in fact there is a nat-ural underlying reason that we explore now.

The first tar geted node, if chosen some what judiciously , will ac-tivate a lar ge fraction of the netw ork, in our case almost Ho we ver, any additional nodes will only reach a small additional fraction of the netw ork. In particular , other central or high-de gree nodes are very lik ely to be acti vated by the initially chosen one, and thus have hardly any mar ginal gain. This explains the shapes of the curv es for the high-de gree and centrality heuristics, which leap up to about 2415 acti vated nodes, but mak e virtually no progress after -wards. The greedy algorithm, on the other hand, tak es the effect of the first chosen node into account, and tar gets nodes with smaller
Figur e 4: Independent cascade model with probability 10% mar ginal gain afterw ards. Hence, its acti ve set keeps gro wing, al-though at a much smaller slope than in other models.

The random heuristic does not do as well initially as the other heuristics, but with suf ficiently man y attempts, it eventually hits some highly influential nodes and becomes competiti ve with the centrality-based node choices. Because it does not focus exclu-sively on central nodes, it eventually tar gets nodes with additional mar ginal gain, and surpasses the two centrality-based heuristics. General Thr eshold and Cascade Models . We have thus far been considering two specific, widely studied models for the dif fusion of influence. We now propose a broader frame work that simulta-neously generalizes these two models, and allo ws us to explore the limits of models in which strong approximation guarantees can be obtained. Our general frame work has equi valent formulations in terms of thresholds and cascades, thereby unifying these two vie ws of dif fusion through a social netw ork.

These two models are equi valent, and we give a method to con-vert between them. First, consider an instance of the general thresh-old model with threshold functions f v . To define an equi valent cascade model, we need to understand the probability that an ad-ditional neighbor u can acti vate v , given that the nodes in a set have already tried and failed. If the nodes in S have failed, then node v  X  X  threshold v must be in the range v 2 ( f v ( S ) ; 1] ever, subject to this constraint, it is uniformly distrib uted.Thus, the probability that a neighbor u = 2 S succeeds in acti vating that the nodes in S have failed, is It is not dif ficult to sho w that the cascade process with these func-tions is equi valent to the original threshold process.
 Con versely , consider a node v in the cascade model, and a set S = f u 1 ; : : : ; u k g of its neighbors. Assume that the nodes in to acti vate v in the order u 1 ; : : : ; u k , and let S Then the probability that v is not acti vated by this process is by def-inition Q k order in which the u i try to acti vate v does not affect their overall success probability . Hence, this value depends on the set and we can define f v ( S ) = 1 Q k ogously , one can sho w that this instance of the threshold model is equi valent to the original cascade process.
 An Inappr oximability Result . The general model proposed abo ve includes lar ge families of instances for which the influence function ( ) is not submodular . Indeed, it may become NP-hard to approx-imate the optimization problem to within any non-tri vial factor .
T HEOREM 4.1. In gener al, it is NP-har d to appr oximate the in-fluence maximization problem to within a factor of n 1 " , for any " &gt; 0 .
 Pr oof . To pro ve this result, we reduce from the Set Co ver prob-lem. We start with the construction from the proof of Theorem 2.4, letting u 1 ; : : : ; u n denote the nodes corresponding to the elements; i.e. u i becomes acti ve when at least one of the nodes cor -responding to sets containing u i is acti ve. Ne xt, for an arbitrarily lar ge constant c , we add N = n c more nodes x 1 ; : : : ; x is connected to all of the nodes u i , and it becomes acti ve only when all of the u i are.

If there are at most k sets that cover all elements, then acti vating the nodes corresponding to these k sets will acti vate all of the nodes u , and thus also all of the x j . In total, at least N + n + k will be acti ve. Con versely , if there is no set cover of size no tar geted set will acti vate all of the u i , and hence none of the will become acti ve (unless tar geted). In particular , fewer than nodes are acti ve in the end. If an algorithm could approximate the problem within n 1 " for any " , it could distinguish between the cases where N + n + k nodes are acti ve in the end, and where fewer than n + k are. But this would solv e the underlying instance of Set Co ver, and therefore is impossible assuming P 6 =
Note that our inapproximability result holds in a very simple model, in which each node is  X  X ard-wired X  with a fix ed threshold. Exploring the Boundaries of Appr oximability . Thus, the gen-eral threshold and cascade models are too broad to allo w for non-trivial approximation guarantees in their full generality . At the same time, we have seen that the greedy algorithm achie ves strong guarantees for some of the main special cases in the social netw orks literature. Ho w far can we extend these approximability results?
We can generalize the proof technique used in Theorems 2.2 and 2.5 to a model that is less general (and also less natural) than the general threshold and cascade models; howe ver, it includes our spe-cial cases from Section 2, and every instance of this model will have a submodular influence function. The model is as follo ws. It is useful to think of the triggering sets in terms of  X  X ive X  and  X  X lock ed X  edges: if node u belongs to the triggering set then we declare the edge ( u; v ) to be live, and otherwise we declare it to be block ed. As in the proofs of Theorems 2.2 and 2.5, a node v is acti vated in an instance of the Triggering Model if and only if there is a live-edge path from the initially tar geted set Follo wing the arguments in these proofs, we obtain the follo wing
T HEOREM 4.2. In every instance of the Trig gering Model, the influence function ( ) is submodular .

Be yond the Independent Cascade and Linear Threshold, there are other natural special cases of the Triggering Model. One ex-ample is the  X  X nly-Listen-Once X  Model. Here, each node v has a parameter p v so that the first neighbor of v to be acti vated causes to become acti ve with probability p v , and all subsequent attempts to acti vate v deterministically fail. (In other words, v to the first neighbor that tries to acti vate it.) This process has an equi valent formulation in the Triggering Set Model, with an edge distrib ution defined as follo ws: for any node v , the triggering set T v is either the entire neighbor set of v (with probability the empty set otherwise. As a result, the influence function in the Only-Listen-Once Model is also submodular , and we can obtain a (1 1 =e " ) -approximation here as well.

Ho we ver, we can sho w that there exist models with submodu-lar influence functions that do not have equi valent formulations in terms of triggering sets, so it mak es sense to seek further models in which submodularity holds.

One tractable special case of the cascade model is based on the natural restriction that the probability of a node u influencing non-increasing as a function of the set of nodes that have pre viously tried to influence v . In terms of the cascade model, this means that p ( u; S ) p v ( u; T ) whene ver S T . We say that a process sat-isfying these conditions is an instance of the Decr easing Cascade Model . Although there are natural Decreasing Cascade instances that have no equi valent formulation in terms of triggering sets, we can sho w by a more intricate analysis that every instance of the De-creasing Cascade Model has a submodular influence function. We will include details of this proof in the full version of the paper . A Conjectur e . Finally , we state an appealing conjecture that would include all the approximability results abo ve as special cases.
C ONJECTURE 4.3. Whene ver the thr eshold functions f v at ev-ery node are monotone and submodular , the resulting influence function ( ) is monotone and submodular as well.
 It is not dif ficult to sho w that every instance of the Triggering Model has an equi valent formulation with submodular node thresh-olds. Ev ery instance of the Decreasing Cascade Model has such an equi valent formulation as well; in fact, the Decreasing Cascade condition stands as a very natural special case of the conjecture, given that it too is based on a type of  X  X iminishing returns.  X  When translated into the language of threshold functions, we find that the Decreasing Cascade condition corresponds to the follo wing natural requirement: whene ver S T and u = 2 T . This is in a sense a  X  X ormalized submodularity X  property; it is stronger than submodularity , which would consist of the same inequality on just the numerators. (Note that by monotonicity , the denominator on the left is lar ger .)
We have thus far been concerned with the progressive case, in which nodes only go from inacti vity to acti vity , but not vice versa. The non-pr ogressive case, in which nodes can switch in both direc-tions, can in fact be reduced to the progressi ve case.

The non-progressi ve threshold process is analogous to the pro-gressi ve model, except that at each step t , each node v new value ( t ) v uniformly at random from the interv al [0 ; 1] v will be acti ve in step t if f v ( S ) ( t ) v , where S neighbors of v that are acti ve in step t 1 .

From the perspecti ve of influence maximization, we can ask the follo wing question. Suppose we have a non-progressi ve model that is going to run for steps, and during this process, we are allo wed to mak e up to k interventions : for a particular node v , at a particular time t , we can tar get v for acti vation at time t . ( v quickly de-acti vate, but we hope to create a lar ge  X  X ipple effect.  X ) Which k interv entions should we perform? Simple examples sho w that to maximize influence, one should not necessarily perform all k interv entions at time 0 ; e.g., G may not even have k nodes.
Let A be a set of k interv entions. The influence of these ventions ( A ) is the sum, over all nodes v , of the number of time steps that v is acti ve. The influence maximization problem in the non-progressi ve threshold model is to find the k interv entions with maximum influence.

We can sho w that the non-progressi ve influence maximization problem reduces to the progressi ve case in a dif ferent graph. Given a graph G = ( V; E ) and a time limit , we build a layered graph G on j V j nodes: there is a cop y v t for each node v in each time-step t . We connect each node in this graph with its neighbors in G inde xed by the pre vious time step.

T HEOREM 5.1. The non-pr ogressive influence maximization prob-lem on G over a time horizon is equivalent to the progressive in-fluence maximization problem on the layer ed graph G . Node active at time t in the non-pr ogressive process if and only if activated in the progressive process.

Thus, models where we have approximation algorithms for the progressi ve case carry over. Theorem 5.1 also implies approxima-tion results for certain non-progressi ve models used by Asa vathi-ratham et al. to model cascading failures in power grids [2, 3].
Note that the non-progressi ve model discussed here dif fers from the model of Domingos and Richardson [10, 26] in two ways. We are concerned with the sum over all time steps t of the ex-pected number of acti ve nodes at time t , for a given a time limit , while [10, 26] study the limit of this process: the expected number of nodes acti ve at time t as t goes to infinity . Further , we consider interv entions for a particular node v , at a particular time while the interv entions considered by [10, 26] permanently affect the acti vation probability function of the tar geted nodes.
In the formulation of the problem, we have so far assumed that for one unit of budget, we can deterministically tar get any node for acti vation. This is clearly a highly simplified vie w. In a more realistic scenario, we may have a number m of dif ferent mark et-ing actions M i available, each of which may affect some subset of nodes by incr easing their probabilities of becoming acti ve, with-out necessarily making them acti ve deterministically . The more we spend on any one action the stronger its effect will be; howe ver, dif-ferent nodes may respond to mark eting actions in dif ferent ways,
In a general model, we choose investments x i into mark eting ac-tions M i , such that the total investments do not exceed the budget. A mark eting str ate gy is then an m -dimensional vector x ments. The probability that node v will become acti ve is deter -mined by the strate gy, and denoted by h v ( x ) . We assume that this function is non-decreasing and satisfies the follo wing  X  X iminishing returns X  property for all x y and a 0 (where we write x y or a 0 to denote that the inequalities hold in all coordinates):
Intuiti vely , Inequality (1) states that any mark eting action is more effecti ve when the tar geted indi vidual is less  X  X ark eting-saturated X  at that point.

We are trying to maximize the expected size of the final acti ve set. As a function of the mark eting strate gy x , each node comes acti ve independently with probability h v ( x ) , resulting in a (random) set of initial acti ve nodes A . Given the initial set expected size of the final acti ve set is ( A ) . The expected revenue of the mark eting strate gy x is therefore
In order to (approximately) maximize g , we assume that we can evaluate the function at any point x approximately , and find a di-rection i with approximately maximal gradient. Specifically , let denote the unit vector along the i th coordinate axis, and be some constant. We assume that there exists some 1 such that we can find an i with g ( x + e i ) g ( x ) ( g ( x + e j ) g ( x )) each j . We divide each unit of the total budget k into equal parts of size . Starting with an all-0 investment, we perform an approx-imate gradient ascent, by repeatedly (a total of k times) adding units of budget to the investment in the action M i that approxi-mately maximizes the gradient.

The proof that this algorithm gives a good approximation con-sists of two steps. First, we sho w that the function g we are trying to optimize is non-ne gati ve, non-decreasing, and satisfies the  X  X i-minishing returns X  condition (1). Second, we sho w that the hill-climbing algorithm gives a constant-f actor approximation for any function g with these properties. The latter part is captured by the follo wing theorem.

T HEOREM 6.1. When the hill-climbing algorithm finishes with str ate gy x , it guar antees that g ( x ) (1 e k k + n ) g ( ^ x ) ^ x denotes the optimal solution subject to P
The proof of this theorem builds on the analysis used by Nemhauser et al. [23], and we defer it to the full version of this paper .
With Theorem 6.1 in hand, it remains to sho w that g is non-negati ve, monotone, and satisfies condition (1). The first two are clear , so we only sketch the proof of the third. Fix an arbitary ordering of vertices. We then use the fact that for any a and change the order of summation, to rewrite the dif ference g ( x + a ) g ( x ) = X
To sho w that this dif ference is non-increasing, we consider x . From the diminishing returns property of h u ( ) , we obtain that h ( x + a ) h u ( x ) h u ( y + a ) h u ( y ) . Then, applying again equation (2), changing the order of summation, and performing some tedious calculations, writing ( v; x ; y ) = h v ( x + a ) h ( y + a ) if v &lt; u , and ( v; x ; y ) = h v ( x ) h v ( y ) we obtain that ( g ( x + a ) g ( x )) ( g ( y + a ) g ( y ))
In this expression, all terms are non-ne gati ve (by monotonicity of the h v ( ) ), with the exception of ( A + f u; v g ) ( A + u ) ( A + v ) + ( A ) , which is non-positi ve because is submodular . Hence, the abo ve dif ference is always non-positi ve, so the diminishing returns condition (1). [1] R. Albert, H. Jeong, A. Barabasi. Error and attack tolerance of comple x netw orks. Natur e 406(2000), 378-382. [2] C. Asa vathiratham, S. Ro y, B. Lesieutre, G. Verghese. The
Influence Model. IEEE Contr ol Systems , Dec. 2001. [3] C. Asa vathiratham. The Influence Model: A Tractable Repr esentation for the Dynamics of Network ed Mark ov Chains.
Ph.D. Thesis, MIT 2000. [4] F. Bass. A new product gro wth model for consumer durables.
Mana gement Science 15(1969), 215-227. [5] E. Ber ger . Dynamic Monopolies of Constant Size. Journal of
Combinatorial Theory Series B 83(2001), 191-200. [6] L. Blume. The Statistical Mechanics of Strate gic Interaction.
Games and Economic Behavior 5(1993), 387-424. [7] J. Bro wn, P. Reine gen. Social ties and word-of-mouth referral beha vior . Journal of Consumer Resear ch 14:3(1987), 350-362. [8] J. Coleman, H. Menzel, E. Katz. Medical Inno vations: A
Dif fusion Study Bobbs Merrill, 1966. [9] G. Cornuejols, M. Fisher , G. Nemhauser . Location of Bank
Accounts to Optimize Float. Mana gement Science , 23(1977). [10] P. Domingos, M. Richardson. Mining the Netw ork Value of Customers. Seventh International Confer ence on Knowledg e
Disco very and Data Mining , 2001. [11] R. Durrett. Lectur e Notes on Particle Systems and
Percolation . Wadsw orth Publishing, 1988. [12] G. Ellison. Learning, Local Interaction, and Coordination.
Econometrica 61:5(1993), 1047-1071. [13] J. Goldenber g, B. Libai, E. Muller . Talk of the Netw ork: A Comple x Systems Look at the Underlying Process of
Word-of-Mouth. Mark eting Letter s 12:3(2001), 211-223. [14] J. Goldenber g, B. Libai, E. Muller . Using Comple x Systems Analysis to Adv ance Mark eting Theory De velopment.

Academy of Mark eting Science Re vie w 2001. [15] M. Grano vetter . Threshold models of collecti ve beha vior .
American Journal of Sociolo gy 83(6):1420-1443, 1978. [16] V. Harinarayan, A. Rajaraman, J. Ullman. Implementing
Data Cubes Efficiently . Proc. ACM SIGMOD 1996. [17] T.M. Liggett. Inter acting Particle Systems . Springer , 1985. [18] M. Mac y. Chains of Cooperation: Threshold Effects in
Collecti ve Action. American Sociolo gical Re vie w 56(1991). [19] M. Mac y, R. Willer . From Factors to Actors: Computational
Sociology and Agent-Based Modeling. Ann. Re v. Soc. 2002. [20] V. Mahajan, E. Muller , F. Bass. Ne w Product Dif fusion Models in Mark eting: A Re vie w and Directions for Research.
Journal of Mark eting 54:1(1990) pp. 1-26. [21] S. Morris. Contagion. Re vie w of Economic Studies 67(2000). [22] G. Nemhauser , L. Wolse y. Inte ger and Combinatorial
Optimization. John Wiley, 1988. . [23] G. Nemhauser , L. Wolse y, M. Fisher . An analysis of the approximations for maximizing submodular set functions.

Mathematical Programming , 14(1978), 265 X 294. [24] M. Ne wman. The structure of scientific collaboration netw orks. Proc. Natl. Acad. Sci. 98(2001). [25] D. Pele g. Local Majority Voting, Small Coalitions, and Controlling Monopolies in Graphs: A Re vie w. 3rd Colloq. on
Structur al Information and Communication , 1996. [26] M. Richardson, P. Domingos. Mining Kno wledge-Sharing Sites for Viral Mark eting. Eighth Intl. Conf . on Knowledg e
Disco very and Data Mining , 2002. [27] E. Rogers. Dif fusion of inno vations Free Press, 1995. [28] T. Schelling. Micr omotives and Macr obehavior . Norton, 1978. [29] T. Valente. Network Models of the Dif fusion of Inno vations .
Hampton Press, 1995. [30] S. Wasserman, K. Faust. Social Network Analysis .

Cambridge Uni versity Press, 1994. [31] D. Watts. A Simple Model of Global Cascades in Random
Netw orks. Proc. Natl. Acad. Sci. 99(2002), 5766-71. [32] H. Peyton Young. The Dif fusion of Inno vations in Social
Netw orks. Santa Fe Institute Working Paper 02-04-018(2002). [33] H. Peyton Young. Individual Str ate gy and Social Structur e:
An Evolutionary Theory of Institutions . Princeton, 1998.
