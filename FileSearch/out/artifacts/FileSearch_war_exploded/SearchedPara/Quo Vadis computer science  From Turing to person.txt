 Epaminondas Kapetanios * 1. A historical overview and perspective
In the early decades of the 20th century the first formal specifications of modern computing machinery has been laid out by Alan Turing and his contemporary fellows [24,11,6] . Since then, numerous computing devices have been either specified in terms of an abstract machine or fabricated to fulfill practical computing purposes. They range from large devices such as
Bombe [7] and ENIAC [2,13] to IBM mainframes [13,21] in the 1950s and 1960s to personal computers and handheld devices [23] in the late 1990s of the 20th century.

This evolution has been mainly driven by the Moore X  X  Law (Intel co-founder Gordon Moore) [17,18,32] according to which ical and social change in the late 20th and the early 21st centuries.

This change is mainly characterized by the paradigm shift in computing where computational, information and commu-nication tasks have been shifted from big centralized computing devices to network-based and personal computers. They did not only become computing platforms but also boosted the amount of data and information produced on a global scale. The invention of the Internet [3,4] and the Web [1] as a major communication platform freed the imagination towards computers and systems, which are capable of co-operating with each other in order to either harness the vast amount of produced data or complex computational tasks.

Distributed software systems and algorithms, distributed and federated databases, co-operative information systems, peer-to-peer systems, are some examples of terms coined in order to describe downsizing and distribution in computing and computer science. Downsizing and distribution, however, gave birth to not only ambitious projects but also grand chal-lenges in computing. The Fifth Generation Computer Systems (FGCS) project [8,22,16,27,19,20] of the Japan X  X  Ministry of
International Trade and Industry, which begun in 1982, is a prominent example of the effort to create a framework for cal-culations using massive parallelism.

The FGCS vision imagined a parallel processing computer running on top of massive databases using a logic programming language to define and access the data. The problem of the choice of concurrent logic programming as the bridge between the parallel computer architecture and the use of logic as a knowledge representation and problem solving language for AI applications has been considered as one of the major reasons for the failure of this project. In particular, the committed choice of concurrent logic programming interfered with the logical semantics of the languages.

Moreover, the project also suffered from being on the wrong side of the technology curve. The introduction of GUI to the masses by Apple Computer together with enabling distribution of databases by the Internet as well as simpler research pro-considering this project a failure, many of the approaches envisioned by the FGCS such as logic programming distributed over massive knowledge bases has been re-interpreted for the integration of logic based programming and relational dat-ries on the stored data. FGCS is also being re-interpreted in current technologies. The Web Ontology Language (OWL) employs several layers of logic-based knowledge representation systems, while many flavors of parallel computing are proliferated.

Nevertheless, the optimal usage of distributed computing, data and knowledge resources has always been the target in order to tackle hard problems in Science, Engineering and Medicine. The SETI (Search for Extra-Terrestrial Intelligence,
Berkeley, USA) project [34] is one prominent example in this category followed by the Human Genome project [35] .Itis no surprise that projects like e-Science [36] , as recently launched by the UK government, and the GRID computing [37] are meant to create a computing paradigm, where  X  X  X omputer is the network X . In all these approaches, however, the problem seems to be well defined and no synergies across participants from different cultural and professional backgrounds are re-quested in order to create a solution.

In the early 21st century, however, the answer of  X  X  X hat is a network X  has been relaxed by the inclusion of users and user communities, which form social networks via computerized means. Involvement of human beings as creators and consum-ers in problem solving and learning tasks as well as of data and knowledge in synergy with computers has been of para-mount importance. Clusters of computers have been enhanced by clusters of humans as well as clusters of humans and games.
 To this extent, in addition to Moore X  X  Law as driving evolutionary force in computing and computer science, the Metcalfe X  X 
Law [15] has become another major factor of the evolution in computing and computer science. According to this law, though the cost of the network grew linearly with the number of connections, its value becomes proportional to the square of the number of users.

Therefore, the new paradigm shift in computing of the 21st century could be the transition from personal computers to personal contents and collective intelligence . The latter, though a vague term, is meant to emphasize the role of humans as contributors to knowledge creation and collectively problem solving in a networked society. On the other side, it emphasizes the role of computers as facilitators of learning and knowledge sharing in collaborative environments via multimedia en-riched contents or games.
 Wikipedia [33] has been a success story of a collaborative environment for knowledge creation and sharing. Facebook [38] , problem related contents are created and shared in the Blogosphere , a prominent example of which is [29] , the blog on Web technology and science of the most reputable journal Nature . Mass media organizations [10] and publishers are already mak-overwhelming amount of data and knowledge available on the Web.

Nevertheless, the Semantic Web and Web 2.0 [14] visions aspire to contribute to a more meaningful data and knowledge sharing paradigm via more or less sophisticated or user generated annotation and description techniques. Even in Software Engineering as one of the major backbones in the development of information and communication systems, the Open Source
Software [41] development groups and societies have been pioneering in terms of collaborative software engineering in the 1990s. This collaborative engineering paradigm has also been embraced by big players such as IBM and the Eclipse Inte-grated Development Environment. Recently, the  X  X  X oftware as service X  has sparked again discussions as to which extent soft-ware can be deployed and reused in a trustworthy manner within both software developers X  and business management communities.

All these aspects did not only reinforce thinking in what constitutes a modern business or enterprise model, is also sparked ideas like the open innovation model [42] (see also recently announced Cambridge X  X IT synergy) where firms leverage the discovery of others and are also willing to commercialize their innovation by using third party firms whose business models create a more compelling competitive position.

Opportunities and paradigm shifts, however, are always bound with grand challenges. Can this amalgamation of humans and machines within a virtual network with the emphasis on personalization of contents become the  X  X  X oing beyond Turing X  machinery of the 21st century in terms of solutions of wicked and messy problems where synergy of different problem solu-tion perspectives are needed? What are the presuppositions in order to provide a new generation of human X  X omputer eco-systems of collaboration, which enable true collaboration for problem solving strategies?
The Interactive Computing paradigm [28,12] by the late 1990s already opened the door to interesting approaches where humans in interaction with machines become problem solution contributors. A prominent example has been that humans, despite all advances in machine intelligence and knowledge discovery techniques, e.g., Ontology extraction and Image communication and collaboration aspects in computing. Is there any potential waiting to be discovered? 2. On the notion of collaboration
Before we embark on exploring the potential of collective intelligence as an emerging solution framework for wicked and general, which are facing a wicked problem.

It is worth mentioning that this notion of collaboration is a stronger form of working together than co-operation, co-ordi-nation and information sharing. Co-operation means playing together with others in the same game according to agreed upon rules of interaction. Prominent examples of this sort of interaction are discussion forums, multi-player games, news-groups, second life, socially beneficial games, Wikipedia.
 examples of co-ordination are Service Oriented Architectures, Workflow Management Systems, Internet protocols, project management, shopping carts, operating systems, etc. Information sharing appears to be the weakest form of collaboration, co-ordination, co-operation or collaboration.

Following these definitions only very few tools qualify as collaboration technologies. On the other side, even with tools with the highest forms of collaboration, there is no guarantee that their users will collaborate on anything. This has been evidenced by the weakest form of collaboration, namely, information sharing, when it gets applied on exciting learning ob-users who developed impressive systems of practice for learning and invention.

Furthermore, collaboration for solving a messy problem seems to have a structure. At least three key stages can be iden-for a group to consider; (b) connect according to common concerns; (c) listen to and learn all perspectives; (d) making ten-address multiple concerns.
 adigm could tackle wicked and messy problems. 3. On the notion of collective intelligence
So far, Computer Science managed to create ecosystems of participation of humans and machines, where value should be created by the integration and collaboration. The Social Web (Web 2.0) is a prominent example of such an ecosystem of par-ticipation, where value is created by the aggregation of many individual user contributions. Another prominent example is the Semantic Web as an ecosystem of data, where value is created by the integration of structured data from many sources.
To this extent, it is envisioned that one fundamental contribution of Computer Science to Science, Technology, Engineer-ing and Medicine (STEM) for the upcoming 4 X 5 years will be the move from personalized contents and information access, i.e., collected knowledge systems and intelligence, what the Social Web and distributed systems are nowadays, to collective knowledge systems and intelligence. Other early pioneers of the human X  X achine model of collective intelligence include Norbert Wiener, the father of cybernetics, Buckminster Fuller, the consummate inventor and system thinker [9] , and Stewart Brand, creator of the first large virtual community on the Internet [25] .

The key, however, is the synergy between humans and machines, which is meant to meet the challenge of boosting the collective IQ of organizations and society. In collective knowledge systems and intelligence both human and machine contribute actively to the resulting intelligence with each doing best what they do best, when it comes to embodying their problem solving in knowledge and data as well as in techniques. People become customers and producers of knowledge, i.e., a source of knowledge, and they have real world problems and interests. People learn and create knowledge in the context of communication and collaboration. Machines are the enablers. They store, remember, search and combine data. They are symbol manipulators and draw mathematical and logical inferences based on this premise.

A subtle, however, important distinction between the CI and the AI (expert systems) vision is given by Tom Gruber, the father of ontology formalisms and folksonomies for the Semantic Web. Though AI technology aspired to build expert systems that act competently as individual experts, the knowledge acquisition bottleneck has limited the reach of these systems, be-cause it takes a lot to get the knowledge in a form that machines can use in order to solve problems. In addition, Machine
Learning and Text Mining techniques can find structures and patterns in large data sets, and thereby help us make better use of our collected data. These techniques depend on their data for the power to reveal new insights. The challenge, however, reasoning with the data.

Summarizing, a first attempt to define a collective knowledge system that could deliver on the opportunity of collective intelligence would be
Definition. human X  X omputer systems in which machines enable the collection and harvesting of large amounts of human-generated knowledge, while enabling emergent knowledge, i.e., computation and inference over the collected information, leading to answers, discoveries, or other results that are not found in the human contributions.

Technology has enabled the generation of collected knowledge systems by making it cheap and easy to capture (cheap sensors, microprocessors, memory, fiber networks, and cellular telephony has meant that a lot of people have computers, smart mobile phones, digital cameras, and broadband); store (cheap disk storage, giant server farms and clusters); distribute (Internet as information superconductor); communicate (asynchronous communication systems, e.g., emails, blogs, wikis). 3.1. The CI Universe of discourse
In respect with the definition and the nature of collective knowledge systems and intelligence as stated above, the big picture can only be depicted by an assembly of smaller Universes the entities of which constitute the integral parts of networked clusters. These can either be machines, software, data, computational models, knowledge bases or humans.

Given that the CI Universe relies on user participation and connectionism rather than pure machine intelligence, users can be knowledge creators, e.g., interpreting and annotating data, images, documents, developing computational models in order to extract knowledge, producing and annotating teaching material, broadcasting events and news, etc.; knowledge consumers, e.g., retrieving and sharing information, receiving news and events, learners and trainees, etc.; software creators in distributed development teams and software as service consumers, e.g., service oriented architecture; problem solvers, e.g., applying the appropriate computational model to the problem at hand, communicate and share knowledge for collective decision making, improve machine learning via human X  X omputer interaction for better under-standing and classification of images or ontology extraction, etc.; gamers as learners and problem solvers, e.g., assembling of stories from various story fragments as delivered by game designers, communication based on game X  X heoretic semantics, etc.

The role of other computerized entities and technologies within the clustered and distributed world of the CI Universe is as follows: the integration of structured data from many sources. In this role, meeting with the Social Web creates personalized knowledge bases from various sources.

Interactive systems and human X  X omputer interaction (HCI) : It contributes to the creation of the CI Universe as an ena-bler of the interactive computing paradigm, and an improver of knowledge extraction, knowledge exchange and learning.

Data and knowledge engineering and management : It contributes to the creation of the CI Universe in that it improves human X  X achine as well as machine based data exchange, integration and understanding. It also contributes in the cre-ation and management of collections of knowledge and data (well structured, text, images, video, audio) as generated by users and their devices.

Software engineering : It contributes to the creation of the CI Universe in that it provides humans with well understood and reusable, trustworthy and high quality collections of software as service for accomplishing synergetic results. images, video, audio) as well as to collective problem solving among computers, e.g., intelligent and multi-agent systems.
It is distinguishable from collective intelligence in that inference via various forms of logic (first-order, three-valued, fuzzy) and collaborative problem solving is purely machine based. User participation, however, in some or all of the com-putational aspects above contributes to the creation of the CI Universe in that it enables the transformation from collec-tions of data to contextualized collections of knowledge. To this extent, it also contributes to the creation of a contextualized collection of computational models as knowledge discovery techniques to be reused for particular patterns of problems (see also Fig. 1 ).

Distributed and network systems : It contributes to the creation of the CI Universe as enabler of the channels across which communication among clusters of software and data in the CI Universe is enabled.
 medical problems. Contextualizing application of these computational models, however, needs to capture human knowl-edge and share experience regarding their application under particular circumstances in order to solve similar problems. contextualized and personalized data (well structured, text, video, audio) and knowledge (aggregated data, multimedia) bases as derived from a vast amount of data and knowledge sources on the Web. It benefits from the cross-fertilization between database and information retrieval techniques, particularly when uncertain and probabilistic data as captured by users, devices and sensor networks, populate the database.
 learning of situations and artifacts via advanced visualization techniques. Visual aspects of understanding and learning in collaborative environments complement the logical aspects of CI.

Security and cryptography : It contributes to the creation of the CI Universe in that it enables more secure networked envi-ronment. In particular, conceiving the CI Universe as a lively and evolving organism, vulnerability can emerge from two different perspectives: (a) entering and leaving the network, and (b) hackers can also form a user community. 3.2. Applications of collective knowledge systems and intelligence
In order to illustrate the contribution of collective knowledge systems and intelligence in synergy with other disciplines, we refer to the following characteristic application paradigms: 6. Increasing returns with scale : Want to rely on and retrieve trustworthy recommendations of restaurants, hotels, books, 7. Collaborative e-learning : Want to improve communication, problem solving as well as assessment within a group 8. Social networking analysis : Want to analyze social networking and their behavior in order to increase trustworthiness 9. e-Governance : Want to rely on the very nature of collective intelligence, which is user participation in governmental 4. On the potential of collective intelligence as problem solver
Given the very nature of CI and its envisioned applications as described in the previous section, it remains questionable to which extent this computing paradigm where the right match between what data and knowledge is available on-line and appropriate reasoning with it could provide a platform for a new (sixth?) computer systems generation project (SGCS), where personal data and knowledge is plugged into a pipeline for the solution of wicked and messy problems in collabora-tive way.

Given also the nature of various forms of synergies ranging from mere information sharing, to co-ordination, co-operation and collaboration as defined in Section 2 , exploring the potential of CI to provide a more effective problem solution mech-synergies to or from CI as problem solver of wicked or messy problems.
 vious section. We also need to provide a methodological framework, which complies with the structure of collaboration and rently, the lack of such a methodological framework proves to be a significant obstacle towards applying CI to solving such problems.

In line with the structure of collaboration as a problem-solving process, the envisioned methodology should address the following questions: (How) do we plug-in personal data and knowledge into a problem solving social network? (How) do we guarantee communication at different levels of expertise and cultural and multi-lingual backgrounds? (How) do we guarantee communication between experts and end users in their role as member of a particular society and participants in problem-solving strategies and techniques? (How) do we harness the inherent complexity of networked solutions? (How) can we create co-operating systems in a cost-effective way? (How) can we integrate systems in a meaningful way without sacrificing autonomy? (How) can we bring together diverse conceptions and interpretations of user communities? (How) do we cope with uncertainty and probability in data management and knowledge discovery? (How) do we create systems to enable collaboration? (How) do we ensure that quality in knowledge and software creation and consumption is assured? (How) can we ensure security and trustworthiness in networked environments? See as a first attempt the article about  X  X 25 years of Mokum X  in this special issue, in particular chapter 3. (How) do we enable learning via computer games and multimedia enhanced knowledge sources? (How) do we make sure, which inference and reasoning techniques are applied to available data? Does reasoning and available data match?
This is by no means an exhaustive list of challenges and questions expecting an answer in order to end up with a method-ology of how to apply CI to the solution of wicked problems. However, problems such as the situation in the US after the
Hurricane Katrina, the impact of the Jet Stream on environmental changes over the UK and the northern hemisphere, the choice of a sustainable fertilization technique in a developing country are some of the wicked problems begging for partic-ipation, synergy and collaboration towards problem solving as enabled by a new generation of data and knowledge sharing perspective as well as a new reasoning and logic based inference technique, where user participation is of paramount importance.

References
