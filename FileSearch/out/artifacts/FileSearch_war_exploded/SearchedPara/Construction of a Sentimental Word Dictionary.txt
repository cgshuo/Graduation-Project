 The Web has plenty of reviews, comments and reports about products, services, government policies, institutions, etc. The opinions expressed in these reviews influence how people re-gard these entities. For example, a product with consistently good reviews is likely to sell well, while a product with nu-merous bad reviews is likely to sell poorly. Our aim is to build a sentimental word dictionary, which is larger than existing sentimental word dictionaries and has high accu-racy. We introduce rules for deduction, which take words with known polarities as input and produce synsets (a set of synonyms with a definition) with polarities. The synsets with deduced polarities can then be used to further deduce the polarities of other words. Experimental results show that for a given sentimental word dictionary with D words, approximately an additional 50% of D words with polarities can be deduced. An experiment is conducted to find the ac-curacy of a random sample of the deduced words. It is found that the accuracy is about the same as that of comparing the judgment of one human with that of another.
 H.3 [ INFORMATION STORAGE AND RETRIEVAL ]: Content Analysis and Indexing X  Dictionaries Algorithm, Experimentation Sentimental word dictionary, Deduction, WordNet
Opinions affect people from all walks of life. A person who wants to buy a product would choose one having excellent reviews and stay away from a product with poor reviews. Our objective is to build a dictionary of sentimental words, which facilitates the analysis and retrieval of opinionated texts. The proposed dictionary has the following majority sentiment property : each word with a given part of speech has polarity p (positive or negative) if the majority sense of the word with that part of speech has polarity p. Existing sentimental word dictionaries do not possess this property. This property is significant, because it is rather natural for humans to classify the polarity of a word in such a man-ner. More importantly, it permits the deduction of other sentimental words with the same property.

Opinion mining (e.g., [15, 6, 10, 8] and opinion retrieval (e.g., [16, 17, 9]) have significant practical interest. We aim to construct a sentimental word dictionary, which is of high quality and has a large coverage of sentimental words. Such a dictionary is essential, because it facilitates both opin-ion mining and opinion retrieval. Most existing sentimental word dictionaries ( General Inquirer [11], Appraisal Lex-icon [13], Opinion Finder [15]) are far from being exhaus-tive and do not possess the majority sentiment property. SentiWordNet [6] gives a score of positivity, a score of nega-tivity and a score of objectivity to each synset, with the sum of scores = 1. Since these scores are obtained by classifiers and through several iterations of extending the seed sets of data, its accuracy is not high. For example, for the synset { iniquity, immorality, evil, wickedness } (morally objection-able behavior) ,
SentiWordNet assigns the degrees P = 0.75, N = 0, O = 0.25, where P stands for positive polarity, N stands for neg-ative polarity and O stands for neutral polarity. Most people would agree that it has a negative instead of a positive po-larity. Quite a few such examples exist in SentiWordNet. Other researchers [1, 12] consider words to have degrees of positivity/negativity. We choose to have a single polarity associated with each word for the reason explained earlier.
The contributions of this paper are:  X 
By using a deduction approach, the resulting sentimental word dictionary contains approximately 50% more words than a given sentimental word dictionary;  X 
The accuracy of the deduced polarities is reasonably high; it is comparable to that of human judgment.

The rest of the paper is organized as follows. Section 2 de-fines the problem of constructing a sentimental word dictio-nary. Section 3 describes our approach of constructing the dictionary. Section 4 is the experimental results. Related works are given in section 5. Section 6 is the conclusion.
Our approach of constructing a sentimental word dictio-nary is as follows. We start from a seed dictionary D , i.e., a small dictionary of sentimental words where each word in the dictionary has the majority sentiment property . Second, we attempt to deduce the polarities of as many additional sentimental words as possible, based on D .

In practice, we construct the sentimental dictionary on top of the electronic dictionary WordNet [7]. The goal is to annotate each word (and its synsets) in WordNet with their corresponding polarities. The idea is to start from a small number of words whose polarities are known and to use the relationships between words in the dictionary to deduce the polarities of the rest of the words. In this work two words are related if they share at least a synset. The deduction process is the main contributions of this paper.

WordNet distinguishes between four part of speeches: noun, verb, adjective and adverb. It groups words into sets of syn-onyms called synsets . Each word with a part of speech has a set of senses, with each sense defined by a synset. A sense has a short, general definition and some examples. An ex-ample synset with a definition is: (1)S: (adj) { bland, flat, flavorless, flavourless, insipid, sa-vorless, savourless, vapid } (lacking taste or flavor or tang) X  X  bland diet X ;  X  X nsipid hospital food X ;  X  X lavorless supermarket tomatoes X ;  X  X apid beer X ;  X  X apid tea X 
This is one of the three senses of the word bland .  X 1 X  is the frequency count of the synset w.r.t. bland . The part delimited by { and } is the synset, that delimited by ( and ) is the definition and the rest are the examples.
Note that the synset in the example is shared by all the words present in the synset. Hence, the words flat , fla-vorless , etc. have the synset among their synsets. The synset may however have different frequency counts with respect to each word. For instance, its frequency count is 0 with respect to the word flat . Whenever a synset has a 0 frequency count we replace it with 0.1. Usually the senses with rare usages of a word have a 0 count. Increasing their frequency counts by a small constant is a standard smooth-ing technique. If two senses of a word have the same synset, then they can be differentiated by their definitions. To ease the presentation, we will not mention the part of speech and the definition of a word, and assume that the sense of each word is characterized by its synset.

We assume that each synset has a unique polarity. For example, the word bland has three senses, with the first two senses being negative and the last sense being positive. A synset of a word has a frequency of use, indicating the X  X rob-ability X  that the word is used in the sense conveyed by the synset. Suppose the frequencies of use of the word bland in the three senses are f 1 , f 2 and f 3 respectively. For instance, the frequency of the sense of the word bland described above is 1. Then, the relative frequency of the synset in the first sense, which denotes the probability that the word is used in the first sense is f 1 = ( f 1 + f 2 + f 3 ). The probability that the word expresses a negative sentiment is ( f 1 + f 2 ) = ( f If this probability is greater than .5, then the majority sense of the word is negative. This property allows the polarities of other words to be automatically deduced. The following definition formally states this property.

Definition 1. (Polarity) Let w be a word and S its set of synsets. Each synset in S has an associated polarity and a relative frequency with respect to w . The word w has polarity p , p  X  { positive, negative } if there is a subset of synsets S  X   X  S such that each synset s  X  S  X  has polarity p and the sum of the frequencies of the synsets in S  X  is larger than 0.5. S  X  is called a polarity dominant subset . If there does not exist any such subset then the word has a neutral polarity.
Given a seed dictionary D , the inference process can be classified into two categories: (1) determine the polarities of as many synsets as possible and (2) determine the polarities of as many additional words not in D as possible. Once the polarities of synsets are determined we employ Definition 1 (and other techniques) to determine the polarities of ad-ditional words. We first describe how the polarities of the synsets are inferred from the polarities of the words and then cover the deduction of polarities for words.
We classify the synset inference rules into single word and multi-word inference rules. We first introduce three single word rules.

A synset of a word is called dominant if its relative fre-quency with respect to the word is larger than 0.5. Synsets enjoying this property are important because, if a synset is of polarity p and is dominant for the word w , then the word has polarity p . Conversely, if the word w is known to have polarity p and it has a dominant synset s , and possibly some other synsets, then s must have polarity p . This rule is one of the basic means of deducing the polarities of the synsets given the polarities of the words.

Inference Rule 1. Let w be a word having a dominant synset s . If w has polarity p  X  { positive, negative } then s has polarity p , too.

Inference Rule 2. Let w be a word with polarity p and exactly two synsets. The synsets have the same relative fre-quency with respect to w (i.e., 0.5). If p is either positive or negative polarity then both synsets have polarity p .
In inference rule 2, if either synset does not have polarity p , then the word w cannot have polarity p . Thus, both synsets must have polarity p .

As an illustration, the adjective advance has positive po-larity in General Inquirer and it has two senses with iden-tical relative frequencies in WordNet. Hence, we deduce that both its synsets have positive polarities.

The next rule is for words with an arbitrary number of synsets. It partitions the set of synsets of a word into those whose polarities are known and those whose polarities are unknown. If the two sets satisfy certain constraints the po-larities of all those synsets whose polarities are unknown can be determined.
 Definition 2. Let w be a word and S be its set of synsets. A subset S  X  of S is a minimally dominant subset of synsets if the sum of the relative frequencies of the synsets in S larger than 0.5 and the removal of any synset s from S  X  will make the sum of the relative frequencies of the synsets in S  X   X  { s } smaller than 0.5.
 For example, the word consummate has three synsets in WordNet, each of them with the same relative frequency 1/3. It is easy to check that any two of its synsets form a minimally dominant subset (their sum of frequencies is 2/3 and 2 = 3 &gt; 1 = 2).

Inference Rule 3. Let w be a word with polarity p , neg-ative or positive, and S be its set of synsets. Suppose S can be partitioned into two sets, S 1 and S 2 . S 1 is the set of the synsets whose polarities are known and are all different from p . S 2 is the set of the synsets whose polarities are ei-ther unknown or known but equal to p . If S 2 is a minimally dominant subset then all its synsets must have polarity p . The word consummate has positive polarity in Opinion Finder dictionary. Suppose one of its synsets has negative polarity. Since the other two synsets form a minimally dom-inant subset, they must each have positive polarity.
We give an example of an inference rule that involves two words sharing a number of synsets. We have defined and implemented 11 multi-word rules.

Inference Rule 4. Let w and v be two words, with po-larities  X  p (  X  is the negation symbol) and p , respectively, where p  X  { positive, negative } . Neither w nor v have a dominant synset. w has n  X  3 synsets { s 1 ; s 2 ; :::; s 3 synsets { s 0 ; s 1 ; s 2 } (i.e., the two words share { the sum of the relative frequencies of s 1 and s 2 with respect to w is greater than 0.5, then the polarity of synset s 0 Most of our rules involve words with up to four synsets. The explanation lies in the fact that more than 95% of the words in WordNet have up to four synsets. Additionally, all the words with five or more synsets share many of their synsets with words having up to four synsets.
The inference of polarities for words is as follows. The polarity of a word w  X  X  D may be determined (i) from its underlying synsets, using Definition 1 and (ii) by comparing the subsets of synsets of w and those of a word with known polarity. The latter case is useful when there are not enough synsets with known polarities so that Definition 1 can be applied. This section covers this case.
 Proposition 1. Let w and v be two words. Let S w and S v be the sets of synsets of w and v , respectively. Suppose that S w  X  S v . If every minimal dominant subset S also a dominant subset in S v then, if word w has polarity p , p  X  { positive, negative } , then word v has polarity p , too.
We noticed that this statement is satisfied in many in-stances by words with multiple spellings (e.g., British vs. American English): e.g., brutalise vs. brutalize , the two words have identical sets of synsets, i.e., S w = S v . Besides the multi-lingual spelling examples, there are also other mo-tivating examples, e.g, the verbs dehydrate and desiccate . These two words have identical sets of synsets.
 Proposition 2. Let w and v be two words. Let S w and S v be the sets of synsets of w and v , respectively. Suppose that S = S w  X  S v  X  =  X  and S  X  = S w  X  S v  X  =  X  . The polarity of w is p , p  X  { positive, negative } , and the polarities of all the synsets in S  X  are known and all are different from p . S must contain some dominant subset of w . If every minimal dominant subset of w in S is also a dominant subset w.r.t. v , then the polarity of word v is p , too.

The results can be used to derive clusters of words with the same polarity. Suppose that there are pairs of words conditions of Proposition 1. If w has polarity p , then v have polarity p . The same principle applies to word pairs satisfying the conditions of Proposition 2. This increases the number of words whose polarities can be determined.
The data sets used in our experiments consist of: WordNet [7] and the sentimental dictionaries General Inquirer [11], Appraisal Lexicon [13] and Opinion Finder [15]. We use POS Words Synsets Op. Finder Gen. Inq. App. Lex. Noun 117,798 82,115 1,907 1,444 2 Verb 11,529 13,767 1,501 1,041 0 Adjective 21,479 18,156 2,608 1,188 1,440 Adverb 4,481 3,621 775 51 317 Total 155,287 117,659 6,791 3,724 1,759 Adjective 2,937 1,407 1,907 Table 2: Inference result using the union dictionary. WordNet 3.0, whose statistics are given in Table 1. The table shows the distribution of the words and synsets per part of speech. Columns 2 and 3 pertain to WordNet. For example, there are 21,479 adjective words, which have 18,156 synsets. In total WordNet 3.0 has 155,287 words and 117,659 synsets. Data cleaning
The three sentimental dictionaries are organized in triplets of the form  X  word; pos; polarity  X  (where pos stands for part of speech), e.g.,  X  bland; Adjective; negative  X  . General In-quirer has 3,994 distinct triplets, Appraisal Lexicon as 1,888 distinct triplets and Opinion Finder has 8,223 dis-tinct triplets. But not all their original entries are useable. The main reason is that a triplet  X  w; pos; p  X  is present in a sentimental word dictionary, but (1) the word w does not appear in WordNet (regardless of pos ) or (2) w with pos is not present in WordNet.

After cleaning, as shown in Table 1, there are 3,724 en-tries in General Inquirer , 1,759 entries in Appraisal Lex-icon and 6,791 entries in Opinion Finder which appear in WordNet. Herein, whenever we refer to theses dictionaries we refer to their cleaned versions.
One of the main experimental results is the deduction of polarities for additional words using the polarities of the words in the disagreement-free union of the three dictionar-ies. A triplet  X  w; pos; p  X  is included into the disagreement-free union dictionary if (1)  X  w; pos; p  X  is in one of the three dictionaries and there does not exist another triplet  X  w; pos; p in another dictionary such that p  X  = p  X  or (2)  X  w; pos; x in one of the three dictionaries, but in a different dictionary there is  X  w; pos; y  X  such that x  X  = y ; in which case, we deter-mine the polarity of  X  w; pos  X  to be p by consulting WordNet and applying Definition 1.

The result of inferring the polarities of new words and synsets using the union dictionary is summarized in Table 2. The table breaks down the outcome by part of speeches. For example, we are given the polarities of 2,315 nouns (out of 7,794 words) and we deduce the polarities of 1,460 new nouns. In the process we deduce the polarities of 1,683 synsets. Overall, we are given the polarities of 7,794 words and we are able to deduce the polarities of 4,075 additional words and the polarities of 5,099 synsets. In other words, an additional 52.2% of the number of input words with polari-ties are deduced. This percentage seems to be a fair estimate of the inference power of our environment as confirmed by running the inference rules on the individual dictionaries. Specifically, we obtain 55% for Opinion Finder , 68% for General Inquirer and 54% for Appraisal Lexicon .
While from a practical point of view this number seems to be a fair characterization of our inference framework, ana-lytically it is not quite fair. The ability to infer the polarities of new words is dependent on two aspects: (1) the structure of WordNet and (2) the distribution of the words in an input dictionary. We briefly discuss these issues next.
There are 40,077 isolate words in WordNet whose polari-ties cannot be automatically determined. These words have the property that their synsets are not shared with any other word in WordNet. In addition, the input words are badly distributed over WordNet, both per part of speech as well as overall. For instance, in WordNet there are 3,554 non-trivial connected components for the adjective part of speech and the input words fall into only 563 of them, which is less than 16%. A non-trivial connected component has at least two words and any two words (synsets) are connected to each other by paths. Overall, the distribution is far poorer. The words fall into less than 5% (1,443 of 33,015) of the non-trivial connected components. This has a negative im-plication: even if more rules are developed a large portion of WordNet still remains inaccessible to polarity inferencing.
In Table 2, 4075 additional words with polarities were deduced. 100 words are randomly chosen from these 4075 words according to their distributions among nouns (22.2%), adjectives (37.5%), adverbs (11.5%) and verbs (28.8%). These 100 words are shown to 3 humans. They are asked to de-termine their polarities. If they are familiar with a word, they can determine its polarity directly using their experi-ence; otherwise, they can utilize WordNet and Definition 1 to determine its polarity. The Kappa statistic [3] is used to measure the agreement, denoted agreement A-H (Automatic versus Human), between the deduced polarities of the words and those given by the humans. It is also used to measure the agreement, denoted H-H (Human versus Human), be-tween the polarities of the words given by different humans. The agreement A-H is 63.3%, which is slightly larger than that of H-H, which is 62%. It should be noted that the de-duction process does not give rise to errors. The  X  X rrors X  only illustrate the discrepancies among the dictionaries.
If the Kappa statistics is over 75% the agreement is as-sumed to be excellent. The reason why the agreement ac-curacy among humans is relatively low, 62%, is that people have preconceived notions of the polarities of words/phrases. As an example, a phrase to be judged by humans is the verb eat at . A human may associate the phrase to mean  X  X ating at a restaurant X  and assigns either a neutral or a positive polarity. However, this phrase means  X  X ecome deteriorate X , according to WordNet. Thus a human who consults Word-Net assigns a negative polarity to it.
The problem of determining the polarities of words has been studied by many researchers (e.g., [5, 8, 9, 10, 15]). The general theme is that there are sets of seed words that have known polarities; e.g., the seed word  X  X ood X  is positive and the seed word X  X ad X  X s negative. These sets of seed terms are grown by various means. For example, synonyms and antonyms [5] are used to expand the sets of seeds. Another technique to expand the seed sets is to apply the pointwise mutual information measure [2] to each target word t w.r.t. each seed word t i . The pointwise mutual information mea-sure is obtained from the co-occurrence frequency of t and t in documents retrieved by a search engine and the frequen-cies of the individual words in those documents. Machine learning algorithms [4] can be employed to classify words into different polarities. According to [5], the performance of [4] is comparable or better than those in [10, 14].
Unlike SentiWordNet , our view is that each synset does not have a degree associated with each polarity. Instead, each synset is 100% positive, 100% negative or 100% neutral.
In this paper, we introduce the concept of deducing the polarities of words based on the polarities of other words. Experimental results show that the number of new words with polarities deduced is approximately 50% of the size of the original sentimental word dictionary. There are quite a few operators such as hyponym , antonym and similar-to in WordNet, which can be used for deduction, as pointed out in [5]. Intuitively, a hyponym synset of a synset with po-larity p also has polarity p and an antonym of a word with polarity p has polarity  X  p . However, we found numerous exceptions to the intuition. We believe that we can find remedies to these situations. Operators such as antonyms and hyponyms behave differently from the inference rules described in Section 3. Specifically, the former type of op-erations do not require the words and synsets to be within a connected component for deductions to operate properly. [1] A. Andreevskaia and S. Bergler. Mining wordnet for [2] K. W. Church and P. Hanks. Word association norms, [3] J. Cohen. A coefficient of agreement for nominal [4] A. Esuli and F. Sebastiani. Determining the semantic [5] A. Esuli and F. Sebastiani. Determining term [6] A. Esuli and F. Sebastiani. Sentiwordnet: A publicly [7] C. Fellbaum. Wordnet: An on-line lexical database [8] V. Hatzivassiloglou and J. Wiebe. Effects of adjective [9] X. Huang and W. Croft. A unified relevance model for [10] J. Kamps, M. Marx, R. Mokken, and M. de Rijke. [11] P. Stone, D. Dunphy, M. Smith, and J. Ogilvie. The [12] P. Subasic and A. Huettner. Affect analysis of text [13] M. Taboada and J. Grieve. Analyzing appraisal [14] P. D. Turney and M. L. Littman. Measuring praise [15] T. Wilson, J. Wiebe, and P. Hoffmann. Recognizing [16] K. Yang, N. Yu, A. Valerio, and H. Zhang. Widit in [17] W. Zhang, C. Yu, and W. Meng. Opinion retrieval
