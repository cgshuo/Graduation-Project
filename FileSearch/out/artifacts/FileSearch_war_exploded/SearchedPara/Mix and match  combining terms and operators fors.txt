 1. Introduction  X  X  X neffectual corporate search tools can be the biggest drag on employee productivity, costing compa-nies as much as $15 million annually, according to new research. X  X  (CNET News.com 11/13/2002)
Search systems, once exclusively the province of trained professionals, are now ubiquitous due to the advent of the World Wide Web and the use of Web technologies within organizations. Companies globally invest millions of dollars digitizing data on every aspect of their operations, with such lofty goals as enhancing employee productivity and improving customer satisfaction while cutting costs (Hansen, Nohria, &amp; Tierney, 1999). Yet those investments are wasted if the search tools providing access to that wealth of information are ineffectual in the hands of their users, as suggested by anecdotal evidence (see the above quote) and an increasing body of academic work (Jansen, Spink, &amp; Saracevic, 2000).

The context of the research presented here is the search for factual information stored in textual doc-uments. We are, therefore, excluding areas such as queries against structured databases (either transactional or data warehouses) (Chan, Wei, &amp; Siau, 1998), data mining (Apte, Liu, Pednault, &amp; Smyth, 2002; Berzal, Blanco, Cubero, &amp; Marin, 2002), and multimedia searches (Lee &amp; Kim, 2001; Lee, Kim, Lee, Chung, &amp;
Cha, 2000). The usefulness of any information search system depends upon (1) its ability to find documents that are relevant to the user, and (2) its ability to help the user find the relevant facts within those docu-ments. While a search system may be very effective at finding  X  X  X elevant X  X  documents in terms of relevance to a query submitted to the search engine, that is no guarantee that the resulting documents will allow the user to find the desired information. Traditional IR research has focused on evaluating IR systems in terms of their precision and recall (Sparck Jones, 1981), where effectiveness is measured in terms of precision at various recall levels (Gudivada, Raghavan, Grosky, &amp; Kasanagottu, 1997). This metric has proven valuable in evaluating the ability of search algorithms to retrieve documents that are relevant to query content and for comparing search engines based on that criterion (see, for example, Hawking, Craswell, Thistlewaite, &amp;
Harman, 1999; Gordon &amp; Pathak, 1999; Leighton &amp; Srivastava, 1999). Defining the appropriate metrics for measuring search system effectiveness becomes much more difficult, however, when the user is introduced into the equation (Jansen &amp; Pooch, 2001). During the last few years, an increasing number of researchers has started to focus on the factors affecting user performance in conducting searches.

According to Marchionini (1992), the information-seeking task can be broken down into five functions: defining the problem, selecting the source, articulating the problem, examining the results, and extracting the relevant information. The third task, articulating the problem, which depends upon the ability of the user to enter a query that is relevant to her information need, is the focus of this paper. We are not evaluating the effectiveness of novel interface designs for enhancing the query formulation process (see
Anick et al., 1990; Young &amp; Shneiderman, 1993, for example). Rather, we are concerned with the ability of searchers to make effective use of existing, standard search features intended to provide assistance for proper query construction. To that end, we examine the detailed composition of queries users entered in an experimental study whose overall results have been reported in an earlier publication (Topi &amp; Lucas, forthcoming). In this study, we defined the problem set by supplying the participants with nine information requests, each of which has only one correct answer (while this does limit our focus to a particular type of search, this was a necessary restriction to maintain experimental control). Participants then searched for answers to those requests. A document was therefore defined as relevant if it contained that answer, and a search was deemed successful if it resulted in the subject finding that answer.
 All participants used the same search engine and thus, its effectiveness did not vary among them.
Furthermore, it is known that the search engine is capable of finding documents containing the correct answers to the information requests from the experimental search space. The unknown variable is the subjects X  ability to express the information need in such a way that the search engine X  X  interpretation of the query will lead to the retrieval of a relevant document. It is the composition of the queries, rather than the effectiveness of the search engine, that is under investigation here. We therefore do not use the traditional precision/recall measures as dependent variables, as they do not vary among study participants. This is consistent with Spink X  X  (2002) finding that traditional precision measures and users X  perceptions regarding the search success and system quality are often not directly correlated. Our interest is in the correctness of the participants X  responses, where correctness is defined as the number of responses to the nine information requests that match the one correct answer for each request.
 One half of the participants were given an assisted search tool with drop-down menus containing
Boolean operators for joining search terms, while the other half used a simple search tool consisting of a single text box. The former interface is similar in design to the advanced search interfaces found at many search sites except that it is limited to assisting the user with Boolean operators (advanced interfaces often provide presentation options, for example, that were not offered here). This limitation was necessary in order to focus on the issue under investigation and maintain appropriate experimental control. The second treatment was training in Boolean operator usage. As reported in our earlier paper, we found that both interventions, individually and together, had a significant positive effect on the correctness of the search. When taken together, however, their effect was no stronger than that of either intervention alone.
In this paper, we will explore at a more detailed level two questions that were left unanswered by the results of our earlier analysis. First, we will provide a more in-depth review of the terms and operators contained in all of the queries entered by all participants during all search sessions, where a session is defined as the entire sequence of queries entered by a searcher for each information request (Jansen &amp;
Pooch, 2001). With this analysis, we will address the following research question: How do the search tool and training manipulations affect the selection of the query terms and the structural characteristics of the queries? Second, we will address the question: How do the selection of the query terms and the structural characteristics of the queries ultimately affect the success of the searches? Our detailed examination of the differences between successful and unsuccessful searches will lead to a better understanding of the factors influencing the ability of searchers to construct expressive queries, which can then be used to improve the support provided during the search process.

The following section of this paper describes research related to this study. This is followed by our research model. Then, we describe the study X  X  methodology and present and discuss its results. We conclude with the implications of our findings on practice and directions for future research. 2. Related work
A very large number of studies over the years have evaluated the effectiveness of search engines and algorithms, as previously noted. Far fewer have considered the characteristics of users and their queries, although interest in this research area has recently increased. In this review of related research, we maintain our focus on research concerning traditional text-based search environments, and do not cover other types of search systems.
 A few studies have directly evaluated the effects of different query structures on search performance.
Gudivada et al. (1997) considered the effects of query composition by formulating two queries in three different ways: conjunctive (using ANDs), disjunctive (using ORs), and phrase (using quotation marks).
These queries were then submitted to 13 search engines. Query results showed that conjunctive and phrase queries perform better than disjunctive queries, in that they retrieve far fewer documents. Eastman (2002) compared the relative precision of the top ranked documents using disjunctive, conjunctive, and phrase queries. While the more precise and narrowly defined (i.e., conjunctive and phrase) queries did return fewer hits, making them easier to process, this reduction was sometimes accompanied by an observed decrease in the precision of the top 10 documents retrieved. This type of precision anomaly is counterproductive to the user X  X  goal of retrieving the most relevant results to a query. Further research is necessary to reach conclusive findings about the observed effects. While these two studies investigated the relationship between query components (i.e., the selection of terms and operators) and search performance, traditional precision/recall measures were used for evaluating search engine effectiveness, which refers to the ability of the underlying search algorithms to retrieve relevant documents. In this study, we focus on human search performance , defined as the ability of the user to (1) form queries with a search engine interface that result in the retrieval of document(s) containing the correct answers to information requests, and (2) find that answer within the retrieved set of documents, independent of the search engine X  X  effectiveness. Our performance measure is therefore the number of correct answers to a set of information requests. As mentioned earlier, this appears to be compatible with the findings of Spink (2002), who found empirical evidence supporting the separation between traditional precision measures and user-based evaluations of a search system.
 Another stream of research has evaluated users X  search behavior by examining search engine query logs.
Abdulla, Liu, and Fox (1998) studied Web IR system-related traffic by examining the sessions, queries, and browsing activities associated with five log files containing 26,824 queries. Query complexity was measured by counting the number of terms and the number of operators in each query. Results showed that searchers rarely used Boolean operators or invoked more advanced search features, and typically entered two terms per query. The authors attributed these behaviors to either the inexperience of the searchers or to Web IR interfaces not being intuitive enough. Later studies confirm their findings (Silverstein, Henzinger, Marais, &amp;
Moricz, 1999; Spink, Wolfram, Jansen, &amp; Saracevic, 2001). Our research seeks the causes and consequences of these behaviors, with the goal of improving the users X  search experience.

Other studies have focused on differences between various user groups, particularly based on users X  experience level. The differences in search behaviors between expert and non-expert Web IR system users was studied by H  X  olscher and Strube (2000), who found that expert searchers used more terms and advanced search operators than the average Web searcher. Sutcliffe, Ennis, and Watkinson (2000) also found that search experts submitted more complex queries and selected more terms than the novice searchers in their study. Conversely, Hsieh-Yee (1993) found little variation in term quantity between experts and novices.
The latter study, which compared the use of search terms and tactics by novice and expert searchers of bibliographic database systems, suggests the importance of term content versus term quantity. It also showed that one must be both knowledgeable about the search topic and technically competent in order to be successful in information retrieval.

Lucas and Topi (2002) compared expert versus non-expert queries on eight search topics and found that the search topic itself had a significant effect on the number of terms and operators comprising a query.
Furthermore, search term selection and usage were more significant predictors of query performance than was operator usage. Cronin-Townsend, Zhou, and Croft (2002) proposed that the degree of ambiguity of a query with respect to the collection of documents being searched is often closely related to query perfor-mance. This ambiguity is quantified using clarity scores, which measure the degree of dissimilarity between the language used in a query and the generic language used in the collection as a whole. A strong positive association was evidenced between the clarity score and the average precision of a query. Jansen (2000) demonstrated that increasing query complexity by adding advanced operators had little effect on the results returned, lending further support to the importance of the terms entered by the searcher. Eastman and
Jansen (2003) found that the choice of search engine and, to a limited extent, the use of query operators had a significant impact on the relative precision of search results. The impact of operators on precision, however, was not always in a positive direction. They reasoned that a user cannot effectively use query operators without understanding the underlying IR system, and pointed to the need for more research into interfaces that provide better support for users.

Overall, user studies have started to shed light on the factors that affect users X  search performance, but there have been few studies investigating the mechanisms that mediate the effects between users X  search behavior and their performance in search tasks. The main purpose of this study is to address this void by evaluating both the factors that affect the users X  selection of search terms and operators, and the effect of the terms and operators on search performance. The following section outlines the research model that guided this study. 3. Research model
In this study, we investigate the effects of the user interface and Boolean logic training on the use of both terms and operators comprising a query. In addition, we explore how term and operator usage affects the correctness of the query results and, ultimately, the success of a search. Search success is defined here as the number of correct answers a participant finds to a set of information requests, each of which has only one correct answer. Our earlier analysis found that users of an assisted search tool (providing assistance in forming syntactically correct Boolean queries) and users of a simple search tool who received training in
Boolean operators had significantly higher aggregate Correctness scores (i.e., the total number of correct answers) for the nine information requests than users of the simple interface who did not receive training.
The assisted interface had a positive effect on correctness over the simple one, but training had a positive impact only for those using the simple interface. Here we explore the reasons behind these findings by determining the impact on term and operator usage of the search interface and Boolean operator training, as shown in Fig. 1, which is an expansion of the model from our earlier paper (Topi &amp; Lucas, forthcoming).
Our model distinguishes between searcher performance and system performance, with our focus being on the former. This is consistent with Spink X  X  (2002) finding that search precision (system performance measure) was not necessarily consistent with users X  perception regarding the success of their search. It is well understood in the IR community that translating a user request into a Boolean query requires a trained person (Ingwersen &amp; Willet, 1995), and studies such as the one undertaken by Siegfried, Bates, and Wilde (1993) indicate that training can improve upon searchers X  querying techniques. In this study, we are emphasizing the impact of training on the two components of queries, namely terms and operators. The model also depicts the fact that the search interface impacts these query components. Shneiderman, Byrd, and Croft (1998) point out that Web search interfaces are often sources of confusion for their users, and
Pollock and Hockley (1997) note that advanced search features mislead searchers into believing that they are for more experienced users. Little information is therefore available concerning user interactions with these features and the effect of their usage on query components.

Based on our earlier analysis, we expect the manipulations of training and search interface together to affect operator usage and term usage (with the exception of misspellings), and the search interface alone to affect those same factors. Both the assisted search tool and the Boolean training exercises were designed to help the user construct syntactically correct queries through proper operator usage. An understanding of the query formation process and how terms can be combined with conjunctive, disjunctive, and negation operators could also have a positive impact on the number and quality of terms used in the queries. The assisted search interface itself is expected to have a positive influence on query components because it was designed to reduce cognitive load by guiding the user in the query formation process (Cooper, 1990).
Operator usage and term usage is expected to affect query quality (i.e., the ability of the query to express the user X  X  information need), which, together with the search engine X  X  effectiveness, has a direct impact on the correctness of the search results.

We do not claim that this model is comprehensive, because clearly operator usage and term usage are affected by many other individual characteristics, such as general intelligence and problem solving ability, general and specific experience with search engines, domain knowledge (H  X  olscher &amp; Strube, 2000), cog-nitive abilities and styles (Allen, 2000; Ford, Miller, &amp; Moss, 2001), etc. The model includes only the variables that are either manipulated in this research (i.e., training and interface) or hypothesized to be affected by those manipulated variables.

It is worth pointing out that the quality of a specific query is determined by the two query components identified in the model and only by them, that is: the usage of terms and the usage of operators (while many search engine algorithms do make use of derived data based on variables such as relevance feedback and click thru, this is not the case with the particular search engine used in this study). The correctness of the searcher X  X  answers depends on the quality of the query, the search engine X  X  ability to return relevant documents, and the searcher X  X  ability to utilize those returned documents using the tools available in the search environment. This third factor, which corresponds to Marchionini X  X  previously mentioned functions of examining the results and extracting the relevant information, is not reflected in our model because it is not a focus of this study.

In keeping with the common language recommendations of Jansen and Pooch (2001), a term is defined here as a string of characters delimited by a space. Boolean operators are not defined as terms unless they are clearly being used within a phrase as a conjunction, in which case they are terms but not operators. A query is defined as a string of zero or more characters entered to the search system. The search engine used in this study (namely, the Microsoft Index Server that is integrated with the Internet Information Server (IIS) on the Windows 2000 operating system platform) requires the use of quotation marks around terms to form phrases, the use of the AND and OR operators for conjunctive and disjunctive queries, respectively, and the use of the NOT operator for negation. Within the operator usage category, quantity refers to the number of operators of each of these types appearing in the user X  X  query, while missing refers to the absence of any operators that should appear either between or, in the case of quotes, around terms in order for the query to be syntactically correct. Carry over is the use of an otherwise valid operator that is not supported by the search system being used (Jansen &amp; Pooch, 2001). In this case, the  X + X  and  X  supported and are, therefore, carry overs. Invalid operators include symbols, such as commas and semi-colons, which have no meaning in queries.

Within the term usage category, quantity refers to the number of terms and phrases appearing in the user X  X  query. For each of the information requests, a correct query that returns the most relevant document as the first result in the answer set has been defined . Matching therefore refers to the number of terms and phrases a test subject X  X  query has in common with the  X  X  X orrect X  X  one (we acknowledge that there is potentially more than one correct query that could produce the optimal results for each infor-mation request). Misspelled corresponds to the number of terms in a query that have been spelled incor-rectly. 4. Methodology 4.1. Design and participants
One hundred and thirty undergraduate students at a small university located in the northeastern USA participated in a controlled laboratory experiment with two experimental manipulations: Training and Search Interface Type. Participants were assigned to one of four treatments, as indicated in Fig. 2. Treatments I, II, and IV were comprised of 32 study participants, while treatment III had 34 participants.
Those in groups II and IV used a simple search tool like those found at commercial Web search sites, while participants in groups I and III used the assisted search tool shown in Fig. 3. Participants in groups I and II received training in Boolean logic, while those in groups III and IV did not. The average age of the par-ticipants was 18.6 years, and 94% were freshmen. Table 1 shows the demographic statistics for the study sample. There were no relevant demographic differences between the participants in the different treatment groups. The results of a 2  X  2 ANCOVA manipulation check with Search Tool (Assisted vs. Simple) and Training (Logic Training vs. No Logic Training) as independent variables and Pretest (a test on the use of
Boolean constructs) indicated that the only factor differentiating the treatments was Logic Training. This suggests that randomization had provided sufficient protection against the potential dangers of the be-tween-subjects design used in this experiment. 4.2. Procedure and task
The participants performed the task as an in-class search exercise in an introductory information technology course in which they were enrolled. Participation was voluntary and no extra credit was offered based on participation in the experiment. As an incentive, $50 prizes were awarded to the two best per-forming participants across the treatments.
 After customary introductions and procedure descriptions, participants in groups I and II completed a
Web-based, interactive Boolean operator training exercise, the length of which varied between 5 and 10 minutes, depending on the participant (the time was not restricted). All participants viewed a slideshow that described the experimental procedure, and then logged on to the system for the collection of background data on demographic characteristics and attitudes. The actual experimental task followed, after which the participants completed additional survey instruments.

The experimental task asked participants to look for answers to the same nine information requests, which appeared in random order. These requests can be grouped by complexity into three categories, based on the contents of the  X  X  X orrect X  X  queries defined by the authors for finding the answer to each of them.
Queries for the three information requests in the first category are simple conjunctive queries containing two terms. The three queries in the second category also require the use of the conjunctive operator but contain a combination of terms and phrases. Those in the third category require the use of the NOT operator, and contain at least four terms and/or phrases. A pilot study confirmed that the nine information requests can be categorized into these three groups based on users X  performance.

The searches were conducted in a research environment against a set of 21,890 HTML documents se-lected specifically for this study. The document database is a snapshot of a university intranet Web site from which all links have been removed in order to maintain sufficient experimental control and reduce irrelevant variance within the treatments. The absence of links forced participants to reformulate queries in order to find new pages, as they cannot browse from a retrieved document to any other page. All of the users X  interactions with the search system, entered via the keyboard, were captured to a database for later analysis using an automated facility created for this research environment. The search environment is described at a detailed level in (Topi, Lucas, &amp; Jain, 2003). 4.3. Data analysis and results
Because of the exploratory nature of this research, we did not present hypotheses that could have been formally tested and, therefore, the analysis of the results is not based on the hypothesis testing approach.
We did, however, follow the guidance of our research model (Fig. 1) when evaluating which relationships to test statistically. There are two sets of relationships under investigation, as depicted in the model of Fig. 1: (1) the impact of the training and interface treatments on the use of operators and terms, and (2) the impact of operator usage and terms on query quality.

In analyzing the first of these, 2  X  2  X  3 ANOVA analyses were performed, with training, interface, and query complexity as independent variables, and one of the following as the dependent variable (with the effect on each operator analyzed separately): number of used ANDs, ORs, AND NOTs, parentheses, and quotes; number of missing ANDs, ORs, AND NOTs, parentheses, and quotes; number of carry over operators; number of invalid operators; number of terms; number of phrases; percent of terms and phrases matching those in the expert queries; and number of misspelled terms. Earlier analyses indicate that query complexity is an essential factor explaining a significant amount of variance. It was therefore included in the analysis as an independent variable in addition to the main experimental manipulations.

OLS multiple regression was used to analyze the second relationship type between operator and term usage and correctness of the query results. Regressions were run separately for each of the query complexity categories because of the different requirements inherent in each. For example, correct queries in the simplest category require only two terms and one AND operator and, thus, it is possible that the use of additional terms and OR operators in this category could be harmful. On the other hand, more terms and a different set of operators are needed in the most complex category. In these regressions, a relevant subset of the term and operator usage variables were the independent variables, and the dependent variable was correctness of the query results. The maximum correctness score for each study participant was three (i.e., all three information requests in the category answered correctly) and the minimum score was zero.
Table 2 provides aggregate descriptive statistics for the research data. Detailed descriptive statistics for all the variables are available by request. Following are the results of both types of analyses and a dis-cussion of our findings. 5. Results 5.1. Effects of treatments on term and operator usage
Training in Boolean operators, the use of the simple versus assisted interface, and interactions between training and the interface had significant effects on many aspects of operator and term usage by study participants. In this section, we will outline the significant results from the ANOVA analyses.
First, there were several highly significant main effects related to Boolean training. Boolean training helped all participants avoid missing required AND operators (full analysis is not meaningful statistically because there were no missing ANDs with the assisted interface, but the difference is clear with the simple strongest for queries in the first two query categories, where no ORs are actually required increased the number of misspelled terms, although the absolute number of those terms was very small. training, however, was on the quality of the terms and phrases used, as measured by the percent of those matching the expert queries. Training had a significant positive main effect over all query categories  X  F  X  1 ; 375  X  X  20 : 383 ; p &lt; 0 : 001  X  on this variable.

The use of the assisted interface over the simple one had a very strong, positive main effect on the number of terms used  X  F  X  1 ; 378  X  X  118 : 982 ; p &lt; 0 : 001  X  and the correct usage of quotes  X  F  X  1 ; 378  X  X  416 : 06 ; p &lt; 0 : 001  X  . In addition, queries written by assisted interface users contained significantly more
AND operators  X  F  X  1 ; 378  X  X  197 : 966 ; p &lt; 0 : 001  X  , which is not surprising when the fact that AND is the default option used by the assisted interface is taken into account. The usage of ANDs was also affected to a lesser extent by training (as noted above), and then by the category, with those in more complex categories using more ANDs. The assisted interface had a significant positive impact on the use of AND NOTs (main effect F  X  1 ; 378  X  X  72 : 124 ; p &lt; 0 : 001  X  , particularly in Category 3 queries, the only category actually that the assisted interface reduced the number of missing AND NOT structures  X  F  X  1 ; 378  X  X  8 : 416 ; p  X  0 : 004  X  . Since the interface adds quotation marks automatically, it had, not surprisingly, a strong impact on their use as well  X  F  X  1 ; 378  X  X  323 : 886 ; p &lt; 0 : 001  X  .

There were a number of interaction effects observed between training and the interface. Queries entered by study participants using the simple interface with no training were unique in several ways: required
AND operators were missing from them (to the extent that a statistical analysis was not meaningful because there were no missing AND operators in the results of the users of the assisted interface), contained no over operators (in this case, statistical analyses were again not meaningful because there were virtually no cases of carry over operators in other treatments). An interaction effect between training and the interface was also observed in the use of invalid operators, with those using the simple interface with no training and addition, there was an interaction effect on the number of terms  X  F  X  1 ; 378  X  X  4 : 312 ; p  X  0 : 039  X  , with training having a more pronounced effect on those using the simple interface. Table 3 summarizes the effects of training and interface on the use of operators and terms.

Based on these results, the training intervention had a very broad effect on the use of various query components; the only areas training did not have an impact on were the use of quotation marks, the use of parentheses, and the use of invalid operators. The assisted interface used in this study had an impact on fewer dimensions of query writing. The only area in which it did have an effect when training did not was in the reduction of the number of missing quotation marks. Interaction effects were common, too, with most of them related to the fact that the Simple Interface/No Training condition was often significantly (and negatively) different from the other conditions.

It is also worth pointing out that participants X  selection of operators and terms was affected by the category of the information request in several ways as well. These effects were, however, largely based on the direct and natural relationship between the information request and the query (for example, that a more complex information request requires more terms and operators and that only certain types of information requests need AND NOT operators). Therefore, the query category is an essential contextual factor and has to be controlled in the statistical analysis (as was done above), but it will not be treated as a separate factor in this analysis. 5.2. Impact of operators and terms on correctness of the results
The other part of the empirical analysis deals with the effect of terms and operators on the correctness of query results. OLS regression was used to analyze this relationship and, as discussed earlier, there were no hypotheses to test. Again, it was essential to take the query category into account as a contextual factor because it is reasonable to believe that the effects vary in different query categories. Therefore, this analysis was performed using three different regression analyses, one for each of the three query categories. The independent variables entered into the regressions included the same variables that were used as dependent variables in the analysis above, except those for which there was no variance in a particular category. Full regression models are included in Table 4.

Findings of the regression analyses varied based on the query category, with all of the models having reasonably good explanatory power, as measured by the variance explained ( R 2 ). For Category 1 (the least complex) queries, the percent of terms and phrases matching those in the expert queries had the strongest positive effect  X  t  X  115  X  X  4 : 397 ; p &lt; 0 : 001  X  on Correctness, followed by the use of quotation marks  X  t  X  115  X  X  2 : 570 ; p  X  0 : 011  X  , and lastly by the number of missing ANDs, which had a negative effect  X  t  X  115  X  X  2 : 364 ; p  X  0 : 020  X  . The total amount of variance explained by the use of operators and the selection of terms was 28.8%. Factors outside this model (including the participants X  ability to utilize the resulting document set) accounted for the remaining differences between the participants X  performance.
For Category 2, the missing ANDs had the strongest and, as expected, negative effect on query result correctness  X  t  X  114  X  X  3 : 845 ; p &lt; 0 : 001  X  , followed by a positive effect for the number of matching terms and phrases  X  t  X  114  X  X  3 : 100 ; p  X  0 : 002  X  . Additional significant factors were missing quotes  X  t  X  114  X  X  2 : 664 ; p  X  0 : 009  X  and the number of quotation marks used, which had an unexpected negative impact on correctness  X  t  X  114  X  X  2 : 480 ; p  X  0 : 015  X  . Finally, the total number of terms approached sig-nificance  X  t  X  114  X  X  1 : 964 ; p  X  0 : 052  X  . This model explained a respectable 36.2% of the variance in the dependent variable Correctness.

For Category 3 queries, Correctness was most strongly and surprisingly positively affected by the number of missing AND NOT operators  X  t  X  112  X  X  2 : 923 ; p  X  0 : 004  X  . This was followed by the negative impact on performance of the use of quotation marks  X  t  X  112  X  X  2 : 321 ; p  X  0 : 022  X  and the positive impact of the percent of matching terms and phrases  X  t  X  112  X  X  2 : 264 ; p  X  0 : 026  X  . The variance explained was 22.1%, which was somewhat lower than for the other two models.

In sum, the number of matching terms and phrases was consistently and in all three categories positively associated with Correctness. Otherwise, the factors linked to Correctness varied based on the individual requirements of the query category. 6. Discussion 6.1. Effects of treatments on term and operator usage
The following discussion interprets how the manipulations of training and interface affected the com-position of the participants X  queries and how the differences in terms and operators contributed to the correctness of their answers by focusing on the most important findings of the previous analysis.
Our research model suggested that training and search interface, both alone and together, have an impact on operator and term usage. This was most decidedly true for operator usage. Users of the simple interface who did not receive training simply did not use operators, particularly Boolean ANDs and AND NOTs, quotation marks, and parenthesis. They were also the only group whose queries exhibited carry over, such as using + and ) operators that are common in popular Web search interfaces. On the other hand, simple interface users with training and assisted interface users in general used more operators and used them more correctly. This is a particularly significant finding in light of numerous studies that have found the correct usage of Boolean operators to be a cognitively complex task for all but the most sophisticated of users (see, for example, Cooper, 1988; H  X  olscher &amp; Strube, 2000; Mischo &amp; Lee, 1987; Siegfried et al., 1993). Training had little additional positive impact on the users of the assisted interface, and it actually seemed to cause a slight increase in their use of invalid operators. Further research is needed to determine the reasons for this negative effect. It appears possible that training in conjunction with the assisted interface confused or overwhelmed the study participants; cognitive overload may have been the culprit.

An unexpected and very interesting finding was that training alone improved the percentage of terms and phrases matching the experts X  queries for users of either interface. The benefit of improving the participants X  understanding of how to form syntactically correct queries therefore appears to extend beyond richer operator usage to richer and better term usage. Further research is needed to understand the reasons underlying this phenomenon; we can only speculate about them at this point. It is possible that Boolean training helped the participants understand the entire task better and thus, freed cognitive resources, thereby enabling the participants to focus on finding the optimal search terms. Alternatively, the effect might have been that training allowed the participants to use less cognitive capacity for determining the correct operators and, therefore, to spend more time on term selection. This issue is particularly important because, with some modern search engines, explicit operator use has almost entirely disappeared. This raises an interesting question: would training in Boolean logic improve the users X  ability to select terms in these contexts? It may well be the case that a search engine that does not require the explicit use of operators reduces cognitive load, freeing capacity enough to enhance the selection of terms. This question should be investigated in future research.
 Our model also shows and the data supports that the search interface affects operator and term usage.
The assisted interface clearly increased the usage of ANDs, AND NOTs, and quotation marks. This was as expected, because the interface automatically added quotation marks around phrases, used the AND operator by default, and offered AND NOT as one of three options in the operator list (along with AND and OR). The assisted interface did not, however, have any impact on the use of OR operators; overall, the participants used very few ORs with either of the interfaces. Importantly, the assisted interface reduced the number of missing AND NOT operators, i.e., improved the participants X  ability to use these operators.
The assisted interface also created an incentive to use more terms within phrases (that is, increased the average length of a phrase), but did not increase the total number of phrases or the percentage of matching terms and phrases.

Overall, the results suggest that both relatively minor changes in the query interface and a brief (5 X 10 minutes, computer-based) training intervention were sufficient to change the search behaviors of the par-ticipants. The average numbers of terms and operators used by the participants in the Simple Interface/No
Training treatment were similar to those found in prior research (Spink et al., 2001; Lucas &amp; Topi, 2002), that is, the participants used on average between two and three terms per query and a single operator in approximately half of the queries. The statistical analysis shows and a simple review of the descriptive statistics effectively demonstrates that both manipulations in this research dramatically increased the number of operators used (to 2 X 4 operators per query) and also had a clear impact on the number of terms used, particularly with the more complex queries that benefited from an increased number of terms. An illustrative observation is that in the Simple Interface/No Training condition, neither the number of terms nor the number of operators increased from the least complex query category to the most complex.
To summarize, receiving training or using an assisted interface has a significant, positive effect on the correct use of Boolean operators. Training also improves the quality of the terms and phrases entered. The assisted interface increases the quantity of terms, resulting in longer, but not more, phrases. 6.2. Impact of operators and terms on correctness
As expected, the most consistent factor affecting query correctness was the match between the terms the participant used and the expert solution. This result is consistent with, for example, Lucas &amp; Topi (2002) and Spink &amp; Saracevic (1997); the latter study found that terms selected from user-generated Question
Statements were a very significant source of high-quality search terms. The importance of the match be-tween the participant and expert query terms was true across the query categories, and the percentage of matching terms and phrases was either the strongest or the second strongest factor in all of the query categories. The numbers of terms and phrases were not directly associated with response correctness in this study.

The results related to the effect of operators on correctness were less conclusive. The strongest finding is the negative impact of missing AND operators in the first two query categories. Clearly, in these cases a system that automatically added a conjunctive operator to connect two separate terms would have been beneficial. Surprisingly, in three of the seven significant associations between an operator factor and cor-rectness, the direction was different from what was expected. For the moderately complex and most complex queries, increasing the use of quotes actually had a negative impact on query correctness, which suggests that quotes were used incorrectly and/or unnecessarily. In the same categories, missing quotes were either strongly (in Category 2) or marginally (Category 3) associated with poor performance. Correct use of quotes to identify phrases is clearly very important to gain successful search results, at least with the search engine used in this study. Another unexpected finding was that with the most complex queries (Category 3), a missing AND NOT structure had a positive impact on correctness. The reason underlying this appears to be as follows: in the relatively small number of cases where AND NOT was used, it was often used incorrectly and in a way that ultimately decreased the quality of the resulting document set.

Overall, the variance explained by the regression models was reasonable (between 22% and 36%) but not high. This indicates that (1) the quality of the terms and, to a lesser extent, the correct use of Boolean operators affect the successfulness of a search operation, and (2) there are additional explanatory factors that were not present in the analysis. As was suggested in the context of our research model, in limiting our focus to the function of problem articulation, we have neglected any investigation of the user X  X  ability to examine the results and extract relevant information. In a previously noted study evaluating user behavior and performance in conducting searches, Sutcliffe et al. (2000) found that above-average performers not only used narrowing and broadening strategies (to decrease and increase the quantity of search results, respectively) but also spent more time evaluating search results. Clearly, an exploration of how participants utilize query results and the variety of individual factors impacting their choices is an important direction for future research. 6.3. Limitations
The participants in our study were all college students enrolled in a required introductory computer course. While their age range, experience, and exposure to and comfort with search engines represent a very small segment of Web users, they are likely to be more representative of today X  X  knowledge workers and are therefore a valid segment of the population for use in this study.

Our search environment was also not typical of that usually encountered on the Web, as browsing was disabled, which conflicts with the favored approach of combining searching with browsing (Catledge &amp;
Pitkow, 1995). This restriction was necessary, however, to isolate the effects of the manipulations on only the search-related factors under investigation here.

Another uniqueness of the setting involved our information requests, each of which has only one correct answer. While this does make it more difficult to find relevant documents, it also simplifies the definition of what is relevant and improves our ability to interpret the research results. Finally, as pointed out by one of the reviewers, we did not explicitly evaluate the effects of the position(s) of the document(s) including the correct answer on the correctness of the results; this would have provided additional clarity to the results. 7. Conclusions and future work
The findings of this study strongly support the use of training or an assisted interface for improving the ability of Web searchers to construct syntactically correct queries. Surprisingly, Boolean training also helps in term selection; perhaps an increased understanding of how queries are put together improves the searcher X  X  ability to focus on both operators and terms. While the combination of terms and operators will improve query composition and lead more readily to relevant documents, the ultimate success of a search will also depend upon the individual characteristics of the searcher.

Future research must continue to address this issue of the key determinants of query success, including how searchers utilize the information contained in retrieved documents. In addition, the relative impor-tance of term quality warrants investigation into training and interface manipulations that directly affect term selection, including feedback mechanisms and the use of concept hierarchies. The effects on search performance of assistance features not considered here, such as personalized search interfaces and infor-mation visualizations, should also be investigated.
 References
