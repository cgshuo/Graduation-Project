 Signal and Image Processing Laboratory, Electronics and Computer Science Faculty, University of Science and Technology of Houari Boumedienne, Algiers, Algeria
School of Computing, Engineering and Information Sciences, Northumbria University, Newcastle upon Tyne, UK Department of Computer Science, King Saud University, Riyadh, Saudi Arabia 1. Introduction: Problem statement and motivation
The increasing need for reliably determining or verifying the identity of a person has spurred active component in several protected applications that render services only to legitimately enrolled users. Traditional methods of establishing a person X  X  iden tity include knowledge-based (passwords) and token-shared, manipulated or stolen thereby undermining the intended security. Biometric authentication deals is speci fi c to the person and can be used in authentication applications [1,2]. 1.1. Iris: When identity matters
The use of iris patterns has been found to be the most reliable and accurate for veri fi cation and in Fig. 1. The physiological complexity of the organ results in a random patterns in iris, which are statistically unique and suitable for biometric measurements [4]. Iris patterns remain unchanged in principle of the current use of iris recognition was fi rst introduced by an eye surgeon. In 1987, two an iris recognition algorithm. Daugman X  X  algorith m, which has been published in 1993 [9], is known as than a decade. Several industrial companies patent the core technology of Daugman X  X  system and are active in providing iris recogn ition products and services [8]. 1.2. Previous works
For the designers of pattern recognition algorithms , iris recognition is a very hard problem. Over the 9] made use of Two Dimensional (2D) Gabor fi lters to demodulate texture phase structure information denote the phase structure of the iris at different scales. Each phase was then quantized to one of the four quadrants in the complex plane. The resultin g 2048-component iris code was used to describe an iris. The difference between a pair of iris codes was measured by their Hamming distance.
Wildes [10,39] represented the iris texture with a Laplacian pyramid constructed with four different
Boles [11] implemented a feature extraction algorithm via zero-crossings representation of a wavelet (1D) signals are then compared with the model features using different dissimilarity function. The as well. However, this algorithm is very computationally intensive in identi fi cation applications.
Tisse et al. [12] analyzed the iris characteristics using the analytic image constructed by the original image and its Hilbert transform. Emergent frequency functions for feature extraction were in essence samples of the phase gradient fi elds of the analytic image X  X  dominant components [16,17]. Iris code is generated by thresholding both the models of emergent frequency and the real and imaginary parts of the instantaneous phase. Finally the matching is performed using Hamming distance.
 In the algorithm proposed by Ma et al. [18], the quality of the images is assessed with the help of Support Vector Machines (SVM). The feature vectors a re generated using the Multichannel Spatial Filters (MSF). In [19], Dyadic Wavelet (DW) for feature vector generation is used. A set of one-dimensional two-dimensional image using a particular class of wavelets. A position sequence of local sharp variation points in such signals is recorded as features. A Fisher Linear Discriminant (FLD) is used to reduce the dimension of the iris feature vector.
 The LTP is averaged in a speci fi c way to produce the elements of a rotation invariant vector. Thus the method performs a loss projection from 2D to 1D. This vector is then normalized so that its elements sum to 1. The matching algorithm uses the  X  X u measure X , which is the product of two measures, one of q with respect to p , otherwise known as the Kullback-Liebler distance.

Monro et al. [14] have developed an iris feature extraction method based on Discrete Cosine Transform (DCT). They applied the DCT to overlapping rectangular image patches rotated 45 degrees from the
Fourier and Wavelet descriptors have been used as powerful tools for feature extraction, which is a crucial processing step in pattern recognition probl ems. However, the main drawback of these methods is Transform (HHT) developed by Huang et al. is a new analysis method for nonlinear and nonstationary (IMFs) that become the bases representing the data using an Empirical Mode Decomposition (EMD). Recently, the HHT has received more attention in terms of interpretations [22 X 24] and applications. 1.3. Data analysis for iris recognition An iris consists of some basic elements, which are similar to each other and interlaced with each other. high-dimensional space and the intrinsic dimensionality of the iris space is known to be much smaller. In fact the iris is believed to be clustered into some low-dimensional manifolds. Subspace techniques aim to reduce the inherent excessive dimensionality of scanned data to make iris recognition algorithms data analysis methods, such as Linear Discriminant Analysis (LDA) and Principal Component Analysis on the emergent method  X  X ndependentComponent Analysis (ICA) X  are also proposed [26 X 28]. However, for the latter, no mathematical detailed and convinced implementation procedure of such approaches has been provided. In this paper, we propose to describe and analyze the performance of iris feature extraction techniques. We are particularly interested in ICA algorithms because they capture local but crucial information in an iris and create a set of compact features for effective recognition tasks. 1.4. Paper organization described. Section 3 is devoted to give the basic concepts and hypotheses of ICA. The performances of some popular ICA algorithms like Joint Approximate Diagonalization of Eigen-matrices (JADE), ICA by relative Newton method and Fast-ICA algorithm are evaluated. We have developed a comparative study between these ICA algorithms and well-known ir is recognition algorithms that can be found in the different certi fi ed subsets of CASIA iris image database [29,30] including an implementation of some mathematical criteria. Finally, the last section concludes the work presented in this paper. 2. Iris recognition system description iris surface. Such a system comprises of modules for iris localization, normalization and enhancement. These procedures called image pre-processing, feature extraction (encoding) and feature matching. the templates in the database in order to determine or validate an individual X  X  identity. Figure 2 shows the block diagram of a typical iris recognition system.
 boundary) and the sclera (outer boundary). Therefore, a captured iris image cannot be expected to have only the iris part as it contains some non-useful part(s). These undesired factors such as occlusion of irises by the eyelids, shadow of eyelids and noise within pupils degrade the pre-processing stage, which can caused a degradation of the overall performance of the system.
 iris inner pupil and outer sclera boundaries. Well-known methods such as the Integro-differential [4], Hough transform [10,12] and discrete circular active contour models [11] are successful techniques for and sclera as perfect circular curves. However, it has been shown that the circular assumption of the contours can lead to inappropriate boundary detection.
 The normalization process refers to preparing a segmented iris image for the feature extraction process. Most normalization methods are based on a Cartesian to polar transformation unwrapping of iris textures into fi xed-size rectangular blocks. Existing normalization approaches include Daugman X  X  Rubber sheets model, Wildes X  image registration and non-linear normalization model [15].

Once the pre-processing step is done, the next step relates to the iris feature vector extraction. Given we have used ICA-based approaches for feature extraction as will be detailed in the following sections. Our proposed system for iris recognition is based on Canny edge detection [40] and Hough transform for iris localization. The Daugman X  X  Rubber sheet model is used for normalization and the Hamming distance is used for matching. 3. Independent component analysis In this section, the ICA method is described in terms of how its model can be estimated. For example, JADE algorithm, ICA by relative Newton method and Fast-ICA algorithm will be detailed. We have chosen these three ICA algorithms because they are different in their theoretical backgrounds. JADE is based on some algebraic and matrix concepts, Fast-ICA uses a neural network-based approach, while ICA by relative Newton method is a conceptual derived from the Newton method-based optimization. and the computational cost. These differences should lead to an optimal choice of the algorithm that is suitable for hardware implementations in terms of memory space usage, computational complexity and characterization accuracy.

ICA represents a powerful statistical method for data analysis, with applications in computational neuroscience and engineering. It consists of automatically identifying the underlying components in a and each mixture is a combination of components that are independent and non Gaussian. However, like all methods, the success of ICA in a given application depends on the validity of the assumptions on 3.1. ICA model estimation Generally, the most popular noise-free linear model of ICA is expressed as follows: where X is a vector variable, of dimension N , in which each variable is an observed signal mixture and S is a vector variable, of dimension M , in which each variable is a source signal. We assume that N M . The mixing matrix A de fi nes a linear transformation on S , which can usually be reversed in order to recover an estimate vector U of S from X , i.e.: where the separating matrix W = A  X  1 is the inverse of A .However, A is an unknown matrix and cannot therefore be used to fi nd W .Let g be the Cumulative Density Function (cdf) of S having a maximum of for the Independent Components (ICs) that are recovered from X by adjusting W until the entropy of g recovered by W is maximized. This ensures that the components of U recovered by W are independent. This, in turn, can be achieved by adjusting W to maximize the entropy of: E = g ( U )= g ( WX ) . Thus, the joint entropy H ( E ) of E is given by the entropy of X plus the change in entropy, denoted by  X  H , induced by the mapping from X to E . The form of g is fi xed, which means that maximizing H ( E ) amounts to maximizing  X  H by adjusting W . This consists of iteratively adding a small amount of the gradient H ( E ) of H ( E ) to W : more ef fi cient natural gradient [32]. 3.2. Pre-processing
Pre-processing on the input data vector, such as returning the centered data and the whitening step, allows to avoid certain indeterminations in the computation of the separation matrix and to simplify the problem of IC extraction. Returning the centered data is dependent on the higher order statistics of the data. The input vector X is thus transformed into: X c = X  X  E { X } . Note that the mixture matrix A is not modi fi ed by this operation. Whitening is a linear transformation that consists of annulling the correlation between the variables and it imposes a variance unit on the variables of the centered vector X Obtaining the matrix V is possible by using the PCA such as: where matrix D is a N  X  N diagonal matrix whose diagonal elements d d ICA developed in the literature, such as for example, the Infomax algorithm [31], but it is recommended because it improves the convergence of the algorithms [33]. 3.3. JADE algorithm
The starting point for the Joint Approximate Diagonalization of Eigen-matrices algorithm is the observation that ICA algorithms generally require an estimation of the distributions of the independent sources or have such an assumption built into the algorithm [34]. It has been noted that optimizing the cumulant approximations of data implicitly performs this process, thus leading to present a number of approximations to information theoretic algorithms that operate on second and fourth order cross-cumulants.

All of the information theoretic measures can be calculated by operations on the cumulants. They present an advantage in the sense that the algorithms do not require gradient descent and thus avoid any convergence problems. A side effect of this is that the JADE algorithm requires no parameter tuning for good performance. A disadvantage of this approach, however, is that estimating a complete set of fourth order cross-cumulants requires the storage of O ( n 4 ) cumulant matrices. The cumulant matrix with elements [ Q x ( M )] where M is an n  X  n matrix and X is a n dimension random vector. Cum ( X )isde fi ned by:
The JADE algorithm uses the second and the fourth order cumulants. The second order cumulant is sources Z = VAS = US . A set of cumulant matrices is estimated from the whitened sources. Cardoso has demonstrated that the separating matrix can be estimated as W = U T V where U is a rotation matrix that makes the cumulant matrices as diagonal as possible according to the JADE contrast function [34]. The JADE contrast function is the sum of squared fourth order cross cumulants from the set de fi ned in Eq. (5):
This contrast function is a measure of the mutual information between the cross-cumulants. Making The matrix that performs the diagonalization on the cumulants can be exploited to perform the separation of the mixed data. 3.4. Fast-ICA algorithm
The basic idea behind the Fast-ICA algorithm is that maximizing the non-Gaussianity leads to estimate the researched ICs. One of the non-Gaussianity measures is the maximization of the negentropy, which is entropy of the random vector that has a non-Gaussian density. Fast-ICA algorithm uses an approximation of the Newton method that is tailored according to the ICA problem. It provides a fast convergence, When it is applied on the gradient, it gives an optimization method that usually converges in a small process, based on fi xed-point algorithm, can be expressed as follows: where  X  w t function and g is its derivative [35]. Note that the function g is the derivative of some non-quadratic of this algorithm was proven in [35]. 3.5. ICA by relative Newton method
In [36], the Newton method is used forQuasi-MaximumLikelihood(QML)forBlind Source Separation (BSS). The concept of QML wit hout the orthogonality constraint, w hich has been recognized for its robustness, is used and good results have been obtained. Recently, the relative Newton method is proposed as an improvement of the Newton method for QML-BSS [37]. Here, we propose to use this method for performing the ICA for iris feature extraction. If the sources are mutually independent, an effective estimator of W can be obtained by minimization of the following objective function: used when the source pdfs are unknown. In the literature, it was shown that the optimization methods based on natural gradient do not give good results, while the relative Newton method gives very good results. The Newton method is a very effective optimization tool and without any particular constraint. which corresponds to solve an equation system. The principal stages of this method for minimization of the QML of Eq. (9) are as follows:  X  Initialize w 1 of the separation matrix and put k = 1 ;  X  If it is not the convergence:  X  Increment k = k + 1 ;
Therefore, if stage 2 is carried out using a standard gradient descent method, we obtain the so-called the relative gradient method [38]. Consequently, the computation cost of the standard Newton method could be overcome by integrating the relative aspect of the Newton method in the above algorithm. In the following modi fi ed system: in two different manners. For example by reiterating the vector such as: or by fi xing the value of the adjustment parameter  X  and update the vector w using the following subroutine:  X  Put  X  = 1and  X  =  X  = 0.3;  X  If  X  L ( w +  X y, X ) &gt;  X  L ( w, X )+  X  X   X   X  L ( w, X ) then  X  =  X  X 
This procedure guarantees a monotonous descent of the objective function. To make the relative optimization algorithm invariant, the relative Newton method is used in order to simplify the Hessian computation. In fact, the Hessian matrix computation of L ( I, U ) has a special structure that allows a computation by considering its structure at the point of solution U 4. Iris recognition process
An iris image contains not only the region of interest but also some unuseful part such as eyelids, localization and normalization of the iris. 4.1. Localization the inner and outer boundaries of the iris. The eyelids and eyelashes normally occlude the upper and lower parts of the iris region. To detect the iris and pupil boundaries, Hough transform is used by involving Canny edge detection to generate an edge map. Gradients are biased in the vertical direction for the outer iris/sclera boundary. Vertical and horizontal gradients are weighted equally for the inner upper and lower eyelid parts using a linear Hough transform. A second horizontal line is then drawn, allows maximum isolation of eyelid regions while a thresholding operation is used to isolate eyelashes. 4.2. Normalization
Normalization refers to preparing a localised iris image for the feature extraction process. Daugman [9] suggested a normal Cartesian to polar transformation that maps each pixel in the iris area into a pair represented as: where x representation often called as rubber sheet model. Rotational inconsistencies are not considered in this representation. The normalized iris images collected are of gray level and their contrast is enhanced using a histogram equalization process. Figure 4 shows the normalization process of an iris image. 4.3. Feature extraction by ICA
The iris images are considered as a mixture of an unknown set of statistically independent source images by an unknown mixing matrix. A separating matrix is obtained by ICA to recover a set of statistically independent basis images (Fig. 5). Many basic models in image processing express the image I ( x, y ) a linear superposition of some features or basis functions a where s of the iris texture, and so we propose to apply ICA and thus to create a set of compact features for an which case we can express the representation as in (1) for ICA model. We assume here that the number of transformed components is equal to the number of the observed variables. This kind of a linear superposition model gives a useful description on a low level where we can ignore such higher-level nonlinear phenomena (e.g., occlusions).

In practice, it is not possible to model a whole image using the model given in Eq. (15). Rather, we apply it on image blocks or windows. Thus, we have partitioned the image into blocks of n  X  n pixels and we have modelled the patches with the model of Eq. (15). Care must then be taken to avoid the border effects, as illustrated in Fig. 6.
 the actual number of vectors of ICA bases. Therefore, the dimension of feature vector becomes smaller by reducing the number of vectors of bases. The whitened data is used as the input for ICA algorithms (presented in Section 3), which computes a set of basis vectors a images are projected into the compressed subspace to obtain a set of coef fi cients s 4.4. Matching and comparison
New test images are then matched to these known coef fi cients by projecting them onto the basis vectors and fi nding the closest coef fi cients in the subspace. We have generated the iris code for storing and comparing feature vectors. The encoding method of iris code is to assign values of 0 or 1 to each IC coef fi cient.

At the fi nal stage of iris recognition system, we have used the Hamming distance to compare two iris matching is shown as follows: where P  X  Q is the logical XOR operation, N is the dimension of feature vector, P of the presented feature vector, while Q 5. Experimental results: Analysis and evaluation
This section deals with the iris recognition process, by evaluating the performance of ICA algorithms for feature extraction and their computation complexities. In order to compare the performance and accuracy of the ICA-based methods for iris feature extraction against the methods proposed in [9,11,18, 19,39], the experiments are performed using three different iris subsets of CASIA database. All of the algorithms are implemented in MATLAB 7.3 and executed on the same computer (Intel Pentium T2330 dual-Core 1.60 GHz CPU, 2048 M RAM). All of the experiments are completed under the same conditions and environment. 5.1. Iris databases description Three subsets of CASIA iris database provided by the Chinese Academy of Sciences  X  Institute of gray-level JPEG fi les, collected under near infra red illumination. An exampl e of each subset of CASIA iris database is shown in Fig. 7.

CASIA V1.0 database contains 756 iris images from 108 subjects. The images were acquired at different stages and the time interval between two collections is at least one month. The size of the from the near infrared illuminators [29].

CASIA V3-Interval database contains a total of 2,655 iris images from more than 249 subjects and digital optics developed by the National Laboratory of Pattern Recognition in China. The captured details are extremely clear.

CASIA V3-Lamp database contains a total of 16,213 non-ideal iris images from more than 411 sub-jects and 819 classes. The collection was taken in one session by using OKI X  X  hand-held iris sensor. The captured images with a size of 640  X  480 pixels have a nonlinear deformation due to variations of visible illumination.
 5.2. Experimental steps
To ensure that there are enough iris image classes from different subjects to evaluate our approach, we have used 756 iris images including 108 classes of CASIA V1.0 database, 1020 iris images including 204 classes of CASIA-IrisV3-Interval subset and 1008 iris images including 112 classes of CASIA-IrisV3-Lamp subset of CASIA-IrisV3-Image database. All iris images have been segmented, normalised with a size of 32  X  240 and enhanced. This has resulted in a total of 756 of CASIA V1.0, 1020 of CASIA-IrisV3-Interval and 1008 of CASIA-IrisV3-Lamp image samples with a size of 32  X  240 pixels.
To evaluate similarity of projected iris images, a corresponding matching metric is used that consists of giving one range of values when comparing the projected iris images of the same eye (intra-class comparisons) and another range of values when comparing projected iris images created from different irises (inter-class comparisons). These two cases have given distinct and separate values; consequently, it is easy to make a decision with a high con fi dence as to whether the two projected iris images come of the subset chosen, i.e. 108, 204, or 112 of CASIA V1.0, CASIA V3-Interval, or CASIA V3-Lamp, respectively. These images have been partitioned to 10,000 image blocks of size of n  X  n pixels, which were taken at random locations from the images, and gathered by normalizing each image block to a column vector X of size ( n 2  X  1). The dimension of the vector X is reduced to R  X  1 . The separating matrix W is calculated using the whitening process and each ICA algorithm described above. Then, the ICs are calculated by projecting all images samples and thus forming new database. The ICs are encoded to be compared in order to take decision. 5.3. Performance analysis We have evaluated the performances of the different algorithms using the following criteria: False Acceptance Rate (FAR), False Rejection Rate (FRR), Equal Error Rate (EER), and accuracy. Simulta-neously, we have assessed the computational complexities of the algorithms.

We have carried out the experiments using JADE, Fast-ICA and ICA by relative Newton method and with the following numbers of the extracted ICs given by R = { 40, 32, 24, 20, 16, 12, 10, 8 } .These experiments have been carried out for each subset of CASIA iris database with two different sizes of image block of 8  X  8 pixels and 16  X  16 pixels. Figures 8 and 9 show the results obtained for each size. Figure 8 shows the performance evaluation of different ICA algorithms according to the number of IC ICA algorithms according to the number of IC. Table 1 depicts the comparison between the numbers of the intra-class and of the inter-class for each subset. Table 2 gives the values of minimum and maximum of EER for each size. 5.3.1. Comments on the databases
From Fig. 8, it can be seen that EERs obtained by CASIA V1.0 and CASIA-IrisV3-Interval for different numbers of ICs and with size of 8  X  8 pixels are lower than 1%. The reason is that these better than the results obtained with 16  X  16 pixels for the image blocks. This means that the ICs values are very small compared to the size of the images and the whitened data fails to capture enough information from the original data. This requires an increase of the number ICA coef fi cients. However, EERs obtained by CASIA-IrisV3-Interval are lower than EERs obtained by CASIA-IrisV3-Lamp. The reason is that CASIA-IrisV3-Lamp images have been obtained by a variation of the visible illumination with a nonlinear deformation, which provides poor results in the localisation and normalisation phases, thus introducing more intra-class variations. Therefore, the EERs obtained by CASIA-IrisV3-Lamp with a size of 16  X  16 pixels for the image blocks are better than those obtained for blocks with f 8  X  8 pixels. An explanation of this behaviour results from the small eigenvalues of the high-frequency components which usually encode noise. One can also observe that the error rates increase when ICA always decrease with the reduction of ICA coef fi cients; this leads to an unstable ICA estimation. 5.3.2. Comments on the results of ICA-based methods From Fig. 8 and Table 2, it can be seen that the best results are obtained with ICA by relative Newton method when image patch size is 8  X  8 pixels and JADE algorithm when image patch size is 16  X  16 pixels for CASIA-IrisV3-Interval database. However, the results obtained with the Fast-ICA algorithm are the worse with block of 16  X  16 pixels for the CASIA-IrisV3-Interval database. However, the CASIA-IrisV3-Lamp database gives better results than those obtained by JADE for blocks of 16  X  16 pixels. Furthermore, JADE algorithm yields good results for blocks 16  X  16 pixels when using CASIA-IrisV3-Lamp database. From Fig. 9, one can conclude that the feature extraction time is approximately the same for all the methods, except of JADE, which is known to be much faster with relatively small matrices. 5.3.3. Comparative study
Among many methods for iris recognition developed in the literature, those proposed in [9,11,39] are the most popular. These methods characterize the local details of the iris based on phase, texture analysis and zero-crossing representation, respectively. Therefore, we have chosen these algorithms for performing a comparative study with our ICA-based approaches by considering the best EERs, in the same image samples (CASIA V1.0). From the results shown in Table 3, we can fi nd that Daugman X  X  algorithm and ICA algorithms provide the best performances, followed by the algorithm developed iris veri fi cation are also compared to the algorithms proposed in [18,19], which have used the CASIA-proposed in [18,19], whi ch are based on a bank Spatial Filters and Dyadic Wavelet, respectively. Also, TSRs of ICA algorithms are higher than TSR of the algorithm proposed in [18,19], which is based on 1D Log Gabor fi lters, as Table 4 shows for each subset of CASIA iris database. 6. Conclusion and future work In this paper we have evaluated the performances of some well-known ICA algorithms: Fast-ICA, JADE algorithm, and ICA by relative Newton method for iris recognition. By using three subsets of CASIA iris database, we have assessed the performances of these algorithms and shown that the number of the ICA coef fi cients, image block size and feature extraction computation time affect the performances. For example, these ICA algorithms are very effective when using very good quality iris images with a small size. However, in the case of noisy and deformable iris images with large block size the performances of the Fast-ICA and ICA by relative Newton method get marginally better when compared against JADE algorithm. However, in general, the results obtained allow us to conclude that ICA could perform well for such application, but it is sensitive to illumination and noise degradations caused by the eyelids and eyelashes. This presents a limitation of ICA based-methods. As future work, we propose to take into account noise in the ICA model with a view to eliminate the bias due to noise or at least reduced for the blurred iris images.
 References
