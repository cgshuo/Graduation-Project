 Methods for modeling and analyzing relational data, i.e., collections of quantified relationships between (usually two) ob jects, are recently attracting much atten-tion in the fields of data mining and machine learning. Examples of such data are link structure of WEB, social networks within human groups, patterns of co-authorship of academic papers, or gene-gene interactions in biological networks. Among various research topics in this field (often called  X  X ink mining X ; see [1] for an extensive review), this study addressed the issue of identifying underlying re-lationships based on stochastic observations, i.e., the  X  X ink prediction X  problem.
Conventionally, pairwise relationships appeared in various contexts are commonly represented as graphs, network s, or equivalently weighted adjacency matrices. For example, cons ider a social relationship among people which is mea-sured by their e-mail transactions with each other. We regard the frequency of e-mails from user i to user n as an observed link (or non-link if zero frequency) x in . Then we assume that the matrix X =[ x in ] is a noise-corrupted observation of underlying true relationship, X , of these users. The link prediction problem is to estimate the true matrix X from the observation X ,where X may contain missing values 1 .
For such problems to recover the true matrix X from observed X , matrix fac-torization techniques [2]  X  [7] have been actively studied in the machine learning field. This is a general technique of approximating an observed matrix X by a low-rank matrix X = U T V under various loss criteria, in order to effectively reduce the degree of freedom of X . Since the true relation is likely to have structures of a low degree of freedom an d the rank-reduced representation is usually good for generalization, the low-rank matrix representation is advanta-geous for prediction. The framework is general and widely applicable, especially in such situations that one does not have enough knowledge of the true relational structure.

Matrix factorization techni ques, however, only consider the cases that target data are sampled from a stationary environment. Many real-world relational data, on the other hand, have such characters that their statistical properties are dynamically changing over time [8]. In the case of e-mail transactions, the true social links are inherently dynamic over long time scales. Observed links at a certain time point (e.g., e-mail counts at a day or a week) are generated from a temporary state of latent relationship at the time, and thus they have distinct statistical characteristics at different time points. Existing matrix factorization techniques have only addressed a single X but not a temporal series X 1 , X 2 ,... .
To address this issue, we propose a dynamic extension of matrix factorization in this study. Our model utilizes the framework of generalized linear models (GLMs) [9] to deal with various kinds of data, employing the original idea of [2] in the context of matrix factorization. The high flexibility of this framework is especially useful when dealing with binary or count data such as in e-mail transaction data.

The rest of this article is organized as follows. In Sec. 2, we introduce the original GLM-based matrix factorization (called  X  X xponential family matrix fac-torization (EMF) X ) of [2]. In Sec. 3, we de rive the Bayesian inference for this model by using the Laplace approximation, and then extend the model into in-corporating a state-space model. A Kalman filter style estimate for this model is also described. In Sec. 4, the results with synthetic and real datasets are shown. In Sec. 5, we summarize our current study and discuss future works. Let U and V be two sets of R and C objects under consideration, respectively. The pairwise relationship between U and V can be stochastically observed as an R  X  C matrix X =[ x in ], where x in is the quantity representing the relation between the i -th element of U and the j -th element of V . In this article, we assume X is asymmetric to allow  X  X irectional X  relation.

Now we assume that the observed matrix X is generated stochastically around its expectation X (the  X  X rue X  matrix). In a probabilistic formulation of matrix factorization (e.g., [5], [10]) , X is often modeled as with a K  X  R matrix U and a K  X  C matrix V .  X  X  X  denotes the transpose. Usually we assume K&lt; min( R, C )sothat X has a degenerated rank. If we assume each x in is independently generated from Gaussian of mean  X  x in and variance  X  2 ,the generative model is simply written as In this case, the maximum likelihood (i.e., least square) estimation of U and V correspond to the singular value decomposition (SVD). However, the Gaussian assumption is not suitable for some types of data, such as binary, count, and non-negative ones.

Gordon [2] employed the GLM framework to extend matrix factorization tech-niques to be applicable to non-Gaussian situations. A typical GLM (with the  X  X anonical link X ) assumes that a target variable is distributed as an exponential family that has a linear regression function of the natural parameter; the expec-tation X under the model then becomes a nonlinear function of input variables. As the same manner, Gordon X  X  model assumed that the expectation X is given by a nonlinear function both of U and V ,thatis, where f (  X  ) is a nonlinear function defined below. More concretely, X is assumed to be distributed as the following generative model: where  X  = U T V ,and u i and v n are the i -th and n -thcolumnvectorsof U and V , respectively. Here, we have defined where  X  is a natural parameter, and F (  X  )=ln exp[ x X  + G ( x )]d x is the log-normalization term. In this case, since the sufficient statistics is X ,themean parameter of this distribution is equal to X by definition. Thus we have x in = f (  X  in )= F (  X  in )where F is the first derivative of F , from the well-known property of exponential family. We note that many important distributions are represented by the form of Eq. (4), such as Bernoulli (binary), Poisson (count) and exponential (non-negative) distributions. In this article, we call this model as exponential family matrix factorization (EMF). In [2], an efficient Newton X  X  method-based procedure to estimate U and V with quadratic regularization (i.e., an MAP estimation under Gaussian priors) was presented.
 3.1 Model Let X t denote an observation at a discretized time step t .Nowwehaveatime-series D T  X { X 1 ,..., X T } and our goal is to obtain a sequence of low-rank matrices { X t } which approximate { X t } . To naively perform this has a very large number of parameters. In order to reduce the number by utilizing the character of the time-series, one good idea is directly to model the dynamics of the underlying features of the data. To this end, we construct a dynamical model that extends the original EMF model to be suitable for time-series relational data. We assume that the parameter  X  = U T V in Eq. (3) now changes with time. Let  X  t be the parameter at time step t .Wealsodenote U t =[ u t 1 ,..., u t R ]and V dynamics of the low-rank matrix  X  t , we assume random walks for U t and V t : The initial values u 1 i and v 1 n are assumed to be sampled from isotropic Gaussian X t is generated from the EMF model, that is, where  X  t =( U t ) T V t . The graphical model is depicted in Figure 1. One may concern about the scale indeterminacy in our parametrization  X  = U
T V , that is, for an arbitrary constant a , replacing U and V respectively as a U and (1 /a ) V does not change the likelihood (6). In [2], this indeterminacy was resolved by introducing quadratic regularization terms which controlled their a priori scales. Similarly, in our model, by appropriately setting the apriori scale (variance) parameters,  X ,  X ,  X  ,and  X  , either by estimating or by hand with a fur-ther regularization, the indeterminacy i s expected to be resolved. Furthermore, our Bayesian scheme rather than the point estimates would also be suitable for such situations. 3.2 Laplace Approximation Now we assume the (conditional) prior distributions of U t and V t basedonthe past sequence D t  X  1 are obtained as Gaussian forms, When a new datum X t is observed, we estimate posterior distributions of U t and V t in a Bayesian manner. However, the calculation of the posteriors with these Gaussian priors (7) and EMF likelihood (2) in closed forms is difficult. It should be noted that this is also true even when the likelihood is also a Gaussian; the Gaussian prior is conjugate for  X  , but not for U or V . If we assume a Gaussian prior directly on  X  ,theposteriorof  X  is also Gaussian; however, the rank constraint on  X  is hard to be applied.

In this study, we approximate them by the Laplace approximation. This makes the posteriors also of Gaussian form, which is useful to derive sequential Bayesian filters. According to the Laplace approximation in a naive way, however, we need to compute the full covariance matrix of size ( RK + CK ) 2 so as to handle all the combinations between U and V . To reduce the computational cost, we further assume the column-wise posterior independence for U and V (a similar assumption is also used in [3]). Then, the posterior after observing the new datum X t is given by Q n are the inverse Hessian of the log-posterior around the MAP points with respect to u t i and v t n , respectively. This approximation allows us to maintain only ( R + C ) covariance matrices of size K 2 .

The posterior means, U t and V t , can be obtained in the same manner as in theoriginalEMF[2].Theinv erse of covariance matrices P t i and Q t n are given by ( u which is the cumulant-generating function, diagonal elements of D t i and D t n are Algorithm 1. Estimation procedure of dynamic EMF the variances of x in  X  X  under the EMF model with parameter  X  t .Wenotethat, although we have assumed conditional independences in the posterior (8), the estimations of u t i and v t n are not independently done; they actually interact with each other, through the estimation of mean and variance of x in under the model, where calculation requir es all the parameters in U t and V t . 3.3 Sequential Bayesian Inference Due to the Gaussian form of the posterior and the independence assumption of Eq. (8), we can utilize the Kalman filter-like sequential Bayesian inference for u i and v n . When we have the ( t bution at the next step t can be obtained by a marginalization: p ( u t i |D t  X  1 )= sition, they are given by After observing X t , the posterior distributions are updated by Eqs. (8)-(9).
In this study, we only employ the forward inference (filtering) but not the backward one (smoothing), because we primarily assume that our algorithm is applied in an online manner. When considering computationally heavier but more accurate prediction , the backward inference, at least back to the recent part, would be necessary. However, our current algorithm still shows high per-formances as seen in simulation experime nts in the next section. Finally, with the posterior of Eq. (8), we obtain a prediction of X t as X t = f (  X  t ), where  X  t =( U t ) T V t . The overall procedure is summarized in Algorithm 1. 4.1 Synthetic Data To evaluate the basic performance of our method, we conducted a simulation experiment with a synthesized datase t. We first prepared a sequence of rank-4 natural parameters {  X  1 ,...,  X  100 } , such that the expectation X varied as illustrated in Fig. 2(a). In these figures, each matrix is aligned as a single column. Then, each observation X t was generated from the Poisson distribution of natural parameter  X  t (Figure 2 (b)).

For comparison, we employed SVD and the original (static) EMF both using sliding windows. That is, each estimate of a low-rank matrix at time step t was based on the previous w + 1 step X  X  observations at t  X  w, t  X  w +1 ,...,t . In our Poisson case, this is equivalent to the use of a compound data  X  X t = (RMSE) between the true sequence X t and the parameter sequence estimated by each of these three methods. In this expe riment, we fixed the transition variances  X  , X  2 in (5) at the true value (= 10  X  4 ) and did not estimate them.
Figure 2(c)-(e) visualize typical results by SVD, EMF, and our method, re-spectively. From these panels, a slight improvement by our method can be seen, that is, the result (Figure 2(e)) is sharper and clearer than the others. Although the difference is not very clear in these fi gures, we can confirm the improvement qualitatively by comparing the RMSE by the three methods (Figure 2(f)). For SVD and EMF, the best results obtained with the optimal w s are presented 2 . We can see that, by regularizing the rank to be low, our method outperforms the other methods in terms of RMSE. 4.2 E-Mail Data Next we tested the effectiveness of our me thod for link prediction with a real-world dataset. In this experiment, we us ed the Enron e-mail dataset [11], the collection of 252,759 e-mails of 151 Enron employees in years from 1998 to 2003. In our experiment, we only used the data from Jan 1st 2001 to Jun 30th 2001 (for 181 days). Then we had a time-series of 181 observations { X 1 ,..., X 181 } each of which corresponds to a single day, where we set x t in =1ifuser i send any e-mail to user n on the t -th day, otherwise set x t in = 0. We omitted the e-mails from/to the outside of the Enron group and only used those exchanged internally within the group.

In this experiment, we cannot know the  X  X rue X  matrix X and therefore the evaluation of RMSE is not possible. To measure the estimation performance, we then explicitly treated a part of ob served matrices as missing values and used them as the targets of link prediction. We randomly chose 1 , 000 and 4 , 000 elements as missing values from those of positive (i.e., x t in = 1) and negative ( x in = 0), respectively. For these test data, we evaluated the area under an ROC curve (AUC) score. The AUC score [12] is widely used as an evaluation criterion in link prediction problems. AUC takes it s value from 0.5 to 1: a perfect classifier gets 1 and random one gets 0.5.

For comparison, we applied the Kalman filter algorithm for each element-wise Bernoulli models in DEMF at their rank = 1 , 2 , 4 , 8 , 16 , 24. The other settings of our model were the same as those in the previous experiment.

The experimental results are shown in Figure 3, in which we can see the supe-riority of our method. Except rank-1 Gaussian DEMF, all the AUC scores by our DEMF were higher than those by the Kalm an filter. Our model effectively used the correlation between elements and the n was successful in the link prediction task. Furthermore, DEMF in the Bernoulli model took the best score (0 . 923), suggesting an advantage of using the GLM framework when dealing with non-Gaussian data. Figure 3(b) shows the ROC curves by the three methods at their individual optimal scores. Although the Kalman filter could successfully predict a missing value when the true one is negative (= 0), keeping the false positive rate 0 as well as Bernoulli DEMF, the prediction often failed when it was pos-itive (= 1), so that the true positive rate was low. The Kalman filter was thus not appropriate for our current problem, since it was probably over-fitted to the real observation sequence which contained only few positives. On the other hand, our DEMF avoided such an over-fitting, enj oying the restricted parametrization through the low-rank matrix factorization. In this study, we proposed a new probabilistic dynamic model based on the ma-trix factorization in order to deal with time-varying relational data. We used the Laplace approximation for deriving the sequential Bayesian estimation to track the temporal change of latent low-rank rel ationship effectively. We demonstrated that our model works well in experiments using both synthetic and real datasets.
Several probabilistic models of dynamic relational data have recently been proposed in the literature. Sarkar et al. [13] introduced a latent space model of dynamic social networks. This model estimates the distance between nodes of a social network in the Bernoulli natural parameter space and was applied to the link prediction. The idea of matrix factorization was also used in searching for the optimal initial parameter. Dyna mic topic model (DTM) [14], a dynamic extension of latent Dirichlet allocation (LDA) [15], is a model of temporal evolu-tion of relationships between docume nts and their words. Because LDA has an interpretation as matrix factorization [16], DTM can also be seen as a dynamic extension of matrix factorization.

In this work, the prediction of X was simply done by the model where pa-rameter was set at the MAP estimate. In the Bayesian paradigm, however, it is usual to use the predictive distribution by marginalizing the model parame-ters U and V with their posterior distributions. Although such an integration requires further approximation, it may b e beneficial for better prediction. We are currently investigating the use of sequential Monte Carlo methods [17], also known as the particle filter, to approximate the integral as well as to improve the dynamic filtering. Furthermore, the decomposed parameters U and V can be regarded as extracted features of underlying relationship structure. These features can be useful for dynamic cluster ing of sequential relational data, such as social networks. This issue is also remained for our future study.
