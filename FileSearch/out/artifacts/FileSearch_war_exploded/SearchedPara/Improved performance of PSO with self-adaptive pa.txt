 1. Introduction
Classical methods of optimization involve the use of gradients or higher-order derivatives of the fitness function. However, they are not well-suited for many real-world problems since they are not able to process inaccurate, noisy, discrete and complex data (Bonabeau et al., 1999 ; Kennedy et al., 2001 ). Thus, robust methods of optimization are often required to generate suitable results. For the last decade, many researchers, including those of the water field, have shifted directions, leaving aside traditional optimization techniques and embarking on the implementation of
Evolutionary Algorithms: Genetic Algorithms ( Savic and Walters, 1997; Wu and Simpson, 2001 ; Mat X   X  as, 2003 ; Wu and Walski, 2005); Ant Colony Optimization ( Maier et al., 2003 ; Zecchin et al., 2006); Simulated Annealing ( Cunha and Sousa, 1999); Shuffled Complex Evolution ( Liong and Atiquzzama, 2004 ); and Harmony
Search ( Geem, 2006 ), among others, in the WSS design. As another example, regarding water resources engineering it is worth quoting ( Cheng et al., 2008 ), which uses genetic algorithms and chaos theory; ( Muttil and Chau, 2006 ), using neural networks and genetic programming; ( Lin et al., 2006 ) and ( Wu et al., 2008 ), which make use of support vector machines and support vector regression, respectively; and ( Cheng et al., 2002 ), combining fuzzy theory with genetic algorithms, among others. One of the evolutionary algorithms that has shown great potential and good perspective for the solution of various optimization problems Izquierdo et al., 2008 ; Janson et al., 2008 ; Montalvo et al., 2008b ; Izquierdo et al., 2009 ) is Particle Swarm Optimization. Swarm intelligence is a relatively new category of stochastic, population-based optimization algorithms that are closely related to evolu-tionary algorithms based on procedures that imitate natural evolution. Swarm intelligence algorithms draw inspiration from the collective behaviour and emergent intelligence that arise in socially organized populations.

Empirical evidence ( Shi and Eberhart, 1999 ) has shown that the algorithm is a promising tool for global optimization, and many variants of this algorithm have been established to improve its performance ( Angeline, 1998 ; L X vbjerg et al., 2001 ; Parsopoulos et al., 2001a, 2001b ; Xie et al., 2002 ; Mendes et al., 2004 ; Jiang of stability and parameter selection have also been discussed (Clerc and Kennedy, 2002 ; Trelea, 2003 ; Yasuda et al., 2003 ; Kadirkamanathan et al., 2006 ; Jiang et al., 2007a ).
 However, one laborious aspect of all metaheuristics, including PSO, is performing the appropriate parameter adjustments ( Ueno et al., 2005 ): the PSO can be applied to solve various kinds of optimization problems effectively by adjusting the parameters of the algorithms properly. But the appropriate adjustment of its parameters is cumbersome and usually requires a lot of time, effort and luck. A distinction between the two primary ways of setting parameter values can be made ( Eiben et al., 1999 ): parameter tuning and parameter control. Parameter tuning consists of finding and setting a priori parameter values, whereas parameter control is about using parameter values that change as the algorithm runs.

Optimal parameter values of population-based metaheuristics such as PSO, which are intrinsically dynamic, depend on the state of the algorithm search. As a consequence, the search state should be equipped with the possibility of modifying the parameter values. Eiben et al. (1999), describes two ways of doing this: adaptive parameter control and self-adaptive parameter control.
In adaptive parameter control, the parameter values change according to a heuristic rule that takes feedback from the current search state. The information used for the current state is usually the current iteration of the search, the performance of operators and/or the diversity of the population. In self-adaptive parameter control, the parameters of the metaheuristic are incorporated into the representation of the solution. Thus, the parameter values evolve together with the solutions of the population. Self-adaptive parameter control has been used in genetic algorithms where the parameters have been incorporated into the chromosomes, thus subjecting them to evolution ( Angeline, 1996 ; Robert et al., 1996;
Herrera and Lozano, 1998 ; Smith, 2003 ; Krasnogor and Gustafson, 2004; Haupt and Werner, 2007 ). Other examples, as in the case of differential evolution, include ( Al-Anzi and Allahverdi, 2007 ; Mezura-Montes and Palomeque-Ortiz, 2009 ; Gong et al., 2009 ).
To our knowledge, while adaptive parameter control is common for the PSO, no PSO algorithm presented in the literature uses self-adaptive parameter control, which renders PSO parameters subject to evolution. For example, adaptive parameter control is used for inertia control in Eberhart and Kennedy (1995) and Arumugam and
Rao (2008) by linearly decreasing inertia over the generations, and in Luo and Yi (2007) by using a fuzzy logical controller. It was also used for the acceleration coefficients in Ratnaweera et al. (2004) and Arumugam and Rao (2008) by balancing the cognitive and the social components. In this paper, in addition to using the adaptive parameter control for the inertia proposed by Eberhart and Kennedy (1995), which has been used with success during the last ten years in many applications with the same meaning and functionality, we embed the other parameters within the evolution variables, so that they are self-adaptively controlled. Other features previously introduced by the authors ( Izquierdo et al., 2008 ; Montalvo et al., 2008a, 2008b, 2008c ), unrelated to this paper, are also considered in thesameframework.

The remainder of this paper is organized as follows: Section 2 presents the rules for the manipulation of the particles in each iteration, and explains how parameters are controlled. In
Section 3, we describe the main algorithm of this paper, which includes other features already introduced by the authors within the co-evolving framework. After introducing the problem of the design of a Water Supply System (WSS), we report and analyze the numerical experimental results on the benchmark problems in Section 4, compare our algorithm results with other existing solutions, and provide the solution for a real-world problem. 2. PSO and the proposed parameter control A swarm consists of a set of an integer number, M , of particles,
X , moving within the search space, S C R d , each representing a potential solution of the problem Find ; min where F is the fitness function associated with the problem, which we consider to be a minimization problem without loss of generality.
In each cycle of the evolution, t , each particle, i , has a position vector,
X  X  t  X  X  X  x i 1 ; ... ; x id  X  ; a velocity vector,
V  X  t  X  X  X  v i 1 ; ... ; v id  X  and the position at which the best fitness was encountered by the particle,
Y  X  t  X  X  X  y i 1 ; ... ; y id  X  X  argmin  X  F  X  X i  X  t  X  X  ; F  X  X Also, the position of the best particle of the swarm,
Y  X  argmin f F  X  X i  X  t  X  ; i  X  1 ; ... ; M g ; is identified. 2.1. Manipulation of particles
In each generation, the velocity of each particle is updated by means of their best encountered position and the best position encountered by any particle
V  X  o V i  X  c 1 rand  X  X  X  Y i X i  X  X  c 2 rand  X  X  X  Y X i  X  X  1  X 
On each dimension, particle velocities are restricted to minimum and maximum velocities, which are user-defined parameters,
V r V j r V max ;  X  2  X  to control excessive roaming of particles outside the search space. Usually, V min is taken as V max .

The position of each particle is also updated in every generation. This is done by adding the velocity vector to the position vector
X  X  X i  X  V i :  X  3  X 
The parameters are as follows: o is a factor of inertia suggested by Shi and Eberhart (1998) that controls the impact of the velocity history into the new velocity. Acceleration parameters c 1 and c 2 are typically two positive constants, called the cognitive and social parameters, respectively. rand ( ) repre-sents a function that creates random numbers between 0 and 1; two independent random numbers are included in Eq. (1), which are used to maintain the diversity of the population.

However, the choice of the PSO algorithm X  X  parameters (such as the group X  X  inertia and acceleration coefficients) seems to be of utmost importance for the speed, convergence and efficiency of the algorithm ( Yao et al., 1999). 2.2. Manipulation of parameters
The role of the inertia weight, o , in (1), is considered critical for the PSO algorithm X  X  convergence behaviour. Although the inertia weight was initially constant, it may vary from one cycle to the next. As it balances global and local searches, it has been suggested to have it decrease linearly with time, usually in a way to first emphasize global search and then, with each cycle of the improvement in the performance of PSO with the decreasing inertia weight over the generations is achieved using an equation proposed by Jin et al. (2007)  X  0 : 5  X 
This parameter is adaptively controlled by using (4) in the proposed framework.

Suitable fine-tuning of cognitive and social parameters c in (1) may result in faster convergence of the algorithm and alleviate PSO, an extended study of these acceleration parameters is given by
Kennedy (1999). As default values, c 1 = c 2 =2 were proposed, but experimental results indicate tha t alternative configurations, de-pending on the problem, may produ ce superior performance. Recent work reports that it might be even better to choose a larger cognitive parameter, c 1 , than a social parameter, c 2 ,butwith c 1 (Ratnaweera et al., 2004 ). Arumugam and Rao (2008) suggest that the acceleration coefficients are neither set to a constant value nor set as a linearly decreasing time var ying function. Instead, they are defined as a function of local best and global best values of the fitness function of a minimization problem.

Finding an appropriate value of V max according to the problem to be solved was a difficult task. Thus, Shi and Eberhart (1998) proposed a modification of their original PSO equation, which did not include the inertia parameter, to the actual Eq. (1). Also, Clerc (1999) introduced another parameter called the constriction factor, which may help to ensure convergence. The constriction model describes the way of choosing o , c 1 and c 2 so that convergence is ensured. By choosing the values correctly, the velocities of all the particles are obviated within the range of [ V max , V max ]. Eberhart and Shi (2000) compared the perfor-mance of PSO using the V max clamping to one using only the constriction factor. Even though the inclusion of the constriction factor seems to increase the rate of convergence, when tested on the benchmark problems, the constriction model failed to reach the specified error threshold within the allocated number of iterations. Later, it was found that since the particles stay far from the desired range of the search space, the constriction model fails to converge within the stipulated number of iterations.
In Section 3, a self-adaptive manipulation of c 1 , c 2 and V considered that avoids the cumbersome task of first localizing and then fine-tuning these three parameters. 3. The proposed approach
In previous works ( Montalvo et al., 2008a, 2008b, 2008c ), the authors have addressed the same optimization problem by using fixed values for parameters c 1 , c 2 and V max . The values used were obtained after some parametric trial and error process, and the obtained results were at the same time among the best and the least computationally expensive in the related literature. An example of this parametric study related to V max is shown in Fig. 1 for one of the water supply networks considered in this paper.
This figure shows the probability for a single run of the algorithm described by Montalvo et al. (2008a) of obtaining a solution with a cost differing from that of the best known solution by less than a certain percent for different fixed values of V can be easily observed that if particles are clamped to less than 30%, the quality of solutions is essentially lower because this small value greatly reduces the particles X  ability to explore. On the other hand, if particles are allowed to change their velocity by more than 40%, much better results are obtained.

Similar arguments may be raised for c 1 and c 2 to show that the best solutions are obtained for certain ranges of these three parameters. But, certainly there is no evidence that the best values have been used simultaneously, or that they are the same for the whole iteration process and/or for all particles. In this paper, the acceleration coefficients and the clamping velocity are neither set to a constant value, like in standard PSO, nor set as a time varying function, like in adaptive PSO variants. Instead they are incorporated to the own optimization problem, as explained below.

Each particle will be allowed to self-adaptively set its own parameters by using the same process used by PSO given by Eqs. (1) and (3). To this end, these three parameters are considered as three new variables that are incorporated with position vectors X i . In general, if d is the dimension of the problem and p is the number of self-adapting parameters, the new position vector for particle i will be: X  X  X  x i 1 ; ... ; x id ; x id  X  1 ; ... ; x id  X  p  X  X  5  X 
It is clear that the first d variables correspond to the real position vector of the particle in the search space, while the last p account for its personal acceleration constants and velocity limit.
Obviously, these new variables do not enter the fitness function, but are manipulated using the same mixed individual X  social learning paradigm as the one used in PSO.

Also, V i and Y i , which represent the velocity and best position so far for particle i , respectively, increase their dimension V  X  X  v i 1 ; ... ; v id ; v id  X  1 ; ... ; v id  X  p  X  ;  X  6  X 
This way, by using Eqs. (1) and (3), each particle will be additionally endowed with the ability of adjusting its parameters by aiming at both the parameters it had when it got its best position in the past and the parameters of the leader, which managed to bring this best particle to its privileged position. As a consequence, particles not only use their cognition of individual thinking and social cooperation to improve their positions, but also to improve the way they do it by accommodat-ing themselves to the best known conditions: namely, their conditions when getting the best so far position and the leader X  X  conditions.

Before providing a schematic representation of the proposed algorithm, two more observations have to be made.

Firstly, the discussion so far considers the standard PSO algorithm, which is applicable to continuous systems and cannot be used for discrete problems like the one we consider here.
To tackle discrete variables, this algorithm takes integer parts of the flying velocity vector components into account; thus, the new velocities V i are integers, and consequently, the new position vector components will also be integers (since the initial position vectors were generated with integer values).

According to this idea, instead of Eq. (1), velocity updating for discrete variables turns out to be
V  X  fix  X  o V i  X  c 1 rand  X  X  X  Y i X i  X  X  c 2 rand  X  X  X  Y X i where fix ( ) implies that we only take the integer part of the result.

Secondly, in ( Montalvo et al., 2008a ), PSO was endowed with a re-generation-on-collision formulation, later generalized in (Montalvo et al., 2008c ), which further improves upon the performance of the standard discrete PSO. The random regenera-tion of the many particles that tended to collide with the best birds was shown to avoid premature convergence, as it prevented clone populations from dominating the search. The inclusion of this procedure into the discrete PSO produces greatly increased diversity, improved convergence characteristics and increased the quality of the final solutions. The modified algorithm can be given by the following pseudo-code, with t as iteration number. t =0
Generate a random population of M particles: X i  X  t  X  M i  X  1 according to (5)
Evaluate the fitness of the particles (only the first d variables enter the fitness function) values of the corresponding parameters are also recorded
Record the global best location, Y n ( t ), and the list of the m best particles to check collisions (including their corresponding parameters) While (not termination-condition) do J Determine the inertia parameter o ( t ), according to (4) J Begin cycle from 1 to number of particles M J t = t +1 Show the solution given by the best particle As in our previous work, we have used a population size of
M =100 particles for most of the tests. Nevertheless, we also use other sizes to compare some specific aspects of performance, as shown in the next section.

Different termination conditions, like number of fitness function evaluations, maximum run time, convergence in the fitness or search space, may be stated ( Shi et al., 2007 ). In this paper, the termination condition stopped the process if, after a pre-fixed number of iterations, no improvement in the solution had been obtained. In this specific case (PSO applied to WSS design) this number has been chosen as 800. We have checked that much smaller values hinder the algorithm in its search ability, while bigger values render the algorithm inefficient as the decreasing inertia impairs the algorithm X  X  search potential.
The performance of the approach introduced herein can be observed from the results obtained for the two benchmark problems and the real-world problem studied in the next section. 4. Testing benchmark problems and results
The optimal design of a WSS involves determining the values of all involved variables in such a way that the investment and maintenance costs of the system are minimal, subject to a number of constraints ( Izquierdo et al., 2004 ). A general strategy for solving the optimal design problem of a WSS involves the balancing of several factors: finding the lowest costs for layout and sizing using new components, reusing or substituting existing components, creating a working system configuration that fulfils all water demands, adhering to the design constraints, and guaranteeing a certain degree of reliability for the system ( Goulter and Coals, 1986; Goulter and Bouchart, 1990 ). The benchmark cases we address here have been used traditionally in the literature and are standard examples used to demonstrate the application of a wide range of tests and analyses. The fitness function that has traditionally been used for them only takes pipeline costs into account. Nevertheless, a generalization to broader classes of fitness functions is straightforward. Hence, in order to facilitate comparisons with the results obtained by other authors, we use the following fitness function to estimate the costs F  X  D  X  X  where P is the number of pipes in the network, D =( D i ) the vector of pipe diameters (which is P -dimensional and its components belong to a discrete set of commercially available diameters), C ( D It should be noted that C ( ) is a non-linear function of diameter.
Also, in order to restrict ourselves to the same rules used in the literature to deal with these benchmark problems, only three kinds of constraints are considered here: continuity equations and energy equations (strongly non-linear), both enforced in the hydraulic model, and lack of satisfaction of minimum pressures at demand nodes, P j Z P min . As a consequence, the total cost of the network is considered as the sum of the network cost (9) and a penalty cost, which is defined as F  X  where K is the number of constraints; v j =( P min  X  P j ) H ( P
H ( ) the Heaviside step function; v j the j th constraint violation; and penalty j represents the penalty parameter corresponding to constraint j with a large value (here 10 9 ) to ensure that infeasible solutions will have a cost greater than any feasible solution. The problems faced in the optimal design of WSSs are great.
Furthermore, this simple variant for the design of a WSS is NP-hard. One of the networks considered in this section, with 21 pipes and 15 potential commercial pipe diameters, has 16 21 possible pipe diameter combinations (including a null option) that constitute the search space of the problem. The second, with 34 pipes and 6 potential pipe diameters has 6 34 possible pipe diameter combinations. These modest networks would require a considerable amount of time for an exhaustive search algorithm to navigate the entire search space of almost 2 10 25 and 2.87 10 26 potential solutions, respectively.

The first case is the New York Tunnel (NYT) water supply network, which has been addressed several times in the literature (Savic and Walters, 1997 ; Maier et al., 2003 ; Mat X   X  as, 2003 ). A complete detailed description can be seen in ( Dandy et al., 1996 ). The system has a fixed head reservoir, 21 tunnels and 19 nodes.
The objective of the NYT problem was to determine the most economically effective design in addition to the existing system of tunnels that constituted the primary water distribution system of the city of New York. Because of age and increased demands, the existing gravity flow tunnels were found to be inadequate to meet the pressure requirements for the projected consumption level.
The construction of additional gravity flow tunnels parallel to the existing ones was considered. All 21 tunnels are considered for duplication. There are 15 available discrete diameters and one extra possible decision which is the  X  X  X o nothing X  X  option. The second case is the Hanoi pipe network, also studied extensively by various researchers ( Savic and Walters, 1997 ; Cunha and Sousa, 1999; Mat X   X  as, 2003 ; Zecchin, 2003 ; Zecchin et al., 2005 ). The complete setting can be found in ( Wu and Simpson, 2001 ). This network consists of a single fixed head source at elevation of 100 m, 34 pipes and 31 demand nodes organized in three loops and two ramified branches. One has to find the diameters (from a set of six commercially available diameters) for the 34 pipes such that the total cost of the network is minimal and the pressure at each node of consumption is at least 30 m.

Even though it is not the main objective of this paper, the PSO version we use here is able to obtain the best solution found in the literature for both systems. This is shown in Table 1 for the New
York system and in Table 2 for the Hanoi case, together with other best solutions found in the literature.

The primary goal of this paper hinges on the evolution of parameters c 1 , c 2 and V max , which are automatically and adaptively managed by the algorithm. Parameters c 1 and c bound to vary between 0 and 5, and V max is allowed to vary within its whole range, from 0 to 100%. Fig. 2 shows, as an example, the evolution of parameters c 1 and c 2 , for the eventual leaders of two runs of the algorithm without the regeneration feature previously described (first row of graphs), and for the eventual leaders of three runs with activated regeneration feature (second row of graphs). Only the first 250 iterations are shown. The results refer to the Hanoi problem. It has to be noted that this is a more difficult problem than NYT. For the sake of brevity we will omit similar graphs for this last problem.

A number of things can be observed here. First, there are random values at the beginning of each execution. Also, the random regeneration undergone by the birds (which were not the leaders during the whole process) is observed in the lower graphs. It can also be observed (lower graphs) how one of the birds managed to reach the optimum before iteration 150. Previously it had been randomly regenerated twice around iterations 40 and 110. As a consequence, it is seen that there is no need for specific initialization and the re-generation-on-collision feature provides increased diversity even for the values of the parameters.
Finally, and most importantly, the clear tendency to approach certain values within a range between 2 and 3 for both parameters can also be readily observed. This tendency is more clearly observed in Fig. 3 , which shows the evolution of c for the particles that eventually got the leadership in 100 runs of the algorithm, but with the re-generation-on-collision feature disabled, for the sake of clarity.
 A similar graph can be produced for the V max evolution ( Fig. 4 ). It can be observed that V max tends to some value in the range [0.34, 0.6].

After running the algorithm100 times, the probability of a single run obtaining a solution differing by less than a certain percent from the best known solution was obtained. This probability, used by the authors as an indicator of the algorithm performance ( Montalvo et al., 2008a, 2008c ), is also very important from a practical point of view, in which  X  X arly X  almost-optimal solutions are much better than  X  X oo late X  best solutions. These probabilities have been plotted in Fig. 5 for the self-adaptive algorithm together with the same curves for fixed values of the parameters, already calculated in ( Montalvo et al., 2008c ).

It is clear that the self-adaptive algorithm exhibits slightly lower performance than the algorithm with fixed parameters, but this is an unfair comparison, since the same number of particles has been used for both algorithms to explore spaces of different dimensions. Clearly, the self-adaptive algorithm has to confront a space of higher dimensionality. By multiplying by 6 (according to the number of used values for the percent variation of V max population of birds for the self-adaptive algorithm, it can be observed (see Fig. 6 ) that its performance is better than that of the algorithm with fixed parameters. For example, one single run guarantees a solution that is less expensive than 5.5% of the best known solution with a probability of 86% for the algorithm with fixed parameters, while the same figure is 95% for the self-adaptive version discussed herein. Additionally, there is an almost complete guarantee that in only one run of the self-adaptive algorithm we will obtain a solution with a cost under 1.08 times the best known solution cost. For the algorithm with fixed parameters, this curve approaches a probability of 100% for values bigger than 8% of the excess cost.

The curves in Fig. 6 are application-dependent and cannot be directly extrapolated to other problems. However, it is seen that the algorithm presented in this paper was able to find the optimum or near-optimum solution without the need for prior adjusting and fine-tuning of the parameters. Also, these results support the initial hypothesis that, when using fixed parameters, neither are the best values for all parameters used simulta-neously, nor are they the same for the whole iteration process and/or for all of the particles.

In the case study we present next  X  which corresponds to a real-world network  X  (see Fig. 7 ) the minimum pressure allowed is 15 m, and the available commercial diameters are given in
Table 3 . This table also includes the Hazen X  X illiams coefficient, C , used in the hydraulic model, and the unit cost of the available and variously sized pipes.

This network, which is fed by a tank, has 294 lines amounting to 18.337 km of pipes, and 240 nodes consuming 81.53 l/s in total.
The dimensionality of this problem, which is of moderate size, is immense.

To compare the performance of the algorithm with and without the self-adaptive feature for this real-world problem a number of runs have been performed. For the case with no self-adaptive parameters, c 1 = c 2 =2 and V max =50% of the variables range were used. For the case with self-adaptive parameters, c and c 2 were allowed to vary between 0 and 5 and V max between 0 and 100% of the variables range.

A population of one hundred birds was used in both cases. A PC with a processor Intel Core 2 Duo T5500 (1.66 GHz), which performed 5.49 iterations per second, was used. In each iteration, the fitness function is evaluated for all the particles and their position is suitably updated. Both versions, with and without the self-adaptive feature, managed to obtain the same  X  X irtually best X  solution in all the cases. This solution has a cost of 2148053 monetary units (Peruvian soles).

On average, the self-adaptive version needed 107 more iterations per run. The minimum number of generations to obtain the best solution was 1293 for the version without self-adaptive 0 1 2 3 4 5 0 1 2 3 4 5 0 50 100 150 200 250 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Vmax / range of variables parameters, and 1459 when the self-adaptive feature was used. It has to be noted that the self-adaptive version had to search on a space of slightly higher dimension. However, the version without self-adaptive parameters started from the highly privileged position of using an a priori fine-tuned set of parameters. 5. Conclusions
PSO is a promising tool for global optimization and many variants of this algorithm have been established to improve its performance. However, one laborious aspect pervading all metaheuristics is how to perform appropriate parameters adjust-ment. To our knowledge, adaptive parameter control is common in EA, but no algorithm presented in the PSO literature uses a self-adaptive parameter control, which renders PSO parameters subject to evolution.

In this paper, PSO is endowed with a self-adaptive evolution feature for three of its parameters, which equals previous results of standard discrete PSO and other evolutionary techniques when applied to two well-known benchmark problems in the literature, namely the Hanoi and New York tunnels systems. However, the main breakthrough is that this formulation obviates the tedious pre-processing task of parameter fine-tuning. The study also shows that this feature together with other modifications previously introduced by the authors can be greatly useful when applied to other real-world problems, what demonstrates the scalability of the algorithm. The main advantages of the method are that it does not require sophisticated operators or parameters and is thus simpler than other evolutionary techniques; it does not need initial feasible particles, nor do the regenerated particles need to be feasible; and finally, it is robust in handling diverse fitness functions and different constraints. Furthermore, having a low number of generations is a major advantage in real water distribution systems where cost and time constraints prohibit repeated runs of the algorithm and hydraulic evaluations. From the studied problems, it can be inferred that obtaining  X  X ood X  solutions with the proposed algorithm is straightforward, since there is no need for a priori parametric study. This algorithm is also relatively inexpensive as the computational cost increased only slightly because of the relatively small increase in the dimensionality of the search space. Therefore, the algorithm is desirable from an engineering point of view, when frequently the goal is to quickly obtain good solutions that are not necessarily very close to the optimum.

The main limitation for this work resides on the lack of a clear rationale regarding the population size, since this parameter has not being subjected to (self)-adaptivity. We point towards the use of small or moderate populations, since the abilities of these particles to decide, as a group, how to move inside the search space, and change their behaviour during the search processes, as well as finding very good solutions in a relatively short period of time, constitutes an open-door environment that could be perfectly exploited to address multi-objective formulations regarding optimization problems in different fields. It is precisely the assembly of these capabilities that makes the PSO algorithm a powerful multi-agent system for solving complex optimization problems, in particular in the water industry.

Finally, since solutions for engineering applications are usually obtained after various executions of the problems in hand, the evolution of the parameters can be recorded and used to train intelligent mechanisms that are able to predict the best parameter values for a given application. In this context, synergic actions between PSO and Support Vector Machines, for example, should be explored.
 Acknowledgements This work has been performed with support from the Grants
BES-2005-9708 and MAEC-AECI 0000202066 awarded to the first and forth authors, respectively, by the Ministerio de Educacio  X  ny Ciencia and the Ministerio de Asuntos Exteriores y Cooperacio  X  nof
Spain. Also thanks to the support of the project IDAWAS, DPI2009-Educacio  X  n y Ciencia.
 References
