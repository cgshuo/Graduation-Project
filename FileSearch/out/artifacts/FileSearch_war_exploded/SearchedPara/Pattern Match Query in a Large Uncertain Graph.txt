 Many studies have been conducted on seeking an efficient solu-tion for pattern matching over graphs. This interest is largely due to large number of applications in many fields, which require ef-ficient solutions for pattern matching, including protein complex prediction, social network analysis and structural pattern recogni-tion. However, in many real applications, the graph data are often noisy, incomplete, and inaccurate. In other words, there exist many uncertain graphs. Therefore, in this paper, we study pattern match-ing in a large uncertain graph. Specifically, we want to retrieve all qualified matches of a query pattern in the uncertain graph. Though pattern matching over an uncertain graph is NP-hard, we employ a filtering-and-verification framework to speed up the search. In the filtering phase, we propose a probabilistic matching tree , PM-tree, based on match cuts obtained by a cut selection process. Based on PM-tree, we devise a collective pruning strategy to prune a large number of unqualified matches. During the verification phase, we develop an efficient sampling algorithm to validate the remaining candidates. Extensive experimental results demonstrate the effec-tiveness and efficiency of the proposed algorithms.
Graphs constitute a generic data model with wide applicability in numerous domains and applications, such as social networks, biological networks, and World Wide Web. Reasons for this in-clude: It can be less complex for a user to shoehorn semi-structured or sparse data into a vertex-edge-vertex data model than a rela-tional data model; Some increasingly popular data sets (such as the Twitter, Facebook, and LinkedIn social networks) are most nat-urally reasoned about using a graph paradigm. Various types of queries have been investigated over graph data, such as subgraph search [31, 36, 4], shortest-path query [3, 7], reachability query [30, 16], and pattern match query [37, 5]. Reachability or shortest path query studies a relation between two vertices in a graph, while pattern match query emphasizes the connectivity between a set of vertices. Thus, a pattern match query is more informative than a simple shortest-path or reachability query. Also, a pattern match query can be answered in polynomial time [12], while processing a subgraph query is # P-complete [13]. Therefore, the database com-munity has put considerable effort in studying the pattern match query problem [12, 22, 10, 37, 5].

All of the above works focus on the applications where edges between two vertices are deterministic. However, these data are inherently uncertain in real applications because of the inevitable noise, incompleteness, and delay during data collection. For exam-ple, in Protein-Protein Interaction (PPI) network, the proteins ob-tained from experiments may either contain some nonexisting pro-tein interactions, or miss some existing ones [29, 6, 27]. In social networks, very often graphs are also used to represent communities of users, where probabilities can be assigned to edges to model the link or the degree of influence between two users. [1, 20]. In com-munication networks or road networks, edge probabilities are used to quantify the connectivity between nodes, or to take traffic uncer-tainty into consideration [14]. The uncertainty in a RDF graph is caused by data errors or semantic extraction inaccuracy in the data integration process [15, 19].

Based on the above discussions, in this paper, we study pattern match queries over a large uncertain graph. In the following, we give the details about probabilistic pattern match query and contri-butions, respectively.
We first introduce graph pattern matching on deterministic graphs, then we will proceed to discuss uncertain graph pattern matching.
Given a query pattern graph q with n vertices { v 1 , ..., v a deterministic graph g c , a deterministic pattern match query re-trieves all matches of q in g c . For a given q and an n vertex set m = { u 1 , ..., u n } in g c , m is a match of q in g c , if (1) the n ver-tices { u 1 , ..., u n } in g c have the same labels as the corresponding vertices { v 1 , ..., v n } in q ; and (2) for any two adjacent vertices v and v j in q , the shortest-path distance of two corresponding vertices { u i , u j } in g c is no larger than a given threshold  X  [11, 37].
Example 1. Consider the query pattern q and the deterministic graph ug c in Figure 1. For this example the probabilities of each edge can be ignored. Let the weight of each edge be  X 1 X  and the distance constraint  X  be  X 3 X . Vertices { 2 , 5 , 7 } or { a match of q in ug c , since their vertex labels are { A, B, C as those of q and the shortest-path distance of each pair of ver-tices is less than  X 3 X . Though the vertex set { 1 , 5 , 7 {
A, B, C } , it is not a match, since the shortest-path distance be-tween vertices 1 and 7 is  X 4 X  that violates the distance constraint.
This semantics of pattern match query has many real life applica-tions [12, 11, 37]. For example, suppose Figure 1 is a graph model of LinkedIn, where vertices represent active users and the edges in-dicate the friendship relations between two users. Job attributes as vertex labels are associated with vertices, i.e., { A, B, C Professor, Student}. The pattern match query q looks for relations between scientist, professor and student. Finding such patterns may help social science researchers discover close connections (due to the distance constraint) between a successful scientist and his/her circle of students or professors.

For the uncertain graph pattern matching, in this paper, we focus on threshold-based probabilistic pattern matching (T-PM) over a large uncertain graph where vertices are deterministic and edges are uncertain. Specifically, let g be an uncertain graph, let q be a query pattern graph, and let  X  be a probability threshold, a T-PM query retrieves all vertex sets m = { u 1 , ..., u n } in g (i.e. n vertices in g ), such that the pattern matching probability (PMP) of m in g is at least  X  . We will formally define PMP later.

We employ the possible world semantics [28], which has been widely used for modeling query processing over uncertain databases, to explain the semantics of PMP. A possible world graph (PWG) of an uncertain graph is a possible instance of the uncertain graph. It contains all vertices and a subset of edges of the uncertain graph, and it has a weight which is the product of all probabilities asso-ciated with the edges. Then, for a query graph q with n vertices { v 1 , ..., v n } and an n vertex set m = { u 1 , ..., u n } graph g , the probability of m being a match of q is the summation of the weights of those PWGs g  X  , of g , where m is a match of q in g . If m is a match of q in g  X  , it should satisfy the two conditions of the deterministic graph pattern matching as defined above.
Example 2. Figure 2 lists partial PWGs of uncertain graph ug as given in Figure 1 and their respective weights. There are all together 2 9 = 512 PWGs for ug , and the sum of all weights is 1. To decide if a vertex set m = { 5 , 6 , 7 } is a match of q in the uncertain graph ug , we first find all of ug  X  X  PWGs that contain m as a match of q . m is a match of q in g  X  , if: (1) vertices in m and q have the same labels, (2) each pair of corresponding vertices in m has a shortest-path distance of at most 3 (  X  is 3). The results are PWGs 1, 2,... Next, we get the summation probability of these PWGs: 0.01248+0.009126+...=0.65. If a threshold 0.6 is used for the query, then m is a qualified match of q in uncertain graph ug .
The above example gives a naive solution to T-PM query pro-cessing. We call it SCAN , as it needs to enumerate all PWGs of the uncertain graph, and to conduct a pattern matching between the query and each PWG. SCAN is very inefficient due to the expo-nential nature of the number of PWGs. Therefore, in this paper, we propose a filter-and-verification method to reduce the search space.
Specifically, given a query pattern graph q and a large uncer-tain graph g , our solution performs T-PM query processing in three steps, namely structural pruning, probabilistic pruning, and verifi-cation. In the structural pruning step, we conduct q on a determin-istic graph g c , that removes uncertainty from g , and get a match candidate set SC q . In the probabilistic pruning, we first obtain a tight upper bound for PMP via a pre-computed index. The index is based on edge cuts of g c . Next we refine the set of candidates in SC q , by pruning those potential matches for which its upper bound is smaller than the probability threshold. In the verification phase, we validate each candidate match remaining after the previous step to determine the final answer set.

To summarize, we make following contributions in this paper.
The remainder of this paper is organized as follows. We formally define T-PM queries over an uncertain graph and give the com-plexity of the problem in Section 2. In Section 3 we will give an overview of our approach while section 4 focuses developing algo-rithms for efficient probabilistic pruning and calculating the upper bounds of the PMP. Index construction and sampling based verifi-cation algorithms will be presented in Sections 5 and 6 respectively. We discuss the results of performance tests on real data sets in Sec-tion 7 and the related works in Section 8. Finally, in Section 9 we present our conclusion.
In this section, we define some necessary concepts and show the complexity of the problem at hand.

Definition 1. ( Uncertain Graph ) An undirected deterministic graph g c , is denoted as ( V, E, , L ) , where V is a set of vertices, E is a set of edges (  X  V  X  V ), is a set of labels, and L : V is a function that assigns labels to vertices. An uncertain graph is defined as g = ( g c , P r ) , where P r : E  X  (0 , 1] is a function that assigns existence probabilities to edges in E .

Note that g can be a disconnected graph, and may have multiple connected components.

Definition 2. ( Possible World Graph ) A possible world graph g  X  = ( V  X  , E  X  ,  X  , L  X  ) is an instantiation of an uncertain graph g = (( V, E, , L ) , P r ) , where V  X  = V , E  X   X  E ,  X  = . We denote the relationship between g  X  and g as g  X  g  X  .
We use P W G ( g ) to denote the set of all possible world graphs derived from g .

Following the convention in [18, 38, 39, 26, 33], we assume the existences of different edges in an uncertain graph are independent. Then, the probability of a possible world graph g  X  is given by:
Definition 3. ( Match [11, 37]) Consider a deterministic graph g , a connected query graph q that has n vertices { v 1 , ..., v and a shortest path threshold  X  . A set of n distinct vertices m = { u 1 , ..., u n } in g c is said to be a match of q , denoted by m if and only if the following conditions hold: (1) L ( u i  X  i  X  [1 , n ] , where L ( u i ) denotes the label of u i ; and (2) If there is an edge between v i and v j in q , the shortest-path distance between u and u j in g c is no larger than  X  .

For example, in Figure 1, assume all edge weights of ug c and  X  = 3 . Then vertex set { 5 , 6 , 7 } is a match of q in ug set { 1 , 5 , 7 } is not a match of q in ug c since the distance between vertices 1 and 7 is larger than  X  .

Definition 4. ( Pattern Matching Probability ) For a query graph q , an uncertain graph g and a vertex set m in g , we define the pat-tern matching probability of m in g under q as: where P M ( q, g ) is g  X  X  possible world graphs that contain m as a match of q , that is, P M ( q, g ) = { g  X  | m D q g  X  , g
Note that, if m is a match of the possible world graph g  X  should satisfy (1) vertex labels of m are the same as the corre-sponding vertex labels of q , (2) each pair of vertices of m in g the shortest-path distance within the threshold  X  .

Definition 5. ( Probabilistic Pattern Matching ) Given an un-certain graph g , a query graph q , and a probability threshold  X  ( 0 &lt;  X   X  1 ), a pattern matching query returns all vertex sets, in g , { m | P r ( m D q g )  X   X , m  X  V ( g ) } .

From Definition 5, we know that in order to answer probabilis-tic pattern match queries efficiently, we must be able to calculate PMP (pattern matching probability) efficiently. We now show the complexity of calculating PMP.

Theorem 1. It is NP-hard to calculate the pattern matching probability.
 Proof. We reduce the well-known NP-complete problem STEINER Tree [13] to computing the pattern matching probability. Consider a query q and a vertex set m that has been a valid match of g the sequel we determine if m is also a valid match of g ; that is to say if the PMP of m in g is at least a given threshold. Assume the existence probability of each edge in g equals p . Define a pathset as a set of edges that connect the vertices in m . Based on Definition 4, it is not difficult to obtain the PMP as: where N i is the number of i -edge pathsets that connect all vertices in m , and | E | is the number of edges of g .

An instance of STEINER TREE is graph g c = ( V, E ) , a set m of target vertices, and an integer bound b . One has to determine whether there is a Steiner tree with b or fewer edges in g one must decide whether there is a set of b or fewer edges which connect all of the target vertices in m by paths. Using an algorithm calculating P r ( m D q g ) , we produce the sequence of pathset num-bers N 1 , ..., N | E | in Equation 3. We then extract l , the size of a minimum pathset. Since l is the index of the first nonzero term in the pathset numbers, it is easily extracted. A pathset for g contains at least a Steiner tree for m ; hence the minimum pathset is a minimum Steiner tree. Thus we just check whether l  X  b . The re-duction is completed.
Figure 3 illustrates a general framework for a pattern match query q over an uncertain graph g , which consists of three phases, namely Structural pruning , Probabilistic pruning , and Verification . The first two phases belong to filtering step and the last one is the veri-fication step. We briefly present each step in the following. Structural Pruning. The idea of structural pruning is straightfor-ward. For n vertices m = { u 1 , ..., u n } in g , if we remove all the uncertainty in the uncertain graph g , and m is still not a match of q in the resulting graph, then m cannot be a match of q in the original uncertain graph.

Formally, for m = { u 1 , ..., u n } X  g , let g c denote the cor-responding deterministic graph after we remove all the uncertain information from g . Then based on Def. 4, it is easy to have Theorem 2. If m 4 q g c , P r ( m D q g ) = 0 .

This theorem shows that only qualified matches in g c under q can be candidates of the T-PM query. Based on this observation, given g and q , we can obtain candidate matches using conventional deterministic graph pattern matching methods. In this paper, we adopt the method in [37] to quickly compute a preliminary set of candidates. [37] uses a distanced-based joining algorithm and many pruning strategies to greatly reduce the search space without performing pairwise matching computation, which enables higher running efficiency than other known graph pattern matching algo-rithms [11]. Assume the result is SC q = { m | m D q g c } is the input for uncertain pattern matching in the next step. Probabilistic Pruning. In this step, we propose a tight upper bound, U pperB , for the pattern matching probability, i.e., P r ( m U pperB . For the given threshold  X  , if U pperB &lt;  X  , m can be pruned safely. In this step, we propose one-by-one and collective pruning algorithms to efficiently obtain the candidate set C into the verification step.
 Verification. In this step, we calculate the true P r ( m each remaining candidate answer m in C q , to make sure m is a true answer, i.e. P r ( m D q g )  X   X  .
As mentioned above, we first conduct structural pruning to ob-tain a set of qualified candidate matches of q in g , after which we use probabilistic pruning techniques to further filter the remaining match set, named SC q .

The principle of the probabilistic pruning is that we get the upper bound of PMP. To facilitate this process, we propose an indexing structure, called Probabilistic Matching Tree (PM-tree).
Before we introduce the structure of PM-tree, we first give some definitions. Given a deterministic graph g c , a cut in g ing of V ( g c ) into two disjoint sets ( X, X ) , where X, X X  X  X = V ( g c ) . Any edge ( u, v )  X  E ( g c ) with u  X  X and v  X  X is said to be crossing the cut and is a cut edge . The set of all cut edges between ( X, X ) is denoted by  X  ( X ) . An x -y cut is a split of the vertices V ( g c ) into two disjoint sets X and X , such that x  X  X , y  X  X .

For e xample, in Figure 1, ( X = { 1 , 2 , 4 } , X = { 3 , 5 , 6 , 7 cut in graph ug c and { e 5 , e 8 } are cut edges of ( X, X ) . ( X, X ) is a 1 -6 cut since 1  X  X  1 , 2 , 4 } and 6  X  X  3 , 5 , 6 , 7 Definition 6. (Probabilistic Matching Tree) The structure of PM-tree is a tree structure T = ( V ( T ) , E ( T )) . Each node of T is a vertex of V ( g c ) , i.e., V ( T ) = V ( g c ) . Each edge e T satisfies the following properties: For each pair of distinct nodes ( s, t ) and an edge e on the unique path between s and t , deleting e separates T into two connected components, X and X ; under these conditions, ( X , X ) is an s -t cut in g c . Specifically, deleting e = ( u, v )  X  E ( T ) results in a u -v cut for u  X  U and v attac h all cut edges of the u -v cut to edge e . We also calculate the connected probability between U and U , and attac h its value to e .
Note that, to avoid confusion, we use node for T , while vertex for uncertain graph g .

Example 3. Figure 4 shows the PM-tree of graph ug in Figure 1, and PM-tree is a tree structure T . Deleting edge (4 , 3) divides T into two parts ( X = { 1 , 2 , 4 } , X = { 3 , 5 , 6 , 7 cut in ug c . The cut edge set  X  ( X ) = { e 5 , e 8 } and its connected probability 0.88 are indexed by the edge (4 , 3) .

Let  X  ( U ) = { e 1 , ..., e | ( U ) | } denote the set of all cut edges be-tween U and U . Then the connected probability between U and U is calculated as follows,
We will give the construction algorithm of PM-tree in Section 5, and then proceed to prove that PM-tree has the properties given in Definition 6.

Furthermore, we need to define match cuts . For m = { u 1  X 
SC q , a match cut of m is a set of edges in g c whose removal causes disconnections between vertices of { u 1 , ..., u n
For example, consider m = { 2 , 5 , 7 } in the deterministic graph ug c shown in Figure 1. The edge set { e 2 , e 4 } or { e 1 } cut of m , since the removal of either of them separates 7 and
Let M c = { c 1 , .., c | Mc | } be the set of all match cuts of m in the deterministic graph g c , Bc i be a Boolean variable for 1 |
M c | , and P r ( Bc i ) be the probability of the match cut c in g , then we have the following lemma to bound the pattern match probability: Lemma 1.
 P ROOF . Due to limited space, we just highlight the main steps. We consider the probability of m not being a match of g , which is given by 1  X  P r ( m D q g ) . First, we group possible worlds into dif-ferent groups such that a possible world in i th group does not con-tain match where each pair of vertices has distance at most i hops ( i  X   X  ). Then we delete edges in possible world graphs in each group until each graph corresponds to a set of match cuts. Also we exchange possible world graphs from different groups until graphs in each new group have the same number match cuts. Finally we use the Inclusion-Exclusion Principle to derive the conclusion
Remark. The match in Lemma 1 is a remaining match after struc-tural pruning.
 To compute the upper bound, we should unfold the formula 5. But it will take exponential steps to unfold the formula. To compute an upper bound efficiently, we take the following strategy. If we select a group of match cuts, IN = { c 1 , ..., c | disjoint in g c , the corresponding Boolean variables { Bc are independent of each other as well. Since IN  X  M c , for the upper bound of P r ( m D q g ) as follows,
Pruning Algorithm: Recall that PM-tree is a tree structure T , and any edge on the unique path between a pair of nodes s and t , indexes a set of cut edges  X  ( U ) between s and t in g c the definition of a match cut, the cut edge set  X  ( U ) is a match cut for any m = { u 1 , ...u n } containing s and t . To conduct prob-abilistic pruning, we first locate each corresponding node in T for m = { u 1 , ...u n } . We traverse all edges in T that connect the nodes in m , and obtain both their indexed cut edges as well as the corre-sponding probabilities as given by Equation 4. We achieve this by using a breadth-first search in T starting in any node contained by m , stopping when all nodes in m are encountered. Next we choose a group of disjoint match cuts and obtain an upper bound using Equation 6. If the upper bound is smaller than the threshold  X  , the candidate m is pruned. We denote the probabilistic pruning condi-tion by CN D , U pperB &lt;  X  . In T , P r ( Bc i ) is the probability of cut edges disappearing, which is given by Equation 4. Thus Equation 6 can now be written as,
Note that we have calculated P r ( Bc i ) offline and attach the value to the corresponding edge in PM-tree.

In all match cuts obtained from PM-tree, there are many groups of disjoint match cuts, which leads to different upper bounds. We want the bound to be as tight as possible to increase its pruning power. Below we convert the problem of computing tightest U pperB into the problem of set packing.

Definition 7. ( Tightest U pperB ) For a match, given the set of each to c i attached a weight given by  X  ln ( P r ( Bc i )) , we want a collection of disjoint match cuts S  X   X  S to maximize P r ( Bc i )) .

Let v = B = e  X  v . Thus maximizing v means minimizing U pperB , and we can obtain tightest (smallest) U pperB . It is known that the set packing is NP-hard [13]. In [2], the maximum weight set packing problem is formulated as a 0-1 integer programming. The integer programming is relaxed to be a linear programming that returns a very tight approximation z , on the weight of the maximum pack-ing set and there is an efficient algorithm that can solve this linear programming problem. Therefore, we use e  X  z computed by the solution given in [2] as the upper bound for P r ( m D q g ) .
Example 4. Consider the uncertain graph ug and a match m = { 2 , 5 , 7 } in Figure 1. Based on PM-tree (of ug ) shown in Figure 4, we can find match cuts S = { c 1 = { e 5 e 6 e 9 } , c 2 = { e 2 e 3 e 5 } , c 4 = { e 2 e 4 } , c 5 = { e 1 }} . Among them, we find three groups of maximal disjoint match cuts: { c 1 , c 4 , c 5 } and { c 3 , c 5 } . Their estimated upper bounds are 0.21, 0.19 and 0.22 respectively. Finally we select the tightest value 0.19 as the upper bound.

Note that PM-tree does not index all cuts in g c , and only indexes a small number of cuts that have powerful pruning capabilities as introduced in Section 5.
 Collective Pruning
The previously proposed algorithm highlights the steps for prob-abilistic pruning on a one by one basis, which is costly. In this subsection, we present solutions to conduct probabilistic pruning collectively.

The rational behind collective pruning is that different matches in SC q may share many cuts, and the common cuts can be used to prune a collection of matches in each probabilistic check. In one-by-one pruning a cut is used many times, while in collective pruning we want to use a cut only once. To achieve this, we first de-termine all cuts of matches in SC q , and then construct an inverted list L c for each cut c such that L c contains all matches sharing c . Below we give a simple example to illustrate the intuition of collec-tive pruning. Let c 1 and c 2 be two disjoint cuts whose inverted lists share a match m . Based on Equation 6, if P r ( c 1 )  X   X  , m cannot be pruned, b ut m is pruned if P r ( c 1 ) P r ( c 2 ) &lt;  X  . Thus we can prune the matches in the inverted lists by iteratively multiplying corresponding P r ( c ) .

Specifically, we construct a graph cG with each node represent-ing a cut inverted list. There is an edge between two nodes if (1) two cuts are disjoint and (2) inverted lists of two cuts share at least one match. We also label the edge by the common matches. We find all maximal cliques in cG using the method proposed in [23]. In each maximal clique cl , we traverse its nodes and, for each new visited node L c , multiply P r ( c ) with the current product. Suppose the current product is S . Obviously S is an upper bound of PMP based on Equation 6. If S &lt;  X  , we delete matches from SC by L c and its visited neighbors. We finish the collective pruning for SC q after traversing all maximal cliques. Algorithm 1 shows the detail steps of collective pruning.

Example 5. We use q (  X  = 3 ,  X  = 0 . 6 ) to query uncertain graph ug in Figure 1. We get matches m 1 = { 2 , 5 , 7 } and m { 5 , 6 , 7 } after structural pruning. Figure 5 shows the process of collective pruning. First, we find all match cuts of m 1 and m from PM-tree; they are given by { c 1 , c 2 , c 3 , c 4 , c construct a graph cG that contains 3 cliques cl 1 , cl 2 and cl we traverse these cliques and apply the probabilistic check. Finally we can prune both m 1 and m 2 while we traverse cl 1 and cl
A maximal clique constructed in the collective pruning assures a maximal number of disjoint cuts, which can make the current upper bound (the product S ) as tight as possible. A maximal clique also assures a maximal number of shared matches, which can prune as many matches as possible in each probabilistic check. For a given match m , m cannot be contained by inverted lists in different maximal cliques due to condition (2), which guarantees m can be pruned in only one maximal clique. Based on these discussions, we have the following conclusion for collective pruning.

Corollary 1. The result of collective pruning is same as that of one-by-one pruning, and the result is obtained by performing as few probabilistic checks as possible.
Definition 6 posed in Section 4 shows the structure and prop-erties of the probabilistic matching tree (PM-tree). This section shows how to construct PM-tree and shows that PM-tree has an effective pruning capability.
 We highlight the properties of PM-tree given in Def. 6.

Property 1. The structure of probabilistic matching tree is a tree structure T = ( V ( T ) , E ( T )) . Each node of T is a vertex of following property: For each pair of distinct nodes ( s, t ) and edge e on the unique path between s and t , deleting e from T separates V ( T ) into two components, X and Y , then ( X, Y ) is an s -t cut in g .

We first define some necessary concepts used in the construction algorithm.

Definition 8. ( Crossing Cuts ) Two cuts ( X, X ) and ( Y, Y ) are crossing cuts if X  X  Y , X  X  Y , X  X  Y , and X  X  Y are all non-empty.
Algorithm 2 shows detail steps of the index construction algo-rithm. First we initialize nodes and edges of T (line 1), then we run an iterative process to construct T . Each iteration mainly con-sists of four steps: 1. Select a supernode X in the current T , and form a reduced graph G  X  from G by contracting each component of G \ X (line 4). 2. Select any two vertices s and t in X , and find non-crossing cuts (line 5). 3. Modify the current T by replacing X by two supernodes, one for A  X   X  X and one for B  X   X  X (line 6-7). Each supernode is made adjacent to A  X   X  X or to B  X   X  X , according to whether its representative node in G  X  appears in A  X  or B 8-13). 4. T indexes cut edges of ( A  X  , B  X  ) and the corresponding probability (line 14). Finally we can replace labels of T and output the final T (line 15).

Example 6. The rational of the algorithm is to use a cut to di-vide the nodes of the graph in each step. The process is recursive until each node is separated from the graph. Figure 6 gives an ex-ample of step-by-step index construction for uncertain graph ug in Figure 1. In the first step, we select nodes 1 and 6, and determine
Figure 6: Construction of PM-tree for uncertain graph ug in Figure 1 the cut e 5 e 8 . As a result, the node set of graph ug are divided into two disjoint sets. We reduce the graph ug by collapsing one node set into single node as shown in the second step. In this step, we select nodes 1 and 4, and compute the cut e 7 e 9 . Note that we can select any two nodes and compute a minimum cut of the two nodes. This process is continued till each node is divided from the graph ug shown in the sixth step.
 Theorem 3. The IndexConstruction algorithm returns a valid PM-tree (i.e., s.t. Property 1), and requires the time of computing | V ( g ) | X  1 non-crossing cuts in graphs of size at most that of g .
Non-crossing cuts play a critical role in constructing PM-tree. To implement IndexConstruction , we should determine non-crossing cuts efficiently, for which we use minimum cuts as non-crossing cuts. Define w : E ( g c )  X  R a weight function on each edge of g . The weight of a cut ( X, X ) in g c is the sum of weights on cut edges, i.e., w ( X ) = in g c , ( X, X ) is a minimum s -t cut if w ( X ) is the smallest among all s -t cuts in g c . For the minimum cut, we have the following non-crossing property.

Theorem 4. Let ( X, X ) be an s -t minimum cut in a graph g with respect to a weight function w . Then for any u, v  X  there is a u -v minimum cut ( Y, Y ) where Y  X  X .
Based on this theorem, we can compute a minimum cut ( A  X  in Line 5 of Algorithm 2 so that A  X   X  X .

All that remains is to assign a weight on each edge of g c that we multiply P r ( U, V ) given in Equation 4 to obtain U pperB . We want a tight U pperB , and hence P r ( U, V ) should be as small as possible. Based on Equation 4, we need to compute the cut with the smallest edge weights. Thus we assign a weight ln (1  X  to each edge e in g c . There are many efficient algorithms that can compute a minimum cut in a deterministic graph [32].
 The space complexity is given below.

Theorem 5. Probabilistic Matching Tree takes O ( | V ( g ) Note that, if g has multiple connected components, we build PM-tree for each connected component. Each PM-tree can sup-port probabilistic pruning since structural pruning has located m in one connected component.

To feed non-crossing cuts to PM-Tree, we can use method in [32] to generate all minimal cuts. But, the minimal cut size is so large that the index has a large cost. To avoid this, we take a learn-ing process as follows: We first generate all minimal cuts C assign each cut to the corresponding edge of T . We use a query log to verify which cuts in C 0 have great pruning power, i.e., many queries in the log can be pruned by these cuts. Next, we select a cut set C  X  C 0 indexed by T to prune queries.
In this section, we compute the pattern matching probability (PMP) of a match in C q to determine the final answer set.

Let f be a path set of g c , that connects each pair of vertices of a match m = { u 1 , ..., u n } within distance  X  . In fact, f contains a Steiner tree. This Steiner tree has { u 1 , ..., u n } as leaves and has the fewest edges connecting { u 1 , ..., u n } within distance  X  . Thus, without loss of generality, we assume f is such a Steiner tree for vertices in { u 1 , ..., u n } . It is NP-complete to compute a Steiner tree, and we use the efficient approximation algorithm described in [9] to obtain all Steiner trees for m .
 Let F = { f 1 , ..., f | F | } be the set of all Steiner trees for m . Based on the Inclusion-Exclusion Principle , we obtain where Bf is a Boolean variable for f , and P r ( Bf ) is the proba-bility of f in g .
 By simplifying this equation, we have
Clearly, we need an exponential number of steps to perform the exact calculation. To prevent this, we develop an efficient sampling algorithm to estimate P r ( m D q g ) .

Assume Steiner trees in F have total edges { e 1 , ..., e is the corresponding Boolean variable of e . Then each Bf can be written in the form of conjunction of some Be s. Algorithm 3 gives detailed steps of the sampling algorithm.

Based on Monte Carlo theory, the adopted value of the sample number N = (4 ln 2 / X  ) / X  2 guarantees the estimated quality [24]:
Lemma 2. For any  X  ( 0 &lt;  X  &lt; 1 ) and  X  (  X  &gt; 0 ), if N (4 ln 2 ) / X  2 then,
In Monte Carlo theory, the values of  X  and  X  are usually both set to 0.1 [24] [18].
In this section, we report the effectiveness and efficiency of our proposed techniques. Our methods are implemented on a Windows XP machine with a Core 2 Duo CPU (2.8 GHz) and 8GB main memory. Programs are compiled using Microsoft Visual C++ 2010.
Real uncertain dataset. The real uncertain graph, Yeast , is ob-tained from the STRING database 1 which contains all known and predicted protein interactions. Yeast has 5,862 vertices, 16,651 edges and 91 distinct labels. The edge weights are all set to  X 1 X . Vertices of Yeast are deterministic, and the edges have an average value of 0.459 for the existence probability. Each query pattern set qi has 20 connected query graphs and query graphs in qi are con-nected size-i graphs, i.e. the edge number in each query is i , which are randomly extracted from the corresponding deterministic graph constraint  X  is set to 1 X 5, and the default value is 3.

Real dataset with synthetic uncertain information. We assign uncertain information for a co-author network g c generated from the citeseer dataset 2 . We call this uncertain graph Citeseer . We treat each author as a vertex in g c and introduce an edge to connect two vertices if and only if there is at least one paper co-authored by the two authors. We label each author (vertex) by his/her af-filiation. For an edge e = ( u 1 , u 2 ) in g c , its weight is assigned as 100 /co ( u 1 , u 2 ) , where co ( u 1 , u 2 ) denotes the number of co-authored papers between authors u 1 and u 2 . There are 521,668 vertices and 1,625,736 edges in the generated g c . We generate existence probabilities for edges following a Gaussian distribution N (  X ,  X  ) . The value of  X  is set to 0.3 X 0.7, and the default value is 0.5; the value of  X  is set to 0.05 X 0.25, and the default value is 0.15. Using the same method as in the real uncertain dataset, we gener-ate query patterns q 2 , q 4 , q 6 , q 8 and q 10 . The distance constraint  X  however is set to 10 X 50, and the default value is 30.

As introduced in Section 3, we implemented the method given in [37] to do the structural pruning. This method is called Structure in experiments. In probabilistic pruning, the method using the best upper bound is called OPT-Bound . To compare with OPT-Bound , we randomly generate groups of disjoint cuts and select the tight-est upper bound; this approach is called Bound . Both OPT-Bound and Bound prune matches in SC q one by one. We implement the collective pruning, Col-pruning , and compare it with one-by-one pruning One-Pruning , i.e., Bound . We feed all these pruning tech-niques with match cuts obtained in the learning. In verification, the sampling algorithm is called SMP , and parameters  X  and  X  used in SMP are both set to 0.1; the method given by Equation 9 is called Exact . We compare the proposed algorithms with the state-of-art Monte-Carlo methods MC [18]. The complete proposed algorithm of this paper is called PM-tree . In all experiments, the probability threshold is set to 0.3 X 0.7, and the default value is 0.5. We report average results in following experiments.
 Exp.1 In the first experiment, we demonstrate the efficiency of SMP against Exact and query quality of SMP in the verification step. We first run structural and probabilistic filtering algorithms against Citeseer and Yeast to create candidate sets. The candidate sets are then verified for calculating PMP using the proposed algo-rithms. Figure 7 reports the result, from which can be observed that SMP is efficient at both uncertain graph datasets and has an aver-age running time of less than 1 second in Yeast, while the curve of Exact grows exponentially. The approximation quality of SMP is measured by the precision and recall metrics with respect to query size also shown in Figure 7. Precision is the percentage of true matches in the output matches. Recall is the percentage of returned true matches in all true matches. The experimental results verify that SMP has a very high approximation quality with precision and recall both larger than 90%.

Exp.2 In this experiment, we report candidate sizes and pruning time of Structure , OPT-Bound and Bound with respect to probabil-ity thresholds in Figure 8. From the results, we observe that the candidate set sizes and running time of OPT-Bound and Bound de-crease with increasing of probability threshold, since larger thresh-olds will remove more false graph matches with low confidences. As shown in Figures 8(a) and 8(b), the candidate sizes of OPT-Bound are much smaller than those of Bound , which indicates that our derived upper bounds are tight enough to have a great prun-ing power. As shown in Figures 8(c) and 8(d), OPT-Bound has a low pruning time (i.e., smaller than 1s on average at Citeseer) but takes more time than Bound due to additional time of solving the set packing problem.

Exp.3 In this evaluation, we study candidate set sizes and prun-ing time of One-Pruning , Col-Pruning and Structure with respect to distance constraints as shown in Figure 9. From the result, we know that both pruning time and candidate set size increase with the increase of the distance constraint, since larger distance con-straints lead to a large remaining set after each filtering step. One-Pruning and Col-Pruning have same candidate sizes but Col-Pruning takes far less time than One-Pruning , which validates our design that many matches are filtered out at each step of the collective pruning.

Exp.4 In the fourth experiment, we examine the probabilistic in-dex feeded by selective cuts in the learning ( PFiltering ) and with all minimal cuts ( Non-PF ). Table 1 shows the number of cuts, can-didate set sizes, pruning time and index building time of PFilter-ing and Non-PF on Citeseer and Yeast. As expected, PFiltering indexes far fewer cuts than Non-PF , but PFiltering requires more index building time due to additional time spent on the cut selec-tion. On the other hand, the candidate set sizes of PFiltering come very close to those of Non-PF . The results confirm that the selected cuts by the learning have a very powerful pruning capability.
Exp.5 In the fifth experiment, we study candidate set sizes and pruning time with respect to different data graph sizes. Figures 10(a) and 10(b) show the results on uncertain graphs, with 5k X 25k nodes, generated from STRING. From the results, we see that all curves are scalable with the increase of number of nodes. Figures 10(c) and 10(d) show the results on uncertain graphs with different edges. In this evaluation, we fix the number of graph nodes (5k) and vary the number of edges from 10k to 50k. The candidate size increases little since the number of nodes is constant and the pattern matching returns node sets. The pruning time increases since more edges should be checked during each filtering step.

Exp.6 Finally we report the total query processing time of Cite-seer in Figure 11 with respect to different uncertainties. PM-tree denotes the complete algorithm, that is, a combination of Structure , Col-Pruning and SMP . Figure 11(a) gives the result by varying  X  from 0.3 to 0.7 in the Gaussian distribution. From this result, we observe that PM-tree is quite efficient with respect to its running time and avoids the huge cost of computing PMP which is NP-hard. PM-tree can process queries within 10 seconds on average which is 40 orders of magnitude faster than MC . MC grows exponentially due to that MC samples a large number of possible worlds to ob-tain satisfactory accuracy. Figure 11(b) gives the result by varying standard deviation  X  of the Gaussian distribution from 0.05 to 0.25. The result shows that the change of PM-tree is very small, which indicates that PM-tree is not sensitive to the variance of Gaussian distribution. In this result, the running time of MC is more than 800 seconds at all values of  X  . Both results validate our design.
The topic most related to our work is managing and mining un-certain graphs, and it can be divided into two categories. The first category is to use online algorithms, i.e. sampling approach, to an-swer queries. Zou et al [38, 39] study frequent subgraph mining on uncertain graph data. Potamias et al [26] study k -nearest neigh-bor queries ( k -NN) over uncertain graphs. Jin et al [17] develop fast peeling algorithms to find highly reliable subgraphs. Liu et al [21] study the problem of reliable clustering on uncertain graphs. But the proposed algorithms in this category do not scale well for a large uncertain graph, and the sizes of their graph datasets are much smaller than those of this paper. The other category first uses a pre-computed index to filter false answers, then remaining candidates are verified by online algorithms. Papapetrou et al [25] propose to use indexing techniques to speed up frequent subgraph mining in uncertain graph databases. Hua et al [14] study short-(a) Verification time on Citeseer (c) Query quality on Citeseer (c) Pruning time on Citeseer (c) Pruning time on Citeseer (c) Candidate size vs. edges est path queries in a large uncertain graph by filtering useless path sets. Yuan et al study the exact and similarity subgraph matching on probabilistic graphs [35, 33]. Yuan et al also develop efficient algorithms to process keyword queries over a large uncertain graph data [34]. Our work falls into the second category, but is essen-tially different from these works. First, our studied query type is completely different from those. Second, computing probability in uncertain pattern matching is harder than that in uncertain subgraph matching or mining. Thus we propose a novel indexing structure and query processing algorithm to speed up the query.

Another most related topic is the context of network reliabil-ity [8]. This topic studies the following problem: given s and t nodes in an uncertain graph, one is asked to compute the proba-bility that t is reachable from s . This problem has been shown to be #P-complete [13]. The authors in [18] investigate another #P-complete problem, that is: given two nodes s and t in an uncertain graph, what is the probability that the distance from s to t is within a user-defined threshold? Obviously, we are studying a more gen-eral problem. Instead of focusing on the probability between any two single nodes, we shift the attention on a set of nodes: given a set of nodes S in an uncertain graph, compute the probability that the distance between each pair of nodes in S is within a thresh-old. To attack the hard problems, most of the work has concerned Monte-Carlo sampling methods [8, 18], which have a major effi-ciency shortcoming due to the large number of samples that is typi-cally needed to obtain satisfactory accuracy. In this paper, we solve the problem of online estimation of reachability queries by pre-computing an offline index that can be exploited to speed-up online query processing. As shown in the evaluation, our index-based al-gorithm, which allows to process our queries very efficiently X  X p to 40 orders of magnitude faster than sampling methods.

Pattern matching on deterministic graphs also relates to the topic studied in this paper. There has been a lot of work done on pat-tern matching via subgraph isomorphism [31, 36, 4]. In light of its intractability, Fan et al [12] relax the strict query condition by im-posing bounds on the number of hops in pattern graphs or by incor-porating regular expressions as edge constraints on pattern graphs [11]. To further refine answers, Ma et al proposed a topology con-strained graph pattern match query [22]. Pattern matching via these query conditions can be performed in polynomial time, i.e., cubic-time [12, 22, 11]. Fan et al also propose efficient strategies to han-dle graph updates [10], and thus eliminating the need to re-perform query algorithms. However all these works are online query pro-cessing and thus do not scale well for very large graphs. Based on the reachability constraint, Cheng et al proposed a pattern match problem over a large directed graph [5]. Similarly, Zou et al study distance constrained graph pattern match queries [37]. Both au-thors in [5] and [37] pre-store decomposed graphs in a relational database, and then utilize the well-studied join algorithms to an-swer pattern match queries efficiently.
Uncertain graphs pervasively exist in real applications such as bioinformatics, where data often exhibit uncertainties. In this pa-per, we study the problem of retrieving matches from a large uncer-tain graphs that satisfy a query graph patten with high confidence. To efficiently tackle this problem, we propose a tree index structure to enable the pruning, which is adaptively designed according to a formal cost model, so that the index not only has a small size but has a great pruning capability. Based on the index, several prun-ing techniques are developed, such as best upper bounds and col-lective pruning, to reduce the search space significantly. We also develop an efficient sampling algorithm to validate the remaining candidates. Extensive experiments have been conducted to demon-strate the efficiency and effectiveness of our approaches. Ye Yuan and Guoren Wang are supported by the NSFC (Grant No. 61100024, 61025007 and 61328202), National Basic Research Program of China (973, Grant No. 2011CB302200-G), National High Technology Research and Development 863 Program of China (Grant No. 2012AA011004) and the Fundamental Research Funds for the Central Universities (Grant No. N130504006). Lei Chen is supported by the NSFC (Grant No. 61328202).
