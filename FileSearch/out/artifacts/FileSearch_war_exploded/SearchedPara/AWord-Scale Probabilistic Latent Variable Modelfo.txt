 This paper describes a probabilistic latent variable model that is designed to detect human values such as justice or freedom that a writer has sought to re ect or appeal to when participating in a public debate. The proposed model treats the words in a sentence as having been chosen based on spe-ci c values; values re ected by each sentence are then esti-mated by aggregating values associated with each word. The model can determine the human values for the word in light of the in uence of the previous word. This design choice was motivated by syntactic structures such as noun+noun, adjective+noun, and verb+adjective. The classi er based on the model was evaluated on a test collection containing 102 manually annotated documents focusing on one con-tentious political issue | Net neutrality , achieving the high-est reported classi cation effectiveness for this task. We also compared our proposed classi er with human second anno-tator. As a result, the proposed classi er effectiveness is statistically comparable with human annotators.
 I.2.7 [ Arti cial Intelligence ]: Natural Language Process-ing -text analysis.
 Algorithms, Experimentation.
 Computational social science, computational linguistics, hu-man values, probabilistic model.

Social scientists have long found it useful to consider hu-man values as latent variables that have explanatory value for the choices that people make [35]. For example, some-one who values innovation over wealth might advocate open-source over proprietary software, while someone who values freedom over social order might resist efforts for gun reg-istration. We can think of values as in uencing not only how people form their own opinions, but also as undergird-ing how people seek to in uence the opinions of others. In this paper, we focus on automatic detection of human val-ues re ected in texts written by advocates of speci c policy positions. We take a step in that direction by evaluating automated classi cation of human values.

Several inventories of human values are used in social sci-ence research (e.g., Friedman et al. [13]; Kahle et al. [22]; Kluckhohn [23]; Rokeach [29]; Schwartz [32]). Integrating key components of these studies, we adopted Cheng and Fleischmann's [6] human value de nition, that is, \values serve as guiding principles of what people consider impor-tant in life." We also base our work on the Meta-Inventory of Human Values (MIHV), which was developed by Cheng and Fleischmann speci cally for the test collection that we use by selecting values speci c to the debate at issue and by iteratively re ning annotation guidelines [7, 12, 10]. Our re-sults, generated using a redistributable collection containing 102 documents with zero or more of six sentence-level hu-man values annotations, indicate that high precision (near 0.8) can be reliably achieved for frequently invoked values with a useful degree of recall (0.55{0.82).

We achieved statistically signi cant classi cation effec-tiveness over existing baselines for this task using a new probabilistic latent variable model in which we rst infer the association between human values and individual word-level human values as latent variables, and then we aggregate those results over all words in a sentence. The structure of our model allows us to model the potential effect of the pre-ceding word, which proves to be useful. Moreover, analysis of 20 dual-annotated documents indicate that with about 80 training documents our automated technique is able to achieve results that are nearly as accurate as those obtained by an independent human annotator as a pseudo-classi er. The remainder of this paper is organized as follows. In Section 2, we describe related work on human value research and on classi cation methods. Section 3 then introduces the test collection that we have used. Section 4 describes our approach to detect human values and Section 5 describes our proposed latent value model. Section 6 presents our results and Section 7 concludes the paper.
Content analysis is one of the approaches to detect human values [11]. The key idea in content analysis is for the social science researchers to personally examine naturally occur-ring content and to assign codes to that content that re ect their interpretation of that content using some pre-existing coding scheme. Subsequent statistical analysis is then done on the assigned codes rather than on the content. Hsieh and Shannon [17] refer to this combination of human interpreta-tion and an existing coding scheme as a\directed approach". One of the limiting factors the directed approach is that the annotation costs scale linearly with the size of the collection. Early in the annotation process, personal involvement of the researcher is important because the theory on which any pre-existing coding scheme is built may need to be adapted for re ecting the unique characteristics of a collection on which social scientists wish to focus. Our automated techniques are intended only for the part of the process when coding guidelines have stabilized and a substantial amount of an-notated data is available.

After we obtained sufficient annotated data, we could automate the annotation process using text classi ers [33] trained with that data. We are not the rst to explore the automated annotation of human values for social science re-search. For example, Bengston et al. [2] used dictionary-based computer aided content analysis to identify how val-ues about forestry have shifted from anthropocentric values to biocentric values over the period 1980 through 2002.
We rst compared the effectiveness of a wide range of classi ers available within Weka [16], and we found that Support Vector Machines (SVMs) [20, 21] performed best. Therefore, we compare our proposed method to SVMs using bag-of-words and bigram features in Section 6. Because we introduce a latent variable model, supervised Latent Dirich-let Allocation (sLDA) offers another appropriate baseline [3]. Essentially, sLDA is an extension of LDA [4] in which the process of constructing the probabilistic latent variable model is in uenced by the known association of words with labels in a set of training documents. sLDA based on gen-eralized linear models is a general framework to model the documents and the responses. Our proposed probabilistic la-tent variable model also captures the relationships between the sentences and values. Thus, we compare our method with sLDA in Section 6.

Griffiths et al. [15] found modeling sequential dependen-cies between word classes to be helpful. Sequential depen-dencies between the words themselves can also be useful, but sparsity risks must be managed. With this in mind, we model sequential word dependencies with the label(s) as-signed to one word stem depending in part on the label(s) assigned to only the previous word stem.

The structure of our problem resembles that of sentiment classi cation, which has been extensively researched [25, 27]. An important difference is that our classi cation of human values is most naturally cast as a multi-category multi-label classi cation, whereas sentiment analysis is typically mod-eled as single-category classi cation. Importantly, human values can help to explain sentiment, given their explana-tory power in relation to attitudes and behavior [34]. What distinguishes our work is our focus on human values with a redistributable test collection and our modeling of relation between sentence-level and word-level values, and sequential dependencies among words in a sentence.
The test collection we used in this paper was originally developed by Cheng et al. [7]. The collection includes 102 written prepared statements ("testimonies") from pub-lic hearings held by the U.S. Senate, House, and Federal Communications Commission (FCC) in which representa-tives of stakeholder groups offered advice to legislative and regulatory bodies on Net neutrality . The key question in the Net neutrality debate is whether the public interest is better served by nondiscriminatory access for all Internet traffic or by some set of reasonable network traffic manage-ment practices for certain types of content or services. Their annotation task focused on the relationship between advo-cacy positions and detectable human values re ected by (or appealed by) written prepared statements.

Traditional paper-based annotations for values posed two challenges: (1) annotated passages could be of any length, and indeed both short (clause-scale) and long (paragraph-scale) passages were annotated; and (2) annotated passages often did overlap, indicating that evidence for multiple val-ues was present in some places. Cheng et al. [7] there-fore elected to constrain the scope of each annotation to be a single sentence, but to allow more than one value per sentence. Clause annotations were extended to sentences, and passages that spanned sentences were accommodated by annotating several consecutive sentences. This set up a well-structured sentence annotation task for supervised machine learning. Their initial experience with sentence annotation revealed poor inter-annotator agreement. Af-ter some iteration of annotation guidelines, they concluded that the Schwartz Values Inventory [32], which was devel-oped through and for surveys, was not necessarily trans-ferable to (manual or automatic) content analysis. To ad-dress this concern, Cheng and Fleischmann [6] developed the Meta-Inventory of Human Values (MIHV) by looking for commonalities among the full range of values inventories proposed towards categories that could be reliably inferred during annotation for content analysis. They selected a sub-set of their MIHV appropriate to our collection, iteratively coding a subset of our collection and iteratively re ned anno-tation guidelines using two annotators until inter-annotator agreement stabilized. The resulting collection is annotated for six human values, the de nitions of which are in Ap-pendix A.

Sentence splitting for the test collection had been per-formed manually, and all 9,890 sentences in 102 documents were manually annotated. Table 1 shows examples of anno-tated sentences. We subsequently removed sentences whose boundaries disagreed with those of TreeTagger [31], sen-tences that after removing words in the SMART stopword list [30] contained more than 40 words, and sentences that (after stopword removal) contained no words. The remain-ing 8,660 sentences were then stemmed by the Porter stem-mer [28]. Table 2 shows the distribution across the six val-T able 1: Examples of human values annotation.
 T able 2: Inter-annotator agreement and prevalence. ues. A total of 1,545 sentences were annotated as containing no value .

A second annotator independently had annotated 20 of the prepared statements (containing 2,430 sentences, after the same ltering process was applied). Table 2 also shows Cohen's kappa, a chance-corrected measure of inter-annotator agreement [1, 8, 24] for those 20 documents.
In order to detect human values, we have to take into account how the values are re ected in text. Surface lan-guage expressions for human values are different from those for most other subject classi cation problems. In using sub-ject classi cation to classify a theme of the document, the themes are often directly represented by language expres-sions, typically by words that occur in the documents [33]. In the case of the human value classi cation, while a value may be indicated by a speci c word in some cases, in many cases the value may be invoked somewhat more indirectly using situation-speci c terminology. In a preliminary anal-ysis of the corpus that we use in this paper, we found the following cases: (1) A word represents value(s).
 (2) A pair of words represents value(s).
 (3) A whole sentence represents value(s).
 (4) Contextual information is required to infer value(s). From the above actual examples in the corpus, we can see that the human values are expressed in variety of forms and multiple values are assigned to a sentence.

Among several approaches to estimate the presence of a category from text, typical basic methods are naive Bayes, k nearest neighbors ( k NN), and SVMs. Ishita et al. [18] adopted these methods to detect human values, however, the results showed that these methods alone are not suffi-cient. One reason is that human values cannot be repre-sented by simple functions such that summation of factors of words in a sentence, contributing to each human value. These function cannot be capture that some speci c words play a determining role to detect certain values. Based on the above considerations, we design our model to rst infer the word-level human values corresponding to each word in a sentence as latent variables, and then aggregate them by logical bitwise OR (see Section 5.1) to estimate the sentence-level human values.

Another characteristic of language expressing human val-ues is that multiple values can be expressed by a single sen-tence. There are the cases in which one word re ects mul-tiple values, as example (c) above illustrates, and multiple words with values can appear in a sentence. As an example of that, the sentence \Part of the reason why the Internet is such a creative forum for new ideas is that there are very few barriers to using the Internet to deliver products, infor-mation and services." has the value innovation based on the word \creative" and the word pair \new ideas" (adjec-tive+noun); and freedom based on the word \barrier." The above examples (d) and (e) in the case (2) suggest that word sense disambiguation directed by syntax is required to de-tect correct human values for word-level. Among several syntax patterns, we focus in our work on two-word colloca-tions, modeling the value of the word in a way that can be in uenced by the previous word because this covers many typical and frequent syntax patterns, as the above examples show.

In this paper, we model cases (1) and (2) above in the next section, that provide an adequate coverage of major cases, in anticipating that the above cases (3) and (4) are minor. We expect our design choice is effective for these major cases, and in our future research, we could perhaps further extend our model to represent whole-sentence meanings and long-distance context in more nuanced ways.
In this section, we propose a new method for detecting human values by using a statistical language model we call our Latent Value Model ( LVM , for short), that estimates the posterior probability of sentence w having values v using Gibbs sampling in a Markov Chain Monte Carlo framework [14]. In order to investigate relationships between words for detecting values as discussed in section 4, we take the effect of the preceding word into account in our LVM .
A sentence w is a sequence of N words denoted by w = ( w 1 ; w 2 ; :::; w N ), where w n is the n -th word in the sequence. The sentence w has sentence-level values v , where v 2f 0 ; 1 = f 000000, 000001, ..., 111111 g . Each bit in the sequence pattern represents one of the six values. The pattern 000000 means the corresponding sentence does not have any values.
We introduce latent variables x into the model to repre-sent the value(s) associated with each word in the sentence. If the word w n has a value x , the sentence w also has the value x . On the other hand, if no word w n in a sentence w has value x, then the sentence w does not have value x . In addition, we assume that each word in a sentence has at most two values. The sequence of the values corresponding to the sentence w is denoted by x = ( x 1 ; x 2 ; :::; x N x n is the word-level value(s) of the word w n .

We restrict x n to be an element in , where = f 000000, 000001, 000010, 000011, 000100, ::: , 110000 g . The cardinal-ity of is 22. We denote 000000 as 0 , 000001 as 1 , ..., and 110000 as 21 , for convenience of notation. Restricting the number of values with which a word can be associated limits sparsity. Whether an at-most-two model is a good choice is an empirical question. In preliminary experiments, single-value models perform poorly and three values models show no further improvement.
 The sentence-level values v are the result of logical bitwise OR operation for all x n (1 n N ). The sequence of word-level value(s), therefore, is restricted to the following N ( v ), when the sentence-level values v are given.
For example, sentence-level values for the sentence \Congress enact safeguards to preserve American consumers' longstand-ing freedom of Internet content choice." calculated as social order (from the word \safeguards") and freedom (from the word \freedom" and \choice").

We also introduce another type of latent variables y = ( y 1 ; y 2 ; :::; y N ) into the model. The context indicator y presses whether the previous word w n 1 in uences the value of w n or not. When the values associated with word w n are subject to the in uence of the previous word w n 1 , y takes the numerical value 1. This design choice is moti-vated by syntactic structures such as noun+noun and ad-jective+noun, or semantic disambiguation associated with verb+noun and verb+adjective. Otherwise, y n takes 0 (The values associated with w n are determined by only w n itself).
For the word sequence ( w n 1 ; w n ), the context indicator y n follows a Bernoulli distribution Bern ( parameter ( w n 1 ;w n ) 1 follows a Beta distribution with the parameters ( 0 ; 1 ): Beta ( 0 ; 1 ) is a Beta-function. When y n takes the value 0, the values associated with the word w n follow a multi-nomial distribution M ulti (  X  w n 0 ;  X  w n 1 , ...,  X  w rameters  X  w n 0:21 follow a Dirichlet distribution with the pa-fo reach n = 1 ; 2 ; :::; N do (i) draw context indicator y n : (ii) draw the word-level value(s) x n : sentence-level values become: rameters ( 0 ; 1 ; :::; 21 ). Hereafter, we use  X  w n for notational convention. When the context indicator y n takes 1, the values associated with the word w n follow a multinomial distribution M ulti (  X  ( w n 1 ;w n ) 0 ;  X  ( w  X  21 ) and its parameters  X  let distribution with the parameters 0:21 . The generative process for the sequence of sentence-level value patterns x = ( x 1 ; x 2 ; :::; x N ), the sequence of context indicators y = ( y y , ::: , y N ) and the sentence-level human value(s) v for a sentence w = ( w 1 ; w 2 ; :::; w N ) in our proposed LVM is as follows in Figure 1. In Figure 1, priors ( w n 1 ;w n ) u sociations .

Our LVM is represented as a graphical model using con-ditioning with gates [26] in Figure 2. The outer plate repre-sents sentences, while the inner plate represents generation of word-level values from a pair of the words or a single word by its context. The dotted box inside the inner plate shows the determination of previous word's in uence depending on the context indicator y . The sentence-level value v is an aggregation of word-level values x for the corresponding sen-tence w . In Figure 2, L is the number of distinct ( w n 1 W is the number of vocabulary and K is xed at 22.
That is, our proposed model can be represented by the following equation (1).

P ( x ; y j w ; ;  X  ) where w 0 is the special symbol ($) expressing the sentence head, and y 1 is always 0. The probabilities P ( y n j w n 1 and P ( x n j y n ; w n 1 ; w n ;  X  ) are de ned as follows: For simplifying notation, the symbol a represents the word w n 1 , and the symbol b represents w n , the previous word of w n in the equation (2), and the same style notation shall apply hereafter. The constant j in equation (2) is the j -th possible word-level value(s) pattern as described in section 5.1.

We assume the following properties about the relation be-tween words and their values: (1) Most words do not have any values, (2) For most two-word sequences, the values associated
We adopt a Bayesian approach to embed these proper-ties in our model. The prior distribution of ( ( a;b ) 0 is 2-dimensional Dirichlet distribution (beta distribution) Dir ( 0 ; 1 ). To re ect the property (2) above, we set the meta-parameters 0 and 1 as follows: 0 &lt; 0 , 1 &lt; 1 and 0 &gt; 1 . The prior distributions of (  X  ( b ) 0 ;  X  tributions Dir ( 0 ; 1 ; :::; 21 ). To re ect the property (1) above, we set the meta-parameters as follows: 0 &lt; 0 ; 1 ; :::; 21 &lt; 1 and 0 &gt; 1 + 2 Furthermore, to keep the number of meta-parameters small, we set the following restrictions: Thus, the free meta-parameters are only and .

When the word-level values x is determined, the sentence-level values v is uniquely determined as v = x 1 x 2 ::: x Therefore, the probability of ( x ; y ; v ) given w is then: The probability of ( x ; y ) given ( w ; v ) is therefore: Let ( W ; V ) be a collection of sentences and their values. W = ( w (1) ; w (2) ; :::; w ( M ) ), where w ( m ) is the m -th sen-tence, and V = ( v 1 , v 2 , ... v M ), where v m is the value(s) of the m -th sentence. The n -th word of w ( m ) is denoted w n , and the length of m -th sentence is denoted N m . The tion ( y (1) ; y (2) :::; y ( M ) ) is denoted Y in a like manner. We ca n get the probability of ( X ; Y ) given ( W ; V ) from (4) as follows: where C Y (( a; b ) ; u ) is the number of times u has been as-signed to a two-word sequence ( a; b ) as the value of context indicator y , C X ( b; t; 0) is the number of times value been assigned to word b without the in uence of the previ-ous word, and C X (( a; b ) ; t; 1) is the number of times value has been assigned to the word b with the in uence of the previous word a .

When x ( m ) 2 N m ( v m ) for all m = 1 ; 2 ; :::; and M , we get the following formula by calculating the marginal probabil-ity:
P ( X ; Y j W ; V; ; ) where ( j ; ) and (  X  j ; ) are the prior distribution of and the prior distribution of  X  , respectively, and ( ) is the gamma function.

We can estimate the value(s) for a sentence w that has N words: Also we can estimate that w has the j -th value (denoted by ( v ) j ) of the six, when  X 
That is, whether a sentence has the j -th value is deter-mined for each j separately. This means that the comparison among SVM, sLDA and LVM is fair enough because both judgements do not take into account combination of values.
We need the probabilities P ( x ; y j w ; ; ) for every x and y to estimate the values of a sentence w . These are the predictive posterior probabilities after giving the training data ( W ; V ), ^ P ( x ; y j w ; W ; V; ; ), to be exact. We ob-tain the following predictive posterior probabilities. We give the derivation of equation (7), the explanation of ^ P ( x ; y w ; W ; V; X ; Y ; ; ) and its calculation in Appendix B. ^ P ( x ; y j w ; W ; V; ; ) (7) =
By the law of large numbers, equation (7) can be approx-imated as follows:
In equation (8), ( X ( s ), Y ( s )) is the s -th sample of ( X ; Y ) that is drawn according to the posterior probability P ( X ; Y W ; V; ; ), given by a Gibbs sampler. We get the condi-tional probability used in Gibbs sampling from equation (5) as follows: wh ere X ( m;n ) is X from which x ( m ) n is removed, and C is a count that does not include the current assignment of x n . The same holds for Y ( m;n ) and C ( m;n ) Y ( ) with y
In this section, we describe our experiment design, report classi er effectiveness, and compare our automated results to those of a human annotator.
We use 102-fold document-scale cross-validation (except in Table 3, where in preliminary experiments we had not grouped sentences by document). 102-fold cross-validation seeks to model the case in which some set of 101 documents have been annotated as training data and we are interested in the degree to which the machine can automatically code all future documents. To select the meta-parameters for each fold, we use 100 documents for development training and one held-out document for development testing. We perform a parameter sweep by training on all sentences in the development training set and then testing on all sen-tences in the one development testing document to select the meta-parameters and that yield the best F 1 , sweep-ing both parameters across 0.05, 0.1, 0.2, 0.5 and 0.9. The 1 01-document training set is trained using the best and , and the resulting model is used to classify the sentences in the test set.

For Gibbs sampling we used 50,000 trials. Thirty percent of those trials were treated as the burn-in period. We used 1-for-3 samples of them as ( X ( t 0 +1), Y ( t 0 +1)), ( X ( t Y ( t 0 + 2)), and so on to calculate equation (8). These pa-rameters were empirically determined in preliminary exper-iments on development data. We apply the same process to determine the frequency threshold for bigram features (use if frequency , a meta-parameter for SVM 1 ) and to determine meta-parameters for sLDA. 2
In order to examine in uence of the previous word, we compare our LVM with LVM ( y n = 0) which is our model without any in uence from the previous word (i.e., with the context indicator y n in the equation (1) always zero. The meta-parameters were same as for LVM .) We also com-pare our models with two types of SVM as fair baselines, SVM(w) and SVM(w, b). SVM(w) uses only word features, and SVM(w, b) uses word and bigram features. We use 2nd-degree polynomial kernel for SVM(w) and linear kernel for SVM(w, b), that kernels are determined respectively in experiments. sLDA [3] is a general supervised method but it inherited the property of LDA [4, 14] which is a generative model for \documents" so that multiple topics are responsible for the words occurring in a single document. When we apply sLDA our test corpus, we assume that one sentence is regarded as a document. This setting might lose reliability of sLDA's be-havior, because the expected number of words which have values in a sentence is a few. However, sLDA is a represen-tative supervised probabilistic model, so we investigate how it works in the actual experiment. Table 3 shows results for SVM(w), SVM(w, b), sLDA, LVM ( y n =0) and LVM . For the comparison between SVM(w, b) and LVM , the difference of the error rate in the average F 1 between them, z = 5 : 98 &gt; Z 0 : 975 (= 1 : 96) suggests that the equality can be rejected at signi cance level 0.05 by a z -test [9] [19]. LVM is much better than sLDA. We can see that even LVM ( y n =0) outperforms SVM(b) and SVM(w, b) (signi cantly for SVM(b), but not signi cantly for SVM(w, b)).

Table 4 shows classi er effectiveness by 102-fold document cross-validation. As can be seen, LVM apparently outper-forms SVM(w, b). This is also true for sLDA, even when the number of topics is set to 22, which is the closest approxi-mation to our model. Note that we omit honor from these micro-averaged results in Table 3 and 4 because no classi er did well for that category due to a scarcity of annotations for that value in our corpus, as illustrated in Table 2.
In sLDA, the response is regressed on the topic propor-tions, while the SVM calculates the weights for the response directly from words. We believe the reason why sLDA works so badly is as follows: (1) it is a model for \document" but not for \sentence" as we mention in the section 6.1; (2) lin-ear regression of the latent variables for words to explain the response is not as well suited to our very sparse data as our estimation of the sentence-level values by a bitwise OR of the word-level values is. h ttp://chasen.org/ taku/software/TinySVM/ http://www.cs.cmu.edu/ chongw/slda/
V alue SV M L VM SV M L VM S VM L VM we alth 0. 735 0 .816 0. 871 0. 681 0 .797 0.7 43 s-order 0. 775 0 .748 0.7 59 0. 820 0 .767 0. 782 ju stice 0. 664 0 .739 0.4 64 0. 544 0 .546 0. 627 fr eedom 0. 681 0 .780 0. 768 0. 704 0 .722 0. 740 inno v 0. 764 0 .736 0. 720 0. 640 0 .741 0.6 85 ho nor 0. 395 0 .571 0. 553 0. 094 0 .461 0.1 62 a verage 0. 712 0 .772 0. 732 0. 668 0 .722 0.7 16 T able 6: Human \classi er" and LVM effectiveness (same 20 test docs., micro-averaged).

In Table 5 shows per-category effectiveness measures for the SVM and for our LVM , respectively. For each com-parison across the two classi ers, the bolded value is the higher of the two results. This is always true for F 1 , even in the case of the category with the fewest training exam-ples, honor . As Table 4 shows, SVM(w) and SVM(w, b) achieve nearly identical F 1 with 102-fold document cross-validation (the same condition reported in Table 5, which models the actual annotation process), with SVM(w) yield-ing F 1 = 0.7166 and SVM(w,b) yielding 0.7154. We there-fore chose SVM(w) with the numerically higher score as the illustrative baseline for Table 5.

The value honor is omitted from the averages in Tables 3 and 4 because we focus our analysis of those tables on relative comparisons between usable classi ers. As Table 5 shows, the recall for honor is too low (0.26, meaning about 3 of every 4 cases are missed) for practical application. Table 5 also shows that our LVM achieves markedly better precision and recall (and thus better F 1 ) on honor than does SVM(w), so including honor in the micro-averages would not have changed the direction of the improvement that Tables 3 and 4 currently show.

To better understand the behavior of LVM on this col-lection, we have looked into the estimated word-level values as the rst step of qualitative analysis. The social scien-tists collaborating on this research identi ed cue words used to invoke particular values during the annotation process. For example, \American consumers will lose basic Internet freedoms, the engine of innovation will be hobbled, and our global competitiveness will be compromised" which is anno-tated with freedom , innovation , and wealth as sentence-level values. The values names serve as good cue words, and LVM assigned the appropriate values for the words \freedom" and \innovation". As for wealth , LVM estimated that \competi-tiveness" has the word-level value wealth with in uence from the previous word \global". We assumed that each word in a sentence has at-most-two values, and LVM aggregates the word-level values above then correctly estimated all three sentence-level values for the sentence. We plan to conduct more detailed qualitative analysis in our future work.
Because human values are unobservable private states rather than observable facts [36], we see the annotator's task as ren-dering an opinion about which values a statement re ects, and the system's task as replicating that result. As our inter-annotator agreement in Table 2 indicates, well trained and quali ed people will sometimes make different judgments about the same sentence. To see how our LVM compares
T able 4: Classi er effectiveness (micro-averaged, w/o honor , 102-fold document cross-validation).
 with human annotator on a per-category basis, we ran exper-iments with the 20 documents (2,430 sentences) annotated by a second annotator as described in Section 3.

For this experiment, we trained LVM on the remaining 82 documents with meta-parameters: = 0 : 2 ; = 0 : 9 (most frequently selected meta-parameters during document cross-validation). For comparability, we treat the rst annotator's annotations of those 20 documents as correct, and we com-pute effectiveness as if the second annotator were a classi er. The results are shown in Tables 6.

Although human performance is not necessarily an upper bound on performance (because the classi er has more ac-cess to evidence about how one annotator makes decisions than another human would), we see it as a useful reference because the utility of our classi er depends on its relative costs and bene ts when compared to the alternative for cod-ing at large scales, which would be to hire many annotators. Our results show that automation can achieve results sim-ilar to human annotation, but at a lower cost (in terms of human effort).

The difference of the error rate in the average F 1 between human and LVM , z = 0 : 465 Z 0 : 975 suggests that the equality cannot be rejected in signi cance level 0.05. This means that LVM effectiveness is statistically indistinguish-able from the human classi er. As can be seen, LVM does about as well as our human second annotator on average, and it does substantially better in both precision and re-call (and thus in F 1 ) than the second annotator on justice . Notably, honor is markedly less problematic for the human second annotator than for LVM .
We have proposed a word-level probabilistic latent vari-able model for detecting the sentence-level human values re ected in prepared statements on a contentious political issue. The model treats the words in a sentence as hav-ing been chosen based on speci c human values, and the values re ected by each sentence thus can be estimated by aggregating the values associated with each word. We have achieved the highest reported sentence classi cation effec-tiveness F 1 = 0.737 in 102-document cross-validation, which is a 3% relative improvement over SVM(w) that does not take account of sequential dependencies between words, as our model does. LVM also improved over SVM(w, b), which uses bigram features.

Our model can determine the human value(s) x n for the word w n in light of the in uence of the previous word w n 1 It is natural to next consider that word w n 's value(s) x might also be in uenced by the both previous word w n 1 and following word w n +1 . This more complex model may suffer from sparsity, however. We might also explore using longer-distance syntactic dependencies found by a depen-dency parser, but since dependency parsing is imperfect, proximity features will likely continue to offer some bene t. This work was supported in part by NSF IIS-0725459, Japan grant-in-aid for scienti c research (B) 25280118, and DARPA contract HR0011-12-C-0015. Thanks go to Scott Block for serving as the second annotator for this project. [1] R. Artstein and M. Poesio. Inter-coder agreement for [2] D. N. Bengston, W. T. J., and D. P. Fan. Shifting [3 ] D. M. Blei and J. D. Mcauliffe. Supervised topic [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [5] A.-S. Cheng. Values in the Net neutrality debate: [6] A.-S. Cheng and K. R. Fleischmann. Developing a [7] A.-S. Cheng, K. R. Fleischmann, P. Wang, E. Ishita, [8] J. Cohen. A coefficient of agreement for nominal [9] T. G. Dietterich. Approximate statistical tests for [10] K. R. Fleischmann. Information and Human Values . [11] K. R. Fleischmann, D. Oard, A.-S. Cheng, [12] K. R. Fleischmann, D. W. Oard, A.-S. Cheng, [13] B. Friedman, J. Kahn, P. H., and A. Borning. Value [14] T. L. Griffiths and M. Steyvers. Finding scienti c [15] T. L. Griffiths, M. Steyvers, D. M. Blei, and J. B. [16] M. Hall, E. Frank, G. Holmes, B. Pfahringer, [17] H.-F. Hsieh and S. Shannon. Three approaches to [18] E. Ishita, D. W. Oard, K. R. Fleischmann, A.-S. [19] N. Japkowicz and M. Shah. Evaluating Learning [20] T. Joachims. Text categorization with support vector [21] T. Joachims. Learning to classify text using support [22] L. R. Kahle, B. Poulos, and A. Sukhdial. Changes in [23] C. Kluckhohn. Values and Value-Orientations in the [24] J. R. Landis and G. G. Koch. A one-way components [25] B. Liu. Opinion Mining and Sentiment Analysis. In [26] T. Minka and J. Winn. Gates: A graphical notation [27] B. Pang and L. Lee. Opinion mining and sentiment [28] M. F. Porter. An algorithm for suffix stripping. In [29] M. Rokeach. Introduction to Information Retrieval. [30] G. M. Salton and M. J. McGill. The smart and sire [31] H. Schmid. Probabilistic part-of-speech tagging using [32] S. H. Schwartz. Are there universal aspects in the [33] F. Sebastiani. Machine learning in automated text [34] T. C. Templeton, K. R. Fleischmann, and [3 5] B. Verplanken and R. W. Holland. Motivated decision [36] J. M. Wiebe. Tracking point of view in narrative.
Table 7 shows the way we de ned each annotated human value [5].
 T able 7: De nition and Annotation Scheme of Val-ues.

The predictive posterior probabilities are calculated by integrating out and  X  as follows: where ( ;  X  j W ; V; ; ) is the posterior probability after giving the training data ( W ; V ).

In the last formula above,  X  is the predictive posterior probability after observation ( W , V , X , Y ), ^ P ( x ; y j w ; W ; V; X ; Y ; ; ).
For instance, when w = ( a , b ), x = ( j , k ) ( a  X  = b ), and by integrating out and  X  as follows:
Also, when w = ( a , a ), x = ( j , k ) ( j  X  = k ), and y = (0 ; 0), ^ P ( x ; y j w ; W ; V; X ; Y ; ; ) can be calculated:
However, in the case of w = ( a , a ), x = ( j , j ), and y = (0 ; 0), ^ P ( x ; y j w ; W ; V; X ; Y ; ; ) becomes: because of the property of the function: ( z + 2) = ( z + 1) z ( z ). When there are more than two occurrences for one unique word, we have to take into account a large number of combinations for the theoretically-derived calculation. Then we approximate above calculation as:
By this approxmation, the predictive probability in the last case above becomes as follows:  X 
We found the difference between the theoretically-derived and the approximate calculation was not statistically signif-icant in preliminary experiments. We therefore used the ap-proximate calculation in our actual implement for efficiency reasons.
