
GECAD, Instituto Superior de Engenharia do Porto, Porto, Portugal
CISUC, Department of Informatics Engineering, University of Coimbra, Coimbra, Portugal Institute of Policy and Management, Chinese Academy of Sciences, Beijing, China 1. Introduction
Classification is an extensively studied topic in machine learning largely due to a variety of applica-tions in real-life world. Traditional classification methods require that the misclassification costs of dif-ferent classes are equal and the class distribution for training is well balanced. However, the assumptions are seldom satisfied in the real-world applications. On one hand, many evidences have demonstrated the necessity of incorporating misclassification cost into classification [27]. Consequently, the non-uniform misclassification cost occupies a unique position in classification. On the other hand, the real-world data is usually characterized by skewed class distribution where there are more instances in some classes than in others. As was known, the classification tends to perform better on the majority class than on the minority class, which is usually of primary interest in decision making (e.g., the sickness in medi-cal diagnosis, the distressed company in bankruptcy prediction and the fraudulent transaction in credit card fraud detection). For these reasons, cost-sensitive learning when the misclassification costs are non-uniform and class-imbalance learning when the class distribution is highly skewed have been a raising interest in the recent study of classification.
In this paper we investigate the effect of class imbalance with respect to cost-sensitive learning. To achieve it, we take the bankruptcy prediction problem as a case study, where both class imbalance and non-uniform misclassification cost prevail. Bankruptcy prediction is of critical importance as the world is observing the most severe financial crisis and the devastating effect of bankrupt companies. It is well known that the performance of a classification system on the distressed class is more important than the overall performance due to the fact that missing the prediction of a bankrupt company will result in a higher loss than the opposite type of error. Besides, the well-managed companies occur more frequently than the out-of-control companies. A real-world French bankruptcy database is used as the experimen-tal data. We studied several cost-sensitive classification algorithms, implemented by instance-weighting strategy which assigns a weight to instances in proportion to the misclassification cost. The empirical re-sults show that cost ratio and class imbalance level both have strong effect on classification performance. When the cost ratio is fixed, class distribution of training data is the main factor for consideration. A near-balanced training data set is favorable when cost ratio is relatively uniform, whereas a near-natural class distribution is preferable when cost ratio becomes significantly different.

The remainder of this paper is organized as follows. Section 2 introduces the related work on cost-sensitive learning and class-imbalance learning. Section 3 gives the methodology regarding the exper-iment design, data set, cost-sensitive classification methods and performance evaluation used in this study. In Section 4, the results are presented and discussed. Lastly, the contributions and future remarks are addressed in Section 5. 2. Related work
Classification is essentially confronted with non-uniform misclassification cost and imbalanced class distribution. The two problems can be dealt with in a unified framework [35]. On one hand, an applicable way to make an algorithm cost-sensitive is to intentionally imbalance the training data by means of sampling techniques. It is usually implemented either by over-sampling the costly class instances, by under-sampling the less costly class instances, or by systematically combining both over-sampling and under-sampling. For example, over-sampling is applied to obtain sensitive and accurate support vector machine classifier on drug data [11]. Generally, sampling techniques can be categorized into random sampling and heuristic sampling. The former simply replicates (or discards) some instances at random, and the latter generates new instances (or selectively removes some redundant instances) based on the inherent characteristic of the data [16,33]. On the other hand, a solution to class imbalance problem is to train a cost-sensitive classifier with the misclassification cost of the minority class greater than that of the majority class. In [19], the class imbalance ratio is merged with cost ratio through rescaling and handled in a cost-sensitive decision tree.

It is well known that the utility of a classifier can be improved by altering the cost ratio or changing the class distribution [12]. For example, changing the class distribution so that the size of one class is two times more than the other systematically imposes a cost ratio of 2:1 to those two classes in cost-sensitive learning. However, no evidence shows the equivalence of the two approaches in terms of performance improvement. In fact, neither of the two methods always outperforms the other due to the fact that the performance is highly dependent on several factors, including the characteristic of data, the formulation of misclassification cost, and the nature of underlying learning algorithms [31]. It is worthy to study the influence of class distribution on cost-sensitive classification when facing with non-uniform misclassification cost and class imbalance simultaneously.
 The class distribution of training data is known to drastically impact on the classification performance. As was analyzed in [30], the natural distribution generally performs well in terms of overall error rate, while a balanced distribution performs well when evaluated by the area under Receiver Operating Char-acteristic (ROC) curve. This gives insight into the practical problem, i.e., how to select the proportion of classes presented in the training data. Likewise, in [13] the comparison of several resampling tech-niques reveals that over-sampling outperforms under-sampling when data sets are strongly imbalanced. However, these studies focus on the relation between class distribution of training data and classification performance, without taking into account the misclassification cost. Some studies have been devoted to the influence of class distribution involving non-uniform cost. It is claimed that cost-sensitive classifiers favor a natural class distribution at relatively even costs, while a balanced class distribution at highly uneven costs [19]. A recent study found that both non-uniform costs and unbalanced class have a signif-icant effect on the classification performance and suggested increasing the sample size and resampling to counteract the effect [18]. The study of this paper follows this research direction. Differently, we use several instance-weighting cost-sensitive learning algorithms, and a real-world French bankruptcy database with a large number of examples and with a highly skewed class distribution. The results are partially consistent with previous work, which might due to the different (built) experimental data set, learning method and evaluation measures. 3. Research design 3.1. Data description
In the experiments we used Diane, a database of French companies and their foreign subsidiaries from the year 2002 to 2006. The 30 financial ratios for analysis are given in Table 1, including financial strength, liquidity, solvability, productivity of labor and capital, margins, net profitability and return on investment. The database contains 107,389 small or medium-sized companies diversified by industrial sections: manufacturing (25.25%), construction (16.85%), real estate (14.27%), IT firms (6.7%), extrac-tive industries (5.18%), and others (31.84%). In the original database, 973 companies are labeled as distressed in 2007 and the others are labeled as healthy. It means the database has a highly skewed class distribution in the sense that the minority class (bankrupt) is less than 1% out of all instances. The ratios are preprocessed by logarithmized operation and then normalized to unity range in prior to the analysis.
The Diane database has been studied in our previous work [5 X 8], however a small data set with bal-anced class distribution is mostly used without taking into account the real class distribution embedded in the data. In this study, a subset with natural class distribution (in other words, the ratio of bankrupt companies to non-bankrupt companies is approximately the same to the one in the original database) is used for test. As a consequence, the biased indication in future prediction is avoided [28]. With respect to the training, different-sized subsets with varying class distribution are used. To achieve this, the test data set is randomly sampled without replacement from the original database, containing 25% of the minority and majority class examples respectively. As a result, the test data set contains 243 distressed examples and 26,569 healthy examples. The remaining examples are used for generating training data sets, which will be described in detail below. Our motivation is to investigate how class distribution of training data impacts the classification performance. 3.2. Cost-sensitive classification methods
Different strategies have been proposed to make a classification algorithm cost-sensitive, such as sam-pling, instance-weighting, post hoc threshold adjusting, and MetaCost [10]. Among them, instance-weighting is a general and easily implemented method by reweighting the training instances for the base classifier. The weight of an instance is assigned according to the misclassification cost of the class. As-sume the misclassification cost is represented by a cost vector S =[ S 1 ,...,S k ] ,where k is the number classes. Let N be the number of instances in the training data, N j the number of instances in class j. The weights can be calculated from the cost vector so that the instances in the costly class are assigned higher weights and the sum of all weights is N [26]. The pioneer method directed to instance weighting might be the cost-sensitive tree induction employing the greedy divide-conquer algorithm [3]. The instance-weighting C4.5 decision tree assigns the samples of different classes with different weights proportional to the corresponding costs [26]. Following this strategy, the cost matrix is incorporated into the regularized least square algorithm [29] and boosting algorithm [25]. In this study, we use Meta cost-sensitive classifier implemented in Weka, an open-source data mining tool [32], to perform cost-sensitive classification. Four widely used algorithms are employed as the base classifier, namely multi-layer perceptron (MLP), C4.5 decision tree (DT), support vector machine (SVM) and logistic discriminant (LOG). All the results are obtained under the default parameter setting. Additionally, a weighted learning vector quantization (LVQ) is used for the same task. 3.3. Weighted LVQ
Learning vector quantization (LVQ) is reported as a successful model with effective performance in the task of predicting the bankruptcy of companies [21]. As a neural network model designed for supervised learning, it achieves comparable performance with other neural networks, support vector machines and multivariate statistical methods [2]. Since the origination from LVQ1 and its variants (LVQ2, LVQ2.1, and LVQ3) by Kohonen [17], a lot of algorithms have been implemented to improve the convergence, diminish the errors and simplify the network processing. A previous contribution is generalized LVQ, which minimizes an explicit error function via a stochastic gradient descent [24]. Concerning the limitation of Euclidian metric, the importance of input dimensions is derived from train-ing data in distinction sensitive LVQ (DLVQ) or determined based on Hebbian learning in common with standard LVQ (RLVQ) [1] and generalized LVQ (GRLVQ) [14]. Likewise, the commonly used nearest neighbor distance is substituted with harmonic average distance to make LVQ insensitive to the initialization [23]. In [22], a subset of points located in risk zones contribute to the effective learning of prototypes and hence the misclassification errors is decreased. Some efforts have been conducted on the extension of LVQ for cost-sensitive learning, such as the wrapped-based method [7] and the embedded-based method [8].

In this work, we use a weighted version of standard batch LVQ algorithm, called wLVQb [5] to investigate (and study) the effect of class imbalance and cost ratio. The description of wLVQb algorithm is given in Fig. 1. As usual, the neurons of LVQ are arranged in a regular grid and trained through a competitive mechanism. Each neuron is associated with a prototype which represents the class region defined by the nearest principle. The learning of LVQ consists of updating the prototypes so that the class boundary fits the training data. The difference from standard LVQ is that the instance weights are incorporated into the updating of prototypes, thus the instances with higher weights have more influence on the prototypes such that they are harder to be misclassified. Additionally, wLVQb algorithm uses a weighted voting principle rather than the standard majority voting principle. The weighted voting principle takes the cost into consideration when labeling the neurons. The training instances are projected to the learned map via the nearest neighbor principle forming a Voronoi set for each neuron, then the number of the instances are aggregated for each different class. Regarding a neuron m p , N pj denotes the number of class j instances in the Voronoi set of m p . The cost of labeling m p as class j is the total cost of the instances in other classes yield by the labeling task. Consequently, the label with the minimum cost is assigned to the neuron.
 3.4. Performance evaluation
We denote the minority class (bankrupt company) as positive and the majority class (healthy company) as negative. The performance of cost-sensitive classifiers is evaluated based on the confusion matrix defined in Table 2, in which N + ( N  X  ) denotes the number of positive (negative) examples, and tp , fp , tn , fn stand for the true positive, false positive, true negative, false negative respectively. For classification task, overall error rate ( Err ) is the most commonly used criterion for performance evaluation. As the cost should be taken into consideration in the evaluation, we also investigate the error rate of minority incorrectly, and N stands for the total number of instances.
 3.5. Experiment strategy
Several factors are considered in the investigation of cost-sensitive classification performance.  X  Misclassification cost ratio (CR) denotes the ratio of cost due to misclassifying a class instance  X  Imbalance ratio (IR) denotes the relative magnitude of positive class and negative class for training.  X  Sample size (N) denotes the number of examples used for training. To avoid the duplication of mi-
To sum up, several sets of training data are generated with both varying imbalance ratio and sample size. In Fig. 2 we schematically represent the number of bankrupt companies in each training data set. For each specification of the factors, the experiment is performed using the following strategy:
Step 1: A data set is randomly sampled from the remaining examples, satisfying the specified sample
Step 2: For the generated training data set, the cost-sensitive classifiers are applied for learning the
Step 3: The test data is input to the resultant model and the class is predicted. The performance is
Step 4: The process is repeated 10 times with random seeds and the results are averaged. 4. Experimental results and discussion
We examine how different values of misclassification cost ratio (CR), imbalance ratio (IR) and data size (N) impact the classification results through the analysis of variance between groups (ANOVA). ANOVA is a statist ical method to compare the means of the observations with respect to several factors. The rationale is to partition the observed variance in a particular variable into components and evaluate the hypothesis that the different levels of a factor have the same effect on the investigated measure against the alternative, i.e., they do not all have the same effect. In this problem, there are three assignable sources of variation, namely CR, IR, and N, so we use two-way ANOVA to test the main effect and the two-factor interaction effect. Table 3 reports the variance analysis of three factors and their interactions with respect to classification errors and expected misclassification cost when using weighted LVQ. The ANOVA table shows the source of the variability, sum of squares (SS) due to each source, degrees of freedom (df) associated with each source, mean squares (MS) (the ratio SS/df), F statistics (the ratios of the mean squares), and p-values for the F statistics. A small p-value (set as &lt; 0.05 in the experiment) associated with a factor indicates that at least one mean is significantly different from the other means, in other words, there is a main effect due to the factor. The results indicate all factors have significant effect on classification errors and on expected misclassification cost (EMC). Additionally, the strong two-way interaction effects are presented between each pair of factors, indicating their joint contribution to classification performance.

In summary, the results of ANOVA test for the studied cost-sensitive classification methods are listed in Table 4. The p-values emphasized in bold face indicate the effect of factors is not statistically sig-nificant at the 5% level. The p-values with effect significant at the level 5% but not at the level 1% are tabulated in italic, and effect significant at the level 1% are reported in normal script. As can be seen from the table, cost ratio (CR) and imbalance ratio (IR) always have strong effect on the performance of all methods, whereas sample size (N) significantly impacts the performance of these methods except for the Decision Tree. In particular, CR and IR have a strong interaction impact on the classification results, which suggests that the two factors should be considered jointly when applying cost-sensitive classification.

Furthermore, we focus on the expected misclassification cost of classification results under different circumstances. We fix imbalance ratio (or cost ratio) and investigate the effect of other two factors on EMC using ANOVA test of wLVQb results. The so-called p-value is shown in Fig. 3, in which the dashed lines indicate the significance level at 5% and 1% respectively. As was observed from the figure, IR (CR) has markedly higher impact on the performance than N when CR (IR) is fixed. When the class distribution of training data is fixed, cost ratio has significant effect on EMC except for the most overbalanced distribution due to the fact that the over bias of minority class of training data leads to all examples classified as the overwhelmed one. Moreover, sample size significantly impacts on EMC only when the minority class accounts for more than 40% of the training data. When the cost ratio value is fixed (a situation more often in practice), imbalance ratio always has significant effect, whereas sample size has significant effect in some circumstances.
We plot the majority class error rate, minority class error rate, overall error rate and expected misclas-sification cost under different misclassification cost ratios and imbalance ratios in Fig. 4. The results are obtained using wLVQb with all available minority class instances as input. The results of other meth-ods show similar patterns and are not reported here due to space limitation. As was disclosed from the figure, changing cost ratio and altering class distribution of training data are two effective approaches to improve the performance of minority class. On one hand, the resulting classifier presents a tradeoff between the performance on the minority class and the majority class with varying cost ratio. When the costs uphold larger difference, the classification error of the minority class decreases, while inversely the error of the majority class increases. The benefit from the improvement on the minority class does not eliminate the degradation of the majority class. As a result the overall performance deteriorates. The expected misclassification cost presents a similar tendency with the overall error because the error of minority class is overwhelmed by that of majority class even with the enlargement of higher cost. On the other hand, increasing the prior probability of a class moves the class boundary towards the class so that the preferential class is classified more accurately, but the overall accuracy degrades. This outcome is consistent with what was concluded in [30]. For a highly imbalanced data set, the classification of a minority class instance becomes more difficult, thus a higher cost ratio is needed in order to achieve desirable accuracy on the costly class. For example, when the majority class is 20 times as large as the minority class, the neural network fails to classify the minority class instance. Increasing the cost ratio yields few errors on the minority class and more tolerance on the majority class.
 When the cost ratio is known, class distribution of training data is the main factor for consideration. When the cost ratio is uniform or relatively even, a near-balanced training data set is favorable due to the evidence that a natural distribution class results in a high minority error (e.g., at a uniform cost, using a training data with only 5% minority class examples all these examples are classified incorrectly). With an overbalanced data, a high overall error is achieved (e.g., when the proportion of minority class accounts for 95% of the training data, all majority class samples are classified incorrectly). When the cost ratio becomes highly uneven, a near-natural class distribution is preferable due to the good performance on overall error and acceptable performance on minority class. For example, at the most extreme unequal cost situation (20:1), a training data set with 5% minority class increases by 38.7% the minority class error rate while decreases by 78.7% the overall error rate compared with the balanced distribution.
For further performance comparison, we show the results of minority error rate, majority error rate, overall error rate, and expected misclassification cost at a fixed cost ratio in Fig. 5 (CR = 1:1) and Fig. 6 (CR = 20:1). As can be observed from the figure, when the minority class level increases from 5% to 95%, the minority error decreases consistently for all methods. However, the amelioration is uneven across different cost ratios. At the extreme unequal cost (20:1), a small change of imbalance level from 5% to 30% results in a large drop (upgrade) of minority (majority) error compared to the equal cost (1:1). The results suggest to use a less imbalanced training data set when the cost is even in order to achieve a sound performance on the minority class, whereas a more imbalanced training data set is appropriate when the cost is highly uneven to achieve a reasonable accuracy on majority class. It should be noted that our findings are not consistent with the results in [35], which handles both class imbalance and non-uniform cost in a unified rescaling approach. In fact, changing the class imbalance is inequivalent to altering the misclassification cost generally [9].
 Finally, an overall view of the classifier performance is depicted in Fig. 7 for the five studied methods. Receiver Operating Characteristic (ROC) curve shows true positive rate ( tpr = tp/N + ) versus false point in ROC space dominates another if it has a higher tpr and a lower fpr . A classifier A is dominated by another B if each point produced by A is dominated by some points produced by B, while no point of B is dominated by a point of A [15]. As can be observed from the figure, the wLVQb algorithm achieves comparable performance with other classifiers. In fact, it seems no classifier always dominates another in ROC space. It might be due to the fact that all studied classifiers adopt the instance-weighting strategy for achieving cost-sensitive learning. 5. Conclusions
Imbalanced class distribution and asymmetric misclassification cost are two closely related problems in the course of classification. Despite the growing popularity of cost-sensitive learning algorithms, little work has been devoted to the effect of class imbalance on cost-sensitive classification performance. In the previous work, learning when the class distribution is unbalanced and learning when the misclas-sification costs are non-uniform are mostly manipulated in the same manner. However, the interaction between class imbalance and non-uniform costs deserves further exploration. In this paper, we examine the effect of misclassification cost ratio, imbalance ratio and sample size on the performance of cost-sensitive classification using a real-world French bankruptcy database. The experimental results show that (1) Both cost ratio and class imbalance have significant effect on classification performance, in par-ticular, they contribute to the performance of all studied classifiers jointly. The sample size of training data influences the classification performance to some extent depending on the given cost ratio and class distribution. (2) Increasing the cost or the proportion of minority class are two effective approaches to improve the true positive (bankrupt) performance, while deteriorate the true negative (healthy) per-formance. (3) When the cost ratio is fixed, class distribution of training data plays an important role on classification results. The effect of class imbalance is uneven across different cost ratios. A near-balanced training data set is favorable when the cost ratio is relatively uniform, and a near-natural class distribution is preferable when the cost ratio becomes highly uneven. These findings are helpful to select appropriate parameters in the task of imbalanced and cost-sensitive classification problems.
There are some limitations of our work which open up several avenues for future research. Firstly, the empirical results are based on five classification methods for the bankruptcy prediction task. Indeed, the frequent occurrence of class imbalance and non-uniform misclassification cost poses the need for extra research efforts. Future work will verify the generalizability of our findings through an expanded analysis of other algorithms, evaluation measures and data sets. In particular, multi-class data sets will be studied which prevail in many real-world applications such as medical decision support. Secondly, our study is limited to instance-weighting strategy for cost-sensitive learning. We intend to study the widely used sampling technique (including random sampling and heuristic sampling) and post hoc threshold adjusting [34] for further investigation and comparison. Thirdly, we have found that class imbalance and cost ratio have prominent effect on the classification performance, however, how to set the best values of imbalance ratio and cost ratio still remains unsolved. In some applications such as bankruptcy prediction and credit card approval, the cost ratio can be explicitly defined based on the profit indicators in the sense that the more loss of profit indicates the higher cost incurred by the misclassification. It can be also specified manually using several ways, e.g., the relative importance as was done in [20]. The best performance might be achieved by selecting a desired distribution of training data and the value of cost ratio through preliminary experiments as illustrated in [4]. This is another problem of practical importance for further work.
 Acknowledgements This work was partly supported by Natural Science Foundation of China (Contract No. 91024004). References
