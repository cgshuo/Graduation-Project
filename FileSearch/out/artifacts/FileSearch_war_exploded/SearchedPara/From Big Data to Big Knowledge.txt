 We are drowning in big data, but a lot of it is hard to in-terpret. For example, Google indexes about 40B webpages, but these are just represented as bags of words, which don X  X  mean much to a computer. To get from  X  X trings to things X , Google introduced the Knowledge Graph (KG), which is a database of facts about entities (people, places, movies, etc.) and their relations (nationality, geo-containment, ac-tor roles, etc). KG is based on Freebase, but supplements it with various other structured data sources. Although KG is very large (about 500M nodes/ entities, and 30B edges/ relations), it is still very incomplete. For example, 94% of the people are missing their place of birth, and 78% have no known nationality -these are examples of missing links in the graph. In addition, we are missing many nodes (corre-sponding to new entities), as well as new types of nodes and edges (corresponding to extensions to the schema).
In this talk, I will survey some of the efforts we are en-gaged in to try to  X  X row X  KG automatically using machine learning methods. In particular, I will summarize our work on the problems of entity linkage, relation extraction, and link prediction, using data extracted from natural language text as well as tabular data found on the web.
 I.2.4 [ Computing Methodologies ]: Artificial Intelligence X  Knowledge Representation Formalisms and Methods
