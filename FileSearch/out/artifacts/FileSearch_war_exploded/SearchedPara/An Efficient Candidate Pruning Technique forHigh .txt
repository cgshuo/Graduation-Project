 Frequent pattern mining [1], [5], [8] plays an important role in data mining and knowledge discovery techniques such as association rule mining, classification, clustering, time-series mining, graph mining, web mining etc. The initial so-lution of frequent pattern mining, level-wise candidate set generation-and-test paradigm of Apriori [1] has revealed many drawbacks that it requires mul-tiple database scans and generates lots of candidate patterns. FP-growth [5] solved this problem by introducing a prefix-tree (FP-tree) based algorithm with-out candidate set generation-and-test. However, frequent pattern mining has two principal limitations. First, it treats all the items have the same impor-tance/weight/price and second, in one transaction each item appears in a binary (0/1) form, i.e. either present or absent. But in our real world scenarios, each item in the supermarket has different i mportance/price and one customer may buy multiple copies of an item. Therefore , frequent patterns only reflect the cor-relation between items, and it does not re flect the semantic significance of the items.

A high utility mining [2], [3], [4], [6], [7] model was defined to solve the above limitations of frequent pattern mining. It allows the user to conveniently mea-sure the importance of an itemset by the utility value. By utility mining, several important decisions in business area like maximizing revenue, minimizing mar-keting or inventory costs can be taken and more important knowledge about itemsets/customers contributing to the majority of the profit can be discovered. Other application areas, such as biological gene database, web click streams, stock tickers, network traffic measurements, web-server logs, data feeds from sensor networks and telecom call records can have similar solutions.

The existing high utility pattern mining algorithms [2], [3], [4], [7] suffer from the level-wise candidate generation-and-test problem. Therefore, they generate a huge number of candidates and need several database scans to mine the ac-tual high utility patterns. Moreover, their number of database scans is directly dependent on the maximum length of the candidate patterns. In this paper, we propose a novel tree-based candidate pruning technique HUC-Prune (high util-ity candidates prune) to efficiently mine high utility patterns without level-wise candidate set generation-and-test. It prunes a large number of unnecessary can-didates during the mining process. It exploits a pattern growth mining approach and needs a maximum of three database scans in contrast to several database scans of the existing algorithms. Extensive experimental results show that our technique is very efficient for high utility pattern mining and it outperforms the existing algorithms.

The remainder of this paper is organized as follows. In Section 2, we describe the related work. In Section 3, we describe the high utility pattern mining prob-lem. In Section 4, we describe our proposed pruning technique HUC-Prune to efficiently mine high utility patterns. In Section 5, our experimental results are presented and analyzed. Finally, i n Section 6, conclusions are drawn. The theoretical model and definitions of high utility pattern mining were given in [2], named MEU (mining with expected utility). They cannot maintain the down-ward closure property of Apriori . They used a heuristic to determine whether an itemset should be considered as a candidate itemset. It usually overestimates, especially at the beginning stages, where the number of candidates approaches the number of all the combinations of items. This is impractical whenever the number of distinct items is large and utility threshold is low. Later, the same authors proposed two new algorithms UMining and UMining H [3] to calculate the high utility patterns. In UMining they have used a pruning strategy based on utility upper bound property. UMining H has been designed with another pruning strategy based on a heuristic method. But, some high utility itemsets may be erroneously pruned by their heuristic method. Moreover, these methods do not satisfy the downward closure property of Apriori and also suffer from the level-wise candidate generation-and-test methodology.

The Two-Phase [4] algorithm was developed based on the definitions of [2] to find high utility itemsets using the downward closure property. They have defined  X  X ransaction weighted utilization X , and proved it can maintain the downward closure property. For the first database scan, their algorithm finds all the 1-element transaction weighted utilization itemset and based on that generates the candidates for 2-element transaction weighted utilization itemsets. In the second database scan, it finds all the 2-element transaction weighted utilization itemset and based on that generates the c andidates for 3-element transaction weighted utilization itemsets and so on. At the last scan, it finds out the actual high utility itemsets from high transaction weighted utilization itemsets. This algorithm suffers from the same problem of the level-wise candidate generation-and-test methodology. CTU-Mine [6] proposed an algorithm that is efficient over Two-Phase algorithm only in dense database when the minimum utility threshold is very low.

The isolated items discarding strategy (IIDS) [7] for discovering high utility itemsets was proposed to reduce some candidates in every pass of databases. They developed efficient high utility itemset mining algorithm FUM and DCG+ and showed that their work is better than all previous high utility pattern mining works. But still their algorithms suffers from the level-wise candidate generation-and-test problem and needs multiple database scans depending on the maximum length of the candidate patterns. Therefore, we propose a novel tree-based prun-ing technique to remove these problems of the existing works. We have adopted similar definitions presented in the previous works [2], [3], [4]. Let I = { i 1 ,i 2 , ......i m } be a set of items and D be a transaction database {
T 1 ,T 2 , ......T n action utility value l ( i p ,T q ), represents the quantity of item i p in transaction T . For example, in Fig. 1(a), l ( b, T 2 ) = 6. The external utility p ( i p ) is the unit the quantitative measure of utility for item i p in transaction T q , defined by For example, u ( b, T 1 )=2  X  6 = 12 in Fig. 1. The utility of an itemset X in transaction T q , u ( X, T q ) is defined by, where X = { i 1 ,i 2 , .......i k } is a k-itemset, X  X  T q and 1  X  k  X  m . For example, u ( bc, T 1 )=2  X  6+8  X  3 = 36 in Fig. 1. The utility of an itemset X is defined by, For example, u ( ab )= u ( ab, T 2 )+ u ( ab, T 4 )+ u ( ab, T 5 )+ u ( ab, T 6 )=44+16+ 42 + 32 = 134 in Fig. 1. The transaction utility of transaction T q denoted as tu ( T q ) describes the total profit of that transaction and it is defined by, For example, tu ( T 1 )= u ( b, T 1 )+ u ( c, T 1 )+ u ( d, T 1 ) = 12 + 24 + 16 = 52 in Fig. 1. The minimum utility threshold  X  , is given by the percentage of total transaction utility values of the database. In Fig. 1, the summation of all the transaction utility values is 427. If  X  is 25% or we can also express it as 0.25, then the minimum utility value can be defined as Therefore, in this example minutil =0 . 25  X  427 = 106 . 75 in Fig. 1. An itemset X is a high utility itemset, if u ( X )  X  minutil . Finding high utility itemsets means determining all itemsets X having criteria u ( X )  X  minutil .Themain challenge of facing high utility pattern mining areas is the itemset utility does not have the downward closure property. For example, if minutil = 106 . 75 in Fig. 1, then  X  e  X  is a low utility item as u ( e ) = 90. However,  X  de  X  is a high utility itemset as u ( de ) = 134. So, the downward closure property is not satisfied. We can maintain the downward closure property by transaction weighted utilization. Transaction weighted utilization of an itemset X , denoted by twu ( X ), is the sum of the transaction utilities of all transactions containing X . For example, twu ( bc )= tu ( T 1 )+ tu ( T 4 ) = 52 + 37 = 89 in Fig. 1. Here, for minutil = 106.75 in Fig. 1 as twu ( bc ) &lt; minutil , any super pattern of  X  bc  X  cannot be a high twu itemset (candidate itemset) and obviously cannot be a high utility itemset. X is a high transaction weighted utilization itemset (i.e. a candidate itemset) if twu ( X )  X  minutil .
 At first, we describe the construction pro cess of our tree structure. Header table is maintained in our tree structure. Each entry in a header table and node of the tree explicitly maintain item-id and twu (transaction weighted utilization) value for each item. To facilitate the tree traversals adjacent links are also main-tained (not shown in the figures for simplicity) in our tree structure. In the first database scan HUC-Prune captures the twu value of all the items in order to prune unnecessary candidates. We have explained in Section 3 that the down-ward closure property can be maintained by using the twu value. Therefore, by pruning the single-element items having low-twu value with respect to the given threshold, HUC-Prune achieves huge gain in tree-based candidate generation process.

Consider the database shown in Fig. 1 and minutil = 106.75. After the first item  X  c  X  X salow twu item and according to the downward closure property its any superset cannot be high utility itemset. Therefore, we prune this item. Next, we sort the header table in descending order according to their twu values and the new order is &lt;b :347, d :308, a :257, e :204 &gt; . In the second database scan, we take only high twu items from the transactions, sort them according to the header table order, and insert them into the tree. For the first transaction T 1 ,which contains item  X  b  X ,  X  c  X  X nd X  d  X , we discard the low twu item  X  c  X  and arrange it according to the header table order. Both  X  b  X  X nd X  d  X  X etthe tu value of T 1 (the tu value of T 1 is 52, shown in Fig. 1). Fig. 2(a) shows the tree after inserting T .Afterthat T 2 is inserted in the tree (shown in Fig. 2(b)). Before insertion the items of T 2 are arranged (at first  X  b  X  X hen X  a  X ) in the header table order. Item  X  b  X  gets the prefix sharing with the existing node containing item  X  b  X . Its twu value becomes 52+44=96, and item  X  a  X  becomes its child with twu value of 44. Fig. 2(c) shows the final tree with the header table for the full database presented at Fig. 1. The following property is true for our tree structure. Property 1. The total count of twu value of any node in the tree is greater than or equal to the sum of total counts of twu values of its children.
 Now, we describe the mining process of our proposed HUC-Prune technique. As our tree-structure has the important property of FP-tree stated in property 1, pattern growth mining algorithm can be directly applicable to it by using the twu value. Consider the database of Fig. 1. The final tree is created for that database is shown in Fig. 2(c). If we take  X  = 0.25 in that database, then minutil = 106.75 according to equation 5. As like FP-growth, we have started from the bottom-most item.

At first the conditional tree of the bottom-most item  X  e  X  (shown in Fig. 3(a)) is created by taking all the branches prefixing the item  X  e  X  and deleting the nodes containing an item which cannot be a candidate pattern (high twu pattern) with the item  X  e  X . Obviously, item  X  a  X  cannot be a candidate itemset with item  X  e  X  as it has low twu value with the item  X  e  X . So, the conditional tree of item  X  e  X  does not contain the item  X  a  X . However, candidate patterns (1) { b , e : 140 } ,(2) { d , e : 166 } ,(3) { e : 204 } are generated for the item  X  e  X . In the similar fashion, conditional tree for item  X  a  X  is created in Fig. 3(b) and candidate patterns (4) { that, conditional tree for item  X  d  X  is created in Fig. 3(c), and candidate patterns (8) { b , d : 228 } ,(9) { d : 308 } are generated. The last candidate pattern (10) { b : 347 } is generated for the topmost item  X  b  X . Third database scan is required to find high utility itemsets from these 10 candidate high twu itemsets. The high and { d , e : 134 } . To evaluate the performance of our pro posed technique, we have performed several experiments on IBM synthetic T10I4D100K dataset and real-life mush-room dataset from frequent itemset mining dataset repository ( http://fimi. cs.helsinki.fi/data/ ). These datasets do not provide the profit values or quantity of items in transactions. As like the performance evaluation of the pre-vious utility based pattern mining [4], [6], [7] we have generated random numbers for the profit values of each item and quantity of each item in each transaction, ranging from 0.01 to 10.0 and 1 to 10 respectively. Observed from real world databases that most of the items carry low profit, we generate the profit values using a lognormal distribution [4], [6], [7]. Our programs were written in Mi-crosoft Visual C++ 6.0 and run with the Windows XP operating system on a Pentium dual core 2.13 GHz CPU with 1GB main memory.

Mushroom (8,124 transactions, 119 dist inct items) is a dense dataset having transaction length 23 for its every transaction. Almost 20% ((23/119)  X  100) of its total items are present in every transaction. Dense datasets have too many long frequent as well as high utility patterns. Because of the probability of an item X  X  occurrence is very high in every transaction, the number of candidate pat-terns and the maximum length of the candidate patterns sharply increase when the minimum threshold decreases in den se datasets. The number of candidates comparison in mushroom dataset is shown in Fig. 4(a). The number of candi-dates rapidly increases below the utility threshold 20%. For utility threshold 10% and 15% its amount is remarkable larger from our candidate patterns. Fig. 4(b) shows the running time comparison in mushroom dataset. As lower threshold has too many long candidate patterns and several database scans are needed for the huge number of long candidate patterns, time difference between existing algorithms and our technique becomes larger as the  X  decreases. So, it is obvious that our technique is better than the existing algorithms in dense datasets.
T10I4D100K (100,000 transactions, 870 distinct items) is a sparse dataset containing average transaction length 10. Sparse datasets normally have too many distinct items. Although in the average case their transactions length is small, but they normally have many transactions. Handling too many distinct items is a serious problem for level-wise candidate generation-and-test method-ology. Therefore, scanning sparse datasets with many candidates several times is a severe problem of the existing algorithms. The number of candidate patterns and runtime comparison in this dataset are shown in Fig. 5(a) and Fig. 5(b) respectively. These figures d emonstrate that our technique also outperforms the existing algorithms in sparse datasets. The key contribution of this paper is to pr ovide a very efficient tree-based candi-date pruning technique for high utility pattern mining. Our technique prunes a huge number of candidates during tree creation time by eliminating non-candidate single-element patterns and also during mining time by using a pattern growth approach. Its maximum number of database scans is totally independent of the maximum length of candidate patterns. It needs maximum three database scans in contrast to several database scans needed for the existing algorithms. Extensive performance analyses show that our technique is very efficient in high utility pattern mining and it outperforms the existing algorithms in both dense and sparse datasets.

