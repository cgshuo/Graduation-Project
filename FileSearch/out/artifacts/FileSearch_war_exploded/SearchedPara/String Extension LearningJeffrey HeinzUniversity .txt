 The problem of generalizing from examples to patterns is an important one in linguistics and computer science. This paper shows that many disparate language classes, many previously dis-cussed in the literature, have a simple, natural and interesting (because non-enumerative) learner which exactly identifies the class in the limit from distribution-free, positive evidence in the sense of String Extension Learners because each string in the language can be mapped (extended) to an ele-ment of the grammar, which in every case, is con-ceived as a finite set of elements. These learners have desirable properties: they are incremental, globally consistent, and locally conservative.
Classes previously discussed in the litera-ture which are string extension learnable in-clude the Locally Testable (LT) languages, the Locally Testable Languages in the Strict Sense (Strictly Local, SL) (McNaughton and Papert, 1971; Rogers and Pullum, to appear), the Piece-wise Testable (PT) languages (Simon, 1975), the Piecewise Testable languages in the Strict Sense (Strictly Piecewise, SP) (Rogers et al., 2009), the Strongly Testable languages (Beauquier and Pin, 1991), the Definite languages (Brzozowski, 1962), and the Finite languages, among others. To our knowledge, this is the first analysis which identi-fies the common structural elements of these lan-guage classes which allows them to be identifiable in the limit from positive data: each language class induces a natural partition over all logically possi-ble strings and each language in the class is the union of finitely many blocks of this partition.
One consequence of this analysis is a recipe for constructing new learnable classes. One no-table case is the Strictly Piecewise (SP) languages, which was originally motivated for two reasons: the learnability properties discussed here and its ability to describe long-distance dependencies in natural language phonology (Heinz, 2007; Heinz, to appear). Later this class was discovered to have several independent characterizations and form the basis of another subregular hierarchy (Rogers et al., 2009).

It is expected string extension learning will have applications in linguistic and cognitive models. As mentioned, the SP languages already provide a novel hypothesis of how long-distance dependen-cies in sound patterns are learned. Another exam-ple is the Strictly Local (SL) languages which are the categorical, symbolic version of n-gram mod-els, which are widely used in natural language pro-cessing (Jurafsky and Martin, 2008). Since the SP languages also admit a probabilistic variant which describe an efficiently estimable class of distribu-tions (Heinz and Rogers, 2010), it is plausible to expect the other classes will as well, though this is left for future research.

String extension learners are also simple, mak-ing them accessible to linguists without a rigorous mathematical background.

This paper is organized as follow.  X  2 goes over basic notation and definitions.  X  3 defines string extension grammars, languages, and lan-guage classes and proves some of their fundamen-tal properties.  X  4 defines string extension learn-ers and proves their behavior.  X  5 shows how im-portant subregular classes are string extension lan-guage classes.  X  6 gives examples of nonregular and infinite language classes which are string ex-tension learnable.  X  7 summarizes the results, and discusses lines of inquiry for future research. This section establishes notation and recalls basic definitions for formal languages, the paradigm of identification in the limit from positive data (Gold, 1967). Familiarity with the basic concepts of sets, functions, and sequences is assumed.

For some set A , P ( A ) denotes the set of all subsets of A and P finite subsets of A . If f is a function such that f : A  X  B then let f  X  ( a ) = { f ( a ) } . Thus, f  X  : A  X  P ( B ) (note f  X  is not surjective). A set  X  of nonempty subsets of S is a partition of S iff the elements of  X  (called blocks ) are pairwise disjoint and their union equals S .

 X  denotes a fixed finite set of symbols, the al-phabet . Let  X  n ,  X   X  n ,  X   X  ,  X  + denote all strings formed over this alphabet of length n , of length less than or equal to n , of any finite length, and of any finite length strictly greater than zero, re-spectively. The term word is used interchangeably with string . The range of a string w is the set of symbols which are in w . The empty string is the unique string of length zero denoted  X  . Thus range (  X  ) =  X  . The length of a string u is de-noted by | u | , e.g. |  X  | = 0 . A language L is L r = { w r : w  X  L } .

Gold (1967) establishes a learning paradigm known as identification in the limit from positive data. A text is an infinite sequence whose ele-ments are drawn from  X   X   X  { # } where # rep-resents a non-expression. The i th element of t is denoted t ( i ) , and t [ i ] denotes the finite sequence let SEQ denote the set of all possible finite se-quences:
The content of a text is defined below. content ( t ) =
A text t is a positive text for a language L iff content ( t ) = L . Thus there is only one text t for the empty language: for all i , t ( i ) = # .
A learner is a function  X  which maps ini-tial finite sequences of texts to grammars, i.e.  X  : SEQ  X  G . The elements of G (the gram-mars) generate languages in some well-defined way. A learner converges on a text t iff there exists i  X   X  ( t [ j ]) = G .

For any grammar G , the language it generates is denoted L ( G ) . A learner  X  identifies a language L in the limit iff for any positive text t for L ,  X  converges on t to grammar G and L ( G ) = L . Fi-nally, a learner  X  identifies a class of languages L in the limit iff for any L  X  L ,  X  identifies L in the limit. Angluin (1980b) provides necessary and sufficient properties of language classes which are identifiable in the limit from positive data.
A learner  X  of language class L is globally con-sistent iff for each i and for all texts t for some L  X  L , content ( t [ i ])  X  L (  X  ( t [ i ])) . A learner locally conservative iff for each i and for all texts t for some L  X  L , whenever  X  ( t [ i ]) 6 =  X  ( t [ i  X  1]) are from Jain et al. (2007). Also, learners which do not depend on the order of the text are called set-driven (Jain et al., 1999, p. 99). Consider some set A . A string extension function is a total function f :  X   X   X  P required that f be onto. Denote the class of func-tions which have this general form SEF .

Each string extension function is naturally as-sociated with some formal class of grammars and languages. These functions, grammars, and lan-guages are called string extension functions, gram-mars , and languages , respectively.
 Definition 1 Let f  X  SEF . 1. A grammar is a finite subset of A . 2. The language of grammar G is 3. The class of languages obtained by all possi-The subscript f is omitted when it is understood from context.

A function f  X  SEF naturally induces a par-tition  X  ( u  X  f v ) iff f ( u ) = f ( v ) .
 Theorem 1 Every language L  X  L union of blocks of  X  Proof: Follows directly from the definition of  X  and the finiteness of string extension grammars. 2 We return to this result in  X  6.
 Theorem 2 L Proof: We show L any word w belonging to L is a subset of G G inclusion follows similarly. 2 String extension language classes are not in gen-eral closed under union or reversal (counterexam-ples to union closure are given in  X  5.1 and to re-versal closure in  X  6.)
It is useful to extend the domain of the function f from strings to languages. An element g of grammar G for language L = L f ( G ) less if it is not useful. A grammar with no useless elements is called canonical .
 Remark 1 Fix a function f  X  SEF . For every L  X  L f , there is a canonical grammar, namely f ( L ) . In other words, L = L ( f ( L )) . Lemma 1 Let L, L  X   X  L f ( L  X  ) Proof: (  X  ) Suppose L  X  L  X  and consider any g  X  f ( L ) . Since g is useful, there is a w  X  L such that g  X  f ( w ) . But f ( w )  X  f ( L  X  ) since w  X  L  X  . (  X  ) Suppose f ( L )  X  f ( L  X  ) and consider any w  X  L . Then f ( w )  X  f ( L ) so by transitivity, f ( w )  X  f ( L  X  ) . Therefore w  X  L  X  . 2 The significance of this result is that as the gram-mar G monotonically increases, the language L ( G ) monotonically increases too. The following result can now be proved, used in the next section Theorem 3 For any finite L L ( f ( L 0 )) is the smallest language in L f contain-ing L Proof: Clearly L L 0  X  L L  X  L  X  (since f ( L ) = f ( L 0 )  X  f ( L  X  ) ). 2 Learning string extension classes is simple. The initial hypothesis of the learner is the empty gram-mar. The learner X  X  next hypothesis is obtained by applying function f to the current observation and taking the union of that set with the previous one. Definition 2 For all f  X  SEF and for all t  X  SEQ , define  X  f as follows:  X  ( t [ i ]) =
By convention, the initial state of the grammar is given by  X  ( t [  X  1]) =  X  . The learner  X  plifies string extension learning . Each individual string in the text reveals, by extension with f , as-pects of the canonical grammar for L  X  L Theorem 4  X  servative, and set-driven.
 Proof: Global consistness and local conservative-ness follow immediately from Definition 2. For set-drivenness, witness (by Definition 2) it is the case that for any text t and any i  X  f ( content ( t [ i ])) . 2
The key to the proof that  X  limit from positive data is the finiteness of G for all L ( G )  X  L . The idea is that there is a point in the text in which every element of the grammar has been seen because (1) there are only finitely many useful elements of G , and (2) the learner is guaranteed to see a word in L which yields (via f ) each element of G at some point (since the learner receives a positive text for L ). Thus at this point the learner  X  is guaranteed to have converged to the target G as no additional words will add any more elements to the learner X  X  grammar.
 Lemma 2 For all L  X  L S such that L is the smallest language in L taining S . S is called a characteristic sample of L in L f ( S is also called a tell-tale ).
 Proof: For L  X  L follows. For each g  X  f ( L ) , choose some word w  X  L such that g  X  f ( w ) . Since f ( L ) is finite (Remark 1), S is finite. Clearly f ( S ) = f ( L ) and thus L = L ( f ( S )) . Therefore, by Theorem 3, L is the smallest language in L Theorem 5 Fix f  X  SEF . Then  X  in the limit.
 Proof: For any L  X  L nite sample S for L (Lemma 2). Thus for any text t for L , there is i such that S  X  content ( t [ i ]) . Thus in L f containing S by Theorem 3 and Lemma 2.
 Thus,  X  ( t ( j )) = f ( S ) = f ( L ) . 2
An immediate corollary is the efficiency of  X  in the length of the sample, provided f is efficient in the length of the string (de la Higuera, 1997). Corollary 1  X  sample iff f is efficiently computable in the length of a string.

To summarize: string extension grammars are finite subsets of some set A . The class of lan-guages they generate are determined by a func-tion f which maps strings to finite subsets of A (chunks of grammars). Since the size of the canon-ical grammars is finite, a learner which develops a grammar on the basis of the observed words and the function f identifies this class exactly in the limit from positive data. It also follows that if f is efficient in the length of the string then  X  ficient in the length of the sample and that  X  globally consistent, locally conservative, and set-driven. It is striking that such a natural and gen-eral framework for generalization exists and that, as will be shown, a variety of language classes can be expressed given the choice of f . This section shows how classes which make up the subregular hierarchies (McNaughton and Pa-pert, 1971) are string extension language classes. Readers are referred to Rogers and Pullum (2007) and Rogers et al. (2009) for an introduction to the subregular hierarchies, as well as their relevance to linguistics and cognition. 5.1 K-factor languages The k -factors of a word are the contiguous subse-quences of length k in w . Consider the following string extension function.
 Definition 3 For some k  X  f ac k ( w ) =
Following the earlier definitions, for some k , a grammar G is a subset of  X   X  k and a word w be-longs to the language of G iff f ac Example 1 Let  X  = { a, b } and consider gram-mars G = {  X , a, aa, ab, ba } . Then L ( G ) = {  X , a }  X  { w : | w |  X  2 and w 6 X   X   X  bb  X   X  } . The 2-factor bb is a prohibited 2-factor for L ( G ) . Clearly, L ( G )  X  L fac
Languages in L which k -factors are permitted or prohibited. Since f ac k  X  SEF , it follows immediately from the results in  X  X  3-4 that the k -factor languages are closed under intersection, and each has a char-acteristic sample. For example, a characteristic sample for the 2-factor language in Example 1 is {  X , a, ab, ba, aa } ; i.e. the canonical grammar it-self. It follows from Theorem 5 that the class of k -factor languages is identifiable in the limit by  X  guage in Example 1 is illustrated in Table 1.
The class L union. For example for k = 2 , con-sider L L 2 = L ( {  X , a, b, aa, ab, bb } ) excludes string aba , but includes ab and ba , which is not possible for any L  X  L
K -factors are used to define other language classes, such as the Strictly Local and Lo-cally Testable languages (McNaughton and Pa-pert, 1971), discussed in  X  5.4 and  X  5.5. 5.2 Strictly k -Piecewise languages The Strictly k -Piecewise (SP et al., 2009) can be defined with a function whose co-domain is P ( X   X  k ) . However unlike the func-tion f ac the k -length subsequences be contiguous. aa } aaa  X  ab } aaa  X   X  aaa  X  b a , aa, ab } aa  X   X  aa  X  b Table 1: The learner  X  elements to the grammar.

A string u = a string w iff  X  v v a 1 v 1 . . . a k v k . The empty string  X  is a subse-quence of every string. When u is a subsequence of w we write u  X  w .
 Definition 4 For some k  X 
In other words, SP quences, contiguous or not, in w up to length k . Thus, for some k , a grammar G is a subset of  X   X  k . Following Definition 1, a word w belongs to the language of G only if SP Example 2 Let  X  = { a, b } and consider the grammar G = {  X , a, b, aa, ab, ba } . Then L ( G ) =  X   X  \ ( X   X  b  X   X  b  X   X  ) .
 As seen from Example 2, SP languages encode long-distance dependencies. In Example 2, L pro-hibits a b from following another b in a word, no matter how distant. Table 2 illustrates  X  ing the language in Example 2.

Heinz (2007,2009a) shows that consonantal harmony patterns in natural language are describ-able by such SP that humans learn them in the way suggested by  X  been used in models of reading comprehension (Whitney, 2001; Grainger and Whitney, 2004; Whitney and Cornelissen, 2008) as well as text classification(Lodhi et al., 2002; Cancedda et al., 2003) (see also (Shawe-Taylor and Christianini, 2005, chap. 11)). 5.3 K-Piecewise Testable languages A language L is k -Piecewise Testable iff when-ever strings u and v have the same subsequences of length at most k and u is in L , then v is in L as well (Simon, 1975; Simon, 1993; Lothaire, 2005).
A language L is said to be Piecewise-Testable (PT) if it is k -Piecewise Testable for some k  X  If k is fixed, the k -Piecewise Testable languages are identifiable in the limit from positive data (Garc  X  X a and Ruiz, 1996; Garc  X  X a and Ruiz, 2004). More recently, the Piecewise Testable languages has been shown to be linearly separable with a subsequence kernel (Kontorovich et al., 2008).
The k -Piecewise Testable languages can also be described with the function SP  X  f ( a ) = { f ( a ) } . Thus functions SP  X  k define grammars as a finite list of sets of subsequences up to length k that may occur in words in the lan-guage. This reflects the fact that the k -Piecewise Testable languages are the boolean closure of the 5.4 Strictly k-Local languages To define the Strictly k -Local languages, it is nec-essary to make a pointwise extension to the defini-tions in  X  3.
 Definition 5 For sets A each i , f ( f 1 , . . . , f n ) 1. A grammar G is a tuple ( G 2. If for any w  X   X   X  , each f 3. The language of grammar G is 4. The class of languages obtained by all such Table 2: The learner  X  elements to the grammar.

These definitions preserve the learning results of  X  4. Note that the characteristic sample of L  X  L of each f tion of L Locally k -Testable Languages in the Strict Sense (Strictly k-Local) have been studied by sev-eral researchers (McNaughton and Papert, 1971; Garcia et al., 1990; Caron, 2000; Rogers and Pul-lum, to appear), among others. We follow the definitions from (McNaughton and Papert, 1971, p. 14), effectively encoded in the following func-tions.
 Definition 6 Fix k  X  fix of length k , the (right-edge) suffix of length k , and the interior k -factors of a word w are
L k ( w ) = { u  X   X 
R k ( w ) = { u  X   X  Example 3 Suppose w = abcba . Then L { ab } , R 2 ( w ) = { ba } and I 2 ( w ) = { bc, cb } . Example 4 Suppose | w | = k . Then L R k ( w ) = { w } Example 5 Suppose | w | is less than k . Then L k ( w ) = R k ( w ) =  X 
A language L is k -Strictly Local ( k -SL) iff for all w  X  L , there exist sets L, R, and I such that w  X  L iff L I ( w )  X  I . McNaughton and Papert note that if w is of length less than k than L may be perfectly arbitrary about w .

This can now be expressed as the string exten-sion function:
Thus for some k , a grammar G is triple formed by taking subsets of  X  k ,  X  k , and  X   X  k , respec-tively. A word w belongs to the language of G only if LRI SL, and henceforth we refer to this class as k -SL. Since, for fixed k , LRI ing results in  X  4 apply. 5.5 Locally k-Testable languages The Locally k -testable languages ( k -LT) are orig-inally defined in McNaughton and Papert (1971) and are the subject of several studies (Brzozowski and Simon, 1973; McNaughton, 1974; Kim et al., 1991; Caron, 2000; Garc  X  X a and Ruiz, 2004; Rogers and Pullum, to appear).

A language L is k -testable iff for all w  X  LRI k ( w 1 ) = LRI k ( w 2 ) then either both w 1 , w 2 belong to L or neither do. Clearly, every language in k -SL belongs to k -LT. However k -LT prop-erly include k-SL because a k -testable language only distinguishes words whenever LRI LRI k ( w 2 ) . It is known that the k -LT languages are the boolean closure of the k -SL (McNaughton and Papert, 1971).

The function LRI  X  languages. Informally, each word w is mapped to a set containing a single element, this element is the triple LRI subset of the triples used to define k -SL. Clearly, L L Locally Testable ( k -LT) languages. 5.6 Generalized subsequence languages Here we introduce generalized subsequence func-tions, a general class of functions to which the SP k and f ac k functions belong. Like those functions, generalized subsequence functions map words to a set of subsequences found within the words. These functions are instantiated by a vec-tor whose number of coordinates determine how many times a subsequence may be discontiguous and whose coordinate values determine the length of each contiguous part of the subsequence.
 Definition 7 For some n  X  h v 0 , v 1 , . . . , v n i the length of the subsequences; i.e. k = P n f ~v ( w ) =
The following examples help make the general-ized subsequence functions clear.
 Example 6 Let ~v = h 2 i . Then f erally, f Example 7 Let ~v = h 1 , 1 i . Then f f Example 8 Let ~v = h 3 , 2 , 1 i and a, b, c, d, e, f  X   X  . Then L prohibit strings w which contain subsequences abcdef where abc and de must be contiguous in w and abcdef is a subsequence of w .

Generalized subsequence languages make dif-ferent kinds of distinctions to be made than PT and LT languages. For example, the language in Ex-ample 8 is neither k -LT nor k  X  -PT for any values erly include the k -SP and k -SL classes (Exam-ples 6 and 7), and the boolean closure of the sub-sequence languages ( f  X  and PT classes.

Since for any ~v , f functions the learning results in  X  4 apply. Note that f is the length of the maximal subsequences deter-mined by ~v . This section provides examples of infinite and nonregular language classes that are string exten-sion learnable. Recall from Theorem 1 that string extension languages are finite unions of blocks of the partition of  X   X  induced by f . Assuming the blocks of this partition can be enumerated, the range of f can be construed as P
Table 3: The language class L
In the examples considered so far, the enumera-tion of the blocks is essentially encoded in partic-ular substrings (or tuples of substrings). However, much less clever enumerations are available. Example 9 Let A = { 0,1 } and consider the fol-lowing function: The function f belongs to SEF because it is maps strings to a finite co-domain. L guages shown in Table 3.
 The language class in Example 9 is not regular be-cause it includes the well-known context-free lan-guage a n b n . This collection of languages is also not closed under reversal.

There are also infinite language classes that are string extension language classes. Arguably the simplest example is the class of finite languages, denoted L Example 10 Consider the function id which id ( w ) = { w } . 5 A grammar G is then a finite words in  X   X  ; in fact, L ( G ) = G . It follows that L It can be easily seen that the function id induces the trivial partition over  X   X  , and languages are just finite unions of these blocks. The learner  X  makes no generalizations at all, and only remem-bers what it has observed.

There are other more interesting infinite string extension classes. Here is one relating to the Parikh map (Parikh, 1966). For all a  X   X  , let f ( w ) be the set containing n where n is the num-ber of times the letter a occurs in the string w . For example f tion mapping strings to singleton sets of natural numbers, so it is a string extension function. This function induces an infinite partition of  X   X  , where the words in any particular block have the same number of letters a . It is convenient to enumerate the blocks according to how many occurrences of the letter a may occur in words within the block. Hence, B currences of a , B one occurrence of a , and so on.
 In this case, a grammar G is a finite subset of e.g. { 2, 3, 4 } . L ( G ) is simply those words which have either 2, 3, or 4, occurrences of the letter a . Thus L guages of infinite size, which is easily identified in the limit from positive data by  X 
This section gave examples of nonregular and nonfinite string extension classes by pursuing the implications of Theorem 1, which established that f  X  SEF partition  X   X  into blocks of which lan-guages are finite unions thereof. The string exten-sion function f provides an effective way of en-coding all languages L in L codes a finite set, the grammar. One contribution of this paper is a unified way of thinking about many formal language classes, all of which have been shown to be identifiable in the limit from positive data by a string extension learner. Another contribution is a recipe for defin-ing classes of languages identifiable in the limit from positive data by this kind of learner.

As shown, these learners have many desirable properties. In particular, they are globally consis-tent, locally conservative, and set-driven. Addi-tionally, the learner is guaranteed to be efficient in the size of the sample, provided the function f itself is efficient in the length of the string.
Several additional questions of interest remain open for theoretical linguistics, theoretical com-puter science, and computational linguistics.
For theoretical linguistics, it appears that the string extension function f = ( LRI defines a class of languages which obey restric-tions on both contiguous subsequences of length 3 and on discontiguous subsequences of length 2 , provides a good first approximation to the seg-mental phonotactic patterns in natural languages (Heinz, 2007). The string extension learner for this class is essentially two learners:  X   X  make predictions about generalizations, which can be tested in artificial language learning experi-ments on adults and infants (Rogers and Pullum, to appear; Chambers et al., 2002; Onishi et al., 2003;
For theoretical computer science, it remains an open question what property holds of functions f in SEF to ensure that L free, or context-sensitive. For known subregular classes, there are constructions that provide deter-ministic automata that suggest the relevant prop-erties. (See, for example, Garcia et al. (1990) and Garica and Ruiz (1996).)
Also, Timo K  X otzing and Samuel Moelius (p.c.) suggest that the results here may be generalized along the following lines. Instead of defining the function f as a map from strings to finite subsets, let f be a function from strings to elements of a lattice. A grammar G is an element of the lattice and the language of the G are all strings w such that f maps w to a grammar less than G . Learners  X  rent hypothesis and the grammar to which f maps develop this idea and demonstrate additional prop-erties of string extension classes and learning, and show that the pattern languages (Angluin, 1980a) Also, hyperplane learning (Clark et al., 2006a; Clark et al., 2006b) and function-distinguishable learning (Fernau, 2003) similarly associate lan-guage classes with functions. How those analyses relate to the current one remains open.
 Finally, since the stochastic counterpart of k -SL class is the n -gram model, it is plausible that probabilistic string extension language classes can form the basis of new natural language process-ing techniques. (Heinz and Rogers, 2010) show how to efficiently estimate k -SP distributions, and it is conjectured that the other string extension lan-guage classes can be recast as classes of distri-butions, which can also be successfully estimated from positive evidence.
 This work was supported by a University of Delaware Research Fund grant during the 2008-2009 academic year. I would like to thank John Case, Alexander Clark, Timo K  X otzing, Samuel Moelius, James Rogers, and Edward Stabler for valuable discussion. I would also like to thank Timo K  X otzing for careful reading of an earlier draft and for catching some errors. Remaining er-rors are my responsibility.

