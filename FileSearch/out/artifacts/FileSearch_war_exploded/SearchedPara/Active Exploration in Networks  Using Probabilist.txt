 Many interesting domains in machine learning can be viewed as networks, with relationships (e.g., friendships) connecting items (e.g., individuals). The Active Exploration (AE) task is to identify all items in a network with a desired trait (i.e., positive labels) given only partial information about the network. The AE process iteratively queries for labels or network structure within a limited budget; thus, accurate predictions prior to making each query is critical to maximiz-ing the number of positives gathered. However, the targeted AE query process produces partially observed networks that can create difficulties for predictive modeling. In particular, we demonstrate that these partial networks can exhibit ex-treme label correlation bias, which makes it difficult for con-ventional relational learning methods to accurately estimate relational parameters. To overcome this issue, we model the joint distribution of possible edges and labels to improve learning and inference. Our proposed method, Probabilistic Relational Expectation Maximization (PR-EM), is the first AE approach to accurately learn the complex dependencies between attributes, labels, and structure to improve predic-tions. PR-EM utilizes collective inference over the missing relationships in the partial network to jointly infer unknown item traits. Further, we develop a linear inference algorithm to facilitate efficient use of PR-EM in large networks. We test our approach on four real world networks, showing that AE with PR-EM gathers significantly more positive items compared to state-of-the-art methods.
 Many interesting applications in machine learning involve data that can be viewed as networks, with relationships (e.g., friendships, hyperlinks) connecting items (e.g., individuals, webpages). The existence of a relationship often implies an association between the traits of the connected items, and these dependencies can be used to improve predictions. The Active Exploration (AE) task is to iteratively identify all items in a network with a particular trait (i.e., items with positive labels) when network information is partially observed [11, 12, 3]. Applications of AE include probing securities traders X  communication networks for individuals involved in fraud, or crawling the Web to gather pages with relevant content via hyperlinks. In these domains resource constraints only allow for the investigation of a limited num-ber of items, and the goal is to maximize identification of items with the target trait within the available budget.
AE is an iterative task in network domains where querying the labels and relationships from the network has an associ-ated cost. The goal of AE is to gather as many items with a particular label (i.e., trait) as possible, within a querying budget. As a result, predictions about what to query in a given iteration can only use the previously queried labels, attributes and relational information.

Every AE process involves three high-level steps: query-ing, learning, and prediction. Querying actions gather ad-ditional information about the network, such as item la-bels (e.g., fraudulent or not) and relational structure (e.g., links from phone records). To decide what to query, AE algorithms use predictive models. These models first learn parameters using the currently available network informa-tion and are then applied for prediction to infer the un-known items X  labels. Given the limited querying budget, it is critical that the models accurately identify items likely to have the target label (to minimize queries). Prior work on AE methods has focused on estimating label probabil-ities through weighted random walks in the network (i.e., predictions are comprised of weighted averages of nearby la-bel values) [11, 12, 3]. However, in some cases estimates that condition directly on the items X  attributes can be more ac-curate than estimates based only on relational information. Relational Machine Learning (RML) (see e.g., [5]) methods can learn the relative importance of dependencies among labels, attributes, and network structure. As such, in this work we propose the first AE method to incorporate RML learning in order to fully leverage all available information.
In [11], the authors introduced a version of the AE task where each query returns an item X  X  label and local relational structure (see Section 5 for discussion of other variants). These queries result in a partially observed view of the un-derlying network each iteration, which the algorithm must use to learn a model and predict the items (among the set of unlabeled instances) that are likely to be positive. We illustrate the process in Figure 1 with a simplified example. In Iteration 1, the algorithm uses the observed labels, rela-tional structure, and attributes to estimate the label proba-bilities for the border items ( v a ,v b ,v c ) and queries the node with highest probability of value 1 (e.g., v c ). This reveals additional structure in Iteration 2, namely, the revealed la-bel for v c and additional links to v d and v e . The resulting partially observed network (1.b) has biased relational simi-larities compared to the full network (1.c) because only the positive neighbors of v c are observed. More generally, this overrepresentation of positive neighbors is a typical case for any effective AE algorithm as AE aims to only acquire pos-itive nodes. In the example, a conventional RML method (using only the observed network) will learn biased parame-ters that result in poor performance on subsequent iterations (e.g., by selecting v d or v e ). An effective use of RML for AE must address the sampling bias in the partially observed net-work to learn parameters that reflect the true dependencies.
In this paper, we demonstrate how the simple label corre-lation bias illustrated in Figure 1 generalizes to the partially observed networks produced by the AE process. In particu-lar, we show that the AE sampling process commonly pro-duces partially observed networks with negatively correlated labels across the edges, in contrast to the positively corre-lated full graph. Since conventional RML models assume a fully observed network is available to learn the parameters, when presented with a highly biased network sample these models struggle.

To address this we develop a semi-supervised learning ap-proach based on expectation maximization (EM). Specifi-cally, we propose to incorporate inferred values of the unob-served labels and edges into the learning step to improve the parameter estimates. With respect to Figure 1.a, this means we will first infer the labels of v a ,v b and v c , then use the in-ferences to relearn the model. Furthermore, since the rela-tionships between the border vertices are also hidden (e.g., the link ( v a ,v b )) we incorporate probabilistic relationships into our formulation. We refer to our method as Probabilis-tic Relational EM , or PR-EM. The space of combinations of possible edges and labels is exponential in the number of items, so we develop a Variational Mean Field (VMF; [6]) approach for approximate inference. Conventional VMF for PR-EM would be quadratic in the number of border nodes, which is computationally prohibitive in an iterative process such as AE. To overcome this, we introduce a linear time approximation to perform PR-EM inference. The contribu-tions of this work can be summarized as: Current approaches to AE use predictive models to decide which items to query [11, 12, 3]. At each iteration, an AE algorithm selects one (or more) items to label from the set of unlabeled items. When an item is labeled, relationships to other items (unlabeled and labeled) are also acquired. Thus the set of unlabeled items consists of the labeled items X  relational neighbors. These items are the border instances, which can be selected for labeling in subsequent iterations. Prior to selection, an AE algorithm utilizes a model to infer the instances that are likely to have the desired class label value. The choice of model is key to success on the AE task: if it returns accurate predictions for the border labels, the algorithm can find larger numbers of instances with the desired label before the budget runs out. Let G =  X  V , E , X , Y  X  define a graph, where V is a set of vertices and E  X  V  X  V is a set of edges, or relationships, be-tween the vertices where ( v i ,v j )  X  E indicates a relationship. Every vertex v i  X  V has a corresponding W -dimensional vector of attributes x i  X  X that is observed, as well as a label y i  X  Y , where y i  X  Y is the space of possible labels. Through this work we utilize Y = { 0 , 1 } as our labels. The instances labeled y i = 1 are the target instances to locate (such as fraudulent traders), and 0 otherwise 1 .
 AE requires the specification of three subgraphs of G : G G
O and G S (Figure 2 illustrates each subgraph). First, let the subgraph G L =  X  V L , E L , X L , Y L  X  consist of the labeled vertices V L  X  V (the 1 / 0 vertices in Figure 2) and the edges between labeled vertices E L  X  E (Figure 2.b). The corresponding set of known labels and attributes is Y L and X L . Next, let V B be the border vertices (blue v b vertices in Figure 2.a). The border vertices are unlabeled but through their relationship with a labeled vertex are known to the active explorer:
Similarly, define the true (actually existing but hidden) set of edges between the border instances E B  X  V B  X  V B Unlike the border vertices V B , the border edges E B are un-observed during the AE process. Let the subgraph G O =  X  V
O , E O , X O , Y L  X  be the subgraph which contains the la-beled subgraph, the border vertices V B , as well as the ob-served edges between the V B and V L (Figure 2.c). Further,
The representations are applicable to all discrete labels, but associated applications are beyond the scope of this work (c) G O probability distribution over the unknown border edges. Algorithm 1 ActiveExploration( G O , C ) X
O = X L  X  X B . The set of edges E O of G O does not contain the unobserved E B (dashed lines in Figure 2.a):
In contrast, the subgraph G S =  X  V S , E S , X O , Y L compasses all labeled and border vertices ( V S = V L  X  V as well as all the true edges between them E S = E O  X  E B (Figure 2.d).

Let E 0 B  X  V B  X  V B be a possible set of border edges (but not necessarily the true set E B ), and E B be all pos-sible combinations of border edges. Our work will require the estimation of the probability of a set E 0 B , P ( E being the true border edges E B . Similarly, G S denotes all combinations of full subgraphs, with G 0  X  G S being a par-ticular combination (Figure 2.e). For ( v i ,v j )  X  V B P ( E jk = 1 | E O ) refers to the probability of ( v that is, the probability that two vertices have an edge be-tween them in the true subgraph G S .

We define three structural characteristics which will be utilized in the upcoming sections. First, let G  X  indicate a particular subgraph (such as G,G L ,G O ,G S ). We define N ( v i ) to be the set of neighbors of a vertex v i : N  X  ( v { v j | ( v i ,v j )  X  E  X  } . Second, as a notational extension, let Y
N  X  ( v i ) indicate the corresponding set of labels for the neigh-bors of a vertex v i . Third, d  X  ( v i ) indicates the degree of the vertex v i in the subgraph G  X  , where d  X  ( v i ) = | N  X  AE algorithms aim to identify positive instances in a graph G in an iterative fashion. During each iteration, the algo-rithm uses the observed subgraph G O to infer the positive probabilities of the unlabeled border labels Y B . The AE algorithm then chooses a small set of border items to label, acquires any new edges and border vertices, and repeats un-til the budget is exhausted.

Algorithm 1 presents pseudocode for a generic AE algo-rithm. It begins with an initial observed graph G O and a classifier C , and proceeds to iteratively sample labels and structure until the query budget runs out. Each iteration of the algorithm begins by modeling the labels of the bor-der items. The algorithm may choose to learn parameters of the model (Line 4), but most current methods skip this step. Then the model is applied for prediction of Y B (Line 5). Instances are selected , or queried, on Line 7, with the goal of maximizing the number of positives identified 2 . The items are then labeled on Line 8, while Lines 9 and 10 iden-tify new border vertices and edges. Lines 12-15 update the observed network with the newly acquired labels, edges and border instances 3 .

The primary task in AE is to infer the border probabili-ties P ( Y B ) on Line 5 using only the observed subgraph G (which are then used for selection on line 7). Prior work infers unknown labels (i.e., y B  X  Y B ) by averaging the la-bels of the neighbors [11], with variants including weighting the neighbors by their attributes [3] or their random walk distances across the network [12]. In contrast, in this paper we learn a model that directly conditions on the attributes and neighboring labels using relational machine learning, so inferences are no longer solely comprised of nearby labels. AE algorithms explicitly target positive instances to label. If the algorithms are successful, they gather larger num-bers of positive samples into the labeled set than negatives, but may make occasional mistakes and gather negatives as well. This is illustrated through the example in Figure 1.a: the algorithm may choose to label v c as it has two positive neighbors. As v c was negative (Figure 1.b), our learning algorithm should take into account the observed mistake, adjust its parameters to incorporate the new information, and use the new estimates to make better predictions on fu-ture samples. However, if the learning algorithm uses just the observed labels in this example network it would ap-pear that negatives only link with positives. In contrast, the full subgraph is positively correlated (Figure 1.c). Thus, a model which learns from the limited G L would assign higher positive probability to neighbors of the negative instances, rather than the neighbors of the positive instances.
We will next demonstrate that throughout the AE pro-cess different subgraphs exhibit different amounts of label correlation bias in comparison to the true graph G ; in par-ticular, the labeled subgraph G L is considerably more biased than subgraphs that incorporate the missing border labels
In this work, we select the most probable examples.
For brevity we omit X , which is updated with V . Figure 3: The correlations of the three subgraphs, G L ,G + O and G + S , along with the full graph correlation G , when using Oracle for AE.
 Y
B . First, let G + O =  X  V O , E O , X O , Y L  X  Y B  X  be the ob-served subgraph augmented with the true Y B labels, and let G + S =  X  V S , E S , X S , Y L  X  Y B  X  , or the full subgraph G augmented with Y B . Next, we will define a classifier to use in the AE algorithm to actively explore the network, choos-ing the most probable instances to explore as predicted by the classifier. As the AE process unfolds, we will measure the label correlations across the links of the G L ,G + O subgraphs against the true graph G , showing that G L ex-hibits the most bias. The classifier that we construct is a hypothetical  X  X racle X  since it will be allowed to cheat and observe the full subgraph G + S for learning (Line 4, Algorithm 1). After learning, the Oracle then infers the unlabeled bor-der vertices (Line 5, Algorithm 1) using the full subgraph G S rather than the observed G O .

We use our Oracle to actively explore two of our datasets (Music and DVD co-purchases  X  dataset details in Section 6.2). In Figure 3, we plot the Pearson correlations of the subgraphs G L , G + O and G + S , as well as the correlation of the full graph G , for each dataset as AE explores utilizing the Oracle for prediction 4 . The G L subgraphs produced by AE when exploring the Music dataset are negatively correlated as we acquire more labels. The Music dataset produces the most striking contrast, but the bias is also observed in the DVD dataset. Note that G + S best models the label correla-tion found in the true graph G , making G S the best option for learning and inference. In contrast, learning from G G
O would result in more biased parameter estimates. Given an observed graph G O , there are a variety of mod-els that can be employed to learn the parameters (Line 4, Algorithm 1) and infer the labels Y B (Line 5, Algorithm 1). Although they have not been applied directly to the AE task before, there are two approaches that can be immedi-ately adapted to this domain. We describe these methods (RML and R-EM) next and analyze how they would use G L and G O . As neither models the full G S , they will experi-ence a larger amount of label correlation bias (as discussed above). To address this, we propose a novel approach (PR-EM), which estimates G S to improve learning and inference. ditional RML conditions directly on a vertex X  X  attributes and neighboring labels, as opposed to weighting the labels of nearby instances. RML formulates the problem in two steps: learning of parameters  X  C using labeled data (Line 4, Algorithm 1), then inferring the missing labels using the parameters (Line 5, Algorithm 1). Existing RML meth-ods assume knowledge of the full graph for learning and
The results are averaged over 100 trials, and the error bars are small and hidden behind the line markers.
 Algorithm 2 R-EM Learning( G O , C ,  X  C ) inference, meaning each conditional distribution is over G . In order to adapt RML to the AE task, this would corre-spond to learning using just the labeled data G L , mean-ing each label y i  X  Y L  X  Y B has a conditional distribution P ( y i | x i , Y N L ( v i ) ,  X  C ). The parameters  X  C the labeled subgraph G L via Maximum Likelihood Estima-tion (MLE) or the more efficient Maximum Pseudolikelihood Estimation (MPLE) [5]: where the second line shows the MPLE maximization prob-lem. We use P L to denote learning on the labeled subgraph G
L ; similarly, RML uses the learned parameters  X   X  C to in-fer the border labels utilizing the subgraph G O , denoted P O ( Y B | Y L , X B , E O ,  X   X  C ) (Line 5, Algorithm 1). expectation maximization (R-EM) algorithm, which utilizes the expected values of the unlabeled instances to improve estimation of  X   X  C . Again, we can adapt this model to the AE task by using Algorithm 2 in place of Lines 4-5 in Algorithm 1. Algorithm 2 first (Line 2) computes the expected values of the unlabeled examples: That is, we use the previous iteration X  X  estimated parame-ters  X  old C to compute the distribution of the border labels. Let Y B indicate the space of possible label combinations for the missing border labels. The distribution of combinations Y
B  X  Y B is used to maximize the pseudolikelihood on the observed subgraph G O (Line 3):
This contrasts with traditional RML, which would learn using just the subgraph G L . The E and M steps are repeated until convergence. However, the R-EM inference step re-mains limited by only inferring over the observed graph G As a result, the expectations of the unlabeled border ver-tices V B are inferred independently as there are no observed edges between the border nodes.
 the border label predictions by utilizing a distribution of possible border edges. Our method will infer the subgraph G
S : this will introduce dependencies between the border labels and allow us to perform collective inference when pre-dicting Y B . Thus, vertices which are  X  X ear X  each other in the network will be able to utilize each other X  X  predictions to jointly improve inferences. In particular, let P ( E 0 B resent the probability of a particular set of edges E 0 B given the observed graph G O . We will extend the relational EM process to marginalize over the distribution of possible border edges: where E 0 S = E O  X  E 0 B . This estimate replaces the previous E-Step of the R-EM method with a collective prediction of Y Our proposed inference step utilizes a distribution over G
S  X  G S , rather than only using G L or G O . As the expec-tations are computed with G S , the M-step is over the full subgraph by using the improved predictions:
As our proposed method incorporate the probabilities of the missing relationships into the learning and inference, we call it Probabilistic Relational EM, or PR-EM. PR-EM can be utilized to jointly infer the probability of missing edges E
B in a network and incorporate the additional information into predicting the unlabeled Y B . PR-EM is designed for AE, where large numbers of edges are unavailable, but can also be applied on other probabilistic network domains.
Unlike learning using just G L or G O , utilizing the dis-tribution over G S presents a unique set of challenges. In the worst case, marginalizing over the full distribution of P ( E 0 B | E O ) would involve a summation over an exponential number of edge combinations. Even when assuming con-ditional independence between the edges, a straightforward implementation of PR-EM would pair every border vertex with each other, resulting in a quadratic runtime. Thus, we also develop a fast algorithm that performs PR-EM inference over the probabilistic edges in O ( d N O ( v b )) for each v This algorithm is linear in the number of observed neighbors of a vertex, rather than a conventional inference algorithm being quadratic in the number of observed neighbors, and is the same runtime as RML and R-EM. In this section we discuss our proposed PR-EM model, with a focus on efficient inference over the probabilistic edges. We begin with a discussion of the inference methods of RML and R-EM, which will be extended to incorporate collective inference when estimating the border labels Y B . Along the way we will incrementally introduce the probability of edges E
B  X  X  B , the corresponding VMF inference algorithm, and our linear time implementation. We make the usual RML Markov assumption and define a generative local conditional model C which falls into the class of models represented by Figure 4.a. That is, given a subgraph G  X  we assume the relational features are conditionally independent from the attributes and each other:
We allow any form for the attributes conditioned on the la-bel; for instance, the Naive Bayes representation falls within this class of models (Figure 4.b), but the attribute condi-tional can be more expressive.
 Inference on the Observed Graph ( G O ) : To start, we for-mulate the inference methods of RML and R-EM. These in-fer the border labels Y B utilizing the joint distribution of Y B given the observed graph G O : P O ( Y B | Y L , X B , E We will then extend to the more difficult distribution over G , which is necessary for our PR-EM method.

Given only the observed graph G O , all border vertices v  X  V B are conditionally independent of each other, mean-ing the joint distribution of border vertices can be broken into inferring each border vertex v i independently. Z i rep-resents the corresponding partition function for the condi-tional log probability of y i . We define  X  i ( y i ) to represent the summation over the observed log probabilities for a vertex v -the log conditional for an instance y i is then:
We can compute each local summation  X  i ( y i ) in O ( d O time. Utilizing the conditional independence provided by G O , RML and R-EM apply the above equation to each v b  X  V B to infer the joint distribution P O ( Y B | Y L , X B , E Inference on the Full SubGraph ( G S ) : The above infer-ence represents the contributions from the observed graph G
O when inferring the border labels Y B . However, it does not incorporate any edges given a full subgraph G 0 S  X  G Consider y i  X  Y B : let V B \ i be the set of vertices in V cluding v i . Similarly, for all v b  X  V B \ i , let E ib variable representing an edge between v i and v b . E ib = 1 when the edge between v i and v b exists, and 0 otherwise. Define E 0 iB as the complete set of random variables E ib the possible edges between v i and all other border vertices. In the next step, we introduce the conditional of y i under the assumption Y B \ i and E iB are known:
When an edge E ib is unobserved the corresponding belief from y b is not incorporated into the summation and does not contribute to y i . The derived conditional log probabilities currently have three complicating elements:
In the rest of this section we will solve each of these issues. We begin by proposing the probability of an edge P ( E ik between two border instances ( v i ,v k )  X  E 0 B . We will then generalize this to the distribution of edges P ( E 0 B | E
First, the probability of an edge E ik is proportional to a two hop random walk across the observed graph G O . Namely, the probability of a random walk taking a single step from a vertex v to a neighbor v 0  X  N  X  ( v ) is ( d  X  ( v ))  X  1 sponding probability of a two hop random walk starting at v and landing at v k on G O is a marginalization over the inter-mediate vertices v j  X  N O ( v i ): P v We allow the random walk to start at either v i or v k and assume the number of edges that are missing per vertex is proportional to the observed number of edges. This enforces more active vertices from the observed subgraph G O to be more active in the full subgraph G S . We introduce the hy-perparameter  X   X  2 to represent the weight of the walk (we divide by 2 without loss of generality). We solve to recover:
As a result, the probability of an edge E ik existing is the weighted summation of the intermediate vertices X  inverted degrees. First, as the summations are defined over G O the probabilities E ij  X  E 0 B are conditionally independent. This result, coupled with the summations being only over the two hop neighbors, initially reduces our complexity to O ( | V Second,  X   X  must lie in the following range: The lower bound of 0 will remain fixed and represents the case where no collective inference is performed (inference reduces to G O ); however, later in this section we will show how in practice the upper bound can be relaxed (0  X   X   X  ). The PR-EM conditional distributions of y i  X  Y B defined in Equation 2 require the other border labels Y B \ i and edges E iB (found in Equation 3). We next incorporate the prob-abilities over these sets utilizing VMF inference. We define a fully factorized approximating distribution over the set of border labels Y B and edges E 0 B , denoted Q ( Y B , E 0
Each Q ( y i ) represents the current probability of each v label to be y i  X  Y . VMF computes the optimal solution of Q ( Y B , E 0 B ) by iteratively updating each Q ( y i ) component until convergence [6]. We next define the updates for each Q ( y i ) given the other Q ( y b ) for y b  X  Y B \ i and E As the E jb  X  E 0 B are independent we do not recompute them at each iteration. Let Y B \ i be the space of possible border labelings except v i , and E 0 iB be the space of all possible v border edges. The VMF update for each conditional is 5 :
For clarity we omit listing x i and E O . These are fixed and conditioned on when inferring y i . where Z Q ( i ) is the variational normalizing constant (replac-ing Z i ). We begin by reducing the newly notated  X  by in-serting our conditionals from Equation 2 and simplifying:
We pause to highlight that the observed dependencies  X  ( y i ) do not depend on the border edge probabilities. Namely, as Q ( E 0 iB ) is a probability distribution and E iB is all combi-nations of border edges the summation must equal 1, allow-ing  X  i ( y i ) to be pulled out of the summation. Similarly, a label y b  X  Y B \ i only depends on Q ( E ib ), with the summa-tion over the distribution of remaining edge factorizations also equaling 1. We further reduce the above 6 : where in the last step we have excluded the case where E ib 0. We insert our derived  X  variables back into log Q ( y where in the last step the local terms  X  i ( y i ) are conditionally independent of the border labels Y B \ i . The border labels Y
B \ i are also independent by the definition of Q :
At this stage the conditionals for the updates depend on the full set of border instances; however, from the derived edge probabilities we can see that P ( E ib = 1) = 0 when v and v b are not within two hops of each other. Let N 2 O B E
O is reintroduced to provide clarity regarding the condi-tional edge distribution P ( E 0 B | E O ).
For the next several equations we omit the partition func-tion Z Q ( i ) for space, as it does not change or simplify. the border vertices within two hops of v i . The above equa-tion reduces to summations over just the two hop neighbors:
At this point we have a collective inference algorithm where each update to Q ( i ) costs O ( d O ( v i ) 2 ). We will next discuss how to reduce this complexity to O ( d O ( v i )). The above formulation implies a simplification we can make: namely, if v k  X  V B is two hops away from both v i 1 ,v i then it will contribute similar amounts of information to both Q ( y i 1 ) and Q ( y i 2 ). In this subsection we will introduce a method which does not recompute the influence from v k when evaluating Q ( y i 1 ) and Q ( y i 2 ).
 We give a simplified example of our approach in Figure 5. In Figure 5a-b, we wish to use the two hop neighbor proba-bilities to infer the label of the vertices v i 1 and v i tively. The total contributed weighted log probabilities from the two hop neighbors for v i 1 and v i 2 are identical, aside from their contributions to each other X  X  estimate. Thus, when computing Q ( y i 1 ) we can store the logarithmic sum of two hop beliefs, then incorporate the previously computed sum when evaluating Q ( y i 2 ). This will allow us to propa-gate the beliefs without having to recompute the weighted evidence from every two hop neighbor. We define the set of variables  X  j ( y ): where N O B ( v j ) is the border neighbors of v j in the observed graph. For each labeled vertex v j ,  X  j ( y ) is the total condi-tional log probabilities of the border neighbors given a label y  X  Y . For example, consider Figure 5.c.  X  e (1) sums over the positive conditional log probabilities of the neighbor-ing v a ,v b ,v c , while  X  f (1) sums over the positive conditional log probabilities of the neighboring v a ,v c . Corresponding summations  X  e (0) and  X  f (0) are also maintained. After we update a single factor Q ( y i ) we can update the neighbor-ing  X  j in O (1) time by subtracting off the old belief (de-termined by Q old ( y i )) and adding in the new belief (deter-mined by Q ( y i )). We apply the derived edge probabilities from Equation 4 to the conditional log probability expressed in Equation 7: In the last step we have noted that an intermediate node v only connects to its immediate neighbors N O ( v j ) out of all the two hop neighbors of v i , N O B ( v i ). We must only exclude v b = v i , as v i is not dependent on the previous Q ( y Figure 5: PR-EM with respect to (a) vertex v i 1 and (b) vertex v i 2 . (c) A more general case values. The relational components are in the same form as weighted Naive Bayes, meaning we must only require 0  X   X   X  to return valid probabilities for Q ( y i ). As  X   X  increase, more influence from the other border neighbors influences Q ( y and smaller values revert to traditional R-EM.

We now reformulate the above equation in terms of the summations  X  j . Define the previous iteration X  X  Q ( y Q old ( y i ). When summing the  X  j variables into our log prob-ability for v i , we subtract off the weighted contribution from the previous iteration:
As we maintain the  X  j summations, when inferring Q ( y i we do not need to recompute the contributions from all the two hop neighbors. Before inferring Q ( y i ) we subtract off the belief proportional to Q old ( y i ) from each neighboring  X  . After inference for Q ( y i ) we add these values back into the neighbor X  X  summations  X  j . We then perform inference on the next border vertex, until convergence. As we only consider the summations stored at each immediate neigh-bor v j , rather than recomputing the value for each possi-ble v k , the inference runtime of a single border vertex v O ( d O ( v i )). This is the same runtime order as independent inference, meaning our PR-EM process does not impact the total runtime. We lay out our PR-EM procedure in Algorithm 3: this col-lective inference replaces the independent inference over V in the original R-EM algorithm (Algorithm 2, Line 2). Here, we give an example for a binary classification task. Every labeled instance keeps track of the two  X  j sums:
In practice, we extend the algorithm to allow the inclusion of the labeled instances as part of the two hop beliefs: when v  X  V L then Q ( y 0 l ) is either 1 or 0, depending on whether y = y 0 l . By adding the labeled neighbors it can incorporate belief from labeled vertices that lie both one and two hops away multiple times, which places higher weight on neigh-boring vertices with a large number of common neighbors.
Algorithm 3 begins by pushing the conditional beliefs from the labeled instances to their relational neighbors, to use when informing the border instances (Lines 6-10). Each it-eration of the loop calls Algorithm 5, which dynamically handles inserting the weighted conditional log probability Algorithm 3 CollectiveInference( G O , C ,  X   X  ,  X  C ) Algorithm 4 InferenceLoop( G O , C , Q , X  (1) , X  (0) ,  X   X  into the correct summation. The collective inference algo-rithm then proceeds to initialize the Q initial samples from local conditionals defined by the generative model C for each of the border instances (Lines 12-15). Q [ v i ] sums the expec-tations of the border instances, which are then pushed into the summations of the immediate neighbors.

After initialization, repeated calls are made to Algorithm 4 for a specified number of iterations. Algorithm 4 begins by removing any belief in the summation that was contributed by the vertex that is being estimated (Lines 3-4). Line 5 computes a new expected value for the vertex by utilizing the running sum of beliefs over the vertex X  X  neighbors , while lines 6-7 update the neighbor X  X  sums of weighted conditional log probabilities, before the loop repeats for the next vertex. Various variations of the AE task exist, with the domains having varying levels of network availability. Each of the previous algorithms provided for solving the corresponding variation of AE reduce to weighted averages of the neigh-boring (or nearby) labels. In [12, 4], the authors assume a full network is available for inference. Garnett et al. [4] performed a lookahead to determine the expected impact of a selection, but the lookahead could be costly for more than a single step. The authors proposed an improvement by us-ing a  X  X oft X  random walk coupled with an estimated impact factor [12]. This allowed a random walk to flow through the currently labeled instances and outperformed the single step lookahead citations. However, these methods do not incor-porate the observed attributes into their estimation. Fang et al. [3] assume a somewhat more restrictive case of AE. Their selection algorithm has the option to only acquire re-lational structure, resulting in a partial free crawl across the network. The authors also allow for usage of node features to formalize a supervised random walk, weighting the transi-Algorithm 5 UpdateSummation( Q ( a ) , X  j ,  X  , C ,  X   X  ,  X  tion probabilities. While their methods do learn the weights of the random walk given the attributes, they do not di-rectly condition on the attribute values and remain limited to weighted averages of the neighbors X  labels. In [11], we presented our AE formulation. Similar to this work, [11] utilizes weighted two hop averages for prediction; however, that algorithm remained quadratic in runtime, did not in-corporate attributes and did not learn a model. In contrast to each of these methods, we learn the label dependencies on both the attributes and neighbors. Our method allows the classifier to learn the relative importance of the attributes versus relational features.

AE has a similar setup as network active learning and active querying, but has distinct goals. For network active learning, a sampler selects instances which either improve the classifier or reduce variance across the network and are not concerned with maximizing the identification of a par-ticular class label [2, 7]. Active learning and AE also have distinct goals from active querying [10]. In active querying, a sampler selects instances to improve the predictions of a particular set of vertices which it cannot sample directly. In this section, we evaluate AE using our proposed PR-EM model, several baseline learning approaches and the state-of-the-art AE methods discussed in Section 5. We compare AE using our proposed method against five competing methods and a random method: each compet-ing method is used for AE (Algorithm 1) to infer the label probabilities of the border vertices. For each method, we list the subgraph it models ( G L ,G O ,G S ) and whether it performs learning (Line 4, Algorithm 1), inference (Line 5, Algorithm 1) or both.

Naive Bayes (NB): This is the independent Naive Bayes estimator: it only uses the vertex attributes when perform-ing estimation and inference and does not utilize any net-work information. It learns (Line 4) using the labeled ver-tices and their corresponding attributes ( Y L , X L ), and ap-plies the result to predict border labels (Line 5) using only the available border attributes ( X B ).
 Relational Naive Bayes (RNB): This is similar to the NB estimator, but uses the labeled relational neighbors as features during estimation and inference. For learning it utilizes the labeled graph G L (Line 4). During inference the border labels use the labels of their relational neighbors with the G O network (Line 5). weighted vote Relational Neighbor (wvRN): This is the estimator introduced in [9] and used for AE in [11]. It does not learn, rather, it selects items which have the highest percentage of positive observed ( G O ) neighbors (Line 5). where the observed graph is negatively correlated.
 Table 2: Data statistics. From the left: Number of vertices, edges, and attributes, label correlation across edges, positive prior.

Soft Random Walk (SoftRW): This is a recently pro-posed method by Wang et al. for AE [12] which improves on the methods of [4]. It does not perform learning  X  it creates a soft random walk through the labeled instances, making a broader scope of label information available to the unlabeled vertices (Line 5). As a result, this method models G S . This is in contrast to only viewing the immediate neighbors with wvRN. We use the parameters suggested in their work.
Supervised Walk (SupRW): This is a recently pro-posed method by Fang et al. for AE [3]. It weights the probability of a walk passing between instances as a func-tion of features created by the endpoint vertices X  attributes, which are learned (Line 4). The predictions are made from the averages of the random walk (Line 5). As the random walk is grounded, only immediate neighbors are used during inference meaning this method only utilizes G O . We use the edge features and linear weighting suggested by the authors. Probabilistic Relational EM (PR-EM (RNB)): Our EM which utilizes the probabilistic relationships  X  we utilize 5 iterations of EM with 10 iterations of our VMF approx-imation during the E-step. Our conditional form is RNB  X  we initialize the attribute parameters using a single max-imization of RNB, while the relational parameters on the first iteration are uniform. Between inference steps we cali-brate the estimates of the PR-EM probabilities so their mean matches the labeled population mean [1]. During learning, we incorporate an informative Beta prior for each relational parameter: B(0, | Y L |  X  P (1)) for the positive conditional probability and B( | Y L | X  P (0), 0) for the negative. We set  X   X  = 2 2 , and will discuss the impact of this selection. As discussed previously, PR-EM performs both learning and inference (Algorithms 2-5) by modeling G S . We compare each of the above methods on four datasets. The full statistics for the datasets are compiled in Table 2. Facebook: This is a snapshot of the Purdue University Facebook network. We include users who have listed their (a) Political Views, (b) Religious Views and (c) Gender. We use the users X  Political views as the label, and Religious Views and Gender as the two attributes.

IMDB: This is the IMDB dataset (www.imdb.com), where the goal is to predict whether a movie is successful (i.e., high box office return). We use a boolean label to indicate if the reported gross receipts were greater than $50 million. We use 19 boolean feature variables indicating whether the movie belongs to any of 19 possible genres. We break the user rating into 9 boolean variables, each of which indicates whether the average movie rating is greater than the corre-sponding variable index. We construct a network by insert-ing an edge if two movies share two or more producers.
DVD: This is the Amazon copurchase network compiled by [8], but we only select the DVD items. This allows us to incorporate 24 genres of movies as features. We construct boolean features based on the average user X  X  review of a product: star ratings are between 1 and 5. The label we predict is whether the item is a top seller (salesrank &lt; 7500).
Music: This is the Amazon copurchase network compiled by [8], but we only select the Music items. This allows us to incorporate 22 styles of music as features in addition to the user rating features, and keep the same top seller labeling. We conduct 100 trials of each method on each dataset 8 . At the beginning of each trial we give every method the same starting subgraph with 20 vertices. The starting subgraphs are created by (a) sampling a single positive instance and (b) actively exploring with the random method 19 times. We set the budget to 10% of the total network size: each method takes the starting subgraph and selects vertices to label until the budget is exhausted. The Select function (Algorithm 1, Line 7) is to choose the 20 most probable
SupRW is not compared on the larger Music dataset due to the expensive learning time at each iteration. instances. The measure we utilize for evaluation is the recall, or number of positive instances identified as the number of selected vertices grows. For each method on each dataset the average positives found over 100 trials is reported. Figure 6 shows the recall for each method on each of the four networks. The only point where PR-EM is ever outper-formed is at the very beginning of the IMDB curve where RNB achieves slightly higher recall. However, PR-EM re-covers and outperforms all other methods by the time 4% of the graph is labeled. At 10% labeled, PR-EM performance is equivalent, or significantly better, than the second best method on all four datasets. Although SupRW does well on Facebook and RNB does well on IMDB, the PR-EM model is the only method to do consistently well across all the net-works. Moreover, it achieves significant gains over all the competing methods on the DVD and Music networks. PR-EM is thus able to learn the important information and use it for accurate predictions across a variety of scenarios. Next, we examine the types of partially observed networks RNB can effectively learn from in comparison to PR-EM. Figure 7 shows the label correlations in G L as we run the AE algorithm with RNB and PR-EM. Notably, in two datasets (DVD and Music), PR-EM learns in a space where the ob-served G L is negative, but is still able to make accurate predictions (Figure 6). In contrast, RNB cannot learn accu-rate parameters in scenarios where effective AE would gen-erate a G L with negative label correlation. In these cases, RNB samples neighbors of negative items rather than posi-tive items, until the G L label correlation becomes more pos-itive. By inferring the missing edges, PR-EM is able to learn correct parameters from heavily biased sample networks.
Lastly, we investigate the impact of the probabilistic re-lationships on performance in terms of the associated  X  parameterization, which controls the weight of the probabil-ities (Section 5.1). The evaluation is performed in compar-ison with RNB. In particular, in Figure 8 we plot the gain percentage , or additional percentage of positives, compared to RNB as we vary  X   X  with different powers of 2. Larger weightings correspond to more probable relationships. RNB only performs well in the IMDB network, which is the only network where RNB observes positive correlations in G (Figure 7.b): even in this network, PR-EM overtakes RNB. Additionally, on the DVD and Music datasets we see that large  X   X  greatly improves the performance. Future work could include methods for automatically tuning  X   X  to fur-ther increase the gains. For all datasets and all parameter-izations, PR-EM outperforms the baselines and competing models over nearly all sample points. In this work we have studied the task of active exploration. We improved on previous work in this area by developing the first AE method to accurately learn a model of the complex dependencies in a partially observed network. We demon-strated that the network gathered by a targeted AE process can exhibit label correlation bias, which can adversely im-pact learning. To address this issue, we modeled probabilistic relationships among the border vertices and developed an ef-ficient collective inference method to jointly infer the item labels at the same time as the missing edges. This makes it feasible to use our collective inference approach within an iterative AE process. We demonstrated the gains offered by our PR-EM method on four real-world datasets, showing that PR-EM outperforms several baseline learning methods as well as previous state-of-the-art AE methods.
 There are several directions to explore in future work. First, our collective inference method could potentially be applied to other domains with probabilistic edges, or to im-prove general RML in observed networks by incorporating labels across the community. Second, the choice of hyper-parameter  X   X  does not generally impact PR-EM perfor-mance compared to competing methods, but the relative performance of different hyper-parameter settings changes depending on the network. We will investigate this effect to estimate the best parameterization based on an observed graph structure.
 This research is supported by NSF under contract numbers IIS-1017898, IIS-1149789, and IIS-1219015.
