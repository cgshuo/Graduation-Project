 Discourse structure, logical flow of sentences, and context play a large part in ordering medical events based on temporal relations within a clinical nar-rative. However, cross-narrative temporal rela-tion ordering is a challenging task as it is dif-ficult to learn temporal relations among medical events which are not part of the logically coherent discourse of a single narrative. Resolving cross-narrative temporal relationships between medical events is essential to the task of generating an event timeline from across unstructured clinical narratives such as admission notes, radiology re-ports, history and physical reports and discharge summaries. Such a timeline has multiple applica-tions in clinical trial recruitment (Luo et al., 2011), medical document summarization (Bramsen et al., 2006, Reichert et al., 2010) and clinical decision making (Demner-Fushman et al., 2009).

Given multiple temporally ordered medical event sequences generated from each clinical nar-rative in a patient record, how can we combine the events to create a timeline across all the nar-ratives? The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives (Cohen et al., 2013). These cross-narrative coreferences act as important anchors for reasoning with in-formation across narratives. We leverage cross-narrative coreference information along with con-fident cross-narrative temporal relation predictions and learn to align and temporally order medical event sequences across longitudinal clinical nar-ratives. We model the problem as a sequence alignment task and propose solving this using two approaches. First, we use weighted finite state machines to represent medical events sequences, thus enabling composition and search to obtain the most probable combined sequence of medical events. As a contrast, we adapt dynamic program-ming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) used to produce global and local alignments for aligning sequences of med-ical events across narratives. We also compare the proposed methods with an Integer Linear Pro-gramming (ILP) based method for timeline con-struction (Do et al., 2012). The cross-narrative coreference and temporal relation scores used in both these approaches are learned from a corpus of patient narratives from The Ohio State Univer-sity Wexner Medical Center.

The main contribution of this paper is a general framework that allows aligning multiple event se-quences using cascaded weighted finite state trans-ducers (WFSTs) with the help of efficient compo-sition and decoding. Moreover, we demonstrate that this method can be used for more accurate multiple sequence alignment when compared to dynamic programming or other ILP-based meth-ods proposed in literature. In the areas of summarization and text-to-text gen-eration, there has been prior work on several order-ing strategies to order pieces of information ex-tracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of in-formation, as discussed next.

Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a com-mon protagonist by using an unsupervised distri-butional method to learn relations between events sharing coreferring arguments, followed by tem-poral classification to induce partial order. The task was carried out on the Timebank newswire corpus, but was limited to an intra-document set-ting. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on the ACE 2005 corpus. However, this approach is also restricted to events within documents and requires annotations for event intervals. We empirically compare our meth-ods for timeline creation from longitudinal clinical narratives to such an ILP-based approach in Sec-tion 7. While a lot of this work has been done in the news domain, there is also some recent work in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to temporal relations between medical events in clinical text. Clinical narratives are written in a distinct sub-language with domain specific termi-nology and temporal characteristics, making them markedly different from newswire text.

There is limited prior work in learning re-lations across documents. Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event argu-ments across sentences and documents. Barzi-lay and McKeown (2005) propose a text-to-text generation technique for synthesizing common in-formation across documents using sentence fu-sion. This involves multisequence dependency tree alignment to identify phrases conveying sim-ilar information and statistical generation to com-bine common phrases into a sentence. Along with syntactic features, they combine knowledge from resources like WordNet to find similar sentences. In case of clinical narratives and medical event alignment, the objective is to identify a unique se-quence of temporally ordered medical events from across longitudinal clinical data.

To the best of our knowledge, there is no prior work on cross-document alignment of event sequences. Multiple sequence alignment is a problem that arises in a variety of domains in-cluding gene/protein alignments in bioinformat-ics (Notredame, 2002), word alignments in ma-chine translation (Kumar and Byrne, 2003), and sentence alignments for summarization (Lacatusu et al., 2004). Dynamic programming algorithms have been popularly leveraged to produce pair-wise and global genetic alignments, where edit distance based metrics are used to compute the cost of insertions, deletions and substitutions. We use dynamic programming to compute the best alignment, given the temporal and corefer-ence information between medical events across these sequences. More importantly, we propose a cascaded WFST-based framework for cross-document temporal ordering of medical event se-quences. Composition and search operations can be used to build a single transducer that inte-grates these components, directly mapping from input states to desired outputs, and obtain the best alignment (Mohri et al., 2000). In natural lan-guage processing, WFSTs have seen varied appli-cations in machine translation (Kumar and Byrne, 2003), morphology (Sproat, 2006), named en-tity recognition (Krstev et al., 2011) and biolog-ical sequence alignment / generation (Whelan et al., 2010) among others. We demonstrate that the WFST-based approach outperforms popularly used dynamic programming algorithms for multi-ple sequence alignment. Medical events are temporally-associated con-cepts in clinical text that describe a medical con-dition affecting the patient X  X  health, or procedures performed on a patient. We represent medical events by splitting each event into a start and a stop. When there is insufficient information to dis-cern the start or stop of an event, it is represented as a single concept. If only the start is known then the stop is set to +  X  , whereas when only the stop is known , the start is set to the date of birth of the Figure 1: Medical event start / stop representa-tion mapped to Allen X  X  temporal relations (Allen, 1981). Temporal ordering of event starts and stops using { before, after, simultaenous } (shown on the right) allows us learn temporal relations between the medical events (shown on the left). e 1 start = e 2 start and e 1 stop = e 2 stop , when e 1 and e 2 core-fer. patient. 1 Often, for chronic ailments like hyper-tension , we would only associate a start with the medical event and set the stop to +  X  . The start of hypertension may be associated with the temporal expression history of in the narrative. This, when considered along with the admission date, allows us to relatively order hypertension with respect to other medical events. A medical event occurrence like chest pain may be associated with a start and a stop, where the start may be determined by the mention of  X  X atient was complaining of chest pain yesterday  X  in the narrative text. Further, the nar-rative may state that  X  X e continued to have chest pain on admission , but currently he is chest pain free X ; this may be used to infer the relative stop of chest pain . Medical events may also be instan-taneous, for e.g., injected with antibiotic . Such events are represented with the start and stop as being the same. Temporal relations exist between the start and stop of events as shown in Figure 1. Learning temporal relations before, after and si-multaneous between the medical event starts and stops corresponds to learning all of Allen X  X  tem-poral relations (Allen, 1981) between the medical events. Following our previous work (Raghavan et al., 2012c), such a representation allows us to temporally order the event starts and stops within each clinical narrative by learning to rank them in relative order of time. The problem definition is as follows: Figure 2: Given temporally ordered medical event sequences, N 1 ,N 2 ,N 3 , we address the task of combining events across these sequences by merg-ing or ordering them to create a single comprehen-sive timeline.

Input: Sequences of temporally ordered med-ical event starts and stops. This corresponds to N 1 ,N 2 , and N 3 in Figure 2. Each sequence cor-responds to a clinical narrative. The total number of sequences correspond to the number of clinical narratives for a patient.

Problem: Combine medical events across these sequences to generate a timeline i.e., a single com-prehensive sequence of medical events over all clinical narratives of the patient.

Expected Output: In the example shown in Figure 2, the output would be as follows: Timeline ( N 1 , N 2 , N 3 )= { cocaine use start &lt; hypertension start = hypertension start &lt; admis-sion1 &lt; chest pain start  X  palpitations start &lt; chest pain stop &lt; heart attack start = myocardial infarction start &lt; admission2 &lt; infection start &lt; MRSA start &lt; admission3 &lt; wounds start } .
The goal of multiple sequence alignment is to find an alignment that maximizes some overall alignment score. Thus, in order to align event se-quences, we need to compute scores correspond-ing to cross-narrative medical event coreference resolution and cross-narrative temporal relations. The first approach to learning a temporal order-ing of medical events across all clinical narratives is to consider all pairs of events across all narra-tives and learn to classify them as sharing one of Allen X  X  temporal relations (Allen, 1981) using a single learning model. Alternatively, a ranking ap-proach, similar to the one used to generate intra-narrative temporal ordering, can also be extended to the cross-narrative case. However, the features related to narrative structure and relative and im-plicit temporal expressions used for temporal or-dering within a clinical narrative may not be ap-plicable across narratives. For instance, a history and physical report may have sections like  X  X ast medical history X ,  X  X istory of present illness X ,  X  X s-sessment and plan X , and a certain logical pattern to the flow of text within and across these sec-tions. Further, temporal cues like  X  X hereafter X ,  X  X ubsequently X , follow from the context around an event mention. The absence of such features in the cross-narrative case does not allow such a model to generate accurate temporal relation predictions.
Thus, for use in our sequence alignment models, we learn two independent classifiers for medical event coreference and temporal relation learning across narratives. We train a classifier to resolve cross-narrative coreferences by extracting seman-tic and temporal relatedness feature sets for each pair of medical concepts. Extracting these fea-ture sets helps us train a classifier to predict med-ical event coreferences (Raghavan et al., 2012a). Another classifier is then trained to classify pairs of medical event starts and stops across narratives as sharing temporal relations { before, after, over-laps } . The learned cross-narrative coreference predictions can then be used along with confi-dent temporal relation predictions to derive a joint probability to enable cross-narrative temporal or-dering. Sequence alignment algorithms have been de-veloped and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang and Jiang, 1994) and various heuristic algorithms have been proposed to solve this problem (Notredame, 2002). We propose a novel WFST-based repre-sentation that enables accurate decoding for MSA when compared to popularly used dynamic pro-gramming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) or other state of the art methods (Do et al., 2012).

In the problem of aligning events across mul-tiple narrative sequences, we want to align tem-porally ordered medical events corresponding to clinical narratives of a patient. Unlike problems in biological sequence alignment where the sym-Figure 3: Score computation for aligning events across temporally ordered event sequences chest episode stop , where events across the sequences oc-cur simultaneously and corefer. Figure 4: Score computation for aligning events across temporally ordered event sequences chest pain start  X  palpitations stop &lt; chest pain stop &lt; palpitations stop , where some events across the se-quences occur simultaneously but do not corefer. bols to be aligned across sequences are restricted to a fixed set, our symbol set is not fixed or cer-tain because the symbols correspond to medical events in clinical narratives. Moreover, we can-not have fixed scores for symbol transformations since our transformations correspond to corefer-ence and temporal relations between the medical events across sequences. The computation of these scores is described next. 5.1 Scoring Scheme Let us assume a , b are medical events in the first clinical narrative and have been temporally or-dered so a &lt; b . Similarly, x , y are medical events in the second clinical narrative such that x &lt; y . There exists a match or an alignment between a pair of medical events, across the sequences, in the following cases: 1. If the medical events are simultaneous and 2. If the medical events are simultaneous and Figure 5: Score computation for aligning events across temporally ordered event se-quences hypertension start &lt; palpitations start &lt; infection start &lt; MRSA start , where events across the sequences do not occur simultaneously and do not corefer. 3. If the a medical event from one sequence 4. If the a medical event from one sequence is We now illustrate how the scores for candidate aligned sequences are computed using the learned cross-narrative coreference and temporal probabil-ities for the following three scenarios:  X  The medical events across sequences are si- X  Some medical events across sequences are si- X  The medical events across sequences are not Thus, the coreference and temporal relation scores can be leveraged for aligning sequences of medical events. These scores are used in both the WFST-based representation and decoding, as well as for dynamic programming. 5.2 Alignment using a Weighted Finite State A weighted finite-state transducer (WFST) is an automaton in which each transition between states is associated with an input symbol, an output sym-bol, and a weight (Mohri et al., 2005). WFSTs can be used to efficiently represent and combine se-quences of medical events based coreference and temporal relation information. The WFST rep-resentation gives us the ability to talk about the global joint probability derived from coreference and temporal relation scores described in Section 5.1. It allows us to build a weighted lattice of se-quences that can be searched for the most probable sequence of medical events from across all clin-ical narratives of a patient. We use unweighted FSAs to represent the input described in Section 3, i.e. temporally ordered sequences of medical events corresponding to clinical narratives. This corresponds to N 1 and N 2 in Figure 6.

Based on whether we want to align the se-quences purely based on coreference scores or both coreference and temporal relation scores, the is a WFST that maps input symbols from N 1 to output symbols in N 2 and is weighted by the prob-ability of coreference or no-coreference between medical events across N 1 and N 2 . The represen-tation in WFST M c + t us to align N 1 and N 2 based on both coreference as well as temporal relation probabilities. The WFST has transitions to accommodate insertion and deletion of medical events when combining the sequences. Deletions correspond to the case when an event in the first sequence does not map to any event in the second sequence; similarly in-sertions correspond to the case where an event in the second sequence does not map to any event in the first sequence. The WFST composition opera-tion allows the outputs of one WFST to be fed to the inputs of a second WFST or FSA. Thus, we build our final machine by composing the three sub-machines as, where i = c or i = c + t . This gives us a com-bined weighted graph by mapping the output sym-bols of the first medical event sequence to the in-put symbols of the second medical event sequence. The scores on the decoding graph are derived from only the coreference probabilities if i = c and both coreference and temporal relation probabilities if i = c + t .

In the medical event sequence alignment prob-lem, we want to align multiple sequences of medi-cal events that correspond to multiple clinical nar-ratives of a patient. Since we want to now combine N all narrative chains belonging to the same patient, the composition cascade to build the final com-bined sequence will be as, where i = c or i = c + t and n is the number of medical event sequences corresponding to clin-ical narratives for a patient. During composition we retain intermediate paths like M i 23 utilizing the ability to do lazy composition (Mohri and Pereira, 1998) in order to facilitate beam search through the multi-alignment. The best hypothesis corre-sponds to the highest scoring path which can be obtained using shortest path algorithms like Djik-stra X  X  algorithm. The best path corresponds to the best alignment across all medical event sequences based on the joint probability of cross-narrative medical event coreferences and temporal relations across the narrative sequences.

The complexity of decoding increases exponen-tially with the number of narrative sequences in the composition, and exact decoding becomes in-feasible. One solution to this problem is to do the alignment greedily pairwise, starting from the most recent medical event sequences, finding the best path, and iteratively moving on to the next sequence, and proceeding until the oldest medi-cal event sequence. The disadvantage of such a method is that it does not take into account con-straints between medical events across multiple event sequences and may lead to a less accurate solution.

An alternative method is to use lazy compo-sition to perform more efficient composition as it allows practical memory usage. We also use beam search to make for an efficient approxima-tion to the best-path computation (Mohri et al., 2005). This allows accommodating constraints from across multiple sequences and generates a more accurate best path. Thus, this method gener-ates more accurate alignments when we have more than two sequences to be aligned.
For instance, instance say a,b  X  N 1 ,x,y  X  N 2 , and m,n  X  N 3 are temporally medical event se-quences corresponding to narratives N 1 ,N 2 and N 3 . Based on the learned pairwise temporal rela-tions, if we have the following constraints a &lt; x , m &gt; x , m &lt; a . Aligning N 1 and N 2 greedily pairwise may give us the best combined sequence as a,x,b,y  X  N 12 . Now in aligning N 12 with N 3 , we won X  X  be able to accommodate m &gt; x and m &lt; a . However, performing a beam search over the composed WFST in equation 2 allows us to accommodate such constraints across multiple se-quences. The complexity of composing two trans-ducers is O ( V 1 V 2 D 1 ( logD 2 + M 2 )) where each edge from the first sequence matches every edge in the second sequence and V i is the number of states, D i is the maximum out-degree and M i maximum multiplicity for the i th FST (Mohri et al., 2005).
We also use popular dynamic programming al-gorithms (Needleman et al., 1970, Smith and Wa-terman, 1981) for sequence alignment of medi-cal events across narratives and compare it to the WFST-based representation and decoding. 5.3 Pairwise Alignment using Dynamic As a contrast, we adapt two dynamic program-ming algorithms for sequence alignment: global alignment using the Needleman Wunsch algo-rithm (NW) (Needleman et al., 1970) and local alignment using the Smith-Waterman algorithm (SW) (Smith and Waterman, 1981). NW allows us to align all events in one sequence with all events in another sequence. A drawback of NW is that short and highly similar sequences maybe missed because they get overweighted by the rest of the sequence. NW is suitable when the two se-quences are of similar length with significant de-gree of similarity throughout. On the other hand, SW gives the longest sub-sequence pair that yields maximum degree of similarity between the two original sequences. It does not force all events in a sequence to align with another sequence. SW is useful in aligning sequences that differ in length and have short patches of similarity. The time complexity of these methods for sequences of length m and n are O ( mn ) .

The scoring scheme described earlier is used to update the scoring matrix for dynamic program-ming. In order to accommodate the temporal re-lations before and after, we insert a null symbol after every medical event in each sequence in the scoring matrix. A vertical or horizontal gap arises when cases 1, 2, 3 and 4 in Section 5.1 mentioned above are not true. If the medical events are not simultaneous, not before or not after, the medical events will not align. Thus, the value of each cell in the scoring matrix is determined by computing the maximum score at each position C ( i,j ) as, max { ( C ( i  X  1 ,j  X  1)+ S ij ) , ( C ( i,j  X  1)+ w ) , where, S ij = max { P ( i = j ) ,P ( i &lt; j ) ,P ( i &gt; j ) } , and w = max { (1  X  P ( i = j )) , (1  X  P ( i &lt; j )) , (1  X  P ( i &gt; j )) } . Here, C ( i  X  1 ,j  X  1) corresponds to a match, whereas C ( i,j  X  1) and C ( i  X  1 ,j ) correspond to a gaps in sequence one and two.

In case of the SW algorithm, the negative scor-ing matrix cells are set to zero, thus making the positively scoring local alignments visible. Back-tracking starts at the highest scoring matrix cell and proceeds until a cell with score zero is encoun-tered, yielding the highest scoring local alignment.
The time and space complexity grows exponen-tially with the number of sequences to be aligned and finding the global optimum has been shown to be a NP-complete problem. The time complexity of aligning N sequences of length L is O (2 N L N ) (Wang and Jiang, 1994). Thus, for MSA using dynamic programming, we use a heuristic method where we combine pairwise alignments iteratively starting with the latest narrative and progressing towards the oldest narrative. Corpus Description. The corpus consists of a dataset of clinical narratives obtained from the [redacted] medical center. The corpus has a total of 2060 patients, and 100704 clinical narratives. We gathered a gold standard set of seven patients (80 clinical narratives overall) with manual anno-tation of all medical events mentioned in the nar-ratives, coreferences, and medical event sequence information. The annotation agreement across annotators is high, with 89.5% agreement corre-sponding to inter-annotator Cohen X  X  kappa statis-tic of 0.86 (Raghavan et al., 2012b). The types of clinical narratives included 27 discharge sum-maries, 30 history and physical reports, 15 radiol-ogy reports and 8 pathology reports. The distribu-tion of the number of medical event sequences and unique medical events across patients is shown in Table 1. The annotated dataset is used to cross-validate and train our coreference and temporal re-lation learning models and to evaluate our cross-narrative medical event timeline.
Evaluation Metric. For each patient and each method (WFST or dynamic programming), the output timeline to evaluate is the highest scoring candidate hypothesis derived as described above. Accuracy of the timeline is calculated as the num-ber of transformations required to obtain the refer-ence sequence in the annotated gold-standard from the one generated by our system. Transformations are measured in terms of the minimum edit dis-tance, insertions, deletions, and substitutions of medical events.

Experiments and Results. We first temporally order medical events within each clinical narrative by learning to rank them in relative order of oc-curence as described in our previous work (Ragha-van et al., 2012c). The overall accuracy of rank-ing medical events using leave-one-out cross val-idation is 82.1%. The resulting medical event se-quences serve as the input to the problem of cross-narrative sequence alignment.

The cross-narrative coreference and temporal relation pairwise classification models described in Section 4 are trained using a Maximum en-tropy classifier. The coreference resolution per-forms with 71.5% precision and 82.3% recall. The temporal relation classifier performs with 60.2% precision and 76.3% recall. The learned pairwise coreference and temporal relation probabilities are now used to derive the score for the WFST and dy-namic programming approaches.

WFST representation and decoding. We build finite-state machines using the open source weighted using the negative log-likelihood of the computed scores. OpenFST provides tools that can search for the highest scoring sequences ac-cepted by the machine, and can sample from high-scoring sequences probabilistically, by treating the scores of each transition within the machine as a negative log probability. The decoding process to compute the most likely combined medical event sequence can be defined as searching for the best path in the combined graph representation (Equa-tion 2). The best path is the one that minimizes the total weight on a path (since the arcs are neg-ative log probabilities). In searching for the best path, the beam size is set to 5. The accuracy of the WFST-based representation and beam search across all sequences using the coreference and temporal relation scores to obtain the combined aligned sequence is 78.9%.
 Dynamic Programming. We use the NW and SW algorithms described in Section 5.3 to pro-duce local and global alignments respectively. We use the scoring scheme described in Section 5.1 to update the cost matrix for dynamic programming and implement the algorithms as described in Sec-tion 5.3. The overall accuracy of sequence align-ment with both coreference and temporal relation scores using NW is 68.7% whereas SW gives an accuracy of 72.1%. In case of aligning just two sequences, both methods yield the same results. The accuracy of cross-narrative MSA for each pa-tient, for each method, using cross validation, is shown in Table 1. Results indicate that the WFST-based method outperforms the dynamic program-ming approach for multi-sequence alignment (sta-tistical significance p &lt; 0.05). Morever, the re-sults using both coreference and temporal realtion scores for alignment outperform using only coref-erence scores for alignment using all approaches. This indicates that cross-narrative temporal rela-tions are important for accurately aligning medical event sequences across narratives. We propose and evaluate different approaches to multiple sequence alignment of medical events.
Approaches to multi-alignment. We address the problem of aligning medical event sequences using a novel WFST-based framework and empiri-cally demonstrate that it outperforms pairwise pro-gressive alignment using dynamic programming. This is mainly because the WFST-based allows us to consider temporal constraints from across mul-tiple sequences when performing the alignment.
Moreover, it also outperforms the integer lin-ear programming (ILP) method for timeline con-struction proposed in (Do et al., 2012). We im-plemented the proposed method that also allows combining the output of classifiers subject to some constraints. We derive intervals from event starts and stops and learn two perceptron classifiers for classifying the temporal relations between events and assigning events to intervals. The classifier probabilities are then used to solve the optimiza-use intra-document coreference information to re-solve coreference before performing the global op-timization. We observe that in case of MSA, the optimal solution using ILP is still intractable as the number of constraints increases exponentially with the number of sequences. Aligning pair-wise iteratively gives us an overall average accu-racy of 68.2% similar to dynamic programming. While this is comparable to the dynamic pro-gramming performance, the WFST-based method significantly outperforms this in case of multi-alignments for cross-narrative temporal ordering.
Performance and error analysis. We perform multi-alignments over medical event sequences for a patient, where each sequence corresponds to temporally ordered medical events in a clinical narrative generated using the ranking model de-scribed in (Raghavan et al., 2012c). The accuracy of intra-narrative temporal ordering is 82.1%. The errors in performing this intra-narrative ordering may propagate to the cross-narrative model result-ing in reduced accuracy. This may be addressed by considering n-best temporally ordered medi-cal event sequences, generated by the ranking pro-cess, and aligning the n-best sequences using the WFST-based framework. This could be feasible as, practically, the WFST-based method for multi-alignment takes only a few secs to align a pair of medical event sequences with average length 40.
The accuracy of alignments across multiple medical event sequences is also affected by the er-ror induced by the coreference and temporal rela-tion scores. Often, insufficient temporal cues leads to misclassification of events incorrectly as shar-ing the  X  X imultaneous X  temporal relation and often as coreferring. This induces errors in the score cal-culation and hence the alignments. Better meth-ods to address the challenging problem of cross-document temporal relation learning, perhaps with the help of structured data from the patient record, could improve the accuracy of alignments.

There is no clear trend with respect to the num-ber of medical events and narratives for a patient (Table 1.), and the alignment accuracy. In fu-ture work, it would be interesting to examine any such correlation and also study the scalability of the WFST-based method for sequence alignment on longer medical event sequences and a larger dataset of patients. Further, the WFST-based method may be used to model multi-alignment tasks in other speech and language problems as well. We propose a novel framework for aligning med-ical event sequences across clinical narratives based on coreference and temporal relation infor-mation using cascaded WFSTs. FSTs provide a convenient and flexible framework to model se-quences of temporally ordered medical events and compose them into a combined graph represen-tation. Decoding this graph allows us to jointly maximize coreference as well as temporal relation probabilities to derive a timeline of the most likely temporal ordering of medical events. This ap-proach to aligning multiple sequences of medical events significantly outperforms other approaches such as dynamic programming. Moreover, we demonstrate the importance of learning tempo-ral relations for the task timeline generation from across multiple clinical narratives by empirically proving that decoding using both coreference and temporal relation scores is far more accurate than decoding with only coreference scores.
 The project was supported by Award Number Grant R01LM011116 from the National Library of Medicine. The content is solely the responsibil-ity of the authors and does not necessarily repre-sent the official views of the National Library of Medicine or the National Institutes of Health. The authors would like to thank Yanzhang He for his input on the WFST-based model.
