 DAWEI SONG
Knowledge Media Institute, The Open University and JIAN-YUN NIE University of Montreal 1. INTRODUCTION
For any applications related to Natural Language Processing (NLP), reasoning has been recognized as a necessary underlying aspect: when we try to retrieve relevant documents in Information Retrieval (IR), to determine the correct an-swer in a Question-Answering (QA) system, or to determine an appropriate sentence in Machine Translation (MT), etc., some forms of reasoning are often underlying. Many of the existing work in NLP deals with specific NLP problems in a highly heuristic manner, yet not from an explicit reasoning perspective. Re-cently, there have been developments on models that allow reasoning in NLP such as language modeling, logical models, models based on Bayesian networks, and so on.

There have been a number of research projects considering NLP applications as a reasoning process. As logic is a normalization of the way we use information to reason and make decisions, the use of appropriate logic allows reasoning to be explicitly modeled. Following the logical uncertainty principle [van Rijsbergen 1986], a number of logic-based models for IR were proposed in the late 1980s and 1990s to integrate reasoning into IR [Lalmas and Bruza 1998].
 Nevertheless, no operational system has been successfully evaluated against
IR benchmark collections and applied to large scale IR tasks. Therefore, this trend has not been followed up on since then. A functional analysis of logical IR models in Wong et al. [2001] has uncovered two major difficulties encountered by the logic-based IR: (1) the lack of automatic means for constructing the background knowledge; (2) the computational overhead inherent in the symbolic logic when pick-
In regard to the first problem, it was argued that when language process-ing tools have advanced further, the concepts, such as different types of term relationship, under the logic-based models could be applied to IR more easily and more directly so that the problem can be largely alleviated. The second problem has to do with the fact that most logical frameworks exist in the realm of symbolic processing where reasoning is a sequential process proceeding from assumptions to a conclusion by applying symbolic rules of inference. These logi-cal frameworks often suffer from high computational complexity when they are applied to large scale applications. This is partially due to the inherent frame problem of symbolic inference which involves picking up appropriate inference rules to perform reasoning [G  X  ardenfors 2000]. It can be more serious when different types of inference rules are taken into account.

There is also renewed interest in logical IR. Song and Bruza [2003] pro-pose to use an information inference mechanism on high-dimensional semantic spaces to underpin reasoning at the symbolic level for logic-based information retrieval. The work of Lau et al. [2004] is a recent successful attempt in this direction.

The NLP and IR area is currently experiencing a theoretical shift with the strong trend of statistical language modeling approaches. This latter frame-work is capable of integrating statistical reasoning. We believe that many ap-proaches using language modeling can be easily described from a reasoning perspective. Classical LM approaches [Ponte and Croft 1998] usually assume independence between indexing units, which are unigrams or bigrams. In real-ity, a word may be related to other word. Such relationships should be properly integrated into LM. Some recent work [Berger and Lafferty 1999; Lafferty and
Zhai 2001; Lavrenko and Croft 2001; etc.] has shown that a LM framework is capable of integrating statistical reasoning into IR. More recent approaches try to extend existing LM by incorporating term relationships or dependencies, for example, grammatical links in Gao et al. [2004], co-occurrence and WordNet relations in Cao et al. [2005]. Collins-Thompson and Callan [2005] propose a
Random Walk Markov chain model wherein the states are terms and the links are term relationships. Bai et al. [2005] exploit inferential term relationships extracted by using a more sophisticated approach, that is, the information flow [Song and Bruza 2003].
 Cross-language IR (CLIR) is another area in which reasoning is required.
Current CLIR approaches consider translation as a separate step. We believe that translation can be better considered by integrating it into a reasoning process. Indeed, as argued in Nie [2003], CLIR may be considered as a special case of inferential IR, and translation can be considered as a special type of reasoning.

Question Answering is also a typical task that requires reasoning. However, reasoning is merely mentioned as such in the current QA approaches, although many specific approaches can be recast as a reasoning process. A logic-based framework Knowing-aboutness [Clifton and Teahan 2005] was recently built and demonstrates favorable performance in TREC QA X 2004 evaluation.

We believe that the basic techniques necessary for these NLP-related appli-cations are mature enough to think about the problem from a broader point of view. The goal of this special issue is to present high-quality contributions that explicate reasoning involved in different areas of natural language processing both at theoretical and/or practical levels. 2. ARTICLES IN THIS SPECIAL ISSUE
We received a total number of twenty submissions. Each articles was reviewed by at least three referees. Finally five articles were selected for publication. The selected articles cover the topics on logical, statistical, and temporal reasoning for information retrieval, query translation, and topic detection and tracking. Nie, Cao and Bai: Inferential Language Models for Information Retrieval.
This article presents a novel language modeling framework for incorporating tern relationships and, in turn, facilitating logical inference in information re-trieval. In particular, inferential mechanisms are developed to expand docu-ment models and/or query models. Term co-occurrences extracted from rele-vance feedback documents and the WordNet term relationships are integrated into the language modeling framework via semantic smoothing. The depth of inference is also taken into account by employing the Markov chain model. The proposed language modeling framework opens a door to overcome the scalabil-ity problem inherent in traditional symbolic logical models. The framework has been successfully evaluated on large scale English and Chinese collections and demonstrated good performance.
 Gao, Nie and Zhou: Statistical Query Translation Models for Cross-Language
Information Retrieval. This article investigates a number of statistical de-pendency translation models incorporating both statistical co-occurrences and syntactical linguistic structures into cross-language query translation. Special attention is paid to the resolution of query translation ambiguities by tak-ing into account a monolingual language model as well as cross-lingual word similarities. Experimental results have shown that the use of linguistic struc-tures in statistical reasoning is more beneficial than the use of co-occurrences and dictionaries. Better results are generated by combining different types of knowledge.

Liu, Jin and Chai: A Statistical Framework for Query Translation Disam-biguation. This article proposes a statistical framework for dictionary-based
CLIR. Although query translation disambiguation is a long-standing research topic in CLIR, this article formulates the problem within a statistical frame-work so that well-known optimization methods can be applied. It estimates the translation probabilities of query words based on the monolingual word co-occurrence statistics. Two variants, namely, Maximum Coherence Model and
Spectral Query Translation Model, are presented. The article shows that the first method can be considered as a special case of the second one. The experi-ments also demonstrate that the proposed approaches are more effective than some existing ones.

Li, Li and Lu: Topic Tracking with Time Granularity Reasoning. This arti-cle investigates reasoning with the granularity of time in Topic Detection and
Tracking (TDT) in order to deal with implicit temporal relatedness between stories and topics. The article proposes to add temporal expression recognition and time granularity reasoning components to TDT. First, it takes into account not only publishing time but also additional temporal information extracted from the stories, for instance, the actual time when a story occurs. Second, a time granularity model is defined and an algorithm for inferring the strongest co-reference between two time stamps is developed. Experiments on two TDT datasets show that the time granularity reasoning can improve the performance of TDT tasks.
 Phan, Nguyen, Ho and Horiguchi: Improving Discriminative Sequential
Learning by Discovering Important Associations of Statistics. The main con-tribution of this article is a data-driven approach towards mining important association rules with weak statistics hidden in the training data. The authors also show how to incorporate the discovered association rules into the learning model of Conditional Random Fields (CRFs). The proposed approach has proven effective in experiments in comparison with the traditional CRF approach for two different tasks, phrase segmentation and named entity recognition. 3. CONCLUSIONS AND FUTURE WORK
We believe that many problems in NLP can be reconsidered from a reasoning perspective in a way more similar to how human beings make inferences with information. In doing so, novel and more sensible solutions may result. Recent advances in statistical processing of natural language have resulted in a num-ber of promising methods. They allow us to integrate logical and statistical inference in NLP more easily than before as demonstrated by the articles in this special issue.

The articles published in this special issue suggest a number of interesting future research directions. (1) We need more coherent models for seamlessly integrating logical and statistical inference; (2) reasoning with information is user-and context-dependent. Therefore, incorporation of user and context is an important issue in the reasoning mechanisms; (3) we need new evaluation paradigms beyond the traditional precision/recall measurement to access cor-rectly the possible additional benefits (such as explanatory power and com-patibility with human reasoning) brought by modeling the NLP problems as reasoning processes. We hope that the articles included in this issue will trigger more investigations in these problems.

We thank all the authors who submitted papers for their contributions. We are grateful to our dedicated reviewers for their professional reviewing services. The reviewers are Azzah Al-Maskari, Leif Azzopardi, Guihong Cao, Anne De Roeck, George Foster, Jianfeng Gao, Eduard Hoenkamp, Jimmy Huang, Rong Jin, Gareth Jones, Mounia Lalmas, Philippe Langlais, Guy Lapalme, Wai Lam,
Raymond Lau, Wenjie Li, Xue Li, Michel Simard, Cheng Niu, Fran Mark Sanderson, Victoria Uren, Maria Vargas-Vera, and Xin Yan.

