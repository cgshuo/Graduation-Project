 1. Introduction
Mining association rules, which is a fundamental problem in the area of data mining, has been extensively studied in recent years [1,4,9,16,18,20,21,23,29,31 X 33,38,40,46,49] . Traditional association rule mining algo-rithms focus on association rules among itemsets within a transaction. Taking stock market databases as an example, association rule mining can be used to analyze the share price movements. Suppose a database of Microsoft and IBM go up, the price of Apple is likely to go up on the same day.  X  This classical association rule expresses the associations among items within the same transaction, thus we call it intra-transactional association rule. However, the traditional approaches cannot capture a rule like:  X  X  X f the stock prices of
Microsoft and IBM go up, the price of Apple is likely to go up two days later.  X  This rule represents some ciation rule.

A number of methods have been proposed for mining inter-transaction association rules movements. Subsequently, two algorithms, E-Apriori and EH-Apriori, for finding frequent inter-transaction itemsets were proposed in Ref. [26] , where EH-Apriori adopts an additional pruning technique used in Ref. [34] . Feng et al. [10] used several optimization techniques, namely, joining, converging, and speeding, to enhance the EH-Apriori algorithm for mining inter-transactional association rules under rule templates. Then,
Tung et al. [41] proposed the FITI algorithm, which is implemented in two phases. First, the frequent intra-transaction itemsets are discovered. Then, these itemsets are used to form the frequent inter-transaction item-frequent inter-transaction itemsets in a depth-first search manner. It has been shown that the ITP-Miner algo-rithm outperforms the previous inter-transaction mining algorithms.

Besides, Li et al. [24] extended the inter-transaction association rules to a more general form of association rules, called generalized multidimensional inter-transactional association rules, which expand rule contexts from point-wise (e.g. two days latter) to scope-wise (e.g. within three days). For example, such generalized inter-transaction association rules could be:  X  X  X fter McDonald and Burger King open branches, KFC will open a branch within two months and between one and three miles away.  X 
In inter-transaction itemsets mining, there are a large number of frequent itemsets and the mining process could be extremely time-consuming. Thus, we incorporate the concept of closed itemsets into inter-transaction quent itemset X is said to be closed if the database does not contain a superset of X with equal support [15,35,37,39,43,47] , where the support of an itemset is defined as the number of transactions containing the itemset in the database. Generally speaking, mining closed itemsets is more efficient than mining a complete set of frequent itemsets. Therefore, we will mine closed ones in our proposed method.

In the last decade, many algorithms have been proposed for mining closed frequent itemsets [11,15,27,29,35 X 37,39,42,43,47] . These algorithms can be classified into four categories [44] , namely  X  X  X est-and-generate  X  ,  X  X  X ivide-and-conquer  X  ,  X  X  X ybrid  X  , and  X  X  X ybrid without duplication  X  .
The  X  X  X est-and-generate  X  category includes CLOSE [36] , and A-close [35] algorithms, which stress on the optimization of a level-wise process to discover the closed itemsets. The  X  X  X ivide-and-conquer  X  category includes CLOSET [37] , TFP [15] , CLOSET+ [43] , and FP-CLOSE [11] algorithms, which use the highly com-[37] devised an algorithm, called CLOSET, which uses an FP-tree and a partitioning technique to mine fre-quent patterns. Subsequently, Han et al. [15] developed the TFP algorithm, for mining top-k closed frequent patterns without a minimum support constraint. Wang et al. [43] integrated more effective strategies and pro-posed an FP-tree-based method called CLOSET+ that builds conditional projected databases in two ways: bottom-up and top-down. FP-CLOSE [11] is a variant of CLOSET+ for mining closed itemsets.
The  X  X  X ybrid  X  category includes CHARM [47] , and CloseMiner [39] algorithms, which use properties of CHARM, which uses an itemset-tidset tree and four pruning properties to enumerate all closed itemsets.
Based on the CHARM algorithm, Singh et al. [39] proposed an algorithm, called CloseMiner, which trans-forms the problem of discovering closed itemsets into a problem of clustering the itemsets with closed tidsets.
The  X  X  X ybrid without duplication  X  category includes DCI-CLOSED [27] , LCM [42] , and PGMiner [30] algo-rithms, which can avoid the main drawback of the  X  X  X ybrid  X  algorithms. These algorithms do not need to store, in main memory, the closed itemsets previously mined since they do not require performing the sub-sumption checking. The DCI-CLOSED [27] and LCM [42] algorithms traverse the search space in a depth-first search manner. The differences between DCI-CLOSED and LCM are the strategies for finding the closure and the data structures for storing the context extracted. The PGMiner [30] constructs a prefix graph structure and decomposes the database to bit vectors of variable lengths, which are assigned to the nodes of the prefix graph. Then, it uses both inter-node and intra-node pruning strategies to mine closed patterns.
To mine closed inter-transaction itemsets, Huang et al. [17] proposed the ClosedPROWL algorithm, which uses closed intra-transaction itemsets to form closed inter-transaction itemsets. The algorithm is implemented in two phases. First, the CHARM algorithm [47] is used to discover closed intra-transaction itemsets. Then, the itemsets discovered are used to form closed inter-transaction itemsets. However, ClosedPROWL can not efficiently prune non-closed itemsets during the mining process.

To resolve this problem, we propose an approach called ICMiner that efficiently mines closed inter-trans-items. For each frequent item found, we scan the database to find a set of domain attributes (called a dataset) containing the frequent item. Next, the ICMiner constructs an ID-tree to generate the closed inter-transaction patterns in a depth-first search (DFS) manner. By using the ID-tree and datasets, the effective pruning strat-egies can be embedded to avoid costly candidate generation and repeated support counting. Therefore, the ICMiner algorithm can efficiently mine the closed inter-transaction patterns.

The remainder of the paper is organized as follows. We present the problem definition in Section 2 , and describe the proposed algorithm in Section 3 . Then, we analyze the time and space complexities of the ICMin-er and the comparing algorithms in Section 4 , and discuss the performance analysis in Section 5 . Finally, we provide some concluding remarks in Section 6 . 2. Problem definition In this section, we define some terms used later.

Definition 1. Let I ={ i 1 , i 2 , ... , i m } be a set of distinct items, and A ={ a attributes. A transaction database D contains a set of transactions in the form of h dat, T dat 2 A , T dat I , T dat is an itemset, and dat is the domain attribute of T the time stamp associated with T dat . We can also say that the T domain attribute dat, or occurs at dat.

For example, Fig. 1 shows a transaction database D containing six transactions, namely, h 1, T h 3, T 3 i , h 4, T 4 i , h 5, T 5 i , and h 6, T 6 i . T the go-up stocks at the end of each trading day, the first transaction means the stock prices of a , b , and d go up on day 1.
 i
Similarly, with respect to v (or the transaction at v ), a transaction T denoted as T u ( u v ). Therefore, an extended transaction consists of a set of extended items, i.e.,
T ( u v )={ i 1 ( u v ), ... , i s ( u v )}, where s is the number of items in T
For example, in the database shown in Fig. 1 , the extended transaction of the transaction at dat = 3 with respect to the transaction at dat = 1 is { a (2), b (2)}.

Definition 3. Let x i ( d i ) and x j ( d j ) be two extended items. x
Moreover, x i ( d i )= x j ( d j )if d i = d j and x i = x For example, a (0) &lt; b (0), and b (0) &lt; a (1).

Definition 4. An inter-transaction itemset (or a pattern) is defined as a set of extended items, { x ( d 1 ), x 2 ( d 2 ), ... , x k ( d k )}, where d 1 =0, d x ( d i )&lt; x j ( d j ), and 1 6 i &lt; j 6 k .

Definition 5. For a transaction h d 1 , T d 1 i in a transaction database D , a mega-transaction, M set of extended transactions in D with respect to d 1 , i.e., M [ ... [ T dk ( d k d 1 ), where h d 1 , T d 1 i , h d 2 , T i &lt; k , and d k d 1 6 maxspan. Note that M d 1 is also an inter-transaction itemset, where d point.

For example, with maxspan = 1, the database in Fig. 1 contains six mega-transactions: M { a (0), b (0), d (0), b (1)}, M 2 ={ b (0), a (1), b (1)}, M c (1), d (1)}, M 5 ={ a (0), b (0), c (0), d (0), a (1), c (1)}, and M is called an l -pattern.
 For example, { a (0), b (0), a (1), c (1)} is a 4-pattern.

Definition 7. Let X ={ x 1 ( i 1 ), x 2 ( i 2 ), ... , x m
We say that X = Y if x i ( i i )= y i ( j i ) for 1 6 i 6 m , where i x (0) &lt; y 1 (0); or (2) there exists k ( P 1) such that x For example, { a (0), d (1)} = { a (0), d (1)}, and { a (0), b (1), d (1)} &lt; { a (0), d (1)}.
Definition 8. Let X ={ x 1 ( i 1 ), x 2 ( i 2 ), ... , x m other words, X is a subpattern (or subset) of Y , denoted as X Y . Note that if s is equal to 0, we say Y contains X or X is a proper subset of Y , denoted as X p Y .

Definition 9. Given a transaction database D , a user-specified minimum support threshold minsup, and an inter-transaction itemset X , let D x be the set of mega-transactions in D containing X . The support of X , sup( X ), is defined as j D x j . If sup( X ) P minsup, we can say that X is a frequent pattern.
Furthermore, we say that Y subsumes X if Y is a super-pattern of X and both have equal support. For
X 1 Y and X 2 p Y .If X 1 , X 2 , and Y have equal support, Y subsumes both X Let us consider the example shown in Fig. 1 . Assume that maxspan = 1, minsup = 3 and X ={ a (0), c (1)}.
Moreover, the mega-transaction formed by the fifth and sixth transactions, { a (0), b (0), c (0), pattern.

Definition 10. A frequent pattern X is closed if there does not exist an itemset X sup( X 0 ) = sup( X ), i.e., X cannot be subsumed by any other pattern.
 quent, X is not closed since X Y . Similarly, if Y has no super-pattern with equal support, it is a closed pattern.

Definition 11. Given two frequent patterns X and Y , X \ Y = ; , an inter-transaction association rule is an implication of the form X ) Y , whose support and confidence are not less than the user-specified thresholds sup( X [ Y )/sup( X ).

According to previous studies [35,48] , all frequent patterns in a database can be generated from the closed patterns. Once the frequent patterns are identified, the association rules can be derived in a straightforward manner. Therefore, the problem of mining closed inter-transaction itemsets involves finding all closed patterns in a database with respect to the user-specified minsup and maxspan thresholds. 3. Mining closed inter-transaction itemsets
We now introduce our proposed algorithm, ICMiner. We first present the data structure ID-pair, and the how it works by an example in Section 3.5 . 3.1. ID-pair and ID-tree
Since the proposed algorithm uses an itemset-dataset pair (ID-pair) to record information about an inter-transaction itemset in an itemset-dataset tree (ID-tree), we begin by defining ID-pair and ID-tree. pattern and t ( X ) is the dataset in which X occurs among the transactions. Let Y
Y m h t ( Y m ) i be the m children of the X h t ( X ) i in an ID-tree; then we have (1) X (2) if m &gt;1, X = Y 1 \ Y 2 \ ... \ Y m . The root of an ID-tree is a null pattern {}.
Let us consider the database shown in Fig. 1 again, and assume that minsup = 3 and maxspan = 1. As shown transactions with domain attributes 1, 2, 3, 4, and 5. The children of node { b (0)} h 1,2,3,4,5 i are one in the proposed algorithm by using some pruning strategies, which will be discussed in Section 3.3 . 3.2. Join operation and joinable class patterns in a joinable class are joinable, and [{}] contains the ID-pairs of all frequent 1-patterns. { {b (0), a (1)} h 2,3,4,5 i ,{ b (0), b (1)} h 1,2,3,4 i ,{ b (0), c (1)} h 3,4,5 i }}. follows: (1) if x 1 &lt; y 1 , X h Y ={ x 1 (0), y 1 ( d )}, where 0 6 d 6 maxspan; (2) otherwise, X h Y ={ x where 0 &lt; d 6 maxspan. Note that there is not an equal sign in  X  X 0 &lt; d  X  in the latter case. a (1)}.

Definition 14. Let X ={ x 1 ( i 1 ), x 2 ( i 2 ), ... , x where k &gt; 1 and m &gt;1. X join Y is defined as X h Y ={ x
Let X and Y be two frequent patterns, where X  X  X  dataset is t ( X )= h t
Y ={ y 1 (0)}, the newly generated 2-pattern is { x 1 (0), y t ( Y )by d , and obtain a new dataset denoted by t d ( Y ). The dataset of X join Y is t ( X ) \ t
X ={ x 1 ( i 1 ), x 2 ( i 2 ), ... , x k ( i k )} and Y ={ y Y is t ( X ) \ t ( Y ).
 the dataset of { a (0), b (1)}, we can shift all dats in the dataset of { b (0)} by 1 and obtain a dataset t shown by black arrows. 3.3. Pruning strategies
The proposed algorithm applies two major pruning strategies to reduce the search space, namely, the down-the node { d (0)} h 1,5 i .

We observe that when joining two frequent patterns of length greater than one, the operation simply inter-the four properties for closed patterns to prune redundant patterns and reduce the search space. Assume there are two ID-pairs X i h t ( X i ) i and X j h t ( X j ) i in a joinable class [ N ], where X k &gt; 1 and m &gt; 1, respectively. The four properties used to join them are described as follows:
Property 1. If t ( X i )= t ( X j ), then replace X i with X
Property 2. If t ( X i ) t ( X j ), then replace X i with X
Property 3. If t ( X i ) t ( X j ), then add X i [ X j h t ( X
Property 4. If t ( X i ) 6  X  t ( X j ), then add X i [ X j 3.4. The ICMiner algorithm
Our proposed algorithm, ICMiner, consists of two phases. First, we scan the database to find all frequent items. For each frequent 1-pattern found, we convert the original transaction database into a set of domain attributes called a dataset. Then, we enumerate all closed patterns in a depth-first search manner. The ICMiner algorithm is detailed in Fig. 4 , and the DFS procedure is described in Fig. 5 .
 dataset. In step 2, a hash table HT is constructed for pruning unnecessary candidate 2-patterns. Then, all 1-the DFS procedure to generate all closed inter-transaction itemsets.

In Fig. 5 , in each class [ N ], X i h t ( X i ) i is the node to be processed and X both X i h t ( X i ) i and X j h t ( X j ) i are in [ N ]. The join operation for X in the root class and span k = 0, we join it to X j h t ( X class and span k 6  X  0, we join X i h t ( X i ) i to X j h t ( X terns in a joinable class are sorted in ascending order according to their supports. After completing the join removed from the ID-tree when the algorithm leaves the DFS procedure in step 31.

We adopt three techniques to speed up the mining process. First, in step 2 of Fig. 4 , we use a hashing approach [5,47] to check the corresponding bucket in the hash table HT before joining a pair of 1-patterns.
The method is applied as follows. When we scan the transaction database to get all frequent 1-patterns, we construct a hash table HT in which each bucket accumulates the supports of all 2-patterns hashing to it. hv , is equal to (( x i (maxspan+ 1) + k ) j I j + x j ) modhashsize, where 0 6 k 6 maxspan, k is the span of HT [ hv ] is incremented by one. By scanning the database once, the HT can be constructed. Before the join operations in steps 6 and 13 of Fig. 5 , we compute the hash value hv tion and shift operations on the datasets for the infrequent 2-patterns.

Second, in steps 8 and 15 of Fig. 5 , we sort the patterns in ascending order according to their supports. Note that if we join X 1 to X 2 , where j t ( X 1 ) j 6 j t ( X By applying properties 1 and 2, we can prune some existing nodes.

Finally, in step 28 of Fig. 5 , the subsumption checking is performed to prune non-closed inter-transaction patterns. Based on the hashing approach [47] , a closed inter-transaction pattern N SHT, where its hash value is computed by shv  X  N i  X  X  t ( N i ). This hash value is the span sum of all dats in t ( N to those of a frequent pattern Z in SHT, then (1) if N i is a sub-pattern of Z , N not be added to SHT, or (2) if N i is a super-pattern of Z , then Z is not closed. Thus, Z should be removed from SHT and N i should be added to SHT. By doing so, we can avoid comparing N and quickly retrieve related patterns. 3.5. An example
Fig. 6 illustrates how the ICMiner algorithm mines all closed inter-transaction patterns for the database shown in Fig. 1 , where minsup = 3 and maxspan = 1. The symbols used in Fig. 6 are described as follows: (1) a cross symbol indicates that the pattern is not frequent; (2) a horizontal line indicates that the pattern is not closed and should be removed according to the four properties; and (3) a dotted circle indicates that the pattern is not closed by the subsumption checking.

To mine the closed inter-transaction patterns in the database, we first compute the support for each 1-pat-(4 1) + (5 1) + (6 1) = 14, shv ({ b (0)}) = 10, and shv ({ c (0)}) = 3, the SHT [14] , SHT [10] , and SHT [3] are updated.
 Thus, { c (0)} is replaced by { a (0), c (0)} as shown in Fig. 6 and Table 1 .
 [{ a (0), b (0), a (1), c (1)}], we stop branching and return to the class [{ a (0)}].
 Table 1 , both { a (0), b (0), b (1)} and { a (0), b (0)} are closed.
 and Table 1 show all closed inter-transaction patterns. 4. Complexity analysis In this section, we analyze the time and space complexities of the ICMiner, EH-Apriori, FITI, Closed-PROWL, and ITP-Miner algorithms.

First, we analyze the time and space complexities of the ICMiner algorithm. Let X the total number of join operations required for 1-patterns is j L1 j level m and Z is the parent of X i at level ( m 1), k P m P 2, by step 21 of Fig. 5 , we can observe that X for the patterns in [ Z ]is( z 1)+( z 2) + +1= z * ( z 1)/2. Therefore, the total number of join opera-tions required for generating all closed k -patterns is non-leaf nodes in T .

Therefore, by the above analyses, the total number of join operations required by the ICMiner is j L 1 j 2  X  maxspan  X  1  X  X  P nl ber of transactions in the database. Thus, the time complexity of the ICMiner is bounded by O  X  X j L 1 j 2 maxspan  X  (1) for a 1-pattern in T , the maximum number of 1-patterns that must be kept in the memory for join oper-class that must be kept in the memory for join operations is bounded by j L1 j
ICMiner processes branches in a depth-first search manner, the maximum number of nodes kept in the mem-fore, the space complexity of the ICMiner is bounded by O ( dl j HT j and j SHT j are the memory space required by HT and SHT, respectively.

Second, for the EH-Apriori algorithm, since it uses the Apriori property to generate inter-transaction can-didates, the number of candidates generated is bound by O ( j FP number of frequent inter-transaction patterns. For each candidate, the EH-Apriori needs to scan j D j mega-transactions to count its support, where each mega-transaction contains at most (maxspan + 1) transactions.
Thus the time complexity of counting the support for each candidate is bounded by O (maxspan l is the average number of items in a transaction. Therefore, the time complexity of the EH-Apriori is bounded manner, the memory requirement is bounded by the number of candidates. Therefore, the space complexity of the EH-Apriori algorithm is bounded by O ( j FP inter j is the memory space required by the hash table for pruning unnecessary candidate 2-patterns.
Third, for the FITI algorithm, since it first finds the frequent intra-transaction patterns and then uses these patterns to generate inter-transaction candidates, the number of candidates generated is bound by the FITI needs to scan (maxspan + 1) encoded IDs for each domain attribute in the transformed FIT tables to count the support, where the length of encoded IDs of a domain attribute is bounded by O ( j D j ).
Thus, the time complexity of counting the support for each candidate is bounded by O (maxspan
Therefore, the time complexity of the FITI algorithm is bounded by O ( j FP
Since the FITI processes branches in a breadth-first search manner, the memory requirement is bounded by the number of candidates. Therefore, the space complexity of the FITI algorithm is bounded by O ( j FP inter j * j FP intra j + j FILT j + j FIT j + j HT by the FILT and FIT, and j HT FITI j is the memory space required by the hash table for pruning unnecessary candidate 2-patterns.

Fourth, for the ClosedPROWL algorithm, since it first finds the closed intra-transaction patterns and then uses these patterns to generate inter-transaction candidates, the number of candidates generated is bound by generated, the ClosedPROWL needs to scan (maxspan + 1) encoded time lists for each domain attribute in the projected window list (PWL) to count its support, where the length of the time list of a domain attribute is bounded by O ( j D j ). Thus, the time complexity of generating a pattern is bounded by O (maxspan fore, the time complexity of the ClosedPROWL algorithm is bounded by O ( j FP span). Since the ClosedPROWL uses the closed intra-transaction itemsets and the time lists to generate inter-transaction patterns in a depth-first search manner, its space complexity is bounded by O ( j CFP intra j * j D j ).

Finally, for the ITP-Miner algorithm, the complexity analysis in Ref. [22] shows that its time complexity is bounded by O ( j FP inter j * j L1 j * maxspan * j D j ), and its space complexity is bound by O ( mp span * j D j + j HT j ), where mp is the length of the longest frequent pattern.

Table 2 lists the parameters used in the complexity analysis and Table 3 summarizes the time and space complexities of those algorithms. Since the number of joinable operations required to generate a k -pattern
X i is equal to the number of patterns in  X  Z ; is the number of nodes in the ID-tree, and n i is the number of joinable operations required to generate a k -i.e. j [ Z ] j , is bounded by j L1 j * (maxspan + 1), which is the maximum number of join operations for X j [ Z ] j , is bounded by j L1 j * (maxspan + 1), which is the maximum number of join operations for X bounded by j L1 j * maxspan. Generally speaking, j L1 j 6 j CFP
P fastest algorithm among them. For the space complexity, the memory requirement of the ICMiner algorithm is affected by the number of transactions in the database and the hash tables HT and SHT. Generally speak-ing, the ICMiner requires more memory space than the ITP-Miner. 5. Performance evaluation To evaluate the performance of the proposed method, we compare it with the EH-Apriori [26] , FITI [41] ,
ClosedPROWL [17] , and ITP-Miner [22] algorithms. Section 5.1 introduces the experiment setup and syn-datasets in Section 5.4 . 5.1. Experiment setup and dataset description
To compare the proposed method with the EH-Apriori, FITI, ClosedPROWL, and ITP-Miner algorithms, formed on an IBM compatible PC with an Intel Pentium IV CPU 3.4 GHz, 1 GB memory, running on the
Linux distribution Fedora Core 6. All the algorithms were programmed using C++ and compiled by gcc 4.1.1. The memory consumption was measured by using the GNU glibc function mallinfo , which can record the maximum heap memory used. The source code of the ClosedPROWL algorithm was provided by Huang et al. [17] .
 thetic datasets, we use the method in Ref. [5] to generate transactions. The parameters are shown in Table 4 .
This process consists of two steps. We first generate potentially frequent inter-transaction itemsets and then generate transactions in the database from those itemsets. The length of each potentially frequent inter-trans-action itemset is derived from a Poisson distribution with mean = k derived from a Poisson distribution with mean = k t .

Table 5 lists the parameters of two synthetic datasets used in the experiments. The first dataset has more transactions, but fewer items in each transaction. On the other hand, the second dataset has fewer transac-tions, but each transaction contains more items. We analyze the performance of the EH-Apriori, FITI,
ClosedPROWL, ITP-Miner and ICMiner algorithms by varying one parameter of the datasets and keeping the other parameters at the default values shown in Table 5 .
 Moreover, we use four real datasets for performance evaluations. The first two datasets collected from
Yahoo [45] , called WINNER and LOSER, are similar to those used in Ref. [41] . The datasets consist of ten stock exchange indices for 3870 trading days from January 1, 1991 to March 31, 2006. The indices are the ASX All Ordinaries Index (ASX), CAC40 Index (CAC), DAX Index (DAX), Dow Jones Index (DOW), FT-SE 100 Index (FTS), Hang Seng Index (HSI), NASDAQ Index (NDQ), Nikkei 225 Index (NKY), Swiss Market Index (SMI), and Singapore ST Index (STI). The first dataset, WINNER, comprises set, called GAZELLE, is obtained from the KDDCup 2000 competition and corresponds to click-stream data for the Gazelle.com web-site [19] . This dataset, which can be downloaded from http://www.ecn.purdue.edu/
KDDCUP/ , contains 59,601 transactions and 498 distinct items, where the average transaction length is 2.5, and the maximum transaction length is 267. The fourth dataset, called CHESS, is compiled from the game state information [3] , which can be downloaded from http://www.ics.uci.edu/~mlearn/MLRepository.html .
The dataset contains 3196 transactions and 76 distinct items, where the length of every transaction is equal to 37.

Finally, for the  X  X  X orst case  X  datasets, they are extremely sparse ones. The definition of the  X  X  X orst case  X  context is given as follows [13] .
 each item belongs to w distinct transactions. Each transaction, among the first w ones, contains ( w 1) distinct items while the last one contains all items.
 ones. If the number of dimensions of a  X  X  X orst case  X  dataset equal to w , there are 2 itemsets when minsup = 1. Even though the worst case is rarely encountered in practice, the  X  X  X orst case  X  datasets allow us to analyze the behavior of an algorithm on extremely sparse ones. Table 6 summarizes the characteristics of the synthetic, real, and  X  X  X orst case  X  datasets used in our experiments. 5.2. Experimental results of synthetic datasets 5.2.1. Basic experiments Fig. 7 shows the runtime versus the minimum support where the latter varies from 0.03% to 0.09% for
Dataset1, and from 10% to 15% for Dataset2. Note that the minimum support is defined the fraction of mega-transactions containing the pattern in the database in the following experiments. As the minimum sup-port increases, the runtime of the algorithms decreases because of the reduction in the total number of fre-quent itemsets. In Fig. 7 , the ICMiner runs 23 X 1700 times faster than the EH-Apriori, 2 X 132 times faster than the FITI, 2 X 80 times faster than the ClosedPROWL, and 1 X 3 times faster than the ITP-Miner.
The ICMiner algorithm outperforms the EH-Apriori, FITI, ClosedPROWL, and ITP-Miner algorithms by order(s) of magnitude on both datasets. This is because the EH-Apriori generates a large number of can-didates and needs to rescan the database, and the FITI generates a large number of candidates and needs to rescan the FIT tables [41] to count the support for all the candidates. Although the ClosedPROWL avoids generating a large number of candidates by scanning the transactions of the corresponding dataset within the maximum span for each frequent pattern to count the support, it cannot efficiently prune non-closed patterns. However, the ICMiner does not need to rescan the database because it intersects and shifts the datasets for each newly generated pattern to speed up the mining process. Moreover, it can use the pruning strategies to remove many non-closed patterns, so it finds the closed inter-transaction itemsets more effi-ciently. Note that the ICMiner outperforms the ITP-Miner is because when the minimum support decreases, the ratio of the number of closed patterns to the number of frequent patterns (called closed ratio) also decreases.

Fig. 8 shows the memory usage as the minimum support increases from 0.03% to 0.09% for Dataset1, and from 10% to 15% for Dataset2. The ICMiner requires 110 X 160 times less memory than the EH-Apriori, and 40 X 42 times less memory than the FITI in both datasets. However, it requires more memory than the ITP-Miner in both datasets and slightly more memory than the ClosedPROWL in Dataset2.

The EH-Apriori consumes the largest amount of memory because it generates a huge number of candidates as the minimum support decreases. The FITI requires more memory than the ICMiner and ClosedPROWL the minimum support decreases, the memory usage increases rapidly. However, the ClosedPROWL uses a data structure to store the closed intra-transaction itemsets and datasets, and a compressed table to store the transformed database. The ICMiner, on the other hand, uses an ID-tree to store the closed inter-transac-tion itemsets and datasets. The memory usage of the ICMiner and the ClosedPROWL increases slowly as the minimum support decreases. Besides, we have noted that the ICMiner requires more memory than the ITP-
Miner in all the cases. This is because the ICMiner uses a hash table for the subsumption checking that requires extra memory space to store candidate inter-transaction patterns. 5.2.2. Scale-up experiments
First, we investigate the scalability as the number of transactions increases. Fig. 9 shows the runtime versus the number of transactions as the number of transactions increases from 10 K to 2000 K for Dataset1, and from 1 K to 20 K for Dataset2. Basically, the number of frequent patterns generated is not affected by the number of transactions. However, the EH-Apriori takes time to rescan the database, the FITI takes time to rescan the large transformed database, while the ClosedPROWL takes time to scan the transactions of the large dataset within the maximum span for each frequent itemset. Meanwhile, the ICMiner and the
ITP-Miner spend time in processing the large datasets. Thus, as the number of transactions increases, the run-time of each algorithm increases linearly.

Next, we investigate the scalability as the average length of transactions increases. Fig. 10 shows the run-time versus the average length of transactions when the average length of transactions varies from 5 to 20 for
Dataset1, and from 100 to 110 for Dataset2. When the average length of transactions increases, extra frequent itemsets are generated. We observe that the ICMiner algorithm is more efficient than the EH-Apriori, FITI, ClosedPROWL, and ITP-Miner algorithms.

Finally, we examine the effect of increasing the number of items. Fig. 11 illustrates the runtime versus the number of items when the number of items changes from 300 to 2100 for Dataset1, and from 400 to 1000 for
Dataset2. We can see that the runtime of the FITI and the ClosedPROWL drastically increases as far as the number of items decreases. The reason is that both the support of each candidate and the number of frequent patterns increase when the number of items decreases. Besides, we can also see that the gap of runtime between the ICMiner and the ITP-Miner increases as the number of items decreases. This is because the closed ratio decreases when the number of items decreases. 5.2.3. Effect of the maximum span
Next, we examine the effect of the maximum span. Fig. 12 illustrates the runtime versus the maximum span when the latter increases from 0 to 8. Clearly, the number of frequent itemsets grows as the maximum span increases. Fig. 12 shows that the ICMiner algorithm is more efficient than the EH-Apriori, FITI, Closed-
PROWL, and ITP-Miner algorithms. 5.3. Experimental results of real datasets
We now evaluate the performance of the ICMiner, EH-Apriori, FITI, ClosedPROWL, and ITP-Miner algorithms by using four real datasets, WINNER, LOSER, GAZELLE, and CHESS.
 The performance on the real datasets is quite similar to that on the synthetic datasets for those algorithms.
Figs. 13 X 16 illustrate the runtime versus the minimum support for the WINNER, LOSER, GAZELLE, and
CHESS datasets, respectively. For the four datasets, the ICMiner runs 2 X 100 times faster than the EH-Apri-ori, 1 X 200 times faster than the FITI, 1 X 4000 times faster than the ClosedPROWL, and 1 X 2 times faster than the ITP-Miner. Figs. 17 X 20 present the runtime versus maxspan for the four datasets. Similarly, for the three datasets, the ICMiner runs 3 X 80 times faster than the EH-Apriori, 1 X 80 times faster than the FITI, 1 X 6000 times faster than the ClosedPROWL, and 1 X 6 times faster than the ITP-Miner. Thus, the experimental results show that the ICMiner algorithm outperforms the other algorithms in all cases.
The reasons why the ICMiner runs fast in these sparse and dense real datasets can be summarized as fol-lows. First, since the ICMiner employs the ID-tree and ID-pairs to mine frequent patterns, it only requires one database scan and can localize candidate joining, pruning, and support counting to joinable patterns. Second, as the hash table HT is used to check if both 1-patterns are joinable, the ICMiner avoids many unnecessary join operations. Third, since the ICMiner adopts a depth-first search procedure and an ID-tree, it can embed effective pruning strategies to avoid generating unnecessary candidates. Therefore, all these features make the
ICMiner more efficient than the comparing methods.
To test the applicability of the generated inter-transaction association rules, we ran the ICMiner on a data-set comprised of ten stock indices for 254 trading days in 2002. For WINNER, the following sample rule was found:  X  X  X TS(0), DOW(2) ) ASX(3)  X  . In other words, if FTS rises on the first day and DOW rises on the third day, then ASX will rise on the fourth day with support = 14% and confidence = 72%. On the other hand, for LOSER, one sample rule found was:  X  X  X TS(0), NDQ(2) ) ASX(3)  X  . That is, if FTS falls on the first day and DOW falls on the third day, then ASX will fall on the fourth day with support = 20% and confidence = 71%. 5.4. Experimental results of  X  X  X orst case X  X  datasets
Since a  X  X  X orst case  X  dataset is extremely sparse, the closed ratio is pretty high when only intra-transaction patterns are mined. Fig. 21 illustrates the runtime versus w , where maxpan = 0, minsup = 1, closed ratio = 100%, and w varies from 1 to 23. Since maxspan = 0, only the frequent intra-transaction patterns are mined in these experiments. The EH-Apriori, FITI, and ClosedPROWL algorithms exhaust the main forms the ClosedPROWL, FITI, and EH-Apriori algorithms. However, the ICMiner algorithm is slower than the ITP-Miner algorithm because under the closed ratio = 100%, the computations of the four properties for closed patterns and the subsumption checking become unnecessary.

On the other hand, Fig. 22 illustrates the runtime versus w , where maxpan = 1 and minsup = 1, w varies from 1 to 17, and the closed ratio declines from 100% to 0.001%. The EH-Apriori, FITI, and ITP-Miner algo-rithms exhaust the main memory when w &gt; 10, w &gt; 11, and w &gt; 13, respectively. We can observe that the
ICMiner algorithm outperforms the ClosedPROWL, FITI, EH-Apriori and ITP-Miner algorithms. This is because under the low closed ratio, a large number of non-closed patterns can be pruned by the four properties for closed patterns. Moreover, the ICMiner adopts a depth-first search procedure and an ID-tree, it can embed effective pruning strategies to avoid generating unnecessary candidates. Therefore, the ICMiner is more effi-cient than the comparing algorithms.

In summary, the ICMiner algorithm outperforms the EH-Apriori, FITI, ClosedPROWL, and ITP-Miner low. Since the ICMiner and ITP-Miner algorithms mine the closed (frequent) patterns in a depth-first search manner, both algorithms run faster than the EH-Apriori and FITI algorithms that mine the patterns in a breadth-first search manner. Although the ClosedPROWL algorithm mines the closed patterns in a depth-first search manner, it cannot effectively prune non-closed patterns during the mining process. When the closed ratio is high, the algorithms of mining closed patterns could be not more efficient than those of mining fre-quent patterns. For example, under the closed ratio = 100% in the  X  X  X orst case  X  dataset, the computations of the pruning strategies for closed patterns become wasteful.

Since the ICMiner employs the ID-tree and ID-pairs to mine closed patterns, it can localize candidate join-ing, pruning and support counting to a joinable class. Moreover, since it adopts a depth-first search approach to mine closed patterns, we can embed effective pruning strategies to avoid generating a large number of unnecessary candidates. Therefore, it is more efficient than the comparing algorithms in most cases. 6. Conclusions and future work We have proposed an efficient algorithm, called ICMiner, for mining closed inter-transaction itemsets.
By using the ID-tree, we can efficiently mine the closed inter-transaction patterns in a depth-first search manner. Moreover, we can avoid generating many frequent but non-closed patterns by using pruning strategies for closed patterns. Thus, our proposed algorithm can efficiently mine closed inter-transaction patterns. The performance study on the synthetic, real, and  X  X  X orst case  X  datasets shows that the ICMiner algorithm is more efficient than the EH-Apriori, FITI, ClosedPROWL, and ITP-Miner algorithms in most cases.

In the future work, we will address a number of research issues related to the ICMiner algorithm. First, we can extend our algorithms to mine the generalized inter-transaction association rules [24] , which can expand we may develop efficient method to mine other concise representations of frequent patterns, such as non-deriv-dimensional closed inter-transaction itemsets, so we will investigate the problem of n -dimensional closed inter-transaction itemsets. Fourth, since the closed inter-transaction itemsets mining may draw an overwhelm-ing number of rules, we can put the focus on the generic bases of association rules [2] , which consist of non-redundant association rules by using closed frequent itemsets and their generators. Therefore, we may extend the ICMiner algorithm to keep track of the set of closed patterns and their associated minimal generators dur-ing the mining process. Fifth, we will apply our proposed algorithm to other domains, such as marketing data and web access logs, to assess its usability. Finally, without generalization, too many patterns may be mined and they may be too detailed. However, by generalizing with a concept hierarchy, we may be able to obtain patterns or rules that are more abstract and meaningful.
 Acknowledgements
The authors are grateful to the anonymous referees for their helpful comments and suggestions. We would like to thank Kuo-Yu Huang for kindly providing us the source code of the ClosedPROWL algorithm. This research was supported in part by the National Science Council of Republic of China under Grant No. NSC 95-2416-H-002-053.

References
