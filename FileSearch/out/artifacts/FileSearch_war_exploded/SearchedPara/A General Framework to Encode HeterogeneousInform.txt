 Traditional pattern mining methods usually work on single data sources. However, in practice, there are often multiple and heterogeneous information sources. They collectively provide contextual information not available in any single source alone describing the same set of objects, and are use-ful for discovering hidden contextual patterns . One impor-tant challenge is to provide a general methodology to mine contextual patterns easily and efficiently. In this paper, we propose a general framework to encode contextual informa-tion from multiple sources into a coherent representation X  Contextual Information Graph (CIG). The complexity of the encoding scheme is linear in both time and space. More importantly, CIG can be handled by any single-source pat-tern mining algorithms that accept taxonomies without any modification. We demonstrate by three applications of the contextual association rule, sequence and graph mining, that contextual patterns providing rich and insightful knowledge can be easily discovered by the proposed framework. It en-ables Contextual Pattern Mining (CPM) by reusing single-source methods, and is easy to deploy and use in real-world systems.
 H.2.8 [ Database Management ]: Database Applications X  Data Mining Heterogeneous sources, contextual pattern mining
Today X  X  explosion in data does not only grow in the num-ber of examples, but also grow in the number of available  X  Part of this work was done when the author was in IBM T.J.Watson Research Center.
 information sources describing related set of objects. Tradi-tional frequent pattern mining methods for association rules [1, 8], sequences [2, 19], and graphs [20, 11] usually work on single information sources. The target objects of inter-est are simply a set of transactions, sequences composed of time-stamped elements, or labeled graphs. However, in re-ality, there are usually multiple heterogeneous information sources describing the contexts or related attributes of the target objects. These sources provide important contextual information not available from any single source alone, but can be useful to understand the data and discover interesting knowledge [13]. For example, in a crime scene analysis case, on Mondays, vehicle thefts happened more frequently in ar-eas with high population density. Interestingly, the same type of crimes on Saturdays happened more frequently in low population density areas. Here the contextual informa-tion, i.e., the population density, from census data feeds but not available in the crime database, played an important role to extract useful crime patterns. Another example is that, in the epidemic spread characterization scenario, the location contexts such as the relative position to a river supplying drinking water, can be extracted from the map data source. Sequential patterns indicating that most people with diar-rhea symptoms had visited downstream areas before getting sick can be discovered. A probable water-borne transmission and the source of contamination can therefore be inferred. Such insightful patterns cannot be found only by analyzing people X  X  symptoms without utilizing the location contextual information of their movements. Most traditional data min-ing methods do not consider the contextual information from the heterogeneous sources, but focus on finding patterns ex-plicitly appearing in a single source. Therefore, they are not directly applicable to these problems.

However, simply joining multiple data sources into a single dataset does not work either; it is well known that join-ing multiple sources not only results in an unnecessarily huge dataset but also leads to the loss of information at the same time (the semantics represented by the linkages between information sources) [5, 7]. Multi-relational data mining (MRDM) [4, 5] can be applied to mine multiple sources. However, in a real-world system, such as a modern enterprise X  X  data analytics platform or a commercial busi-ness intelligence product, it is usually expensive to deploy a new set of algorithms, as it often involves intensive test-ing and requires a lot of engineering effort. Yet, another practitioners X  concern recently raised from real-world appli-cations of mining multiple sources is the  X  X ase of use X  [14]. In this paper, we answer the question that: given a set of traditional single-source pattern mining algorithms, how to non-intrusively and maximally reuse them for discovering insightful patterns across multiple heterogeneous sources? In real-world applications, one of the most common ways in which multiple information sources relate to each other is the star schema, which consists of a target dataset and a number of heterogeneous contextual information sources. The target dataset is a main information source of objects that are of primary interest, where the primary key identi-fies the target objects (a target object can be a transaction, a sequence, or a graph in the dataset), and several foreign keys identify the identities inside a target object (an iden-tity can be an item inside a transaction or sequence, or a label of graph vertex or edge). The contextual information sources provide auxiliary information about all or a subset of objects in the target dataset, where the primary key is linked to a foreign key (possibly via predicates, Section 2.3) in the target dataset. These information sources contain the features (either constant or dynamic over time) of the iden-tities inside the target objects, which provides rich context for mining insightful patterns of target objects. Figure 1 is an example of star schema of a target dataset and four con-textual information sources. We define patterns discovered from such multiple sources as contextual patterns :
Definition 1 (Contextual Pattern). A pattern of the target objects, which contains the information explicitly appearing in the target dataset and the information implicitly represented across the contextual information sources.
Apparently, contextual patterns can only be mined by collectively considering the target dataset and the contex-tual information sources. Figure 2 illustrates the flow of the proposed Contextual Pattern Mining (CPM) concept. As shown, the idea of CPM is quite different from the tradi-tional MRDM approaches, although sharing the same objec-tive. By solving the problem from a new perspective, CPM outperforms the traditional MRDM approaches, in terms of non-intrusiveness, ease of use, and efficiency. More details can be found in Section 6. The main challenge of CPM is how to effectively encode multiple sources of contextual in-formation before running a traditional single-source pattern mining method, so that contextual patterns can be easily discovered. In this paper, we propose the Contextual In-formation Graph (CIG) encoding framework to solve this problem. An example of CIG in the crime analysis scenario is given in Figure 3. It encodes the population densities (POPDEN) as well as the ratios of male to female (RMF) of census tracts where the crime had happened. With CIG, a
Figure 3: Contextual Information Graph (CIG) single-source pattern mining algorithm accepting taxonomy as an additional input can be applied to the target crime his-tory dataset. We also show that simply joining contextual information to the target dataset does not work, and can result in a large number of redundant patterns (Section 5). The advantages of the proposed CIG encoding framework include: (1) Generality. CIG supports mining all the three types of popular frequent patterns: itemset/association rule, sequence, and graph. (2) Efficiency and scalability. With the HashSet and HashMap data structure, both the time and space complexities of CIG encoding are linear. The Knowledge-to-Identity path query on CIG in pattern mining stage (Section 2.2) is constant in time. (3) Robustness. CIG is capable of handling missing values, dynamically changing values, and multiple values on contextual features. (4) No information loss. CIG encoding is a one-to-one mapping of the contextual information sources.
In most cases, frequent pattern mining deals with discrete features [7]. In this paper, we assume all the contextual in-formation (including time information) is in discrete feature values, or has been discretized according to some criterions. To effectively conduct Contextual Pattern Mining (CPM), we encode all available contextual information by a CIG, which is a labeled DAG (Directed Acyclic Graph) with la-bels associated only with its vertices. Let  X  denote the set of contextual information,  X  denote the set of identities, and  X  denote the set of linkages between  X  and  X  .
 Definition 2 (Contextual Information Graph). A Contextual Information Graph (CIG) is a labeled bipartite directed graph  X  = (  X , X , X  ) , s.t. (1)  X   X , X   X   X   X   X , X  (  X  )  X  =  X  (  X  ) if  X   X  =  X  , and (2)  X  edge (  X , X  )  X   X , X   X   X , X   X   X  , where  X  is the label function of the vertices in  X  .

An example is given in Figure 3. Available contextual in-formation collected from census data feeds consists of two features (POPDEN and RMF) for each identity (census tract). Here  X  is the set of all possible combinations of a feature and its value (vertices in the upper half of the CIG), where one vertex stands for a combination.  X  is the set of all identities (vertices in the lower half of the CIG), where one vertex stands for an identity. The meaning of a vertex is shown by its label displayed aside. The directed edges from a vertex in  X  to a vertex in  X  denote the linkages between the identities and the feature values, which constitute set  X  . As can be seen, the first condition in Definition 2 means that in a CIG  X  = (  X , X , X  ), the label of a vertex is unique that only one vertex in  X  stands for a specific feature value and only one vertex in  X  stands for a specific identity. The second condition means that the linkages exist only between the identities and the feature values, and are represented by directed edges from a feature value to an identity.
Algorithm 1 summarizes the CIG encoding procedure. For some applications, contextual information is not fixed, and Algorithm 1 CIG Encoding
Figure 4: CIG of Fixed Contextual Information can be changing over time. For example, temperature of an outdoor location varies over time, and traffic flow of a road may change between working hours and midnight. There-fore, on line 3, if the features of an identity change over time, a vertex indicating the state at a specific discrete time frame will be created. In reality, multiple values for one feature can exist. In this case, the algorithm reads every possible combination of the feature and its values, and cre-ates separate vertices. Figure 4 is an example of encoding fixed contextual information from one source into a CIG. ID indicates the identities. F1 and F2 are two multi-valued features. The labels of vertices are shown inside. Figure 5 encodes dynamic contextual information from one source. The only difference in the CIG is that an identity state ver-tex is defined by its ID together with a time stamp. When encoding multiple sources, the resulting CIG is the union of several small CIGs, each is constructed from one source. As shown in Figure 2, we propose to perform Contextual Pattern Mining in two steps: (1) construct a CIG from the contextual information sources, and (2) apply a single-source pattern mining algorithm to discover contextual patterns. The single-source pattern mining algorithm can be imple-mented based on an existing Generalized Pattern Mining (GPM) algorithm [16, 6, 17, 9, 3] with only minor modifi-cation or even no change at all. GPM algorithms accept a taxonomy of the identities besides reading a target dataset as primary input, and can mine generalized patterns across dif-ferent levels of the taxonomy. A taxonomy describes the con-cept hierarchies (ontologies) of identities, typically appear-ing as a tree with great depth or forest structures. In most cases, a taxonomy is defined by human knowledge and con-structed manually. Figure 6 is an example of a taxonomy of items. In a taxonomy, all the leaf nodes are specific identities appearing in target objects. The non-leaf nodes are virtual concepts defined by human knowledge. A directed edge from a higher level concept to a lower level concept, or from a con-cept to an identity indicates the conceptual generalization, i.e., reversely is-a semantics. For instance, in Figure 6, con-cept Outerwear generalizes identities Jacket and Ski Pants , thus Jacket is-a Outerwear , and Ski Pants is-a Outerwear . With this taxonomy, generalized association rule mining [16, 6] can discover rules like  X  Outerwear  X  Hiking Boots  X  from a Figure 5: CIG of Dynamic Contextual Information
Figure 6: Taxonomy of Items (adopted from [16]) dataset of item purchase transactions, meaning that the cus-tomers bought Outerwear also bought Hiking Boots . How-ever, specialized rules only at identity (item) level, such as  X  Jacket  X  Hiking Boots  X  and  X  Ski Pants  X  Hiking Boots  X , may not be frequent or confident. Generalized sequential pattern mining [17] and generalized graph mining [9, 3] work in similar ways.

CIG is different from taxonomy in the following aspects: (1) A CIG can be automatically constructed with Algo-rithm 1, whereas defining a taxonomy heavily requires in-volving human knowledge in most cases. (2) In a CIG  X  = (  X , X , X  ), there is no edge connecting two vertices in  X  , i.e., no linkage exists between the vertices representing con-textual information. However, in a taxonomy, such linkages define relationships between two concepts. (3) In a typi-cal taxonomy of a tree (or forest) structure, vertices repre-senting identities have in-degree = 1. Whereas in a CIG  X  = (  X , X , X  ), vertices in  X  representing identities have 1  X  in-degree  X   X   X   X  . (4) We can regard both contextual infor-mation and concepts as knowledge. It can be proven that if a path exists in a CIG that starts from a vertex represent-ing knowledge and ends at a vertex representing an identity, it always contains only one edge. But in a taxonomy, such paths can contain multiple edges. Generally, we call such a path the Knowledge-to-Identity (KI) path.
 Definition 3 (Knowledge-to-Identity (KI) Path).
 Given a CIG  X  = (  X , X , X  ) , a KI path exists from knowl-edge (  X  =  X  ) to identity  X  iff.  X  (  X , X  )  X   X  , s.t.  X  (  X  ) = (  X  =  X  ) , X  (  X  ) =  X , X   X   X , X   X   X  . We denote it by (  X  =  X  )
In existing GPM algorithms, the KI path is usually re-ferred as the antecedent-descendant relationship on a taxon-omy. In most cases, the KI path query is the only necessary interface that a GPM algorithm interacts with a taxonomy [16, 6, 17, 9, 3]. To be specific, a GPM algorithm only needs to know the followings to mine generalized patterns, all of which are essentially KI path queries: (1) Given an identity, identify all the antecedents, i.e., concepts generalizing the identity. (2) Given a concept, identify all the descendants, i.e., lower level concepts and identities specializing the con-cept. (3) Given a concept and an identity, check if there exits a path connecting them. We can see that as long as these KI path queries can be done on CIG, a GPM algorithm can accept a CIG by blindly treating it as a taxonomy, and the output will be contextual patterns.

This is a favorable characteristic: We can conduct CPM by non-intrusively leveraging traditional GPM algorithms, with an appropriate way of encoding new information that GPM algorithms cannot directly handle. And indeed, per-forming the KI path queries on CIG is straightforward (Sec-tion 2.4). We can find that CPM can be done with a rela-tively small cost. With the CIG encoding, existing single-source GPM algorithms can be reused to the maximum level. One thing should be noticed is that, if the GPM algorithm applied only accepts tree (or forest) structured taxonomies, it may need minor changes so that a general DAG structured CIG can be processed. In this case, the time complexity bounds of a GPM algorithm [16, 6, 17, 9, 3] does not change if replacing a taxonomy input by a CIG. This is because in a general sense, KI path query on either a taxonomy or a CIG shares the same time complexity if the taxonomy and the CIG are isomorphic. Besides, since CIG is a bipartite graph, KI path queries on it can be highly efficient (Section 2.4). It is also feasible to combine a taxonomy to a CIG, so that the algorithm can discover contextual patterns and tradi-tional generalized patterns simultaneously. However in this case, KI path queries are essentially done on a DAG not necessarily being bipartite. Such KI path queries become the general graph reachability queries. Labeling and index-ing methods [18] can be employed to accelerate the queries. Specific CPM algorithms for mining contextual association rules, sequences, and graphs will be presented in Section 4.
In some cases, contextual information may not be directly linked to identities, but via predicates . Take the crime scene analysis as example. To study the factors contributing to crime, contextual information such as location features, need to be considered. The location of a crime is usually repre-sented by GPS coordinate in IT systems of police depart-ments. However, environmental contexts, such as popula-tion densities of the communities and types of the buildings nearby, do not directly relate to the GPS location. In this case, a predicate defining a relationship between two iden-tities is needed to correlate available information. Specifi-cally, in the crime example, spatial predicates (e.g., within , close to ) [10] can define spatial relationships between a GPS location identity and the contextual identities (community, building, etc.). The computation of predicates is usually done externally (e.g., by a computation engine or a lookup table), but a predicate itself can still be directly represented in the target dataset. Table 1 illustrates an example of a tar-get dataset relating to contextual identities via predicates. Consider each target object has a feature F1. The values of F1 include predicates  X  1 (  X  ) and  X  2 (  X  ). Using the crime exam-ple, F1 could denote the spatial features derived from GPS coordinates, and  X  1 and  X  2 may stand for within and close to relationships, respectively. ID1 and ID2 that relate to tar-get objects via  X  1 and  X  2 could stand for a community and a building, respectively. CPM treats an instantiated predicate (in the above example,  X  1 (ID1) or  X  2 (ID2)) as a whole to be one item. It works by simply defining the following.
Definition 4. Given a CIG  X  and a predicate  X  (  X  ) ,  X  (  X  =  X  )  X   X  (  X  ) on  X  iff. (  X  =  X  )  X   X  on  X  .
 For example, given the CIG in Figure 4 and the dataset in Table 1, we have  X  1 (F1=a)  X   X  1 (ID1),  X  1 (F2=x)  X   X  1  X  (F1=b)  X   X  2 (ID2), and  X  2 (F2=x)  X   X  2 (ID2). By doing so, CPM can deal with predicates as well as ordinary identities.
In our implementation, a HashSet is used to store the vertices  X   X   X  given a CIG  X  = (  X , X , X  ). One HashMap is used to store the directed edges  X  , where each key is a vertex  X   X   X  , and its mapped value is a HashSet of all Table 1: Dataset Relating Contexts via Predicates its descendant vertices on  X  , defined by {  X   X   X   X   X , (  X , X  )  X   X  } . Another HashMap representing the reverse edges is also maintained, where each key is a vertex  X   X   X  , and its mapped value is a HashSet of all its antecedents, defined by {  X   X   X   X   X , (  X , X  )  X   X  } . These two HashMaps are built simultaneously on line 9 in Algorithm 1.

Time Complexities: On HashSet/HashMap, it is known that any insertion or search operation is  X  (1) asymptot-ically, assuming there is no collision. In practice, this is usually true, especially when sufficiently large capacity of the HashSet/HashMap is available as compared to the to-tal number of elements (keys) to be stored. In this case, in Algorithm 1, line 4 (vertex insertion), line 6 (vertex search) and line 9 (edge insertion) are all constant in time. The time complexity of Algorithm 1 is thus  X  ( P  X   X   X   X  P  X   X   X  (  X   X   X  ), linear to the amount of information encoded 1 worst case of HashSet/HashMap operations is  X  (  X  ) only if, in the extreme case, that all hashes collide for the total  X  elements in the HashSet/HashMap. Figure 7 demonstrates a simple example of Hash collision. Therefore, in most cases, the time complexity of CIG encoding is linear. Only once scanning of all the contextual information is sufficient to construct CIG. Because CIG is always a bipartite graph, KI path query is equivalent to edge search. Given a constructed CIG, assuming no collision, searching all descendants or an-tecedents of a vertex and searching an edge defined by two specified vertices in the HashMaps, are all constant in time. respectively, where  X  is the max degree of vertices in  X  . In a word, any KI path query on CIG is constant in time in most cases, where there is no hash collision.

Space Complexities: A HashSet/HashMap typically has space complexity of  X  (  X  ), where  X  is the number of elements stored. In our case, the HashSet for vertices has  X  (  X   X   X   X   X  ) =  X  (  X   X   X  +  X   X   X  ) space complexity. We can also in-fer that the two HashMaps have  X  (  X   X   X  +  X   X   X  ) and  X  (  X   X   X  +  X   X   X  ) space complexities, respectively. Therefore, the overall space complexity of a CIG is  X  (  X   X   X  +  X   X   X  +  X   X   X  ).
In this section, we experimentally validate the linear time and space complexities of CIG encoding and the constant time complexity of KI path query. All the experiments are done on a machine with Intel Core2 2.66GHz CPU and 2GB memory, using Java programming with the initial capacity of 16 and the load factor of 0.75 for HashSet/HashMap. The results are shown in Table 2 and Figure 8, which are obtained on the contextual information used in Section 4. Figure 7: HashSet of Capacity 8. Keys { 8 , 56 , 11 , 73 } stored with hash function  X  mod 8 . 56 and 11 collide.
Table 2: Results of Time and Space Complexities Figure 8: Linear Complexities of CIG Encoding The contextual data is represented by the integer type to eliminate the effects of varying hash code calculation time and storage size caused by data types like string. We can find that the CPU time of CIG encoding is linear to  X   X   X  , and the storage (space) of CIG is linear to (  X   X   X  +  X   X   X  +  X   X   X  ). Two linear equations fitting the samples are also shown in Figure 8. Both have the R square highly close to 1, indicat-ing the linearities. To verify the constant time complexity of KI path queries, in each test, we randomly generate KI path queries 10 4 times and report the total CPU time. It is shown from Table 2 that the KI path query is efficient and only costs nearly constant time in the order of 20ms across all tests, in spite of the data change. In summary, all the results are consistent with the analyses in Section 2.4.
Applications of specific contextual pattern mining algo-rithms to three case studies are given in this section.
Data Overview: The first case study is on the real crime history of the City of Spokane, WA, USA. Contextual as-sociation rule mining is conducted to find crime patterns. Totally 816 crime incidents of 3 general types, Drugs (167 incidents), Vehicle Theft (552 incidents), and Robbery (97 incidents), reported in the northeast city (covering 10 census tracts) during Jan 2009 to Mar 2010, constitute the target dataset. The day of week on which the incident happened and its general type are included in pattern mining as nor-mal attributes. The geometries of the census tracts and 23 major streets in the area are also used to derive spatial fea-tures for each incident, including within a tract and close to a street (distance &lt; 500 feet). A sample of the target dataset in transaction format is given in Table 3 (tid indicates id of transaction/incident). Figure 9 is a map overview of the data. The US Census Bureau data is involved as a contex-tual information source. Population density (per sq mi) and ratio of male to female are considered as contexts. Because these two features, according to the domain knowledge, can influence the distribution of crime occurrences. The tracts X  features are summarized in Table 4. A CIG that encodes the POPDEN and RMF is constructed for CPM. A portion of the CIG is shown in Figure 3. A simple taxonomy of  X  X very street is-a Road  X  is also combined as part of the CIG.
Contextual Association Rule Mining: The contex-tual association rule mining is summarized in Algorithm 2. As in the generalized association rule mining [16], first the transactions are expanded with the contextual information related to items using KI path queries on the CIG, where an item can be a predicate or an identity. Duplicate features ex-panded, if any, are removed. For example, after expansion, Table 3 will become Table 5. Then frequent itemsets are enu-merated and pruned as in typical generalized association rule mining. Any itemsets containing an item  X  the other are pruned to prevent generating itemsets like { within(Tract26), within(POPDEN=Low) } and { close to(Trent Av), close to(Road) } . Such itemsets indicate the correlation between an item and its context, which can be frequent but provide redundant knowledge already represented in the CIG. It can be proven that only pruning 2-itemsets is sufficient (Lemmas 1 and 2 in [16]) to eliminate such redundant patterns.
 Algorithm 2 Contextual Association Rule Mining Results: We use min sup = 2% and min conf = 80%. No pattern about Robbery can be found, which indicates the randomness of these crimes. If only the crime target dataset is regarded as input without other information, only 12 rules including the following two can be found (support and confidence are shown in brackets,  X  indicates  X  X ND X ):
If the taxonomy of streets is further involved, 20 rules (including the above 12) can be found, corresponding to the output of typical generalized association rule mining. Below list two new rules. Both can be verified in Figure 9.
If the CIG encoding POPDEN and RMF features is fur-ther involved for CPM, 212 rules (including the above 20) can be found, including the followings. Table 5: Samples of Expanded Crime Target Dataset
These results show that, on Saturdays, Vehicle Theft crimes are more probable to occur in tracts with POPDEN=Low and RMF=High. However, on Mondays, tracts with POP-DEN=VeryHigh have more chance to report such type of crimes. For Drugs crimes, RMF=High or Low can increase the probability of reporting the incidents near a road. Mean-while, no pattern of Drugs and RMF=Avg can be discov-ered. The detected rules reveal the hidden patterns of the crimes and provide extra insights. Data Overview: The dataset is from the IEEE VAST Challenge 2011 Mini-Challenge 1. It contains 1,023,077 mi-croblogs collected during Apr 30 X  X ay 20, 2011 (21 days), each has GPS coordinates, date, and author id. With text analysis, each microblog is tagged with 34 candidate epi-demic keywords as its features, include: fever, diarrhea, cough, ache, etc. Among all, two keywords, fever and di-arrhea, are used to derive two sequence datasets. The fever dataset consists of all microblogs from authors who sent at least one message tagged by fever . The diarrhea dataset consists of all microblogs from authors who sent at least one message tagged by diarrhea . There are 40,472 microblogs sent by 2,786 authors in the fever dataset, and 16,353 mi-croblogs sent by 1,196 authors in the diarrhea dataset. For each author, a sequence of microblogs s/he sent is constructed. Each microblog is an element (itemset) of a sequence. The statistics of lengths and number of distinct dates of sequences in the two datasets are summarized in Table 6. It can be seen that in both datasets, on average, an author sent at least one microblog every two days. We can say that the sequences reflect the general movements of the people. Studying these sequences can help conduct some reasonable characteriza-tion on the spreads of fever and diarrhea.

Figure 11 shows the city map, which serves as the con-textual information source for this case study. There are 13 districts, 6 water bodies (a river and 5 lakes) and 13 hospi-tals in the city. The river flowing from north to southwest, is known as part of the drinking water supply system. Using the map, the spatial features within (  X  ) and close to (  X  ) (dis-tance &lt; 1km) are derived for microblogs. A sample sequence in the fever dataset is shown in Tables 7. Sequences in the diarrhea dataset are similar and omitted. Importantly, Table 6: Statistics of Sequences in The Two Datasets features of the districts including their relative orientations to the river (up/mid/downstream) and to the entire region (north/south/east/west/center) (Table 8), are involved as contextual information and encoded by a CIG (Figure 10). A taxonomy indicating that  X  X very hospital is-a Hospital  X  is also combined as part of the CIG.

Contextual Sequential Pattern Mining: The con-textual sequential pattern mining is summarized in Algo-rithm 3. With the same CIG, we apply Algorithm 3 once to the fever dataset and once to the diarrhea dataset, to find unique patterns for each. Similar to the contextual associ-ation rule mining, first the sequences are expanded via KI path queries on the CIG. Redundant patterns here refer to those sequences with an element (itemset) containing both an item and its contexts. Such an element rephrases the link-age information already represented the CIG, but provides nothing useful for new pattern discovery. Patterns with such elements are pruned during mining the sequences. Three additional time constraints are implemented: window-size, min-gap, and max-gap [16]. Explicitly, we set windows-size = 0 day, enforcing that all the items in an element must oc-cur within the same day, but not necessarily from the same microblog. Min-gap and max-gap determine the minimum and the maximum time difference between two consecutive elements, respectively. We set min-gap = 0 day. Consider-ing the frequency of people sending microblogs and the intu-ition that short term activities affect people X  X  health more, we set max-gap = 2 days. It indicates that an element can occur at most 2 days before the next element. The dates of microblogs are also regarded as items in pattern mining. Algorithm 3 Contextual Sequential Pattern Mining Results on Fever Dataset: We use min sup = 40%. Since we are interested in knowing where the people visited before they mentioned fever, sequences ending with fever are selected and analyzed. Without the contextual information, traditional sequence mining only finds four patterns as below (support shown in brackets):
Patterns (1) and (2) are sequences of only one element (a 2-itemset). Patterns (1) X (3) indicate that people mentioned fever mostly on May 18 and 19. These imply the fever out-break may start from May 18. Pattern (4) implies that the
Figure 10: CIG Encoding Contexts from Table 8 ground zero location for fever could be Downtown because people mentioned fever just after they visited Downtown in the last two days. However, as shown below, this is far from the whole picture. CPM with the contextual information of districts X  features finds four additional patterns ( X  X O= X  omitted in within (  X  )):
These imply that not just the people who visited Down-town, but more precisely, the ones who visited the central and midstream areas would mention fever. CPM also finds patterns that start with fever and end with close to(Hospital) :
It is revealed that, after the people got fever (especially in the city center), they went to hospitals on May 20. These additional insights can be vital for government and medical agency. They could collect relevant information from the hospitals to understand the medical nature of the epidemic, and take actions to control the disease spread.

Results on Diarrhea Dataset: We use a larger min sup = 80%, as it is observed that people X  X  movements in this dataset are not as random as in the fever dataset. Similarly, sequences ending with diarrhea are analyzed. Traditional sequence mining without the contextual information cannot find any pattern. In contrast, CPM finds the followings (only closed patterns [19] are shown here to save space):
These imply that people mentioned diarrhea mostly after visiting the southwest and downstream areas on May 19. If instead using min sup = 40% as on the fever dataset, a pattern indicating the diarrhea outbreak started and lasted after May 18, i.e., on May 19 X 20, can also be found:
However, still no pattern like  X  X iarrhea  X  close to(Hospital) X  is detected, suggesting the patients with diarrhea did not go to hospitals for treatment although they felt sick. Figure 11: Ground Truth of Epidemic Spreads
Ground Truth: The ground truth provided by the Chal-lenge committees is summarized in Figure 11. The ground zero location is a bridge over the river at the joint of mid-stream and downstream. On May 17, a truck carrying food contaminated by harmful spores had an accident there. The spores were dispersed into the air and the river, spread through wind and water current, and led to the outbreaks of inhalation and gastrointestinal diseases. Fever and diarrhea are two major symptoms, respectively. Due to the different incubation periods, the inhalation disease first outbreak on May 18 in Downtown, Uptown, and part of Plainville (re-vealed by patterns (5) X (8)). The disease also dispersed to the wide east on May 19 X 20 by west wind, but with much lower density. The gastrointestinal disease then outbreak on May 19 in downstream/southwest areas (revealed by pat-terns (12) X (15)). Unlike the diarrhea microblogs, the fever microblogs were collected in almost everywhere of the city, which makes the movement pattern noisy. Many people with the inhalation disease went to different hospitals on May 20 (revealed by patterns (9) X (11)). But people with the gas-trointestinal disease never did, which is also verified by our results. In conclusion, CPM draws a complete and accurate picture of the epidemic outbreaks, and provides useful clues to infer the correct ground zero location. Data Overview: The dataset comes from the IEEE Info-Vis 2007 Contest. It contains 20,204 US movies (2000 X 2006). For each movie, at least one director, one cinematographer and the first ten billed actors and actresses (at most 20 act-ing persons) are given with names. Movies are classified into 20 genres. Multiple genres are allowed. On average, one movie has 1.75 genres. IMDB and Netflix ratings, in-cluding the average rating score and the number of votes are also available. The movie collaboration graph is defined as such: a vertex represents a person, and an edge between two persons indicates they collaborate in at least one movie. We create two collaboration graph series: (1) by movie re-lease year, and (2) by movie genre. Frequent subgraphs are mined on the two series, respectively. As graph mining can-not be done on the entire collaboration graph with up to 50,000 vertices and a million edges, we truncate the graphs by only considering the most popular (POP) and the best rated (BEST) movies, and also the persons that perform at least a certain number of movies. For example, in the Ac-tion movies, only the top 10 movies in the number of user ratings ranking (POP) and the top 10 movies in the aver-age rating score ranking (BEST) are selected, respectively. The resulting four series of collaboration graphs are listed in Tables 9 X 10. Sample graph data is shown in Figure 12. Contextual information is defined over vertices (persons) by their acting preferences. For each person, all genres of the Figure 12: POP Drama Movies &amp; CPM Result movies s/he has performed are collected. The top genres determined by either a large count or a large relative ratio are chosen as the person X  X  acting genres. A CIG encoding the genre features of persons is shown in Figure 13.
Contextual Graph Mining: First we define the contex-tual subgraph isomorphism by conceptually extending the generalized subgraph isomorphism [9, 3]. We denote the vertex set of a graph  X  by  X  (  X  ), and the edge set by  X  (  X  ). A graph  X  is a contextual subgraph of another graph  X   X  if there exits a contextual subgraph isomorphism from  X  to  X  Definition 5 (Contextual Subgraph Isomorphism).
 Given a CIG  X  , a contextual subgraph isomorphism is an in- X   X  (  X  (  X  ) , X  (  X  )) on  X  , where  X  and  X   X  are the label functions of  X  and  X   X  , respectively.
 The contextual graph mining is shown in Algorithm 4. Similar to the contextual association rule and sequence min-ing, here the over-generalized graph patterns [9, 3] need to be pruned: If a graph pattern  X  X  X  is a contextual subgraph of a graph pattern  X  X  X   X  (  X  X  X   X  =  X  X  X   X  ) and their supports are identical, then  X  X  X  is an over-generalized pattern.
 Algorithm 4 Contextual Graph Mining
Results: We apply a traditional graph mining algorithm, gSpan [20], a generalized graph mining algorithm, Taxo-gram [3], and CPM (Algorithm 4) to the movie graphs using min sup = 100%: gSpan runs without any additional infor-mation, thus only finds subgraphs consisting of specific per-sons; Taxogram runs with a taxonomy that, for each person, Table 10: Movie Collaboration Graphs by Genre Figure 13: CIG Encoding Persons X  Genre Contexts a concept defined by his/her primary genre (with the largest relative ratio) is associated; CPM runs with the CIG in Fig-ure 13. Results are summarized in Table 11. On the four graph series, gSpan only finds two subgraphs in total, sug-gesting that there is few consistent collaboration patterns at specific person level. By generalizing persons with the pri-mary genre, Taxogram finds more patterns. With more con-textual information available, CPM achieves the best results in name of the patterns discovered. It finds patterns more than 10 times of Taxogram in almost all graph series includ-ing several interesting ones: First, POP movies tends to have more common collaboration patterns than BEST movies in either the temporal investigation or the horizontal by-genre comparison. This suggests that there exists some common actor  X  X lavor ingredient X  to attract audience through adver-tising, across the years and the genres. In contrast, there are fewer common patterns for BEST movies. Every top-ranked movie may has its own reason for success. We fur-ther checked the discovered patterns among POP movies of different genres. In the 66 subgraphs with the largest size of 6, most are with the mixed person genre of Drama, Com-edy and Thriller (Figure 12). This suggests that to produce a popular movie, there should at least have movie stars in these three genres to play to the gallery.
One may ask why simply joining the contextual informa-tion to the target dataset and then running a traditional single-source pattern mining algorithm does not work for CPM. The reason is two-fold: (1) The join can generate replicated contextual features for one target object, which makes the joined dataset contain redundancy and can result in meaningless patterns. For example, in Section 4.1, di-rectly joining the Road information to the third row (tid=266) of Table 3 can generate two close to(Road) predicates. If this occurs frequently in the crime target dataset, itemsets like { close to(Road), close to(Road) } can become frequent. But such patterns are meaningless. (2) The join will cause information loss that, the linkages between identities and the contextual information are removed. Again, take the case study in Section 4.1 as an example. Even if with removing the data redundancy caused by the join and Table 5 is ob-tained, itemsets like { within(Tract26), within(POPDEN=Low) } and { close to(Trent Av), close to(Road) } can be generated and frequent. However, such patterns reveals nothing new Table 11: Collaboration Graph Mining Results but the known correlation between an item and its related feature, which is already represented in the CIG. It is a common issue among association rule, sequence, and graph mining. It is known that, if a small pattern, e.g., a mean-ingless 2-itemset in the above two cases, is frequent, it is bound to enlarge the search space by growing to larger pat-terns [16, 17, 9, 3], which inevitably leads to the generation of a huge number of redundant or over-generalized patterns. A feasible way to handle this is to post-process all the pat-terns after they are generated, by filtering the result with additional information. However, one may need to enumer-ate nearly all possible patterns due to its NP-completeness, which makes it intractable, especially when min sup is small. Previous study [16] has shown that, not generating useless patterns in the earliest stage can make the algorithm 100 times faster than post-processing. On the other hand, the proposed CPM approach can avoid all these issues.

Table 12 shows the comparisons between CPM and run-ning traditional pattern mining on the datasets simply joined with the contextual information (denoted by  X  X imple Join X ). We can see that, with same parameters,  X  X imple Join X  al-ways costs more CPU time and finds a lot more patterns. However, none of the extra patterns is useful or provides new insight. The larger the dataset is and the smaller min sup is, the more obvious that CPM is advantageous. In the case study of Section 4.3, graph mining without pruning over-generalized patterns yields little difference and thus is not shown here. Because the CIG is bipartite, a large number of over-generalized patterns can exist only when there are many specified patterns. However, from Table 11 we can see that, with min sup = 100%, only 2 specified subgraph patterns, both of which contain 2 vertices, can be found (the first row, gSpan result). The largest possible number of over-generalized patterns of the two 2-vertex subgraphs is: (the number of contexts of one vertex)  X  (the number of contexts of the other)  X  1. In this specific case study, this number is small. Therefore, no significant difference can be observed between CPM and  X  X imple Join X  here. However, we should keep in mind that, generally, pruning over-generalized con-textual graph patterns is needed, especially when the num-ber of specialized patterns is large.
 There are two ways of handling missing values in CPM. Suppose feature  X  to be encoded has missing value. One way is to insert a vertex with label (  X  =  X  X  X  X  X  X  ) to the CIG and CPM works. This may make (  X  =  X  X  X  X  X  X  ) appear in the final patterns, which makes sense and is needed in some cases. The other way is to ignore all missing values when constructing the CIG, then they will not be considered in pattern mining. It is possible that the identities are not the same among different contextual information sources, which is not a problem for CIG encoding. As can be seen in Al-gorithm 1, CIG encoding can also be done incrementally. Whenever new contextual information sources are available, given a previously constructed CIG, new information can be encoded without re-encoding the previous information sources. The effects of different discretization methods to CIG encoding include the followings. Given a fixed size of identities  X   X   X  , a fine granularity of feature discretization can increase  X   X   X  and  X   X   X  of a CIG  X  = (  X , X , X  ), which can en-large the search space for pattern mining because the num-ber of frequent combinations can increase, and vice versa. Nonetheless, the linear time and space complexities of CIG encoding do not change at all.
Previous studies on frequent pattern mining mainly fo-cus on mining from a single source. The most typical pat-tern mining methods include itemset/association rule min-ing [1, 8], sequential pattern mining [2, 19], and graph min-ing [20, 11]. In this paper, we propose the CPM approach that appropriately utilizes available contextual information from multiple sources for pattern discovery. The goals of CPM and multi-relational data mining (MRDM) approaches proposed to discover patterns involving multiple tables (re-lations) [4, 5] are similar, but they have different focuses: (1) CPM addresses to involve contextual information by non-intrusively utilizing existing single-source pattern min-ing methods, i.e., with a two-step  X  X IG encoding + pattern mining X . The CIG encoding works with different types of pattern mining methods (itemset/associaiton rule, sequence, and graph), and can be seen as a unified pre-processing step, given that the contextual information sources link to the target dataset in a star schema. Because the encod-ing is efficient, with an efficient single-source pattern mining method implementation, the two-step strategy of CPM can be efficient and implemented with limited effort. This is especially meaningful for systems that already have a suite of single-source pattern mining algorithms seeking a quick and cheap enabling technique to collectively mine new in-formation sources. On the other hand, implementing and deploying new algorithms is usually far more expensive in real-world systems. (2) Typical MRDM approaches solves the similar problem but in an intrusive way. To be spe-cific, implementing MRDM approaches usually cannot reuse existing single-source pattern mining algorithms, especially when joining multiple tables is not considered a good solu-tion. MRDM approaches based on inductive logic program-ming (ILP) [12, 4] can be applied to a general class of data mining problems and do not restrict to star schema of tables. Nonetheless, due to the generality, ILP based approaches can often be far less efficient in specific tasks compared with CPM. For example, WARMR [4] can be seen as a generalized algorithm for mining itemsets and sequences. Previous work [5] has pointed out that due to its general-purpose nature, WARMR does not fully exploit the properties of the specific patterns compared with traditional itemset and sequence mining algorithms [1, 2] and their GPM versions [16, 17]. On the other hand, CPM based on the proposed CIG en-coding framework works directly with the GPM algorithms designed for specific tasks, including association rule mining (Section 4.1), sequence mining (Section 4.2), and graph min-ing (Section 4.3). Therefore, we can infer that in most cases, the proposed CPM approach can have better efficiency than ILP based approaches when solving a same problem.

A different MRDM approach recently proposed is RMiner [15]. It is designed to mine the MCCS (Maximal Connected Complete Subgraph) pattern in the  X  -partite graph repre-sentation of a MRD (multi-relational database). First, mul-tiple (say,  X  ) tables in a MRD is converted into a  X  -partite graph. Then RMiner runs on the graph to find patterns in the form of MCCS. The differences between the proposed CPM approach and RMiner include: (1) CPM searches pat-terns of classical forms (itemset/association rule, sequence, and subgraph) in a space defined by the CIG and the tar-get dataset (of transactions, sequences and graphs). RMiner searches MCCS patterns which is far different from classi-cal forms, and on the  X  -partite graph defining its search space. (2) The proposed CIG encoding only encodes con-textual information into a graph, which is always bipartite. The target dataset of transactions, sequences, or graphs is not changed a bit. In contrast, RMiner runs on the  X  -partite graph which actually encodes the entire MRD of all the  X  tables. Although both CPM and RMiner work with graph representations of information, they are significantly different. More fundamentally, RMiner has a different ob-jective with traditional MRDM approaches that it finds in-teresting (defined by the maximum entropy model) pattern of co-occurring attributes [15], whereas CPM finds similar patterns to traditional MRDM approaches.

To obtain contextual patterns, other alternatives may also exist to the proposed CPM approach. However, they require either significant intrusive modifications to the pattern min-ing algorithms or the development of new algorithms, so that the contextual information can be handled appropri-ately. The CPM approach proposed in this paper, i.e.,  X  X IG encoding + pattern mining X , is the shortest path and the cheapest way so far we can find. As long as the applied GPM algorithms accept a general DAG structured CIG, no modification is required and CPM can be done transparently to the end users. This makes the system much easier to use, and little engineering effort is required.
With a growing number of information sources describing properties of related objects in today X  X  big data challenge, we propose a general framework to encode contextual informa-tion from multiple sources via the Contextual Information Graph (CIG) for Contextual Pattern Mining (CPM). The main objective is the capability to reuse the existing single-source pattern methods without any modification and with high efficiency and ease. The proposed approach discov-ers more predictive, insightful, and interesting patterns that traditional pattern mining algorithms cannot find. The CIG encoding does not introduce any additional computational cost to the pattern mining process, except the pre-processing of the contextual data, which has linear time and space com-plexities. Missing values, multiple values, and dynamically changing contextual information can also be handled. We demonstrate through case studies that, the mining of all the three major types of contextual patterns, i.e., association rule, sequence, and graph, are well supported by our frame-work. Experiments and case studies on real-world datasets demonstrate that contextual patterns containing richer in-formation and more useful insights are discovered by CPM, which is both efficient and easy to use; on the other hand, traditional methods cannot discover most of these interest-ing patterns. [1] R. Agrawal and R. Srikant. Fast algorithms for mining [2] R. Agrawal and R. Srikant. Mining sequential [3] A. Cakmak and G. Ozsoyoglu.
 [4] L. Dehaspe and H. Toivonen. Discovery of frequent [5] S. D X zeroski. Multi-relational data mining: an [6] J. Han and Y. Fu. Discovery of multiple-level [7] J. Han, M. Kamber, and J. Pei. Data mining: concepts [8] J. Han, J. Pei, and Y. Yin. Mining frequent patterns [9] A. Inokuchi. Mining generalized substructures from a [10] K. Koperski and J. Han. Discovery of spatial [11] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graphs [12] S. Muggleton. Inductive logic programming. New [13] K. Olsen and A. Malizia. Automated personal [14] D. Page and M. Craven. Biological applications of [15] E. Spyropoulou and T. De Bie. Interesting [16] R. Srikant and R. Agrawal. Mining generalized [17] R. Srikant and R. Agrawal. Mining sequential [18] H. Wang, H. He, J. Yang, P. Yu, and J. Yu. Dual [19] J. Wang, J. Han, and C. Li. Frequent closed sequence [20] X. Yan and J. Han. gSpan: Graph-based substructure
