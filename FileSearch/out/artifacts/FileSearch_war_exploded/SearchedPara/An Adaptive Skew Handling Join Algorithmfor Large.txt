 With the wave of big data coming, join plays an essential role in large-scale data analysis. Unfortunately, traditional RDBMS are no longer practical for such large-scale data. Parallel framework MapReduce[ 1 ] has been proven as a powerful approach for large-scale data analysis.
 However, data skew happens naturally in many applications. The well-known 2/8 law[ 2 ] demonstrates this phenomenon. Data skew will cause load imbalance and hot nodes which may overshadow the strengths of parallel infrastructure. Several improvements have been proposed[ 3  X  5 ] to handle skewness, however, there is still some room for improvement. For example, [ 3 ] can X  X  execute the query adaptively. [ 4 , 5 ] fail in balancing the workload very well when data skew is severe. What X  X  more, existing skew join algorithms haven X  X  considered reducing communication cost by filtering records not in the join result.
 To overcome above problems, we propose a mixed data structure comprising Bloom Filter and Histogram(BFH). Based on BFH, Bloom Filter and Histogram Join(BFHJ) is proposed to handle data skew adaptively. BFHJ can detect and filter unnecessary records. Furthermore, BFHJ adopts a heuristic partitioning strategies to balance the workload. Experiments on TPC-H demonstrate that BFHJ outperforms the state-of-the-art methods. In the following sections, BFHJ will be presented and evaluated. The intuition of Bloom Filter and Histogram Join(BFHJ) is to handle data skew adaptively and reduce communication cost. This section describes the architec-ture of this adaptive skew handling join algorithm using MapReduce framework. 2.1 The BFH Data Structure BFH is a statistical data structure encompassing Bloom filter[ 6 ] and equi-width histogram. BFH is built on the join attribute. It combines the space efficiency of Bloom filter and the statistical property of histogram, which will help us estimate the distribution of join attribute before query processing. There are two key components in BFH: (i) a single-hash-function Bloom filter of size m(bits); (ii) a hash table of counters for each non-zero bit of the Bloom filter, which is considered as an equi-width histogram. Each bin in the histogram is treated as a join part in our algorithm. 2.2 Filter and Partitioning Strategy Assume that the BFH of relation L and R have been created called bfh . A new operation called bitwise multiply is defined for bfh get the distribution of join attribute in the result. In the bitwise multiply oper-ation, the bitmaps are conducted a bitwise-and operation. The corresponding bins between two histograms are conducted a multiply operation.
 The new bitmap is considered as a filter. If the value equals 0 in the filter, this indicates the corresponding record is not in the result. Although few records will not be detected, it is a trade-off between space and accuracy. In the new histogram after the bitwise multiply operation, the value of each bin represents the count of a join part in the join result, which can also be considered as the workload of this join part.
 task is to to assign each join part to each reducer, minimize the max workload, make the workload among reducers more balanced. Unfortunately, solving the optimal assignment strategy is NP hard. So, an adaptive heuristics partitioning strategies BFH-S(Sequence) is proposed which is shown in Algorithm 1 . Algorithm 1. BFH-S Partitioning Strategy reducer, and assign it to the reducer which has the smallest total workload. We repeat these steps until all parts have been assigned. All our experiments are run on a 20-nodes cluster of Hadoop, which is an open-source implementation of MapReduce. We compare the performance of Reduce-Side join(RSJ),Pig X  X  skew join(PSJ), Hive X  X  skew join(HSJ) and our BFHJ. is executed: select * from Customer C, Supplier S where C.Nationkey = S.Nationkey. To control skewness, we randomly choose a portion of data and change Nationkey to some values. To evaluate the BFH filter, 15% records which are not in the join result are randomly selected by changing Nationkey. 3.1 Experimental Results The BFH size is set to 10000 which is a trade-off between space and capacity. Then BFH uses less than 100kb space. Tab. 1 shows the creation cost of BFH on different data scale. From Tab. 1 , the creation time accounts for less than 5% of the whole query time of BFHJ when skewness is 0.1. It is acceptable because BFH could be reused.
 algorithms. The data scale is 50G and the skewness is set to 0.1 on both relations. BFHJ are less than other algorithms since the BFH filter some unnecessary records. If BFH size is fixed, the amount of filtering records decreases with the cardinal increasing. It is because more bits are set to 1 which is a false positive. When the cardinal is 12000, all the bits are set to 1, so the filter ratio is 0. In Fig. 1(b) , the query time is decreasing with the cardinal increasing because total join results decrease. Significantly, no matter what the cardinal is, BFHJ is better than other algorithms in terms of query time. To evaluate the load balance, we figure out the using time of each reducer when cardinal is 4000. In Fig. 1(c) , RSJ will cause some hot reducers because of the skew. PSJ X  X  range partition can X  X  handle the skew on both relation. HSJ improves the performance, but the using time are still unbalanced. The results show that BFHJ can achieve the most balanced workload. To handle data skew adaptively, this paper proposes the mixed data structure BFH. Based on BFH, Bloom Filter and Histogram Join(BFHJ) is proposed. BFHJ reduce communication cost by detecting and filtering unnecessary records. BFHJ balance workload by adopting a heuristic partitioning strategies. Experi-ments demonstrate that BFHJ outperforms the state-of-the-art methods.
