 Although content-based image retrieval has been extensively studied [Smeulders et al. 2000; Lew et al. 2006], searching image and photo by textual queries remains one of the most common and imperative functions for most intelligent multimedia systems. For many real-world multimedia systems, raw images and photos are often not associated with text labels or human tags. Automated image annotation thus becomes an impor-tant technique to make massive collections of unlabeled images and photos searchable by existing text indexing and retrieval solutions.

In general, an image annotation task is to assign a set of text labels or semantic tags to a novel image based on its visual (and textual if any) content. A typical image annotation approach usually requires two key steps. One is to extract visual features to represent the images [Lowe 2004], and the other is to build accurate classifica-tion models from the training images and employ them to predict tags/lables for the query/test images [Carneiro et al. 2006]. Over the past decade, significant efforts have been expended for automated image annotation and object recognition tasks in several areas, including multimedia, computer vision, image processing, and machine learning [Jeon et al. 2003; Smeulders et al. 2000; Lew et al. 2006].

Despite encouraging progresses, most image annotation methods work well on small-sized dataset with high quality training data, but often fail when it comes to large-scale real-world applications for photo tagging due to the well-known semantic gap between low-level image features and high-level semantic concepts. Besides the challenge aris-ing from the semantic gap, it is also expensive and time-consuming to collect a large set of manually labeled training data for the conventional methods. Therefore, it is urgent to develop new effective paradigms for automated photo tagging beyond the traditional approaches.

Recently, due to the popularity of social networks and social web, massive tagged images have been available on the web, which are referred to as  X  social images/photos  X . Unlike typical WWW images [Hoi and Lyu 2004], social images often contain manually-labeled tags and rich user-generated contents, which offer a new opportunity to resolve some long-standing challenges in multimedia, for example, the semantic gap. In this article, we investigate an emerging retrieval-based annotation paradigm for automated photo tagging by mining massive social images freely available on the web. The basic idea is to first retrieve a set of most similar images for a test photo from the social image repository, and then assign the test photo with the most popular tags associated with the set of similar social images [Wang et al. 2006].

The crux of a retrieval-based annotation paradigm is to accurately find the set of similar images. It mainly relies on two key components: (1) image representation by extracting salient visual features from images, and (2) distance measure for computing the dissimilarity between the two images based on the extracted features. In this article, we focus on the second challenge by learning an optimal metric for distance measure, known as  X  X istance Metric Learning X  (DML) [Xing et al. 2002].

Existing DML methods work only with explicit side information, which is given either in the forms of class labels [Weinberger et al. 2006; Goldberger et al. 2005] or pairwise constraints [Xing et al. 2002; Bar-Hillel et al. 2005; Hoi et al. 2006b]. Besides, existing DML methods also assume that the given side information is clean and perfect. Such assumptions seldom hold in a real application. For example, in our application, the tags and contents generated by users for images are often erroneous, and more importantly cannot be used directly as the explicit side information. This motivates us to study a new approach of distance metric learning from uncertain/implicit side information.
To this end, in this paper, we present a novel Probabilistic Distance Metric Learn-ing (PDML) framework [Wu et al. 2009], which aims to learn distance metrics from noisy and uncertain side information for automated photo tagging tasks. The proposed framework consists of two steps: (1) an unsupervised learning approach for discovering probabilistic side information from hidden erroneous and implicit side information con-tained in rich user-generated content of social image data; and (2) a PDML approach for learning an optimal distance metric from probabilistic side information.
In summary, the key contributions of this article include: (1) a retrieval-based anno-tation scheme powered by a novel DML technique for automated photo tagging; (2) a novel probabilistic DML framework to learn metrics from erroneous and implicit side information; (3) two effective PDML algorithms, pRCA and pDCA, to learn optimal metrics from probabilistic side information; (4) extensive experiments to verify the ef-ficacy of our algorithms in comparison to a number of state-of-the-art DML algorithms for automated photo annotation tasks.

The rest of this article is organized as follows. Section 2 reviews related work. Sec-tion 3 presents an overview of the proposed DML framework for automated photo annotation, and proposes solutions for discovering implicit constraints from social photo repositories. Section 4 proposes the probabilistic DML method and gives two efficient algorithms, that is, probabilistic Relevance Component Analysis (pRCA) and probabilistic Discriminative Component Analysis (pDCA). Section 5 discusses the application of PDML to automated photo tagging. Section 6 presents the experimental results and Section 7 concludes this work. Our work is mainly related to two groups of research. One is the group of studies on exploring web/social photo repositories for image annotation and object recogni-tion [Russell et al. 2008; Torralba et al. 2008; Yan et al. 2008]. The other is related to the group of DML studies [Bar-Hillel et al. 2005; Si et al. 2006]. We briefly review some representative work in both sides. Automated image/photo annotation has been actively studied over the past decade in multimedia community. Among a variety of conventional approaches, a widely studied paradigm is the supervised classification approach, in which classification models, such as SVM [Fan et al. 2004], are trained from a collection of human-labeled training data for a set of predefined semantic concept/object categories [Carneiro et al. 2006; Carneiro and Vasconcelos 2005; Duygulu et al. 2002; Wang et al. 2008b]. Besides, semi-supervised learning methods are also explored in recent literature [Li and Sun 2006; He and Zemel 2008].

Recent years have witnessed a surge of emerging interests in exploring web photo repositories for image annotation/object recognition problems. One promising approach is the retrieval-based (or termed  X  X earch-based X ) paradigm [Russell et al. 2008; Wang et al. 2006, 2008a; Torralba et al. 2008]. Russell et al. [2008] built a large collection of web images with ground truth labels for helping object recognition research. Wang et al. [2006] proposed a fast search-based approach for image annotation by some efficient hashing technique. Torralba et al. [2008] proposed efficient image search and scene matching techniques for exploring a large-scale web image repository. These studies are usually focused on techniques for fast indexing and search, while we focus on learning effective distance metrics from erroneous and implicit side information. Yan et al. [2008] proposed a learning based method for improving the efficiency of manual image annotation with the hybrid of tagging and borrowing. Our work differs from theirs by focusing on fully automated photo annotation. Besides, we also notice there are some related work that also learned distance metrics from tagged media collection, such as Qi et al. [2009] and Wang et al. [2008a]. Our study differs from them by emphasizing metric learning from uncertain side information. From a machine learning point of view, our work is closely related to DML studies. Firstly, we review some basics of DML. Given a set of n data examples X in d -dimensional vector space, the Mahalanobis distance between any two examples x and x j is defined as: where M is a positive semi-definite matrix that satisfies the property of valid metric and can be decomposed as M = A A . The goal of DML is to find an optimal Mahalanobis metric M from training data (side information) that can be either class labels or general pairwise constraints [Xing et al. 2002].

In literature, DML studies can be roughly divided into two major categories. One is to learn metrics with explicit class labels, such as Neighbourhood Components Analysis (NCA) [Goldberger et al. 2005], which are often studied for classification [Fukunaga 1990; Globerson and Roweis 2005; Weinberger et al. 2006; Yang et al. 2006]. The other is to learn metrics from pair-wise constraints that are mainly used for clustering and retrieval. Examples include RCA [Bar-Hillel et al. 2005] and Discriminative Component Analysis [Hoi et al. 2006a], amongst others [Xing et al. 2002]. Our work is more related to the second category, though some methods in the former category could be converted to the latter.

Lots of research studies focus on learning more effective distance metrics with the assistance of the high level semantic from the side information such as pairwise con-straints [Xing et al. 2002; Hoi et al. 2006a; Weinberger et al. 2006; Davis et al. 2007; Hoi et al. 2010; Jin et al. 2009]. An earlier and well-known DML approach was proposed by Xing et al. [2002], who formulated the task as a convex optimization problem. The ma-jor drawback of their work is computational inefficiency for large scale dataset. Later, RCA was proposed [Bar-Hillel et al. 2005] to learn metrics with equivalent/relevant constraints, which is simple and efficiency. Discriminant Component Analysis (DCA) further improves RCA by incorporating negative constraints [Hoi et al. 2006a]. Most recently, regularized DML and semi-supervised DML algorithms were also studied [Si et al. 2006; Hoi et al. 2010], which were often formulated as an SDP problem and again difficult to be used in large applications. The existing DML algorithms are restricted to rely on explicit pairwise constraints. Our probabilistic DML overcomes this limitation by exploiting implicit side information, in particular the user-generated content for images, in a probabilistic learning framework. Here we review a well-known and effective DML technique, that is, Relevant Compo-nent Analysis (RCA) [Bar-Hillel et al. 2005], since it is highly related to our work. The basic idea of RCA is to identify and down-scale global unwanted variability within the data. In particular, RCA suggests to change the feature space used for data representa-tion by a global linear transformation in which relevant dimensions are assigned with large weights. More formally, given a set of data examples X pairwise constraints indicating whether two data examples are similar (or dissimilar). RCA forms a set of m  X  chunklets X  C j ={ x ji } n j i = 1 defined as a group of data examples linked together by similar pair-wise constraints ( X  X ust-link X ).
 The optimal transformation by RCA is then computed as A =  X  Mahalanobis matrix is equal to the inverse of the average covariance matrix of chun-klets, that is, M =  X  C  X  1 , where  X  C is defined as follows: where  X  j denotes the mean of j th chunklet, x ji denotes the i th example in the j th chunklet and n is the total number of examples. RCA is simple, efficient, and easy to implement. Similar to other conventional DML techniques, RCA also requires a set of explicit  X  X ositive X  pairwise constraints provided for the learning task, which limits its application when the side information is given implicitly. Discriminative Component Analysis (DCA) [Hoi et al. 2006a] aims to learn from both positive constraints and negative constraints. Here a positive constraint indicates two instances are in the same chunklet, and a negative one indicates two instances are in different chunklets. For each chunklet j , a set of discriminative chunklets is formed if there is at least one negative constraint with the j th chunklet.

DCA learns the optimal transformation A by maximizing the total variance between discriminative chunklets and minimizing the total variance of data instances in the same chunklet simultaneously, which can be formally formulated as follows: where D j is the discriminative set for the j th chunklet, m j th chunklet, and n b is the cardinality of all the discriminative sets. Side information is critical to any distance metric learning algorithm. It typically appears in the forms of pairwise constraints, which a positive (negative) constraint indicates whether a pair of samples are similar (or dissimilar). Traditional DML meth-ods assume that perfect side information is provided explicitly, which is referred to as certain side information . In most studies, certain side information is cast in the hard pairwise constraints that indicate two examples are either absolutely similar or absolutely dissimilar. Besides, certain side information is usually assumed to be perfect without any error. The manual nature of certain side information makes it expensive to collect. These limitations restrict the application of certain side information.
In our study, we focus on learning a distance metric from uncertain side information that allows the uncertainty when generating the side information, which differs from the certain side information in several aspects. First, it is often generated automatically, for example, derived from the user-generated content of social images available on the web. Thus, uncertain side information is often much cheaper to acquire than certain side information. Second, it adopts  X  X oft X  pairwise constraints, in which each pairwise constraint is associated with a confidence/uncertainty. It is the soft constraints that allow us to better deal with the potentially noisy constraints. We first give an overview of the proposed semantic metric learning framework for learning metrics from social image data. Figure 1 shows a flowchart illustrating the proposed framework with application to automated photo tagging.

In the figure, the right column shows a retrieval-based photo tagging solution. Specif-ically, given a novel photo, the idea of the retrieval-based tagging approach is to firstly perform a similarity search for finding top k most similar photos from the social photo repository, and then annotate the novel photo with top t ranked tags associated with the k retrieved photos. Our main effort focuses on learning an effective metric to re-duce semantic gap for the similarity based search process, which is shown in the left panel of the flowchart. In this section, we discuss the main ideas of our metric learning framework.
 Since no explicit side information is available, we cannot directly apply regular DML techniques. Therefore, the first step towards DML is to discover possible side information from training data, which is essential to DML. In another words, we wish to find some forms of side information, which could indicate how likely two social image examples are similar or dissimilar. One solution is to discover some  X  X hunklets X  (similar to RCA) from training data such that images in the same chunklets are similar to each other, and images in different chunklets could be similar or dissimilar, up to the similarity of the two associated chunklets. Since such chunklets are not explicitly available (also cannot be easily formed as RCA), we refer to them as  X  latent chuklets  X . Intuitively, a latent chunklet can be viewed as a common semantic topic shared by the social images in the chunklet. Thus, it is possible that one image belongs to multiple chunklets.

To find the latent chunklets effectively and precisely, we propose a graphical model to estimate the probabilities of assigning an image to the latent chunklets. We refer to this step as  X  X atent Chunklet Estimation X  (LCE) step. By LCE, we obtain side information in the form of latent chunklets with probabilistic assignments, which we refer to as  X  X robabilistic side information X  or  X  X ncertain side information X . Finally, the last step of our semantic metric learning is to find an optimal metric from the probabilistic side information. In this article, we propose two PDML algorithms, that is, probabilistic relevant component analysis (pRCA) and probabilistic discriminative component analysis (pDCA), for solving the PDML tasks effectively.

Next we first present the algorithms for latent chunklet estimation followed by the proposed pRCA and pDCA algorithms in the subsequent section. Typically, a social image contains rich information, such as tags, title, description, comments, visual content, etc. In this article, we propose two approaches for discovering side information of latent chunklets from rich contents of social images. One is a graphical model approach, and the other is a clustering-based approach. For simplicity, we focus on exploring two key types of information, that is, textual and visual. It is not difficult to engage additional information in our framework. 3.2.1. Latent Chunklet Definition. First of all, we assume that there are m latent chunklets available, each of them represents a hidden topic z i , in which both visual images and associated textual metadata (e.g., tags) in the chunklets are generated from the hidden topic. Figure 2 shows the graphical model for social image modeling. The upper part of the graph represents the visual model. The images can be represented by some local feature descriptor, for example, bag of visual words representation [Lowe 2004], and each visual word a is generated from certain topic z a by a multinomial distribution On the left side,  X  is a Dirichlet distribution with hyper parameter the graph represents the textual model generating textual tags, in which the tags. For simplicity, we also assume that the tags are generated from a multinomial distribution  X  z w parameterized by the topic z w . Thus, a topic z contains two parts, that is, z = [ z a , z w ].
 Our goal is to estimate the hidden distribution P ( z a | I belonging to a certain topic z a , and the hidden distribution P ( z of topic z w existing in tag document d . Such conditional probabilities will be further used to predict the inter-chunklet variation and intra-chunklet variation. We discuss the generating process of the graphical model below.

First,  X  is the parameter for the topic distribution, which follows a Dirichlet distri-bution with parameter  X  : Further, given  X  ,topic z is drawn from a multinomial distribution, and follow some Dirichlet distributions: Here, we denote  X  = [  X  a , X  w ]. Finally, given topic z , both tags and visual words follow multinomial distributions: 3.2.2. Inferences. The main idea of the graphical model is to capture the conditional joint probability of tag document d and image x . A tag document is modeled by a bag of words d ={ w } , and the image x is represented by a bag of visual words x joint probability P ( z , x , d |  X ,  X  ) can be written as: where a represents a visual word in the social image, and tags with the social image. Further, according to the assumptions, the conditional joint probability of topic z , visual word a ,tag w with respect to parameters expressed as follows: To calculate the chain of conditional probability in the above equation, Gibbs sam-pling is adopted. Although variational methods can also be used, we choose the Gibbs sampling for its simplicity and applicability to our problem. Specifically, it repeatedly draws a topic z with respect to the conditional distribution. Then, visual words and tags are generated with the conditional probability given the topic z .

The objective of inference in the Gibbs sampling is to obtain the conditional distri-bution of hidden topic given the observed data. The Bayesian estimation of conditional distributions of tag, visual words, and topics are calculated as: In the previous equation, z w, i represents topic z for tag denotes topic z for visual word a in the i th sampling; n assigned to the j th topic before the i th sampling; n  X   X  words assigned to the j th topic before the i th sampling; n word a assigned to the j th topic before the i th sampling; n j th topic that appears in image x before the i th sampling; n j th topic that appears in tag document d before the i th sampling. Besides, W is the size of the tag dictionary, A is the size of the visual word dictionary, and m is the number of topics.

With these estimations, we can calculate the marginal by integrating out the param-eter  X  and sampling the topic with the following distribution:
Finally, we can calculate the topic relationship given parameter where z i and z j are any two topics from the set Z .

As a summary, each topic z i represents a chunklet. We can compute the conditional probability P ( z i | x , d ) that represents the relationship between the example and the tween the two chunklets. These probabilities can be adopted and explored for DML. Besides the complex topic model approach, it is also possible to study other methods to generate the probabilistic chunklets as long as the technique is able to find out the probability relationship between the examples. Here, we discuss another approach, the fuzzy k-means (FKM) clustering method [Bezdek 1981], for generating the latent chunklets.

The fuzzy k-means clustering algorithm [Bezdek 1981] partitions a set of n data the same clusters are minimized. Specifically, the optimization task of FKM can be formulated as follows: where P  X  R n  X  k is the membership matrix, whose element p ability of each data point belonging to each of the clusters (chunklets). C denote the centroids of the clusters (chunklets). The exponent that determines the degree of fuzziness, and d ij is the distance between the i th example and the j th cluster/chunklet: where x i denotes the features of the i th image, and M is the distance metric. If M is equal to an identity matrix, the distance measure reduces to Euclidian space. Here we use the tag vector to represent each image. Each image is represented as a K -dimensional vector, and the k th dimension of x ik indicates whether the image contains the k th tag, that is, if the k th tag appears in the i th image, x
By clustering the social images based on the tag vectors using the FKM algorithm, we can achieve the clustering results, which include both the set of clusters/chunklets and the membership matrix P that describes the assignment probability of each example to the chunklets. Such output membership matrix P will then be used as the probabilistic chunklets in the subsequent PDML task. In this section, we present a probabilistic DML (PDML) method for learning metrics from probabilistic side information. Unlike regular RCA learning, the latent chunklets are represented by some probabilistic distributions rather than  X  X trictly-hard X  pairwise constraints. Therefore, the challenge of PDML is how to exploit the uncertain side information for optimizing the metric in the most effective way. In this section, we present a probabilistic RCA technique, which extends the regular RCA in a probabilistic metric learning approach. We first introduce some definitions and notations.
Letusdenoteby x i a d -dimensional visual feature vector of an image, and z latent chunklets. Further, we denote by  X  k a center (mean) for a latent chunklet z  X  = (  X  the membership probabilities of associating examples with chunklets, where p ( p probability of observing example x i given chunklet z k ,thatis, p
In our approach, we initialize P by a prior probability matrix P which were obtained from the Latent Chunklet Estimation or the clustering process. The objective of our DML task is to learn an optimal metric M in a d -dimensional feature vector space, that is, M  X  R d  X  d . To exploit latent chunklets in DML, we formu-late a probabilistic extension of RCA, termed as  X  X robabilistic Relevance Component Analysis X  (pRCA), as follows: where parameter  X   X  0 constraints the difference between the prior probability matrix
P 0 (known from the previous side information generation stage) and the proxy proba-bility matrix P (unknown),  X  is a regularization constant, norm of a matrix, and  X  M denotes the mahalanobis distance under metric M .
This formulation can be interpreted as a robust optimization problem with bounded uncertainty on the probability matrix P . In particular, for the objective function, the first term is to minimize the sum of squared distances from examples to their chunklet centers, and the second term is to prevent the solution M from being obtained by shrinking the entire solution space. For the constraints, the one in (11) is to restrict the matrix of desired probability assignments P to be close to the prior matrix P remaining set of constraints in (12) are used to enforce the probability requirements. The following corollary shows that RCA can be viewed as a special case of pRCA.
C OROLLARY 1. For the optimization in (10) , when fixing the means of chunklets the matrix of probability assignments P ( assuming with hard assignments of 0 and 1) , the pRCA formulation reduces to regular RCA learning.
 The proof of Corollary 1 can be found in Appendix A.

We now discuss optimization techniques to solve pRCA. In general, the problem in (10) is a nonlinear optimization task with three sets of variables M , P ,and  X  can be easily computed once P is found. It is usually hard to find the global optima directly. To address this challenge, we present an iterative optimization algorithm by applying alternating optimization techniques [Bezdek and Hathaway 2003], which is widely used to solve multi-variable nonlinear optimization tasks.

Our iterative algorithm consists of three steps: (1) fixing P and fixing M and  X  to optimize P ; and (3) fixing P and M to find Corollary 1, the first step is equivalent to solving regular RCA, that is, M where  X  C is the average chunklet covariance matrix with the given P . The last step is straightforward, that is,  X  = P X , where X is a matrix of all training data.
We now focus on the second step. In particular, by fixing M and can be rewritten as follows: where the constraint in (11) was moved to the objective. This problem is a quadratic program (QP), which can be solved by some existing convex optimization software. However, for a real web application, the training data size can be very large, this poses a challenge of huge computation when solving a large-scale QP problem by a standard QP solver. To this end, we develop a fast algorithm, which is able to solve this optimization very efficiently.

To ease our discussion, we notice that p i , i = 1 ,..., n are completely decoupled in (13) given  X  k . Thus, we can rewrite (13) into a set of n independent optimization tasks, one for each p i ,thatis, It can be easily shown that solving the previous problem is equivalent to solving the problem in (13). We now discuss a fast algorithm to solve this problem. We first introduce the Lagrangian of the optimization as follows: where f = ( x i  X   X  1 2 M ,..., x i  X   X  m 2 M ),  X  is a Lagrange multiplier and of non-negative Lagrange multipliers. By differentiating it with respect to p the following optimality condition: By applying the KKT condition, whenever p k &gt; 0,  X  k should be zero. Therefore, if p we have the following result: Combining the fact that p k  X  0, we have the following: The next issue is to find the optimal  X  for the previous equation. The following propo-sition provides an efficient solution to find the optimal value of approach [Duchi et al. 2008].

P ROPOSITION 1. Let f denote the vector by sorting f in decreasing order, the optimal value of  X  to (16) can be computed as:  X  = X  1  X   X  k = 1 ( f found via a sorting approach, that is,
The proof for Proposition 1 can be found in Appendix C. By Proposition 1, we can solve the QP problem (14) in O ( n log( n )), which is significantly faster than standard QP solvers using interior point methods that are often in O ( n pRCA algorithm in Algorithm 1. The following corollary guarantees the convergence of the proposed algorithm.

C OROLLARY 2. Algorithm 1 converges to the local optimum for the optimization prob-lem of probabilistic relevance component analysis in (10) .

It is not difficult to verify Corollary 2 by following the convergence theory of alter-nating optimization [Bezdek and Hathaway 2003].
 Although the technique in Proposition 1 has a worst-case time complexity of complexity, we suggest another more efficient approach, as shown in Algorithm 2, by adopting an efficient Euclidean projection method that can be solved in linear time [Liu and Ye 2009]. It formulates the Euclidean projection problem as an efficient root finding task. More details of this technique can be found in Liu and Ye [2009].
 Similarly, we can also generalize the DCA technique [Hoi et al. 2006a] by applying the proposed probabilistic distance metric learning framework in order to incorporate both positive and negative pairwise constraints. Specifically, we formulate the probabilistic Discriminative Component Analysis method (pDCA) as follows: where p ij denotes the joint probability of two web images, which is estimated by the latent chunklet estimation process, for example, p ij = P ( z approach. As a result, (1  X  p ij ) measures the dissimilarity between any two chunklets, which implicitly represents the probability of negative constraint. Therefore, in the above formulation, the first constraint is introduced to avoid two dissimilar chunklets from being too close by exploring negative constraints.

Similar to the approach in solving pRCA, we can also solve the pDCA problem by an iterative algorithm of three steps. The first step is to fix P and for which the optimization can be reduced as follows: It can be shown that this optimization is almost equivalent to the regular DCA. The second step of the iterative algorithm is to fix M and  X  , and then optimize P .Forthis step, it is clear to see that the reduced optimization of the pDCA formulation in (18) becomes the same QP problem as shown in (13). The last step is to update the chunklet means  X  based on the optimized P . Finally, Algorithm 3 summarizes the iterative algorithm of probabilistic DCA.
 In this section, we discuss the application of pRCA to the exploitation of social photo repositories for automated photo tagging tasks. Given a novel photo, the automated tagging task is to annotate the photo labels or tags, which often reflect certain semantic concepts/objects. To overcome the limitation of conventional approaches, we investigate a retrieval based approach to automated photo tagging tasks by exploring a huge number of social photos freely available on the web. We formally formulate our approach as follows:
Let I q ={ x q , T q } denote a query image for tagging, where x contents of the image, and T q denotes a set of unknown tags to be found in the tagging task. In general, a retrieval based tagging approach consists of two steps: (1) retrieving a set of visually similar social photos, which are closest to the query photo; and (2) annotating the query photo by a set of most relevant tags that are associated with the retrieved similar photos.

For the first step, there are two typical approaches to find a set of nearest neighbors with respect to a query image. One is to retrieve the k -nearest neighbors of the query image, that is, where n is the total number of photos in the social photo repository. The other way is to retrieve a set of nearest photos within certain distance range, that is, where is a predefined distance threshold. For both approaches, it is clear that an effective distance metric M is essential to retrieve the set of nearest neighbors. In this article, we adopt the first approach and employ the metric learned by pRCA to compute the k-NN list.

For the second step, we suggest an information theory based tag ranking scheme by adopting the voting by maximum likelihood scheme. Specifically, we define a set of candidate tags T w as: where T i represents the set of tags associated with image I w by f ( w j | I k ). The conditional probability of each tag given the k th similar photo I calculated as follows: where  X  is a smoothing parameter which is simply fixed to the vocabulary size in our experiments. The likelihood of assigning the tag w j to the test image I where p ( I k | I i ) is estimated by the visual similarity between two images, which is cal-culated by where we use a Gaussian kernel to model the visual conditional probability and kernel parameter that is empirically determined by a validation set.
 We then incrementally add the best tag w  X  into the tag set for the query image T = T where p ( w | I i ) represents the probability the candidate photo I This formula indicates that we prefer to assign the query image with a tag according to both tag frequency and image visual similarity. The goal of our experiment is to examine if the proposed distance metric learning method is more effective than conventional methods for automated photo tagging tasks. To this purpose, we first conduct a numerical evaluation by comparing the proposed algorithms with a number of state-of-the-art distance metric learning algorithms, and further examine the influence of varied parameters and settings that could affect the performance of the proposed automated photo tagging scheme. Finally, we note that all experiments were run in the same environment with a typical PC of 2.8 GHz CPU with Matlab. We collected a large social photo testbed with over 1,000,000 photos crawled from www.Flickr.com, in which most photos contain user-tags and other metadata. There are around 200,000 tags in the dataset. The average occurrence of each tag is around a knowledge database set. Since both the images for metric learning and for knowledge databased are crawled from Flickr, the tag property and distribution of the two sets are similar. In this section, we describe the details of the three partitions.
The training set is used for learning distance metrics. In particular, we randomly sampled 16,588 photos with tags from the whole social photo testbed. We did not make any refinements on the associated tags. To provide visual words for training the models, we construct the bag-of-visual-words representation by extracting local features from the training photos using the SIFT descriptor [Lowe 2004].

The test set is used for evaluating the photo tagging performance. In particular, we randomly picked 2,000 photos from the whole photo testbed as the query images to test the photo tagging performance. To improve the quality of test data, we created the annotation ground truth by manually removing some clear noises to refine the original tags.

The rest social photos are engaged as the knowledge database set, which serves the base of social photo repository for tagging. We also randomly selected 200,000 photos from the knowledge database. We perform directly similarity search on this small knowledge database, for the comparison with the search results in the whole knowledge database, in which LSH indexing [Andoni and Indyk 2008] is adopted to improve the search efficiency. We try to see whether the scale of the knowledge database will help improve the performance.

Finally, for the photos in both test set and the knowledge database, we extract a set of effective and compact visual features [Hoi et al. 2006b, 2009], including: (1) grid color moments, (2) edge direction histogram, (3) Gabor textual features, and (4) Local binary pattern histograms. In total, a 297-dimensional feature vector is used to represent each photo. The reason that here we do not adopt local features, such as SIFT, is primarily due to the efficiency consideration. To examine the effectiveness of our technique, we compare the proposed pRCA and pDCA algorithm with some baseline and a number of state-of-the-art DML meth-ods, including (1) a baseline that simply adopts Euclidean distance, (3) regular RCA [Bar-Hillel et al. 2005], (3) Discriminative Component Analysis (DCA) [Hoi et al. 2006a], (4) Information-Theoretic Metric Learning (ITML) [Davis et al. 2007], (5) Large Margin Nearest Neighbor (LMNN) [Weinberger et al. 2006], (6) Neighbourhood Com-ponents Analysis (NCA) [Goldberger et al. 2005], and (7) Regularized Distance Metric Learning (RDML) [Si et al. 2006]. Note that we excluded other DML methods in our comparison mainly due to their computational infeasibility for such large-scale applica-tions. For example, the well-known DML method in Xing et al. [2002] is only applicable to a very small dataset.

Regarding the two proposed algorithms, pRCA and pDCA, there are some common property, that is, both of them adopt the probabilistic constraints, which is also the key advantage over traditional RCA and DCA methods. In general, pDCA can be viewed as an extension of pRCA. The difference is that pRCA only minimizes the distance between the relevant samples, while pDCA both minimize the distance between high relevant samples and maximize the distance between low relevant samples.
Since no explicit side information is available for traditional DML, in training stage, we performed clustering on training photos using both visual features and tag co-occurrence information. Photos that have similar visual contents and share common tags will be grouped together. Finally, we generate side information from the resulting clusters (after removing trivial clusters) as the inputs for DML.

We sample the same subset of image pairs for both deterministic metric learning and probabilistic metric learning. For the probabilistic metric learning, we estimate the probabilistic chunklets by the sample image content and their tags. For the deter-ministic metric learning, if the sampled pair of images share any tag, they are in same chunk; otherwise, in different chunks Regarding parameter settings, for the pRCA learning, we assume there are m ( m latent chunklets for the N ( N = 16 , 588) training examples, and generate an m matrix of probabilistic latent chunklets distribution by the graphical model as the probabilistic side information, which is used as the prior probability matrix P metric learning. For the extraction of visual words in LCE, we set the number of visual words A = 1 , 000, and the number of tags W = 2 , 000. The parameter simply fixed to 0 . 5 for all experiments.

For other DML methods, we adopt the same settings, that is, 500 chunklets for producing the side information. For their parameters, we chosen them according to the suggestions/empirical results in the original work.

To evaluate the automated photo tagging performance by different methods, we em-ploy the proposed retrieval-based annotation solution presented in Section 5. Firstly, for each query photo in the test set, top k nearest photos from the database are first re-trieved as the set of candidate images. Then, we annotate the query photo by assigning top t tags ranked by the function in (25). Finally, we adopt standard average precision and average recall at top t tags as performance metrics to evaluate the automated photo tagging performance. Figures 3 and 4 show average precision and average recall at top t annotated tags, respectively. For these results, we fixed the number of nearest neighbors k to 30 for all compared methods. In both figures, the horizontal axis denotes the number of top tags t that ranges from 1 to 10.
 From the figures, we can draw several observations. First of all, we found that most DML techniques outperformed the baseline by simple Euclidean distance. This shows that DML techniques are beneficial and critical to the retrieval-based photo tagging tasks. Second, we found that for some cases, some DML methods did not perform well, and sometimes performed even worse than the Euclidean method. For example, for the case of top-1 annotated tag, we found that DCA performed slightly worse than Euclidean. We believe this is mainly due to the noisy side information issue. This again shows that it is important to develop some effective and robust method in our problem. Further, we observe that the proposed pRCA algorithm considerably outperformed other approaches in most cases. For instance, for the case of top-1 tag, pRCA achieved average precision of about 31%, which improves the baseline approach over 40% and over RCA about 20%. Finally, comparing the two proposed methods, pRCA and pDCA, we found they are quite comparable, in which pDCA tends to be slightly more effective than pRCA.
 Figure 5 further shows the precision-recall curves. Similar observations were found. The proposed algorithms, pRCA and pDCA, considerably outperform the others. This is because our methods use the probabilistic constraints rather than the traditional hard constraints. The probabilistic constraints can better reflect the relationship between the examples and thus achieve more accurate results. These results again validate the efficacy and significance of our technique. We also notice that an important parameter, that is, the number of nearest neighbors k , could affect the annotation performance considerably. To examine how is its impact, we evaluate the annotation performance of the proposed annotation method by varying the value of parameter k . Figures 6 and 7 show the average precision results of the proposed pRCA and pDCA annotation approaches by varying the value of k from 10 to 50.

From the experimental results, we found that when k equals to 30, the resulting annotation performance is generally better than the other cases. We suspect the main reason is that if we set k too large, for example, 50, many noisy tags may be included; as a result, there may not exist so many relevant images in the database, which thus could harm the performance. However, if we set k too small, some relevant tags may not appear, which again would degrade the annotation performance. In our annotation framework, the size of the knowledge database plays a critical role in affecting the annotation quality. In this experiment, we aim to evaluate how the size of knowledge database affects the image annotation performance. In particular, we vary the size of the knowledge database from 20,000 to 1,000,000 and evaluate the average precision/recall of image annotation based on each database. Figure 8 summarizes the comparison of the annotation performance with respect to two knowledge databases of different sizes.

As we can see from the figure, when the size of the knowledge database increases, the performance of the retrieved based photo tagging solution is improved considerably. The main reason is because once we have a larger database, the chance of finding the similar/relevant images can be potentially increased, which thus leads to the improve-ment of the annotation quality as the performance of retrieval-based tagging method highly depends on the relevance of the retrieved similar images. The third experiment is to evaluate the time efficiency of the proposed DML algorithm. To this purpose, we compare time performance of our algorithm with other DML al-gorithms. Table I summarizes the evaluation of average time cost results that were obtained by running the compared algorithms in our DML tasks.

From the results, we can see that the most efficient method is the regular RCA approach, and the least efficient one is NCA that was significantly slower than the others. Finally, by comparing our algorithms with the other competing algorithms, we found that both pRCA and pDCA are quite competitive, which though are slightly worse than RCA, DCA, and RDML, are considerably more efficient than ITML, LMNN, and NCA.This is due to the efficient sorting algorithm. Since we use a sorting algorithm instead of to solving the QP problem directly, our methods can be much faster than its counterparts. As discussed previously, we suggest two kinds of approaches to generating the latent chunklets (i.e., side information). One is the sampling method using the graphical model, and the other is the clustering approach using the fuzzy k-means. In this section, we aim to compare the sampling method with the clustering method to examine their influence on the final image annotation task.

We evaluate the performance of both methods by computing their average precision and average recall scores. For the clustering-based approach, we adopt the fuzzy k-means algorithm [Bezdek 1981], which also generates a soft probabilistic relationship between samples and the clusters. For fair comparison, we generate the same numbers of chucklets/clusters using the same settings for both compared methods. Figure 9 shows the results of average precision and average recall of the image annotation task.
From the experimental results, we found that both methods perform quite compa-rably for the automated image tagging task. Empirically, the graphical model based approach is slightly better than the clustering based approach. This is reasonable as the graphical model may generate more natural and effective initial chunklets compared with the clustering based approach. Since the probabilistic chunklets will be automatically updated in the subsequent distance metric learning process, the initialization actually has limited influence on the final performance. This also shows that the proposed algorithm is robust to the noisy side information. In addition to the previous quantitative evaluations, our last experiment is to examine qualitative performance of our automated photo tagging solution. We randomly picked a list of query photos from the test set and showed the qualitative retrieval and anno-tation results in Figures 10 and 11, respectively. From these results, we can observe that our solution generally achieved better qualitative results than others. On average, our method can produce more than five correct annotations for each image, which is better than other methods. Also the retrieval result shows our method can produce more relevant images. This article investigated a new problem, termed  X  X robabilistic Distance Metric Learn-ing X  (PDML), which aims to learn distance metrics from uncertain side informa-tion that implicitly exists in some real applications. Unlike conventional DML techniques that work with explicit side information, the PDML problem is more challenging given that the side information is not explicitly available. We proposed a novel two-stage PDML framework, which firstly discovers probabilistic side in-formation from the data using an unsupervised learning approach, and then em-ploys some effective probabilistic DML algorithm to find an optimal metric from the probabilistic side information. In particular, we proposed two effective PDML algo-rithms, that is, probabilistic RCA and probabilistic DCA. We applied the proposed technique to automated photo tagging on a large-scale social photo testbet with over one million photos from Flickr. By comparing our technique with a number of state-of-the-art DML methods extensively, we concluded that our technique is effective and promising for solving this challenging problem. Future work will extend our framework by exploring more social information to boost automated photo tagging [Sigurbj  X  ornsson and van Zwol 2008; Stone et al. 2008].

P ROOF .Byfixing  X  and P , the optimization reduces to: By differentiating the Lagrangian with respect to M , we have the following equality: Hence, we have the optimal solution: M = 1  X   X  C  X  1 , where matrix When p ( k ) i takes only 0 or 1, it can be seen clearly that the solution of M is almost identical to the solution learned by RCA (up to a global scale factor). Hence, pRCA reduces to regular RCA learning in this special case.
 Our proof was inspired by the study in Duchi et al. [2008]. First of all, to simplify (16), we denote by a k = p 0 k  X  f k  X  . As a result, p k in (16) can be written as:
Let a denote the vector by sorting a in decreasing order, our goal is to show that the optimal value of  X  to the solution in (29) can be computed as:  X  can be found via a sorting approach, that is, In order to prove this result, we shall first introduce a lemma:
L EMMA 1. Let p denote the optimal solution to the minimization problem in (3) ,lets and t are two indices such that a s &gt; a t , where a s = If p s = 0 ,thenp t must also be zero.

P ROOF . We can prove it by contraction, that is, assume that p us introduce a vector p by setting p s = p t , p t = p s ,and p clear the constraint sum ( p ) = 1 still holds. We now compare the two objectives: This result means obj ( p ) &gt; obj ( p ), which contradicts the fact that p is the optimal (minimal) solution.

Lemma 1 implies that those non-zero solutions p k should have the largest values of a . This shows that we can find p k by sorting vector a in decreasing order, denoted as a . As a result, by combining the optimality condition, we have equation: where  X  is a constant number. Once  X  is given, it is straightforward to have: Finally, the optimal value of  X  can be found by applying the following lemma, which was proved in Shalev-Shwartz and Singer [2006].
 minimization problem below: and assume that  X  is sorted in decreasing order. Then, the number of strictly positive elements in p is: Applying this lemma leads to complete the proof of this proposition.

