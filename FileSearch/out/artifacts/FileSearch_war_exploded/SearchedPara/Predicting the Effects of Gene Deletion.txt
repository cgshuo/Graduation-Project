 SIGKDD Exploration s. Volume 4, Issue 2  X  page 101 In this paper, we describe techn iqu es that can b e used to p redict the e ffects of gene deletion . We will focus mainly on the c reation of predictive variables, and then b riefly discuss different mod eling techn iqu es that have been u sed succe ssfully o n this data.
 KDD Cup , KDD , gene, deletion , prediction , mod el, interaction , decision tree, essential, text mining. The 2002 KDD Cup was an exercise in ou r abilit y to p redict the effects of gene deletion . Given to the c on testants were a series of relation al tables as well as nu merou s abstracts discussing many of the genes. By using text mining algorithms and relation al algorithms, we bu ilt a series of 1000 variables that cou ld po tentially predict the narrow and b road classes of the pro blem. Beca use the data was s parse, we had to come up with a way to select t he best variables, combine tho se variables into group variables, and app ly a low complexity mod el to avoid o ver -fitti ng. The tables includ ed informati on on three specific prop erties for the genes. The prop erties includ ed location o f the gene ac tion in relation to the ce ll structure (e.g. cell membrane or nu cleus), the protein class of the protein p rodu ced o r activated b y the gene (e.g. actins or cyclin s), and the fun ction o f the protein p rodu ced as it related to cellular fun ction (e.g. metabo lic or energy related). The prop erties for eac h gene lay within multil evel architecture or hierarchy. These hierarchical t ables also were a vailable. In add ition , tables of gene -to -gene interaction s and gene a liases were given with d epend ent variables (the narrow and b road po sitive classes) for the training set. Finally, abstracts and tables relating the gene a liases were provided for mining. We used text -mining algorithms to con vert this text into a set of nu meric variables that wou ld likely be predictive of the two classes. The c reation o f gene c haracteristic variables was condu cted in such a fashion as to allow the processing between the ge ne specific c haracteristics and the hierarchal structure of the three gene c haracteristics. Several variables wou ld b e c reated for eac h gene a nd its action location characteristics. These variables wou ld reflect the specific location as well as any sub g roup ing characteristics the gene c on tained as a result of the hierarchy of the location table. All variable a nd h ierarchal l evels were designed to b e binary for eac h po tential level of location , protein and p rotein fun ction . An example of this variable s et for gene YO R113 W and p rotein class wou ld equ al 1 for Proteases, Transcription factors, Zinc -coo rdinating DN A -bind ing do mains, and Cys2His2 zinc -finger and zero for all other group s and sub group s of protein classes. More variable c rea tion was derived b y con catenating the naming no menclature of the a lias names to d erive several variables from the text no menclature itself. Examples for gene YO R113 W wou ld b e Y, YO R, OR, 1, 13 , 113 , and W. This was don e to identify any naming no menclatur e c haracteristics that cou ld o ffer predictive values. High frequ ency gene a liases also were examined in this fashion . Most of the key variables did no t come from the data tables that were given. The key variables were generated b ase d on a text -mining algorithm searching a database of 15 ,234 abstracts discussing these genes. Our first step was to b rowse throu gh several articles con taining narrow and b road class genes, and to compile a list of words that intuitively app eared like they cou ld b e predictive key words. The final li st con tained 23 words: change, chromosome, delete, direct, elusive, ethano l, FK506 , glucose, Hst1, ime2, inh ibit, interact, molecular, nd t80 , promoter, radioactive, rapamycin, repress, sensitive, Set3C, signal transdu ction , transcription , and tumor. We a lso equ ated p lurals, past tense, and o ther forms of the same word to b e interpreted in the same way. For eac h o f these key words, we generated 3 variables, as we were no t sure which wou ld b e more predictive: 1) A coun t of ho w many times a key word app eared in the same article a s a gene, 2) A coun t of ho w many times a key word app eared within 100 characters of the gene, and 3 ) A coun t of ho w many times a key word app eared within 60 characters of the gene. As it turned ou t, there was no general rule of which o f the 3 were more predictive, as it varied from on e key word to ano ther. The stron gest predictors ou t of the e ntire data set were based on the key words: complex, mutation , interact, and essential. Of the 6 30 genes that app eared in an abstract con taining the word  X  X nteract X , 21 were narrow class genes, and 11 were broad class genes. This s ingle variable narrows do wn more than h alf of the narrow class genes in a littl e more than on e fifth o f the data set. I t shou ld also b e no ted that sorting the test set by this variable a lon e yields an ROC area of 0.6516 , enou gh to rank 3 rd on the narrow po sitive c lass in the KDD Cup . The first idea is ob viou s: Check to see which genes interact with t he target genes. This idea qu ickly is disregarded as on e find s that no t a single gene interacts with more than on e gene in the predicted classes, thu s wiping ou t the po ssibilit y of any statistical significance for the predictabilit y of an interaction with a single gene. Add ition ally, it can also b e seen that abou t on e ou t of fou r genes in the predicted classes have a ny interaction s at all, so at best the presence of interaction s can b e on e fou rth o f the solution . The total nu mber of interaction s was a st ron g predictor. 5.5% of the 128 genes with 10 o r more interaction s were in the narrow class (compared to 1 .1% of the remaining g enes). Furthermore, SIGKDD Exploration s. Volume 4, Issue 2  X  page 102 by evaluating v ariou s group s of genes interacting with the target genes (primarily the narrow partiti on ), some stron g patterns were ob served. How did we determine which group s of genes to evaluate for interaction s? We used all of ou r 500 variables as group s and generated 500 interaction variables, eac h representing the nu mber of interaction s with genes havin g that variable X  X  value greater than 0 . The most predictive interaction was evaluating interaction with essential genes. Out of 260 genes interacting with this group , 12 were targets in the narrow class (ou t of on ly 15 total narrow class genes with any i nteraction s at all). The biggest prob lem in mod eling this data was the sparseness of the data. There were very low frequ encies of target values, and non e of the variables were e xtremely predictive. This requ ired a mod el of extremely l ow complexity to avoid o ver -fitti ng. Furthermore, we felt t hat on e c ou ld no t split ou t a validation /test set since further dilution o f the frequ encies wou ld bo th weaken the mod el significantly and give a n un reliable test set result. Given more time, re -s ampling method s cou ld h ave been u sed to test the reliabilit y of ou r mod els. However, ou r time limitation s led u s to d ecide to d esign a single mod el, and try as best we c ou ld to avoid o ver -fitti ng. To d emon strate ho w qu ickly over -fitti ng cou ld o ccur with this data, we ran linear regression on the best 6 variables. For the narrow class, the ROC area was 0.6350 (on the test set), which is less than the ROC area when sorting by the single best variable. In section 3 .1, we discuss the techn iqu es actually use d for ou r sub mission in the KDD Cup . In section 3 .2, we discuss ideas for improvement after taking away the time con straints of the c ompetiti on . First, we sorted ou r variables by correlation to the depend ent variable, and cho se 0 .08 as a c utoff, since that i nclud ed 54 variables, which was more than enou gh to work with. Within that group , we e valuated sub sets of the dataset where eac h o f the variables was greater than 0 , and also the sub set where the value was greater than 1 . Wit hin eac h o f these sub sets, we decided upon which on es had significantly high p ercentages of the depend ent value. 13 variable ranges app eared the best. We then created a variable that was a c oun t of these ranges, and n amed it  X  X ood Var1 X . Of the 141 genes that had a  X  Good Var1 X  value of 3 or greater, 14 were in the narrow class. This beca me the first key split of ou r decision tree, which we further split based on combination s of variables that app eared to sho w the highest predictabilit y. In the sub set tha t did no t have a  X  Good Var1 X  value of 3 o r more, we ran a similar variable selection p rocess, and combined a second set of 25 variables into a variable named  X  X ood Var2. X  Variables with a  X  Good Var2 X  value of 5 o r more proved to b e highly predictive, so that beca me ou r second key decision cut po int. In further decision tree splits, we did no t use an automated algorithm, du e to the sparseness of the data relative to the c omplexity of an automated d ecision tree. Each cut po int was manu ally decided upon b ased on loo king at statistics of the predictabilit y of variables within the decision tree nod e, and then checking to see which on es were backed up by predictabilit y over the e ntire data set. If we had no t don e this check, there wou ld have been no statistically significant predictors within ou r nod es, du e to the tend ency of decision trees to make data progressively more sparse. As we found ou rselves very close to the deadline for sub mitti ng ou r entry, we did no t create c ombination variables for the broad class. We simply used  X  X ood Var1 X ,  X  X ood Var2 X , and the highly correlated variables to the broad class. We then u sed the same decision tree techn iqu e that we used for the narrow class. For pu rpo ses of the KDD Cup , time c on straints prev ented many teams from utili zing the best po ssible mod el, bu t rather a qu ick mod eling techn iqu e. For pu rpo ses of this paper, we made a few mod eling improvements and app lied a second mod el (narrow partiti on on ly) to the test set to give a better idea of wha t the po tential of the data set cou ld b e. Und er the time c on straints, variables with the highest correlation to the depend ent variables were the on es con sidered, as this is a qu ick and easy calculation . However, there a re better techn iqu es for variable selection that cou ld h ave been u sed that wou ld b e less influenced b y rando m patterns. In ou r case, we e xamined sub sets of the data where ind epend ent variables were greater than 0 , and greater than 1 . Within these sub sets, we defined a measure that evalua ted the size of the predictive value minu s a penalty for po tential no ise. This measure we defined as N NP  X  E(N NP )  X  SD[E(N represents the nu mber of occurrences of the narrow partiti on within the sub set. E(N NP ) r epresents the e xpected nu mber of occurrences, based on the frequ ency within the e ntire dataset. SD[E(N NP )] is the stand ard d eviation o f this expected nu mber of occurrences. When remod eling using this measure of predictabilit y, we a lso created 4 group s of variables s imilar to the princip le of  X  X ood Var1 X  a nd  X  X ood Var2 X  discussed in the previou s s ection . We a pp lied this mod el, and ob tained a test set result of 0.70 , a large improvement from ou r previou s result. Due to the sparse data, and lack of solid variables, it was impo rtan t t o h ave a very low complexity mod el. We acc omplished this by combining several predictive variables into group ed variables. We a lso kept the mod el as s imple a s po ssible by manu ally partiti on ing a decision tree. We scraped for more data by forfeiting a test set. We a lso improved the po wer of ou r variables by creating the 500 interaction variables (that is, gene interaction s, no t data mining interaction s) . We ac kno wledge A.I. Insight, Inc. and MEDai, Inc. for the use of their prop rietar y predictive mod eling techno logy, MITCH. (Multiple Intelligent Tasking Compu ter Heuristics) [1] Sa ccha romyce s Geno me Deletion Project web p age, the list [2] Fun ction al Profiling of the Sacc haromyces cerevisiae [3] Winzeler, E., Sho emaker, D., Astromoff, A. Liang, H., et al. [4] Sho emaker, D., Lashkari, D.A., Morris, D., Mittmann , M. &amp; SIGKDD Exploration s. Volume 4, Issue 2  X  page 103 David Vogel stud ied Mathematics at M.I.T. and earned a M.S. in Scientific Compu ting at N.Y.U. For his thesis, he invented a new techn iqu e for calculating radiation expo sure, which was s everal times qu icker and more acc urate t han the indu stry stand ard. After leaving the Nuclear Engineering indu stry in 1998 , Mr. Vogel found h imself at A.I. Insight, where he is no w the Senior Scientist. Having been un satisfied with the mainstream predictive mod eling software packages that are a vailable to b e pu rchased, Mr. Vogel l ed the way at A.I. Insight i n the develop ment of MITCH (Multiple Intelligent Tasking Compu ter Heuristics). This software has been app lied toward the medical indu stry, where it has excee ded the level of acc uracy that ha s been pub lished in medical j ou rnals as the  X  Theoretical Maximum X  predictive acc uracy. Mr. Vogel has also incorpo rated MITCH into the creation o f a stock mod el, no w being licensed for the pu rpo se of managing an investment fund . Mr. Vogel has s ub mitted en tries for the KDD Cup in 2001 and 2002 , and h as earned hono rable mention s on bo th o cca sion s.
 Rand y C. Axelrod, M.D. is the Vice President and Executive Medical Director for Sentara Healthcare in Norfolk, Virginia. He rece ived h is BS from Tulane University and h is MD from the University of Cincinn ati. Dr. Axelrod h as been with Sentara for nearly seven years focusing on clinical i nformation and h ealth care ou tcomes research and improvement for the Hampton Roads comm un ity. His efforts have focused on the in tegration o f A.I. techno logy into h ealth care delivery on the provider side a s well as the payer side. His improvements in clinical ou tcomes and inno vation s have rece ived many nation al awards. In 2001 , Dr. Axelrod rece ived the Inno vator X  X  Aw ard from the Health Insurance Association o f America a nd Nation al Und erwriter for his work with artificial i ntelligence in the health insurance 
