 The Web of Data (WoD) is a rapidly expanding part of the general Semantic Web (SW) landscape where hundreds if not thousands Linked Data (LD) datasets are published every year. When publishing their dataset, authors often do not care to provide a ded-icated schema but rather refer to openly available sources such as DBpedia, YAGO, GeoNames, etc. While these resources enable a rapid expansion of the WoD by reduc-ing the publication effort, a more precise schema  X  X ailored to the dataset content X  would facilitate its further exploiting, e.g., querying or integration with other dataset [13]. the design of methods and tools for schema discovery from LD [1, 7, 17]. In its most general wording [17], the corresponding task is aimed at mining relevant schema el-ements, esp. classes (both identifying and producing definitions/descriptions thereof), subclass and subproperty links, rules, etc.
 class identification, 2) class hierarchy construction, 3) definition of property domains and ranges, 4) class name assignment. The first two steps can be automated to a large extent: Many methods from the literature would address them as a single task and apply hierarchical clustering to 1 and 2 whereby the similarity measure is based on shared properties among resources. In particular, formal concept analysis (FCA) techniques have been frequently used to that end, due to the nice structural properties of its final result, the concept lattice. Compared to that, task 3 has often been implicitly addressed by the proposed methods. ity in the distribution of the predicates or the (predicate,object) pairs across the triples of the LD dataset, class naming is inherently manual task. Indeed, it involves interpreting the resource cluster behind a new class and hence assessing its relevance. To the best of our knowledge, none of the methods from the literature have addressed the (partial) automation of the process, e.g., by providing plausible candidates for class names. Yet this could be a great relief for the human analyst, especially with approaches which tend to generate a large number of classes such as those exploiting FCA or affiliated pattern mining techniques.
 discovery from data. As the emphasis is on the aforementioned step 4, we choose a relatively unambitious variant of the first stage of the process: Our goal is to define the class hierarchy and feed in property domains and ranges (whenever applicable), which amounts to designing an RDF Schema for the initial dataset. More thorough class descriptions in expressive languages, e.g., OWL 2 EL, although relevant, are beyond our scope. Thus, our method applies FCA to jointly address the first three steps of the schema discovery task. For class naming, typing information from generally available external sources such as DBpedia is factored in whereas the properties of the FCA output, i.e., the concept lattice, are exploited to ensure produced names are both most specific and unique.
 from the WoD. Its choice was dictated by the need to keep the FCA output reasonably-sized without applying strong filtering techniques so that the potential of our naming technique could be assessed in a fair manner. The output set of classes was assessed in terms of recall, precision and f-measure w.r.t. to a reference class set and the results were judged promising.
 section 3 provides background to the study. Sections 4 and 5 describe our method and the experimental study, respectively. Finally, section 6 concludes. The aforementioned schema discovery tasks are dealt with in the larger field of ontol-ogy learning [13] whereas individual methods address specific subsets thereof. Most methods only address the first two of them, i.e., the construction of the class hierarchy, a.k.a. the taxonomy. To that end, they apply a hierarchical clustering algorithm, either FCA-based or a statistical one, e.g., nested k-means. In [5], a comparison is drawn be-tween three clustering paradigms, FCA and two statistical ones, with their respective merits for ontology learning. The authors conclude that FCA performs better and pro-duces clusters that are easier to interpret yet there is a price to that as concept lattices tend to grow rapidly.
 A LD dataset where a schema, albeit present, is unexpressive (RDFS) and unmarked within the overall RDF graph is provided with a richer, OWL EL-level ontology. A re-lated FCA application is presented in [1] where authors use FCA to detect incorrect or incomplete typing in LD datasets. Here FCA is a mere means to the discovery of strong associations between types to use as correcting templates for the RDF data.
 Delteil et al. [7]. The proposed method is FCA-based, yet the target concept are not intended to become RDFS classes, as in our case, but rather fit to the conceptual graph template. Thus, their intents comprise chains of triples of a fixed length (gradually increasing along an iterative construction process), rather than being set of attributes translating RDF properties as proposed here.
 of other contexts: For instance, enhancing the functionalities of RDF repositories or the entire WoD w.r.t. navigating, browsing, visualizing, etc., motivated a large body of work [2, 9, 12, 14]. Noteworthily, relational extensions of FCA to fit graph-shaped data are used in [9] and [2], called logical concept analysis (LCA [10] and relational concept analysis (RCA) [15], respectively. Similarly, mining quieries or query answer by means of FCA has been actively researched on [4, 6, 16].
 ing, has been addressed in the context of ontology learning from texts [18]. Yet, given the specific nature of the input data, the techniques used to that end are totally unrelated to the one we present here.
 tasks. 3.1 The RDF/S Data Models As a generic data model, RDF 1 represents the information on the web in the form of subject-predicate-object triples. Each triple is a sentence describing a re-source. A resource is an entity which can be a subject, predicate or object in an RDF triple. The subject or first part of an RDF triple is a resource which the statement de-scribes. The predicate or second part of the triple is the property or aspect which relates the resource to an object. Therefore, the object is the third part of the triple which could be another resource or a literal value defined as a string or a number, a date, etc. tensible knowledge representation language which adds vocabulary to RDF in order to express the information about classes and their relations including superclass/subclass relations and properties (predicate relationships between the classes). 3.2 DBpedia DBpedia 3 is a project which aims at extracting structured information from the Wikipedia content. In addition to free text information, DBpedia also uses the different types of structured information from Wikipedia including the infobox templates 4 , title, abstract, categorization information, images, geo information, and external url links. This open source data set is available on the web as linked data (RDF triples) [3]. 3.3 Formal Concept Analysis Formal Concept Analysis (FCA) is a lattice theory-based approach towards the discov-ery of conceptual knowledge from data [11]. Datasets are introduced as formal contexts , i.e., objects-to-attributes cross tables.
 Definition 1 (Formal Context). A formal context is a triple K ( G, M, I ) , where G and M are sets of objects and attributes, respectively, and I  X  G  X  M is an incidence relation.
 attribute m . Figure 1 depicts on the left a sample context drawn form a Russia-related dataset found on the WoD (In the figure labels are shown instead of full URIs). It is made of five resources as objects and six properties as attributes, whereas the incidence reflects the composition of the triples from the dataset.
 regularities in the distribution of attributes over the set of objects. The revealed concep-tual structure of the context is called (formal) concepts in FCA: Definition 2 (Concept). A pair ( A, B )  X   X  ( G )  X   X  ( M ) is a (formal) concept of the context K ( G, M, I ) iff A 0 = B and B 0 = A . A is called the extent and B the intent of the concept.
 ure 1.
 concepts are partially ordered by set-theoretic inclusion of extents. Thus, a subconcept-of relation  X  K is defined by: Moreover, following the Central Theorem of FCA [11], the partial order induces a com-plete lattice on the concept set.
 Property 1 (Concept Lattice). For a formal context K ( G, M, I ) with its concept set C K , the partially ordered set L K =  X  X  K ,  X  K  X  is a complete lattice where the join ( W ) and follows: known to be closure operators [8] in any Galois connection.
 senting concepts are annotated with respective intents and extents. Mathematically, the graph of that diagram follows the transitive restriction of the lattice order  X  K , i.e., the precedence  X  relation. The lattice of our sample context is shown next to it in Figure 1. Our method comprises three steps: At step one, FCA algorithms are applied to an appro-priate transformation of the RDF dataset to construct its concept lattice. At step two, the concepts are converted into RDFS classes and subconcept-of links from the lattice into subclass assertions. Moreover, property domains and ranges are set to the classes gath-ering the resources referred in the property triples. Finally, at step three tentative names are composed for the newly designed classes using labels recovered from DBpedia. 4.1 Mining conceptual knowledge from LD In this step, the RDF data is converted to a formal context depicted as a binary table. As illustrated before, binary table has objects and attributes respectively in its rows and columns as well as binary values which indicate if an object has a specific attribute or not. Each resource in RDF data is an object in the binary table and the predicates of that resource are attributes in the table. For example, to map the RDF triple (Marc Chagall, live X  X n, Germany) to formal context the first member of RDF triple Marc Chagall is extracted as an object in the table and its predicate live X  X n is extracted as an attribute in the table. One can see that only the two first parts of a triple are used in formal context. The last member of any RDF triple can be a subject of a new triple to be considered in the table. For example, from the previous triple Germany is the first member of another triple in RDF data which is (Germany, has X  X el X  X ode, 49) , i.e., Germany is an object in the table but one cannot continue on since 49 is a literal and cannot not be a subject of any other triple in the RDF data, i.e., 49 is not an object in the binary table. Note that, if there exist resources without any predicate in dataset unlike literals they can be included in the formal context as the objects without any attributes.
 sulted lattice demonstrates the conceptual hierarchy of our data. Each concept contains similar objects (RDF individuals); in other words, objects with similar attributes (pred-icates). Hierarchy structure also shows the superconcept and subconcept relations be-tween the concepts. 4.2 Translating the concept lattice into RDFS At this step, four basic rules are applied to turn the lattice into an RDFS schema: resources) and bottom become RDFS classes. Unless the extent of the lattice bottom dataset), it is ignored as well.
 ubClassOf assertion is created for their respective RDFS translations whenever those exist (see above).
 regularity of the concept lattice. In fact, for any attribute m , there is a unique maximal concept that has m in its intent. The concept c = ( m 0 , m 00 ) , called the attribute concept of m , is such that for any other concept  X  c = ( A, B ) , m  X  B entails  X  c  X  K c . Now given an RDF property p , its domain is set to the class yielded by translation of the attribute concept of m ( p ) , the counterpart of p in the formal context. For example, the equivalent RDFS for the concept Person with three attributes has X  X ame and has X  X irthplace and live X  X n is a class with the domain of the three predicates has X  X ame and has X  X irthplace and live X  X n . Finally in the generated RDFS, there is no need to draw the same properties for the subclasses of Person such as Politician ( This also applies to the ranges). reflect the (predicate,object) pairs in the RDF triples. Thus, there is no equivalent of the above attribute concept to rely on. However, another structural property of the lattice comes into play here: In fact, for any object subset A  X  G , there is a unique minimal concept whose extent contains A , i.e., ( A 00 , A 0 ) . Now, for any property whose values are resources, we set its range to the class that translates the minimal concept comprising all property values (as objects) in its extent. For properties of literal values, ranges are not established. For example, both has X  X irthplace and live X  X n are related from one resource to another resource which are respectively the individuals of the concept Person and Country ; but, has X  X ame relates from one resource (individuals of the concept Person ) to a literal. Therefore, the equivalent RDFS, is a class Country (and Person ) with range (and domain) of only two predicates has X  X irthplace and live X  X n . 4.3 Naming RDFS classes The final stage of our method generates candidate names for the discovered classes. The basic idea behind our method is to bring in typing knowledge from DBpedia and to exploit its ontological structure. We posit that for each class, an appropriate name must be designed which represents every class member.
 Sources of naming information For each dataset resource, we query DBpedia re-sources that match it. There are alternative typing sources in DBpedia, the most obvi-ous being its ontology. Indeed the DBpedia classes shared by the members of a FCA-discovered concept can be a good starting point for naming. However, these classes might not be very specific and provide for a discriminant names in some cases. An-other source is the dc:description property of DBpedia resources, yet it requires some light-weight NLP to be applied as explained below. Finally, discriminant names might be obtained by appending some dataset-specific information to overly general class names, e.g., the properties shared by class members (from the underlying con-cept intent). In the next paragraph, we describe four techniques to compose names from external as well as internal information.
 Naming techniques We factor out shared DBpedia typing information in a much sim-ilar way FCA factors out the shared properties into concept intents. Thus, for a set of DBpedia resources that are recognized as matches for our dataset resources, we col-lect all the known types from the DBpedia ontology. Then, we intersect the resulting class lists and take the most specific type in the intersection. For instance, consider Lake Onega and Neva River as the resources to be grouped together and their concept should get a name based on the types they share in DBpedia. The types of any resource in DB-pedia are retrieved from the rdf:type predicate. Figure 2 shows the Dbpedia content for both Lake Onega and Neva River resources ( dbpedia-owl prefix indicates the classes belong to the OWL ontology of DBpedia). The intersection list of the types in our example is [ Place , BodyOfWater , NaturalPlace ] whereby BodyOfWater is the most specific one.
 relevant resources inside DBpedia even though they are recognized with different names in different context, e.g., Neva is used instead of the Neva River in some data. Luckily, DBpedia has a ready-made solution: For every such resource, the dbpedia-owl:wik iPageRedirects predicate lists known alternative names. Figure 3 shows the DB-pedia page for the Neva River with different names.
 retrieved by our basic naming technique. For instance, assume a resource represents a person and the rdf:type predicate only refers to the Person class. Assume also two FCA-output classes whose members are in fact famous musicians and famous writ-ers, respectively, but all we can retrieve from DBpedia is their common type Person . We have a clear naming conflict and a natural way out would the to retrieve the more specific information about their professions.
 DBpedia resources which represent people. The retrieval process is a bit more complex here as the content of the predicate is free text with few constraints, hence it requires some light-weight NLP. We illustrate it below through an example.
 class. The dc:description for Rihanna contains the  X  Singer , songwriter  X  string while for Facundo Cabral it is X  Canadian singer and songwriter  X . Notice that  X  and  X  and  X  ,  X  are phrase separators in the overall literal that are easy to spot. Moreover, in English multi-term phrases only the last word is of interest as it is the leading noun. Thus, with this heuristic rule we can easily guess the types of the resource, in particular, the profession-related ones for representations of famous people.
 and X  Songwriter  X  and so has John Bottomley (capitalization is ours). The intersection of the lists is again  X  Singer  X  and  X  Songwriter  X , hence, the assigned class name will be  X  Singer Songwriter  X .
 output identical names for a number of classes. In such cases, we artificially produce discriminant names by appending the name of a property to the one retrieved by the pre-vious techniques. The structural regularities of the lattice help again: due to the unique-ness of concept intents, there is at least one more attribute in an intent w.r.t. the intent of the parent concept. By choosing these differential properties, we ensure classes are named differently from their immediate super-classes, which, inductively, ensures the uniqueness of all names.
 be produced as they group resources of totally unrelated types. We keep their automated names and leave them to the analyst X  X  judgment. We conducted an experimental study on the validity of our approach. A single dataset form the WoD was chosen to run on our schema discovery tool. 5.1 Dataset We used a LD dataset about Russia which comprises 1159 triples. It covers data about Russia X  X  culture (theaters, museum, galleries, etc.), nature (rivers, lakes, parks, etc.), famous Russian people, entertainments and other features. The dataset contains both instance and schema level triples. Since our goal is to assess the discovery of schema level by only looking at the instance level, we hid the former part from our method. Thus we used only the 539 triples about individual resources as input to the FCA-based tool. The remainder was used as a ground truth in the evaluation for the final schema. 5.2 Experimental results The formal context of the Russia dataset has 92 objects and 47 attributes. There are 256 (object,attribute) pairs in the context. The concept lattice of the Russia dataset has 69 concepts whereas the top and the bottom ones are trivial.
 name the nodes in the graph. The version of DBpedia used for this research work is 3.8. The algorithm chooses the names for the classes according to the common information their objects share in DBpedia. Therefore, there is a reduction in the number of nodes compared to the concept lattice due to the same names applied to some nodes. In order to tune this reduction, the attribute concatenation technique (refer to Section 4.3 in the paper) has been applied for naming same nodes differently as much as possible. The attribute concatenation is used for the concepts with the same name as their par-ents: The differential attribute name is appended to the temporal name. For example, both concepts 7 and 23 got  X  PopulatedPlace  X . Since 7 is the parent of 23 a differential attribute, e.g., distance unit region is added, hence the name of 23 changes to  X  Popu-latedPlace with distance unit region  X . 5.3 Evaluation To evaluate our approach, we assess how well our method categorizes the dataset against the provided schema by the dataset. Notice that the naming process also indirectly effects our evaluation since applying the attribute concatenation technique which de-creases the number of concepts with the same names (i.e., overall increasing in the number of concepts) can drastically improve the clustering performance.
 Precision, Recall and F-Measure.
 To evaluate the approach against the provided schema by the dataset, only the relevant classes in the dataset are considered. Since in the provided schema there are also some classes without any instances (or instances with no properties), in the evaluation the relevant classes the provided schema stands for the classes which have instances and at least one of their instances is used to construct the concept lattice, i.e., the instances with properties.
 Recall is a measure which calculates the number of the relevant classes extracted from the dataset: are extracted to construct the resulted RDFS graph is 36. Among all of the discovered classes only 27 are relevant. Therefore, the value is 27 / 35.
 Precision shows the number of extracted classes from the dataset which are relevant: The exact value is 27 / 36.
 By applying the attribute concatenation technique the number of relevant classes in-creases from 17 to 27. The table below shows the improvement in the Precision, Recall and F-Measure after applying that technique. Figure 4 shows the final RDFS graph. 5.4 Discussion A comparison between the class names we produces and the original ones is provided below.
 by considering locations. For example, the approach created both classes Museum and Art Museums And Galleries In Russia whereas the provided schema only contains Mu-seum . Another example covers people with different professions. Our approach created both classes Novelist and Writer whereas initially we only had Author . It seems the automated approach provides more accurate names although there are also some defi-ciency compared to the original schema. Indeed, unnamed classes remain in our case: For example, the concept 13 comprises two objects Russian Winter Folk Festival and the Festival of the North . Since no information is retrieved from DBpedia for those objects, no name can be created. Another example is concept 16 with ice skating . The resource should be typed sport but the information is missing from DBpedia (search with ice skating is fruitless). The corresponding classes in the original schema are Fes-tival and Sport , respectively.
 general view, it would be reasonable to ignore the concepts with too few instances. Depending on the size of dataset one can decide about a threshold. We presented here a method for extracting exploitable schema knowledge from datasets on the WoD. It reveals the implicit conceptual structure in RDF data by applying con-cept analysis to a straightforward representation of the linked data as a resource-to-property cross-table. The method then assigns names to discovered RDFS classes that reflect both known DBpedia types and shared properties of the member resources. The approach underwent a preliminary experimental evaluation whose results indicate it performs well.
 of variable sizes and provenance. In a future refinement of the approach, combining a range of external resources, e.g., WordNet or Wikipedia, for class naming will be investigated. Another avenue consists in feeding in property values into the conceptual analysis: For instance, links between resources could be mined to yield richer class descriptions, e.g., by means of dedicated mining frameworks [15].

