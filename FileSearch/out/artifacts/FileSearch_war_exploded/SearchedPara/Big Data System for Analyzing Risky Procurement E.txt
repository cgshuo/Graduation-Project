 An accredited biennial 2014 study by the Association of Cer-tified Fraud Examiners claims that on average 5% of a com-pany X  X  revenue is lost because of unchecked fraud every year. The reason for such heavy losses are that it takes around 18 months for a fraud to be caught and audits catch only 3% of the actual fraud. This begs the need for better tools and processes to be able to quickly and cheaply identify potential malefactors. In this paper, we describe a robust tool to iden-tify procurement related fraud/risk, though the general de-sign and the analytical components could be adapted to de-tecting fraud in other domains. Besides analyzing standard transactional data, our solution analyzes multiple public and private data sources leading to wider coverage of fraud types than what generally exists in the marketplace. Moreover, our approach is more principled in the sense that the learn-ing component, which is based on investigation feedback has formal guarantees. Though such a tool is ever evolving, a deployment of this tool over the past 12 months has found many interesting cases from compliance risk and fraud point of view across more than 150 countries and 65000+ vendors, increasing the number of true positives found by over 80% compared with other state-of-the-art tools that the domain experts were previously using.
 H.2.8 [ Knowledge Management ]: Data Mining Algorithms c  X  in a wide variety of domains, we focus our attention on iden-tifying procurement related risk or fraud. In large companies there are procurement groups, which buy goods and services from tens of thousands of vendors/suppliers all across the globe every year amounting to billions of dollars of spend. Given the scale of these operations, it is hard to enforce airtight compliance procedures in the interest of time and money, which makes it a breeding ground for nefarious ac-tivity. Here are a couple of real examples of procurement fraud. An employee of a large company bought a few USB drives every month at the company X  X  expense over a couple of years and was selling them in the black market. Since, USB drives are inexpensive they were below the spend clip levels set by the company per purchase order and thus it went undetected for years. Another example was that of a company employee creating a company on his spouse X  X  maiden name and then routing business to that company.
Studying hundreds of such cases of procurement fraud in the last few years, we created a taxonomy ellucidating the broad categories to which these different cases belonged to. This taxonomy is seen in figure 1. The taxonomy, we be-lieve, gives more structure to the problem than just enu-merating individual cases. Moreover, it assists us in better understanding the different types of fraud as well as the dis-tribution of the cases across these categories. At a high level there are only two entities namely, company employees and vendors that the company buys from. Hence, fraud occurs through actions of any of the individual entities or through their interactions. In our review of prior fraudulent cases, we found that fraud based on collusion between employee and vendor had the highest occurance. Collusion essentially is secret or illegal cooperation or conspiracy, especially in order to cheat or deceive others. Relative to procurement, collu-sion involves at least two parties making an arrangement or agreement which provides at least one of the parties an unfair and illegal competitive advantage.
 There are a few products that quantify procurement fraud. Based on our study they [3, 9] mostly tackle just the leftmost column in figure 1, that is vendor fraud. Moreover, they are mainly based on business rules with mininmal analytics. Others are based on supervised learning [2] and thus require labelled data, which is often unavalaible in our setting. A few consulting firms also have products mainly relating to text analytics that scan emails and identify employees based on high risk words or phrases. Certain toolboxes in SPSS can identify aliasses [11] of a person or direct relationships [12] such as husband (employee)  X  wife (vendor), but not multihop relationships such as husband (employee)  X  wife  X  cousin(vendor) in an efficient manner. There are other tools [8], which are mainly used for investigative purposes but not for detection. All of these tools cover small portions of the taxonomy but none of them is even close to being comprehensive.

Our system is the most comprehensive that we know of, since we model collusion detection and all the different types of fraud, not being limited to only certain restricted types. As we will see later, to accomplish this we have the ability to analyze various public and private data sources including social network data to detect collusion. Moreover, our ap-proach is more principled in the sense that our online updat-ing scheme based on investigation feedback has theoretical guarantees, with the goal of reducing false positives and at the same time maintaining interpretability.

Besides, the proprietary data sources we access also the following public data:
There are multiple sources that we use which contain un-structured data. In fact, even the standard transactional data which has invoice and purchase order (PO) informa-tion, contains text fields which can serve as a rich source of information. In our system we mine this comments field to check if the work was not authorized by the company by matching certain keywords and phrases. We also try to extract the invoice date and compare it with the PO create date to verify that they occurred in the correct chronological order. Sometimes, no PO is created a priori and it is created as an after thought, which is not acceptable. We can also check if there are indications that the work started prior to PO creation or that the actual commodity code is different from what has been entered into the appropriate structured field indicating category.

Other unstructured sources include risk reports, which can be mined to get a feel for the political situation in a certain country or geography. Employee emails can be mined to see if high risk word or phrases have been used in interaction with vendors indicating possible malicious activity.
Anomalous events are a combination of expert provided business rules and analytical techniques such as statistical 9
After acquiring the appropriate approvals. We mentioned before that we do not have labeled data. Hence, we cannot train a supervised model to rank entities based on a fraud score. To limit the number of false positives we come up with an initial weighting signifying the impor-tance of the different events using a combination of domain expertise and the frequency of occurrence of the different events. In particular, we derive a weight in [0 , 1], where a higher weight indicates that the event is more important in identifying fraud. These weights are based on evaluation of the events with experts and us devaluing events that occur frequently based on our analysis of real data.

In the design, we insist on weights of individual events being normalized i.e., between [0 , 1], so that they are in-terpretable. The weight of an event can be viewed as the probability that a fraud has occurred given that the partic-ular event was triggered. We believe, such semantics make it easier for the expert not only to be able to interpret the importance of events available in the system, but also in de-termining the relative importance of new events that may be added in the future. This is not the case if the events have unbounded weights, as is witnessed in some current tools. Confidences of events are complimentary to their weights. While weights indicate the importance of an event in detect-ing fraud, confidences signify our belief in the occurrence of the event. For example, if we consider the vendor requestor monopoly event, it either occurs or doesn X  X  occur. If the event is triggered our confidence would be 1 else it would be 0. As we can see here, the confidence is different from the weight, which is a fixed number irrespective of if the event occurs or not. We use both of these indicators, that is, con-fidences and weights to determine the probability of fraud by an entity, which we will visit in detail in subsection 2.1.7.
Confidences for most events are either 1 or 0 depending on if they are triggered or not respectively. However, they are a real number between [0 , 1] for some events. A good example is the country corruption event. We calculate the confidence for this event as follows: c CPI = 100  X  CPI 100 . CPI lies between [0 , 100], where a higher CPI indicates lesser risk. However, in our design we want the confidences to lie in [0 , 1], where a higher value indicates a stronger signal for the event.
We have described events on transactional data or RFx data that indicate the possibility of collusion. Analyzing so-cial network data could significantly enhance our confidence in such findings. As mentioned before, there are companies which sell information about individuals regarding where all and with whom they lived in the last decade. In addition, would be determined by the frequency of the communication between the various entities and checking the content for high risk words or phrases.
From experience with dealing with domain experts across different industries, we believe that for them to gain faith in the system it is necessary to have high precision even if it is at the expense of some recall. In other words, many false positives can immediately inhibit interest amongst practi-tioners and experts for such a tool. Thus, the unsupervised component is of relatively low importance in the initial de-ployments of this application.

Nevertheless, methods from infrequent pattern mining [7] could be of considerable significance here, in identifying low support but high recall sequences in the data. These meth-ods are of interest in anti-terrorism, where one monitor-ing suspicious money movements through different bank ac-counts.

If the patterns found by these methods are interesting they could lead to new rules that need to be checked in the future. This capability should not be ignored as humans are always adapting and hence, it is important to uncover suspicious behaviors not known to be risky by the experts.
As we have discussed in previous subsections, each event i is associated with a weight w i  X  [0 , 1] and given an entity E we have a corresponding confidence c E i  X  [0 , 1] of occurrence. Thus, the probability that an entity is fraudulent/risky is 1 minus the probability that it is not fraudulent. The prob-ability that it isn X  X  fraudulent is the probability that none of events that are triggered for it are fraudulent. Formally, given a total number of n possible events I = { 1 ,...,n } the probability that entity E is fraudulent is given by, where for any event i , w i c E i is the probability that entity E is fraudulent given that the event was triggered with confi-dence c E i . Notice that for events that are not triggered for entity E , the corresponding confidences c E i would be 0, thus not contributing to the overall fraud probability.

We can now rank entities in descending order based on our score namely, the fraud probability P E f . Entities higher up in the list would be potentially of more interest than those lower down. Information regarding entities of interest can then be passed to other investigative tools. Results of the investigation can be entered into our tool as feedback or can lead to updating of the events as shown in figure 2.
It is clear from the formulation in equation 1 that we can score entities with whatever universe of events we have at a particular stage of the system development. Hence, even without the social networking and unsupervised learn-ing component we can still obtain a ranked list. This is de-picted in figure 2 by the thin arrow connecting the weights assignment block to the ranked list block, thus circumvent-ing the blocks described in the previous two subsections.
On presenting the user with a ranked list of possibly fraud-ulent candidates, the user can further investigate entities If we set g i = ln ( p i ) and b = ln (2(1  X  y )) we can rewrite the above equation as, The function in equation 5 is not convex. For convex loss functions however, it has been shown in [14] that online gradient descent with projections onto a convex set, which is [0 , 1] in our setting, achieves low regret. For this result to be applicable to us, we need to derive a convex approximation of our loss function. We accomplish this by linearizing the portion in equation 5 after the negative sign, which makes the following new function a convex upper bound of L , Taking partial derivatives of L u with respect to (w.r.t.) each of the non-zero g i  X  X  and setting each such derivative to zero, leads to the update procedure described in algorithm 2. The weights are then projected onto [0 , 1], where I ( . ) is an indi-cator function, which is 1 when the parametrized condition is true and is 0 otherwise. Thus, our solution achieves low regret w.r.t. L u , which is a convex upper bound of L .  X  in algorithm 2 is the learning rate. We set a signif-icantly higher learning rate for fraudulent cases than for non-fraudulent ones, since in the real world most cases are likely to be non-fraudulent. Given this, we do not want our weights to converge to 0 quickly when feedback on non-fraudulent cases is provided. At the same time we want to average risk. complements the central data processing system for ana-lyzing massive amounts of data. IBM InfoSphere BigIn-sights is based on an open source Apache Hadoop platform, which includes social media accelerators and text analy-sis toolkits that can be leveraged to process large struc-tured/unstructured data sources such as social media, email, etc., using low cost commodity hardware. IBM InfoSphere Streams can be used to capture and process data in near real-time.

Finally, the risk analytics engine contains a library of anomalous events and analytic modules based on IBM SPSS, Python and Java that work in a co-ordinated fashion to score and rank risky entities.
Our first client for this system is IBM itself. The reasons for this are at least three-fold: First, if IBM itself is not using the system why would an external client be interested. Second, using IBM as a test bed we can enhance the system by removing kinks and testing it on large amounts of data consisting of billions of dollars of spend with hundreds of thousands of employees and tens of thousands of vendors. Third, a successful deployment within IBM will result in the relevant organizations providing support for the system in front of external clients. Saying this we have already demoed the system to potential external clients with positive feedback.

Our current deployment has been for IBM corporate com-prising of experts from Accounts Payable (AP), and Policies and Practices (P&amp;P) . The former tries to identify fraudu-lent entities, while the latter tries to identify entities posing a significant compliance risk. Based on their experience us-ing the tool over the past 12 months, we have received the following feedback: South America, Africa, Asia, Mexico and Eastern Europe. This aggregated view can provide a guideline of regions of the world to focus on.

In figures 5 and 6, we see a more detailed view of two ven-dors that potentially present high risk and were identified by our tool. In the summary tab in both these figures, we see the (anonymized) vendor name followed by more vendor specific information in the next four columns. The No. of Events column, denotes the number of events triggered for this vendor. The last column is the risk score (x100) com-puted by our method. The preceding four columns are risk scores based on a partition of the universal list of events. Essentially, they act as thumbnails providing a quick sneak peek into where the problem lies for the particular entity. So for example in figure 5, most of the risk for that vendor is associated with its invoice/transactional data. In addition, there is also a collusion risk. Analogously, for the vendor in figure 6 all his risk can be attributed to non-compliant and potentially fraudulent transactions. More details about the particular events that were triggered leading up to these risk scores can be found in the Events tab below 2 . The tool 9 2 The risk score for each event is its weight multiplied by confi-dence (x100). and deploy it with other internal and external clients. The idea is to have a universal list of events with default initial weights that are customizable by the experts in the partic-ular organization. Therefore, every new organization/client will have their own independent instantiation of our system. An effective system such as this will potentially not only identify fraud but will also serve as a deterrent for entities that are currently committing fraud or those that are con-sidering of doing it in the future.

Deploying such a system has many challenges. One of the main challenges is being able to access sensitive private data. For example, some of our events require accessing em-ployee bank account data, which is highly sensitive informa-tion. We tackle this problem by letting HR run the specific events in their firewall and returning only the result. Af-terall, our system only needs to know if a particular event was triggered for an entity or not. For instance consider the event, where we check to see if a vendor bank account num-ber matches an employee bank account number. This would require knowing the bank account numbers of both these entities. However, we could send HR a list of vendor bank accounts and they could match them against the employee database and return to us the list of vendors that matched. This completely absolves them from sending us the employee bank account numbers. An analogous strategy can be used for other events that require sensitive data, where only the list of entities for whom the event was triggered is returned to us by the responsible party.

Another challenge is the type of data that the client is ready to subscribe to. The client may not want to buy or pay for accessing certain paid data sources that may carry useful signals. In certain cases, a particular geography may have restrictions on the public data that may be used incriminate anyone. For example, in Europe using publicly available social data to accuse an individual is strongly discouraged.
Given these restrictions in regards to accessing different data sources, which could lead us to potentially miss im-portant signals, we can either settle with what we have or try to be more creative. From an analytics perspective a possible way of mitigating the impact of the absence of these data sources is to implement an extrapolated scoring scheme. What we mean by this is that using available data from existing clients (viz. IBM) we can figure out through techniques such as association rule mining the likelihood of certain combination of events to co-occur. Based on these insights we can score entities of a new client with their lim-ited data by seeing the events that have been triggered for each entity and appending those with events that are likely to be triggered if in fact they had the data. In essence, we are extrapolating the score based on our knowledge of other similar clients. This extension could of course be erroneous but its probably our best estimate given the missing data sources.

Another extension to the system would be to come up with joint weights/probabilities for certain groups of events. Of course we cannot consider all possible groups as this list is exponential in the number of events. However, certain groups of events being simultaneously triggered may have more information than multiplying their importances as if they were independent. An alternate way of dealing with this if the groups are disjoint, is to combine the events in each group into a single corresponding composite event with an associated weight, in which case, the machinery described
