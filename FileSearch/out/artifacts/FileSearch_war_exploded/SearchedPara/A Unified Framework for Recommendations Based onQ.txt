 } Social network systems such as FaceBook and YouTube have played a significant role in capturing both explicit and im-plicit user preferences for different items in the form of rat-ings and tags. This forms a quaternary relationship among users, items, tags and ratings. Existing systems have uti-lized only ternary relationships such as users-items-ratings, or users-items-tags to derive their recommendations. In this paper, we show that ternary relationships are insufficient to provide accurate recommendations. Instead, we model the quaternary relationship among users, items, tags and ratings as a 4-order tensor and cast the recommendation problem as a multi-way latent semantic analysis problem. A unified framework for user recommendation, item recom-mendation, tag recommendation and item rating prediction is proposed. The results of extensive experiments performed on a real world dataset demonstrate that our unified frame-work outperforms the state-of-the-art techniques in all the four recommendation tasks.
 H.3.3 [ Information Search and Retrieval ]: [information filtering] Algorithms, Experimentation, Measurement, Performance Tensor factorization, Recommendation, Social tags, Person-alization, Collaborative Tagging
The amount of information on the Web is increasing at a lightning pace. In order to adequately cope with this in-formation overload, recommendation systems are needed to bring the relevant resources to the attention of the users automatically. Recommendation systems are typically clas-sified according to the type of tasks they are intended for, which include: 1. User recommendation -Here the task is to identify 2. Item recommendation -Instead of stopping at identi-3. Tag recommendation -This task has emerged recently 4. Item rating prediction -Here, the task goes beyond
Till now, most, if not all, recommendation systems uti-lize only ternary relationships in generating their recommen-dations. The collaborative filtering-based recommendation systems [8, 1, 12, 18] typically make use of the users-rating-items relationship to group users based on their ratings on h ttp://www.amazon.com http://www.facebook.com http://www.youtube.com http://www.flickr.com http://www.netflix.com items, whereas the tag-based recommendation systems uti-l ize the users-tags-items relationship to perform the various tasks [20, 19, 15]. We argue that recommendations based on ternary relationships are not accurate as they would have missed out important associations.
 Table 1: Ternary relations among user, rating and item
Let us consider the ternary relationship users-rating-item s in Table 1. From this table, we conclude that users U 1 , U , U 4 have common interests with U 3 since they all like the movie  X  F orrest Gump  X . Hence, these users will be highlighted to U 3 and the movies  X  BeautifulMind  X  and  X  Groundhog Day  X  will be recommended to U 3 because U 1 and U 2 also like  X  Beautiful Mind  X  and  X  Groundhog Day  X . Note that  X  T oy Story  X  is not recommended to U 3 since U dislikes the movie.
 Table 2: Ternary relations among user, tags, and item Table 2 shows the ternary relationship users-tags-items. T he users U 2 , U 4 and U 5 are said to have common interests with U 3 because they all tag the movie  X  F orrest Gump  X  as  X  comedy  X . Thus, U 2 , U 4 and U 5 will be highlighted to U At the same time, the movies  X  Groundhog Day  X  and  X  T oy story  X  will be recommended to U 3 since U 2 and U 4 also tag  X  Groundhog Day  X  and  X  T oy story  X  as  X  comedy  X . In addi-tion, suppose U 3 wants to tag the item  X  Groundhog Day  X , the set of tags {  X  comedy  X  ,  X  excellent  X  ,  X  over rated  X  } will be recommended to him/her as they have been used to tag  X  Groundhog Day  X  previously.

Now, instead of the two ternary relationships, we have the quaternary relationships among users, tags, ratings, and items as shown in Table 3. We note that only users U 2 Table 3: Quaternary relations among users, tags, ratings and items and U 4 w ould be highlighted to U 3 and the only movie rec-ommended to U 3 is  X  Groundhog Day  X . This is because even though U 1 is highlighted under the ternary relation-ship users-ratings-items, we realize from the quaternary re-lationship that U 1 likes  X  F orrest Gump  X  as a psychology movie, whereas U 3 likes the movie  X  F orrest Gump  X  as a comedy. Hence, U 1 does not share a common interest with U . As a result, U 1  X  X  item  X  Beautiful Mind  X  is also not recommended to U 3 .
 Similarly, under the ternary relationship users-tags-items, U 5 is highlighted to U 3 and the movie  X  T oy Story  X  is recom-mended to U 3 . However, the quaternary relationship in Ta-ble 3 shows that U 5 dislikes the movie  X  F orrest Gump  X  al-though he/she tags it with  X  comedy  X . Since U 3 and U 5 have different opinions on  X  F orrestGump  X  even though they both use the tag  X  comedy  X , U 5 should not be considered as having common interests with U 3 . At the same time, we observe that although U 4 tags  X  T oy Story  X  as  X  comedy  X , he/she does not like it. Hence  X  T oy Story  X  should not be recom-mended to U 3 .

For tag recommendation, suppose U 3 wants to tag  X  Ground -hog Day  X , a system based on the quaternary relationship would recommend the set of tags {  X  comedy  X  ,  X  excellent  X  } . Note that the tag  X  X  overrated  X , which is one of the tags recommended based on the ternary relationship users-tags-items, will not be recommended to U 3 . This is because we are able to infer from the quaternary relationship that U likes the movie  X  Groundhog Day  X  as it is a comedy. Since the tag  X  overrated  X  is associated with the rating  X  dislike  X , it is not a good tag to recommend for U 3 .

The above examples clearly illustrates the need to con-sider the quaternary relationship among users, tags, ratings, and items together. The quaternary relationships can reveal semantics that cannot be obtained otherwise. This is rein-forced by the following observations: 1. Users may use the same tag for an item but have differ-2. Items may have multiple tags indicating their different 3. Some tags may carry implicit semantics that can reveal
In order to capture the quaternary relationship among users, items, tags and ratings, we propose a model based on the 4-order tensor. We apply the Higher-Order Singular Value Decomposition (HOSVD) [11] in the 4-order tensor to reveal the latent semantic associations among users, items, tags and rating. With this model, we design a unified frame-work to perform item rating prediction as well as user, item and tag recommendations. We carry out experments on a real world dataset to demonstrate the effectiveness of our proposed approach. To the best of our knowledge, this is a first work to explore the use of the quaternary relation-ship among user, items, tags and ratings for recommenda-tion tasks.

The rest of this paper is organized as follows. Section 2 provides the background on tensor operation and approxi-mation. Section 3 presents the algorithm for quaternary se-mantic analysis. Section 4 describes the unified framework for user, item and tag recommendations as well as item rat-ing prediction. Section 5 presents the experimental results. Related work is given in Section 6, and we conclude the paper in Section 7.
Tensor algebra and multilinear analysis have been applied successfully in many domains [9, 11]. In this section, we review the concepts and terminologies used in the paper. A tensor is a multidimensional array. An N-order tensor dimensions I 1 , I 2 ,  X   X   X  I N .

For example, the corresponding 3-order tensor A for the example dataset in Table 4 is:
Definition 1. The matrix unfolding of an N-order ten-tained by keeping the index d fi xed while varying the other indices.

The unfolding of our example 3-order tensor A along each dimension is: Note that the definition of the matrix unfolding involves the tensor dimensions I 1 , I 2 , I 3 in a cyclic way. Hence, for the unfolding of dimension I c  X  I a I b , the index I b varies more slowly than I a .
 Definition 2. The n-mode product of a tensor A = R is a ( I 1  X  I 2  X   X   X  I n  X  1  X  J n  X  I n +1  X   X   X   X  I N entries are given by
For example, the 1-mode product of a tensor A = R 2  X  3  X  4 by a matrix U = R 5  X  2 , denoted as A  X  1 U is an 5  X  3  X  4 tensor in which the entries are given by
The Higher-Order Singular Value Decomposition (HOSVD) is a generalization of the Singular Value Decomposition (SVD) to higher-order tensors [11] and can be written as n-mode product: where U ( n ) contain the orthonormal vectors (or n-mode sin-gular vectors) spanning the column space of the A ( n ) (n-mode matrix unfolding of A ). S is the core tensor and has the property of all orthogonality.
 Consider our example tensor A and its matrix unfolding A (1) . We perform SVD on A (1) and obtain the resultant left singular matrix:
With this, the core tensor S  X  R 3  X  3  X  3 can be constructed as described in [11]. We have S = A  X  1 ( U (1) ) T  X  2 ( U
Definition 3. The n-rank of tensor denoted by R N = rank n ( A ), is the dimension of the vector space spanned by the n-mode matrix We denote the rank of tensor A as rank ( A ) = ( rank 1 ( A )  X   X   X  , rank n ( A ))
Definition 4. Given a tensor A = R I 1  X  X  X  X  X  I N , the RANK  X  ( R 1  X   X   X  , R N ) approximation  X  A is defined as min B  X  S , S = { B || rank ( B )  X  ( R 1  X   X   X  , R N ) } where || A  X  B || least-square cost. 6
Suppose we want to get the RANK-(2,3,3) approximation, we first retain the first c i column of matrix U ( i ) at mode i (1  X  i  X  3) as follows: t he square frobenius norm is defined as || A || 2 F P We can now construct the approximate core tensor  X  S  X  R Finally, we obtain the RANK-(2,3,3) approximation  X  A =  X  where || A  X   X  A || 2 F =0.618 which is minimized.
The main idea behind the quaternary semantic analy-sis is to capture the underlying relationships among users-tags-items-ratings. Suppose we have a list of quadruples &lt; u,t,r,v &gt; denoting that a user u will provide tag t to a movie v and give the rating r if he has watched v before. We first model this list of quadruples as a 4-order tensor A  X  U  X  T  X  R  X  V , where U is the set of all users, V the set of all items/resources, T the set of all tags and R the set of ratings. An entry A ( u, t, r, v ) has a value 1 if the quadruple &lt; u,t,r,v &gt; exists, otherwise it has a value of 0.
We reduce the rank of the original tensor to minimze the effect of noise on the underlying population and reduce spareness. This is achieved by approximating the tensor A to a lower rank tensor. Given the dimensions of users, tags, ratings and items, namely, c 1 , c 2 , c 3 , c 4 , we want to obtain square frobenius norm defined as: is minimized.

In our experiments, we set c 1 , c 2 , c 3 , c 4 to preserve 70%, 90%, 80%, 90% of the original tensor information in each dimension respectively (see Section 5.6).
A lgorithm 1 shows the details for approximating a ten-sor. We first apply SVD on the four matrix unfoldings A
In order to obtain the left matrix of the SVD, we first define a matrix C i as follows:
Since each  X  U ( i ) and  X  V ( i ) are orthogonal and each S diagonal, we substitute (1) into (2):
Therefore, each required U ( i ) can be computed by diago-nalizing each C i and taking its eigenvectors (Lines 3-4). Algorithm 1 Q uaternary Semantic Analysis Input: Output: 1: Initialization: From the quadruple (users, items tag 2: Calculate the matrix unfolding A (1) , A (2) , A (3) , and 3: Construct the variance matrix C i = A ( i ) A T ( i ) for each 4: Compute U ( i ) by diagonalizing C i , 1  X  i  X  4 5: Remove the least significant rows | U | X  c 1 , | V | X  c 6: Calculate the approximate core tensor  X  S as follows: 7: Approximate the original tensor by:
Consider our example quaternary relations in Table 3. We i nitialize the the weights of the quadruples to 1, as shown in Table 5. A 4-order tensor A  X  R 5  X  4  X  4  X  2 can be con-structed from this table. For example, the first quadruple &lt; U 1 , psychology, like, F orrestGump &gt; will correspond to the entry A (1 , 1 , 1 , 1)=1.
 For each matrix unfolding A ( i ) , 1  X  i  X  4, we compute U User Tag Rating Item Val
We maintain only a subset of the original dimensions in each of the four modes (Line 5). Here, we choose c 1 = 4 , c 4 , c 3 = 4 , c 4 = 2. The resulting  X  U ( i ) are shown as follows:
Lines 6-7 computes the approximate tensor  X  A . The final weights of the quadruples are shown in Table 6. We observe t hat the algorithm has added the following four quadruples: &lt;U 3 , comedy , like , Groundhog Day &gt; &lt;U 3 , excellent , like , Groundhog Day &gt; &lt;U 3 , comedy , dislike , Toy story &gt; &lt;U 3 , overrated , dislike , Toy story &gt;
Note that user U 3 has not used the tag  X  excellent  X  previ-ously, and there is no indication on which item should be rec-ommend to U 3 based on the tags  X  comedy  X  and  X  excellent  X  in the original table (recall Table 5). However, the newly added quadruples indicate that the movie  X  Groundhog Day  X  is associated with user U 3 and tags  X  comedy  X  and  X  excellent  X  with a weight of 0.25. Hence, the movie  X  Groundhog Day  X  will be recommended to U 3 .
 User Tag Rating Item Val
We observe that latent associations such as the newly a dded quadruples in Table 6 may not be found if the ten-sor data is sparse, that is, most of the entries are 0. This problem is particularly acute as we are working with the quaternary relationship. We overcome this problem by ap-plying a smoothing technique to Line 1 in Algorithm 1. The smoothing method is based on the similarity between items. For each user &lt; u, r, t &gt; in the tensor, let S 1 be the set of items that are rated and tagged by user u , and S 2 = V -S 1 where V is the set of all items/resources. We as-sign &lt; u, r, t, v j &gt; with the overall similarly between item v  X  S 2 and the items in S 1 .

The overall similarity between item v j  X  S 2 and the items in S 1 can be calculated as follows: where sim ( v i , v j ) is the cosine similarity between items v and v j , assuming the items are represented by vectors of word weights.

The most time consuming steps in Algorithm 1 are the di-agonalization of the unfolding matrices and the computation of the approximate core tensor. For real world applications involving large tensors, the work in [9] utilizes parallel archi-tectures to optimize memory usage and reduce computation time. Note that the approximate tensor needs to be up-dated when we have new users, items, or tags. We adopt the methods described in [20] to incrementally update the approximate tensor.
In this section, we describe how the proposed quaternary semantic analysis can provide a unified framework for the 4 common tasks: item recommendation, item rating predic-tion, user recommendation and tag recommendation.
We conduct experiments to evaluate the effectiveness of our proposed framework for item recommendation, item rat-ing prediction and tag recommendation. We implemented our framework in MATLAB and run the experiments on a 2.33Ghz Intel Core 2 CPU with 4GB RAM, running Win-dows 7-64 bit.
W e use the publicly available MovieLens dataset available at http : //www.grouplens.org/node/ 73. This dataset com-prises of two files. The first file contains users X  tags on differ-ent movies. The second file contains users X  ratings on differ-ent movies on a scale of 1 to 5, with 1 being bad and 5 being excellent. By joining these two files over user and movie, we obtain the quadruples &lt; user, movie, tag, rating &gt; . We have a total of 24563 quadruples with 2,026 users, 5,088 movies, and 9,078 tags. We pre-process these quadruples to generate a subset such that each user, movie and tag oc-cur at least 10 times in the dataset. The resulting dataset has 11122 tuples with 201 users, 501 movies, and 404 tags. Table 7 shows the statistics of the users X  ratings after pre-processing.

W e first evaluate the effectiveness of the proposed quater-nary analysis model ( QSA ) for item recommendation. We compare our method with the following existing methods: 1. UPCC [16]. This method uses the Pearson X  X  Correla-2. IPCC [18]. This method uses the Pearson X  X  Correla-3. Probabilistic Matrix Factorization (PMF) [17]. 4. Ternary Semantic Analysis (TSA) [20]. This method
We use the Hit Ratio [8] as the metric to evaluate the effectiveness of the various item recommendation methods. For each user u  X  U , we randomly choose one item i that has a rating of 5 and withhold the quadruples involving u and i . Then we run the 5 methods to generate the top N items recommended for this user. If the item i is among the top N recommended items, then we say that a hit has occurred. The hit ratio of a method is given by: F igure 1 shows the hit ratio of the 5 methods as we vary N. We observe that the proposed QSA method has a higher hit ratio compared to the other methods. In particular, QSA outperforms TSA, PMF, IPCC and UPCC by more than 23%, 50%, 60% and 80% respectively. This is because QSA can find more accurate latent associations using qua-ternary relationships compared to ternary relationships of either users-items-ratings or users-items-tags. UPCC and IPCC find similar users or items (neighbors) by calculat-ing Pearson correlation coefficient. If a user has few ratings for items, then it will be difficult for UPCC and IPCC to find neighbors. The PMF approach suffers from the data sparsity problem and is unable to extract sufficient feature information. On the other hand, TSA captures user X  X  inter-est (topic) by using tag, but does not judge how much he likes these topics (rating). By utilizing quaternary relations, the proposed QSA overcomes the data sparsity problem and captures both users X  opinions and interests with the rating and tagging information. Figure 1: Hit ratio for Top N item recommendation
In order to evaluate the effectiveness of QSA in recom-mending interesting users, we determine the similarity of items among the recommended top N users [20] since users with shared interests are more likely to tag and rate similar items. We compute the item similarity as the average of the cosine similarity of their TF  X  IDF tag term vector [20] and cosine similarity of the rating vector [18].
 Let NB u be the set of top N users recommended to u . The intra-neighborhood similarity is given by the average cosine similarity of all items for the users in NB u : where I u and I w are the sets of items tags by users u and w .
Let Random u be the set of N users randomly chosen from the set of users U  X  { u } . We can determine the inter-neighborhood similarity as follows: InterSim ( Random u ) = where I u and I w are the sets of items tags by users u and w respectively. Table 8: Comparison of intra-and inter-similarity b etween QSA and TSA Table 8 shows the intra-similarity and inter-similarity of Q SA and TSA. We observe that the average intra-similarity is consistently higher than the average inter-similarity for both QSA and TSA. In particular, QSA outperforms TSA in intra-similarity indicating that more relevant users are found by QSA. Table 8 shows that the average of intra-similarity for QSA is about 0.15, while the average inter-similarity is only 0.065.
For the task of tag recommendation, we evaluate our algo-rithm QSA against the two state-of-the-art methods: TSA [20] and RTF [15]. For each user u  X  U , we randomly choose one item i and remove all quadruples involving u and i from the dataset. Then we run the 3 methods to generate the top N tags recommended for this user.

We use the standard recall and precision measures to eval-uate the results: where T u,i is the set of tags used by user u on item i .
Figures 2(a) and 2(b) show the precision and recall of the 3 methods for varying values of N. It is clear that QSA is able to achieve a higher recall and precision compared to the other two methods.
In this set of experiments, we evaluate the predictive per-formance of QSA for item ratings. We compare QSA with UPCC, IPCC and PMF only because TSA is based on user-item-tag relationship and does not use rating information.
We use the Mean Absolute Error (MAE) and Coverage as the evaluation metrics [1]. Coverage refers to the fraction of items that an algorithm is able to give a predicted rating. The MAE is given by: w here r u,i is the rating given by user u for item i ,  X  r predicted rating and D is the size of the testing dataset.
We use 80% of the dataset as training set and 20% as the testing set, and compute the MAE and coverage for differ-ent methods. The five-fold cross validation results are shown in Table 9. We observe that the coverage is not 100% for UPCC and IPCC, which confirms that these two methods are unable to deal with the problem of data sparsity effec-tively. On the other hand, QSA alleviates the data sparsity F igure 2: Precision and recall for tag recommenda-tion problem with the help of tagging information, thus achieving 100% coverage with a lower MAE.

To analyze the statistical significance of the results, we MAE values obtained using methods A and B respectively. Let d i = a i  X  b i and  X  d be the average value of d i , i = 1 , 2 ,  X   X   X  , n . We set the null hypothesis as  X  d = 0. The p-value is computed using the t-statistics: w here s is the standard deviation of d . A p-value that is less than 0 . 01 indicates the existence of statistically signifi-cant evidence against the null hypothesis. We compare the results of QSA against UPCC, IPCC and PMF and obtain the p-values of 3.52E-06, 4.02E-06 and 1.70E-03 respectively. These results indicate that the improvement in the MAE val-ues for QSA is statistically significant compared to UPCC, IPCC and PMF.
We also conduct experiments to study the effect of core tensor dimensions c 1 , c 2 , c 3 , and c 4 on the performance of our algorithm QSA. We first vary each dimension to find the settings that give the best performance. This occurs when c 1 = 45 , c 2 = 125 , c 3 = 165 , c 4 = 4.

For ease of visualization, we vary two of the four dimen-sions and keep the other two dimensions fixed at their opti-mal values. The results are shown in Figure 3. Figure 3(a) shows the effect on hit ratio as we vary c 1 and c 2 while keeping c 3 fixed at 165 and c 4 fixed at 4. Figure 3(b) shows the effect on hit ratio as we vary c 1 and c 3 while keeping c 2 fixed at 125 and c 4 fixed at 4. Figure 3(c) shows that results of varying c 2 and c 3 while c 1 and c 4 are fixed at 45 and 4 respectively. From the figures, we observe that a good approximation of the original diagonal can be achieved by preserving 70%, 90%, 80%, 90% of the original tensor infor-mation in each dimension respectively, that is, c 1 = 45 , c 125 , c 3 = 165 , c 4 = 4.
In this section, we review the related work in the various recommendation tasks.

Item recommendation. Existing systems for item rec-ommendation can be roughly divided into two major cate-gories. Content-based systems [2, 14] make use of explicitly stated profiles of users or products to characterize their na-ture. On the other hand, systems based on collaborative filtering (CF) [18, 17] do not exploit such explicit user pro-files. Instead, they infer the user profiles through their past activities, such as their transaction history or product satis-faction expressed in ratings. These systems rely only on the associations between users, ratings, and items. They cannot be easily used to consider the the quaternary relationship among users, items, tags and ratings.

Recent work has focused on using tags to recommend items. The work in [21] proposed a generic method to in-corporate tags to CF algorithms. This is done by decom-posing the users-tags-items relationship into 3 binary rela-tionships, namely, users-tags, tags-items, and user-items. A fusion method is then applied to perform item recommenda-tion. [19] tries to infer tag preferences and recommend items to users based on their tag preferences. Recently, a ternary semantics analysis approach [20] has been proposed to uti-lize the ternary relationship users-items-tags for recommen-dation. None of these works have utilized the associations among users, items, tags and ratings.

User recommendation. Social networking sites have adopted the simple strategy of suggesting friends-of-friends to increase the connectivity among their users. Recently, content-based approaches [7] were proposed to match the content of user profiles and determine user similarities for recommendation. Research has also been done using known social network structures for recommendations. Groh et al. [4] generated user neighborhood information from known so-cial network structures and demonstrated that collaborative filtering based on such neighborhoods outperforms classic collaborative filtering methods. The work in [20] proposed a ternary semantic analysis unified framework to perform user recommendation.

Tag recommendation. Personalized tag recommenda-tion has attracted significant attention recently. The work in [6] provides a comprehensive evaluation and comparison of several state-of-the-art tag recommendation algorithms in three different real world datasets. Content-based col-laborating filtering technique has been proposed in [13] to automate tag assignments to blogs. The works in [5, 20] have shown to generate high quality tag recommendations that outperform baseline methods such as the most-popular models and collaborative filtering [6].

Item rating prediction. There are three approaches to item rating prediction: user-based methods [12], item-based methods [18], and model-based methods [3, 17]. User-based methods search for similar users and utilize the ratings of these similar users to make prediction, while item-based methods search for similar items and utilize the ratings of these similar items to make prediction. Model-based meth-ods try to learn a model from the data using statistical learn-ing techniques. All these approaches are based on tenary relationships.
In this work, we have shown that quaternary semantic analysis can lead to more accurate recommendation. We have proposed using a 4-order tensor to model the four heterogenous entities: users, items, tags and ratings. We further employed the higher order singular value decompo-sition to reduce the dimensionality of the 4-order tensor, thereby casting the recommendation problem as a multiway latent semantic analysis problem. Extensive experiments have been conducted on a real world dataset for item recom-mendation, user recommendation, tag recommendation, and item rating prediction. The results demonstrated that qua-ternary semantic analysis outperforms state-of-the-art algo-rithms in all the four tasks. [1] X. Amatriain, N. Lathia, J. M. Pujol, H. Kwak, and [2] M. Balabanovi  X c and Y. Shoham. Fab: content-based, [3] S. Funk. Netflix update: Try this at home.. [4] G. Groh. Recommendations in taste related domains: [5] A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme. [6] R. J  X  aschke, L. Marinho, A. Hotho, S.-T. Lars, and [7] C. D. M. M. Jilin Chen, Werner Geyer and I. Guy.. [8] G. Karypis. Evaluation of item-based top-n [9] T. G. Kolda and J. Sun. Scalable tensor [10] Y. Koren. Factorization meets the neighborhood: a [11] L. D. Lathauwer, B. D. Moor, and J. Vandewalle. A [12] G. Linden, B. Smith, and J. York. Amazon.com [13] G. Mishne. Autotag: a collaborative approach to [14] R. J. Mooney and L. Roy. Content-based book [15] S. Rendle, L. Balby Marinho, A. Nanopoulos, and [16] P. Resnick, N. Iacovou, M. Sushak, P. Bergstrom, and [17] R. Salakhutdinov and A. Mnih. Probabilistic matrix [18] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [19] S. Sen, J. Vig, and J. Riedl. Tagommenders: [20] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos. [21] K. H. L. Tso-Sutter, L. B. Marinho, and
