 The field of information retrieval still strives to develop models which allow semantic information to be integrated in the ranking process to improve performance in comparison to standard bag-of-words based models. Cross-lingua l information retrieval is an example of where such a model is required, as content or concepts often need to be matched across languages. To overcome this problem, a conceptual model has been adopted in ranking an entire corpus which normally exploits latent/implicit features of the text. One of the drawbacks of this model is that the computational cost is significant and often intractable in modern test collections. Therefore, approaches utilizing concept-based models for re-ranking initial retrieval results have attracted a considerable amount of study, in particular the latent concept model. However, fitting such a model to a smaller collection is less meaningful th an fitting it into the whole corpus. This paper proposes a late fusion method which incorporates scores generated by using external knowledge to enhance the space produced by the latent concept method. This method is further demonstrated to be suitable for multilingual re-ranking purposes. To illustrate the effectiveness of the proposed method, experiment s were conducted over test collections across three languages. The results demonstrate that the method can comfortably achi eve improvements in retrieval performance over several re-ranking methods. H.3.3 [ Information Systems ]: Information Storage and Retrieval -Information Search and Retrieval; I.2.7 [ Computing Methodologies ]: Artificial Intelligence -Natural Language Processing. Algorithms, Experimentation, Languages. Cross-lingual Information Retrie val, Document Re-Ranking, Data Fusion, Linear Combination Model.  X  vocabulary mismatch  X  problem. A document may be semantically relevant to a query despite the fact that the specific query terms used and the terms found in the document completely or partially differ [2]. An extreme example of this is cross-lingual information retrieval (CLIR) where content or concepts need to be matched across languages. Consequently, overlap with respect to linguistic terms (or via translated words) should not be a necessary condition in query-document similarity calculation. Methods relying on the  X  X ag-of-words X  model display poor performance in many cases. In order to overcome the vocabulary mismatch problem, several solutions have been suggested which exploit semantic relations between text units. Among these methods, the latent model, the explicit model and the mixed model are commonly employed [6, 7]. However, these models have well documented drawbacks. Firstly, these methods are very computationally complex. In the latent model, comple xity grows linearly with the number of dimensions and the number of documents. This has been the biggest obstacle to the widespread adoption of this kind of method. For the explicit and mixed model, the number of dimensions used to map documen ts onto the external knowledge space are often limited to ten thousand [3] so that it is feasible to process the large test collections used. Another problem with the explicit model is that the docum ents are often distributed over thousands of dimensions in whic h the semantic relatedness will degrade dramatically [1]. How to find these dimensions is not reported and this may significantly influence the retrieval performance. Therefore, researchers started to consider integrating the aforementioned models into smaller, controlled document collections to address these shortc omings and assist the retrieval process. Zhou and Wade [6] proposed a Latent Dirichlet Allocation (LDA)-based method to model the latent structure of  X  X opics X  deduced from the initial retrieval results. However, due to the smaller corpus size, fitting a latent model into this corpus has less meaning than fitting the same model into a large, web-scale corpus. This means that some form of justification has to be applied to achieve better pe rformance. A simple approach to address this problem is to direct ly apply the explicit or mixed model to a controlled corpus to improve ranking performance. A similar problem will arise in the latent model in this single semantic space, resulting in limited improvements. In the setting of CLIR, this problem becomes more complicated. CLIR focuses on research into the retrieval of documents written in languages different to the language in which the query is expressed [5]. Assuming that query translation is employed, the simplest approach to addressi ng the cross-lingual re-ranking problem is to directly appl y the monolingual methods on the results obtained using the tran slated query. Obviously, the drawback of this approach is that errors resulting from translation noise will be inheri ted by the re-ranking process, which may result in unsatisfactory performance. To address the challenges described above, Zhou et al. further introduced a method incorporating scores generated using external knowledge to enhance th e semantic space produced by the latent concept method [7]. This method is intended to produce global consistency across the semantic space: similar entries are likely to have the same re-ranking scores with respect to the latent and manifest concepts . This is extended in the current paper to solve the cross-lingual document re-ranking problem by automatically indu cing a semantic correspondence between two languages (query language and document language) using parallel Wikipedi a corpora through a late fusion approach. This correspondence is then used to project the inquiry into another language in the semantic space to accomplish the re-ranking task. In this section, the problem addr essed by this paper is defined. The latent document re-ranking model implemented is also described briefly. Let  X  X  X  X  X   X   X ,  X   X ,...,  X   X  denote the set of documents to be retrieved. Given a query  X  , a set of initial results  X  top documents are returned by a standard IR model (initial ranker). However, typically the performance of the initial ranker can be improved upon. The purpose of our re-ranking method is accuracy at the most highly ranked results. The specific method used here is borrowed from [6], which is based on the LDA model. In this model, the topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all documents. The distance between a query and a document based on this model is defined via the Kullback-Leibler divergence: The final score is then obtained through a linear combination model of the re-ranking scores based on the initial ranker and the latent document re-ranker, shown as follows: where  X  X  denotes original scores returned by the initial ranker and  X  is a parameter that can be tuned with  X 1 X  meaning no re-ranking is performed. This algorithm is named latent-lda . Another well-known approach to the latent model is the LSI method. It is based on Singular Value Decomposition (SVD), a technique from linear algebra. It uses cosine correlation to compute the similarity between a query and a document in a SVD space to obtain  X  X   X  X  X  X   X  X  X  X  : This is combined with the orig inal score to produce the final latent-lsi algorithm score: In this section the concept of a cross-lingual explicit re-ranking model is presented which is based upon external knowledge resources. Please refer to [7] for details about this model applied in a monolingual setting. A very important characteristic of Wikipedia is that articles are linked across languages. Cross-li ngual links are those that link a database in another language. A pr evious analysis of this cross-lingual link structure betwee n the German and English Wikipedia showed that 95% of these links are indeed bi-directional [4]. The existence of a language link function  X  X  X  X  X  X  X  X   X  X  X  X  is assumed that maps an article of Wikipedia  X  to its corresponding ar ticle in Wikipedia  X   X  . Given a document  X  X   X  in language  X  , the document can be indexed with respect to another language , X  by transforming the vector  X   X   X  X   X   X  into a corresponding vector in the vector space that is spanned by the articles of Wikipedia in the target language: This linking function is calculated as follows: Where With  X | X  X 1 X   X  | ,  X | X  X 1 X   X  | . So that in order to get the representation of a document  X  X  X  in language  X  with respect to Wikipedia  X   X  it is simply a case of computing the function: The score produced by this model can then be calculated as the cosine similarity 1 : To apply this method to re-ranking,  X   X  and  X   X  the number of highly relevant documents for a given query. There are two alternative ways of applying this method. Suppose that the original query is written in language  X  and the translated query is written in language  X  . It is possible to use the original query to search in  X   X  and find the correspondent articles in  X  or the translated query could be used to search in  X   X  and locate the correspondent articles in  X   X  : Note that  X  X   X  X  X  X   X  X  X  X  is used later for m onolingual explicit model The final ranking score is defined as: As in the latent model,  X  X  denotes original scores returned by  X  X 1 X  meaning no re-ranking is performed. This algorithm is named as explicit-cross . It has two permutations, explicit-cross-q and explicit-cross-d which correspond to CL-ESA1 and CL-ESA2 respectively. Armed with the latent and explic it models defi ned above, the late fusion method proposed by th is paper is now described. A simple assumption is taken he re: the number of dimensions produced by the explicit model has to correspond to the number of dimensions induced by the latent model. Based upon this assumption, the late fusion met hod can be conducted so as to make a constraint: |  X   X  |  X  X  . This approach then takes the inputs from the original score, the latent model and explicit model and produces the final ranking score through a linear combination model, defined as:  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X   X   X  X  X 1 X   X   X  X  X   X  X  X   X  X  X   X  X  X  X  X   X  X  X  X   X  X  X  X  and These algorithms, denoted as fusion-lda and fusion-lsi , can be viewed as specific to monolingu al re-ranking. For cross-lingual re-ranking, the scores of the fusion-lda-cross and fusion-lsi-cross algorithms are defined as: and An interesting point is that the results produced by the monolingual explicit model can ac tually help the cross-lingual  X  lda-cross-mix and fusion-lsi-cross-mix for cross-lingual re-ranking: and This concludes the description of the proposed re-ranking models and methods. The text corpus used in the experiment described below consisted of elemen ts of the CLEF-2008 2 and CLEF-2009 European Library (TEL) collections 3 written in English, French and German. All of the documents in the experiment were indexed using the Terrier toolkit 4 . Prior to indexing, Porter's stemmer and a stopword list 5 were used for the English documents. A French and German analyzer 6 was used to analyze the French and German documents. The initial ranker used in this study is the classic vector space model. A Wikipedia database in English, French and German was used as an explicit concept space. Only those articles that are connected via cross-language links between all thr ee Wikipedia databases were selected. A snapshot was obt ained on the 29/11/2009, which contained an aligned collection of 220,086 articles in all three languages. Parameters are tune d so as to maximize mean average precision (MAP). The following evaluation metrics were chosen to measure the effectiveness of the various appr oaches: the precision of the top 5 documents (Prec@5), the prec ision of the top 10 documents (Prec@10), normalized discounted cumulative gain (NDCG), MAP and Bpref. Statisticall y-significant differences in performance were determined us ing a paired t-test at a confidence level of 95%. Whenev er a re-ranking method assigns different documents with the same score, the ties are broken by document ID. For the cross-lingual part of the experiments, firstly the performance of different variants of explicit models is compared to determine which one should be chosen to use in the late fusion methods. A straightforward observation is that in fact methods. In more detail, express-cross-d and express-cross-q  X  X  performance are on some occasions better than that of the express-mono algorithm. This partially confirmed that directly applying monolingual methods into the cross-lingual applications may not always produ ce the most beneficial results. The performance of the fusion methods are considered with respect to the non-monolingual runs. As illustrated by Table 1, significant margin in many test runs. While fusion-lda-cross and fusion-lsi-cross methods sometimes delivered better performance than that of monol ingual methods, more noticeable improvements were observed in the methods incorporating monolingual re-ranking scores. This cross-lingual re-ranking The test collections used in CLEF-2008 and CLEF-2009 are in fact identical. http://www.clef-campaign.org http://terrier.org ftp://ftp.cs.cornell.edu/pub/smart/ http://lucene.apache.org/ BL BL performance is a favorable indication of the stability of the late fusion technique. This paper proposed and evaluated a late fusion approach for re-performance. This paper also proposed a way to apply the explicit model to the cross-lingual re-ranking problem, and performed a systematic comparison between different models. It would be beneficial to conduct a direct comparison between ranking and re-ranking using the proposed algorithmic variations. Future work will also include identifying different combination models rather than the linear combination model used for data fusion. This research is supported by the Science Foundation Ireland (Grant 07/CE/I1142) as part of the Centre for Next Generation Localisation (www.cngl.ie) at Trin ity College Dublin and Dublin City University. [ 1] Cimiano, P., Schultz, A., Sizov, S., Sorg, P. and Staab, S. [2] Furnas, G. W., Landauer, T. K., Gomez, L. M. and Dumais, S. T. [3] Potthast, M., Stein, B. and Anderka, M. A Wikipedia-Based [4] Sorg, P. and Cimiano, P. Cross-language Information Retrieval [5] Zhou, D., Truran, M., Brailsford, T. and Ashman, H. A Hybrid [6] Zhou, D. and Wade, V. Latent Document Re-Ranking. In [7] Zhou, D., Lawless, S., Min, J. M., and Wade, V. Dual-Space Re-
