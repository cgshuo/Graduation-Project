 Tag recommendation approaches have historically focused on maximizing the relevance of the recommended tags for a given object, such as a movie or a song. Nevertheless, differ-ent users may be interested in the same object for different reasons X  X or instance, the Star Wars movies may appeal to both adventure as well as to fantasy movie fans. In this sit-uation, a sensible strategy is to provide a user with diverse recommendations of how to tag the object. In this paper, we address the problem of recommending relevant and di-verse tags as a ranking problem. In particular, we propose a novel tag recommendation approach that explicitly takes into account the possible topics (e.g., categories) underly-ing an object in order to promote tags with high coverage and low redundancy with respect to these topics. We thor-oughly evaluate our proposed approach using data collected from two popular Web 2.0 applications, namely, LastFM and MovieLens. Our experimental results attest the effec-tiveness of our approach at promoting more relevant and diverse tags in contrast to state-of-the-art relevance-based methods as well as a recently proposed method that takes both relevance and diversity into account.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing; H.3.5 [ Information Storage and Retrieval ]: Online Information Services Algorithms, Experimentation Tag Recommendation, Relevance, Diversity  X  (a) Artist styles in AllMusic Fig ure 1: Complementary cumulative distribution of the number of categories per object.

The Web 2.0 is characterized by an unprecedented amount of user-generated content. This content usually comprises a main object (e.g., a video) and several sources of data associ-ated with it, referred to as its features . The textual features of an object are well-defined blocks of text such as title, tags, description and user comments, used to describe the object X  X  content [5]. Among all textual features, tags have attracted special attention as they offer an effective data source for Information Retrieval (IR) services such as search [17] and classification [13], and may capture user interests reason-ably well [17]. In this context, there is a large interest in developing strategies to recommend tags to users, providing relevant and useful tag suggestions for a target object, and improving the quality of the generated tags and, indirectly, of the IR services that rely on them.

Tag recommendation methods have historically focused mostly on maximizing the relevance of the recommended tags [5, 18, 27]. When recommending tags for a target ob-ject, relevance refers to how well the recommended tags de-scribe the contents of the target object. However, relevance by itself may not be enough to guarantee recommendation usefulness and effectiveness [4, 25]. For example, a list of synonyms that well describe the object X  X  content is arguably relevant, but also redundant and less useful than a more di-versified list covering more aspects related to the object. As argued in [4], objects on the Web 2.0 may be multifaceted , being related to various aspects and topics.

We illustrate this point by showing, in Figure 1, the dis-tributions of the number of styles for different music artists and the number of genres for different movies, computed over datasets collected from AllMusic and MovieLens 1 , re-spectively. According to Figure 1, 84% of the artists and 63% of the movies are associated with more than one cat-egory (style or genre). Take for instance the movie  X  X ister Act X , starring Whoopi Goldberg. Its main genre is Comedy, but it also presents elements from the Action and Musical genres. Arguably, it would be appropriate to recommend tags related to all these genres for this movie. According to Figure 1, the distribution is even more biased towards larger numbers of categories for music artists.

While diversity is an important aspect in tag recommen-dation, our previous work [4] is, to our knowledge, the only one to address aspects other than relevance for tag recom-mendation. In [4], we defined the diversity of a list of rec-ommended tags implicitly , as the average semantic distance [4, 13, 19] between each pair of tags in the list, such that a set of synonyms or semantically similar words has low diver-sity. However, this approach has the disadvantage of being more subject to data sparsity, because the estimates of the semantic similarities are based on tag co-occurrences [4].
We here propose an alternative approach to address diver-sity in tag recommendation. We define diversity explicitly , in terms of the capacity of the recommended tags to cover different aspects or topics of the target object, an approach inspired by diversification algorithms proposed in the con-text of search [22]. To this end, we exploit an explicit taxon-omy represented by categories, commonly available in Web 2.0 applications, as topics for objects.

In order to recommend relevant and diverse tags, we model tag recommendation as a ranking problem. That is, we aim to produce a ranking function f that assigns scores to can-didate tags based on: (1) relevance estimates generated by a baseline state-of-the-art tag recommendation strategy, and (2) our diversification approach, which rescores candidate tags such that they better cover the topics of the target ob-ject. This allows us to sort candidate tags according to their joint relevance and diversity estimates.

Our method is a re-ranking strategy, and thus can be ap-plied over the recommendations produced by any relevance-based strategy. In particular, we apply it over a state-of-the-art Genetic Programming (GP) based tag recommender [5], here referred to as GP r , and over a novel strategy that uses Random Forests ( RF ), a learning-to-rank technique [6] that has not been applied to tag recommendation yet. Our approach, called explicit Tag Recommendation Diversifier or xT ReD , modifies the original scores produced by GP r (or by RF ), bringing tags that better contribute to covering the topics of the target object to higher positions of the ranking.
We evaluate our method on datasets collected from 2 pop-ular applications -LastFM and MovieLens -comparing it against GP r and GP rnd [4], which extends GP r to include metrics of diversity and novelty. Our goals are: (1) assess-ing to which extent we can improve diversity without harm-ing relevance, and (2) comparing our explicit diversification strategy against the implicit GP rnd method. Our results show that our method outperforms the best relevance-based strategy on which it is based by up to 45% in diversity with-out harming relevance. It also outperforms GP rnd by up to 54% in diversity and 10% in relevance, with the best results produced when xTReD is applied jointly with RF. Moreover, among the two relevance-driven strategies, the new RF-based recommender outperforms the state-of-the-art GP r by up to 7% in relevance.

In sum, the main contributions of this paper are: (1) an al-ternative definition of diversity for tag recommendation that explicitly captures the multifaceted nature of many Web 2.0 objects; (2) a novel strategy to diversify tag recommenda-tions that leads to significant gains in diversity, with no harm to relevance, over state-of-the-art strategies; (3) an analysis of Random Forests as an alternative learning-to-rank strat-egy for recommending relevant tags, and (4) an extensive evaluation of all strategies in large real datasets.
The rest of this paper is organized as follows. Section 2 discusses related work. Section 3 formally states the problem we tackle. Section 4 introduces the tag recommendation methods analyzed here. Our experimental methodology and results are discussed in Sections 5 and 6, while Section 7 offers conclusions and directions for future work.
The tag recommendation literature is rich in techniques exploiting co-occurrence patterns computed over a history of tag assignments [5, 4, 27], words extracted from multiple textual features of the target object [18], as well as metrics of tag relevance to filter out irrelevant terms or give more importance to the relevant ones [5, 18]. In [5], we proposed several heuristic methods that jointly exploit these three di-mensions, and showed that they outperform previous ap-proaches in various datasets. We, as well as other authors [7, 27], also exploited learning-to-rank (L2R) techniques, such as RankSVM [5, 7], RankBoost [27] and Genetic Program-ming (GP) [5], to  X  X earn X  a model that ranks tags based on a set of relevance metrics. Other dimensions of the problem, such as personalization, have also been tackled, often using the user X  X  history of tag assignments [20].

In common, all these previous efforts focus on tag rele-vance as the single criterion of tag quality . However, other aspects such as diversity may also be important. Indeed, result diversification is a problem that has been addressed in other contexts, particularly web search [11]. In this con-text, two main families of diversification approaches have emerged to tackle query ambiguity [23]. Implicit approaches seek to promote diversity by scoring a given search result proportionally to its difference to the results ranked ahead of it, e.g., in terms of these results X  textual dissimilarity [8] or the divergence of their language models [28]. In contrast, explicit approaches seek to diversify the search results on the basis of their coverage of some property of the user X  X  query, such as multiple query categories [1] or multiple query re-formulations [22]. Explicit approaches represent the current state-of-the-art [23], and provide the basis for our approach.
In the general context of (item) recommendation, previous work mostly focused on implicit approaches. Celma et al . [9] and Vargas et al . [25] evaluated novelty and diversity in terms of popularity and dissimilarity of items, based on the idea that novel and diverse items must be different from all items that have been seen or consumed. Ribeiro et al. [21] exploited a multi-objective pareto optimization algorithm to jointly address relevance, novelty and (implicit) diversity. Wartena and Wibbels [26] improve item recommendation by detecting different topics of interest in the user profile and then generating recommendations for each of these topics.
We are aware of only one previous attempt to explore re-sult diversification in the specific context of tag recommen-dation. Very recently, we extended our previous GP-based method [5] to include metrics related to both diversity and novelty [4]. However, inspired by [25], we previously adopted an i mplicit definition of diversity, which captures the seman-tic distance between different tags in a recommendation list. In contrast, building from recent search result diversification efforts [22, 23], we here adopt an alternative definition by ex-plicitly representing the multiple topics associated with an object, as discussed in Section 3.

The original GP-based solution proposed in [5] and its re-cent extension [4] are here taken as baselines for comparison against our novel approach, being described in Section 4.1. We note that, although we currently do not address per-sonalization, our approach can be easily extended to pro-duce personalized recommendations, by taking into account a topic distribution biased towards each user X  X  interests.
The tag recommendation problem we address here can be stated as: Given a set of initial tags I o , priorly as-signed to the target object o , and a set of textual features F o = { F 1 o , ..., F n o } , where F i o contains the terms in textual feature i of o , produce a sorted list of candidate tags C ( C o  X  I o =  X  ) so that both relevance and diversity objectives are maximized, and recommend the k candidates in the top positions of C o . We focus on recommending tags for a tar-get object, aiming at improving the quality of tags in the objects, and indirectly the effectiveness of services that use tags as a data source. We leave the task of tackling diversity in personalized recommendations to the future.

The main focus of this work is on the diversity of the recommended tags. Diversity can be defined implicitly or explicitly. As an example of the former, Vargas et al . [25] defined diversity as the average pairwise difference between the items in the recommendation list. Inspired by them, we have previously defined diversity in the specific context of tag recommendation as the average semantic distance be-tween the recommended tags, such that a list of synonyms or semantically related words present low diversity [4].
An explicit definition of diversity usually exploits a taxon-omy, such as a set of categories or topics. In that perspec-tive, a list of recommended items is diverse if it presents items that cover different topics. This approach has been applied in search result diversification [22, 23], being useful to increase the chances that at least one document will sat-isfy the information need of the target user. This is also the perspective we employ here, thus a diversified list of tags must cover as many topics related to the target object as possible, and as early in the ranking as possible.
Given our focus, we approach the tag recommendation task as a ranking problem . That is, we aim at developing a ranking function that assigns scores to each candidate tag c , allowing us to sort candidates so that those that represent more relevant and diverse recommendations for the object o appear in higher positions in C o . This is achieved in two steps: (1) a state-of-the-art relevance-driven tag recommen-dation strategy is used to produce relevance estimates, and (2) our diversifier approach rescores candidate tags such that they better cover the topics of the target object.
This section describes the analyzed tag recommendation methods. All approaches employ a learning-to-rank (L2R) technique, for example, Genetic Programming (GP) or Ran-dom Forest (RF), to build a ranking function that assigns sco res to candidate tags according to some criterion (e.g., probability of relevance). The two state-of-the-art baselines use GP as L2R technique, and are described in Section 4.1. We present our new relevance-driven RF-based strategy as well as our new diversifier approach in Section 4.2. All meth-ods extract candidate tags from (1) co-ocurrence patterns with tags already in the target object o (tags in I o ), and (2) other textual features in o , namely, title and description.
Our baseline methods are based on Genetic Programming (GP), a framework inspired by the biological mechanisms of genetic inheritance and evolution of individuals in a popula-tion [3]. GP is a non-linear method that has been applied to various IR tasks. We were the first to use it for recommend-ing tags [4, 5], having obtained competitive (or superior) results over other approaches.

GP implements a global search mechanism by evolving a population of individuals over multiple generations. Each individual, representing a possible solution for the target problem, is modeled as a tree composed of terminals (leaves) and functions (inner nodes), related to the target problem. In each generation, each individual is evaluated by a fit-ness function, defined based on quality metrics related to the problem at hand. Only individuals with the highest fit-ness values are selected, according to some selection method, to evolve the population. An initial randomly generated population is evolved, generation after generation, through crossover and mutation operations. The individual with the best fitness value, usually part of the last generation, is cho-sen as the final solution for the problem.

GP directly optimizes a target (fitness) function, and al-lows for easy extensions to include more problem-related features (terminals) and to address other aspects of the tar-get problem (by, for instance, adapting the fitness func-tion). In particular, as reported in [5], GP outperforms other learning-to-rank techniques (RankSVM) in some scenarios, being statistically tied with it in many others. Thus, GP provides a promising framework to develop effective tag rec-ommendation solutions.

In our first GP-based baseline, here referred to as GP r [5], an individual is a tag ranking function with a tree repre-sentation built from nodes defined as follows. The sum (+), subtraction (  X  ), multiplication (  X  ), division ( / ) and natural logarithm ( ln ) operations are used as inner nodes. Protected division and logarithm are implemented such that these op-erations return 0 (default) when their inputs are outside their domains. Terminals are either constants, uniformly distributed between 0 and 1, or variables, selected from a set including (the values of) the metrics listed in Table 1. These metrics capture the following aspects related to the relevance of a candidate tag c to a target object o : (1) co-occurrence patterns, whose strengths are expressed by the confidences of association rules between previously assigned ta gs (tags in I o ) and c , where the rules are extracted from the training set, (2) the power of c to discriminate o from other objects, (3) the power of c to describe o  X  X  content, and (4) the predictability of c as a tag in the object collection. For illustration purposes, a tree representation of function V ote + wT S/ 0 . 5 has operation  X + X  as root, with variable V ote and operation  X / X  as its children. The inner node  X / X  has variable wT S and constant 0 . 5 as children.

The fitness of an individual represents the quality of the recommendations produced by the corresponding ranking function. It is computed as the Normalized Discounted Cu-mulative Gain ( NDCG ) [2] of the top-k tags in the rec-ommendation list produced by the function for a sample of objects in a validation set, with k =5.

Only relevance metrics are used by GP r (as terminals and fitness function). Since our approach diversifies GP r results, comparing both methods allows us to assess to which extent we can exploit a tradeoff between relevance and diversity.
GP r was recently extended to include attributes related to the diversity and novelty of a list of tags [4]. This ex-tension, here called GP rnd (our second baseline), adds the Average Distance to other Candidates ( ADC ) metric to the list of terminals. ADC captures the diversity that a can-didate c brings to a recommendation list C o by the aver-age semantic distance between c and each other candidate tag in C o . The ADC of c with respect to C o is defined as ADC ( c, C o ) = 1 | C measures the dissimilarity between candidates c 1 and c 2 the relative difference between the sets of objects O 1 and O in which they appear as tags. That is, dist ( c 1 , c 2 ) = If b oth sets are empty, dist ( c 1 , c 2 ) is set to 1, the maximum value. GP rnd also adopts a different fitness function, aiming at jointly maximizing relevance, diversity and novelty. For each object o in the validation set, the fitness of a candidate ranking function f is computed as: where C o is the recommendation list produced by f for o , and 0  X   X   X  1 and 0  X   X   X  1 are tuning parameters. The fitness function includes NDCG @ k to capture the rele-vance of the recommended tags in C o , as well as AIP @ k and AILD @ k , which are related to the novelty and the diversity of these tags, respectively.

AIP @ k , or Average Inverse Popularity over the top k po-sitions of the ranking, was adapted from [25] to be a nor-malized average of the IF F values of the top-k tags in C IF F , a variation of the traditional IDF metric [2], favors tags that do not occur too often. It was used to estimate the novelty of a tag under the assumption that the lower the popularity of a tag, the higher its novelty [4].

AILD @ k , or Average IntraList Distance in the top k po-sitions [25], captures the diversity of the tags in C o . Specifi-cally, given the normalization constant K  X  = ( k 2  X  k ) / 2 and dist ( c i , c j ) as defined above, AILD @ k of C o is computed as AILD @ k and ADC metrics capture the notion of diversity in a list of tags implicitly, by means of the dist ( c i , c tion: a list with tags that are more semantically dissimilar is considered more diverse.

Although GP rnd captures novelty, in addition to relevance and diversity (our goal), a comparison against our solution is fair since, as noted in [4], a simplified version of the method with the novelty component turned off (  X  =0) does not out-perform the complete solution in any of the three aspects.
We now describe the new tag recommendation strategies proposed here. We start by describing a relevance-driven tag recommender that exploits Random Forests to learn a tag ranking function, being thus an alternative to GP r (Section 4.2.1). We then introduce our topic diversifier, which can be jointly applied with any relevance-driven strategy to produce relevant and diversified recommendations (Section 4.2.2).
Random Forests (RF) is an ensemble learning method in which n t decision trees are trained with distinct subsets of the training set (with size n b ), randomly sampled with re-placement in order to reduce the correlation among them. The decision tree learning happens in a recursive way: first, the most discriminative feature (according to some measure, such as Information Gain) is selected as a decision node. The selected training samples are split according to a split value (such as the average attribute value), and the process repeats in a top-down fashion. In order to further reduce the cor-relation between the decision trees, before each split a frac-tion  X  of the features is randomly selected to be considered as candidates for splitting, instead of considering the whole set of attributes. The decision rule is given by averaging the n t predictions of the trained trees. The crucial aspects that make RF a good learner are ( i ) the reduced correla-tion between the decision trees composing the ensemble and ( ii ) the better-than-random-guess predictions of each tree. To achieve strong decision trees (i.e, trees with better pre-diction performance than random guessing), each decision tree is typically grown to its maximum depth, containing n terminal nodes, where n l is a tuning parameter.

In order to be applied to our context, each tree outputs a relevance score to be assigned to each candidate tag c in a (test) object. The scores given by each tree to c are averaged and used to produce the final ranking of candidates. RF has achieved promising results in other contexts (e.g, document ranking [14]). It is used here as an alternative to GP r to produce a relevance based ranking of candidate tags. We use the RF implementation available in the RankLib tool 2 and exploit the same attributes used by GP r (Table 1) to build the trees.
Unlike GP rnd , we propose to address tag diversity in an explicit way, by seeking to directly maximize the set of top-ics (or categories) covered by the recommended tags. In its general form, maximizing topic coverage is an NP-hard prob-lem [1]. Fortunately, there is a well-known greedy algorithm for this problem, which achieves an approximation factor of (1  X  1 /e )  X  0 . 632 of the optimal solution [15]. This is also the best possible polynomial-time approximation for the prob-lem, unless NP  X  DTIME( n O (log log n ) ), where n is the num-ber of items to be diversified [12, 16]. Our method, called explicit Tag Recommendation Diversifier, or xT ReD , builds upon this greedy approach, as described in Algorithm 1. xTReD takes as input an object o an d a diversification cut-off  X  . In its first step, xT ReD calls a tag recommendation method rec to produce an initial ranking C o of recommended tags based only on relevance (line 1). Any relevance-driven tag recommender could be used in this step. We here eval-uate: (1) GP r , to make our approach comparable to the GP rnd baseline, and (2) our new relevance-driven method RF . xTReD ( o,  X  ) 1 C  X  o  X  rec ( o,  X  ) // relevance-driven recommendations 3 while | C S o | &lt; min (  X , | C o | ) do 7 end while 8 return C S o
Let C  X  o be the top  X  recommendations in C o . The goal is to produce a permutation of C  X  o so as to raise the diversity in the top positions of the ranking of recommended tags, given that those tags are often the ones that the user looks at. A complete permutation of C o (  X  = | C o | ) could be produced. However, we can reduce  X  for efficiency reasons and as a means to restrict the search for more diverse tags among the most relevant ones, avoiding severe relevance penalties.
The permutation C S o is initialized as an empty set (line 2), and is iteratively constructed (lines 3-7). The sub-modular objective function f ( o, t, C S o ) scores each yet unselected tag t  X  C  X  o \ C S o in light of the object o and the tags already in C S o , selected in the previous iterations of the algorithm (line 4). The highest scored tag, t  X  , is then removed from C o (line 5) and added to C S o (line 6). Finally, the produced diverse ranking C S o is returned (line 8).

To instantiate the objective function f ( o, t, C S o ) in Algo-rithm 1, we build upon a state-of-the-art framework for di-versifying search results, called xQuAD [22]. The xQuAD framework instantiates the aforementioned function in order to score the documents retrieved for a given query propor-tionally to these documents X  coverage and novelty in light of the multiple possible information needs underlying this query [22]. In our adaptation, instead of a ranking of docu-ments for a query, we seek to diversify a ranking of tags for a given object. More precisely, we propose a novel instanti-ation of the objective function f ( o, t, C S o ), such that: f ( o, t, C S o ) = (1  X   X  ) p ( t | o ) where Z is a set of topics associated with the object o and 0  X   X   X  1 is a tuning parameter used to balance the trade-off between promoting relevance or diversity. The greater the value of  X  , the more importance is given to diversity. The idea is to promote tags which are simultaneously highly related to at least one of the topics of the target object and little related to the topics of the tags already selected as recommendation (captured by the product over t  X   X  C S hence increasing the coverage of topics in the top positions of the list of recommendations. Besides addressing an explicit notion of diversity, our strategy has the advantage of making the weight given to diversity adjustable at recommendation time, unlike GP rnd , which needs to train a new model for each new value of  X  , and is hence more time-consuming.
When  X  = 0, Equation (2) reduces to p ( t | o ), which results in a pure relevance-driven tag recommendation, as produced by a non-diversification baseline. In our experiments in Sec-tion 6, we define p ( t | o ) = 1 /r t , where r t is the position of the tag t in the ranking produced by the initial ranker rec . In order to estimate the second half of Equation (2), we infer the distribution p ( z | o ) of topics z  X  Z for an object o from the available training data, as we will discuss in Section 5.2. Finally, to estimate how much a given tag t covers the topic z of the object o , we approximate the probability p ( t | o, z ) as probability that tag t is related to topic z . In turn, p ( z | t ) is of objects in which z appears as a topic and t appears as a tag, and f ( t ) is the number of objects containing tag t , both in the training set.
This section describes the setup used in our experimen-tal evaluation of the tag recommendation methods, includ-ing datasets (Section 5.1), evaluation methodology (Section 5.2), and method parameterization (Section 5.3).
Our evaluation is performed using two datasets, contain-ing title , tags , description and categories associated with ob-jects from MovieLens and LastFM. The MovieLens dataset 3 contains 100,000 tags applied to 10,000 movies. The genres associated with each movie were used as categories. The LastFM dataset 4 is the same used in [4, 5]. We collected the musical styles associated with 35,975 artists in this dataset from the AllMusic site 5 , and used them as artist categories.
We removed stopwords and applied the Porter stemming algorithm 6 to avoid trivial recommendations (e.g., plurals and other variations of the same word). We also discarded objects with fewer than 2 tags. Our processed datasets comprise a sample of the textual features of 35,975 LastFM artists and 6,500 MovieLens movies.
As in most tag recommendation studies [4, 5, 24, 18], we adopted an automatic evaluation approach: half of the tags, randomly selected from all tags previously assigned to an object, are used as gold standard , i.e., as the relevant tags for that object. These tags are not used by the tag recommenders, being thus removed from I o , which is used as input by the recommenders. A manual evaluation of tags is an expensive process in terms of time and human effort, besides being subjective, and thus is left for future work.
As in [5], the experiments were performed using a 5-fold cross-validation. That is, the objects are distributed into five equal-sized portions. Three portions are treated as the training set, used to compute all features exploited by both GP and RF. A fourth portion is used as the validation set, which, in turn, is used to  X  X earn X  the solutions (i.e., generate t he ranking function by both techniques) and to tune pa-rameters of the methods (e.g.,  X  , GP and RF parameters). The last portion is used for testing.

In order to estimate how related a tag t is to a topic, which is necessary to evaluate topic diversity and used by the diversifier algorithm, we estimate the probability of a topic given a tag using training data. That is, the level of relationship of a tag t to a topic z is given by p ( z | t ), defined in Section 4.2. The topics correspond to categories obtained from our datasets, as described in Section 5.1.

We evaluate the tag recommendation methods in terms of the relevance and the diversity of their results. We use NDCG @ k to assess the relevance of a ranked list of tags. To assess the diversity of this list, we used three metrics traditionally used for evaluating search result diversification methods [10]. Two of them X  X RR-IA and  X  -NDCG X  X re the primary evaluation metrics used in the diversity task of the TREC Web track [11]. They are cascade metrics that penalize redundancy by modeling the behavior of a user who stops inspecting the ranking once a relevant tag is ob-served [25]. While ERR-IA measures the expected retrieval performance with respect to multiple topics,  X  -NDCG in-corporates a notion of the expected gain attained by each ranked tag. We also report (sub)topic recall X  S -Recall [28], which quantifies the fraction of unique topics associated with the object that are covered by the top ranked tags. All di-versity metrics use the probability of a topic z given a tag t , p ( z | t ), to estimate whether a recommended tag is related to a given topic of the object. They are computed over the top-k tags in the recommendation list, with k =5 as in [4, 5].
Following [4], we evaluate diversity orthogonally to rele-vance. Thus, a tag considered irrelevant might contribute with higher diversity. Alternatively, we could embed rele-vance in the diversity metric such that only relevant tags could contribute to raise diversity. We opted for an orthog-onal assessment of diversity because, unlike in previous di-versification efforts in other contexts [11], our data about tag relevance and object topics is sparse, that is, we do not have a complete sample of all relevant tags spread across the topics they cover for each object. Instead, we estimate how related the tags are to a topic using training data, and use this estimation in the diversity metrics. One might ar-gue that tags considered irrelevant 7 should not contribute to raise diversity, despite being related to a topic of the object. We note however that we tuned all methods to maximize the average diversity across all objects, without harming rel-evance (on average). After this tuning, we observed that a tag considered irrelevant contributed to amplify diversity for only a small fraction of the objects (less than 4%). Thus, we did indeed filter out the vast majority of such cases.
Note that we can evaluate the diversity of recommenda-tions for objects with a single category by verifying if the recommended tags are related to that single topic. How-ever, the redundancy is high when recommending tags from the same topic, which could cause a loss in  X  -NDCG .
We ran a series of experiments using data from the valida-tion set to determine the best parameters for each method. For both GP r and GP rnd we fixed the parameters of the evolutionary process at the same values reported in [5]. We set the population size at 200, the maximum tree depth at 8, and the maximum number of generations at 200. We also employed tournament selection of individuals to evolve the population, i.e., we randomly select, with replacement, 2 individuals from the population and choose the one with highest fitness. Moreover, crossover and mutation opera-tions were performed at rates 0.6 and 0.1, respectively.
For GP rnd , as in [4], we set  X  =  X  , varying both at the same time 8 , in the [0,0.6] interval. These parameters cap-ture the tradeoff between relevance and the combination of novelty and diversity. Larger values of  X  (or  X  ) lead to great losses in relevance. The value that lead to the best diver-sity 9 without harming relevance is 0.25 and 0.1 for LastFM and MovieLens, respectively.

According to validation experiments, our RF-based tag recommender is very insensitive to parameterization. The results obtained with different numbers of trees ( n t =1, 5, 50) are statistically tied (with 95% confidence). We chose n t due to the lower cost. We also fixed the fraction of attributes selected in each node as  X  =0 . 3, after verifying that other values (e.g., 0.25, 0.5 and 0.75) lead to the same results. Different sizes for the bootstrap sample n b also led to the same results, and we set n b =300. The only parameter that (slightly) impacts results is the number of leaves n l : the best result is obtained with the largest value tested ( n l =1000).
For our diversifier xT ReD , we set the number of positions of the ranking to be diversified  X  =25, for efficiency reasons and because the tags in the top positions are much more likely to be selected (and visualized by the user) than lower ranked tags. Our objective with xT ReD is also to maximize diversity without harming relevance. Thus, we performed a grid search to find the best values for  X  , the trade-off between relevance and diversity, as will be discussed in Section 6.1.
We now discuss the results of the analyzed tag recommen-dation methods, namely, the baselines GP r and GP rnd , and our new strategies RF and xT ReD . Whenever necessary, we refer to our diversifier as xT ReD rec , where rec is the ini-tial ranker used ( GP r or RF ) All results are averages of 25 executions (5 folds, 5 random seeds). Our goal is to answer the following key research questions: 1. Can we effectively diversify tag recommendations with-2. Is our explicit diversifier effective in contrast to a state-3. Is Random Forests an effective learning-to-rank tech-
We here analyze the sensitivity of our method to its key parameter  X  , by searching for the best parameter value in Fig ure 2: Impact of parameter  X  in xT ReD effectiveness. the validation set . Figure 2 shows average NDCG and  X  -NDCG results for xT ReD GP r , along with 95% confidence intervals 10 , as functions of  X  . Results for xT ReD RF and for other diversity evaluation metrics are similar (omitted).
When  X  =0, xT ReD outputs the same recommendation list as the baseline it uses as initial ranker ( GP r or RF ). The closer  X  gets to 1, the more the baseline X  X  recommendation list is rearranged, favoring diversity, which reaches its max-imum at  X  =1, for both datasets. The gains of xT ReD GP r in  X  -NDCG over the results for  X  =0 (i.e., GP r ) reach 39% in LastFM and 44% in MovieLens for  X  =1. Corresponding gains for xT ReD RF over RF are 46% and 40%.

Such impressive gains in diversity come with no statis-tically significant loss in relevance (NDCG). Thus, for both initial rankers, the maximum diversification level (  X  =1) does not hurt relevance. This is possibly due to: (1) tags pro-moted by xT ReD may present high relevance as they tend to be related to the topics (categories) of the object, and (2) xT ReD promotes relevant tags even if  X  =1, due to the prob-is part of the diversity component of Equation (2), represent-ing the probability that tag t is related to both topic z and object o . Thus, the diversifier also promotes tags with high chance of being related to the object. In contrast, the bene-fits introduced by GP rnd are much more modest (if any), as discussed in the next section.

Thus, recalling our first research question, we found that it is possible to significantly increase diversity without harm-ing relevance with our xTReD method by adjusting its pa-rameter  X  . Best results are obtained with  X  =1.
We now turn to our second and third research questions, on the effectiveness 11 of our explicit diversification approach and of the RF relevance-driven method. Towards answering them, we perform a series of experiments with objects in the test set , comparing our xT ReD approach (with both RF and GP r as initial rankers), the state-of-the-art GP rnd implicit diversifier, and the two relevance-driven methods ( GP r and RF ). All methods are parameterized with the best parameter values found in the validation set.
In the following, we fix the maximum allowed degrada-tion in relevance at 3%, and assess the gains in diversity, in terms of all metrics, achieved by xT ReD and GP rnd over the relevance-driven method they build upon. We choose the 3% threshold to favor the GP rnd baseline since this threshold Table 2: Results of the analyzed methods in test set. Best results (and their statistical ties) in bold.
 leads to the best tradeoff between relevance and diversity for tha t method. We note however that our xT ReD methods produce statistically tied relevance results even if we allow maximum diversification (as discussed in Section 6.1). Table 2 shows average NDCG ,  X  -NDCG , ERR -IA and S -Recall results for all methods, for both datasets. It also shows statistical significance indicators (according to a two-sided t-test with p &lt; 0.05): the first indicator symbol refers to the comparison of the corresponding method against GP r while the second refers to the comparison against GP rnd . Symbols  X  ,  X  and  X  indicate significant improvement, de-crease and statistical tie, respectively, with 95% confidence.
We start by comparing the state-of-the-art baselines. We find that GP rnd produces only small improvements, on av-erage, in explicit diversity (up to 3.4% in  X  -NDCG , 3.1% in ERR -IA and 2.5% in S -Recall ). These average results are consistent with [4], which reports similar gains in terms of implicit diversity, captured by the AILD metric (Section 4.1). However, due to higher variability, the average gains of GP rnd in the explicit diversity metrics adopted are not statistically significant, as they are tied with GP r results with 95% confidence. This is because AILD promotes in-frequent tags, which tend to be more dissimilar to any tag since there is little information about their co-occurrence (the source of information for AILD to estimate the seman-tic differences between tags). On the other hand, infrequent tags also carry little information about their related topics, being less appropriate to cover the object X  X  topics.
We now turn to our diversifier xT ReD . Following the discussion in Section 6.1 (which was based on results of the validation set), we find that xT ReD GP r greatly outperforms GP r , achieving gains of up to 45%, 44% and 37%, on av-erage, in  X  -NDCG , ERR -IA and S -Recall , respectively, in the test sets. The corresponding gains of xT ReD RF over RF reach 45%, 47% and 29%, respectively. Such gains in diver-sity come with no statistically significant losses in relevance in neither dataset. One might argue that our diversity im-provements are expected because the diversifier exploits the same source of topics used to evaluate diversity. However, this is a valid approach because this information is com-monly available in objects in the form of categories. The surprising aspect is the possibility of obtaining very large gains with no loss in relevance, as discussed in Section 6.1.
We next compare our xT ReD methods against the state-of-the-art GP rnd baseline, which provides implicit diversifi-cation. We find that xT ReD GP r outperforms GP rnd by as much as 44%, 43% and 38% in average  X  -NDCG , ERR -IA and S -Recall , respectively. The gains are larger in Movie-Lens, but are also quite impressive in LastFM, ranging from 26% to 35%. In terms of relevance, xT ReD GP r produces results with average NDCG at least as good as those of GP rnd , with even some modest gains (3%) in LastFM. Com-paring xT ReD RF a gainst GP rnd , we find that the former provides even further improvements in all diversity and rel-evance metrics, with average gains in  X  -NDCG , ERR -IA and S -Recall and NDCG reaching 54%, 53%, 43% and 10%, respectively. In sum, answering our second question, our ex-plicit xT ReD diversifier, particularly when using RF as the initial ranker, is much more effective than the alternative GP rnd method in improving the diversity of recommenda-tions produced by the relevance-driven strategies.
Finally, tackling our third research question, we find that our new RF method outperforms the state-of-the-art GP r strategy, with statistically significant gains in all (relevance and diversity) metrics, in both datasets. The average im-provements in NDCG ,  X  -NDCG , ERR -IA and S -Recall reach 7%, 10%, 7% and 13%, respectively. Thus, the use of RF is a competitive alternative to GP r , producing gains in terms not only of relevance but also diversity, even though both strategies are focused on relevance only and exploit the same set of attributes. This happens because since RF rec-ommends more relevant tags in higher positions of the rank-ing (higher NDCG ), these recommended tags have higher probability of being related to the topics of the target object, thus presenting a higher topic diversity. This also impacts the effectiveness of our diversifier, which is higher when RF is exploited as initial ranker, as discussed above.
In sum, we found that: (1) although relevance and diver-sity of recommendations may seem conflicting objectives, it is possible to effectively increase diversity without harming relevance with our xT ReD diversifier, which also has the advantage of being flexible (adjustable) at recommendation time, (2) our explicit diversifier is much more effective at re-ducing redundancy and covering different topics of the target object than the state-of-the-art GP rnd baseline, the only pre-vious tag recommender that exploits diversity (implicitly), and (3) our new relevance-driven RF tag recommender out-performs the alternative, state-of-the-art GP r in terms of not only relevance but also diversity. We have addressed the problem of recommending tags for Web 2.0 objects, which are usually multifaceted, by propos-ing two new methods: a diversification approach ( xT ReD ), which exploits an explicit taxonomy to decrease redundancy and increase the number of topics of the target object cov-ered by the recommended tags, and a relevance-driven Ran-dom Forests (RF) based tag recommender. Our evaluation of the methods on two datasets showed that it is possible to increase the average diversity of a list of recommended tags in up to 45% with no significant impact on relevance. We also found that our explicit diversifier is much more effec-tive than GP rnd , a state-of-the-art implicit diversification strategy and the only alternative to xT ReD in the litera-ture, reaching gains in both diversity and relevance of 54% and 10%, respectively. Our approach also has the advantage of being adjustable at recommendation time, unlike GP rnd which requires the user to choose the weight given to the relevance/diversity tradeoff at model training time. Finally, we also found that our new RF-based recommender outper-forms a state-of-the-art relevance driven Genetic Program-ming based method not only in terms of relevance (gains of up to 7%) but also diversity (gains of up to 10%).
As future work, we intend to deal with other aspects of the problem, such as personalization and the novelty of rec-ommendations in the perspective of specific users. We also plan to employ multi-clustering strategies as an alternative to infer the object topics, which can be useful when no cat-egory information is available.
