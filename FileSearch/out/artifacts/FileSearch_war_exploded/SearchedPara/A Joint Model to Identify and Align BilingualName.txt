 National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences Behavior Design Corporation entities (NEs) between Chinese and English. The model is motivated by the following obser-vations: (1) whether an NE is translated semantically or phonetically depends greatly on its detected NEs can act as anchors and provide further information while selecting NE candidates. NE anchors).
 insensitive F-score of identified NE pairs increases from 78.4% to 88.0% (12.2% relative im-provement) in our Chinese X  X nglish NE alignment task, and the type-sensitive F-score increases from 68.4% to 83.0% (21.3% relative improvement). Furthermore, the proposed model demon-learning is conducted to train the adopted English NE recognition model, the proposed model also significantly boosts the English NE recognition type-sensitive F-score. 1. Introduction
Named entities (NEs), especially person names (PER), location names (LOC), and organization names (ORG), deliver essential context and meaning in human languages.
Therefore, NE translation plays a critical role in trans-lingual language processing tasks, such as machine translation (MT) and cross-lingual information retrieval. To learn NE translation knowledge, bilingual NE alignment (which links source NEs and target
NEs to generate desired NE pairs) is the first step in producing the NE translation table (which can then be used to train the NE translation model). Furthermore, with additional alignment constraints from the other language, the alignment module can also refine those initially recognized NEs, and thus can be adopted to conduct semi-supervised learning to learn monolingual NE recognition models from a large untagged bilingual corpus.
 identified, the NE recognition errors propagate into the alignment stage. The type-insensitive inclusion rate 1 of the initial recognition stage thus significantly limits the final alignment performance. One way to alleviate this error propagation problem is to jointly perform NE recognition and alignment. Such a combined approach is usually infeasible, however, due to the high computational cost of evaluating alignment scores for a large number 2 of NE pair candidates.
 usually used to first identify NEs and then align them. Two such kinds of sequential strategies that alleviate the error propagation problem have been proposed. The first strategy, named asymmetry alignment (Al-Onaizan and Knight 2002; Moore 2003;
Feng, Lv, and Zhou 2004; Lee, Chang, and Jang 2006), identifies NEs only on the source side and then finds their corresponding NEs on the target side. Although this approach avoids the NE recognition errors resulting from the target side, which would otherwise be brought into the alignment process, the NE recognition errors from the source side continue to affect alignment.
 symmetry alignment (Huang, Vogel, and Waibel 2003), expands the NE candidate sets in both languages before conducting the alignment. This is achieved by using the original results as anchors, and enlarging or shrinking the boundaries of the anchors to generate new candidates. This strategy fails to work if the NE anchor has already been missed in the initial NE recognition stage, however. In our data set (1,000 Chinese X 
English sentence pairs randomly selected from the Chinese News Translation Text corpus [LDC2005T06]), this strategy significantly improves the type-insensitive NE pair inclusion rate from 83.9% to 96.1%; 3 in the meantime, the type-insensitive Chinese NE (CNE) recognition inclusion rate rises from 88.7% to 95.9%, and that of English NE (ENE) from 92.8% to 97.2%. This strategy is thus adopted in this article. lem of error propagation, the final alignment accuracy, in terms of type-sensitive F-score 230 (achieved by the approach proposed by Huang, Vogel, and Waibel [2003]) continues to be as low as 68.4% (see in Table 3 in Section 4.3). After having examined the data, we found the following: (1) How a given NE is translated, either semantically (called translation ) or phonetically (called transliteration ), depends greatly on its associated entity type. 4 The translation mode ratio , which is the percentage of NE internal tokens that are translated semantically, thus can help to identify the NE type. (2) Entities within an aligned pair should share the same type, and this restriction should be integrated into the NE alignment model as a constraint. (3) In prior work, the initially identified monolingual NEs were used only to construct the candidate set without playing any role in final NE identification. Indeed, these monolingual NEs do carry other useful in-formation and can act as anchors to give NE likelihoods , which can provide additional scope preference information to those regenerated candidates.
 tion mode ratio, enforces the entity type consistency constraint, and also utilizes the NE likelihoods. This proposed approach jointly identifies and aligns bilingual NEs under an integrated framework, which consists of three stages: Initial NE Recognition, NE-
Candidate Set Expansion, and NE Re-identification &amp; Alignment. The Initial NE Recog-nition stage identifies the initial NEs and their associated NE types in both the source and target. In the next stage, NE Candidate Set Expansion regenerates the candidate sets in both languages in order to remedy the initial NE recognition errors. In the final stage, NE Re-identification &amp; Alignment jointly recognizes and aligns bilingual NEs via the proposed joint model. The experimental results validate our proposed three-step method.
 between Chinese and English was originally introduced in Chen, Zong, and Su (2010).
In this article, the problem has been re-formulated and derived. The new derivation starts from two given NE sequences , whereas the original derivation only begins with one given NE pair . We also give more details of the problem study, model analysis, and experiments. Moreover, we report additional experiments, which include those that study the effect of adopting different initial NE recognizers and the effectiveness of the proposed model across different domains. Finally, a complete error analysis is given in the current version.
 posed method. Afterwards, the proposed model is formally introduced in Section 3. Section 4 describes experiments conducted on various configurations of the method. The associated error analysis and discussion of results are presented in Section 5. Section 6 gives applications of the proposed model. We review related work in Section 7.
Finally, conclusions are drawn in Section 8. 2. Motivation
By examining the NEs initially recognized in aligned sentence pairs, we have the following two observations: (1) Alignment can help fix those NEs that are initially in-correctly recognized when they are not the correct counterparts of each other. Therefore, alignment and recognition should be jointly optimized. (2) Alignment cannot help in determining the appropriate scope when each word within an NE (or within its larger context window covering the NE) is correctly matched to its counterpart. Therefore, the information of those initial NEs should be utilized to decide the appropriate NE scope.
The following two sections further elaborate on these two observations. 2.1 Alignment Helps NE Recognition In NE recognition, both boundary identification and type classification are required. The complexity of these tasks varies with different languages, however. For example,
Chinese NE boundaries are not obvious because adjacent words are not separated by spaces. In contrast, English NE boundaries are easier to identify with explicit words and capitalization clues. On the other hand, classification of English NE type is considered more challenging (Ji and Grishman 2006).
 semantic meaning, the NE that is more reliably identified in one language can be used to identify its less reliable counterpart in the other language. This benefit, which is observed in both NE boundary identification and type classification, indicates that alignment can be used to locate those NEs that are initially incorrectly recognized. For example, once the correct boundaries are drawn in one language, word equivalences inside an aligned NE pair can help identify NE boundaries in the language that does not have explicit clues (e.g., Chinese). As shown in Example (1), even though the desired
Chinese NE  X   X   X   X   X   X   X   X   X  is only partially recognized as  X  recognition stage, it can be recovered if the English counterpart North Korean [no X  X ]
Central News Agency is given. The reason for this is that News Agency is better aligned to  X   X   X   X   X , rather than be deleted, which would occur if  X  corresponding Chinese NE.
 is less reliably identified. Moreover, in identifying the NE type, it helps if we know whether a word is translated or transliterated. As illustrated in Example (2), the word lake in the English NE is linked to the Chinese character  X  found to be a translation, not a transliteration. Because translation rarely occurs for personal names (Chen, Yang, and Lin 2003), the desired NE type  X  X OC X  should be shared between the English NE Lake Constance and its corresponding Chinese NE  X   X   X   X  . X  As a result, the original incorrect type  X  X ER X  of the given English NE is fixed; it thus corroborates the need for using the translation mode ratio and NE type consistency constraint. 232 2.2 Initial NEs Carry NE Scope Information
In Huang, Vogel, and Waibel (2003), initial NE information was discarded once the new candidate set was generated. Alignment scores alone, however, are incapable of selecting the appropriate NE scope in some cases. For instance, when each word in an
NE is correctly matched to its counterpart, the alignment score might still prefer an incorrect NE pair with smaller scope, even after the normalization of alignment terms has been considered (explained in Section 4.3). On the other hand, when words sur-rounding the desired NE are also correctly matched to their counterpart, the incorrect
NE pair with larger scope might be chosen. As illustrated in Example (3), the desired NE pair {  X   X  ::[Germany] } is initially correctly recognized, although the wrong NE pair {  X   X   X   X  ::[Germany economy] } is finally selected from the regenerated candidate set if only alignment scores are used in the final selection process. This is because the extra words  X   X   X   X  X nd economy are a perfect translation of each other, thus resulting in the incorrect pair {  X   X   X   X  ::[Germany economy] } , which receives a higher alignment score than does the correct NE pair {  X   X  ::[Germany] } .
 potentially useful information that is commonly used in monolingual NE recognition models. For example, the bigrams of text surrounding NEs are frequently adopted in a monolingual NE recognition model, but not in a bilingual alignment model. Other examples include case information, part-of-speech (POS) triggers, gazetteer features, and external macro context features mentioned in Zhou and Su (2006). The alignment model fails to consider the monolingual context surrounding NEs while determining
NE scope, resulting in the error mentioned in Example 3. By ignoring the initial NEs after their corresponding candidate sets have been generated, we lose the information provided by these initial NEs that is otherwise available to the alignment model.
Therefore, though the initially detected NEs might be unreliable by themselves, they should act as anchors to provide scope preference information, even after the expanded candidate set has been generated from these NEs. 3. The Proposed Joint Model
Given a Chinese X  X nglish sentence pair ( Sc , Se ), with its initial (denoted by lower case letter b, for  X  X eginning X ) Chinese NEs [ Cb i [ Eb
Chinese and English, respectively; Tc i and Te j are the original NE types assigned to Cb and Eb j , respectively. (For the reader X  X  convenience, all adopted notations are listed in
Table 1 for quick reference.) We first regenerate two NE candidate sets (by enlarging and shrinking the boundaries of those initial NEs) to include, we hope, the correct corresponding candidates that failed to be recognized in the first stage. Let C denote the two sets that include those regenerated candidates for Chinese and English pairs of the final Chinese and English NEs will be extracted from the Cartesian product of C Kc 1 and E Ke 1 . Here, only NE pairs in one-to-one mappings will be extracted, as most applications are only interested in this kind of correspondence. Therefore, we will let C and E K 1 denote the two extracted candidate sets to be linked, and these sets will consist of non-overlapping NE candidates from C Kc 1 and E Ke 1 , respectively (for conciseness, we will not explicitly distinguish between the indices C E and E Ke 1 ).
 indices of those regenerated Chinese and English NEs within C the subscript a ( k ) denotes that C a ( k ) is aligned to E assigned and shared by C a ( k ) and E k (as they should denote the same entity). Assuming that only one-to-one mappings of NE pairs will be extracted, the problem of getting 234 the final desired aligned NE pairs C  X  a ( k ) , E  X  k , T allowable combination of NE pairs (and their re-assigned NE types), given all the initial
NEs (i.e., [ Cb i , Tc i ] Nc i = 1 and [ Eb j , Te j ] Ne Se ). This can be formulated as follows: operate over each re-assigned type-sequences T K 1 (where T belongs to PER, LOC, ORG for each given NE pair included in the NE X  X air sequence). The outer argmax operator will cross every admissible NE X  X air sequence.
 with respect to C K 1 and E K 1 , without making any independence assumptions among those NE pairs included in the associated NE X  X air sequence. This equation is thus computationally infeasible due to a large search space. Therefore, it is fur-ther simplified and derived as follows by first explicitly denoting the link between
C ble alignment between C K 1 and E K 1 . We will then have K ! different possible align-ments between them (i.e., total factorial of K different A follows.

NE Alignment Probability and NE Type Re-assignment Probability, respectively, for finding the final alignment A K S ,1 among C K 1 and E used to assign preference to each selected C K 1 and E K 1 act as anchors). For brevity, we drop the associated subscripts hereafter, if there is no confusion. These probabilities will be further described in Sections 3.1 and 3.2. Finally, the joint identification and alignment framework that incorporates the initial
NE recognition process, candidate set construction, and the associated search process are given in Section 3.3. 3.1 Bilingual Related Probabilities The NE alignment probability represents the likelihood of a specific alignment A given C and E and their associated T . Because Chinese word segmentation in-troduces errors, especially for transliterated words, the NE alignment probability
In addition, because internal component alignment (denoted as A , to be defined later) within a given NE pair carries important information (as illustrated in Section 2), the internal component alignment will be introduced as follows.
 where R = A P ( A | E , T ) is a normalization value, 5 which will be ignored for simplicity, leaving only the probability P ( A | E , T ) to be derived.
 a linked pair of a Chinese component cp a ( n ) (which might contain several Chinese char-acters) and an English word ew n within C and E , respectively, with their translation mode M n to be either translation (abbreviated as TS )or transliteration (abbreviated as TL ). We assume that there are N component transformations in total, including N translation transformations [ cp a ( n ) , ew n , TS ] N TS [ cp tion of internal translation mode varies greatly across various NE types (as illustrated in footnote [4] of this article), the associated translation mode ratio  X  = ( N tant feature and is included in the internal component alignment specified previously.
For example, if the A between  X   X   X   X   X   X   X  X nd Constance Lake is [
TL ]and[  X  , Lake , TS ]( N TS = N TL = 1), then its associated translation mode ratio will be 0.5 (i.e.,  X  = 1 / 2).
 introducing the translation mode M n and the translation mode ratio  X  as follows: 236 which integrates internal component alignment information such as translation mode ratio and NE type constraint, is finally obtained as follows.
 where R is the normalization factor defined by Equation (4), and will be ignored in the final selection. In Equation (6), the mappings between internal elements is trained from the syllable/word alignment of NE pairs of different NE types. For translitera-tion, the model adopted in Huang, Vogel, and Waibel (2003), which first romanizes
Chinese characters and then transliterates them into English characters, is used in for P ( cp a ( n ) | TS , ew n , T ).
 in Equation (3), is derived as follows.

As Equation (7) shows, both the initially assigned Chinese NE type Tc and the initially assigned English NE type Te are adopted to jointly identify their shared NE type T . 3.2 Monolingual NE Likelihoods
The monolingual related probabilities in Equation (3) represent the likelihood that a regenerated NE candidate is the true NE, given its originally detected NE. For Chinese, we derive the likelihood as follows.
 Here Lb is the length (in characters) of the original recognized Chinese NE Cb .Let d d R denote the left and right distance , respectively (which are based on the numbers of
Chinese characters), that C shrinks/enlarges from the left and the right boundaries of its anchor Cb . In Example (1) in Section 2.1, in the case where the given Cb and C are  X   X   X   X   X   X  X nd X   X   X   X   X   X   X   X , respectively, then d tively. Let String [ C ] denote the associated Chinese string of C , cc character within that string, and L denote the total number of Chinese characters within
C . Then we will have a range of bigram probabilities for candidates with different lengths. Therefore, it is systematically biased 6 (in probability value) towards candidates with shorter lengths. On the English side, following Equation (8), P ( E be derived similarly; the unit is a word, however, rather than a character. scope preference to each regenerated NE based on its associated initial NE. The initial
NE therefore still plays a role in the final selection process, even after its related candi-date set has been generated, which is important when all words involved are correctly matched to their counterparts, as explained in Section 2.2. In contrast, Huang, Vogel, and Waibel (2003) adopt only type-dependent bigrams as the NE likelihood. The initial
NE thus will not play any role in the final selection process after its related candidate set has been generated. The scope preference information carried by the initial NE is therefore not utilized in their model.
 we now have the final desired model. For simplicity, all the probabilities involved are estimated by the Good-Turing smoothing technique (Chen and Goodman 1998) unless otherwise specified. 3.3 Framework for Jointly Identifying and Aligning Bilingual NEs
In jointly identifying and aligning bilingual NEs, a three-stage framework is adopted: (A) Initial NE Recognition, generating the initial NE anchors with off-the-shelf pack-ages, (B) NE Candidate Set Expansion, expanding the associated NE Candidate set to remedy the errors made in the previous stage, and (C) NE Re-identification &amp; Align-ment, extracting the final NE pairs from the Cartesian product of source and target candidate sets (created in the second stage) via a search process. Figure 1 presents the detailed procedure of this framework. 238
Chinese NE to enlarge/shrink its boundaries to four characters on each side, and only allow two words for English.

Each NE and its type in this example is separated by  X / X . Only partial and relevant information is shown here. recognized as  X   X   X   X   X  initially with an incorrect NE type PER. In addition, the desired English NE [Galapagos National Park] is split into [Galapagos] and [National Park], initially two NEs. After each NE Candidate set has been expanded, the desired
NEs  X   X   X   X   X   X   X   X   X  and [Galapagos National Park] are included in C and E candidate sets, respectively. The desired NE pair {  X   X   X   X   X   X   X   X   X  National Park], ORG } can thus be located.
 the expansion step, all NEs that are initially incorrectly recognized can then be in-cluded. The generated search space, however, would be too large to be tractable. In our observation, four Chinese characters for both shrinking and enlarging, and two
English words for shrinking and three for enlarging, are found to be adequate in most cases. (Note that only the candidate that contains at least one original character/ word is allowed.) Under this condition, the inclusion rates for NEs with correct boundaries can be increased to 94.6% (from 88.7%) for Chinese, and 96.3% (from 92.8%) for English, respectively; the NE pair inclusion rate can even be increased to 95.3% from 83.9%. Because the inclusion rate achieved by this strategy (with limited range) is only 0.8% lower than that obtained without any range limitation (which is 96.1%, as some NEs might have been completely missed in the first stage), this setting is adopted in this article to reduce the search space. Even with this expansion strategy, however, those missing and spurious (false positive) errors still cannot be remedied, because we will neither create additional anchors nor delete any existing anchor. 4. Experiments on Various Configurations
To evaluate the proposed approach, prior work (Huang, Vogel, and Waibel 2003) is re-implemented as our baseline (see Section 4.2). This is because the work not only adopts the same candidate set expansion strategy mentioned previously, but also uti-lizes monolingual information when selecting NE pairs (only a simple bigram model is used, however). This is in contrast to other works (Feng, Lv, and Zhou 2004; Lee, Chang, and Jang 2006), which only used alignment scores.
 tions. The adopted training set includes two parts. The first part consists of 110,874 aligned sentence pairs from newswire data in the Foreign Broadcast Information Service (LDC2003E14 7 ) corpus, which is denoted as Training Set I. The average length of the Chinese sentences in this data set is 74.6 characters, and the average length of the English sentences is 30.2 words. Training Set I is initially tagged by Chinese/English
NE taggers, and then reference NE boundaries and types are manually labeled. The second part of the training set is the LDC2005T34 8 bilingual NE pair list with a total of 218,772 NE pairs, which is denoted as Training Set II. The required features (e.g.,
NE type and translation-mode) are then manually labeled throughout the two training sets. Because Training Set II only contains isolated NE pairs that are not associated with their surrounding context, Training Set I is thus required to train those context-related parameters.
 on Training Set II, and tagging cost is trained on Training Set I. For the proposed approach, the NE likelihoods are trained on Training Set I, and Training Set II is used to train the parameters relating to the NE alignment probability.

Consortium (LDC) Chinese X  X nglish News Text (LDC2005T06) corpus, which contains at least one NE pair in each sentence. The average length of Chinese sentences is 59.4 characters, and the average length of English sentences is 24.8 words. The answer keys to NE recognition and alignment are annotated manually, and used as the gold standard to calculate the metrics of precision (P), recall (R), and F-score (F) for both
NE recognition and alignment. A total of 765 Chinese NEs and 747 English NEs are manually identified in the test set, in which there are 718 reference NE pairs (including 214 PER pairs, 371 LOC pairs, and 133 ORG pairs). NE alignment result is a subset of NE recognition results, because not all those recognized NEs can be aligned. sentence pairs selected from the LDC2005T06 corpus, which includes 482 manually tagged NE pairs. The average length of Chinese sentences is 56.4 characters, and the average length of English sentences is 23.2 words. There is no overlap between the training, development, and test sets.
 proposed model. Among them, the results of initial NE recognition are given in Sec-tion 4.1, and those related to the baseline system are given in Section 4.2. In Section 4.3, a series of experiments are conducted to examine the effect of various features adopted in the proposed model. The weighted version of the proposed model is also tested. 240 Furthermore, the effectiveness of adopting different initial NE recognizers is shown in
Section 4.4, and the effectiveness of the proposed model across different domains is illustrated in Section 4.5. Finally, the result of directly using all available features under a Maximum Entropy framework without developing a principled model is given in
Section 4.6. 4.1 Initial NE Recognizers Both the baseline alignment system and the proposed model share the same Initial NE Recognition subtask. The systems adopt the Chinese NE recognizer reported in
Wu, Zhao, and Xu (2005), which is a hybrid statistical model incorporating multi-knowledge sources, and the English NE recognizer included in the publicly available
Mallet toolkit 9 (McCallum 2002) to generate initial NEs. These two initial NE recog-nizers are adopted because their performance is comparable to other state-of-the-art systems (Gao, Li, Wu, and Huang 2005; Zhou and Su 2006). The NE recognition baseline performances reported subsequently are provided by these two packages. A total of 789 Chinese NEs and 752 English NEs are recognized.
 English (the highest performance in each column is in bold). It is observed that the F-score of ORG type is the lowest among all NE types for both English and Chinese.
This is because many organization names are only partially recognized or missed alto-gether. In addition, the precision rate of PER type is lowest among all English NE types because many location names or abbreviated organization names tend to be incorrectly recognized as person names in English. In general, the initial Chinese NER outperforms the initial English NER, as the NE type classification turns out to be a more difficult problem for this English NER system. 4.2 The Baseline System
The model of Huang, Vogel, and Waibel (2003) is re-implemented in our environment as the baseline system, and is briefly sketched here for the reader X  X  convenience. There are three cost features in Huang X  X  alignment model: (1) transliteration cost, which measures the phonetic similarity of the aligned NEs; (2) translation cost, which is similar to IBM model-1 (Brown et al. 1993); and (3) tagging cost, which evaluates bigram probabilities of the aligned NEs based on the same NE type.
Set I (with 110,874 aligned sentence pairs) by the GIZA++ toolkit (Och and Ney 2003), the transliteration cost is trained on all person names (all are transliterated) and translit-erated location and organization names included in Training Set II. The tagging cost is trained on the tagging result of Training Set I by the initial NE detection system.
F-score (regarding their NE types) is obtained from this baseline system. This relatively poor performance is mainly due to errors in the initial NE recognition stage that are brought into the subsequent alignment stage. To diminish the accumulative effect of errors, the same expansion strategy described in Section 3.3 is then adopted to enlarge the possible NE candidate set. However, only a slight improvement is obtained (from 64.1% to 68.4% for type-sensitive F-score), as shown in Table 3 in Section 4.3. Therefore, it is conjectured that the baseline alignment model is unable to perform well if the features proposed in this article are not adopted. 4.3 The Re-identification and Alignment Joint Model
To examine the individual effect of features adopted in the model, a series of experi-ments are first conducted on the development set. All features mentioned in Section 3 are verified by their contributions and are then adopted for further experiments on the test set. Table 3 lists only the representative performance of NE alignment (NEA) on the test set, and gives two performance measures for the experiments. The first one (named type-insensitive ) only checks the scope of each NE without taking its associated
NE type into account (which is the approach adopted in most of the literature on NE recognition), and is reported as the main metric in Table 3. The second one (named type-sensitive ) also evaluates the associated NE type of each NE. To evaluate the type-sensitive performance for NE pairs with correct boundaries, we give one point to any
NE pair that also possesses the correct type-tags on both sides, and give 0.5% if only one side is correct. Of course, zero points are given if both types are incorrect or the boundary of any NE is incorrect. With the rules specified herein, the type-sensitive results are also given within the parentheses in Table 3, and a large degradation is observed. The configurations of various experiments are listed as follows.
ExpB: This is the baseline system (Huang, Vogel, and Waibel 2003), which is re-Exp1: Exp1 (named B-Probabilities ) adopts all bilingual related probabilities involved in 242
Exp2: Furthermore, because the NE alignment probability would favor the candidates
Exp3: Exp3 (named N-Full Model ) manifests the full power of the proposed recognition in this article and to normalize all feature probabilities. This configuration will thus be taken for further improvement in the following sections.
 features should be weighted differently according to their contribution, however. Those weighting coefficients can be learned from the development set via the well-known
MinimumErrorRateTraining approach (Schl  X  uter and Ney 2001; Och 2003) (commonly abbreviated as MERT). To save computational cost, we only re-evaluate the scores of candidate pairs in a pre-generated pool, instead of regenerating new candidate pairs each time when W t (the vector of weighting coefficients at i -th iteration) is updated to
W t + 1 (of the next iteration). For each sentence pair, its corresponding pool is first created by using W 0 (i.e., Exp3) to generate the top 50 NE pairs process. Subsequently, when we switch W t to W t + 1 , we only re-score (and then re-rank) those candidate pairs inside the pool according to W t + 1
MERT training ( MERT-W, N-Full Model , abbreviated as MERT-W). The result demon-strates that MERT is effective and useful. Entries in bold indicate that the model signif-icantly outperforms the baseline system. (All statistical significance tests in this article are measured with 95% confidence level on 1,000 re-sampling batches [Zhang, Vogel, and Waibel 2004]). the test set type-insensitive F-score of identified NE pairs from 78.4% to 87.1% (11.1% relative improvement), and the type-sensitive F-score from 68.4% to 81.7% (19.4% relative improvement). Therefore, this MERT-W version is adopted in all further experiments. 4.4 Effect of Adopting Different Initial NE Recognizers
To study whether the final performance of NE alignment is sensitive to the choice of initial NE recognizers, we investigate the final alignment performance across different Chinese and English NE recognizers.
 (Wu X  X  system, adopted earlier) but with different English NE recognizers that include the Mallet toolkit (used before), the Stanford NE recognizer (Finkel, Grenager, and
Manning 2005), and Minor Third (Cohen 2004). Table 4 shows the type-insensitive and type-sensitive (within parentheses) results. Table 5 shows the effect on NE alignment performance. From Tables 4 and 5, we find that NE alignment performance is actually not sensitive to the NE recognition result. Although the performance of different NE recognizers are various (type-insensitive 13 F-scores are 90.1%, 92.1%, and 92.5%, re-spectively), the gaps among their corresponding NE alignment results are negligible (type-sensitive F-scores of weighted versions are 81.7%, 81.4%, and 81.4%, respectively), as their candidate sets are enlarged based on initially recognized NEs. It is also note-worthy that although the F-score of the Stanford NE recognizer is higher than that of the Mallet toolkit, its corresponding NE alignment performance is lower than the model based on the Mallet toolkit. We conjecture that the lower recall of Stanford NE 244 recognizer leads to lower NE alignment performance because the recall of NER is closely related to the NE pair inclusion rate (please refer to footnote 1), which is the upper bound of its corresponding NE alignment performance.
 ognizer (Mallet) but with different Chinese NE recognizers, including Wu X  X  system (as before), BaseNER (Zhao and Kit 2008), and S-MSRSeg (Gao, Li, Wu, and Huang 2005). The comparisons are given in Tables 6 and 7. From these tables we also see that the
NE alignment result is not sensitive to the NE recognition result (84.1% to 87.4% type-insensitive for NER vs. 80.1% to 81.7% type-sensitive in F-score for NEA), although the performance of NE alignment is related to the recall of the Chinese NE recognizer (the weaker side). We also note that the type-insensitive F-score performance gap among various English NE recognizers in Table 5 is less than that of the Chinese NE recognizers in Table 7 (0.2% vs. 1.3%), which is mainly due to the different gaps among their original performances (2.4% vs. 3.3%, shown by Tables 4 and 6).
 and the worst English NE recognizer (Minor Third) is conducted in Table 8. From Table 8 we see that the final NE alignment performance is primarily determined by the weaker side, which is the one that gives the lower recognition recall rate. In this particular case, the performance of the combination of S-MSRSeg and Minor Third (79.9% type-sensitive F-score) is mainly driven by the performance of the Chinese S-MSRSeg (80.1% in Table 7). This is because the NE pair inclusion rate is usually dominated by the weaker side. 4.5 Effectiveness of the Proposed Model Across Different Domains
To test the effectiveness of the joint model across domains, we compare the baseline and our joint model on three different domains (News, HK Hansards, and Com-puter Technology). To do this, two other test sets are selected from HK Hansards (LDC2004T08) and from the computer domain (training data in CWMT08), tively (the test set used in the previous sections is from the News domain). Each of these new test sets also includes 300 randomly selected sentence pairs.
 domains. Also, it is clear from Table 10 that our joint model outperforms the baseline in all three domains, which indicates that the advantage of our joint model holds over various domains. On the other hand, the smaller improvement observed in the HK Hansards domain might be due to the possibly easier task of initial NE recognition and
NE alignment. 15 (Note that the baseline performance in this domain is much higher than others X  X ith an NE alignment type-sensitive F-score of 83.7% compared with 246 68.4% and 70.3% in News and Computer domains, respectively). Therefore, those novel features of our joint model are not crucial in easy cases. 4.6 Maximum Entropy Framework with Primitive Features
We propose and derive the model described previously in a principled manner. One might wonder, however, whether it is worthwhile to derive such a model after all related features have been proposed, as all proposed features can also be directly integrated into the well-known maximum entropy (ME) framework (Berger, Della Pietra, and
Della Pietra 1996) without making any assumptions. To show that not only features, but also the adopted model contributes to performance improvement, we build an
ME model that directly adopts all primitive features mentioned previously as its input (including the internal component alignment-pair, initial and final NE type, NE bigram-based string, and left/right distance), without involving any related probabilities derived in the proposed model.
 pairs that include at least one NE pair are first extracted from Training Set I. A total of 90,412 sentence pairs are obtained, as some sentence pairs only have either Chinese or
English NEs, and 298,302 NE pairs are identified. This ME method is implemented with the YASMET 16 package, and is tested under various training-set sizes (400, 4,000, 40,000, and 90,412 sentence pairs). Because the NEs of the bilingual NE pair list (Training Set II) do not contain their corresponding sentences, the ME approach lacks the necessary context to extract specific ME features and hence this list is left out of our training data for both the baseline ME model and our joint model.
 age 17 with five classes (i.e., PER, LOC, ORG, Incorrect-Boundaries, Correct-Boundaries-
Incorrect-Type). A five-class approach outperforms a three-class approach (YASMET) in this case (it has many more features as well). Table 11 shows only the type-sensitive
F-scores evaluated on the same test set to save space. The data within the parentheses are relative improvements, and entries in bold indicate that the performance of the derived model is statistically better than that of the ME models.
 model. Because a reasonably derived model not only shares the same training set with the primitive ME approach, but also enjoys the additional knowledge introduced by the human researcher (i.e., the assumptions/constraints implied by the model), it is not surprising that a good model does perform well, and the relative improvement becomes more noticeable when the training set becomes smaller. the NE alignments and Maxent fails to do so on the test set, we find that the internal component alignment-pair feature in the Maxent approach to be dominant in causing 56% of the errors (10 out of 18). In contrast, our corresponding internal mapping prob-80% of the time (8 out of 10).
 which is incorrectly linked to Bolivia holds as a NE pair by the ME approach, whereas our model correctly aligns  X   X   X   X   X   X  X ith Bolivia .Thisisbecause X  transliterated into Bolivia ,but X   X   X   X  is translated into holds .Given T = LOC, the in- X   X   X   X  X nd hold within an LOC NE pair, and prefers the correct result. This example illustrates the utility of the explicit dependency constraint imposed by the model, which is not possible in the ME approach. 5. Discussion and Error Analysis
Although the proposed model substantially improves alignment performance, errors do remain. Therefore, we would like to know what the limitations of the proposed model are, and what kinds of problems still remain X  X n essential component in finding future directions for further improvements. In the test set, a total of 718 NE reference-pairs and 739 aligned NE pairs are generated from the proposed joint model (MERT-W version).
Among the generated NE pairs, there are 104 (out of 739) boundary errors (regardless of their re-assigned types), or 14.1%. Also, among the remaining 635 NE pairs with correct boundaries, 41 (6.5%) are re-assigned to the incorrect NE type. Boundary identification, therefore, is still a crucial problem.
 limits. As mentioned in Section 3.3, the inclusion rate of those desired NE pairs (within the Cartesian product of expanded candidate sets C K 1 and E the system adopted in the final selection stage, which in the current setting is 95.3%.
In comparison, the type-insensitive F-score of MERT-W is 87.1%, indicating that there is still a significant 8.2% scope for improvement, even though a great improvement has already been made over the baseline system. We examine this gap and propose solutions to address the errors in the following section. 5.1 Classification of Type-Insensitive NE Pair Errors
There are 111 type-insensitive NE pair errors in the test set (104 boundary errors plus 7 others not included in the output list due to missing anchors), and these can be classified into the following six main categories. (I) Reference Inconsistency (11%): The NE references from Chinese and English (II) Missing Anchor (14%): Although the NE reference is consistent, not all their 248 (III) Over-generating Anchors (10%): Similarly, additional spurious NE anchors
The remaining cases with correct corresponding anchors are further classified as follows. (IV) Inconsistent Components (12%): Although their corresponding anchors are (V) Expansion Limitation (5%): Even though all the internal components are (VI) Others (48%): Even if all internal components are matched and their a specified NE pair, and the unmatched components are underlined. The numbers in parentheses in the last column denote the number of NE pairs of the corresponding category. Among all categories, Category (I) errors (Reference Inconsistency, 11%) are irrelevant to the alignment model, and are attributed to the asymmetrical distribution of bilingual NEs (corresponding NEs might sometimes be missed or replaced by the pronoun it ). As illustrated in Table 12, CNE  X   X   X   X   X ( Fossett ) is initially recognized as  X   X   X   X  and finally linked to an irrelevant ENE Northam (  X   X  corresponding counterparts Fossett and  X   X   X   X  do not appear in the original sentence pair, and our alignment model assumes that the linking between NEs is a one-to-one mapping. One possible simple solution would be to set a minimal threshold on alignment scores that filters out such spurious linking. This may introduce the risk that some correct NE pairs might be pruned away at the same time, however.

NE anchors in the initial recognition stage. As an example in Table 12, the corresponding anchor of the Chinese NE  X   X   X   X ( ASEAN ) is not initially identified. Because each candidate set is generated from the given anchor, a missing anchor implies that its associated candidate set will not exist, thereby making it impossible to generate the corresponding NE pair. Although increasing the number of output anchors generated from the initial recognition stage can relieve this problem, doing so makes the subsequent alignment task harder. Additionally, the spurious anchors generated might introduce even more errors.
 anchors generated in the initial recognition stage. For instance, the CNE  X  originally aligned with the ENE Lee Nam-shin by transliteration. A spurious ENE South is also identified in the initial stage, however. This spurious ENE South is then incorrectly linked to a virtual CNE with the highest score,  X   X  , X  which is a sub-string of the desired
CNE  X   X   X   X  , X  and also a Chinese translation for south . This prevents the correct NE pair from being generated. Both missing and over-generating anchor problems are largely dependent on the NE recognition toolkits adopted in the initial stage. Using the current expansion strategy, the initial NE recognizers with lower recall (or precision) tend to result in worse NE-pair recall (or precision) in the final alignment stage. ponents within NEs that were not originally matched. Because words in NEs are not always translated literally, there are insertions and deletions during NE translation.
As an example, shown in Table 12 and illustrated previously, the incorrect result {  X   X   X   X  ::[Berlingen] } is generated for its reference {  X   X   X   X   X  its Chinese component  X   X   X ( town ) is originally unmatched. In the worse case, those unmatched components could interleave with matched components within the NE pair, and thus prevent some matched components from being included. For example, in the reference {  X   X   X   X   X   X   X  ::[European Commission] } , both the Chinese compo-nents  X   X   X ( alliance )and X   X   X   X ( execution ) have no counterparts, and they would have prevented the matched portion {  X   X   X  ::[Commission] } from being included in the final output. As a result, only {  X  ::[European] } is eventually extracted. To tackle this problem of component insertions/deletions that sometimes occur in English X  X hinese translation, the alignment model should be further enhanced to allow the component to be linked to an empty element, NULL. Introducing this freedom, however, might have the side effect of including additional spurious Chinese characters (or English words).
Further study is required to justify this idea; given that this category accounts for only 12% of the errors, we propose to defer this for later studies.
 problem that the desired candidate (i.e., reference) is excluded during the candidate 250 set expansion stage. Table 12 shows that the final output of the reference  X   X   X   X   X   X  ::[British Pharmaceutical Firm GlaxoSmithKline]
This reference has three Chinese initial anchors:  X   X   X   X ( British ),  X   X   X   X   X   X ( SmithKline ), and it also has two English initial anchors: British Pharmaceuti-cal and Firm GlaxoSmithKline . Because only four characters are allowed for boundary enlarging/shrinking for Chinese anchors (three words for English anchors), the refer-ence CNE is beyond the scope of any Chinese initial anchor during the expansion stage.
Therefore, it could not be included in the candidate set for final selection. In addition, the adjacent Chinese component  X   X   X   X   X  could not be recovered due to the translation re-ordering of the Chinese components X  X ts counterpart Glaxo is far apart from British in the given sentence. Similarly, the adjacent English words Pharmaceutical Firm could not be recovered, as its counterpart  X   X   X   X  is far apart from  X  the constraint during the expansion stage can increase the reference coverage, it must be weighed against the corresponding lower precision.
 proposed model still makes a significant number of mistakes. These kinds of errors,
Category (VI) (Others, 48%), account for the largest portion among all errors. There-fore, they are further hierarchically classified in Table 13 according to their associated transformation types and origins.

Other Category in Table 12) are first classified by their corresponding transformation types: (VI.A) Abnormal Transformation (27%), whose transformation types are not as-sumed by the model (i.e., neither normally translated nor normally transliterated); and (VI.B) Normal Transformation (21%), whose components are either normally translated or normally transliterated. A detailed explanation is given as follows.
 types that are not assumed by our alignment model. It can be further divided into three classes according to their origins: (VI.A.1) English Acronym (11%), whose ENE is an acronym; (VI.A.2) Chinese Abbreviation (8%), whose CNE is an abbreviation; and (VI.A.3)
Irregular Translation (8%), whose components are transformed neither semantically nor phonetically. These cases are interesting and are illustrated herein.
  X   X   X   X ( International Criminal Court ) is tagged as  X   X   X   X   X   X   X  its English counterpart is the acronym ICC .Linking X   X   X   X   X   X   X  beyond the ability of our model. On the other hand, Chinese NEs are also occasionally abbreviated. For example, in Class (VI.A.2) (Chinese Abbreviation, 8%),  X 
Chinese abbreviation of  X   X   X   X   X   X ( Peace-keeping ), which is also difficult to align to its English counterpart. Such acronym and abbreviation cases are not rare in NE translation. We believe that an expansion table (or even anaphora analysis) for acronyms and abbreviations can help handle such issues.
 neither semantically nor phonetically. As an example for Class (VI.A.3) (Irregular Trans-lation, 8%), CNE  X   X   X   X  (which is the name of a Japanese emperor, and consists of Japanese kanji characters) is incorrectly linked to an English word Hirohito (whose Chinese translation should be  X   X   X   X ), although it should be linked to ENE Akihito . In this example, the Japanese kanji  X   X   X   X  is directly adopted as the corresponding
Chinese characters (as those characters are originally borrowed from Chinese), which would be pronounced as ming-ren in Chinese and thus deviates significantly from the
English pronunciation of Akihito . Therefore, it is translated neither semantically nor phonetically. This phenomenon mainly occurs in loanwords or out-of-vocabulary terms and the model would have to be extended to cover those new conversion types. Such an extension is very likely to be language-pair dependent (e.g., with an additional Japanese phonetic table for cases such as the given example), however. normally. It can be further divided into two classes according to their sources: (VI.B.1)
Bias from NE likelihoods (18%), which prefers the incorrect NE pair scope due to its associated monolingual likelihood scores, and (VI.B.2) Bias from Bilingual Probabilities (3%), which introduces extra non-NE words in the output due to high alignment scores of words that are adjacent to the NE. Further illustration is given as follows.  X   X  X  X   X   X  and the English NE South and North Koreas are initially recognized as  X  ( Korea )and North Koreas , respectively; the model finally chooses a partial alignment result {  X   X  ::[North Koreas] } . In this case, every component in either the CNE or the ENE is well matched to its counterpart. Therefore, there is no significant differ-ence among the alignment scores of various NE pair candidates with different scopes (such as {  X  ::[Koreas] } , {  X   X  ::[North Koreas] } ,and Koreas] } ,etc.) output of the reference {  X   X   X   X  ::[Beatrix] } is {  X   X   X 
Chinese initial anchors:  X   X   X   X  (pronounced as bi-cui in Chinese) and  X 
According to the training data, both  X   X   X ( ke )and X   X   X   X ( ke-si ) could be aligned to the English letter x . There is no significant difference, therefore, in the alignment scores between {  X   X   X  ::[Beatrix] } and {  X   X   X   X  ::[Beatrix] } cases (as described in Section 2.2), monolingual likelihood scores dominate the scope 252 preference. Addressing this shortcoming is beyond the capability of the alignment model, and the adjacent contextual (non-NE) bigrams, to be proposed later, can only correct 5 of the 20 errors in this class. No easy and effective solution for this kind of problem can currently be found.
 for those cases where incorrect NE pairs are selected due to the bilingual align-ment score. For example, the final output of the reference {  X   X   X   X  X  X  ::[championship at World Cup] } . Although both desired CNE and ENE have already been correctly recognized in the initial stage, the bilingual NE alignment feature prefers to include the additional Chinese common noun  X 
English word championship , because they are a perfect mutual translation. At first glance, it seems that we could use the lower casing of championship as a feature. Other refer-ences with lower case words could also be found (e.g., {  X   X   X  X  X   X   X   X   X  ministerial meeting] } ), however. Therefore, additional features such as their relative positions are also required.
  X   X   X   X   X   X ( yi-si-lan-bao , in Chinese pronunciation) and the English NE Islamabad are both correctly recognized in the initial stage. The model chooses a longer align-ment result {  X   X   X   X   X  ::[Islamabad] } in the final stage, however. In this case, the
Chinese character  X   X   X  (land, pronounced as di in Chinese) could also be phoneti-cally aligned to syllable  X  X  X  with high probability. Therefore, there is no significant difference in the alignment scores between  X   X   X   X  ::[Islamabad] and  X  ::[Islamabad]. We may need to resort to using a richer bilingual context (i.e.,  X   X   X   X   X   X   X   X  ...  X ; In the map of Islamabad ... ) as features to resolve this issue. If its
Chinese adjacent contextual word  X   X   X   X ( map ,pronouncedas di-tu ) could be aligned to the corresponding English word map , and given that  X   X   X  nouns in their respective languages, it is possible to determine that this extra Chinese character  X   X   X  should not be linked to the ENE Islamabad .
 be more complex and must use additional features (possibly knowledge-rich features).
Because this class accounts for only 3% of the errors, we leave the problem for future work. 5.1.1 Features Contributing to Boundary Errors. Among the 111 alignment errors analyzed, 76 of them 18 have their references covered by the expanded candidate set. The scores of their associated features are then further inspected to determine which features contribute to the errors. This is assessed by counting the number of times (denoted by #Worst ) that a specific weighted feature-score gets the worst difference when those incorrect NE pairs are compared to their corresponding references. A large #Worst would imply that this feature should get more attention in pursuing further perfor-mance improvement.
 malized TS/TL Transformation) is the most dominant feature in making those errors.
Following this, F2 (Normalized Translation Mode), F7 (Normalized Chinese Bigram), and F10 (Normalized English Bigram) are on the second tier. Both F1 and F2 are related to alignment, which coincides with our observation that alignment-related Categories (i.e., IV, VI.A, and VI.B.2) occupy the largest portion of errors (62% of 76 inspected errors). The errors dominated by F7 and F10 are further discussed as follows. a spurious anchor, and two are due to abnormal transformations), all others selected the sub-strings of their corresponding CNE references. Furthermore, each selected sub-string included the Chinese bigrams that appear more frequently than those within the remaining sub-string (of its reference CNE). In other words, F7 tends to select only the portion with high frequency bigrams when all related components are aligned. For example, for the reference {  X   X   X   X   X   X   X   X  ::[National Center for Tobacco-Free
Kids] } ,only {  X   X  ::[Center] } is extracted, as this Chinese bigram is frequently used in various organization names. Further inspection of those seven cases (which prefer the sub-string) reveals that three of them are with unmatched components (Category IV); therefore only four of them are, in fact, due to the problem of F7.
 chose the sub-strings of their corresponding ENE reference, and the remaining six errors selected the strings unrelated to the reference due to spurious anchors and an acronym. It therefore seems that different languages possess different error patterns. ing related bigrams. This is because the current bigram model does not consider the im-plied restriction on the context surrounding the given CNE. In other words, a given CNE also implies that its left and right adjacent characters should not be a part of CNE (or its left and right adjacent characters must be in a non-NE region). In our data set, two adja-cent non-NE Chinese characters (or words for English) are found to be sufficient for both left and right contexts. Therefore, the following additional terms are further proposed to take care of this issue: P ( cc  X  1 | cc 0 , T )  X  P ( cc where cc L 1 is the given CNE, cc 0 and cc L + 1 are its left and right adjacent non-NE char-acters, respectively. This formula can be easily derived from P ( C to Equation (8). The derivation also applies to English. To test this supposition, the related experiment (Exp4 [ MERT-W, N+Full Model ] specified in Table 3) is updated as Experiment 5 with the probability features shown here.
 denoted by MERT-W-CB ) replaces [ L l = 1 P ( cc l | cc l
P ( cc  X  1 | cc 0 , T )  X  P ( cc 0 | cc 1 , T )  X  P ( cc L + 2 The same is done for English.
 comparison). The entries in bold indicate statistically significant improvements over 254 their counterparts. Results show that the performance has indeed improved, and six of the targeted seven cases (four CNE and three ENE errors, as mentioned previously) have been corrected (the remaining error is due to data sparseness and cannot be corrected). According to coefficient weighting by MERT process, P ( cc given NE, the more influential it is. This observation confirms our intuition about the context effect. A similar trend is also observed for other contextual non-NE characters. 5.2 NE Type Errors In addition to the 111 boundary errors just analyzed, there are also NE type errors. Among those 635 NE pairs with correct boundaries in the test set, there are 41 (6.5%) NE type errors in Exp4 (MERT-W). Among them, 175 PER, 248 LOC, and 212 ORG
NE types are assigned. The associated confusion matrix of various NE types is shown in Table 16 (the numbers within the parentheses are the relative ratios of their output types). All except 5 of the 41 NE type errors originated from transliterated NE pairs (not shown in the table). This is consistent with our observation that even a human annotator finds it challenging to identify correct types for transliterated NE pairs in the absence of context.
 and ORG is a distant third. In addition, PER and LOC are the types that are most often confused with one another. These observations match the distribution of transliterations in each type (the transliteration mode ratios for PER, LOC, and ORG are 100%, 71.4%, and 25.2%, respectively), as it is very difficult to determine the type when a NE is transliterated without context.
 non-NE characters are also helpful. For example, {  X   X   X  ::[Myers] identified as LOC, when in fact it should have been PER in the context  X  ( president Myers ). The left adjacent contextual bigrams  X  that the following NE is likely to be PER. Table 15 shows that an additional four type errors are also corrected apart from the six boundary errors. Therefore, in comparison with the original MERT-W, this new version (MERT-W-CB) gains more in type-sensitive
F-score (an increase of 1.5%, from 81.5% to 83.0%) than in type-insensitive F-score (an increase of 0.9%, from 87.1% to 88.0%).
 biguating NE types, however. For instance, the reference {  X   X   X  rectly identified as PER, which should be LOC in the context  X 
Because  X   X   X   X   X  X ollowsapreposition X   X   X ( at ) in the associated context, it indicates that  X   X   X   X   X  is a location name. We can also easily find counterexamples, however, such as  X   X   X  X  X   X   X   X ( around Bush ), in which  X   X  X  X   X ( Bush ) is PER, not LOC. In fact, both PER and LOC can be freely exchanged in this situation in either a Chinese or English context. Therefore, more complicated syntactic or semantic information is required in some cases involving transliteration.
 initial NE types (i.e., Tc and Te ) assigned in the first stage. Among 41 errors, 22 (54%) have both incorrect Tc and Te , 16 (39%) have correct Tc but wrong Te , and only 3 (7%) have correct Te but incorrect Tc . This distribution shows that Tc is more reliably assigned in the first stage than is Te , which confirms the observation in Ji and Grishman (2006) that English NE type assignment is more challenging. 5.2.1 Features Contributing to Type Errors. Similarly, the study for #Worst on weighted feature-scores is also performed under MERT-W-CB (i.e., Exp5). There are 37 type errors with correct boundaries, and we have examined that F4 (NE Type Re-assignment) is the most dominant feature in making these errors. Because this feature LogP ( T (Equation [7]) always assigns an incorrect type when both Tc and Te are incorrect (11 out of 13 F4 errors belong to this class), it is not surprising that it is ranked at the top
LogP (  X  A | T ) in Equation (6) always prefers PER (which are always completely translit-erated in the corpus) when all components in an NE are transliterated (i.e.,  X 
Therefore, the feature is ranked second (31 out of 37 errors are complete transliterations, although only 10 of them should have been assigned PER). It is found that all nine cases in this category are not PER (only two of them are not transliterated), which further supports our analysis. Solving these type errors requires that these two features be conditioned on more features, and requires further study. Finally, the top four features in making type errors are related to alignment (Equations [6] and [7]), which indicates that monolingual lexicon information (both English and Chinese bigrams) is more reliable in deciding NE type. 6. Applications of the Proposed Model It would be interesting to know how the proposed model performs in real applications.
Because MERT-W performs best in our tests, it is adopted in this study on real applica-tions. Section 6.1 presents the effectiveness of improving NE recognition, and Section 6.2 shows how the improved NE recognition can be used in learning a monolingual NE recognition model (also NE translation table/models) in a semi-supervised manner. 6.1 On Improving Monolingual NE Recognition
As explained in Section 2.1, the alignment result can also be used to refine the initially recognized NEs. The improvements that MERT-W made in refining the boundaries and
NE types of those initially recognized Chinese/English NEs are shown in Tables 17 and 18, respectively. For comparison, the rows associated with the initial recognizers and the 256 alignment baseline systems are also given in the two tables (as before, the entries in bold indicate that differences are statistically significant). In addition, figures in parentheses indicate the corresponding differences in performance compared to the initial version (shown in Table 2).
 proved the initial NE recognition type-insensitive results for both Chinese and English. It also shows that MERT-W significantly outperforms the baseline. In particular, Chinese ORG is observed to yield the largest improvement among NE types in both Chinese and
English, which matches our previous observations that the boundary of a Chinese ORG is difficult to identify using only the information from the Chinese sentence. significantly improves the initial NE recognition results for both Chinese and English. Note that English ORG yields the largest gain among NE types in both Chinese and
English, again supporting our earlier observation that an English ORG cannot be easily identified when only the English sentence is available. It must be noted that the baseline alignment model deteriorates the original NE recognition in overall performance (even though it can correct some NE initial boundary errors as shown in Table 17), because it does not use the features/constraints proposed in the joint model. 6.2 On Learning NE Recognition Models via Semi-Supervised Learning
In many NLP applications, the associated process will be considerably simplified if the included NEs can be identified first. Therefore, it is important to have a good NE recognizer that has been well trained. Various domains frequently have different sets of NEs, however, and new NEs also emerge over time. We thus need to periodically update the NE recognition model (also the NE translation table/model, if it is for MT), which necessitates the need to ensure short training times (including set-up time and human effort). This requirement can be addressed well in a semi-supervised learning set-up where parameters/tables are learned from a large unlabeled corpus with a small (albeit human) annotated seed set.
 does not imply a minimizing of error rate at the same time. Without additional con-straints, a monolingual NE model is usually unable to converge to the desired point in the parameter space. On the other hand, as shown in the previous section, the align-ment module can further refine the initially recognized NEs with additional mapping constraints from the other language. The proposed joint model thus can be used to train the monolingual NE recognition model via semi-supervised learning on a large un-labeled bilingual corpus. In other words, when semi-supervised learning is conducted for learning the NE recognition model, MERT-W is expected to guide the search pro-cess for convergence towards the human annotation. This advantage is important for regularly updating the NE recognition and translation table/models.
 (1) A small pre-labeled corpus acts as seed data. Based on these seed data, (2) Perform the Chinese/English NE recognition toolkits and the NE (3) Denote the located NE pairs as correctly labeled and combine them with (4) Re-train the Chinese/English NE recognition toolkit and also re-train the (5) Repeat Steps (2) through (4) until convergence. The final Chinese/English re-trained (because it is not an open source toolkit), only the English NE recognizer and 258 the alignment model are updated during training iterations. In our experiments, 50,412 sentence pairs are first extracted from Training Set I as unlabeled data. Various labeled data sets are then extracted from the remaining data as seed corpora with different sizes (100, 400, 4,000, and 40,000 sentence pairs). The test set is still the same 300 sentence pairs that were adopted previously.
 gence. 19 The Initial-NER in Table 19 indicates the initial performance of the NER model re-trained from different seed corpora. Three different approaches are tested: (1) English
NER only ( NER-Only ), (2) the alignment baseline model ( NER+Alignment-Baseline ), and (3) our weighted joint model MERT-W ( NER+Alignment-Weighted ). The first case performs semi-supervised learning only on English data without involving alignment, whereas the last two cases include alignment, and both the English NER model and the alignment model are re-trained during iterations. The numbers in parentheses show relative improvements over Initial-NER . The entries in bold indicate statistically significant improvements over Initial-NER .
 convergence. This is because maximizing likelihood does not imply minimizing the error rate. With additional mapping constraints from the other language, however, the alignment module can guide the search process to converge to a more desirable point in the parameter space. It must be noted here that the contribution of additional constraints increases with smaller seed corpora, because constraints become more important when the labeled data set is smaller.
 before and after convergence due to space constraints. Two different models are tested: (1) the alignment baseline model ( NER+Alignment-Baseline ), and (2) our weighted joint model ( NER+Alignment-Joint ). The data in parentheses indicate relative improvements over the performance before training. The entries in bold indicate statistically significant improvements over the model before training.
 semi-supervised learning. Note that the improvement is greater on smaller data sets, which is common in most semi-supervised learning tasks. learning process in comparison with the alignment-baseline model, because informa-tion from the aligned sentence is utilized more effectively. Results demonstrate that the proposed joint model, combined with semi-supervised learning, offers significant improvement for semi-automatically updating the NE recognition model and the NE translation table. Additionally, the impact is greater when less time is available for labeling seed data. 7. Related Work
There is significant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random fields (McCallum and Li 2003; Jiao et al. 2006), modified transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002),
AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global information (e.g., label consistency, context features) from monolingual resources have been adopted (Krishman and Manning 2006; Zhou and Su 2006). In prior work on the use of bilingual
NE alignment for NE recognition, Huang and Vogel (2004) used an iterative process to extract a smaller but cleaner NE translation dictionary and then used the dictionary to improve the monolingual NE annotation quality. Ji and Grishman (2007) adopted several heuristic rules for using bilingual-text information to correct NE recognition errors.
 usually adopted. Typically, an NE is either transliterated or semantically translated. For transliteration, Knight and Graehl (1998) were pioneers in adopting the probabilistic model to align the components within an NE pair. Since then, similar approaches have been applied to various language pairs such as English/Arabic (Stalls and Knight 1998), English/Chinese (Chen et al. 1998b; Wan and Verspoor 1998; Lin and Chen 2002; Lee and Chang 2003; Lee, Chang, and Jang 2003; Gao, Wong, and Lam 2004; 260
Pervouchine, Li, and Lin 2009), English/Japanese (Knight and Graehl 1998; Tsuji 2002), and English/Korean (Lee and Choi 1997; Oh and Choi 2002, 2005). Moreover, Li,
Zhang, and Su (2004), and Li et al. (2007) presented a joint source channel model for transliteration, and automated the semantic transliteration process, which takes origin and gender into account for personal names.
 et al. (2005) proposed a phrase-based context-dependent joint probability model for semantic translation, which is similar to phrase-level translation models in statistical MT (Zong and Seligman 2005; Hu, Zong, and Xu 2006). Chen, Yang, and Lin (2003) and Chen et al. (2006) studied formulation and transformation rules for English X  X hinese
NEs. They adopted a frequency-based approach for extracting key words of NEs with or without dictionary assistance and constructed transformation rules from the bilingual
NE corpus. Their studies focused on transformation rules with particular attention to distinguishing translated parts from transliterated parts; the performance of rule-application in NE translation was not described, however. Chen and Zong (2008) pro-posed a chunk-based probabilistic translation model for organization names, although, its application to person and location names has not been studied.
 (translation, transliteration, or other abnormal types), the NE transliteration/translation models mentioned usually lead to unsatisfactory results, especially for infrequently occurring NEs. Recent studies have therefore focused on extracting new NE pairs from either bilingual corpora or Web resources, so that the corresponding human translation can be directly adopted (or used for training). To do this, however, NE alignment is an essential tool. Due to the relatively poor quality of Web data, such alignment approaches are usually limited unless significant effort is devoted to data cleaning; therefore, we do not discuss these approaches.
 found in the literature are conducted after an initial NE identification stage so that the complexity of the task can be reduced. The associated cost is that those initial NE recognition errors propagate into the following alignment stage. Both symmetric (which first identifies NEs in both languages) and asymmetric (which first identifies NEs in only one language) strategies have been proposed to mitigate this problem (Moore 2003), and are described here.
 translation dictionary from the bilingual corpus, and then used it to improve the
NE annotation performance iteratively. Huang, Vogel, and Waibel (2003) described a multi-feature NE alignment model to extract NE equivalences (with translation, transliteration, and tagging features), from which a NE translation dictionary was then constructed. Kumano et al. (2004) proposed a method to extract English X  X hinese NE pairs from a content-aligned corpus. This approach tries to find the correspondences between bilingual NE groups based on the similarity in their order of appearance in each document. Additionally, an abridged version of our work has been presented in our ACL-10 paper (Chen, Zong, and Su 2010). Among those symmetric approaches, only Huang, Vogel, and Waibel and Chen, Zong, and Su adopt the expansion strategy, described below.
 to translate NEs from Arabic to English using monolingual and bilingual resources.
Given an Arabic NE, they used transliteration models (including a phonetic-based and a spelling-based model), a bilingual dictionary, and an English news corpus to first generate a list of English candidates, which were then re-scored by a Web resource.
Moore (2003) developed an approach to learning phrase translations from a parallel corpus based on a sequence of cost models. A maximum entropy model for NE align-ment was presented in Feng, Lv, and Zhou (2004). Lee, Chang, and Jang (2006) proposed to align bilingual NEs in a bilingual corpus by incorporating a statistical model with multiple sources. Turning to comparable corpora, Shao and Ng (2004) presented a hybrid method to mine new translations from Chinese X  X nglish comparable corpora, combining both transliteration and context information. Sproat, Tao, and Zhai (2006) investigated the Chinese X  X nglish NE transliteration equivalence within comparable corpora.
 target side from affecting alignment, errors on the source side continue to propagate to later stages. To reduce error propagation from both the source and the target, Huang,
Vogel, and Waibel (2003) proposed to first identify the NEs in both the source and target, and then enlarge the obtained NE candidate sets for both languages before conducting alignment. Based on the observation that NE boundaries are frequently identified in-correctly, the enlarging procedure is done by treating the original recognition results as anchors and then increasing the number of candidates by expanding or shrinking the boundaries of those originally recognized NEs in both languages.
 et al. (2003) and others in several ways, however. First, in all the alignment papers mentioned here, the adopted probabilities are directly used as features for log-linear combination or ME training without derivation. In contrast, our work fully derives a probabilistic joint model, for both identification and alignment, in a principled way. Second, unlike previous approaches that discard the information of initially identified
NE anchors after the anchors have been expanded, our approach uses this information in the final selection process. Third, we propose new features, such as translation mode and its ratio, boundary shifting distance, and contextual bigrams. Fourth, we introduce a normalization step that removes the systematic bias preferring shorter NEs. Fifth, the effect of each individual feature, the influence of adopting different NE recognizers, the effectiveness across different domains, the effect of using a derived model (compared to ME), and the effect of the alignment model in semi-supervised learning are studied.
Finally, the causes of alignment errors and type re-assignment errors are extensively investigated and categorized. 8. Conclusion
This article develops a novel and principled model for jointly conducting NE recogni-tion and alignment. To the best of our knowledge, this is the first work that formally captures the interactions between NE recognition and NE alignment. The joint model not only greatly improves NE alignment performance, but also significantly boosts NE recognition performance.
 bigram model used in the baseline system. Moreover, both the translation mode ratio and the entity type consistency constraint are critical in identifying the associated
NE boundaries and types, as evidenced by the 21.3% relative improvement on type-sensitive F-score (from 68.4% to 83.0%) in our Chinese X  X nglish NE alignment task. The superiority of the proposed model has been shown to hold over the various domains tested.
 recognized NEs. This is achieved by utilizing additional mapping information from the 262 other language. In our experiments, when semi-supervised learning is conducted to train the adopted English NE model (with only 100 seed sentence pairs), the proposed model greatly boosts the English NE recognition type-sensitive F-score from 36.7% to 47.4% (29.2% relative improvement) in the test set.
 example, Chinese characters and English words adopted in the model are visible units in the given languages, and no language-dependent features, such as morpheme/part-of-speech (or prefix/suffix), are used. In addition, the model does not use linguistic rules or tree banks. Therefore, although our experiments are conducted on Chinese X 
English language pairs, it is expected that the proposed approach can be applied to other language pairs with little adaptation effort.
 Acknowledgments References 264
