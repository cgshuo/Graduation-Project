 Majority of the studies on modeling the evolution of a social network using spectral graph kernels do not consider tempo-ral effects while estimating the kernel parameters. As a re-sult, such kernels fail to capture structural properties of the evolution over the time. In this paper, we propose temporal spectral graph kernels of four popular graph kernels namely path counting, triangle closing, exponential and neumann. Their responses in predicting future growth of the network have been investigated in detail, using two large datasets namely Facebook and DBLP. It is evident from various ex-perimental setups that the proposed temporal spectral graph kernels outperform all of their non-temporal counterparts in predicting future growth of the networks. Given a non-empty set of objects X , a kernel k : X X X  X  R is a measure of similarity between two objects x  X  X  and y  X  X  satisfying two properties; (i) symmetry i.e., k ( x,y ) = k ( y,x ) and (ii) positive semi definite i.e., where c x ,c y  X  R . For a finite set X , a kernel can be uniquely represented by a matrix K of order |X| X |X| where K [ x ][ y ] relates to k ( x,y ). For graph kernels, x and y are either nodes in the graph or the graph itself quantifying how similar two nodes in a graphs are or how similar two graphs are? [1, 2, 3, 4]. In recent studies, graph kernels (in both forms) have been applied in various social network analysis prob-lems such as link prediction [4, 5, 6, 7], network evolution [8, 9], community detection [10]. Social networks evolve over time and solution to above problems can be greatly affected by temporal parameters of the evolution [11, 12]. However, majority of the above studies do not consider temporal pa-rameters. This paper revisits the study [8] of modeling net-Exponential kernel K ( A ) = exp( A ) =
Neumann kernel K ( A ) = ( I  X   X  U X U T )  X  1
Let A s and A t be the adjacency matrices of the source graph and target graph respectively. The predicted target graph A 0 t can be defined using spectral graph kernel as A 0 t = U F ( X  s ) U T where U is constant over time.
Kernel parameters can be learnt using two different ap-proaches; (i) learn the parameter individually for all eigen-values or (ii) learn a common parameter for all the eigen-values that minimizes the average prediction error. This paper uses the second approach and estimates the parame-ters using a polynomial based regression. For learning the kernel parameters, we use a reference dataset. This study uses a validation graph as a reference dataset to estimate the parameters, which is a snapshot of the evolving network taken at a particular time between the source and target snapshots. Considering A s , A v and the A t as the adja-cency matrices of the source, the validation and the target networks respectively, the validation network A v satisfy the following inequality.
 A matrix X &lt; Y iff X [ i ][ j ]  X  Y [ i ][ j ]. For learning pa-rameters, we define an absolute square error using reference dataset as follows: Since U is assumed to be time invariant, the square error sum is defined as follows: where  X  i is the i th eigenvalue and r is the rank of the ma-trix A s and  X  v i is the i th eigenvalue of the matrix A v . Now the task is to find the kernel X  X  parameters that minimize the above square error sum E ( e ) using regression. Table 1 (4 th column) shows the criteria error functions of applying re-gression for all the kernels. The parameters a , b and c are learnt using the reference dataset A v and respective regres-sion function f ( . ).
If we consider a sequence of snapshots taken at different time stamps, we can estimate a sequence of kernel param-eters defining the evolution of the network between subse-quent snapshots. The plots in figure 1 show the changing lowing absolute error.
 where  X  s i and  X  t i are the actual i th eigenvalues of the source and target network graphs and r is the rank of the matrix. In this paper, performance of non-temporal and temporal graph kernels have been investigated using two experimen-tal setups. In the first setup, the source and target graphs are fixed and validation graph changes. It allows us to in-vestigate the effect of validation graph in modeling the evo-lution of the graph. Table 3 compares the performance be-tween different kernels. For all kernels (both temporal and non-temporal), performance increases (error decreases) as we move the validation graph closer to the target graph. It indicates that validation graphs closer to source graph are underspecified and do not capture much information of the target graph. This observation is true for both Facebook and DBLP networks and also for both temporal and non-temporal kernels.

In the second setup, validation and target graphs are fixed and source graph changes. It allows us to investigate the ef-fect of time gap between source and target graph in model-ing the evolution. Since we get the best performance when validation set is closest to the target (in first setup), we therefore fix the validation graph to be closest snapshot (8 th for Facebook and 5 th for DBLP). Table 4 compares the per-formance between different kernels. Since validation graph is close to target, variation in prediction error is small. Still nels, the absolute spectral error is modified as follows: From the Tables 3 and 4, it is evident that temporal ker-nels outperform almost all of its non-temporal counterparts. With proposed model, an improvement of upto 66% over Facebook dataset and upto 40% over DBLP dataset can be achieved. Temporal kernels also predict future evolution better (referring to the experimental cases where validation is closer to source and farther from target in Table 3). Fur-ther among all the kernels, path counting spectral graph kernel outperforms all other kernels for both temporal and non-temporal over both the Facebook and DBLP datasets.
This paper proposes temporal graph kernels for four spec-tral graph kernels namely path counting, triangle closing, exponential kernel,neumann kernel and compares their per-formances using two large datasets namely Facebook and DBLP. From various experimental setups, it can be inferred that non-temporal kernels fail to capture structural growth of the network. In almost all the experimental cases, tem-poral kernels outperform their non-temporal counterparts. [1] S. V. N. Vishwanathan, N. N. Schraudolph, [2] R. I. Kondor and J. D. Lafferty. Diffusion kernels on [3] A. Smola and R. Kondor. Kernels and regularization [4] F. Fouss, L. Yen, A. Pirotte, and M. Saerens. An [5] D. Liben-Nowell and J. Kleinberg. The link-prediction
