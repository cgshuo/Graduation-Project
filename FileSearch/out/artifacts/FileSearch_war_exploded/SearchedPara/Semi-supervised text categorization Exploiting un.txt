 Department of Computer Engineering, Alzahra University, Tehran, Iran 1. Introduction
Data mining can be defined as the nontrivial extraction of implicit, previously unknown, and poten-tially useful information from data [1]. Generally, data mining is the process of analyzing data from different perspectives and summarizing it into useful information. Technically, data mining is the pro-cess of finding correlations or patterns among dozens of fields in large databases. Data are any facts, numbers, images, or text that can be processed by a computer.

Web popularity and large volume of text documents which are available in electronic formats, lead to discovering hidden knowledge from document corpuses. Text Mining is the discovery of new, im-plicit, and previously unknown information by automatically extracting information from text docu-ments. Nowadays almost 80 X 90% data are stored in unstructured or semi-structured forms like text [2, 3].

So text mining is interested in many fields like medicine, bioinformatics, economics and information technology. It can cover many processes like classification, clustering, summarization and information in text mining. Applications of text classification technology are becoming widespread. In the defense against spam e-mail, suspect messages are flagged as potential spam and set aside to facilitate batch uals based on learned profiles of user interest. In content management, documents are categorized into
All these applications are done by machine learning algorithms  X  including Support Vector Machines (SVMs) and K-nearest neighbour  X , however before applying these algorithms, some pre-processing should be done on text data, i.e. a document should be represented into a numeric feature vector. By far, the most common transformation is the  X  X ag of words X , in which each column of a feature vector corresponds to a specific word of the corpus [5].

Supervised learning methods use only labeled data to train and learn classifiers. Due to the diversity obtain, as they require the efforts of experienced human annotators. Meanwhile unlabeled data may be relatively easy to collect in practice.

Recently, semi-supervised learning has been proposed to make use of unlabeled and labeled data by assuming that data with similar attributes lead to similar labels. This learning framework deals with situations where labeled data is only a few while unlabeled data is given in a large quantity. In text are related to different topics and label assigning are difficult and time consuming.

The main algorithms of semi-supervised learning include generative models, Self-training, Co-training, S3VM, various graph-based methods and so on. Self-training is a commonly used method for aggregating technique that achieves strong classifier by using multiple learners [6].
 in text classification and semi-supervised methods. The proposed semi-supervised algorithm and dy-namic weighting are explained in Section 3. After a brief description of our dataset, an experimental 2. Research background the semi-supervised learning with its approaches will be presented. 2.1. Text classification tories, selective dissemination of information to consumers, spam filtering, identification of document which can be too expensive, or simply not feasible given the time constraints of the application or the number of documents involved [4].
 2.2. Semi-supervised learning
Semi-supervised learning is somewhere between supervised and unsupervised learning, so classifier much more unlabeled samples available than labeled ones, i.e. | D L || D U | . Semi-supervised learning task. Its most popular methods are defined as follows [7,8]: In Generative method, by looking only at unlabeled data, marginal data distribution P ( x ) can be estimated. It assumes a model p ( x, y )= allows supervised learning methods to be applied for semi-supervised learning task. Co-training assumes a good classifier, and then uses the predictions of each classifier on unlabeled examples to argue the training set of the other. TSVM is an extension of standard support vector machines with unlabeled data. The goal of TSVM is to find labels of the unlabeled data. Intuitively, unlabeled data guide the linear boundary away from dense regions, so that the decision boundary has the smallest generalization error bound on unlabeled data. Since TSVM requires solving a combinatorial optimization problem, methods define a graph where the vertices are labeled and unlabeled examples in the dataset, and edges (may be weighted) reflect the similarity (or distance) of examples. These methods usually assume label smoothness over the graph [6,7,9]. 3. Proposed semi-supervised algorithm
Figure 1 illustrates the general framework of our proposed semi-supervised method. According to this system returns learned model. In the next figures, the learning unit is expanded.

More detail of Fig. 1 is shown in Fig. 2. It can be seen that the labeled and unlabeled text documents are pre-processed firstly. The weighted term-document matrices which are the outputs of pre-processing will be returned. 3.1. Preprocessing phase
The document classification preprocessing consists of three main parts: feature extraction, feature selection and term (feature) weighting. Data pre-processing steps are shown in Fig. 3. 3.1.1. Feature extraction
In order to classify the documents, the documents must be represented by a data structure, which is more appropriate for further processing, than a plain text. The text documents can be conveniently represented in a high-dimensional vector space where terms are associated with vector components. Despite of its simple data structure without using any explicit semantic information, the vector space model enables very efficient analysis of huge document collections. In this document representation, each word is a dimension in the feature space. Each vector representing a document in this space will have a component for each word.

According to Fig. 3, feature extraction step comprises 5 sub-steps including discarding HTML/XML tags, tokenization, stopword removal and word stemming by Porter algorithm. Then converting the doc-uments to a Term-Document Matrix: Each vector relates to a document and each feature in the vector corresponds to a word in the corpus (dictionary). The words component of the document vector is the frequency of the word in that document [10 X 12]. 3.1.2. Feature selection
The best subset contains the least number of features that most contribute to accuracy. The whole search space for optimization contains all possible subsets of features is time-consuming and computa-tionally expensive. Here combination of genetic algorithm and ant colony is used as a feature selection approach [13]. 3.1.3. Term weighting
Standard normalized TF-IDF is used as the weighting function Eq. (1). Then it should be normalized. is the number of documents in the training dataset [14]. 3.2. Two level training phase is semi-supervised learning stage, and the second one is supervised learning stage. The unlabeled data
Then L Final enters the supervised learning stage and trains a traditional supervised algorithm. So the output of this system is a learned model. 3.2.1. Semi-supervised learning stage
In this stage the self training algorithm with ensemble learning approach is used. It means that a meta learner. a. One level semi-supervised framework b. Two levels semi-supervised framework c. n levels semi-supervised framework In each ensemble learning two problems should be considered: 1-Selection of learning algorithms combination approach 2-Selection of n learning algorithms and tuning them in an arrangement These issues will be discussed in the next sections.
 Combination approaches
In this section, we explain some well-known weighting approaches in ensemble learning. Then our proposed approach is presented [15].  X  Majority Vote: is perhaps one of the oldest strategies for decision making. Assume that the label  X  Weighted Majority Vote: If the classifiers in the ensemble are not of identical accuracy, then it  X  Proposed dynamic weighting Selection of leaning algorithm
For best learning algorithms selection in each level of proposed framework, some points should be ones are presented [4,10,16].
 the average number of tokens per document, while M ave is the average vocabulary (number of non-document. | D | is number of training data. M is number of stump decision tree and T is number of iteration in adaboost algorithm.

For multi-class classification, the one-against-all method is used which means that a number of classes should be multiplied to these time order.

According to experimental results and our studying, the order of performance (micro-averaged) of these algorithms is shown as follows [10]: These algorithms should be selected for each level of proposed framework according to their advantages, disadvantages and time complexities in Table 1, to achieve high or near high efficiency. So trade-off between time complexity and efficiency should be considered in proposed arrangement.

In this section we proposed a tuned arrangement of algorithms for each level of framework in a theo-retical manner. Then in experimental section, it X  X l be check practically.

As it X  X  shown in Fig. 6, if algorithms in each level can label an unlabeled data, the unlabeled data won X  X  need to pass the next levels of proposed framework. Thus it X  X  better to arrange more appropriate in each iteration just one training time cost is considered for each level of algorithms. According to Table 1:  X  The decision trees have average efficiency and due to its simplicity and relatively low time com- X  For text classification, AdaBoost is the standard boosting algorithm. Adaboost is sensitive to noisy  X  Rocchio is classic method for document routing or filtering in information retrieval. According  X  Naive Bayes classifier performs well over a wide range of classification problems, including medical  X  The KNN classifier has been studied for e-mail spam filtering and text classification because of its  X  SVMs can handle with exponentially or even infinitely many features; the only thing that needs to Based on the proposed weighting method, at the first level of this ensemble method more than two algorithms should be used. Here, according to the mentioned reasons, the framework with two levels which at the fist level SVM, KNN, and Rocchio and at t he second level a neural network algorithm and section. 3.2.2. Supervised learning stage Here a strongest learner i.e. SVM is applied as a supervised algorithm to achieve high performance. 4. Experimental result This program is run in Matlab 7.6.0 on PC with core 2 duo 2.5 GHz CPU and 3 GB of RAM. 4.1. English corpus
Reuters-21578 corpus is one of the most popular datasets used in text classification. This corpus consists of categorized business news reports. The 21,578 documents in this collection are organized in over 100 imbalance categories and each document might be assigned to one or more than one categories. The standard ModApte split uses 75% of the articles for training and 25% for testing. In this research, testing examples which are defined by ModApte split [10,20].
 4.2. Performance measure
Usually precision ( P ) and recall ( R ) are used for performance measurement. Another commonly c
In multi classes problem, there are two possible ways of averaging above measures, namely, macro average and micro average. The macro average weights equally all the classes, regardless of how many documents belong to it. The micro average weights equally all the documents, thus favoring the perfor-mance on common classes. Furthermore, Micro F1 largely depends on common categories while Macro F1 is influenced by each category. In order to compare the performances on all categories and each category, both Micro F1 and Macro F1 are used in this paper [4,21,22].
 problems, one for each class, and some form of averaging is used to achieve a final performance. Most { c against-all binary classifiers [10]. 4.3. Results
The process of experiments is done as follows: Ratio % of the documents from each category in train-ing dataset is randomly selected as labeled data. The rest of the training documents are employed as of labeled data, according to Ratio%, are 67, 336, 1007, 1678, 2350, 3021, 3693, 4364 and 5035) to design a wide range of scenarios. For minimizing potential biases from the randomized sampling pro-cess and obtain more reliable performance evaluations, we perform the validation process 10 times. The overall effectiveness of each technique examined in the experiments is then estimated by averaging the performance obtained from the 10 individual validation trials [23,24].

Here we will show the results of different algorithms X  arrangement which were discussed in previous axis represent the percentage of labeled data ( Ratio %) and performance measure respectively [25,26]. a. In this section the different inter stage arrangements and intra stage arrangements of proposed b. Result of proposed framework and its arrangement for different categories of dataset: c. Comparison between proposed semi-supervised method with some other popular semi-supervised 5. Conclusion
This paper is concerned with the problem of using both labeled and unlabeled data to classify the ten common document classes of Reuters corpus. The usefulness and the contribution of unlabeled data are shown. A two stage learning unit is introduced which contains a semi-supervised stage and supervised stage. The proposed semi-supervised stage has an ensemble learning and self-training framework which stage arrangements are introduced, as well as dynamic majority vote weighting. The algorithm repeats with new labeled training dataset and unlabeled ones. The proposed semi-supervised algorithm with test data of standard ModApte split is evaluated. Experimental result shows that the proposed algorithm improves performance of semi-supervised text classification specially when few amount of labeled data are available.
 Acknowledgement
This work is supported by Education and Research Institute for ICT (ERICT) under grant number 8971/500.
 References
