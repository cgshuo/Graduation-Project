 Paraphrase extraction became one of the main research topics of computational linguistics these days. Enormous amount of research results have been published through many workshops as well as conferences [8, 4] and so on. In paraphrase acquisition, extraction of candidates from an entire corpus is the first and tough task. This difficulty can be reduced to some extent by using parallel corpus. [1] is one of the most successful research using parallel corpus. Their idea is that they use contexts to extract paraphrases from aligned sentences that are translation of the same sentence of the other language. As for paraphrase extraction from monolingual corpus, [6] proposed an unsupervised method using contexts. [3] improves these works by employing syntactic structures.
 is desirable we have to utilize them for paraphrase extraction. In fact, we are witnessing the rapid growth of mobile terminals such as mobile phones or PDAs that are used by ordinary people every day. These kinds of mobile devices have a small and low resolution screen. On the other hand, an ordinary personal computer has a big and high resolution screen. In this circumstance, two types of Web pages, one for mobile devices and the other for personal computers, are developed separately even though they describe the same topic or contents written in the same language. These two types of Web pages are, from the viewpoint of computational linguistics, regarded as comparable corpora because thetopicsaresamebutthesurfacetextsarenot.Thisiswhyweproposeto use these two types of Web pages for the purpose of paraphrases extraction. As expected, Web news articles for mobile devices are much shorter and more compact than Web news articles for ordinary personal computers. Due to this, a paraphrase we can extract from these two types of Web pages is a pair of ordinary expression and compressed form of it, like  X  X he bomb has exploded X  and  X  X omb explosion. X  They are, obviously, useful to compress a formal sentence into a shorter phrase. In addition, this kind of short sentences are used many places, for instance, short messages displayed on low resolution screens in a train, on advertisement screens on building wall or inside of shops, etc. In this situation, our research topic is important for a new but widely used short and compact expression of language.
 at first. We can easily find the place where candidates of paraphrases exist in the texts if we focus on the aligned sentences. On the contrary, if we use non-aligned corpus, detecting candidates is hard and has a high computational cost. We detour this problem by using the two types of Web pages collected from the Web. Then the problem is reduced to ranking of many candidates of paraphrases extracted from them.
 alignment in Section 3. Section 4 is for paraphrase extraction, and Section 5 is the conclusion. 2.1 Characteristics Henceforth, we call the Internet newspaper articles aimed at personal computers  X  X eb articles X  and those aimed at mobile phones  X  X obile articles. X  More than a hundred Web newspaper articles written in Japanese are distributed on the Web every day by Mainichi newspaper company (http://www.mainich.co.jp/). Their lengths are a few hundreds to five hundreds characters and the average length is about 250 characters. An Web article consists of several key words, a title and a body of text. These articles consist of ordinary and formal written sentences.
 by Mainichi newspaper company on the Web. The average length of one mobile article is around 50 characters for the old types of mobile phones. A mobile article consists only of the body text. downloaded them on a day-to-day basis. Actually we have collected 48,075 pairs of Web articles and mobile articles of Mainichi newspaper from April 26th 2001 to March 30th 2003. Since one mobile article often consists of more than one sentences, the total number of sentences of a mobile article is 88,333. 2.2 Final Parts of Mobile Articles X  Sentence Mobile articles are short and compact. We find this compactness especially ap-pearing at a final part of mobile article X  X  sentences. Ordinary formal Japanese sentences, which are obviously used in Web articles, almost always end with a verb or an auxiliary verb of present or past tense because Japanese is a head final language. On the contrary, sentences of mobile articles end variety of POSs as shown in Table 1, where the ratio is the total of each case against the above described 88,333 mobile sentences. We got a POS tag of each word by Japanese morphological analyzer: Chasen [7].
 mainly expressing an action, etc. Its English counterpart is a noun appearing in the pattern of light verb + noun, i.e.  X  X ennis X  in  X  X o tennis. X  All of SA-HEN MEISIs do not necessarily mean an action. Some are for mental state change or whatever. Nevertheless we, henceforth, call SA-HEN MEISI action noun in the remainder of this paper for simplicity. 3.1 Article to Article Alignment As stated previously, the number of Web articles is larger than the number of mobile articles. Since mobile news articles of a day are the excerpts of the whole Web news articles of the day, every mobile article finds its counterpart in the same day X  X  Web articles. Thus the search space for a counterpart Web article of the mobile article is significantly narrowed down to the same day X  X  articles. In this circumstance, the first thing to do is to find the Web article which corresponds to each mobile article. For this we use the similarity score: SimArtic l e ( W, M )where W means a Web article and M means a mobile article defined below, where K is the number of W  X  X  key words which also appear in M , T is the number of nouns in the title of W which also appear in M ,and NN is the number of nouns that appear in both of W  X  X  body and M . The parameters a and b are weights of the first and second factors respectively and both are chosen to be 3.0 experimentally. Figure 1 shows the relation between SimArtic l e and accuracy of article alignment for randomly selected 605 mobile articles, where machine output alignments are checked by hand. As seen from Figure 1, sentence pairs whose SimArtic l es are more than 35 are correct pairs and resulting in 481 correct pairs. Thus we apply this threshold of 35 to all of Web articles and mobile articles described in Section 2. 3.2 Sentence to Sentence Alignment Next, we extract sentence pairs from these aligned pairs of articles. Since newspa-per articles always put the most important information in the first few sentences, we only focus on the first paragraph of Web articles. Practically, sentences of Web article aligned to the sentence of mobile article are identified by the following method where Ws means a sentence in the Web article X  X  first paragraph, { Ws } means the set of them, Ms means a sentence of mobile article, and Ws ( Ms )is a Web article sentence aligned to Ms , where the similarity is defined as a number of nouns appearing in both of Ws and Ms . We extract 88,333 aligned pairs of sentences by this method. We choose 500 pairs randomly from these pairs and checked them by hand and found that 92.8% of them were correctly aligned. This figure might not be sufficiently high for alignment task itself. The main objective of our research, however, is extraction of paraphrases by means of some statistical method. Therefore we decided not to pay more effort for alignment per se but to proceed to the task of paraphrases extraction using the pairs of sentences extracted by this method. 4.1 Background Paraphrases would be used for many purposes including text simplification [5]. Our target, which is a little bit similar with their work, is to extract expressions of the same meaning in Web sentences and mobile sentences. The latter is a more compact and simplified form of the former. Then what we want to extract is paraphrases by which we simplify Web sentences into sentences that can be used as mobile sentences.
 and the last noun phrases of mobile sentences. A last part of ordinary Japanese sentence is usually a verb, on the contrary, a last part of Japanese sentence of compact text like mobile articles is often an action noun as already seen in Table 1. For instance, Japanese verb phrase  X  X kira-ka ni na-tta X ( X  X e discovered X ) is sometimes paraphrased with a noun  X  X an-mei X  which can be translated into  X  X e known X ,  X  X roved to be X , etc. As shown in this example,  X  X XX X (YYY) means that XXX is a part of Japanese sentences and YYY is its English gloss. following way. Firstly, post positional particles (PPP) are function words like prepositions of English, and are one or two characters length. Then we combine a word right adjacent of PPP to make one distinct expression. Secondly, since our paraphrase extraction algorithm is based on frequencies as described later, we select expressions that occur more than two times. Then we have had 4566 distinct expressions, which contain 1085 distinct action nouns.
 of them are action noun like  X  X an-mei. X  From the viewpoint of paraphrasing, this is a compression of a phrase which contains a pattern of action noun + light verb. Considering these factors, we focus on this type of expressions as our target of paraphrase extraction in this paper. The following is an example where a character string separated by a space or hyphen corresponds to one Japanese character. Note that a character connected by hyphens is one morpheme. The italic parts of these two sentences are the paraphrases we try to extract by the system we will propose in the remaining of this paper.
 Mobile sentence ending part:  X  X i-ko gen-in han-mei  X  (the cause of the accident Web sentence ending part:  X  X i-ko gen-in ga akira-ka ni na-tta  X  (the cause of 4.2 Extraction Framework What we want to extract is a set of expressions appearing in Web sentences that are the paraphrases of the action noun appearing at the end of mobile sentences. Then the first thing to do is to extract action nouns from mobile sentences. We have already done it and showed the result in Table 1. Here, a set of mobile sentences having an action noun: AN is denoted as  X  { Ms ( AN ) } .  X  The next thing to do is to gather a set of Web sentences which may have the paraphrase of the given AN . Since we have already had is the big amount of aligned pairs of Web sentence and mobile sentence as stated in Section 3, it is easily accomplished by simply gathering Web sentences being aligned with each mobile sentence in {
Ms ( AN ) } .Wedenoteitas X  { Ws ( AN ) }  X  henceforth. Once we get { Ws ( AN ) } , the remaining problem is to extract a candidate of paraphrase of AN from { Ws ( AN ) } . This process is formally described as follows.
 easier to extract sentences which may contain paraphrases than paraphrase ex-traction researches that do not use this kind of aligned sentences. Even though we use aligned sentences to extract paraphrases, we still have many possible types of paraphrases like a noun, a noun phrase, verb, verb phrases, and so on. Thus we make the procedure at Step 3 one step easier by focusing on the last parts of sentences in { Ws ( AN ) } . By this narrowing down, we can identify where paraphrases exist. The remaining problem is how to implement Step 3 of Figure 2. 4.3 Character Based Extraction with Branching Factor and Since AN s are located at the end of mobile sentences, it is reasonable to ex-pect many paraphrases of AN are also located at the last part of sentences in {
Ws ( AN ) } . Of course, some paraphrases might be located not at the end of sentence. The method we use is, however, based on statistics of distribution of target expressions. Thus we only focus on the last part of sentences. word based extraction. This is because 1) we are free from error of morpholog-ical analyzer whose accuracy is still around 95% for Japanese, 2) the proposed method is independent on language and can be applied any language, and 3) the proposed method can extract paraphrases exhaustively including character string not yet recognized as a word. One example of 3) is an abbreviation like  X  X -ing X  meaning  X  X rossing. X  Of course we loose a sophisticated linguistic infor-mation a morphological analyzer gives us, however, we take the merits 1) 2) and 3) more in our character based extraction.
 from the end of sentence of { Ws ( AN ) } we should extract. To solve this problem, we first cut out some character strings which are probably paraphrases of AN from Ws ( AN ). For this we introduce an important notion that we call  X  X ranch-ing factor. X  A similar idea,  X  X ccessor variety X , has been proposed in [2], however their aim is word segmentation which is completely different application. Branching Factor. Here, we firstly introduce a forward branching factor of a character string Cs in a set of sentences which makes it easy to understand thenotionofbranch.Ifthelengthof Cs is necessary to express explicitly, we explicitly write down Cs ( n )where n is the length in character, henceforth. acters which are right adjacent to Cs in a set of sentences. Let Cs be a character  X  X . X  Then F B ( X  X  X ) is big because we may have many kinds of characters af-ter  X  X  X  of the first character of words, like  X  X a X ,  X  X e X , etc. After  X  X a X ,  X  X  X  of  X  X ame X ,  X  X  X  of  X  X ature X , etc. may come, and still F B ( X  X a X ) is high. But after  X  X atu X , very few kinds of character can come like  X  X  X  of  X  X ature. X  Thus F B decreases as we proceed right within a word. Obviously, once a word ends, F B suddenly increases. Thus we would extract linguistically meaningful expression by cutting out character strings at the point where a F B increases. The notion of F B is proven to be useful to segment out the meaningful expression [9]. Thus, what we need is a branching factor of the other direction, namely a back-ward branching factor: BB . BB ( Cs ) is defined as the number of distinct char-acters that are left adjacent to Cs in a set of sentences. We expect that if we scan character strings backwards from the end of sentence, the same situation as described in a forward branching case is expected to happen. We depict the situation with more concrete example. Consider, for instance, a Japanese sen-tence. and  X  X a X  indicates one Japanese character. If we take a set of Web sentences {
Ws ( AN ) | AN =  X  X you-mei X  } (= { Ws ( X  X you -mei X ) } ), the following figure depicts the situation of backward branching. dependent morpheme indicating past tense. Therefore very many kinds of char-acter come to the left of  X  X a X  as shown in Figure 3. Thus BB ( X  X a X ) is very large. BB ( X  X i-ta X ), where  X  X i-ta X  means  X  X id X  in English, is rather low because there can be several possible action nouns whose meaning is same or similar with  X  X you-mei X  (express). Then longer the string is, the smaller BB becomes. However, any word can come to the left of  X  X you-mei si-ta X , that means BB turns to increase at this point. Here  X  X ncrease X  of BB ( Cs ( n )) means: lated using a set of sentences { Ws ( X  X you-mei X ) } in Figure 4. Clearly, character strings whose BB is increasing coincide with coherent expressions like  X  X ki-ra-ka ni si-ta X (disclosed) and  X  X anga-e wo aki-ra-ka ni si-ta X (disclosed his/her opin-ion).
 expression like words or phrases. Therefore, BB is useful to extract character strings of fixed and/or coherent expression. Concretely, if we cut out strings: Cs ( n )where BB ( Cs ( n )) increases, that Cs ( n ) is a linguistically coherent and fixed expression which turns out to be a good candidate of paraphrase. Frequency, Length and Their Combination. As all of the Ws ( AN )s con-tain paraphrases of AN , we expect that many of them share the same expression which has the same meaning AN has. The character string which has a high frequency within { Ws ( AN ) } probably is a paraphrase of AN . Therefore a fre-quency of character string is a good indicator of how likely the character string is a paraphrase.
 namely n of Cs ( n ). If we take character strings only based on their frequencies, we probably encounter the following cases. One extreme case is short strings like  X  X i-ta X (did). Since every action noun can come just left of  X  X i-ta X , BB ( X  X i-ta X ) is high and possibly increasing, and the frequency of  X  X i-ta X  is obviously high, we might extract  X  X i-ta X  in some { Ws ( AN ) } .Ofcourseitisnotdesirablebecause apparently  X  X i-ta X  is not a paraphrase of any action noun. The other extreme case is a long expression like  X  X aku-zitu tou-kyou de tai-ho sa-re-ta X (got arrested in Tokyo yesterday). It is not a paraphrase of action noun  X  X ai-ho X (arrest) because it expresses too detailed information than  X  X ai-ho X  expresses. Thus we have to exclude too long and too short strings.
 lowing formula, where n is obviously the length( Cs ( n )). By (5), the importance of Cs ( n )inwhich out. It is reasonable for Japanese because 1) action nouns almost always consists of two Chinese characters and 2) Paraphrases in longer Web sentences for action nouns in mobile sentences are expected to be longer than two characters. A longer Cs gets a high score but the score is saturated because of log function. frequencies. Thus, the combination of length and frequency would exclude too long and too short strings at the same time. In addition, it is not necessary to search very long character strings because the target is the paraphrase of one action noun. Thus we only focus on character strings that are shorter than 30 characters.
 Ranking Algorithm. Based on these considerations, we propose a paraphrase extraction system which corresponds to Step 3 of Figure 2 as shown below. that we use at Step D of Figure 5. For this we propose the following definitions, where freq( C BB ( n )) is the frequency of the string C BB ( n )in { Ws ( AN ) } .As stated in 4.3, if two factors: 1) decreasing of frequency of Cs ( n ) and 2) increasing of log( n  X  1) as n becomes longer, are well combined, we can exclude too long Cs ( n ). Since as stated in 4.3, we can exclude too short Cs ( n ) by log( n  X  1), we can exclude too short and too long Cs ( n ) and pick up frequently occurred character strings.
 4.4 Word Based Extraction The above described character based extraction method is easily translated into a word based extraction method by replacing character with word. For this, since Japanese is an agglutinative language, we have to do morphological analysis and POS tagging. We use the evaluation function defined by (6) except that the length used in (5) is counted in character because we try to exclude one or two character length string. If we count the length in word, we may exclude longer strings which may be a good paraphrase. 4.5 Experimental Results and Evaluation We evaluated the paraphrases resulted in sorting algorithm described in Figure 2 and Figure 5 combined with definitions of Para definedin(6)andwordbased method described in 4.4. For evaluation, we test whether the resultant candidates of paraphrases are correct paraphrases in any context. This is done by hand because this correctness is known based on deep semantic analysis including even some consideration about contexts. Since we have 1159 action nouns among 4566 types of sentence ending expressions, we cannot evaluated every candidate of paraphrase for every ranked character string C BB ( n ) by hand. Then we firstly evaluate precisely the ten most frequently used Japanese action nouns in our corpus as shown below.
 However they are roughly similar. We expect to extract paraphrases that are similar but have a little bit distinct meaning of the original action nouns. Actu-ally, we test by hand the ten highest ranked candidates for each of these ten AN s resulted in by the above described sorting algorithms and calculate precisions against the first to N -th candidates defined by the following formula, where C ( i ) means the number of correct paraphrases within i highest candidates. character based method is used, nine out of the ten highest ranked candidates are correct paraphrases. If we take three highest ranked candidates of the character based method, almost 87% are still correct. Moreover about 55% of ten highest ranked candidates are correct. It is not shown in Figure 6, but the Precision( N ) gradually degraded and Precision(20) still maintains 50%. The results of word based method is lower. This result indicates that the expressions resulted in by our aligned sentences and extraction algorithm based on character string are high quality candidates of paraphrase.
 ranked candidates of paraphrases for most frequent 100 action nouns. The results of their accuracy for each of first, second and third candidates are shown in the Table 2, where  X  X ccuracy X  means the ratio of the extracted correct paraphrases over all the extracted candidates of paraphrases. In this case, the word based method outperforms the character based method. This is because in middle to low frequency cases, the word based method picks up more grammatically reason-able paraphrases at the top three ranks than the character based method which is aimed at extracting paraphrases exhaustively and may produce ungrammati-cal candidates. Finally we show some examples of extracted paraphrases where we can replace  X  X th X  with any noun or action noun. happyou (announce). happyou-sita (made anouncement), suru-to happyou-sita (announced to do sth.), sita-to happyou-sita (announced that sth. has been done), seisiki-ni happyou-sita (formally announced), akiraka-ni sita (disclosed), kouhyou-sita (publicly announced), to kata-tta (talked X ... X ), kettei (decide). kime-ta (decided), suru-koto-wo kime-ta (decided to do sth.), kettei-sita (made a decision), suru-koto-wo kettei-sita (decided to do sth.), wo kettei-sita (made a decision to do sth.), hanmei (discover). waka-tta (discovered), de waka-tta (discovered by sth (=ev-idence)), akira-ka ni na-tta (proven to be), hamei-sita (turn out to be) We collected and aligned Web news articles and news articles for mobile phones over two years. Using this aligned corpus, we extract character strings of para-phrases of action nouns appearing at the end of mobile sentences based on the combination of branching factor, frequency and length. The samples of the result show high precision and indicate semi-automatic paraphrase extraction to be re-alistic in practical use. Our future work is to extract other types of paraphrases like sentence end with post positional particles from our aligned sentences.
