 1. Introduction
Social simulation is a research field that applies computational methods to study issues in the soc ial sciences. The issues explored include problems in sociology, political science, economics, anthro-pology, geography, archeology and linguistics ( Takahashi et al., 2007 ). Nowadays, several social simulation platforms are used (e.g.
MASON, Repast ( North et al., 2006 ), Netlogo ( Gilbert and Troitzsch, them are based on the concept of a ver y simple totally reactive agent, without any cognitive capability. However, in a large number of systems developed under the artific ial intelligence branch, which attempt to reproduce intelligent hu man behaviours, the agents used in the modelling process show autonomy, proactivity, adaptability, reasoning, planing capabilities, and so on ( Jennings and Wooldridge, 1998 ). This is accomplished by the so called cognitive architectures.
Such systems manage decision making, memory and learning, among others (e.g. Soar ( Laird, 2008 ), ICARUS ( Langley and Choi, 2006 ), ACT-R ( Anderson, 1996 ), etc.) ( Sun, 2007 ). They are both con-ceptually heavy models and intensive CPU consuming approaches.
This last fact makes them unfeasible for social simulations with a high number of agents in the socie ty. Other approaches, using a society of agents that executes cognitive architectures, are therefore needed. In this way, the BDI-based technologies (like Jason, 3APL ( Hindriks, 1999) or CoJack ( Evertsz et al., 2008 )) sit between the reactive social simulation platform s and the cognitive architectures.
BDI architecture provides several in teresting cognitive capabilities to social agents. Its conceptual complexity is lower than that offered by cognitive architectures, but it is still an intensive CPU consuming technology, according to the requirements of social simulation, where a great number of social entities must be simulated.
The application domains of this work are given by a set of simulation scenarios where people are surrounded by embedded intelligent objects within an environment that is able to recognize and to respond to different individuals. This is the common characteristic of several systems grouped under the name of
Ambient Intelligent (AmI) systems. From the perspective of these systems, where it is necessary to reproduce intelligent behaviours simulating humans as far as possible and as necessary, it is very important to provide higher-level intelligent behaviours. Nowadays, living labs are the approach to choose when a small
AmI system is considered. Systems of this type are those which may be found in Smart homes, for example ( Friedewald et al., 2005 ), when users are from one to five (i.e. a family). The main idea behind living labs is that user satisfaction is studied by reproducing artificially the real environment in which the system and the user will interact (i.e. the smart home) and studying user reactions meanwhile she is living in such an environment. The kind of systems we are concerned with are large-scale systems (i.e. those located within an intelligent building or a hospital).
Obviously, it is not feasible to artificially reproduce such a huge living lab. In this case, the approach we follow to test function-ality of services and applications within systems is simulation. The simulation paradigm we use is MABS (MultiAgent-Based
Simulation). With this approach, we simulate the physical envi-ronment, the hardware of the system (i.e. mainly sensors and actuators), and the users inside. The only thing which is real is the software we want to validate, which is connected to the simula-tion in real time.

Two simple examples of simulation scenarios we are developing in our lab are Ubik ( Serrano et al., 2009 ) and Cardinea ( CARDINEA, 2009 ). In Ubik, we are interested in studying AmI systems on the intelligent building physical scenario, the simulation model incor-porates workers on the building with different behaviour patterns depending on their role in the organization. There we investigate, as an example, the effect of intelligent mechanisms to guide people in situations like a fire by means of audio or visual signals (e.g. an electronic message panel). In Cardinea, the situation is different, but the dimensions of the physical environment are similar. Here, physical hospitals with personal (care givers, doctors, assistants) and patients are simulated.

Both examples have in common that some users (agents in this case) are distinguished from the rest in terms of their skills. In the intelligent building example, some of the users may have received special instruction in order to coordinate evacuations. In the hospital example, some of the doctors may be in charge of rearranging per-sonnel at the hospital to cope with a peak in the number of incoming patients. Both kinds of users, wh en simulated in a MABS platform, need intelligent capabilities (i.e. coordination skills and intelligent decision making abilities in this case). These are cognitive capabilities.
Such users may be modelled by means of cognitive agents, compu-tational processes that act like certain cognitive systems or act intelligently according to a cognitive definition. Actions of cognitive agents may be the result of processes concerning to deliberative, coordination, learning, adaptatio n and planning capabilities of the entities. Social simulation tools like MASON, RePast, NetLogo, SeSAm,
Breve, among others, do not support these cognitive capabilities. At the least, mechanisms to reason and to communicate are required.
On the other hand, the cognitive architectures do not support the simulation of a high number of social (reactive) agents, as several scenarios like Ubik and Cardinea require. Adding cognitive capabilities to current social simulation platforms seems the intuitive way to obtain cognitive behaviours in social simulations.
These scenarios require (1) capabilities for simulating a high number of (reactive and cognitive) agents, (2) capabilities for replicating the experiments, and (3) useful monitoring tools in order to examine the behaviour of the simulated agents. MASON is distinguished from the rest of social simulation platforms since it offers these features in a suitable and simple way.
For that reason, the objective of this work is to provide cognitive (and communicative) capabilities to some agents in the social simulations given by MASON.

Using BDI agents to provide cognitive capabilities to a social simulation system seems a very interesting idea. Thus, Bordini and
H  X  ubner (2009) show how Jason can be used to carry out BDI agent-based simulations. Jason is implemented in Java and is available as Open Source, distributed under GNU LGPL ( Bordini et al., 2007 ).
According to social scenarios defined by Ubik and Cardinea, and from a practical point of view, Jason has two important disadvantages: (1) it is not able to support a high number of agents (each agent is running on a Java thread, and JVM imposes rigid restrictions in this way, and MASON can simulate hundreds of thousands of agents), and (2) it is not possible to replicate the same simulation (in MASON the simulation can be replicated using the same random seed in different simulations). These are two very important elements for experimentation.

It is necessary to clarify that Ubik and Cardinea scenarios consider wide agent populations, with a high number of agents, but not all of them exhibit cognitive behaviours. The simulated scenarios consist of a high number of reactive agents and a reduced number of cognitive ones.

For this reason, it is not possible to use any social simulation platform independently. The social simulation platforms do not support the cognitive and communicative requirements of con-sidered scenarios. On the other hand, we cannot use only a cognitive architecture because cognitive architectures are not capable to simulate a high number of reactive agents.
 So, the proposal of this paper is based on the integration of MASON and Jason to give cognitive capabilities to some agents in the current developed social simulations, where there is a large number of social agents and a small number of cognitive ones, and where the replication of experiments is very important.
The rest of the paper is structured as follows. Section 2 highlights the main characteristics of MASON as an agent-based social simula-tion architecture. Section 3 presents the interesting features of Jason for social simulation and from the point of view of integration with MASON. Next, in Section 4, the paper gives some alternatives to integrate these two technologies. It proposes one of them to develop a concrete implementation to show the utilization of this approach. Section 5 discusses an implementation of an illustrative situation where a high number of simple reactive agents are guided by a reduced number of cognitive age nts. The performance and beha-viour of two types of agents are resumed using MASON simulation toolkits. Section 6 comments on the relationships between the approach and previous works of ot her authors. Finally, Section 7 gives conclusions and shows some ideas for future work. 2. MASON
MASON is a single-process, discrete-event simulation core and visualization library written in Java, designed to be flexible enough to be used for a wide range of simple simulations, but with a special emphasis on swarm multiagent simulations of many agents (even millions). But, it does not support the representation of communicative and cognitive capabilities of the agents ( Luke et al., 2005 ).

It is structured in two layers: model and visualization. In simulation model layer, it provides, among others, (1) a discrete-event scheduler, (2) a high-quality random number generator, and (3) a variety of fields which hold objects and associate them with locations. The visualization layer allows for display of fields and user control of the simulation. It separates the model features from the visualization and control functionalities. From this layer, a model defined in the previous layer can be treated as a self-contained entity. 2.1. Model layer: the environment
A MASON model is entirely contained within a single instance of a user-defined subclass of SimState . This class represents the environment and contains a discrete-event schedule (given by class Schedule ). The schedule controls the simulation, providing a variety of breakpoint to agents running in the environment. Such breakpoints provide a single point to include own programming code used to customize their behaviours. Through executing these break points, agents can sense the environment, other agents, or act, so modifying the environment or their own status.
Two interesting simulation breakpoints are offered by Step-pable and Stoppable interfaces. These interfaces can be implemen-ted by the agents in order to run and stop in the MASON environment. Steppable defines the abstract method step , invoked when agent receives one tick from the Schedule. Stoppable defines the method stop , invoked when Schedule stops the agent.
The order in which the Schedule arranges the execution of agents is established by MASON. It depends on the sequence of numbers given by the random number generator. The seed, used to generate random numbers sequence, can be specified. This way, a given MASON simulation can be replicated several times, using the same seed in two different simulations.

The order in which the agents are simulated in each timestep is not relevant for a wide range of application domains. From the point of view of simulated agents, one step can be considered as an indivisible unit of time passed between two consecutive ticks received from Schedule . The metrics used to evaluate the perfor-mance of the simulated agents are computed at the end of each timestep, when all simulated agents complete their own time-step. So, the execution policies adopted by the Schedule do not introduce bias inside simulation.

Schedule also allows the environment to invoke the beginning of the next step of the simulation. This functionality is provided by the method nextStep .

Fields in MASON relate arbitrary objects or values of them with a location within a virtual space. Many of these fields are simple wrappers from simple 2D and 3D arrays. These structure can also provide sparse relationships between objects. The use of these structures is optional. 2.2. Visualization
Objects, developed in this layer, may examine model-layer objects, using an appropriate reference to the environment
SimState given by class GUISimState . MASON visualizes the objects through displays: GUI windows which provide 2D and 3D views on the underlying fields. It is also possible to define some customized displays. This is very interesting for experimentation, because it allows underlying model objects to be inspected. It is a way to monitor the simulation step by step. For example, some real time charts can be provided, or data about simulation can be stored by a logger agent. 3. Jason
In Jason, the agent definition can be given in two complemen-tary ways: (1) by means of its BDI representation, so allowing the achievement of its cognitive capabilities, and (2) through its Java-code representation, allowing, on the one hand, its inclusion in
Java-based social environments and, on the other, the mainte-nance of its own knowledge schemes, thus perceiving the envir-onment and other agents, execution of the actions, among other things. The cognitive representation of agents is managed by an interpreter for an extended version of AgentSpeak programming language (based on the BDI agent architecture), including also speech acts-based inter-agent communication. Using Saci 1
Jade (for example), a Jason multi-agent system can be distributed over a network effortlessly ( Bordini et al., 2007 ).

Implementation of a BDI agent can include instances of certain data structures. The most relevant structures are (1) beliefs base, where the agent stores all current beliefs, (2) set of events, which might trigger the execution plans, (3) plan library, where agent know-how is stored, (4) set of intentions, where agents store their focus-of-attention, and (5) a queue of messages received from other agents ( Bordini and H  X  ubner, 2009 ).

However, from the point of view of social simulation, other components are needed. Jason gives an environment in which the agents run. The environment, and the agents running in it, can be controlled in two predefined ways. Moreover, Jason gives the possibility of selecting the underlying agent architecture, which provides communication facilities among agents. Jason provides some predefined agent architecture but also permits a customized one to be defined. 3.1. Jason environment
The environment in Jason is a representation of the real environment in which the agents are running. In implementation terms, the life-cycle of each agent in Jason is executed on one independent thread in the JVM. For this reason, the number of agents running is limited by the characteristics of the JVM. The theoretical limit of threads in a JVM is about 1000. However, experimentally, this number is reduced to a few hundred, depend-ing on the complexity of the reasoning processes of the agents.
The representation of the environment is supplied by Environ-ment class. It is responsible (1) for maintaining the state of the environment, (2) for simulating the execution of actions required by the agents, and (3) for giving a symbolic representation of the state of the environment to the agents running in it. Jason environment is a passive entity. Only when agents sense the environment, its state is perceived by them. It never sends notifications to agents when its state changes.

This class has, among others, two methods to update the perception of the agents and to execute their actions. The first, getPercepts , is called by agents when they want to update their BDI perceptions taking into account their own knowledge representa-tion, environment characteristics, etc. The second one, executeAc-tion , is invoked by agents when they want to execute any action.
Generally, actions can result from a BDI deliberative process. 3.2. Execution modes
In a MABS, several mechanisms are necessary to synchronize the reasoning-cycle of agents and the actions that they take.
Environment can be used to perform some kind of synchroniza-tion in this way. Jason offers two ways to manage synchronization of reasoning life-cycle of running agents: (1) asynchronous, where all agents continue the next reasoning-cycle as soon as they have finished the previous one, and (2) synchronous, that defines steps to control the simulation, such that the next step will not begin until all agents finish the previous one.

The customization of the agent can be obtained by writing code in each breakpoint of the reasoning-cycle that synchronous execution controller gives. The synchronous controller is offered by the TimeSteppedEnvironment class.

In the synchronous execution mo de, the end of the reasoning-cycle of each agent can be captured in the method receiveFinished-
Cycle . This method is invoked by any agent when it finishes its cycle, obtaining a copy of the agent state. In terms of integration with
MASON, this method can be used to carry out updating and revise processes of intentions and goal s bases. Maybe, this is the most important breakpoint, using a sy nchronous Jason execution mode in which cognitive features may be included at the end of each step. 3.3. Support to communicative actions
Jason gives the possibility of sending perceptions from one agent to another using AgentSpeak methods. It includes predefined pre-dicates such as .send ( Bordini et al., 2007 ). Communication acts are supported by the message transport mechanism implemented by the agent architecture that it uses. When using agent architectures provided by Jason (Centralized, Saci, Jade), transporting of the messages is transparent to the programmer: it is given by the architecture. However, if the programmer does not use any architec-ture, or customizes the owner architecture, he must implement the required mechanisms to offer c ommunication between agents according to the communicative requirements of the system. 3.4. Customized agent architectures
In Jason, every agent has an architecture responsible for the execution of actions and maintaining agent perceptions up to date.
This architecture can be customized by any agent, extending the class AgArch supplied by Jason. Writing a new subclass is done by refining several methods, such as: perceive , act , sendMsg , broadcast , and checkMail ( Bordini et al., 2007 ).Thesearethemostinteresting breakpoints, invoked by the simulator controller, from the point of view of social simulation and possible integration with MASON.
By designing a customized agent architecture, it is possible to use only the BDI interpreter in stand-alone agents. Of course, communicative functionalities are not available by default. They have to be added from a third party or by reusing SACI or Jade. 4. Some alternatives to integrate MASON and Jason
There are several alternatives to integrate MASON and Jason in order to provide cognitive behaviours in social agent simulations.
The most important ones, depending on the role played by each platform, are the following: 1. The simulation is controlled by MASON environment, where
Jason environment (and the execu tion of cognitive agents sup-ported by them) is executed like any other MASON agent. The tick is given by MASON environment, and each element (reactive agents and Jason environment) executes a step of its simulation. 2. The simulation is controlled by Jason environment, where
MASON environment (and the agents supported by them) receives the tick simulation after all Jason agents. The tick is given by Jason environment, and each element (cognitive agents and MASON environment) executes a step of its simulation. 3. The simulation is controlled by MASON environment, without using Jason environment. All agents are MASON agents and only those with cognitive capabilities use functionalities of the
BDI interpreter and, possibly, others supplied by a customized agent architecture.

Alternatives 1 and 2 require a representation of all agents to be available at both environments. There are two reasons for this requirement: (1) attributes of reactive MASON agents must be known by cognitive Jason agents, because they are used in their deliberative process, and (2) attributes of cognitive Jason agents must be mapped in non-real MASON agents because monitoring tools inspect agents running in the same environment, and Jason environ-ment does not support a high number of agents, as is required in this work. Furthermore, it is interesting to keep monitoring facilities and tools given by MASON. In both cases, mapping some agents attributes into entities of the other environment seems to produce significant overload for the simulation at the end of each time step.
The mapping functions between cognitive Jason agents and non-real MASON agents (considered in alternatives 1 and 2) are simple.
The agents from both platforms share a common description based on a set of interesting attributes for both simulated environments.
In this way, when each step of the Jason environment is finished, the attributes of cognitive agents interesting from monitoring purposes will be updated into non-real agents running in the
MASON environment. The non-real MASON agents do not perform any action in each timestep. However, their attributes are intro-spected by monitoring tools offered by MASON.

In both alternatives, a reduced number of cognitive agents with reasoning capabilities is used.

However, from the point of view of implementation, the first alternative is not achievable because Jason environment, represented by class TimeSteppedEnvironment , does not allow the beginning of the next step of the simulation to be invoked. (It does not offer any public functionality that support s this.) Besides, MASON environ-ment also provides the method nextStep to begin the next step.
On the other hand, alternative 3 is based on an interesting yet simple idea. It considers that any cognitive agent is implemented like any other MASON agent but it is able to commit an entire Jason reasoning-cycle using BDI interpreter. This approach does not use the Jason environment. Consequently, many functional-ities delivered by Jason platform are not available in this case. Specially, communication features must be implemented by means of a customized architecture. It is not an easy task.
At this point, it should be pointed out that alternative 2 is able to support reasoning and communicative capabilities for a reduced number of cognitive agents coexisting with thousands of reactive agents. But, programming efforts (and skills required) and overload produced in a large social simulation generate some preliminary doubts about its suitability in some scenarios. On the other hand, it seems that alternative 3 offers an inexpensive way of combining both technologies, but it does not s upport any communicative action by default. It is the programmer who has to address this issue.
The following subsections comment on the implementation details of alternatives 2 and 3. 4.1. Jason controls the simulation
In this alternative, the simulation is controlled by Jason environment. The functionality of synchronous execution mode of the environment is obtained by an extension of the class TimeSteppedEnvironment . Cognitive agents specify their beha-viours using AgentSpeak code. Reactive agents implement some interfaces like Steppable and Stoppable in order to run and stop in the MASON environment.

This environment maintains (1) cognitive agents, which use a BDI interpreter and communicative primitives of Jason, (2) a reference to a MASON environment, which receives one tick when one Jason step terminates (using stepFinished method), and (3) a data structure to maintain mirrors of (references to) all reactive agents in the MASON environment. This is necessary because cognitive agents need to know some attributes of reactive agents in all steps of the simulation. References to reactive agents must be accessible in all Jason simulation steps. In the same way, mirrors of cognitive agents, maintained in MASON environment, need to be updated from the state of cognitive agents in each step. The mirrors updating process can be carried out at the end of the global step, captured by stepFinished method, once the MASON environment finishes the launching step.

Fig. 1 shows a simplified sequence diagram of each reasoning-cycle, considering alternative 2, where MASON environment is controlledbyJason.Atthebeginn ing of the reasoning-cycle (sup-ported by method getPercepts ), the cognitive agents must update their own base of perceptions (i.e. the interesting knowledge used in deliberative process in this step). From this breakpoint, an agent can sense the state of the environment and/or can request the knowl-edge structures in order to update its BDI percepts. This alternative mean needs any data coming from the reactive agents located at mirrors maintained in the Jason environment. This data is eventually required for a correct reasonin g process on cognitive agents.
When BDI reasoning terminates, method executeAction is invoked. It is possible to put some code in this breakpoint to execute the action resulting from the BDI reasoning (i.e. conclu-sions of the deliberative process). Generally, conclusions of deliberative process can be (1) execution of internal actions to change its own state or the state of the environment, or (2) mes-sages to other agents. The receiver of such messages can be a cognitive agent (running in the same Jason environment) or a reactive one (running in the MASON environment). If the target agent is a cognitive one, it can use communicative capabilities offered by Jason. But, if the target is a reactive MASON agent, it needs an auxiliary data structure to communicate with it. This structure must be maintained in the MASON environment, for example, and must be accessible by cognitive agents. In each simulation step, reactive agents sense the MASON environment and read this shared data structure.

The logic of reactive agents is encoded in the method step of the interface Steppable given by MASON. In this alternative, coordination between agents is supported by communicative capabilities given by Jason environment. 4.2. MASON controls the simulation
In this alternative, simulation is controlled by MASON environ-ment. This environment maintains cognitive and reactive agents at the same functional level without any duplicity of attributes of the agent state. All of these agents must implement some interfaces such as Steppable and Stoppable in order to run and to stop. The logic is encoded in the method step of the interface Steppable given by MASON. Cognitive agents do not use any Jason environment to reason and communicate. Only the BDI interpreter is used in each cognitive agent. To orchestrate the reasoning-cycle and deliver some basic communicative functions into each cognitive agent, an owner agent architecture is customized by the extension of AgArch class of Jason. This customization defines method such as perceive , act , sendMsg and checkMail (please, see 3.4). A simplified sequence diagram of each simulation step is given in Fig. 2 , considering alternative 3, where the simulation is controlled by MASON environment without using Jason one.

In order to guarantee communication between cognitive and reactive agents (in a simple or in a complex way), the two types of agents must extend a common basic agent architecture. Reactive ones do not need to redefine their behaviour for methods perceive and act . Cognitive agents redefine these methods to customize their own reasoning-cycle.

Both types of agents need to launch a reasoning-cycle in each simulation step. The invocation of the new reasoning-cycle can be made from the breakpoint given by the step method at the interface Steppable of MASON. The method getTS().reasoning-
Cycle () given by AgArch class is responsible for executing a reasoning-cycle in a given agent.

Like the previous alternative, cognitive agents need to update their percepts at the beginning of the reasoning-cycle (supported by method perceive ). Then, when BDI reasoning concludes, method act is invoked. Finally, checkMail breakpoint is activated to read messages that other agents have sent. In contrast, method sendMsg is executed when BDI interpreter find .send primitive in the code of BDI cognitive agent. The functionality of the last two methods must be implemented by the customized agent archi-tecture, according to the communicative requirements of the scenario. 4.2.1. Communication of agents without using Jason
Since no Jason environment is used in this alternative, com-municative capabilities must be under the responsibility of the programmer of the new agent architecture. Developing a com-plex, robust, and reliable message transporting system or reusing an existing one can be a very hard task. But there are a number of scenarios where communicative requirements are very simple ( Serrano et al., 2009 ).

There are several available mechanisms to provide commu-nications support (e.g. ACL, based on blackboard, tuple-spaces ( Coulouris et al., 2001 ), shared memory, etc.). A simple mechan-ism can be suitable to give communicative capabilities to several kinds of scenarios (like Ubik and Cardinea), where communica-tion between agents is very simple too. For these scenarios, this alternative proposes a shared memory-based mechanism. 4.3. Discussion
This section intends to clarify under what circumstances one approach (either alternative 2 or 3, alternative 1 is out of the question) prevails over the other. The criteria we have used to articulate this brief discussion are the following: (1) efficiency of the simulation, (2) communicative requirements of the scenario, (3) capabilities to monitor agents, system behaviour during the social simulation, and (4) programming skills needed in order to maintain a good model productivity.

According to efficiency requirements (i.e. criteria 1), alterna-tive 2 is clearly worse. Mapping cognitive agents into Jason environment can produce a significant overload in the informa-tion shared between the two environments. At each time step, cognitive agents must update their corresponding mirror in the
Jason environment data structure. This is an important reason if we consider the high number of reactive agents used in the social simulation scenarios mentioned before.

In line with the needs of interaction among agents (i.e. criteria 2), solution number 2 is good when the cognitive agents need advanced coordination mechanisms (e.g. decentralized planning or flexible coordination within teams of agents). Approach 3 is suitable for scenarios with simple communication requirements.
On the other hand, if the training needed is taken into account, it is considerably harder to reach a good practice using solution 2.
In such case, mastering the Jason environment and AgentSpeak language is a must. Besides, MASON programming is also required as an additional skill. However, option number 3 only requires mastering MASON and AgentSpeak. Details about Jason architec-ture are not needed as it is not used. 5. Experimentation
This section is devoted to evaluating the suitability of each alternative for an illustrative scenario where a reduced number of cognitive agents (which perform very simple reasoning and communicative actions) and a high number of reactive ones are simulated. This scenario resumes, in a simple way, the main important characteristics of the both real scenarios, Ubik and Cardinea.
 Section 5.1 offers a brief description of the illustrative scenario. Following, the next subsection defines the BDI strategy of cogni-tive agents coded following Jason architecture. Some screenshots of running scenario and monitoring tools are showed in Section 5.3. The next subsection is devoted to compare alternatives 2 and 3. The numbers of reactive agents considered in this comparison (from 500 to 2500) are smaller than the number of reactive agents required in the real scenarios because Jason is not able to simulated a higher number of reactive agents in a timely manner.
In Section 5.5, we have just discussed that alternative 3 is specially suitable for a high number of agents, where a few of them require cognitive capabilities, and with no need for a sophisticated communication scheme. Such features are precisely those which will be used in Ubik and Cardinea scenarios. 5.1. Sheep and Shepherds example
The example scenario used here is based on the metaphor of the shepherds of sheep. A physical space in the country is populated by a number of sheep (i.e. reactive agents) belonging to different shepherds (i.e. cognitive agents). Both sheep and shepherds initially move in eight directions (N, NE, E, SE, S, SW, W, NW). Within this space each sheep moves in a randomly assigned and fixed direction. It only changes its direction when a shepherd reaches it and forces it to move out to the stable (in such case, the sheep disappears from the yard). The sheep only obeys its corresponding shepherd. Thus, a sheep only goes to the stable when is reached by its own shepherd.

During the simulation of this scenario, sheep and shepherds encounter each other. At this point, the scenario assumes that several encounters may take place in the same instant and in the same place. The simulated scenario allows simultaneous encoun-ters since agents in real scenarios like Ubik and Cardinea perform simultaneous cognitive behaviours. In the Sheep and Shepherds scenario, four types of encounters may occur: (A) a shepherd with another shepherd, (B) a sheep with another sheep, (C) a shepherd with a sheep of his flock, and (D) a shepherd with a sheep of another shepherd X  X  flock.

Encounters of types A and B do not require any reasoning from shepherds, but C and D do in order to determine what the shepherds does. If the encounter is type C, the shepherd orders the sheep to go to the stable, changing the moving direction of the sheep. If the encounter is type D, the sheep is stopped and the shepherd informs the sheep X  X  owner about the presence and location of the sheep. If the sheep is going to the stable rather than moving normally (because of a previous encounter with his shepherd), it does not stop, and the shepherd does not inform about its location.

Each shepherd can follow his own strategy for moving towards the stopped sheep of his flock (i.e. those which were previously reached by a different shepherd, and their location were notified). For example, a shepherd can maintain a list of stopped sheep locations so, when the list size is greater than a certain threshold T , the shepherd goes to their encounter.

This is a suitable example to show how, in a social environ-ment, some agents could carry out cognitive processing while others (a great majority) behave in a reactive way. This example includes a large number of reactive agents (sheep) moving in given directions, and a small number of cognitive agents (shep-herd) supervising them.

Each shepherd needs to carry out some deliberative processing in order to decide what action to execute. In this case, the BDI interpreter, as offered by Jason, is a suitable way to obtain the action corresponding to the percepts of the shepherd. Commu-nicative requirements of this scenario are very simple: shepherds only need to inform, in some (not all) steps, about the location of sheep. For these reasons, approach 3, presented in Section 4.2, seems useful for providing cognitive behaviours to agents in wide social simulations. 5.2. Cognitive shepherd agent
The shepherds are represented by cognitive agents, using the ideas presented in Section 4.2. It is necessary to provide agents with an architecture to execute a reasoning-cycle and to perform basic communicative functions. The shepherds are coded in Java, extending the class AgArch given by Jason and redefining the methods perceive , act , sendMsg and checkMail . The strategical behaviour of the shepherds is written using AgentSpeak code, executable by the Jason BDI interpreter. But this is not enough for agents to run within the MASON environment. Thus, by extending the ArArch class, and implementing the interfaces Steppable and Stoppable given by MASON, the agent implementation is finished.
Cognitive shepherds must execute a reasoning-cycle from the step method in order to perceive (the state of the environment and the other agents), to act (giving orders to the sheep) and to commu-nicate with other shepherds (reporting the locations of the sheep).

The BDI code of cognitive shepherd agents, representing strategies D, is shown below: //strategy D: finds a sheep of other flock  X  step( _ ) o -.send(L,tell,locatedAt(PosX,PosY)); toStop(B).

The BDI strategy is simple because the study of the strategy of the shepherds is out of the scope of this work. We simulate a relatively simple cognitive behaviour for a reduced number of cognitive agents, which interact with a high number of reactive ones using the two proposed alternatives for controlling the simulation.

When a shepherd agent receives the simulation tick, the method step is executed. From this method, the agent launches a reasoning-cycle (one cycle per simulation step). First, the method perceive needs to update the base of perceptions by adding the percept foundSheep ( B , S , PosX , PosY ). This percept indicates that sheep B was found in the position PosX, PosY, and its state is S. It is worth indicating that, when a shepherd initializes his base of perceptions, he needs to add possible new knowledge related to his flock: inFlock ( L , B ). This perception indicates that sheep B is in the flock of shepherd L . The set of all perceptions of this type is shared by all shepherds in the system.

In the next phase of the reasoning-cycle, the BDI interpreter executes BDI code and, eventually, produces actions. These actions must be interpreted by handlers supplied by the method act . These handlers set up the state of sheep agents, according to the specific case.

Note that strategy D implies sending one message to another shepherd. The predefined primitive .send triggers the execution of the method sendMsg in the sender agent. This method writes in the shared memory dedicated to guaranteeing the communica-tion between shepherd agents. The receiver agents need to inspect the shared memory to receive messages. The shared memory is accessible to all agents in the MASON environment. 5.3. Monitoring the scenario
All implementations of this scenario used to obtain the offered evidences for the alternatives 2 and 3 are available at http:// sourceforge.net/projects/integratingmj/ .

Fig. 3 offers some screenshots of running scenario using the monitoring tools provided by MASON. It is important to point out that all evidences presented in the following sections are not collected using these graphical user interfaces. The graphical interfaces were removed from the simulations to avoid the introduction of possible bias related with the management of the graphical tools. 5.4. Comparison of alternatives 2 and 3 through experimentation
The first set of experiments is devoted to bring up a compara-tive analysis between alternatives 2 and 3. The analysis is based on the use of the Sheep and Shepherds scenario, where a high number of reactive agents and a small number of cognitive ones are simulated.

This way, Fig. 4 ashowsthetotaltimeof the simulations using each alternative to simulate different numbers of reactive agents (sheep) n  X  500 , 1000 , ... , 2500 and nl  X  8 cognitive ones (shep-herds). Considering n  X  2500 reactive agents, alternative 2 computes very high times (160,32 min), su ggesting a linear relationship between the total simulation time and the number of reactive agent.
Considering the alternative 2, it was not possible to obtain evidences for n  X  15,000 reactive agents (usual number of social agents in several real scenarios like Ubik or Cardinea), because the memory of JVM was not enough.

The total time of the simulation obtained for the alternative 2 is greater than the one obtained for alternative 3. For the same number of sheep, simulation times using alternative 2 are around 100 times the simulation times produced by alternative 3. It suggests a significant overload in the management of the reason-ing process, the message interchanging and the underlying agents platform. The most relevant evidences related to the study of how this time is consumed are discussed later.

Firstly, given the great difference between simulation times of alternatives 2 and 3, Fig. 4 b shows the portion of the total simulation time dedicated to cognitive processing, message inter-changing, or agent life-cycle management. This time includes (1) reasoning time (consumed by BDI interpreter since percep-tions are taken into account until actions are returned), (2) time dedicated to interchange messages between cognitive agents (using the functionalities of the underlying agent platform), (3) time dedicated to manage the life-cycle of the agents, basically. The figure does not give in a separate way the evolution of these times because any communicative actions take place using alternative 3.

Fig. 4 b shows a significant difference between alternatives 2 and 3. Using the alternative 2, the major part (more than 99%) of the time is consumed by cognitive processing, the message interchanging and/or the life-cycle management. The difference between simulation times of the two alternatives represents the cost of providing communicative functionalities, since the complexity of the agents is the same for the two alternatives. The figure evidences that Jason not only consumes more time than MASON to control the simulation, but a lot of time is dedicated to cognitive processing (managing life-cycle, reasoning, and providing communicative functionalities).

The alternative 2 is not a suitable choice for simulating a small number of cognitive agents into a large social simulation. The simulation times computed by the alternative 2 are higher than the times computed by the alternative 3 although the cognitive and communicative requirements of the agents are low. The low cognitive and communicative requirements considered in Sheep and Shep-herds scenario are similar to the requirements of some real scenarios like Ubik and Cardinea, where a small number of cognitive and specialized agents and a large number of reactive ones are executed. 5.5. Evaluation of alternative 3 through experimentation
Experimental evaluations are focused on the study of the scalability of the approach, but not on the appropriateness of the strategies of the shepherds (this is not relevant in the context of this paper). In this way, two types of experiments were carried out: (1) evaluating the performance of the simulation for several sizes of populations of reactive agents, and (2) evaluating the performance for several numbers of cognitive agents.

These evaluations are based on the analysis of time variables (i.e. both real execution time and simulation time steps) when shepherds manage to get a sheep out of the yard.

The simulation parameters are the following: d : dimension of the yard where sheep and shepherds move; p : density of agents (including sheep and shepherds) per unit of area of the yard; n : number of sheep in the yard (obtained by using the density parameter and the area of the yard); nl : number of shepherds in the yard; and T : minimal number of stopped sheep needed their shepherd to look for them.

Some configurations of the simulation are compared in the next subsections. Experimentation parameters were set up according to the real requirements of Ubik and Cardinea. This data was obtained by maintaining the density of agents in the yard d  X  0.3, the minimal number of stopped sheep needed their shepherd to look for them T  X  0 : 02 n . The simulations were repeated 10 times and results averaged after that. The experi-ments are carried out on a dedicated machine, with GNU/Linux, four Intel(R) Xeon(R) X3230 1.66 GHz processors, and 8 Gb of memory. 5.5.1. Several number of reactive sheep
Some simulations are carried out to compare the performance of the system when the number of reactive sheep changes. Fig. 5 shows the real time and simulation one when 90% of sheep were already put in the stable, for different numbers of sheep n  X  2500,5000, y ,30,000, and nl  X  8 shepherds.

These simulations evidence the ability of this approach to simulate large social simulations in a finite and short time. 0 5 10 15 20 25 30 time (min) 50000 100000 150000 200000 0.2 0.4 0.6 0.8 1.2 1.4 1.6 1.8 time alternative 3 (min) time alternative 2 (min) 0 20 40 60 80 100
It suggest a linear relationship between times and the number of sheep (social agents) in the simulation. The increase in the real time seems not only related with reasoning process carried out into cognitive shepherds. It is logical that these times are increased when the number of social agents and the dimensions of the yard are increased too. Simulation time increases linearly when the number of sheep and the size of the yard grow. 5.5.2. Varying the number of shepherds
Other experimental conditions are simulated in order to study the performance of the approach when the number of cognitive agents is increased. The numbers of shepherds in these experiments correspond to the most usual numbers of cognitive agents in Ubik or Cardinea scenarios. Fig. 6 shows the real time and the simulation one when 90% of sheep escape from the yard, for different numbers of shepherds nl  X  2,3, y ,20, and n  X  15,000 sheep.

These new experiments show the ability of this approach to simulate various cognitive agents in large social simulations in a finite and short time. The real execution time is increased when the number of cognitive shepherds grows, because a greater number of reasoning processes and communicative acts are carried out. Besides, the simulation time is kept around the same value, independently of the number of shepherds in the yard. In this problem, the defined strategy of the shepherds does not improve the performance when a greater number of shepherds are in the yard. In these configurations (where the number of sheep is the same), when the number of shepherds is increased, consequently, the number of sheep per each shepherd is decreased. There is a greater number of cognitive agents but with a minor number of reactive ones for each of them. This is interesting for Ubik and Cardinea in order to describe the suitable number of agents performing cognitive tasks such as decision making, reasoning, coordination, planning.

In the Sheep and Shepherds scenario, coordination advantages do not reduce the simulation time because a shepherd travels large distances to find his sheep. 6. Related works
In Gilbert (2006) , several relevant considerations are given of when social models need to take account of the details of cognitive architectures and when cognitive architectures need to take account of social phenomena. The problem of how to select a cognitive architecture, when it has been decided that one needs to include a cognitive model into social simulations, is discussed. Several authors ( Sun, 2006; Taatgen et al., 2006; Wray and Jones, 2006; West et al., 2006; Parisi and Nolfi, 2006 ) consider that cognitive and social behaviours are at different levels of the relationships in the social simulation community. They consider that social behaviour emerges from cognitive (individual) ones. In this way, social simulation technologies are presented at the social level, and the cognitive architectures at the cognitive one.
Gilbert (2006) also points out that social simulations do not always need to be coupled to cognitive models. Sometimes, a mixed level modelling seems inevitable, such as those in which BDI models are used. Several interesting examples of the problems and benefits of mixed level models are thus provided. For instance, Schurr et al. (2006) consider that individual agents maintain cognitive models (at the cognitive level) of the team as a whole (the social level), in order to improve the coordination of the actions of the agents. In contrast, Parisi and Nolfi (2006) use very simple agents that exhibit behaviour similar to the flocking of birds or the schooling of fish, and show that this behaviour can be the result of the interaction of individual (local) and social (global) factors.
Agent-based simulations in Ubik and Cardinea scenarios require emulating cognitive behaviours in a reduced number of social agents. In these scenarios, according to the previous ideas, a mixed approach is followed, where a small number of agents perform cognitive activities (like reasoning, decision making, planning, etc.), at the same time that a large number of agents behaves as simple reactive social entities. Simulation of scenarios with a high number of reactive agents and a reduced number of cognitive ones is discussed also by other authors like Kennedy et al. (2009) by means of RebeLand model ( Cioffi-Revilla and Rouleau, 2010 ).
Thus, a technology that able to simulate large social simula-tions, where some agents perform cognitive activities, is required. In this work, a proposal to integrate MASON and Jason is given.
MASON stands out among a set of several MABS technologies like SWARM 3 , RePast ( North et al., 2006 ), Ascape ( Parker, 2001 ), StarLogo ( Colella et al., 2001 ), NetLogo ( Gilbert and Troitzsch, 2005 ), SeSAm ( Kl  X  ugl et al., 2006 ) or Breve ( Klein, 2003 ), taking into account its ability to simulate a large number of social agents and to replicate simulations basically. Considerations offered by Nikolai and Madey (2008) , Allan (2009) , Castle and Crooks (2006) , Tobias and Hofmann (2004) , Railsback et al. (2006) , where several time (min) 50000 100000 150000 200000 timesteps comparative analyses between MABS technologies are given, are also taken into account.

On the other hand, several cognitive architectures are studied in order to provide cognitive capabilities to some agents in social simulations. Soar ( Laird, 2008 ), ICARUS ( Langley and Choi, 2006 ),
ACT-R ( Anderson, 1996 ), 4CAPS ( Just and Varma, 2007 ), CHREST ( Gobetetal.,2001 ), Copycat ( Hofstadter and Mitchell, 1995 ), DUAL ( Kokinov, 1994 ), EPIC ( Kieras and Meyer, 1997 ), CLARION ( Sun, 2007 ), PRODIGY ( Veloso et al., 1995 ) highlight from the rest of cog-nitive architectures. These cogniti ve architectures are conceptually heavy models and intensive CPU consuming technologies. Moreover, most of them use a owner language to specify the knowledge of the agent or require large programming or technology familiarization efforts. For instance, several influential cognitive architectures, like
ACT-R, Soar, CLARION, EPIC and 4CAPS, have computational imple-mentations as interpreters of a special coding language.
Special interest is given to the BDI-based cognitive technologies such as 3APL ( Hindriks, 1999 ) (and its extension Goal Directed 3APL
Dastani et al., 2003 ), CoJack( Evertsz et al., 2008 ), or Jason. The BDI architecture is one of the most studied architectures for cognitive agents. As Gilbert (2006) points out, the BDI model is a different kind of model from the cognitive ones (i.e. Soar, ACT-R, CLARION), which are more firmly based on psychological theorizing and experimental evidence, which is very useful in combining cognitive and social levels in one mixed one.

Jason is a Java-based platform for the development of multi-agent systems, at the core of which lies an interpreter for an extended version of AgentSpeak ( Rao, 1996 ), one of the best known languages based on the BDI architecture. However, Jason is not able to simulate the high number of agents that Ubik and
Cardinea require. Jason, similar to the rest of mentioned cognitive architectures, assumes that (1) all entities perform cognitive activities, and (2) these activities are carried out every time. In
Ubik and Cardinea scenarios, only a small number of agents need to perform cognitive behaviours, and these behaviours are not exhibited in each timestep of the simulations.

Bordini and H  X  ubner (2009) show how Jason can be used to simulate BDI agents. However, ideas offered in the present work suggest that Jason has limitations in the field of social simula-tions. In terms of implementation features, the number of agents running in Jason is limited by JVM (social simulations usually involve a large number of agents). Also, distribution agent architectures (such as JADE or SCAI) impose a significant overload on Jason-based social simulations. Moreover, this approach requires more programming efforts than other typical agent-based simulation toolkits.

In this way, Kennedy et al. (2009) suggest that some cognitive architectures such as Soar or ACT-R are not suitable for represent-ing a social human society. In social simulation a large number of agents must be simulated, but only a small number of them need to perform cognitive actions. They propose three cognitive levels to classify agents according to their cognitive capabilities: simple, rule-based and cognitive agents. These ideas are used in Rebeland ( Cioffi-Revilla and Rouleau, 2010 ) where agents are very simple.
Also, according to Sun (2007) it is possible to identify several types of agents in social simulations according to their cognitive requirements or capabilities. In social simulations, the great major-ity of the agents exhibits a very simple behavioural logic, which is basically reactive. Only a small number of agents needs to perform reasoning, planning, decision making, among other cognitive activ-ities. Thus, Sun distinguishes between two types of cognitives architectures: software-(cognitive) and psychology-oriented. He proposes to use software-oriented ones in social simulation in order to understand human social behaviours. He illustrates his ideas by means of the CLARION architecture. He also points out the chal-lenges facing cognitive social simulation. Most agent models in social simulation have been extremely simple. Using cognitive models (incorporating realistic tendencies, inclinations and cap-abilities of individual cognitive agents) can help to understand, in a realistic way, the interaction between individuals ( Sun, 2007 ). He suggests that more realistic and cognitive agent models, incorpor-ating realistic tendencies, inclinations and capabilities of individual cognitive agents, can serve as a more realistic basis for under-standing the interaction between individuals. 7. Conclusions and future work
The integration approach presented in this paper is based on the idea of supporting cognitive behaviour of certain agents in wide social agent simulations. It proposes using Jason to provide cogni-tive capabilities to a reduced number of agents, running on a wide social simulation supported by MASON. Several alternatives to combine Jason and MASON are considered, taking into account the number of reactive and cognitive agents and the communica-tive requirements of two real scenarios, Ubik and Cardinea. An illustrative scenario, which resumes the common characteristics of the real ones, is used to compare two of the proposed alternatives and to collect some evidences about the scalability of one of them: the simulation is controlled by MASON (alternative 3).
The alternative 3, when simulation is controlled by MASON, is able to simulate adequate (inclusive greater) numbers of agents required by real scenarios like Ubik or Cardinea, in a suitable time.
At the same time, this alternative guarantees the simple commu-nicative requirements of these scenarios, using a very simple communication mechanism based on shared memory. Obviously, if communicative/cooperative requirements are increased, the alternative we use could not be as suitable as that presented here. One solution might be to improve the communication mechanism. It can be made better in two ways: (1) using a more sophisticated method, like LINDA ( Coulouris et al., 2001 ), where agent X  X  communication achieves global coordination  X  for exam-ple, it may be interesting to considers tuple spaces (or any other type of associative memory) to ensuring mutual exclusion  X  and (2) giving support to some high-level human communicative social activities such as produce/hear an audible signal, write/ read an informative panel, send/receive an email, etc.
Besides, communicative/cooperative requirements in the simulation can be complex; so, it may be necessary to adopt other alternatives (not used in the example). In this case, one of the agent architectures provided by Jason could be used at the risk of a significant overload to the simulation. On the other hand, this alternative needs an efficient mechanism to manage duplica-tion of agent X  X  information into environments of two different technologies. In this direction there is plenty of interesting work to be done. Deep comparative studies about the performance of the two feasible alternatives (alternative 2 and 3) must be carried out in further works. Several benchmarks such as the number and the time consumptions for BDI reasoning processes, message interchanging, life-cycle management, for example, must be included in these analyses.
 References
