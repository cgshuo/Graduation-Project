 O. Chapelle  X  S. S. Keerthi Abstract RankSVM (Herbrich et al. in Advances in large margin classifiers. MIT Press, Cambridge, MA, 2000; Joachims in Proceedings of the ACM conference on knowledge discovery and data mining (KDD), 2002) is a pairwise method for designing ranking models. SVMLight is the only publicly available software for RankSVM. It is slow and, due to incomplete training with it, previous evaluations show RankSVM to have inferior ranking performance. We propose new methods based on primal Newton method to speed up RankSVM training and show that they are 5 orders of magnitude faster than SVMLight. Evaluation on the Letor benchmark datasets after complete training using such methods shows that the performance of RankSVM is excellent.
 Keywords Ranking Support vector machines AUC optimization 1 Introduction Learning to rank is an important problem in web page ranking, information retrieval and other applications. Several types of machine learning algorithms have been considered for this problem: pointwise methods (Cossock and Zhang 2006 ) (in these methods each document is encouraged to give a score that is in par with its relevance); pairwise methods (Herbrich et al. 2000 ; Joachims 2002 ) (here, if document A is more relevant than document B then the score of A is encouraged to be above the score of B ); and, listwise methods (Cao et al. 2007 ) (in this class of methods the training loss function is based on the list of all participating documents and their scores).

In this paper we focus on pairwise methods. Several pairwise ranking methods have been proposed in the literature: RankBoost (Freund et al. 2003 ), RankNet (Burges et al. 2005 ), LambdaRank (Burges et al. 2007 ), GBRank (Zheng et al. 2008 ) and RankSVM function used and in the way the models are trained.

The RankSVM method forms a ranking model by minimizing a regularized margin-based pairwise loss. Consider a web page ranking problem whose training data comprises: a number of queries; for each query a set of documents; for each (query, document) pair a query. From these judgments, a set of preference pairs P can be constructed by comparing the relevance of the documents associated with a given query. If  X  i ; j  X 2P then document i is preferred over document j . The RankSVM model is built by minimizing the objective function (Herbrich et al. 2000 ; Joachims 2002 ) where  X  is a suitable loss function such as  X   X  t  X  X  max  X  0 ; 1 t  X  2 :
Currently the only publicly available software for solving RankSVM is SVMLight (Joachims 2002 ). 1 This software explicitly forms all difference vectors x i x j corre-sponding to  X  i ; j  X 2P to set up a standard classification problem and solves for w using a dual method. This method is very slow. Any SVM solver for classification can in fact be used to train RankSVM: what is needed is simply to construct a training set made of the straightforward adaptation of an SVM classifier can also be very slow.

Most works (MSR 2008 ) that determine baseline performance values for RankSVM specify a limit on the number of iterations in SVMLight. This is unfortunate because this leads to incomplete training and hence poor ranking results being assigned to RankSVM. performer; for example, on the Ohsumed dataset it is the best performing published method!
This motivates us to look for fast methods of training RankSVM. We consider the primal Newton method (Keerthi and DeCoste 2005 ; Chapelle 2007b ) that is known to be fast for SVM classifier training; Sect. 2 reviews this method. Efficient adaptation of this method for optimizing ( 1 ) requires care. In Sects. 3 and 4 we give two different ways of x i x j vectors is avoided. The complexity of this method is O ( nd ? p ). We have made code for that method publicly available. The second method exploits the fact that P arises methods can be further extended; this is discussed in Sect. 6 .

Finally, note that after this paper has been submitted, T. Joachims released code 3 for training RankSVM based on the structured output learning framework (Tsochan-taridis et al. 2005 ). This code is much faster than SVMLight and the training times appear to be comparable to the ones obtained using our methods. 2 Newton optimization for linear SVM We present in this section the primal training algorithm of a linear SVM classifier along the lines of (Keerthi and DeCoste 2005 ; Chapelle 2007b ). Given a training set of n examples  X  x 1 ; y 1  X  ; ... ;  X  x n ; y n  X  ; where x i 2 following optimization problem:
As argued in (Keerthi and DeCoste 2005 ; Chapelle 2007b ), there is no need to solve this problem in the dual X  X hich is a common practice for SVM solvers X  X nd it can be solved more efficiently in the primal. Since ( 2 ) is an unconstrained and differentiable objective function, the two following standard optimization methods can be used:
Non-linear conjugate gradient . This is one of the most popular gradient based methods search procedure. This one dimensional line search can be performed using standard
SVMs this line search can be done in O ( n ) time if the matrix vector multiplication X s is precomputed, s being the search direction and X the data matrix,
Truncated Newton . In Newton optimization, the weight vector is updated at each iteration as w w H 1 g ; where H and g are respectively the Hessian and gradient of the objective function. In our case, computing the O ( nd 2 ) time and solving the linear system proposed a truncated Newton method (Dembo and Steihaug 1983 ) in which the Hessian is not computed explicitly and the linear system is solved by linear conjugate gradient. Both methods are roughly equivalent (Chapelle 2007a ) and even though we could have chosen either of them as a basis for the RankSVM training, we decided to use the truncated Newton method. Details for this method are as follows.
 objective ( 2 ) is, and the Hessian is with I being the identity matrix.

The Newton step H -1 g can be approximatively computed with linear conjugate gra-multiplication H s for some vector s : And this can be computed as: where D is a diagonal matrix with D ii = 1if i 2 sv ; 0 otherwise.
 constant (which seems to be the case in practice), the total complexity is also O ( nd ). Note the number of non-zero elements of X .

A sketch of the truncated Newton method for solving ( 2 ) is given in Algorithm 1, where we ignored the bias term b for simplicity. We purposely do not give any details about the steps involved in the linear conjugate gradient algorithm as it is a well documented method (Barrett and Romine 1994 ). There are several possible variations around it, but all of them rely on Hessian vector multiplications. In our implementation we used the minres function from Matlab. 3 A first implementation for RankSVM As mentioned in the introduction, any software for linear SVM classification can be used to x i x j for  X  i ; j  X 2P : In matrix form, this means replacing the matrix X by AX where A is a a row k of A such that A ki = 1, A kj =-1 and the rest of the row is 0.
 Since the size of the new training matrix AX is p 9 d , applying naively the truncated Newton method presented in the previous section would yield an O ( pd ) complexity. However, it is possible to do better because the AX matrix does not need to be computed explicitly. Indeed, because of the linear conjugate gradient algorithm, the Hessian vector multiplication can be written as, where now I and D are p 9 p matrices. By multiplying from the right, this product can be computed in O ( nd ? p ) time due to the sparseness of A .
We call this adaptation of Algorithm 1 to the RankSVM formulation PRSVM , which stands for Primal RankSVM. Matlab code for this algorithm is available at http:// olivier.chapelle.cc/primal/ . 4 A better algorithm As indicated earlier, computing gradient and Hessian times vector form the crucial time-gradient and Hessian of L . Since g = w ? C g L and H s  X  s  X  CH L s ; we focus on finding efficient ways of computing g L and H L s : In Sect. 4.1 we take up the case of a single query and two relevance levels, and, in the subsequent section explain how the ideas extend to the general case. 4.1 Case of single query and two relevance levels the lower relevance class g : Let y = X w . Using A and B we can rewrite the loss as where  X   X  t  X  X  max  X  0 ; 1 t  X  2 : It is useful to define so that  X   X  y i y j  X  can be rewritten more simply as max  X  0 ; ~ y j ~ y i  X  2 : Let reversing the order of summation for the other two terms and simplifying we get where and | S | denotes the cardinality of a set S . We can also get the gradient g L using: dependance of b k on ~ y k : Computation of y = X w needs O ( nd ) time. It is then easy to get the a and b vectors in requires O ( nd ) time. Thus the time complexity of g L is O ( n log n ? nd ).
Now consider doing the Hessian vector multiplication needed to find conjugate gradi-ent: we want to compute H L s for a given vector s : H L s is given by Let d = X s . If we define c k using: then, using ( 6 ) and ( 5 ) it is easy to derive H L s as In each major iteration of Newton training (see Algorithm 1), a w is given, the gradient is computed at that w , and then H s is computed for several s vectors in the inner loop (linear done only once when g L is computed. After that, each H s requires O ( nd ) time.
If we compare with the first implementation of RankSVM given in Sect. 3 , we can see relatively normal situations the speed-up obtained is quite decent.

The ideas of this section extend to other margin-based loss functions. Consider first the hinge loss: For  X   X   X  1 in ( 4 ) it is easy to get the following loss and sub-gradient expressions: where q k = 1if k 2 A and q k =-1if k 2 B : This idea for  X  1 is not new and is exactly the same as in (Joachims 2006 ). Since L is non-differentiable for  X   X   X  1 ; Newton method cannot be used and so a bundle method is employed in (Joachims 2006 ).

Next consider Huber loss: It is easy to see that The first term is the squared hinge loss in ( 4 ). The second term is nothing but a shifted squared hinge loss and can be taken care of using ideas similar to those used for squared hinge loss. Thus, for Huber loss also it is easy to give fast methods for computing gradient and doing Hessian times vector operations.

More generally, we can also compute efficiently the objective function and its gradient for any piecewise quadratic function. The complexity scales linearly with the number of been shown to be well approximated by a piecewise quadratic function (Keerthi and gradient of the RankNet objective function (Burges et al. 2005 ). 4.2 Extension to multiple levels/queries relevance. More generally, we may have Q queries and each query q may have a set of documents associated with it. Let us denote by D ( q ) the set of indices of these documents:
Instead of binary relevance labels, documents may have relevance labels r i from an sponds to the most irrelevant label and R is perfect relevance.
 As mentioned in the introduction, the preference pairs are extracted within each query. We can thus rewrite the set of preference pairs P as the following disjoint union: We can then rewrite the objective function ( 1 ) as: time with n qr  X jP qr j using the technique described in Sect. 4.1 where the higher class is A  X f i ; i 2 D  X  q  X  ; r i  X  r g and the lower one is B  X f i : i 2 D  X  q  X  ; r i \ r g : Since operation can be done in O ( nd ) time. We denote this method by PRSVM ? since it improves on the method presented in Sect. 3 . 5 Experiments involving our methods and SVMLight. The experiments are designed to demonstrate gains in training efficiency and also point out the importance of such gains. 5.1 Ranking experiments We experiment with the Ohsumed and TD 2004 datasets from the Letor 3.0 distribution 4 (Liu et al. 2007 ). Some statistics associated with these datasets are given in Table 1 .
We used the same 5 splits in training/validation/test as the ones provided in the Letor NDCG@10 over the 5 splits.

The reason we considered the Ohsumed and TD 2004 datasets is that they are the datasets with the largest number of preference pairs in the Letor collection. This makes the problem more interesting. On each fold, each training set generates, on average, 350,000 preference pairs for the Ohsumed dataset and 648,000 pairs for TD 2004. The two datasets (irrelevant, partially relevant and highly relevant) and only two levels for TD 2004. Also TD 2004 has a large number of documents per query (nearly 1,000 on average), but only a few of them are relevant, whereas Ohsumed has fewer documents, but 30% of them are relevant (either partially or highly).
 As far as we know, SVMLight is the only publicly available software for training RankSVM. We thus compared the following algorithms:
PRSVM This is the algorithm described in Sect. 3 based on SVM primal training; it scales linearly with the number of pairs, which in the worst case is quadratic in the number of examples. Code for that method is available at http://olivier.chapelle.cc/primal/ . PRSVM ? This is the improved version of the above algorithm, as described in Sect. 4 . This scales as O ( n log n ).

SVMLight The software downloaded from http://www.svmlight.joachims.org .Weran it in ranking mode with the -z p option.

SVMLight# Same as SVMLight, but with the -# 5000 option, which limits the number of iterations to 5,000. This is how the benchmark results on the Letor website were obtained (MSR 2008 ).

We begin with a study of the influence of the parameter C on the training time as well as the generalization performance. Results are shown in Fig. 1 . As with most SVM software optimizers, training time increases with C for PRSVM and PRSVM ? . We did not run any experiments with SVMLight in this setting because of the prohibitive training time (see ization performance, the best C is 10 -4 on Ohsumed and 10 -2 on TD2004.

We now compare training times and generalization performances under two settings for the choice of C :
Results for these two settings are reported in Tables 3 and 4 respectively. The following conclusions can be drawn from this experiment. First, not surprisingly, the NDCG@10 is almost the same for SVMLight and PRSVM/PRSVM ? : the only difference between these two methods is the linear versus quadratic penalization of the errors; in most real world the number of iterations for SVMLight as done in (MSR 2008 ) (the SVMLight# entry) can really hurt performance. This is particularly striking from Fig. 2 . RankSVM appears to be one of the worst algorithms reported on the Letor website, but with our implementation it becomes the best algorithm. This is unfortunate because previously people have been led to conclude that RankSVM is an inferior algorithm. Third, PRSVM /PRSVM ? are several orders of magnitude faster than SVMLight. This is also expected because SVMLight is not suited for large scale linear learning. An adaptation of SVMPerf (Joachims 2005 , 2006 )to ranking would probably be much better than SVMLight. But as noted earlier, we compared to SVMLight because it is the only publicly available software to solve RankSVM. And finally, PRSVM ? is faster than PRSVM. Still, on these problems, the number of prefer-ence pairs is relatively small (less than a million) and PRSVM, for which code is publicly available, can be used without any problem. 5.2 Optimization of the AUC We present an experiment on a binary classification problem for optimizing the area under classified pairs (Joachims 2005 ): relevance. This is also the special case discussed in Sect. 4.1 .

The classification problem we consider here is the problem of separating documents in the CCAT category from the remaining documents in the RCV1 text collection (Lewis et al. 2004 ). We fixed C to 0.005 so as to obtain good performance on the test set using the entire training set.

Our main aim in this experiment is to illustrate that PRSVM ? has a better time complexity than PRSVM. For this purpose, we trained both methods with various training n = 19,200, we could not train PRSVM because the number of pairs (around 10 8 ) caused In that figure, we also included the training time of SVMPerf (Joachims 2005 ). It is also an O ( n log n ) method for optimizing the AUC, so it is not surprising to see that both methods are very near in terms of time complexity. This method was run with the -w 3 option for the optimization method (that turned out to be the fastest one) and e (the stopping criterion) set to 0.001. We chose this value of e because it resulted in a relative duality gap of about 10 -5 which is of the same order of magnitude than the relative stopping criterion that we used: Newton decrement/objective function value \ 10 -6 .

The current implementation of SVMPerf (Joachims 2005 ) only allows AUC optimiza-tion, i.e., it only solves the one query and binary relevance case of the ranking problem. If achieve training times that are comparable to the ones reported for PRSVM ? in Sect. 5.1 . 6 Discussion/extension The algorithms described in this paper can be extended and improved in several ways. We discuss some of them below. 6.1 Online optimization chastic gradient descent converge faster to a good solution than batch algorithms (Bottou and Bousquet 2008 ). The Pegasos algorithm (Shalev-Shwartz et al. 2007) for instance is the result of applying stochastic gradient descent to SVMs for classification.
As mentioned in the introduction, we can apply any SVM solver algorithm for solving the RankSVM. Applying stochastic gradient X  X hich is essentially what Pegasos is w &gt; x j  X  ; it is clear that the objective function ( 1 )is learning rate.
 quadratically with n ) and does not leverage the O ( n log n ) trick developed in Sect. 4 .In order to get the best of both worlds, we can do the stochastic gradient descent at the query level instead of the pair level. This means that we randomly select a query, compute the gradient of the part of the objective function associated with that query X  X hat can be done in O ( n log n ) time X  X nd take a step in that direction.

Coming back to the notations used in Eq. ( 7 ), let us define the loss associated with query q as The overall objective function can thus be written as chastic gradient algorithm is summarized in Algorithm 3.
 6.2 Different margin/weights indeed an inversion at the top of the ranking is more costly than one at the bottom; also an inversion between two documents having several levels of difference in their labels should be more heavily penalized than one involving two adjacent labels.
 the difference in DCG 5 obtained by permuting documents i and j , that these weights depend on the current ranking. Instead, if p i and p j are the positions in d , the following sum is an upper bound on the difference between the optimal DCG and the DCG achieved with the current ranking:
Margin rescaling . Set the margin to
It is easy to verify that both methods yield an upper bound on With terminology margin/slack rescaling comes from (Tsochantaridis et al. 2005 ). Weighting of the RankSVM objective function has also been studied in (Cao et al. 2006 ).
For these reasons, it is worth studying optimization methods capable of handling any difficulty to this new setting: one just has to make minor changes to the procedures used for computing the objective function, its gradient and the Hessian vector multiplication.
But it is not possible to do so for general d ij for the method described in Sect. 4 . Two special cases where the gradient can still be computed in O ( n log n ) time are: (1) margin case the ideas of Sect. 4.2 need to be slightly modified to separately deal with the loss term corresponding to each pair of relevance levels. 6.3 Non-linear kernel We have proposed in this paper a primal based optimization of linear RankSVM. More function k . The so-called kernel trick (Aizerman et al. 1964 ; Scho  X  lkopf and Smola 2002 ) H ; x 7 ! /  X  x  X 2H ; where / is such that 8 x ; x 0 ; k  X  x ; x 0  X  X  /  X  x  X  &gt; /  X  x 0  X  :
There is a certain misconception that kernel methods can only work in the dual. But as explained in (Chapelle 2007b ), one can also train a non-linear SVM in primal. The same holds true for RankSVM. The key observation comes from the representer theorem (Kimeldorf and Wahba 1970 ): since the objective function ( 1 ) only depends on the reg-function minimizing ( 1 )in H can be written as: is a linear combination of the training samples.

From the expansion ( 10 ) it appears that to train a non-linear version of RankSVM one can use standard optimization techniques over the b i . Since there are n variables a Newton method would for instance take O ( n 3 ) operations to converge. This cubic scaling is typical for kernel methods unless approximate solutions are sought.

In contrast, if one uses a dual method such as SVMLight, the number of variables to optimize is jPj because there is a Lagrange multiplier for each constraint associated with a preference pair. Assuming that the training time is also cubic in the number of variables and that jPj X  O  X  n 2  X  ; the complexity of a dual method is O ( n 6 ). This is the reason why SVMLight is so slow in the experimental evaluation of Sect. 5 .

Finally, if one is interested in reusing the code for the linear case, one approach is to perform the optimization directly in feature space. The reason why this is feasible is that when mapped to this feature space, spans a vectorial subspace E H whose dimension is at most n . By choosing a basis for E and expressing the coordinates of all the points in that basis, we can then directly work in E .

Let  X  v 1 ; ... ; v n  X 2 E n be an orthonormal basis of E , 6 where v p is expressed as condition. One of them can be found by inverting the Cholesky decomposition of K . and Smola 2002 ; Sect. 14.2).

Now we can use the following mapping w : X 7 ! R n : problem. 7 Conclusion usefulness in efficiently solving web page ranking and binary AUC optimization problems, scale problems arising in practice. In particular we have made the code for PRSVM available: with this code researchers interested in learning to rank can now train RankSVM required by SVMLight. References
