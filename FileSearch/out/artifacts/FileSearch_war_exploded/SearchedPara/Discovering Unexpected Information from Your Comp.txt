 Ever since the beginning of the Web, finding useful information from the Web has been an important problem. Existing approaches include keyword-based search, wrapper-based information extraction, Web query and user preferences. These approaches essentially find information that matches the user's explicit specifications. This paper argues that this is insufficient. There is another type of information that is also of great interest, i.e., unexpected information, which is unanticipated by the user. Finding unexpected information is useful in many applications. For example, it is useful for a company to find unexpected information about its competitors, e.g., unexpected services and products that its competitors offer. With this information, the company can learn from its competitors and/or design counter measures to improve its competitiveness. Since the number of pages of a typical commercial site is very large and there are also many relevant sites (competitors), it is very difficult for a human user to view each page to discover the unexpected information. Automated assistance is needed. In this paper, we propose a number of methods to help the user find various types of unexpected information from his/her competitors' Web sites. Experiment results show that these techniques are very useful in practice and also efficient. Information interestingness, Web comparison, Web mining. The Web is increasingly becoming an important channel for conducting businesses, for disseminating information, and for communicating with people on a global scale. This is not only true for businesses, but also true for individuals. More and more companies, organizations, and individuals are publishing their information on the Web. With all this information publicly available, it is natural that companies and individuals would like to find useful/interesting information from these Web pages. personal or classroom use is granted without fee provided that copies are not made or distributed tbr profit or commercial advantage and that requires prior specific pcrmission and/or a tee. KDD 01 San l:rancisco CA USA Copyright ACM 2001 1-58113-391-x/01/08...$5.00 Existing research has proposed many approaches for web information finding. Most of them are also widely used. These approaches include keyword-based search, manual browsing, wrapper-based information extraction, Web queries, and user preferences. Keyword-based search [e.g., 5] using search engines, such as Yahoo, Alta Vista, Google, and others, is perhaps the most popular method. A search engine allows the user to specify some keywords, and the system then finds those Web pages that contain the keywords. In manual browsing, a Web browser such as Netscape or Internet Explorer is used by the user to browse specific Web pages to manually find interesting information. Wrapper-based approaches [e.g., 2, 13, 9, 15] enable the user to extract specific pieces of information from targeted Web pages. Web query languages [e.g., 19, 12, 6] give the user the opportunity to query the Web. In the user preference approach [e.g., 26], information is given to the user according to his/her preferences. In essence, all these approaches are based on explicit specifications of the user. They are only able to find information that matches the user's specifications. The drawback of these approaches is that it is hard for the user to find unexpected information. They can only help the user find anticipated information because what the user specifies can only be derived from his/her existing knowledge space. In this paper, we argue that finding only what the user explicitly specifies is not sufficient. Those pieces of information that have not been specified by the user may also be of great interests. It is just that the user does not know about them, or has forgotten about them. Such information may be unexpected and can be of great importance in practice. For instance, it is important for a company to know what it does not know about its competitors, e.g., unexpected services and products that its competitors offer. With this information, the company can learn from its competitors and/or design counter measures to improve its competitiveness. Such business intelligence information is increasingly becoming crucial to the survival and growth of any company. Existing web information extraction techniques cannot find such unexpected information, as it is unlikely (or impossible) for one to specify something that one has no idea of. Currently, to find such information the user has to manually browse the Web pages of the competitors. However, manual browsing of every Web page can be very time consuming because a typical commercial Web site can have hundreds of pages or more. There may also be many relevant sites (i.e., many competitors) to be analyzed. Automated assistance is thus needed. Using a computer system to find unexpected information from a Web page (or site) is not a simple task. A piece of information can be unexpected to one company (or user), but not unexpected to another. Hence, whether a piece of information is unexpected is essentially subjective. It depends on the current operations of the company (or the interests of the user), and what it (or he/she) already knows about the competitors. This problem is analogous to the interestingness problem in data mining [e.g., 21, 25, 17, 18, 20], which is described as follows; Many data mining algorithms often generate a large number of rules from a database, and most of the rules are actually not interesting to the user. But due to the large number of rules, it is very difficult for the user to inspect them manually to identify those truly interesting ones. In the context of the Web, the situation is similar. With a large number of Web pages, finding interesting or unexpected information manually is also a difficult task. In this paper, we propose an approach to help the user find unexpected information from his/her competitors' Web sites. In the context of the Web, the unexpectedness of a piece of information is defined as follows: Unexpectedness: A piece of information is unexpected if it is relevant but unknown to the user, or it contradicts the user's existing beliefs or expectations. Note that in this definition, the condition "it is relevant" is important. Not every piece of unknown information is interesting. A piece of information must first be relevant to the user. For example, if the user is a marketing executive, in his/her professional capacity he/she will not be interested in a piece of information on how to plant a tree, although the piece of information may well be unknown to him/her. However, a piece of information on a new marketing strategy will certainly be of interest as it is relevant and unknown to him/her. The proposed approach aims to find interesting/unexpected information from a Web site, which can be a company site (e.g., the site of one's competitor) or a personal home page. This Web site the competitor site. From the definition above, we see that to find unexpected information from a Web site, we need to know the user's expectations (or existing knowledge) about the site. From these expectations, the system can find unexpected information from the site. In this work, we use the information contained in the user's own Web site (which can be a company site or the user's home page) and some additional knowledge of the user about the competitor as the existing knowledge or expectations. Our task of finding interesting information from the competitor site thus becomes a problem of comparing the two sites to find similar and different information. Using the user's own site to represent part of the user's existing knowledge or expectations is appropriate as it allows him/her to find similar and different (or unexpected) information that exist in the competitor site, which is what one is often interested in. The basic idea of the proposed approach is as follows: Given a user site U, a competitor site C, and some existing knowledge or expectations E about the competitor from the user, our system (called WebCompare) first analyzes U to extract all its key information. It then analyzes C, and compares the information contained in C with that in U and E to find various types of unexpected information from C. In this work, we only use the textual information in a Web page. Two schemes are used to represent the information in the page 1: (1) Vector space representation: This representation is (2) Concepts: These are combinations of keywords that occur In this research, we have designed a number of methods to compare two Web sites to help the user find different types of unexpected information. The proposed techniques are general. They can be used in any domain and for any application. Our implemented system (WebCompare) is also highly interactive due to its efficiency. So far, a number of experiments and application tests have been performed. It is shown that the proposed techniques are useful in practice. Although there are many existing techniques that help one find useful information from the Web, to the best of our knowledge, there is still no technique that helps one find unexpected information. Existing approaches to finding useful information on the Web all focus on what the user wants or specifies explicitly. These approaches include keyword-based search, wrapper-based information extraction, user preference specifications, Web and XML queries, and resource discovery. In keyword-based search, the user specifies some keywords, and a search engine (e.g., Yahoo, Excite, Alta Vista, and Google) finds those Web pages that contain the keywords, and ranks them according to various measures. In Web information extraction [e.g., 2, 13, 9, 15, 8], a wrapper or a specific extraction procedure is built automatically or manually for a Web page to extract some specific pieces of information requested by the user, e.g., extracting the prices of some products. User preference based approaches are commonly used in push type of systems [e.g., 26], where the user specifies what categories of information are interesting to him/her. The system then gives him/her only those types of information in the user-specified preference categories. In Web query based approaches, database query language such as SQL is extended and modified so that it can be used to query semi-structured information resources, XML documents and Web pages [e.g., 19, 12, 6, 8]. Web resource discovery aims to find resources (Web pages) related to the user requests [e.g., 16, 7, 8, 9, 10, 13]. This approach uses techniques such as link analysis, and text hyperlinks ll6], which will be studied in our future work. Even without such considerations, the proposed methods are already showing very promising results. classification algorithms to find relevant pages. The pages can also be grouped into authoritative pages, and hubs. All these existing approaches essentially view the process of finding useful information from the Web as a query-based process, although the queries may be of different forms, search query, information extraction query, preference query, Web, XML or semi-structured data query, and resource query. These approaches suffer from the following problems. 1. It is hard to find unexpected information. They can only find 2. The user often does not know or is unable to specify In summary, the proposed technique not only helps the user identify the required information, but also helps him/her find different types of unexpected information. The user is thus exposed to more possible interesting aspects of the Web pages rather than only focusing on his/her current interests (which he/she may not be completely sure). Our work is related to the interestingness research in data mining. The issue of interestingness of discovered rules has long been identified as an important problem [21, 25, 17, 18, 20]. This is due to the fact that data mining algorithms often produce too many rules, and most of the rules are of no interest to the user. A number of approaches [21, 25, 17, 18, 20] have been proposed to help the user deal with the problem. These approaches are, however, not suitable for the Web. The reason is that rules are structured and have clear syntax and semantics, while information on the Web is semi-structured. Different methods are thus needed for finding unexpected/interesting information from Web pages. In this work, we only use textual information in a Web page to find interesting information. Each page is thus treated as a text document. One of the representation schemes that we employ is the widely used vector space model. Here, we review this model. In vector space representation, each document is described by a set of keywords called index terms (or simply terms). term is simply a word whose semantics helps to remember the document's main themes. An index term is also associated with a weight. Let p be the number of index terms in the collection of of a document dj. For an term that does not appear in the document dj, wi, j = 0. A document dj is represented with an index term vector dj = (wlj, w2,j, ..., wpj). In information retrieval, the objective is to find a set of relevant or similar documents of a given query document (which is also represented as a vector). computed using the popular cosine measure weights to index terms. Perhaps, the most widely used weighting scheme is the TF-IDF scheme [23, 3], where TF is the Definition: Let N be the total number of documents in the system We are now ready to present the proposed methods. We will use both the vector space model and keyword combinations (or concepts) to represent the text in a Web page. Below, we first discuss our comparison methods based on these representations. We then describe how the user's previous knowledge can be incorporated in the comparison process. We have designed 5 methods to compare the user site U and the competitor site C to help the user find various types of interesting and/or unexpected information from the competitor site. Let U {cl, c2 .... , cv} be the set of pages in the competitor's Web site. The 5 methods are discussed below. 1. Finding the corresponding C page(s) of a U page: Here, the 147 4. 5. In almost all situations, the user has some existing knowledge about the application domain and its competitors. Our system allows him/her to express this knowledge, which is then used in comparison. User's existing knowledge serves two purposes: 1. It allows the system to discover truly unexpected information. 2. It allows the user to check whether his/her expectations are In our framework, user's knowledge is also expressed as keywords, concepts, and hypertext links. Let E be the set of user-specified keywords, concepts and links. E consists of two parts, E 8, and Es. Eg contains all the general items (keywords, concepts or links) of the domain that the user knows about and does not want them ranked high. Es contains specific items of the site that the user knows about and does not want them ranked high. Note that the two sets, Eg, and Es, are quite different. E s contains those common items of a domain, which the user does not want them ranked high. E 8 can be reused in comparison with any site of the application domain. For example, in the travel domain, "departure" and "date" are very common. They should not be case of a particular site, the user may know some items in it and he/she does not want them ranked high. The user can put them in E,. For example, if the user knows that a travel company offers "free and easy" tours, he/she can put "free and easy" in E~ in comparing the site. "free and easy" may not be put in Eg because download all its pages. During the process, it also records those outgoing links. After crawling, a sitemap is built to allow the user to choose pages for comparison. keywords from a Web page, and performs the standard use the Smart system [23] for this purpose. After keywords are extracted from a page, the association miner is executed to find all the concepts from the page. Section 4 to analyze pages from the user site and the competitor site to help the user find various types of unexpected information. (Note that unexpected term and concept finders are combined into one). want to find those most unexpected pages in MineSet with respect to DM-II. The resulting ranked pages are given in Table 1 (only the top 15 pages are shown). We can see that these pages are MineSet's documentation pages. This is quite interesting to us, as we do not have any html documentations for our system. We plan to add such pages to our site to help our users. to focus on a specific topic for detailed analysis. We are interested in technology comparison of MineSet and DM-II. Our technology page is the research project page, 
The keywords here are given in full words rather than their stems, which can be hard to understand in some cases. ineSetNT_T-7.html 151 Since the proposed technique deals with subjective interestingness of information, it is difficult to have an objective measure of its performance. There is also no existing system that is able to perform our task. Thus, we could not do a comparison. We have carried out a number of experiments involving domain users to check whether the system is useful in practice. In this section, we first discuss our application experiences and then report experiment results on the time efficiency of the system. Our users are from three different organizations: a travel company, a private educational institution, and a diving company. Each of them compared their company site with a competitor site. Before using our system, our users all knew something about their competitors, and had browsed their competitor's Web pages before. Interestingly, our system helped them find a lot of information that they did not find previously. The main reason is that their competitors' sites all have a large number of pages. For example, the competitor's site of the travel company has more than 250 pages. Our user did not go through many of them before. Our system helped him find many previously undiscovered interesting pages. Many of these pages describe some tourist attractions in a number of countries that he had never heard of (mainly in those newly opened-up countries). The system also helped him find some previously unknown educational travel destinations. Many interesting (unexpected) links to tourist information services, entertainment companies and small hotels at: different destinations were uncovered. The user was also a little surprised to find that their competitor guides their customers to some medical care groups in a number of small destinations. This information is of immediately use to the user company. In the cases of education and diving applications, many pieces of unexpected information were also discovered. Our system helped the users perform much better analysis due to the following reasons:  X  It allowed them to quickly focus on those potentially  X  Due to the difficulties of manual analysis, the users often gave  X  If a page is long, the users often do not read it carefully, and  X  Our system is able to attract the users as it always provides If we assume that the length (i.e., the number of keywords) of a Web page is constant, all our algorithms are essentially linear in the number of pages involved. It is reasonable to assume the length of a Web page as constant because the average length of a page does not vary a great deal from one site to another. We have performed many experiments using a number of Web sites. All the experiments were run on a Pentium II 350 PC with 64MB of memory. Table 6 shows the running times for computing different values using 5 Web sites. The time for association mining in each page is given in the final column. Note that association mining is only performed once for each page at the beginning. The results are used in each subsequent comparison. Since the time complexities of all algorithms are basically linear in the number of pages, Table 6 gives the average running time (in sec.) per page for computing different values. Column 1 lists the URLs used as the C sites. The U site is our DM-II site. The number next to each URL is the number of pages from the site (dead links are not counted) used in our experiments. Column 2 gives the average execution time per C page in computing cosine similarity measures for finding corresponding C pages of a U page. Column 3 gives the average time for computing for a U page and a C page (both keywords and concepts comparisons are done at the same time). Column 4 gives the average time for computing unexpPi per page. The final column gives the average execution time for mining concepts per page sim. unexpTr,i,j unexpPi using association mining. Here, the minimum support is set to 1%. Since a small page may have fewer than 100 sentences, then any keyword combination will form a frequent itemset. Hence, we also use a minimum count threshold. In our experiment we set it to 2, i.e., any frequent itemset must appear in a page at least two times. Note that we have also experimented with other sites as U sites. The average execution times per page are roughly the same. From Table 6, we observe that all the computations can be done very efficiently. The system can easily handle a large number of pages in a short time. The time for crawling is not reported (which is done only once), as its efficiency depends on a number of factors, which are well understood. For keyword extraction, we used the Smart system [23]. Outgoing links of each site are recorded during crawling. Comparing the outgoing lists of two sites is straightforward and fast. 
In this paper, we argued that only finding information that matches the user's specifications is insufficient for Web information discovery. In many applications, finding information that the user has no idea of is also of great importance. This paper proposed a number of methods to help the user find unexpected information from his/her competitors' Web sites. Experiment results and real-life applications show that the proposed techniques are very useful in practice and efficient. 
In our future work, we will study the use of metadata and ontology to provide more information related to keywords to create a more intelligent system. We will also study how links can be used to infer more unexpected information. This research may be extended as a methodology for monitoring a competitor's Web site. In this context, we can treat the old web pages of the site as the existing knowledge. Any unexpected changes to the old pages by the competitor will be reported to the user. [1] R. Agrawal and R. Srikant. Fast algorithms for mining [2] N. Ashish and C. Knoblock. Wrapper generation for semi-[3] R. Baeza-Yayes, and B. Ribeiro-Neto. Modem Information [4] R. Bayardo. Efficiently mining long patterns from [5] S. Brin, and L. Page. The anatomy of a large scale [6] S. Ceri, S. Comai, E. Damiani, P. Fraternali, and L. Tanca. [7] S. Chakrabarti, M. van den Berg, and B. Dom. Focused [8] W. Cohen. Integration of heterogeneous databases without [9] M. Craven, D. DiPasquo. D. Freitag, A. McCaUum, T. [10] J. Dean and M. R. Henzinger. Finding related pages in the [ 11 ] Dulin Core Home Page, http://purl.org/DC. [12] D. Florescu, A. Levy, A. Mendelzon. Database techniques [13] R. Feldman, Y. Liberzon, B. Rosenfeld, J. Schler and J. [14] D. Gibson, J. Kleinberg, P. Raghavan. Inferring web [15] T. Guan and K. F. Wong. KPS -a Web information mining [16] J. Kleinberg. Authoritative sources in a hyperlinked [17] B. Liu, and W. Hsu. Post-analysis of learnt rules. AAAI-96. [18] B. Liu, W. Hsu, and S. Chen. Using general impressions to [19] A. Mendelzon, G. Mihaila, T. Milo. Querying the World [20] B. Padmanabhan, and A. Tuzhilin. Small is beautiful: [21] G. Piatesky-Shapiro &amp; C. Matheus. The interestingness of [22] Resource Description Framework (RDF) Schema [23] G. Salton and M. J. McGill. Introduction to Modern [24] G. Salton and C. Buckley. Term-weight approaches in [25] A. Silberschatz, and A. Tuzhilin, What makes patterns [26] G. Underwood, P. Maglio and R. Barrett. User-centered 
