 DONNA HARMAN, National Institute of Standards and Technology NORIKO KANDO, National Institute of Informatics PRASENJIT MAJUMDER, Dhirubhai Ambani Institute of Information and Communication Technology MANDAR MITRA, Indian Statistical Institute and CAROL PETERS, Istituto di Scienza e Tecnologie dell X  X nformazione Over the last few years, there has been a significant growth in the amount of re-search activity on Indian language Information Retrieval (IR) and allied prob-lems. For much of this time, however, standard benchmark datasets were not publicly available. Thus, it was difficult to measure how much actual progress was being made as a result of this research. More recently, efforts have been made to create evaluation frameworks that provide reusable test collections for experimentation, as well as a common forum for comparing models and tech-niques. For example, the Forum for Information Retrieval Evaluation 1 (FIRE) provides Cranfield-style text collections in Indian languages that may be used to evaluate systems for monolingual and cross-lingual IR. Owing to the avail-ability of the FIRE data, groups have been able to conduct IR experiments on Indian languages on a larger scale than was hitherto possible. Similarly, the Named Entities Workshop (NEWS 2009) 2 held in connection with ACL-IJCNLP 2009 provided training and test data for a task requiring machine transliteration of proper names from English to a set of languages (including the Indic languages Hindi, Kannada, and Tamil). This is thus a good time to take stock of the lessons learned, as well as to identify interesting problems and issues that can be fruitfully investigated in the future. The idea of a spe-cial issue of TALIP devoted to Indian language IR was rooted in this context. A total of sixteen submissions were received in response to the call for articles for this issue. Each article was carefully reviewed by three reviewers, and six articles were finally selected for publication.

The first article,  X  X he FIRE 2008 Evaluation Exercise X  by Majumder et al., provides the motivation and background for the FIRE initiative. It describes how the FIRE 2008 test collection was constructed, and summarizes the approaches adopted by various participants. The authors also discuss the limitations of the datasets, and outline the tasks planned for the next iteration of FIRE.

The next two articles investigate monolingual retrieval for Bengali, Hindi, and Marathi, using the FIRE datasets. Commonly used components of a typ-ical IR system are studied in detail. Dolamic and Savoy X  X  article,  X  X ompar-ative Study of Indexing and Search Strategies for the Hindi, Marathi, and Bengali Languages X , studies both light and aggressive stemming approaches for Bengali, Hindi, and Marathi, using a number of different IR models. These stemmers are compared to language-independent methods such as character n -gram indexing, and word truncation.
 Leveling and Jones in their article, X  X ub-word Indexing and Blind Relevance Feedback for English, Bengali, Hindi, and Marathi IR, X  try a corpus-based stemming approach based on morpheme induction, as well as sub-word in-dexing units (e.g. word prefixes of various lengths, word-internal character n -grams, and consonant-vowel-consonant sequences). They study how blind relevance feedback (BRF) may be applied when sub-word-level units are used for indexing.

The next two articles look at the problem of transliteration. Transliteration is an important component of cross-lingual IR systems. During query transla-tion, named entities often need to be accurately transliterated (rather than translated) into the target language. The article  X  X ompositional Machine Transliteration X  by Kumaran et al. looks at building transliteration systems by combining multiple transliteration modules serially or in parallel. Serial composition consists of chaining two transliteration systems X  X rom language X to language Y , and from language Y to language Z  X  X o create an X  X  Z transliteration engine. In parallel composition, evidence from multiple translit-eration paths between X and Z is aggregated for improving the quality of the system. The experiments reported in this article make use of the NEWS 2009 Transliteration Shared Task data.
 In the second article on transliteration,  X  X ransliteration for Resource Scarce Languages, X  Chinnakotla et al. present a different approach to building a transliteration system for a language pair even when no suitable parallel cor-pora exist for that pair. They use a combination of manually formulated rules and a character-level language model and evaluate their approach both directly as well as by applying it to a cross-lingual IR task. This article, too, uses the NEWS 2009 Transliteration Shared Task data.
 The final article,  X  X n Information Extraction System for Urdu X  X  Resource Poor Language X  by Smruthi et al., addresses Natural Language Processing (NLP) tasks for Urdu, a language that is not addressed by any of the other articles. It describes a number of basic Urdu NLP modules, ranging from word segmentation, through morphological analysis, part of speech tagging, named entity recognition, and shallow parsing. These modules have been inte-grated into a commercial text processing tool that is geared towards informa-tion extraction.

This set of articles thus provides a diverse sampling of current research re-lated to Indian language IR. We hope that it will serve to drive deeper and wider investigations in this area.
 We would like to thank all the authors who submitted articles for the special issue. We are especially grateful to the reviewers for their detailed and constructive comments. The following is an alphabetical list of the reviewers who reviewed submissions to the special issue.

