 Accurately and effectively detecting the locations where search queries are truly about has huge potential impact on increasing search relevance. In this paper, we define a search query X  X  dominant location (QDL) and propose a solution to correctly detect it. QDL is geographical location(s) associated with a query in collective human knowledge, i.e., one or few prominent locations agreed by majority of people who know the answer to the query. QDL is a subjective and collective attribute of search queries and we are able to detect QDLs from both queries containing geographical location names and queries not containing them. The key challenges to QDL detection include false positive suppression (not all contained location names in queries mean geographical locations), and detecting implied locations by the context of the query. In our solution, a query is recursively broken into atomic tokens according to its most popular web usage for reducing false positives. If we do not find a dominant location in this step, we mine the top search results and/or query logs (with different approaches discussed in this paper) to discover implicit query locations. Our large-scale experiments on recent MSN Search queries show that our query location detection solution has consistent high accuracy for all query frequency ranges. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  search process, retrieval models, information filtering Algorithms, Performance, Experimentation. Information retrieval, local search, query X  X  dominant location, search, search query location, search relevance. A number of search queries are associated with geographical of the query) or implicitly (i.e., the location is not present in the query string). Accurately and effectively detecting the locations where search queries are truly about has huge potential impact on increasing search relevance, bringing better targeted search results, and improving search user satisfaction. In this paper, we define a query X  X  dominant location (QDL) and present a novel solution that effectively detects it. A QDL is geographical location(s) associated with a query in collective human knowledge. QDL is very important in that if it exists, it should be used as the intended location for the query. Challenges in detecting queries X  dominant locations lie in that QDL is a subjective and collective measure. It is the location existing in the collective human knowledge. The location name contained in the query string may or may not mean a geographical location. Even if it does, it may not mean the dominant location that we are seeking. On the other hand, there are queries that do not contain any location names but do have dominant locations. Running entity extraction algorithms based on geographical location dictionary look-up introduces high false positives for queries whose location names do not mean locations or are not dominant locations, and high false negatives for queries that do not contain location names. From our experience, what is important for location-explicit queries is false positive suppression. There are two scenarios where a false positive can happen. One is when a query is geographically ambiguous. For example, the query  X  X enzel washington X  contains a location name  X  X ashington X  but the query is not geographical at all. [1,6,11,12], using statistical analysis or natural language processing to suppress this type of false positives. The second scenario is also hard to suppress and we have not seen an algorithmic solution in the literature yet. As an example, the word  X  X entucky X  in  X  X entucky fried chicken X  does mean state of Kentucky, USA. It is where KFC was originated from. But KFC has grown into a world-wide business and today Kentucky should not be the QDL for the query. This query is locally intended but does not have a QDL. In this paper, we present a solution that effectively suppresses false positives of both types. We are also able to detect dominant locations for location-implicit queries and minimize false negatives (misses). For example, our solution will give  X  X eattle, WA, USA X  as the QDL to the query  X  X pace needle. X  For these queries, location name extraction from query simply does not work. In our solution, we mine top search results or search logs to infer locations. Knowing a query is local but does not have a QDL is also important because only when a local query does not have a QDL, other (distributed) locations (such as from user IPs) can be used. For example the query  X  X cDonald X  X  X  (another fast food restaurant chain worldwide) does not have a QDL. When user searches for McDonald X  X , his intention is normally the one closest to where he is currently located at. Therefore, the location of McDonald X  X  to user geographically apart from each other. Thus collectively in human knowledge, we know that  X  X cDonalds X  is a local query but without a QDL. This example illustrates the difference between local intention and dominant location of a search query. Table 1 gives sample location-explicit and location-implicit queries, shown with their dominant locations and local intention. Local intention detection is not covered in this paper (which we are doing as the next step of our research). Our contributions from this paper include:  X  A formal definition of query X  X  dominant location (QDL), and  X  A novel solution that detects QDLs from queries both with  X  A classification system that categorizes search queries into  X  A large-scale evaluation of our QDL solution using these In this paper, we first describe some work related to our research. Then we formally define the QDL and categorize search query into distinct types. Next we will describe our QDL detection solution. We will first give an overview of our solution, and then discuss the query tokenization algorithm and our approaches of detecting locations from search results and query logs. We will also give our experimental results to show the performance and speed of our solution. Finally, we will summarize for this paper, discuss how our DQL detection will improve local search, and point out future research directions. In the natural language processing (NLP) community, there are a lot of efforts on Named Entity Recognition (NER) (e.g., [5,18]). Named entities are phrases that contain the names of persons, organizations, locations, times and quantities. NER systems try to identify all the named entities in a sentence or a paragraph of text, and tag them with appropriate entity types. For location entity names, researchers recently started to work on determining the actual places meant by them, which is usually called  X  X rounding X  [11,12]. For instance, one needs to determine whether a location name  X  X ashington X  means a state or a city. Usually the  X  X rounding X  algorithms use a gazetteer to verify geographic names, and use context information in the text to help distill the correct sense of a name. In our case, since queries are usually short and are often not proper sentences, NLP techniques are difficult to apply for high accuracy. In addition, NLP algorithms are too slow to process a large quantity of queries in a short period of time. Instead of tagging locations for only a few words such as in a query, there is also much work on tagging locations for a web page or a web site [1,6]. The basic idea behind this is to use more information, such as ZIP codes, phone numbers, languages, and HTML links, in addition to only the words appeared in the gazetteer, to deduce the location focus. Based on all the locations extracted from one page, an algorithm is applied to identify geographical locations at a proper level in a given location hierarchy. Their work is complementary to ours, since when the web location is known, the search engine can conveniently return pages with locations related to the QDL to improve the user satisfaction. The work most related to this paper is [10]. In that paper, the authors classified web queries into two types: local and global. They define a query as local if its best matches on a web search engine are likely to be local pages, like  X  X ouses for sale. X  A number of classification algorithms have been evaluated using search engine queries. However, their experimental results showed that only a rather low precision and recall can be achieved. Their work is more similar to the concept of  X  X ocal intention X  described in the first section of our paper, which we think is a related but different problem to QDL. A number of commercial search services have started to support location-based search. Some of them, like Google and Yahoo! X  X  local search sites [8,17] require users to specify a location qualifier, in addition to giving a search query. More recently, MSN and Google Search [13,9] added location look-up capability that extracts location qualifiers from search query strings. These algorithms are based on some location string matching rules. For example, for a search for  X  X izza Seattle X , Google returns  X  X ocal results for pizza near Seattle, WA. X  However, no commercial search sites have yet successfully derived locations from location-implicit queries. For example, for a search for  X  X izza near space needle X , Google does not return any local results for pizza businesses around Space Needle (which is in downtown Seattle). In summary, there already exist a number of studies on tagging geographical information to text or web content. However, none of them has worked on web queries for detecting geographical locations from them. The main challenges include the location word ambiguities and the lack of context information since most queries are short. In the rest of this paper we will explain how our solution effectively solved the query location detection problem. We define queries X  dominant location as: Definition 1: Query X  X  Dominant Location (QDL) is one or more geographical locations associated with a query in collective human knowledge, i.e., prominent location(s) agreed by majority of people who know the answer to the query. This definition is rather subjective. We are trying to detect query X  X  dominant location, which is agreed by majority of the people. Therefore, the detected location can be used by most search users. For example, majority of people think query  X  X ew york style pizza X  searches for a special type of pizza and therefore s hould not have a dominant location. For another query  X  X ew york pizza X , someone may consider it means the same as  X  X ew york style pizza X , but many other users consider it is searching for a pizza place local in New York city. Therefore, this query has a QDL, which is New York, NY, USA. In this paper, we also categorize search queries into the following four distinctive types by presence of location keywords and QDL:  X  Queries without location keywords and do not have QDLs  X  Queries with location keywords and have QDLs (Type-2) .  X  Queries without location keywords but have QDLs (Type- X  Queries with location keywords but do not have QDLs The simplest way for detecting QDL is doing a location dictionary look-up in the query. This approach would solve our problem if all queries contained location names and none of them had any ambiguities. However, in reality, a significant portion of web queries do not have this good property. Different from the look-up approach, the basic principle to our solution is to use top search results as an approximation of the majority opinion to the answer of the query, since web pages can be looked as a huge collection of human knowledge and a good search engine returns the most relevant and popular usage/answer to the query in top results. Search queries are often short, containing only several words. One needs to leverage additional and related contextual information to provide more precise results. We use three types of information sources: queries, search results, and query logs. If we detected the QDL from the query, we do not need to look further. Search results contain two parts: text blobs (snippets) and returned web URLs (result pages). Query log contains several pieces of information: user location, search query, and web pages on the result list users clicked on. They also represent different view points: queries surely represent the intention of the current user; query logs usually represent the interest of previous search users; while search results stand for the interest of web authors. We believe that by combining information from different points of view, a complete understanding of the QDL can be obtained. Figure 1 shows the work flow of our QDL detection algorithm. In our solution, we calculate a QDL for each of the three information sources: queries (QDL-query), search results (QDL-result), and query logs (QDL-log). Then we combine the three locations together to get the final result. The basic principle for combining QDLs is that we consider users X  interest take precedence over web authors X  interest, while the current user X  X  interest takes precedence over previous users X  interest. Our QDL detection combination rules are: 1. If the query contains location keywords, then we calculate the 2. If the query log is available, we calculate the QDL-log. If the 3. We retrieve search results and calculate the QDL-result based 4. If we do not find a QDL yet, the input query does not have We observe that search engines always do their best to return most up-to-date, relevant, and popular content and documents in the top portion of the returned results. This tells us that we should be able to use these top results to approximate the current collective human knowledge (sufficient for our purposes of improving search relevance). In other words, top results from a good search engine should represent the most popular and correct context and usage of the query on the web. This observation has also been utilized by other researchers. One example is [2] for building an automatic question answering system using search results. We developed a query tokenization algorithm to break a query into atomic parts (tokens) by usage of the query in top search results. In the outcome, if the location name contained in the original query is not an atomic token, then it is part of a well-known phrase and thus is not the QDL. There are some work from NLP on noun phrase extraction [3,4] which is related to our problem. Compared with their approaches, our approach is more light-weight. It is based on a much smaller while more relevant corpus (snippets). conditional probability Pr( TL|Q ). According to the Bayes X  law, we have: Pr( Q|TL ) is usually called typing model, and Pr( TL ) is called language model. In a real system, typing error processing can be separated from location processing. Therefore, all Pr( Q|TL ) equals to one. In this way, the problem becomes maximizing Pr( TL ) which represents the priori probability of token list. We estimate Pr( TL ) as follows: where TF ( t j ) and TF ( s i ) stand for the frequency of token t result snippets. m is the number of all possible tokens for a given query and n is the number of tokens in TL . For example, m is 15 for a query  X  X entucky fried chicken in seattle X  and n is 3 if it is split into  X  X entucky fried chicken | in | seattle X  ( X  X  X  denotes token boundary). When calculating TF , we only count the longest match for a token occurrence e.g., for an occurrence  X  X entucky fried chicken X , we do not add a count to either  X  X entucky fried X  or  X  X ried chicken. X  We now walk through the algorithm with an example query  X  X entucky fried chicken in seattle. X  Query tokenization and explicit location detection algorithm: Step 1: Submit the query to search engine and collect a list of tokens (sub-queries) from top result snippets returned from the search engine. For our example, we parsed top 30 results and the following table lists tokens we obtained in descending order by each token X  X  TF . TF % is the number of occurrences of a token divided by total number of occurrences of all tokens in the top search result. Step 2: Assemble tokens from Step 1 back into original query, starting from the top one. A token cannot be reused in the assembly process. For our example, we obtained the following token lists. Step 3 : Pick the top token list from Step 2. For our example, we pick  X  X entucky fried chicken | in | seattle. X  Step 4: For each token in the Step 3 outcome, repeat Steps 1-3 until it is not further breakable. For our example, we send  X  X entucky fried chicken X  to search engine, and found it is not further breakable because the first sub-token on the returned list is the i nput token itself. Step 5: Output the final token list that only contains atomic tokens and has the largest Pr( TL ). For our example, the final output of the algorithm is:  X  X entucky fried chicken | in | seattle. X  From this example, we have shown how the tokenization algorithm suppresses false positives. B ecause  X  X entucky X  is always used together with  X  X ried chicken, X  by itself it cannot be a geographical location. The token  X  X eattle X  is atomic and not ambiguous, thus the QDL of this query is  X  X eattle, WA, USA. X  Please note that we could further validate the QDL by looking at other context sources we use in our solution. We further illustrate the power and accuracy of our tokenization algorithm by examining the following two queries:  X  X eattle best coffee X  vs.  X  X eattle X  X  best coffee. X  These two queries are very similar but mean for different things. The first query is a general term, by which the user is searching for the best coffee in Seattle area; whereas the second query is used to search for a coffee shop chain named as Seattle X  X  Best Coffee (which was originated from Seattle but now has expanded into other cities as well). Our tokenization algorithm breaks the first query into three atomic tokens:  X  X eattle | the result, QDL for the first query  X  X eattle best coffee X  is  X  X eattle, WA, USA X  and the second query  X  X eattle X  X  best coff ee X  does not have a QDL. Another advantage from our tokenization algorithm is that because the algorithm is completely based on live search results, search queries will always be broken correctly by current popular usage. One can think that we are always using a fresh corpus representing the most relevant and current documents corresponding to each query. It will be impossible to have a static corpus work as relevant and complete as what is provided from a good search engine. We are aware that some false positive suppression implementations are using well-known named entity list for exclusion. Comparing with our approach using live web corpus, having an exclusion list would require additional and non-trivial cost to create, maintain and constantly update the list for practical and consistent coverage over time. If we do not get a QDL from the last step, we move on to mine query logs to detect the implicit QDL for the query. User IPs and clicked URLs for the query from the log are used in our solution. For user IPs, we first map them to user locations. If we treat the collection of user locations as a web document, then the location detection problem becomes similar to that in [1,6]. An algorithm needs to be designed to find out the dominant location in a list of extracted locations. The main issues here are dealing with the location hierarchy and returning locations with appropriate levels in the hierarchy. It would be erroneous to simply calculate the frequency of locations and return those most frequent ones as the results. As illustrated in Figure 2, if we got one  X  X eattle, X  two  X  X alifornia, X ,, three  X  X an Diego, X , two  X  X os Angeles, X  and two  X  X an Francisco. X , it X  X  clear that the main location focus should be California instead of any mentioned cities in California, nor it should be the state of Washington, or Seattle. Figure 2. Illustration of implicit dominant location detection. In [1,6], different but similar algorithms have been designed to use the reinforcement relationships between different location hierarchies to solve this problem. Another advantage of such algorithms is that they can be used to disambiguate those location names corresponding to multiple physical locations. In this paper, we use a modified version of their algorithms, as illustrated in the following: Implicit dominant location detection algorithm: 1. Map all the extracted location names to a hierarchy view of a 2. Two measures are borrowed from the CGS/EGS approach [6], 3. Once the power and spread values are computed, the final For clicked URLs, we retrieve their content and merge them into one page. Based on our gazetteer, we extract all location names from the page, and then use the above algorithm to calculate the dominant location. The location extracted from user locations may be biased by the popularity of the search engine and the use of proxy servers. For example, a search engine may be popular only in a particular area, then most of the user logs will come from that area. The situation is similar to when many users access the Internet behind proxy servers. Based on such considerations, we use much larger thresholds for the power and spread values for user locations. In addition, we set a minimal number of log items that a query should have before calculating its QDL-log. When combining the QDLs from user locations (QDL-log-IP) and from clicked URLs (QDL-log-URL), we first combine the two location trees together in Step 1 of the above algorithm, and then apply Step 2 and Step 3 to the combined tree. The new f(l) for a location node l is calculated as: where 0&lt;  X  &lt;1. f(l, QDL-log-URL) stands for the frequency of l in the clicked pages, while f(l, QDL-log-IP) represents the frequency in the IP locations. If no QDL has been obtained from either queries or query logs, finally, we look at the search results. The algorithm is similar to that in Section 4.3. The only difference is that the input is the result snippets or result pages. We merge the snippets or page content from top search results into one page, and use the same location-implicit query dominant location detection algorithm to calculate QDL-result. Our data set is a recent MSN Search log over a 30-day period of time. We randomly selected 10,000 unique US English queries from each of these five disjoint query frequency ranges: SINGLE, VERY_LOW, LOW, MID, and HIGH. These ranges cover the entire MSN search frequency bandwidth. As examples, SINGLE contains single-hit queries and HIGH contains the most popular queries. To recognize and extract the geographical keywords referred in queries, a set of geographical thesauruses must be constructed in advance. First, needed location entities are collected from various sources, including USA Zip codes from [15], telephone numbers from [14], and geographical names from [7]. Given a Zip code, there were usually several corresponding geographical names in our geographical data sources. One of them is the standard geographical name for the Zip code while the others are aliases of the standard name. After synthetically considering Zip codes and corresponding geographical names, we could obtain the standard hierarchical location tree table, the geographical name table and the Zip code table. Then the telephone number table is constructed by synthesizing the standard hierarchical location tree table and telephone number information. As the result, our geographical hierarchy contains levels of country (USA only), state, and city. On average, a state-level node has about 455 city nodes. In this paper, for queries with locations outside USA, we define them as no QDL. In our experiments, the search results/snippets are obtained by sending the queries to the MSN search engine [13]. Our experimental environment is a machine with Intel Xeon CPU 3.06 GHz, 2 GB RAM, 100Mbps internet connection (the real bandwidth is affected by multiple factors, therefore, is not listed here) and running Microsoft Windows Server 2003. First, we asked a team of human editors to label all sample queries into the four query types and recorded their found QDLs. Table 4. Distribution of query types for different frequencies. As shown in Table 4, a total of 11.7% of the queries have labeled QDLs (Type-2 and Type-3 combined). This number fits the lower bound of the number reported in [10], where 11.9% to 16.2% of their test queries are local. Remember that there are local queries that do not have QDLs. Among queries with QDLs, about 6.0% of them (or 0.7% of all queries) belong to Type-3, i.e., they are location-implicit queries but have QDLs. Among queries with location keywords, 19.7% of them (or 2.7% of all queries) do not have QDLs. From this data, we can see that dictionary look-up approach will not achieve satisfactory performance without incorporating more context information, since they will introduce false positives from Type-4 and add false negatives from Type-3. The query-by-type distribution has different characteristics in different query frequency ranges. The Type-1 queries are the largest query group across board, which only dipped in the MID range. The MID range has the highest concentration of Type-2 and Type-4 queries. The HIGH range has the lowest Type-2 queries but has the highest and the second highest concentrations of Type-3 and Type-4 queries, respectively. In summary, queries in MID to HIGH frequency ranges are more likely to have QDLs. But meanwhile, these ranges also have the highest concentrations of Type-4 queries. Correct QDL detection is therefore more important to MID to HIGH frequency ranges. This importance should be emphasized considering that these ranges bring bigger portions of search traffic. Table 5 shows that queries with QDLs are on average longer (in word count) than those without QDLs. Type-2 queries are the longest, since they contain location keywords that are QDLs. We evaluated the outcome of our QDL detection solution using labeled queries. A computational outcome for a query is said to be correct only when all of its QDLs exactly match the labeled results, or both computational and labeled QDLs are null. In our experiments, precision is used to measure the fraction of detected QDLs in the computational results that are correct, comparing to the labeled results. Recall is used to measure the fraction of QDLs in the labeled queries that are captured in our computational results. Note that precision often can be increased at the expense of recall, and vice versa. Therefore we combine precision and recall into a single metric using Micro-F1 [16]. In addition, due to the sheer volume of queries that need to have dominant locations detected, the processing time has become a critical factor to the performance. Therefore, we also report the per-query average running time cost. We separate the computational time cost and the page downloading time, since the latter is greatly affected by the network conditions. Due to the lack of space, we only highlight the key results and observations from our experiments in the following subsections. In the following two tables, P, R, and F represent Precision, Recall, and Micro-F1 measures, respectively. The parameter to query tokenization is the number of top snippets it should parse from the search results. At first, QDL-query performance (F) increases as number of snippets increases. The F measure reached the peak of 0.651 at snippets = 30. Beyond 30 snippets, QDL-query performance starts to decrease. The reason for decreased performance with increased number of snippets beyond 30 is that additional snippets do not always represent majority opinion to the answer of the query, thus we started to introduce noise to the dominant location detection. We observed the same pattern in QDL-log-IP, where F peaks at minimum frequency = 80. The reason is when minimum frequency increases, precision will improve while recall will drop more significantly, since fewer queries will be processed. Table 7. QDL-log -IP performance by min. query frequency.
 In QDL-log-URL, we use first N clicked web pages due to large page downloading and parsing time. We also control the numbers of snippets and pages to use in QDL-result-snippet and QDL-result-page, respectively. Using more snippets or pages usually improve the precision, but reduce the recall. In Figure 3, using 20-30 snippets or pages looks to be a good choice. Using URLs in the log does not improve the performance much, compared with using search results. This is mainly because search users normally only look at top results and clicked links from these top results. Figure 3. QDL-log-URL, QDL-result-snippets, and QDL-result-Table 8 lists optimal parameter values selected for our solution. We compared our approaches to a simple dictionary look-up method and to Google [9] (where we sent our queries to Google and checked whether it returned correct local results). Table 9 shows the performance and computational cost of Look-up, Google, and our algorithms. In this table, CT stands for Computational Time in milliseconds (excluding page downloading time), and DP stands for number of Downloaded Pages (either search result pages or returned web pages) per query. As expected, algorithms based on result pages require more downloading time. If we can cache them on the server, then the downloading time can be greatly reduced. Based on this comparative study of algorithms, we found: 1. Look-up and Google are quickest ways for getting results, but 2. QDL-query works well for location-explicit queries but we 3. QDL-result-snippet and QDL-result-page have similar 4. Combining QDL-query and QDL-log-combined achieved the 5. Without access to search query logs, or trying to reduce the Next we studied error distributions by query types for different algorithms and for different query frequency ranges. There are three types of errors. EFP: false positives (returns a QDL that does not exist); EFN: false negatives (returns no QDL while there is one); and ELoc: correctly detects that there is a QDL but returns one different from the labeled QDL. Query types 1 and 4 each has one type of error, and query types 2 and 3 each has two types of errors. The following three tables give these error distributions as the percentage of queries in the entire frequency bandwidth, in the MID range, and in the HIGH range for look-up, Google, QDL-query, and QDL-combined (using QDL-query and QDL-log-combined) algorithms. First, this study shows that our algorithms perform consistently across all query frequency ranges. In all cases, QDL-combined and QDL-query always have lower error rates than Look-up or Google. Across all frequencies, the best algorithm QDL-combined outperforms Look-up and Google in reducing error rates by 84.7% and 87.7%, respectively. QDL-combined wins over Google by having much lower false negative rate resulted from better recalls in Type-2 and Type-3 queries. Moving to the MID range where we have higher concentrations of QDL-positive queries and queries that contain location keywords but do not have QDLs, both Look-up and Google had much worse error rates. The overall error rate of QDL-query also increased by 43%, but is less proportional to the 48% higher concentration of Type-2 queries in the MID range. The QDL-combined algorithm remained to have the lowest error rates in this frequency range, and is the overall winner. The QDL-combined algorithm also has the lowest overall error rate in the HIGH frequency range, followed by QDL-query. In summary, our approach (QDL-combined and QDL-query) had the best performance in our tests. They had much higher Micro-F1 values and lower error rates than a Look-up method and Google, thanks to their ability to suppress both false positives and false negatives, where Look-up is not good at either and Google is good at former but much worse at latter. In this paper, we presented a novel solution for detecting dominant locations from search queries. A dominant location is one or few locations agreed by majority of users who know the answer to the query. Knowing a query X  X  dominant location will effectively improve local search relevance because when it exists, QDL is the true geographical location that a user is intended to search at or around. Our solution minimizes false positives by tokenizing search queries according to their most popular and current web usage. For location-implicit queries, we look for QDLs on a given geography hierarchy from a combination of data sources including search results and query logs. With our modified power and spread measures, we effectively suppressed false negatives as well. Another advantage of our solution using the live search results is that our outcome will be always up to date, capturing the correct and current locations for queries. We do not rely on (thus do not have incurred maintenance costs for) any inclusion or exclusion named entity lists that we would otherwise have to consult with every time to check for a query. In conclusion, in this paper we defined search query X  X  dominant location (QDL) and proposed a novel solution using top search results and query logs to detect it. Large-scale experimental results show that our QDL detection algorithms achieved high performance in both accuracy and speed, and consistently outperformed the look-up method and Google by Micro-F1 and accuracy measures. We continue with our work in improving our algorithms and in addressing other important open issues. One of them is to measure query X  X  local search intention. Knowing that a query is local but does not have a QDL is also very important for improving search relevance. Another venue of our research is to cluster search queries by content intention, dominant location, and local search intention, and to develop fast algorithms to classify new search queries into existing query clusters to facilitate real-time search relevance improvement. [1] Amitay, E., Har'El, N., Sivan R., and Soffer, A. Web-a-where: [2] Banko, M., Brill, E., Dumais S., and Lin J. AskMSR: Questing [3] Bourigault, D. Surface grammatical analysis for extraction of [4] Church, K.W. A stochastic parts program and noun phrase [5] Cucerzan, S., and Yarowsky, D. Language independent NER [6] Ding, J., Gravano, L., and Shivakumar N. Computing [7] Geographic Names Information System (GNIS). [8] Google local search: http://local.google.com [9] Google search. http://www.google.com [10] Gravano, L., Hatzivassiloglou, V., and Lichenstein, R. [11] Li, H., Srihari, R. K., Niu, C., and Li, W. Location [12] Li, H., Srihari, R. K., Niu, C., and Li, W. InfoXtract location [13] MSN Search. http://search.msn.com/ [14] North American Numbering Plan. [15] USPS  X  The United States Postal Services. [16] Van Rijsbergen, C.J. Information Retrieval. Butterworths, [17] Yahoo! local search. http://local.yahoo.com/ [18] Zhou G., and Su, J. Named entity tagging using an HMM-
