 A useful feature to facilitate critical literacy would alert users when they are reading a controversial web page. This requires solving a binary classification problem: does a given web page discuss a controversial topic? We explore the fea-sibility of solving the problem by treating it as supervised k-nearest-neighbor classification. Our approach (1) maps a webpage to a set of neighboring Wikipedia articles which were labeled on a controversiality metric; (2) coalesces those labels into an estimate of the webpage X  X  controversiality; and finally (3) converts the estimate to a binary value using a threshold. We demonstrate the applicability of our ap-proach by validating it on a set of webpages drawn from seed queries. We show absolute gains of 22% in F 0 . 5 on our test set over a sentiment-based approach, highlighting that detecting controversy is more complex than simply detecting opinions.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Storage and Re-trieval  X  Query formulation, Information filtering controversy detection, sentiment analysis, critical literacy
Publishing material about controversial issues is of para-mount importance to a functioning democracy, as it allows disagreements to be aired in public. However, when search-ing for discussion of a controversial issue it is all too easy to cherry-pick from the results. For example, those against gun rights will surely find material supporting this posi-tion (the tragedy of school shootings), whereas those for gun rights will find other evidence (the Second Amendment in the U.S.). At the same time, people searching for Issels Treatment will find a convincing web site describing this  X  X omprehensive immunotherapy for cancer X ; yet it is listed as a  X  X ubious treatment X  by Quackwatch [11] and the Amer-ican Cancer Society considers it unproven and maybe harm-ful [2]. An unsuspecting reader who has not heard of the controversy is likely to be misled or uninformed. Even care-ful readers suffer from a  X  X ilter bubble X  [9] wherein automatic and social systems guide readers toward what they expect, feeding into confirmation bias rather than encouraging them to seek the multiple perspectives available on a subject.
We are interested in techniques that encourage and facil-itate healthy debates, allowing users to critically approach these issues. One way to do so is to alert users when their search results represent a perspective on a controversial is-sue; for example, imagine a warning presented at the top of a web page:  X  X his webpage represents one of several per-spectives on a controversial topic. X  To do so, we need to answer a non-trivial question:  X  X s this topic controversial? X 
Note that our goal differs from  X  X iversifying X  search re-sults, wherein  X  perhaps  X  each of the perspectives might be presented in a ranked list. Instead, we aim to identify whether a single page in isolation discuses a topic with wide ranging perspectives. This study is an early investigation into whether that challenge can be solved.

We approach this as an estimation problem: determin-ing the level of controversy in a topic, while thresholding it for binary classification. We utilize a supervised k-nearest-neighbor classifier on web pages that uses labeled estimates of controversy in Wikipedia articles to determine the like-lihood that a web page is controversial itself. Essentially, a page similar to controversial pages is likely controversial itself. Our choice of Wikipedia articles as labeled neighbors is motivated both by topical coverage, as well the possibility of using unsupervised labels of controversy from prior work.
We use a collection of 377 web pages that were manually judged as controversial or not. Our approach yields F 0 . 5 64.8% and accuracy of 72.9% for our test set. Hypothesizing that controverial material is often highly opinionated, we compare our results to a sentiment analysis classifier; we outperform it consistently on all metrics but recall.
To the best of our knowledge, this problem has not been formulated as such before, though several special cases have been explored by previous researchers.

Controversy Detection in Wikipedia. Early work on detecting controversy focused on Wikipedia, where struc-tured data and revision history provide powerful scaffolding, simplifying detection [7]. Wikipedia pages manually tagged as controversial are a valuable resource, but using the man-ual tags alone can be problematic due to inconsistency and sparseness of tagging [10, 14]; thus, identifying controver-sial Wikipedia articles that have not been manually tagged adds value. Recent work reexamined the variety of machine learning and handcrafted approaches previously published, and offers different criteria: one suggested metric,  X  X  X , neu-tralizes vandalism, which was cited in prior work as a con-founding issue in Wikipedia [14]; another paper leveraged collaboration networks between individual editors to identify controversy, with significant improvements reported [12].
Controversy on the web. Our goal is to widen the scope of controversy detection to the entire web. Work on controversy outside Wikipedia has made progress on tar-geted domains, e.g. Twitter [10] and news [3, 5]; they largely considered politics and politicians. In our case, we would like to approach all controversies, whether political, medical, or religious. The closest work to ours creates a collection [3]; we detect controversy in isolation and in ad-hoc situations.
Recent work includes diversifying search results for con-troversial queries [6], with less focus on detection that a query is controversial in the first place. Reliance on sources such as Debatepedia 1 [3, 6] presupposes that the debate has been covered. Yet debate websites focus on political issues; as of this writing Debatepedia has no entry discussing Home-opathy. We consider the problem of detecting controversy to have potential utility as a precursor step in diversifying controversial queries, though that is not our main focus.
Sentiment analysis. One approach that can apply to controversy is sentiment analysis, used to detect words that indicate high polarity and opinion [5, 10]. However, unlike sentiment,  X  X ontroversies are much more complex and opin-ions are often expressed in subtle forms, which makes deter-mining pro/con polarities much more difficult than [...] prior work on opinion mining X  [3, p. 523]. We compare our ap-proach to a baseline sentiment analysis system [1] and show that its performance is lower for this task, yet it has high recall and bears further investigation (see Section 4.3).
To investigate the feasibility of our approach, we construct a suitable data set. We hypothesize that we can detect con-troversy indirectly by using the controversiality of Wikipedia articles that are similar to the starting webpage. Thus, our data set also includes judgments on the controversiality of Wikipedia articles.
 Our data set, described in Table 1, was created as follows. We selected 41 seed articles from Wikipedia. The articles were chosen based on their implied level of controversy, with some clearly controversial ( X  X bortion X ) and others clearly not controversial ( X  X ary Poppins X ). We used only the Wiki-pedia article X  X  title as a query to the blekko search engine From up to top 100 results returned for queries, we selected http://dbp.idebate.org/ http://blekko.com only webpages that also appeared in ClueWeb09 category B 3 to allow reproducibility. We also omitted Wikipedia articles, pages that could not be displayed properly, and pages that had no nearest neighbors among the Wikipedia articles (see below and Section 4.2), leaving 377 web pages over the 41 seed topics.

We split this collection into training and testing sets based on the seeds  X  since our pages were not chosen indepen-dently. We wanted approximately a 60-40 split, so we di-vided our seeds randomly into 30% whose  X  X elated X  web-pages were labeled as all training, 20% as all testing, and 50% of the seeds whose webpages were split, as one group, at a 60-40 ratio between the training and testing collections. The final distribution of the collections differed slightly due to our selection method, as shown in Table 1: the training set had a lower proportion of controversial pages than the testing set (29.8% vs. 38.0%).

We created an annotation tool to capture the controversy level of these pages. We ask how controversial is the topic discussed by the webpage, and the options were:  X 1 -clearly controversial X ,  X 2 -possibly controversial X ,  X 3 -possibly non-controversial X , or  X 4 -clearly non-controversial X . By design, 344 of the 377 pages were annotated by more than one an-notator for 851 total judgments. Table 2 summarizes the agreement among the annotators. 65.1% of the pages had complete agreement, accounting for 64.7% of the judgments. Another 17.4% had a majority (2 of 3) vote, with 17.4% of the pages tied among two annotators.
 Our approach also relies on labeled data from Wikipedia. We used a variation of the annotation tool to judge the controversiality of Wikipedia articles. For each of the 377 pages we found its nearest Wikipedia articles using queries to blekko (as described in Section 4.2), for a total of 8755 unique Wikipedia articles. We annotated as many top-rank-ing Wikipedia articles as we could, resulting in 1761 Wiki-pedia articles judged by our annotators, as shown in Table 1. Of these, 331 were annotated by more than one annotator, and they agreed on 81.6% of the Wikipedia pages.

Whenever a webpage or Wikipedia article was annotated more than once, we took the average value of all the judg-ments (in the range [1..4]) as its controversy score, which we use in our approach and evaluation. To convert into a bi-nary value, any score below a threshold of 2.5 (the midpoint of our 4-point range) is considered controversial.
We evaluate our approach as a binary classifier model, where a page is classified as controversial or not controver-sial . For this approach, the set marked as controversial by the system can be compared to the truth set described ear-lier. We calculate precision, recall, F 1 , F 0 . 5 , and accuracy. As a new problem, no obvious baseline algorithm exists. However, since controversy can arguably be described as the presence of strong opposing opinions, a natural baseline is a sentiment analysis classifier. For our baseline, we took a modified version of a state-of-the-art sentiment classifier, a logistic regression model on sentiment features [1]. The only modification is the division into classes, since we are most in-terested in the presence of sentiment, not its direction; thus, http://lemurproject.org/clueweb09/ we train a binary classifier in which positive, negative, and mixed sentiments are considered one class ( X  X entiment X ) and neutral sentiment the other ( X  X eutral X ). The sentiment class is taken as controversial; the neutral, as noncontroversial. Table 2: Inter-annotator agreement. Results are shown
As two additional baselines, we generated random values as estimates of controversy. One random function assigns equal probability to controversial and noncontroversial pages ( X  X andom 50  X ), and another assigns controversy based on the incidence in the training set, i.e., 29.8% ( X  X andom 29 . 8 each random approach, we averaged the scores of 3 runs. Fi-nally, we also use a dominant class baseline, which judges every webpage as noncontroversial, and thus has zero preci-sion and recall but non-zero accuracy.
Our approach maps a webpage to a set of Wikipedia arti-cles, and uses the controversiality of those articles to predict whether the page at hand is controversial or not. We use a supervised approach that uses our annotators X  judgments of Wikipedia articles to create an estimator of controversy for the webpage, which we then convert to a binary value.
Our starting point is a webpage, from which we automati-cally generate a query by selecting the top ten non-stopword terms from that page. As mentioned above, we use these terms to query Wikipedia (via blekko), and eliminate any user or talk pages. As mentioned in Section 3, we have la-bels of controversy on 20% of these articles (with preference towards articles ranking higher in the retrieval). We use our annotators X  judgments of Wikipedia articles whenever they are available. We aggregate the score over k neighbors of the webpage to receive a final controversy score. As men-tioned in Section 3, we convert the score to binary using a threshold of 2.5.

We vary 4 different parameters in our runs: 1. Stop set : We used two stop sets, the 418 INQUERY stop set [4] or a short, 35 term set (  X  X ull X  vs.  X  X ight X  stop). 2. k : we control for the number of neighboring Wikipedia articles used in the calculation. We used [1..20], and one run with no limit (all available matching articles are used). 3. Handling non labeled data : We use two alterna-tives to  X  X ill in the blanks X  when labeled data was not avail-able: One guesses a score of 2.5 for absent neighbor labels, and the other guesses a score of 2.5 for web pages where no neighbors were labeled. However, both versions achieved similar scores, and were identical for all the runs presented; we thus omit this parameter in the remainder of our paper. 4. Aggregate function : we use one of three methods to aggregate the k neighbors X  scores: Max , Average , and Exponential Average -an average weighted by 1 2 rank .
All in all, we had 252 parameterized runs (2 stopping options  X  2 methods  X  3 aggregate functions  X  21 limit values). In order to choose the best parameters, we ran a parameter sweep on the training set.
Table 3 shows the results of the parameter sweep, with runs optimized for P, R, F 1 , Accuracy and F 0 . 5 on the train-ing set. The upper half of the table presents scores on the training data (the runs used to select the parameters among the 252 possibilities) and the parameters that achieved those scores. The lower part of the table shows the evaluation measures for those same parameters on the test set. All 4 baselines are presented for each of the sets.
Looking at the results in Table 3, we note that scores on the test set are consistently higher than baseline runs for all metrics but recall. We observe that the runs optimizing for precision and recall on the training set  X  top two rows of Table 3  X  remained stable in the test set. The run optimizing for precision in training also outperformed other runs for Accuracy and F 0 . 5 in the test set. In all cases, we present F 0 . 5 in addition to F 1 ; we prefer higher precision over recall.
The results for the test set are in line with the training results, indicating that our method is successful in detecting webpages with controversial topics. The best run overall (Light, k=4, average) achieves 21.9% and 21% absolute gain in F 0 . 5 over the sentiment and random baselines respectively. Accuracy is 10.9% higher than the best baseline.

In all runs, we used a threshold value of 2.5 on both our es-timator and annotations to create binary judgments. Using the threshold on the estimator was also validated by running a Precision-Recall curve on the training set.
 Table 3: Results for the best methods, optimizing for P, R, F 1 , Accuracy and F 0 . 5 on the training set; presented on both sets. Bold cells in the training set rep-
While the Full stopping runs achieved higher F  X  X  and ac-curacy on the training set, they were less stable across the folds. In our analysis we found that we had a lower propor-Figure 1: Scatter Plot between Sentiment and sys-tem scores. Presented for Light-4-avg run on all sets. Sen-tion of labeled data among the Wikipedia articles from Full stopping (25.8% compared to 42.6% for Light stopping); this resulted in a higher reliance on estimating unlabeled data. Among Light stopping runs alone, the Light-4-avg runs op-timized accuracy and F 0 . 5 in training, which is consistent with that run achieving the best test results. An additional run not presented, which optimized F 1 in training among the Light stopping runs (k=3, max aggregate function), was more stable with respect to F 1 than the Full Stopping runs.
The sentiment classifier has high recall but low precision; not every sentiment implies controversy. While the senti-ment classifier achieves P, F 0 . 5 and accuracy scores that are sometimes comparable to random, its extremely high recall nonetheless leads to F 1 scores that are above random. This consistently high recall suggests it may be valuable as a clas-sification feature; we found that sentiment scores were not correlated with controversy scores, suggesting that combin-ing the two may yield improvement, as shown in Fig. 1.
In addition to the results presented here, we ran our ap-proach on another set of webpages, using a small set of queries from the TREC Blog track [8] as additional seeds. The results for this set (not presented here) were lower for both our approach and all baselines; however, the set was too small to draw any significant conclusions from the results. Additionally, we also tried two unsupervised approaches: the first, based on the presence of dispute tags manually added to the article [7, 12], and the second using the  X  X  X  score as defined by Yasseri et al. [14]. However, in our experiments these unsupervised approaches were not successful, in some cases performing worse than random (results not presented here). We found that the scores in both these methods did not line up with our Wikipedia annotations; we have several hypotheses for these results that we hope to explore soon, but which are beyond the scope of this short paper.
We showed that a supervised nearest-neighbor approach can be used to detect whether a webpage discusses a con-troversial topic. We map the page to Wikipedia articles and use annotated data to estimate their controversy lev-els, then using those scores to produce a controversy score for the original webpage. Our results demonstrate that re-lated Wikipedia pages can be used to detect controversy, with our method achieving considerable improvements com-pared to both a sentiment-based classifier, and random and dominant class baselines.

The benefit of using Wikipedia articles as neighbors lies in both coverage, as well as the potential for unsupervised approaches to be substituted for the supervised estimates of Wikipedia article controversiality. We plan to look into un-supervised approaches for controversy detection such as dis-pute tags and the  X  X  X  metric [14], and analyze why our at-tempts failed; we will also investigate additional approaches such as a  X  X eta X  classifier [7] and collaboration networks [12].
Our current approach to find neighbors can also be im-proved by using a state-of-the-art research search engine, or using other methods of matching webpages to Wikipedia [13]. The sentiment classifier, with its excellent recall, may be useful as a feature. We would like to address topics that are not covered in detail in Wikipedia, but are nonetheless controversial. On a larger scope, we would also like to go beyond detecting controversy at the topic level, to detect stances and alignment of a specific page to that topic. We thank E. Aktolga, H. Sepehri Rad, T. Yasseri and E. Yom-Tov for fruitful discussions and resources. Thanks to CIIR lab members and the anonymous reviewers for their comments. This work was supported in part by the Cen-ter for Intelligent Information Retrieval and in part by NSF grant #IIS-1217281. Any opinions, findings and conclusions or recommendations expressed in this material are the au-thors X  and do not necessarily reflect those of the sponsor.
