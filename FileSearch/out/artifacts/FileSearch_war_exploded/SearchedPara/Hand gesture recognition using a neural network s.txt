 1. Introduction
Hand gesture recognition is a promising research field in computer vision. Its most appealing application is the develop-ment of more effective and friendly interfaces for human X  machine interaction, since gestures are a natural and powerful way of communication. Moreover, it can be used for teleconferen-cing because it does not require any special hardware. Last but not least, it can be applied to the interpretation and learning of sign languages.

Hand gesture recognition is a complex problem that has been dealt with in many different ways. Kjeldssen and Kender (1996) suggest an algorithm of skin color segmentation in the HSV color space and use a backpropagation neural network to recognize gestures from the segmented hand images. Huang and Huang (1998) propose a system consisting of three modules: (i) model-based hand tracking that uses the Hausdorff ( Huttenlocher et al., 1992 ) distance measure to track shape-variant hand motion, (ii) feature extraction by applying the scale and rotation invariant Fourier descriptors and (iii) recognition by using a 3D modified
Hopfield neural network. Hongo et al. (2000) use a skin color segmentation technique in order to segment the region of interest and then recognize the gestures by extracting directional features and using linear discriminant analysis. Manresa et al. (2000) propose a method of three main steps: (i) hand segmentation based on skin color information, (ii) tracking of the position and the orientation of the hand by using a pixel-based tracking for the temporal update of the hand state and (iii) estimation of the hand state in order to extract several hand features to define a deterministic process of gesture recognition. Huang and Jeng (2001) suggest a model-based recognition system that also consists of three stages: (i) feature extraction based on spatial (edge) and temporal (motion) information, (ii) training that uses the Principal Component Analysis, the Hidden Markov Model (HMM) and a modified Hausdorff distance and (iii) recognition by applying the Viterbi algorithm. Herpers et al. (2001) use a hand segmentation algorithm that detects connected skin X  X one blobs in the region of interest. A medial axis transform is applied, and finally, an analysis of the resulting image skeleton allows the gesture recognition. Yoon et al. (2001) propose a system consisting of three different modules: (i) hand localization, (ii) hand tracking and (iii) gesture spotting. The hand location module detects hand candidate regions on the basis of skin color and motion. The hand tracking algorithm finds the centroids of the moving hand regions, connects them, and produces a hand trajectory. The gesture spotting algorithm divides the trajectory into real and meaningless segments. This approach uses location, angle and velocity feature codes, and employs a k -means clustering algorithm for the HMM codebook. Triesch and Von der Malsburg (2001) propose a computer vision system that is based on Elastic Graph Matching, which is extended in order to allow combinations of different feature types at the graph nodes. Chen et al. (2003) introduce a hand gesture recognition system to recognize continuous gesture before stationary background. The system consists of four modules: a real-time hand tracking and extraction, feature extraction, HMM training, and gesture recogni-tion. First, they apply a real-time hand tracking and extraction algorithm to trace the moving hand and extract the hand region, and then they use the Fourier descriptors to characterize spatial features and the motion analysis to characterize the temporal features. They combine the spatial and temporal features of the input image sequence as the feature vector. After having extracted the feature vectors, they apply HMMs to recognize the input gesture. The gesture to be recognized is separately scored against different HMMs. The model with the highest score indicates the corresponding gesture. Xiaoming and Ming (2003) use an RCE neural network-based color segmentation algorithm for hand segmentation, extract edge points of fingers as points of interest and match them based on the topological features of the hand, such as the center of the palm. Tan and Davis (2004) track the face and hand regions using color-based segmentation and
Kalman filtering. Next, different classes of natural hand gesture are recognized from the hand trajectories by identifying gesture holds, position/velocity changes, and repetitive movements.
According to the method proposed by Doulamis et al. (2005), the gesture segmentation is performed based on skin color information, the segmented regions are represented using the
Zernike moments and finally an adaptive hierarchical content decomposition algorithm is applied. Wachs et al. (2005) identify static hand gesture poses by using Haar-like features to represent the shape of the hand. These features are used as input to a fuzzy c -means clustering algorithm for pose classification. A probabil-istic neighborhood search algorithm is employed to automatically select a small number of Haar features, and to tune the fuzzy c -means classification algorithm. Licsar and Sziranyi (2005) use a background subtraction method in order to accomplish hand segmentation and classify the static hand gestures based on the Fourier descriptors. The recognition method consists of a supervised and an unsupervised training procedure. Finally, a new technique for shape-based hand recognition is proposed by Yoruk et al. (2006) .

In the proposed method, hand gesture recognition is divided into four main stages: the detection of the hand X  X  region, the approximation of its shape, the extraction of its features, and finally its identification. The detection of the hand X  X  region is achieved by using a color segmentation technique based on a skin color distribution map in the YCbCr space ( Chai and Ngan, 1998, 1999 ). The technique is reliable, since it is relatively immune to changing lighting conditions and provides good coverage of the human skin color. It is very fast and does not require post-processing of the hand image. Once the hand is detected, a new
Self-Growing and Self-Organized Neural Gas (SGONG) ( Atsalakis and Papamarkos, 2005a, b, 2006 ; Atsalakis et al., 2005 ) neural network is used in order to approximate its shape. The SGONG is an innovative neural network that grows according to the hand X  X  morphology in a very robust way. As it is shown in Fig. 1 (a), the
SGONG starts with only two neurons and grows up until its output neurons takes the shape of the hand. Also, an effective algorithm is developed in order to locate the gesture X  X  raised fingers, which is a necessary step for the recognition process. In the final stage, suitable features are extracted that identify, regardless to the hand X  X  slope, the raised fingers. Finally, the completion of the gesture X  X  recognition process is achieved by using a likelihood-based classification method.

The proposed gesture recognition system has been trained to identify 31 hand gestures that derive from the combination of raised and not raised fingers. This set of gestures can be used for human X  X omputer communication without the interference of any special hardware. It has been tested by using a large number of input images and the achieved recognition rate is very promising.
A short version of the proposed technique is accepted for presentation in ICIP2006 ( Stergiopoulou and Papamarkos, 2006 ). 2. Description of the method
The purpose of the proposed gesture recognition method is to recognize a set of 31 hand gestures. The principal assumption is that the input images include exactly one hand. Furthermore, the gestures are made with the right hand, the arm is roughly vertical, the palm is facing the camera and the fingers are either raised or not. Finally, the image background is plain and uniform. The entire method consists of the following four main stages: Stage 1: Hand region detection.
 Stage 2: Approximation of the hand X  X  morphology.
 Stage 3: Finger identification.
 Stage 4: Recognition process.

Analysis of these stages follows. 2.1. Hand region detection
The first step of a hand recognition process is the detection of the hand region. In the proposed method, this is achieved through color segmentation, i.e. classification of the pixels of the input image into skin color and non-skin color clusters. The technique is based on color information, because color is a highly robust to morphologic variations of the hand. Secondly and importantly it allows a simple and fast processing of the input image. On the other hand, skin color varies quite dramatically. It is vulnerable to changing lighting conditions and it differs among people and especially among people from different ethnic groups. The perceived variance, however, is really a variance in luminance due to the fairness or the darkness of the skin. Moreover, researchers claim that skin chromaticity is roughly invariant among different races ( O X  X ara, 2002 ; Albiol et al., 2001 ). So regarding skin color, luminance introduces many problems, whereas chromaticity includes useful information. Therefore, skin color detection is possible and successful by using proper color spaces that separate luminance from chromaticity components. 2.1.1. YCbCr color space The proposed hand region detection technique is applied in the
YCbCr color space. YCbCr was created as part of ITU-R BT.601 during the development of a world-wide digital component video standard. It is a television transmission color space and some-times is known as a transmission primary. It is device dependent and also quite unintuitive. YCbCr is useful in compression applications and most importantly it separates RGB into lumi-nance and chrominance information. In particular, Y is the luminance component and Cb , Cr are the chrominance compo-nents. RGB values can be transformed to YCbCr color space using the following equation: Y Cb
Cr 2 6 4
Given that the input RGB values are within range [0,1] the output values of the transformation will be in the ranges [16,235] for Y and [16,240] for Cb and Cr . Fig. 2 shows the histograms of the Y , Cb and Cr components of three different skin color hands: (a) a white hand poorly illuminated, (b) a white hand well illuminated and (c) a black hand well illuminated. As it was marked previously, the Y component varies greatly whereas the Cb and Cr components are approximately the same for the three input images. Consequently, the YCbCr color space is indeed a proper space for skin color detection. 2.1.2. Skin color detection technique
The classification of the pixels of the input image into skin color and non-skin color clusters is accomplished by using a thresholding technique that exploits the information of a skin color distribution map in the YCbCr color space.

In this method, which is a modification of the Chai and Ngan method ( Chai and Ngan, 1998, 1999 ),amapofthechrominance components of skin color was created by using a training set of 50 images. It was found that Cb and Cr values are narrowly and consistently distributed. Particularly, the ranges of Cb and Cr values are, as shown in Fig. 3 , R Cb  X  [80,105] and R Cr  X  [130,165], respectively. These ranges were selected very strictly, in order to minimize the noise effect and maximize the possibility that the colors correspond to skin.

The steps of the skin color detection technique are the of the ( i , j ) pixel.
 Step 1: Comparison of the Cb ( i,j ) and Cr ( i,j ) values with the R and R to the hand region.

Step 2: Calculation of the Euclidean distances between the Cb
Cr values and the limits of the R Cb and R Cr ranges, for every pixel:
D
D
D
D
Step 1: Comparison of the Euclidean distances with a proper threshold. If at least one distance is less than the threshold value, then the pixel belongs to the hand region. The proper threshold value is taken equal to 18.

In conclusion, the color segmentation rules are summarized by the following conditions:
D [ D 2 [ D 3 [ D 4 p Threshold ) X  i ; j  X 2 hand 8 &gt; &lt; &gt; :
The output image of the color segmentation process is considered as binary. As illustrated in Fig. 4 the hand region, that is the region of interest, turns black and the background white. The hand region is normalized to certain dimensions so that the system becomes invariant to the hand X  X  size. It is worth to underline also that the segmentation results are very good (almost noiseless) without further processing (e.g. filtering) of the image. In particular, the technique was tested by a set of 180 input images and the rate of successful segmentation was 99.46%. 2.2. Approximation of the hand X  X  morphology
The aim of this stage of the hand recognition process is the approximation of the hand X  X  morphology. This is accomplished by applying the SGONG neural network ( Atsalakis and Papamarkos, 2005a, b, 2006 ; Atsalakis et al., 2005 ) on the segmented (binary) image. 2.2.1. Self-growing and organized neural gas
The SGONG is an unsupervised neural classifier. It achieves clustering of the input data, so as the distance of the data within the same class (intra-cluster variance) is small and the distance of the data stemming from different classes (inter-cluster variance) is large.
It is an innovative neural network that combines the advantages both of the Kohonen Self-Organized Feature Map (SOFM) ( Kohonen, 1990, 1997 ) and the Growing Neural Gas (GNG) ( Fritzke, 1994, 1995 ) neural classifiers according to which, the learning rate and the radius of the neighborhood domain of neurons is monotonically decreased during the training procedure. Furthermore, at the end of each epoch of the SGONG classifier, three crite ria that improve the growing and the convergence of the network are applied. This is a main advantage of the SGONG classifier as it can adaptively determine the final number of neurons. This characteristic permits SGONG to capture efficiently the feature space (See Experiment 1) and consequently the shape of the hand.

The SGONG consists of two layers, i.e. the input and the output layer. It has the following main characteristics: Is faster than the Kohonen SOFM as the growing mechanism of GNG is used.

In contrast with GNG classifier, a local counter that influences the learning rate of this neuron and the strength of its connections is defined for each neuron. This local counter depends only on the number of the training vectors that are classified in this neuron.

The dimensions of the input space and the output lattice of neurons are always identical. Thus, the structure of neurons in the output layer approaches the structure of the input data.
Criteria are used to ensure fast convergence of the neural network. Also, these criteria permit the detection of isolated classes.
 The coordinates of the output neurons are the coordinates of the classes X  centers. Each neuron is described by two local parameters related to the training ratio and to the influence by the neighborhood neurons. Both of them decrease from a high to a lower value during a predefined local time in order to gradually minimize the neurons X  ability to adapt to the input data. The network begins with only two neurons and it inserts new neurons in order to achieve better data clustering. Its growth is based on the following criteria:
A neuron is inserted near the one with the greatest contribu-tion to the total classification error, only if the average length 0 1000 2000 3000 4000 5000 6000 0 of its connections with the neighbor neurons is relatively large.

The connections of the neurons are created dynamically by using the  X  X  X ompetitive Hebbian Learning X  X  method.

The main characteristic of the SGONG is that both neurons and their connections approximate effectively the topology of input data. This is the exact reason for using the specific neural network in this application. 2.2.1.1. The training steps of the SGONG network. The training pro-cedure for the SGONG neural classifier starts by considering first two output neurons ( c  X  2). The local counter N i that expresses the number of vectors that have been classified to the Neuron ( i  X  1,2), of the created neurons are set to zero. The initial posi-tions of the created output neurons, i.e., the initial values for the weight vectors W i , i  X  1,2 are initialized by randomly selecting two different vectors from the input space. All the vectors of the training data set X 0 are circularly used for the training of the SGONG network. The training steps of the SGONG are the following: Step 1: At the beginning of each epoch the accumulated errors
AE set to zero. The variable AE i (1) expresses, at the end of each epoch, the quantity of the total quantization error that corresponds to
Neuron i , while the variable AE i (2) represents the increment of the total quantization error that we would have if the Neuron removed.

Step 2: For a given input vector X k , the first and the second winner neurons Neuron w 1 , Neuron w 2 are obtained: for Neuron w 1 jj X k W w 1 jj p jj X k W i jj8 i 2 X  1 ; c (4) for Neuron w 2 X k W w 2 jj p jj X k W i jj8 i 2 X  1 ; c and i
Step 3: The local variables AE i (1) and AE i (2) change their values according to the relations: AE AE N where N w 1 is the number of vectors classified to the neuron Neuron w 1 .

Step 4: If N w 1 p N idle (The variable N idle determines the required number of consecutive vectors that should be classified to a class in order to define a well-trained neuron.) then the local learning Otherwise, the local learning rates have the constant values e 1 2 1 r
The learning rate e 1 i is applied to the weights of Neuron the winner neuron ( w 1  X  i ), while e 2 i is applied to the weights of Neuron i if this belongs to the neighborhood domain of the winner soft competitive effects between the output neurons. That is, for each output neuron, it is necessary that the influence from its neighboring neurons to be gradually reduced from a maximum to a minimum value. The values of the learning rates e 1 i and e 2 not constant but they are reduced according to the local counter N . Doing this, the potential ability of moving neuron i towards an input vector (plasticity) is reduced by time. Both learning rates change their values from maximum to minimum in a period, which is defined by the N idle parameter. The variable r wi takes its minimum value r min  X  1 and in a period, defined also by the N idle parameter, reaches its maximum value r max .

Step 5: In accordance to the Kohonen SOFM, the weight vector of the winner neuron Neuron w 1 and the weight vectors of its neighboring neurons Neuron m , m A nei ( w 1), are adapted according to the following relations:  X  W 0 m  X  2 m  X  X 0 k W 0 m  X  ; 8 m 2 nei  X  w 1  X  (13)
Step 6: With regard to generation of lateral connections, SGONG employs the following strategy. The Competitive Hebbian Rule is applied in order to create or remove connections between neurons.
As soon as the neurons Neuron w 1 and Neuron w 2 are detected, the connection between them is created or is refreshed. That is s
With the purpose of removing superfluous lateral connections, the age of all connections emanating from Neuron w 1 ,exceptthe connection with Neuron w 2 ,isincreasedbyone: s  X  s w 1 ; m  X  1 ; 8 m 2 nei  X  w 1  X  with m a w 2(15) where s  X  s j ; i X 1 ; 8 i ; j 2 X  1 ; c with i a j (16)
If the connection between Neuron i and Neuron j exists then s otherwise s i , j  X  1. The expressions s i , j and s j , i equal. If the connection s i,j exists, the positive value of quantity s expresses the age of the lateral synapse.

Step 7: At the end of each epoch it is examined if all neurons are in idle state , or equivalently, if all the local counters N greater than the predefined value N idle and the neurons are considered well trained. In this case, the training procedure stops and the convergence of SGONG network is assumed. The number of input vectors needed for a neuron to reach the idle state influences the convergence speed. If the training procedure continues, the lateral connections between neurons with age greater than the maximum value a are removed. Due to dynamic generation or removal of lateral connections, the neighborhood domain of each neuron changes in time in order to include neurons that are topologically adjacent.
Step 8: Also, three criteria that modify the number of the output neurons c and make the proposed neural network to become self-growing are applied. These criteria are applied in the following order:
A class (neuron) is removed if for a predefined consecutive number of epochs, none of the training samples has been classified in this class.

A new class (neuron) is added near the class with the maximum contribution to the total quantization error (with the maximum AE (1) ), if the average distance of its vectors from neighboring classes is greater than a predefined value. This value is expressed as a percentage of the average distance between all classes.

The class (neuron) with the minimum average distance of its vectors from neighboring classes is removed if this quantity is less than a predefined value. This value is expressed as a percentage of the average distance between all classes.
In order to make the network convergence faster it can be defined not to apply the above criteria when the total number of epochs is above a predefined value. This has as a result the rapid passing of all neurons to the idle state and therefore the finalizing of the training procedure. After the training procedure, the denormalized vectors W i , i  X  1, 2, y , c express the centers of the final classes, i.e. the coordinates of the output neurons.
 A detailed description of SGONG can be found in Atsalakis and
Papamarkos (2005a, b, 2006) and Atsalakis et al. (2005) while its implementation can be found in http://www.papamarkos. gr/uploaded-files/Papaparkos/demos/sgong_demo.htm . 2.2.2. Application of the self-growing and self-organized neural gas network
In the proposed method the input data of the SGONG are the coordinates of random samples of the black/hand pixels.
Let X k  X  ( i , j ) be the k th input vector, where ( i , j ) are the coordinates of a randomly selected black pixel and k A [1, N
The number N iv of the input vectors that are used for the training process is chosen to be approximately 5% of the black pixels, in order to achieve satisfactory approximation of the hand shape and fast time convergence. If N iv 5 5% the SGONG describes less adequately the hand and if N iv b 5%, it converges slowly to a grid of output neurons similar to the one created by using
N C 5%.

During the training, the network grows gradually on the hand region and a structure of neurons and their connections is finally created. The output neurons X  coordinates are calculated by using
Eqs. (12) and (13) and the criteria described in Step 8 of the training process. These coordinates correspond to pixels of the black segment. Let W p  X  ( i , j ) be the p th weight vector, i.e. ( i , j ) the coordinates of the p th output neuron, and let s be the 2D array that describes the connections between the output neurons.
Specifically, if s pq  X  1 then the output neuron p is not connected with the output neuron q .If s pq 4 0, then there is a connection between the output neurons p and q .

At the end of the training process, the SGONG defines approximately 80 classes on the hand region. It is obvious however, as shown in Fig. 5 , that the shape of the hand could be described by using fewer output neurons.

A smaller set of output neurons is desirable, because it results in faster processing and thus faster finger features extraction.
Therefore, a sufficient number of final classes is used as a threshold parameter of the SGONG X  X  training process. The final number of the output neurons should satisfy the following criteria: Each finger should be described by a small number of neurons.
The grid of neurons should approximate successfully the hand contour.

The grid of neurons should approximate successfully the palm region.

After testing, we have found that the proper number of neurons that satisfies these rules is 33. The satisfactory approximation of the morphology of the hand using 33 output neurons is shown in Fig. 6 .

Finally, it is worth to underline that the output data of the network is the array of the neurons X  coordinates W p and the 2D array of the neurons X  connections s pq . Based on this information, important finger features are extracted.
 2.3. Finger identification
The recognition of static hand gestures can be implemented by finger identification. Therefore the proposed method extracts robust features that describe successfully the properties of the fingers. The features are invariant to the hand X  X  morphology as well as to its slope and size. Moreover, the features X  values are discrete for every type of finger and exploit efficiently the morphologic information of the grid of the output neurons. The finger identification process consists of the following stages: Stage 1: Determination of the number of the raised fingers. Stage 2: Extraction of hand shape characteristics.
 Stage 3: Extraction of finger features.

An analysis of the above stages follows. 2.3.1. Determination of the number of the raised fingers
The aim of this stage is to determine the number of the raised fingers as well as the coordinates of the neurons that represent them. The most important finger neurons are: (a) the neurons that correspond to the fingertips (fingertip neurons) and (b) the neurons that describe the fingers X  lower limit (root neurons).
The determination of the raised fingers is accomplished by locating the fingertip neurons, which are also used as a starting point for the detection of the rest of the finger neurons.
Observations of the structure of the output neurons X  grid lead to the conclusion that fingertip neurons are connected to neighborhood neurons by only two types of connections: (i) connections that go through the background and (ii) connections that belong exclusively to the hand region. The crucial point is that fingertip neurons use only one connection of the second type. Based on this conclusion, the process of the determination of the number of fingers is as follows:
Step 1: Remove all the connections that go through the background ( Fig. 7 (b)).

Step 2: Find the neurons that have only one connection. As indicated in Fig. 7 (c), these neurons are the fingertips.
Step 3: Starting from the fingertip neurons find successively the neighbor neurons. Stop when a neuron with more than two connections is found. This is the finger X  X  last neuron (root neuron) (Fig. 7 (d) and (e)).
 In special cases, the above algorithm leads to false conclusions. For example, as shown in Fig. 8 (a), the algorithm detects five fingertips, although the gesture consists of only four fingers. This type of error can be avoided by comparing every finger X  X  length (i.e. the fingertip and root neuron distance) with the mean fingers X  length. If a finger X  X  length differs significantly from the mean value then it is not considered to be a finger. The results of this check are shown in Fig. 8 (b). 2.3.2. Extraction of hand shape characteristics
The morphology of the hand affects and changes the values of the fingers X  features. Therefore, it is necessary to specify the fundamental characteristics of the hand X  X  shape before proceeding to the feature extraction.
 2.3.2.1. Palm region. Many input images include redundant in-formation, such as the presence of a part of the arm. This re-dundant information could reduce the accuracy of the extraction techniques and lead to false conclusions. Therefore, it is important to locate the hand region that describes most effectively and ac-curately the morphology properties, i.e. the palm.

The algorithm of finding the palm region is based on the observation that the arm is thinner than the palm. Thus, a local minimum should appear at the horizontal projection of the binary image. This minimum defines the limits of the palm region. This procedure is as follows: Step 1: Create the horizontal projection of the binary image
H [ j ], j A [1, Image Height]. Apply a mean filter on the horizontal projection, in order to reduce the local variance for every j .
Step 2: Find the global maximum H [ j GlobalMax ] and each one of the local minima H [ j min ]of H [ j ](Fig. 9 (b)).

Step 3: Calculate the slope of the line segments connecting the global maximum and each one of the local minima that satisfies
The minimum H [ j min ] that corresponds to the greatest of these slopes is denoted as j lower and defines the lower limit of the palm region only if its distance from the maximum is greater than a threshold value equal to ImageHeight/6 ( Fig. 9 (c)).

Step 4: The point that defines the upper limit of the palm region is denoted as j upper and is obtained by the following relation (Fig. 9 (d)):
H  X  j
Step 5: The palm region is defined by the lines j lower and j order to achieve greater accuracy, the finger neurons are not included in the set of palm region neurons ( Fig. 9 (e) and (f)). 2.3.2.2. Palm center. The coordinates of the center of the palm are taken equal to the gravity center of the coordinates of the neurons
N palm neurons. Then the coordinates of the palm center are defined by according to the following equation: x
Fig. 10 shows three examples of the determination of the palm center. 2.3.2.3. Hand slope. Despite the roughly vertical direction of the arm, the slope of the hand varies. This fact should be taken into consideration because it affects the accuracy of the finger features extraction, and consequently, the efficiency of the identification process. The recognition results depend greatly on the correct calculation of the hand slope. In order to achieve more accurate results, the estimation of the hand slope is based on the combi-nation of two different techniques.

According to the first technique, the hand slope is equal to the angle of the line segment connecting the palm center and the middle of the wrist with the horizontal axis. The steps of this algorithm are the following:
Step 1: Define the middle of the wrist ( x wrist , y wrist line that corresponds to the j lower of the palm region, one can locate the leftmost point of the wrist as the first black pixel that belongs to the j lower line and the rightmost point of the wrist as the last black pixel ( Fig. 11 (a)).

Step 2: The slope ( Fig. 11 (b)) of the line segment that connects the middle of the wrist and the palm center is given by HandSlope 1  X  tan 1
According to the second technique, the hand slope is estimated by the angle of the left side of the palm. The technique consists of the following steps:
Step 1: Find the neuron N Left , which belongs to the palm region and has the smallest horizontal coordinate.

Step 2: Obtain the set of palm neurons N AboveSet that belong to the upper left boundary of the neurons grid. To do this, and for each neuron, starting from the N Left , we obtain the neighborhood neuron which has, simultaneously, the highest vertical and the lowest horizontal coordinates ( Fig. 12 (a)).

Step 3: Obtain the set of palm neurons N BelowSet that belong to the lower left boundary of the neurons grid. To do this, and for each neuron, starting from the N Left , we obtain the neighborhood neuron which has, simultaneously, the lowest vertical and horizontal coordinates ( Fig. 12 (b)).
 finger neurons and the neurons that do not belong to the palm region.

Step 5: Calculate the difference of slopes of the line segments that connect two successive neurons. Remove from the N Set neurons whose slope differs from the previous slope more than a predefined threshold.

Step 6: The first and the final neurons of the set N Set define the hand X  X  slope ( Fig. 12 (c) and (d)).

The final estimation of the hand slope is based on both techniques and is calculated by the equation: HandSlope  X  0 : 6 HandSlope 1  X  0 : 4 HandSlope 2 (21)
As shown in Fig. 13 , the hand slope is successfully approximated. Let Hand Slope Line (HSL) be the line that passes through the palm center and forms an angle with the horizontal axis equal to the hand slope. The hand slope is considered as a reference angle and is used in order to improve the finger features X  extraction techniques.
 2.3.3. Extraction of finger features
The extracted features describe morphologic and geometric properties of the fingers. The method proposes the extraction of three features. 2.3.3.1. Finger angles. A geometric feature that individualizes the fingers is their, relative to the hand slope, angles. The two different types of angles are the following:
RC Angle : It is an angle formed by the HSL and the line that joints the root neuron and the hand center ( Fig. 14 (a)). This angle provides the most discrete values for each finger and thus is valuable for the recognition:
R ^ C  X  HandSlope tan 1
TC Angle : It is an angle formed by the HSL and the line that joints the fingertip neuron and the hand center ( Fig.14 (b)). It is used directly for the finger identification process: 2.3.3.2. Distance from the palm center. A powerful feature for the identification process is the vertical distance of the finger X  X  root neuron from the line passing through the palm center and having the same slope as the HSL. An example is illustrated in Fig. 14 (c).
The feature is invariant to the size of the hand, because its value is divided by the length of the palm. The length of the palm is de-fined as the distance between the leftmost and the rightmost neuron of the palm region. 2.4. Recognition process
The final stage of the proposed method is, of course, the recognition of the hand gesture. The recognition process is based on the choice of the most probable finger combination of a set of feasible gestures. This is accomplished by classifying the raised fingers into five classes (thumb, index, middle, ring, little) according to their features. The classification depends on the probabilities of a finger to belong to the above classes. The probabilities derive from the features X  distributions. Therefore, the recognition process consists of three stages: Stage 1: The off-line calculation of the features X  distributions. Stage 2: The likelihood-based classification.

Stage 3: Final classification. 2.4.1. Calculation of features X  distributions The finger features are naturally occurring features. Hence a Gaussian distribution could model them successfully. Their distributions are calculated by using a training set of 100 images from different people. The following process is carried out off-line and is regarded as the training process of the proposed hand recognition system.

If f i is the i th feature ( i A [1,3]), then its Gaussian distributions p fi x  X  X  X  where j  X  1, y ,5, m cj fi is the mean value and s cj fi is the standard of the above features are shown in Fig. 15 . As it can be observed, the five classes are well defined and well discriminated. 2.4.2. Likelihood-based classification
The first step of the classification process is the calculation of the likelihood RPc j of a raised finger to belong to each one of the five classes. Let x 0 be the value of the i th feature f i lihood is the sum of the likelihoods of all the features for each class and is calculated according to the following equation: RPcj  X 
For example, let Fig. 16 (a) be the input image. As analyzed previously, the image is processed (segmentation and application of the SGONG), the finger features are extracted and finally the possibilities of every raised finger to belong to each one of the five classes are calculated. The raised fingers are numbered as shown in Fig. 16 (b). Table 1 indicates the features X  values of every raised finger of Fig. 16 (b), as well as the likelihood RPc j .
For example, finger No. 2 belongs to the following classes in order of higher possibility: Ring, Middle. It is worth to underline classification, the sum of the likelihoods RPc j will eliminate the error and lead to correct classification. For instance, finger No. 4 is classified falsely as Thumb according to the Distance value. The sum RPc j , however, classifies it correctly as Index.
The above process has the disadvantage that two fingers may be classified to the same class. Therefore, it is used only as a starting point of the final recognition process. 2.4.3. Final classification
The hand gesture recognition is accomplished by choosing the most probable finger combination. Firstly, the algorithm defines all the feasible gestures by calculating the combination of the five classes to the number of raised fingers: 5
N  X  where N is the number of raised fingers. For example, Table 2 presents the feasible gestures when N  X  4. The empty classes (fingers that are not raised) are denoted by  X  X   X  X , whereas the non-empty classes by  X  X  x  X  X .

Considering the order of classes as it appears at Table 2 , the non-empty classes are numbered from left to right. Then, for every one of the feasible gestures the sum of the likelihood of the i th finger to belong to the i th non-empty class is calculated. For example, the possibility of the first gesture of Table 2 is calculated by summing the likelihood of finger No. 1 to be Little, finger No. 2 to be Ring, finger No. 3 to be Middle and finger No. 4 to be Index.
As shown in Table 2 , this gesture is the most probable and thus it is considered to correspond to the input image of Fig. 16 (a). 3. Experimental results
The hand gesture recognition system, which was implemented in Delphi, was tested by using hand images from different people with varying morphology, slope and size. The conclusions drawn concern the robustness of the features as well as the recognition rate of the system. 3.1. Experiment 1 The innovation of the proposed method is the use of the
SGONG neural network in order to approximate the hand X  X  morphology. SGONG combines the advantages of both the
Kohonen SOFM and the GNG neural network. Its main advantage is that it can adaptively determine the final number of neurons and thus it can capture the feature space effectively. The following experiment will show that the SGONG network converges faster compared to the Kohonen SOFM and GNG networks, and that achieves effective description of the structure of the input data.
Consider the image of Fig. 17 (a) as the input space (i.e. the coordinates of the black pixels are the input vectors of the network). Application of the SGONG on the image leads to the determination of 163 output neurons. The SGONG converges after 286 epochs and, as Fig.17 (b) shows, describes the input space very well. As for as the Kohonen SOFM is concerned, the grid of output neurons is determined to be 13 13. It converges ( Fig. 17 (c)) slower than the SGONG after 372 epochs. The GNG neural network uses as an input parameter the final number of 163 output neurons and it converges ( Fig. 17 (d)) after 299 epochs. It is worth to underline that the GNG and mainly the SGONG neural network describe efficiently the isolated classes contrary to the Kohonen SOFM, which preserves its initial neighbor neuron connections.
Fig.18 (a) X (f) show stages of the growing procedure of the three neural classifiers.
 3.2. Experiment 2
The goal of this experiment is to study the extracted features X  effectiveness, because it plays a significant role in the outcome of the recognition process. The effectiveness of a feature is associated with the value of the finger recognition rate achieved. The higher the recognition rate, the more effective the feature. Using the set of 503 fingers of the 180 input gestures the recognition rates for every feature are shown in Table 3 .

The above finger recognition rates are justified by taking into consideration the features X  distributions shown in Fig. 15 . The lowest recognition rate is the one of TC angles, because as shown in Fig. 15 (b) it has the less discriminated distribution. As far as the feature distance from the center of the palm is concerned, the class of Index is not well separated from the class of the Thumb. Hence an Index is often classified falsely as a Thumb or vice versa.
It is worth, also, to mention that the RC angle has the highest finger recognition rate, because there is no significant overlapping of the probability distributions of the classes. 3.3. Experiment 3
Experiment 3 aims to determinate the proposed system X  X  recognition rate. Therefore, the system is tested with 180 test hand images 1800 times. The recognition rate, under the conditions described in the beginning of Section 2, is 90.45%.
This satisfactory recognition rate is due to the robustness of each one of the stages of the proposed method. The mistakes of the recognition process are due to false feature extraction and mainly due to false estimation of the hand slope.

Figs.19 X 23 present a number of examples of the output images of the proposed gesture recognition system. It is obvious that the recognition is successful regardless of the slope of the hand. The average computation time required for recognition of a hand gesture is about 1.5s, using a 3GHz CPU. 4. Conclusions
This paper proposes a new technique for hand gesture recognition which is based on hand gesture features and on a neural network shape fitting procedure. Firstly, the hand region is isolated by using a skin color filtering procedure in the YCbCr color space. This is a very fast procedure that results in noiseless segmented images regardless to the variation of the skin color and the lighting conditions. The stage that concerns the fitting of the hand X  X  shape as well as the stage of finger features extraction is based on the innovative and powerful Self-Growing and Self-Organized Neural Gas network which approximate the hand X  X  morphology in a very satisfactory way. As a result, the extracted finger features are well discriminated, they are invariant to the hand X  X  size and slope and thus they conduce to a successful recognition. Finally, the hand gesture recognition, which is based on the Gaussian distribution of the finger features, takes into consideration the possibility of a finger belonging to each one of the five feasible classes as well as the likelihood of all the feasible finger combinations to correspond to input hand gesture. It is found from the experiments that the recognition rate is very promising and approaches 90.45%.

As a result, it is worth to underline that the key characteristic of the proposed hand gesture recognition technique is the use of the SGONG neural network. The reason is twofold; SGONG is able to describe very effectively the shape of the hand, and thus allows the extraction of robust and effective features, and moreover it achieves it by converging faster than other networks.
 References
