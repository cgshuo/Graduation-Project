 University ofCalifornia, Berkeley University ofCalifornia, Berkeley University ofCalifornia, Berkeley but this type of annotation is expensive.
 and numerical optimization. On two standard semantic parsing benchmarks, we show that our logical forms.
 1. Introduction
One of the major challenges in natural language processing (NLP) is building systems thatbothhandlecomplexlinguisticphenomenaandrequireminimalhumaneffort.The whereannotatinglinguisticexpressionswiththeirassociatedlogicalformsisexpensive butuntilrecently,seeminglyunavoidable.Advancesinlearninglatent-variablemodels, however, have made it possible to progressively reduce the amount of supervision required for various semantics-related tasks (Zettlemoyer and Collins 2005; Branavan etal.2009;Liang,Jordan,andKlein2009;Clarkeetal.2010;ArtziandZettlemoyer2011;
Goldwasser et al. 2011). In this article, we develop new techniques to learn accurate semantic parsers from even weaker supervision.
 questionsgivenastructureddatabaseoffacts;seeFigure1foranexampleinthedomain of U.S. geography. This problem of building natural language interfaces to databases (NLIDBs)hasalonghistoryinNLP,startingfromtheearlydaysofartificialintelligence with systems such as L UNAR (Woods, Kaplan, and Webber 1972), C HAT -80 (Warren andPereira1982),andmanyothers(seeAndroutsopoulos,Ritchie,andThanisch[1995] foranoverview).WebelieveNLIDBsprovideanappropriatestartingpointforsemantic parsingbecausetheyleaddirectlytopracticalsystems,andtheyallowustotemporarily sidestep intractable philosophical questions on ho wto represent meaning in general.
Early NLIDBs were quite successful in their respective limited domains, but because thesesystemswereconstructedfrommanuallybuiltrules,theybecamedifficulttoscale up, both to other domains and to more complex utterances. In response, against the backdrop ofastatisticalrevolutioninNLPduringthe1990s,researchersbegantobuild systemsthatcouldlearnfromexamples,withthehopeofovercomingthelimitationsof rule-based methods. One of the earliest statistical efforts was the C HILL system (Zelle and Mooney 1996), which learned a shift-reduce semantic parser. Since then, there has been a healthy line of work yielding increasingly more accurate semantic parsers by usingnewsemanticrepresentationsandmachinelearningtechniques(Milleretal.1996; ZelleandMooney1996;TangandMooney2001;GeandMooney2005;Kate,Wong,and
Mooney2005;ZettlemoyerandCollins2005;KateandMooney2006;WongandMooney 2006; Kate and Mooney 2007; Wong and Mooney 2007; Zettlemoyer and Collins 2007; Kwiatkowski et al. 2010, 2011).
 ity, however, their application in semantic parsing achieved only limited success. One of the main obstacles was that these methods depended crucially on having examples of utterances paired with logical forms, and this requires substantial human effort to obtain.Furthermore,theannotatorsmustbeproficientinsomeformallanguage,which drastically reduces the size of the annotator pool, dampening any hope of acquiring enough data tofulfill the vision of learning highly accurate systems.
 sibility of learning a semantic parser without any annotated logical forms (Clarke et al. 390 2010;ArtziandZettlemoyer2011;Goldwasseretal.2011;Liang,Jordan,andKlein2011). example pairs, where x is an utterance (e.g., a question) and y is the corresponding answer,wewishtolearnamappingfrom x to y .Whatmakesthismappingparticularly interestingisthatitpassesthroughalatentlogicalform z ,whichisnecessarytocapture the semantic complexities of natural language. Also note that whereas the logical form z was the end goal in much of earlier work on semantic parsing, for us it is just an intermediate variable X  X  means towards an end. Figure 2 shows the graphical model which captures the learning setting we just described: The question x , answer y ,and world/database w are all observed. We want to infer the logical forms z and the parameters  X  of the semantic parser, which are unknown quantities.
 increase the difficulty of the learning problem. The core challenge here is program induction : On each example ( x , y ), we need to efficiently search over the exponential space of possible logical forms (programs) z and find ones that produce the target answer y , a computationally daunting task. There is also a statistical challenge: How do we parametrize the mapping from utterance x to logical form z so that it can be learned from only the indirect signal y ? To address these two challenges, we must first shouldtheformallanguageforthelogicalforms z be,and(ii)whatarethecompositional mechanisms for constructing those logical forms? for representing logical forms, including SQL (Giordani and Moschitti 2009), Prolog (Zelle and Mooney 1996; Tang and Mooney 2001), a simple functional query language called FunQL (Kate, Wong, and Mooney 2005), and lambda calculus (Zettlemoyer and
Collins 2005), just to name a few. The construction mechanisms are equally diverse, in-cludingsynchronousgrammars(WongandMooney2007),hybridtrees(Luetal.2008),
Combinatory Categorial Grammars (CCG) (Zettlemoyer and Collins 2005), and shift-reduce derivations (Zelle and Mooney 1996). It is worth pointing out that the choice of formal language and the construction mechanism are decisions which are really more orthogonalthanisoftenassumed X  X heformerisconcernedwithwhatthelogicalforms looklike;thelatter,withhowtogenerateasetofpossiblelogicalformscompositionally given an utterance. (Ho wtoscore these logical forms isyet another dimension.) the construction mechanism; one or the other is often chosen for convenience from existing implementations. For example, Prolog and SQL have often been chosen as formal languages for convenience in end applications, but they were not designed for representing the semantics of natural language, and, as a result, the construction mechanism that bridges the gap between natural language and formal language is generally complex and difficult to learn. CCG (Steedman 2000) is quite popular in computationallinguistics(forexample,seeBosetal.[2004]andZettlemoyerandCollins [2005]). In CCG, logical forms are constructed compositionally using a small handful of combinators (function application, function composition, and type raising). For a wide range of canonical examples, CCG produces elegant, streamlined analyses, but its success really depends on having a good, clean lexicon. During learning, there is often a great amount of uncertainty over the lexical entries, which makes CCG more cumbersome. Furthermore, in real-world applications, we would like to handle disflu-ent utterances, and this further strains CCG by demanding either extra type-raising rulesanddisharmoniccombinators(ZettlemoyerandCollins2007)oraproliferationof redundant lexical entries for each word (Kwiatkowski et al. 2010).
 traditioninfavorofanewformallanguageandconstructionmechanism,whichwecall dependency-basedcompositionalsemantics (DCS).TheguidingprinciplebehindDCS istoprovideasimpleandintuitiveframeworkforconstructingandrepresentinglogical forms.LogicalformsinDCSaretreestructurescalled DCStrees .Themotivationistwo-fold: (i) DCS trees are meant to parallel syntactic dependency trees, which facilitates parsing;and(ii)aDCStreeessentiallyencodesaconstraintsatisfactionproblem,which canbesolvedefficientlyusingdynamicprogrammingtoobtainthedenotationofaDCS tree. In addition, DCS provides a mark X  X xecute construct, which provides a uniform way of dealing with scope variation, a major source of trouble in any semantic for-malism.Theconstruction mechanisminDCSisageneralizationoflabeleddependency parsing,whichleadstosimpleandnaturalalgorithms.Toalinguist,DCSmightappear unorthodox, but it is important to keep in mind that our primary goal is effective programinduction,notnecessarilytomodelnewlinguisticphenomenainthetradition of formal semantics.
 probabilistic model, which is depicted in Figure 2. The semantic parser is a log-linear distributionoverDCStrees z givenanutterance x .Notably, z isunobserved,andwein-steadobserveonlytheanswer y ,whichisobtainedbyevaluating z onaworld/database 392 w . There are an exponential number of possible trees z , and usually dynamic program-ming can be used to efficiently search over trees. However, in our learning setting (independent of the semantic formalism), we must enforce the global constraint that z produces y . This makes dynamic programming infeasible, so we use beam search (though dynamic programming is still used to compute the denotation of a fixed DCS tree). We estimate the model parameters with a simple procedure that alternates be-tweenbeamsearchandoptimizingalikelihoodobjectiverestrictedtothosebeams.This yields anatural bootstrapping procedure in which learning and search are integrated. geographydomain(ZelleandMooney1996),and J OBS ,ajobqueriesdomain(Tangand
Mooney 2001). On G EO , we found that our system significantly outperforms previous work that also learns from answers instead of logical forms (Clarke et al. 2010). What is perhaps a more significant result is that our system obtains comparable accuracies to state-of-the-art systems that do rely on annotated logical forms. This demonstrates the viability of training accurate systems with much less supervision than before. semanticformalism.Section3presentsourprobabilisticmodelandlearningalgorithm.
Section 4 provides an empirical evaluation of our methods. Section 5 situates this work in abroader context, andSection 6concludes. 2. Representation
In this section, we present the main conceptual contribution of this work, dependency-based compositional semantics (DCS), using the U.S. geography domain (Zelle and
Mooney 1996) as a running example. To do this, we need to define the syntax and semantics of the formal language. The syntax is defined in Section 2.2 and is quite straightforward: The logical forms in the formal language are simply trees, which we call DCS trees .InSection2.3,wegiveatype-theoreticdefinitionof worlds (alsoknown asdatabasesormodels)withrespecttowhichwecandefinethesemanticsofDCStrees. treestorepresentlogicalformsasconstraintsatisfactionproblemsorextensionsthereof, and(ii)dealingwithcaseswhensyntacticandsemanticscopediverge(e.g.,forgeneral-ized quantification and superlative constructions) using a new construct which we call mark X  X xecute . We start in Section 2.4 by introducing the semantics of a basic version of DCS which focuses only on (i) and then extend it to the full version (Section 2.5) to account for (ii).
 mechanism for mapping a natural language utterance to a set of candidate DCS trees (Section2.6). 2.1 Notation
Operations on tuples will play a prominent role in this article. For a sequence ( v 1 , ... , v k ), we use and v ,weuse u + v = ( u 1 , ... , u | u | , v 1 , ... , v | components of v specified by i ; we call v i the projection of v onto i . We use negative v 3,1 = ( c , a ), v  X  3 = ( a , b , d ), v 3,  X  3 = ( c , a , b , d ). 2.2 Syntax of DCS Trees
The syntax of the DCS formal language is built from two ingredients, predicates and relations: in which nodes are labeled with predicates and edges are labeled with relations; each node also maintains an ordering over itschildren. Formally: Definition 1 (DCS trees)
Let Z bethesetofDCStrees,whereeach z  X  Z consistsof(i)apredicate z . p Table 1)and achild tree e . c  X  Z .

We will either draw a DCS tree graphically or write it compactly as p ; r where p is the predicate at the root node and c 1 , ... , c DCS tree expressed using both graphical and compact formats.
 394 tree,onlywithpredicates inplace ofwords. Aswe X  X lseeoverthecourse ofthissection, itisthistransparencybetweensyntaxandsemanticsprovidedbyDCSwhichleadstoa simple and streamlined compositional semantics suitable for program induction. 2.3 Worlds
In the context of question answering, the DCS tree is a formal specification of the question. To obtain an answer, we still need to evaluate the DCS tree with respect to a database of facts (see Figure 4 for an example). We will use the term world to refer to this database (it is sometimes also called a model, but we avoid this term to avoid confusion with the probabilistic model for learning that we will present in Section 3.1).
Throughout this work, we assume the world is fully observed and fixed, which is a realistic assumption for building natural language interfaces to existing databases, but questionable for modeling the semantics of language in general. 2.3.1 Types and Values. To define a world, we start by constructing a set of values
The exact set of values depends on the domain (we will continue to use U.S. geog-raphy as a running example). Briefly, V contains numbers (e.g., 3
Washington  X  V ),tuples(e.g., (3, Washington )  X  V ),sets(e.g., other higher-order entities.

V ,which includes the following: need a bit more machinery: To avoid logical paradoxes, we construct order of complexity using types (see Carpenter [1998] for a similar construction). The casual reader can skip thisconstruction without losing any intuition.
 1. The primitive type  X  T ; 2. The tuple type ( t 1 , ... , t k )  X  T for each k  X  0and each non-tuple type 3. The set type { t } X  T for each tuple type t  X  T .
 Notethat { } , {{ }} ,and(( ))are not valid types.
 1. For the primitive type t = ,the primitive values V have already been 2. For atuple type t = ( t 1 , ... , t k ), V t isthe cross product of the values ofits 396 3. For aset type t = { t } , V t contains all subsets of itselement type t : Let V =  X  t  X  T V t be the set of all possible values.
 ( t Now we define a world formally.
 Definition 2 (World)
Aworld w : P  X  V { TUPLE }  X  X  V } is a function that maps each non-null predicate p P \{  X  } to a set of tuples w ( p )  X  V { values ( w ( X ) = V ).
 if A is empty, then A RITY ( A ) is undefined. No wfor a predicate p define A RITY w ( p ),thearity of predicate p with respect to w , as follows:
Thenullpredicatehasarity1byfiat;thearityofanon-nullpredicate p isinheritedfrom the tuples in w ( p ).

Remarks. In higher-order logic and lambda calculus, we construct function types and values, whereas in DCS, we construct tuple types and values. The two are equivalent in representational power, but this discrepancy does point out the fact that lambda calculus is based on function application, whereas DCS, as we will see, is based on declarative constraints. The set type { ( , ) } in DCS corresponds to the function type  X  (  X  bool ). In DCS, there is no explicit bool type X  X t is implicitly represented by using sets. 2.3.2 Examples. The world w maps each domain-specific predicate to a set of tuples (usually a finite set backed by a database). For the U.S. geography domain, w has a set of pairs of entities and where theyare located ( loc ),andso on: Toshorten notation, we use state abbreviations (e.g., CA = California : state ). (thinkoftheseashelperfunctions),whichusuallycorrespondtoaninfinitesetoftuples.
Functions are represented in DCS by a set of input X  X utput pairs. For example, the semanticsofthe count t predicate (foreachtype t  X  T )containspairsofsets S andtheir cardinalities | S | : setofkey X  X aluepairs(withkeysoftype t )andreturnstheaveragevalue.Fornotational convenience,wetreatanarbitrarysetofpairs S asaset-valuedfunction:Welet S x . The semantics of average t contains pairs of setsand their averages: w ( average t ) =
Similarly,wecandefinethesemanticsof argmin t and argmax t key X  X alue pairs and returns the keys that attain the smallest (largest) value:
The extra min and max is needed because S ( x ) could contain more than one value. We thus argmin t denotes apartial function (same for argmax t ( t = ).Toreducenotation,weomit t torefertothisversion: count = count , average = average , and soforth. 398 2.4 Semantics of DCS Trees without Mark X  X xecute (Basic Version)
The semantics or denotation ofaDCStree z with respect to a world w is denoted z
First, we define the semantics of DCS trees with only join relations (Section 2.4.1). In this case, a DCS tree encodes a constraint satisfaction problem (CSP); this is important because it highlights the constraint-based nature of DCS and also naturally leads to a computationally efficient way of computing denotations (Section 2.4.2). We then allow
DCS trees to have aggregate relations (Section 2.4.3). The fragment of DCS which has only join and aggregate relations is called basic DCS . 2.4.1 Basic DCS Trees as Constraint Satisfaction Problems. Let z be a DCS tree with only assignment a . Thepredicates and relations of z introduce constraints: 1. a ( x )  X  w ( p ) for each node x labeled with predicate p 2. a ( x ) j = a ( y ) j for each edge ( x , y ) labeled with
Wesaythatanassignment a is feasible ifitsatisfiesthesetwoconstraints.Next,foranode x ,define V ( x ) = { a ( x ) : assignment a isfeasible } the denotation of the DCS tree z with respect to the world w to be z x is the root node of z .

The non-root nodes are existentially quantified, the root node c is  X  -abstracted, and all constraints introduced by predicates and relations are conjoined. The  X  -abstraction equivalence between the Boolean function  X  c . p ( c )and theset
Remarks. Note that CSPs only allo wexistential quantification and conjunction. Why did we choose this particular logical subset as a starting point, rather than allowing universal quantification, negation, or disjunction? There seems to be something fun-damental about this subset, which also appears in Discourse Representation Theory (DRT) (Kamp and Reyle 1993; Kamp, van Genabith, and Reyle 2005). Briefly, logical forms in DRT are called Discourse Representation Structures (DRSs), each of which conjoineddiscourseconditions(constraints),and(iii)nestedDRSs.Ifweexcludenested
DRSs,aDRSisexactlyaCSP. 3 Thedefaultexistentialquantificationandconjunctionare quite natural for modeling cross-sentential anaphora: Ne wvariables can be added to aDRSandconnectedtoothervariables.Indeed,DRTwasoriginallymotivatedbythese phenomena (see Kamp and Reyle [1993] for more details). 4 that they are unable to capture long-distance dependencies such as those arising from to state , but this dependence cannot be captured in a tree structure. A solution is to simply add an edge between the its node and the state node that forces the two nodes to have the same value. The result is still a well-defined CSP, though not a tree-structured one. The situation would become trickier if we were to integrate the other relations (aggregate, mark, and execute). We might be able to incorporate some ideas from Hybrid Logic Dependency Semantics (Baldridge and Kruijff 2002; White 2006), giventhathybridlogicextendsthetreestructuresofmodallogicwith nominals ,thereby allowinganodetofreelyreferenceothernodes.Inthisarticle,however,wewillstickto trees and leave the full exploration of non-trees for future work. denotation z w of a DCS tree z with only join relations. Now we will show how to compute z w efficiently. Recall that the denotation is the set of feasible values for the root node. In general, finding the solution to a CSP is NP-hard, but for trees, we can exploit dynamic programming (Dechter 2003). The key is that the denotation of a tree depends on itssubtrees only through their denotations:
Ontheright-handsideofEquation(12),thefirstterm w ( p )isthesetofvaluesthatsatisfy the node constraint, and the second term consists of an intersection across all m edges of { v : v with respect to some value t forthechild c i .
 operations: join and project . Jointakes across product oftwosetsof tuplesand retains the resulting tuples that match the join constraint: Project takes aset of tuples and retains afixed subset of the components:
ThedenotationinEquation(12)cannowbeexpressedintermsofthesejoinandproject operations: 400 where i = (1, ... ,A RITY w ( p )).Projectingonto i retains only components corresponding to p .
 with the number of nodes, but there is also a dependence on the cost of performing the joinandprojectoperations.Fordetailsonhowweoptimizetheseoperationsandhandle infinite setsof tuples (for predicates such as count ),seeLiang (2011). therecurrenceinEquation(15)isonlyonewayofcomputingthisdenotation.Inlightof theextensionstocome,however,wenowconsiderEquation(15)astheactualdefinition order toaccess the intuition of using declarative constraints. 2.4.3 Aggregate Relation. Thus far, we have focused on DCS trees that only use join relations,whichareinsufficientforcapturinghigher-orderphenomenainlanguage.For example, consider the phrase number of major cities . Suppose that number corresponds to the count predicate, and that major cities maps to the DCS tree city ; cannotsimplyjoin count withtherootofthisDCStreebecause count needstobejoined withthe set of major cities (the denotation of city ; 1 1 tree  X ;  X  : c ,wheretherootisconnectedtoachild c via  X  .Thedenotationoftherootis simply the singleton set containing the denotation of c : middlenodeis { ( s ) } , where s is all major cities. Everything above this node is an ordinary CSP: s constrains the count node, which in turns constrains the root node to | s | .Figure5(b)showsanotherexampleofusingtheaggregaterelation  X  .Here,thenode right above  X  is constrained to be a set of pairs of major cities and their populations. The average predicate then computes the desired answer.
 andtwo predicates, union and contains , which are definedin the expected way: an example of a disjunctive construction: We use the aggregate relations to construct twosets,onecontainingOregon,andtheothercontainingstatesborderingOregon.We taketheunionofthesetwosets; contains takesthesetandreadsoutanelement,which then constrains the city node.

Remarks. A DCS tree that contains only join and aggregate relations can be viewed as a collection of tree-structured CSPs connected via aggregate relations. The tree struc-ture still enables us to compute denotations efficiently based on the recurrences in Equations (15)and (16).
 aggregate relation corresponds to the abstraction operator in DRT and is one way of making nested DRSs. It turns out that the abstraction operator is sufficient to obtain the full representational power of DRT, and subsumes generalized quantification and disjunction constructs in DRT. By analogy, we use the aggregate relation to handle disjunction (Figure 5(c)) andgeneralized quantification (Section 2.5.6). does not have universal quantification, negation, and disjunction. The aggregate rela-tionisanalogoustolambdaabstraction,andinbasicDCSweusetheaggregaterelation to implement those basic constructs using higher-order predicates such as not , every , and union . We can also express logical statements such as generalized quantification, which go beyond first-order logic. 2.5 Semantics of DCS Trees with Mark X  X xecute (Full Version)
Basic DCS includes two types of relations, join and aggregate, but it is already quite expressive. In general, however, it is not enough just to be able to express the meaning of a sentence using some logical form; we must be able to derive the logical form compositionally and simply from the sentence.
 dependency structure shown in Figure 6(a). Figure 6(b) shows that we can in principle 402 already use a DCS tree with only join and aggregate relations to express the correct semantics of the superlative construction. Note, however, that the two structures are quite divergent X  X he syntactic head is city and the semantic head is argmax . This diver-gence runs counter to a principal desideratum of DCS, which is to create a transparent interface between coarse syntax and semantics.
 use the DCS tree in Figure 6(c) to represent the semantics associated with Figure 6(a); these two are more similar than (a) and (b). The focus of this section is on this mark X  executeconstruct X  X singmarkandexecuterelationstogivepropersemanticallyscoped denotations tosyntactically scoped tree structures.
 lo win the tree with a mark relation ; then, higher up in the tree, we invoke it with a corresponding execute relation (Figure 7). For our example in Figure 6(c), we mark the population node, which puts the child argmax in a temporary store; when we execute the city node, we fetch the superlative predicate argmax from thestore and invoke it. contexts besides superlatives, such as quantification and negation. In each of these cases, the general template is the same: A syntactic modifier lo win the tree needs to havesemanticforcehigherinthetree.Aparticularlycompellingcaseofthisdivergence happenswithquantifierscopeambiguity(e.g., Some river traverses every city quantifiers appear in fixed syntactic positions, but the surface and inverse scope read-ingscorrespondtodifferentsemanticallyscopeddenotations.Analogously,asinglesyn-tactic structure involving superlatives can also yield two different semantically scoped denotations X  X he absolute and relative readings (e.g., state bordering the largest state
The mark X  X xecute construct provides a unified framework for dealing all these forms of divergence between syntactic and semantic scope. See Figures 8 and 9 for concrete examples of thisconstruct. 2.5.1 Denotations. Wenowformalizethemark X  X xecuteconstruct.Wesawthatthemark X  execute construct appears to act non-locally, putting things in a store and retrieving them later. This means that if we want the denotation of a DCS tree to only depend on the denotations of its subtrees, the denotations need to contain more than the set of feasiblevaluesfortherootnode,aswasthecaseforbasicDCS.Weneedtoaugmentde-notationstoincludeinformationaboutallmarkednodes,becausethesecanbeaccessed by an execute relation higher up in the tree.
 d consists of n columns . The first column always corresponds to the root node of z , and the rest of the columns correspond to non-root marked nodes in z . In the example in Figure 10, there are two columns, one for the root state node and the other for size node,whichismarkedby C .Thecolumnsareorderedaccordingtoapre-ordertraversal of z ,socolumn1alwayscorrespondstotherootnode.Thedenotation d containsasetof arrays d . A , where each array represents a feasible assignment of values to the columns of d ; note that we quantify over non-marked nodes, so they do not correspond to any columninthedenotation.Forexample,inFigure10,thefirstarrayin d . A correspondsto assigning( OK )tothe state node(column1)and( TX ,2.7e5)tothe size node(column2).
If there are no marked nodes, d . A is basically a set of tuples, which corresponds to a denotationinbasicDCS.Foreachmarkednode,thedenotation d alsomaintainsa store 404 with information to be retrieved when that marked node is executed. A store  X  for a markednodecontainsthefollowing:(i)themarkrelation  X . r ( C intheexample),(ii)the basedenotation  X . b ,whichessentiallycorrespondstodenotationofthesubtreerootedat themarkednodeexcludingthemarkrelationanditssubtree( size w and (iii) the denotation of the child of the mark relation ( argmax Thestore of any unmarked nodes isalways empty (  X  =  X ).
 Definition 3 (Denotations)
Let D be the set of denotations , where each denotation d 406
Note that denotations are formally defined without reference to DCS trees (just as sets of tuples were in basic DCS), but it is sometimes useful to refer to the DCS tree that generates that denotation.
 d . r i = d . X  i . r , d . b i = d . X  i . b ,and d . c i = d . X  identical to d , except with d . X  i = x ; d { r i = x } , d analogously. We also define a project operation for denotations: A ;  X  [ i ]
A } ;  X  columns with empty stores ( i &gt; 1suchthat d . X  i =  X ). We can then use d [ projecting away the non-initial columns with empty stores. For the denotation d in
Figure 10, d [1] keeps column 1, d [  X   X ] keeps both columns, and d [2, columns.
 senting the semantics of wh -questions such as What states border Texas? But what about polar questions such as Does Louisiana border Texas? The denotation should be a simple
Boolean value, which basic DCS does not represent explicitly. Using our new deno-tations, we can represent Boolean values explicitly using zero-column structures: true corresponds to a singleton set containing just the empty array ( d istheempty set ( d F =  X  ).
 mapping from DCS trees to these structures. As in basic DCS, this mapping is defined recursively over the structure of the tree. We have a recurrence for each case (the first line isthe base case, and each of the others handles adifferent edge relation):
We define the operations  X   X  j , j ,  X  , X i ,and M in the remainder ofthis section. 2.5.2 Base Case. Equation (19) defines the denotation for a DCS tree z with a single node with predicate p . The denotation of z has one column whose arrays correspond to the tuples w ( p ); the store for that column isempty. handside, p ; e ; j j : c isaDCStreewith p attheroot,asequenceofedges e followedby afinaledgewithrelation j j connected to a child DCS tree c . On the right-hand side, we take the recursively computed denotation of p ; e , the DCS tree without the final edge, andperforma join-project-inactive operation(notated  X   X  j , j child DCS tree c .
 the core of the join operation in basic DCS X  X ee Equation (13)), and then projects away the non-initial empty columns: 7
We concatenate all arrays a  X  A with all arrays a  X  A that satisfy the join condition a = a 1 j . The sequences of stores are simply concatenated: (  X  +  X  ). Finally, any non-initial columns with empty stores are projected away byapplying ride. As another piece of convenient notation, we use  X  to represent all components, so  X  imposes the join condition that the entire tuple has toagree ( a 2.5.4 Aggregate Relations. Equation (21) defines the recurrence for aggregate relations.
RecallthatinbasicDCS,aggregate(16)simplytakesthedenotation(asetoftuples)and puts it into a set. Now, the denotation is not just a set, so we need to generalize this operation. Specifically, the aggregate operation applied to a denotation forms a set out of the tuples in the first column for each setting of the rest of the columns: 408
The aggregate operation takes the set of arrays A and produces two sets of arrays, A and A ,whichareunioned(notethatthestoresdonotchange).Theset A istheonethat firstcomestomind:Foreverysettingof a 2 , ... , a n ,weconstruct S ( a ),thesetoftuples a in the first column which co-occur with a 2 , ... , a n in A .
 co-occurwithanyvalueof a 1 in A ?Then, S ( a ) =  X  ,butnotethat A byconstructionwill not have the desired array [  X  , a 2 , ... , a n ]. As a concrete example, suppose A = have one column ( n = 1). Then A =  X  ,rather than the desired donotco-occurwithany a 1 in A ,soforwhichonesdoweactuallyinclude[
Certainly, the answer to this question cannot come from A , so it must come from the denotation([ a i ]  X   X  i . b . A [1]).Forthis a 2 , ... , a a , ... , a n does not co-occur with any a 1 .An example is given in Figure 11. resent feasible values of a CSP and can only contain positive information. When we aggregate, we need to access possibly empty sets of feasible values X  X  kind of negative information, which can only be recovered fromthe base denotations.
 2.5.5 Mark Relations. Equations (23), (24), and (25) each processes a different mark tobe ( r , d , c ):
The base denotation of the first column b 1 is set to the current denotation d .This,in some sense, creates a snapshot of the current denotation. Figure 12 shows an example of the mark operation. 2.5.6 Execute Relations. Equation(22)definesthedenotationofaDCStreewherethelast execute operation X i tothedenotation of thechild ( c w ).
 heavy lifting. The operation is parametrized by a sequence of distinct indices i that specifiestheorderinwhichthecolumnsshouldbeprocessed.Specifically, i indexesinto the subsequence of columns with non-empty stores. We then process this subsequence of columns in reverse order, where processing a column means performing some op-erations depending on the stored relation in that column. For example, suppose that columns 2 and 3 are the only non-empty columns. Then X 12 column 2. On the other hand, X 21 processes column 2 before column 3. We first define 410 theexecute operation X i forasingle column i .There are threedistinct cases, depending on the relation stored in column i :
Extraction. For a denotation d with the extract relation E in column involves three steps: (i) moving column i to before column 1 ( away non-initial empty columns (  X  [  X   X ]),and (iii)removing thestore (
An example is given in Figure 13. There are two main uses ofextraction. 1. Bydefault, the denotation of aDCStree isthe set of feasible values ofthe 2. Unmarked nodes (those that do not have an edge with a mark relation) are Generalized Quantification. Generalizedquantifiersarepredicatesontwosets,a restrictor
A and a nuclear scope B . For example,
Wethinkofthequantifierasamodifierwhichalwaysappearsasthechildofa Q relation; and state correspondstotherestrictor.Thenuclearscopeshouldbethesetofallstates thatAlaskaborders.Moregenerally,thenuclearscopeisthesetoffeasiblevaluesofthe restrictor node with respect to the CSP that includes all nodes between the mark and but with respect tothe CSPcorresponding tothe subtree rooted at that node. we are executing column i . We first construct a denotation for the restrictor d denotation for the nuclear scope d B . For the restrictor, we take the base denotation in column i ( d . b i ) X  X ememberthatthebasedenotationrepresentsasnapshotoftherestric-tor node before the nuclear scope constraints are added. For the nuclear scope, we take the complete denotation d (which includes the nuclear scope constraints) and extract column i ( d [ i ,  X  i ][  X   X ] {  X  1 =  X  }  X  X ee (29)). We then construct d aggregate operation to each. Finally, we join these sets with the quantifier denotation, stored in d . c i :
When there is one quantifier, think of the execute relation as performing a syntactic rewriting operation, as shown in Figure 14(b). For more complex cases, we must defer to(34).
 the DCS tree before execution is the same in both readings, as shown in Figure 15. The 412 surface scope reading, X 21 gives the inverse scope reading.
 quantifier is processed for each city , which is an unprocessed marked node. Here, the extract relation isa technical tricktogive city wider scope.

Comparatives and Superlatives. Comparative and superlative constructions involve com-paringentities,andforthiswerelyonaset S ofentity X  X egreepairs ( x , y ),where x isan entity and y is a numeric degree. Recall that we can treat S as a function, which maps we would have adegree for the size of each neighboring state.
 x is  X  X ore than X  y as measured by S ; w ( less ) is defined analogously: tions.IntermsoftheDCStree,therearethreekeyparts:(i)theroot x ,whichcorresponds to the entity to be compared, (ii) the child c of a C relation, which corresponds to the information X  (which will be described later) used for comparison. We assume that the root is marked (usually with a relation E ). This forces us to compute a comparison degreeforeachvalueoftherootnode.Intermsofthedenotation d correspondingtothe
DCS tree prior to execution, the entity to be compared occurs in column 1 of the arrays by concatenating the corresponding tuples of each array in d . A :
Note that the store of column i 1 is kept and the others are discarded. As an example: + 2,1 ( { [(1),(2),(3)],[(4),(5),(6)] } ;  X  1 ,  X  2 ,  X  3 mation, is extracted to column 1 (and thus column 2 corresponds to the entity to be compared). Next, we create a denotation d S whose column 1 contains a set of entity-degree pairs. There are twotypes of degree information: 1. Suppose the degree information hasarity 2 (A RITY ( d . A [ i ]) = 2).This 2. Suppose the degree information hasarity 1 (A RITY ( d . A [ i ]) = 1).This 414
Having constructed d S , we simply apply the comparative/superlative predicate which hasbeenpatientlywaitingin d . c i .Finally,thestoreof d  X  X column1wasdestroyedbythe concatenationoperation + 2,1 ( ( )  X  ),sowemustrestoreitwith operation isasfollows: An example of executing the C relation is shown in Figure 16(a). As with executing a tree, asshown in Figure 16(b).
 ity1andarity2typesofdegreeinformation,respectively.Figure9(c)showsanexample ofacomparativeconstruction.Comparativesandsuperlativesusethesamemachinery, differing only in the predicate: argmax versus more ; 3 1 predicateshavethesametemplatebehavior:Eachtakesasetofentity X  X egreepairsand returns any entity satisfying some property. For argmax , the property is obtaining the highest degree; for more , it is having a degree higher than a threshold. We can handle swapping in a different predicate; the execution mechanisms defined in Equation (41) remain the same.
 scope to be made in a clean and modular fashion. Superlatives also have scope am-biguities in the form of absolute versus relative readings. Consider the example in
Figure9(d).Intheabsolutereading,wefirstcomputethesuperlativeinanarrowscope theemptyset(becausenostatesborderAlaska).Intherelativereading,weconsiderthe first state as the entity we want to compare, and its degree is the size of a neighboring state. In this case, the lower state node cannot be set to Alaska because there are no thatdoeshaveneighbors).ThetwoDCStreesinFigure9(d)showthatwecannaturally account for this form of superlative ambiguity based on where the scope-determining execute relation isplaced without drastically changing the underlying tree structure.
Remarks. ThesescopedivergenceissuesarenotspecifictoDCS X  X veryserioussemantic formalismmustaddressthem.Generativegrammarusesquantifierraisingtomovethe quantifierfromitsoriginalsyntacticpositionuptothedesiredsemanticpositionbefore semantic interpretation even occurs (Heim and Kratzer 1998). Other mechanisms such as Montague X  X  (1973) quantifying in, Cooper storage (Cooper 1975), and Carpenter X  X  (1998) scoping constructor handle scope divergence during semantic interpretation.
Roughly speaking, these mechanisms delay application of a quantifier,  X  X arking X  its spotwithadummypronoun(asinMontague X  X quantifyingin)orputtingitinastore(as inCooperstorage),andthen X  X xecuting X  X hequantifieratalaterpointinthederivation eitherbyperformingavariablesubstitutionorretrievingitfromthestore.Continuation, fromprogramminglanguages,isanothersolution(Barker2002;Shan2004);thissetsthe semantics of a quantifier to be a function from its continuation (which captures all the semanticcontentoftheclauseminusthequantifier)tothefinaldenotationoftheclause. 416
Intuitively, continuations reverse the normal evaluation order, allowing a quantifier to remain in situ but still outscope the rest of the clause. In fact, the mark and execute relations of DCS are analogous to the shift and reset operators used in continuations.
Oneofthechallengeswithallowingflexiblescopeisthatfreevariablescanyieldinvalid scopings,awell-knownissuewithCooperstoragethatthecontinuation-basedapproach solves. Invalid scopings are filteredout bythe construction mechanism (Section 2.6).
DCS trees (which contain mark and execute relations) are the final logical forms X  X he handling of scope divergence occurs in the computing their denotations. The analog in the other mechanisms resides in the construction mechanism X  X he actually final logical form is quite simple. 9 Therefore, we have essentially pushed the inevitable complexity from the construction mechanism into the semantics of the logical form.
Thisisaconscious designdecision: Wewantourconstruction mechanism, whichmaps naturallanguagetologicalform,tobesimpleandnotburdenedwithcomplexlinguistic issues, for our focus is on learning this mapping. Unfortunately, the denotation of our logical forms (Section 2.5.1) do become more complex than those of lambda calculus expressions, but we believe this is a reasonable tradeoff to make for our particular application. 2.6 Construction Mechanism
We have thus far defined the syntax (Section 2.2) and semantics (Section 2.5) of DCS trees, but we have only vaguely hinted at how these DCS trees might be connected to natural language utterances by appealing to idealized examples. In this section, we formally define the construction mechanism for DCS, which takes an utterance x and produces aset ofDCS trees Z L ( x ).
 totakeadependencyparsetreeoftheutterance,replacethewordswithpredicates,and attach some relations on the edges to produce a DCS tree. To a first approximation, this is what we will do, but we need to be a bit more flexible for several reasons: (i) some nodes in the DCS tree do not have predicates (e.g., children of an E relation or parent of an X i relation); (ii) nodes have predicates that do not correspond to words (e.g., in words might not correspond to any predicates in our world (e.g., please ); and (iv) the
DCS tree might not always be aligned with the syntactic structure depending on which syntactic formalism one ascribes to. Although syntax was the inspiration for the DCS formalism, we will not actually use it in construction.
 the purpose of the construction mechanism is to try to generate the exact set of valid logical forms for a sentence. We vie wthe construction mechanism instead as simply a way of creating a set of candidate logical forms. A separate step defines a distribution over this set to favor certain logical forms over others. The construction mechanism shouldthereforesimplyoverapproximatethesetoflogicalforms.Linguisticconstraints that are normally encoded in the construction mechanism (for example, in CCG, that quantifiers cannot extend their scope beyond clause boundaries) would be instead encoded as features (Section 3.1.1). Because feature weights are estimated from data, one can vie wour approach as automatically learning the linguistic constraints relevant toour end task. 2.6.1 Lexical Triggers. Theconstructionmechanismassumesafixedsetof lexical triggers triggeredby s (( s , p )  X  L ).Weshouldthinkofthelexicaltriggers L notaspinningdown the precise predicate for each word, but rather as producing an overapproximation.
Forexample, L mightcontain { ( city , city ),( city , state ),( city , river ), ... initial ignorance prior tolearning.
 overt lexical element. Their name is inspired by trace/null elements in syntax, but they serveamorepracticalratherthanatheoreticalrolehere.AsweshallseeinSection2.6.2, trace predicates provide more flexibility in the construction of logical forms, allowing ustoinsertapredicatebasedonthepartiallogicalformconstructedthusfarandassess itscompatibilitywiththewordsafterwards(basedonfeatures),ratherthaninsistingon apurelylexicallydrivenformalism.Section4.1.3describesthelexicaltriggersandtrace predicates that we use in our experiments. describe a recursive mechanism for mapping an utterance x = ( x set of candidate DCStreesfor x . Thebasic approach isreminiscent ofprojective labeled dependency parsing: For each span i .. j of the utterance, we build a set of trees C Theset of trees forthespan 0 .. n isthefinal result: areignored).Thesecombinationsarethenaugmentedviaafunction A andfilteredviaa function F ;thesefunctionswillbespecifiedlater.Formally, C as follows: Thisrecurrence has twoparts: 418 relations and at most d trace predicates ( d is a small integer that keeps the set of DCS treesmanageable):
Here, T d ( a , b ) is the set of DCS trees where a is the root; for T former isdefined recursively asfollows:
First, we consider all possible relations r  X  R and try appending an edge to a with tions, but only a small finite number of them make sense: We consider join relations only for j  X  X  1, ... ,A RITY ( a . p ) } and j  X  X  1, ... ,A RITY ( b . p ) for which i does not contain indices larger than the number of columns of b wefurtherconsiderallpossibletracepredicates p  X  L ( ),andrecursivelytrytoconnect a withtheintermediate p ; r : b ,nowallowing d  X  1additionalpredicates.SeeFigure18 for an example. In the other direction, T d is definedsimilarly: than are explicitly triggered by the words. This ability is useful for several reasons.
Sometimes, there is a predicate not overtly expressed, especially in noun compounds difficult to enumerate all the possible predicates that they might trigger; it is simpler computationally to try to insert trace predicates. We can even omit lexical triggers for transitive verbs such as border because the corresponding predicate border can be inserted asatrace predicate.
 cates. The augmentation function A adds additional relations (specifically, E and/or X on asingle DCS tree: 2.6.3 Filtering using Abstract Interpretation. Theconstructionprocedureasdescribedthus far is extremely permissive, generating many DCS trees which are obviously wrong X  forexample, state ; 1 1 : &gt; ; 2 1 3 ,whichtriestocompareastatewiththenumber3.There isnothingwrongwiththisexpressionsyntactically:Itsdenotationwillsimplybeempty (withrespect totheworld). But semantically, this DCStreeis anomalous.
 though the denotation is empty in this world, it is possible that it might not be empty 420 in a different world where history and geology took another turn, whereas it is simply impossible tocompare cities and numbers.
 cussion about possible worlds. Given a world w , we define an abstract world  X  ( w ), to be described shortly. We compute the denotation of a DCS tree z with respect to this abstract world. If at any point in the computation we create an empty denotation, wejudge z to be impossible and thro wit a way. The filtering function F is defined as follows: 10 valuestoabstractvalues:3: length becomes  X  : length , Oregon : state becomes and in general, primitive value x : t becomes  X  : t . We perform abstraction on tuples componentwise, so that ( Oregon : state ,3: length ) becomes ( abstraction of sets is slightly more complex: The empty set maps to the empty set, a set containing values all with the same abstract value a maps to valueswithmorethanoneabstractvaluemapsto { MIXED } .Finally,aworldmapseach predicate onto a set of (concrete) tuples; the corresponding abstract world maps each predicateontothesetofabstracttuples.Formally,theabstractionfunctionisdefinedas follows:  X  (( v 1 , ... , v n )) = (  X  ( v 1 ), ... ,  X  ( v n )) [tuple] (52)
No wreturning to our motivating example at the beginning of this section, we see that the bad DCS tree has an empty abstract denotation state ;  X  ; X  . The good DCS tree has a non-empty abstract denotation: state ;
AK  X  ( w ) = { (  X  : state ) } ; X  , asdesired.
Remarks. Computing denotations on an abstract world is called abstract interpretation (Cousot and Cousot 1977) and is a very powerful framework commonly used in the programminglanguagescommunity.Theideaistoobtaininformationaboutaprogram (in our case, a DCS tree) without running it concretely, but rather just by running it often much richer than standard type systems. 2.6.4 Comparison with CCG. We no wcompare our construction mechanism with CCG (see Figure 19 for an example). The main difference is that our lexical triggers contain lessinformationthanalexicalentryinaCCG.InCCG,thelexiconwouldhaveanentry such as which gives detailed information about how this word should interact with its context.
In DCS construction, however, each lexical trigger only has the minimal amount of information:
A lexical trigger specifies a pre-theoretic  X  X eaning X  of a word which does not commit to any formalisms. One advantage of this minimality is that lexical triggers could be easily obtained from non-expert supervision: One would only have to associate words with database table names (predicates).
 lexicon. In linguistics, this complexity usually would end up in the grammar, which would be undesirable. We do not have to respect this tradeoff, however, because the 422 constructionmechanismonlyproducesanoverapproximation,whichmeansitispossi-ble tohave both a simple  X  X exicon X  and asimple  X  X rammar. X  we never just have one clean lexical entry per word. Rather, there are often many possible lexical entries (and to handle disfluent utterances or utterances in free word-order languages, we might actually need many of them[Kwiatkowski et al. 2010]):
No wthink of a DCS lexical trigger major major as simply a compact representation for a set of CCG lexical entries. Furthermore, the choice of the lexical entry is made not relations between DCS subtrees. It is exactly at this point that the choice can be made, because after all, the choice is one that depends on context. The general principle is to compactlyrepresenttheindeterminacyuntilonecanresolveit.Compactlyrepresenting a set of CCG lexical entries can also be done within the CCG framework by factoring lexical entries intoa lexeme and a lexical template (Kwiatkowski etal. 2011). recent work, Zettlemoyer and Collins (2007) introduced more general type-changing combinators to allo wconversion from one entity into a related entity in general (a kind of generalized metonymy). For example, in order to parse Boston flights , Boston predicates in DCS, but there is an important distinction: Type changing is a unary operation and is unconstrained in that it changes logical forms into ne wones without regard for how they will be used downstream. Inserting trace predicates is a binary operation that is constrained by the two predicates that it is mediating. In the example, to would only be inserted to combine Boston with flight . This is another instance of the general principle of delaying uncertain decisions until there ismore information. 3. Learning
In Section 2, we defined DCS trees and a construction mechanism for producing a set of candidate DCS trees given an utterance. We no wdefine a probability distribution over that set (Section 3.1) and an algorithm for estimating the parameters (Section 3.2).
The number of candidate DCS trees grows exponentially, so we use beam search to control this growth. The final learning algorithm alternates between beam search and optimization of the parameters, leading to a natural bootstrapping procedure which integrates learning and search. 3.1 Semantic Parsing Model
The semantic parsing model specifies a conditional distribution over a set of candi-date DCS trees C ( x ) given an utterance x . This distribution depends on a function  X  ( x , z )  X  R d ,whichtakesa( x , z )pairandextractsasetoflocalfeatures(seeSection3.1.1 forafullspecification).Associatedwiththisfeaturevectorisaparametervector  X  intuitively measures the compatibility of the utterance x with the DCS tree z . We expo-nentiate the score and normalize over C ( x ) toobtain aproper probability distribution:
C ( x ). 3.1.1 Features. Wenowdefinethefeaturevector  X  ( x , z )  X  R and allows us to generalize to new instances that share common features. instantiates a set of features. Figure 20 shows all the feature templates for a concrete example. Thefeature templates are asfollows: 424 essentially any distribution over sequences and labeled trees X  X here is nothing spe-
P RED R EL P RED ) capture properties of the tree independent of the utterance, and are similar to those used for syntactic dependency parsing. The other feature tem-in the DCS tree with words in the utterance, similar to those in a model of machine translation. 3.2 Parameter Estimation
We have no wfully specified the details of the graphical model in Figure 2: Section 3.1 describedsemanticparsingandSection2describedsemanticevaluation.Next,wefocus on the inferential problem ofestimating the parameters  X  of the model from data. 3.2.1 Objective Function. We assume that our learning algorithm is given a training data set
D containingquestion X  X nswerpairs( x , y ).Becausethelogicalformsareunobserved, answer y given an utterance x . This marginal log-likelihood sums over all z evaluate to y : Here, C y ( x )istheset ofDCS trees z with denotation y .
 tree that evaluates to y ( C y ( x ) =  X  ). Define an objective function two terms. The first term is the sum of the marginal log-likelihood over all feasible 426 training examples. The second term is a quadratic penalty on the parameters  X  with regularization parameter  X  .Formally: but O (  X  , C ) is the difference of two log-partition functions and hence is not concave (nor convex). Thus we resort to gradient-based optimization. A standard result is that the derivative of the log-partition function is the expected feature vector (Wainwright andJordan 2008). Using this, we obtain the gradient ofour objective function:
Updating the parameters in the direction of the gradient would move the parameters towards the DCS trees that yield the correct answer ( C y didate DCS trees ( C ). We can use any standard numerical optimization algorithm that requires only black-box access to a gradient. Section 4.3.4 will discuss the empirical ramifications of the choice of optimization algorithm. 3.2.2 Algorithm. Given a candidate set function C ( x ), we can optimize Equation (71) to obtainestimatesoftheparameters  X  .Ideally,wewoulduse C ( x ) = sets from our construction mechanism in Section 2.6, but we quickly run into the prob-lem of computing Equation (72) efficiently. Note that Z L grows exponentially with the length of x . This by itself is not a show-stopper. Our features (Section 3.1.1) decompose along the edges of the DCS tree, so it is possible to use dynamic programming 12 to compute the second expectation of Equation (72). The problem is computing the first expectation which sums over the subset of candidate DCS trees z satisfying the constraint z
Though this is a smaller set, there is no efficient dynamic program for this set because the constraint does not decompose along the structure of the DCS tree. Therefore, we need to approximate Z y L , and, in fact, we will approximate expectations in Equation (72) are coherent.
 for each span i .. j . In our approximation, we simply use beam search, which truncates let  X  respect tothe beam search: could generate good candidate sets C ( x ) using beam search candidate sets C ( x ), we could generate good parameters by optimizing our objective
O (  X  , C ) in Equation (71). This problem leads to a natural solution: simply alternate between the two steps (Figure 21). This procedure is not guaranteed to converge, due to the heuristic nature of the beam search, but we have found it to be convergent in practice.
 choosing the most likely answer y , summing out the latent logical form z : 4. Experiments
We have no wcompleted the conceptual part of this article X  X sing DCS trees to rep-resent logical forms (Section 2), and learning a probabilistic model over these trees (Section 3). In this section, we evaluate and study our approach empirically. Our main result is that our system can obtain comparable accuracies to state-of-the-art systems that require annotated logical forms. All the code and data are available at cs.stanford.edu/ ~ pliang/software/ . 4.1 Experimental Set-up
We first describe the data sets (Section 4.1.1) that we use to train and evaluate our system. We then mention various choices in the model and learning algorithm (Sec-tion 4.1.2). One of these choices is the lexical triggers, which are further discussed in Section 4.1.3.
 428 4.1.1 Data sets. We tested our methods on two standard data sets, referred to in this article as G EO and J OBS . These data sets were created by Ray Mooney X  X  group during the 1990s and have been used toevaluate semantic parsers for over adecade.
U.S. Geography. The G EO data set, originally created by Zelle and Mooney (1996), con-tains880questionsaboutU.S.geographyandadatabaseoffactsencodedinProlog.The questions in G EO ask about general properties (e.g., area, elevation, and population) of geographicalentities(e.g.,cities,states,rivers,andmountains).Acrossallthequestions, there are 280 word types, and the length of an utterance ranges from 4 to 19 words, with an average of 8.5 words. The questions involve conjunctions, superlatives, and negation, but no generalized quantification. Each question is annotated with a logical formin Prolog, for example: annotated logical forms on the provided database toobtain the correct answers.
Some predicates contain the set of tuples explicitly (e.g., mountain ); others can be derived (e.g., higher takes two entities x and y and returns true if elevation ( x ) &gt; other predicates as arguments. We do not use the provided domain-specific higher-order predicates (e.g., highest ), but rather provide domain-independent higher-order
This provides more compositionality and therefore better generalization. Similarly, we use more and elevation instead of higher . Altogether, P contains 43 predicates plus one predicate for each value (e.g., CA ).

Job Queries. The J OBS data set (Tang and Mooney 2001) contains 640 natural language queriesaboutjobpostings.Mostofthequestionsaskforjobsmatchingvariouscriteria: job title, company, recruiter, location, salary, languages and platforms used, areas of expertise, required/desired degrees, and required/desired years of experience. Across allutterances, thereare388wordtypes,andthelengthofanutterance rangesfrom2to 23words, with an average of 9.8 words.
 negation and disjunction. Here isan example: the logical forms are evaluated on this database, however, close to half of the answers are empty (no jobs match the requested criteria). Therefore, there is a large discrepancy between obtaining the correct logical form (which has been the focus of most work on semantic parsing) and obtaining the correct answer (our focus).
 follows: We created m = 100 jobs. For each job j , we go through each predicate p (e.g., company ) that takes two arguments, a job, and a target value. For each of the possible a database with a total of 23 predicates (which includes the domain-independent ones) inaddition tothevalue predicates (e.g., IBM ).
 likely yield different answers. For example, consider two logical forms:
Under the random construction, the denotation of z 1 is S where each job is included in S 1 independently with probability  X  , and the denotation of z 2 is S 2 , which has the same distribution as S 1 but importantly is independent of S
Therefore, the probability that S 1 = S 2 is [  X  2 + (1  X  multiple employers), but it ensures that if we get the correct answer, we probably also obtain the correct logical form. 4.1.2 Settings. There are a number of settings that control the tradeoffs between compu-tation, expressiveness, and generalization power of our model, shown here. For now, we will use generic settings chosen rather crudely; Section 4.3.4 will explore the effect of changing these settings.

Lexical Triggers The lexical triggers L (Section 2.6.1) define the set of candidate DCS
Features Our probabilistic semantic parsing model is defined in terms of feature tem-
Number of training examples ( n ) An important property of any learning algorithm is
Number of training iterations ( T ) Our learning algorithm (Figure 21) alternates be-
Beam size ( K ) The computation of the candidate sets in Figure 21 is based on beam
Optimization algorithm Tooptimizetheobjectivefunction O (  X  , C )ourdefaultistouse Regularization (  X  ) Theregularizationparameter  X &gt; 0intheobjectivefunction s is a sequence of words and p is a predicate. We run experiments on two sets of lexical triggers: base triggers L B and augmented triggers L B + P 430 Base Triggers. The base trigger set L B includes three types ofentries:
Augmented Triggers. Wenowdefinetheaugmentedtriggerset L B + P domain-specific information than L B . Specifically, for each domain-specific predicate (e.g., city ), we manually specify a single prototype word (e.g., city ) associated with that predicate. Under L B + P , city would trigger only city because city is a prototype word,but town wouldtriggerallthe NN predicates( city , state , country ,etc.)because itis not aprototype word.
 in Section 4.2, prototype triggers are not absolutely required to obtain good accuracies, buttheygiveanextraboostandalsoimprovecomputationalefficiencybyreducingthe set of candidate DCStrees. 1980), so that mountains triggers the same predicates as mountain . We also decompose superlatives into two words (e.g., largest is mapped to most large ), allowing us to con-struct the logical form more compositionally. 4.2 Comparison with Other Systems
We no wcompare our approach with existing methods. We used the same training-test splits as Zettlemoyer and Collins (2005) (600 training and 280 test examples for G EO , 500 training and 140 testexamples for J OBS ).For development, we created fiverandom splitsofthetrainingdata.Foreachsplit,weput70%oftheexamplesintoa development training set and the remaining 30% into a development test set . The actual test set was only used for obtaining final numbers. 4.2.1 Systems that Learn from Question X  X nswer Pairs. Wefirstcompareoursystem(hence-forth, LJK11) with Clarke et al. (2010) (henceforth, CGCR10), which is most similar to our work in that it also learns from question X  X nswer pairs without using annotated logical forms. CGCR10 works with the FunQL language and casts semantic parsing as integer linear programming (ILP). In each iteration, the learning algorithm solves the 432
ILP to predict the logical form for each training example. The examples with correct predictionsarefedtoastructuralsupportvectormachine(SVM)andthemodelparam-etersare updated.
 and our approach. They use ILP instead of beam search and structural SVM instead of log-linearmodels,butthemaindifferenceiswhichexamplesareusedforlearning.Our approach learns on any feasible example (Section 3.2.1), one where the candidate set contains alogical formthatevaluates tothe correct answer. CGCR10uses amuch more stringentcriterion:Thehighestscoringlogicalformmustevaluatetothecorrectanswer.
Therefore,fortheiralgorithmtoprogress,themodelalreadymustbenon-triviallygood before learning even starts. This is reflected in the amount of prior knowledge and initializationthatCGCR10usesbeforelearningstarts:WordNetfeatures,syntacticparse trees, and a set of lexical triggers with 1.42 words per non-value predicate. Our system with base triggers requires only simple indicator features, POS tags, and 0.5 words per non-value predicate.
 ples.Table2comparestheempiricalresultsofthissplit.Weseethatoursystem(LJK11) with base triggers significantly outperforms CGCR10 (84% vs. 73.2%), and it even outperformstheversionofCGCR10thatistrainedusinglogicalforms(84.0%vs.80.4%).
Ifwe use augmented triggers, we widen the gap byanother 3.6percentage points. 4.2.2 State-of-the-Art Systems. We no wcompare our system (LJK11) with state-of-the-overvie wofthe systems: whereasoursystemlearnsonlyfromannotatedanswers.Ontheotherhand,oursystem doesrelyonafewmanuallyspecifiedlexicaltriggers,whereasmanyofthelatersystems role in the initial stages of learning because they constrain the set of candidate DCS trees; otherwise we would face a hopelessly intractable search problem. The other systems induce lexica using unsupervised word alignment (Wong and Mooney 2006, 2007; Kwiatkowski et al. 2010, 2011) and/or on-line lexicon learning (Zettlemoyer and
Collins 2005, 2007; Kwiatkowski et al. 2010, 2011). Unfortunately, we cannot use these automatic techniques because theyrely on having annotated logical forms. the accuracy of the logical forms: precision (the accuracy on utterances which are 434 successfully parsed) and recall (the accuracy on all utterances). We only focus on recall (a lower bound on precision) and simply use the word accuracy to refer to recall. system is evaluated only on answer accuracy because our model marginalizes out the latent logical form. All other systems are evaluated on the accuracy of logical forms. To calibrate, we also evaluated KZGS10 on answer accuracy and found that it was quite similar to its logical form accuracy (88.9% vs. 88.2%). 16 system would necessarily have a high logical form accuracy because multiple logical forms can produce the same answer, and our system does not receive a training signal to tease them apart. Even with only base triggers, our system (LJK11) outperforms all buttwoofthesystems,fallingshortofKZGS10byonlyonepercentagepoint(87.9%vs. 88.9%). 17 With augmented triggers, our system takes the lead (91.4% vs. 88.9%). and ZC05) are actually outperformed by P RECISE , which is able to use strong database type constraints. By exploiting this information and doing learning, we obtain the best results. 4.3 Empirical Properties
Inthissection,wetrytogainintuitionintopropertiesofourapproach.Allexperiments inthissectionwereperformedonrandomdevelopmentsplits.Throughoutthissection,  X  X ccuracy X  means development test accuracy. 4.3.1 Error Analysis. To understand the type of errors our system makes, we examined one of the development runs, which had 34 errors on the test set. We classified these errors into the following categories (the number of errors in each category is shown in parentheses): 436 4.3.2 Visualization of Features. Havinganalyzedthebehaviorofoursystemforindividual utterances, let us move from the token level to the type level and analyze the learned parameters of our model. We do not look at ra wfeature weights, because there are complex interactions between them not represented by examining individual weights. Instead, we look at expected feature counts, which we think are more interpretable. p ]: p  X  P } .Wedefinea distribution q (  X  )over J asfollows:
Think of q ( j ) as a marginal distribution (because all our features are positive) that represents the relative frequencies with which the features j our training data set D and trained model p ( z | x ,  X  Z between what this distribution and raw feature weights capture, suppose we had two features, j 1 and j 2 , which are identical (  X  ( x , z ) across the two features, but the features would have the same marginal distribution ( q ( j 1 ) = q ( j 2 )).Figure 23 shows some of the feature distributions learned. 4.3.3 Learning, Search, Bootstrapping. Recall from Section 3.2.1 that a training example is feasible (with respect to our beam search) if the resulting candidate set contains a
DCStreewiththecorrectanswer.Infeasibleexamplesareskipped,butanexamplemay become feasible in a later iteration. A natural question is ho wmany training examples are feasible in each iteration. Figure 24 shows the answer: Initially, only around 30% of the training examples are feasible; this is not surprising given that all the parameters are zero, so our beam search is essentially unguided. Training on just these examples improves the parameters, however, and over the next few iterations, the number of feasible examples steadily increases toaround 97%.
 needed to learn, but learning also improves search. The general approach is similar in spirittoSearn(Daume,Langford,andMarcu2009),althoughwedonothaveanyformal guarantees at this point.
 first,where easy isdefined bythe ability of beam search togenerate the correct answer.
Thisbootstrappingoccursquitenaturally:Unlikemostbootstrappingalgorithms,wedo not have to set a confidence threshold for accepting ne wtraining examples, something the beam search. 4.3.4 Effect of Various Settings. So far, we have used our approach with default settings (Section4.1.2).Howsensitiveistheapproachtothesechoices?Table5showstheimpact ofthefeaturetemplates.Figure25showstheeffectofthenumberoftrainingexamples, number of training iterations, beam size, and regularization parameter. The overall conclusion is that there are no big surprises: Our default settings could be improved on slightly, but these differences are often smaller than the variation across different development splits.
 given candidate sets (see Figure 21). Thus far, we have been using L-BFGS (Nocedal 1980), which is a batch algorithm. Each iteration, we construct the candidate 438 sets C ( t ) ( x ) for all the training examples before solving the optimization problem (SGD) (Robbins and Monro 1951), which updates the parameters after computing the candidate set for each example. In particular, we iteratively scan through the training examples in a random order. For each example ( x , y ), we compute the candidate set using beam search. We then update the parameters in the direction of the gradient of the marginal log-likelihood for that example (see Equation (72)) with step size t  X   X  :
The trickiest aspect of using SGD is selecting the correct step size: A small  X  leads to quick progress but also instability; a large  X  leads to the opposite. We let L-BFGS and
SGD both take the same number of iterations (passes over the training set). Figure 26 shows that a very small value of  X  (less than 0 . 2) is best for our task, even though only values between 0 . 5 and 1 guarantee convergence. Our setting is slightly different because we are interleaving the SGD updates with beam search, which might also lead to unpredictable consequences. Furthermore, the non-convexity of the objective function exacerbates the unpredictability (Liang and Klein 2009). Nonetheless, with aproper  X  , SGD converges much faster than L-BFGS and even to a slightly better solution. 5. Discussion
The work we have presented in this article addresses three important themes. The first theme is semantic representation (Section 5.1): Ho wdo we parametrize the mapping from utterances to their meanings? The second theme is program induction (Section 5.2):
How do we efficiently search through the space of logical structures given a weak feedbacksignal?Finally,thelastthemeis grounded language (Section5.3):Howdoweuse constraints from the world to guide learning of language and conversely use language tointeract with the world? 5.1 Semantic Representation
Since the late nineteenth century, philosophers and linguists have worked on elucidat-ing the relationship between an utterance and its meaning. One of the pillars of formal semantics is Frege X  X  principle of compositionality, that the meaning of an utterance is built by composing the meaning of its parts. What these parts are and ho wthey are composed is the main question. The dominant paradigm, which stems from the seminal work of Richard Montague (1973) in the early 1970s, states that parts are lambdacalculusexpressionsthatcorrespondtosyntacticconstituents,andcomposition isfunction application. 440 construe compositionality as factorization. Factorization, the way a statistical model breaks into features, is necessary for generalization: It enables us to learn from pre-viously seen examples and interpret ne wutterances. Projecting back to Frege X  X  orig-inal principle, the parts are the features (Section 3.1.1), and composition is the DCS construction mechanism (Section 2.6) driven by parameters learned from training examples.
 tation becomes designing a good statistical model. But statistical modeling must also deal with the additional issue of language acquisition or learning, which presents complications: In absorbing training examples, our learning algorithm must inevitably traverse through intermediate models that are wrong or incomplete. The algorithms must therefore tolerate this degradation, and do so in a computationally efficient way. For example, in the line of work on learning probabilistic CCGs (Zettlemoyer and
Collins 2005, 2007; Kwiatkowski et al. 2010), many candidate lexical entries must be entertained for each word even when polysemy does not actually exist (Section 2.6.4). 2011), but this is all done within the constraints of CCG. DCS represents a departure from this tradition, which replaces a heavily lexicalized constituency-based formalism with a lightly-lexicalized dependency-based formalism. We can think of DCS as a shift in linguistic coordinate systems, which makes certain factorizations or features more accessible. For example, we can define features on paths between predicates in a DCS tree which capture certain lexical patterns much more easily than in a lambda calculus expression or a CCGderivation.
 (Alshawi,Chang,andRinggaard2011),whichisalsomotivatedbythebenefitsofwork-ing with dependency-based logical forms. The goals and the detailed structure of the twosemanticformalismsaredifferent,however.Alshawi,Chang,andRinggaard(2011) focus on parsing complex sentences in an open domain where a structured database or world does not exist. Whereas they do equip their logical forms with a full model-theoreticsemantics,thelogicalformsareactuallyclosertodependencytrees:Quantifier scope isleft unspecified, and the predicates are simply the words. from Discourse Representation Theory (DRT) (Kamp and Reyle 1993) X  X ot from the treatment of anaphora and presupposition which it is known for, but something closer quantified and constraints are combined via conjunction X  X  Discourse Representation
Structure (DRS) in DRT, or a basic DCS tree with only join relations. Computationally, theselogicalstructuresconvenientlyencodeCSPs.Linguistically,itappearsthatexisten-tialquantifiersplayanimportantroleandshouldbetreatedspecially(KampandReyle 1993). DCS takes this core and focuses on semantic compositionality and computation, whereas DRT focuses more on discourse and pragmatics.
 ful to think about DCS from the perspective of programming language design. Two programming languages can be equally expressive, but what matters is how simple it is to express a desired type of computation in a given language. In some sense, we designedtheDCSformallanguagetomakeiteasytorepresentcomputationsexpressed bynaturallanguage.AnimportantpartofDCSisthemark X  X xecuteconstruct,auniform frameworkfordealingwiththedivergencebetweensyntacticandsemanticscope.This constructallowsustobuildsimpleDCStreestructuresandstillhandlethecomplexities of phenomena such as quantifier scope variation. Compared to lambda calculus, think of DCS as a higher-level programming language tailored to natural language, which results in simpler programs (DCS trees). Simpler programs are easier for us to work withand easier foranalgorithm tolearn. 5.2 Program Induction
Searching over the space of programs is challenging. This is the central computational challenge of program induction, that of inferring programs (logical forms) from their behavior (denotations). This problem has been tackled by different communities in various forms: program induction in AI, programming by demonstration in Human X 
Computer Interaction, and program synthesis in programming languages. The core computational difficulty is that the supervision signal X  X he behavior X  X s a complex function of the program that cannot be easily inverted. What program generated the output Arizona , Nevada ,and Oregon ? grams for not a single task but for multiple tasks. The intuition is that when the tasks are related, the solution to one task can help another task, both computationally in navigating the program space and statistically in choosing the appropriate program if parsingwork,wewanttoinferalogicalformforeachutterance(task).Clearlythetasks are related because they use the same vocabulary to talk about the same domain. tion (words) which can be used to guide the search. There have been several papers that induce programs in this setting: Eisenstein et al. (2009) induce conjunctive for-mulae from natural language instructions, Piantadosi et al. (2008) induce first-order logic formulae using CCG in a small domain assuming observed lexical semantics, and Clarke et al. (2010) induce logical forms in semantic parsing. In the ideal case, the words would determine the program predicates, and the utterance would determine the entire program compositionally. But of course, this mapping is not given and must be learned. 442 5.3 Grounded Language
In recent years, there has been an increased interest in connecting language with the world. 18 One of the primary issues in grounded language is alignment X  X iguring out what fragments of utterances refer to what aspects of the world. In fact, semantic parsers trained on examples of utterances and annotated logical form (those discussed in Section 4.2.2) need to solve the task of aligning words to predicates. Some can learn from utterances paired with a set of logical forms, one of which is correct (Kate and
Mooney 2007; Chen and Mooney 2008). Liang, Jordan, and Klein (2009) tackle the even more difficult alignment problem of segmenting and aligning a discourse to a database offacts, where many parts on either side are irrelevant.
 worldtoguidethelearningandinterpretationoflanguage.Wesawthattypeconstraints from the database/world reduce the set of candidate logical forms and lead to more accurate systems (Popescu, Etzioni, and Kautz 2003; Liang, Jordan, and Klein 2011).
Even for syntactic parsing, information from the denotation of an utterance can be helpful (Schuler 2003).
 it opens the door to many ne wtypes of supervision. We can obtain ans wers given a world,whicharecheapertoobtainthanlogicalforms(Clarkeetal.2010;Liang,Jordan, and Klein 2011). Other researchers have also pushed in this direction in various ways: learning a semantic parser based on bootstrapping and estimating the confidence of its own predictions (Goldwasser et al. 2011), learning a semantic parser from user interac-tionswithadialogsystem(ArtziandZettlemoyer2011),andlearningtoexecutenatural languageinstructionsfromjustarewardsignalusingreinforcementlearning(Branavan et al. 2009; Branavan, Zettlemoyer, and Barzilay 2010; Branavan, Silver, and Barzilay 2011). In general, supervision from the world is indirectly related to the learning task, but it isoften much more plentiful and natural toobtain.
 learnedtointerpretlanguagetotroubleshootaWindowsmachine(Branavanetal.2009;
Branavan,Zettlemoyer,andBarzilay2010),winagameofCivilization(Branavan,Silver, andBarzilay2011),playalegalgameofsolitaire(Eisensteinetal.2009;Goldwasserand
Roth2011),andnavigateamapbyfollowingdirections(VogelandJurafsky2010;Chen and Mooney 2011). Even when the objective in the world is defined independently of language (e.g., in Civilization), language can provide a useful bias towards the non-linguistic endgoal. 6. Conclusions
The main conceptual contribution of this article is a ne wsemantic formalism, dependency-based compositional semantics (DCS), and techniques to learn a semantic parser from question X  X nswer pairs where the intermediate logical form (a DCS tree) is induced in an unsupervised manner. Our final question X  X nswering system was able to matchtheaccuraciesofstate-of-the-artsystemsthatlearnfromannotatedlogicalforms. system (which can be construed as a natural language interface to a database) and open-domain question X  X nswering systems. The former focuses on understanding a question compositionally and computing the answer compositionally, whereas the lat-terfocusesonretrievingandrankinganswersfromalargeunstructuredtextualcorpus.
The former has depth; the latter has breadth. Developing methods that can both model the semantic richness of language and scale up to an open-domain setting remains an open challenge.

Neither DCS nor the learning algorithm is tied to having a clean rigid database, which couldinsteadbeadatabasegeneratedfromanoisyinformationextractionprocess.The key is to drive the learning with the desired behavior, the question X  X nswer pairs. The latent variable is the logical form or program, which just tries to compute the desired answerbypiecingtogetherwhateverinformationisavailable.Ofcourse,therearemany open challenges ahead, but with the proper combination of linguistic, statistical, and computational insight, we hope to eventually build systems with both breadth and depth.
 Acknowledgments References 444
