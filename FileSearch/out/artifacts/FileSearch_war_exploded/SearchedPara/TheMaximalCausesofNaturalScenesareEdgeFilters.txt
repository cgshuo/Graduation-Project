 puertas@fias.uni-frankfurt.de If Sparse Coding (SC, [1 ]) or Independent Compo nent Analysis (ICA; [2, 3 ]) are applied to image patches, basis functions a re inferred that closely re semble Gabor wavelet fu nctions. Because of the similarity of these functi ons to simple-cell recept ive fields in primary visu al cortex, SC and ICA became the standard mod els to explain simple-cell responses, and they are t he primary choice in modelling the local statis tics of natural images. S ince they were first intro duced, many different versions of SC and ICA have been investigated. W hile many studies focused on different ways to in the underlying generat ive model itself. The mod elling of observation nois e can thus be regarded as the major difference b etween SC and ICA (see, e.g., [7]). Furthermore, d ifferent forms of inde-pendent sparse priors hav e been investigated by m any modelers [8, 9, 10], while other approaches have gone a step further a nd studied a relaxation of the assumption of indepen dence between hidden variables [11, 12, 13]. An assumption that has, in the context of image s tatistics, been investigate d relatively little is the assumption of linear sup erpositions of basis funct ions. This assumption is not only a hallmark of SC and ICA but, indeed, is an essential part of man y standard algorithms inc luding Principal Com-ponent Analysis (PCA), Factor Analysis (FA; [14 ]), or Non-negative Matr ix Factorization (NMF; [15]). For many types of data, linear superposition can be motivated by the a ctual combination rule of the data components (e .g., sound waveforms com bine linearly). For other t ypes of data, including visual data, linear superp osition can represent a se vere approximation, how ever. Models assuming linearity are, nevertheles s, often used because the y are easier to study ana lytically and many de-rived algorithms can be a pplied to large-scale prob lems. Furthermore, they perform well in many applications and may, to certain extents, succeed w ell in modelling the distr ibution, e.g., of local image structure. From th e perspective of probabili stic generative models, a major aim is, however, [7]). To accomplish this , the crucial properties o f the data generation sho uld be modelled as re-alistically as possible. If the data components com bine non-linearly, this sh ould thus be reflected by the generative model. Unfortunately, inferring t he parameters in probabi listic models assuming non-linear superpositions has been found to be muc h more challenging than in the linear case (e.g. [16, 17, 18, 19], also com pare [20, 21]). To model image patches, for instan ce, large-scale applica-tions of non-linear model s, with the required large numbers of observed and hidden variables, have so far not been reported.
 In this paper we study th e application of a probab ilistic generative model w ith strongly non-linear superposition to natural image patches. The basi c model has first been su ggested in [19] where tractable learning algorith ms for parameter optimiz ation where inferred for the case of a superpo-sition based on a point-w ise maximum. The mode l (which was termed Maximal Causes Analys is ; MCA) used a sparse prio r for independent and bi nary hidden variables. T he derived algorithms compared favorably with state-of-the-art approache s on standard non-linear benchmarks and they were applied to realistic d ata. However, the still de manding computational c osts limited the appli-cation domain to relative ly small-scale problems. The unconstrained model for instance was used with at most H =20 hidden units. Here we u se a novel learning algori thm to infer the paramete rs of a variant of the MCA g enerative model. The app roach allows for scaling t he model up to several hundreds of observed and hidden variables. It enabl es large-scale application s to image patches and, thus, allows for studying the inferred basis function s as it is commonly done for linear approaches. bution (  X  X  ( n )  X  D  X  1 , D is the number of observe d variables). For these da ta we seek parameters  X =( W, X , X  ) thatmaximizethedatalik elihood L =  X  N n =1 p (  X  X  ( n ) |  X ) underavariantoftheMC A generative model [19] wh ich is given by: and where N ( y d ; w, X  2 ) denotes a scalar Gaussia n distribution. H denotes the number of h idden of Gaussian noise instea d of Poisson noise in [1 9]. Eqn.2 results in the basis functions  X  W h = ( W 1 h ,...,W Dh ) T of the MCA model to be c ombined non-linearly by a point-wise maximum. T his becomes salient if we co mpare (2) with the linear case using the vectorial n otation max h {  X  W  X   X  max h { W  X  where N (  X  X  ;  X  X ,  X ) denotes the multi-variat e Gaussian distribution ( note that  X  As in linear approaches s uch as SC, the combined basis functions set the m ean values of the ob-served variables y d , which are independentl y and identically drawn from Gaussian distributio ns Figure 1: A Example patches extrac ted from an image and p reprocessed using a Diff erence of Gaussians filter. B Two generated patches c onstructed from two Gabo r basis functions with app rox-imately orthogonal wave vectors. In the upper-righ t the basis functions were combined using linear superposition. In the low er-right they were combi ned using a point-wise m aximum (note that the max was taken after channel-s plitting (seeEqn.15 and F ig.2). C Superposition of twocoll inear Ga-bor functions using the s um (upper-right) or point -wise maximum (lower-r ight). D Cross-sections through basis functions ( along maximum amplitu de direction). Left: Cros s-sections through two different collinear Gabor functions (compare C). R ight: Cross-sections throu gh their superpositions using sum (top) and max (bottom). with variance  X  2 (Eqn.2). The difference b etween linear and non-lin ear superposition is illust rated in Fig.1. In general, the maximum superposition results in much weaker in terferences. This is the case for diagonally overla pping basis functions (Fig .1B) and, at closer inspec tion, also for overlap-ping collinear basis funct ions (Fig.1C,D). Strong i nterferences as with linea r combinations can not be expected from combin ations of image compone nts. For preprocessed im age patches (compare Fig.4D), it could thus be argued that the maximum combination is closer to t he actual combination rule of image causes. In any case, the maximum r epresents an alternative to study the implications of combination rules in th e image domain.
 Tooptimizetheparamete rs  X  oftheMCAmodel(1)an d(2),weuseavariational EMapproach(see, e.g., [22]). That is, instea d of maximizing the likel ihood directly, we maxim ize the free-energy: in the M-step (while q is kept fixed). As a multi ple-cause model, an exac t E-step is computationall y intractable forMCA. Add itionally, theM-stepisan alytically intractable beca use ofthenon-linearity in MCA. The computati onal intractability in the E-step takes the form of expectation values of functions g ,  X  g (  X  X  )  X  algorithm, our approach a pproximates the intractab le expectations  X  g (  X  X  )  X  over the hidden space of  X  X  : where K n is a small subset of the hidden space. Eqn.6 rep resents a good approxim ation if the set
K n contains most of the pos terior probability mass. The approximation will be referred to as Expectation Truncation and can be derived as a variational EM approach (see Suppl.A). For other generative models similar truncation approa ches have successfully b een used [19, 23]. For the learning algorithm, K n in (6) is chosen to contai n hidden states  X  X  with at most  X  active causes  X  formally we define: where the index set I contains those H  X  hidden variables that are the most likely to have ge nerated evaluated). To determine the H  X  hidden variables for I we use those variables h with the H  X  largest values of a selection function S h (  X  X  ( n ) ) which is given by: p ( s h =1 |  X  X  ( n ) ,  X ) of for most data points Eqn. 6 with Eqn.7 indeed final ly approximates the true e xpectation values with high accuracy.
 Having derived tractable approximations for the e xpectation values (6) in the E-step, let us now derive parameter update equations in the M-step. An update rule for the w eight matrix W of this model was derived in [19 ] and is given by: where the parameter  X  is set to a large value (w e used  X  =20 ). The derivation of the u pdate rule for  X  (Gaussian noise has prev iously not been used) is s traight-forward, and the u pdate equation is given by: ( |M| is the number of elemen ts in M ). The subset contains th e data points for which ( 6) finally represents a good approx imation. It is defined to contain the N cut data points with largest v alues  X  expected number of data points that have been gen erated by states with less or equal to  X  non-zero entries: The selection of data poi nts is an important differ ence to earlier truncation approaches (compare [19, 23]), and its necessit y can be shown analytica lly (Suppl.A).
 Update equations (9), (10 ), and (11) have been der ived by setting the deriva tives of the free-energy (w.r.t. W and  X  ) to zero. Similarly, we c an derive the update equa tion for the sparseness pa rameter  X  . However, as the approxi mation only considers sta tes  X  X  witha maximum of  X  non-zero entries, the update has to correct for an underestimation of  X  (compare Suppl.A). If s uch a correction is taken into account, we obtain th e update rule: N cut = N ). For  X  = H  X  = H , Eqn.13 thus falls back t o the exact EM update rul e that can canonically  X  between one and H we can thus choose the accuracy of the used app roximation. The higher t he valueof  X  themoreaccurateisthea pproximationbutthelarg erarealsothecomputatio nalcosts. For intermediate values of  X  we can obtain very good approximations with sma ll computational costs. Crucial for the scalabilit y to large-scale problems is hereby the preselectio n of H  X  &lt;H hidden variables using the select ion function in Eqn.8.
 Figure 2: Illustration of patch preprocessing and basis function visualizati on. The left-hand-side shows data points obtain ed from gray-value patch es after DoG filtering. T hese patches are trans-formed to non-negative d ata by Eqn.15. The algo rithm maximizes the data likelihood under the MCA model (1) and (2), and infers basis functions (second from the right). For visualization, the basis functions are displa yed after their parts have been recombined again. Theupdateequations(9), (10),(11),and(13)togeth erwithapproximation(6) with(7)and(8)define a learning algorithm that optimizes the full set of p arameters of the MCA ge nerative model (1) and (2). We will apply the alg orithm to visual data as re ceived by the primary vis ual cortex of mammals. In mammals, visual infor mation is transferred to t he cortex via two types o f neurons in the lateral geniculus nucleus (LGN) : center-on and center-off cells. The sensitivity of ce nter-on neurons can be modeled by a Difference of Gaussians (DoG) filter with positive central part, while the sensitivity of center-off cells can be mo delled by an inverted suc h filter. A model for prep rocessing of an image patch is thus given by a D oG filter and a successive splitting of the positive a nd the negative parts of the filtered image. Mo re formally, we use a DoG filter to generate patches  X   X  X  with  X  D =26  X  26 pixels. Such a patch is the n converted to a patch of size D =2  X  D by assigning: (for d =1 ,...,D ) where [ x ] + = x for x  X  0 and [ x ] + =0 otherwise. This proced ure has repeatedly been used in t he context of visual data processing (see, e.g., [24 ]) and is, as discussed, closely aligned with mam malian visual preprocessi ng (see Fig.2 for an illust ration).
 Before we applied the a lgorithm to natural imag e patches, it was first e valuated on artificial data with ground-truth. As inferred basis functio ns of images most comm only resemble Gabor wavelets, we used Gabor functions for the generati on of artificial data. The Gabor basis functions were combined according to the MCA generative m odel (1) and (2). We use d H gen = 400 Gabor functions for generation. The variances of the Ga ussian envelop of each G abor were sampled from a distribution in n x /n y -space (Fig.3C) with  X  x and  X  y denoting the standard de viations of the Gaussian envelop e, and with f denoting the Gabor fre quency. Angular phases and cen-ters of the Gabors were sampled from uniform d istributions. The wave vector X  X  module was set to 1 ( f = 1 same range as the parame ters inferred in preliminar y runs of the algorithm on natural image patches. Forthegenerationofeach artificialpatchwedrewa binaryvector  X  X  accordingto(1)with  X H gen = 2 . We then selected the |  X  X  | corresponding Gabor fun ctions and used channel-splitting (15) to convert them into basis functions with only non-negative pa rts. To form an artificial p atch, these basis func-tions were combined usin g the point-wise maximu m according to (2). We g enerated N = 150000 patches as data points in t his way (Fig.3A shows so me examples).
 The algorithm was applie d with H = 300 hidden variables and app roximation parameters  X  = 3 and H  X  = 8 . We generated the data w ith a larger number of bas is functions to better matc h the continuous distribution of the real ge nerating components of i mages. The basis functio ns  X  W h were initialized A C B by setting them to the av erage over all the preproc essed input patches plus a small Gaussian white noise (  X  0 . 5% of the corresponding mea n). The initial noise param eter  X  was set following Eqn.1 1  X H =2 . Themodelparametersw ereupdatedaccordingtoE qns.9to13using 60 EMiterations. To help avoiding local optim a, a small amount of Gau ssian white noise (  X  0 . 5% of the average basis function value) was adde d during the first 20 iterations, was linearly decreased to zero betwee n updates considered all N data points ( |M| = N ). Between iteration num ber 20 and 40 the amount of used data points was li nearly decreased to ( |M| = N cut ) where it was kept const ant for the last 20 iterations. Considering a ll data points for the upda tes initially, has proven b eneficial because the selection of data points is based on very incomplete knowledge during the firs t iterations. Fig.3B displays some of the typical basis function s that were recovered in a run of the algorithm on artificial patches. As can be observed (and as could have been expected ), they resemble Gabor functions. When we ma tched the obtained basis functions with Gabor fun ctions (compare, e.g., [25, 26, 27] for details), the Gabor parameters ob tained can be analyzed fu rther. We thus plotted the values parameterizing the Gabor shapes in an n x /n y -plot. This also allowed us to investigate how well the generating distribution of artificial G abors was recovered. Fig .3C shows the gener-ating (green) and the reco vered distribution of Gab ors (blue). Although som e few recovered basis recovered sparseness leve l was with  X H =2 . 62 a bit larger than the initi al level of  X H gen =2 . This is presumably due t o the smaller number of basis function in the mo del H&lt;H gen . Also this mismatch. Dependin g on the parameters of th e controls, we can observ e different amounts of outliers (usually not more than 5%  X  10% ). These outliers are usua lly basis functions that re present more than one Gabor or s mall Gabor parts. Import antly, however, we found that the large majority ular, when we changed th e angle of the generating distribution in the n x /n y -plots (e.g., to 25 o or 65 o ), the angle of the recove red distributions changed accordingly. Note that th ese controls are a quantitative version of the artificial Gabor and gratin g data used for controls in [1]. Application to Image Pa tches. The dataset used in the e xperiment on natural ima ges was prepared by sampling N =200000 patches of  X  D =26  X  26 pixels from the van Hate ren image database [28] (while constraining random selection to patch es of images without man -made structures). We preprocessedthepatches asdescribedaboveusing aDoGfilter 1 witharatioof 3:1 betweenpositive and negative parts (see, e .g., [29]) before convertin g the patches using Eqn.1 5.
 The algorithm was applie d with H =400 hidden variables and app roximation parameters  X  =4 and H  X  =12 . We used parameter in itialization as described above and ran 120 EM iterations (also as described above ). After learning the inf erred sparseness level wa s  X H =1 . 63 and the inferred noise level was  X  =1 . 59 . The inferred basis func tions we found to resemb led Gabor-like functions at different lo cations, and with differe nt orientations and frequ encies. Additionally, we obtained many globu lar basis functions with no or very little orientat ion preferences. Fig.4 shows a selection of the H =400 functions after a run of the algorithm (see suppl. Fig.C.1 for Figure 4: Numerical exp eriment on image patche s. A Random selection of 12 5 basis functions of lection of preprocessed p atches extracted from nat ural images. E Selection of data points g enerated according to the model us ing the inferred basis func tions and sparseness level (but no noise). all functions). The patch es in Fig.4D,E were cho sen to demonstrate the h igh similarity between preprocessed natural patc hes (in D) and generated ones (in E). To highlight t he diversity of obtained basis functions, Figs.4B, C display some of the mo st globular and elongated examples, respectively. The variety of Gabor sha pes is currently actively discussed [30, 31, 10, 32 , 27] since it became obvious that standard lin ear models (e.g., SC and ICA), could not explain this diversity [33]. To facilitate comparison wit h earlier approaches, we have applied Gabor mat ching (compare [25]) and analyzed the obtaine d parameters. Instead of matching the basis funct ions directly, we first computed estimates of the ir corresponding receptive fields (RFs). These estim ates were obtained by convoluting the basis fun ctions with the same DoG filter as used for preproce ssing (see, e.g., [27] and Suppl.C.1 for details ). In controls we found th at these convoluted fields were closely matched by RFs estimated using re verse correlation as descr ibed, e.g., in [7].
Figure 5: Analysis of G abor pa-rameters ( H = 400 ). A Angle-frequency plot of basis f unctions.

B n x /n y distribution of basis functions. C Distribution mea-sured in vivo [33] (red triangles) and corresponding distri bution of MCA basis functions (blu e).
 After matching the (conv oluted) fields with Gabor functions, we found a re latively homogeneous distribution of the fields X  orientations as it is comm only observed (Fig.5A). The frequencies are analyzetheGaborshapes ,weplottedtheparameter susingan n x /n y -plot(assuggestedin[33] ). The broad distribution in n x /n y -space hereby reflects the high diversity of basis fu nctions obtained by our algorithm (see Fig.5B ). The specific form of th e obtained shape distribu tion is, hereby, similar to the distribution of mac aque V1 simple cells as m easure in in vivo recordings [33]. Howeve r, the MCA basis functions do q uantitatively not match th e measurements exactly ( see Fig.5C): the MCA distribution contains a h igher percentage of stron gly elongated basis func tions, and many MCA functions are shifted slig htly to the right relative to the measurements. If the basis functions are matched with Gabors dir ectly, we actually do not observe the latter effect ( see suppl. Fig.C.2). If simple-cell responses are associated with the poste rior probabilities of mult iple-cause models, the basisfunctionsshould, ho wever, notbecomparedto measuredRFsdirectly(al thoughitisfrequently done in the literature). To investigate the implica tions of different number s of hidden variables, we also ran the algorithm with H =200 and H =800 . In both cases we obser ved qualitatively and qua ntitatively similar distributions of basis fun ctions. Runs with H =200 thus also contained man y circular symmetric basis functions (see supp l. Fig.C.3 for the distribu tion of shapes). This obs ervation is remarkable because it shows that suc h  X  X lobular X  fields are a v ery stable feature for the MCA approach, also for small numbers of hidden variables. Based on stand ard generative models wi th linear superposition it has recently been argue d [32] that such functions are only obtained in a reg ime with large numbers of hidden variables relativ e to the input dimensiona lity (see [34] for an early contribution). We have studied the app lication of a strongly non -linear generative model to image patches. The model combines basis fu nctions using a point-wis e maximum as an alterna tive to the linear com-bination as assumed by S parse Coding, ICA, and m ost other approaches. Ou r results suggest that changing the component combination rule has a s trong impact on the distr ibution of inferred ba-sis functions. While we still obtain Gabor-like fu nctions, we robustly obs erve a large variety of basis functions. Most no tably, we obtain circular symmetric functions as w ell as many elongated functions that are closely associated with edges tra versing the entire patch (c ompare Figs.1 and 4). Approaches using linear component combination, e.g. ICA or SC, do usual ly not show these fea-tures. The differences in b asis function shapes betw een non-linear and linear approaches are, in this respect, consistent with th e different types of interf erences between basis fun ctions. The maximum results in basis function c ombinations with much l ess pronounced interferen ces, while the stronger (compare Fig.1).
 For linear approaches, a l arge diversity of Gabor sh apes (including circular s ymmetric fields) could only be obtained in very over-complete settings [3 4], or specifically modell ed priors with hand-set sparseness levels [10]. S uch studies were motivat ed by a recently observed discrepancy of recep-tive fields as predicted by SC or ICA, and receptive fields as measured in vivo [33]. Compared to these measurements, the M CA basis functions and th eir approximate receptive fields show a similar diversity of shapes. MC A functions and measure d RFs both show circula r symmetric fields and in both cases there is a te ndency towards fields elo ngated orthogonal to the wave-vector direction (compare Fig.4). Possibl e factors that can influenc e the distributions of basi s functions, for MCA as and different noise mode ls. Even if the prior type is fixed, differences for th e basis functions have been reported for differe nt settings of prior param eters (e.g., [10]). If poss ible, these parameters should thus be learned al ong with the basis functi ons. All the different fac tors named above may result in quantitative diff erences, and the shift of the MCA functions relati ve to the measurements might have been caused b y one of these factors. Fo r the MCA model, possib le effects of assuming binary hidden variables r emain to be investigated. Presumably, also depend encies between hidden structures of specific arra ngements of edges and te xtures are considered. As the components in such models are combined les s randomly, the implicati ons of their combination rule may even be more pronounced in these case s.
 In conclusion, probably neither the linear nor th e maximum combination rule does represent the exact model for loc al visual component com binations. However, wh ile linear component combinations have exten sively been studied in the context of image statistic s, the investigation of other combination rules has been limited to relat ively small scale applica tions [17, 16, 35, 19]. Applying a novel trainin g scheme, we could ove rcome this limitation in the case of the MCA generative model. As wit h linear approaches, we fo und that Gabor-like basis functions are obtained. markedly different, howe ver. Future work should, thus, at least be aware tha t a linear combination of components is not the only possible choice. To recover the generating ca uses of image patches, a linear combination mig ht, furthermore, not be th e best choice. With the r esults presented in this work, it can neither be co nsidered as the only pract ical one anymore.

