 Conventional classification methods tend to focus on features of in-dividual objects, while missing out on potentially valuable pairwise features that capture the relationships between objects. Although recent developments on graph regularization exploit this aspect, ex-isting works generally assume only a single kind of pairwise fea-ture, which is often insufficient. We observe that multiple, hetero-geneous pairwise features can often complement each other and are generally more robust in modeling the relationships between objects. Furthermore, as some objects are easier to classify than others, objects with higher initial classification confidence should be weighed more towards classifying related but more ambiguous objects, an observation missing from previous graph regularization techniques. In this paper, we propose a Dirichlet-based regular-ization framework that supports the combination of heterogeneous pairwise features with confidence-aware prediction using limited labeled training data. Next, we showcase a few applications of our framework in information retrieval, focusing on the problem of query intent classification. Finally, we demonstrate through a series of experiments the advantages of our framework on a large-scale real-world dataset.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Design, Experimentation, Performance graph regularization, pairwise features, confidence, query intent classification, applications in information retrieval  X  W ork done during an internship at Microsoft Research.

Many applications in information retrieval (IR) call for effective classification techniques. For instance, the problem of text cate-gorization is fundamental to a myriad of real-world tasks, such as automated email organization, spam detection, and information fil-tering. As another example, fine-grained query intent classification enables a search engine to direct users to the intended search verti-cals, greatly enhancing user experience.

While any conventional machine learning algorithm can be used for classification in IR applications, straightforward adaptation is generally unfruitful, since there exist challenges beyond traditional classification tasks. One prominent issue is the sparsity of fea-ture vectors. For instance, in our query intent classification dataset, about 95% of the queries contain no more than five words.
Recent developments in graph-based regularization [20, 18, 2, 3] somewhat tackles the problem of feature sparsity. Instead of object-level features that are independently extracted from each object, we now consider pairwise features that are extracted from each pair of objects. Hence, each object can potentially be paired with any other object for feature extraction. In this work, we employ pairwise fea-tures derived from similarity functions between objects, such that a graph can be constructed by linking similar objects with edges. The edges can be used to propagate classification evidence from one ob-ject to another based on the key assumption of consistency  X  X imilar objects are likely to have similar class labels [20]. In other words, the classification of an object can be  X  X elped X  or regularized by its neighbors on the graph. In comparison, conventional classifica-tion algorithms cannot easily incorporate pairwise features without blowing up the parameter space and subsequently requiring more labeled training data.

Given the above benefits, graph-based regularization has also been adopted in IR applications, most notably through the use of a click graph [12, 7, 11] in query intent classification. A click graph usually consists of queries and websites as its vertices. A query q and a website w are connected by an edge if q results in a click landing on w . Intuitively, two queries connected to the same website are related, and thus should share a similar prediction.
While making the same assumption of consistency, we are moti-vated by two core observations, which entail key intuitions towards a more effective graph-based regularization framework.

First , most existing regularization framework only deals with a single kind of pairwise feature. However, heterogeneous pairwise features often exist. For instance, in query intent classification, queries can be related through not only clicks, but also other pair-wise features, including lexical similarity ( X  X cer laptop X  and  X  X ap-top X  are related due to word overlap), co-session (the second query could be a refinement of the first in the same session), and the simi-larity of search result pages (two queries that retrieve simi lar pages may be similar themselves). These different pairwise features po-tentially complement each other, as some may only cover a small fraction of all queries ( e.g. , not all shopping queries have associ-ated product clicks). In addition to sparsity, some pairwise features may lack the robustness to capture similarities between two ob-jects. E.g. , while both queries  X  X p 3 in 1 X  and  X  X anon printer X  refer to printers, they contain no common words and thus their similar-ity cannot be represented by lexical pairwise features. To support heterogeneous pairwise features, the challenge lies in how different similarity functions can be aggregated to optimize the regulariza-tion, which is missing from previous regularization frameworks.
Second , in existing graph regularization, the extent to which the classification of an object o influences o 0 only depends on their sim-ilarity. Greater similarity between o and o 0 means that they have stronger influences on each other. While this is reasonable, a sec-ond factor, largely overlooked by previous work, is the confidence of classification. If we are more confident about the prediction on o , we expect it to influence its neighbors on the graph more. On the other hand, if we are unsure about the prediction on o , we should minimize its influence. In other words, we use objects that are eas-ier to classify (with higher classification confidence) to help predict harder ones (with lower classification confidence), but less so the other way round. Existing regularization works do not provide for a mechanism to incorporate classification confidence. In contrast, our modeling of objects with Dirichlet priors allows us to interpret the observation counts as confidence.

Finally, another challenge of classification lies in the require-ment of a large amount of labeled training data, especially in real-world IR applications with a large number of classes. Our experi-ments on query intent classification involve 2043 classes, and thus require much more labeled training queries than, say, a binary clas-sification task. Our framework deals with the shortage of labeled training data in two ways. To begin with, like other graph-based regularization frameworks ( e.g. , [20, 18]), classification evidence is propagated across the graph along the edges. By using more un-labeled data, we generally obtain a denser graph that promotes such propagation, and hence improve the performance. Our experiments show that adding more unlabeled data yields superior results, de-spite using the same set of labeled training data. Next, our frame-work allows for fewer parameters, independent of the number of classes. Hence, even with limited training data and a large number of target classes, our technique is effective.

In this paper, we propose a regularization framework that can be applied to different applications, hinged on our insights above. To summarize, we make the following contributions: Pairwise features. Many IR classification tasks are plagued by feature sparsity. Thus, a significant amount of research has studied augmenting the feature vector ( e.g. , [4, 16, 15, 5] for query-intent classification). Unfortunately, these techniques are generally not universal to other classification tasks. Driven by the hypothesis that  X  X imilar objects share similar labels X  [20], we consider pairwise features that allow for feature extraction from any pair of objects, potentially expanding the feature space.

Although it is difficult to incorporate pairwise features in con-ventional classification algorithms without blowing up the parame-ter space, they have been used in recent graph-based regularization frameworks [20, 18, 2, 3] and related random walk approaches [17, 7]. Examples of their applications in IR include the use of click graphs [12, 10, 7, 11] in query intent classification, and document affinity matrices [8, 9] in text retrieval. However, unlike this pa-per, most of these works do not consider heterogeneous pairwise features, which complement each other and thus play an important role in improving classification accuracy. While a recent work [11] explores a content-based pairwise feature in addition to co-clicks, its treatment is limited as it lacks a mechanism to effectively aggre-gate arbitrary pairwise features. In particular, their parameters are manually selected, making it difficult to extend to more pairwise features. In comparison, we learn the parameters via an iterative optimization process.
 Confidence. Existing regularization frameworks [20, 18, 2, 3] and their task specific realizations ( e.g. , [12, 10, 7, 11] for query in-tent classification and [8, 9] for text retrieval) do not recognize the importance and hence take advantage of the classification confi-dence associated with objects. We observe the need of confidence-aware regularization, and exploit it to improve classification accu-racy. Specifically, we are more confident about objects that are easier to classify, which should have a larger influence towards the prediction of their neighbors.
 Limited training data. To deal with the shortage of labeled train-ing data, many task specific techniques exist ( e.g. , [1, 12, 13, 15] for query-intent classification). However, they are often highly tailored and cannot be easily extended to a generic framework. In our framework, we benefit from using more unlabeled data by exploiting the relationships between objects, leveraging the semi-supervised nature of graph-based regularization [20, 18, 2, 3]. In addition, our framework involves a small parameter space indepen-dent of the number of target classes, and thus performs well even with limited training data and thousands of target classes. In this section, we develop our graph regularization framework. It is universal to different classification tasks, including our exam-ple application on query intent classification in Sect. 4.
Given a set of objects O and a set of classes C , each object o  X  O has some distribution over C . We regularize the class distribution of o by the class distributions of objects similar to o , i.e. , adjust the prediction on o according to objects similar to it. To start, we capture objects and their pairwise similarity features using a graph. Next, based on the graph, we introduce our regularization model.
We model objects and their pairwise features with a graph G = ( O, R ) . O is the set of objects that define the vertices . R is the set of relationships between objects that describe the edges of the graph, which are derived from the pairwise features between ob-Figure 1: Example graph for classification of shopping querie s. jects. We use the toy graph in Fig. 1 for the task of query intent classification in the shopping domain as our running example. Vertices. Each object or the target entity of classification is a vertex on the graph. For example, the query  X  X anon X  in Fig. 1 is a vertex to be classified as a digital camera or inkjet printer, among others. Edges. An edge on the graph is represented as a triplet ( o, o R , which models the relationship between two objects o and o based on a pairwise feature  X  . Unlike traditional object-level fea-tures that are independently extracted from each object ( e.g. , words in each document in text classification),  X  is in fact a feature defined on a pair of objects that describes their mutual similarity. Concep-tually,  X  can be understood as a particular similarity function on two objects. For instance, as Fig. 1 illustrates, it can be the cosine similarity between the word vectors of two queries (lexical pair-wise feature), or the number of co-clicks for two queries (co-click pairwise feature). Thus, there can exist as many edges between two objects as the number of pairwise features, such as between  X  X anon X  and  X  X anon sd1000 X  in Fig. 1.

The strength of a relationship is encoded as the non-negative weight of its corresponding edge ( o, o 0 ,  X  ) , and is thus a func-tion of the two objects o, o 0 and the pairwise feature  X  , denoted as W ( o, o 0 ,  X  ) . W ( o, o 0 ,  X  ) can be understood as the similarity be-tween o and o 0 with respect to  X  . By convention, W ( o, o iff the edge ( o, o 0 ,  X  ) /  X  R . In this paper, we consider bi-directional, symmetric relationships, which have equal strengths in both direc-tions, i.e. , W ( o, o 0 ,  X  ) = W ( o 0 , o,  X  ) .
Given K target classes { 1 , . . . , K } , each object o  X  O has an underlying probability distribution over the K classes that captures the possible user intents. E.g. , in Fig. 1 the distribution for the query cating that the user may be looking for a digital camera with prob-ability 0 . 3 , an inkjet printer with probability 0 . 2 , etc.
As such a distribution is inherently latent, we undertake a  X  X istri-bution over distributions X  instead. Specifically, we model the class distribution of each object o using a Dirichlet prior Dir (  X  rameterized by a vector  X  o = (  X  o [1] , . . . ,  X  o [ K ]) . Informally, it describes the distribution over all possible latent class distribu-tions of o , given that each class i  X  X  1 , . . . , K } has been observed  X  [ i ]  X  1 , potentially fractional, times. The Dirichlet prior also conveniently allows us to treat the total count of observations  X  the classification confidence X  X e are more confident in the prior if  X  is larger. We call  X  o the prior confidence of o :
In particular, we only consider unimodal Dirichlet priors, i.e. ,  X  i  X  { 1 , . . . , K } ,  X  o [ i ] &gt; 1 , such that  X  o scribe later, such a prior may be derived from an initial object-level classifier or previous iterations of the regularization algorithm.
Given a prior over possible class distributions for an object o , we can treat its neighbors as additional evidence to support its clas-sification. In particular, we consider the neighbors as observation data, weighted by their similarity, from which we can compute a posterior distribution over possible class distributions for o . Alter-natively, we can interpret this as a form of regularization in that the original belief on o is regularized by the belief on its neighbors.
Let N ( o ) denote the set of neighbors of o on the graph. Specif-ically, for each neighbor o 0  X  N ( o ) , we can interpret its Dirichlet prior Dir (  X  o 0 ) as observing  X  o 0 [ i ]  X  1 instances of class i for each of the K classes when drawing  X  o 0 instances from the underlying multinomial distribution for o 0 . Under the assumption that similar objects share similar labels and hence observations, we deem that each neighbor o 0 contributes to the classification of o an observation of S ( o, o 0 )(  X  o 0 [ i ]  X  1) counts for each of the K classes, weighted by the similarity S ( o, o 0 ) between o and o 0 . As o can be connected to o 0 via multiple pairwise features, we define the similarity be-tween the two objects as a linear combination of their similarity W ( o, o 0 ,  X  ) across all pairwise features: where each  X   X  is a parameter specifying the overall influence of  X  towards S ( o, o 0 ) . We will learn these parameters in Sect. 3.3 to optimize the regularization.

Since the Dirichlet distribution is conjugate to the multinomial distribution, factoring in additional multinomial observations still results in a Dirichlet posterior. Specifically, given a Dirichlet prior Dir (  X  ) , the posterior distribution after observing  X  [ i ] counts in each class i is simply Dir (  X  +  X  ) , where  X  = (  X  [1] , . . . ,  X  [ K ]) . Hence, for an object o with prior Dir (  X  o ) , the additional weighted observation data from each neighbor o 0 would give us the Dirichlet posterior Dir ( b  X  o ) , where:
Similar to the prior confidence (Eq. 1), we can compute the pos-terior confidence for the object o as below:
However, since all observations are potentially noisy in practice, having more neighbors and hence more observation data does not necessarily imply a higher posterior confidence. As a heuristic, we normalize the observation data by the number of contributing objects weighted by their similarity, S o = 1 + This results in a normalized Dirichlet posterior Dir ( e  X  malized posterior confidence e  X  o for each object o : e  X  o  X  1 =
Intuitively, this normalization step causes observations from neigh-bors of o to  X  X djust X  our confidence in o (Eq. 6), rather than to raise it monotonically in the unnormalized version (Eq. 4).
We can understand Eq. 5 as a form of regularization. Informall y, our original belief on object o , as prescribed by its prior Dir (  X  is regularized by its neighbors, which change our belief and pro-duce the regularized distribution Dir ( e  X  o ) . Note that in the special case that o has no neighbors ( N ( o ) =  X  ), Eq. 5 would give us e  X  o =  X  o , i.e. , no regularization is done.
 Confidence-aware prediction. Given the regularized Dirichlet dis-tribution Dir ( e  X  o ) for an object o , we can make a prediction on o by first choosing the most likely class distribution, i.e. , the mode distribution e m o of Dir ( e  X  o ) . Subsequently, we assign classes to o according to e m o , say, by taking the top k classes with the largest probabilities in e m o , or all classes above a given probability thresh-old. Since e  X  o [ i ] &gt; 1 ,  X  i , the mode has a closed form solution: where e  X  o is the normalized posterior confidence of o in Eq. 6.
Unlike previous regularization frameworks [20, 18, 2, 3], the prediction by e m o is confidence-aware , as we will now demonstrate. Dividing both sides of Eq. 5 by e  X  o , we obtain:
In Eq. 8, the left hand side is simply e m o . On the right hand side,  X  o  X  1 =  X  o m o ,  X  o  X  O , where m o is the mode distribution of Dir (  X  o ) . Moreover, taking Eq. 6 into consideration, Eq. 8 can be further expressed as:
Similar to the harmonic method [20], Eq. 9 implies that the reg-ularized mode e m o is a weighted average of the original (unregular-ized) modes m o and m o 0 ,  X  o 0  X  N ( o ) . However, unlike [20], the weight on each neighbor o 0 is S ( o, o 0 )  X  o 0 , which factors in both the similarity S ( o, o 0 ) and the confidence  X  o 0 . Hence, our model is confidence-aware, i.e. , objects with higher confidence  X  weighed more in the regularization. As motivated in Sect. 1, such a property is desirable, since an object with low confidence would potentially introduce noise and thus its influence should be down-played. On the other hand, [20] and other regularization models [18, 2, 3] only assign weights according to the similarity between the objects, without utilizing the confidence.
 Alternative interpretation. Our regularization (Eq. 5) is equiv-alent to the minimization of a cost function, the essence of many graph-based regularization frameworks [20, 18, 2, 3]. Specifically, we minimize the following function over e  X  o ,  X  o  X  O :
E = 1 where k X k is the Euclidean distance. Intuitively, the regularization should not change the original belief on o too much, i.e. , we want Dir ( e  X  o ) to be close to the prior Dir (  X  o ) . Additionally, Dir ( e  X  should be close to the prior Dir (  X  o 0 ) of each neighbor o from which observations are contributed towards o .

To see the equivalence, we minimize E by setting its derivative with respect to e  X  o to zero: which is algebraically equivalent to Eq. 5.
In the above model (Eq. 5), an object o is only regularized by its neighbors on the graph. In most scenarios, indirectly related objects, such as  X  X eighbors of neighbors X , also provide additional evidence for o . The evidence from  X  X eighbors of neighbors X  can be captured by regularizing Dir ( e  X  o ) again. In general, we propose an iterative regularization algorithm, which can potentially model the evidence from any object with a path to o on the graph.
 Iterative regularization. As our regularized distribution Dir ( e  X  is also Dirichlet, we can feed it back as input for regularization again in the exact same way as we have done in Sect. 3.2.1, treat-ing Dir ( e  X  o ) as the new Dirichlet prior for o . The process can be repeated for any number of iterations.

Let  X  (0) o ,  X  o denote the Dirichlet parameter of the initial prior for an object o . Furthermore, let  X  ( t ) o be the regularized Dirichlet parameter after t iterations,  X  t &gt; 0 . Similar to Eq. 5, it is easy to see that  X  t  X  1 ,  X  o  X  1 =
As shown, we only need to know the Dirichlet parameters from the previous iteration to compute  X  ( t ) o . To start the iterative pro-cess, we bootstrap from t = 0 by specifying  X  (0) o ,  X  o, for the ini-tial prior of each object. How they are initialized is an orthogonal issue to our regularization framework. Different strategies may be applied based on the application, as we will discuss in Sect. 4.
Finally, we make predictions using the mode distributions after t iterations of regularization, m ( t ) o = (  X  ( t ) o  X  1 ) / X  manner as discussed in Sect. 3.2.1.
 Number of iterations. The iterative regularization process can be interpreted as a form of information propagation on the graph. In each iteration, information is propagated from each object to its neighbors. The propagation is repeated such that indirectly related objects are also affected through longer-range dependencies.
The total number of iterations T is an important parameter to de-cide, with similar effects as the length parameter in random walks [17, 7]. In particular, when T = 1 , it reduces to a simple weighted voting by neighbors. But as T  X   X  ,  X  ( T ) o becomes the same for every object o in each connected component of the graph, similar to what have been discussed in [17, 7].

Intuitively, if T is too small, only very short-range dependencies can be captured, ignoring potentially useful long-range ones. On the other hand, if T is too large, all dependencies regardless of its range will be captured, making the result less discriminative. Thus, an optimal T would ensure a desirable trade-off between short and long-range dependencies. While the optimal T can be selected ei-ther manually [7] or heuristically [17], we propose to learn it in the next subsection.
In addition to the total number of iterations T , each pairwise feature  X  has a parameter  X   X  that specifies the overall influence of  X  towards the similarity between two objects (Eq. 2). Thus, our parameters are T and  X  , where  X  , {  X   X  :  X   X  } .

We propose to learn the parameters with a heuristic objective function defined on only T and  X  . Since |  X  | is generally small as restricted by the number of possible pairwise features between ob-jects (in our experiments |  X  | = 2 ), only a few labeled objects are needed for learning. In comparison, traditional supervised classifi-cation techniques train a model for each target class. In real-world applications where the number of target classes is large ( K = 2043 in our experiments), an enormous amount of training data would be required, as we would expect at least a few labels for each class. On the other hand, with our heuristic objective function, we require far fewer than K to achieve good classification accuracy.

Our first attempt defines a global error function to optimize the parameters. However, due to computational challenges, we sub-sequently propose a local error function for the dynamic selection of parameters in each iteration. As the parameters are chosen to minimize the error functions, any existing numerical optimization technique can be used. In particular, we apply Powell X  X  method [14] to solve the optimization problem.
Given a labeled training set O L  X  O , and an initialization for the Dirichlet parameters  X  = {  X  (0) o : o  X  O } at t = 0 , we can define an error function as the minimization objective: where m ( T |  X  ,  X ) o denotes the mode after T iterations of regular-ization (using Eq. 12), with the initialization  X  and parameters  X  . u  X  o is the  X  X old standard X  distribution derived from the labels of o . k  X  k is the Euclidean distance. (Note that alternative dis-tance measures such as KL-divergence may also be used.) We se-lect parameters that minimize this global error, i.e. , {  X  arg min  X  ,T G err ( O L ,  X  ,  X  , T ) .
 When T = 1 , m ( T |  X  ,  X ) o can be computed for all o  X  O only the neighbors of objects in the labeled training set O T = 2 , we need to consider  X  X eighbors of neighbors X  as well. For larger T  X  X , we potentially need to compute iteratively over the en-tire graph of labeled and unlabeled objects. This makes the compu-tation of the error function very costly. As many optimization tech-niques require repeated computation of G err (  X  ) for different values of  X  and T , such an error function is computationally infeasible.
As an efficient alternative to minimizing the global error, we propose an algorithm where we regularize the Dirichlet parameters  X  o (Eq. 12) and update the parameters  X  in alternating fashion. In each iteration, we regularize the classification using the  X  learned from the previous iteration. As the Dirichlet distribution on every object changes after regularization, we update  X  by minimizing the error function for the next iteration. This is similar in spirit to the Expectation-Maximization (EM) algorithm. However, unlike EM which maximizes the likelihood function of the parameters, we are minimizing an error function. Our approach involves the following two steps in each iteration t,  X  t  X  0 : (1) Regularization step. If t = 0 , initialize  X  (0) o ,  X  o  X  O , ac-(2) Minimization step. To update  X  for the next iteration, we
Although in the regularization step, we still need to update the entire graph, it is acceptable as it is done only once per iteration. In contrast, to solve the optimization problem in each minimiza-tion step, the error function has to be computed numerous times. Thus it is important the error function involves only light-weight computation. Our local error function (Eq. 14) is defined using the global error function (Eq. 13) with T = 1 , which can be easily computed using only the neighbors of the objects in the training set O
L , where typically | O L || O | . E.g. , in most of our experiments, | O L | is less than 0.1% of | O | .

Another distinction in our iterative optimization is that we do not explicitly learn T , the maximum number of iterations. In-stead, we terminate the iterations when the minimum local error min  X  L ( t ) err (  X  ) converges. Although such convergence is guaranteed as established below, similar to EM, there is no guarantee that the global minimum min  X  ,T G err (  X  ) can be achieved.
 Proposition 1: As defined in Eq. 14, the sequence of local mini-mum errors { min  X  L ( t ) err ( O L ,  X ) }  X  t =1 converges to a finite limit. P
R OOF : Let  X  0 denote that all parameters  X   X  are zero. Then,
Note that (  X  ) holds since  X  0 implies that no regularization is done X  X e get the same error as the minimum error of the previous iteration. Thus, the sequence is monotonically non-increasing. Ad-ditionally, the minimum error is bounded from below by zero. Any bounded monotone sequence converges to a finite limit.
W e now discuss the applications of the regularization framework on real-world classification tasks in information retrieval. We first formalize what components of the regularization framework must be realized in any application. Next, we showcase a specific appli-cation on query intent classification in the shopping domain, fol-lowed by brief discussions of applications on other tasks. Finally, we describe the target scenarios of our applications.
Realizing our regularization framework requires a vertex model and one or more edge models .
 Vertex model. As we see in Eq. 12, to enable iterative regular-ization, we need an initial model for t = 0 , characterized by the Dirichlet parameters  X  (0) o ,  X  o  X  O . Since each object o is a ver-tex in the graph, we call this initialization a vertex model . As  X  o =  X  (0) o m (0) o + 1 , which entails both the mode distribution and the confidence, we can equivalently set  X  (0) o by initializing m o and  X  (0) o separately, as we do in Sect. 4.2.
 Edge model. In Sect. 3, the strength of a relationship between two objects o, o 0 is abstracted into a weight function W ( o, o where  X  is the pairwise feature that induces the relationship. Since relationships are edges on the graph, we call the realization of the weight function W ( q, q 0 ,  X  ) for a pairwise feature  X  an edge model .
We address the problem of query intent classification in the shop-ping domain. Given a query q  X  Q from a query log of an e-commerce website, and a set of K predefined product categories, the task is to map the query to a product category, with a limited amount of labeled queries. Additional resources such as exis ting product metadata may also be leveraged. In the following, we present how we can realize the vertex and edge models for this task. Note that the set of queries Q in the given query log form the vertices on the graph instead of the generic objects O in Sect. 3. Vertex models. Any conventional query classification algorithm can be used to initialize the mode m (0) q for each query q  X  Q , as long as the output of the algorithm can be converted to a probability distribution over the K categories, which is taken as the most likely distribution, i.e. , the mode distribution m (0) q . We first introduce a vertex model based on unigram language models, followed by possible alternatives.
 Language Vertex Model. As input, we leverage existing product metadata from online shopping sites such as Bing Shopping product is associated with metadata that include attributes such as name, brand and description, as well as the category to which the product belongs. From this data, we build a unigram language model  X  i for each category i  X  { 1 , . . . , K } based on all observed words from the attribute values of the products in that category, weighted by product popularity. Given a query q , to estimate m we evaluate the query likelihood p ( q |  X  i ) ,  X  i , and convert it to a probability distribution over categories by applying Bayes X  rule: mated by the total popularity of all products in each category.
On the other hand, to initialize the confidence, we build a back-ground model  X  b by considering all products in our metadata. The intuition is that queries with a lower background model likelihood are easier to classify, as a low likelihood means that the words in the query are rare and more likely to be identified as belonging to those few categories that contain these rare words, resulting in higher classification confidence. On the other hand, a high likeli-hood implies that the query words are very common and appear in many categories, leading to lower confidence classification. Empir-ical study shows that the probability of a correct classification of a query is fairly correlated with its negative log likelihood. Thus, we initialize the confidence as follows:
The language vertex model only requires a weak supervision from the product metadata, which is available from shopping web-sites. No training labels for individual queries are needed. Alternative Vertex Models. To initialize the mode distribution, we can also use supervised but substantially more accurate classifiers. The disadvantage of using a supervised classifier is that it requires a large amount of labeled training queries to achieve good classifi-cation accuracy. However, after applying our regularization frame-work, using the weakly supervised unigram models can achieve comparable results to using a well-trained fully supervised classi-fier for the vertex model, as we shall observe in the experiments.
Eq. 15 is only a simple heuristic for the purpose of initializing the distribution confidence. Other heuristics can be used, such as the query length (longer queries provide additional features to guide its classification), or the consistency of the outputs from multiple classifiers (queries with more consistent outputs are arguably eas-ier to classify). However, developing more theoretical confidence estimation methods, such as those explored by works on query dif-ficulty [6], is beyond the scope of this paper.
 Edge models. Among many possible pairwise features between queries, we focus on the lexical (  X  lex ) and co-click (  X  h ttp://www.bing.com/shopping Lexical Edge Model. Given two queries q and q 0 from a query log, we can view each as a set of words, denoted by  X  ( q ) and  X  ( q respectively. We can then define the lexical edge model as follows:
This edge model is a symmetric, binary similarity measure: we draw an edge between two queries if one of them contains all words in the other. E.g. , W (  X  X anon X  ,  X  X anon camera X  ,  X  lex W (  X  X anon printer X  ,  X  X anon camera X  ,  X  lex ) = 0 .

Although this edge model is simple, it is more effective in pre-liminary experiments than other more sophisticated models such as cosine similarity. One possible explanation is that our binary simi-larity results in less noise than cosine similarity.
 Co-click Edge Model. We can also establish relationships between queries using co-click pairwise features. Intuitively, if two queries have more clicks that land on product pages belonging to the same category, they are more closely related. In many cases, we may only be able to deduce that two clicks lead to the same category ( e.g. , they land on the same URL, or URLs with the same prefix such as example.com/digital_camera/... ), but we may not know the actual category, or how to map the vendor category to ours. For-mally, we define the co-click edge model as follows, adapted from the co-citation/click measures in [19, 10]:
In this edge model, each c is a category, which could be a  X  X irtual category X  with no direct correspondence to a target category, for reasons discussed above.  X  q  X  Q , #( q, c ) denotes the number of clicks associated with query q that leads to category c . N is the total number of clicks across all queries, whereas N c is the number of total clicks that lead to category c . Thus, N/N c has an effect similar to inverse document frequency, i.e. , more popular categories contribute less to the similarity between two queries. We also use a logarithm function to model a sublinear growth of the similarity with respect to the number of clicks.
 Additional Edge Models. The following pairwise features can also be considered, although they are not used in our experiments.
We briefly discuss how we can realize our regularization frame-work on other applications in IR. As discussed in Sect. 4.2.1, the vertex model is often easy to realize using an existing classifier for the initial mode distribution and various heuristics for the initial confidence. Hence, for the following applications, we only discuss the choice of the pairwise features for their edge models, which are often neglected in conventional classification.
 Offer classification. Given a product offer from a vendor, which is presented as a list of attribute-value pairs ( e.g. , product name, brand, image, description, as well as product-specific attributes such as focal length for cameras), the task is to map it to our predefi ned categories. (Imagine we are an e-commerce website receiving feeds on offers from different vendors, whose attribute schemas and cat-egory taxonomies vary.) The following pairwise features could be used: (i) the graphical similarity between two product images; (ii) the overlap of product-specific attribute names, since products from the same category often share similar attribute names even across vendors; (iii) lexical similarity between the names and descriptions of two products.
 Text classification. This is a classic task in IR that assigns each document to a class. With additional resources such as access statistics, social media and embedded hyperlinks, we suggest the following pairwise features: (i) co-readership, the number of read-ers who accessed both of the two documents within some time win-dow; (ii) social tagging, the distributional similarity of the user tags on social sharing sites; (iii) hyperlinks in the documents, where similar documents likely point to similar pages; (iv) lexical simi-larity in the contents of two documents.
As our regularization framework requires multiple iterations over the entire graph G = ( O, E ) , it is not intended for online classi-fication. Instead, it is designed for offline computation, where the precomputed predictions for each object in O is stored in an index. Given a seen object o ( i.e. , o  X  O ), its precomputed prediction is directly fetched from the index. If o is previously unseen ( i.e. , o /  X  O ), we can use the vertex model to classify it on-the-fly. Al-ternatively, we may potentially look up o  X  X  neighbors on the graph using an inverted index, locality sensitive hash, or other means, and subsequently regularize the classification of o using its neighbors for one iteration online.

As an example, let us consider a real scenario involving a live search system on the task of query intent classification. In this situation, as time passes, the live system collects a growing amount of data, including queries and clickthroughs. Thus, it is ideal if our regularization framework can be applied periodically offline (say, on a daily or weekly basis), in order to leverage more data and update the precomputed index accordingly. As our experiments show (Sect. 5.3), our approach runs fast enough on a single machine to be computed daily for at least tens of millions of queries.
Alternatively, we can apply our framework and take objects with highly confident predictions as labeled training data. Using these automatically generated training data, we can iteratively train a su-pervised classifier, extending the approach described in [12].
To analyze the performance of our regularization framework, we conduct extensive experiments on our showcase application of query intent classification, using a large scale real-world dataset.
The objective of our experiments is to validate that the proposed framework can utilize heterogeneous pairwise features as well as classification confidence to improve the performance, especially in a scenario with limited training data. This objective cannot be ac-complished by comparing our approach with existing state-of-the-art techniques for query intent classification. Instead, we choose different schemes of our framework as the baselines ( e.g. , using the same framework, but we assume only one kind of pairwise feature or uniform confidence). Note that in each iteration, our framework makes a similar form of updating on the predictions (Eq. 9) as the well-known graph regularization method Harmonic [20]. Hence, different schemes of our framework are well represented baselines for existing graph regularization techniques.
Figure 2: Examples of (a) lexical and (b) co-click neighbors. Dataset. We obtain a hierarchy of product categories from Bing Shopping. As our regularization framework targets generic classi-fication problems, which may not have hierarchical categories as labels, we use only the most detailed 2043 leaf categories ( i.e. , K = 2043 ), instead of taking advantage of the category taxonomy. Thus, our task is to predict the leaf category for each query.
In our experiments, we use a query log containing four million distinct queries. Some of these queries have been labeled by human judges, which we split into two disjoint subsets for training and testing. Specifically, the training set consists of 10 K labeled queries for parameter learning, and the test set consists of over 10 K labeled queries for evaluation. Although we reserve 10 K labeled queries for training, we only use 1 K of them in all experiments except in Sect. 5.2.4, where we vary the number of training queries. We also use clickthrough data to build the co-click edge model. There are about 11 million clicks associated with about 1 / 4 of all queries. The fact that most queries do not have any click motivates the necessity of heterogeneous pairwise features.
 Vertex model. Unless otherwise stated, we use the language vertex model (Sect. 4.2.1) in all experiments, which is weakly supervised and requires no labeled training queries. However, to demonstrate the robustness of our framework, we also compare it with an alter-native vertex model in Sect. 5.2.2.
 Evaluation metrics. For each query, we sort the categories ac-cording to their predicted probabilities, from which we can apply the following metrics.
We first present some illustrative results, providing insights on why our approach works.
 Query 1:  X  X anon 35 X . This query is misclassified as camcorder by the unigram language model, since both words in the query are not sufficiently discriminative. However, its lexical neighbors re-veal some interesting information, as illustrated in Fig. 2(a). Given these neighbors, it is not surprising that our approach can correctly classify this query as camera-lens .
 Query 2:  X  X p laptop hard drive X . This query is misclassified as laptop by the unigram model, since the words  X  X p laptop X  strongly suggest laptops. This time, its co-click neighbors, as shown in Fig. 2(b), allow our approach to correctly classify it as hard-drive .
We compare our approach to the vertex model and regularization baselines that only consider one kind of pairwise feature. Overall results. The results are reported in Fig. 3 and 4. While all regularization methods generally outperform the unigram model especially at high recall levels, we make two further observations.
First , neither Reg-Lex nor Reg-Click clearly dominates the other, which only uses lexical and co-click features, respectively. Nor-mally we would expect Reg-Click to perform much better than Reg-Lex, since the former uses co-click pairwise features, a form of user feedback that may be more indicative than pairwise lexi-cal features. For instance, many queries may be lexically similar yet unrelated ( e.g. ,  X  X aptop X  and  X  X aptop bag X ), or related but ex-hibit no lexical similarity ( e.g. ,  X  X p 3 in 1 X  and  X  X anon printer X ). Instead, our results can be explained by the sparsity of the click-through data, where only 1 / 4 of the queries have received at least one click, but almost all queries have lexically similar neighbors.
Second , by using both pairwise features, our approach performs substantially better than Reg-Lex and Reg-Click. One reason is that a single kind of pairwise feature cannot cover all queries. A second reason is that the combined evidence of both pairwise features is more informative than any single one alone, thus directly improv-ing queries that have both features and indirectly improving queries that connect to neighbors with both features.
 Result breakdown. We further analyze the performance on two subsets of queries X  X ueries with clicks and ones without X  X s shown in Fig. 5. As expected, Reg-Click performs well for queries with clicks, but has no effect on queries without clicks. On the other hand, Reg-Lex improves the accuracy for both subsets of queries. It is not surprising that our approach outperforms both Reg-Click and Reg-Lex for queries with clicks, since in this subset, both pairwise features improve the classification accuracy. However, we also out-performs all baselines for queries without clicks, although using co-click pairwise features alone has no effect on this subset. In this case, because classification evidence is iteratively propagated across all edge models in our approach, improvements to queries with clicks will influence their lexical neighbors, not all of which may have clicks. By combining heterogeneous pairwise features, we can extend the reach of each individual pairwise feature to in-Figure 5: Accuracy comparison for queries with/without clic ks. fluence and improve the performance of more queries via heteroge-neous long-range dependencies.
 Alternative vertex model. To demonstrate the robustness of our framework, we also evaluate our approach with an alternative re-gression vertex model . Specifically, we initialize the modes using a supervised logistic regression model (Regression) trained from a large number of labeled queries, with query words as features. To initialize the confidence, we use the query length as a heuristic, as empirical study suggests a correlation between longer queries and better classification accuracy of the regression model X  X onger queries contain more word features to guide the classification. The results of using the regression vertex model are shown in Fig. 6. Similar to using the language vertex model as reported in Fig. 4, our approach outperforms the baselines by a clear margin, even though the improvements are not as substantial. We expect such results, since the regression model is a much stronger model than the unigram model, and is thus harder to improve upon. This is analogous to ensemble methods in machine learning, where it is generally easier to improve over weak learners than strong learn-ers. Interestingly, despite initializing from a much stronger vertex model, the final results from regularizing the regression model is only slightly better than those from regularizing the unigram model. Thus, subsequent experiments use the language vertex model, which enjoys the additional benefit of being weakly supervised.
Next, we investigate the effect of the confidence initialization on regularization. Specifically, we compare our heuristic method in Eq. 15 (Heuristic) with the following two strategies.

We call the first strategy NoConf, which uses the same frame-work as ours, except that no confidence information is applied. In other words, uniform confidence is used to initialize each query.
We label the second strategy Simulated, which also uses the same framework as ours. However, we initialize the confidence differently, since our confidence estimation (Eq. 15) is only a sim-ple heuristic. To minimize the adverse effect of weak confidence Figure 6: Accuracy comparison with regression vertex model.
Figure 7: Accuracy with different confidence initialization s. estimation, we generate more reliable confidence values via a sim-ulation. Specifically, for each labeled query, we sample a random value x from two Gaussian distributions. If the top-1 category pre-dicted by the unigram model is correct, then x  X  N (0 . 8 , 0 . 1) ; otherwise, x  X  N (0 . 2 , 0 . 1) . Subsequently, we initialize the confi-dence of the labeled query with x , clipped to the range [0 , 1] . For each unlabeled query, we initialize its confidence to 0.512, which is the top-1 accuracy of the unigram model on the test queries.
The results of the different confidence initialization strategies are presented in Fig. 7. Although Heuristic only uses a simple heuris-tic (Eq. 15) to initialize the confidence, it performs better than No-Conf, which is not confidence-aware. On the other hand, Simulated performs the best, since it initializes confidence in a more reliable way. Thus, with more sophisticated confidence estimation, we can expect even better results from our framework.
In the following experiments, we vary the amount of data in three aspects: the number of labeled training queries, total queries, and clickthroughs. It is important to study the effects of varying the amount of data, since in practical scenarios, data is collected from a live system gradually.
 Number of training queries. Recall from Sect. 3.3, we require some labeled queries as training data in order to learn the parame-ters  X  . We examine the number of training queries needed to reach convergence on accuracy. Varying from 10 to 10 K training queries, we record the corresponding performance in Fig. 8(a). The results reveal that with merely 10 training queries, we can already achieve a substantial improvement over the unigram baseline. Furthermore, with as few as 100 training queries, the performance has nearly converged. Considering that 100 is much smaller than the 2043 categories in this classification task, we demonstrate that our model requires very few training queries indeed. This is not surprising as we are not directly modeling the categories, which would require 2000 + training queries at the minimum, one for each category. In-stead, we use the training queries only to learn  X  , the weights of pairwise features. Coupled with the weakly supervised language vertex model, our approach reaches convergence with very few training queries in total.
 Number of total queries. The majority of our queries are unla-beled and not directly used for parameter learning. However, as we increase the number of unlabeled queries, we also improve the con-nectivity of the graph. To evaluate the effect, we randomly sample a subset of all queries, and apply our approach using this subset as the total set of queries. The sample size varies between 1% and 100% of all queries. To eliminate any differences due to labeled training queries, our samples include the same set of 1 K training queries throughout. The results are presented in Fig. 8(b). Despite using the same set of training queries, the accuracy of our approach increases as the amount of total queries used increases. Although
Figure 8: Accuracy versus amount of training/total queries.
Figure 9: Accuracy versus the amount of clickthroughs. m ost of the improvement is achieved when the amount of queries is initially increased from 1% to 20% , further increases result in smaller but continual improvements. From this trend, we expect that the accuracy can be further improved, but to a lesser extent, with an even larger query set.
 Number of clickthroughs. Finally, we investigate the effect of varying the number of clickthroughs. Specifically, we randomly sample between 0% and 100% of clickthroughs from our query log, while using all queries and the same set of training queries. Fig. 9(a) and (b) illustrate the effect the amount of clickthroughs has on Reg-Click and our approach 2 , respectively. In both methods, using a larger number of clickthroughs improves accuracy. Similar to the effect of increasing the number of total queries, the improve-ments diminish as more clickthroughs are used. Nevertheless, the improvements have not converged, suggesting that additional click-through data will further increase performance.
Although our regularization framework is designed to be applied offline periodically (Sect. 4.3), efficiency is still important. For instance, to apply it daily, it shall not take longer than a day. The following experiments evaluate the efficiency of our approach.
As our approach is iterative, the number of iterations required to achieve convergence is crucial to efficiency. Our experiments show that convergence is fast, with 2 to 4 iterations in most settings. In particular, when using all available data, Fig. 10(a) illustrates the convergence of classification accuracy with a precision-recall plot. Iteration-0 corresponds to the initial vertex model. Regularization in Iteration-1 results in a larger improvement, whereas Iteration-2 shows smaller improvement. There is virtually no improvement from Iteration-3 (not shown in the figure), which indicates that the T he number of clickthroughs does not affect the performance of Reg-Lex, which only utilizes lexical pairwise features.
Figure 10: Convergence of (a) accuracy; (b) minimum error.
Figure 11: Execution time versus amount of total queries. a ccuracy has converged. From another perspective, Fig. 10(b) il-lustrates the sequence of minimum errors in each minimization step (Eq. 14), which converges after only 3 iterations.
We start with a simple complexity analysis. As we scan all edges and vertices of the graph once in each iteration, the complexity is O (( E + V ) T ) , where T is the number of iterations, E is the number of edges and V is the number of vertices ( i.e. , queries). E poten-tially increases faster than V  X  X he number of edges introduced by a new query potentially grows with the number of existing queries. Hence, the overall execution time would grow faster than a linear rate as we introduce more queries. Note that we do not consider the time to build the graph, which can be incrementally constructed whenever a new query is collected. Thus, it is unnecessary to build the graph from scratch every time.

In Fig. 11, we record the execution time on a single 8 -core PC with 32 GB memory. Consistent with our analysis above, the execu-tion time grows slightly faster than a linear rate against the number of total queries. Nevertheless, when all four million queries are used, the execution time is just under 20 minutes. This is a reason-able time frame for our framework to be applied frequently ( e.g. , on a daily basis), at least on the scale of tens of millions of queries. Furthermore, as the number of new queries within a fixed time interval tends to decrease over time, the total number of queries should grow sublinearly. Lastly, as Sect. 5.2.4 shows, including more queries brings in gradually less boost in accuracy. Thus, we do not expect to handle an arbitrarily large number of queries, since it would not achieve a noticeable benefit beyond a certain point.
In this paper, we proposed a Dirichlet-based graph regulariza-tion framework, driven by our key observations on heterogeneous pairwise features and confidence-aware classification. Building on the proposed framework, we discussed example realizations of sev-eral real-world IR tasks, particularly query intent classification in the shopping domain. Finally, we conducted extensive experiments on a large-scale real-world dataset to verify our observations. With limited training data, our approach effectively leverages heteroge-neous pairwise features and classification confidence. [1] S. Beitzel, E. Jensen, O. Frieder, D. Lewis, A. Chowdhury, [2] M. Belkin, I. Matveeva, and P. Niyogi. Regularization and [3] M. Belkin, P. Niyogi, and V. Sindhwani. Manifold [4] A. Broder, M. Fontoura, E. Gabrilovich, A. Joshi, [5] H. Cao, D. Hu, D. Shen, D. Jiang, J. Sun, E. Chen, and [6] D. Carmel and E. Yom-Tov. Estimating the query difficulty [7] N. Craswell and M. Szummer. Random walks on the click [8] F. Diaz. Regularizing query-based retrieval scores.
 [9] F. Diaz. Improving relevance feedback in language modeling [10] X. He and P. Jhala. Regularized query classification using [11] M. Ji, J. Yan, S. Gu, J. Han, X. He, W. Zhang, and Z. Chen. [12] X. Li, Y. Wang, and A. Acero. Learning query intent from [13] X. Li, Y. Wang, and A. Acero. Extracting structured [14] W. Press, S. Teukolsky, W. Vetterling, and B. Flannery. [15] D. Shen, Y. Li, X. Li, and D. Zhou. Product query [16] D. Shen, J. Sun, Q. Yang, and Z. Chen. Building bridges for [17] M. Szummer and T. Jaakkola. Partially labeled classification [18] D. Zhou, O. Bousquet, T. Lal, J. Weston, and B. Sch X lkopf. [19] D. Zhou, B. Sch X lkopf, and T. Hofmann. Semi-supervised [20] X. Zhu, Z. Ghahramani, and J. Lafferty. Semi-supervised
