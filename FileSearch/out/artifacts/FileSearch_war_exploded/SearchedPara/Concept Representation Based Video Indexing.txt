 This poster introduces a novel concept-based video indexing approach. It is developed based on a rich set of base con-cepts, of which the models are available. Then, for a given concept with several labeled samples, we combine the base concepts to fit it and its model can thus be obtained ac-cordingly. Empirical results demonstrate that this method can achieve great performance even with very limited labeled data. We have compared different representation approaches including both sparse and non-sparse methods. Our con-clusion is that the sparse method will lead to much better performance.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Index X  indexing methods Algorithms, Experimentation Video indexing, concept detection, sparse representation
As has long been acknowledged, the central problem of content-based video search is the semantic gap which lies between low-level features and high-level queries. Concept-based video indexing is a promising approach to bridging the gap. Typically, concept-based indexing is accomplished by machine learning methods. Since the to-be-indexed concepts are not mutually exclusive, a general scheme is to conduct a binary classification for each concept. A training set is gathered for each concept and models are learned from these data. Then these models are used to detect the concepts for newly coming video units.

Extensive research has been dedicated to the learning-based concept detection [2][5][4]. However, the existing re-sults are still not satisfying and the detection performance usually highly relies on the number of training samples. Re-cently, many studies reveal that exploring the correlation among concepts is a possible approach to boosting the con-cept detection performance. These methods can mainly be Figure 1: The illustrative scheme of concept repre-sentation based indexing categorized into two approaches: Context Based Concept Fusion (CBCF) [2][5] and correlative concept learning [4]. The first approach adopts a post-processing step to refine the results obtained by individual concept models, whereas the second approach directly explores the concept relationship in the learning process. These two approaches have shown encouraging performance, but a limitation is that they need to establish all the to-be-indexed concepts. That means, if a new concept is added into the lexicon, then the CBCF or correlative concept learning has to be re-implemented to take it into account. In this paper, we investigate a novel concept representation approach for video indexing. The basis of this scheme is a rich set of base concepts, such as an ontology. Then, given an out-of-set concept with several la-beled samples, we can represent it as a  X  X inear combination X  of the base concepts through regression methods. Therefore, we only have to train accurate models for the base concepts, and then the model of any new concept can be easily ob-tained by combining the base models, as illustrated in Fig. 1. It is worth noting that actually this scheme and the tra-ditional CBCF or correlative concept learning are aiming at different targets, although they are all developed by leverag-ing the relationship of concepts. The CBCF and correlative concept learning aim to obtain better indexing results for a fixed concept set, whereas our proposed approach aims to better index new concepts.

For the specific concept representation approach, in this study we have compared three different methods: least square regression, ridge regression and Lasso. Experiments demon-strate that the Lasso algorithm performs much better than the other two methods due to its sparsity property. Consider a concept set that contains m base concepts C = { c 1 , c 2 , . . . , c m } , of which the models f i available. Then we are given a new concept c . Suppose these concepts have all been annotated on a dataset X = { x 1 , x 2 , . . . , x n } . Define an n  X  m matrix Y where y if x j is positive for base concept c i , and otherwise y Denote by v the label vector of concept c , i.e., v i = 1 if x relevant with respect to c and other wise v i = 0. Then the concept representation is formulated as fitting v by combin-ing the column vectors of Y .

This task can actually be accomplished by different regres-sion methods. In this work we compare three different algo-rithms: least square regression, ridge regression and Lasso. These methods can be formulated in a general regularization framework as where  X  is the weighting vector and R (  X  ) is a regularizer on  X  . The three representation methods actually only differ in the form of R (  X  ), i.e., where k . k 2 and k . k 1 indicate L2-norm and L1-norm, respec-tively. Existing studies reveal that the L1-norm of  X  can lead to sparsity in terms of  X  , i.e., only a subset of  X  is non-zero [6]. Therefore, Lasso can be regarded as a sparse representation method, whereas the other two methods are non-sparse.

For least square and ridge regression, their closed-form so-lution can be directly obtained from Eq. (1). For Lasso, we apply the optimization method proposed in [6]. After solving  X  , the model of the target concept can be directly obtained by combining the base models, i.e., f ( x ) =
We conduct experiments on the benchmark video corpus of TRECVID 2005 which contains 61901 sub-shots [1]. A set of 374 concepts (a subset of LSCOM) have been anno-tated on these data [7], and Yanagawa et al. have provided SVM models for these concepts (we name them Columbia SVM models in the following discussion). They separate the dataset into four partitions, including a  X  X raining set X  with 41847 sub-shots, a  X  X alidation set X  with 7022 sub-shots, a  X  X usion set X  with 6525 sub-shots, and a  X  X esting set X  with 6507 sub-shots. The Columbia SVM models are learned from the samples of training set with three feature sets: 225D grid color moment, 73D edge direction histogram and 48D Gabor texture.
 In our experiments, we test the indexing of 39 concepts of LSCOM-Lite [3] on the testing set, and we regard the other 374-39 = 335 concepts as the base concepts. That means, for each of the 39 LSCOM-Lite concepts, we represent it by the 335 base concepts and then obtain its model by fusing the 335 Columbia SVM models. We implement the three different representation methods with varied numbers of la-beled samples that are randomly selected from the training set. The parameter  X  in Eq. (1) is simply set to 100. It is
Figure 2: MAP comparison of different methods worth noting that here the number of labeled samples is only for the 39 concepts, and the models of the base concepts are learned on all the training set of 41847 sub-shots. This is sensible since the base concepts can serve any new concept in our scheme, and thus we can gather more training data for them in order to obtain accurate models.

For comparison, we also learn SVM models for the 39 con-cepts with the labeled data. We adopt RBF kernel and the parameters are tuned on the validation set. We adopt Aver-age Precision (AP) and Mean Average Precision (MAP) as our performance evaluation metrics. Experimental results are illustrated in Fig. 2. From the results we can clearly see the superiority of the representation-based methods over SVM. Among the three representation methods, Lasso con-sistently outperforms the other two methods. This can be attributed to the sparsity property of Lasso (the advantage analysis of  X  X parsity X  can be found in [6] can the references therein). We can see that the Lasso-based concept repre-sentation method can achieve an MAP measure of 0.305 with only 600 labeled samples. This is a surprisingly good performance considering the limited labeled data. In our experiments, the SVM models need more than 16,000 train-ing samples to achieve this performance (the performance of Columbia SVM models, which have used 41,847 training samples, is about MAP 0.388).
This research is partly supported by FY08-RES-THEME-072 from Microsoft Research Asia.
