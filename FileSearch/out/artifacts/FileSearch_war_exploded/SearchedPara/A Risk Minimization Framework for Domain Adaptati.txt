 Supervised learning algorithms usually require high quality labeled training set of large volume. It is often expensive to obtain such labeled examples in every domain of an applica-tion. Domain adaptation aims to help in such cases by utiliz-ing data available in related domains. However transferring knowledge from one domain to another is often non triv-ial due to different data distributions among the domains. Moreover, it is usually very hard to measure and formu-late these distribution differences. Hence we introduce a new concept of label-relation function to transfer knowledge among different domains without explicitly formulating the data distribution differences. A novel learning framework, Domain Transfer Risk Minimization (DTRM), is proposed based on this concept. DTRM simultaneously minimizes the empirical risk for the target and the regularized empiri-cal risk for source domain. Under this framework, we further derive a generic algorithm called Domain Adaptation by La-bel Relation (DALR) that iteratively updates the target hy-pothesis function and outputs for the source domain until it converges. We provide an in-depth theoretical analysis of DTRM and establish fundamental error bounds. We also experimentally evaluate DALR on the task of ranking search results using real-world data. Our experimental results show that the proposed algorithm effectively and robustly utilizes data from source domains under various conditions: differ-ent sizes for source domain data; different noise levels for source domain data, and different difficulty levels for target domain data.
 H.4 [ Information Systems Applications ]: Miscellaneous; I.5.1 [ Pattern Recognition ]: Models-statistical algorithms domain adaptation, risk minimization, label-relation, source domain, target domain
In most supervised learning settings, a learner is provided with some solved cases (examples and corresponding labels) and is supposed to learn how to solve new cases. We use the term  X  X abels X  to refer to both class labels for classification task and real valued targets for regression task. For example, in learning to rank search results, a learner is provided with relevance judgments for a set of query document pairs. This labeling is done usually by human experts, which is quite expensive and time consuming. Moreover, we may not have enough resources and human experts in every domain to create sufficiently large, good quality training data set, e.g., we may not have experts for each target language for which we want to develop a ranking model. But we may have good training data available in one domain and it can be of great value if we can utilize it in other domains of the same application. For instance, if we can use relevance judgments in English language to train a model for other language(s), we can overcome scarcity of data in those languages.
Similar situations arise in various other important appli-cations where we want to overcome scarcity of data in a domain (target domain) by utilizing data from related do-mains (source domains). In text mining applications, such as text classification, tagging and name entity recognition, we want to use plenty of labeled data from popular domains such as business journal domain to help target domains such as scientific publication domain with little labeled data. In recommendation systems, we are interested in using review data from source domains such as book domain to help pre-dicting rating of production in target domains such as dvd domain. In email spam detection, we may have sufficient labeled data for general spam detection, but not enough la-beled data for a specific group of users. It is always desirable to use the general domain data to help build a personalized spam detection model for the group of users.
Although domain adaptation has phenomenal impact on various applications, it has started to gain more attention only recently [20, 31]. The main challenge of domain adap-tation is to deal with different data distributions among do-mains. A model trained with data from a source domain or combined multi-domain data usually does not work well for the target domain, because it violates the basic supervised learning assumption -identical distribution between train and test data.

An intuitive solution to domain adaptation is to explic-itly formulate the distribution difference between a source domain and target domain and then to use the distribution difference to adapt the model from the source domain to the target domain [19, 4, 21, 35]. However, directly for-mulating distribution difference faces three big challenges. First, in the real world, the distribution difference is very hard to measure and formulate. Two domains could differ in the conditional distributions, marginal distributions or joint distributions. For high dimensional data such as text data, web data and image data, it is very difficult to formulate the distribution in a single domain, not to mention the distri-bution difference involving multiple domains. Second, even if we manage to formulate the differences between a single source and target domain, we can not efficiently extend them to multiple source domains, since different source domains could be different from the target domain in different ways. Third, formulating the distribution difference is usually tied to the specific data distributions and hence, the algorithm design for domain adaptation often remains heavily domain-specific, application-specific and learning-task-specific.
In this paper, we take a different approach to domain adaptation. Instead of directly formulating the data distri-bution differences, we formulate the relation between the hy-pothesis functions of different domains in the output space. We assume that hypothesis functions in the target and the source domain, h t ( x ) and h s ( x ), respectively, are related and there exists a relation function for their outputs. We name this function as label-relation function. Since in most applications, the outputs are scalars and the relationships between outputs are intuitively interpretable, it is relatively easy to formulate a label-relation function (Section 3.2). We can then use the label-relation function to transfer the knowledge from the source domain to the target domain.
Our main contributions can be summarized as follows: 1. Based on the concept of the label-relation function, we 2. Under the DTRM framework, we derive an algorithm 3. We prove the objective function is non-increasing un-
Historically, special cases of domain adaptation have been explored in the literature under different names, including sample selection bias [17], class imbalance [19], and covariate shift [35]. Those studies mainly address the difference be-tween training and testing data distribution. For example, class imbalance assumes that the density of input variables conditioned on output variables is the same for train and test data, while the marginal density of output variable is different for train and test data.

Recently domain adaptation has increasingly attracted at-tention from machine learning community, mainly in the form of domain adaptation or transfer learning [20, 31]. While domain adaptation and transfer learning apply the same principle to transferring knowledge across domains, it is worth to note that transfer learning may not distinguish the target domain from the source domain.

A popular class of domain adaptation methods is based on instance re-weighting [4, 21, 10, 25, 5, 18, 13, 36, 12], which assumes that certain parts of the data in the source domain can be reused for the target domain by re-weighting. [21] proposed a heuristic method to remove  X  X isleading X  train-ing instances from source domain so as to include  X  X ood X  instances from labeled source-domain instances and unla-beled target-domain instances. [10] introduced a boosting algorithm, TrAdaBoost, which assumes that the source and target domain data use exactly the same set of features and labels, but the distributions of the data in the two domains are different. TrAdaBoost attempts to iteratively re-weight the source domain data and target domain data to reduce the effect of the  X  X ad X  source data while encour-age the  X  X ood X  source data to contribute more for the tar-get domains. [4] proposed a framework to simultaneously re-weight the source domain data and train models on the re-weighted data with a kernel logistic regression classifier. Those above studies have shown the promise of data re-weighting for many application such as NLP [21] and special learning tasks such as binary classification [10, 12]. To some extent, our algorithm can also be viewed as a re-weighting style algorithm. To our best knowledge, under the DTRM framework, it is the first time that re-weighting is general-ized to different learning tasks in various applications.
Another category of domain adaptation approaches fo-cuses on feature presentation [6, 32, 26, 9, 1, 2, 3, 24], where a feature representation is learned for the target domain and used to transfer knowledge across domains. A structural correspondence learning (SCL) algorithm [6] was proposed to use unlabeled data from the target domain to extract features so as to reduce the difference between source and target domains. A simple kernel mapping function is in-troduced in [11], which maps the data from both domains to a high-dimensional feature space. [32] proposed to apply sparse coding, an unsupervised feature construction method, to learning higher level features across domain. [26] pro-posed a spectral classification framework for cross-domain transfer learning problem, where the objective function is to seek consistency between the in-domain supervision and the out-of-domain intrinsic structure.
The third category of approaches can be viewed as parameter-sharing approaches [33, 23, 15, 8], which assumes that the source tasks and the target tasks share some parameters or priors of their models. An efficient algorithm MT-IVM [23], which is based on Gaussian Process (GP), was proposed to handle multi-domain learning case. MT-IVM tries to learn parameters of GP over multiple tasks by assigning the same GP prior to the tasks. Similarly, Hierarchical Bayes (HB) is used with GP for multi-task learning [33]. [15] borrowed the idea of [33] and used SVMs for multi-domain learning. The parameters of SVMs for each domain is assumed to be separable into two terms: a common term across tasks and a task specific term. [27] proposed a consensus regulariza-tion framework for transfer learning from multiple source domains to a target domain.

The fourth category of approaches is based on relational knowledge transfer [29, 14, 28]. [28] proposed the algorithm TAMAR, which transfers relational knowledge with Markov Logic Networks (MLNs) across relational domains. MLNs combines the compact expressiveness of first order logic with flexibility of probability. TAMAR was later extended to the single-entity-centered setting of transfer learning [29], where only one entity in the target domain is available. [14] proposed an approach to transferring relational knowledge based on a form of second-order Markov logic. In summary, those approaches assume that some relationship among the data in the source and target domains are similar.
Another related field is semi-supervised learning [7, 38, 22, 30], which addresses the problem that the labeled data are too few to build a good classifier by making use of a large amount of unlabeled data and a small amount of the labeled data. Co-training [7, 38], which trains two learners for two views by iteratively including unlabeled data, is closely re-lated to domain adaptation. The major difference is that in co-training, we have one set of instances with features partitioned into two  X  X iews X . In domain adaptation, we use different sets of data instances from different domains.
Finally, it is worth to mention that most work in the lit-erature focus on classification. Our study addresses both regression and classification for domain adaptation.
First, a word about notation. We use R to denote the set of real numbers, R + to denote the set of nonnegative real numbers, and R ++ to denote the set of positive real num-bers. X denotes instance space and Y denotes output space. In this study, we consider the most general case for both clas-sification and regression, i.e., we consider X to be R d and Y to be R . we Let h : X  X  Y denote the function we want to learn and H denote a function space. The target func-tion h t and the source function h s denote the functions we want to learn from the target and the source domain, respec-tively. We define a domain as a data distribution D on the instance space X . D t and D s are for the target and source domain, respectively. S t = { ( x t i , y t i ) } n i =1  X  X  X  Y  X  D denotes the training data sampled from the target domain; S data sampled from the source domain. l : Y  X Y  X  R is a loss function defined on a pair of outputs.

Let us first consider the conventional supervised learn-ing setting. Suppose that we only have training data from the target domain, S t = { ( x t i , y t i ) } n i =1  X  X  X Y  X  D learning algorithm takes S t as input to learn the function, h : X  X  Y , which is the optimal solution to minimize the risk function R : Y  X Y  X  R , where F t ( x, y ) denotes the cumulative density function of ( x, y ) on the target domain.

We cannot minimize the functional R t directly, since F t is unknown. Instead, based on the training data, we mini-mize the empirical risk function,
Under the conventional risk minimization, if the training data sample size n is small, the empirical risk  X  R t is not a reliable estimate of the true risk R t and we cannot expect to obtain a good estimation of the target function h t .
In the domain adaptation learning setting, we have addi-tional training data from a source domain (we assume one source domain here and later we will show it is easy to extend the proposed framework and algorithm to multiple source problem is how we use S s to help learn the target function h . To achieve this goal, we need to transfer knowledge from S s to S t . Note that since D t is different from D s , simply combining S t and S s is not a justified approach. As dis-cussed in Section 1, in general, it is hard to formulate the difference between D t and D s , especially when X = R d with large d .

On the other hand, we observe the following facts in the output space. First, the relation between a pair of outputs is much easier to formulate, since in most applications, the output space is single dimension, i.e., Y  X  R . Second, the relation between the outputs of h t and h s is usually intu-itive and implies the basic feasibility for domain adaption in most applications. For example, in the ranking problem, h t and h s are the optimal ranking functions for the target domain D t (query-document distribution for a country) and the source domain D s (query-document distribution for an-other country). Given any query-document instance x from D s , we obtain two ranking scores y t = h t ( x ) and y s = h We expect certain correlation between y t and y s . For exam-ple, y t and y s are positively correlated with a significant probability. If y t is totally independent with y s , we cannot expect that the training data from S s can help learn h t since that implies two domains have totally different rank-ing principals, i.e., the optimal ranking function from one domain cannot give anything more than random guess for the instances from another domain. Similarly in sentiment classification, we expect that the output of the rating func-tion h s in the book domain is correlated with the output of the ranking function h t in the dvd domain in a certain way; otherwise, the training data from the book domain cannot be helpful for the dvd domain.
Therefore, we propose the concept of label-relation func-tion, r : Y X Y  X  R to formulate the relation between two la-bels (outputs) such that r ( y t , y s ) measure the  X  X onsistency X  between y t and y s . We have plenty of choices of function spaces for r . In this study, we select to use the exponential function such that, where d : Y  X Y  X  R + is a distance function. We choose the exponential function exp(  X  d ( y t , y s )) due to the follow-ing reasons. First, the function provides intuitive measure for the consistency between two labels, since its output is between 0 and 1 with 1 denoting the perfect consistency of two labels. Second, the exponential function leads to less computation effort for the algorithm (Section 4).
Next, we propose a new risk minimization framework for domain adaptation, which transfers knowledge from the source domain to the target domain through the label-relation func-tion. We summarize the following assumptions for the frame-work.
We call the output of h t as target label denoted by y t and the output of h s as source label denoted by y s . In the source domain, for each instance x , the source label y s observable but the target label are not observable. We treat the target label for the source domain as hidden variables to incorporate the source domain data into the risk function. where  X   X  R ++ is a positive normalization constant. We call the framework based on the above risk function as Do-main Transfer Risk Minimization (DTRM). In this frame-work, by introducing the hidden target label y t and the label-relation function r into the source domain, the addi-tional information from source domain data S s = { ( x s j is used to learn the target function, h t .
 mize the following empirical risk minimization to learn h
The above empirical risk is helpful for us to understand the intuition behind the DTRM. Basically, DTRM aims to  X  X elect X  the training instances from the source domain to help according to their  X  X sefulness X , which is measured through the label-relation function. The main difference be-tween DTRM and the conventional re-weighing framework [21] is that DTRM does not explicitly formulate the data distribution difference in input space and this lead to sev-eral algorithmic advantages (Section 4).
In this section, we derive the domain adaptation algorithm under DTRM framework.

Our task is to solve the following minimization problem, where  X  R a is defined in Eq.(6), and  X  = { y t j } n + m the hidden target labels for the source domain instances.
Since this is a general minimization problem, it seems that for a specific loss function l , we need to derive a specific problem. However, we show that under a weak assumption for l , we can derive a general algorithm that applied to a wide range of loss functions.

We assume that the loss function l is positive definite, i.e., l : R  X  R  X  R + and l ( y, y ) = 0. Positive definiteness is a weak assumption easily satisfied in real applications, since most popular loss functions, such as Euclidean distance, 0-1 loss, and KL-divergence, are non-negative and equal to zero if only if inputs are identical.

To derive a general domain adaptation algorithm, we also assume that a base learner L is given to minimize the loss function l , i.e., it is flexible for domain experts to choose the best base learner for certain applications as an input. For example, for a binary classification task, SVM may be chosen as the input base learner to the general domain adaptation algorithm.

In the minimization problem, we need to learn both the target function h t and the hidden target labels for the source convex problem. We derive an iterative algorithm which
We re-formulate the risk function as follows. tion of  X  R a is reduced to the minimization of the weighted loss function l , which we can directly apply the base learner L to optimize. We assume that the base learner L returns the following solution, Algorithm 1 Domain Adaptation by Label Relation Input: S t = { ( x t i , y t i ) } n i =1 , S s = { ( x s base learner L.
 Output: A target function h t .
 Method: 1: Initialize h t . 2: repeat 3: for j = n + 1 to n + m do 4: let y t j = h t ( x s j ) 5: end for 6: Update w i such as 7: Call base learner L to obtain 8: until convergence with w i defined in Eq.(10).

Next, we update { y t j } n + m j = n +1 when h t is fixed. Now our task is
It seems that given a specific loss function l and a specific label-relation function r , we need to derive a specific algo-rithm to solve this optimization problem. However, using the positive definiteness of the loss function and the nice property of the exponential function (relation function), we can derive a general updating rule applicable to all these loss functions and relation functions. We propose the following theorem to provide the updating rule.
 lution to the minimization problem in (12) .

Proof. Since l ( h t ( x s ) , y t )  X  0 and r ( y t , y s tain the following deduction, Hence, the global minimum of  X  R a w.r.t. { y t j } n + m minimum is attained when l ( h t ( x s j ) , y t j ) = 0, i.e., y (by positive definiteness of the loss function l ). Proof is completed.

Theorem 1 provides a simple updating rule to update { y
Based on updating rules (11) and (14), we propose a gen-eral domain adaptation algorithm, Domain Adaptation by Label Relation (DALR), which is summarized in Algorithm 1. Algorithm 1 alternatively updates the target function h t and the hidden target labels { y t j } n + m the information from the source domain to h t through the label-relation function r . The intuition behind the algo-rithm is that the instances in domain training data S s = target function h t and through the label-relation function the model iteratively makes use of the source domain data instances based on their most recent X  X sefulness X  X ntil it con-verges. The following theorem guarantees the convergence of the DALR algorithm.

Theorem 2. Algorithm 1 monotonically decreases the risk function  X  R a in Eq. (6) .

Proof. Let  X  R a e and  X  R a e +1 denote the risk function at e th and e + 1th iterations, respectively. During the e + 1th iteration, we have the following updates, Then, we have the following deduction, In the above deduction, the first inequality results from Eq.(15) and the last equality can be obtained by substi-tuting Eq. (16) into  X  R a e +1 . The proof is completed. Based on Theorem 2, Algorithm 1 is guaranteed to converge. In practice, we observe that the DALR algorithm converges very fast, usually in a few iterations.

The DALR algorithm can also be viewed as a re-weighting style algorithm. However, DALR uses model self-adjustment and label-relations to iteratively adjust the  X  X sefulness X  of the source data instances and this avoids directly dealing with the distribution differences in the input space. More-over, under DTRM framework, DALR generalizes re-weighting to different learning tasks in various applications. In sum-mary, the DALR algorithm has the following advantages. (1) It is applicable to a wide range of applications, since it is not designed for a specific loss function. (2) It is easy to extend it to multiple source domains; we just need to combine the data sets from multiple source domain into a single data set as the input. Since the algorithm does not make assumptions about source domains, it will automati-cally select  X  X seful X  training examples from the input data from multiple source domains. (3) It is flexible to allow do-main experts to choose the best suitable base learner for a specific application.
In this section, we provide theoretical analysis for the pro-posed framework algorithm. Specifically, we aim to answer the following fundamental questions. 1. Is the empirical risk  X  R a an unbiased estimator of the 2. How close is the empirical risk  X  R a to the true R a 3. How close is the optimal function learned by the DALR
We show that the empirical risk  X  R a is an unbiased esti-mator of the true risk R a by the following theorem.
Theorem 3. For a given function h t  X  X  ,  X  R a is an un-biased estimator of R a .
 Proof.

Next, we derive the error bound between the empirical risk  X  R a and the true risk R a to answer the second question. We begin with some notations for improving clarity. z
Hence, we can formulate  X  R a as the following,
The following theorem provides the error bound between  X  R a and the true risk R a .

Theorem 4. Let H be a function space with VC dimen-sion c , and b is the upper bound for the loss function l . Then, for every h t  X  X  , with probability 1  X   X  , |  X 
R a  X  X  a | X  b Proof.

P [ |  X  R a  X  X  a | X  t ] = P [ |  X  z  X  E  X  z | X  t ] where and in the third equality. In the above deduction, the first equal-ity results from Theorem 3 and the first inequality results from Hoeffding X  X  inequality. The above results holds true for a single h t  X  H . For the whole function space H , with the standard uniform bound argument with VC dimensions as our growth function, we have
P [ |  X  R a  X  X  a | X  t ]  X  ( 2( n + m ) We let the RHS equal to  X  and solve for t . Hence, we obtain,
P [ |  X  R a  X  X  a | X  b the proof is completed.

Finally, we address the third question, how close is the optimal function learned by the DALR algorithm to the true optimal function, i.e., what is the best the DALR algorithm can do. We define the following notations for clarity. Then, we have
Then, we propose the following definition to measure the distance between two domains.

Definition 1. Let H be a function space with VC dimen-sion c and l : R  X  R  X  R + be a loss function, the distance between two domains, D t and D s is defined as Computing 4 H ,l is NP-hard. In practice, we can use boot-strapping to approximate it. For convenience, we use  X  to
If we let h 0 denote the true risk minimizer for the tar-get domain such that h 0 = arg min h  X  X  R t ( h ) and h  X  the empirical minimizer for domain adaptation such that h  X  = arg min h  X  X   X  R a ( h ), then the third question is equiva-lent to ask that what is the error bound between R t ( h  X  R ( h 0 ). The following theorem answers this question.
Theorem 5. Let H be a function space with VC dimen-sion c and b is the upper bound for the loss function l . Then, with probability 1  X   X  ,
R t ( h  X  )  X  2 b
Proof. With triangle inequality and Theorem 4, the proof can be done (details are omitted).

Theorem 5 provides theoretical justification for the intu-itions about the DALR algorithm (also true for most domain adaptation algorithms). For example, when two domains are closer with each other (  X  is smaller), the optimal function learned by the algorithm is more accurate w.r.t the true function (the error bound is tighter). Another interesting example is that when  X  is larger, the size of the source do-main data m is more important and the size of the target domain data n is less important for the error bound, i.e.,  X  controls the relative importance of the source domain data w.r.t. the target domain data. Note that based on Theorem 5, increasing or decreasing  X  does not necessarily improve the error bound.
As a general domain adaptation algorithm, DALR can be applied to a wide range of applications. In this section, we apply DALR to an important application, ranking, to demonstrate the properties and effectiveness of DALR.
Under machine learned ranking problem setting, each query-document pair is represented as a feature vector x , the out-put of the ranking function y is a real value denoting the relevance between the query and the document. Hence, in this study, we treat ranking as a regression problem. Note that most domain adaptation approaches in the literature are limited to classification. DALR does not have this lim-itation, since it is applied to classification and regression in the same way. For the base learner, we select to use gra-dient boosting tree [16], which has shown great potential for ranking [37]. We use the popular L2 norm as the loss function.

For the relation function, there are many choices with dif-ferent distance functions. In this study, we propose the fol-lowing two designs. The first design provides soft weights to measure the relation between two labels based on Euclidean distance,
The second one provides 0/1 weights to measure the rela-tion based on a threshold, where t denotes a threshold. Note that this relation function can also be formulated as an exponential function such that r ( y t , y s ) = exp( I [ | y t  X  y s | &gt; t ](  X  X  X  ) + I [ | y where I denotes an indicator function.

We use DALR-L2 to denote the algorithm with the rela-tion function in Eq.(29) and DALR-Bi to denote the algo-rithm with the relation function in Eq.(30). We compare our algorithms with the following three approaches. The first one is the baseline approach based on the target do-main data only (called Base). The second one is an intu-itive domain adaptation approach, which applies the base learner to the Source Domain data only (referred to SD). The third ones is an effective domain adaptation algorithm based on Optimal Combination of source domain data and target domain data (referred to OC) [5, 34]. This approach assumes that there exists an optimal convex combination of the target domain data and source domain data distribu-tions to learn the target function. As an effective algorithm that also does not depend on specific loss functions, it is a suitable comparison for the DALR algorithms.
We use data sets from a search engine. The training exam-five levels of relevance. We select to use four domains cor-responding to four different countries/languages.The source domain D0 is large, including about 1 . 2 million training ex-amples. The target domain D1 has about 6 , 000 training examples, representing a typical situation that labeled ex-amples are scarce. There are two more data sets from target domains D2 and D3. We will focus on D1 for detailed study on the properties of the DALR algorithm, while using the other domain data for comparing different algorithms. Table 1 summarizes the size of the data sets.

We use Mean Squared Error (MSE) as the evaluation met-ric, since it is consistent with the loss function L2 norm. Six-fold cross validation is used for testing. For the initial model, we use the model trained based on the target domain model.

The constant  X  in the relation function controls the rel-ative weight of source domain data against the target do-main data as Theorem 5 suggested. We test DALR-L2 and DALR-Bi algorithms on D0 (source domain) and D1 (target domain) with different  X  values, which provide different rel-ative weights of source domain data against the total weight of all data as shown in the X axis in Figure 1. Figure 1 shows that  X  is not monotonically related to the perfor-mance. This is consistent with Theorem 5. From Figure 1, we observe that for both algorithms, when the weight of the source data equals to the weight of the target data (the rele-vant weight is 0.5), we achieve the best performance (lowest MSE). In all the following experiments, we use this optimal  X  value. Figure 1: Effect of relative weight of source domain data against the total weight of all data. Figure 2: Effect of different sizes of the source data on MSE of the five algorithms shows that the per-formance is positively correlated with the size of the source data. DALR perform best under different sizes.
Since domain adaptation aims to use sufficient labeled data from source domain to help target domain with lim-ited labeled data, it is critical to see how different sizes of source data affect the performance of the algorithms. We randomly sample data from the source domain D0 with dif-ferent sizes, from 50K to 200K. We use D1 as target domain to test the five algorithms.

Figure 2 shows that how different sizes of source domain data affect MSE for all five algorithms. MSE of the base line does not change, since it only uses the target domain data. For the other four algorithms, the MSE decrease when the size increases. This is consistent with Theorem 4 and Theorem 5, when the source domain data size m becomes larger, the estimation becomes closer to optimal solution. At the same time, we observe that when the size is larger than 100K, the performances of the algorithms tend to be  X  X aturated X . Finally, we observe from Figure 2 that for all different sizes, the DALR algorithms perform better than other algorithms. Base performs worst due to the limited Figure 3: Effect of different levels of noise of the source domain data on MSE of the five algorithms shows that the DALR algorithms are most robust to noise. size of the target domain data. SD does not perform well since it violates the basic assumption of supervised learning that train data and test data should have the same distribu-tion. The possible reason that OC approach performs worse than the DALR algorithms is that OC X  X  assumption about the optimal convex combination of the target domain data and source domain data distributions is not true for the data set. On the other hand, DALR makes an easily-satisfied as-sumption based on the label-relation.
In real applications, the source domain data may have noise and it is always desirable for a domain adaptation al-gorithm to be robust to noise. We test the robustness of all five algorithms by intentionally adding noise into the source domain data D0. We add noise as follows. A training ex-ample is randomly selected, and its label value is randomly replaced by a value that is not the current one. We change different percentages of the source domain data to create different levels of noise.

Figure 3 shows that how different levels of noise of the source domain data affect the performances of the five algo-rithms. MSE of the base line does not change, since it only uses the target domain data. For SD and OC algorithms, when the noise increases, their performances drop signifi-cantly. This is consistent with the intuition that noise can be transferred from the source domain to the target domain and hurts the accuracy of the learned function. On the other hand, it is surprising to observe that the DALR algorithms are affected by noise very slightly. Even with 50% training examples added with noisy scores, the performances of the DALR algorithms do not change significantly. The reason that the DALR algorithms are very robust to noise is that DALR is capable of identifying  X  X sefulness X  of the training examples through the label-relation function and hence, it automatically  X  X xcludes X  the noise examples. Since the size of source domain data is large (about 1.2 million), even after the DALR algorithms  X  X xclude X  50% noisy training exam-ples, the rest of the data is enough for the DALR algorithms to provide good performance. In summary, DALR provides much better performance for noisy source data due to its high robustness to noise. Figure 4: Comparing the DALR algorithms with other algorithms on different target domains shows that the DALR algorithms perform best on different target domains.
Finally, we compare the DALR algorithms with other al-gorithms on different target domains. By using different target domains, we have different distances between the tar-get domain and source domain. Based on the prior knowl-edge about the languages/countries associated with these domains, the difference between D1 and D0 is the smallest.
From Figure 4, we observe that the DALR algorithms pro-vides best performance for all three target domains. For the two target domains, D2 and D3, which are more differ-ent from the source domain D0, the DALR algorithms show more improvements compared with SD and OC approaches. This shows another great potential for DALR to deal with more difficult problems, since usually when two domains are more different from each other, the domain adaptation task becomes harder.
In this paper, based on the concept of the label-relation function we propose a novel domain adaptation framework (DTRM). An iterative algorithm (DALR) derived under this framework updates the target hypothesis function and out-puts for the source domain until convergence. The algorithm is applicable to a wide range of applications due to the fact that it does not rely on formulating data distribution differ-ences among the domain for transferring knowledge. We can easily extend it to make use of labeled data from multiple source domains. It can work with any base learner in classi-fication or regression settings. We hope that this flexibility will encourage the wider use of it. We prove the objec-tive function is non-increasing under the updating rules and hence the convergence of the algorithm is guaranteed; we provide the theoretical analysis for the bounds on the risk for domain adaptation. Our extensive experimental results show that the DALR algorithms consistently, robustly and effectively use the source domain data to improve the accu-racy of models on the target domain under various condi-tions: different sizes for source domain data; different noise levels for source domain data, and different difficult levels for target domain data.

There are a number of interesting directions for future work. For example, currently the  X  is set via empirical es-timation, we are investigating how to learn it on the fly; also we found that DALR-Bi version of the algorithm works slightly better than DALR-L2 and we would like to investi-gate the reasons and formulate guidelines for choosing the best label-relation function.
The authors gratefully acknowledge the insightful com-ments of Dr. Byron Dom, which allowed us to significantly improve our paper. [1] R. Ando and T. Zhang. A high-performance [2] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task [3] A. Argyriou, C. Micchelli, M. Pontil, and Y. Ying. A [4] S. Bickel, M. Br  X  uckner, and T. Scheffer. [5] J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and [6] J. Blitzer, R. McDonald, and F. Pereira. Domain [7] A. Blum and T. Mitchell. Combining labeled and [8] E. Bonilla, K. Chai, and C. Williams. Multi-task [9] W. Dai, G. Xue, Q. Yang, and Y. Yu. Co-clustering [10] W. Dai, Q. Yang, G. Xue, and Y. Yu. Boosting for [11] H. Daume. Frustratingly easy domain adaptation. In [12] H. Daum  X e. Cross-task knowledge-constrained self [13] H. Daume III and D. Marcu. Domain adaptation for [14] J. Davis and P. Domingos. Deep transfer via [15] T. Evgeniou and M. Pontil. Regularized multi-task [16] J. Friedman. Greedy function approximation: a [17] J. Heckman. Sample selection bias as a specification [18] J. Huang, A. Smola, A. Gretton, K. Borgwardt, and [19] N. Japkowicz and S. Stephen. The class imbalance [20] J. Jiang. A Literature Survey on Domain Adaptation [21] J. Jiang and C. Zhai. Instance weighting for domain [22] T. Joachims. Transductive inference for text [23] N. Lawrence and J. Platt. Learning to learn with the [24] S. Lee, V. Chatalbashev, D. Vickrey, and D. Koller. [25] X. Liao, Y. Xue, and L. Carin. Logistic regression [26] X. Ling, W. Dai, G.-R. Xue, Q. Yang, and Y. Yu. [27] P. Luo, F. Zhuang, H. Xiong, Y. Xiong, and Q. He. [28] L. Mihalkova, T. Huynh, and R. Mooney. Mapping [29] L. Mihalkova and R. Mooney. Transfer learning by [30] K. Nigam, A. McCallum, S. Thrun, and T. Mitchell. [31] S. J. Pan and Q. Yang. A survey on transfer learning. [32] R. Raina, A. Battle, H. Lee, B. Packer, and A. Ng. [33] A. Schwaighofer, V. Tresp, and K. Yu. Learning [34] G. Schweikert, C. Widmer, B. Sch  X  olkopf, and [35] H. Shimodaira. Improving predictive inference under [36] M. Sugiyama, S. Nakajima, H. Kashima, P. von [37] Z. Zheng, K. Chen, G. Sun, and H. Zha. A regression [38] X. Zhu. Semi-supervised learning literature survey.
