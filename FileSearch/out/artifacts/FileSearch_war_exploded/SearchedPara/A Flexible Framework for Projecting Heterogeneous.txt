 In many real world settings the data to analyze is heteroge-neous consisting of (say) images, text and video. An elegant approach when dealing with such data is to project all the data to a common space so standard learning methods can be used. However, typical projection methods make strong assumptions such as the multi-view assumption (datum in one data set are always associated with a single datum in the other view) or that the multiple data sets have an over-lapping feature space. Such strong assumptions limit what data such work can be applied to. We present a framework for projecting heterogeneous data from multiple data sets into a common lower dimensional space using a rich range of guidance which does not assume any overlap between the in-stances or features in different data sets. Our work can spec-ify inter-dataset (between instances in different data sets) guidance and intra-dataset (between instances in the same data set) guidance, both of which can be positively or nega-tively weighted. We show our work offers substantially more flexibility over related methods such as Canonical Corre-lation Analysis (CCA) and Locality Preserving Projections (LPP) and illustrate its superior performance for supervised and unsupervised learning problems.
 H.2.8 [ Database Applications ]: Data mining; I.2.6 [ Artificial Intelligence ]: Learning Algorithms Dimensionality Reduction; Spectral Methods; Heterogeneous Data A growing trend in data mining and machine learning is that the data to analyze does not consist of a single in-stance type or come from a single source, but instead con-tains fundamentally different instance types. This gives rise to multiple data sets which may not have overlapping fea-tures or common instances. Examples include personal in-formation management (images, video, text and geographic tags) and health care records (medical scans, written-notes and medical records). For some special situations the multi-view setting, where each instance has multiple descriptions (views), is natural and many algorithms exist to exploit this extra information [10, 18, 27]. This effectively requires the different data sets to have overlapping instances. Similarly, other methods require the two data sets to have overlapping features [16].
 However, a broader setting is required in many other situ-ations. For example, consider a collection of personal data consisting of images, videos and emails. While there are mul-tiple types of data, instances in the different data sets do not have common features nor do they represent different views of the same instance. As such, a more pragmatic model is re-quired to learn a useful embedding of the data. We propose to use relationships between any pair of instances whether they be in the same or different data sets. We focus on the relations of similarity and dissimilarity between instances. This form of guidance has been used extensively in areas such as metric learning and constrained cluster-ing [6,22,24]. It has been shown to be useful at making use of many forms of guidance including side information (i.e. from labels), personal preferences and even geometry [1]. We use this guidance to learn an embedding in which pairs of in-stances with the similar relationship are close to each other and pairs of instances with the dissimilar relationship are far from each other. Our work makes use of this type of rela-tional information as well as weighted variations to project all data sets to a common lower dimensional space, allowing analysis using standard methods. For example, after project-ing all instances to a common space we may cluster them for organization reasons (see Figure 9). Similarly we may use a nearest-neighbor retrieval algorithm to related objects (see Figure 8).
 Embedding two or more data sets with no overlapping fea-ture or instances is a very challenging problem since it re-quires embedding data to a lower dimensional space when the data are fundamentally different and no obvious dis-tance function exists between them. Existing methods to achieve this aim fall into a number of different categories with most being methods that make the multi-view assump-tion [10,18,27]. We can characterize each by the type of guid-ance/relationships they require the user to provide, allowing us to see how our method is different. Figure 1 explains the differences between common methods and our method and below we briefly summarize their limitations so as to better explain the contributions of our work.
 Though this existing work has made significant progress in the area of heterogenous data embedding it is limited in a number of ways that prevents its use for embedding funda-mentally different data types. The limitations with existing work are: 1. They typically restrict the type of data they accept. 2. The type of guidance is typically limited to unweighted 3. They do not necessarily embed all instances into the Our contribution to the field is we present a framework for embedding heterogeneous sets of data with no limitations on whether the data sets or feature space overlap. This allows a variety of pairwise relationships such that: 1. The embedding is generated using pairwise intra-dataset 2. The relational guidance can be both positively (simi-3. Every instance is embedded into a common space (see 4. Our experimental results show such guidance is useful The outline of the paper is as follows. In section 2 we de-scribe our method. In section 3 we present experimental re-sults of our method applied to K-Nearest Neighbors clas-sification and K-Means Clustering. Finally, in section 4 we discuss related work and then conclude. For clarity we shall initially describe our work for just two data sets X and Y (which may have different feature sets) and in the following subsection show how it can be extended to additional data sets. Our guidance comes in two forms: intra-dataset and inter-dataset relationships (as shown in Figure 1) between pairs of instances. For both forms of guidance we allow a weight to be associated in [  X  1 , +1] . This weight can be interpreted as a degree-of-belief or confidence in the relationship. A large positive/negative weight indicates strong belief that two in-stances are very similar/dissimilar. A weight of 0 indicates no knowledge of the relationship between the two instances. We encode both intra-dataset and inter-data set relation-ships into one matrix W which has a blockwise structure as shown in Figure 2.
 tures all these relations. The upper left and bottom right Figure 2: The block structure of W for two different data sets. As we can see W consists of several different matrices. W XX and W Y Y encodes the intra-dataset relationships and W
XY and W Y X the intra-dataset relationships. blocks contain the intra-dataset relationships between the instances in X and Y respectively. The upper right and bottom left entries will contain the inter-dataset similari-ties/dissimilarities between instances in X and Y . We can now examine how the guidance used in related work can be encoded in W . Earlier Manifold Learning methods such as Locality Preserving Projections (LPP) and its vari-ations [3, 9] are single view methods that take guidance in the form of an adjacency matrix A G . They can be viewed as only allowing intra-data set constraints for a single data set. Thus, the weight matrix for LPP would be: Multi-view LPP (MVLPP) [27] is a multi-view extension of Locality Preserving Projections. Intra-dataset guidance can be given for each data set and is encoded in matrices A X and A Y . Within our framework, W would be: where I is the identity matrix. The identity matrix in the off diagonal blocks of W MV LPP captures the multi-view as-sumption. Note that as this is a multi-view method, X and Y must have the same number of instances which is not the case for our method.
 Canonical Correlation Analysis (CCA) also makes the multi-view assumption but only specifies inter-dataset relations which can be captured as follows: We now discus our formulation which allow both intra-dataset and inter-dataset relationships. We wish to use the previously mentioned relational infor-mation (encoded in W ) to project all data into a common lower dimensional space using projection vectors a and b . Letting I and J be index sets over X and Y we can write the optimization problem of learning two sets of projection vectors which respect the given guidance as restrictions. The first and third terms of equation 2 optimize the intra-dataset embedded distance between instances in X and Y respectively based on the relational information in W , while the second term optimizes the inter-dataset embedded dis-tance between instances in X and Y . The objective function matches our intuition and can even handle conflicting guid-ance. Since our aim is to minimize the objective function a positive w ij indicates that the projection vectors should place the two instances close together to minimize the ob-jective. Conversely, a negative value of w ij indicates the two instances should be projected to be far apart to minimize the objective value. Since w ij is weighted the algorithm may choose to satisfy guidance with larger weights at the cost of guidance with smaller weights.
 Through some linear algebra (explained below) and intro-ducing a constraint so there are not infinite solutions, equa-tion 2 can be transformed into the following: Figure 3: Our formulation to embed two data sets, it can easily be extended to multiple data sets, as discussed later. We spend the rest of this section deriving equation 2, which can be skipped on the first reading of this paper. The first of the three terms in equation 2 can be expanded to: 1 2 ( X  X  X Let D XX be a diagonal matrix such that the entry D agonal matrix whose diagonal entries are the sums of the weights of the edges between instances in X . Note that in the first expression of equation 3, for each x i we can sum over the entire row of W and hence rewrite the term as a
XD XX X T a . The fourth expression can be rewritten in an identical form. The second and third expressions can be written together in matrix form as  X  2 a T XW XX X T a where W
XX corresponds to the block of W relating X to X . Hence equation 3 can be more concisely written as Letting L XX = D XX  X  W XX we get A similar transformation can be performed on the second and third terms in equation 2 to get Where W XY and L Y Y are defined similarly to W XX and L
XX respectively. We can then concatenate a and b into one vector p , concatenate X and Y into Z as shown in equation 2 and concatenate W XX ,W Y Y ,W XY ,W Y X into W as shown in Figure 2. This allows us to rewrite equation 6 as: However, equation 7 can in some circumstances be trivially solved by p = 0 and has infinite number of solutions oth-erwise so we add the constraint a T ( XD XX X T +  X I ) a = 1 where  X  is a small positive constant and I is the identity ma-trix. This problem can be solved as a generalized eigenvalue problem. We do not add the typical a T XD XX X T a = 1 constraint because in order for this problem to have a real (i.e. non-complex) solution XD XX X T must be made pos-itive definite which may not be the case if there is more negative guidance for an instance that positive guidance or X has fewer training instances than features. Note that the constraint need not include b since it is coupled with a via W .
 Extensions to More Than Two Data Sets. This for-mulation can naturally be extended to m data sets (hence producing projection vectors a 1 ... a m ) by further adding to W and Z , letting p T = [ a T 1 ... a T m ] and using the formulation in equation 8 Obtaining multiple projection vectors (the k smallest eigen-vectors for instance) allows embedding instances into a k dimensional space. As mentioned previously, equation 7 can be solved as a gen-eralized eigenvalue problem. The key operations of this are solving the generalized eigenvalue problem and matrix in-version. For solving the generalized eigenvalue problem we used the eig function of MATLAB, which uses the QZ method. The complexity of the QZ method is approximately O (66 N 3 ) and the space requirement is O ( N 2 ) where N is the number of dimensions of X [4]. However, this will re-turn all eigenvectors and we only require the k smallest if we are to embed the data into k dimensional space. Instead, libraries such as ARPACK [12] (the library used by Matlab X  X  eigs function) that implement more scalable eigenproblem methods can be used. In all our experiments the total run-time was less than a second on a typical quad-core laptop. Some of the other methods discussed in the paper -CCA, LPP and Manifold Alignment -also reduce to generalized eigendecomposition problems. Depending on the solver, matrix inversion may also be required. Thus, these methods have comparable complexity. Metric learning methods require solving a Semidefinite Program (SDP). While SDP solvers can run in polynomial time with respect to the size of the problem, but because SDPs tend to have many variables they generally do not scale as well to high dimensional problems [21]. A limitation to our method as presented is that it can only learn a linear transformation. This can be efficiently ad-dressed by using the "kernel trick" to learn a nonlinear trans-formation. The kernelized version of our formulation is: where we define K
XX and K Y Y are kernels for X and Y .  X  and  X  are the dual variables associated with X and Y .
 In our experiments we use a combination of Kernels and features to describe our data. See the experimental section for details. Here we propose experiments to compare our framework to CCA. In particular we shall ask the following questions: All data sets and code will be made publicly available once the paper is accepted so as to recreate the experimental results presented here.
 Our Data Set. We focus on personal information manage-ment problems since they are not only important but easy for a non-expert to verify. We believe this setting is an ideal application of our work because personal information man-agement involves finding structure in sets of heterogeneous instances in which arbitrary intra-dataset and inter-dataset relationships are available.
 PIM data sets containing video, text and images like the one mentioned in the introduction are not readily available so we use the one made publicly available in [29] that con-tains images, text-tags and location information. The data set consists of 500 images taken at 99 different locations (described using longitude and latitude) around Asheville, North Carolina. The images are tagged with one or more of 590 possible descriptors. Each image is associated with a single location, but images can have multiple tags and each tag can be associated with multiple images. For our ex-periments, images are represented using SIFT features [14] which are used to construct a kernel, tags are represented by simple indicator vectors that are all 0 except for the entry corresponding to the tag which is 1 and locations are rep-resented using a Gaussian Kernel applied to the longitude and latitude values.
 Now we give the method for constructing the guidance ma-trix W . For each image-tag tag entry in W , we set it to 1 if the image has the tag, 0 otherwise. Similarly, for experi-ments that used locations, we set each image-location entry in W to 1 if the image was taken at that location and 0 otherwise. All other entries were set to 0 .
 For all experiments we selected the top N most common tags (where N varies based on the experiment) excluding the five most common tags in the data set because they are associated with a large majority of the images.
 For all experiments except the embedding experiment in sec-tion we 3.1: We hope our method can perform better than or comparable to CCA using the same guidance and perform significantly better when more guidance is used.
 For our experiments we compared four methods: Here we test how well our method embeds the data. We purposely use all available relational information (images to tags and images to locations) to see how well it works with 1000s of pieces of relational guidance. The resultant embedding is shown in Figure 5 and shows instances from all data sets are well interspersed in the embedding. Another test of our embedding is how well the relational information used to drive the process is respected in the embedding. We would hope our learning of non-linear projection vectors will allow for most of the guidance to be respected. Figure 6 shows how well the guidance is respected both in terms of the guidance given to the algorithm (training left plot) and guidance not given to the algorithm (testing right plot). In the left plot we see our method performs significantly better than CCA and adding extra guidance does not diminish its ability to satisfy the guidance. An important result is that in our embedding over 90% of guidance is satisfied by 50% of the closest pairs.
 As expected, the amount of guidance satisfied is not as great for the test set (because the test is not used to learn the em-bedding). Nevertheless, the fraction satisfied is significantly greater than CCA. The type of guidance our methods can handle is novel so there is not an elegant way to apply CCA using the guid-ance we want to encode. Hence, we implicitly encode the re-lationships by duplicating entries. For example, if an image x is associated with two tags y j ,y k , then we augment the data set used by CCA with two pairs: ( x i ,y j ) and ( x For our classification experiments we randomly removed 20% of the images for the test set and the remaining were used for training. This was repeated 10 times for each exper-iment. The experiments we ran learned a set of projection vectors given a training set of images and tags and then used them to embed the training and test images. To pre-dict tags for the test set we simply use the k nearest tags in the embedded space.
 For accuracy we measured the Normalized Cumulative Dis-counted Gain (NCDG) [11] of the predicted tags. NDCG is a measure of how well an instances nearest tags, ordered from closest to furthest, match the order of the tags as given in the data set (by a domain expert). That is if an instance has q tags, then we retrieve its q nearest tags and see how well that ordering matches the ground truth. This is a much more informative measure of performance than measures such as the Rand index or precision since it factors in the orders of the tags.
 For all experiments cross validation was used to choose regu-larization parameters and the number of projection vectors. Figure 7 shows the performance of our method and CCA versus varying numbers of maximum projection vectors (the actual number of projection used was still selected using cross validation). We see our methods performs significantly better than CCA. Furthermore, our method is able to ob-tain stronger results using fewer projection vectors. We con-jecture our better performance is because our formulation is based on minimizing embedded distance while CCA is based on maximizing embedded covariance [7].
 Figure 8 shows the performance of our method and CCA without constraints on the maximum number of projec-tion vectors used (essentially the right-most extreme points in Figure 7 versus varying size training sets. We measure performance using NDCG as before and include in our com-parison a baseline method of guessing the most frequent tags ( Guess ). As before if a test set instance has q tags, then we retrieve the q nearest tags to the instance and note their or-der and compare this ordering to the ground truth. We see that for very small data sets all methods perform similarly but as more training data becomes available our method is able to perform significantly better than CCA which itself only performs marginally better than Guess . This shows our method is able to handle lots of guidance as with each ad-ditional training instance comes more guidance and a more complex W matrix. A particularly novel use of heterogeneous embedding is that it allows applying unsupervised learning techniques to in-stances from multiple data sets. This could involve rank-ing/retrieval, organizing (such as by using hierarchical clus-tering methods) or, as we show here, clustering heteroge-neous instances. As before, we use relationships between im-ages and their geographic location as well as between tags and images to embed images, tags and locations into a com-mon space. We then run standard k-means clustering on the embedded images, tags and locations.
 First we show that our method can lead to meaningful clus-terings. For k-means we set the number of clusters to 10. Due to space restrictions, Figure 9 shows the images, tags and lo-cations closest to the cluster centroids for just 3 such clusters (all clusters are shown in Figure 5. From these experiments we see that the resulting clusterings contain a mix of simi-lar tags, locations and images. Importantly, we see that the images and locations within each cluster are consistent with each other. The left-hand side cluster contains of a series of parks outside the downtown area, the right-hand side clus-ters are of two downtown attractions: an annual rock festival and another cultural event. Clustering.
 right shows the performance on the test set. 30 and training size was all available training images. maximum number of vectors fixed to 30. image was generated using Google Maps; Map Data: Google 2014. Though visual inspection of the clusters is useful, a more quantitative measure of performance is to compute the Rand Index for varying training set sizes and number of clusters. The Rand index here measures how well the image-tag re-lations are respected by the clusters. A value of 1 means a perfect matching. We hope that each cluster will contain im-ages with similar tags. For these experiments we learn pro-jection vectors on a training set, apply them to a test set, cluster the test set and report the Rand Index. This was re-peated for 10 different training and test sets. Our results are shown in Figure 10. We see that regardless of the number of clusters, our method out performs or performs comparable to CCA and again adding in more guidance (and objects) produces even better results. The related work falls into a number of distinct areas which we now survey.
 Graph Driven Dimension Reduction. Much work has been done on graph based embeddings for machine learning. Locally Linear Embedding [19] and Laplacian Eigenmaps [2] are both popular graph based embedding techniques. Here we can view the graphs as encoding intra-dataset similar relationships which are used to embed one data set. [17], [8] and [9] learn projection vectors for out-of-sample embed-dings. Many graph embedding methods were unified by the graph embedding framework of [25]. Multi-view extensions to these techniques have been proposed such as [18,27] but, unlike our work, neither allows arbitrary inter-dataset rela-tionship.
 Manifold Alignment. Manifold Alignment methods [6,22] model multiple data sets as lying on manifolds and attempts to learn projections which align these manifolds. The key different between their work and ours is they model the data as lying on a manifold, while we do not.
 Multi-View Dimension Reduction. Multi-view dimen-sionality reduction has also received a great deal of attention in the machine learning community. Canonical Correlation Analysis (CCA) [10] is a classical technique that has been applied to multi-view dimensionality reduction [7]. Recent work has considered the use of 3 view CCA for embedding images, tags and semantic classes [5]. These works can be viewed as embedding multiple data sets but under very lim-ited relational information, namely an instance from a data set can only have a relationship with a single instance from another data set.
 Heterogeneous Learning. Learning with multiple sources has received some attention. The problem of clustering with heterogenous instances and side information was addressed in [29]. [13] and [26] studied Heterogeneous Transfer Learn-ing in which relational information is used to transfer knowl-edge from different domains. In [13] the source domain is documents and the target domain is images labeled with tags while in [26] the source and target domains are text documents in different languages.
 Multi-modal Similarity and Metric Learning. Learn-ing with heterogeneous data has been addressed using Simi-larity Learning [15] and Metric Learning [23,28]. While these works address a similar problem, they differ greatly from our work. First, none of these works propose incorporat-ing weighted guidance and [28] does not allow intra-dataset guidance. [15] requires solving an expensive semidefinite pro-gram. [23] suggests a graphic model for metric learning with heterogeneous data with the goal of being more scalable locations. From left to right, k = 2 , 5 , 10 . than [15]. While their framework is more scalable, the opti-mization problem they propose cannot be solved for exactly and has many parameters that need to be set which makes it more difficult to use than our framework. The complexity of modern data sets has made analysis a great challenge. A growing tend is for data to be heteroge-neous consisting of fundamentally different data from differ-ent sources. An elegant method is to project such data to a common space so standard algorithms can be used, but ex-isting methods make strong assumptions such as there being overlapping instances or features to perform this projection. We proposed a flexible technique for embedding heteroge-neous data into a common space. Our method differs from existing work in that it can provide weighted, positive and negative guidance using both inter-dataset and intra-dataset relationships. Most importantly, it does not assume the in-stances or features in the different data sets overlap. Exist-ing multi-view work such as CCA typically can only provide positive unweighted guidance of limited cardinality (that is each instance can be paired with only a single other in-stance). Though manipulating the data can help alleviate some of these situations, such as duplicating instances to re-move the cardinality restriction, we seek a more principled method.
 Our spectral formulation learns a projection vectors for each data set such that intra-dataset and inter-dataset guidance is respected. Guidance takes the form of weighted values be-tween  X  1 (dissimilar) and 1 (similar) with no limits on the amount of guidance given for a particular instance. In our experimental results testing the embedding (see Figure 6) we see that our method does a good job of of embedding the data to respect the guidance given to it. In our exper-iments our method performs better than or at least com-parable to CCA for both classification and clustering appli-cations. Our classification experiments use the embedding our method learns to perform K-Nearest Neighbors classifi-cation (see Figures 7 and 8). Our results on clustering show that it produces meaningful clusterings (see Figure 9) whose Rand index (see Figure 10) is better than those achieved by a comparable method.
 Our plans for future work are to explore further uses of em-bedding data into a common space and in particular explore new forms of guidance. Additionally, we plan to investigate connections between our work and Spectral Graph Theory. The authors gratefully acknowledge support of this research via ONR grants N00014-09-1-0712, N00014-11-1-0108 and NSF Grant NSF IIS-0801528. [1] Sugato Basu, Ian Davidson, and Kiri Wagstaff. [2] Mikhail Belkin and Partha Niyogi. Laplacian [3] Ian Davidson. Knowledge driven dimension reduction [4] Gene H. Golub and Charles F. Van Loan. Matrix [5] Yunchao Gong, Qifa Ke, Michael Isard, and Svetlana [6] Jihun Ham, Daniel Lee, and Lawrence Saul.
 [7] David R. Hardoon, Sandor Szedmak, Or Szedmak, [8] Xiaofei He, Deng Cai, Shuicheng Yan, and Hong-Jiang [9] Xiaofei He and Partha Niyogi. Locality preserving [10] Harold Hotelling. Relations between two sets of [11] Kalervo J X rvelin and Jaana Kek X l X inen. Ir evaluation [12] R. B. Lehoucq, D. C. Sorensen, and C. Yang. Arpack [13] Yuan Lin, Yuqiang Chen, Gui-Rong Xue, and Yong [14] David G. Lowe. Distinctive image features from [15] Brian McFee and Gert R. G. Lanckriet. Learning [16] Sinno Jialin Pan and Qiang Yang. A survey on [17] Yanwei Pang, Lei Zhang, Zhengkai Liu, Nenghai Yu, [18] Novi Quadrianto and Christoph Lampert. Learning [19] Sam T. Roweis and Lawrence K. Saul. Nonlinear [20] Ajit P. Singh and Geoffrey J. Gordon. Relational [21] Lieven Vandenberghe and Stephen Boyd. Semidefinite [22] Chang Wang and Sridhar Mahadevan. A general [23] Pengtao Xie and Eric P. Xing. Multi-modal distance [24] Eric P. Xing, Andrew Y. Ng, Michael I. Jordan, and [25] Shuicheng Yan, Dong Xu, Benyu Zhang, and Hong [26] Qiang Yang, Yuqiang Chen, Gui-Rong Xue, Wenyuan [27] Xuesong Yin, Qi Huang, and Xiaodong Chen.
 [28] Xiaohua Zhai, Yuxin Peng, and Jianguo Xiao.
 [29] Weifeng Zhi, Xiang Wang, Buyue Qian, Patrick [30] Yin Zhu, Yuqiang Chen, Zhongqi Lu, Sinno Jialin
