 Named Entity Recognition is a subtask of information extraction. Its purpose is to identify and classify certain proper nouns into some predefined target entity classes such as person, organization, location and temporal expressions.
Much previous work on NER followed the supervised learning approach [2], [3], [9], [12], [15] which requires a large hand-annotated corpus. Such approaches can achieve good performances. Howev er, annotating such a corpus requires a lot of human effort. This problem can be solved by using a sequence-based semi-supervised method that trains a classification model on an initial set of labelled data, makes predictions on a separate set of unlabelled data, and then iteratively attempts to create an improved model using predictions of the previously gener-ated model (plus the original labelled data). Based on this method, we propose a semi-supervised learning method for r ecognizing named entities in Vietnamese text by combining proper name coreferen ce, named-ambiguity heuristics with a powerful sequential learning model, C onditional Random Fields (CRFs). Our approach inherits the idea of Liao and Veeramachaneni [6] and expands it by using proper name coreference. Starting by training the model using a small data set that is tagged manually, the le arning model extracts high confident named entities with and finds low confident NEs by using proper name corefer-ence rules. The low confident NEs are put in the training data set to learn new context features.
 Example 1. (a) /It rains heavily in (b) /The govern-In Example 1, both  X  /Hochiminh city X  and  X   X  are Location entities and refer to one lo cation. However, the system can only find one Location entity with high confident score, which is  X  entity by the system since the confidence score of this phrase is smaller than the threshold. Based on the coreferent rules, the system discovers that  X  that point of view,  X   X  is considered as a low confidence part of  X  entity. It is put in the training set to relearn the new feature context.
In addition, based on our empirical study, several named entity (NE) rules are manually added to the system, in order to create new training data from unlabelled text.

The rest of this paper is organized as follows. Section 2 introduces recent studies on semi-supervised NER methods and works that inspire our research. Section 3 briefly introduces include CRF and the training and inference of the CRF. Section 4 discusses the semi-supervised NER problem for Vietnamese text and our solution to this problem. Section 5 analyzes our experimental results. Finally, our conclusions and future work are given in Section 6. The term  X  X emi-supervised X  (or  X  X eakly supervised X ) is relatively recent. The main technique for semi-supervised learning is called  X  X ootstrapping X  and involves a small degree of supervision for starting the learning process.
Niu et al [13] present a bootstrapping approach for NER. This approach only requires a few common noun/ pronoun seeds that correspond to the concept for the target NE type, e.g. he / she / man / woman for Person entity. The entire boot-strapping procedure is implemented as training two successive learners: (i) a decision list is used to learn the parsing -based high precision NE rules; (ii) a Hidden Markov Model is then trained to l earn string sequence-based NE pat-terns. The second learner uses the training corpus automatically tagged by the first learner.

Mohit and Hwa [11] used Expectation Maximization (EM) algorithm along with their Na  X   X ve Bayes classifier to form a semi supervised learning framework. In this framework, the small labelled dataset is used to do the initial assignments of the parameters for the Na  X   X ve Bayes classifier. After this initialization step, in each iteration the Na  X   X ve Bayes classifier classifies all of the unlabelled examples and updates its parameters based on the class probability of the unlabelled and labelled NE instances. This iterative procedure continues until the parameters reach a stable point. Subsequently, the updated Na  X   X ve Bayes classifies the test instances for evaluation.

Perrow and Barber [14] take advantage of the simple idea that if a term is annotated with a label in one name, it is highly likely that this term should be annotated with the same label everywhere in the data. Then they annotated this label everywhere in the corpus, assuming that the annotations are the same unless explicitly told otherwise (by further annotations). In this way, they used all the data in the corpus, containing largely only partially annotated records. To learn the parameters (the transition and emission probability tables) they use the Expectation Maximization (EM) algorithm which is an iterative algorithm that increases the likelihood of the corpus given the model parameters in each iteration.

The Yarowsky algorithm [17], originally proposed for word sense disambigua-tion, makes the assumption that it is very unlikely for two occurrences of a word in the same discourse to have different senses. This assumption is exploited by se-lecting words classified with high confidence according to sense and adding other contexts of the same words in the same discourse to the training data, even if they have low confidence. This allows the algorithm to learn new contexts for the senses leading to higher accuracy.

Wong and Hwee [16] use the idea of multiple mentions of a token sequence being to the same named entity for feature engineering. They use a named entity recognition model based on the maximum entropy framework to tag a large unlabelled corpus. Then the majority tags of the named entities are collected in lists. The model is then retrained by us ing these lists as extra features. This method requires a sufficient amount of manually tagged data initially to work.
Liao and Veeramachaneni [6] repeated learning to improve training corpus and the feature set by selecting unlabelled data that has been classified with low confidence by the classifier trained on the original training data, but whose labels are known with high precision from independent evidence. They propose two strategies of obtaining such independent evidence for NER. The first strategy is based on the fact that multiple mentions of capitalized tokens are likely to have the same label and occur in independently chosen context and call that the multi-mention property. The second stra tegy is based on the fact that entities such as organizations, persons, etc., have context that is highly indicative of the class, yet is independent of the other cont ext (e.g. company suffixes like Inc., Co., etc.; person titles like Mr., CEO, etc.). They use two heuristics to find the low confidence sequence tokens. In the first heuristics, if the sequence of tokens has been classified as (Organization, Person, Location) with high confidence score (larger than a threshold T), their syste m forces the labels of other occurrences of the same sequence in the same document, to be (Organization, Person, Location) and adds all such duplicate sequences classified with low confidence (smaller than T) to the training data for the next iteration. The second heuristics is removing company suffix or person title from the sen tence. Then the system reclassifies the sentence after removing the company s uffix or person title and checks whether the labels have low confidence score or not. If it has low confidence score, the sequence will be added to the training data.

Our research bases on [6] and expands it by combining proper name corefer-ence, named-ambiguity heuristics with a powerful sequential learning model, Con-ditional Random Fields. This approach will be discussed in detailed in Section 4. Conditional random fields are undirected graphical models trained to maximize a conditional probability [7].

A linear-chain CRF with parameters  X  = {  X  1 ,..., X  N } defines a conditional probability for a state (or label) sequence y = y 1 ,...,y T given an input sequence x = x 1 ,...,x T to be where T is the length of sequence, N is the number of features, Z x is the normal-ization constant that makes the probability of all state sequences sum to one, f ( y t  X  1 ,y t , x ,t ) is a feature function which is often binary-valued, but can be real-valued, and  X  k is a learned weight associated with feature f k . Large positive values for  X  k indicate a preference for such an event, while large negative values make the event unlikely.

The weights of a CRF,  X  = {  X  1 ,..., X  N } , are a set to maximize the conditional log-likelihood of labelled sequences in some training set, D = { ( x 1 , l 1 ) , ( x 2 , l 2 ) ,..., ( x M , l M ) } : where the second sum is a Gaussian pr ior over parameters (with variance  X  )that provides smoothing to help cope with sparsity in the training data.
When the training labels make the state sequence unambiguous (as they often do in practice), the likelihood function in exponential models such as CRF is convex, so there are no local maxima, and thus finding the global optimum is guaranteed. It has recently been shown t hat quasi-Newton methods, such as L-BFGS, are significantly more efficient tha n traditional iterative scaling and even conjugate gradient [10].

Inference in CRF is to find the most probable state sequence y  X  corresponding to the given observation sequence x . In order to find y  X  , one can apply the dynamic programming technique with a slightly modified version of the original Viterbi algorithm for HMMs. The training module of our NER takes as input a small set of Vietnamese documents that have been annotated for three types of named entities in-cluding Person, Organization and Location, e.g., ! &lt; Person &gt; "#$ % &amp; &lt; /Person &gt; ' ( ) *+ '# , &lt; Orgnization &gt; , -. / 0 12 "3 &lt; /Orgnization &gt; /Mr.Nguyen Canh Luong currently keeps the position of vice-president of Hanoi University of Science and Technology.
The model after one training step is used to repredict unlabelled training data. The confident score is computed to find the high confidence NEs. The low confident NEs are then found based on the confident score and heuristics.
Section 4.1 presents Vietnamese characteristics that involve the organization of named-entities, in order to create heuristics for finding low confidence NEs. From that point of view, the heuristics are used in our system are proposed. Section 4.2 introduces the semi-supervised learning algorithm for recognizing named entities. 4.1 Characteristics of Vietnamese Proper Names There are some cases of ambiguities be tween entities in Vietnamese text, as shown below. 1. Case 1: One name or one NE is a part of another NE. More specifically, 2. Case 2: The recognition of a name entity depends on its context. For These ambiguities will be considered to cr eate NER rules, as reported in Section 4.2.

Beside the above rules, the forms of named entities in Vietnamese are also considered to recognize NE. These forms are shown below:  X  Person Names: [prefix] + [family name] + [middle name] + name  X  Organization Names: [prefix] + [category] + [category of business] + name  X  Location Names: [prefix] + name In the above forms,the words in the square brackets are optional and the name can sometimes be abbrevia ted. This abbreviation can be placed in round brackets or not. Based on above forms, Nguyen and Cao [5] created the proper name coreference rules for Vietnamese text as shown in Table 1.

Some rules in Table 1 can be applied suitably with other languages. For ex-ample, rule 2 can be used to find name coreference in English, e.g, Steven Paul Jobs and Jobs. Specific rules for a certain language are also welcoming to make our system more efficient when being operated for that language. 4.2 Semi-supervised Learning Algorithm Based on the idea of Liao and Veeramachaneni [6] , our system starts by training a model from a small labelled data L . This model is used to find new training data from unlabelled text. After extract ing NEs by using the model getting from the training process, the low confidence NEs in unlabelled texts are detected by using heuristics for proper name corefe rence, some special rules, and rules for resolving ambiguity problems in labeling entities. The system is then retrained on the new data which includes low confidence NEs above. This process is repeated until the system cannot be improved. The algorithm is shown in Table 2 below.
In the training process (Step 1), training documents are first parsed by a Part of Speech (POS) tagger [8] to split documents into words and to get the syntactic roles of words in the sentences. Then features used in the CRF algorithm are calculated and a model C is build. The features are common features that are widely applied in other NER systems. These features are the word itself, the orthographic feature, the gazetteer feature and the POS of the current word, two words before and two words after the current word. In other words, all above mentioned features are calculated for the window size of five. In the extracting process ( Step 2), the unlabelled documents are parsed by a POS tagger and calculated all features like Step 1. Then, these documents are labelled by the classifier that is produced by using the model C received from Step 1.The documents after being labelled in this process are called labelled documents. After the labeling process, the confidence scores are calculated by using constrained forward-backward algorithm [4] (Step 2.1). This algorithm calculates the sum of probabilities of all paths passing through the constrained segment (constrained to be the assigned labels).

Then, all NEs (Person, Location, Organization) that have high confidence scores (the score is la rger than a threshold t 1) will be combined with the proper name coreference rules in Table 1 to create searching patterns. The NE with a high confidence score is called a high-confident NE. Each searching pattern is accompanied by the label of the high-confident NE that produces that pattern. For examples, if the old C finds that the phrase  X  "#$ /Nguyen Chi Mai X  is a Person entity with high confidence score, after applying proper name conference rules, the patterns  X   X ,  X  "#$ /Nguyen X ,  X   X  X nd X  "#$ /Nguyen Chi Mai X  are detected. These patterns are also tagged as Per-son. With these produced patterns, we perform a process of pattern matching on the labelled documents to extract matched sequences of tokens, called entity candidates. Each entity candidate is assigned a label which is similar to the label associated with the pattern it matches (Step 2.2). The candidates which have low confidence scores (the score is smaller than t 2) or have no label in terms of the old model will be added to the training data with their assigned labels (Step 2.5 and 2.6). These entity candidates are considered as  X  X ood entity candidates X . This heuristics is called heuristic Group 1.

The reason for using two thresholds t 1 2 and t 2 3 is to ensure only the new knowledge that the old model does not have is added to the training data. The NEs whose confidence score is in the range of t 1and t 2 are not used for finding new NEs and are not added to the training data to avoid potential ambiguities. As mentioned in Section 4.1, there are several ambiguities in Vietnamese text. Due to these ambiguities, some good entity candidates found above may not be real entities, but are parts of other entities. They may have been assigned with a label different than their correct labe l. To solve this problem, the good entity candidates are processed further as indicated below: 1. Post process 1: In the labelled documents, for each of the good entity can-2. Post process 2: if a good entity candidate or the NP that replaces an NE Besides the above heuristics, the system also uses other NER rules that are proposed by us, based on our empirical study. These rules are called Group 2 and are shown in Table 3 below (Step 2.3). Again, some modifications and/or additions that are specific for different languages can help the system adapt successfully to other languages.

In addition, to balance the training data, the word which is predicted as O by C with high confidence score and satisfies one of three conditions (contains no capitalized token, is not a number, is not in a stopword list) will be added to the training data (Step 2.4).

Since the window size is five (two words on the left and two words on the right of the current token), features of t wo consecutive tokens before and after the low confidence NEs are also added to the training data.
 Table 5 show the result of nine iterations of the process when the heuristics in Group 1 and Group 2 are used.

Our experiments use 900 unlabelled documents, and 50 documents labelled manually. Each document contains about 750 tokens. All of these documents are taken from newspaper websites on economi cs, politics, cultures and education. 50 labelled documents are taken as initial training data; and 900 unlabelled documents are used as testing data. After each round running the training pro-cess, 100 documents from those 900 unlabelled documents are taken to find low confidence NEs.

Three experiments were carried out: (i) using the two heuristics in [6]; (ii) using the heuristics in Group 1; and (iii) using the heuristics in Group 1 and Group 2. The results are shown in Table 4 below.

These experiments are evaluated base d on Precision, Recall, and F-measure, in which:  X  Precision ( P ): number of correctly assigned labels divided by the total  X  Recall ( R ): number of correctly assigned labels divided by the number of  X  F-measure: F = 2  X  P  X  R Table 4 shows that when the proper name coreference heuristics are used, the results are better than when using the heuristics in [6], especially for the Location and Organization entities. This is because the Location and Organization entity in Vietnamese text are very complicated. When the heuristics in Group 1 and Group 2 are used, the system a lso receives higher F-scores.

Table 5 shows that the more new data is added to the training data, the more accurate the system is. If a bigger corpus is used, the system promises to provide a higher accuracy. This paper presents a semi-supervised l earning method for recognizing named entities in Vietnamese text. The system starts by training a model with a small labelled data set using CRFs algorit hm, then the received model is used to find new training data from unlabelled text. After extracting NEs by using the model getting from the training process, the low confidence NEs in unlabelled text are detected by using h euristics for proper name coreference, some special rules, and rules for resolving ambiguity problems in labeling entities. The system is then retrained on the new data which includes these low confidence NEs. In evaluating the system, our experiments are carried out with the heuristics mentioned above and the heuristics in [6]. The experimental results show that our heuristics outperform the heuristics in [6]. Our future work includes: (i) carrying out experiments with a larger corpus; (ii) investigating other rules that can improve the accuracy of the system; and (iii) experimenting the system with other entity types.

