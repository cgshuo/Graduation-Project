 As consumers accumulate more and more personal imagery, searching for specific images has become increasingly difficult. Consumers typically provide little or no annotations, and automated classifiers and concept tagging tools are limited in their scope and vocabulary. This work addresses this sparsity of semantic information by levera ging domain-specific information provided by online photo-sharing communities. Such information enables improved search by allo wing user-provided search terms to be expanded into a set of semantically related concepts, using relevant semantic relationships provided by millions of users. Our system first extracts meta data using a modest number of image and event-based semantic classifiers, as well as any meaningful file or folder name s. When users pose text-based queries, our system retrieves images from their personal image collections by leveraging Flic kr X  X  tag dataset for concept expansion. This approach enables users to search their collections without having to manually annota te their pictures. We compare the retrieval performance of us ing a Flickr-based concept expander with the performan ce obtained without concept expansion and with using a WordNet-based concept expander. The results demonstrate that common sense knowledge gleaned from online photo sharing communities can enable meaningful image search on consumer image collections, searches that would be impossible using only the available image metadata. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval .
 Algorithms. concept expansion, Flickr, image search, multimedia search, multimedia retrieval, semantic search, WordNet As consumer collections of pe rsonal multimedia grow, so grows the challenge of finding a particular , or even a relevant, asset. A consumer wishes to find a part icular picture they vaguely remember, perhaps to reminisce, or to include in a special creative work. Or, the consumer is interested in searching for types of pictures X  X rom a certain place, of a particular person, etc. Without automated tools for image retrieval, the consumer must potentially browse through their entire collection, examining each asset to see if it matches what they seek. The ability to search and retr ieve assets hinges upon two key pieces of functionality: the ability to express or describe what one characterize how well each asset satisfies the specified query. Query interfaces may take di fferent forms, including both graphical and textual modes. Graphi cal or visual interfaces can be effective for certain applications, but require some sort of visual example. Text-based interfaces allow users to describe what they are looking for, using terms from their natural language. Consumer image search terms typically can be separated into who, what, when, or where categories. The query may be expressed as a list of keywords, such as  X  X lorida vacation, X  or it may be a more complex expressi on, such as  X  X ictures of the crocodiles we saw while vacationing in the Everglades. X  The latter form requires complex na tural language parsing to extract the semantic concepts, such as  X  X here=Everglades, Florida, X   X  X hat=crocodiles, X  and  X  X hen=v acation. X  Matching these queries against a set of pictures re quires having the corresponding semantic information either available or readily inferable for each asset. Few people invest the time and energy required to tag their images, although some might group related photos into folders with a descriptive name; for photos of particular importance, they might even rename the file. Metadata recorded by the capture device, such as the capture date and time, provides basic  X  X hen X  information. Although still relatively rare, geospatial information is increasingly becoming available and recorded at capture time, providing valuable location inform ation. Automatic extraction of semantic information using peop le and object recognition, along with scene and material classifiers, can greatly increase the amount of available semantic information, although the performance of such classifiers varies. This work focuses on text-based queries and specifically considers mechanisms for bridging the concepts used by consumers to describe their search target with the concepts used by the system to describe the assets it has indexed. In this work, a consumer X  X  image collection is first indexed using various semantic indexers or classi fiers to produce a high-level characterization of each asset. The semantic indexers include image understanding algorithms such as scene, material, and color classifiers, as well as algorithms that interpret image Exif data. Optionally, the indexing process may also include user-provided content such as image captions or even the image pathname. The results from all of these indexers are combined to form a unified characterization for each asset in the form of a bag of concepts, such as { X  X acation X ,  X  X aster X ,  X  X alm Springs X ,  X  X amily X ,  X  X aby X ,  X  X each X , ...}. To search against the collection, the user enters in a text-based query. Query terms are run through a concept expander to produce a more complete set of related concepts. A common approach for concept expansion is to use the WordNet [3] lexical database. The linguistic mappings performed by WordNet are just that X  linguistic mappings. They do not capture common sense relationships such as the fact that fireworks are often associated with July, or that flowers are often red or yellow. An important part of this work is to levera ge such common se nse relationships whenever possible to improve the search results. Numerous online photo sharing communities such as Flickr, Photobucket, and the Kodak Gallery enable users to tag pictures with labels, which can provide a rich source of knowledge about commonly related concepts. Flickr is one of the larger such communities, containing over four billion uploaded photos [6]. This site is popular with photo enthusiasts as well as consumers simply interested in sharing thei r photos. Flickr permits individual photos to be tagged with up to 75 distinct tags. Our system uses the Flickr getRelated API [7] to map a search term to a set of terms that are likely to co-occur as labels in the Flickr database. The Flickr getRelated function returns for a given tag, the set of tags that are most frequently used together with that tag in tagging images. Such co-occurring terms may not be linguistically related. However, because they are likely to appear together as labels on images, and as the goal of this work is to search consumer image collections, their co-occurrence as Flickr tags makes them reasonable expansion te rms. This work compares the quality of the search results using the raw search terms as provided by the consumer with concept expansion based on Flickr and WordNet. Our work focuses on taking the user from an unindexed collection to initial search results, by combining semantic indexing with Flickr-based concept expansion. Given the sparse and imprecise semantic characterization of assets used by our system, we do not expect every search result to be relevant. However, people have become accustomed to searching for information using tools such as Google, which return back a page ful of responses, with the user visually skimming those results for relevance. Once a relevant item is found, the user can go directly to that result, and perhaps use that result as a launching pad to other relevant results. In the same manner, this system returns back a set of ranked results, which should be viewed as just the first step in information retrieval. As long as at least on e returned result is relevant, the system has given the user a starting point into their collection. A complete system would then provide the user with other tools for branching out from that image to other images. Secondary navigation strategies might incl ude retrieving other images from the same event, featuring the same person, or having similar visual features. Related work is reviewed in the next section. Section 3 discusses background research conducted to understand the types of queries consumers wish to conduct. S ection 4 describes the system architecture, and Section 5 presents the details of our concept expansion methodologies. We presen t the experimental results of our system in Section 6 and cl ose with a final discussion in Section 7. Representing concepts as terms and applying statistical text retrieval techniques for image retrieval is not new. In [17], the authors propose a retrieval system that represents both multimedia documents and queries as sets of feature terms using Boolean vectors, and uses statistical text retrieval models to perform relevance calculations. The work described here, while using a statistical retrieval model, leve rages the Indri [19] text-based information retrieval system with a simple, keyword-based representation of image concepts, in order to allow us to focus on the primary purpose of this research X  X oncept expansion for consumer image searches. Past work has looked at a variety of means for concept expansion, including common sense knowledge . For example, [14] uses semantic concept expansion by leveraging the Open Mind Common Sense (OMCS) Knowledge Base as its source of real-world knowledge. Rules are derived from the OMCS knowledge base and represented as a type of semantic network, specifically, a weighted graph of concepts. Co ncepts are then expanded using spreading activation. The approach described here also seeks to use common sense knowledge for its concept expansion, but leverages Flickr as its basis fo r that common sense knowledge. In particular, in this work, the co-occurrence of tags as used to tag images within Flickr serves as a source of common sense knowledge. Although this form of common sense knowledge is weaker than OMCS or a formally constructed knowledgebase such as Cyc [12], it is directly related to the subject matter of consumer photography and is readily available in an already-analyzed form. Alternative approaches for con cept expansion rely on lexical techniques. In [8], the authors us e the lexical database WordNet X  X  synonym, hypernym, and hyponym relationships to expand queries for images on the Web. Using a lexical expansion mechanism such as WordNet can easily result in irrelevant concepts being used as part of the expansion. For example, words commonly used in English often have multiple meanings or senses. Using WordNet terms for an unintended sense of the word may result in noise and decreased precision in the search results. To address this problem, [8] filters search terms by using a term semantic network (TSN) that is specific to their collection. The term semantic network is constr ucted by using an association mining algorithm to establish one -to-one relationships between words. The strength (or weakness) of these relationships is then used to filter out expansions sugg ested by WordNet. This type of approach may be applicable to both the Flickr and WordNet expansion mechanisms used in our work, but further work would be needed to determine how this approach might apply to this domain. Unlike [8], our work searches over a user X  X  personal image collection, and the vocabulary associated with the collection is likely to be much smaller than would be present in a Web-based search system. Our system can also incorporate WordNet X  X  synonym, hypernym, and hyponym relationships as part of its expansion mechanism; however, such relationships are rather limited. The language-b ased expansion provided by WordNet is not likely to indicate that beache s are often associated with vacations, or that manatees are associated with Florida, but such common sense associations are available from Flickr. The wealth of information available via sources such as Flickr has previously been harnessed for th e related problem of annotating images; for example, in [18], the authors describe a system for suggesting additional tags fo r pictures based upon a limited snapshot of Flickr X  X  database. An earlier work [1] provided the user with a way to iteratively se arch through a subset of images downloaded from Flickr by either specifying tags, or by searching for visually similar images. The work described in [2] considered two semantic similarity measures for video retrieval, one based on the Lin metric for word similarity, and the other based on a metric of pointwise mutual information for information re trieval, PMI-IR. The better performing PMI-IR approach com putes similarity between any two concepts by measuring the li kelihood of text co-occurrence in web documents as reported by Yahoo search; the Lin metric uses WordNet as its knowledgebase. Although our implementation is currently for still imagery, our technique should be readily applicable to video; likewise, th eir technique should transfer to still images. Our work uses a domain-specific knowledgebase (Flickr) for determining co-occurre nce rather than arbitrary web documents. A different approach to this problem is adopted in [13], where the authors also implement text-bas ed queries on consumer image collections. In [13], the authors use the query to first identify relevant and irrelevant images from a set of 1.3 million images obtained from the Photosig.com online community, which are then used to train k-nearest neighbor and decision stump classifiers, which are then used to rank the consumer images. Although our approach requires precomputing both semantic descriptors for each asset as well as tag co-occurrence metrics, these computations are done in advance and they do not impact the retrieval performance. This work is distinguished from the prior work in that it provides a model for a consumer-centric system for fast real-time image retrieval, where the consumer is not required to perform any further tagging tasks beyond what they might normally do. By leveraging web-accessible domain-specific semantic information obtained from the Flickr photo-shar ing community, the system is able to significantly enhance the value of available metadata, enabling the system to accurately retrieve assets from the collection. We conducted an online survey to characterize how consumers would like to query their personal image and video collections. As part of the survey, we asked users to submit five to ten top text queries that they would like to pose to their image and video collections. A total of 4813 queries from 932 different American-based users were analyzed. The length of user queries was an average of two words, with a standard deviation of 1.3 words and a median of two words. This is about one word less than that reported for general web searches [11] and about two words less than that reported for web-based image searches [9][10], although the latter case includes words such as  X  X mage X  or  X  X peg X  as part of the query. In terms of query content, each query was translated into a sequence of query codes and the que ry codes were organized into a query ontology. High-level results show that users query most frequently by when, then by who, other, what, and where. The top  X  X hen X  query terms included event references (e.g., Thanksgiving) and year. The top  X  X ho X  query terms referenced a person by first name. The top  X  X  ther X  query terms consisted of connector references such as  X  X nd X ,  X  X f X , and  X  X t X . The top  X  X hat X  terms referred to things such as pets or nature. The top  X  X here X  terms referred to citie s. The top query term pairs consisted of when-when queries (e.g., Christmas 2008) and who-when queries (e.g., Mom X  X  birt hday). The survey results were used to inform the developmen t and evaluation of our image retrieval system described herein. The system consists of several major components illustrated in Figure 1. The system runs indexe rs on the user X  X  personal image collection to produce descriptive conceptual data, represented as one descriptor document per imag e. These descriptor documents are then indexed using the Indri information retrieval system. The query processor takes user queries and expands them into queries for Indri, using Flickr and WordNet (not shown) to obtain an expanded set of concepts. The ex panded search terms are supplied to Indri, with the resulting image descriptors returned to the user interface to display the appropriate image thumbnails. The asset descriptor documents are simple XML-based documents containing semantic descriptors. Th is type of document structure was used to enable the use of the Indri information retrieval system for indexing. Figure 2 illustrates the body of an asset descriptor, which is describe d further in Section 4.3.2. Figure 3 provides a screenshot of the system in action. A separate mode was used for testing and co llecting ground-truth data. In the example, the user had entered the search term  X  X anatee X  and requested that the system perf orm the search using only the Flickr-based concept expansion methodology. The lower left shows the returned results by file name, along with their respective scores; the lower right shows image t humbnails. In the example, all four pictures in the first row of pictures and one picture in the second row portray manatees. A key goal of this work is to enable image retrieval in the absence of user-provided annotations. To th is end, the system employs as many conceptual level indexers as feasible. These indexers use advanced image understanding and recognition techniques to automatically label images or video clips with semantic concepts typically associated with consumer imagery. To determine which indexers to run, we must trade off the cost of running the indexer with the expect ed return, i.e., the quality of the conceptual information provide d by the indexer. The system currently includes a variety of customary scene and material classifiers (e.g., mountain, be ach, and water) as well as a probabilistic event classifier [3], which classifies an event into one of four types: vacation, family moment, party, or sports. The event classifier uses both image-level features such as people present, indoor/outdoor, and type of scene detected (e.g., nature, urban, beach), and event-level f eatures including inter-event time and the time of day. Face detectors are combined with age and gender estimators to infer high-level conceptual descriptors of the people portrayed in an image, using terms such as baby, boy, girl, man, and woman. Related concepts provided by Flickr often include color names; the system uses a color analyzer to generate image color labels from a list of twelve common color names [4]. Running all the various pixel-based image indexers may take up to a second per image to run, or more, depending on the speed of the machine, but such classifiers are expected to be run in the background, in advance of any retrieval operations. Most cameras record the time of capture with the image, and this information can be a valuable source of semantic information. An auto-event labeler maps the date to the name of a holiday, such as Christmas. The current auto-event labeler is primarily aware of American holidays, but could be easily adapted to incorporate different calendars for other loca lities and cultures; it could also be extended to be aware of personal calendar items such as birthdays. Similarly, the date an d time are mapped to time of day as well as the season of the year. Some cameras record the latitude and longitude of where an image was captured; alternatively, such information is often added afterw ards by the user. If geospatial information is available, the sy stem uses the online geonames.org web service to reverse geocode th e latitude and longitude to the place name as well as to an expected geospatial feature type, using terms from the geonames.org vocabulary, such as park or school. Finally, should the user have provid ed the system with any type of annotations, such information is also included in the image descriptor. While users seldom provide captions, they often do give the file or containing folder a descriptive name. Our system uses the Indri information retrieval system to rank and retrieve asset descriptor docum ents. Corresponding images can then be easily retrieved and displayed to the user, as shown in Figure 3. In this section, we pr ovide an overview of Indri and how it is used within our image retrieval system. The Indri information retrieval system [19] is a hybrid document search engine, based upon a combination of language modeling and inference network retrieval [15]. A language modeling system is one in which the system computes an estimated probability for generating a given query, given a pa rticular language model for a document. The document language model is not the document itself, but can be thought of as a se t of probabilities, or priors, for the words in a given vocabulary. Us ing this model, the probability that a given word is in a document can be estimated. Using the simple maximum likelihood a ssumption, the probability p given term w occurring in document D is defined as follows [16]: where number of words in the document. The maximum likelihood assumption is seldom used in practi ce. If a word is not present in a given document, the maximum lik elihood assumption results in a zero probability. To avoid this problem, most retrieval systems apply a smoothing function. We used Indri X  X  default, the Dirichlet smoothing function. Using this smoothing function, the probability of a given term r , given a document D, is defined as: where D r tf , is the term frequency of r in D, ) | ( C r P is the probability of r given the entire collection of documents C, and provides the smoothing function; if  X  is 0, then the formula degenerates to the maximal likel ihood assumption (1). The default value for  X  in Indri is 5000. Preliminary testing of our system indicated that the retrieval performance was improved by using a smaller value of  X  . This is consistent with previous research on smoothing [20], which indicates that if the queries are small, as is expected in our system, then smaller values of  X  results. Larger values of  X  result in more smoothing, and consequently decrease the precision of the results. We used 750 in our tests. The term ) | ( C r P represents the probability of a given term r for a given collection of documents C. This probability may be modeled by considering the re lative frequency of each term appearing in the collection. In this case, note that (2) still returns a value of zero for terms that do not appear in any document in the collection. The Indri inference network model applies Bayesian logic to define how complex queries ma y be composed from simpler terms. The leaves of the inference network are the representation nodes, corresponding to the probability of a given term appearing in a document, using the languag e model. Various representation nodes may be combined using beli ef nodes, using both weighted and unweighted belief operators [16]. The #combine operator is an example of an unweighted belie f operator, defined as follows: The b i are the values of the constituent n belief nodes, which may be either the base probabilities for the representation nodes X  X he individual search terms X  X r other belief nodes. The weighted equivalent is #weight, defined as The w i specify the weights to be associated with each belief node. Indri defines a relatively rich set of belief operators that allow arbitrarily complex inference networks to be constructed. Indri combines the inference network model with the underlying language model to compute for a given query, the probability that a given document model satisfies that query. The document model is a smoothed multiple-Bernoulli distribution representation of a document. The overall probability that a given document satisfies a query is represented by the document node, which combines the various document models into a single probability. The probabilities from a set of docum ents from a document collection may be used in order to compute a rank ordering. Queries are made in Indri using a high-level query language, which supports operators such as #combine and #weight, as well as additional operators, includ ing proximity operators and filtering operators. Indri is designed as a document retrieval system. As such, its model was not a perfect match for using it to match probabilistic data generated by some of our image indexers. For example, our scene classifiers generate numeric scores. The asset document creator normalizes this score and then outputs the concept term a variable number of times, in pr oportion to how highly the term scored. This introduces round-off error, and the computed probability will depend upon the smoothing function. Indri provides a way to specify tabl es of priors, and this approach was originally used to model the probabilistic data associated with the scene and material classifiers. However, when queries contain a mixture of terms, some associated with data for which priors are specified, and some not, the priors had an undue impact on the outcome. For example, consider the term  X  X ountain. X  Our scene classifier included a mountain scen e detector, so it was possible to generate a table of priors specif ying for each image some prior probability that the document contained this term, based on the output of the scene detector. An asset descriptor document might contain the term mountain independe nt of the scene detector. For example, the geospatial indexer may have reverse geocoded the GPS coordinates to determine th at the picture was taken on a mountain. Or the user may have provided the term mountain as part of a caption or the filename. These other sources of information could even be more accurate than the scene classifier. Ideally the two sources of info rmation should be seamlessly woven together to form an overa ll probability that the mountain concept belonged to an image. However, merging these two sources of data proved to be problematic. Although the asset document generator could scale the priors as needed, it appeared that it would require considerable document analysis to determine the scaling function. Instead, we observed a major discontinuity in the computed probabilities between those based on a prior value and those based solely on the presence of the word in the document. Without a way to smoot h the differences between the two types of probabilities, the sy stem returned anomalous scores. To avoid this problem, we adopted the simple approach of making the frequency of such terms in the asset descriptor dependent upon their probability or score. For example, Figure 2 shows a sample asset descriptor document where the corresponding image has a higher probability of portraying rock than water. Flickr provides a means for people to tag pictures with one or more keywords; it also supports a flexible API for developers to access Flickr content and summar izing data. This API includes the method getRelated, which return s a list of tags related to a specified tag, based upon cluster analysis performed by Flickr. The details of the algorithm used to compute related tags has not been published. However, it appears that the returned list of tags is the set of keywords most likely to co-occur with the specified tag. We use the getRelated API in this work as a source of common sense information. This interface provides us with a set of related concepts, and one ti ed to the domain of interest: consumer photography. Although th e Flickr community includes a disproportionate number of pros umer and professional content, it also contains a considerable amount of  X  X veryday X  photos X  activities, events, and places that could apply to almost anyone. Some examples will illustrate the type of content provided by this interface. For the keyword  X  X acation, X  the getRelated method returns the following list: For the keyword  X  X urkey, X  getRelated returns the following: The latter list indicates the am biguous nature of the term X  X t could be referring to the country of Turkey, or the bird. As keeping with the prosumer bent of the Flickr audience, the set of tags also includes terms specific to the photo taking activity, such as  X  X ikon X  and  X  X lackandwhite, X  which tell us nothing about the concept. The tags returned by Flickr appear to be in order of co-occurrence frequency. In using these tags fo r expansion, the system takes only the first n tags, where n by default is ten. The expanded query consists of the original keyword plus the keywords from Flickr. Weights are applied as in the case of WordNet. The terms provided by Flickr are weighted 0. 1, relative to the weight of 1.0 assigned to the user-specified term. One limitation of the Flickr getRelated interface is that it does not return compound words as such; instead, such tags are made into single words by removing spaces. Hence,  X  X ew York X  becomes  X  X ewyork X  when returned by the getRelated method. To compensate for the specific but common case of state names, the system recognizes and substitutes the full state name for the abbreviated form of states having names composed of compound words. WordNet groups words into sets of cognitive synonyms, or synsets. A word may have multiple synsets, corresponding to different senses of the word. Rather than use all possible senses of a word, we limit ourselves to the two most common senses, as reported by WordNet. Moreover, a word may be used both as a noun and as a verb, with the noun and verb forms each having separate synsets. For the purposes of this work, we consider only the noun synsets for a word. When a user provides a list of search terms, it is generally not readily possible to determine the intended part of speech for each term. We make the simplifying assumption in this work that search terms are intended as nouns, and limit ourselves to the use of noun synsets. We expect that people are more likely to provide nouns or noun forms of verbs as search terms than verbs, and this assumption was borne out by the results of our online survey described in Section 3, where people rarely used verbs as search terms. WordNet also links words related by hypernym/hyponym relationships, as well as other rela tionship types not used in this work. A word is a hypernym of another word if the first word represents a more general class than the second word: for example, ballgame is a hypern ym of baseball. A word is a hyponym of another word if it represents a more specific instance of a more general class; baseball is a hyponym of sport. This work uses the synonym, hypernym and hyponym relationships defined by WordNet to identify related words. As with synsets, we limit the expansion to noun senses of the word only. WordNet can return hypernym chains, for example, sport is a hypernym of athletic game which in turn is a hypernym of outdoor game, a generalization of field game, a generalization of ballgame, a generalization of baseball. As the classes become more general, they are less useful for the purposes of concept expansion. Consequently, our syst em only considers two levels of hypernyms, and that only for the two primary senses of the word. For hyponyms, the system again only considers the hyponyms for the two primary senses of the word, and only the immediate hyponyms are used. The system expands a term usin g WordNet by constructing a bag of terms, using the terms pr ovided by WordNet X  X  synset, hypernym, and hyponym relationships. We expect that the user-provided term should have a higher weight than synonyms, which in turn should have a higher weight than the hypernyms and hyponyms. After experimenting with various weights, we adopted the following weight assignments: To assess the relative performance of Flickr-based concept expansion, we compared its re trieval performance against not using any expansion and against using WordNet-based expansion. All testing was first-party testi ng; test participants generated meaningful queries for their pe rsonal collections, and provided ground-truth results for each query. Our study included five test participants with collections of va rying sizes, as shown in Table 1. Collections were as provided by th e user, with file and directory names as they were in the user X  X  environment. While the majority of images did not have meaningful filenames, many image files resided in a directory with a name corresponding to a date, activity or place. Two of the test participants had some geotagged images in their collections; one collection had approximately 20 images with associated Exif captions. Most collections spanned several years. Some collections included duplicates of some images, at different resolutions, where the participant had resized some images for the purposes of sharing; this was especially true for Participant G. Because of the difficulty of obtaining ground-truth data, two of the authors participated as test participants. In keeping with the types of queries we found that consumers typically wish to perform, the queries were one-to three-word when, who, where, or what type queries, where the what type queries included both objects and activities. The complete set of queries and the associated precisi on/recall results for the datasets with user-provided metadata are shown in Table 2. Some subjectivity is involved in dete rmining the ground truth. In the most extreme case, one participant searched for  X  X om and dad, X  expecting pictures of the particip ant X  X  mother and father, but the participant also accepted results of the participant and his wife, if the picture was taken at a time wh en he had children. However, the vast majority of the queries did not have such ambiguous interpretations. For two-word queries , participants expected the search results to satisfy both te rms. The raw collections as provided by the test participants represent the type of collections real consumers would have: some user-provided metadata, largely in the form of meaningful directory and file names, but not much. In addition, as noted in Table 1, some participants had manually or automatically geotagged imag es. To provide a worse-case scenario, each participant collection was cloned, and all directories and files renamed before the images were indexed. In addition, geospatial information was discarded in the cloned copy. Although an increasing number of capture devices automatically record geospatial information, most consumer imagery is still not geotagged. The cloned collection wa s also indexed, to assess the performance of the system when leveraging only typical image capture-time Exif or pixel data. As would be expected, the vocabulary associated with the metadata-reduced, cloned collection was much smaller than the vocabulary for the corresponding original collection. For example, for participant W, the meaningful vocabulary for the ori ginal collection consisted of approximately two thousand w ords, while the corresponding vocabulary for the metadata-re duced collection consisted of approximately seventy words. Each test participant was instructed to supply five to seven queries, searching for ev ents, places, ac tivities, and objects, in line with the types of queries our consum er research indi cated as being most important to consumers. For each query, the query was expanded using each of the tested expansion methods, with the top twenty results from each method taken and presented to the user. The user was instructed to i ndicate whether or not the results were correct. The test was repeated with the participant X  X  cloned collection, where user-provided me tadata had been deleted. The results were analyzed to determine the precision and recall of the various expansion methodologie s. In addition, we considered the overall utility of the system, by considering what the likelihood was that the system woul d return at least one relevant result that would rank in the top twenty results. Figure 4 illustrates the expected probability of returning at least one relevant result, given asset de scriptors that may include user-provided metadata. The crosshair indicates the proportion of searches that returned at least one correct result. To assign confidence values to these proportions, we assumed a beta distribution, and computed the confidence interval for  X  = 0.1. As can be seen from the graph, the Flickr-based concept expansion provides significantly better re sults than using no concept expansion. Combining the F lickr and WordNet expansion methodologies provided nearly identi cal results in this case. Using WordNet alone as the expansion methodology did not provide significantly better results than using no expansion methodology, although the observed proportion of successful results was higher. In Figure 5, we show the same type of data, but this time as applied to the cloned collections, lacking the user-provided and geospatial metadata. The same conclusions apply, although here the difference between Flickr and no expansion is barely statistically significant. Combining Flickr with WordNet strengthens the separation. For reference, the average precision using the combined approach for our test queries was 0.36 compar ed to 0.30 with no expansion; these numbers drop to 0.25 and 0.16 respectively when the queries were executed against the collection with no user-provided metadata. The average precision using just Flickr-based expansion was similar to the precision using the combined approach. To confirm our expectation that the presence of user-provided metadata improved the quality of the search results, we performed a paired t-test to compare the precision for each query as returned by the two methods . The presence of user-provided metadata significantly improved the results, with a one-tail p = 0.004 (mean change = 0.11, st. dev. = 0.04, t-stat(34) = 2.78). Fast response time is a critical requirement for any practical search system. We measured the time to execute each of the queries as shown in Table 2, us ing the combined Flickr plus WordNet expansion mechanism, and taking the first twenty results. The average response time was 0.63 seconds with a standard deviation of 0.23, ru nning on a Intel Xeon processor (2.67 GHz, high-speed Internet connectivity, 32-bit Windows XP). No special effort was made to optimize the execution time. In considering the query results, we note both some characteristics that resulted in more successful results, as well as areas that merit further research. As most consum ers do not want to review more than one page of search results, our data analysis only considered the performance of the system relative to the top twenty search results. As would be expected, the pres ence of user-provided metadata results in better precision: the more annotations provided by the user, the better the expected re sults. Even with no user-provided metadata, our Flickr-based concept expansion mechanism significantly improved search perfo rmance compared to not using an expansion mechanism. Le veraging information such as pathnames and geospatial ta gs significantly improved performance. Meaningful file and folder pathnames are often available for free, in that th e consumer has provided such information as part of their asset organization; geospatial information is increasingly becoming available automatically. In looking at specific queries, so me queries included terms that were directly returned by one of th e asset indexers or were part of user-provided data; for example, our holiday recognizer tagged some images with the tag  X  X hristm as, X  and several of the queries did involve this tag. Likewise, th e vacation tag was also directly returned by our event classifier, although in this case the classification was not always accurate. The more interesting queries were ones such as manate e, illustrated in Figure 3. For that particular term, the concept expander expands the term to the following Indri query when using F lickr as the concept expansion method: This query worked with 100% recall, even though the term manatee was not part of the collec tion vocabulary. In this case, the relevant images were geotagged, and the latitude and longitude information was mapped by the geospa tial indexer to tags such as Wildlife State Park and Florida. The pixel-based water classifier further improved the expansion, re sulting in four of the manatee pictures being the top-ranked resu lts. Without the water tag, those pictures still ranked in the top twenty, but further down the list. However, in the absence of user-provided and geospatial metadata, this query is essentia lly hopeless, returning no valid matches in the top twenty results, as the water tag by itself was insufficient to identify the correct images. As another example, the user que ry  X  X olf X  had moderately high precision, as shown in Table 2, but this is hardly surprising as the relevant images were in a folder named  X  X olf. X  Due to space limitations, we do not show the test query results data for the case where there is no user metadata. In that case, the precision for the golf query dropped to 5% (one image) using the Flickr-based expansion mechanism, but it is worth noting that the Flickr-based mechanism was the only one that returned any valid images for that query. The retrieved imag e matched based on the results of the scene and color classifiers. An area for future research is to identify which classes of asset desc riptor tags are most useful for query expansion. This research would indicate where improvements in indexer accuracy would most improve retrieval results, as well as potentially indicate additional indexer types that could be helpful. We note that both Flickr and Wo rdNet expansion could result in adding irrelevant terms. If these terms were part of the collection vocabulary, then these terms could negatively impact the search results. This is illustrated in Ta ble 2 where for a few queries the Flickr results are actually worse than using no expansion. For these queries, the user-provided search terms typically matched at least one of the more reliable asset descriptor terms X  X erms provided by the user or by the date-based autolabeller. The Flickr-based expansion, while im proving recall in one case, did so at the expense of decreasing precision. We conducted some informal expe riments to determine how the Flickr-based algorithm performed when varying the number of terms used to do the expansion. We postulate that the number we used, ten, might be generally too low; however, using twenty or more seemed to add more noise and more error in the results. Techniques such as the term semantic network used in [8] could possibly be adapted to the work here, to filter the expanded search terms. Such filtering could be applied in several different ways. The WordNet expansion could be filtered by using Flickr to determine the strength of the sugge sted associations. In addition, if the user supplies multiple search terms, filtering could be used to ensure that the expanded terms are consistent with all terms. For example, our current expansion algorithm will include the word ocean for the query  X  X ermont vacation, X  since ocean is related to vacation according to Flickr. Since oceans are not typically associated with Vermont, dropping the term ocean from the expansion will improve the precision. We also note that the behavior and semantics of the Indri information retrieval system did not always match our intended semantics. Queries consisting of multiple terms were mapped to a single Indri expression using a weighted combination operator. This resulted in a weighted disjunction, although our test participants considered the results to be erroneous unless all terms were satisfied. For example, the  X  X irthday beijing X  query readily returned pictures from Beijing, as those pictures had been geotagged, but it did not succeed in retrieving the birthday pictures. A more complex rewriting of queries into one or more Indri expressions would be requir ed to more closely match user intent, and should result in improved precision. Considerably more effort would be required to develop an information retrieval system that more closely matche d our data model, and it is unclear how much that would imp rove system performance. Our method of representing probabilistic values resulted in a loss of precision. For many queries, multiple assets had the same score, and because we only considered th e top twenty results, the cut-off in some cases was indiscriminate. A more precise means to represent probabilistic scores would have provided better differentiation in the ranking of results, and we may do more work in this area in the future. We anticipate consumer applications will have a growing need for information retrieval systems that can readily handle a mix of probabilistic and non-probabilistic metadata. Our implementation makes real-time calls to the Flickr getRelated interface to expand searches. This highly available interface typically provides results very qu ickly, making it suitable for real-time interactive use. Our experimental system often returns results within one second, including the calls to Flickr, the WordNet expansion, and finally the Indri que ries. No real-time pixel-level image processing is required, as all semantic information is extracted in advance, enabling fast response tim es. Performance could be further improved by caching common keyword expansions, although real -time invocations of the Flickr service ensure that our system X  X  expans ion tracks current usage. We considered using other sources of knowledge such as Wikipedia, but a dataset such as Flickr is a better fit for our search space. Although the currently collected data is limited, the results indicate that meaningful image search is possible on consumer image collections without requir ing the consumer to provide metadata beyond that which th ey might normally provide. Our initial success in this domain le verages the shared knowledge of millions of Flickr users as to what concepts are likely to go together in the context of consumer imagery. This readily-obtained knowledge provides us w ith a fast way to expand consumer queries into sets of semantic concepts that can be readily extracted from consumer imagery. By combining concept expansion with image semantic cl assifiers, our system provides consumers with real-time interactive search and retrieval capabilities for their unlabeled or sparsely labeled personal image collections. Madirakshi Das, Dhiraj Joshi, Jiebo Luo and Tony Scalise provided helpful insights and observa tions on this work. We also thank the test participants for prov iding us with real user data and the anonymous reviewers for their helpful feedback. [1] Aurnhammer, Melanie, Peter Hanappe, and Luc Steels. [2] Ayata, Yusf, Mubarak Shah and Jiebo Luo,  X  X tilizing [3] Das, Madirakshi, and Alexande r Loui.  X  X vent Classification [4] Das, Madirakshi, R. Manmatha , and Edward M. Riseman, [5] Fellbaum, Christiane (ed.), Wordnet: An Electronic Lexical [6] Flickr,  X 4,000,000,000, X  Flickr Blog, [7] Flickr,  X  X lickr.tags.getRelated, X  [8] Gong, Zhiguo, Chan Wa Cheang, and Leong Hou U,  X  X eb [9] Goodrum, Abby and Amanda Sp ink,  X  X mage Searching on [10] Jansen, Bernard J., Amanda Sp ink, and Jan Pedersen,  X  X n [11] Kamvar, Maryam, Melanie Kellar, Rajan Patel, and Ya Xu, [12] Lenat,  X  X YC: A Large-scale Investment in Knowledge [13] Liu, Yiming, Dong Xu, Ivor W. Tsang, and Jiebo Luo, [14] Liu, Hugo and Henry Lieberman,  X  X obust Photo Retrieval [15] Metzler, Donald and W. Br uce Croft,  X  X ombining the [16] Metzler, Donald,  X  X ndri Retrieval Model Overview, X  [17] Ren, Reede, Martin Halvey and Joemon M. Jose, [18] Sigurbj X rnsson, B X rkur and Ro elof van Zwol,  X  X lickr Tag [19] Strohman, Trevor, Donald Metzler, Howard Turtle, and W. [20] Zhai, Chengxiang and John Lafferty,  X  X  Study of Smoothing 
