 ALI FARGHALY Monterey Institute of International Studies and KHALED SHAALAN The British University in Dubai 1. THE ARABIC LANGUAGE The Arabic language is both challenging and interesting. It is interesting due to its history [Versteegh 1997], the strategic importance of its people and the region they occupy, and its cultural and literary heritage [Bakalla 2002]. It is also challenging because of its complex linguistic structure [Attia 2008]. gible and functional for more than fifteen centuries. Culturally, the Arabic language is closely associated with Islam and with a highly esteemed body of literature. Strategically, it is the native language of more than 330 mil-lion speakers [CIA 2008] living in an important region with huge oil reserves crucial to the world economy, and home as well to the sacred sites of the world three monotheistic religions. It is also the language in which 1.4 billion Muslims perform their prayers five times daily. Linguistically, it is character-ized by a complex Diglossia situation [Diab and Habash 2007; Farghaly 1999; Ferguson 1959, 1996]. Chronologically Classical Arabic represents the lan-guage spoken by the Arabs more than fourteen centuries ago, while Modern Standard Arabic is an evolving variety of Arabic with constant borrowings and innovations proving that Arabic reinvents itself to meet the changing needs of its speakers. At the regional level there are as many Arab dialects as there are members of the Arab league. The diglossic nature of the Arabic language will be discussed in detail in Section 2.
 a native language, in an area extending from the Arabian/Persian Gulf in the East to the Atlantic Ocean in the West. Arabic is a highly structured and derivational language where morphology plays a very important role [Attia 1999; Beesley 2001; Buckwalter 2004; Farghaly 1987; McCarthy 1981; Soudi et al. 2007]. Arabic NLP applications must deal with several complex prob-lems pertinent to the nature and structure of the Arabic language. For exam-ple, Arabic is written from right to left. Like Chinese, Japanese, and Korean there is no capitalization in Arabic. In addition, Arabic letters change shape according to their position in the wor d. Modern Standard Arabic does not have orthographic representation of short letters which requires a high degree of homograph resolution and word sense disambiguation. Like Italian, Span-ish, Chinese, and Japanese, Arabic is a pro-drop language, that is, it allows subject pronouns to drop [Farghaly 1982] subject to recoverability of deletion [Chomsky 1965].
 such as English. However, it also is unique in terms of its history, diglossic nature, internal structure, inseparable link with Islam, and the Arabic culture and identity. Any Arabic NLP system that does not take the specific features of the Arabic language into account is certain to be inadequate [Shaalan 2005a; 2005b]. The challenge the Arabic language poses to researchers is not limited to the social aspects of the language, but also extends to its inherent linguistic structure which will be elaborated below.
 gained increasing importance, and several state-of-the-art systems have been developed for a wide range of applications, including machine translation, information retrieval and extraction, speech synthesis and recognition, local-ization and multilingual information retrieval systems, text to speech, and tu-toring systems. These applications had to deal with several complex problems pertinent to the nature and structure of the Arabic language. Most ANLP systems developed in the Western world focus on tools to enable non-Arabic speakers make sense of Arabic texts. Arabic Tools such as Arabic named en-tity recognition, machine translation and sentiment analysis are very useful to intelligence and security agencies. Because the need for such tools was urgent, they were developed using machine learning approaches. Machine learning does not usually require deep linguistic knowledge and fast and inexpen-sive. Developers of such tools had to deal with difficult issues. One problem is when Arabic texts include many translated and transliterated named entities whose spelling in general tends to be inconsistent in Arabic texts [Shaalan and Raza 2008]. For example a named entity such as the city of Washington could a sizable corpus of Arabic-named entities which would have helped both in rule-based and statistical named entity recognition systems. Efforts are being made to remedy this. For example, the LDC released in May 2009 an entity translation training/dev test for Arabic, English, and Mandarin Chinese. A third limitation is that NLP tools developed for Western languages are not easily adaptable to Arabic due to the specific features of the Arabic language. Recognizing that developing tools for Arabic is vital for the progress in ANLP, the MEDAR consortium has started an initiative for cooperation between Ara-bic and European Union countries for developing Arabic language Resources [Choukri 2009]. 1.1 Significance of ANLP for the Arabic-Speaking Population Funding for the development of ANLP applications has surged in the U.S. since September 11, 2001. The U.S. Department of Homeland Security was confronted with very difficult tasks ranging from identifying Arabic names correctly at airport security and in Ar abic documents seized by the American authorities in the U.S. and abroad. They also had accumulated an enormous volume of Arabic texts that they had no clue as to whether they were rele-vant or not. They had neither the human expertise needed to perform the task nor the time to wait for human translators to complete the task. ANLP tools that could scan such documents to recognize names, places, dates, etc., of interest soon became essential. As a result, funding became available for companies and research centers to develop tools such as named entity recog-nition, machine translation, especially spoken machine translation, document categorization, etc.
 tionally viable grammars of Arabic, statistical approaches that rely primarily on training data and parallel texts gained momentum. Machine learning sys-tems usually give good results when the training set and the testing data are similar. There is also a point at which more training data does not make sig-nificant improvement. Moreover, there may be some structures or entities that are sparse. In this case the machine learning component does not have enough data to make the right generalization.
 different objectives and usually employ both rule-based and machine-learning approaches. The following are some of the objectives of ANLP for the Arab World: 1. Transfer of knowledge and technology to the Arab World . Most recent publi-2. Modernize and fertilize the Arabic language . This follows from (1) above. 3. Improve and modernize Arabic linguistics . Arabic NLP needs a more formal 4. Make information retrieval, extract ion, summarization, and translation 2. ARABIC DIGLOSSIA Diglossia is a phenomenon [Ferguson 1959, 1996] whereby two or more vari-eties of the same language exist side-by-side in the same speech community. Each is used for a specific purpose and in a distinct situation. Using the wrong variety in a situation is usually ridiculed. Thus, it differs from the more famil-iar examples of regional dialects in Italian or Persian where many speakers use their local dialect at home and within the community, but use the standard language when communicating more formally or with speakers from other regions.
 rieties of the same language are used within a speech community [Farghaly 2005] and in circumscribed situations. Classical Arabic is the language of religion and is used by Arabic speakers in their daily prayers while Modern Standard Arabic (MSA), a more recent va riety of Classical Arabic, is used by educated people in more formal settings such as in the media, classroom, and business. With family, friends, and in the community, people speak their own regional dialect which varies considerably from region to region. These three varieties are available to every Arab on a daily basis. For example, on any given day an Arabic speaker will use Classical Arabic while reciting his daily prayers; MSA when listening to or reading the news, and his particular dialect at home with family or friends.
 a more standard form of a language. It may develop from different origins and is quite stable. With respect to Arabi c, a diglossic situation can be traced to the earliest knowledge of the language and Classical Arabic itself and has remained very stable for over fifteen centuries.
 Classical Arabic, while the regional dialects are low varieties with MSA occu-pying an intermediate position. The same can be said for other diglossic situa-tions such as Greek, Creole, and Swiss German [Ferguson 1959]. But what is important is that with each situation, including Arabic, the same features can be found that more clearly define true diglossia.
 situation it is only appropriate to use the high variety, for example, in a speech, news broadcast, or lecture hall; and the low variety when communicating with family and in more personal settings.
 sumed to be representative of a speaker X  X  educational level and/or social stand-ing. With Arabic, the prestige accorded Classical Arabic is associated with religion, that is, Islam and the Quran and a highly esteemed literary heritage. body of literature written in the high variety that is esteemed by its speech community. For Arabic, there is an extensive legacy of poetry and philosophical and scientific treatises.
 Arabic, as well as other diglossia, the low variety or dialect is acquired by children at home and without explicit rules of grammar and is assumed to be acquired  X  X aturally. X  The high variety, Classical Arabic and MSA are learned at school in the same way any other foreign language would be acquired. tradition of grammar as is the case with Classical Arabic. There are grammar texts, dictionaries, and works on style and pronunciation. There is an accepted and established norm for grammar, vocabulary, and pronunciation which has minimal variation. In contrast, the same body of standards does not exist for the low variety and as a result there is considerable variation in grammar, vocabulary and pronunciation. This poses a significant problem with respect to the teaching of Arabic to non-native speakers who are generally taught MSA in the classroom but are frustrated by their inability to communicate more naturally with native speakers. When they attempt to learn a dialect such as Egyptian, Levantine, or Gulf Arabic there are few, if any, resources available to them to convey the proper grammar and method of vocabulary building. dardization of a language, but in fact the diglossic situation is remarkably stable. With respect to Arabic the two varieties have existed side by side for more than 1,500 years.
 between varieties as evidenced by certai n features present in MSA or Classical Arabic [Ryding 2005] while absent from any dialect. For example, Classical Arabic has three cases marked by case en dings where the dialects have none. Further the word order differs as well in that Classical Arabic and MSA have mostly VSO (Verb-Subject-Object) wo rd order while most Arabic dialects are SVO. There are differences in the Wh-construct as well with MSA fronting it and in Egyptian Arabic it is not fronted. And in general, the low variety has a simpler grammatical structure than MSA and less complex morphological structure.
 according to Ferguson [1959]: 2.1 Diglossia and ANLP There are of course, significant implications for developing NLP systems in a diglossic situation like Arabic. First, it is very difficult and almost impossi-ble for any one ANLP single application to process data from all the varieties of Arabic. Each variety has its own grammar, lexicon, and morphology even though they have some properties in common. An ANLP application has to specify beforehand which variety it is aiming to address. Moreover, the appli-cation has to have a good  X  X nderstanding X  of the linguistic properties of the particular variety it aims at. An understanding of the complex sociolinguistic situation of Arabic can be very useful for ANLP researchers and developers. that is primarily written in MSA. However, when attempting to apply these tools to transcribed Egyptian or Levantine text, they are far from accurate since there are significant variations in grammar, syntax, and expressions from one variety to another and between the dialects themselves. Further-more, there are few resources available i n the form of gramma rs or dictionaries as the basis for developing NLP for the dialects.
 taken by researchers at Columbia University [Habash et al. 2005]. In their approach, they have made the assumption that is it simpler to develop NLP systems for the dialects by first extract ing and categorizing the systematic grammatical features of a dialect, ma king it more like MSA and then applying MSA natural language processing tools to process a text. Another approach, built upon the same assumption, is to create Dialect Treebanks that resem-ble MSA Treebanks by exploiting systematic regularities within a dialect and among dialects. For example the work reported in Shaalan et al. [2007] trans-fers Egyptian Arabic texts to MSA using a lexical transfer approach in ad-dition to changing the SVO Egyptian order into the MSA VSO order. They also enhanced the tables of Buckwalter X  X  morphological analyzer to transform Egyptian Arabic words into MSA words. Following then same approach one could also reuse MSA tools to p rocess colloqu ial Arabic.
 fine what constitutes the Arabic language, and, in turn, assumes that there is a core entity that has well-defined phonological, morphological and syntactic properties. It also proposes that the three main varieties of Arabic, Classical Arabic, the colloquials, and Modern Standard Arabic share a common core or an inter-Arabic grammar. This is likely, given the mutual intelligibility among all speakers of Arabic and the ability of illiterate Muslims to understand the Quran. A core inter-Arabic grammar in addition to Dialect Treebanks and lex-ical resources for the dialects would greatly facilitate the development of NLP tools and systems for transcribed texts of the Arabic dialects. 2.2 Solutions The most important solution for Arabic Diglossia is to build resources for the various varieties of Arabic. The LDC has already built corpora for Egyptian, Levantine, and Iraqi Arabic. In addition, there is an important project at Columbia University to build a Treebank of Arabic dialects using resources already available for Modern Standard Arabic. The project exploits systematic mapping of Modern Standard Arabic to some dialects at the phonological and morphological, and lexical levels.
 Arabic Diglossia for their applications since it is hard to build a system that can handle all of the varieties of Arabic simultaneously. Developers must be clear as to which variety of Arabic is appropriate for their specific appli-cations. For example, an application for speech recognition of Arabic tele-phone conversations will most probably need dialect resources while another for processing Arabic news broadcasts would require Modern Standard Arabic resources whether in the form of linguistic knowledge or in corpora for training purposes.
 3. THE ARABIC SCRIPT One of the key linguistic properties of the Arabic language that poses a chal-lenge to the automatic processing of Arabic is the Arabic script itself. Although Arabic is a phonetic language in the sense that there is one-to-one mapping between the letters in the language and the sounds they are associated with, Arabic is far from being an easy language to read due to the lack of dedicated letters to represent short vowels, changes in the form of the letter depend-ing on its place in the word, and the absence of capitalization and minimal punctuation.
 letter ( X   X   X ) b is always pronounced as  X  X aa, X  unlike letters in English that have more than one pronunciation. For example, the letter  X  X  X  in English may be pronounced as / z / as in  X  X ause X  or / s / as in  X  X ail X  or / sh /asin X  X ure. X  Fur-ther, while English has silent letters such as the  X  X  X  in  X  X neumatic X  the  X  X  X  in  X  X oubt, X  the  X  X  X  in  X  X now X  and the  X  X h X  in  X  X eight, X  Arabic has no silent let-ters. Moreover, Arabic does not combine two letters to produce a new sound. For example, combining the letters  X  X  X  and  X  X  X  in English sometimes produces a voiceless interdental fricative as in  X  X hink X  or a voiced interdental fricative as in  X  X hough. X  However, this distinction is highly systematic in English since in most lexical words the  X  X h X  is pronounced as it is in  X  X hink X  while most func-tional words assume the other pronunciation.
 short vowels in the language, short vowels have been represented by diacritics which are marks above or below the lette rs. However, these diacritics have been disappearing in contemporary writings and readers are expected to fill in the missing short vowels through their knowledge of the language. But the absence of short vowels from MSA texts makes it difficult for non-native speak-ers of Arabic to learn the language and presents challenges to the automatic processing of Arabic.
 in the word. For example, the letter (  X  )  X  X  X in X  has an initial shape (  X  X  ), a me-(  X  ). The selection of the correct shape relative to its position in the word is rule governed. All Arabic word processo rs implement these rules so that the user does not have to manually select the correct shape. Hence there is only one key for each letter, and the encoded rules both recognize the context and insert the correct shape automatically. Moreover, there are shapes which the morphological processing tool should handle. For example, the Hamza letter is changed to other forms during the morphological and syntactic generations of the inflected word. For example, the use of the letter  X   X   X (Yehtoindicate my), with the irregular (broken) plural  X   X  X  X  X   X  (colleagues) produces  X   X  X  X  X  X   X  (my-colleagues) instead of  X   X  X   X   X  X  . X  with an uppercase letter and end with a period. In NLP applications such as machine translation, information retrieval, clustering, and classification it is necessary to split a running text correctly into sentences and a sentence splitter capitalizes on these features. But scripts such as Arabic, Chinese, Japanese, and Korean have neither capitalization nor strict rules of punctu-ation and their absence makes the task of preprocessing a text much more difficult.
 in languages such as Arabic than it is in languages like English due to the absence of strict punctuation rules. I n fact, it is common in Arabic discourse to write an entire paragraph without a single period except at the end of that paragraph. Sentences are often conjoined via the Arabic coordinators (  X  ) wa and (  X  ) fa and Arabic discourse is characterized by excessive use of coordina-tion, subordination and logical connectives.
 boundaries, but also play an important role in the task of named entity recog-nition (NER) [Benajiba et al. 2008; Farghaly 2007; Shaalan and Raza 2009], which has become an essential component of many NLP applications. Be-ginning with the 1987 Message Understanding Conference (MUC) and the subsequent series of conferences [Grisham and Sundheim 1996], Informa-tion Extraction (IE) has become the focus of research in many NLP applica-tions. While Information Retrieval involves identifying relevant documents in response to queries and ranking them such that the most relevant docu-ments are placed at the beginning, the focus of IE is to extract words and phrases that denote entities, actions, or relations of interest to the user. The task involves extracting from unstructured texts entities such as person names, postal addresses, zip codes, person titles, cities, regions, buildings, etc. Because some of these entities have a strict format, practitioners in the field acknowledge that capitalization and punctuation facilitate recognition of these patterns.
 pattern consisting of an uppercase wo rd followed by an initial with an op-tional period followed by an uppercase word to extract person names such as Hillary R. Clinton and Mary A. Hoffman. There are many patterns that can be recognized and extracted with a high degree of confidence by utilizing capitalization and punctuation rules: street addresses, some company names, some person names, zip codes, phone numbers, Social Security numbers, and e-mail addresses to name but a few. But a computational linguist developing IE applications for languages like Arabic, where the script does not allow for capitalization nor does it follow strict punctuation rules, must have insights into the structure and syntax of the Arabic language to identify patterns in the absence of these rules [Shaalan and Raza 2008, 2009]. This presents a much more challenging task for the development of IE systems for Chinese, Korean, and Arabic. 3.1 Normalization of the Arabic Script Another challenge facing researchers and developers of Arabic computational linguistics is the dilemma of normalization. The problem arises because of the inconsistency in the use of diacritic mar ks and certain letters in contemporary Arabic texts. Some Arabic letters share the same shape and are only dif-ferentiated by adding certain marks such as a dot, a hamza or a madda placed above or below the letter. For example, the  X  X lif X  in Arabic (  X  )maybethreedif-ferent letters depending on whether it has a hamza above as in (  X  )orahamza below as in (  X  ) or a madda above as in (  X  ). Recognizing these marks above or below a letter is essential to be able to distinguish between apparently similar letters.
 earlier nor do they adhere to the  X  X roper X  inclusion of marks above or beneath some Arabic letters. To manage this problem, the common practice in Arabic NLP systems is to normalize the input text [Larkey and Connell 2001]. For example, in order to handle the different variations in Arabic script, Larkey and Connell [2001] replace the initial alif with a hamza above or below with simply an alif, or bare alif. They also normalize the alif madda with a bare alif. Further, they normalize the final taa marbuuTa (  X  or  X  X  ) with a final haa (  X  or  X   X  ) and the alif maqsuura (  X  )withtheyaa(  X  ).
 signed by The Stanford Natural Language Processing Group implements a similar normalization strategy for Arabic texts.
 and Senellart 2003] also incorporated normalization. But it soon became ap-parent that although normalization improves recognition by solving the vari-ability in input, it increases the probability of ambiguity [Farghaly 2010]. For example, normalizing an initial alif with a hamza above or below it, removes an important distinction between (  X   X  )annand(  X  X  ) inn. The first translates into  X  X hat X  and must be followed by a nominal sentence. The second could translate into  X  X o X  which indicates the English infinitive, but whose trans-lation is meaningless if followed by a noun. In short, although normaliza-tion solves recognition problems, it cre ates the unintended effect of increased ambiguity. 3.2 Ambiguity and NLP Systems The many levels of ambiguity pose a significant challenge to researchers de-veloping NLP systems for Arabic [Attia 2008]. The reason is that ambiguity exists on many levels as evidenced by Maamouri and Bies [2010] who show 21 different analyses of the Arabic word (  X  X  X  ) tmn, produced by BAMA. At SYS-TRAN, which has been developing machine translation systems for over 40 years, it was estimated that the average number of ambiguities for a token in most languages was 2.3, whereas in MSA it reaches 19.2. Although ambiguity is caused primarily by the absence of short vowels, at SYSTRAN researchers have found ambiguity in Arabic to be present at every level. (1) Homographs: A word belonging to more than one part of speech such (2) Internal word structure ambiguity: That is, when a complex Arabic word (3) Syntactic ambiguity: As in the case of a prepositional attachment as in (4) Semantic ambiguity: Sentences and phrases may be interpreted in dif-(5) Constituent boundary ambiguity: For example  X   X  X  X  X  X  X   X  X  X  X  X   X  X  X  X   X  mdyr albnk (6) Anaphoric ambiguity: As in  X   X  X  X   X  X  X   X  X  X   X  X  / qala Ali annahu najah /Ali said features of Arabic such as the pro-drop structure, complex word structure, lack of capitalization, and minimal punctuation contribute to ambiguity, but it is the absence of short vowels that contributes most significantly to ambiguity. lost. The first is most of the case markers that define the grammatical function of Arabic nouns and adjectives. For example, a Damma , which is a high back rounded vowel at the end of a common noun or adjective marks the nominative case whereas a fatHa , which is a low front vowel in the final position of a com-mon noun, marks the accusative case and a kasra which is a high front vowel marks the genitive case. The absence of case markers and thus the grammat-ical function of a word, creates multiple ambiguities due to the relatively free word order in Arabic and because Arabic is a pro-drop language.
 script is the lexical and part of speech information. Thus, in the absence of internal voweling it is sometimes impossible to determine the part of speech (POS) without contextual clues. For example, without contextual clues a word like (  X   X  ) mn could be a preposition meaning  X  X rom, X  a wh-phrase meaning  X  X ho X  or a verb meaning  X  X ranted. X  An Arabic token such as (  X   X   X  ) ktb without internal voweling could be a plural noun  X  X ooks, X  an active past tense verb  X  X rote, X  a passive past tense verb  X  X as written X  or a causative past tense verb  X  X e made him write. X  lenging is that all of these features are present in one. 3.3 Solutions Tokenization in Arabic presents a problem because of the rich and complex morphology of Arabic. A token is usually defined as a sequence of one or more letters preceded and followed by space. This definition works well for non-agglutinative languages like English. Attia [2007] points out that tokenization of Arabic texts is a non-trivial task. For example a single Arabic word may contain up to four different tokens. Thus, tokenization requires knowledge of the constraints on concatenating affixes and clitics within Arabic words. A distinction needs to be made between clitics which are syntactic units and thus have their own part of speech but do not stand alone, and affixes that mark grammatical inflections such as tense, number and person agreement. Attia X  X  solution to the Arabic tokenization problem involves combining the morpho-logical analysis and tokenization in one process.
 deeper into the language to detect regularities that could help in information extraction. For example, many Arabic names have a middle token such as  X   X  X   X  /bin/ meaning  X  X on of. X  This could be a linguistic trigger that recognizes names such as  X  X sama bin Laden X  even if they are not in the names dictionary. Recog-nizing patterns of Arabic names, dates, addresses, etc., can improve recall of Arabic entity recognition. 4. THE NONCONCATENATIVE ARABIC MORPHOLOGY Arabic is characterized by its nonconcatenative morphology [McCarthy 1981] which presents a challenge to the structuralists theory of the morpheme. They defined the morpheme as a minimal linguistic unit that has a meaning. By minimal it is always meant that a morpheme cannot have a morpheme bound-ary within it. This definition works well for languages with concatenative morphology like English. McCarthy [1981] points out that the building blocks of Arabic words are the consonantal root which represents a semantic field such as  X  X TB X   X  X riting X  and a vocalism that represent a grammatical form. Arabic stems are described in terms of prosodic templates such as CVCVC. The Cs represent the root radicals and Vs represent the vocalism [Cavalli-Sforza et al. 2000]. Thus words such as  X   X  X   X   X /katab/ is formed by an association of the radicals to the vocalism. While McCarthy proposes that Arabic words are analyzed at tiers (the root and the vocalism), Farghaly [1987] proposed a three tiered Arabic morphology by adding a third level for catenative affixation to Arabic stems.
 ogy and morphological analysis and early NLP systems have benefited from this work [Al-Sughaiyer and Al-Kharashi 2004; Soudi et al. 2007]. A pioneer-ing work in Arabic computational morphology has been that of Hlal [1985] which was based on a lexicon of Arabic roots, prefixes, and suffixes and tak-ing Arabic words as input, decomposing each word by identifying all prefixes, suffixes, and infixes and then recovering the root. Many Arabic morphological systems followed a similar approach while improving the performance [Beesley 2001; Rafea and Shaalan 1993]. Almost all computational treatment focused on recovering the roots from Arabic words.
 Morphological Analyzer (BAMA) [Buckwalter 2002], begun in the 1980s and made commercially available in 2000. The BAMA system is based on three tables: a table each for Arabic stems, Arabic prefixes, and Arabic suffixes. There are constraints placed on the prefixes and suffixes that can combine with a stem to form a legitimate Arabic word. The BAMA X  X  dictionary of stems is extensive and has a very high coverage. The BAMA system became avail-able at UPenn LDC and soon became the morphological module of choice for most statistically-based ANLP applications in the U.S. It became the preferred module because it was possible for developers with no knowledge of the Arabic language to process unstructured Arabic texts due to its brilliant bidirectional transliteration schema from the Arabic script to the Latin script. The BAMA became the foundation for subsequent ANLP systems and expedited the de-velopment of an Arabic NLP system for machine translation and information retrieval during the last few years.
 proaches to Arabic morphology were based on theoretical considerations and aimed to recover the Arabic consonantal root from Arabic words. In contrast, the Buckwalter system was pioneering because it implemented a stem-based approach to Arabic morphology. Buckwalter showed that it is simpler to con-sider the stem rather than the root as the basic unit of Arabic lexicon, but the users of the BAMA also have access to root information. The system in-corporates three separate lexicons: prefixes, stems, and suffixes with tables to assess the compatibility of stems, prefixes, and suffixes. In addition to seg-mentation and stemming, the BAMA provides English glosses, full case end-ings, and noun case endings. It does not perform context-sensitive analysis but does give all possible analyses of the words in the input text. The MADA sys-tem [Habash and Owen 2005] goes one step further by using a disambiguation module that determines the corre ct POS tag in a specific context. 4.1 Systran X  X  Stem-Based Morphological Generator The traditional Arab grammarians X  account of Arabic morphology in terms of roots and patterns is very precise and explicit and most work on Arabic morphology aims to identify and separate the prefixes and suffixes from the surface word and recover the root or stem that may have undergone mor-phemic changes. SYSTRAN X  X  system [Farghaly and Senellart 2003] made a fundamental distinction between two kinds of affixes that can be attached to roots or stems. The first is an affix with only a grammatical meaning such as subject-verb agreement, tense or mood markers. While not part of the SYSTRAN dictionary, they are genera ted by its Arabic morphological gen-erator that produces all the surface forms each stem could assume. Other researchers [Beesley 1996; Cavalli-Sforza et al. 2000; Habash 2004; Hosny et al. 2008; Shaalan et al. 2006] also developed morphological generators for Arabic.
 parts of speech can be attached to a stem or root to form a token that has a syntactic structure. For example, the token (  X   X  X  X  X  X  X  X  ) bi X  X mmdynh (in the city) aprepositionand ( X   X  X   X  ) al (the) which is the definite article. In this way, exter-nal morphology describes the way the rule-governed affixes representing the different parts of speech are attached to Arabic stems.
 4.2 Morphological Processing and the Dialects Although most work in Arabic NLP focuses on developing NLP tools and sys-tems for MSA, there is both a strong need and interest to develop systems to analyze Arabic dialects. But because there are limited parallel MSA-dialect resources and few annotated Arabic dia lect texts, it has been difficult to de-velop these tools.
 by researchers. One of the early morphological analyzers and generators for Arabic dialects, MAGEAD, uses an analyzer without a lexicon by exploiting regularities among dialects through sound changes at the radical level and thus, explicit analysis of roots and patterns [Habash and Owen 2005]. Needed to develop this system are representations of phonology and orthography to be able to both analyze and generate morphology for applications to NLP. In the MAGEAD system, an Arabic lexeme is defined as a root, a meaning index, and a morphological behavior class, and it is this definition that allows operation without a lexicon. The hypothesis is that morphological behavior class is vari-ant independent enabling a lexeme-based representation to operate without a lexicon. 4.3 Arabic as an Agglutinative Language The development of Arabic NLP systems is further challenged by two addi-tional linguistic properties: word aggl utination and the pro-drop feature. An agglutinative language constructs complex words that often contain affixes and clitics representing various parts of speech. For example, a verb may em-bed within itself its subject and object as well as other clitics signifying tense, gender, person, number, and voice.
 consonantal root that represents a semantic field and a discontinuous melody (vocalism) that carries a grammatica l meaning. The root and the melody are represented at different tiers and together they form a prosodic template [McCarthy 1981] such as CVCVC as in  X  X   X  X  X  X   X  raHal  X (travel)and  X  X  X  X  X   X  alim  X  (learn).
 of  X  X nderstanding X  while the melody which consists of the two discontinuous short vowels  X  a  X  i  X  represents the past tense. The  X  a  X  suffix represents the third person, singular and masculine. The root and the melody together form the verb stem  X  X   X  /fahim+a /. But a different melody such as  X  aa-i  X  X nthesame root creates the present participle  X   X  X  X  faahim meaning  X  X nderstanding X  as in  X   X  X   X   X  X  X  ana faahim , or  X  X  am understanding. X  be deconstructed into as many as four different parts of speech or morphemes. Forexample,theArabicsentence  X  X  X  X  X  X  X  / wra X  X ytuhum /  X  X nd I saw them X  is writ-ten as one word and may be decomposed into the following four morphemes: 1.  X  / wa / Conjunction  X  X nd X  2.  X   X   X  / r X  X a /PasttenseVerb X  X aw X  3.  X  X  / tu / Subject Pronoun  X  X  X  4.  X  X   X  / hum / Object Pronoun  X  X hem X 
The interaction between the phonological rules and morphological deriva-tions of Arabic words makes the deconstruction of Arabic words even more difficult. For example, the alif maqsuura  X  /aa/ in the stem only occurs in the final position. A phonological rule changes the alif maqsuura into a yaa X   X  / ii / when it is attached to a suffix or a clitic as is seen in the above example. Thus the complex internal structure of Arabic words makes tokenization, usually one of the early preprocessing tasks of a text, very challenging [Attia 2007]. makes the decomposition of Arabic words possible. However, it is far from an easy process due to the high degree of ambiguity in Arabic [Attia 2008]. For example, the word  X   X  X  / whm / has at least four valid analyses: 1.  X  +  X   X  / wa+ hum / CONJ SUBJPRON/OBJPRON  X  X nd they X  2.  X  +  X   X  / wa+hammun / CONJCOMMON NOUN  X  X nd worry X  3.  X  X   X  / wahm / COMMON NOUN  X  X llusion X  4.  X  +  X   X  / wa+ hamma / CONJ PVERB  X  X nd he initiated X 
Furthermore,  X   X  hum as a functional word is ambiguous in at least three ways. It can be a SUBJPRON (they); OBJPRON (them) or a POSSESSIVE-PRON (their). It could also be a lexical word NOUN (worry) or a VERB (initiated). However, it is possible to disambiguate a word like  X   X  by gram-matical rules. If it is attached to a verb, it is an object pronoun, whereas if it is attached to a noun it must be a pronoun. If attached to a complementizer such as  X   X  anna or a conjunction like  X  wa or  X  fa , it is a subject pronoun. 4.4 Arabic as a Pro-Drop Language Another linguistic feature that complicates NLP systems for Arabic is due to the fact that Arabic is a pro-drop language. In Arabic, subject pronouns [Farghaly 1982] may be freely dropped subject to the Recoverability of Dele-tion Condition [Chomsky 1965]. The property of dropping the subject pronoun and allowing  X  X ubjectless sentences X  is not limited to the Arabic language, as Italian, Spanish, and Korean are a few of the languages that permit subjectless sentences.
 is assumed that Universal Grammar (UG) consists of principles and parame-ters that have different values. A child X  X  innate UG will fix the setting of the parameters and principles based on his early linguistic experience. The pro-drop is a parameter within UG; so an Arabic speaking child, based on his expo-sure to his native language will set it to the value  X  X ositive. X  As a result, s/he can comprehend and produce subjectless sentences whereas an English speak-ing child would set it to  X  X egative X  and not allow dropped subject pronouns. pro-drop feature. For example, [Dell X  X rletta et al. 2005] point out that in Italian as a pro-drop language, the sequence of Verb-Noun could be either Verb-Object with a dropped subject or it could be a sequence of Verb-post ver-bal subject, which results in a case of syntactic ambiguity; this observation may be applied to Arabic and possibly all pro-drop languages. 4.5 Solutions There are several resources available for the morphological analysis of Arabic. The Xerox Arabic Morphological Analyzer Generator was developed in the 1990 X  X  by Ken Beesley at Xerox Research Center in Europe. 1 The imple-mentation uses finite state technology. It recovers Arabic roots and performs both analysis and generation. Arabic words can be entered using the Arabic script. Another resource for Arabic mor phology is Tim Buckwalter X  X  morpho-logical analyzer. 2 It differs from the Xerox morphological system in that it is stem-based and used a transliteration system that maps Arabic characters to Latin-based representation. A third resource is  X  X arf X  which is an engine that can generate Arabic verbs, nouns, gerunds, adjectives from their roots. 3 5. SYNTACTIC STRUCTURE OF ARABIC Arabic is a relatively free word order l anguage. While the primary word order in Classical Arabic and Modern Standard Arabic is verb-subject-object (VSO), they also allow subject-verb-object (SVO) and object-verb-subject (OVS). It is common to use the SVO in newspapers headlines. Arabic dialects exhibit the SVO order. All varieties of Arabic allow subjectless sentences when the subject is recoverable. Like Russian, all varieties of Arabic allow equational sentences without explicit use of the equivalent of verb  X  X o be X  in English. So,  X  X  a stu-dent X  meaning  X  X  am a student X  is perfectly grammatical in Arabic. wh-phrase at the beginning of the question as in  X   X  X  X   X  X  X  X  X   X  X   X  X  X hodidyou meet yesterday. X  However, Egyptian Arabic does not front the question phrase butkeepsitinplaceasin X   X  X  X   X  X  X  X  X  X   X   X  X  X  X  X   X   X  X ho did you see yesterday. X  noun referring to the lexical head in relative clauses. A typical Arabic relative clause will look like this literal translation  X  X  met the woman who you talked to her last night. X  modifiers have to agree in number, gender, case, and definiteness. In SVO structures, a verb must agree with its subject in gender, number, and person. However, in VSO sentences the verb is always in the singular even when its subject is dual or plural. The feature definiteness plays an important role in constituent formation. For example a noun construct usually begins with an indefinite noun followed by either a definite or indefinite noun as in  X   X   X  X he manager of the bank. X  The first term of the Arabic construct  X   X   X  X   X   X   X  X anager X  is indefinite whereas the second noun  X   X  X  X  X  X   X   X  X he bank X  is definite. In noun phrases consisting of a quantifier and a noun, the quantifier and the noun must disagree in gender. For example  X   X  X  X  X   X  X  X   X   X  X hree-masc men-masc X  is ungrammatical because the word  X  X hree X  is masculine, and so is  X  X en X . The phrase  X   X   X  X   X   X  X  X  X   X   X  X hree-fem men-masc X  is a grammatical Arabic phrase be-cause the quantifier and the noun disagree in gender.
 cal Arabic which was developed in from the 8th to the 10th centuries. Classical Arabic grammar was written to account fo r a closed corpus; that of the Quran and the Hadith which represents the Prophet X  X  sayings. Traditional Arabic grammarians clearly defined their goal which was to protect the purity of the Arabic language which was threatened when large number of people converted to Islam after the Islamic conquests and when the features of the native lan-guages of these new converts to Islam interfered with their ability to learn Arabic. So as a result, they made errors while they were reciting the Quran. In the absence of a Classical Arabic reference grammar and lexicons it would not be clear which usage was correct. A rab grammarians undertook the task of standardizing the correct usage of Arabic and in particular the correct pronun-ciation  X   X  X  X  X  X  X  X   X  (recitation) of the Quran as well as its correct interpretation. Correspondingly, the Quran is always written with full representation of the short vowels and with explicit case marking. Thus Arab grammarians had to account for case markings in their grammar texts.
 ern books which represent much of the input to ANLP programs are written in MSA and as such they do not show short vowels nor do they have explicit representation of most case markings. In processing such texts, syntactic constituency is crucial for the correct analysis of Arabic and for identifying constituent boundaries. Traditional Arabic grammar does not provide ANLP developers of MSA texts with the type of grammar they need. For example, tra-ditional Arabic grammar would analyze the following three phrases as idaafa or a noun construct: 1.  X  X  X  X   X  X  X  X  X   X  X anager of the bank X  2.  X   X  X   X  X   X  X  X  X   X  X ith sharp intelligence X  3.  X   X  X  X  X  X  X  X  X   X  X n top of the house X  second term is governed by the first and is assigned a genitive case. So they grouped them together as idaafa . In an Arabic machine translation system for example, we must be able to distinguish these three phrases by one of the following analyses: (1) is a noun phrase, (2) is an adjectival phrase, and (3) is a prepositional phrases. Such an analysis is more relevant and useful in ANLP applications than the traditional analysis which treats them as having one structure based on case ending which is not applicable to texts in MSA.
ANLP would benefit greatly from surface-based grammars of MSA the same way NLP systems benefited from lexical-based grammar formalisms such as Lexical Functional Grammar [Bresnan 2000] and Head Phrase Structure Grammar [Sag and Pollard 1994]. 5.1 Solutions Grammatical descriptions of Modern Standard Arabic has started to appear [Badawi et al. 2004; Ryding 2005]. Such descriptions are very useful in the processing of contemporary Arabic although they were not written from a com-putational viewpoint. The annotated Arabic corpora that have been developed at the LDC is extremely valuable for ANLP applications. Modern Standard Arabic texts have been analyzed with insights from traditional Arabic gram-mar as well as from modern linguistic theories. The LDC has also compiled corpora for some Arabic dialects and Arabic-English parallel corpora that are very useful for machine translation. Recently, as we mentioned earlier, the LDC released an annotated entity extraction corpus for Arabic. Another impor-tant resource is the Prague Arabic Dependency Treebank which implements a functional approach to the analysis of Modern Standard Arabic. There are also resources for Arabic dialects such as the Arabic Treebank at Columbia Univer-sity and the Arabic dialects corpora at the LDC. 6. CONCLUSION There are Arabic language features that are inherently challenging for ANLP researchers and developers. These features include the nonconcatenative na-ture of Arabic morphology, the absence of the orthographic representation of Arabic short vowels from contemporary Arabic texts, the need for an ex-plicit grammar of MSA that defines linguistic constituency in the absence of case marking. The new grammar also m ust describe important aspects such as anaphoric relations, the subjectless sentences, and discourse analysis. In spite of these challenges, significant work has been done in ANLP in applica-tions such as entity extraction [Shaalan and Raza 2009], machine translation [Farghaly and Senellart 2003; Shaalan et al. 2004; Fraser and Wong 2009; Sawaf 2009; Abdel Monem et al. 2009], and sentiment analysis [Almas and Ahmed 2007].

