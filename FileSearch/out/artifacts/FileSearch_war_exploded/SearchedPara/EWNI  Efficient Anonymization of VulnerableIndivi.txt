 Social networks, patient networks, email networks, and disease transmission networks are all examples of graphs that can be studied to learn about information diffusion, com-munity structure and different system processes; however, they are also all examples of graphs containing potentially sensitive information. For some of these networks, it is not just the personal information that is sensitive, but also the position or existence of an individual in the graph. For example, the existence of a patient in a disease transmis-sion network may be deemed as highly sensitive. As a result, a need exists to obscure sensitive topological information while still maintaining accurate graph properties for those studying these network s. Furthermore, because res earchers are typically inter-ested in data exploration applications, like community identification and information diffusion, our goal is to publish an anonymized, transformed network that is resilient against identity attacks and can be effectively studied as a graph.

A number of approaches have been proposed for anonymizing graphs. The re-search literature can be separated into two groups, those that add noise to the base graph and those that generalize the base graph. The former approaches use edge in-sertions and deletions to either deterministically create common patterns in the graph [24,16,25,3,26,7,6,22,19] or probabilistically add uncertainty [13,23,10,4]. The gener-alization strategy hides the detail level of the network by partitioning the graph into subgraphs, grouping nodes into clusters [5,20], or releasing specialized data structures that are specific for answering certain types of queries [12,14,11]. In this work, we investigate ways to publish a base graph that is sufficiently anonymized, contains suf-ficient detail for graph mining tasks using different graph properties, and is efficiently computed.

This work makes the following contributions: (1) Describes the use of simple graph metrics to guide the anonymization process; (2) Proposes a local anonymization strat-egy focusing on edge insertion or deletion to only the subset of nodes that are considered vulnerable and; (3) Experimentally evaluates the proposed method and shows that the released graph maintains a high degree of accu racy for different graph properties, in-cluding degree, betweenness, diameter, and av erage path length on five real world data sets, and are an order of magnitude more efficient than a well known approach that alters the entire graph.

The rest of the paper is organized as follows. Related literature is presented in sec-tion 2. In section 3, we provide necessary background and our privacy model. Our anonymization strategies are presented in section 4, followed by an experimental eval-uation in section 5, and conclusions in section 6. A number of previous works have shown that just removing the labels of published graphs is not sufficient for anonymization [2,12,17]. The main threats against these na X vely anonymized networks are node re-identification and edge disclosures .
Research focusing on adding noise to the base graph considers different strategies for edge insertion and edge deletion. Liu and Terzi [16] apply k -anonymity by ensuring that the degree of all nodes is k -anonymous. Zhou and Pei [25] focus on preventing neighborhood attacks by enforcing k -anonymous subgraphs based on a measure of the local neighborhood graph for all nodes. Their method relies on adding edges to the graph to make nodes that have distinct neighborhoods similar to other nodes. Wu et al [22] extend Zhou and Pei X  X  work by introduc ing the k-symmetry model that accounts for anonymization based on the degrees of each node X  X  neighbors. Similarly, Zou et al. [26] use k -automorphism to make subgraphs k -anonymous. More recently, Cheng et al. [6] developed the k -isomorphism method to preserve privacy at the subgraph level. Bhagat et al. [3] introduce the concept of label lists as a potential anonymity mechanism for obscuring the identity of a particular node. Z heleva and Getoor [24] present a number of anonymization strategie s for avoiding sensitive edge inference breaches. Tai et al focus on a particular edge breach referred t o as a friendship breach [19]. Das et al. [7] present a method for anonymizing social network graphs with weighted edges. Their linear programming anonymization method focuses on anonymizing the edge weights and preserving properties of the graph that are expressible as linear functions of the edge weights. In all these works, the anonymization procedure is applied to the entire graph. In contrast, we propose applying our anonymization procedure to a small subset of the full graph, thereby efficiently obtaini ng a releasable graph w ith comparable error. 3.1 Background Let G ( V, E ) represent a simple, undirected graph, where V = { v 1 ,v 2 , ..., v n } is the set of nodes and E = { e ij =( v i ,v j ) | v i  X  V and v j  X  V, and i = j } is the set of edges in G . Given a node v i in V , its neighbors N ( v i ) are the set of vertices adjacent to v union of the edges between v i and the nodes in N ( v i ) and the edges between the nodes in
N ( v N ( v i )  X  v i ,E S  X  E ( N ( v i )) } .

The degree of a vertex is the size of the neighborhood, | N ( v i ) | . Betweenness cen-trality is calculated by computing all of the graph X  X  shortest paths and determining how many shortest paths a given node appears in. Sociologists measure the importance of individuals in a network using different centrality measures, including degree centrality (hubs) and betweeness centrality (brokers) [ 21]. Computer scientists have used these same measures in different graph mining algorithms. 3.2 Privacy Model In this work, a data owner is interested in publishing a graph G =( V ,E ) that is an anonymized version of G . We assume that there is a bijective function f : V  X  V that maps every vertex in V to a vertex in V . We do not, however, require that all edges in E appear in E . Some edges in E may also not be present in E .

Most literature focuses on adversarial att acks on three parts of a graph: nodes, edges, and subgraphs. In this paper, our primary focus is on anonymizing nodes. We assume adversaries know the degree of one or more nodes, where the number of nodes known is small, | V known | &lt;&lt; | V | . However, the adversary does not know the neighborhood sub-graph S of any of the nodes in V known . Similar to related literature, k -degree anonymity occurs if at least k nodes have the same degree [16].
 Definition 1. Node exposure or a node identity breach occurs if any node in G is not k -degree anonymous.
 It is straightforward to determine if a node identity breach occurs using degree sets, where D a is a set of vertices in G having degree a : D a = { v i | deg ( v i )= a | v i  X  V } . We d e fi n e D as the set of all degree sets. For exa mple, in Figure 1 the complete set D of degree sets is D 1 = { A } ,D 2 = { C, D } ,D 3 = { B } .If k =2 , then nodes A and B are exposed because D 1 and D 3 each have only one node in their sets.
 Definition 2. Subgraph exposure occurs if all the neighborhood subgraphs of nodes in a particular degree set D j are the same.
 neighborhood subgraphs for a particular degree set are the same, then the adversary will know S ( v i ) with certainty. 1 When we consider subgraph exposure, we must deter-mine if all the subgraph neighborhoods are the same structure for a particular degree set. In other words, are they isomorphic? Determining if different neighborhoods in the graph are isomorphic is expensive t o compute. However, because our neighborhood subgraphs are ego networks, we can use some simple social network metrics, e.g. clus-tering coefficient, to identify degree sets containing exposed neighborhood structures.
The clustering coefficient CC v i of a vertex v i is a normalized value that shows how well connected the neighbors of vertex v i are: CC v i = 2 | S ( v i ) | | N ( v | N ( v i ) | X  2 . The clustering coefficient of a node ranges from 0 (no neighbors con-nected to each other) to 1 (all neighbors c onnected to each other). In Figure 1, the clustering coefficient of B, C, and D are 0 . 333 , 1 and 1, respectively.

To understand whether nodes in the same degree set D a have the same or similar neighborhood structure, we can compare the variance of the clustering coefficient: where CC ( D a ) is the clustering coefficient of each node in the degree set D a , var is the variance of these values, and  X  is the threshold for dissimilarity allowed in the neighborhood. If all the nodes in a degree set must have the exact same neighborhood subgraph to be exposed, then  X  =0 and the exposure occurs with var ( CC _ dif a )= 0 .However,if k is particularly large and want to extend the definition of subgraph exposure to allow for a very small percentage of the subgraphs for a degree set to not be isomorphic, then  X &gt; 0 . Returning to our example in Figure 1, nodes C and D in D 2 have the same connectivity structure, var ( CC _ dif a )=0 ; therefore, by definition both nodes have subgraph exposure.
 Problem Statement: Given a social network G , we want to publish G , a distorted version of G modified using a set of edge operations such that: 1) each vertex in V is represented in G ; 2) every vertex in V is k-degree anonymous in G ; 3) the degree of nodes that are already k-degree anonymous are not alterable; and 4) reasonable accuracy of different centrality and path measures exists in G .
 While we focus on degree anonymity to quantify structural uniqueness in this work, any reasonable set of graph properties can be used to define unique parts of a graph, e.g. centrality measures, neighborhood measur es, or subgraph structures. Therefore, we also propose a general definition for vulne rable components of a graph as follows: Definition 3. Inagraph G ,a weak node , v w , is a node that is identifiable in the graph based on one or more graph properties. The presence of weak nodes in a graph re-duces the overall anonymity of G . We define W as the set of all weak nodes in G .A weak neighborhood subgraph , S v i , occurs when the neighborhood subgraph of v i is isomorphic to all the other neighborhood subgraphs in D | N ( v i ) | . Algorithm 1. EWNI -Anonymization Approach In this section, we present our approach for graph anonymization. As described in Algorithm 1, our general approach is similar to that in [16]. The general approach pro-posed in [16] gathers the degrees of all nodes in G , identifies which degree sets do not have k nodes, and then changes the degree of those nodes to either match the closest de-gree that is k -degree anonymous or create a new degree set that is k -degree anonymous. After creating the new degree set, they construct a graph G basedonit.
 Similarly, we begin by determining the set of weak nodes ( find _ weak _ nodes () ). We then apply a graph anonymization algorithm based on edge modification to only neighborhoods of weak nodes. We consider two strategies, edge insertion and proba-bilistic edge modification. After graph anonymization, a graph construction step follows that is based on the computed degree sequence. Here we follow the standard procedure proposed in Liu and Terzi [16] and will, therefore, focus on the first two parts of the task in the remainder of this section. 4.1 Finding Weak Nodes and Neighborhood Subgraphs Our approach for calculating weak nodes is presented in Algorithm 2. For completeness, we also describe how to calculate weak subgraphs. Here, if | D i | &lt;k , a set of vulnerable nodes exists. Therefore, all nodes v i  X  D i in that degree set are added to a list of nodes ( weak_Da ) identified as weak due to their degree set length. We also track the difference between | D i | and k , allowing us to later rank the level of weakness of the nodes. When CC_dif &lt; X  , all nodes v i  X  D i are added to a list of node neighborhoods ( weak_cc ) identified as weak due to their CC_dif value. This is the EWNI _ CC _ DIF () function in Algorithm 2. Running our weak node identification method returns two lists, one of weak nodes and one of nodes with weak neighborhoods. The EWNI algorithm has a time complexity of O ( | V | X  ( | V | + | E | )) . However, in the worst case, it can require O ( | V | ) more disk space. As will be illustrated in section 5, in practice we find that the number of weak nodes and nodes with weak neighborhood subgraphs in a network is a small proportion of the total number of nodes. It also remains small as the size of the network increases. 4.2 Anonymizing G Our localized strategy focuses on changes to only the weak nodes and weak neighbor-hood subgraphs. The remaining parts of the graph remain the same. While we can our Algorithm 2. Efficient Weak Node Identification weak node techniques to different anonymization algorithms, we choose to explain the proof of concept using the general framework proposed in [16]. We first describe our approach for anonymization that applies edge insertion to the weak nodes in the graph. We then explain a variation that considers both insertions and deletion.
 Weak Node Edge Insertion: Let D W be the degree sequence of the weak nodes. For this method, we directly apply a greedy algorithm similar to [16] to only weak nodes, W . This algorithm creates a group of the first k highest degree nodes that are not k-degree anonymous and assigns them all the highest degree in the group. The algorithm then computes two costs, the cost of merging the ( k +1) -th node with the current group and the cost of starting a new group, where the cost is based on the number of edges that need to be inserted in each case. In order t o help with the decision, the algorithm looks ahead to k other nodes. The algorithm continues recursively until all the weak nodes are considered. The run time is O ( | W | X  k ) . The proof of correctness is straightforward. Probabilistic Weak Node Anonymity: For this method, we mimic the Weak Node Edge Insertion algorithm described above, but instead of always adding edges to make the k -sized group of nodes k -degree anonymous, we randomly determine whether to add or delete edges. Let p be the probability for deleting an edge and q =1  X  p be the probability for adding an edge. We first sort the degrees of the nodes in W .Thengiven the sorted set of weak nodes, during each iteration for a size k group we randomly insert or delete edges to the nodes in each weak degree set based on p and q . If the decision is to insert an edge, we insert edges to the nodes in the group until all the degrees of the nodes are equal to the highest degree in the group. If the decision is to delete an edge, we delete edges and decrease the degrees in the group until all the degrees are equal to the lowest degree in the group. This process continues until all the weak degree sets are members of k -degree anonymous degree sets. This method combines both a deterministic and probabilistic adding of noise to obtain k -degree anonymity. Proof. (Sketch) Nodes that are not in D W are already k -degree anonymous by defini-tion. Since the nodes in D W are considered in groups of k and, in each group, all nodes are assigned the same degree, these nodes become k -degree anonymous. Consequently, the produced graph (using [16]) satisfies k -degree anonymity as it consists of k -degree anonymous nodes.
 Probabilistic Weak Neighborhood Subgraph Anonymity: While our focus is on node exposure, our probabilistic weak node anonym ity algorithm could be extended for neigh-borhood subgraphs by only considering nodes and edges that are in W based on both weak _ cc and weak _ Da . Generally, the algorithm would focus on adding and removing edges that exist between neighbors that are weak. We save this analysis for future work. In this section we evaluate our approach in terms of 1) graph edit distance between G and G ; 2) accuracy of graph properties; and 3) efficiency of anonymization on five real world networks (graph properties shown in Table 1). The PolBlogs graph represents a network of hyperlinks between webl ogs about US po litics in 2005 [1]. The Jazz graph shows connections between different jazz musicians [8]. The Email graph is a network of email interchanges between members of t he University Rovira i Virgili [9]. The Wiki graph is a network representing user participation in different elections [15]. Last, the Facebook graph is from a crawl of a subset of public Facebook pages. Because this crawl followed a snowball sampling pro tocol with multiple s eeds, we remove nodes that only have a single degree since they are an artifact of the sampling approach. Sensitivity Analysis of Probabilistic Anonymization: Before comparing our anonymization algorithm to other algorithms, we want to understand the sensitivity of the percentage of additions vs. deletions of edge s. In other words, does the actual percentage of additions versus deletions affect the accu racy of the graph properties of interest?
Figure 2 shows the percentage of error introduced for our probabilistic method when we vary the percentage of edges that are in serted and deleted. Each experiment was run 10 times and the average results are presented. The x-axis shows the probability of deleting an edge as opposed to inserting it. The y-axis shows the amount of error introduced for each measure. This figure sho ws that the amount of error introduced is relatively constant, but does rise some as the probability of insertions becomes higher than deletions. Therefore, for the remainde r of our experiments, we will set the proba-bility of deleting an edge to 95% and the probability of adding an edge to 5%. Accuracy of Graph Properties: We now consider the accuracy of the released, per-turbed graphs. The methods we consider are as follows: the original Liu and Terzi al-gorithm [Liu], removal of weak nodes from the graph [Na X ve], Liu and Terzi applied to only weak nodes [Liu-Weak], our probabilistic anonymization [Prob], [Prob] with the first operation forced to be a deletion [Prob-Del-1st] or with the first operation forced to be an insertion [Prob-Ins-1st]. A na X ve approach for anonymizing weak nodes is to produce a graph G that simply removes each weak node, v w in W and incident edges to nodes in N ( v w ) from G . In the last two methods, to reduce the variance of the ba-sic probability anonymization procedure, we force the first operation to be consistent across runs. This is necessary because of the generally large variance in the degrees of the nodes in the first k weak nodes. Because they are the highest degree nodes, deleting or inserting has the largest amount of impact on this 1st group of nodes. Forcing the first action to always be the same reduces the variance to under 5%. The different algo-rithms were run ten times and the aver age error introduced by each method for k =10 is shown in Figure 3. If a bar is missing, then G was disconnected. We measured the error for varying values of k and the results were similar to those when k =10 .The x-axis shows the different data sets and the y-axis shows the value of the graph prop-erty as computed on the original graph G [Original], and on the anonymized graph G produced by each tested method.

From Figure 3 we see that the best performer is [Prob-Del-1st] and the na X ve removal of weak nodes generally results in the highest error across all data sets and measures. The exception to that is the betweenness calculation, where it generally outperforms the other methods. We suspect this occurs because the other approaches are adding at least a small fraction of edges to the graph, thereby creating new paths and potentially reducing the number of shortest paths each node lie s on. With the exception of the political blogs data set, applying Liu and Terzi to just the weak nodes introduces less error than applying the algorithm to the entire graph. In general, our probabilistic methods perform comparable or better than the other methods on these data sets.

Since our methods do not guarantee a minimum number of edge modifications to G , we also compare the graph edit distance between G and G . We set the baseline to be the Liu and Terzi method and compare the graph edit distances based on that method. Table 2 shows these results for each of the data sets averaged over 10 runs with k =3 and k =10 , respectively. The table should be read as follows. For the Jazz dataset, the [Liu-Weak] algorithm needs 669 fewer graph edit operations than [Liu] when k =3 and 13 fewer graph edit operations when k =10 . Looking at the entire table, we see that [Prob] has the smallest edit distance in all cases.

Finally, Singh and Zhan propose a measure called topological anonymity that uses node and subgraph exposure to quantify the level of risk associated with releasing a particular graph G [18]. It is computed as follows: where k represents the required number of nodes in a degree set and n is the number of nodes in G .The ta score, ranging from  X  1 to 1 , with  X  1 indicating that the graph is highly susceptible to both node and neighborhood subgraph exposure, and 1 indicating that the nodes are well anonymized.

As another method to quantify the level of anonymity of G compared to the other approaches, we compute the topological anonymity of G for the different methods. Figure 4 (shown below) illustrates the improvement in the ta score after anonymization. All the algorithms improve with the exception of the na X ve one.
 Weak Nodes Distribution: We now compare the distribution of weak nodes to deter-mine if they are similar or different across our data sets. Figure 6 shows the distribution of weak nodes when k =10 . The x-axis shows the degree of each weak node, and the y-axis shows the number of nodes with that degree. In all cases, the maximum of the y-value is k -1 , since degrees that have k or more nodes are not considered weak. These graphs show a number of interesting properties about the distribution of weak nodes. The main similarity among the graphs is that the far left side does not have any weak nodes, indicating that low degree nodes are generally k -degree anonymous. The Jazz network is the one exception. Second, we observe that as the degree increases, the num-ber of nodes with that degree decreases and the bars become sparser as we move from left to right along the x-axis. This may be an indication that there are fewer nodes with high degree and that those nodes are not always weak. Both of these observations sup-port theories that state social networks often follow a power law distribution. Finally, the figures highlight that the distribution of the weak nodes differs from data set to data set.
In addition to considering the number of weak nodes with each degree, we are also interested in the subgraphs formed by these weak nodes. They represent the portion of the graph that is most vulnerable to attack. Figure 7 shows that weak nodes tend to be highly connected, with all weak nodes in the Political Blogs network contained in one component, and the majority of weak nodes i n the Facebook network contained in one component. We measure the vulnerability asso ciated with subgraphs by considering their size and connectivity to other weak nodes. The subgraph vulner ability index is de-| W | is the total number of weak nodes, and | C SVI is 1 and 0 . 822 for Political Blogs and Facebook, respectively.
 Efficiency Results: Table 3 compares the run time of the Liu and Terzi algorithm to our delete first probabilistic anonymization algorithm with the probability of deleting an edge set to 95% and the probability of adding an edge set to 5% when k =10 . The second and third columns compare the preprocessing cost of the two approaches. The next two columns compare the anonymization approaches followed by the total run time in milliseconds.

Our preprocessing cost is higher than the original Liu and Terzi algorithm and is always the dominant cost of the approach. The Liu and Terzi algorithm precomputes a degree set map. Our algorithm precomput es a degree set map and clustering coeffi-cients. While for small graphs our preprocessing cost is high, as the size of the graph increases, it increases linearly, resulting in an overall run time that is still less than the overall run time of the Liu and Terzi algorithm.

Table 3 shows that our anonymization run time increases sublinearly and is orders of magnitudes faster than Liu and Terzi as the s ize of the graph increases. This is because our cost is related to the number of weak nodes in the graph, which is a small fraction of the total number of nodes. To evaluate the run time of the anonymization algorithm as the number of weak nodes increases, we simulate an increase in the number of weak nodes for each data set. Figure 5 shows that the run time increases linearly. Therefore, even when the number of weak nodes increases, the algorithm performs efficiently. This paper investigates anonymization of social graphs for data publishing. Current ap-proaches apply anonymization techniques to the entire graph. We introduce the concept of weak nodes and propose approaches that only anonymize those nodes. We show that the number of weak nodes tends to be small in real world networks and anonymiza-tion focusing on these nodes is orders of magnitude faster and maintains the same level of accuracy and a low edit distance when c ompared to traditional methods. By not distributing the noise uniformly across the graph, more of the original distribution and properties are well maintained. Future work will investigate weak subgraph anonymiza-tion and try to understand the impact of releasing a partially generalized graph. Acknowledgments. We would like to give a special thanks to our paper reviewers. Their insightful comments help improve the paper significantly. Finally, the experi-ments reported in this work were conducted at Georgetown University.
