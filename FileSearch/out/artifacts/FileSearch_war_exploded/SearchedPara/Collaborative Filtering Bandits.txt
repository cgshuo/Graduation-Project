 Classical collaborative filtering, and content-based filtering methods try to learn a static recommendation model given training data. These approaches are far from ideal in highly dynamic recommendation domains such as news recommen-dation and computational advertisement, where the set of items and users is very fluid. In this work, we investigate an adaptive clustering technique for content recommenda-tion based on exploration-exploitation strategies in contex-tual multi-armed bandit settings. Our algorithm takes into account the collaborative effects that arise due to the inter-action of the users with the items, by dynamically grouping users based on the items under consideration and, at the same time, grouping items based on the similarity of the clusterings induced over the users. The resulting algorithm thus takes advantage of preference patterns in the data in a way akin to collaborative filtering methods. We provide an empirical analysis on medium-size real-world datasets, showing scalability and increased prediction performance (as measured by click-through rate) over state-of-the-art meth-ods for clustering bandits. We also provide a regret analysis within a standard linear stochastic noise setting.
 Filtering and Recommending; Recommender Systems; On-line Learning; Collaborative Filtering; Clustering; Bandits; Regret; Computational Advertising
Recommender Systems are an essential part of many suc-cessful on-line businesses, from e-commerce to on-line stream-ing, and beyond. Moreover, Computational Advertising can be seen as a recommendation problem where the user pref-erences highly depend on the current context . In fact, many recommendation domains such as Youtube video recommen-dation or news recommendation do not fit the classical de-scription of a recommendation scenario, whereby a set of users with essentially fixed preferences interact with a fixed set of items. In this classical setting, the well-known cold-start problem, namely, the lack of accumulated interactions by users on items, needs to be addressed, for instance, by turning to hybrid recommendation methods (e.g., [19]). In practice, many relevant recommendation domains are dy-namic, in the sense that user preferences and the set of active users change with time. Recommendation domains can be distinguished by how much and how often user pref-erences and content universe change (e.g., [24]). In highly dynamic recommendation domains, such as news, ads and videos, active users and user preferences are fluid, hence classical collaborative filtering-type methods, such as Ma-trix or Tensor-Factorization break down. In these settings, it is essential for the recommendation method to adapt to the shifting preference patterns of the users.

Exploration-exploitation methods, a.k.a. multi-armed ban-dits, have been shown to be an excellent solution for these dynamic domains (see, e.g., the news recommendation evi-dence in [23]). While effective, standard contextual bandits do not take collaborative information into account, that is, users who have interacted with similar items in the past will not be deemed to have similar taste based on this fact alone, while items that have been chosen by the same group of users will also not be considered as similar. It is this sig-nificant limitation in the current bandit methodology that we try to address in this work. Past efforts on this problem were based on using online clustering-like algorithms on the graph or network structure of the data in conjunction with multi-armed bandit methods (see Section 3).

Commercial large scale search engines and information retrieval systems are examples of highly dynamic environ-ments where users and items could be described in terms of their membership in some preference cluster. For instance, in a music recommendation scenario, we may have groups of listeners (the users) clustered around music genres, with the clustering changing across different genres. On the other hand, the individual songs (the items) could naturally be grouped by sub-genre or performer based on the fact that they tend to be preferred by the same group of users. Ev-idence has been collected which suggests that, at least in specific recommendation scenarios, like movie recommenda-tion, data are well modeled by clustering at both user and item sides (e.g., [31]).

In this paper, we introduce a Collaborative Filtering based stochastic multi-armed bandit method that allows for a flex-ible and generic integration of information of users and items interaction data by alternatively clustering over both user and item sides. Specifically, we describe and analyze an adaptive and efficient clustering of bandit algorithm that can perform collaborative filtering, named COFIBA (pro-nounced as  X  X offee bar X ). Importantly enough, the clustering performed by our algorithm relies on sparse graph represen-tations, avoiding expensive matrix factorization techniques. We adapt COFIBA to the standard setting of sequential content recommendation known as (contextual) multi-armed bandits (e.g., [5]) for solving the canonical exploration vs. exploitation dilemma.

Our algorithm works under the assumption that we have to serve content to users in such a way that each content item determines a clustering over users made up of rela-tively few groups (compared to the total number of users), within which users tend to react similarly when that item gets recommended. However, the clustering over users need not be the same across different items. Moreover, when the universe of items is large, we also assume that the items might be clustered as a function of the clustering they de-termine over users, in such a way that the number of distinct clusterings over users induced by the items is also relatively small compared to the total number of available items.
Our method aims to exploit collaborative effects in a ban-dit setting in a way akin to the way co-clustering techniques are used in batch collaborative filtering. Bandit methods also represent one of the most promising approaches to the research community of recommender systems, for instance in tackling the cold-start problem (e.g., [25]), whereby the lack of data on new users leads to suboptimal recommen-dations. An exploration approach in these cases seems very appropriate.

We demonstrate the efficacy of our dynamic clustering al-gorithm on three benchmark and real-world datasets. Our algorithm is scalable and exhibits significant increased pre-diction performance over the state-of-the-art of clustering bandits. We also provide a regret analysis of the holding with high probability in a standard stochastically linear noise setting.
We assume that the user behavior similarity is encoded by a family of clusterings depending on the specific feature (or context, or item) vector x under consideration. Specifically, we let U = { 1 ,...,n } represent the set of n users. Then, given x  X  R d , set U can be partitioned into a small number upper bounded by a constant m , independent of x , with m being much smaller than n . (The assumption m &lt;&lt; n is not strictly required but it makes our algorithms more effective, and this is actually what we expect our datasets to comply with.) The clusters are such that users belong-ing to the same cluster U j ( x ) tend to have similar behav-ior w.r.t. feature vector x (for instance, they both like or both dislike the item represented by x ), while users lying in different clusters have significantly different behavior. The mapping x  X  { U 1 ( x ) ,U 2 ( x ) ,...,U m ( x ) ( x ) } specifying the actual partitioning of the set of users U into the clusters de-termined by x (including the number of clusters m ( x ) and its upper bound m ), as well as the common user behavior within each cluster are unknown to the learning system, and have to be inferred based on user feedback.

For the sake of simplicity, this paper takes the simple viewpoint that clustering over users is determined by lin-ear functions x  X  u &gt; i x , each one parameterized by an un-known vector u i  X  R d hosted at user i  X  U , in such a way that if users i and i 0 are in the same cluster w.r.t. x then u i x = u &gt; i 0 x , while if i and i 0 are in different clusters w.r.t. x then | u &gt; i x  X  u &gt; i 0 x |  X   X  , for some (unknown) gap param-eter  X  &gt; 0, independent of x . 1 As in the standard linear bandit setting (e.g., [5, 23, 12, 3, 13, 21, 30, 34, 16, 1], and references therein), the unknown vector u i determines the (average) behavior of user i . More concretely, upon receiv-ing context vector x , user i  X  X eacts X  by delivering a payoff value where i ( x ) is a conditionally zero-mean and bounded vari-ance noise term so that, conditioned on the past, the quan-tity u &gt; i x is indeed the expected payoff observed at user i for context vector x . Notice that the unknown parameter vector u i we associate with user i is supposed to be time invariant in this model. 2
Since we are facing sequential decision settings where the learning system needs to continuously adapt to the newly received information provided by users, we assume that the learning process is broken up into a discrete sequence of rounds: In round t = 1 , 2 ,... , the learner receives a user index i t  X  U to serve content to, hence the user to serve may change at every round, though the same user can re-cur many times. We assume the sequence of users i 1 ,i 2 is determined by an exogenous process that places nonzero and independent probability to each user being the next one to serve. Together with i t , the system receives in round t a set of feature vectors C i t = { x t, 1 , x t, 2 ,..., x encoding the content which is currently available for rec-ommendation to user i t . The learner is compelled to pick some  X  x t = x t,k t  X  C i t to recommend to i t , and then ob-serves i t  X  X  feedback in the form of payoff a t  X  R ing system is to maximize its total payoff P T t =1 a t over T rounds. When the user feedback at our disposal is only the click/no-click behavior, the payoff a t is naturally interpreted as a binary feedback, so that the quantity P T t =1 a t T clickthrough rate (CTR), where a t = 1 if the recommended item was clicked by user i t , and a t = 0, otherwise. CTR is the measure of performance adopted by our comparative experiments in Section 5.

From a theoretical standpoint (Section 6), we are instead interested in bounding the cumulative regret achieved by our algorithms. More precisely, let the regret r t of the learner at time t be the extent to which the average payoff of the best choice in hindsight at user i t exceeds the average payoff of the algorithm X  X  choice, i.e., We are aimed at bounding with high probability the cumu-lative regret P T t =1 r t , the probability being over the noise variables i t (  X  x t ), and any other possible source of random-ness, including i t  X  see Section 6.
As usual, this assumption may be relaxed by assuming the existence of two thresholds, one for the within-cluster dis-tance.
It would in fact be possible to lift this whole machinery to time-drifting user preferences by combining with known techniques (e.g., [11, 28]).
The kind of regret bound we would like to contrast to is one where the latent clustering structure over U (w.r.t. the feature vectors x ) is somehow known beforehand (see Sec-tion 6 for details). When the content universe is large but known a priori, as is frequent in many collaborative filter-ing applications, it is often desirable to also group the items into clusters based on similarity of user preferences, i.e., two items are similar if they are preferred by many of the same users. This notion of  X  X wo-sided X  clustering is well known in the literature; when the clustering process is simultaneously grouping users based on similarity at the item side and items based on similarity at the user side, it goes under the name of  X  X o-clustering X  (see, e.g., [14, 15]). Here, we consider a com-putationally more affordable notion of collaborate filtering based on adaptive two-sided clustering.

Unlike previous existing clustering techniques on ban-dits (e.g., [1, 29]), our clustering setting only applies to the case when the content universe is large but known a priori (yet, see the end of Section 4). Specifically, let the content universe be I = { x 1 , x 2 ,..., x |I| } , and P ( x { U ters over the set of users U induced by item x h . Then items x , x h 0  X  X  belong to the same cluster (over the set of items I ) if and only if they induce the same partition of the users, i.e., if P ( x h ) = P ( x h 0 ). We denote by g the number of dis-tinct partitions so induced over U by the items in I , and work under the assumption that g is unknown but signifi-cantly smaller than |I| . (Again, the assumption g &lt;&lt; |I| is not strictly needed, but it both makes our algorithms ef-fective and is expected to be satisfied in relevant practical scenarios.)
Finally, in all of the above, an important special case is when the items to be recommended do not possess specific features (or do not possess features having significant pre-dictive power). In this case, it is common to resort to the more classical non-contextual stochastic multiarmed ban-dit setting (e.g., [6, 4]), which is recovered from the con-textual framework by setting d = |I| , and assuming the content universe I is made up of the d -dimensional vectors e ,h = 1 ,...,d , of the canonical basis of R d , As a conse-quence, the expected payoff of user i on item h is simply the h -th component of vector u i , and two users i and i 0 belong to the same cluster w.r.t. to h if the h -th component of u equals the h -th component of u i 0 . Because the lack of useful annotation on data was an issue with all datasets at our dis-posal, it is this latter modeling assumption that motivates the algorithm we actually implemented for the experiments reported in Section 5.
Batch collaborative filtering neighborhood methods rely on finding similar groups of users and items to the target user-item pair, e.g., [33], and thus in effect rely on a dynamic form of grouping users and items. Collaborative Filtering-based methods have also been integrated with co-clustering techniques, whereby preferences in each co-cluster are mod-eled with simple statistics of the preference relations in the co-cluster, e.g., rating averages [18].

Beyond the general connection to co-clustering (e.g., [14, 15]), our paper is related to the research on multi-armed ban-dit algorithms for trading off exploration and exploitation through dynamic clustering. We are not aware of any spe-cific piece of work that combines bandits with co-clustering based on the scheme of collaborative filtering; the papers which are most closely related to ours are [16, 27, 29, 8, 22, 1, 2]. In [16], the authors work under the assumption that users are defined using a feature vector, and try to learn a low-rank hidden subspace assuming that variation across users is low-rank. The paper combines low-rank ma-trix recovery with high-dimensional Gaussian Process Ban-dits, but it gives rise to algorithms which do not seem prac-tical for sizeable problems. In [27], the authors analyze a non-contextual stochastic bandit problem where model pa-rameters are assumed to be clustered in a few (unknown) types. Yet, the provided solutions are completely different from ours. The work [29] combines ( k -means-like) online clustering with a contextual bandit setting, but clustering is only made at the user side. The paper [8] also relies on bandit clustering at the user side (as in [27, 29]), with an emphasis on diversifying recommendations to the same user over time. In [22], the authors propose cascading bandits of user behavior to identify the k most attractive items, and formulate it as a stochastic combinatorial partial monitoring problem. Finally, the algorithms in [1, 2, 26] can be seen as a special case of COFIBA when clustering is done only at the user side, under centralized [1, 26] or decentralized [2] environments.

Similar in spirit are also [7, 9, 10, 20]: In [7], the authors define a transfer learning problem within a stochastic multi-armed bandit setting, where a prior distribution is defined over the set of possible models over the tasks; in [9], the authors rely on clustering Markov Decision Processes based on their model parameter similarity. In [10], the authors discuss how to choose from n unknown distributions the k ones whose means are largest by a certain metric; in [20] the authors study particle Thompson sampling with Rao-Blackwellization for online matrix factorization, exhibiting a regret bound in a very specific case of n  X  m rank-1 matrices. Yet, in none of above cases did the authors make a specific effort towards item-dependent clustering models applied to stochastic multi-armed bandits.

Further work includes [25, 32]. In [25], an ensemble of contextual bandits is used to address the cold-start problem in recommender systems. A similar approach is used in [32] to deal with cold-start in recommender systems but based on the probability matching paradigm in a parameter-free bandit strategy, which employs online bootstrap to derive the distribution of the estimated models. In contrast to our work, in neither [25] nor [32] are collaborative effects explicitly taken into account.
COFIBA , relies on upper-confidence-based tradeoffs be-tween exploration and exploitation, combined with adaptive clustering procedures at both the user and the item sides. COFIBA stores in round t an estimate w i,t of vector u associated with user i  X  X  . Vectors w i,t are updated based on the payoff feedback, as in a standard linear least-squares approximation to the corresponding u i . Every user i  X  U hosts such an algorithm which operates as a linear bandit al-gorithm (e.g., [12, 3, 1]) on the available content C i t specifically, w i,t  X  1 is determined by an inverse correlation matrix M  X  1 i,t  X  1 subject to rank-one adjustments, and a vector b i,t  X  1 subject to additive updates. Matrices M i,t are initial-ized to the d  X  d identity matrix, and vectors b i,t are initial-ized to the d -dimensional zero vector. Matrix M  X  1 i,t  X  1 used to define an upper confidence bound cb i,t  X  1 ( x ) in the approximation of w i,t  X  1 to u i along direction x . Based on the local information encoded in the weight vectors w i,t  X  1 and the confidence bounds cb i,t  X  1 ( x ), the algorithm also maintains and updates a family of clusterings of the set of users U , and a single clustering over the set of items I . On both sides, such clusterings are represented through con-nected components of undirected graphs (this is in the same vein as in [1]), where nodes are either users or items. A pseudocode description of our algorithm is contained in Fig-ures 1, 2, and 3, while Figure 4 illustrates the algorithm X  X  behavior through a pictorial example.

At time t , COFIBA receives the index i t of the cur-rent user to serve, along with the available item vectors x t, 1 ,..., x t,c t , and must select one among them. In order to do so, the algorithm computes the c t neighborhood sets N , one per item x t,k  X  C i t based on the current aggrega-tion of users (clusters  X  X t the user side X ) w.r.t. item x Set N k should be regarded as the current approximation to the cluster (over the users) i t belongs to when the cluster-ing criterion is defined by item x t,k . Each neighborhood set then defines a compound weight vector  X  w N k ,t  X  1 the aggregation of the corresponding matrices M i,t  X  1 vectors b i,t  X  1 ) which, in turn, determines a compound con-fidence bound 3 cb N k ,t  X  1 ( x t,k ). Vector  X  w N k dence bound cb N k ,t  X  1 ( x t,k ) are combined through an upper-confidence exploration-exploitation scheme so as to commit to the specific item  X  x t  X  C i t for user i t . Then, the payoff a is received, and the algorithm uses  X  x t to update M i t performed at user i t , though this will affect the calculation of neighborhood sets and compound vectors for other users in later rounds.

After receiving payoff a t and computing M i t ,t and b i COFIBA updates the clusterings at the user side and the (unique) clustering at the item side. In round t , there are multiple graphs G U t,h = ( U ,E U t,h ) at the user side (hence many clusterings over U , indexed by h ), and a single graph G t = ( I ,E I t ) at the item side (hence a single clustering over I ). Each clustering at the user side corresponds to a single cluster at the item side, so that we have g t clusters  X  I 1 ,t ,...,  X  I g t ,t over items and g t clusterings over users  X  see Figure 4 for an example. On both user and item sides, up-dates take the form of edge deletions. Updates at the user side are only performed on the graph G U t, the selected item  X  x t = x t,k t . Updates at the item side are only made if it is likely that the neighborhoods of user i significantly changed when considered w.r.t. two previously deemed similar items. Specifically, if item x h was directly connected to item  X  x t at the beginning of round t and, as a consequence of edge deletion at the user side, the set of users that are now likely to be close to i t w.r.t. x h is no longer the same as the set of users that are likely to be close to i w.r.t.  X  x t , then this is taken as a good indication that item x h is not inducing the same partition over users as  X  x t hence edge (  X  x t , x h ) gets deleted. Notice that this need not imply that, as a result of this deletion, the two items are now belonging to different clusters over I , since these two items may still be indirectly connected.
The one given in Figure 1 is the confidence bound we use in our experiments. In fact, the theoretical counterpart to cb is significantly more involved, same efforts can also be found in order to close the gap, e.g., in [4, 1].
 It is worth stressing that a naive implementation of COFIBA would require memory allocation for maintain-ing |I| -many n -node graphs, i.e., O ( n 2 |I| ). Because this would be prohibitive even for moderately large sets of users, we make full usage of the approach of [1], where instead of starting off with complete graphs over users each time a new cluster over items is created, we randomly sparsify the com-plete graph by drawing an Erdos-Renyi initial graph, still retaining with high probability the underlying clusterings { U works under the assumption that the latent clusters U i ( x are not too small  X  see the argument in [1], where it is shown that in practice the initial graphs can have O ( n log n ) edges instead of O ( n 2 ). Moreover, because we modify the item graph by edge deletions only, one can show that with high probability (under the modeling assumptions of Section 2) the number g t of clusters over items remains upper bounded by g throughout the run of COFIBA , so that the actual stor-age required by the algorithm is indeed O ( ng log n ). This also brings a substantial saving in running time, since updat-ing connected components scales with the number of edges of the involved graphs. It is this graph sparsification tech-niques that we used and tested along the way in our exper-imentation parts.

Finally, despite we have described in Section 2 a setting where I and U are known a priori (the analysis in Section 6 currently holds only in this scenario), nothing prevents in practice to adapt COFIBA to the case when new content or new users show up. This essentially amounts to adding new nodes to the graphs at either the item or the user side, by maintaining data-structures via dynamic memory allo-cation. In fact, this is precisely how we implemented our algorithm in the case of very big item or user sets (e.g., the Telefonica and the Avazu dataset in the next section).
We compared our algorithm to standard bandit base-lines on three real-world datasets: one canonical benchmark dataset on news recommendations, one advertising dataset from a living production system, and one publicly available advertising dataset. In all cases, no features on the items have been used. We closely followed the same experimen-Figure 4: In this example, U = { 1 ,... 6 } and I = { x 1 ,..., x 8 } (the items are depicted here as 1 , 2 ,..., 8 ). (a) At the beginning we have g 1 = 1 , with a sin-gle item cluster  X  I 1 , 1 = I and, correspondingly, a single (degenerate) clustering over U , made up of the unique cluster U . (b) In round t we have the g = 3 item clusters  X  I 1 ,t = { x 1 , x 2 } ,  X  I 2 ,t = { x  X  I 3 ,t = { x 6 , x 7 , x 8 } . Corresponding to each one of them are the three clusterings over U depicted on the left, so that m U t, 1 = 3 , m U t, 2 = 2 , and m U t, 3 = 4 . In this example, i t = 4 , and  X  x t = x 5 , hence b h t = 2 , and we focus on graph G U t, 2 , corresponding to user clustering {{ 1 , 2 , 3 } , { 4 , 5 , 6 }} . Suppose in G U t, 2 the only neighbors of user 4 are 5 and 6. When updating such user clus-tering, the algorithm considers therein edges (4 , 5) and (4 , 6) to be candidates for elimination. Suppose edge (4 , 6) is eliminated, so that the new clustering over U induced by the updated graph G U t +1 , 2 becomes {{ 1 , 2 , 3 } , { 4 , 5 } , { 6 }} . After user graph update, the al-gorithm considers the item graph update. Suppose x 5 is only connected to x 4 and x 3 in G I t , and that x 4 is not connected to x 3 , as depicted. Both edge ( x 5 , x 4 ) and edge ( x 5 , x 3 ) are candidates for elimi-nation. The algorithm computes the neighborhood N of i t = 4 according to G U t +1 , 2 , and compares it to the the neighborhoods N U `,t +1 ( i t ) , for ` = 3 , 4 . As-sume N 6 = N U 3 ,t +1 ( i t ) , because the two neighborhoods of user 4 are now different, the algorithm deletes edge ( x 5 , x 3 ) from the item graph, splitting the item cluster { x 3 , x 4 , x 5 } into the two clusters { x 3 { x 4 , x 5 } , hence allocating a new cluster at the item side corresponding to a new degenerate clustering {{ 1 , 2 , 3 , 4 , 5 , 6 }} at the user side. (c) The resulting clusterings at the beginning of round t + 1 . (In this picture it is assumed that edge ( x 5 , x 4 ) was not deleted from the item graph at time t .) tal setting as in previous work [12, 1], thereby evaluating prediction performance by click-through rate.
Yahoo!. The first dataset we use for the evaluation is the freely available benchmark dataset which was released in the  X  X CML 2012 Exploration &amp; Exploitation Challenge X  4 . The aim of the challenge was to build state-of-the-art news arti-cle recommendation algorithms on Yahoo! data, by building an algorithm that learns efficiently a policy to serve news articles on a web site. The dataset is made up of random traffic records of user visits on the  X  X oday Module X  of Ya-hoo!, implying that both the visitors and the recommended news article are selected randomly. The available options (the items) correspond to a set of news articles available for recommendation, one being displayed in a small box on the visited web page. The aim is to recommend an interesting article to the user, whose interest in a given piece of news is asserted by a click on it. The data has 30 million visits over a two-week time stretch. Out of the logged information contained in each record, we used the user ID in the form of a 136-dimensional boolean vector containing his/her fea-tures (index i t ), the set of relevant news articles that the system can recommend from (set C i t ); a randomly recom-mended article during the visit; a boolean value indicating whether the recommended article was clicked by the visit-ing user or not (payoff a t ). Because the displayed article is chosen uniformly at random from the candidate article pool, one can use an unbiased off-line evaluation method to compare bandit algorithms in a reliable way. We refer the reader to [1] for a more detailed description of how this dataset was collected and extracted. We picked the larger of the two datasets considered in [1], resulting in n  X  18 K users, and d = 323 distinct items. The number of records ended up being 2 . 8 M , out of which we took the first 300 K for parameter tuning, and the rest for testing.

Telefonica. This dataset was obtained from Telefon-ica S.A., which is the number one Spanish broadband and telecommunications provider, with business units in Europe and South America. This data contains clicks on ads dis-played to user on one of the websites that Telefonica oper-ates on. The data were collected from the back-end server logs, and consist of two files: the first file contains the ads interactions (each record containing an impression times-tamp, a user-ID, an action, the ad type, the order item ID, and the click timestamp); the second file contains the ads metadata as item-ID, type-ID, type, order-ID, creative type, mask, cost, creator-ID, transaction key, cap type. Overall, the number n of users was in the scale of millions, while the number d of items was approximately 300. The data contains 15 M records, out of which we took the first 1 , 5 M for parameter tuning, and the rest for testing. Again, the only available payoffs are those associated with the items served by the system. Hence, in order to make the proce-dure be an effective estimator in a sequential decision process (e.g., [13, 17, 1, 23]), we simulated random choices by the system by generating the available item sets C i t as follows: At each round t , we stored the ad served to the current user i and the associated payoff value a t (1 = X  X licked X , 0 = X  X ot clicked X ). Then we created C i t by including the served ad along with 9 extra items (hence c t = 10  X  t ) which were drawn uniformly at random in such a way that, for any item e h  X  I , if e h occurs in some set C i t , this item will be the one served by the system 1 / 10 of the times. The random selection was done independent of the available payoff val-https://explochallenge.inria.fr/category/challenge ues a t . All our experiments on this dataset were run on a machine with 64GB RAM and 32 Intel Xeon cores.

Avazu. This dataset was prepared by Avazu Inc, 5 which is a leading multinational corporation in the digital adver-tising business. The data was provided for the challenge to predict the click-through rate of impressions on mobile devices, i.e., whether a mobile ad will be clicked or not. The number of samples was around 40 M , out of which we took the first 4 M for parameter tuning, and the remaining for testing. Each line in the data file represents the event of an ad impression on the site or in a mobile application (app), along with additional context information. Again, payoff a t is binary. The variables contained in the dataset for each sample are the following: ad-ID; timestamp (date and hour); click (boolean variable); device-ID; device IP; connection type; device type; ID of visited App/Website; category of visited App/Website; connection domain of vis-ited App/Website; banner position; anonymized categorical fields (C1, C14-C21). We pre-processed the dataset as fol-lows: we cleaned up the data by filtering out the records having missing feature values, and removed outliers. We identified the user with device-ID, if it is not null. The number of users on this dataset is in the scale of millions. Similar to the Telefonica dataset, we generated recommen-dation lists of length c t = 20 for each distinct timestamp. We used the first 4 M records for tuning parameters, and the remaining 36 M for testing. All data were transferred to Amazon S3, and all jobs were run through the Amazon EC2 Web Service.
We compared COFIBA to a number of state-of-the-art bandit algorithms: We tuned the optimal parameters in the training set with a standard grid search as indicated in [13, 1], and used the test set to evaluate the predictive performance of the algorithms. Since the system X  X  recommendation need not coincide with the recommendation issued by the algorithms we tested, we only retained the records on which the two recommendations were indeed the same. Because records are discarded on https://www.kaggle.com/c/avazu-ctr-prediction the fly, the actual number T of retained records ( X  X ounds X  in the plots of the next subsection) changes slightly across algorithms; T was around 70 K for the Yahoo! data, 350 K for the Telefonica data, and 900 K for the Avazu data. All experimental results we report were averaged over 3 runs (but in fact the variance we observed across these runs was fairly small).
Our results are summarized in Figures 5, 6, and 7. Fur-ther evidence is contained in Figure 8. In Figures 5 X 7, we plotted click-through rate ( X  X TR X ) vs. retained records so far ( X  X ounds X ). All these experiments are aimed at testing the performance of the various bandit algorithms in terms of prediction performance, also in cold-start regimes (i.e., the first relatively small fraction of the time horizon in the x -axis). Our experimental setting is in line with previous ones (e.g., [12, 1]) and, by the way the data have been prepared, gives rise to a reliable estimation of actual CTR behavior under the same experimental conditions as in [12, 1]. Figure 8 is aimed at supporting the theoretical model of Section 2, by providing some evidence on the kind of clustering statis-tics produced by COFIBA at the end of its run.

Whereas the three datasets we took into consideration are all generated by real online web applications, it is worth pointing out that these datasets are indeed different in the way customers consume the associated content. Generally speaking, the longer the lifecycle of one item the fewer the items, the higher the chance that users with similar prefer-ences will consume it, and hence the bigger the collaborative effects contained in the data. It is therefore reasonable to expect that our algorithm will be more effective in datasets where the collaborative effects are indeed strong.

The users in the Yahoo! data (Figure 5), are likely to span a wide range of demographic characteristics; on top of this, this dataset is derived from the consumption of news that are often interesting for large portions of these users and, as such, do not create strong polarization into subcommunities. This implies that more often than not, there are quite a few specific hot news that all users might express interest in, and it is natural to expect that these pieces of news are intended to reach a wide audience of consumers. Given this state of affairs, it is not surprising that on the Yahoo! dataset both LINUCB-ONE and LINUCB-V (serving the same news to all users) are already performing quite well, thereby making the clustering-of-users effort somewhat less useful. This also explains the poor performance of LINUCB-IND , which is not performing any clustering at all. Yet, even in this non-trivial case, COFIBA can still achieve a significant increased prediction accuracy compared, e.g., to CLUB , thereby sug-gesting that simultaneous clustering at both the user and the item (the news) sides might be an even more effective strategy to earn clicks in news recommendation systems.
Most of the users in the Telefonica data are from a diverse sample of people in Spain, and it is easy to imagine that this dataset spans a large number of communities across its pop-ulation. Thus we can assume that collaborative effects will be much more evident, and that COFIBA will be able to leverage these effects efficiently. In this dataset, CLUB forms well in general, while DYNUCB deteriorates in the initial stage and catches-up later on. COFIBA seems to sur-pass all other algorithms, especially in the cold-start regime, all other algorithms being in the same ballpark as CLUB . Finally, the Avazu data is furnished from its professional digital advertising solution platform, where the customers click the ad impressions via the iOS/Android mobile apps or through websites, serving either the publisher or the ad-vertiser which leads to a daily high volume internet traffic. In this dataset, neither LINUCB-ONE nor LINUCB-IND displayed a competitive cold-start performance. DYNUCB is underperforming throughout, while LINUCB-V demon-strates a relatively high CTR. CLUB is strong at the be-ginning, but then its CTR performance degrades. On the F igure 8: A typical distribution of cluster sizes over users for the Yahoo dataset. Each bar plot corre-sponds to a cluster at the item side. We have 5 plots since this is the number of clusters over the items that COFIBA ended up with after sweeping once over this dataset in the run at hand. Each bar represents the fraction of users contained in the corresponding cluster. For instance, the first cluster over the items generated 16 clusters over the users (bar plot on top), with relative sizes 31%, 15%, 12%, etc. The second cluster over the items generated 10 clusters over the users (second bar plot from top) with relative sizes 61%, 12%, 9%, etc. The relative size of the 5 clusters over the items is as follows: 83%, 10%, 4%, 2%, and 1%, so that the clustering pattern depicted in the top plot applies to 83% of the items, the second one to 10% of the items, and so on. other hand, COFIBA seems to work extremely well during the cold-start, and comparatively best in all later stages.
In Figure 8 we give a typical distribution of cluster sizes produced by COFIBA after at the end of its run. 6 The emerging pattern is always the same: we have few clusters over the items with very unbalanced sizes and, correspond-ing to each item cluster, we have few clusters over the users, again with very unbalanced sizes. This recurring pattern is in fact the motivation behind our theoretical assumptions (Section 2), and a property of data that the COFIBA algo-rithm can provably take advantage of (Section 6). These bar plots, combined with the comparatively good performance of
COFIBA , suggest that our datasets do actually possess clusterability properties at both sides.

To summarize, despite the differences in the three
Wi thout loss of generality, we take the first Yahoo dataset to provide statistics, for similar shapes of the bar plots can be established for the remaining ones. datasets, the experimental evidence we collected on them is quite consistent, in that in all the three cases COFIBA significantly outperforms all other competing methods we tested. This is especially noticeable during the cold-start period, but the same relative behavior essentially shows up during the whole time window of our experiments. COFIBA is a bit involved to implement, as contrasted to its com-petitors, and is also somewhat slower to run (unsurprisingly slower than, say, LINUCB-ONE and LINUCB-IND ). On the other hand, COFIBA is far more effective in exploit-ing the collaborative effects embedded in the data, and still amenable to be run on large datasets.
The following theorem is the theoretical guarantee of COFIBA , where we relate the cumulative regret of COFIBA to the clustering structure of users U w.r.t. items I . For simplicity of presentation, we formulate our result in the one-hot encoding case, where u i  X  R d , i = 1 ,...,n , and I = { e 1 ,..., e d } . In fact, a more general statement can be proven which holds in the case when I is a generic set of feature vectors I = { x 1 ,..., x |I| } , and the regret bound depends on the geometric properties of such vectors. 7
In order to obtain a provable advantage from our clus-terability assumptions, extra conditions are needed on the way i t and C i t are generated. The clusterability assump-tions we can naturally take advantage of are those where, for most partitions P ( e h ), the relative sizes of clusters over users are highly unbalanced. Translated into more practical terms, cluster unbalancedness amounts to saying that the universe of items I tends to influence users so as to deter-mine a small number of major common behaviors (which need neither be the same nor involve the same users across items), along with a number of minor ones. As we saw in our experiments, this seems like a frequent behavior of users in some practical scenarios.

Theorem 1. Let the COFIBA algorithm of Figure 1 be run on a set of users U = { 1 ,...,n } with associated profile vectors u 1 ,..., u n  X  R d , and set of items I = { e such that the h -th induced partition P ( e h ) over U is made up of m h clusters of cardinality v h, 1 ,v h, 2 ,...,v h,m tively. Moreover, let g be the number of distinct parti-tions so obtained. At each round t , let i t be generated uni-formly at random 8 from U . Once i t is selected, the num-ber c t of items in C i t is generated arbitrarily as a func-tion of past indices i 1 ,...,i t  X  1 , payoffs a 1 ,...,a C 1 ,...,C i t  X  1 , as well as the current index i t . Then the se-quence of items in C i t is generated i.i.d. (conditioned on i c and all past indices i 1 ,...,i t  X  1 , payoffs a 1 ,...,a sets C i 1 ,...,C i t  X  1 ) according to a given but unknown dis-tribution D over I . Let payoff a t lie in the interval [  X  1 , 1] , and be generated as described in Section 2 so that, condi-tioned on history, the expectation of a t is u &gt; i let parameters  X  and  X  2 be suitable functions of log(1 / X  ) . If c  X  c  X  t then, as T grows large, with probability at least
I n addition, the function cb should be modified so as to incorporate these properties.
Any distribution having positive probability on each i  X  X  would suffice here. 1  X   X  the cumulative regret satisfies 9
X where S = S ( h ) = P m h j =1  X  v h,j , h is a random index such that e h  X  D , and E [  X  ] and var (  X  ) denote, respectively, the expectation and the variance w.r.t. this random index. To get a feeling of how big (or small) E [ S ] and var [ S ] can be, let us consider the case where each partition over users has a single big cluster and a number of small ones. To make it clear, consider the extreme scenario where each P ( e h one cluster of size v h, 1 = n  X  ( m  X  1), and m  X  1 clusters of size v h,j = 1, with m &lt; E [ S ] = p n  X  ( m  X  1) + m  X  1, and var ( S ) = 0, so that the resulting regret bound essentially becomes e O ( the standard regret bound one achieves for learning a single d -dimensional user (aka, the standard noncontextual bandit bound with d actions and no gap assumptions among them). At the other extreme lies the case when each partition P ( e has n -many clusters, so that E [ S ] = n , var ( S ) = 0, and the resulting bound is e O ( be achieved in the case when var ( S ) &gt; 0, where also the interplay with c starts becoming relevant. Finally, observe that the number g of distinct partitions influences the bound only indirectly through var ( S ). Yet, it is worth repeating here that g plays a crucial role in the computational (both time and space) complexity of the whole procedure.

Proof of Theorem 1. The proof sketch builds on the analysis in [1]. Let the true underlying clusters over the authors show that, because each user i has probability 1 /n to be the one served in round t , we have, with high prob-ability, w i,t  X  u i for all i , as t grows large. Moreover, because of the gap assumption involving parameter  X  , all edges connecting users belonging to different clusters at the user side will eventually be deleted (again, with high prob-ability), after each user i is served at least O ( 1  X  2 ) times. By the way edges are disconnected at the item side, the above is essentially independent (up to log factors due to union bounds) of which graph at the user side we are referring to. In turn, this entails that the current user clusters encoded by the connected components of graph G U t,h will eventually converge to the m h true user clusters (again, independent of h , up to log factors), so that the aggregate weight vectors  X  w
N k ,t  X  1 computed by the algorithm for trading off explo-ration vs. exploitation in round t will essentially converge to u i t at a rate of the form 10 where h t is the index of the true cluster over items that  X  x belongs to, j t is the index of the true cluster over users that i belongs to (according to the partition of U determined
The e O -notation hides logarithmic factors in n , m , g , T , d , 1 / X  , as well as terms which are independent of T .
Because I = { e 1 ,..., e d } , the minimal eigenvalue  X  of the process correlation matrix E [ X X &gt; ] in [1] is here 1 /d . More-over, compared to [1], we do not strive to capture the geom-etry of the user vectors u i in the regret bound, hence we do not have the extra by h t ), T h t ,j t ,t  X  1 is the number of rounds so far where we happened to  X  X it X  cluster V h t ,j t , i.e., and the expectation is w.r.t. both the (uniform) distribution of i t , and distribution D generating the items in C i t ditioned on all past events. Since, by the Azuma-Hoeffding inequality, T h t ,j t ,t  X  1 concentrates as we have It is the latter expression that rules the cumulative regret of COFIBA in that, up to log factors: Eq. (2) is essentially (up to log factors and omitted addi-tive terms) the regret bound one would obtain by knowning beforehand the latent clustering structure over U .
Because h t  X  C i t is itself a function of the items in C can eliminate the dependence on h t by the following simple stratification argument. First of all, notice that Then, we set for brevity S ( h ) = P m h j =1  X  v h,j , and let h the index of the true cluster over items that x t,k belongs to (recall that h t,k is a random variable since so is x t,k S ( h t,k )  X  so that, after some overapproximations, we conclude that P t =1 r t is upper bounded with high probability by
O E D [ S ( h )] + q c the expectation and the variance being over the random in-dex h such that e h  X  X  .
We have initiated an investigation of collaborative filter-ing bandit algorithms operating in relevant scenarios where multiple users can be grouped by behavior similarity in dif-ferent ways w.r.t. items and, in turn, the universe of items can possibly be grouped by the similarity of clusterings they induce over users. We carried out an extensive experimen-tal comparison with very encouraging results, and have also given a regret analysis which operates in a simplified sce-nario. Our algorithm can in principle be modified so as to be combined with any standard clustering (or co-clustering) technique. However, one advantage of encoding clusters as connected components of graphs (at least at the user side) is that we are quite effective in tackling the so-called cold start problem, for the newly served users are more likely to be connected to the old ones, which makes COFIBA in a po-sition to automatically propagate information from the old users to the new ones through the aggregate vectors  X  w N In fact, so far we have not seen any other way of adaptively clustering users and items which is computationally afford-able on sizeable datasets and, at the same time, amenable to a regret analysis that takes advantage of the clustering assumption.

All our experiments have been conducted in the setup of one-hot encoding, since the datasets at our disposal did not come with reliable/useful annotations on data. Yet, the al-gorithm we presented can clearly work when the items are accompanied by (numerical) features. One direction of our future research is to compensate for the lack of features in the data by first inferring features during an initial train-ing phase through standard matrix factorization techniques, and subsequently applying our algorithm to a universe of items I described through such inferred features. Another line of experimental research would be to combine different bandit algorithms (possibly at different stages of the learn-ing process) so as to roughly get the best of all of them in all stages. This would be somewhat similar to the meta-bandit construction described in [25]. Another one would be to combine with matrix factorization techniques as in, e.g., [20].
We would like to thank the anonymous reviewers for their helpful and constructive comments. The first author thanks the support from MIUR and QCRI-HBKU. Also, the first and the third author acknowledge the support from Ama-zon AWS Award in Machine Learning Research Grant. The work leading to these results has received funding from the European Union X  X  Seventh Framework Programme (FP7/ 2007-2013) under CrowdRec Grant Agreement n  X  610594.
