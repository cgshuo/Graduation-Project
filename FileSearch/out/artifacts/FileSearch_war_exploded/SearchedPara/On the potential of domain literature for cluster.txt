
In many complex knowledge discovery problems, such as 
In this paper we reach one step further than classical text 
As a first case, we cluster a custom collection of yeast 
As a conclusion, we observe in both cases that the infor-finding the most effective textual source of information and the best text representation is essential if we want to inte-grate text and data in knowledge discovery. 
The paper is organized as follows: Section 2 presents a framework for the integrated analysis of data, domain knowledge, and literature with an emphasis on the evalua-tion of the use of literature in statistical methods. Section 3 summarizes the text representations, relevance measures, and general linguistic preprocessing used in the paper. Sec-tion 4 discusses the usage of literature in clustering expres-sion data and overviews the genomic information sources for the model organism yeast. Quantitative measures for the us-ability of literature in clustering are introduced. Section 5 presents the medical problem of assessing ovarian tumors by ultrasonography together with the task of identifying a probabilistic model of the corresponding clinical measure-ments. We introduce Bayesian networks together with a standard score based on data for the identification of such models. We also introduce a new score based on literature that plays a role similar to the previous score in identifying Bayesian network substructures but this time from litera-ture instead of data. Section 6 presents the comparison of literature-based clustering against expert knowledge in the yeast genomic domain and the comparison of the literature-and data-based scores used in learning Bayesian networks in the ovarian cancer domain. Results are reported for several vector representations of text and types of textual informa-tion sources. Specifically, we report results on the use of automatically expanding the initial annotation of the vari-ables. Finally, Sections 7 and 8 contains the discussion, con-clusion, and our view on how the integrated use of literature and statistical data is possible. 
In most domains the information that can be used in mod-eling comes from different types of sources. On the one hand, we have the observed cases, which lead to a data set D. This type of information is the most straightforward to work with. On the other hand, a lot of prior domain knowl-edge can be available in various formats. In this paper we will restrict this prior knowledge to (1) textual information and (2) a small amount of expert knowledge for validation. Textual information is hard to deal with in computational and statistical procedures and it needs a lot of preprocess-ing to convert into a usable format, but it can be valuable when only a few data samples are present or the data is noisy. The optimal but most difficult strategy would be to use both information sources in the model building pro-cess in some integrated fashion. To evaluate the possibilities of such combined methodologies, we investigate the agree-ment between data-based scores commonly used in Bayesian network model selection and a newly introduced text-based score explained in Section 5. Additionally, we compare the results of a text-based clustering with a gold standard pro-vided by an expert, as explained in Section 4. 
In both cases we have a set of domain variables V1,..  X , Vm, which represent medical observations in the Bayesian net-work case and yeast genes in the cluster case. For these variables we want to derive somehow a relatedness measure based on textual information. To achieve this, an expert an-notates these domain variables with free text (describing the variables) and relevant references for this variable in the lit-erature repository. The following step converts these textual annotations into a vector representation used in the experi-ments explained above. It is expected that there will be no strict match between the textual information and the data or prior knowledge, but to some extent they should reveal the same relations. In the presented framework, we hope to demonstrate that both information sources can complement each other in an integrated model building process. 
We assume that we have a free-text annotation for each domain variables. Such an annotation can further contain references to domain-related document collections. These two types of annotations give rise to the commonly used vectorial text representations and the reference representa-tion. 
The representation called the vector space model encodes a document in eL k-dimensional space where each component represents a corresponding word, neglecting the grammat-ical structure of the text. We applied the Porter stemmer to canonize the words [6], the synonyms were replaced, and the phrases were detected and merged. In both domains, we automatically constructed a large vocabulary containing more than one million words and manually compiled a small vocabulary containing less than one thousand words. Based vides for each document d~ in the collection (annotations plus document repository), a vector of term scores vlj. We computed the fbllowing controlled indices for the document collections (see [17, 11]): Additionally, we computed another type of index called the reference representation (see for example [18]). Each anno-tation contains references to different documents from the repository. As a representation, we consider which docu-ments each annotation refers to: 
To express the similarity between pairs of documents and the similarity of a document to a set of documents, we used the following definitions [17, 11]. For pairs of documents di and dj we used the cosine of the angle between the corre-sponding normalized vector representations: a priori distribution over the local dependency struc-
In our analysis, GO (which provides only brief keyword Annotation I Weighting scheme I Hier KMed GO bool 0.2494 0.1608 GO bool restr 0.2252 0.1561 GO-ML2o bool GO-ML20 freq GO-ML20 tf.idf GO-ML2o reference YC bool YC tf.idf 
YC-ML2o I ty.idf Table 2: Contingency table for best clustering. the domain variables by their relevance to the Pathology variable according to a medical expert, the statistical data, and the literature. 
Table 3: Relevance ranking of variables for the vari-able Pathology by text, data, and a medical expert 
Rank Text Data Expert 1 2 3 4 5 6 7 8 9 10 11 12 
In Fig. 2 the domain variables are positioned on the coor-further the correlation between text-and data-based scores. 
Fig. 3 shows all palrwise relevance scores gT(yl, Vj). 
Figure 2: Text-and data-based relevance scores for tion, Boolean representation, the small domain vo-cabulary). 
To evaluate the effect of the different text representations, annotations type, and domain vocabularies on the relation of text and data scores, we computed the correlation coefficient and the Spearman rank correlation coefficient Rs. For the variable V/, Rs is defined as Rs = 1 6 L'~=l'Rankwe't~Tr/~j RankDst~(Trlj)) 2 where Pi is the number of possible parental sets for vari-able V/ and ~iy,j = 1,... ,Pi are all the possible parental 
Figure 3: The vizuaiisation of text-based relevance scores gT(v~, Vj) for the pairs of domain variables (.free text annotation, tf.idf representation, the small do-main vocabulary, threshold 0.2). sets (which are all possible combinations of the other vari-ables upto a certain fixed number of parents t, i.e., we have P~ = ,~t z) possible combinations). 
We also report the average of the Spearman rank corre-lation coefficients for the variables. Additionally, we report a special rank-correlation measure defined as follows. For each variable, the text-and data-based scores define a text rank and data rank for the parental sets. Define a ma-trix R in which the akl element is the number of times the parental sets have text rank k and data rank I. Clearly, if the scores or their rankings for each variable are identi-cal this will be a diagonal matrix. Now define a matrix R' which is the 4-by-4 partitioning of R with the following intu-itive interpretation for the four partitions: highly relevant, moderately relevant, less relevant, and not relevant. The respective diagonal consists the following pairs from upper left to lower right: (highly relevant by text, highly relevant by data), (moderately relevant by text, moderately relevant by data), and so on. We report the normalized trace of R ', that is the correspondence between the text and data~based ranking using this 4-graded granularity for all the variables and only for Pathology also. 
Table 4 presents the results for the most interesting set-tings while Table 5 contains a more structured and detailed reports for a larger number of settings. 
Table 4: Relations between text-and data-based scores. The correlation coefficients, the Spearman rank correlations, and the normalized trace of the text-rank-data-rank matrices are reported for the respective settings (free text, optionally expanded with dictionary entries or MEDLINE abstracts, set size is 1). tf.idf, T-O3 0.49 0.44 0.80 0.34 0.31 bool, T-ML~2 0.71 0.48 0.61 0.34 0.30 
In our study on text clustering, we found the freq and applied on the expanded annotation to be superior to the boolean representation and the reference representation. An optimal choice between them, however, depends on the an-notation source and cannot be known in advance. The Gene Ontology and functional annotation database SWISS-PROT proved valuable sources of free-text information, especially curated databases of structured and unstructured informa-tion not only provide indispensable access to information, but also constitute useful sources to automatically extract knowledge from domain literature. The poor performance of the reference representation partly can be explained by its sensitivity to the quality of the expansion (kernel quality and retrieval quality). 
Because no data set of gene expression data can serve as a high-quality benchmark for clustering, we conducted our comparison of various annotations and vector representa-tions on a custom gene partition. Although the constructed clustering problem is fairly easy from a biological viewpoint, it made it possible to isolate the effects of various informa-tion sources and parameterizations on the cluster perfor-mance. We found that internal scores can provide an im-portant confidence measure in the quality of text-clustering and indirectly in the comparison between text-based and data-based clustering. 
One of our aims is to construct a statistical representation suitable for integrating prior knowledge in expression-based gene clustering, We therefore outline in Fig. 7 how we plan to use the current representation. Using the terminology in [14], we depict early, intermediate, and late integration of expression data and text. Early integration pools both types of statistical data and passes it to the cluster algorithm. In-termediate integration creates one variable-to-variable sim-ilarity matrix for each data type, merges them in some way, and passes them to a clustering algorithm. Finally, late in-tegration compares or merges two separate analyses. The question which of these schemes provide a good foundation for integrated cluster analysis constitutes a topic of our fu-ture research. Figure 4: Various ways of integrating domain liter-ature and data in clustering 
For the Bayesian network, the text-and data-based scores proved to be significantly correlated and rank-correlated. From the medical point of view, the ranking of the parental sets seems surprisingly good. Contrary to our expectations, the expansion of the annotations with manual or automati-cally selected references could not improve the performance, which needs further investigations. The related reference representation :similarly has a poor performance. 
One future research direction is the incorporation of text-based scores in various Bayesian network algorithms. The Bayesian framework presented in Section 5.2 offers a prin-cipled method for the incorporation of prior domain knowl-edge through prior distributions. Currently, we are investi-gating methods for such a transformation and evaluate their effects on the classification performance in the ovarian can-cer domain. A related direction is the general investigation of the score gT(., .) and the corresponding conditional inde-pendence statements in an induced Bayesian network. 
Finally, in both applications the text-based scores, that text, while the annotations are already structured into var-ious fields. For example, the MEDLINE references contain manually curated MeSH keywords. A structured text rep-resentation with a corresponding text-based score exploit-ing this structural information may have many advantages. A related research topic would be a more refined linguistic analysis, including better phrase identification or shallow parsing for a better representation of the content yielding an improved sim(., .), enhancing also the text-based score. 
In this paper, we assumed to have short free-text descrip-tions for the domain variables and a huge repository of re-lated domain literature. We used data and external assess-ments for evaluation purposes. We considered the prob-lem of identifying which text representations and statistical scores best support the use of literature in statistical models. We investigated this potential for two statistical methods: clustering and Bayesian network learning. Firstly, we re-ported the performance in clustering yeast genes against an expert reference. Secondly, we reported the correspondence between text and data in scoring Bayesian network substruc-tures in the medical task of modeling the joint distribution of clinical measurements of ovarian tumors. Results reported for various types of textual information sources and vecto-rial text representations indicate that the use of literature and statistical data can be formulated in a common frame-work and their effects can be compared. This suggests that closely coupled representations and methods are a viable foundation in the development of integrated text and data analysis methods. 
Dr. Bart De Moor is a full professor at the Katholieke Uni-versiteit Leuven, Belgium. Yves Moreau is an assistant professor at the K.U.Leuven and a postdoctoral researcher with the Bel-gian Fund for Scientific Research (F.W.O. -Vlaanderen). Pe-ter Antal and Patrick Glenisson are Research Assistants with the K.U.Leuven. Geert Fannes is a Research Assistant with the F.W.O. Vlaanderen. Our research is supported by grants from: Research Council KUL: Concerted Research Action GOA-Mefisto 666, IDO (IOTA Oncology, Genetic networks); Flemish Govern-ment: Fund for Scientific Research Flanders (projects G.0256.97, G.0115.01, G.0240.99, G.0197.02, G.0407.02, research communi-ties ICCoS, ANMMM), AWI (Bil. Int. Collaboration Hungary/ Poland), IWT (Soft4s, STWW-Genprom, GBOU-McKnow, Eureka-Impact, Eurek~-FLiTE); Belgian Federal Government: DWTC (IUAP IV-02 (1996-2001) and IUAP V-10-29 (2002-2006), Progr. Sust. Dev. PODO-II (CP-TR-18) 
Janick Mathys (KUL/ESAT-SCD, email: j anick, mathys~esat, kuleuven, ac. be) and Bart De Moor (K.U.Leuven/ESAT-SCD, email: bart. demoor~esat, kuleuven, ac .be) and Yves Moreau (K.U.Leuven/ESAT-SCD, emaih yves .moreau~esat. kuleuven, ac .be). [1] P. Antal, T. Meszaros, B. De Moor, and 
T. Dobrowiecki. Annotated bayesian networks: a tool to integrate textual and probabilistic medical knowledge. In Proc. of the 13th IEEE Syrup. on 
Comp.-Based Med.Sys. (CBMS01), pages 177-182, 2001. Bethesda, MD. [2] P. Antal, T. Meszaros, B. De Moor, and 
T. Dobrowiecki. Domain knowledge based information retrieval language: an application of annotated bayesian networks in ovarian cancer domain. In Proc. of the 14th IEEE Syrup. on Comp.-Based Med.Sys. (CBMS02), pages .-., 2002. Maribor, Slovenia. [3] C. Blaschke, J. Oliveros, and A. Valencia. Mining functional information associated with expression arrays. Funct Integr Genomics, 1:256-268, 2001. [4] G. F. Cooper and E. Herskovits. A bayesian method for the induction of probabilistic networks from data. 
Machine Learning, 9:309-347, 1992. [5] D. M. et al. Use of keyword hierarchies to interpret gene expression patterns. Bioinformatics, 17:319-326, 2001. [6] W. B. Frakes. Stemming algorithms, in W. B. Frakes and R. Baeze-Yates: Information retrieval. Prentice 
Hall, 1992. [7] D. Heckerman. Learning bayesian networks: The combination of knowledge and statistical data. 
Machine Learning, 20:197-243, 1995. [8] A. Jain and R. Dubes. Algorithms for clustering data. 
Prentice Hall, 1988. [9] T. Jenssen, A. Laegreid, J. Komorowski, and 
E. Hovig. A literature network of human genes for high-throughput analysis of gene expression. Nature 
Genetics, 28:21-28, may 2001. [10] L. Kaufman and P. Rousseeuw. Finding groups in data. Wiley-Interscience, 1990. [11] R. Korfhage. Information Storage and Retrieval New 
York: Wiley Computer Pub., 1997. [12] D. Masys. Linking microarray data to the literature. 
Nature Genetics, 28:9-10, 2001. [13] G. Milligan and M. Cooper. A study of the comparability of external criteria for hierarchical cluster analysis. Multivariate Behavorial Research, 21:441-458, 1986. [14] P. Pavlidis, J. Weston, J. Cai, and W. Grundy. Gene functional classification from heterogeneous data. In Proceedings of the 5th International Conference on 
Computational Molecular Biology (RECOMB 2001), 2001. [15] J. Pearl. Probabilistie Reasoning in Intelligent 
Systems. Morgan Kaufmann, 1989. [16] J. Quakenbush. Computational analyis of microarray data. Nature Reviews Genetics, 2:418-427, 2001. [17] B. R.-N. R. Baeza-Yates. Modern Information 
Retrieval. ACM Press, 1999. [18] H. Shatkay, S. Edwards, W. Wilbur, and M. Boguski. 
Genes, themes and microarrays, using information retrieval for large-scale gene analysis. In Proceedings of the Eighth International Conference on Intelligent Systems for Molecular Biology, Menlo Park, CA, 
USA, pages 317-328. AAAI, 2000. [19] D. Timmerman. Ultrasonography in the assessment of ovarian and tamoxifen-associated endometrial pathology. Ph.D. dissertation, Leuven University 
Press, D/1997/1869/70, 1997. [201 D. Timmerman, L. Valentin, T. H. Bourne, W. P. 
Collins, H. Verrelst, and I. Vergote. Terms, definitions and measurements to describe the sonographic features of adnexal tumors: a consensus opinion from the international ovarian tumor analysis (iota) group. Ultrasound Obstet Gynecol, 16(5):500-505, Oct 2000. A typical entry in our local database YeastCard is com-posed of Gene Ontology and SWISS-PROT information.  X  Gene Name: YER133W  X  GO Biological Process: protein phosphatase type1  X  GO Molecular Function: glycogen metabolism  X  GO Description: Glycogen accumulation  X  SP Protein Name: cytoplasmic  X  SP Function: involved in control of glycogen metabolism meiosis translation chromosome segregation cell polar-ity and g2/m cell cycle progression, ppl may act in opposition to the ipll protein kinaae in regulating chro-mosome segregation.  X  SP SubCeUular Location: cytoplasmic  X  SP Similarity: belongs to the ppp family ofphosphatases. pp-1 subfamily.  X  SP Organism: yeast, saccharomyces cerevisiae A typical annotation for a domain variable is illustrated with the annotation of the variable CA125: "The ca 125 antigen is a glycoprotein that is expressed by most epithelial ovarian and is recognized by a monoclonal antibody, serum ca 125 is the tumor marker with the highest sensitivity for ovarian cancer (bast et al 1983, jacobs et al 1989, knapp et al 1996, cuckle 1996). This tumor marker will detect nearly 80 percent of advanced (stage iii) ovarian cancers (see ta-ble i), but only about 44 percent of patients with stage i disease (vergote et al 1987, euckle &amp; wald 1991, bourne et al 1994a, maggino et al 1994). In premenopausal patients positive results are frequently encountered in menstruating or pregnant women and in a wide variety of benign con-ditions, such as benign ovarian tumors (10%) endometriosis (20-30~0), liver cirrhosis (60-70%), pancreatitis (30%), pelvic inflammatory disease, uterine fibroids and meigs syndrome (100%)...." 
