 This paper addresses the challenges in detecting the potential cor-relation between numerical data streams, which facilitates the re-search of data stream mining and pattern discovery. We focus on local correlation with delay, which may occur in burst at different time in different streams, and last for a limited period. The un-certainty on the correlation occurrence and the time delay make it diff cult to monitor the correlation online. Furthermore, the con-ventional correlation measure lacks the ability of ref ecting visual linearity, which is more desirable in reality. This paper proposes effective methods to continuously detect the correlation between data streams. Our approach is based on the Discrete Fourier Trans-form to make rapid cross-correlation calculation with time delay allowed. In addition, we introduce a shape-based similarity mea-sure into the framework, which ref nes the results by representative trend patterns to enhance the signif cance of linearity. The similar-ity of proposed linear representations can quickly estimate the cor-relation, and the window sliding strategy in segment level improves the eff ciency for online detection. The empirical study demon-strates the accuracy of our detection approach, as well as more than 30% improvement of eff ciency.
 H.2.8 [ Database Management ]: Database Applications Data stream; Correlation Detection; Linear Approximation
The analysis of correlation between numerical data streams is an important issue for stream mining, and has attracted much scien-tif c interest. Its major purpose is to explore the interactional link and dependency relationship between data streams, and to a certain degree, evaluate the similarity of streaming data patterns. The oc-currence or the loss of correlation usually indicates special events, which help discover groups of objects with similar behaviors or po-tential anomalies. Due to the important role it plays, correlation has been widely studied for continuous query [10] and sequence pat-tern mining [15], which benef t the applications of gene expression clustering [20], stock price prediction and physiological analysis.
In this paper, we focus on local correlation detection, which may occur in burst, last for certain duration, and then disappear. Un-like the correlation of whole data stream, local correlation is of-ten asynchronous, which is called lag correlation . For example, the increase of the exchange rate of Australian dollar may result in the increase of New Zealand dollar, which can be delayed by sev-eral hours. Consequently, simply evaluating the similarity of data streams at the same time period can make the correlation incon-spicuous. Therefore we propose to take into account the potential time delay for correlation analysis. The property of localization indicates that sliding window is suitable for correlation evaluation and the detection can be performed continuously.

Figure 1 exemplif es the scenario of this problem. We consider monitoring two data streams and capturing the correlated subse-quences. It is clear that S 2 has positive correlation with layed by time T , but conventional similarity measure methods can-not match them together, since the corresponding subsequences in the same time period are not similar, and the delayed time is un-known in advance. Such situation requires sophisticated approach for correlation detection, which supports analysis based on time de-lay. However, the uncertainty on the occurrence of correlation and the length of time delay increase the challenge. As the data come continuously, timely reminders should be made if the correlation is identif ed to indicate important events or unexpected cases.
Much effort has been devoted to designing various techniques to continuously match similar subsequences in streaming data [11, 16]. However, correlation represents a more general relationship between streams, which potentially takes place between different kinds of streams. As a result, the conventional distance-based sub-sequence matching is not suitable for detecting correlation, and in-stead, more general Pearson coeff cient should be applied. Similar problems have been addressed in [14, 17, 22]. Sakurai et al. [17] designed BRAID to monitor a group of data streams, and detect all the pairs having lag correlation. They proposed to f nd the f rst maximum point on the global cross-correlation coeff cient curve of two data streams, which takes time delay as a variant. However, BRAID considers the whole stream and measures the global corre-lation, which fails to detect local correlation. Zhu et al. [22] pro-posed StatStream based on Discrete Fourier Transform to monitor thousands of data streams. Their approach performs well in dealing with large amount of data, but it is designed for ad hoc query other than continuous query, and has strict constraint on the time delay.
Due to the limitations of previous works on this problem, we propose a framework to deal with the continuous detection of local Pearson correlation coeff cient with time delay. Similar to conven-tional approaches processing streaming data, a sliding window is applied in our framework. Given the maximal time delay allowed, and a minimal correlation duration required, we analyze the subse-quences in the sliding window, and f nd if there is any correlation occurring. Since the time delay factor is involved, our solution also employs the Discrete Fourier Transform (DFT). Unlike the existing work in [22], we take the advantage of the properties of DFT, and solve the cross-correlation coeff cient with random time shift by reverse DFT on the inner product of two stream sequences. If the correlation is identif ed, incremental evaluation will be performed until the correlation is lost. Otherwise we can slide the window to the next candidate location.
 We further address an important issue that the widely applied Pearson coeff cient cannot ref ect the linearity of sequences [1], which delivers more salient meaning in practice. Therefore we pro-pose to ref ne the detection results by linear approximation of the data streams. The linear approximation can describe the data pat-tern from global and approximated level and help evaluating the linearity by comparing the representations based on the segment similarity. Based on the properties of the approximation technique, we are able to make early pruning to avoid unnecessary calculation by estimating the correlation. In the window sliding mechanism, updating and evaluating the window every time a new data point is received can result in unnecessary comparison and ineff cient slid-ing. The approximation technique can further optimize the sliding mechanism with eff cient segment-level sliding. The concept of approximation helps dramatically reduce the computational com-plexity, and make the online detection more practical.

The main contributions of our work are summarized as follows:
The remainder of this paper is organized as follows. In Section 2 we give some basic concepts and the formal problem def nition. We introduce the basic method to calculate the cross-correlation function in Section 3. The linearity enhancement and the sliding mechanism are discussed in Section 4. Experimental results are presented in Section 5, followed by a brief review of related works in Section 6. Finally we conclude our work in Section 7.
First of all, we assume that the numerical data streams are run-ning synchronously and sampled at a f xed rate. Without loss of generality, we take the time interval of sampling as time unit, so that all the sampled data values are continually aligned to consec-utive integer scales along the time axis, and the data stream can be treated as a discrete signal sequence. To simplify the problem, we only discuss how to monitor two data streams. It is straightforward to extend the detection to multiple streams. In order to continuously detect the correlation of two streams, we apply sliding window to keep the most recent synchronous subsequences of the streams.
Based on the assumption above, we can formally def ne some fundamental concepts of our problem. The numerical time series 1) } stands for the subsequence of  X  x with limited length x ( n )  X  R is the value of the ( n + 1) th data point of the subse-quence. We also use x n for alternative x ( n ) if no conf ict exists. We def ne len ( x ) as the length of x , and st ( x ) is the starting time stamp of x . Similar concepts are also applied to  X  y . The problem we propose to address is to continuously discover the local correlation between data streams. Here the correlation is evaluated by widely applied cross-correlation coeff cient (Pearson coeff cient). For two sequences x and y , which have the same length N and same start-ing time stamp, the correlation coeff cient is calculated as: where  X  x and  X  y stand for the mean value of x and y respectively.
If time delay is considered, there can be certain time gap between the starting time stamps of two subsequences, between which the cross-correlation is evaluated. Assume the time delay on  X  y the Equation (1) can be modif ed into: Here  X  x = 1 that the time delay can also be applied on  X  x , and the Equation (1) actually describes r xy (0) . r xy (  X  )  X  [  X  1 , 1] indicates the linear correlation of the sequences, and can ref ect the similar behavior of sequence trend. Theoret-ically, when the evaluated parts of two sequences are correlated, r xy (  X  ) will return a value close to 1 or -1. We def ne  X  delay giving the maximum cross-correlation coeff cient. That is, The correlation score of x and y is given by cor ( x, y ) = | r
We keep the sliding window over data streams to monitor the most recent data points. When salient correlation occurs between the current subsequences, we detect and report it, as well as cor-responding time delay. In order to make the analysis more practi-cal, we require that only those correlated subsequences with long enough duration are meaningful. Also the time delay should be within a tolerant range. Then the problem we are interested in can be formally def ned below.
 Given two data streams  X  x ,  X  y , when the correlation score of their subsequences cor ( x, y )  X   X  , and x , y satisfy:  X   X  T , min { len ( x ) , len ( y ) } X  ( L +  X  ) , report the correlation score and the time delay  X  .

In our work, the maximum time delay allowed T and the mini-mum duration of the correlation L are given in advance to specify the query. We keep a window with width of T + L , so the poten-tial correlation can be explored from current window. During the processing, the data points keep coming, and the sliding window is continuously updated to make dynamic correlation detection.
In this section, we will discuss how to evaluate the cross-correlation between different data sequences. We will f rst derive a straightfor-ward solution after transforming the Equation (2). We then design the DFT-based approach that can eff ciently calculate the correla-tion score to support random time delay in correlation.
Let M = N  X   X  , and we can transform Equation (2) to the following equation: The limits of summation are ignored for compact representation. Equation (4) means that the cross-correlation coeff cient can be computed by simple summations of the point values, which sup-port incrementally computation. Based on this equation, we can design a straightforward approach to detect the correlation.
Intuitively, once the sliding window receives the new data points, we incrementally update the basic summations (e.g., P x 2 P x n ) of the subsequences, x and y , within the sliding window. Then for every possible time delay  X   X  [  X  T, T ] , we calculate the correlation coeff cient according to Equation (4). Here since time delay can be applied on both x and y , when  X   X  0 , r xy (  X  ) ally equals r yx (  X   X  ) . When we get the correlation coeff cients for all possible  X  values, the maximal value is chosen as correlation score, together with the corresponding  X  . If the correlation score is greater than the predef ned threshold  X  , we report the correlation, and the corresponding  X  is returned as time delay  X  .

After processing the points in current window, if the correlation condition is satisf ed, the current correlated subsequences should be kept, and when the following data points come in, we make the incremental calculation of cross-correlation score until the corre-lation is lost. Otherwise, the sliding window reads the next data points and recalculate the correlation score.

It is obvious that the naive solution can continuously detect the local correlation between the engaged streams. However, for each new data point and each possible time delay, we have to recalculate the cross-correlation coeff cient, which will result in high compu-tation complexity. The main cost is produced by the sum of inner-product for different  X  as described in Equation (4). In the area of signal processing and statistical analysis, the sum of inner-product is usually calculated by DFT for eff ciency purpose. Therefore, we propose to make use of the theoretical results of DFT to design a more sophisticated approach for correlation detection.
In this part, we will f rst introduce the basic knowledge of DFT, and provide important lemmas and properties in DFT theory, based on which our DFT-based solution will be elaborated.

Let x = { x (0) , x (1) , . . . , x ( n ) , . . . , x ( N  X  1) } quence, and the Discrete Fourier Transform of x be X = { X (1) , X (2) , . . . , X ( k ) , . . . , X ( N  X  1) } , we have The inverse Fourier Transform of X is
If applying normalization to the sequence x , we can generate the normalized sequence  X  x , where each sequence point value is Here  X  x = q 1
Similarly, we also normalize the N-point sequence y . By the normalization form of sequence x and y , we can easily educe the following lemma:
L EMMA 1. The correlation coeff cient of x and y can be cal-culated by the inner-product of normalized sequences  X  x and
The following theorem describes an important property of DFT, which inspires a new way to calculate the vector inner-product and the cross-correlation of x and y : T HEOREM 1. For two N-point sequences x and y , if r xy (  X  ) = P x ( n ) y ( n +  X  ) , then the DFT of r xy (  X  ) is given by where X ( k ) and Y ( k ) are the DFT of x and y respectively, and X  X  ( k ) denotes the complex conjugate of X ( k ) .
 calculated by inverse DFT on R xy after applying DFT on  X  x  X  y . Since we are able to directly derive the correlation coeff cient with all possible time delay  X  , the computation complexity can be signif cantly improved.

For the normalized sequence  X  x and  X  y , we have the following lemma to quickly compute their DFT coeff cients:
L EMMA 2. Let X be the DFT of x , and  X  X be the DFT of nor-malized sequence  X  x , we have Furthermore, we have Hence in order to get the correlation score of x and y , we only need to keep the summations of P x 2 n , P x n , P y 2 n and P and calculate the DF T of x and y .

However, according to the theory of DFT, the N-point DFT cal-culation is actually for periodic signals with period of N. When we calculate the DFT of a N-point sequence, the actual effect is to periodically extend the N-point sequence, and return the principal values of the DFT on the periodically extended sequence. So if di-rectly apply the DFT of x and y to calculate the cross-correlation function, error may be brought in by incorrect periodic overlapping when time delay is applied. As a result, we f rst extend x with zero values, so that the length of the two sequences increases to N  X   X  2 N  X  1 .

By zero extending, we can conclude the following important property:
P ROPERTY 1. The result of cross-correlation function based on inverse DF T on R xy ( k ) satisf es: r xy (  X  ) = r xy (  X  ) (0  X   X   X  N  X  1) r It means that r xy ( N  X   X   X  ) = r yx (  X  ) = r xy (  X   X  )  X   X  N  X  1 , we can get the correlation coeff cients with time delay on y . At the meantime, we can also get the coeff cients with time delay on x from the r xy (  X  ) values when N  X   X  N +1  X   X   X  N As widely proposed in signal processing, we apply Fast Fourier Transform to eff ciently calculate the DFT coeff cient. We use a concrete example to test the correctness of the DFT-based vector inner-product calculation. Assume x = { 1 , 2 , 3 , 4 , 5 } { 6 , 7 , 8 , 9 , 10 } , and we f rst extended the original sequences to 16 points for the convenience of FFT calculation. By inverse FFT calculation, the result of vector inner-product function with delay From the result we can directly f nd the inner-product value with random time delay, which demonstrates that the approach is work-ing correctly.

Similarly, after processing the points in current window, we can also incrementally keep the detected correlation when receiving new data points. Otherwise we repeat the algorithm to evaluate new data points. The DFT-based approach solves the problem from the view of frequency space, which enables the result to cover time de-lay on both x and y . As we will discuss in next section, it can also reduce the computational cost.
In this section, we will discuss the complexity of the naive ap-proach and the DFT-based approach. Since the data stream is po-tentially inf nite, or semi-inf nite, and the same computation repeats on new arrival points, we only discuss a complete computation for the subsequences in a sliding window. As described in previous sections, we assume the length of sliding window is N = L + T where L is the minimal duration of correlation, and T is the maxi-mal time delay allowed. We can summarize the following conclu-sions: L EMMA 3. For the naive algorithm, the space complexity is O ( N + T ) , and the time complexity is O ( T N ) .

P ROOF . For the naive algorithm, since the maximal time delay is given by T , the correlation should be calculated for  X  T  X   X   X  T . Then the number of multiplication operations is N +2[( N  X  1)+( N  X  2)+  X  X  X  +( N  X  T )] = ( T +1) N +( L  X  1) T. The time complexity is thus O ( T N ) .

The space needed to store the data sequences is 2 N , and the space to store the basic summations is 2(2 T + 1) , so the space complexity is O ( N + T ) .
 L EMMA 4. For DFT-based algorithm, the space complexity is O ( N ) , and the time complexity is O ( N log N ) .
 P ROOF . The DFT-based algorithm applies FFT to calculate the DFT coeff cients, which involves three complete N  X  -point FFT cal-tion operation is
The space needed to store the data sequences are 2 N , and the storage for FFT calculation is 4 N  X  for FFT results and N result. So the space complexity for FFT-based algorithm is O ( N ) .

From the analysis above, we conclude that if the time delay al-lowed is not large (e.g., T  X  N ), naive algorithm can perform well. However, in practical applications, the allowed time delay usually varies much, especially when the monitoring window is large. So for the consideration of scalability, we choose DFT-based algorithm as the core calculation algorithm.
In this section, we discuss the utilization of linear representation to enhance the correlation detection, prune the correlation candi-dates and help the design of eff cient window sliding.
Although to certain degree correlation coeff cient indicates the linear dependency of two sequences, it still cannot precisely char-acterize the relationship of linearity, which is more desirable and has more semantic meaning in practical applications. As exempli-f ed in [1], four pairs of sequences in Figure 2 are in totally differ-ent correlationship but with the same correlation coeff cient 0.816. This example indicates that the correlation coeff cient cannot com-pletely identify the linearity and replace the visual examination. Therefore, it is necessary to f nd a representation to describe the vi-sual shape of sequences, which can play the auxiliary role to f lter those sequences dissimilar in shape outlines.

Furthermore, although FFT provides powerful improvement in computation eff ciency, it is still not eff cient enough for online pro-cessing, especially when it is required to recalculate the correlation function for each new coming data point. It is a huge waste of time to evaluate every new data point, since there can be much redun-dancy. To effectively reduce the unnecessary calculation, and make the window sliding more eff cient, we bring in the approximation technique, and propose to estimate the correlation score by certain compact representation.

In our work we apply Piecewise Linear Representation (PLR) to approximate the data points. It is to continuously use line segments to approximate the data stream points. As shown in Figure 3, the data stream can be represented by several line segments, which can indicate the trend of the data stream from macroscopic view.
The reasons that we choose linear approximation to represent the data stream fall into three aspects: 1. We are interested with the Figure 2: Four pairs of sequences in different correlationships but with the same calculated correlation coeff cient.
 linear correlation, and the linear representation keeps the overall changing trend of the data stream, so it is the best way to retrieve the global shape feature of a data stream; 2. The compact represen-tation of data stream provides us the trend information to rapidly compare the subsequences and estimate the correlation, which can prune the unnecessary calculation from an early stage; 3. The prop-erty of segments inspires us an eff cient way to slide the window along data streams. Since the data streams are divided into seg-ments by the linear approximation algorithm, the sliding procedure can go ahead segment by segment rather than point by point, which will signif cantly reduce the number of subsequence comparisons.
We summarize two criteria for choosing the algorithm to gen-erate PLR: 1. The algorithm is able to control the approximation ratio, so as to make the approximation not too coarse nor too f ne; 2. Each line segment minimizes the approximation error on cor-responding subsequence, so as to precisely describe the sequence trend. In this work, we apply SWAB algorithm proposed by Keogh et al. [7] to make linear approximation, which can achieve the on-line eff ciency and is suitable for sliding window. We control the PLR generation by the approximation ratio (e.g., the number of segments is f xed). The more details can be found in [7].
As mentioned before, we propose to utilize the compact repre-sentation of data stream to estimate the correlation and conduct early pruning. Once the line segments are generated within the sliding window, we can primely evaluate the similarity of the linear representations, which can ref ect the linearity similarity between sequences and is capable to f lter the subsequences dissimilar in shape.

Since the correlation is sensitive to the increasing and decreas-ing trend of data point values, we propose to evaluate the similar-ity of line segments from the view of data changing trend. Af-ter the generation of line segments, we propose to transfer the line segments into pairs of numbers, named segment pairs. Each seg-ment pair describes the characteristics of a line segment, which consists of the length of the line segment as well as the chang-ing trend. If the slope of the line segment is greater than 0, we set the changing trend as  X 1 X , otherwise the changing trend is  X -1 X . For example, { (5 , 1) , (4 ,  X  1) , (5 , 1) } means the sequence is approximated by three segments. The f rst one has 5 points and is increasing; the length of second one is 4, and it is decreasing; the third increasing one has length 5. If duplicate the trend sym-bols according to the segment length, we can get the following seg-which ref ects the overall changing trend of the data sequence.
So for the two subsequences in the sliding window, we can f rst compare their similarity by the segment trend sequences. If two sequences are in correlation, their segment trend sequences should be similar, since the correlation indicates the linear dependency of the sequences. We apply Longest Common Subsequence (LCS) to evaluate the similarity of two segment trend sequences. Given two segment trend sequences BX and BY with length N assume BX i is the i-length pref x of BX , bx i is the i th element of BX , and LCS ( i, j ) is the length of the LCS of BX i and sim ( BX, BY ) = LCS ( N, N ) /N be the similarity score of and BY , and it is recursively calculated as follows,
The Trend Sequence Similarity ref ects the similarity of data be-havior, or to certain degree, the similarity of stream shape. If the two trend sequences are similar enough according to the Trend Sequence Similarity, we continue on the cross-correlation evalu-ation as designed in previous sections, otherwise the sliding win-dow moves on to receive new coming points. Since the calculation of LCS only concerns XOR operation other than multiplication, it can be more eff cient than the complete correlation analysis, and potentially reduce much unnecessary correlation calculation.
Now we analyze the relationship between the correlation coeff -cient of two sequences and their Trend Sequence Similarity. The following theorem guarantees that sim ( BX, BY ) is actually an upper bound of correlation coeff cient r xy (0) , so that it can safely prune those false candidates.

T HEOREM 2. Given discrete sequences x and y of length N , and their trend sequences BX and BY , the cross-correlation co-eff cient of x and y satisf es:
P ROOF . First of all, we have the following inequality: For the two sequences, if certain part has strong correlation, the global trend of the data point should be same. The linear approx-imation can be viewed as a f ltering on the original data stream. Thus after approximation, the noise affecting the correlation is f l-tered out, and only the principal pattern remains. It is obvious that the correlation coeff cient of trend sequences will be larger than that of original streams, and the inequality is established.
Now we prove cor ( BX, BY )  X  sim ( BX, BY ) . When BX and BY are the same, assume that for BX , the number of  X 1 X  is a , and the number of  X -1 X  is b ; for BY , the corresponding numbers are c = a and d = b . Then we have, Also, sim ( BX, BY ) satisf es
When BX and BY are different, without loss of generality, we can suppose that a  X  b , and for c and d , two cases are possible: c = a +  X  , d = b  X   X  , or c = a  X   X  , d = b +  X  (  X   X  0 ). Assume the Humming distance of BX and BY is  X   X  , (  X   X   X   X  ), then the cross-correlation is
If c = a +  X  and d = b  X   X  , we have cor ( BX, BY ) = ( ab  X  a X   X  ) / (
If c = a  X   X  and d = b +  X  , we have cor ( BX, BY ) = ( ab  X  b X   X  ) / (
For the two cases,
It means that the cor ( BX, BY )  X  ( ab  X  b X  )  X  alw ays holds.

Now we prove that a = rN (0 . 5  X  r  X  1) , then b = (1  X  r ) N . The inequality above can be transferred into: For 2 r 2  X  2 r + 1 ,  X  1 =  X  4 &lt; 0 , so 2 r 2  X  2 r + 1 &gt; 0 For the inequality above,  X  2 =  X  2 r ( r 3  X  6 r 2 + 9 r  X  4) f ( r ) = r 3  X  6 r 2 + 9 r  X  4 , the derivative of f ( r ) which is larger than 0 within [0 . 5 , 1] , so So the objective inequality always holds.

With the fact that the similarity of segment trend sequences is the upper bound of the cross-correlation coeff cient, trend segment similarity can be used to prune unnecessary correlation calcula-tion. When detecting correlation, cross-correlation coeff cient is measured only if trend sequences suggest potential candidates in current window. Considering the potential time shift, we set the threshold for segment similarity around L/ ( L + T ) . (Recall that T is the maximal time delay allowed and L is the minimal duration of the correlation.) Algorithm 1: segLC S Algorithm Input : segBX , s egBY
Output : segLCS ( N 1 , N 2 ) 1 for i  X  1 to N 1 do 2 for j  X  1 to N 2 do 3 L 1 = 4 L 2 = 5 L 3 = 6 segLCS ( i, j ) = max { L 1 , L 2 , L 3 } ; 7 Update tmpBX i , tmpBY j ; 8 end 9 end 10 Report segLCS ( N 1 , N 2 ) ;
Howe ver, the complexity of LCS calculation is O ( N 2 ) , we pro-pose to further improve it based on the characteristics of the trend sequence. As mentioned before, the segment trend sequences can named segment pair sequence. Since the symbols  X 1 X  and  X -1 X  both appear as blocks, we can make use of this property and ac-celerate the calculation of common subsequence. Instead of trend sequences, we directly utilize the block representation of segment pairs, and modify the standard LCS calculation, so that the overall complexity can be dramatically reduced. The new designed algo-rithm is named segLCS, which is elaborated in Algorithm 1.
We denote the segment pair sequence as segB , and the i th seg-ment pair segB i = { len i , trend i } , where len i and trend def ned as previously mentioned. During the LCS calculation, we match the whole segments other than each symbol of segments, and record the maximal overlapping part. Notice that after the match-ing of each pair of segment, we record the remaining parts which are not matched, but could be potentially matched by the following segments. Such remaining part is recorded as tmpB i . For example, given the segment pairs { 5 , 1 } and { 4 , 1 } , the symbol  X 1 X  of length 4 are matched, and the remaining part for these two segments are { 1 , 1 } and { 0 , 1 } . So when matching the following segments, the remaining part { 1 , 1 } should also be taken into consideration. If the current pairs are { 5 , 1 } and { 4 ,  X  1 } , then the remaining parts should be still { 5 , 1 } and { 4 ,  X  1 } .

Based on the segLCS ( N 1 , N 2 ) , the similarity between the seg-ment pair sequences is given by segLCS ( N 1 , N 2 ) /N . The ad-vanced segLCS algorithm can achieve O ( N 1  X  N 2 ) complexity, which is a huge improvement on calculation cost. However, segLCS is based on greedy algorithm, which cannot always guarantee the optimal result. So if the requirement for response time is high, we can choose segLCS, otherwise standard LCS can work well.
The line representation can provide excellent properties to esti-mate correlation and enhance the linearity. Furthermore, the form of line segment inspires us to scan the stream data according to the line segment. Based on such inspiration, we design an eff cient sliding mechanism to update the sliding window, so as to accelerate the online detection.

As demonstrated in Figure 4, we slide the window according to the endpoints of the line segments in the window. After evaluating
Figure 4: Sliding mechanism based on segment endpoints. the points in current window, if salient correlation is detected, we can follow incremental evaluation; if we cannot detect salient cor-relation, the window can be directly moved to the nearest endpoint of the line segments. In this way, the window updating can be more eff cient to reduce much redundant calculation.
In this part, we describe our experimental evaluation of the pro-posed framework. The evaluation is conducted on both synthetic and real data, in terms of the effectiveness and eff ciency of the proposed algorithms.
In our experiments, we perform our algorithm to detect the lo-cal correlation between data streams, and compare the results with naive solution that is able to detect all correlation, so as to demon-strate its effectiveness on correlation exploration. Standard recall rate is used for performance measure when f xing the precision rate to be 100% . In order to show the advantage of our algorithm on time eff ciency, we carry it out on data streams with size varying power brought by linear approximation is also analyzed to show the effective acceleration. All the algorithms are implemented in C++ and all the experiments are performed on a PC with CPU of Intel Core 2.13GHz, and memory of 2 GB.

We test the algorithms on both synthetic and real data streams, so that the conclusion can be made based on a wide range of data distribution. The synthetic data sets are depicted below: For real data, we choose the following data sets: ftp://ftp.ngdc.noaa.gov/STP/SOLAR_DATA/ SUNSPOT_NUMBERS/
For the effectiveness evaluation, we will test if the proposed framework can successfully detect the potential correlation between data streams, and also compare the effect of our proposed algo-rithms with conventional technique to measure sequence similarity.
We f rst study the performance of correlation detection by our proposed algorithms. Since the naive algorithm can detect all the local correlations, we will f rstly calculate the correlation score at every time stamp using naive solution as ground truth. The corre-lation score reported by DFT-based algorithm will be further com-pared with those by naive solution.

Figure 5 to Figure 8 demonstrate the estimation of our algorithms for all data streams. The blue curve is the correlation score curve calculated by naive solution, and the red triangles record the corre-lation score of DFT-based algorithm. From all the f gures we can f nd that, the results detected by our algorithms are laid on the cor-relation score curve at the occurrence of correlation mostly, which demonstrates the effectiveness of our solution. In Figure 5 and Fig-ure 7, the results indicate obviously that the local correlation scores (the red triangles) follow the periodic pattern.
In our approach, we apply linear approximation to improve the linearity of detected results. Hence the algorithm may ignore some subsequences with high correlation score but dissimilar in shape pattern. However, this kind of dismissal is to certain degree sub-jective to users X  visual examination, so it is hard to determine such dismissal is true or false. As a result, we use the precision and re-call as evaluation criteria. Since at the seconde phase of the frame-work, the precision rate can be guaranteed at 100% , we only com-pare the recall rates. In order to evaluate the effectiveness of our proposed shape-based similarity measure, we also replace segLCS similarity by the classic shape-based similarity measure, Dynamic Time Warping (DTW) distance, to test the corresponding recall rates. The evaluation and comparison results are given in Table 1, where GT stands for ground truth of the number of correlated sub-sequences given by exhaustive search, and Record stands for the number of detected correlation by corresponding algorithm.
As summarized in Table 1, the recall rate keeps above 70% which indicates our algorithm can detect most of the salient cor-relation with high visual similarity, and effectively reduce the false alarm on the subsequences with low visual similarity. Our results are always superior than that given by DTW distance, and the rea-http://lwf.ncdc.noaa.gov/oa/climate/ research/anomalies/index.html son is our proposed similarity measure can reduce the effect of the value scale of data, and focus on the trend information; while the distance-based approach, e.g., DTW distance, will select those can-didates with absolutely high similarity but ignore those with only similar trends, which however, can derive high correlation score. Moreover, it is sensitive to set proper threshold for DTW-based ap-proach to f lter the potential candidates.
The eff ciency evaluation will focus on the performance of the framework in streaming scenario, and discuss the effect of different factors on the improvement of time eff ciency.
We f rst study the scalability of the algorithms. We compare the running time of naive algorithm, the DFT-based algorithm with standard LCS similarity and that with segLCS similarity on the ran-dom data stream. The length of the stream varies from 10 3 to
Figure 9 illustrates the changing trend of running time as the data size increases. We can conclude that all algorithms achieve near linear running time to the data size, which is determined by the sliding window framework. However the complexity of DFT-based algorithm is lower than naive solution for processing sliding window, so it can effectively reduce the running time by about over the naive algorithm. We can also explore the advantage of segLCS similarity on time eff ciency, which improves the running time by about 25% over the standard LCS similarity measure.
Now we discuss the effect of the maximal time delay on the time eff ciency. As mentioned before, the complexity of naive algorithm is
O ( T N ) ( T is the maximal time delay allowed), and O ( N log N ) for DFT -based algorithm. So the superiority on time eff ciency may be different when the maximal time delay varies. We change the maximal time delay from 50 to 5000, and run both algorithms on the random data with length of 10 5 (the DFT-based algorithm goes without LCS similarity pruning). We compare the running time of both algorithms, and record them in Figure 10.

In the f gure, the y-axis stands for the proportion of running time between DFT-based algorithm and naive algorithm. When maxi-mal time delay is small, the running time of DFT-based algorithm is longer than naive solution, because the DFT-based algorithm al-ways calculates the correlation with every possible time delay even if it exceeds T . However, as the growth of T , the DFT-based algo-rithm outperforms naive algorithm signif cantly, which brings im-provement at about 80% off. Such improvement denotes the ad-vantage of FFT calculation on time eff ciency when T is relatively large. Based on the analysis above, we conclude that the choice of algorithm can be adaptive according to the maximal time delay.
Finally, we pay attention to the pruning power brought by line approximation during the sliding mechanism. The pruning power (PP) is def ned as:
In this part, we still perform our algorithm on random stream. In order to control the compression ratio, we change the error bound when bottom-up algorithm generates the line segments. As the er-ror bound increases, the compression ratio will also increase, and the linear approximation technique will divide the data stream into less line segments. As a result, when sliding along the data streams, the complete correlation calculation can be reduced dramatically. Figure 11 describes the pruning power brought by linear approxi-mation technique. The curve gives an impressive pruning rate of 95% at least, and when error bound increases, the pruning power can even be improved to 98% . The analysis of time series stream has been engaged for decades. Generally speaking, the techniques in correlation analysis are re-lated to numbers of elementary problems such as time series index-ing [8] and continuous queries on data stream.

Indexing technique is a fundamental part of database system, and much work has been done to index time series sequences. Faloutsos et al. [3] applied DFT to represent sequences in database, and map each sequence into points in feature space. Besides the approach in frequency domain, PAA [18] and APCA [6] are proposed to rep-resent and organize time series sequences as line segments in time domain. Inde xing techniques can be applied to evaluate the similar-ity of data sequences, but they usually deal with retrieval in static database, and hard to apply for monitoring streams.

Similar problem is also involved in the research of clustering gene expression data. OP-Cluster [12] and TP-Cluster [13] are de-signed to discover the positive co-regulation of gene expression on different conditions, that is, the gene expressions synchronously increase or decrease across certain conditions. However, these two algorithms cannot support shifting matching. Zhao et al. [20] pro-posed Co-GCluster algorithm to successfully f nd both positive and negative co-regulations, but it is not designed for time series data.
Continuous query deals with the problem of evaluating sequence similarity in data stream, which involves similarity measure as well as correlation analysis. DTW [2] is applied to continually compare query sequence with the subsequences in data stream in the works of [16, 21]. Lim et al. [11] made continuous sequence matching on data stream supporting variable-length and variable-tolerance. However, continuous query is usually based on distance measure, and rarely considers the relationship of multiple streams.
For stream correlation analysis, Papadimitriou et al. [15] started from the auto-covariance matrices of single data stream, and an-alyzed the local correlation of two data stream by comparing the eigenvector matrices. Gao et al. [4] addressed the problem of mon-itoring the streams to discover relevant events/patterns. It applied FFT to eff ciently f nd the cross correlations of time series, and f nd the NN of time series at many time positions. Zhang et al. [19] pro-posed HBR to transfer time series stream into boolean series suc-cessively, so that to reduce the complicated calculation of correla-tion. However, these works only considered synchronously match-ing with no time delay.

Zhu et al. [22] proposed a method based on DFT to solve the problem of monitoring tens of thousands of time series data streams in an online fashion and detect the correlation. But there are strict constraints on the supported time delay. BRAID [14, 17] is pro-posed to deal with the lag correlation issue. It focused on time and space eff ciency during online processing. But since it only calcu-lated the global correlation of data streams, it can hardly applied to solve the local correlation problem. Horvan et al. [5] proposed to use Markov arrival process to approximate the inter-arrival time distribution and the lag correlation. However, it dealt with the traf-f c process which follows the stochastic modeling.
We address the problem of local correlation detection on two data streams, and allow certain time delay, which is common and signif cant in practical applications. We design a framework to ful-f ll the online detection of local correlation, which supports random time delay on random data stream. The core idea of correlation evaluation is DFT-based cross-correlation calculation. Linear ap-proximation is introduced to explore the characteristics of stream shapes and enhance the linearity. The line segment representation is used for global similarity evaluation, which can estimate the cor-relation score, reduce the unnecessary calculations, and enable the incorporation of an eff cient window sliding approach. [1] F. Anscombe. Graphs in statistical analysis. The American [2] J. D.J.Berndt. Using dynamic time warping to f nd patterns [3] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. Fast [4] L. Gao and X. S. Wang. Continually evaluating [5] G. Horvath, P. Buchholz, and M. Telek. A map f tting [6] E. Keogh, K. Chakrabarti, M. Pazzani, and S. Mehrotra. [7] E. Keogh, S. Chu, D. Hart, and M. Pazzani. An online [8] E. Keogh and C. A. Ratanamahatana. Exact indexing of [9] B. Lathi. Signal processing and linear systems . Berkeley [10] H.-S. Lim, J.-G. Lee, M.-J. Lee, K.-Y. Whang, and I.-Y. [11] H.-S. Lim, K.-Y. Whang, and Y.-S. Moon. Similar sequence [12] J. Liu and W. Wang. Op-cluster: clustering by tendency in [13] J. Liu, J. Yang, and W. Wang. Biclustering in gene expression [14] A. Mueen, S. Nath, and J. Liu. Fast approximate correlation [15] S. Papadimitriou, J. Sun, and P. Yu. Local correlation [16] Y. Sakurai, C. Faloutsos, and M. Yamamuro. Stream [17] Y. Sakurai, S. Papadimitriou, and C. Faloutsos. Braid: stream [18] B.-K. Yi and C. Faloutsos. Fast time sequence indexing for [19] T. Zhang, D. Yue, Y. Gu, Y. Wang, and G. Yu. Adaptive [20] Y. Zhao, J. X. Yu, G. Wang, L. Chen, B. Wang, and G. Yu. [21] M. Zhou and M. H. Wong. Eff cient online subsequence [22] Y. Zhu and D. Shasha. Statstream: statistical monitoring of
