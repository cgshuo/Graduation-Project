 Metaphor is perhaps the most flexible and adaptive tool in the human communication toolbox. It is suited to any domain of discourse, to any register, and to the description of a ny concept we desire. Speakers use metaphor to communicate not just meanings, but their feelings about those meanings. The open -ended nature of metaphor interpretation means that we can use metaphor to simultaneously express and elicit opi n ions about a giv en topic. Metaphors are flexible co n ceits that allow us to express a position while seeking elaboration or refutation of this position from others. A metaphor is neither true or false, but a conceptual model that allow speakers to negotiate a common viewpo int .
Computational models for the interpretation and elaboration of metaphors should allow speakers to exploit the same flexibility of expression with m a-chines as they enjoy with other humans. Such a goal clearly requires a great deal of knowledge, since m e t aphor is a knowledge -hungry mechanism par excellance (see Fass, 1997). However, much of the knowledge required for metaphor interpret a tion is already implicit in the large body of met a phors that are active in a community (see Martin, 1990; Mason, 2004). Existing metaphors are the m selves a valuable source of knowledge for the pr o duction of new metaphors, so much so that a system can mine the relevant knowledge from corpora of fi g-urative text (e.g. see Veale, 2011; Shutova, 2010).
One area of human -machine interaction that can clearly benefit from a competence in metaphor is that of information retrieval (IR). Speakers use metaphors with ease when eliciting information from each other, as e.g. when one suggests that a certain CEO is a t y rant or a god, or tha t a certain company is a dinosaur while another is a cult. Those that agree might r e spond by elaborating the metaphor and providing su b stantiating evidence, while those that disagree might refute the metaphor and switch to another of their own choosing. A well -chosen metaphor can provide the talking points for an informed conversation, allowing a speaker to elicit the desired knowledge as a comb i-nation of objective and subjective elements.

In IR, such a capability should allow searchers to express their inf ormation needs subjectively, via a f fective metaphors like  X  X  is a cult X . The goal, of course, is not just to retrieve documents that make explicit use of the same metaphor  X  a literal matc h-ing of non -literal texts is of limited use  X  but to retrieve texts whose own metaphors are consonant with those of the searcher, and which elaborate upon the same talking points. This requires a co m-puter to understand the user X  X  metaphor, to appr e-ciate how other metaphors might convey the same affective vie w point, and to understand the different guises these metaphors might assume in a text.
IR extends the reach of its retrieval efforts by expanding the query it is given, in an attempt to make explicit what the user has left implicit. Met a-phors, like under -specified quer ies, have rich meanings that are, for the most part, implicit: they imply and suggest much more than they specify. An expansionist a p proach to metaphor meaning, in which an affective metaphor is interpreted by ge n-erating the space of related metaphors and talking points that it implies, is thus very much suited to a more creative vision of IR, as e.g. suggested by Veale (2011). To expand a metaphorical query (like  X  X ompany -X is a cult X  or  X  X o m pany -Y is a dinosaur X  or  X  X  was a tyrant X ), a system must first e xpand the metaphor itself, into a set of plausible construals of the metaphor (e.g. a company that is viewed as a dinosaur will likely be powerful , but also bloated , lumbering and slow ).
 The system described in this paper, Metaphor Magnet , demonstrates thi s expansionist a p proach to metaphorical inference. Users express queries in the form of affective metaphors or sim i les, perhaps using explicit + or  X  tags to denote a positive or negative spin on a given concept. For instance,  X  Google is as  X  powerful as M i crosoft  X  does not look for documents that literally contain this sim i-le, but documents that express viewpoints that are implied by this simile, that is, documents that di s-cuss the negative implications of Google X  X  power, where these implications are first unde r stood in relation to M i crosoft. The system does this by first considering the metaphors that are conve n tionally used to describe Microsoft, f o cusing only on those metaphors that evoke the property powe r ful , and which cast a negative light on Microsoft . The i m-plications of these metaphors (e.g., dinosaur , bully , monopoly , etc.) are then examined in the co n text of Google, using the metaphors that are typically used to describe Google as a guide to what is most apt. Thus, since Google is often described a s a g i ant in web texts , the negative properties and b e haviors of a stereotypical giant  X  like lumbering and spraw l-ing  X  will be considered apt and highlighted .
To perform this kind of analysis reliably, for a wide range of metaphors and an even wider range of topics, requires a robustly shallow approach. We exploit the fact that the Google n -grams (Brants and Franz, 2006) contains a great many copula metaphors of the form  X  X  is a Y X  to unde r-stand how X is typically viewed on the web. We further exploit a large dictionary of affective ster e-otypes to provide an understanding of the +/ -pro p-erties and behaviors of each source concept Y. Combining these resources allows the Met a phor Magnet system to understand the implications of a metaphorical query  X  X  as Z X  in terms of the qual i-ties that are typically considered salient for Z and which have been corpus -attested as apt for X.
We describe the construction of our lexicon of affective stereotypes in section 2. Each stereotype is associated with a set of typical p roperties and beha v iors (like sprawling for giant , or inspiring for guru ), where the overall affect of each stereotype d e pends on which subset of qualities is activated in a given context (e.g., giant can be construed pos i-tively or negatively, as can baby , soldier , etc.). We describe how Metaphor Magnet exploits these st e-reotypes in sec tion 3, before providing a worked example in section 4 and screenshots in section 5. We construct the lexicon in two stages. In the first stage, a large collection of stereotypical descri p-tions is harvested from the Web. As in Liu et al . (2003), our goal is to acquire a lightweight co m-mon -sense representation of many everyday co n-cepts. In the s e cond stage, we link these common -sense qualitie s in a support graph that captures how they mutually su p port each other in their co -description of a stereotyp i cal idea. From this graph we can estimate positive and negative valence scores for each property and behavior, and default averages for the stere o types that exhibit them .
Similes and stereotypes share a symbiotic rel a-tionship: the former exploit the latter as reference points for an evocative description, while the latter are pe r petuated by their constant re -use in similes. Expan d ing on the approac h in Veale (2011), we use two kinds of query for h arvesting stereotypes from the w eb. The first,  X  X s ADJ as a NOUN X , a c-quires typical adjectival properties for noun co n-cepts; the second,  X  X ERB +ing like a NOUN X  and  X  X ERB + ed like a NOUN X , acquires typical ve rb behaviors. Rather than use a wildcard * in both positions (ADJ and NOUN, or VERB and NOUN), which yields limited results with a search engine like Google, we generate fully instantiated similes from hypotheses generated via the Google n -grams. Thus, fro m the 3 -gram  X  X  drooling zombie X  we generate the query  X  X rooling like a zo m bie X , and from the 3 -gram  X  X  mindless zombie X  we ge n-erate  X  X s mindless as a zombie X .
 or more w eb documents via Google are considered to contain promising associations. But this still gives us over 250,000 web -validated simile assoc i-ations for our stereotypical model. We quickly fi l-ter these candidates manually, to ensure that the contents of the lexicon are of the hig h est quality. As a re sult, we obtain rich d e scriptions for many stereotypical ideas, such as B aby , which is d e-scribed via 163 typical properties and b e haviors like crying , drooling and guileless . After this filte r-ing phase, the stereotype lexicon maps 9 , 479 ster e-otypes to a se t of 7 , 898 properties and behaviors, to yield more than 75,000 pairings.
 automatically linking these properties and beha v-iors to each other in a support graph. The intuition here is that properties which rein force each other in a single description (e.g.  X  X s lush and green as a jungle X  or  X  X s hot and humid as a sauna X ) are more likely to have a similar affect than properties which do not support each other. We first gather all Google 3 -grams in which a pair of stereotypical properties or behaviors X and Y are linked via c o-ordination, as in  X  hot and h u mid  X  or  X  kicking and screaming  X . A bidirectional link between X and Y is added to the support graph if one or more stere o-types in the lexicon contain both X and Y. If this is not so, we consider whether both d e scriptor s ever reinforce each other in w eb similes, by po s ing the w eb query  X  as X and Y as  X . If this query has non -zero hit s , we also add a link between X and Y. no te the set of neighboring terms to p , that is, the set of properties and behaviors that can mutually support p . Since every edge in N represents an a f-fective context, we can estimate the likelihood that a property p is ever used in a positive or negative c ontext if we know the positive or negative affect of enough members of N( p ). So i f we label enough vertices of N as + or -, we can interpolate a pos i-tive/negative valence score for all vert i ces p in N . cally negative words, and a set +R of typically po s itive words. Given a few seed members of -R (such as sad , disgusting , evil , etc.) and a few seed members of +R (such as happy , wonderful , etc.), we find many other candidates to add to +R and -R by considering n eig h bors of these seeds in N . After three iterations in this fashion, we populate +R and -R with approx. 2000 words each.
 N -( p ) as follows: We can now assign positive and negative v a lence scores to each vertex p by interpolating from re f-erence va l ues to their neighbors in N : If a term S denotes a stereot ypical idea and is d e-scribed via a set of typical properties and behaviors t ypical(S ) in the lexicon, then: Thus, (5) and (6) calculate t he mean affect of the properties and behaviors of S , as represented via typical(S ) . We can now use (3) and (4) to separate typical(S ) into those elements that are more neg a-tive than positive (putting a negative spin on S ) and into those that are more posit ive than negative (pu t ting a positive spin on S ): 2.1 Evaluation of Stereotypical Affect In the process of populating +R and -R , we ident i-fy a r eference set of 478 positive st e reotypes (such as saint and hero ) and 677 negative stere o types (such as tyrant and monster ). When we use these refe r ence points to test the effectiveness of (5) and (6)  X  and thus, indirectly, of (3) and (4) and of the ster e otype lexicon itself  X  we find that 96.7% of the positive stereotypes in +R are correctly a s-signed a positivity score greater than 0.5 ( pos(S) &gt; neg(S ) ) by (5), while 96.2% of the negative stere o-types in -R are correctly assigned a negativity score great er than 0.5 ( neg(S) &gt; pos(S ) ) by (6). The Google n -grams are a rich source of affective metaphors of the form Target is Source , such as  X  X ol i ticians are crooks X ,  X  X pple is a cult X ,  X  X acism is a disease X  and  X  X teve Jobs is a god X . Let src(T) d e note the set of stereotypes that are commonly used to d e scribe T, where commonality is defined as the presence of the corresponding copula met a-phor in the Google n -grams. To find metaphors for proper -named entities like  X  X ill Gates  X , we also analyze n -grams of the form stereotype First [Middle] Last , such as  X  tyrant Adolf Hitler X . Thus : src (racism) = { problem, disease, joke, sin , po i-src (Hitler) = { monster , criminal , tyrant , idiot , 
We do not try to discriminate literal from non -literal assertions, nor do we even try to define lite r-ality. We simply assume each putative metaphor offers a pote n tially useful perspective on a topic T. properties ascribable to T via met a phors in src (T): We can also use the posTypical and negTypical var i ants in (7) and (8) to focus only on metaphors that project positive or negative qual i ties onto T . metaphor T is S is not a known stereotype in the lexicon, as happens when one describes Apple as Scientology . When the set typical (S) is empty, sr c-Typical ( S ) may not be, so srcTypical ( S ) can act as a p roxy represent a tion for S in these cases. the interpretation of T is S are given by: In the context of T is S , the metaphorical stereotype M  X  src (S)  X  src (T )  X  {S} is an apt vehicle for T if: and the degree to which M is apt for T is given by: We can construct an interpretation for T is S by considering not just {S}, but the stereotypes in src (T) that are apt for T in the context of T is S , as well as the stereotypes that are commonly used to describe S  X  that is, src (S)  X  that are also apt for T: (13) interpretation (T, S) In effect then, the interpretation of T is S is itself a set of apt metaphors for T that expand upon S. The elements { M i } of in terpretation (T, S) can now be sorted by aptness ( M i T, S ) to produce a ranked list of interpretations (M 1 , M 2 ... M n ). For any inte r-pretation M, the salient features of M are thus: If T is S is a creative IR query  X  to find doc u-ments that view T as S  X  then interpr e t a tion (T, S) is an expansion of T is S that i n cludes the co m-mon metaphors that are consistent with T viewed as S. F or any viewpoint M i , salient (M i , T, S ) is an e x pa n sion of M i that i n cludes all of the qualities that T is lik e ly to e x hi b it when it behaves like M i Consider the query  X  Google is Microsoft  X , which expresses a need for documents in which Google exhibits qualities typically associated with M i-crosoft. Now, both Google and Microsoft are co m-plex concepts, so there are many ways in which they can be considered similar or dissimilar, either in a good or a bad light. However, the most sa lient aspects of M i crosoft will be those that underpin our common metaphors for Microsoft, i.e., stere o-types in src (Microsoft). These metaphors will pr o-vide the talking points for the inte r pretation . metaphors, 57 for Microsoft and 50 for Google: src (Microsoft) = { king, master, threat, bully, giant, src (Google) = { king, engine, threat, brand, giant, So the following qualities are aggregated for each: s rc Typical (Microsoft) = { trusted, menacing, ruling, src Typical (Google) = { trusted , lurking reig n ing, Now, the salient qualities highlighted by the met a-phor , namely salient (Google, Microsoft), are: { celebrated, menacing, trusted, challenging, esta b-lished, threatening, admired, respected , ... } Thus, interpretation (Google, Microsoft) contains: { king, criminal, master, leader, bully, threatening, giant, threat, monopoly, pioneer, dinosaur, ... } Suppose we focus on the metaphorical expansion  X  X oogle is king X , since king is the most highly ranked element of the interpretation. Now, sal i-ent ( king , Google, Microsoft) contains: { celebrated, revered, admired, respected , ruling, a r rogant, commanding, overbearing, reigning , ... } These properties and behaviors are already i m plicit in our perception of Google, insofar as they are salient aspects of the stereotypes to which Google is frequently compared. The metaphor  X  X oogle i s Microsoft X   X  and its expansion  X  X oogle is king X   X  simply crystalizes th e se qualities, from perhaps different comparisons, into a single act of ideation. Consider the metaphor  X  X oogle is -Microsoft  X  . Since -Microsoft is used to impart a negative spin ( + w ould im part a positive spin) , negTypical is here used in place of typical in (9) and (10) . Thus: src Typical ( -Microsoft ) = { menacing, threatening, twisted , raging, feared, salient (Google, -Microsoft ) = Now interpretation (Google, -Microsoft ) becomes: { criminal, giant, threat , bully, victim, devil, ...} In contrast, interpretation (Google, + Microsoft ) is: { king, master, leader, pioneer , partner, ...} More fo cus is achieved with the simile query  X  X oogle is as  X  powerful as Microsoft X . In expli c it similes, we need to fo cus on just a sub set of the salient prope r ties, using e.g. this variant of (10): In this -powerful case, the interpretation becomes: { bully, giant, devil , monopoly , dinosaur, ...} Metaphor Magnet is designed to be a lightweight web application that provides both HTML output (for h u mans ) and XML (for client applications). The system allows users to enter queries such as Google is  X  Microsoft , life is a + game , Steve Jobs is Tony Stark , or even Rasputin is Karl Rove (queries are case -sensitive). Each query is e x panded into a set of apt met aphors via mappings in the Google n -grams, and each metaphor is expanded into a set of co n textually apt qualities. In turn, each quality is then expanded into an IR query that is used to r e-trieve relevant hits from Google. In effect, the sy s-tem allows user s to interface with a search engine like Google using metaphor and other affective language forms. The demonstration system can be a c cessed using a standard browser at this URL :
Metaphor Magnet can exploit t he properties and behaviors of its stock of almost 10,000 stereotypes, and can infer salient qualities for many pro p er -named entities like Karl Rove and Steve Jobs using a combination of copula statements from the Google n -grams (e.g.,  X  Steve Jobs is a vis ionary  X ) and category assignments from Wikipedia .

The interpretation of the simile/query  X  Google is as -powerful as Microsoft  X  thus highlights a sele c-tion of affective viewpoints on the source concept, Microsoft , and picks out an apt selection of vie w-point s on the target Google . Metaphor Magnet di s-plays both selections as phrase clouds in which each hyperlinked phrase  X  a combination of a n apt st e reotype and a salient quality  X  is clickable, to yield linguistic evidence for the selection and co r-responding w eb -search results (via a Google gad g-et) . The phrase cloud representing Microsoft in this simile is shown in the screenshot of Figure 1, while the phrase cloud for Google is shown in Fi g ure 2. Figure 1 . A screenshot of a phrase cloud for the perspective c ast upon the source  X  X icrosoft X  by the simi le  X  Google is as  X  powerful as M i crosoft  X . Figure 2 . A screenshot of a phrase cloud for the perspective cast upon the target term  X  Google  X  by the simile  X  Google is as  X  powerful as M i crosoft  X . Met aphor Magnet demo n strates the potential util i-ty of affective metaphors in h u man -computer li n-guistic interaction, and acts as a web service from which other NL applications can derive a measure of metaphorical comp e tence. When a c cessed as a service , Met a phor Ma g net return s e i ther HTML or XML d a ta, via simple get r e quests. For illustrative purposes , e ach HTML page also pr o vides the URL for the corr e spond ing XML -stru c tured data set. This research was partly supported by the WCU (World Class University) program under the N a-tional Research Foundation of Korea ( Ministry of Edu c ation, Science and Tec h nology of Korea, Pr o-ject No: R31 -30007) , and partly funded by Science Found a tion Ireland via the Centre for Next Gener a-tion L o calization (CNGL) .

