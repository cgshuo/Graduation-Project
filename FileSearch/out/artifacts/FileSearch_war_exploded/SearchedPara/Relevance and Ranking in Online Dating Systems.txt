 Match-making systems refer to systems where users want to meet other individuals to satisfy some underlying need. Examples of match-making systems include dating services, resume/job bulletin boards, community based question an-swering, and consumer-to-consumer marketplaces. One fun-damental component of a match-making system is the re-trieval and ranking of candidate matches for a given user. We present the first in-depth study of information retrieval approaches applied to match-making systems. Specifically, we focus on retrieval for a dating service. This domain of-fers several unique problems not found in traditional infor-mation retrieval tasks. These include two-sided relevance, very subjective relevance, extremely few relevant matches, and structured queries. We propose a machine learned rank-ing function that makes use of features extracted from the uniquely rich user profiles that consist of both structured and unstructured attributes. An extensive evaluation car-ried out using data gathered from a real online dating service shows the benefits of our proposed methodology with respect to traditional match-making baseline systems. Our analysis also provides deep insights into the aspects of match-making that are particularly important for producing highly relevant matches.
 H.3.5 [ Online Information Services ]: Web-based services Algorithms,Experimentation dating systems, relevance
A match-making system is a bulletin board where people seek to meet other individuals in order to satisfy a particu-lar need. Many match-making systems exist today includ-ing dating services, resume/job bulletin boards, community-based question answering systems, and consumer-to-consumer marketplaces. Despite the popularity of such systems, rela-tively little research has been conducted on the design of in-formation retrieval models particularly suited for the match-making task.

Typically, in a match-making system, each user is associ-ated with a profile that includes general information about the user. For example, in an online dating service, the pro-file will include the user X  X  location, physical attributes (e.g., hair color), and political affiliation. On a job seeking site, the profile may contain the job seeker X  X  education, years of experience, and desired salary range. It is also common for users of these systems to be able to define the attributes they would like matches to satisfy. In match-making sys-tems, these are often called target profiles . In information re-trieval terminology, the target profile can be considered the user X  X  information need, or query. A key aspect of match-making systems is the ranking of candidate matches for a given user. Different ranking functions are used to compute the relevance of a match to a user. In this paper, we study information retrieval-based ranking functions in this con-text. To the best of our knowledge, this is the first in-depth study of retrieval and ranking in a match-making system. We use an online dating service as our main application. One key observation is that in such systems, two-sided rel-evance is a natural way of ranking matches. Intuitively, matches that satisfy a given user X  X  target profile and whose target profile is also satisfied by the given user own profile , are preferred to matches whose target profile is not satisfied by the given user. Consider the situation where user u is in-terested in someone with attributes similar to those of user v but v is not interested in someone with attributes similar to those of user u . In this case, we argue that it is unde-sirable for a retrieval system to rank v highly for u . There are two reasons for this. First, we would like to avoid v be-ing contacted by undesirable candidates. Second, we would like to maximize the likelihood that u receives a reply. An-other interesting aspect of the dating domain is subjective relevance. Understanding the relevance of a pair of individ-uals often requires a complex understanding of the intents of both users. This makes a good match more difficult to de-tect than document relevance and as a result is particularly interesting from an information retrieval perspective.
This paper has three primary contributions. First, we for-mulate the match-making task as an information retrieval problem, whereupon user profiles are ranked with respect to a given target profile using a machine learned ranking func-tion. Second, we exploit the uniquely rich nature of user profiles by extracting novel features based on their struc-tured (e.g., age, income) and unstructured (e.g., description) attributes. Finally, we undertake an extensive evaluation using the data from a real-life online data site in order to determine the level of interest between two users. Our ex-periments also provide interesting insights into the types of features and models that are the most useful for these types of systems.

The rest of this paper is laid out as follows. First, Sec-tion 2 provides an overview of previous work related to match-making systems. Then, in Section 3 we formally define the match-making problem from an information re-trieval perspective. Section 4 discusses our proposed ma-chine learned ranking framework. Sections 5 and 6 detail our experimental methodology and present our experimental evaluation, respectively. Finally, Sections 7 and 8 conclude the paper with some discussions and directions for future work.
There is a large body of research related to match-making systems. Previous research has looked at match-making from algorithmic, empirical, and even psychological perspec-tives. We now highlight the previous research that is most related to our study.

First, in mathematics there is the well-known stable mar-riage problem. This problem aims to find a matching be-tween all pairs of men and women such that it cannot be the case that two potential partners both prefer each other to their current partner [11]. When there is no distinction between sets of users, this is the stable roommate problem [13]. In combinatorics, the assignment problem refers to matching tasks and agents so as to minimize some cost. In our situation, we are not required to provide a hard match-ing between users, but rather to rank possible partners for a given user. This distinction is necessitated by the interactive nature of online match-making systems.

There have also been a number of studies that have specif-ically looked at dating systems. Hitsch et al. provide a very detailed exploration into factors influencing match-making in online dating systems [12]. Ranganath et al. explore how language used during speed dating sessions can be used to predict potential matches [24].

The combination of information retrieval and database ap-proaches has been a fertile area of research recently. Such research is related to our work because of the structured nature of user profiles in match-making systems. Several previous studies have investigated the use of free text re-trieval for a structured database [22, 16]. An important side effect of this is a ranking of records based on predicted relevance. Lavrenko et al. proposed structured relevance models for retrieving records from semi-structured data sets that have missing field information[18]. Follow-up work by Yi et al. used the structured relevance model for match-ing resumes to recruiter queries [26]. Several other methods have also been proposed for ranking database results [7, 6, 19] and for using explicit relevance feedback within database systems [21, 25, 3]. Our approach is unique in that we take a feature-oriented, machine learning-based approach to the problem that provides a great deal of flexibility and a strong level of effectiveness.

Finally, the task of finding users (rather than documents) that satisfy an information need has been addressed in a variety of contexts. For example, in the TREC Enterprise Track, the Expert Search task requires participants to rank human experts with respect to specific topic [1]. Expert Search situations occur when a user seeks an expert. How-ever, the expert has no constraint over who contacts her. One other difference is that users, both queriers and experts, usually do not have semistructured profiles. Completely de-centralized search algorithms for individuals have also been studied in the context of social network analysis [17]. Fur-thermore, the reviewer assignment problem also involves a search over a set of users [14, 15]. While related, none of these tasks exhibit the unique properties exhibited by the online dating match-making task. We consider a retrieval scenario consisting of a set of users, U , each of whom maintains a self-description and a query. For a user u  X  U , a description, d u , consists of a set of descriptive attributes. These attributes may be scalar, cate-gorical, or free text. In this paper we consider the attributes presented in Table 1. A query, q u consists of a set of con-straints on candidate attribute values. In this paper, we consider binary and scalar preferences. Binary constraints indicate that a certain attribute be present in a candidate record. Scalar constraints indicate that a scalar attribute be a certain value or in a certain range.

For each user, u , we would like to rank all other users, v  X  U  X  X  u } , such that relevant matches occur above non-relevant candidates.
We adopt a machine learning approach to learning our ranking model [20]. Machine learned ranking models con-sist of three parts: ranking features, relevance, and a rank-ing function. Ranking features include all signals we observe which may influence the scoring of a candidate match. In our work, relevance refers to two users being an appropriate match (e.g. they want to meet). Finally, the ranking func-tion is a model of relevance given observable ranking fea-tures. In this section, we be explain in some detail each of these components as they relate to the match-making task.
Given a user X  X  query, we are interested in ranking all other users in decreasing order of two-way relevance. We consider three types of features that we believe are predictive of rele-vance. All of the features that we consider are based on the match-making attributes listed in Table 1.
 First, we extract a number of features from user profiles. The user profiles represent information about a given user. Profiles typically only specify a single value for a given at-tribute rather than multiple values. This is due to the fact that users have a single age, a single body type, a single astrological sign, and so on. When ranking for a particular user, u , the profile features of a candidate, v , can be thought of as independent of user u and her query. We represent a candidate X  X  profile features with the notation tures), a querier X  X  profile features with and the concatenation of both sets as
Our second set of features compares pairs of user pro-files. We expect that match relevance will be influenced when some profile features are very different (e.g. age). We compare two profiles in a match by comparing the individual profile features, We also implemented a simple score comparing the similar-ity of pairs of users X  text self-description. For each user u , we compute an ` 2 -normalized tf.idf-based term vector, t based on the self-description. Given a pair of users, the text comparison is, Notice that, unlike our non-text feature comparison, the text comparison is a similarity as opposed to a difference. This is a minor issue since our modeling should be able to support both flavors of features. We present a pair X  X  comparison features with  X  (331 features).

The final set of features represent attribute matches with respect to a user X  X  query. These are the attributes that the querier desires a potential match to have. For the scalar attributes, users can specify a range of values of interest, such as age between 18 and 35. These ranges are trans-formed into two scalar features, one representing the min-imum allowable value and the other representing the max-imum. In our age example, this would correspond to the features age min = 18 and age max = 35. With categor-ical attributes, users specify one or more desirable values for each attribute. These preferences are encoded as binary features, one for each possible attribute value. For example, if a user is interested in matches with red or blonde hair, then the features hair red and hair blonde would be set to true (1) and all other hair color features (e.g., hair black) would be set to false (0). Finally, users can specify the im-portance of each attribute. The possible options are  X  X ust match X ,  X  X ice to match X , and  X  X ny match X . Here,  X  X ust match X  attributes are those that the querier requires to be satisfied for a match to be relevant,  X  X ice to match X  are those attributes that the user would like to matches, but does not require, and  X  X ny match X  means the user would be satisfied with any match for the given attribute. These attribute importances are encoded as binary features (e.g., hair must match, hair nice to match, and hair any match). Our set of match features represent how well each attribute matches between a user X  X  query and a candidate profile as well as the attribute preferences of the querier. For exam-Figure 1: Graphical representation of the feature sets we consider in our experiments. ple, if a querier is interested in matches with a given hair color, a match feature would encode whether a candidate X  X  profile attribute satisfied that hair color as well as how im-portant that attribute match was. Match features of this form are extracted for all query attributes. We represent a candidate X  X  match features with respect to a querier X  X  query with the notation  X  X  X  q (156 features), a querier X  X  match fea-tures with respect to the candidate X  X  query with  X  X  X  features), and the concatenation of both sets as  X  X  X  features).

Figure 1 provides a graphical depiction of the symbols used to represent the different feature sets.
Relevance in classic text retrieval tasks (e.g. TREC ad hoc retrieval tasks) is often interpreted as topical relevance. When interpreted this way, some degree of editorial assess-ment of document relevance can be performed. In a match-making system, queries are often constrained to a small set of structured attributes. Therefore, asking an editor to de-tect two-sided relevance can be a more time-consuming task; the editor would need to determine the intent of a querier given a structured query as well as a potentially rich profile in both directions. Furthermore, in many cases, the rele-vance of matches in a match-making system is more subjec-tive than topical relevance. For example, there may be many subtle attributes in the profile or query which are important to the users but difficult to detect, even with query attribute preferences. Because of this, accurately determining intent and relevance may be impossible.

In order to address the difficulty with editorial relevance assessment, a retrieval system can use behavioral informa-tion of a running system to detect when users have found rel-evant information. This approach is practiced in web search when relevance engineers monitor user clickthrough patterns [5, 23, 2]. Because salient behavioral information normally occurs after a query is issued, we refer to these behavioral signals as post-presentation signals. We are interested in tuning ranking function parameters using queries with post-presentation signals and generalizing to queries with no post-presentation signals.

Match-making systems provide a unique set of post-presentation relevance signals which can be used both for training and evaluation. For example, if two users exchange phone num-bers, they are probably a good match. On the other hand, if one user X  X  message never receives a reply, then they were probably a poor match. We present a complete list of our post-presentation features in Table 2. Instead of committing to a single feature to define relevance, we engineer a set of high precision rules to define relevance and non-relevance for a subset of matches. In our work, we consider as relevant any matches where users exchanged contact information; we consider as non-relevant any matches where at least one user inspected the other X  X  profile but did not send a message as well as any matches where one user sent a message but the other did not reply. We refer to matches satisfying these rules as  X  X abeled X  matches.

We often have post-presentation features likely to corre-late with relevance but whose exact relationship we are un-sure of. In this situation, because we have a small set of (automatically) labeled matches, we can train a model to predict the labels of these unlabeled matches. Specifically, we train a logistic regression model using the labeled set and the unlabeled features in Table 2 (i.e. we only use those fea-tures not used to infer relevance). We then use this model to label the unlabeled set with predicted relevance. For a match of users u and v , we use the notation P ( R| u,v ) to refer to the predicted relevance. We force labeled users to have P ( R| u,v )  X  X  0 , 1 } based on the automatic labeling.
We want to be clear that our predicted relevance is a noisy signal. For example, a successful interaction will not be de-tected if messages are exchanged through an external proto-col. Furthermore, even when messages are exchanged within a system, it may be that the match is inappropriate. Mes-saging is also subject to false negatives if contacts are not initiated due a searcher X  X  perceived probability of response. Nevertheless, we believe that basing relevance for a dating system on behavioral information is both more reliable and more efficient than editorial labeling.
There are many different ways to define a ranking function for the match-making task. In this work, we make use of a machine learned ranking function based on gradient boosted decision trees (GBDTs) [10]. We chose to use GBDTs for several reasons. First, GBDTs can handle both numerical and categorical features, which is a good fit for the types of attributes found in match-making systems. Second, GBDT-based ranking functions can be trained using a wide vari-ety of relevance sources, including manual labels and click-through data. Finally, these models have been shown to be highly effective for learning ranking functions [27].
We now provide a basic overview of GBDTs. Given a querier u and a candidate match v , we use GBDTs to com-pute a relevance score for the pair. As the name implies, GBDTs are boosted regression trees. Let f u,v be the fea-Table 2: Post-Presentation Features. These features measure the interactions between users after they have seen a profile. Labeled features are bolded. Regular expressions used to detect meeting were taken from [12]. ture vector associated with the pair ( u,v ). A regression tree defines a function T ( u,v ) by partitioning the space of feature values into disjoint regions R j , j = 1 , 2 ,...,J , which are as-sociated with the terminal nodes of the tree. Each region is assigned a value  X  j such that T ( u,v ) =  X  j if f u,v Thus, the output of the regression tree is computed as: where  X  = { R j , X  j } J 1 , are parameters and I is the indica-tor function. Given a pair of users, a single regression tree will return a single real-valued score for that pair of users. Precisely how the score is computed depends on the model parameters R j and  X  j .

For a given loss function L these model parameters are estimated by minimizing the the total loss: where y u,v = P ( R| u,v ) is the actual or predicted relevance label for pair ( u,v ). Numerous heuristics exist for solving this optimization problem, the details of which are beyond the scope of this paper. In all of our experiments, we use mean squared error as our loss.

A boosted regression tree is an aggregate of such trees, each of which is computed in a sequence of stages. That is, where at each stage m ,  X  m is estimated to fit the residuals from stage m  X  1 as follows: where  X  is a free parameter known as the shrinkage rate. Another important free parameter is the depth of the indi-vidual regression trees T . If the depth of the trees is greater than 1, then interactions between features are taken into account.

Thus, given a training set consisting of pairs of users and their associated relevance labels, we can learn a GBDT model model {  X  i } M i =1 , which is an ensemble of regression trees. At test time, we use the learned model to score, and subsequently rank, candidate matches v with respect to queries u using s M ( u,v ).

Finally, the GBDT algorithm also provides what is called feature importance [10]. The importance is computed by keeping track of the reduction in the loss function at each feature variable split and then computing the total reduc-tion of loss function along each feature variable. The feature importance can be useful for analyzing which features con-tribute the most to the learned model.
We collected the profiles and queries for users of a per-sonals system during the fall of 2009. We collected user interaction data during this time period. After processing, we had 6,420,563 matches with features from Table 2 de-fined. We bootstrapped from labeled features to label un-labeled matches. We kept only users who had at least one relevant match with P ( R ) &gt; 0. After this processing, our data set consisted of 33,233 users (18,457 men and 14,776 women). We split our data into training, testing, and val-idation sets by user . This prevents us from evaluating on features observed in the training set. However, as a result, some matches cannot be observed because users are in differ-ent splits. Our data sets consisted of a training (7716 users, 17538 matches), validation (3697 users, 7543 matches), and testing set (4836 users, 10636 matches). Users whose only matches were broke by partitioning were removed from the experiments.

Text comparison features used idf statistics from the col-lection of user self-descriptions and the set of SMART stop-words.
We can compute standard information retrieval metrics, macro-averaged over users. That is, we iterate through all users, considering each user a  X  X uerier X  and all other users with labels or predictions  X  X andidates X  to be ranked. Because we use both relevance predictions, we evaluate using met-rics supporting estimates of the probability of relevance. In particular, we use the probabilistic versions of the following metrics: average precision (AP), precision at k documents (P@k), normalized discounted cumulative gain at rank k (NDCGk), and expected reciprocal rank (ERR). These are defined by, The expected reciprocal rank metric was recently proposed by Chapelle et al. [4] and is designed for tasks with prob-abilistic relevance grades. The metric overcomes some of the position bias issues associated NDCG by incorporating a simple cascade-style user browsing model [8].
 We define two sets of evaluation users as, U 1 would only include those users who have at least one la-beled relevant match. On the other hand, U R 0 would only in-clude those users who have at least one match with non-zero predicted relevance. Because the reliability and robustness of rank metrics is influenced by the number of candidates being ranked, we only evaluate over users with five or more matches with P ( R| u,v ) defined.

We will present results under two evaluation regimes: la-beled and predicted. For the labeled evaluation, we use the set of users in U R 1 as queriers and only the matches labeled by our rules (i.e. P ( R| u,v )  X  X  0 , 1 } ). In this case, our met-rics reduce to their standard, non-probabilistic form. For the predicted evaluation, we use the set of users in U R queries and all matches with P ( R| u,v ) defined.

To identify statistically significant differences between two ranking functions with respect to a given retrieval metric we use a paired, one-tailed non-parametric bootstrap test [9]. We adopt this significance test because it allows us to sample users non-uniformly. We sample a user u by max v P ( R| u,v ). For U R 1 , this results in uniform sampling. For U R 1 , this re-sults in sampling proportional to the most relevant match. All significance tests are reported at the p &lt; 0 . 05 level.
We estimated GBDT models using different subsets and combinations of features regressing against P ( R| u,v ). These runs are labeled  X  X  X  q (match only),  X  (profile similarity only), and  X  X  X  q (two-way match only). We also experiment with a runs which combine sets of features. Because of unbalanced class distributions, we weighed in-stances according to, so that we give a match weight according the source of its label.

Gradient-boosted decision trees have several free parame-ters: number of trees, number of nodes, and shrinkage. We trained our decision trees using the training partition and selected free model parameters using the validation set, ex-ploring ranges of free parameter values, number of nodes { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 25 , 50 } number of trees { 5 , 10 , 50 , 75 , 100 , 250 , 500 , 1000 } Although we train on the full set of matches, we validate using the pool depth restriction we use in evaluation. The results of our experimental evaluation are shown in Table 3. We can make several observations about our runs from these results. First, and perhaps most strikingly, we see that using metrics. Recall that the and thus we are essentially learning nothing more than a static ranking of the profiles. In fact, there are no statistical differences between the strongest runs and
Second, features comparing both users,  X  , although effec-tive, do not yield significant improvements over the query independent ranking (and actually results in a statistically significant drop for P@5 under both evaluation sets).
Using only match features, both one-way and two-way, re-sults in the worst performance across metrics. These drops in performance are statistically significant across metrics compared to the next best run,  X  , except P@5 and P@10 for the labeled relevance set and P@5 for the predicted rel-evance set. When we compare  X  X  X  q and  X  X  X  q runs, we observe statistically significant gains for four of the eight metrics for the labeled relevance set (AP, ERR, NDCG5, NDCG10) and four of the eight metrics for the predicted relevance set (AP, ERR, NDCG5, NDCG10).

We note that, when combining  X  and  X  X  X  q features, we see improvements compared to only using  X  or  X  X  X  q . Compared to using only  X  features, statistically significant improvements are isolated to one metric for labeled relevance set (P@5) and three metrics for the predicted relevance set (NDCG5, NDCG10, P@10). All improvements are statistically signif-icant compared to using the  X  X  X  q alone.

Finally, combining although not as strong as our other combination (  X   X  X  X  q ). Fur-thermore, this run degrades performance compared to using only tistically significant.

In Table 4, we show the top fifteen features, as measure by their feature importance as described in Section 4.3, for each run we evaluated. As the results indicate, the most important features across runs tend to be those associated with distance, age, height, the profile having been featured, and the user X  X  subscription status. When considering match features (  X  X  X  q ,  X  X  X  q ), we notice the selection of both match val-ues as well as constraints, suggesting that the algorithm is indeed taking advantage of the users X  preferences, not just the match value. When we consider two-way match fea-tures, match features in both directions are selected, indi-cating that both users X  match preferences are important for ranking. Finally, we note that the text similarity measure, when available, often ranks highly in terms of feature im-portance, suggesting that non-relational attributes also play an important role.
We were surprised that that model trained only using features resulted in such strong performance. Does this im-ply that attributes specific to the querier are irrelevant? Most likely not. There could be several other reasons for this. For example, the expressiveness of the query repre-sentation may be limited. Even though users are provided with the ability to indicate the importance of specific traits and their values, the importance value is still discrete; these importances are unlikely to be as expressive as real-valued weights applied in the machine learned model. Although it may seem that the attributes in Table 1 are not informa-tive enough to rank candidates, this hypothesis is unlikely to be supported since the same representation. Finally, it might be that the user is just not agile enough with the query interface to produce effective queries. This suggests that alternative interfaces or more intuitive features might be better at eliciting effective queries from the users for this particular task.

The strength of the our data gathering process. We only experiment with pairs of users who have interaction features defined, in the form of profile views or message exchanges. Users may become cognizant of how their own attributes compare to the pref-erences associated with the profiles they view. This is espe-cially true since profile displays include information about the user X  X  query. There is likely a self-censoring process in-volved whereby a user only sends a message if they notice that they match the profile X  X  preferences.

The conjunctions of features noticeably did not provide statistically significant improvements for many metrics. This result likely follows from the number of features considered in the aggregated set compared to the training set size. For example, The combination of in a vector of 1614 features. With only 17,538 training in-stances, it is unlikely that the model had enough data to learn an accurate predictor, thereby degrading ranking ef-fectiveness. We believe that, with more training data, our combined runs would significantly outperform the simpler baselines.

In addition to physical attributes related to age and height, those attributes with the strongest predictive power were distance, subscription status, and whether a user X  X  profile had been featured. While the distance constraint is under-standable to many (e.g. individuals are looking for matches within their city or state), the others require some explana-tion. The subscription status of a user indicates an invest-ment in the search process. If a user has paid money for extra site features, they may be more engaged in the system and willing to look for matches. On the other hand, when the site decides to feature a profile, this raises the credibil-ity of the user, making them more attractive to other users. As a result, we expect these users to be more successful at finding matches.

The importance of the text similarity feature when in conjunction with the match features, suggests that there is information present in the text description that can be exploited for ranking. Text provides user an unconstrained field to discuss arbitrary interests. The ability to detect sim-ilarity in these interests using a very simple text similarity measure means that eliciting text from users and exploiting it for ranking is a good avenue for future work.  X  X  X  q similarity (  X  ), one-way match (  X  X  X  q ), and two-way match (  X  X  X  q ). Statistical significance between pairs of runs for a metric are described in the text. runs except  X  , more than fifteen features were selected by the algorithm.
We have presented the problem of ranking for match-making systems. We motivated this problem by its ubiquity as well as its compelling differences with many standard re-trieval scenarios. Specifically, we believe that the notions of two-way relevance, its detection, and usefulness for ranking are all very different from many search problems.

We found that, for our problem setting, query-independent ranking provided a simple and effective method for ranking candidate matches. This greatly simplifies system design since ranking can be done globally, with some simple filter-ing for important match constraints (e.g. distance, age). At the same time, we believe that users X  queries, as they are often revealed to all users in a system may provide a self-censoring which in turn results in a higher quality list of candidates. Furthermore, we believe that such systems may benefit from different query interfaces more appropriate for the task. This might include the option of users to issue free text queries, as text similarity appeared to be a strong predictor of relevance when combined with match features.
There is a wide range of research problems associated with retrieval in match-making systems. In the area of rel-evance, future work includes discovering additional implicit relevance signals. More interestingly, we can design system modules which, as a side effect, detect relevance with high accuracy. In the area of features, future work includes the refinement of features we propose and development of new attributes found to be highly correlated with relevance. For example, new structured attributes might be detected by in-specting text description term matches which are correlated with relevance. Finally, in the area of ranking, it may be possible to develop improved loss functions that take into account the unique notion of two-way relevance.
We would like to thank Sergiy Matusevych, Seena Cheran-gara, Ramesh Gollapudi, and Ramana Lokanathan for help-ful discussions and support.
