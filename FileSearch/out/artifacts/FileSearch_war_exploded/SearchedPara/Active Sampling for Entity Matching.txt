 In entity matching, a fundamental issue while training a classifier to label pairs of entities as either duplicates or non-duplicates is the one of selecting informative training examples. Although active learning presents an attractive solution to this problem, previous approaches minimize the misclassification rate (0-1 loss) of the classifier, which is an unsuitable metric for entity matching due to class imbal-ance (i.e., many more non-duplicate pairs than duplicate pairs). To address this, a recent paper [1] proposes to max-imize recall of the classifier under the constraint that its precision should be greater than a specified threshold. How-ever, the proposed technique requires the labels of all n input pairs in the worst-case.

Our main result is an active learning algorithm that ap-proximately maximizes recall of the classifier while respect-ing a precision constraint with provably sub-linear label com-plexity (under certain distributional assumptions). Our al-gorithm uses as a black-box any active learning module that minimizes 0-1 loss. We show that label complexity of our algorithm is at most log n times the label complexity of the black-box, and also bound the difference in the recall of clas-sifier learnt by our algorithm and the recall of the optimal classifier satisfying the precision constraint. We provide an empirical evaluation of our algorithm on several real-world matching data sets that demonstrates the effectiveness of our approach.
 H.2.8 [ Information Systems ]: Database Management X  Database Applications [Data Mining]; H.3.3 [ Information Systems ]: Information Storage and Retrieval X  Information Search and Retrieval [Clustering] entity matching, deduplication, active learning, imbalanced data
Entity Matching (EM) is the problem of determining if two entities in a data set refer to the same real-world object. Entity matching is a complex and ubiquitous problem that appears in numerous application domains (including image processing, information extraction and integration, and nat-ural language processing), often under different terminology (e.g., coreference resolution, record linkage, and deduplica-tion [ 14]).

Machine learning approaches [31, 8, 6] for entity matching often learn a classifier over pairs of entities labeling them as duplicate or non-duplicate. The classifier is built over mod-els such as SVM or logistic regression, using features like string similarity. The models are trained over labeled exam-ple pairs, which are usually costly to obtain. Active learning techniques [ 13 , 19 , 2, 16 , 5, 4] are therefore used to carefully select the examples to label while learning a good classifier  X  one that minimizes the 0-1 loss. These algorithms provide label complexity guarantees, i.e., guarantees on the number of labeled examples required to learn the classifier.
In entity matching, the number of duplicate pairs is typi-cally small, o ( m ), for a dataset of m entities. On the other hand, the total number of pairs including non-duplicates can be  X ( m 2 ). While blocking techniques [30, 22 ] are used to reduce the number of pairs considered for entity matching from  X ( m 2 ) to a more manageable number, denoted n , the non-duplicates still vastly outnumber the duplicate pairs, often by a ratio of 100 to 1, as evident in many bench-mark entity matching datasets. In such cases, minimizing 0-1 loss is insufficient: a classifier that labels all pairs as non-duplicates has a small 0-1 loss of less than 1%. Thus even this extremely poor classifier is considered good under 0-1 loss.

To address this, a recent paper [1 ] considers precision and recall 1 of the classifier as the objective functions. Precision in entity matching is the fraction of pairs labeled as dupli-cates that are true duplicates, and recall is the fraction of true duplicates labeled as duplicates. So the classifier that labels all pairs as non-duplicates, labels no true duplicates as duplicates, and has a recall of 0. Thus the classifier is correctly considered poor under the recall metric.

Arasu et al. [ 1] provide an active learning algorithm to maximize recall under a constraint that precision should be greater than a specified threshold. The algorithm makes a monotonicity assumption on the precision and recall of the classifier over its parameter space. The algorithm then
That work actually considers an approximation of recall metric, but we ignore this distinction for now. searches for the optimal classifier essentially through a bi-nary search over classifiers in the high-dimensional parame-ter space. Due to this high-dimensional binary search, the algorithm has high label complexity (i.e., many labeled ex-amples requested) and high computational complexity, and in the worst-case requires the labels of all n input pairs. Furthermore, the monotonicity assumption does not usually hold in practice, and while the algorithm still returns a fea-sible classifier satisfying the precision constraint, its recall is often poor.

In this paper, we propose an active learning algorithm for optimizing recall under the precision constraint, using as a black-box any active learning approach that minimizes 0-1 loss. We first use a Langrange multiplier to cast the preci-sion constrained recall optimization problem into an uncon-strained one with an objective that is a linear combination of precision and recall. For a fixed value of the Langrange multipier, the linear objective can be optimized using the given black-box. Then we search for the right value of the Langrange multiplier. For this we embed all classifiers in a two dimensional space, and perform a search along the convex hull [24 ] of the embedded classifiers.

A major challenge in our work is to ensure that the search over the embedded classifiers is efficient, and we show that via discretization techniques, we are able to achieve a rather low number of worst-case O (log 2 n ) calls to the black-box. We also show that additional calls would not help: our out-put classifier is guaranteed to be the best one that can be found using any number of calls to the black-box. By com-parison, [ 1] has exponential (in the number of dimensions) worst-case computational complexity.

While the classifier output by our algorithm need not be optimal in terms of its recall, we show that it is pareto-optimal (i.e., no other classifier dominates it in both recall and precision). We also provide additional guarantees on how close our output classifier is to the optimal by showing that they lie on the same edge of the convex hull of the embedded classifiers, and coincide in case the optimal is a vertex point.
 Contributions and Outline:  X  Our main result is an active learning algorithm that ap- X  We use the IWAL active learning algorithm [ 5] as the  X  We provide an empirical evaluation of our algorithm on
We present background on active learning in Sec. 2, fol-lowed by our approach in Sec. 3. We then discuss experi-mental evaluation in Sec. 5 and conclude in Sec. 6.
In this section, we define the notation and setup the prob-lem formally. We also briefly review the important active learning techniques.
Let E be the set of all entities for the matching task, and m be the size of E . We assume that the set of all candi-date entity pairs to be matched from E has been generated (say by some blocking technique) and denote it as C . We denote n = | C | be the number of candidate pairs. For a pair of entities ( e 1 ,e 2 ), we assume that a d -dimensional feature vector x = ( x 1 ,x 2 ,...,x d ) represents the similarity between entity e 1 and e 2 , and let X be the set of all feature vectors corresponding to pairs in C . We say that the label of x  X  X , denoted y ( x ), is 1 if x corresponds to a duplicate pair, and  X  1 otherwise. In this paper, we consider linear classifiers defined as follows.

Definition 2.1. A linear classifier h is represented by a d -dimensional vector w = ( w 1 ,...,w d ) . h classifies a feature vector x as positive, i.e. h ( x ) = 1 if w.x  X  0 and negative, i.e. h ( x ) =  X  1 , otherwise.

We let H be the set of all linear classifiers. For any clas-sifier h  X  H , we define number of false positives, false nega-tives, true positives as the following:
The precision and recall of a classifier are then defined as Problem. We wish to maximize recall under the precision constraint. Formally, this is stated as below.

Problem 1 (Recall). Given  X   X  [0 , 1] , find h  X  H to The Recall problem is difficult to solve because recall(h) and precison(h) are complex functions of h .
Now we briefly review the main problems and techniques in active learning.
 Problems. In active learning, the focus has primarily been to solve the problem of minimizing 0-1-loss. We call this problem as the 01-Loss problem. The goal of the problem 2 is to minimize the total number of false negatives and false positives. We state it below.

Problem 2 (01-Loss). Find h  X  H to A slight generalization of the problem considers a weighted loss function in which false negatives and false positives have different penalties. We denote the problem as LossWeighted and define it below.

Problem 3 (01-LossWeighted). Given  X   X  [0 , 1] , find h  X  H to Techniques. One of the first active learning algorithms was given in [10 ]. The algorithm solves the 01-Loss prob-lem for separable datasets  X  datasets for which a classifier exists having 0 empirical 0-1 loss. The paper showed that a good classifier can be learnt for separable datasets using only O (log n ) labeled examples. The algorithm was based on the idea of selective sampling: each example point is queried with a probability, computed based on the point and previ-ously labeled examples.

Since [10 ], several approaches have been proposed to han-dle non-separable datasets. Most recently, IWAL [5 ] pro-posed an efficient active learning algorithm having sublin-ear label complexity under some distributional assumptions. The algorithm is again based on selective sampling, and as-signs a probability of querying an example based on the disagreement between two classifiers, each learnt on all pre-viously labeled examples, but differing in the labels for the example of interest. The algorithm guarantees the following properties.

Theorem 2.2 (IWAL [ 5]). IWAL approximately min-imizes 01-loss using O ( error ( h  X  ) n X  + amples, where error ( h  X  ) is the 01-loss of the optimal clas-sifier, and  X  , the disagreement coefficient [ 16], is a parame-ter depending on the source distribution and the hypothesis class, but independent of the number of points n .

Under certain distributional assumptions [5 ],  X  is a small constant and error ( h  X  ) = o (1). Thus the label complexity is provably sublinear under those assumptions.
In this section, we describe our approach to solve the Re-call problem given a black-box to solve the 01-Loss prob-lem. We use two algorithms: (i) ConvexHull algorithm that approximately solves Recall using a solution for the 01-LossWeighted problem, and (ii) RejectionSampling algorithm that reduces an instance of 01-LossWeighted problem into that of the 01-Loss problem. We describe each of the algorithms below. But we first begin by slightly generalizing the Recall problem.
Learning literature considers a more difficult version of Loss problem when the examples come from an unknown distribution, here we consider the simpler problem using the empirical distribution, for which the same techniques apply. Problem Generalization: The Recall problem maxi-mizes recall under the precision constraint. Maximizing recall( h ) of a classifier h is equivalent to minimizing the frac-tion of false negatives, fn ( h ) /n . (Note that tp ( h ) + fn ( h ) is a constant independent of h .) Instead of just minimizing this fraction, we consider here a more general problem that minimizes a linear combination of false negatives and false
Further, the constraint on precision can be transformed into a simpler one. Denoting = (1  X   X  ) / X  , we can write.
This gives us a generalized version of the Recall problem that we call as RecallWeighted .

Problem 4 (RecallWeighted). Given  X   X  [0 , 1] and  X  [0 ,  X  ) , find h  X  H to Note that for  X  = 1, the solution for RecallWeighted problem is same as that of Recall problem.
Now we describe the ConvexHull algorithm that ap-proximately solves the RecallWeighted problem by re-peatedly solving the 01-LossWeighted problem. Note that the objective of both problems is the same, but Recall-Weighted has an additional precision constraint. The Con-vexHull algorithm essentially removes the constraint using a trick similar to Lagrange multipliers. We describe this be-low.
 Embedding. We embed a classifier h as a point in two dimensional space with the first coordinate equal to negative of the objective and the second to the slack of the precision constraint, as shown below.

Thus, the RecallWeighted problem is equivalent to finding a classifier h that has the highest X ( h ) under the constraint that Y ( h )  X  0. Note also that finding a classifier h that maximizes X ( h ) +  X Y ( h ) for a given  X  can be shown to be equivalent to the 01-LossWeighted problem (with appropriate  X  ).

Let P = { ( X ( h ) ,Y ( h )) : h  X  H } be the set of all two-dimensional embeddings of all possible linear classifiers. While P need not be a convex set, we denote C to be the convex hull polytope of points in P and say a classifier h lies on C if ( X ( h ) ,Y ( h )) lies on an edge of C . Any classifier h lying on C is pareto-optimal: no other classifier h 0 exists that has both  X  X ( h 0 ) (i.e. objective) as well as Y ( h 0 ) (i.e. precision) better than h . We will show that ConvexHull algorithm returns classifiers on the convex hull. (Hence the name.)
Even though the set of all linear classifiers H is expo-nentially large in the number of dimensions, the size of P is bounded by O ( n 3 ), since many classifiers embed to the same point in P . To see this, note that embedded coor-dinates X ( h ) and Y ( h ) are functions of fn ( h ), fp ( h ), and tp ( h ), each of which can vary from 0 to n . 10: end while 11: return h
Since H is exponentially large, and P much smaller, we perform our search for optimal classifier in the embedded space. For the search, we define S the set of all possible slopes of lines joining any two points in P , and  X  a sorted array of all possible values  X  where  X  1 / X  is a slope in S . show that both S and  X  have at most O ( n 3 ) distinct values. The ConvexHull Algorithm. For the algorithm, we as-sume a black-box B for the 01-LossWeighted problem that takes a  X  and returns a h maximizing X ( h ) +  X Y ( h ). The algorithm, shown in Algorithm 1, essentially does a binary search over values in  X . Starting from the two extreme ele-ments  X [ min ] ,  X [ max ], the algorithm repeatedly picks their midpoint  X  =  X [( max + min ) / 2], and then computes a clas-sifier h maximizing X ( h ) +  X Y ( h ) using the black-box B . Depending on whether Y ( h )  X  0 or not, the intervals are updated to ensure that we always have at least one extreme point that satisfies feasibility requirement Y ( h )  X  0. Finally the algorithm terminates with a feasible solution, i.e. a clas-sifier h with Y ( h )  X  0. We can show following additional properties of the algorithm.
 Theorem 3.1 (Complexity of ConvexHull). The ConvexHull algorithm terminates with a feasible classifier (i.e. classifier satisfying the precision constraint) with label complexity at most 3 log n times that of black-box B used in the algorithm.

Proof. Since size of  X  is bounded by O ( n 3 ), the bi-nary search procedure finishes in at most 3 log n iterations. This immediately gives the required label and computational complexity bounds for the algorithm. The feasibility of the solution is guaranteed as a result of the binary search as long as one classifier h exists with Y ( h )  X  0, i.e satisfies the pre-cision constraint. This is always true, for a linear classifier labeling all points as negative.
 On the optimality of the solution: In general, the so-lution returned by the ConvexHull algorithm need not be optimal. Recall the set C , the convex hull polytope of em-bedded points. Each classifier on C is pareto-optimal: i.e. no other classifier dominates it on both the value of objective and precision. The optimal classifer is guaranteed to lie on the convex hull, while the algorithm can return some other point on the same edge. Many times the two coincide, and the algorithm does return the optimal classifier. We state this result formally below.

Theorem 3.2. The optimal solution lies on the convex hull C . The ConvexHull algorithm returns a classifier on the same edge of the convex hull. If the optimal is a vertex point of C, then the algorithm returns the optimal solution.
Proof. First note that any pareto-optimal classifier lies on the convex hull. If not, then extending the line Y = X from the point towards the convex hull results in a classifier dominating it in both objective value as well as precision. Since optimal is also pareto-optimal, it has to lie on the convex hull.

Next we show that the black-box B (  X  ) also returns a h on the convex hull C . Assume the contrary, and suppose it returns a classifier h not on the convex hull. Then for h , there is a point on an edge AB of the convex hull that strictly dominates it in terms of both objective value and precision. Then one of the two vertices, either A or B, has as good or better X +  X Y value, contradicting the assumption.

Furthermore, we show that h = B (  X  ) lies on an edge AB , then its slope has to be  X  1 / X  . This follows directly from linearity of the objective function X +  X Y . Thus our black box function gives us, for each  X  , either a vertex of the con-vex hull, or a point on the line of the convex hull that has slope  X  1 / X  . Let  X  0 be the smallest  X  for which h = B (  X  ) is feasible, i.e. Y ( h )  X  0. If  X  1 / X  0 is a slope whose value lies between slopes of two existing edges in the convex hull, then the binary search of the ConvexHull algorithm would give the vertex corresponding to  X  0 . Furthermore, that vertex will be optimal. If  X  1 / X  0 is the slope of one of the edges (say AB) of the convex hull, then the binary search find  X  and B (  X  0 ) will return a point on AB. Also the optimal will be on the same edge.
 On the efficiency of the algorithm: As stated, Algo-rithm 1 needs to explicitly construct the sorted list  X  that can have O ( n 3 ) elements. Thus the overall time complex-ity of the algorithm is O ( n 3 ) + 3 log n  X  T ( B ): O ( n construction of  X  and 3 log n  X  T ( B ) during active learning, where T ( B ) is the time complexity of black-box B used in the algorithm.

Note that the O ( n 3 ) term might make the algorithm in-feasible for large datasets. We now show how to eliminate the explicit construction of  X , when  X  and are restricted to fractions of fixed bit length b (thus encompassing rep-resentation of floats in modern computer processors.) Our approach is to design a  X  0  X   X  whose constituent values are equally spaced apart (at a discretization factor  X  ). We may then simply do a binary search over the integral multiples of  X  and avoid explicit enumeration of  X  0 .

Since  X  and are fractions of bit length at most b , we can show using Equations 1 and 2 that numerators of X ( h ) and Y ( h ) are an integral multiple of 1 / 2 b . Now, consider the smallest difference between two slopes in  X . Let r/s and t/u be two slopes. We have: r/s  X  t/u = ( ru  X  ts ) /su . First, the smallest non-negative value of ru  X  ts can be shown to be 1 / (2 2 b n 2 ). Second, the value of su is at most 1. Thus, the smallest difference between slopes is 1 / (2 2 b n 2 ). We use this value as our discretization factor  X  . The largest value of  X   X   X  is O ( n 3 ), and thus, the new size of  X  0 is O ( n O ( n 5 2 2 b ). Now, since  X  0 contains all values from 0 to n in multiples of 1 / (2 2 b n 2 ), we may perform binary search without explicitly enumerating the values in  X  0 . Thus, the overall time complexity is (5 log n + 2 b log 2)  X  T ( B ). 10: end for 11: return B h (  X  x,  X  y )
In this section we describe the RejectionSampling al-gorithm that reduces the 01-LossWeighted problem into an instance of 01-Loss problem. Recall that the differ-ence in the two problems is that while the former minimizes atives and false positives, the latter only minimizes their sum. Both the problems are however unconstrained. Our algorithm is very similar to idea of rejection sampling used for transforming cost-sensitive binary classification into the standard setting [ 32, 23 ]. Our analysis is slightly different as we use empirical loss functions rather than distribution ones.
 Black-box: We assume a black-box B for solving the 01-Loss problem. We further assume that B reads all input points one by one, maintaining some internal state as it is reading the points, which it uses to determine whether or not to ask the label for the next point. We model this be-havior as follows: B accepts as input a sequence of points  X  x = x 1 ,...,x k along with their labels  X  y = y 1 ,...,y new point x , and returns true or false indicating whether or not to query the label for this point. Once all points have been considered, a function B h accepts all the points  X  x for which labels were asked, along with all their labels  X  y , and returns the classifier h minimizing 01-loss. Note that the label complexity of the black-box is exactly the size of se-quence  X  x , since those are points that the black-box decided to query.

Since the 01-LossWeighted problem has a penalty  X  for false negative and 1  X   X  for false positive, one can use B for solving the 01-LossWeighted problem if the distribution of false negatives and false positives is changed appropriately. This can be done simply by rejecting a positive point with probability 1  X   X  and a negative point with probability  X  . However, given just a point we do not know its label, and thus cannot decide its rejection probability. To overcome this we query B to check whether or not query the point X  X  label, and if it returns true , we use the label to set the re-jection probability. This procedure works, but since we are rejecting even labeled points, the label complexity takes a hit.

The algorithm formally corresponding to the above intu-ition is defined in Algorithm 2. It begins with empty se-quences  X  x ,  X  y for points and their labels. It then repeat-edly picks a new point, and uses the black-box to determine whether or not to query the point X  X  label. The black-box is provided all points  X  x and their labels  X  y . If the black-box de-cides not to query the point, it is ignored and the algorithm moves to the next point. Otherwise, the points label is de-termined, and used to determine the rejection probability. If the point is rejected, then it is ignored even though its la-bel has already been queried. Otherwise, the point is added to the sequence of labeled points  X  x . Finally, the black-box is fed all the labeled points in  X  x and their labels, and the returned classifier is output.

Since RejectionSampling algorithm is randomized, we can only show probability bounds on its optimality and la-bel complexity. The following theorem shows that w.h.p the objective value of the returned classifier is within O (1 / away from the optimal. Additionally, it shows that label complexity is bounded in expectation. The same label com-plexity bound can be shown to hold w.h.p.

Theorem 3.3. Let h rs be solution returned by the Re-jectionSampling algorithm. Then with probability at least 1  X   X  , the difference in the objective value of h optimal is at most O ( p log  X /n ) . Furthermore, the expected label complexity of the algorithm is at most max (  X  1  X   X  times the label complexity of the black-box B for the 01-Loss problem.

Proof. Denote FN ( h ) ,FP ( h ) the set of false negatives and false positives for a classifier h . Since some false posi-tives and false negatives are rejected in a random run of the RejectionSampling algorithm, denote for a point x , r ( x ) the random variable equal to 1 if x is selected in tionSampling , and 0 if it is rejected.

The black-box B essentially minimizes the objective Obj ( h ) tation E ( h ) of Obj ( h ) over the coin tosses of the algorithm the 01-LossWeighted problem. Using Hoeffding, we can say that w.p. 1  X   X  , Obj ( h ) deviates from its expectation E ( h ), by at most O ( p log  X /n ).
 This shows that If h  X  is an optimal classifier for the 01-LossWeighted problem, w.p. 1  X   X  , | Obj ( h  X  )  X  E ( Obj ( h is bounded by O ( p log  X /n ). Similarly, w.p. 1  X   X  , | Obj ( h E ( Obj ( h rs ) | is bounded by O ( p log  X /n ). Now we know that since the black-box returned h rs , Obj ( h rs )  X  Obj ( h Since h  X  is optimal for the 01-LossWeighted problem, and E ( h  X  ) the objective for the same, we know E ( h  X  )  X  E ( h This shows that difference in Obj ( h rs ) and E ( h  X  ) is no more than O ( p log  X /n ). Hence proved.

The proof of expected label complexity follows directly from the expected number of labeled examples rejected by the RejectionSampling algorithm.
Now we describe our overall approach. We do not in-troduce new techniques here, but explain and analyze how the various algorithms are run together. We begin by run-ning the ConvexHull algorithm for solving the Recall problem. During its run, ConvexHull might make calls to its black-box for solving the 01-LossWeighted problem. Whenever a call is made, we invoke a run of the tionSampling algorithm. When that in turn makes a call to its black-box for solving the 01-Loss problem, we invoke a run of the IWAL algorithm [5 ]. We describe this process in detail below. We also compute the label complexity of the overall process.
 Run of ConvexHull algorithm: We use ConvexHull algorithm to solve an instance of the RecallWeighted problem with  X  = 1  X  1 / log n . Note that the objective instead of fn ( n ) n that we need to do for solving the Recall problem. However, since  X  = 1  X  1 / log n is very close to 1, the two objectives can be shown to be at most 1 / log n away from each other. Thus an approximate solution for Recall-Weighted for this  X  is a good approximate solution for the Recall problem. Here we solved RecallWeighted instead of Recall to ensure bounded labeled complexity when running the RejectionSampling algorithm, which we discuss next.
 Run of RejectionSampling algorithm: During the above run of ConvexHull algorithm, whenever a call to the black-box for solving the 01-LossWeighted problem is made, we invoke the RejectionSampling algorithm. Note that the objective for the 01-LossWeighted problem is given by X ( h ) +  X Y ( h ), which expands to Thus RejectionSampling algorithm solves an instance of 01-LossWeighted problem with This  X  0 determines the rejection probabilities and the label complexity of the RejectionSampling algorithm. Finally, when the run is complete, we return the output classifier to the ConvexHull algorithm Run of IWAL algorithm [5 ]: During the above run of RejectionSampling algorithm, whenever a call to the black-box for solving the 01-Loss problem is made, we invoke the IWAL algorithm, which is described in detail in [ 5]. We only use it as a black-box here, and return its output to the RejectionSampling algorithm.

Now we reason about the total number of examples that are queried in the above process.

Theorem 3.4 (Overall label complexity). The la-bel complexity of our overall approach is at most O (log times that of the IWAL algorithm. Since IWAL algorithm has a label complexity of O ( error ( h  X  ) n X  + overall label complexity is O (2 log 2 n error ( h  X  ) n X  + Under certain distributional assumptions [5], this label com-plexity is sublinear.

Proof. From theorem 3.1 , the label complexity of Con-vexHull is 2 log n times that of the black-box Rejection-Sampling used in the algorithm. Further, since we can show that Since is a constant independent of n , max (1 / X  0 , 1 / (1  X   X  is O (log n ). Thus from Theorem 3.3 , the label complexity of
RejectionSampling is at most O (log n ) times the label complexity of the black-box IWAL used. Finally, since the IWAL complexity is O ( error ( h  X  ) n X  + in Theorem 2.2 , we get the required result.
The work related to us can be placed under three cate-gories. We describe each of them in turn.
 Entity Matching. Many techniques have been proposed for the entity matching problem [ 14 , 21 ]. The ones most rel-evant to us are learning-based techniques that train a clas-sifier over labeled pairs of examples. These include naive bayes [31 ], decision trees [8 ], SVMs [6 ]. All of these tech-niques are fully supervised, i.e., they do not try to reduce the label complexity by choosing the pairs whose labels to request. To reduce the number of labeled examples, [20 ] describes an algorithm that uses a heuristic string similar-ity function and then samples pairs having varied similarity scores. The algorithm cannot directly be applied for active learning as it is only for training data selection, but can in fact be used in conjunction with our active learning algo-rithm as a preprocessing step to select the pool of candidate pairs. Another training set construction method for dedu-plication is the described in [ 7]. The training examples se-lected by this approach are a mixture of examples with high textual similarity and randomly sampled examples. In con-trast to this static approach, our active learning algorithm is more dynamic and systematically explores the example space while also providing guarantees on precision.
 Active learning for entity matching. Several authors have previously studied the application of active learning to entity deduplication problems [9 , 25 , 26 , 28 ]. However, these approaches do not provide any guarantees in terms of precision or recall, which is undesirable for datasets with highly imbalanced classes.

The previous work most similar to ours is [1 ], which also provides an active learning algorithm to maximize recall un-der a constraint that precision should be greater than a specified threshold. Their algorithm essentially performs a binary search in the high-dimensional parameter space by assuming monotonicity in precision with respect to param-eters. In the worst-case the algorithm queries the labels of all the examples and its computational complexity is ex-ponential in the number of parameters. Our approach, in contrast, provides guarantees on precision while being computationally and label efficient. In addition, it does not require a monotonicity assumption which may not hold in general and therefore can be applied to other imbalanced classification problems.
 Active learning for general classification. Our method is also related to active learning for classification tasks. There is a large and growing body of work [ 27 ] on active learning for binary classification. A good summary of recent theoret-ical work in the area is provided in [13 ]. However, almost all related work on active learning for the general binary classification problem focuses on 0-1 loss minimization. We described two such related works in Section 2. In our work, we use IWAL [ 5] as a black-box active learner for 0-1 loss.
To our knowledge, [ 4] is the only active learning algo-rithm that minimizes general loss functions in addition to 0-1 loss. However, the algorithm cannot perform constrained optimization required for ensuring our precision constraint. Furthermore, no direct efficient implementation of algorithm is known for the class of linear classifiers. Previous ap-proaches [2 , 12 , 16 ] also require maintaining a candidate set of hypotheses (called a version space), which is computation-ally infeasible. Recent agnostic active learning approaches, which our algorithm builds upon, achieve sub-linear label complexity [2 , 4, 5, 16 ] when assumptions are made about low label noise in the data distribution. It is also known that under unbounded noise models, sub-linear label complexity is impossible [3 , 17 ]. An exponential improvement in label complexity for unbounded noise was shown recently but it assumes that data has multiple views [ 29].

The majority of active learning research has focused on querying the most informative examples needed to learn the classifier. More recent papers have also considered querying representative examples [11 ], and querying examples that are both representative and informative [ 18].
In this section, we describe our experimental setup (Sec-tion 5.1 ) and present results comparing our approach against a previous state-of-the-art algorithm [ 1] on several real-world datasets (Section 5.2 ).
A brief description of the four real-world datasets used in our experiments is shown in Table 1. These include:  X  Business : This is a dataset of local business listings used  X  Person : This is a record linkage dataset from the UCI ma- X  DBLP-ACM [20]: This is a large bibliography record link- X  Scholar-DBLP [20]: This is a dataset of 589,326 pairs The last three datasets are highly imbalanced.
We implement three algorithms for active learning.  X  monotone : This is our implementation of the algorithm  X  vw : This is an implementation of the IWAL algorithm [ 5]  X  cvhull : This is an implementation of both Convex-Note that all of our datasets consist of labeled examples. The active learning algorithms are run on the datasets as follows: as the active learning algorithm reads the exam-ples the labels are kept hidden. Whenever the algorithm requires a label for a specific example, its label is read from the dataset and given to the algorithm. This cuts out the need for a human involvement of labeling during our exper-iments.
In Fig. 1, we report the F-1 achieved by monotone and cvhull on all datasets, as the threshold used for the preci-sion constraint is varied. We do not report the F-1 for vw since it returns classifier that often violates the precision constraint. The graphs show than cvhull has consistently higher F-1 that monotone over all datasets and precision thresholds. The difference in F-1 between the two algorithms is as big as 0 . 15 in some cases, but becomes smaller (around 0 . 05 on average) for highest precision threshold of 0 . 9. While this difference is still significant, it does indicate that the gains at high precision thresholds are limited, possibly ow-ing to limited choices of classifiers satisfying the precision constraint.

In Fig. 2, we report the number of queries required by monotone and cvhull on all datasets, as the threshold used for the precision constraint is varied. We again do not report the number for vw , since it returns a classifier that often violates the precision constraint. The graphs show that cvhull requires significantly lower number of queries than monotone on all but 2 cases. The difference in number of examples is particularly stark for Person and Scholar-DBLP datasets, sometimes more than 3000 examples. A particularly attractive property of cvhull is that it learns the classifier in around 500 points for all but one datasets and all threshold values.

In Fig. 3, we compare the computation time for the two algorithms monotone and cvhull as the number of di-mensions is varied for the Person dataset. The figure clearly demonstrates that monotone has an exponential complex-ity w.r.t number of dimensions, while cvhull has an almost a constant dependence.

In Fig. 4, we show that that vw often fails to produce a Dataset Schema Size Ratio (+/-) Blocking Function Features
Business name(N), street(S), city(C), zip(Z), 3958 0 . 115 Jacc (N)  X  0 . 2, Jacc (S)  X 
Person first-name(F), last-name(L), sex(S), birth-574913 0 . 004 SoundEQ (F), SoundEQ (L), Figure 3: The computational complexity of the two algo-rithms as the dimension is varied. Figure 4: The constraint satisfaction percentage of vw ac-tive learning algorithm over 10 random runs for different datasets. feasible classifier, i.e. one that satisfies the precision con-straint. The graph plots the success rate, i.e. the fraction of times, over 10 random runs, the algorithm outputs a fea-sible classifier. Obviously as the precision threshold is in-creased, number of feasible classifiers decrease, and so does the success rate. This graph demonstrates the need for the ConvexHull and RejectionSampling algorithms used in cvhull on top of vw .
In this paper, we proposed an active learning algorithm for the entity matching problem. The algorithm tries to learn a classifier with maximum recall under a constraint that its precision should be greater than a given threshold. The algorithm uses any of the existing active learning tech-nique for minimizing 01-loss as a black-box. We showed that the algorithm outputs a classifier having recall close to the optimal, and has good label and computation complexity. We also compared the algorithm against the state-of-the-art active learning algorithm for entity matching, and show that we outperform it in terms of metrics such as F1 of the trained classifier, number of labeled examples required, and computation time on several real-world datasets. [1] Arvind Arasu, Michaela G  X  otz, and Raghav Kaushik. [2] Maria-Florina Balcan, Alina Beygelzimer, and John [3] Maria-Florina Balcan, Andrei Z. Broder, and Tong [4] Alina Beygelzimer, Sanjoy Dasgupta, and John [5] Alina Beygelzimer, Daniel Hsu, John Langford, and [6] Mikhail Bilenko and Raymond J. Mooney. Adaptive [7] Mikhail Bilenko and Raymond J. Mooney. On [8] Surajit Chaudhuri, Bee-Chung Chen, Venkatesh [9] Peter Christen. Probabilistic data generation for [10] David Cohn, Les Atlas, and Richard Ladner.
 [11] Sanjoy Dasgupta and Daniel Hsu. Hierarchical [12] Sanjoy Dasgupta, Daniel Hsu, and Claire Monteleoni. [13] Sanjoy Dasgupta and John Langford. Tutorial [14] Ahmed K. Elmagarmid, Panagiotis G. Ipeirotis, and [15] A. Frank and A. Asuncion. UCI machine learning [16] Steve Hanneke. A bound on the label complexity of [17] Steve Hanneke. Adaptive rates of convergence in [18] Sheng-Jun Huang, Rong Jin, and Zhi-Hua Zhou.
 [19] Nikos Karampatziakis and John Langford. Online [20] Hanna K  X  opcke and Erhard Rahm. Training selection [21] Hanna K  X  opcke and Erhard Rahm. Frameworks for [22] Andrew McCallum, Kamal Nigam, and Lyle H. Ungar. [23] Paul Mineiro. Cost-Sensitive Binary Classification and [24] Franco P. Preparata and Michael I. Shamos.
 [25] Steffen Rendle and Lars Schmidt-Thieme. Active [26] Sunita Sarawagi and Anuradha Bhamidipaty.
 [27] Burr Settles. Active learning literature survey. [28] Sheila Tejada, Craig A. Knoblock, and Steven Minton. [29] Wei Wang and Zhi-Hua Zhou. Multi-view active [30] Steven Euijong Whang, David Menestrina, Georgia [31] William E. Winkler. The state of record linkage and [32] Bianca Zadrozny, John Langford, and Naoki Abe.
