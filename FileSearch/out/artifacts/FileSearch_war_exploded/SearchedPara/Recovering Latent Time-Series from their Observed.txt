 Hidden variables, evolving over time, appear in multiple se t-tings, where it is valuable to recover them, typically from o b-served sums. Our driving application is  X  X etwork tomogra-phy X , where we need to estimate the origin-destination (OD) traffic flows to determine, e.g., who is communicating with whom in a local area network. This information allows net-work engineers and managers to solve problems in design, routing, configuration debugging, monitoring and pricing. Unfortunately the direct measurement of the OD traffic is usually difficult, or even impossible; instead, we can easily measure the loads on every link, that is, sums of desirable OD flows.

In this paper we propose i-FILTER, a method to solve this problem, which improves the state-of-the-art by (a) in -troducing explicit time dependence, and by (b) using real-istic, non-Gaussian marginals in the statistical models fo r the traffic flows, as never attempted before. We give experi-ments on real data, where i-FILTER scales linearly with new observations and out-performs the best existing solutions , in a wide variety of settings. Specifically, on real network tra f-fic measured at CMU, and at AT&amp;T, i-FILTER reduced the estimation errors between 15% and 46% in all cases.  X  This author thanks the Data Privacy Laboratory and the Center for Automated Learning and Discovery (CALD) at Carnegie Mellon University for their support.  X  This author thanks the support by the National Science Foundation under Grants No. IIS-0083148, IIS-0113089, IIS-0209107, IIS-0205224, INT-0318547, SENSOR-0329549, EF-0331657, IIS-0326322 and by the Pennsylvania Infras-tructure Technology Alliance (PITA) Grant No. 22-901-0001. Additional funding was provided by donations from Intel, and by a gift from Northrop-Grumman Corporation. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation, or other funding parties.
 Categories and Subject Descriptors: I.2.6 [Artificial Inteligence]: Learning General Terms: Algorithms Keywords: Origin-Destination Traffic Flows, Link Loads, self-organizing Bayesian Dynamical System, MCMC, Parti-cle Filter, Informative Priors, Empirical Bayes
Knowledge about the origin-destination (OD) traffic ma-trix allows network engineers and managers to solve prob-lems in design, routing, configuration debugging, monitori ng and pricing; in fact the OD traffic matrix provides valuable information about who is communicating with whom in a network, at any given time. Unfortunately the direct mea-surement of the OD traffic is usually difficult, or even infea-sible, in real networks. The direction of current research i s to develop methods to infer the OD traffic flows from ob-served traffic loads on the links of the network, however the methods that have been proposed so far seem not to fully take advantage of two of the main empirically observed fea-tures of network traffic; namely its very skewed marginal distribution, and its time dependent nature.

In this paper we present i-FILTER, an intelligent filtering method which improves the models present in the literature by introducing two realistic assumptions: i-FILTER uses a two-stage estimation procedure: estimates the pattern of time-dependencies, and eventually uses it to gain in precision.
In our experiments, using the best log-Normal model re-duced the estimation error of previously proposed meth-ods by 35%, and the introduction of explicit stochastic dy-namical behavior reduced the estimation error up to 46%. The magnitude of the improvements entailed by the sim-ple ideas we propose goes far beyond that of state-of-the-ar t re-sampling schemes that could be used to refine any given set of estimates. Further a stochastic dynamical behavior played an essential role in our models; it served as the right channel where to introduce prior information about the OD flows, gained in stage-one of our procedure.

The rest of the paper is organized as follows: Section 2 describes the problem and the relevant issues in more detail . Section 3 surveys the relevant literature. Section 4 descri bes our proposed methodology. Section 5 reports the results of our experiments on real data. Section 6 discusses our main findings and their relevance towards our solution to the problem, and Section 7 concludes with some final remarks and future research directions.
In this paper we write M for matrices, v ( t ) for column vectors at time t , and v ( i, t ) for their generic component i .
We begin by defining the problem, introducing the rele-vant issues, and discussing related works.
In a formulation of the problem we want to solve there are several time series which we would like to estimate, but which we cannot observe, say, a vector of traffic flows x ( t ) over times t = 1 , ..., T . However, we are able to observe linear combinations of these traffic flows, the vector of link loads y ( t ) over times t = 1 , ..., T , and we know which compo-nents of x ( t ) mix into each of the components y ( i, t ) at each time t trough the routing matrix A , that does not change over time. This problem can be decomposed in three sub-problems, which we now define.

Problem 1. (Network Tomography) Given the matrix of link loads Y ( `  X  T ) and a routing matrix A ( `  X   X  ) , we want to find the matrix of non-observable OD traffic flows X (  X   X  T such that Y = A  X  X . Always  X  &gt; ` .

For example, the linear equations that correspond to the routing scheme of the star network in figure 2 below are: y (1 , t ) measures the traffic load on the link from node 1 to the router and captures both the OD flow from node 1 to node 2, x (2 , t ), and the OD flow from node 1 to itself, x (1 , t ). y (3 , t ) measures the traffic load on the link from the router to node 1 and captures both the OD flow from node 2 to node 1, x (3 , t ), and the OD flow from node 1 to itself, x (1 , t ). Figure 2: Two subnetworks connect to a router in a
In the example above we want to estimate four (  X  ) un-observable quantities starting from three ( ` ) independent observations 1 . The system is under-specified,  X  &gt; ` , hence some extra information is needed in order to identify one single solution.

Problem 2. (Prejudices) Choose a set of additional con-straints to be imposed on X (  X   X  T ) in order to make the  X  X et-work tomography X  problem exactly determined.

The likelihood of the data entailed by a statistical model provides us with a natural criterion to discern  X  X ikely X  sol u-tions from unreasonable ones. Following this idea we model the unobservable quantities x ( t ) with a joint probability dis-tribution; this induces a probabilistic mapping on the spac e of the observations y ( t ) via equation 1, so that we can com-pute the likelihood of the observations, and look for traffic flows that maximize the probability of particular data ob-servations. Unfortunately in time-independent models the likelihood of y ( t ) is not necessarily unimodal, even as we as-sume independent components in x ( t ), and even as we use well-behaved functional forms for their distributions. Mo re information is needed to identify a solution.

At this point there are two main ways to introduce the extra information we need. In a purely data-driven ap-proach we would augment the data in some way, whereas in a knowledge-driven approach we would make use of infor-mative priors in a Bayesian setting, with the complication
We assume that routers neither generate nor absorb traffic. in this latter case of defining what we mean by  X  X nforma-tive X . Data augmentation can be realized, for example, by raising the likelihood of the data to a power, as in simulated annealing, or by borrowing observations from epochs close in time to the current one to obtain a smoothed average solution. Alternatively, we can build  X  X nformative X  prior s based on partial knowledge about the magnitude of the OD flows, and update using Bayes rule and a  X  X ore accurate X  data model.

Problem 3. (Speed) Solve efficiently the  X  X etwork to-mography X  problem, under the  X  X rejudices X  of problem 2.
We offer a novel solution to the  X  X rejudices X  problem, which satisfies the efficiency requirement of the  X  X peed X  prob -lem. The two-stage estimation procedure at the core of i-FILTER corresponds to a non-parametric empirical Bayes learning strategy, where the observations are used to first calibrate informative priors, and then to filter the posteri or distributions of the OD flows given the data. Our solu-tion: (1) uses realistic models for the OD flows; (2) takes advantage of the time dependence of the data while using the whole history of observations { y (1) , ..., y ( t ) } to estimate x ( t ) in a proper Bayesian fashion.
To the best of our knowledge dynamical systems have never been used to solve the  X  X etwork tomography X  prob-lem 2 . Previous works assume independent OD flows across different epochs. We use dynamical systems, which natu-rally extend previous approaches by assuming time depen-dence explicitly .

Definition 1. Gaussian linear state-space models are de-fined by the set of equations, where { e ( t ) } is an i.i.d. Gaussian process with variance-covariance matrix Q , and F is a known matrix. Further x (0)  X  Normal ( m , V ) and independent of e ( t ) for t  X  1.
Wei et al. (2002) and others use HMMs to approach a different problem, also called  X  X etwork tomography X .
In figure 3 above we show the graphical representations for the  X  X etwork tomography X  problem at subsequent time points in a static setting, and its natural extension to a dy-namic setting, by means of various state-space models (SSM henceforth). Classical state-space modeling strategies a la Box and Jenkins would look for the additional constraints needed to solve problem 2 in a known dynamical behav-ior suggested by some physical law underlying the specific problem at hand and from known seasonal patterns in the traffic, for example the laws of motion in tracking the tra-jectories of moving objects, or from the presence of strong cross-correlations among the OD flows. This knowledge would translate into constraints on F , and Q in the sys-tem 2 above, and would serve the critical role of driving the inferences towards one particular solution.
As we discussed above the  X  X etwork tomography X  prob-lem is under-specified, and allows for infinite valid solu-tions. Fienberg (1968, 1970) studied the geometry of the underlying mathematical problem and identified the (  X   X  ` )-dimensional space of solutions. By assuming specific margi-nal probability distributions for the OD flows we induce a probability map on the the space of measurements. Vander-bei and Iannone (1994) show that assuming Poisson OD traf-fic does not yield a necessarily convex probability map, and Vardi (1996) further shows that solving the likelihood equa -tions may yield local maximum whereas the actual global maximum is on the boundary, assuming Poisson traffic. Both these works assume a fixed vector of parameters for all epochs . Tebaldi and West (1998) propose a fully Bayesian framework with non-informative priors based on Poisson traffic and ac-knowledge the need for informative priors, but they do not specify how to obtain them. In fact, using the measurements at time t in order to estimate the OD flows at the same epoch, flat priors over the possible amount of traffic yield uniform or multi-modal posteriors. Their work is important in that they explore the extent to which it is possible to find a solution at each epoch without using the information entailed by past or future measurements. Figure 4: A summary of the models present in the liter-
Solutions to the problem in the non-statistical literature consider a fixed vector of parameters across all epochs as the favorite solution to overcome the lack of information entai led by the measurements. For example, a typical solution would assume traffic flows at different epochs as independent for each OD route and estimate a fixed vector of parameters by composing the constraints given by the measurements via generalized least squares. Similar solutions differ in the w ay they compose the constraints given by the measurements at different epochs; the alternatives include the assumptions of multivariate Gaussian or multinomial measurements and the composition is carried out via maximum likelihood or via Bayes theorem, or else using maximum entropy arguments, and so on. Economic approaches that explicitly deal with congestion had also been tried with success. As we noted above, these solutions all assume an underlying fixed vector of parameters which governs the OD traffic at all epochs, and we can express them as solutions of a common minimization problem (Airoldi 2003, Zhang et al. 2003).

Several of these time-independent solutions have been ap-plied locally in order to get a time-varying solution for the OD flows, otherwise constant across time. A drawback of such approaches is that they cannot obtain estimates for the OD flows corresponding to several measurements. For ex-ample, a window of 11 observations would not inform about the first and last 5 OD flows (  X  25 mins). A recent ap-proach due to Cao et al. (2000) assumes multivariate Gaus-sian OD flows, i.i.d. across time. However, they propose a clever parametrization with several desirable propertie s which yields reliable estimates. Further Cao et al. (2001) show how to estimate OD traffic flows in bigger networks by solving sub-problems and then composing their solutions. Medina et al. (2002) compare several methods and survey the literature. Zhang et al. (2003) propose a gravity model for the OD traffic, and use Stein X  X  shrinkage estimator to refine their estimates.
The log-Normal distribution has never been used to model the OD traffic flows, however several works support this distribution for traffic in communication networks and over the Internet. Empirical studies and theoretical models tha t recreate realistic traffic flows from underlying processes co n-sistently come to the conclusion that network traffic flows are skewed and bursty, see Mandelbrot (1965), Leland et al. (1993), Coutin and Carmona (1998), Sarvotham et al. (2001), Wang et al. (2002), and Cao et al. (2002). Most of the skewed distributions follow the characterization gi ven by Zipf (1932), and its generalizations given by Mandelbrot (1953) and Bi et al. (2001). In particular Bi et al. show that the truncated log-Normal distribution is flexible enough to fit a wide variety of such observed behaviors. We show the log-log plots for the two data sets we used in figure 6 below.
Ghahramani and Hinton (1996) show how to learn all the parameters in the system 2, in our case F , Q , m , and V , by means of the EM algorithm. Higuchi (2001) shows how a self-organizing system can be built from non-linear non-Gaussian systems, so that all the relevant parameters are learned during the filtering process. Gilks and Berzuini (2001) propose a particle filter that keeps particles divers e.
Briefly, i-FILTER uses a two-stage approach to the filter-ing problem. In the first stage we find preliminary, smooth estimates for the OD flows, which make a good guess for the averages of the OD traffic, and in the second stage we refine these smooth estimates by looking for spikes and bursty pe-riods with one single pass over the data. We model the OD flows as Bayesian dynamical systems, and we use a EM and particle filter as learning algorithms 3 .
 Figure 5: A non-parametric empirical Bayes approach
More specifically, we use the linear Gaussian SSM and re-lated EM steps proposed in Airoldi and Faloutsos (2004), which includes the model in Cao et al. (2000) as a special case, to obtain smooth estimates of the OD traffic, and we then use these estimates to calibrate informative priors fo r the parameters underlying the dynamic of a non-Gaussian system, in non-parametric empirical Bayes fashion. Even-tually the particle filter makes good use of these priors and of the skewed models, and finds a sequence of better poste-rior distributions for the traffic flow on each OD route; we pick their means as point estimates. Our experiments show i-FILTER achieves an error 15% to 46.5% smaller than that of state-of-the-art methods in all cases.
In our experiments on Carnegie Mellon origin-destination traffic we noticed that assuming a fixed relationship between x ( i, t ) and x ( i, t + 1) is an unrealistic constraint. Our solu-tion is to assume a relationship between the means of the OD flows  X  ( i, t ) and  X  ( i, t +1) instead, and to allow for some error. The SSM yields smooth estimates that capture infor-mation about this relationship, which we pass to the next estimation stage. In fact, we introduce soft constraints on the average process {  X  ( t ) t  X  1 } in the form of informative priors for the parameters underlying its dynamical behavio r.
An implementation of i-FILTER described in this paper is available for the open source R environment, on request. We reduce the number of parameters by merging dynamic and error terms into a stochastic dynamical behavior. The marginal models for the OD traffic flows are independent log-Normals 4 . The main objects of interest are then the the point estimate for the OD traffic vector at time t is given by the mean  X  x ( t ) = E ( x ( t ) | y (1) , ..., y ( t ) ).
The static version of i-FILTER considers independent prob-lems at each epoch. Briefly, we are interested in estimating at each time t we write: where p is log-Normal, parametrized so that E ( x ( i ) |  X  ,  X  ) = i = 1 , ...,  X  and i 6 = j . Notice that  X  is common across OD flows at each epoch, and that  X  is a known scalar, which we obtain by inspection of Y . The priors for the  X  ( i ) are for i 6 = j . The prior for  X  is proportional to a constant, to 1 / X  or to 1 / X  2 .
This dynamic version of i-FILTER, which yields the best results, implements the following Bayesian dynamical sys-tem: where p is log-Normal, parametrized so that for i = 1 , ...,  X  tice that  X  ( t ) is common across OD flows at time t , and that  X  is a known scalar, which we obtain by inspection of Y . The priors for  X  ( i, 0) are log -Normal (  X  ( i, 0) ,  X  ) i = 1 , ...,  X  and independent for i 6 = j , and for a big num-ber  X  that accounts for the uncertainty of the means of OD flows at time zero. The prior for  X  ( t ) is proportional to a constant, to 1 / X  ( t ) or to 1 / X  ( t ) 2 . The priors for ( i, t ) are dent for i 6 = j .
The crucial question at this point is: how do we cali-brate the hyper-parameters underlying the prior distribu-tions of  X  ( t )? First we obtain a preliminary set of estimates  X  x ( t ) with the Gaussian linear SSM. Then, in the case of i-FILTER static, (  X  1 ,  X  2 ) at each time are set so that mean and variance of  X  correspond to those of  X  x ( t ). Variances can be made much larger without significant loss of preci-sion. The intuition is that the preliminary estimates indic ate us where OD flows are on average. In the case of i-FILTER dynamic the intuition is the same, however it is not possi-ble to set priors for  X  ( t ) as the sequence {  X  (1) , ...,  X  ( T ) } is going to be determined by  X  (0) alone. The solution is then
Airoldi (2003) also considers Gamma models.
Airoldi (2003) also considers Gamma, Uniform, and trun-cated Gaussian priors. to extract from {  X  x (1) , ...,  X  x ( T ) } information about their lo-cal dynamical behavior and use it to calibrate informative priors for { ( t ) , t  X  1 } . Technically, we set ( i, t ) as inde-pendent log-Normals; we use the facts that product convo-lution of log-Normals is log-Normal (equation 4), and that log -Normal (  X  1 ( i, t ) ,  X  2 ( i, t )) = exp { N (  X  solve the convolution problem exactly for (  X  1 ( i, t ) ,  X  for i = 1 , ...,  X  . In other words, values for (  X  1 ( t ) ,  X  computed from (  X  x ( t ) ,  X  x ( t  X  1)) at each time, and these pa-rameters need not be learned.  X  ( i, 0) is set to be the average of corresponding OD flow { x ( i, t ) , t  X  1 } .

Notice that every two-stage method that finds prelimi-nary estimates and refines them uses {  X  x (1) , ...,  X  x ( T ) } in the second stage, in some way. We prefer to translate this infor-mation into information about the means of the OD flows {  X  (1) , ...,  X  ( T ) } , according to the intuition that preliminary estimates can identify a smooth version of the OD flows we are looking for, which make reasonable guesses for their un-derlying average processes.
In order to filter the posterior distributions of the origin-destination flows and estimate the parameters of the mod-els, i-FILTER implements a slight variation of the sample-resample-move algorithm of Gilks and Berzuini (2001), whic h we briefly outline below. For simplicity define v ( t ) to be the vector of all parameters in the model at time t , v ( t ) := ` x ( t ) ,  X  ( t ) , ( t ) ,  X  ( t )  X  , and v (0) := `  X  (0) Algorithm 1. Enhanced Particle Filter:
At t = 0 generate N particles {  X   X  ( i ) (0) } N i =1 using  X  (0) ,  X  . 1. Set t = t + 1 . Move each particle like so: (a) generate 2. Resample N new particles from {  X  v ( i ) ( t ) } N i =1 3. Move the new set of particles according to a MCMC
For details about the MCMC see Airoldi (2003).
A recent result in network tomography (see Cao et al. 2001) is that it is possible to reformulate filtering problem s corresponding to complex networks as a sequence of prob-lems corresponding to small, simple networks.
 Lemma 1. The complexity of i-FILTER is O (  X   X  T ) .
Proof. We use results by Cao et al. (2001) which imply that a tomography problem corresponding to a network with  X  origin-destination flows is equivalent to O (  X  ) tomography problems, which correspond to disjoint sub-sets of, say, on e to four OD traffic flows in the original problem. This fact along with the fact that our solution is linear in the number of time points for which the OD traffic need be filtered, yields a total complexity of O (  X   X  T ) for i-FILTER.
Lemma 1 implies if we solve the  X  X etwork tomography X  problem for small size networks, we immediately solve it for arbitrary size networks with comparable estimation errors . Further the following result holds: Lemma 2. i-FILTER is based on an irreducible MCMC. Proof. See Airoldi (2003)
Lemma 2 implies that i-FILTER is able to explore the support of the whole joint posterior distribution of the OD flows. A proof of this fact is needed since the MCMC uses a Gibbs sampler with Metropolis steps.
We had two data sets available. Both of them included validation data. The analysis of Carnegie Mellon origin-destination traffic flows supports the hypothesis of a very skewed distribution. In figure 6 we plotted the logarithms of the observed flows versus the logarithms of the number of times measurements of such a size appear (aka. log-log plot), after discarding t he measurements smaller than a standard packet (53 bytes = 424 bytes). The log-log plot indicates a log-Normal distri-bution may be appropriate. A histogram of the logarithms of the flows indicated that a logarithmic transformation is actually too mild to remove all the skewness, and a dou-ble logarithmic transformation would be more appropriate. The AT&amp;T data set is much smaller, and contains traffic flows generated on a smaller network; they are less skewed overall, and a logarithmic transformation is enough to yiel d a symmetric histogram for the truncated flows.
We used the CMU data set to drive our modeling choices, on star network topologies. In order to test both the per-formance of i-FILTER and the robustness of its underlying log-Normal model we eventually set the CMU data aside, and used the AT&amp;T data set as an independent validation data set.

Recall, as we noted in section  X  4.3 above, that it is possible to break down a big filtering problem on a complex network into a sequence of smaller problems on (disjoint) simple sta r networks. Hence, it was enough to test the performance of our methods on the simple star network in figure 1, com-posed by one router and two nodes connected to it. We used subsets of non-observable origin-destination flows from th e AT&amp;T data set, to generate the link loads corresponding to the simple star network topology above, and then compared the estimation errors of the competing methods in the task of reconstructing the non-observable OD flows. Combining realistic models and time dependence into i-FILTER reduced the error obtained with local likelihood between 15.0% and 46.5%. We performed experiments to answer the following questions: 1. Skewed Marginals: what is the impact of skewed model 2. Time Dependence: what is the impact of explicit time 3. Informative Priors: what constraints should we im-4. Scalability: does our algorithm scale well with the prob-We were most interested in assessing the differential impact on the estimation error of our novel ideas, as opposed to the methods present in the literature. That is, we measured the goodness of the competing methods by computing the corresponding estimation errors, as given by the ` 2 distances between the true OD flows in the validation set and the estimates. The best results were obtained with log-Normal distribution for the flows and Gaussian vague priors.
To isolate the effect of realistic distributions for the OD flows, we compared the estimates obtained with i-FILTER where no time dependence was assumed, for Gamma and log-Normal models, and a variety of non-conjugate priors (Uniform, Gaussian, Gamma,l log-Normal) and different pa-rametrizations, with the estimates obtained by local likel i-hood. Introducing realistic model reduced the error betwee n 25.4% and 40.8%. See figure 7.
To isolate the effect of explicit time dependence, we com-pared the estimates we obtained with the gaussian linear SSM in Airoldi (2003) that uses independent AR(1) pro-cesses for the OD flows, with the estimates obtained with local likelihood. Introducing time dependence reduced the error by 15.5% on average; the reduction ranged between 8.5% and 31.0%. See figures 7 and 8.
In 60% of the time points uninformative priors yielded flat or multi-modal posteriors, whereas in the remaining 40% of the time points uninformative priors yielded wide uni-moda l posteriors. In the static case, the effect of one data point, ble configurations receive zero posterior probability. On t he other hand, informative priors with wide variance all yield ed uni-modal distributions. Further, they have the advantage of requiring fewer particles than uninformative priors; kn ow-ing where to sample may introduce bias, but the thick tails of the log-Normal distribution of both x ( t ) |  X  ( t ) ,  X  ( t ) and ture several of the hidden spikes. See figures 10 and 12. i-FILTER reconstructs the OD flows with one single pass over the data; the first stage of the procedure and the cali-bration of the priors are also linear in the problem size, as w e compute the posterior distributions using the gaussian lin -ear SSM on a large sliding windows, for example. Figure 9 below shows that in less than one hour i-FILTER calibrates the informative priors and recovers the flows corresponding to one-day worth of data for the small network in figure 2, on a Powerbook G4 1.25Ghz. Figure 9: i-FILTER scales linearly with the problem size (number of time ticks).
In this paper we propose i-FILTER, a two-stage procedure which naturally fits in a non-parametric empirical Bayes framework. i-FILTER reduced the estimation error 6 in all cases, and on average between 15% and 46.5%, when com-pared to state-of-the-art methods on real traffic data. Such improvements (see figure 11) are due to three factors: 1. realistic log-Normal distributions for the OD flows, 2. dynamical systems as a natural way to deal with data 3. informative priors calibrated via empirical Bayes, Further, i-FILTER scales linearly with the size of the prob-lem. Briefly, we recover a smooth version of the OD flows, we use it to calibrate informative priors for some crucial para m-eters, and eventually we use a Bayesian dynamical system to refine the estimates and capture bursty traffic. This method-ology allows us to combine the three simple ideas above: a realistic model for the data, the use of a filtering scheme which takes advantage of time, probabilistic constraints t o overcome the under-determinacy of the problem.
 More in detail, in the first stage we use the Gaussian linear SSM proposed in Airoldi and Faloutsos (2004) to estimate a smooth version of the OD traffic, and we calibrate informa-tive priors for  X  ( t ) using these estimates. These priors incor-porate information about the magnitude and the dynamical behavior of the OD traffic flows on average , and softly con-strain the location of the average processes {  X  ( t ) , t  X  1 } . Other methods proposed in the literature make use of pre-liminary estimates, but they only retain the information about the magnitude of the OD flows given by the such es-timates in the refining stage  X  see for example Zhang et al. (2003) who use shrinkage to improve the solutions given by a gravity model. In our method, the fact that we retain also the information about the local dynamical behavior yields a significant jump in the final accuracy. Another channel
Measured in ` 2 distance from the true OD flows. through which informative priors help achieve a better ac-curacy is by reducing the bias entailed by multiple modes in the posterior distributions. Making the posteriors more uni-modal improves the precision of the point estimates of the OD flows (the posterior means) as we show in figure 10 be-low. Informative priors do drive the inferences about the OD flows towards the preliminary guesses, however the two lay-ers of our model and the use of soft probabilistic constraint s entail enough flexibility to capture several of the spikes in many cases, for an example see figure 12 below. Further our first-stage estimates are safely based on a model which entails a one-to-one relationship between OD flows and mea-surements, as it includes the model by Cao et al. (2000) as a special case.

In the second stage the primary object of interest becomes estimates for the OD flows at time t . The Bayesian dy-namical system brings further improvements, as we show in figure 8 above, due to the fact that we make use of all the observations up to time t in computing the posterior distributions P ( x ( t ) | y (1) , ..., y ( t ) ); conditioning on more observations yields a narrower variability. Local methods use fewer observations in a short window around t , instead. The improvement i-FILTER achieves goes beyond the con-tribution of state-of-the-art methods even when combined with recent resampling schemes which improve any given set of estimates.
In this paper we described i-FILTER, a two-stage estima-tion method that combines three simple ideas: 1. log-Normal models to account for skewed, and bursty 2. a novel Bayesian dynamical systems to take advantage 3. informative priors as soft constraints to overcome the
We offer simple heuristics to understand our modeling choices; first-stage estimates capture smooth average pro-cesses, second-stage estimates capture the spikes. We test ed our methodology on star topologies using real traffic mea-sured at Carnegie Mellon (12100 OD flows) and AT&amp;T (16 flows) and reduced by 15% to 46.5% the estimation error ob-tained with state-of-the-art methods, in all cases. Finall y, we provided a solution to the problem of how to calibrate in-formative priors in our Bayesian dynamical systems, where no clear guidance about the dynamic of the hidden OD flows is available. In the future we plan to explore whether peri-odic traffic patterns may also be discovered successfully.
The authors thank Dr. Stephen E. Fienberg for engaging discussions, Dr. Jin Cao, Dr. Srinivasan Seshan, Dr. Rus-sel Yount and Dr. Frank Kietzke for providing the traffic data measured at AT&amp;T and at Carnegie Mellon University, which made this work possible, Dr. Irina Rish and Dr. Alina Beygelzimer at IBM T.J. Watson for helpful comments.
