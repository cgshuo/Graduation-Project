 1. Introduction
Nowadays, semiconductor manufacturing operates in an intense competitive environment. Companies working in this industry are striving to improve process quality while also improving production equipment effectiveness. In recent years, research has been focused on virtual metrology ( Min-Hsiung et al., 2007 ; Ferreira et al., 2009 ), dynamic control plan ( Bettayeb et al., 2011 ), maintenance and Fault
Detection and Classification (FDC) ( Hong et al., 2012 ). However, these remain challenging areas. Semiconductor ma nufacturing is a complex process, and a variety of equipment (as shown in Fig. 1 ), including production and metrology equipment, continues to demonstrate a natural drift. If this drift becomes larger than the threshold value, it might result in propagation of significant failures, immediately affecting the production process and leading to a large number of products in the manufac turing process being scrapped.
Therefore, it is critical to precisely and quickly locate the causes of failures for repair and maintenance purposes. Diagnosis solutions are then proposed. In this field of research, a number of approaches have been proposed including Fanti and Seatzu (2008) , Cabasino et al. (2010) , Genc and Lafortune (2003 , 2005) , Ru and Hadjicostis (2009) , Ruiz-Beltran et al. (2006) and Elodie et al. (2010) .
However, these approaches do not allow for uncertainty of feedback information to be easily taken into account. A key part of our approach is on-line confiden ce (uncertainty) computation based on the historical data and feedback information generated by production equipment. Several studies have been proposed to address the uncertainty related to diagnosis. Hong et al. (2012) presented an FDC approach, using a neural network in plasma etching, followed by investigation of the uncertainty associated with fault diagnosis. The evidential reasoning method via the Dempster X 
Shafer (DS) theory was used in this approach. Chavez et al. (2011) consider confidence of measured i nformation uncertainty in quali-tative reasoning. Info rmation uncertainty can be quantified via measurements of non-specificity and conflict. The fuzzy sets method is used to determine the qualitative level of confidence for both AR (Approximate Reasoning) and ER (Evidential Reasoning) inference mode vector results associated with each scenario based on the available information. However, the confidence value is limited to a finite set of elements, e.g. {Very High, High, Medium, Low, Very
Low}, and this method has identified a scenario that is a series of actions and events. Thus, these are inconsistent with the context and our issue. Simon and Weber (2006) focuses on methods for model reliability uncertainty. This appro ach proposes a specific integration of the Dempster X  X hafer (DS) theory in Bayesian Network (BN) tools in order to handle the epistemic uncertainty problem and use the advantages of Bayesian Network tool power to model system reliability ( Cobb and Shenoy, 2003 ). Nevertheless, this approach handles only the epistemic uncertainty of the system state according to epistemic uncertainty of component state without considering other system factors such as production context, type of products, variations in production and product specification.
 to an on-line diagnosis system ( Deschamps and Zamai, 2007 )to help human operators locate equipment at the origin of a failure and analyze the impacts of failures in Automated Manufacturing
Systems. The extensive approach is mainly based on calculation of confidence of feedback information derived from production equipment. Particularly, we focus on integrating the Bayesian Network to calculate confidence of reported information.
To illustrate this issue, we suggest an application for a semicon-ductor manufacturing system.

The remainder of the paper is organized as follows: in Section 2 , the study context is presented to introduce the issue. Section 3 presents the  X  X LFI X  concept and the main impacting parameters.
The Bayesian Network approach is then described, and its major points are discussed in Section 4 , followed by Modeling Dynamic
CLFI in Section 5 . The algorithm and implementation of the CLFI computation model is described in Section 6 ,while Section 7 gives the conclusion and future prospects. 2. Context and problem Semiconductor manufacturing is an Automated Manufacturing System (AMS), structured around CIM architecture ( Jones and
Saleh, 1989 ) with three main parts: controlled system, control system and product flow ( Fig. 2 ). The controlled system is a set of elementary functional chains (FCs) ( Deschamps and Zamai, 2007 ) where its operating parts are controlled by the control system based on the information collected from the controlled system. Consequently, the behavior of the control architecture is generic and is based on the principle of observability ( Cambacau, 1991 ). It allows use of the remote procedure call (RPC) principle to launch the requests which are sent to the lowest level (customer request) i.e. level 1 within the control system.

In reality, an AMS consists of hardware, software, organiza-tional and human elements ( Zio, 2009 ). It is subjected to uncer-tainties due to its operating parts (failures of sensors, actuators, etc.) and customer requests (variations in production and product specifications). In order to guarantee reactivity of the AMS, the reactive loop in the control system and dynamic reconfiguration are proposed in papers Courvoisier (1990) and Henry et al. (2012) . The reactive loop is characterized by collaboration of several supervision, monitoring and control (SM&amp;C) functions such as detection, diagnosis, prognosis, decision, and automatic control ( Zamai et al., 1998 ). Consequently, depending on the operating mode (normal or abnormal running), the purpose of the coordi-nation level is to manage a set of FCs by using services offered by these FCs ( Fig. 2 ). In case of propagated failure in the product, detected by metrology equipment, the coordination level has to locate the origin of failure in the production equipment used in the failure.

Fig. 3 illustrates a classical production system of a semicon-ductor with four production (M1, M2, M3, M4) and metrology equipment items. A final product in such a system often requires more than 700 processing steps ( Byungwhan and May, 1995 ). Product quality is ensured by the inspections carried out in a large number of steps during the production process with the embedded metrology (inside M1, M2, M3, M4). Each control step returns a report on process execution status to the coordination control module. Nevertheless, this metrology equipment in man-ufacturing systems implies a lack of confidence in feedback information derived from production equipment, essentially due to location and quantity of sensors in production equipment.
In Fig. 4 , we present the problem associated with the open loop that may introduce doubts (uncertainties) as to the success of the operated service, thus implying an increased risk of (Not OK) product parts not being observed. This will result in the default response (OK) by the control module. A failure detected by the metrology equipment guarantees that one or more process steps have failed. Hence, to locate the origin of failure within production equipment, a large number of approaches ( Lafortune et al., 2001 ; Deschamps and Zamai, 2007 ; Fanti and Seatzu, 2008 ) have been proposed. Particularly, Deschamps and Zamai (2007) proposed the on-line diagnosis function providing information on the capacities of operating parts and incorporating generic rules for fault diagnosis. In this method, the response against each executed request is inserted in the diagnosis model finding the possible origin of the failure (inconsistent operation execution) and its consequence on the other services based on the doubt propagation principle. Doubt corresponds to the information that must be qualified as su spect: this mechanism ( Deschamps and
Zamai, 2007 ) is referred to as propagation-before and propagation-after of a diagnosis model. This approach offers a binary evaluation of the reported confidence depend ing on the presence or absence of the product sensors within the equipment, which is a drawback.
Therefore, combining the above analysis with the advantages of BN as shown ( Cobb and Shenoy, 2003 ; Weber et al., 2010 ), we propose refining this confidence to between 0 and 1 via the Bayesian
Network. In this approach, we consider significant factors directly impacting the confidence value such as reliability of many sensors in measurement systems, production c ontext, maintenance activities, human expertise and type of products and its historical metrology, etc. ( Weber et al., 2010 ; Zio, 2009 ).

Accurate computation of confidence of feedback information based on collected data plays an important role in the final diagnosis. We thus suggest the on-line module for computation of the confidence level of feedback information (CLFI) in real time ( Fig. 5 ). Next, we present the definition of the CLFI, the character-ization of CLFI and its model. 3. Confidence level of feedback information (CLFI) controlled system of Automated Manufacturing Systems (AMS) is based on previous and current data of the operating parts, followed by the computation of CLFI at coordination level. 3.1. Definition have correctly performed the requested services. It is a probability value between 0 and 1. The purpose of CLFI computation is to support diagnosis and provide relevant information about correct actions confidence of reported information. 3.2. Characterization of CLFI equipment, we have developed a partnership with the interna-tionally reputed semiconductor manufacturers within the Eur-opean IMPROVE project. This project aims at improving European semiconductor fabrication efficiency by providing better methods and tools to control process variability, thus reducing cycle time and enhancing equipment effectiveness. Based on the information provided by industrial partners (STMicroelectronics, LPFundary,
INTEL), we mainly focus on analyzing the factors which directly affect the CLFI based on Fault Detection Classification (FDC), Failure Modes and Effects Analysis (FMEA), and Statistical Process
Control (SPC), etc. An analysis of equipment life from FDC data ( Table 1 ) is given as an illustration, and represents monitoring of evolution of equipment parameters. For confidentiality reasons the table is voluntarily limited and some information is hidden.
For a given item of equipment, Table 1 shows the start and end time of the event, the type of product, the type of maintenance processing, etc.

Initial data analysis and brainstorming sessions held with engineers have resulted in the following seven main parameters with high impact on the CLFI: Reliability of sensors in the measurement system ( R ). Production context ( C ).
 Position of sensor ( P ) in the acquisition chain.
 Type of product ( TP ).
 Reference metrology for each type of product ( Me ).
 Preventive maintenance activities ( PM ).
 Corrective maintenance activities ( CM ).

These parameters are obviously different from the behavior issues as the whole production process is fully automated in most of the semiconductor production facilities. The production context and the product mix are well recorded, and preventive maintenance is clearly characterized. However , sensor data from the production and metrology equipment have an inherent temporal value that must be used to improve confidence of the reported information level. The reliability of a measurement system ( Maquin et al., 1994 ) is highly temporal and varies according to usage and operating conditions. It is thus difficult to determine the relationship between measurement system reliability and real time reported information.
In this paper, we propose CLFI as estimation in real time of the probability distribution function of a metrology system with respect to reported information and type of product. It is highly impacted by corrective maintenance as this type of maintenance cannot be scheduled.

Therefore, we need to find an app roach who have characteristics response following capabilities: data are complex, incomplete and uncertain; relationship is cause -effect -failure; parameters are dependent and discrete, processing in the real-time and dynamic.
To accurately model the relationship between the above-mentioned parameters affectin g the CLFI, we have relied on the expert X  X  knowledge and on probabi listic methods e.g. Expectation Maximization (EM) ( Dempster et al., 1977 ), Markov chain Monte
Carlo (MCMC) ( Gilks et al., 1995 ), Neural Network ( Nauck et al., 1997 ). Besides, some important probabilistic analysis methods are mentioned ( Bouaziz et al., 2011 ) in the European IMPROVE project. Particularly, we have adopted a Bayesian approach to model the
CLFI. A real time CLFI computation module, presented in this paper, combines knowledge represent ation in a graphical form (direct dependence relationships: cause -effect -failure) and probabil-istic knowledge uncertainty ( Populaire, 2000 ). In fact, this method is used to model a directed acyclic graph (DAG) as causal dependen-cies of information even if they are imperfect or missing. It is thus ideally adapted to the context of our study as learning and inference of this real time CLFI computatio n module have powerful features enabling merging of incomplete data with assistance of an expert.
In the proposed approach, the BN allows probability computa-tion based on knowledge gained ( Niculescu et al., 2006 ; Ben-Gal, 2007 ) and Dynamic Bayesian Network aims one X  X  efforts to solve the processing in the real-time and dynamic. This issue will be presented in more detail in Section 4 . 4. The proposed evolutionary approach based on Bayesian Networks
In this section, we present a number of approaches beginning with simple models and then complex ones to gradually eliminate the condition limits based on Bayesian Networks. Firstly, the reason of choosing Bayesian Networks as our approach and the related works in this domain are presented. Then, we gradually choose dependent conditions which are appropriate to our issue by Tree Augmented Na X   X  ve Bayes models. Finally, we present a dynamic approach (changing over time) based on Dynamic Bayesian Network combined with Markov Chain. They are sub-scribed as follows.

BNs are a family of probabilistic graphical models providing joint distribution for a set of random variables ( Ben-Gal, 2007 ). Known as a DAG, they are used to represent uncertain knowledge in artificial intelligence ( Korb and Nicholson, 2004 ). The structure of a DAG combines sets of nodes and arcs where nodes represent a set of random variables from a domain. A set of directed arcs (or links) connects pairs of nodes, re presenting direct dependencies between variables, where variables are defined over several states. Assuming that these are discrete variables, the strength of the relationship between variables is estimated by conditional prob-ability distributions associated with each node. BNs are applied in cases of uncertainty, when we know certain conditional probabil-ities and seek unknown probabilities for given specific conditions. To achieve this goal, one of the BN models is widely used as a Na X   X  ve Bayes model ( Cuiping et al., 2009 ; Jiangtao et al., 2009 ; Lowd and Domingos, 2005 ). This model is based on the simplest assumption that variables are conditionally independent in a given node (class): the Na X   X  ve Bayes model is presented by a single common parent node to all the variable nodes. It has certain advantages such as an intuitive technique that does not require a large amount of data before learning can begin, and fast computation, etc. ( Ben-Gal, 2007 ). Therefore, the Na X   X  ve Bayes model provides reasonably good results in some practical problems and is particularly suitable for our analysis. It is a simple and efficient approach for classifying new training set instances. Unfortunately, their features are not always independent and we can find a correlation. Therefore, Tree Aug-mented Na X   X  ve Bayes (TAN) was introduced by Friedman et al. (1997) as a natural extension to the Na X   X  ve Bayesian classifier. We will describe TAN model in more detail in the next paragraph.
In recent years, some approaches to DBNs, HMMs and DNBC have been proposed. DBNs are considered in the first paper by Dean and Kanazawa (1989) . These are an extension of Bayesian Networks to model probability distributions over time (to handle temporal models) ( Murphy, 2002 ). It can be defined as a repeti-tion of conventional networks in which we add one causal one time step to another. DBNs are used in most stochastic process models and applications in tracking multiple targets with model-ing uncertainty in the relational dynamic domain ( Manfredotti, 2009 ). They usually generalize Hidden Markov Models (HMMs) and Kalman Filter Models (KFMs) by representing the hidden and observed state in terms of state variables which can have complex interdependencies ( Ghahramani, 1998 ). Particularly, the approach by Avile  X  s-Arriaga et al. (2003) and Palacios-Alonso et al. (2010) presented the Dynamic Naive Bayesian Classifiers (DNBC) model whose base structure is a NBC. This combines the advantages of an NBC simple structure and algorithms with those of a HMM, and the capacity to model complex dynamic processes. A DNBC decomposes the observation node into a set of independent attri-butes ( Mart X   X  nez and Sucar, 2008 ). A method is developed to auto-matically learn a DNBC from data. It determines: the number of hidden states, the relevant attributes , the best discretization, and the structure of the model. Palacios-Alonso et al. (2010) proposes a special coding scheme in order to group dependent attributes and remove irrelevant ones for model DNBCs. The similar and different highlighted aspects of DNBCs and HMMs are considered by Avile  X  s-Arriaga et al. (2011) . DNBC solved many problems for voice recogni-tion, speech recognition, image processing etc.

With respect to computation, these approaches are often used to estimate future states and parameters or find probability P  X  X t , Y t  X  . However, this is not the issue dealt with in this paper. Our goal is to estimate the probability of states when parameters are observed at the current time, and the previous state corre-geometric shapes, the DNBC model is similar to HMM. Never-theless, state variables of the report in the system considered are observed, while the state variables of the HMM model are hidden.
We therefore proposed to develop a novel model (DBNMC) based on Dynamic Bayesian Network and Markov Chain in order to estimate the CLFI. This is used to compute the probability of state at the present time with knowledge of the probability of state in the past time, and parameters at the present time based on the structure shown in Section 4.2 . 4.1. Tree Augmented Na X   X  ve Bayes (TAN) models
TAN models are a special family of Bayesian Networks that allow computation with correlated features. A specific TAN model presents dependence features. In this case, we show seven features in the model as they are suitable for our study in the following chapters. Fig. 6 comprises nodes C , x 1 , x 2 , ... , x from C to all nodes. These nodes are dependent on features x , x 2 , ... , x 7 and we can compute P  X  C 9 x 1 , x 2 , ... , x as the evidence node.

Based on the approach presented by Friedman et al. (1997) and the transformation for coherence with the model in Fig. 6 ,we can rewrite the posterior probability as follows:
P  X  C 9 x 1 , x 2 , x 3 , x 4 , x 5 , x 6 , x 7  X  X  P  X  x 1
C  X f c 1 , c j , ... , c m g X  1  X  where
P  X  x 1 , x 2 , x 3 , x 4 , x 5 , x 6 , x 7 9 C  X  X  P  X  x 1 9 C  X  : P  X  x
P  X  x 4 9 C : , x 3  X  : P  X  x 5 9 C , x 3  X  : P  X  x 6 9 C , x 3
Eq. (4) is derived from the Bayes theorem and the structured model in Fig. 6 .
 In practice, there are relationships between variables in time.
A variable which causally affects others will be its parent in the network. This limitation has motivated the study of metrologies that can improve BN. Thus, temporal order specifies the direction of causality playing an important role in the design of a Dynamic
Bayesian Network. 4.2. Dynamic Bayesian Network combined with Markov Chain
Some studies showed the combination of DBN with a Markov chain ( Weber and Jouffe, 2003 ; Rajapakse and Zhou, 2007 )to perform tasks such as diagnosis, monitoring, prediction, etc, and reliability modeling for complex manufacturing processes. The combination of the Markov process with the DBN method is ideal for computing the reliability of complex systems such as semi-conductor manufacturing systems. It is introduced in the follow-ing paragraphs.

We consider a first-order MC model as a simple DBN. The definition of the Markov process says that each state only depends on the directly previous state.

P  X  S t 9 S 1 : t 1  X  X  P  X  S t 9 S t 1  X  , t  X  1 , 2 , ...  X  3  X  and, observations depend only on current state: P  X  X t 9 S t , X t 1  X  X  P  X  X t 9 S t  X  , t  X  1 , 2 , ...  X  4  X  state-transition function P  X  S t 9 S t 1  X  , and its observation function P  X  X t 9 S t  X  .
 defines the prior P  X  S 1  X  , and B -is a two-slice temporal Bayes net (2TBN) which defines P  X  S t 9 S t 1  X  by means of a Directed Acyclic Graph (DAG) (see Fig. 7 ) as follows: P  X  S t 9 S t 1  X  X  approach is used as a reference model to build a new model ( Fig. 7 ). For further details, the implementation of this model for estimation of CLFI will be presented in Section 5.2 . In the next section, we build a CLFI computation model. 5. CLFI computation model computation model. Indeed, the basic TAN yields good model probability that could address the factors in a reasonable fashion, as well as weak independence assumption in the Na X   X  ve Bayesian approach. Nevertheless, Bayesian Networks and TAN models, which do not deal with time, are constructed by combining prior knowledge of experts and a set of observed data. To adapt to dependence parameters and reports changing over time, we thus present the method with a different approach to expand the TAN model that changes over time. Our approach gives a new model to improve resolution of feedback information reliability problems by combining the Dynamic Bayesian Network with a Markov
Chain (MC), known as the DBNMC model ( Fig. 7 ). In the next section, we present the method for building a CLFI computation model based on the TAN model approach (see Section 5.1 ) and the dynamic computation model of CLFI based on DBNMC (see
Section 5.2 ). 5.1. CLFI computation model by a TAN approach
Na X   X  ve Bayes models presented in Section 4 . CLFI is the posterior factors such as R , P , C , TP , PM , CM and Me (see Section 3.2 ).
According to the arguments and assumptions given in the previous section, we can model each of these effects-elements as a node (variable). In particular, the Report ( Re ) variable is the parent node ( C ) in the structure of the TAN model for probability ( Fig. 6 ). An arrow from the generic node Report ( Re ) to node R or P , etc. means that R or P is conditionally dependent on the reported information level. For each node, a conditional probability quan-tifies the effect of the parents on that node. One thing to note here ( Fig. 8 ) is that dependence between nodes, e.g. type of product ( TP ) at time t , has a specific metrology ( Me ) value. The structure of the TAN model in this case is developed by experts from correla-tion in data and experience.

Mathematically speaking, CLFI is the posterior probability computed as follow: CLFI  X  Re  X  X  P  X  Re 9 R , P , C , TP , Me , PM , CM  X  X  6  X 
Combining (1) and (2) to compute CLFI( Re ), x 1 , ... , x
P  X  Re 9 R , C , P , TP , Me , PM , CM  X  X 
P  X  Re  X  : P  X  R 9 Re  X  : P  X  C 9 Re  X  : P  X  P 9 Re  X  : P  X  TP
According to (1) we have the expression for the probability that ( Re Corresponding to C in (1) ) will take on ( Re  X  OK) or ( Re  X  Not OK). In Eq. (7) we need to compute P  X  Re  X  , P  X  R 9
P  X  P 9
Re  X  , P  X  TP 9 Re  X  , P  X  Me 9 Re , TP  X  , P  X  PM 9 Re  X  and P  X  CM is computed from the training set (data) by counting the number of occurrences of the Reported event, for example ( Reported  X  OK) or ( Reported  X  Not OK). The probability P  X  C 9 Re  X  , P  X  P P  X  PM 9 Re  X  , P  X  CM 9 Re  X  can be estimated by counting how often each value C , P , TP , PM , CM occurs within a class in the training set.
The computation model for the CLFI that we present in this section takes into account the observed data such as: C , P , TP , PM and CM . However, reliability of the measurement system varies over time. We thus propose a model for the measurement system and the approach EM algorithm to find the correlation between measurement system reliability and Report  X  P  X  R 9 Re  X  . This is presented in Section 5.1.1 . The probability P  X  Me 9 Re , TP  X  in ( 7 )is developed in Section 5.1.2 . 5.1.1. Measurement system reliability
Sensor reliability is defined as the probability r ( t ) of the non-failure of the sensor at time t , which represents the intrinsic quality of the sensor. It is a main factor in CLFI calculation as lower sensor reliability means lower CLFI. r  X  t  X  X  1 function.

Sensor time to failure is described by the probability density function. For exponentially distributed times to failure of sensor ( Dhillon, 2002 ), sensor reliability can be written as, l : failure per a time unit. The measurement system is made up of many sensors, and is represented by a block diagram. The probability of failure or success of one of these sensors is estimated to calculate the probability of failure or success of the overall system. In this case, the system consisting of m sensors with respective reliabilities r ( t ) may define the reliability of a measurement system by R  X  f  X  r i  X  t  X  , r 2  X  t  X  , ... , r m  X  t  X  X  .

Depending on the functions and tasks of the measurement system, the system block diagram could be series, parallel or bridge systems ( Dhillon, 2005 ). Therefore, we need to determine the structure to calculate the associated reliability of a measure-ment system. For example, in an automated production system as shown in Fig. 9 , we consider the activity part of the machine M2 with sensor setting as in Fig. 9 to define the block diagram. This is find reliability of a measurement system over time. With a constant failure rate and exponentially distributed times to fail-ure of sensor i ( i  X  1, y ,5), at time t , the equation of the parallel system for dependent sensor reliability is presented as follows: R  X  t  X  X  1  X  1 e l 1 t  X  X  1 e l 2 t  X  2  X  1 e l 4 t  X  2  X  8  X 
How does reliability of the measurement system ( R ( t )) affect the CLFI? This factor is one of many factors that we need to consider. The problem is how to determine the relationship between them from the information provided by historical production data. This relationship should be standardized accord-ing to a specific function, taking change over time into account in real time. At a certain time with fixed reliability of the measure-ment system R ( t ), we can identify a Report event that is (OK) or (Not OK). However, at a random time in the report, it is difficult to find the probability of the Report event. To achieve this, relying on historical production data, we compute the probability distribu-tion function R ( t ) and the probability of Report event occurrence.
Now, we use the EM algorithm ( D X  X ouza, 2002 ) to determine the parameters of the Gaussian Mixture such as t i , m i , s i f  X  x  X  X  where t i is the mean and m i is the covariance, s i are indicator variables that are multinomial distributions,  X  P k i t i
We performed this task on MATLAB. To ensure that accuracy and computation times were not too long and complex, we chose the numbers of Gaussian as 3. We then ob tained the following results.
In Fig. 10 , the X -axis represents measurement system relia-bility at time t , while the Y -axis represents probability of the
P  X  R 9 Re  X  one. 5.1.2. Metrology activities for each type of product
As presented in the above section, the metrology machine is located at the end of a process to decide whether end products are
OK or Not OK. Our goal in this part is to analyze the relationship between the metrology decision, the type of product, and the reported information ( Re ) to show elements affecting confidence of reported information. We assume correct report by the metrol-ogy machine, random testing in a batch of products, and existence of a fixed late time comparison with the report of manufacturing machines.

For example (as shown in Tables 2 and 3 ), we consider three types of products, A, B and C, which pass through production machines M3. The historical production data for three dates are shown in Table 2 . The first column shows data on the random time receiving reports from M3. The results of the metrology machine are shown in Table 3 . The metrology machine randomly tests all types of products with, on average, one time per date. Column 3 in Table 3 supplies two possible values ( Metrology  X 
Pass )or( Re  X  Not Pass ). Pass means that the quality of a product manufactured by the machine is good, while Not Pass means the opposite. Considering a particular case at 01:42:00, 08-Jan-2005 ( Table 2 ), product type B after the production process at machine
M3 had received the report ( Re  X  OK). However, after a fixed late time at 17-Jan-2005, the metrology report received was Not Pass .
This means that there is a difference between the reports of M3 and the metrology machine resulting in an uncertainty of reported information on production machines. We thus need to analyze the impact of reported information and metrology in the CLFI model.
 as follows: P  X  Me 9 TP , Re  X  X  P  X  Me , TP , Re  X  P  X  TP , Re  X   X  P  X  Me , TP , Re  X  U  X f P as s , Not _ Pass g X  10  X  survey period to compute P ( Me , TP ,Re) from (Eq. (10) ). However, we faced difficulties with the time reported in Tables 2 and 3 such as the difference in format and the number of reports (production data time reports on average 10 times/day, whereas metrology data reports once every day). We can solve this problem by integrating the data ( Table 4 ) on the sampling principle. The result of metrology in the production system reflects the quality of the product in one day. In other words, the time before the new results or the result in ( t 1) will be true at any time before it. of occurrences (simultaneous appearance of values) in Table 4 , e.g. {Type A,OK,Pass}.
 5.2. CLFI Dynamic Model
In this section, we propose a different approach to improve the accuracy of TAN when reported information changes over time. In the case of our research, CLFI depends on several impact factors such as operating states of components and its production context over time, e.g. degraded health state, remain ing-useful-life of the component/ machine, changing quality of sensors, maintenance etc. When these factors change over time, reported information also changes. There-fore, when computing CLFI of reported information at the present time, we have to consider the impacts of the previous CLFI on the present CLFI.

Experts and operating engineers in the semiconductor manufac-turing field suggested that the state s of reported information at the present time only depend on one preceding state. Also, at a certain time, equipment parameters only affect the current states of the report at the same time and do not affect the previous states ( Fig. 11 ). Moreover, if we consider the second order then it would depend on the two preceding states, and so on. When the order increases, computation is more complex with a larger amount of data.Inanycase,asmemoryisfinitewejustusethefirstorder.
The above analysis of our model approach fits in well with the nature of the first order Markov chain, presented in Eqs. (3) and (4) in Section 4 . Based on analysis and giving the DBNMC model presented in Section 4.2 and the CLFI model using a TAN approach in Section 5.1 , we propose a dynamic model of CLFI shown in
Fig. 11 a. To ensure simple presentation and calculation, we give another model as shown in Fig. 11 b. As presented with respect to the DBNMC model (see Section 4.2 ), our goal is: how to compute the probability of Reported information at the present time when we know the probability of Report in the past time and these parameters at the present time ( y t ). This means that we have to compute probability P  X  Re t 9 y t , Re t 1  X  : where y y  X f R t , C t , P t , TP t , Me t , PM t , PC t g To achieve this goal, we use the fundamental probability theory, Bayes X  theorem, and the combination properties of DBN with the first-order Markov process as given above.
 Based on the fundamental rule, we obtain: P  X  A 9 B  X  P  X  B  X  X  P  X  A \ B  X  X  P  X  B 9 A  X  P  X  A  X  X  11  X 
The fundamental rule is used to calculate the probability of seeing both A and B when we know the probability of A given B and the probability of B . By conditioning on another event C , the fundamental X  rule can also be written as: P  X  A 9 B \ C  X  P  X  B 9 C  X  X  P  X  A \ B 9 C  X  X  12  X  Application Bayes X  theorem, we obtain: P  X  A 9 B  X  X  P  X  B
Bayes X  theorem provides us with a method for updating our belief as an event A given that we obtain information about another event B . For this reason, P ( A ) is usually referred to as the prior probability of A , whereas P  X  A 9 B  X  is referred to as the poster-the likelihood of A given B . A similar fundamental rule can also be written with a new event C : P  X  A 9 B , C  X  X  P  X  B In particular, we have: P  X  Re t 9 Re t 1 , y t  X  X  P  X  Re t , Re t 1 Application of Bayes X  theorem, we obtain: P  X  Re t , Re t 1 9 y t  X  X  P  X  Re t 1 9 Re t , y t  X  : P  X  Re P  X  Re t 9 y t , Re t 1  X  X  P  X  Re t 1 From the CLFI Dynamic Model using the DBNMC approach, Fig. 11 b, Re t has relationships with y t , Re t 1 and does not depend on y t 1 (Markov properties). Re t 1 depends on Re t , y t 1 rewrite as follows: P  X  Re t 9 y t , Re t 1  X  X  P  X  Re t 1 where P  X  Re t 1 9 Re t  X  P  X  Re t 1  X   X  We obtain the equation as follows: P  X  Re t 9 y t , Re t 1  X  X  P  X  Re t 5.2.1. Computing method components in the model In order to compute the probability: P  X  Re t 9 y t , Re t 1 define the specific component in Eq. (20) .
 Where
P  X  Re t  X  : A prior probability, computed from the training set (data) by counting of occurrence events.

P  X  Re t 9 y t  X  : An observation function where data arrivers in real time, it is a posterior probability estimating from model TAN (as mentioned above in Section 5.1 ).

P  X  Re t 9 Re t 1  X  : The transition probability distribution among states over time, it describes the effects of previous states on the recognition of the current state.

In this case we could observe Re 1 : T ( T : Time of survey data). To do that, we could compute by normalizing the matrix of co-occurrences (counts) (21) :
P  X  M _ states  X  X  N  X  i , j  X  P where N  X  i , j  X  X 
Re t 1 , Re t  X f i , j g X  22  X 
I ( Re ) is a binary indicator that is 1 even if ( Re  X  OK) occurs, and is 0 when ( Re  X  Not OK). Thus is the number of transitions in a given sequence. 5.2.2. Example
In the specific case of the following production data ( Fig. 12 ) and application (22) :
From Fig. 12 , we have four cases among states over time as follows:
Re t 1  X  OK -Re t  X  Not _ OK
Re t 1  X  OK -Re t  X  OK
Re t 1  X  Not _ OK -Re t  X  OK
Re t 1  X  Not _ OK -Re t  X  Not _ OK Computation transition matrix probability M_states: For each moment in real time, to estimate the probability
P  X  Re t 9 Re t 1  X  , we can refer to the states transition matrix M_states ( Fig. 13 ) to find the corresponding probability value P  X  Re
For example, at time t 1, the value of the report returned by the equipment is equal to (NOT OK). However at time t , the latter changes to (OK). Probability of states transition is defined as follows:
P  X  Re t  X  OK 9 Re t 1  X  Not _ OK  X  X  4 5 6. Algorithm and implementation 6.1. CLFI computing algorithm time from the structure presented in Fig. 14 , based on the character-istics and formulas given by the CLFI Dynamic Model. We started with data analysis to identify the relationships and impacts on reported information through the experience and knowledge of experts who built the Bayesian Network structure. The same data are used to compute conditional probabilities from the training data set during the learning step. The CLFI is computed in real time by the computation model to report the (report  X  training set) information prior to sending it to the diagnosis module.

The proposed algorithm presented in Fig. 15 performs two main tasks: (i) learning and (ii) testing. With respect to learning, it estimates the conditional probabilities of each component by multiplying it with Eqs. (7) and (20) , whereas for testing, after receiving a new vector of parameters, it computes the conditional probabilities based on the Model Dynamic of CLFI. The final output value of the algorithm is CLFI. 6.2. Implementation program on MATLAB
In an AMS as shown in Fig. 5 , we consider the historical data collected from production equipment M3 and the metrology data fed from the files as shown in frame (1) on Fig. 17 . After com-pletion of the production process on machine M3, its control system reports process end at the coordination level. This report provides information about the parameters of M3 and its current operating status. If the received report is (OK) then the control system ends the process considering the processed product to be
Ok. However, if the report is (Not OK), the product in M3 will be considered (Not OK). In both cases, we consider the effects of metrology equipment on the production process and its associated confidence of reported information.
 In Fig. 17 : Time  X  {hh:mm date month year}; R  X f 0 C 100 % g ;
P  X  {Open-Loop (OL), Pre-Actuator (PA), Actuator (AC), Pre-Actua-tor  X  Actuator (PA.AC), Effectors (EF), Effectors  X  Pre-Actuator (EF.PA), Effectors  X  Actuator (EF.AC), Effectors  X  Actuator  X  Pre-
Actuator (EF.AC.PA)}; C  X  {Normal production ( N ), Mass produc-tion ( MP ), Change recipes ( CR )}; PM  X f 0 C m g ; CM  X f 0
After implementing the program with algorithms and mathe-matical formulas expression, we obtain the results of the states transition matrix ( Fig. 16 ) and the interface of the confidence of feedback information computing model as shown in Fig. 17 .
We introduce some main frames in the interface as follow: (1) Input data (Production and Metrology data). (2) Description of the model structure. (3) The temporary result of Eq. (7) . (4) The reported information at time t . (5) Presentation of probability P  X  R 9 Re  X  over time. (6) The temporary result of probability P  X  Me , TP , Re  X  . (7) Show all the calculated results.

In line 30 of frame 7, the CLFI of Report is (OK) with the current parameters of M3, e.g. R  X  0.8249. This means that reliability of the measurement system, considering its operated time is 0.8249. C  X  N , P  X  EF , TypeA, PM  X  0, CM  X  0, and association with the backward reference metrology activity ( Me  X  Pass) is computed as 47.49%.

In this case, the CLFI of equipment M3 that has correctly performed the requested services (Reported  X  OK) is 47.49% at the time of computation, with the current equipment parameters and the production context. It helps automation engineers to locate the process equipment leading to product failure detected by the Metrology. Changeover time in the current parameters of M3 results in different CLFIs (Frame 7). 6.3. Discussion
To evaluate our results, we propose using the confidence linguistic values for report consist of set {Very low, Low, Medium, High, Very high}. Next, we run the proposed algorithm in a process with the following scenarios. Finally, we discuss and assess each scenario from which infers the evaluation of our model.
 We propose 3 main scenarios ( Table 5 ) as following
Scenario A: In this scenario, we give a number of assumptions for equipment at time t such as a high reliability of measurement system ( R  X  98,40%), operation in normal production context, position of sensor put in all functional chains ( P  X  EF.AC.PA), equipment without maintenance before ( PM  X  0, CM  X  0). It means that the status of equipment is very good. Logically, operation of equipment will send to coordination level a report with high confidence level (Report  X  OK, CLFI  X  Very high).

Scenario B: The assumptions are a low reliability of measure-ment system ( R  X  10%), without sensors posited on functional chains ( P  X  OL), operating in mass production context and passing a number of maintenance for equipment ( PM  X  10, CM  X  10).
In this case, the status of equipment is bad. Therefore, we infer logically that the operation of equipment will send the coordina-tion level a report with very low confidence level (Report  X  OK, CLFI  X  Very low).

Scenario C: The conditions are the high reliability of measure-ment system ( R  X  98,40%), the normal operation context, position of sensor put in all FCs (P  X  EF.AC.PA), equipment without main-tenance before ( PM  X  0, CM  X  0). However, it is assumed that reliability of measurement system decrease over time. Thus, CLFI also reduce over time (Report  X  OK, CLFI reduce from Very high to Very low).

The results of the implementation of these scenarios on our model are presented in Fig. 18 . Thanks to this, we have a number of following conclusion. In scenario A, CLFI is very high (CLFI  X  99,07%, in line 33 of Fig. 18 ). By contrast, Scenario B show the very low CLFI result (CLFI  X  2.16e 6, in line 33 of Fig. 18 ). For Scenario
C, it is easy to see that the decrease of CLFI corresponds with the decrease of reliability of measurement system (From line 1 of Fig. 19 ). This decrease is shown in chart ( Fig. 20 ).
Above, we give three main cases of scenario. Besides, we also present other cases called the opening cases of Scenario A. In this case, the conditions are the same with scenario A but sensor is only put at PA. Thus, CLFI is logically inferred less than CLFI of Scenario A. Indeed, the result in our program is CLFI  X  PA  X  X  16 , 69 % o CLFI  X  EF : AC : PA  X  X  99 , 07 % . Similarly, when we change other factors such as Context and PM, CM, the results are also smaller such in lines 34, 35 and 36 of Fig. 18 .
 completely appropriate for the beginning evaluation of experts and logical inference. Moreover, it adapts in the real time. logical inference are mostly accepted.
 6.4. Contribution of CLFI in diagnosis model
Based on process data and the experts knowledge, we are now able to evaluate the confidence of all the reported information taken from the equipment. The resulting CLFI is a value between 0 and 1 that extends the diagnosis inference proposed by Deschamps and Zamai (2007) .

Hence, let us consider the proces s of Semiconductor Manufactur-ing shown in Fig. 21 to point out the important role of CLFI for diagnosis. In this example, we consider three main activities such as (M1) Cut-chip (Step 1), (M3) Encapsulation (Step 2) and Metrology (Step 3  X  random). This production system can make many different types of products. The Diagnosis mechanism is based on the approach proposed in Deschamps and Zamai (2007) . It is triggered on event sent (requests) and received (reports) by the coordination level. For each of these events, the algorithm builds, in real-time, a model of the past evolution of the controlled system. This model is then composed of the past executed services (Pre)-Constraints, (Pre)-Conditions and Effects of the se services. Collecting the infor-mation like this could make the size of a model increasing. Based on the exploitation of the controlled s ystem observability, the approach manages the size of the resulting model. To do this, ( Deschamps and
Zamai, 2007 ) suggested the hypothesis  X  X  if a requested evolution of the controlled system is correlated with a change in a state of a sensor, then this evolution is correct  X  X .

In this case, the corresponding executed operation is removed from the model. So, in case of failure detection by metrology equipment, the resulting diagnosis model is only composed by suspect operations. Using a doubt propagation principle (propa-gation-before) aims to isolate all possible origins of the detected failure. However, here, the number of candidate can be large.
Thus, our contribution plays an important role in integrating an online CLFI value in the diagnosis model. Among the suspected operations, our approach provides here a key element to help human operator in fault isolation.

In the considered example (see Fig. 21 ), a product type A is processed step by step on M1 for Cut-chip and M3 for Encapsula-tion. Then, product is tested through metrology equipment. The result of this operation is  X  X  no pass  X  X  corresponding to product failure detection. Considering the resulting diagnosis model shown in Fig. 21 , two previous operations can be considered as suspect: cut-chip on M1 and encapsulation on M3. Considering now CLFI values (M1 with CLFI  X  0.75% and M2  X  0.64%) provides to a human operator new element to optimise maintenance process: here M1 must be controlled first. 7. Conclusion
This paper proposes a concept of confidence level of feedback information (CLFI) to help automation engineers locate the process equipment leading to product failure detected by the Metrology. The proposed CLFI index is a value between 0 and 1, and is computed based on the DBNs and Markov Chain approach, which is widely accepted as a methodology to learn uncertainties. Furthermore, we have developed an algorithm and a computation module for real time computation of the said CLFI index. Based on the algorithms and the Model Dynamic of CLFI, a tool developed in Matlab is presented and proposed for use in the semiconductor manufacturing industry. Our work is an extension to the diag-nosis approach proposed by Deschamps and Zamai (2007) . Based on the analysis, we have highlighted seven main factors that impact the CLFI. Our proposed DBNMC model processes the inherent uncertainty reported information and obtains the pos-terior probability of the reported information. It is thus able to provide the diagnosis module with the information which it needs to facilitate location of the origin of an equipment failure in a given production process. Furthermore, we are currently working on the extension of the proposed Model Dynamic of CLFI with the inclusion of continuous variables.

In future, we focus on validating the model on the data collected from a intentionally reputed semiconductor manufac-turing industry within the European IMPROVE project. Next, we will propose integrating this type of CLFI module in a diagnosis system developed in Deschamps and Zamai (2007) to test the resulting global approach on a real case. Finally, we will apply this model in the optimization and accurate detection alarms in production systems.
 References
