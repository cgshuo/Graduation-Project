 How can we find communities in dynamic networks of social interactions, such as who calls whom, who emails whom, or who sells to whom? How can we spot discontinuity time-points in such streams of graphs, in an on-line, any-time fashion? We propose GraphScope , that addresses both prob-lems, using information theoretic principles. Contrary to the majority of earlier methods, it needs no user-defined param-eters. Moreover, it is designed to operate on large graphs, in a streaming fashion. We demonstrate the efficiency and effectiveness of our GraphScope on real datasets from sev-eral diverse domains. In all cases it produces meaningful time-evolving patterns that agree with human intuition. H.2.8 [ Database applications ]: Data mining Algorithms
Graphs arise naturally in a wide range of disciplines and application domains, since they capture the general notion of an association between two entities. However, the as-pect of time has only recently begun to receive some atten-tion [15, 20]. Some examples of the time-evolving graphs include: (a) Network traffic events indicate ongoing com-munication between source and destination hosts, similar to the NETWORK dataset in our experiments; (b) Email net-works associate a sender and a recipient at a given date, like the ENRON data set [2] in the experiments; (c) Call detail records in telecommunications networks associate a caller with a callee. The set of all conversation pairs over each week forms a graph that evolves over time, like the pub-licly available  X  CELLPHONE  X  dataset of MIT users calling each other [1]; (d) Transaction data: in a financial institution, who accessed what account, and when; (e) In a database compliance setting [4], again we need to record which user accessed what data item and when.
 Copyright 2007 ACM 978-1-59593-609-7/07/0008 ... $ 5.00.
To complicate matters further, large amounts of data such as those in the above examples are continuously collected and patterns are also changing over time. Therefore, batch methods for pattern discovery are not sufficient. We need tools that can incrementally find the communities and mon-itor the changes. In summary, there are two key problems that need to be addressed:
P1) Community discovery: Which groups or communities
P2) Change detection: When does the community struc-Moreover, we want to answer these questions (a) without re-quiring any user-defined parameters, and (b) in a streaming fashion.

For example, we want to answer questions such as: How do the network hosts interact with each other? What kind of host groups are there, e.g., inactive/active hosts; servers; scanners? Who emails whom? Do the email communi-ties in a organization such as ENRON remain stable, or do they change between workdays (e.g., business-related) and weekends (e.g., friend and relatives), or during major events (e.g.,the FBI investigation and CEO resignation)?
We propose GraphScope, which addresses both of the above problems simultaneously. More specifically, Graph-Scope is an efficient, adaptive mining scheme on time-evolving graphs. Unlike many existing techniques, it requires no user-defined parameters, and it operates completely automati-cally, based on the Minimum Description Length (MDL) principle. Furthermore, it adapts to the dynamic environ-ment by automatically finding the communities and deter-mining good change-points in time.

In this paper we consider bipartite graphs, which treat source and destination nodes separately (see example in Fig-ure 2). As will become clear later, we discover separate source and destination partitions, which are desirable in sev-eral application domains. Nonetheless, our methods can be easily modified to deal with unipartite graphs, by constrain-ing the source-partitions to be the same as the destination-partitions [6].

The main insight of dealing with such graphs is to group  X  X imilar X  sources together into source-groups (or row-groups ), and also  X  X imilar X  destinations together, into destination-groups (or column-groups ). Examples in Section 6.2 show how much more orderly (and easier to compress) the adja-cency matrix of a graph is, after we strategically re-order its rows and columns. The exact definition of  X  X imilar X  is actu-ally simple, and rigorous: the most similar source-partitions for a given source node is the one that leads to small encod-ing cost (see Section 4 for more details).

Furthermore, if these communities (source and destina-tion partitions) do not change much over time, consecutive snapshots of the evolving graphs have similar descriptions and can also be grouped together into a time segment, to achieve better compression. Whenever a new graph snap-shot cannot fit well into the old segment (in terms of com-pression), GraphScope introduces a change-point, and starts a new segment at that time-stamp. Those change points of-ten detect drastic discontinuities in time. For example on the ENRON dataset, the change points all coincide with im-portant events related to the ENRON company, as shown in Figure 1 (more details in Section 6.2).
 Figure 1: ENRON dataset (Best viewed in color). Rela-itors communities and their changes in a stream of graphs efficiently. It has the following key properties: We demonstrate the efficiency and effectiveness of our ap-proach in discovering and tracking communities in real graphs from several domains.
 The rest of the paper is organized as follows: Section 2 reviews the related work. Section 3 introduces some nec-essary definitions and formalizes the problem. Section 4 presents the objective function. Section 5 presents our pro-posed method to search for an optimal solution, Section 6 shows the experimental evaluation and Section 7 concludes.
Here we discuss related work from three areas: mining static graphs, mining dynamic graphs, and stream mining.
Graph mining has been a very active area in the data mining community. From the exploratory aspect, Faloutsos et al. [10] have shown the power-law distribution on the Internet graph. Kumar et al. [14] discovered the bow-tie model for web graphs.

From the algorithmic aspect, graph partitioning has at-tracted much interest, with prevailing methods being ME-TIS [12] and spectral partitioning [16]. Even in these top-performing methods, users must specify the number of par-titions k . Moreover, they typically also require a measure of imbalance between the two pieces of each cut.

Information-theoretic Co-clustering [9] simultaneously re-orders the rows and columns of a normalized contingency ta-ble or a two-dimensional probability distribution, where the number of clusters has to be specified. The Cross-association method [7] formulates the co-clustering problem as a binary matrix compression problem. Noble and Cook [17] propose an entropy-based anomaly detection scheme for graphs.
All these methods deal with static matrices or graphs, while GraphScope is designed to work with dynamic streams. Moreover, most of methods except for cross-association re-quire some user-defined parameters, which may be difficult to set and which may dramatically affect the final result, as observed in [13]. Keogh et al. [13] proposed the notion of parameter free data mining. GraphScope shares the same spirit but focuses on different problems.

In addition to graph mining, several storage schemes [11, 18] have been proposed to compress large binary matrices (graphs) by column reordering. However, none of those scheme perform both column and row reordering and their focus is on compression rather than mining.
From the exploratory viewpoint, Leskovec et al. [15] dis-covered the shrinking diameter phenomena on time-evolving graphs. Backstrom et al. [5] study community evolution in social networks.

From the algorithmic aspect, Sun et al. [20] present dy-namic tensor analysis, which incrementally summarizes ten-sor streams (high-order graph streams) as smaller core ten-sor streams and projection matrices. This method still re-quires user-defined parameters (like the size of the core ten-sor). Moreover, it gives lossy compression. Aggarwal and Yu [3] propose a method to selectively store a subset of graphs to approximate the entire graph stream and to find community changes in time-evolving graphs based on the user specified time interval and the number of communi-ties. Again, our GraphScope framework avoids all these user-defined parameters.
In this section, we formally introduce neccessary notation and formulate the problems.
Calligraphic letters always denote graph streams or graph stream segments (consisting of one or more graph snapshots), Sym. Definition
G , G ( s ) Graph stream, Graph segment t Timestamp, t  X  1. m , n Number of source(destination) nodes.

G ( t ) Graph at time t ( m  X  n adjacency matrix). i, j Node indices, 1  X  i  X  m , 1  X  j  X  n .

G ( t ) i,j Indicator for edge ( i, j ) at time t . s Graph segment index, s  X  1. t s Starting time of s -th segment. k s , ` s Number of source (dest.) partitions for segment s . p, q Partition indices, 1  X  p  X  k s , 1  X  q  X  ` s .
I p Set of sources belonging to the p -th partition, dur-
J q Similar to I ( s ) p , but for destination nodes. n p Dest. partition size, n ( s ) p  X | J ( s ) p | , 1  X  p  X  `
G p,q Subgraphs induced by p -th and q -th partitions of  X  H ( . ) Shannon entropy function while individual graph snapshots are denoted by non-calli-graphic, upper-case letters. Superscripts in parentheses de-note either timestamps t or graph segment indices s , accord-ingly. Similarly, subscripts denote either individual nodes i, j or node partitions p, q .

Definition 3.1 (Graph stream). A graph stream G is a sequence of graphs G ( t ) , i.e., which grows indefinitely over time. Each of these graphs links m source nodes to n destination nodes.
 For example in Figure 2, the first row shows the first three graphs in a graph stream, where m = 4 and n = 3. Fur-thermore, the graphs are represented as sparse matrices in the bottom of Figure 2 (a black entry is 1, which indicates an edge between the corresponding nodes; likewise a white entry is 0).

In general, each graph may be viewed as an m  X  n binary adjacency matrix, where rows 1  X  i  X  m correspond to source nodes and columns 1  X  j  X  n correspond to destina-tion nodes. We use sparse representation of the matrix (i.e., only non-zero entries are stored) whose space consumption is similar to adjacency list representation. Without loss of generality, we assume m and n are the same for all graphs in the stream; if not, we can introduce all-zero rows or columns in the adjacency matrices.
 One of our goals is to track how the structure of the graphs G ( t ) , t  X  1, evolves over time. To that end, we will group consecutive timestamps into segments.

Definition 3.2 (Graph stream segment). The set of graphs between timestamps t s and t s +1  X  1 (inclusive) consist the s -th segment G ( s ) , s  X  1 , which has length t s +1
Intuitively, a  X  graph stream segment  X  (or just  X  graph seg-ment  X ) is a set of consecutive graphs in a graph stream. For example in Figure 2, G (1) is a graph segment consisting of two graph G (1) and G (2) .

Next, within each segment, we will partition the source and destination nodes into source partitions and destination partitions, respectively.

Definition 3.3 (Graph segment partitions). For each segment s  X  1 , we partition source nodes into k s source partitions and destination nodes into ` s destination parti-tions. The set of source nodes that are assigned into the p -th source partition 1  X  p  X  k s is denoted by I ( s ) p . Similarly, the set of destination nodes assigned to the q -th destination partition is denoted by J ( s ) q , for 1  X  q  X  ` s . The sets I ( s ) p (1  X  p  X  k s ) partition the source nodes, in the sense that I ( s ) p  X  I ( s ) p 0 =  X  for p 6 = p 0 , while S Similarly, the sets J ( s ) q (1  X  q  X  l s ) partition the destination nodes. For example in Figure 2, the first graph segment G (1) has source partitions I (1) destination partitions J (1) 1 = { 1 } , J (1) 2 = { 2 , 3 } where k 2, ` 1 = 2. We can similarly define source and destination partition for the second graph segment G (2) , where k 2 = 3, ` = 3.
In this paper, the ultimate goals are to find communities on time-evolving graphs along with the change-points , if any. Thus, the following two problems need to be addressed.
Problem 1 (Partition Identification). Given a graph stream segment G ( s ) , how to find good partitions of source and destination nodes, which summarize the funda-mental community structure.
 The meaning of  X  X ood X  will be made precise in the next sec-tion, which formulates our cost objective function. However, to obtain an answer for the above problem, two important sub-questions need to be answered (see Section 5.1):
Problem 2 (Time Segmentation). Given a graph stream G , how can we incrementally construct graph seg-ments, by selecting good change points t s .
 Section 5.2 presents the algorithms and formalizes the notion of  X  X ood X  for both problems above. We name the whole analytic process GraphScope .
Our mining framework is based on one form of the Min-imum Description Length (MDL) principle and employs a lossless encoding scheme for a graph stream. Our objective function estimates the number of bits needed to encode the full graph stream so far. Our proposed encoding scheme takes into account both the community structures, as well as their change points in time, in order to achieve a concise description of the data. The fundamental trade-off that de-cides the  X  X est X  answers to problems 1 and 2 in Section 3.2 Figure 2: Notation illustration: A graph stream with 3 is between (i) the number of bits needed to describe the communities (or, partitions) and their change points (or, segments) and (ii) the number of bits needed to describe the individual edges in the stream, given this information.
We begin by first assuming that the change-points as well the source and destination partitions for each graph seg-ment are given, and we show how to estimate the bit cost to describe the individual edges (part (ii) above). Next, we show how to incorporate the partitions and segments into an encoding of the entire stream (part (i) above).
In this paper, a graph is presented as a m -by-n binary matrix. For example in Figure 2, G (1) is represented as
Conceptually, we can store a given binary matrix as a bi-nary string with length mn , along with the two integers m and n . For example, equation 1 can be stored as 1100 0010 0011 (in column major order), along with two integers 4 and 3.
To further save space, we can adopt some standard lossless compression scheme (such as Huffman coding, or arithmetic coding [8]) to encode the binary string, which formally can be viewed as a sequence of realizations of a binomial random variable X . The code length for that is accurately estimated as mnH ( X ) where H ( X ) is the entropy of variable X . For notational convenience, we also write that as mnH ( G ( t ) Additionally, three integers need to be stored: the matrix sizes m and n , and the number of ones in the matrix (i.e., the number of edges in the graph) denoted as | E | 1 . The | E | is needed for computing the probability of ones or ze-ros, which is required for several encoding scheme such as Huffman coding cost for storing three integers is log ? | E | + log ? m + log where log ? is the universal code length for an integer 2 that this scheme can be extended to a sequence of graphs in a segment.

More generally, if the random variable X can take values from the set M , with size | M | (a multinomial distribution), the entropy of X is where p ( x ) is the probability that X = x . Moreover, the maximum of H ( X ) is log | M | when p ( x )= 1 | M | for all x  X  M (pure random, most difficult to compress); the minimum is 0 when p ( x ) = 1 for a particular x  X  M (deterministic and constant, easiest to compress). For the binomial case, if all symbols are all 0 or all 1 in the string, we do not have to store anything because by knowing the number of ones in the string and the sizes of matrix, the receiver is already able to decode the data completely.

With this observation in mind, the goal is to organize the matrix (graph) into some homogeneous sub-matrices with low entropy and compress them separately, as we will de-scribe next.
Given a graph stream segment G ( s ) and its partition as-signments, we can precisely compute the cost for transmit-ting the segment as two parts: 1) Partition encoding cost : the model complexity for partition assignments, 2) Graph encoding cost : the actual code for the graph segment. The description complexity for transmitting the partition assignments for graph segment G ( s ) consists of the following terms:
First, we need to send the number of source and destina-tion nodes m and n using log ? m +log ? n bits. Note that, this term is constant, which has no effect on the choice of final partitions.

Second, we shall send the number of source and destina-tion partitions which is log ? k s + log ? ` s .

Third, we shall send the source and destination partition assignments. To exploit the non-uniformity across parti-tions, the encoding cost is mH ( P ) + nH ( Q ) where P is a multinomial random variable with the probability p i = m ( s ) and m ( s ) i is the size of i -th source partition 1  X  i  X  k Similarly, Q is another multinomial random variable with q 1  X  i  X  ` s .

For example in Figure 2, the partition sizes for first seg-partition assignments for G (1) costs  X  4( 2 4 log( 2 4 )+ 3( 3 log(
In summary, the partition encoding cost for graph seg-
To encode a positive integer x , we need log ? x  X  log 2 x + log 2 log 2 x + . . . , where only the positive terms are retained and this is the optimal length, if the range of x is un-known [19] where P and Q are multinomial random variables for source and destination partitions, respectively.
 After transmitting the partition encoding, the actual graph segment G ( s ) is transmitted as k s ` s subgraph segments. To facilitate the discussion, we define the entropy term for a subgraph segment G ( s ) p,q as the subgraph segment G ( s ) p,q . In particular, if the entire sub-graph segment is all 0 or all 1 (the density is exactly 0 or 1), the entropy term becomes 0.
 With this, the graph encoding cost is of segment s ; |G ( s ) p,q | is the size of sub-graph segment, i.e, m segment defined in equation 3.

In the sub-graph segment G (1) 2 , 2 of Figure 2, the number the density  X  (1) 2 , 2 = 7 8 , and the entropy H ( G (1) log 1 8 ).

Putting everything together, we obtain the segment en-coding cost as the follows: Definition 4.1 (Segment encoding cost).
 encoding cost, C ( s ) g is the graph encoding cost.
Given a graph stream G , we partition it into a number of graph segments G ( s ) ( s  X  1) and compress each segment separately such that the total encoding cost is small.
Definition 4.2 (Total cost). The total encoding cost is where C ( s ) is the encoding cost for s -th graph stream segment. For example in Figure 2, the encoding cost C up to times-tamp 3 is the sum of the costs of two graph stream segments G decompose the graph into subgraphs that are homogeneous, i.e., close to either fully-connected (cliques) or fully-discon-nected. Additionally, if such cliques are stable over time, then it places subsequent graphs into the same segment. The encoding cost penalizes a large number of cliques or lack of homogeneity. Hence, our model selection criterion favors simple enough decompositions that adequately capture the essential structure of the graph over time.

Having defined the objective precisely in equation 3 and equation 4, the next step is to search for optimal partition and time segmentation. However, finding the optimal solu-tion is NP-hard 3 . Next, in Section 5, we present an alter-nating minimization method coupled with an incremental segmentation process to perform the overall search.
In this section we describe our method, GraphScope by solving the two problems proposed in Section 3.2. The goal is to find the appropriate number and position of change-points, and the number and membership of source and des-tination partitions so that the cost of (6) is minimized. Ex-haustive enumeration is prohibitive, and thus we resort to alternating minimization. Note that we drop the subscript s on k s and ` s whenever it is clear from the context.
Specifically, we have two steps: (a) how to find good com-munities (source and destination partitions), for a given set of graph snapshots that belong to the same segment. (b) when to declare a time-tick as a change point and start a new graph segment. We describe each next.
Here we explain how to find source and destination par-titions for a given graph segment G ( s ) . In order to do that, we need to answer the following two questions: Next, we present the solution for each step.

Algorithm 1 : ReGroup (Graph Segment G ( s ) ; partition size k , ` ; initial partitions I ( s ) , J ( s ) )
Compute density  X  ( s ) p,q for all p, q based on I ( s ) repeat until no change ; Given the number of the best source and destination par-titions k and ` , we want to re-group sources and destina-tions into the better partitions. Typically this regrouping procedure alternates between source and destination nodes. Namely, we update the source partitions with respect to the current destination partitions, and vice versa. More specifi-cally, we alternate the following two steps until it converges:
It is NP-hard since, even allowing only column re-ordering, a reduction to the TSP problem can be found [11]. The cost of assigning a row to a row-group is discussed later (see (8)). The pseudo-code is listed in Algorithm 1. The initialization of Algorithm 1 is discussed separately in Sec-tion 5.3.
 Given different values for k and ` , we can easily run Al-gorithm 1 and choose those leading to a smaller encoding cost. However, the search space for k and ` is still too large to perform exhaustive tests. The central idea is to do local search around some initial partition assignments, and adjust the number of partitions k and ` as well as the partition as-signments based on the encoding cost.

Algorithm 2 : SearchKL (Graph Segment G ( s ) ; initial partition size k , ` ; initial partitions I ( s ) , J ( s ) repeat until no changes ; Here we present the details of how to compute the encod-ing cost of assigning a node to a particular partition. Our discussion focuses on assigning a source node to a source partition. The assignment for a destination node is sym-metric.

Recall a graph segment G ( s ) consists of ( t s +1  X  t s G of 2 graphs, G (1) and G (2) . Likewise, every source node in a in these ( t s +1  X  t s ) graphs. Therefore, the total number of possible edges out of one source node in G ( s ) is ( t s +1
Furthermore, the destination partitions J ( s ) i divide the des-tination nodes into ` disjoint sets with size n ( s ) i (1  X  i  X  ` , P nation partitions ( ` = 2), where the first destination parti-tion J (1) 1 = { 1 } , and the second destination partition J { 2 , 3 } .

Similarly, all the edges from a single source node in graph segment G ( s ) are also split into these ` sets. In G (1) ure 2, the edges from the 4-th source node are split into two sets, where the first set J (1) 1 has 0 edges and the second set J 2 3 edges
More formally, the edge pattern out of a source node is generated from ` binomial distributions p i (1  X  i  X  ` ) with respect to ` destination partitions. Note that p i (1) is the density of the edges from that source node to the destination partition J ( s ) i , and p i (0) = 1  X  p i (1). In G (1) 4-th source node has p 1 (1) = 0 since there are 0 edges from from 4 to J (2) 1 = { 2 , 3 } .

One possible way of encoding the edges of one source node is based on precisely these distributions p i , but as we shall see later, this is not very practical. More specifically, using the  X  X rue X  distributions p i , the encoding cost of the source node X  X  edges in the graph segment G ( s ) would be where ( t s +1  X  t s ) is the number of graphs in the graph seg-ment, n is the number of possible edges out of a source node for each graph 5 , H ( p i ) = P x = { 0 , 1 } p i ( x ) log p tropy for the each source node X  X  partition.

In G (1) of Figure 2, the number of graphs is t s +1  X  t s 3  X  1=2; the number of possible edges out of the 4-th source node n = 3; therefore, the 4-th source node costs 2  X  3  X  (0 + log 3 4 + 1 4 log 1 4 ) = 2 . 25. Unfortunately, this is not practical to do so for every source node, because the model complexity is too high. More specifically, we have to store additional m` integers in order to decode all source nodes.

The practical option is to group them into a handful of source partitions and to encode/decode one partition at a time instead of one node at a time. Similar to a source node, the edge pattern out of a source partition is also generated from ` binomial distributions q i (1  X  i  X  ` ). Now we en-code the i -th source node based on the distribution q i for a partition instead of the  X  X rue X  distribution p i for the node. The encoding cost is py. Intuitively, the cross-entropy is the encoding cost when using the distribution q i instead of the  X  X rue X  distribution p . In G (1) of Figure 2, the cost of assigning the 4-th node to second source partition I (1) 2 is 2  X  3  X  (0+ 3 4 log 7 8 which is slightly higher than using the true distribution that we just computed (2.25). However, the model complexity is much lower, i.e., k` integers are needed instead of m` .
So far, we have discussed how to partition the source and destination nodes given a graph segment G ( s ) . Now we present the algorithm to construct the graph segments in-crementally when new graph snapshots at arrive every time-tick. Intuitively, we want to group  X  X imilar X  graphs from consecutive timestamps into one graph segment and encode them all together. For example, in Figure 2, graphs G (1) and G (2) are similar (only one different edge), and therefore
One edge from 4 to 3 in G (1) , two edges from 4 to 2 and 3 in G (2) in Figure 2. ( t s +1  X  t s ) n is the total number of possible edges of a source node in the graph segment we group them into one graph segment, G (1) . On the other hand, G (3) is quite different from the previous graphs, and hence we start a new segment G (2) whose first member is G
The guiding principle here is still the encoding cost. More specifically, the algorithm will combine the incoming graph with the current graph segment if there is a storage benefit, otherwise we start a new segment with that graph. The meta-algorithm is listed in Algorithm 3.

Algorithm 3 : GraphScope (Graph Segment G ( s ) ; En-coding cost c o ; New Graph G ( t ) output : updated graph segment, new partition
Compute new encoding c n of G ( s ) S { G ( t ) }
Compute encoding cost c for just G ( t ) // check if there is any encoding benefit if c n  X  c o &lt; c then else
Once we decide to start a new segment, how should we ini-tialize the number and membership of its partitions? There are several ways to do the initialization. Trading-off con-vergence speed versus compression quality, we propose and study two alternatives: Fresh-start. One option is to start from a small k and ` , typically k = 1 and ` = 1, and progressively increase them (see Algorithm 2) as well as re-group sources and destina-tions (see Algorithm 1). From our experiments, this scheme is very effective in leading to a good result. In terms of computational cost, it is relatively fast, since we start with small k and ` .
 ten have a strong similarity. We can leverage this similarity in the search process by starting from old partitions. More specifically, we initialize k s +1 and ` s +1 to k s and ` tively. Additionally, we initialize I ( s +1) and J ( s +1) J ( s ) . We study the relative CPU performance of fresh-start and resume in Section 6.3.
In this section, we will evaluate the result on both com-munity discovery and change detection of GraphScope us-ing several real, large graph datasets. We first describe the datasets in Section 6.1. Then we present our experiments, which are designed to answer the following two questions:
Finally, we present some additional mining observations that our method automatically identifies. To the best of our knowledge, no other parameter-free and incremental method for time-evolving graphs has been proposed to date. Our goal is to automatically determine the best change-points in time, as well as the best node partitionings, which concisely reveal the basic structure of both communities as well as their change over time. It is not clear how parameters of other methods (e.g., number of partitions, graph similarity thresholds, etc) should be set for these methods to attain this goal. GraphScopeis fully automatic and, as we will show, still able to find meaningful communities and change points.
In this section, we describe the datasets in our experi-ments. The traffic trace consists of TCP flow records collected at the backbone router of a class-B university network. Each record in the trace corresponds to a directional TCP flow between two hosts, with timestamps indicating when the flow started and finished. With this traffic trace, we use a window size of one hour to construct the source-destination graph stream. Each graph is represented by a sparse ad-jacency matrix with the rows and the columns correspond-ing to source and destination IP addresses, respectively. An edge in a graph G ( t ) means that there exist TCP flows (pack-ets) sent from the i -th source to the j -th destination during the t -th hour. The graphs involve m = n =21,837 unique cam-pus hosts (the number of source and destination nodes) with a per-timestamp average of over 12K distinct connections (the number of edges). The total number of timestamps T is 1,222. Figure 3(a) shows an example of superimposing 6 source-destination graphs in one time segment of 18 hours. Every row/column corresponds to a source/destination; the dot there indicates there is at least a packet from the source to the destination during that time segment. The graphs are correlated, with most of the traffic to or from a small set of server-like hosts.

GraphScope automatically exploits the sparsity and cor-relation by organizing the sources and destinations into ho-mogeneous groups as shown in Figure 3(b).
 This consists of the email communications in Enron Inc. from Jan 1999 to July 2002 [2]. We construct sender-to-recipient graphs on a weekly basis. The graphs have m = n = 34 , 275 senders/recipients (the number of nodes) with
Two graphs are superimposed together by taking the union of their edges. Figure 3: NETWORK before and after GraphScope for the an average of 1,479 distinct sender-receiver pairs (the num-ber of edges) every week.

Like the NETWORK dataset, the graphs in ENRON are also cor-related. GraphScope can reorganize the graph into homo-geneous partitions (see the visual comparison in Figure 4). Figure 4: ENRON before and after GraphScope for the The CELLPHONE dataset records the cellphone activity for m = n =97 users from two different labs in MIT [1]. Each graph snapshot corresponds to a week, from Jan 2004 to May 2005. We thus have T =46 graphs, one for each week, excluding weeks with no activity.

We plot the superimposed graphs of weeks 38 to 42 in 2004 at Figure 5(a), which looks much more random than NETWORK and ENRON . However, GraphScope is still able to extract the hidden structure from the graph as shown in Figure 5(b), which looks much more homogeneous (more details in Section 6.2). Figure 5: CELLPHONE before and after GraphScope, for DEVICE dataset is constructed on the same 97 users whose cellphones periodically scan for nearby phones and comput-ers over Bluetooth. The goal is to understand people X  X  be-havior from their proximity to others. Figure 6(a) plots the superimposed user-to-user graphs for one time segment where every dot indicates that the two corresponding users are physically near each other. Note that the first row rep-resents all the devices that do not belong to any of the 97 individual users (mainly laptop computers, PDAs and other peoples X  cellphones). Figure 6(b) shows the resulting user partitions for that time segment, where cluster structure is revealed (see Section 6.2 for details). Figure 6: DEVICE before and after GraphScope for the The TRANSACTION dataset has m = n =28 accounts of a com-pany, over 2,200 days. An edge indicates that the source ac-count had funds transfered to the destination account. Each graph snapshot covers transaction activities over a window of 40 days, resulting in T =51 time-ticks for our dataset.
Figure 7(a) shows the transaction graph for one times-tamp. Every black square at the ( i, j ) entry in Figure 7(a) indicates there is at least one transaction debiting the i th ac-count and crediting the j th account. After applying Graph-Scope on that timestamp (see Figure 7(b)), the accounts are organized into very homogeneous groups with a few excep-tions (more details in Section 6.2). Figure 7: TRANSACTION before and after GraphScope for a
Now we qualitatively present the mining observation on all the datasets. More specifically, we illustrate that (1) source and destination groups correspond to semantically meaningful clusters; (2) the groups evolve over time; (3) time segments indicate interesting change-points. Figure 8: NETWORK zoom-in (log-log plot): (a) Source Despite the bursty nature of network traffic, GraphScope can successfully cluster the source and destination hosts into meaningful groups. Figure 8(a) and (b) show the ac-tive source and destination nodes organized by groups for two different time segments. Note that Figure 8 is in log-log scale to visualize those small partitions. For example, source nodes are grouped into (1) active hosts which talk to a small number of hosts, (2) P2P hosts that scan a number of hosts, and (3) administrative scanning hosts 7 which scan many hosts. Similarly, destination hosts are grouped into (1) active hosts, (2) cluster servers at which many students login remotely to work on different tasks, (3) web servers which hosts the websites of different schools, and (4) mail servers that have the most incoming connections. The main difference between Figure 8(a) and (b) is that a source group of unusual scanners emerges in the latter. GraphScope can automatically identify the change and decide to split into two time segments.
 As in NETWORK , we also observe meaningful groups in CELL-PHONE . Figure 9 (a) illustrate the calling patterns in the fall semester of 2004, where two strong user partitions (G1 and G2) exist. The dense small partition G3 is the service call in campus, which has a lot of incoming calls from everyone. Figure 9 (b) illustrates that the calling patterns changed during the winter break which follows the fall semester. The evolving group behavior is also observed in the DEVICE dataset. In particular, two dense partitions appear in Fig-ure 10(a): after inspecting the user ids and their attributes, we found that the users in group U 1 are all from the same school with similar schedule, probably taking the same class; the users in U 2 all work in the same lab. In a later time seg-ment (see Figure 10(b)), the partition U 1 disappeared, while the partition U 2 is unchanged.
 TRANSACTION As shown in Figure 7(b), GraphScope successfully organizes the 28 accounts into three partitions. Upon closer inspec-
The campus network is constantly running some port-scanning program to identify potential vulnerabilities of the in-network hosts. Figure 9: CELLPHONE : a) Two calling groups appear dur-Figure 10: DEVICE : (a) two groups are prominent. Users tion, these groups correspond to the different functional groups of the accounts (e.g.,  X  X arketing X ,  X  X ales X ) 8 . In Fig-ure 7(b), the interaction between first source partition (from the top) and second destination partition (from the left) cor-respond to mainly the transactions from assets accounts to liability and revenue accounts, which obeys common busi-ness practice.
 The source and destination partitions usually correspond to meaningful clusters for the given time segment. Moreover, the time segments themselves usually encode important in-formation about changes. Figure 1 plots the encoding cost difference between incorporating the new graph into the cur-rent time segment vs. starting a new segment. The verti-cal lines on Figure 1 are the top 10 splits with largest cost savings when starting a new segment, which actually corre-spond to the key events related to Enron Inc. Moreover, the intensity in terms of magnitude and frequency dramatically increases around Jan 2002 which coincides with several key incidents such as the investigation on document shredding, and the CEO resignation.
We compare fresh-start and resume (see Section 5.3) in terms of compression benefit, against the global compres-sion estimate and the space requirement for the original graphs, stored as sparse matrices (adjacency list represen-tation). Figure 11 shows that both fresh-start and resume
Due to anonymity requirements, the account types are obfuscated. GraphScope achieve high compression gain (less than 4% of the original space), which is even better than the global compression on the graphs (the 3rd bar for each dataset). Our two variations require about the same space.
 Figure 11: Relative Encoding Cost: Both resume and
Now we illustrate the CPU cost (scalability) of fresh-start and resume . As shown in Figure 12(a) for NETWORK (similar result are achieved for the other datasets, hence omitted), the CPU cost per timestamp/graph is stable over time for both fresh-start and resume , which suggests that both pro-posed methods are scalable to streaming environments.
Furthermore, resume is much faster than fresh-start as shown in Figure 12(b), especially for large graphs such as in NETWORK . There, resume only uses 10% of CPU time com-pared to fresh-start . (a) CPU cost ( NETWORK ) (b) Relative CPU Figure 12: CPU cost: (a) the CPU costs for both re-
We propose GraphScope, a parameter-free scheme to mine streams of graphs. Our method has all of the following de-sired properties: 1) It is rigorous and automatic, with no need for user-defined parameters. Instead, it uses the Mini-mum Description Language (MDL) principle, to decide how to form communities, and when to modify them. 2) It is fast and scalable, carefully designed to work in a streaming set-ting. 3) It is effective, discovering meaningful communities and meaningful transition points.

We also present experiments on several real datasets, span-ning 500 Gigabytes. The datasets were from widely di-verse applications (university network traffic, email from the Enron company, cellphone call logs and Bluetooth connec-tions). Because of its generality and its information theo-retic underpinnings, GraphScope is able to find meaningful groups and patterns in all the above settings, without any specific fine-tuning on our side.

Future research directions include extensions to create hi-erarchical groupings, both of the communities as well as of the time segments.

