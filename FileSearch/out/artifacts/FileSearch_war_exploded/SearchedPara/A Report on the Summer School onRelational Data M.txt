 Relational Data Mining (RDM) is the multi-disciplinary field dealing with knowledge discovery from relational databases consisting of multiple tables. To emphasize the contrast to typical data mining approaches that look for patterns in a single relation of a database, the name Multi-Relational Data Mining (MRDM) is often used as well. Mining data which consists of complex/structured objects also falls with-in the scope of this field: the normalized representation of such objects in a relational database requires multiple tables. The field aims at integrating results from existing fields such as inductive logic programming (ILP), KDD, data mining, machine learning and relational databases; producing new techniques for mining multi-relational data; and practical applications of such techniques.
 Present RDM approaches consider all of the main data min-ing tasks, including association analysis, classification, clus-tering, learning probabilistic models and regression. The pattern languages used by single-table data mining approa-ches for these data mining tasks have been extended to the multiple-table case. Relational pattern languages now include relational association rules, relational classification rules, relational decision trees, and probabilistic relational models, among others. RDM algorithms have been devel-oped to mine for patterns expressed in relational pattern languages. Typically, data mining algorithms have been up-graded from the single-table case: for example, distance-based algorithms for prediction and clustering have been upgraded by defining distance measures between examples/ instances represented in relational logic. RDM methods have been successfully applied across many application ar-eas, ranging from the analysis of business data, through bioinformatics (including the analysis of complete genomes) and pharmacology (drug design) to Web mining (e.g., infor-mation extraction from Web sources).
 The Summer School on Relational Data Mining provided a comprehensive introduction to the techniques and appli-cations of relational data mining by leading experts in the field. The lectures given at the school are summarized be-low. The slides of the lectures were published as handouts and are also available for download at the Web page of the school http://www-ai.ijs.si/SasoDzeroski/RDMSchool  X  The introductory lecture, X  X n introduction to relati-onal data mining X  by Sa X so D X zeroski, first summarized the standard data mining tasks (classification, regres-sion, clustering, association discovery) and approaches (trees, rules, nearest-neighbor) and illustrated them for the propositional case. After demonstrating the need to mine (multi)-relational data, the topic of RDM was introduced and a brief overview of RDM approa-ches was given.  X  The second lecture, X  X n introduction to inductive logic programming X , given by Peter Flach on behalf of Nada Lavra X c, introduced the field of ILP, which is concerned with learning logic programs from examples and back-ground knowledge. Fundamental topics such as search-ing the space of program clauses and the generality lattice induced by theta-subsumption were covered, as well as generic ILP approaches based on the search of refinement graphs and least general generalization.  X  The lecture  X  X ropositionalization as a way of under-standing RDM and ILP X , also presented by Peter Flach, covered another generic approach to ILP, namely the approach of transforming a relational learning problem to a propositional one. The talk clarified the relation-ship between relational and propositional learning and the role of representation in RDM. It also presented an approach to propositionalization for individual-center-ed strongly typed representations, where feature con-struction is guided by types.  X  The three main messages of the lecture  X  X  methodol-ogy of ILP X  by Luc De Raedt were that: (1) ILP ap-plies essentially to any machine learning / data mining task, not just concept learning, (2) There is a recipe for deriving new ILP algorithms from propositional ones, and (3) ILP as an expressive framework has many spe-cial cases, which are often studied separately.  X  The lecture  X  X ogical trees for classification, regres-sion and clustering X  by Hendrik Blockeel presented an approach to using decision trees for relational prob-lems. The approach extends well known techniques for induction of decision trees in two ways: (1) Predic-tive clustering generalizes over several induction tasks (classification regression and clustering), while (2) First order logical decision trees make trees usable in the context of ILP. The resulting technique therefore com-bines the high expressiveness of first order logical deci-sion trees with the efficiency and accuracy of decision trees.  X  The lecture  X  X elational subgroup discovery X , given by Stefan Wrobel, dealt with the problem of finding inter-esting patterns which are only valid in selected regions of the instance space. These local patterns are often impossible to find if we try to model the entire instance space. The talk first introduced several medical and business problems which can be successfully solved by relational subgroup discovery, and then presented the algorithm MIDOS which can be used for finding rela-tional descriptions of subgroups.  X  The next lecture by Stefan Wrobel, titled  X  X elational distance-based methods X , presented several relational instance based learning systems and explained the dis-tance functions used in these systems. The talk also presented several successful applications of these tech-niques in the fields of chemistry and biology.  X  The lecture  X  X ernel-based learning from structured data X , given by Thomas Gaertner, first gave a clear explanation of the basics of support vector machines. The problem of selecting an appropriate kernel func-tion for a given domain was pointed out, emphasizing that the kernel is a part of the background knowledge about a domain. The talk then discussed how to con-struct kernel functions for structured data and con-cluded with some example applications of this tech-nique.  X  The lecture  X  X earning statistical models from rela-tional data X  given by Lise Getoor presented an exten-sion of statistical models for relational problems. It first covered the topic of Bayesian networks, which are the foundation of the Probabilistic Relational Models (PRMs). PRMs, ways to learn their structure and pa-rameters from data, and their applications to practical problems were then discussed.  X   X  X ayesian logic programs X  (BLPs), discussed in the lecture by Luc De Raedt (presenting joint work with Kristian Kersting), are the first order equivalent of Bayesian networks. In addition, they generalize pure Prolog, dynamic Bayesian netorks, dynamic Bayesian multinets, hidden Markov models etc. The talk first focussed on the language of BLPs, then on leaning the parameters and structure of BLPs.  X  In the lecture  X  X pplications of ILP/RDM to bioinfor-matics X , Ross King presented a number of successful applications of ILP/RDM to real problems in the field of bioinformatics. The applications presented included structure activity relationship modeling, functional ge-nomics and  X  X he Robot Scientist Project.  X  The lecture  X  X DM Applications; An overview X , given by Sa X so D X zeroski, presented a variety of ILP/RDM applications with a more detailed description of some selected applications. Besides the applications in the area of bioinformatics, which were the topic of the previous talk, the lecture presented applications from areas of medicine, environmental science, traffic en-gineering, mechanical engineering, text/web mining, natural language processing, business data analysis, music, software engineering and adaptive systems man-agement.  X  The last lecture on  X  X nductive databases X  was given by Luc De Raedt. Inductive databases store both data and patterns valid in the data. In inductive databases, data mining is viewed as a querying process. The first part of the talk presented several examples of (pre-liminary) inductive databases while the second part described a logic oriented view on the principles of in-ductive databases.

