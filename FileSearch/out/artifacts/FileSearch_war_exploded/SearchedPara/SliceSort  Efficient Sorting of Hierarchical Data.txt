 Sorting is a fundamental operation in data processing. While the problem of sorting flat data records has been extensively studied, there is very little work on sorting hierarchical data such as XML documents. Existing hierarchy-aware sorting approaches for hierarchical data are based on creating sorted subtrees as initial sorted runs and merging sorted subtrees to create the sorted output using either explicit pointers or absolute node key comparisons for merging subtrees. In this paper, we propose SliceSort , a novel, level-wise sort-ing technique for hierarchical data that avoids the drawbacks of subtree-based sorting techniques. Our experimental per-formance evaluation shows that SliceSort outperforms the state-of-art approach, HErMeS , by up to a factor of 27%. H.2.4 [ System ]: Query processing Hierarchical Data, Slicesort, Sorting
Sorting is a fundamental operation in data processing and techniques to optimize sorting  X  X lat X  data have been exten-sively studied for both main-memory and external memory contexts [7, 6]. However, there is very little work on sorting hierarchical data such as XML documents [9, 8]. In a fully sorted hierarchical document, the list of child nodes of every non-leaf node is sorted according to some given criteria (e.g., the key of the child node or some function of the contents in the subtree rooted at the child node). As a simple ex-ample, Figures 1(b) and (c) show an unsorted and a sorted hierarchical data, respectively, where the nodes are sorted alphabetically by their key values given by the node labels.  X 
The work was done when the author was at National Uni-versity of Singapore.

Hierarchical sorting has application in the archival of sci-entific data, which is predominantly stored in hierarchical data formats. To archive a new data version, an efficient approach is to first sort the new data and then merge it with the existing data version [8, 9].

Example 1. Consider the archival approach proposed in [3] to store multiple versions of hierarchical data. Figure 1(a) shows an example archived document, V 1 -2 , that consists of two data versions. Each node in the document has a node label (e.g., /, A, B) and either an explicit version tag (in-dicated by  X  X  = ... X ) or an implicit version tag. A node X  X  version tag indicates in which version(s) of the document the node is present; for example, node  X  X  X  is present in only version 1, node  X  X  X  is present in only version 2, and the root node  X / X  is present in both versions 1 and 2. A node without an explicit version tag has an implicit tag that is inherited from its parent node. For example, nodes  X  X  X  and  X  X  X  both inherit the version tag from its parent node  X  X  X  and they are all present in only version 1; while node  X  X  X  inherits its ver-sion tag from node  X  X  X  and appears only in version 2. Note that the document V 1 -2 is hierarchically sorted based on the lexicographical order of its node labels: the child nodes of the root node are sorted with node  X  X  X  preceding node  X  X  X , and the child nodes of node  X  X  X  are sorted with node  X  X  X  preceding node  X  X  X .
 Consider a new version of the document V 3 (shown in Figure 1(b)) to be merged into the archived document V 1 -An efficient approach to merge the documents is to first sort V 3 into V 3 (shown in Figure 1(c)) and merge them using a synchronized traversal of the pair of sorted documents [3]. The merged archived document is shown in Figure 1(d).
Another application of hierarchical sorting is in change detection of XML documents, which is useful to control the changes in a warehouse with a large volume of XML docu-ments [8]. Detecting changes in such an environment serves many purposes such as versioning, querying the past, and monitoring the changes [4, 5, 10]. Earlier works on change detection in XML documents (e.g., [4, 5, 10]) operate on un-sorted documents that are assumed to be entirely resident in main memory. However, the state-of-the art approaches that can operate on large, disk-based data are based on sorted documents [8].

Hierarchical sorting is also useful for processing batch up-dates to an existing sorted XML document. The idea is to sort the batch of updates and merge it with the existing document [9, 8].

Hierarchical sorting is also useful in the evaluation of or-der by clause in XPath [1] and XQuery [2] that allows the (a) Archived document (b) New document (c) Sorted new document (d) Updated archived document results of queries to be output in a specific order. This clause sorts the sequence of result XML fragments, but does not recursively sort the fragments themselves. However, with the help of DTDs, hierarchical sorting can be expressed in XPath and XQuery using explicitly specified nested order by clause. The hierarchical sorting can provide an efficient algorithm for processing such queries.

A straightforward method to sort hierarchical XML data is to flatten the XML tree into a file of flat records so that conventional sorting methods can be applied to sort this derived format [9]. In this approach, each XML node is represented by an absolute key, which is formed by the con-catenation of the local keys of all nodes along the path from the root node to this node, and the collection of XML nodes are sorted based on their global absolute keys. Although this approach is easy to implement, it has very poor perfor-mance as it is sorting the nodes globally using their absolute keys instead of exploiting the hierarchical structure of the input data to sort each collection of sibling nodes locally. To address the limitation of this naive approach, two hierarchy-aware approaches, NeXSort [9] and HErMeS [8], have recently been proposed. Both of these methods are based on a two-phase approach: the first phase creates sorted runs each of which is a sequence of one or more sorted subtrees, and the second phase merges the sorted runs to produce the final sorted output. A subtree is referred to as sorted iff the list of child nodes of every non-leaf node belonging to this sub-tree is sorted according to the given criteria.

In NeXSort , each sorted run consists of a single sorted subtree, and explicit pointers are used to link the sorted subtrees to maintain the parent-child relationships for par-ent and child nodes that are stored in different sorted runs. By exploiting these explicit pointers, the final sorted output is produced using a depth-first traversal of the sorted runs by following the appropriate pointers. Thus, the second phase of NeXSort essentially merges all its single-subtree sorted runs in one pass by a depth-first traversal of its sorted runs (starting from the sorted run containing the root node) with the help of the pointers to sorted child subtrees. In contrast to NeXSort , HErMeS is a generalization of the well-known ex-ternal merge-sort technique. Sorted runs are created using a hierarchy-aware replacement selection algorithm such that each sorted run is a sequence of sorted subtrees, and each data node is associated with an absolute key represented in a compressed form. The sorted runs are iteratively merged in the second phase to form the sorted output.

In summary, the two existing hierarchy-aware approaches are both based on creating sorted subtrees as initial sorted runs and merging sorted subtrees to create the sorted out-put. The merging of two subtrees requires locating in one subtree the parent node of the root node of the other sub-tree. Whereas NeXSort performs the merging by using ex-plicit pointers, HErMeS merges based on comparing absolute node keys.
 In terms of performance, HErMeS was shown to outperform NeXSort [8]. The drawback of NeXSort is that as each sorted run consists of only a single sorted subtree, there are many more sorted runs created in the first phase, and the merging of these sorted runs in the second phase using the explicit pointers incurs a lot of random disk I/Os. For HErMeS ,its drawback is the overhead incurred for manipulating absolute node keys.
 In this paper, we propose a novel approach, named Slice-Sort , that does not require using explicit pointers or global absolute keys for sorting hierarchical data. Instead, Slice-Sort sorts in a top-down, level-by-level manner by using only local node keys. Given any two nodes at the same level in a hierarchical document, the relative ordering of the two nodes can be determined as follows: if the nodes are sibling nodes (i.e., they have the same parent), then the two nodes are ordered based on their local node keys; otherwise, the nodes are ordered based on the relative ordering of their parent nodes.
 SliceSort sorts data in three phases. In the first phase, SliceSort reorganizes the pre-order-formatted input XML document into  X  X lices X , where each slice corresponds to the data at a level in the document. SliceSort essentially scans the input document in depth-first order, and transforms and stores the data in a breadth-first ordered format. In the second phase, each slice (starting from the top slice) is sorted using the well-known external merge-sort algorithm; the nodes at each slice are ordered using their local node keys as well as the relative ordering of their parent nodes. In the third phase, SliceSort performs a depth-first traversal of the sorted slices to transform them to the sorted, pre-order-formatted document.

Our paper makes the following contributions. 1. We introduce a novel technique, SliceSort ,forsorting 2. We conduct a performance evaluation study to com-
The input to the hierarchical sorting problem is a tree-structured XML document T in where the tree nodes are or-ganized in a pre-ordered format. The output is a sorted XML document T out (also in pre-ordered format) that is de-rived from T in such that for each internal node in T out its child nodes are ordered based on some sort key.
In general, the sort key for a node n can be an arbitrary function of the contents of the subtree rooted at n (e.g., size of subtree in terms of number of nodes). For simplicity of presentation, in this paper, we assume that each node n is associated with a  X  X ocal X  key, denoted by key ( n ), which is a string value that is stored as one of the node X  X  attributes in the input document T in . Thus, given two sibling nodes n and n in T in , the subtree rooted at n precedes that at n in T out if and only if key ( n )precedes key ( n ) lexicographically. We will discuss how SliceSort can handle more general sort keys that can be derived dynamically at run-time in Sec-tion 2.4. We use payload ( n ) to denote any other attribute values and textual contents associated with node n . In this paper, we use h to denote the height of T in ;thus, T in has h + 1 levels of nodes, where the root node is at level 0 and the last level of leaf nodes is at level h . Wewillusethe term  X  X ree X  and  X  X ierarchical document X  interchangeably. SliceSort consists of three phases. In the first phase, SliceSort flattens T in into  X  X lices X , L 0 ,  X  X  X  , L h ,whereeach slice L i corresponds to the nodes at level i in T in .Inthe second phase, the slices are sorted top-down starting from L 0 to L h ; each slice is sorted using the established external merge-sort algorithm. Finally, in the third phase, Slice-Sort performs a depth-first traversal of the sorted slices to stitch them together to produce T out . In the following, we elaborate on the three phases assuming that all the data and structurescanbestoredinthemainmemory. Weconsider memory management issues in Section 3.
In the first phase, SliceSort transforms the pre-order-formatted T in into a level-wise representation containing h + 1 slices of data. Each slice, denoted by L i ,isasequential list of all the nodes at level i in T in . The ordering of the nodes in L i are consistent with their ordering in T in : a node n precedes another node n in L i if and only if n and n are at level i in T in such that n precedes n in the pre-order traversal of T in . SliceSort creates the h + 1 slices by performing a single sequential scan of T in :aseachnodeis encountered in the pre-order traversal scan of T in , the node is appended to slice L i ,where i is the level of the node.
To maintain the hierarchical structure of the data, the slices are created such that the parent-child relationships in T in are preserved by recording some additional informa-tion in the slices. Specifically, for each slice, each node is assigned a unique integer identifier, denoted by id ( n ), rep-resenting its sequential rank in the slice. That is, if n is the j th node in a slice, then id ( n )= j . For each node n , we also record the identifier of its parent node, denoted by parid ( n ) 1 . Thus, each node n in a slice is represented by a formation in the slices can be used to reconstruct T in .Note that the parid ( n ) of a node n is easily derived by simply us-
For the root node n root of T in , parid ( n root )=0. ing a stack to maintain the identifiers of the ancestor path of nodes of the current node being processed in T in . The second phase sorts the slices created by the first phase. Let L i denote the sorted slice L i , i  X  [0 ,h ]. The idea of SliceSort is that once all the slices have been sorted, T can be generated by stitching the nodes in the sorted slices together based on their parent-child relationships. There-fore, given two nodes n and n in slice L i , n precedes n in T out if and only if n precedes n in L i .
 It follows that we can define the hierarchical sorting of T in in terms of the level-wise sorting of the slices as follows. Given two nodes n and n in slice L i , n precedes n in L i one of the following conditions holds:
C1. n and n are sibling nodes and key ( n )precedes key ( n );
C2. n and n have different parent nodes (given by p and
Based on the above recursive sorting definition, SliceSort sorts the slices in a top-down manner by sorting L i before L +1 .For L 0 , the sorting is trivial since L 0 consists of only the root node of T in .For L 1 , since all the nodes are sibling nodes (their parent is the root node of T in ), they are sorted based simply on condition C1. For the general case of L i i&gt; 1, the sorting of L i may need to take into account the ordering of the nodes in L i  X  1 due to condition C2.
To facilitate the checking of the ranks of the nodes in the sorted slices, SliceSort creates a mapping table, denoted by MT i , during the sorting of L i to L i .Giventherankofa node n in L i , MT i returns the rank of n in L i .Each MT is created during the final merging pass to generate L i :as each node n is output to L i ,weset MT i [ id ( n )] = j ,where id ( n )and j are the ranks of n in L i and L i ,respectively. At end of the second phase, all the slices have been sorted. Since the ordering of the nodes in each L i is equivalent to the ordering of nodes at level i in T out , all that remains to be done in the third and final phase of SliceSort is to stitch together the nodes in the sorted slices based on their parent-child relationships to produce T out organized in pre-order format. This is achieved by essentially performing a depth-first traversal of the sorted slices.

For each sorted slice L i , we first initialize a cursor to point to the first node of L i . We refer to the node pointed by the cursor in L i as the current node in L i and denote it by n The depth-first traversal of the sorted slices is performed by visiting the current nodes in them in a top-down manner. The traversal first visits the root node n 0 in L 0 and outputs n 0 to T out . The traversal then recursively visits n 1 and so on. In general, whenever the traversal visits a node n i ,it first checks whether n i is a child node of n i  X  1 based on the parid information. If n i is a child of n i  X  1 , then the traversal outputs n i to T out and recursively visits n i +1 .Otherwise, if n i is not a child of n i  X  1 , then it means that the entire subtree rooted at n i  X  1 has been output to T out .Inthiscase, if n i  X  1 is not the last node in L i  X  1 , then the cursor in L updated to point to the next node in L i  X  1 and the traversal then recurses by visiting the new n i  X  1 ;otherwise,if n is the last node in L i  X  1 , then it means the entire subtree rooted at n i  X  2 has been output to T out and we recursively check if n i  X  2 isthelastnodein L i  X  2 and so on. The depth-first traversal (and hence also SliceSort ) terminates once all the nodes in the sorted slices have been visited and output
Our discussion of SliceSort has so far assumed that the sorting criteria is based on the local keys associated with the nodes in the input tree. It is straightforward to adapt SliceSort to other sorting criteria that is based on the con-tents of the subtree rooted at each node. Examples include (1) the total size (in bytes) of the subtree, (2) the number of nodes in the subtree, (3) the height of the subtree. To handle such general sorting criteria, SliceSort only needs to modify slightly its first phase. Specifically, for each node n that is encountered in the pre-order traversal, SliceSort maintains n in a data stack and updates its sorting value during the traversal of its subtree. After the entire subtree rooted at n has been visited, SliceSort appends n together with its derived sorting value into the corresponding slice and removes n from the data stack. The maximum number of nodes to be maintained in the data stack is bounded by the height of the input tree.

Note that the two existing hierarchy-aware approaches ( NeXSort and HErMeS ) can also be adapted to handle such general sorting criteria by inserting a node into an initial sorted run only after the subtree rooted at the node has been traversed.
In our simplified discussion of SliceSort in the previous section, we have assumed that all the data and structures can be stored in main memory. Clearly, this assumption does not hold when the input data is large. In this section, we explain how SliceSort manages memory to sort large data files. Let B denote the total number of memory pages allocated for sorting.
In the first phase, memory needs to be allocated among the input data T in and the slices ( L 0 ,  X  X  X  , L h ). SliceSort allocates one memory page for reading T in and the remaining memory pages (denoted by M pages) for storing the slices. Let B i denote the main memory buffer allocated for slice L , i  X  [0 ,h ], which has M i pages; thus h i =0 M i = M .As SliceSort scans T in , each data node at level i is appended to B i . Whenever B i becomes full, SliceSort will flush B to the disk file corresponding to slice L i .

SliceSort uses a simple heuristic to allocate the memory for the slices such that each M i is proportional to an esti-mated size of L i . Assuming that the height of T in is h ,the average size of a node is navg , and the average node fan-out of T in is f . The number of nodes in L i is estimated to be f and the size of L i is estimated to be f i  X  navg . The total size of nodes in T in is estimated to be size = h i =0 f i  X  navg . Therefore, each M i is max { 1 , f i  X  navg size  X  M } pages.
Theremainingissueishowarethevaluesof h , navg ,and f estimated? To estimate h , SliceSort scans the first few pages of T in and estimates h to be the maximum length of the root-to-leaf paths sampled. Similarly, to estimate navg , SliceSort scans the first few pages of T in and es-timates navg to be the average size of all nodes sampled. Since size  X  M , the estimated value of f is derived to be SliceSort will dynamically reduce the buffer pages for the allocated slices (flushing buffers if necessary) to create new buffers for the additional slices using the same heuristic.
Since SliceSort relies on the well-known external merge-sort algorithm for sorting slices, the memory allocation pol-icy for the sorting is already taken care and optimized. How-ever, there are two additional considerations sorting each L 1. the creation of the mapping table MT i during the final 2. the use of the mapping table MT i  X  1 to create the ini-Since the number of nodes in L i isknownattheendofthe first phase, the storage required for MT i is known before the start of the second phase. In this section, we discuss the construction and usage of MT i when MT i cannot fit entirely in main memory.
 To construct MT i during the last merging pass of sorting L , we allocate one memory page P to store MT i and flush P to disk when it becomes full. As each record is output to the final sorted run of L i , we append an entry for the record into P . Thus, in contrast to the main-memory resident MT discussedinSection2.2,whichissortedinascendingorder of the rank of nodes in L i , the disk copy of MT i is ordered in ascending order of the rank of nodes in L i .

To create the initial sorted runs of L i +1 , we essentially need to perform a foreign-key join of L i +1 and MT i to map parid ( n )ofeachnode n in an initial sorted run to its rank in L . This can be achieved using an appropriate standard join algorithm that is chosen in a cost-based manner. For exam-ple, using the nested-loop join method, k memory pages will be allocated for loading L i +1 (the  X  X uter relation X ) and the remaining ( B  X  k ) pages will be allocated for loading MT (the  X  X nner relation X ). Thus, the size of each initial run is at most k pages. To maximize the size of each initial run, k is set to B  X  1.
In the third phase, memory needs to be allocated for read-ing in the sorted slices and writing the sorted output T out Similar to the allocation principle for the first phase, Slice-Sort allocates one page for writing T out , and allocates the remaining memory pages among the sorted slices L i such that the size of the buffer B i for each L i is proportional to its size (which is known at the end of the second phase).
Thus, for each L i , SliceSort sequentially scans L i and loads the pages of L i into B i until the buffer B i is full. Whenever all the nodes in B i have been output to T out , SliceSort will read into B i the next sequence of pages from L i .
This section presents our experimental study to evaluate the efficiency of our proposed SliceSort algorithm. We compare SliceSort against state-of-the-art approach, HEr-MeS , for sorting of hierarchical data.
 Platform. Our experiments were conducted on a dual-core, 2 . 33GHz PC running Linux 2.6.32-41, 32-bit with 3 . 75GB of RAM, and a 250GB hard disk. Both SliceSort and HEr-MeS were implemented in C++.
 Data Sets &amp; Parameters. To create input data sets, we used the same data generator from [8] that generates input XML documents. Each node in the generated tree has a ran-domly generated character string as its label. Following [8], we used the node label as its key value and set the payload ofanodetobeempty.

The data generator allows the following three parameters to be varied: the node label (i.e., key) length, the maximum tree height, and node fan-out. The fan-out of each node follows a uniform distribution ranging from 0 to a specified maximum fan-out value.

Due to the space limit, we only present the results on varying fan-out parameter; similar trends are also observed for varying other parameters. We generated 4 data sets, D to D 4 , by setting height =8, keylength = 10, and varying fanout using the values 16 , 18 , 20, and 22. The buffer size used in the experiments is 1000MB.
 Metrics. The algorithms are compared in terms of their end-to-end running time which includes the time to read the input tree document, sort, and write the sorted docu-ment into an output file. The dominant CPU operations in both algorithms are the number of key comparisons ,whichis counted as follows. For SliceSort , the number of key com-parisons refers to the number of local node key comparisons. The comparisons of parent node identifiers (during the sec-ond phase) are excluded because the identifier comparisons, which are integer value comparison, are much cheaper than the XML node key comparisons, which are string value com-parisons. For HErMeS , the key comparisons include both the comparisons on local keys of nodes in the tree and abso-lute keys because HErMeS needs to store the absolute keys on sorted runs in some cases. Thus, a key comparison in HErMeS is more expensive than that in SliceSort .

The dominant I/O operation of SliceSort and HErMeS is the number of passes to read and write the entire document. Results. Figure 2 compares the performance of SliceSort and HErMeS as a function of the fan-out parameter (corre-sponding to data sets D 1 to D 4 ). The results show that SliceSort outperforms HErMeS in the order of 18% to 27%. The second and third columns in Table 1 show the detailed breakdown of the running times for D 4 ; we omit showing the results for the other data sets as they exhibit similar trends. Observe that although SliceSort incurred more I/O time than HErMeS , the CPU time spent by SliceSort is much smaller than that of HErMeS , resulting in SliceSort having an overall better performance than HErMeS . Comparing the number of passes required for sorting, HErMeS is more effi-cient as it requires only two passes: one pass to read the input tree to create initial sorted runs, and another pass to merge the initial sorted runs to create the output tree. In contrast, SliceSort requires one pass for each of its three phases. However, the number of key comparisons in Slice-Sort is much lower than that of HErMeS with SliceSort incurring about 30% fewer key comparisons compared to HErMeS . Furthermore, as explained, one key comparison in SliceSort is less costly than that in HErMeS .Consequently, the CPU time incurred by SliceSort is much smaller than that of HErMeS . In this work, we introduced a novel technique, Slice-Sort , for sorting hierarchical data. In contrast to exist-ing hierarchy-aware sorting methods which rely on subtree-based sorted runs, SliceSort employs a top-down, level-wise sorting technique to avoid the drawback of subtree-based sorting. Our experimental performance evaluation shows that SliceSort outperforms the state-of-art approach, HErMeS , by a significant factor.
 Acknowledgment We would like to thank the authors of [8] for the code of HErMeS , and particularly Ioannis Kolt-sidas for his help in answering our questions.
