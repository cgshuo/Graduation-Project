 One of the key obstacles in making learning protocols realistic in applications is the need to supervise them, a costly process that of-ten requires hiring domain experts. We consider the framework to use the world knowledge as indirect supervision. World knowledge is general-purpose knowledge, which is not designed for any spe-cific domain. Then the key challenges are how to adapt the world knowledge to domains and how to represent it for learning. In this paper, we provide an example of using world knowledge for do-main dependent document clustering. We provide three ways to specify the world knowledge to domains by resolving the ambi-guity of the entities and their types, and represent the data with world knowledge as a heterogeneous information network. Then we propose a clustering algorithm that can cluster multiple types and incorporate the sub-type information as constraints. In the ex-periments, we use two existing knowledge bases as our sources of world knowledge. One is Freebase, which is collaboratively collect-ed knowledge about entities and their organizations. The other is YAGO2, a knowledge base automatically extracted from Wikipedi-a and maps knowledge to the linguistic knowledge base, Word-Net. Experimental results on two text benchmark datasets (20news-groups and RCV1) show that incorporating world knowledge as indirect supervision can significantly outperform the state-of-the-art clustering algorithms as well as clustering algorithms enhanced with world knowledge features.
 Categories and Subject Descriptors: H.2.8 [Database Manage-ment]: Database Applications X  Data Mining General Terms: Algorithms; Experimentation.
 Keywords: World Knowledge; Heterogeneous Information Net-work; Document Clustering; Knowledge Base; Knowledge Graph.
Machine learning algorithms have become pervasive in multiple domains, impacting a wide variety of applications. Nonetheless, a key obstacle in making learning protocols realistic in applications is the need to supervise them, a costly process that often requires hiring domain experts. In the past decades, machine learning com-munity has elaborated to reduce the labeling work done by human for supervised machine learning algorithms or to improve unsu-pervised learning with only minimum supervision. For example, semi-supervised learning [6] is proposed to use only partially la-beled data and a lot of unlabeled data to perform learning with the hope that it can perform as good as fully supervised learning. Trans-fer learning [28] uses the labeled data from other relevant domains to help the learning task in the target domain. However, there are still many cases that neither semi-supervised learning nor transfer learning can help. For example, in the era of big data, we can have a lot textual information from different Web sites, e.g., blogs, fo-rums, mailing lists. It is impossible to ask human to annotate all the required tasks. It is also difficult to find relevant labeled domain-s. Recognizing that some domains can be very specific and really need the domain experts to perform annotation, e.g., the medical domain publication classification. Therefore, we should consider a more general approach to further reducing the labeling cost for learning tasks in diverse domains.

Fortunately, with the proliferation of general-purpose knowledge bases (or knowledge graphs), e.g., Cyc project [18], Wikipedia, Freebase [5], KnowItAll [9], TextRunner [2], WikiTaxonomy [29], Probase [40], DBpedia [1], YAGO [35], NELL [26] and Knowl-edge Vault [8], we have an abundance of available world knowl-edge. We call these knowledge bases world knowledge [11], be-cause they are universal knowledge that are either collaboratively annotated by human labelers or automatically extracted from big data. When world knowledge is annotated or extracted, it is not collected for any specific domain. However, because we believe the facts in world knowledge bases are very useful and of high quality, we propose using them as supervision for many machine learning problems. People have found it useful to use world knowledge as distant supervision for entity and relation extraction and embed-ding [25, 39, 41]. This is a direct use of the facts in world knowl-edge bases, where the entities in the knowledge bases are matched in the context regardless the ambiguity. A more interesting question is can we use the world knowledge to indirectly  X  X upervise X  more machine learning algorithms or applications? For example, if we can use world knowledge as indirect supervision, then we can ex-tend the knowledge about entities and relations to more generic text analytics problems, e.g., categorization and information retrieval.
Thus, we consider a general machine learning framework that can incorporate world knowledge into machine learning algorithm-s. As mentioned, world knowledge is not designed for any specific domain. For example, when we want to cluster the documents about entertainment or sports, then the world knowledge about names of celebrities and athletes may help while the terms used in science and technology may not be very useful. Thus, a key issue is how we should adapt world knowledge to the domain specific tasks. An-other problem is when we have the world knowledge, how we can represent it for the domain dependent tasks. For example, because most of the knowledge bases use a linked network to organize the knowledge, to adapt the world knowledge to domains, we should consider how to use the linked data. Although traditional machine learning algorithms using world knowledge just treat world knowl-edge as  X  X lat X  features in addition to the original text data [11, 22], the structure of the knowledge provides rich information about the connections of entities and relations. Therefore, we should also carefully consider the best way to represent the world knowledge for machine learning algorithms.

In this paper, we illustrate a framework of machine learning with world knowledge using a document clustering problem. We selec-t two knowledge bases, i.e., Freebase, YAGO2, as the sources of world knowledge. Freebase [5] is a collaboratively collected knowl-edge base about entities and their organizations. YAGO2 [35] is a knowledge base automatically extracted from Wikipedia and maps the knowledge to the linguistic knowledge base, WordNet [10]. To adapt the world knowledge to domain specific tasks, we first use semantic parsing to ground any text to the knowledge bases [4]. We then apply frequency, document frequency, and conceptualiza-tion [32] based semantic filters to resolve the ambiguity problem when adapting world knowledge to the domain tasks. After that, we have the documents as well as the extracted entities and their relations. Since the knowledge bases provide the entity types, the resulting data naturally form a heterogeneous information network (HIN) [13]. We show an example of such HIN in Figure 1. The specified world knowledge, such as named entities ( X  X ush X ,  X  X ba-ma X ) and their types ( Person ), as well as the documents and the words form the HIN. We then formulate the document clustering problem as an HIN partitioning problem, and provide a new algo-rithm to better perform clustering by incorporating the rich struc-tural information as constraints in the HIN. For example, the HIN builds a link (a must-link constraint) between  X  X bama X  of sub-type Politician in one document and  X  X ush X  of sub-type Politician in another document. Such link and type information could be very useful if the target clustering domain is  X  X olitics. X 
The main contributions of this work are highlighted as follows:
In this section, we discuss how we enable world knowledge to indirectly  X  X upervise X  machines, instead of just using world knowl-edge as additional features. In general, performing machine learn-ing with world knowledge, we should follow four steps: (1) Knowl-edge acquisition. (2) Domain adaptation. (3) Data and knowledge representation. (4) Learning. Since we assume the world knowl-edge is given, we skip step one in this study. Then given the world knowledge, we should consider adapting it to specific domains. S-ince the knowledge can be ambiguous without context, we should consider using domain dependent data to find the best knowledge to use. For example, when a text mentions  X  X pple, X  it can refer to a company or a fruit. In the knowledge base, we have both. There-fore, we should choose the right one to use. Then given the filtered knowledge we have as well as the domain dependent data, we use a better representation which considers the structure information of the linked knowledge rather than just considering the knowledge as flat features. After we have the representation, we can design a learning algorithm for domain dependent task.

The above four steps are general, which means they may apply to many applications. In this section, we demonstrate how to select the right knowledge to use and to represent this knowledge for the task of document clustering. Then in the next section, we will introduce the learning algorithm to perform better document clustering given the representation.
In this subsection, we propose a world knowledge specification approach to generate specified world knowledge given a set of do-main dependent documents. We first use semantic parsing to ground any text to the knowledge base, then provide three semantic filter-ing approaches to avoid ambiguity of the extracted information.
Semantic parsing is the task of mapping a piece of natural lan-guage text to a formal meaning representation [27]. This can sup-port question answering by querying a knowledge base [17]. To our best knowledge, most previous semantic parsing algorithms or tools developed are for small scale problems but with complicated logi-cal forms, until Berant et al. [4] develop a system that can handle very large scale knowledge bases such as Freebase. They use the developed system to solve question answering problem with Free-base. In their work, they formulate their problem to match answers to the questions, which is a supervised learning process. Similar to them, we are also working with very large scale world knowledge bases, but unlike them, we do not match question and answers. Our task is to ground any text to the knowledge base entities and their relationships in the prescribed logical form. Therefore, our problem is a fully unsupervised problem.

We first introduce the problem formulation and then introduce how we perform unsupervised semantic parsing. Let E be a set of entities and R be a set of relations in the knowledge base. Then the knowledge base K consists of triplets in the form of ( e where e 1 ,e 2  X  E and r  X  R . We follow [4] to use a simple version of Lambda Dependency-Based Compositional Semantic-s (  X  -DCS) [21] as the logic language. From each sentence in the document, we can parse four possible  X  -DCS logic forms [4]: (1) Unary: an entity e is a unary logic form (e.g., Obama ); (2) Binary: a relation r is a binary logic form (e.g., PresidentofCountry ); (3) Join: r.e is a unary logic form, denoting a join, where r is a binary and e is a unary (e.g., PresidentofCountry.Obama ); (4) Intersec-tion: e 1  X  e 2 ( e 1 ,e 2  X  E ) denotes set intersection, where e e are both unaries (e.g., Location.Olympics  X  PresidentofCoun-try.Obama ).

In simpler terms, semantic parsing can be understood as the fol-lowing process. First, given a piece of text  X  X bama is the president of United States of America, X  it maps the entities as well as the re-lation phrases in the text to knowledge base. So  X  X bama X  and  X  X -nited States of America X  are mapped to knowledge base, resulting in two unary logic forms People.BarackObama and Country.USA , where People and Country are the type information in Freebase. The relation phrase  X  X resident X  is mapped to a binary logic for-m PresidentofCountry. Notice that, the mapping process skips the words  X  X s X  and  X  X f. X  The mapping dictionary is constructed by aligning a large text corpus to the knowledge base. A phrase and a knowledge base entity or relation can be aligned if they co-occur with many of the same entities. We select two knowledge bases, i.e., Freebase and YAGO2. For Freebase, we just use the mapping already existing in the released tool shown in [4]. For YAGO2, we follow [4] and download a subset of ClueWeb09 1 to find the new mapping for YAGO2 entities and relations. Second, it uses some rules (i.e., grammar) to combine the basic logic forms to generate the restricted four logic forms above, and rank the results. For the example shown in this paragraph, People.BarackObama  X  Presi-dent.USA is generated to represent its semantic meaning. Notice that, President.USA is generated by joining the unary Country.USA with the binary PresidentofCountry.

When there are more than one candidate semantic meanings for a sentence, in [4], they learn the ranks based on the annotated question-answer pairs. For our task, this annotation is not available. There-fore, instead of ranking or enumerating all the possible logic forms (which is found to be not feasible in limited time), we constrain the entities to be the maximum length spanning phrases recognized by a state-of-the-art named entity recognition tool [30]. We then per-http://www.lemurproject.org/clueweb09.php/ form the two steps introduced above by using the maximum length spanning noun phrase as entities, and use the phrase between them in the text as relation phrase. We propose to use the following three semantic filtering methods to resolve the ambiguation problem.
For each sentence in the given document, the output of semantic parsing is a set of logic forms that represent the semantic mean-ing. However, the extracted entities can be ambiguous. For exam-ple,  X  X pple X  may be associated with type Company or Fruit . There-fore, we should filter out the noisy entities and their types to ensure that the knowledge we have is good enough as indirect supervision for document clustering. We assume that in the domain specific tasks, given the context, the entities seldom have multiple mean-ings. Thus, we propose the following three approaches to select the best knowledge to use for further learning process.

Frequency based semantic filter (FBSF). We use the frequency of a type for an entity appearing in a document as the criterion to decide whether the entity should be extracted for the domain specific task in a sentence. Here we assume the most frequent type of an entity from all the sentences of the document is the correct semantic meaning.

Document frequency based semantic filter (DFBSF). Similar to the frequency based method, we use the document frequency (DF) of a type of an entity as the criterion to find the most likely seman-tic meaning. Here we assume that if an entity appears in multiple documents with the same type, then the type should be the correct semantic meaning.

Conceptualization based semantic filter (CBSF) . Motivated by the approaches of conceptualization [32, 33] and entity disambigua-tion [20], we represent each entity with a feature vector of entity types, and use standard Kmeans to cluster the entities. Then in each cluster, we use the intersection operation to find the most likely en-tity type for the entities in the cluster. In this case, different entities can be used to disambiguate each other. Here we assume that the type that can best fit the context is the correct semantic meaning.
The output of semantic parsing and semantic filtering is then the document associated with the entities, which are further associated with the types (or concepts, categories, the names can be different for different knowledge bases and relations). For example, in Free-base, we select the top level named entity categories (i.e., domains) as the types, e.g., Person , Location , and Organization . In addition to the named entities, we also regard the document and word as t-wo types. Then we use an HIN to represent the data we get after semantic parsing and semantic filtering.

DEFINITION 1. A heterogeneous information network (HIN) is a graph G = ( V , E ) with an entity type mapping  X  : V  X  X  and a relation type mapping  X  : E  X  R , where V denotes the entity set and E denotes the link set, A denotes the entity type set and R denotes the relation type set, and the number of entity types |A| &gt; 1 or the number of relation types |R| &gt; 1 .

The network schema provides a high-level description of a given heterogeneous information network.

DEFINITION 2. Given an HIN G = ( V , E ) with the entity type mapping  X  : V  X  A and the relation type mapping  X  : E  X  R , the network schema for network G , denoted as T G = ( A , R ) , is a graph with nodes as entity types from A and edges as relation types from R . Figure 2: Heterogeneous information network schema. The speci-fied knowledge is represented in the form of heterogeneous infor-mation network. The schema contains multiple entity types: docu-ment D , word W , named entities {E I } T I =1 , and the relation types connecting the entity types.

Then for our world knowledge dependent network, we use the network schema shown in Figure 2 to represent the data. The net-work contains multiple entity types: document D , word W , named types. Notice that, we use  X  X ntity type X  to represent the node type in HIN, as Definition 1 showed. We use  X  X amed entity type X  to represent the type of the name mentioned in text (widely used in NLP community), e.g., person, location, and organization names. The entities in HIN do not have to be named entities, e.g., the categories of animals or diseases. We denote the document set as D = { d 1 ,d 2 ,...,d M } , where M is the size of D , the word set as W = { w 1 ,w 2 ,...,w N } , where N is the size of W , and the entity set as E t = { e t 1 ,e t 2 ,...,e t V t } , where V t is the size of E t = 1 ,...,T where T is the total number of named entity types we find in the knowledge base. Note that if there are no named entities, then the network reduces to a bipartite graph containing only doc-uments and words.
In this subsection, we present our clustering algorithm using HIN, constructed from domain dependent documents and the world knowl-edge. Given the HIN, it is natural to perform HIN partitioning to obtain the document clusters. In addition to the HIN itself, let us re-visit the structural information in a typical world knowledge base, e.g., Freebase. In the world knowledge base, the named entities are often organized in a hierarchy of categories. Although there are ad-ditional category information for each entity, we only use the top level named entity types as the entity types in HIN. For example,  X  X arack Obama X  is a person, where person is the top level category. In addition, he is the president of the  X  X nited States, X  a politician, a celebrity, etc.. Another example is that  X  X oogle X  is a software company, plus it has a CEO. This shows that the entities can have some attributes. We choose to use top level entity types for the HIN schema since then we will have a relatively dense graph for each pairwise nodes in the network schema. The fine-grained named en-tity sub-types or the attributes are also very useful to identify the topics or the clusters of the documents. Therefore, in this section, we introduce how we incorporate the fine-grained level of named entity types as constraints in the HIN clustering algorithm.
To formulate the clustering algorithm for the domain dependent documents, we denote latent label sets of the documents as L { l 1 ,l d 2 ,...,l d M } . We also denote L w = { l w 1 ,l for words, and L e t = { l e t set. In general, we follow the framework of information-theoretic co-clustering (ITCC) [7] and constrained ITCC [31, 38] to for-mulate our approach. Instead of only performing on the bipartite graph, we need to handle multi-type relational data, as well as more complicated constraints.

The original ITCC uses a variational function to approximate the joint probability of documents and words, which is: where  X  d k d and  X  w k w are cluster indicators to formulate the condi-tional probability, and k d and k w are the corresponding cluster in-dices. q ( d m ,w i ) is used to approximate p ( d m ,w i the Kullback-Leibler (KL) divergence: = D KL ( p ( D , W ,  X  D ,  X  W ) || q ( D , W ,  X  D ,  X  W )) where  X  D and  X  W are the cluster sets, p ( W|  X  d k d ) denotes a multino-mial distribution based on the probabilities Symmetrically, we have Moreover, p (  X  w k w |  X  d k d ) and p (  X  d k d |  X  w k the joint probability q (  X  d k d ,  X  w k w ) = P l Motivated by ITCC, according to the network schema shown in Figure 2, our problem of HIN clustering is formulated as where all the probabilities can be defined similar to the document-word bipartite graph. We omit the detailed definitions due to the space limitation. A summary of the notations is shown in Table 1. Table 1: Notations for clustering algorithm. The indicators are used for the probability representation, while the indices are used as ids for the clusters.

To incorporate the side information of the fine-grained named entity sub-types or the attributes as indirect supervision for doc-ument clustering, we define the constraints for the named entities we find after semantic parsing. We take the t th entity label set E an example, and use must-links and cannot-links as the constraints. We denote the must-link set associated with e t i as M e t cannot-link set as C e t as where w M is the weight for must-links, and p ( D| e t i 1 multinomial distribution based on the probabilities ( p ( d p ( d M | e t i 1 )) T , and I true = 1 , I false = 0 . The above must-link cost function means that if the label of e t i 1 is not equal to the la-bel of e t i 2 , then we should take into account the cost function of how dissimilar the two entities e t i 1 and e t i 2 are. The dissimilarity is computed based on the probability of document D given the enti-ties e t i 1 and e t i 2 as Eq. (4). The more dissimilar the two entities are, the larger cost is imposed.
 For cannot-links, the cost function is defined as where w C is the weight for cannot-links, and D t max is the maxi-mum value for all the D KL ( p ( D| e t i 1 ) || p ( D| e of e t i 2 , then we should take into account the cost function of how similar they are.

Integrating the constraints for L e 1 ,..., L e T to Eq. (3), the ob-jective function of constrained HIN clustering is: J
CHINC = D KL ( p ( D , W ) || q ( D , W )) From this objective function we can see that, the must-links and cannot-links are imposed to the entities that the semantic parsing detects. Since the task is document clustering, the sub-types of en-tities serve as indirect supervision because they cannot directly af-fect the cluster labels of the documents. However, the constraints can affect the labels of entities, and then the labels of entities can be transferred to the document side to affect the labels of documents.
Since global optimization of all the latent labels as well as the approximate function q (  X  ,  X  ) is intractable, we perform an alternat-ing optimization shown in Algorithm 1. We iterate the process to optimize the labels of documents, words, and entities. Meanwhile, we update the function q (  X  ,  X  ) for the corresponding types.
For example, to find label l d m of document d m , we have: l d m = arg min
To find label l w i of word w i , we have:
To find the label l e t algorithm [3] to iteratively assign a label to the entity. We update one label l e t l To transfer the original objective function (6) to Eq. (9), we should follow Eq. (2) where we replace the document and word notations to the entity notations. To understand why Eq. (2) holds, we suggest to refer to the original ITCC for detailed derivation [7].
Then, with the labels L d , L e t and L w fixed, we update the model function q ( d m ,w i ) , q ( d m ,e t i ) , and q ( e s j influenced by the must-links and cannot-links. Thus we can modify them the same as ITCC [7] and only show the update of q ( d here: q ( d m |  X  d k d ) = q ( d m )
Algorithm 1 summarizes the main steps in the procedure. The objective function (6) with our alternating update monotonically decreases to a local optimum. This is because the ICM algorithm decreases the non-negative objective function (6) to a local opti-mum given a fixed q function. Then the update of q is monotoni-cally decreasing as guaranteed by the theorem proven in [31].
The time complexity of Algorithm 1 is O ( n D , W  X  ( K d P ( K e t + K e s ))  X  iter AO , where n  X  ,  X  is the total number of non-zero elements in the corresponding co-occurrence matrix, n number of constraints, iter ICM is the number of ICM iterations, K d ,K w and K e t are the number of document clusters, word clus-ters and entity clusters of type t , and iter AO is the number of the alternating optimization iterations.
In this section, we show the experimental results to demonstrate the effectiveness and efficiency of our approach on document clus-tering with world knowledge as indirect supervision.
We use the following two benchmark datasets to evaluate domain dependent document clustering. For both datasets we assume the numbers of document clusters are given. 20Newsgroups (20NG): The 20newsgroups dataset contains about 20,000 newsgroups documents evenly distributed across 20 news-groups. 2 We use all the 20 groups as 20 classes.

RCV1: The RCV1 dataset is a dataset containing manually la-beled newswire stories from Reuter Ltd [19]. The news documents are categorized with respect to three controlled vocabularies: in-dustries, topics and regions. There are 103 categories including all nodes except for root in the hierarchy. The maximum depth is four, and 82 nodes are leaves. We select top categories MCAT (Mar-kets), CCAT (Corporate/Industrial) and ECAT (Economics) in one portion of the test partition to form three clustering tasks. The three clustering tasks are summarized in Table 2. We use the original source of this data, and use the leaf categories in each task as the ground-truth classes.
 Table 2: RCV1 dataset statistics. #(Categories) is the number of all categories; #(Leaf Categories) is the number of leaf categories; #(Documents) is the number of documents. MCAT 9 7 44,033 CCAT 31 26 47,494
ECAT 23 18 19,813 Then we introduce the knowledge bases we use.

Freebase: Freebase 3 is a publicly available knowledge base con-sisting of entities and relations collaboratively collected by its com-munity members. Now, it contains over 2 billions relation expres-sions between 40 millions entities. We convert a logical form gener-ated by our unsupervised semantic parser of the world knowledge specification approach introduced in Section 2.1 into a SPARQL query and execute it on our copy of Freebase using the Virtuoso engine.

YAGO2: YAGO2 4 is also a semantic knowledge base, derived from Wikipedia, WordNet and GeoNames. Currently, YAGO2 has knowledge of more than 10 million entities (like persons, organi-zations, cities, etc.) and contains more than 120 million facts about these entities. Similar to Freebase, we also convert a logical form into a SPARQL query and execute it on our copy of YAGO2 using the Virtuoso engine. http://qwone.com/~jason/20Newsgroups/ https://developers.google.com/freebase/ http://www.mpi-inf.mpg.de/departments/ databases-and-information-systems/research/ yago-naga/yago/ In Table 3, we show some statistics about Freebase and YAGO2. Table 3: Statistics of Freebase and YAGO2. #(Entity Types) is the number of entity types; #(Entity Instances) is the number of entity instances; #(Relation Types) is the number of relation types; #(Re-lation Instances) is the number of relation instances.
 Note that in most knowledge bases, such as Freebase and YA-GO2, entities types are often organized in a hierarchical manner. For example, Politician is a sub-type of Person . University is a sub-type of Organization . All the types or attributes share a common root, called Object . Figure 3 depicts an example of hierarchy of types. In general, we use the highest level under the root object as the entity types (e.g., Person ) as specified world knowledge in-corporated in the HIN, and the direct children (e.g., Politician ) as entity constraints. In the following experiments, we select Person , Organization , and Location as the three entity types in the HIN, because they are popular in both Freebase and YAGO2.

Before applying the specified world knowledge to downstream text analytics tasks, such as document clustering in our case, we need to evaluate whether our world knowledge specification ap-proach could produce the correct specified world knowledge.
In order to test the effectiveness of our world knowledge spec-ification approach, we first sample 200 documents from 20 news-groups, i.e., 10 documents from each category. Second, we split the documents into sentences. After post-processing, 3,232 sen-tences are generated for human evaluation. Third, we use our world knowledge specification approach in Section 2.1 with three dif-ferent semantic filtering modules to generate the specified world knowledge for each sentence, which consists of relation triplets in the form of ( e 1 ,r,e 2 ) with the type information. Afterwards, we ask three annotators to label the specified world knowledge accord-ing two criterion: (1) whether the boundaries of e 1 and e rectly recognized or not; (2) whether the entity type of e are correct or not. It is annotated as correct if both (1) and (2) are satisfied. We check the mutual agreement of the human annotation, which is around 91 . 3% accuracy.

We then test the precision of three different specified world knowl-edge generated by the corresponding semantic filtering method. The results are shown in Table 4. From the results we can see that, Table 4: Precision of different semantic filtering results. FBSF rep-resents frequency based semantic filter; DFBSF represents docu-ment frequency based semantic filter; CBSF represents conceptu-alization based semantic filter.
 CBSF outpeforms the other two ways to generate the correct se-mantic meaning. The main reason is that, conceptualization based method is able to use the context information to help judge the real semantic of the text rather than only taking the statistics of the data into account. Here we only care about precision because we wish to use world knowledge as indirect supervision. The recall will not be very important.
In this experiment, we compare the performance of our model, constrained heterogeneous information network clustering (CHINC), with several representative clustering algorithms such as Kmeans, ITCC [7] and CITCC [31]. The parameters used in CHINC to con-trol the constraints are w M and w C . We set them following the rules tested in [31]. We also denote our algorithm without constraints as HINC.  X  X B X  and  X  X G X  represent two different world knowledge sources, Freebase and YAGO2, respectively. We re-implement all the above clustering algorithms. Notice that, for CITCC, we fol-low [31] to generate and add constraints for documents and words. We also use the specified world knowledge as features to enhance the Kmeans and ITCC. The feature settings are defined as below:
We employ the widely-used normalized mutual information (NMI) [34] as the evaluation measure. The NMI score is 1 if the clustering results match the category labels perfectly and 0 if the clusters are obtained from a random partition. In general, the larger the scores are, the better the clustering results are.

In Table 5, we show the performance of all the clustering algo-rithms with different experimental settings. The NMI is the average NMI of five random trials per experiment setting. Overall, among all the methods we test, CHINC consistently performs the best a-mong all the clustering methods. We can see that HINC+FB and HINC+YG perform better than ITCC with BOW+FB or BOW+YG features, respectively. This means that by using the structural in-formation provided by the world knowledge, we can further im-prove the clustering results. In addition, the algorithms with Free-base consistently outperform the ones with YAGO2, since Freebase has much more facts compared with YAGO2 as shown in Table 3; besides, one can see in Figure 4 that Freebase could consistently specify more entities than YAGO2 does from all of the documen-t datasets. CITCC is the strongest baseline clustering algorithm, because it uses the ground-truth constraints derived from category labels based on the human knowledge. We use 250K constraints to perform CITCC. As shown in Table 5, HINC performs competitive with the CITCC. CHINC significantly outperforms CITCC. This shows that by automatically using world knowledge, it has the po-tential to perform better than the algorithm with the specific domain knowledge.
We also evaluate the effect of varying the number of entity clus-ters of each entity type in CHINC on the document clustering task. Figure 5 shows the results of clustering with different numbers of entity clusters of each entity type on  X  X HINC + Freebase X  for the 20NG dataset. The number of entity clusters varies from 2 to 128. The default number of iterations is set as 20 , which will be dis-cussed in Section 4.4.2. When testing the effect of the number of entity clusters of one entity type, the numbers of entity clusters of the other two entity types are fixed as twice as the number of doc-ument clusters, which are 40 and 40 in 20NG, respectively. It is shown that for this dataset, more entity clusters may not result in improved document clustering results when a sufficient number of entity clusters is reached. For example, as shown in Figure 5, af-ter reaching 32, the NMI scores of CHINC actually decrease when the numbers of entity clusters further increase. From the results, we can conclude that, there exist certain values of the number of entity clusters leading to the best clustering peformance. Similar to the results on  X  X HINC + Freebase X  for 20NG dataset, in the rest of the experiments, we fix the number of entity clusters of each entity type to be twice the number of document clusters.
We evaluate the impact of the number of iterations of the al-ternating optimization (Algorithm 1) on CHINC in relation to the execution time of the optimization algorithm as well as the cluster-ing performance. We increase the number of iterations from 1 to 80. For example, for each number of iterations, we run CHINC five trials, and the average execution time and NMI are summarized in Figure 6. From the result, one can conclude that the larger number of iterations is, the more significant the improvement on clustering performance. This improvement eventually drops, tapers out, and becomes stable. The reason is that, along with the increase of the number of iterations, the alternating optimization algorithm comes to covergence. However, the execution time still increase in a near-ly linear manner. For example, as shown in Figure 6, after reaching 20 , the performance stays stable. Thus, we set the number of itera-tions as 20 in the remaining experiments with the consideration of both performance and efficiency. Similarly, we set the number of iterations as 20 when conducting experiments on the other combi-nations of document datasets and world knowledge bases.
Rather than using human knowledge as constraints, we use the specified world knowledge automatically generated by our approach as constraints in CHINC. Based on the specified world knowledge, it is straightforward to design constraints for entities.
Entity constraints. (1) Must-links. If two entities belong to the same entity sub-type, we add a must-link. (2) Cannot-links. If t-wo entities belong to different entity sub-types, we add a cannot-link. For example, the entity sub-types of  X  X bama X  and  X  X nited States X  are Politician and Country respectively. In this case, we ad-d a cannot-link to them.

We then test the performance of our proposed CHINC by using the specified world knowledge as constraints described above. We show the experiments on  X  X HINC + Freebase X  for 20NG dataset in Figure 7. Each x -axis represents the number of entity type con-straints used in each experiment, and y -axis is the average NMI of five random trials. The constraints derived from entity type #1, #2, and #3 are eventually added to CHINC as shown in Figure 7a, Fig-ure 7b and Figure 7c, respectively. We can see that CHINC outper-Figure 4: Statistics of the number of en-tities in different document datasets with different world knowledge sources.
 forms the best clustering algorithm with the human knowledge as shown in Table 5 (CITCC: 0 . 569 ) with even no constraints (HINC: 0 . 571 ). By adding more and more constraints, the clustering result of CHINC is significantly better. So CHINC is able to use infor-mation in world knowledge specified in the HIN, and the entity sub-type information can be transferred to the document side. The results show the power of modeling data as heterogeneous infor-mation networks, as well as the high quality of constraints derived from world knowledge.

From Figure 7, by increasing the number of constraints, we find that the average execution time of five trials increases linearly, and the clustering performance measured by NMI is increasing as men-tioned before. Figure 7c shows the effects of the constraints of al-l the three entity types on the clustering performance as well as the execution time. After the number of constraints reach 50M, the increase of performance drops and stays stable. At this point, the execution time is around 1.2M (ms). In Figure 8, we can see the similar results on the other combinations of document datasets and knowledge bases. We also find that the average execution time of our algorithm with Freebase as world knowledge source is greater than that with YAGO2. As shown in Figure 4, the reason is that each document datasets with Freebase could be specified much more en-tities than that with YAGO2. From the results, we can see that our algorithm is scalable to use the large scale specified world knowl-edge as constraints, and cluster large amounts of documents.
In this section, we review the related work on machine learning with world knowledge and heterogeneous information networks, and have a detailed discussion on them.
 Figure 8: Analysis of the efficiency of our algorithm on different document datasets with different world knowledge sources.
Most of the existing usage of world knowledge is to enrich the features beyond bag-of-words representation of documents. For ex-ample, by using the linguistic knowledge base WordNet to resolve synonyms and introduce WordNet concepts, the quality of docu-ment clustering can be improved [14]. The first paper using the ter-m  X  X orld knowledge X  [11] extends the bag-of-words features with the categories in Open Directory Project (ODP), and shows that it can help improve text classification with additional knowledge. Following this, by mapping the text to the semantic space provided by Wikipedia pages, it has been proven to be useful for short text classification [12] and clustering [15, 16]. Liu et al. [22] also use another knowledge base of taxonomy, Probase, to enrich the fea-tures of ads keywords to build a new taxonomy of domain depen-dent keyword set. All of the above approaches just consider to use world knowledge as a source of features. However, the knowledge in the knowledge bases indeed has annotations of types, categories, etc.. Thus, it can be more effective to consider this information as  X  X upervision X  to supervise other machine learning algorithms and tasks.

Distant supervision uses the knowledge of entities and their re-lationships from world knowledge bases, e.g., Freebase, as super-vision for the task of entity and relation extraction [25, 39, 41]. It considers to use knowledge supervision to extract more entities and relations from new text or to generate a better embedding of entities and relations. Thus, the application of direct supervision is limited to entities and relations themselves.

Song et al. [31] consider using fully unsupervised method to gen-erate constraints of words using an external general-purpose knowl-edge base, WordNet. This can be regarded as an initial attempt to use general knowledge as indirect supervision to help clustering. However, the knowledge from WordNet is mostly linguistically re-lated. It lacks of the information about named entities and their types. Moreover, their approach is still a simple application of con-strained co-clustering, where it misses the rich structural informa-tion in the knowledge base.
A heterogeneous information network (HIN) is defined as a graph of multi-typed entities and relations [13]. Different from traditional graphs, HIN incorporates the type information which can be use-ful to identify the semantic meaning of the paths in the graph [36]. This is a good property to perform graph search and matching. O-riginal HINs are developed for the applications of scientific pub-lication network analysis [36, 37]. Then social network analysis also leverages this representation for user similarity and link pre-diction [42]. Seamlessly, we can see that the knowledge in world knowledge bases, e.g., Freebase and YAGO2, can be naturally rep-resented as an HIN, since the entities and relations in the knowledge base are all typed. We introduce this representation to knowledge based analysis, and show that it can be very useful for our documen-t clustering task. Note that there is also a series of methods called multi-type relational data clustering [23, 24]. While they require the data to be structural beforehand (e.g., providing information of authors, co-authors, etc.), our method only needs the input of raw documents. In addition to the multi-type relational information, we also incorporate the type information provided by the knowledge base as constraints to further improve the clustering results.
In this paper, we study a novel problem of machine learning with world knowledge. Particularly, we take document clustering as an example and show how to use world knowledge as indirect supervi-sion to improve the clustering results. To use the world knowledge, we show how to adapt the world knowledge to domain dependen-t tasks by using semantic parsing and semantic filtering. Then we represent the data as a heterogeneous information network, and use a constrained network clustering algorithm to obtain the documen-t clusters. We demonstrate the effectiveness and efficiency of our approach on two real datasets along with two popular knowledge bases. In the future, we plan to use world knowledge to help more text mining and text analytics tasks, such as text classification and information retrieval.
 Chenguang Wang gratefully acknowledges the support by the Na-tional Natural Science Foundation of China (NSFC Grant Number 61472006) and the National Basic Research Program (973 Program No. 2014CB340405). The research is also partially supported by the Army Research Laboratory (ARL) under agreement W911NF-09-2-0053, and by DARPA under agreement number FA8750-13-2-0008. Research is also partially sponsored by National Science Foundation IIS-1017362, IIS-1320617, and IIS-1354329, HDTRA1-10-1-0120, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov), and MIAS, a DHS-IDS Center for Multimodal Information Access and Synthesis at UIUC. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied by these agencies or the U.S. Government. [1] S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, [2] M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and [3] S. Basu, M. Bilenko, and R. J. Mooney. A probabilistic [4] J. Berant, A. Chou, R. Frostig, and P. Liang. Semantic [5] K. D. Bollacker, C. Evans, P. Paritosh, T. Sturge, and [6] O. Chapelle, B. Sch X lkopf, and A. Zien, editors.
 [7] I. S. Dhillon, S. Mallela, and D. S. Modha.
 [8] X. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, [9] O. Etzioni, M. Cafarella, and D. Downey. Webscale [10] C. Fellbaum, editor. WordNet: an electronic lexical database . [11] E. Gabrilovich and S. Markovitch. Feature generation for [12] E. Gabrilovich and S. Markovitch. Computing semantic [13] J. Han, Y. Sun, X. Yan, and P. S. Yu. Mining knowledge from [14] A. Hotho, S. Staab, and G. Stumme. Ontologies improve text [15] J. Hu, L. Fang, Y. Cao, H.-J. Zeng, H. Li, Q. Yang, and [16] X. Hu, X. Zhang, C. Lu, E. K. Park, and X. Zhou. Exploiting [17] T. Kwiatkowski, L. S. Zettlemoyer, S. Goldwater, and [18] D. B. Lenat and R. V. Guha. Building Large [19] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. Rcv1: A new [20] Y. Li, C. Wang, F. Han, J. Han, D. Roth, and X. Yan. Mining [21] P. Liang. Lambda dependency-based compositional [22] X. Liu, Y. Song, S. Liu, and H. Wang. Automatic taxonomy [23] B. Long, Z. M. Zhang, X. W X , and P. S. Yu. Spectral [24] B. Long, Z. M. Zhang, and P. S. Yu. A probabilistic [25] M. Mintz, S. Bills, R. Snow, and D. Jurafsky. Distant [26] T. M. Mitchell, W. W. Cohen, E. R. H. Jr., P. P. Talukdar, [27] R. J. Mooney. Learning for semantic parsing. In CICLing , [28] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE [29] S. P. Ponzetto and M. Strube. Deriving a large-scale [30] L. Ratinov and D. Roth. Design challenges and [31] Y. Song, S. Pan, S. Liu, F. Wei, M. Zhou, and W. Qian. [32] Y. Song, H. Wang, Z. Wang, H. Li, and W. Chen. Short text [33] Y. Song, S. Wang, and H. Wang. Open domain short text [34] A. Strehl and J. Ghosh. Cluster ensembles X  X  knowledge [35] F. M. Suchanek, G. Kasneci, and G. Weikum. Yago: a core of [36] Y. Sun, J. Han, X. Yan, P. S. Yu, and T. Wu. Pathsim: Meta [37] Y. Sun, B. Norick, J. Han, X. Yan, P. S. Yu, and X. Yu. [38] C. Wang, Y. Song, D. Roth, C. Wang, J. Han, H. Ji, and [39] Z. Wang, J. Zhang, J. Feng, and Z. Chen. Knowledge graph [40] W. Wu, H. Li, H. Wang, and K. Q. Zhu. Probase: A [41] C. Xu, Y. Bai, J. Bian, B. Gao, G. Wang, X. Liu, and T.-Y. [42] J. Zhang, X. Kong, and P. S. Yu. Transferring heterogeneous
