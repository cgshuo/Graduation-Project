 Statistical machine translation (SMT) is based on training statistical models from large corpora of hu-man translations. It has the advantage that it is very fast to train, if there are available corpora, compared to rule-based systems, and SMT systems are often relatively good at lexical disambiguation. A large drawback of SMT systems is that they use no or lit-tle grammatical knowledge, relying mainly on a tar-get language model for producing correct target lan-guage texts, often resulting in ungrammatical out-put. Thus, methods to include some, possibly shal-low, linguistic knowledge seem reasonable.

The main focus for SMT to date has been on translation into English, for which the models work relatively well, especially for source languages that are structurally similar to English. There has been less research on translation out of English, or be-tween other language pairs. Methods that are useful for translation into English have problems in many cases, for instance for translation into morpholog-ically rich languages. Word order differences and morphological complexity of a language have been shown to be explanatory variables for the perfor-mance of phrase-based SMT systems (Birch et al., 2008). German and the Scandinavian languages are a good sample of languages, I believe, since they are both more morphologically complex than English to a varying degree, and the word order differ to some extent, with mostly local differences between En-glish and Scandinavian, and also long distance dif-ferences with German, especially for verbs. Some problems with SMT into German and Swedish are exemplified in Table 1. In the Ger-man example, the translation of the verb welcome is missing in the SMT output. Missing and mis-placed verbs are common error types, since the German verb should appear last in the sentence in this context, as in the reference, begr  X  u X en . There is also an idiomatic compound, redebeitrag ( speech+contribution; intervention ) in the refer-ence, which is produced as the single word beitrag in the SMT output. In the Swedish example, there are problems with a definite NP, which has the wrong gender of the definite article, den instead of det , and is missing a definite suffix on the noun syns  X  att(et) ( (the) approach ).

In this proposal I outline my thesis work which aims to improve statistical machine translation, par-ticularly into Germanic languages, by using pre-and postprocessing on one or both language sides, with an additional focus on error analysis. In section 2 I present a thesis overview, and in section 3 I briefly overview MT evaluation techniques, and discuss my work on MT error analysis. In section 4 I describe my work on pre-and postprocessing, which is fo-cused on compounding, definite noun phrases, word order, and error correction. My main research focus is how pre-and postpro-cessing can be used to improve statistical MT, with a focus on translation into Germanic languages. The idea behind preprocessing is to change the training corpus on the source side and/or on the target side in order to make them more similar, which makes the SMT task easier, since the standard SMT mod-els work better for more similar languages. Post-processing is needed after the translation when the target language has been preprocessed, in order to restore it to the normal target language. Postpro-cessing can also be used on standard MT output, in order to correct some of the errors from the MT sys-tem. I focus my work about pre-and postprocessing on four areas: compounding, definite noun phrases, word order, and error correction. In addition I am making an effort into error analysis, to identify and classify errors in the MT output, both in order to fo-cus my research effort, and to evaluate and compare systems.

My work is based on the phrase-based approach to statistical machine translation (PBSMT, Koehn et al. (2003)). I further use the framework of factored machine translation, where each word is represented as a vector of factors, such as surface word, lemma and part-of-speech, rather than only as surface words (Koehn and Hoang, 2007). I mostly utilize factors to translate into both words and (morphological) part-of-speech, and can then use an additional sequence model based on part-of-speech, which potentially can improve word order and agreement. I take ad-vantage of available tools, such as the Moses toolkit (Koehn et al., 2007) for factored phrase-based trans-lation.

I have chosen to focus on PBSMT, which is a very successful MT approach, and have received much research focus. Other SMT approaches, such as hi-erarchical and syntactical SMT (e.g. Chiang (2007), Zhang et al. (2007a)) can potentially overcome some language differences that are problematic for PB-SMT, such as long-distance word order differences. Many of these models have had good results, but they have the drawback of being more complex than PBSMT, and some methods do not scale well to large corpora. While these models at least in princi-ple address some of the drawbacks of the flat struc-ture in PBSMT, Wang et al. (2010) showed that a syntactic SMT system can still gain from prepro-cessing such as parse-tree modification. Machine translation systems are often only evalu-ated quantitatively by using automatic metrics, such as Bleu (Papineni et al., 2002), which compares the system output to one or more human reference trans-lations. While this type of evaluation has its advan-tages, mainly that it is fast and cheap, its correla-tion with human judgments is often low, especially for translation out of English (Callison-Burch et al., 2009). In order to overcome these problems to some extent I use several metrics in my studies, instead of only Bleu. Despite this, metrics only give a single score per sentence batch and system, which even us-ing several metrics gives us little information on the particular problems with a system, or about what the possible improvements are.

One alternative to automatic metrics is human judgments, either absolute scores, for instance for adequacy or fluency, or by ranking sentences or seg-ments. Such evaluations are a valuable complement to automatic metrics, but they are costly and time-consuming, and while they are useful for comparing systems they also fail to pinpoint specific problems. I mainly take advantage of this type of evaluation as part of participating with my research group in MT shared tasks with large evaluation campaigns such as WMT (e.g. Callison-Burch et al. (2009)).
To overcome the limitation of quantitative evalu-ations, I focus on error analysis (EA) of MT output in my thesis. EA is the task of annotating and clas-sifying the errors in MT output, which gives a qual-itative view. It can be used to evaluate and compare systems, but is also useful in order to focus the re-search effort on common problems for the language pair in question. There have been previous attempts of describing typologies for EA for MT, but they are not unproblematic. Vilar et al. (2006) suggested a ty-pology with five main categories: missing, incorrect, unknown, word order, and punctuation, which have also been used by other researchers, mainly for eval-uation. However, this typology is relatively shallow and mixes classification of errors with causes of er-rors. Farr  X  us et al. (2010) suggested a typology based on linguistic categories, such as orthography and se-mantics, but their descriptions of these categories and their subcategories are not detailed. Thus, as part of my research, I am in the progress of design-ing a fine-grained typology and guidelines for EA. I have also created a tool for performing MT error analysis (Stymne, 2011a). Initial annotations have helped to focus my research efforts, and will be dis-cussed below. I also plan to use EA as one means of evaluating my work on pre-and postprocessing. In this section I describe the four main problem ar-eas I will focus on in my thesis project. I summarize briefly previous work in each area, and outline my own current and planned contributions. Sample re-sults from the different studies are shown in Table 2. 4.1 Compounding In most Germanic languages, compounds are writ-ten without spaces or other word boundaries, which makes them problematic for SMT, mainly due to sparse data problems. The standard method for treat-ing compounds for translation from Germanic lan-guages is to split them in both the training data and translation input (e.g. (Nie X en and Ney, 2000; Koehn and Knight, 2003; Popovi  X  c et al., 2006)). Koehn and Knight (2003) also suggested a corpus-based compound splitting method that has been much used for SMT, where compounds are split based on corpus frequencies of its parts.

If compounds are split for translation into Ger-manic languages, the SMT system produces output with split compounds, which need to be postpro-cessed into full compounds. There has been very little research into this problem. For this process to be successful, it is important that the SMT system produces the split compound parts in a correct word order. To encourage this I have used a factored trans-lation system that outputs parts-of-speech and uses a sequence model on parts-of-speech. I extended the part-of-speech tagset to use special part-of-speech tags for split compound parts, which depend on the head part-of-speech of the compound. For instance, the Swedish noun p  X  arontr  X  ad ( pear tree ) would be tagged as p  X  aron | N-part tr  X  ad | N when split. Using this model the number of compound parts that were produced in the wrong order was reduced drastically compared to not using a part-of-speech sequence model for translation into German (Stymne, 2009a).
I also designed an algorithm for the merging task that uses these part-of-speech tags to merge compounds only when the next part-of-speech tag matches. This merging method outperforms reim-plementations and variations of previous merging suggestions (Popovi  X  c et al., 2006), and methods adapted from morphology merging (Virpioja et al., 2007) for translation into German (Stymne, 2009a). It also has the advantage over previous merging methods that it can produce novel compounds, while at the same time reducing the risk of merging parts into non-words. I have also shown that these com-pound processing methods work equally well for translation into Swedish (Stymne and Holmqvist, 2008). Currently I am working on methods for fur-ther improving compound merging, with promising initial results. 4.2 Definite Noun Phrases In Scandinavian languages there are two ways to express definiteness in noun phrases, either by a definite article, or by a suffix on the noun. This leads to problems when translating into these lan-guages, such as superfluous definite articles and wrong forms of nouns. I am not aware of any published research in this area, but an unpublished report shows no gain for a simple pre-processing strategy for translation from German to Swedish (Samuelsson, 2006). There is similar work on other phenomena, such as Nie X en and Ney (2000), who move German separated verb prefixes, to imitate the English phrasal verb structure.

I address definiteness by preprocessing the source language, to make definite NPs structurally simi-lar to target language NPs. The transformations are rule-based, using part-of-speech tags. Definite NPs in Scandinavian languages are mimicked in the source language by removing superfluous definite articles, and/or adding definite suffixes to nouns. In an initial study, this gave very good results, with rel-ative Bleu improvements of up to 22.1% for trans-lation into Danish (Stymne, 2009b). In Swedish and Norwegian, the distribution of definite suffixes is more complex than in Danish, and the basic strat-egy that worked well for Danish was not successful (Stymne, 2011b). A small modification to the ba-sic strategy, so that superfluous English articles were removed, but no suffixes were added, was success-ful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the de-coder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Prepro-cessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatically learnt rules (e.g. Xia and McCord (2004), Zhang et al. (2007b)), which are basically language independent.
I have performed an initial study on a language independent word order strategy where reordering rule learning and word alignment are performed iter-atively, since they both depend on the other process (Stymne, 2011c). There were no overall improve-ments as measured by Bleu, but an investigation of the reordering rules showed that the rules learned in the different iterations are different with regard to the linguistic phenomena they handle, indicating that it is possible to learn new information from iter-ating rule learning and word alignment. In this study I only choose the 1-best reordering as input to the SMT system. I plan to extend this by presenting sev-eral reorderings to the decoder as a lattice, which has been successful in previous work (see e.g. Zhang et al. (2007b)).

My preliminary error analysis has shown that there are two main word order difficulties for trans-lation between English and Swedish, adverb place-ment, and V2 errors, where the verb is not placed in the correct position when it should be placed before the subject. I plan to design a preprocess-ing scheme to tackle these particular problems for English-Swedish translation. 4.4 Error Correction Postprocessing can be used to correct MT output that has not been preprocessed, for instance in or-der to improve the grammaticality. There has not been much research in this area. A few examples are Elming (2006), who use transformation-based learning for word substitution based on aligned hu-man post-edited sentences, and Guzm  X  an (2007) who used regular expression to correct regular Spanish errors. I have applied error correction suggestions given by a grammar checker to the MT output, show-ing that it can improve certain types of errors, such as NP agreement and word order, with a high pre-cision, but unfortunately with a low recall (Stymne and Ahrenberg, 2010). Since the recall is low, the positive effect on metrics such as Bleu is small on general test sets, but there are improvements on test sets which only contains sentences that are affected by the postprocessing. An error analysis showed that 68 X 74% of the corrections made were useful, and only around 10% of the changes made were harm-ful. I believe that this approach could be even more useful for similar languages, such as Danish and Swedish, where a spell-checker might also be use-ful.

The initial error analysis I have performed has helped to identify common errors in SMT output, and shown that many of them are quite regular. A strategy I intend to pursue is to further identify com-mon and regular problems, and to either construct rules or to train a machine learning classifier to iden-tify them, in order to be able to postprocess them. It might also be possible to use the annotations from the error analysis as part of the training data for such a classifier. The main focus of my thesis will be on designing and evaluating methods for pre-and postprocess-ing of statistical MT, where I will contribute meth-ods that can improve translation within the four ar-eas discussed in section 4. The effort is focused on translation into Germanic languages, including German, on which there has been much previous research, and Swedish and other Scandinavian lan-guages, where there has been little previous re-search. I believe that both language-pair dependent and independent methods for pre-and postprocess-ing can be useful. It is also the case that some language-pair dependent methods carry over to other (similar) language pairs with no or little modifica-tion. So far I have mostly used rule-based process-ing, but I plan to extend this with investigating ma-chine learning methods, and compare the two main approaches.

I strongly believe that it is important for MT re-searchers to perform qualitative evaluations, both for identifying problems with MT systems, and for eval-uating and comparing systems. In my experience it is often the case that a change to the system to im-prove one aspect, such as compounding, also leads to many other changes, in the case of compounding for instance because of the possibility of improved alignments, which I think we lack a proper under-standing of.

My planned thesis contributions are to design a detailed error typology, guidelines, and a tool, tar-geted at MT researchers, for performing error anno-tation, and to improve statistical machine translation in four problem areas, using several methods of pre-and postprocessing.

