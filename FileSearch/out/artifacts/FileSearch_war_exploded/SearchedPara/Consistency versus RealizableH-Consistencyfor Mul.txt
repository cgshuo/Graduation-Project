 Philip M. Long plong@microsoft.com Microsoft, 1020 Enterprise Way, Sunnyvale, CA 94089 Rocco A. Servedio rocco@cs.columbia.edu Classification into k &gt; 2 classes is often addressed by learning a real-valued scoring function h z for each class z  X  X  1 ,...,k } , and then classifying an item x as argmax z h z ( x ). To learn the scoring functions, a pop-ular approach is to minimize the average, over train-some loss function.
 One very natural loss function ( Zhang , 2004 ), which generalizes the loss function used by LogitBoost ( Friedman et al. , 2000 ), is Minimizing this loss function has been shown to be consistent ( Zhang , 2004 ); informally, this means that minimizing this loss function results in a classifier whose accuracy is close to that of the Bayes optimal classifier. 1 (We give a precise definition of consistency in Section 2.2 .) Such consistency has been cited as a hallmark of a principled algorithm ( Harchaoui et al. , 2012 ).
 Another loss function, due to Crammer &amp; Singer ( 2001 ), is If all other scores h z ( x ) are at least 1 less than h y then this loss is 0; otherwise this loss is the maximum, over all other scores, of the amount by which that score fails to satisfy this constraint. L CS is not consistent ( Tewari &amp; Bartlett , 2007 ).
 A puzzling empirical finding. Consider the fol-lowing, apparently easy, synthetic learning problem. Training and test examples are generated i.i.d. The source used to generate examples is linearly separable: there is a  X  X arget weight vector X  w z  X  R 100 for each class z  X  { 1 ,..., 10 } , and a random example ( x ,y ) is obtained by generating x  X  R 100 according to the uniform distribution on the unit ball, and assigning a label y that maximizes w y  X  x . The target weight vectors are the rows of a 10  X  100 matrix W that is generated as follows: a 10  X  2 matrix A and a 2  X  100 matrix B are generated by i.i.d. sampling their compo-nents from the standard normal distribution, and W is set to equal AB .
 We generated 10000 training and 10000 test exam-ples from such a source, and used them to evaluate two algorithms. One algorithm learned the weights v ,..., v k to minimize L logit ( y, v 1  X  x ,..., v k  X  x ) using 100 epochs of ASGD ( Polyak &amp; Juditsky , 1992 ; Xu , 2011 ; Bottou , 2010 ) and the other was the same, ex-cept with L CS . (Both algorithms also used a mild Frobenius norm regularizer. Please see Section 5 for the details.) We repeated this process five times. The algorithm that minimized (the consistent) L logit had average test accuracy 87.5%, while the algorithm that minimized (the inconsistent) L CS had average test ac-curacy 94.4%. For one source, the accuracy obtained from L logit was 82.6%, while the accuracy from L CS was 94.2%. Thus, in these experiments on a seemingly easy synthetic learning problem, the consistent algo-rithm (minimizing L logit ) performs significantly less well than the algorithm (minimizing L CS ) which is known not to be consistent. Given how easy this learn-ing problem seems to be, the outputs of the algorithm minimizing L logit are surprisingly inaccurate. Discussion of the experimental results. What happened? Because W has low rank, a given weight vector w y tends to be similar to weight vectors for some other classes, and consequently a good classi-fier for a given example ( x ,y ) will tend to also assign high scores to some classes other than y . Minimiz-ing L CS is compatible with this desideratum. During training with a stochastic gradient descent algorithm, once the weight vectors have sufficiently large magni-tude, informally, L CS does not mind classes other than y also having a high score, and a stochastic gradient update according to this loss function eventually will not change any weights. On the other hand, if L logit is trained by stochastic gradient descent, it will keep  X  X nocking down X  the scores for classes other than y . Put another way, L CS is only trying to classify the data correctly by a certain margin, while L logit is try-ing to fit a model for the conditional probability that the class is y . The consistency of L logit implies that minimizing this loss will lead to near-optimal accuracy if this minimization is done over the space of all scor-ing functions . However, in the above experiment, we performed the minimization only over the class of lin-ear functions. (We note that this is a standard practice for large-scale multiclass image classification, see e.g. ( Weston et al. , 2010 ; Lin et al. , 2011 ; Perronnin et al. , 2012 )). This provides a possible explanation of L logit  X  X  relatively poor performance.
 Our results. As described above, in our experiments, using L CS led to significantly better accuracy than L logit even though L logit is consistent and L CS is not. To explain this phenomenon we introduce a new no-tion, which we term realizable H -consistency , where H is a restricted class of scoring functions. Informally, a loss function is realizable H -consistent if for any source that admits a zero-error classifier using scoring func-tions from H , any scoring functions from H which minimize the expected loss will have classification er-ror close to zero. For learning algorithms that use a restricted class H of scoring functions, H -consistency may be more relevant than the original notion of con-sistency, which deals with all possible scoring func-tions, and realizable H -consistency is a more basic re-quirement.
 We show that the loss function L CS is realizable H -consistent for any class H of scoring functions that is closed under scaling (i.e. if h  X  H then  X h  X  H for all real  X  ). This implies that L CS is realizably consistent with respect to linear scoring functions (as well as with respect to deep nets, see the discussion after Theorem 9 ). We also show that L logit is not realizably consistent with respect to the set of linear functions. These results together imply that the ratio between the error probabilities of an algorithm min-imizing L logit and an algorithm minimizing L CS can be arbitrarily large, even if we restrict to linearly sep-arable sources. Our lower bound for L logit holds for any loss function satisfying some general conditions, and applies for several other loss functions previously proposed for multiclass classification.
 Our results suggest that the refined notion of H -consistency may sometimes be a more useful and rele-vant one than the original notion of consistency. In set-tings where learning algorithms use a restricted class H of scoring functions, H -consistency may be more closely linked to classification accuracy than general consistency. 2.1. Basics Throughout this paper Y denotes the set [ k ] = { 1 ,...,k } . A source is a joint distribution P over X  X  Y . We write P X to denote the marginal distribu-tion of P over X .
 Recall that the Bayes optimal classifier for source P is the mapping f : X  X  Y such that for each x  X  in the Pr ( x,y )  X  P [ y = t | x = x  X  ] for every t 6 = f ( x  X  ) . 2.2. Different notions of consistency We begin by recalling the standard notion of consis-tency.
 For  X  &gt; 0 and a source P , we say that a func-tion h = ( h 1 ,...,h k ) from X to R k  X  -minimizes E Note that the scoring functions a 1 ,...,a k above may range over all measurable mappings from X to R . Definition 1. A loss function L is consistent if for any source P and any  X  &gt; 0 there exists some  X  &gt; 0 such that if h = ( h 1 ,...,h k )  X  -minimizes E isfies g ( x )  X  argmax  X  y  X  Y h  X  y ( x ) for all x  X  X , then where f is the Bayes optimal classifier.
 The notion of a consistent loss function defined in Definition 1 was studied by ( Zhang , 2004 ). A closely related notion was studied by Tewari and Bartlett ( Tewari &amp; Bartlett , 2007 ). Following those authors (and, others, including ( Breiman , 2004 ; Long &amp; Servedio , 2010 )), we abstract away estimation error, and study the consequences of minimizing loss with respect to the underlying distribution.
 Definition 2. A source P is realizable if for each x  X  in the support of P X , there is a y  X  such that Definition 3. A loss function L is realizable con-sistent if for any realizable source P , for any  X  &gt; 0 there is a  X  &gt; 0 such that if h = ( h 1 ,...,h k )  X  -isfies g ( x )  X  argmax  X  y  X  Y h  X  y ( x ) for all x  X  X , then We now define a notion of consistency with respect to a set H of scoring functions. This formalizes the notion that choosing scoring functions from H so as to mini-mize the loss does nearly as well, in terms of classifica-tion error, as the best combination of scoring functions from H . (Very similar notions have long been stud-ied; see ( Vapnik , 1989 ; Haussler , 1992 ; Kearns et al. , 1992 ).) Let H be a set of functions mapping X to R . For  X  &gt; 0, we say that a function h = ( h 1 ,...,h k ) from X to R k  X  -minimizes E ( x,y )  X  P [ L ( y,h 1 ( x ) ,...,h with respect to H if Definition 4. Let H be a set of measurable func-tions from X to R . A loss function L is H -consistent if for any source P and any  X  &gt; 0 , there is a  X  &gt; 0 such that if h 1 ,...,h k  X  H  X  -minimize E g : X  X  Y satisfies g ( x )  X  argmax  X  y  X  Y h  X  y ( x ) for all x  X  X , then for all, a 1 ,...,a k  X  H , and any f : X  X  Y such that f ( x )  X  argmax  X  y  X  Y a  X  y ( x ) for all x  X  X , we have Note that the original notion of consistency from Def-inition 1 corresponds to H -consistency when H is the class of all measurable functions.
 Definition 5. A source P is realizable w.r.t. H if there exist h 1 ,...,h k  X  H such that, for any g : X  X  x  X  in the support of P X .
 Realizable sources correspond to learning scenarios in which there is a  X  X arget function X  that always provides the correct label for each example.
 Definition 6. A loss function L is realizable H -consistent if the following holds: for any source P that is realizable w.r.t. H and any  X  &gt; 0 , there is a  X  &gt; 0 such that if h 1 ,...,h k  X  H  X  -minimize E The Crammer-Singer loss is defined as follows: One may easily use a construction due to Tewari and Bartlett ( Tewari &amp; Bartlett , 2007 ) to prove that L is not consistent (see also ( Zhang , 2004 )). Because of differences in the details of our definitions and theirs, we have included a proof of Theorem 7 in Appendix A . Theorem 7. L CS is not consistent.
 While L CS is not consistent, we now show that it is realizable H -consistent for any class H of scoring func-tions that satisfies the following natural scaling condi-tion: Definition 8. A class H of scoring functions is closed under scaling if for any h  X  H and any real  X  , the function  X h belongs to H .
 The set of linear functions is closed under scaling, and any set of scoring functions can be easily closed under scaling by adding all scalings of all of its members. Theorem 9. For any H that is closed under scaling, the Crammer-Singer loss L CS is realizable consistent w.r.t. H .
 Proof : Let P be a realizable source w.r.t. H . Let h ,...,h k  X  H be such that, if gap( x ) = h y ( x )  X  Choose  X  &gt; 0, and let  X  &gt; 0 be such that by 1 / X  , we claim that
E ( x,y )  X  P [ L CS ( y, (1 / X  ) h 1 ( x ) ,..., (1 / X  ) h all j 6 = y , we have that L CS is always at most 1, and hence Now suppose that g 1 ,...,g k  X  H approximately min-Then ( 2 ) implies that bound on the probability (over ( x,y )  X  P ) that y 6 = argmax  X  y g  X  y ( x ). This completes the proof. Note that the proof of Theorem 9 goes through almost without modification if L CS is replaced with for any continuous monotone function  X  : R  X  R + such that lim x  X  X  X  X   X  ( x ) = 0, including the function  X  defined by  X  ( x ) = ln(1 + e x ). The key is that these loss functions concern a competition among the scores, instead of evaluating the scores independently. We also note that beyond the class H of linear func-tions, Theorem 9 also implies that L CS is realizable H -consistent in the case that H is the set of functions computed by a deep network with a given architecture, or a convolutional network, if the squashing functions are left off of the output nodes. (The loss function can be viewed as taking on the role of the squashing function for the output nodes, so this is reasonable.) Throughout this section we fix X to be the domain R n and we let H denote the class of all linear functions X  X  R , i.e. H = { x  X  v  X  x , v  X  R n } .
 Our main result in this section is a proof that any loss function that satisfies some general conditions, de-tailed below, is not realizable consistent for the class of linear scoring functions: Theorem 10. Let  X  : R  X  R &gt; 0 = { x  X  R : x &gt; 0 } be any function such that (a)  X  is twice con-tinuously differentiable, (b)  X  is strictly convex, (c) Then the loss function L  X  defined as
L  X  ( y,h 1 ( x ) ,...,h k ( x )) :=  X  h y ( x ) + is not realizable H -consistent, where H is the class of all linear functions.
 It can be easily checked that this theorem implies that many of the  X  X ecoupled X  loss functions of ( Zhang , 2004 ) (see Section 4.4.2 of ( Zhang , 2004 )), shown there to be consistent, are in fact not realizable H -consistent. These include the L logit function (for which  X  ( x ) = ln(1 + e x )) and the L Q loss function defined by
L Q ( y,h 1 ( x ) ,...,h k ( x )) =  X  h y ( x ) + (for which  X  ( x ) = x 2 / 2). (Our proof will establish lower bounds of 1 / 5 on the error probability for algo-rithms minimizing L logit and L Q .) The main steps in proving Theorem 10 are to (I) de-fine a source P that is realizable w.r.t. H , and (II) prove that the optimal ( v  X  1 ,..., v  X  k )  X  H k that min-tuples of functions in H as the final k arguments to L ) is such that for g ( x ) = argmax  X  y  X  Y h  X  y ( x ), we have Pr ( x ,y )  X  P [ g ( x ) 6 = y ] is bounded below by 4  X  where  X  &gt; 0 is a constant that depends only on  X  (defined below). Once this is done Theorem 10 is an immediate consequence (taking  X  = 4  X  in Definition 6 ). We now turn to these two tasks. (I): The source P . We now define the source P over X  X  Y that we shall consider. This source is very simple and in fact only uses the domain X = R 2 . The number k of classes is 8. The source depends on the loss  X  through a parameter that is defined as follows. Since  X  is twice continuously differentiable and strictly convex, there is a  X  &gt; 0 such that Choose such a  X  . (For L Q , any positive constant will work, and for L logit , we may choose  X  = 1.) Let  X  = min {  X  X   X  X  (0) / 5 , 1 / 20 } . (For both L Q and L logit 1 / 20.) Next, define the k  X  2 matrix W whose rows are w 1 ,..., w k : for i = 1 ,...,k , The marginal P X is defined as follows. Each of w 1 , w 3 , w 5 , w 7 have probability  X  (these are the  X  X ight points X ), and each of w 2 , w 4 , w 6 , w 8 have probability 1 / 4  X   X  (these are the  X  X eavy points X ). The weight matrix W whose rows are w 1 ,..., w 8 is then used to classify x as y = argmax z w z  X  x , so P is realizable with respect to H . (II): The vector of functions in H that mini-mizes L  X  has poor classification accuracy. Hence-forth V shall denote a k  X  2 matrix whose rows are v ,..., v k . Let us define the function  X  as follows: x )] .
 We want to show that  X  has a unique minimum. As a step in this direction, let us first show that  X  is strictly convex.
 Directly expanding the definition of P , separating the expectation into the heavy points and the light points, we get that  X ( V ) equals Since  X   X  is convex,  X   X  is strictly convex (by property (b) of the theorem  X  modifying any entry of V affects  X  ( v z  X  w j ) for at we have that  X  is strictly convex.
 Now, let us eliminate the possibility that the value of  X  can get arbirarily small. First, because  X  ( t ) &gt; 0 for all t , for any example ( x ,y ) we have  X  v y  X  x + Since inf x  X  R  X  ( x )  X  x &gt;  X  X  X  (by property (d) of the theorem statement), and  X  is an average of such losses, the function  X  is lower bounded (there is some value C  X  R such that  X ( V ) &gt; C for all V ).
 Next, let us eliminate the possibility that  X  has no minimum; since  X  is strongly convex, this can only occur if the value of  X  gets smaller and smaller as V heads to infinity in some direction. We claim that any V with a very large entry must have  X ( V ) &gt;  X ( V zero where V zero is the all-zero input. To see this, suppose | V zi | &gt; M for some row z and column i . Choose some y  X  X  1 ,.., 8 } other than z such that the angle between v z and w y is at most  X / 4. (There must be at least one such y .) Then  X ( V )  X   X  X  ( v z  X  w y )  X   X  X  ( || v z || cos(  X / 4))  X   X  X  ( M/ which is larger than  X ( V zero ) for M sufficiently large, by our assumption that  X  goes to +  X  as M  X  +  X  (by property (c) of the theorem statement). So for the purpose of minimizing  X , we can assume without loss of generality that the domain of  X  is [  X  M,M ] 8  X  2 for some constant M &gt; 0 . Since  X  is a strictly con-vex function defined on a bounded domain, there is a unique V  X  at which it achieves its minimum value. In the rest of the proof we will show that the error rate of V  X  w.r.t. P is at least 4  X . To prove this, first let us characterize the form of V  X  . We claim that there are real values q and r such that First, let us prove that V  X  2 , 1 = 0. Suppose V  X  2 , 1 by negating V  X  2 , 1 in V  X  , then V  X  6 = V  X  but  X ( V  X  ) =  X ( V  X  ). Since this contradicts the uniqueness of the minimizing point V  X  , it must be the case that V  X  2 , 1 0. The other 0-entries in ( 5 ) can be established in a similar way.
 We can prove that similarly by exploiting the symmetry of  X  across the x 2 axis, and we can prove that similarly by exploiting the symmetry across the line x Below we will show that q &gt; 2 r ; we claim that this this, consider first the classification of w 1 . We have So, if q/r &gt; 2, then V  X  misclassifies w 1 , and, similarly, all the other light points.
 We now proceed to show that q &gt; 2 r. Our analysis will make use of the function t : R  X  R defined by t ( x ) =  X   X  ( x )  X   X   X  (  X  x ) .
 for z = 1 ,..., 8 in order, one per line, we get This simplifies to It is clear that t (0) = 0. Furthermore, t  X  ( u ) =  X   X  X  ( u )  X   X   X  X  (  X  u )(  X  1) =  X   X  X  ( u ) +  X  since  X  is strictly convex. Thus t is increasing on all of R . Hence by ( 6 ) we have that r must be positive, and moreover that Now we consider a different partial derivative, line, we get Note that from the above equation it is clear that q must be positive (recall that t (0) = 0 and t is increas-ing). Also, since t is increasing ( 8 ) implies We want to combine this constraint with ( 7 ) to prove that q &gt; 2 r .
 Toward this end, we claim that t ( r )  X  5  X / we have from ( 7 ), implies that r  X   X / 2. (Recall that  X  was defined back at ( 3 ).) To see this, first assume for contradiction that r &gt;  X / 2. Then, since  X   X   X  X   X  X  (0) / 5. Since this is a contradiction, we have r  X   X / 2.
 Since r  X   X / 2, we have t (2 r ) = and, similarly t ( r )  X  2 r X   X  X  (0) / by ( 9 ). Since t is increasing, this implies q &gt; 2 r . This concludes the proof of Theorem 10 . Experiments used a source P generated as follows. The domain X was R d for d = 100. The number k of classes was 10. Class labels were assigned by apply-ing a  X  X arget classifier X  generated as follows. A weight matrix W  X  R 10  X  100 was generated by randomly gen-erating a 10  X  2 matrix A and a 2  X  100 matrix B , and setting W = AB . The components of A and B were sampled i.i.d. from the standard normal distribution. If we refer to the rows of W as w 1 ,..., w k as before, then the class y assigned to x was chosen to maxi-mize w y  X  x . Elements of X were chosen uniformly at random from the surface of the unit ball.
 We did experiments with three different loss functions: L
CS , L logit and L Q ( Zhang , 2004 ). For each loss func-tion L in this list, we experimented with the algo-rithm that, given ( x 1 ,y 1 ) ,..., ( x m ,y m ), chooses V and b ,...,b k to minimize  X  2 where || X || F is the Frobenius norm, and  X  = 10  X  6 . The minimization was done using Averaged Stochastic Gradient Descent ( Polyak &amp; Juditsky , 1992 ; Xu , 2011 ; Bottou , 2010 ) (ASGD) with a step size of p 1 /t on the t th update.
 In our experiments, we used 10000 training examples and 10000 test examples. We ran each algorithm for 100 epochs. At the end of each epoch we evaluated the accuracy of the algorithm on the test data. We repeated this process, including the random generation of the target weight matrix W , five times. Results are plotted in Figure 1 . In this work we proposed the new notion of realizable H -consistency, which is a variant of the standard no-tion of consistency for loss functions. Our experimen-tal and theoretical results indicate that for multiclass learning algorithms that work by minimizing a loss function over a restricted class H of scoring functions, realizable H -consistency may sometimes be more use-ful than consistency as a guide to classification perfor-mance.
 Consideration of realizable H -consistency highlights circumstances where loss functions like L CS , which involve a competition among the scores for different classes, may be preferred to generalizations of one-vs-rest, such as L logit . As discussed after the proof of Theorem 9 , L CS is realizable H -consistent because it incorporates such a competition, and not, for example, because it generalizes the hinge loss. (The hinge loss was shown to be optimally noise-tolerant for binary classification, in a certain sense, in ( Ben-David et al. , 2012 ).) In future work it would be interesting to extend our analyses to a non-realizable setting.
 We thank Shenghuo Zhu, Anelia Angelova and Yuan-qing Lin for valuable conversations.
 We will analyze the following source P . The domain consists of a single element x and the number k of classes is 3.
 We first characterize the optimal value of P with re-spect to L CS .
 minimized by setting h 1 ( x ) = h 2 ( x ) = h 3 ( x ) = 1 , where it takes the value 1 .
 Before proving Lemma 12 , we point out the follow-ing sanity check: one can easily verify that perturbing the solution h 1 ( x ) = h 2 ( x ) = h 3 ( x ) = 1 by adding or subtracting a small positive constant to any of the variables while keeping the others constant makes the solution worse.
 Now we proceed with the detailed proof.
 Proof (of Lemma 12 ): For possible values u 1 ,u 2 ,u 3 of h to be minimized is  X  ( u 1 ,u 2 ,u 3 ) def = (3 / 7)[1  X  u 1 + max { u 2 ,u 3 The minimimum of  X  can be equivalently represented as A Lagrange multiplier formulation is
L = (3 z 1 + 2 z 2 + 2 z 3 ) / 7 We claim that the following solution is optimal: Let us now check the KKT conditions. First, let X  X  check partial derivatives with respect to z ,z 2 ,z 3 ,u 1 ,u 2 ,u 3 respectively: All of the inequalities relating z 1 ,z 2 ,z 3 to u 1 ,u 2 tary slackness conditions are satisfied for those con-straints; since  X   X  i, + = 0 for all i , the complementary slackness constraints are satisfied for those constraints also. This completes the proof.
 Armed with Lemma 12 , we are ready for the following. Proof (of Theorem 7 ): Choose  X  &gt; 0, and consider g 1 ,...,g 3 for which g 1 ( x ) = g ( x ) = 1 and g 3 ( x ) = 1 +  X / 2. We have  X  is, we have q ( x ) = 3, so, for the Bayes optimal f , we have completing the proof.
 Ben-David, S., Loker, D., Srebro, N., and Sridharan,
K. Minimizing the misclassification error rate using a surrogate convex loss. In ICML , 2012.
 Bottou, L. Large-scale machine learning with stochas-tic gradient descent. In Proceedings of the 19th In-ternational Conference on Computational Statistics (COMPSTAT X 2010) , pp. 177 X 187, 2010.
 Breiman, L. Some infinity theory for predictor ensem-bles. Annals of Statistics , 32(1):1 X 11, 2004. Crammer, K. and Singer, Y. On the algorithmic im-plementation of multiclass kernel-based vector ma-chines. JMLR , 2:265 X 292, 2001.
 Friedman, J., Hastie, T., and Tibshirani, R. Additive logistic regression: A statistical view of boosting. The Annals of Statistics , 38(2):337 X 407, 2000. Harchaoui, Za  X  X d, Douze, Matthijs, Paulin, Mattis,
Dud  X  X k, Miroslav, and Malick, J  X er X ome. Large-scale image classification with trace-norm regularization. In CVPR , pp. 3386 X 3393, 2012.
 Haussler, D. Decision theoretic generalizations of the
PAC model for neural net and other learning ap-plications. Information and Computation , 100(1): 78 X 150, 1992.
 Kearns, M. J., Schapire, R. E., and Sellie, L. M. To-ward efficient agnostic learning. Proceedings of the 1992 Workshop on Computational Learning Theory , pp. 341 X 352, 1992.
 Lee, Y., Lin, Y., and Wahba, G. Multicategory sup-port vector machines: Theory and application to the classification of microarray data and satellite radi-ance data. Journal of the American Statistical As-sociation , 99(465):67 X 81, 2004.
 Lin, Y., Lv, F., Zhu, S., Yang, M., Cour, T., Yu, K.,
Cao, L., and Huang, T. Large-scale image classifica-tion: fast feature extraction and SVM training. In CVPR , pp. 1689  X  1696, 2011.
 Liu, Y. Fisher consistency of multicategory support vector machines. In UAI , pp. 291 X 298, 2007.
 Long, P. M. and Servedio, R. A. Random classification noise defeats all convex potential boosters. Machine Learning , 78(3):287 X 304, 2010.
 Perronnin, F., Akata, Z., Harchaoui, Z., and Schmid,
C. Towards good practice in large-scale learning for image classification. CVPR , pp. 3482 X 3489, 2012. Polyak, B. T. and Juditsky, A. B. Acceleration of stochastic approximation by averaging. SIAM J. Control Optim. , 30(4):838 X 855, 1992.
 Tewari, A. and Bartlett, P. L. On the consistency of multiclass classification methods. JMLR , 8:1007 X  1025, 2007.
 Vapnik, V. N. Inductive principles of the search for empirical dependences (methods based on weak con-vergence of probability measures). Proceedings of the 1989 Workshop on Computational Learning Theory , 1989.
 Weston, J., Bengio, S., and Usunier, N. Large scale image annotation: learning to rank with joint word-image embeddings. Machine Learning , 81(1):21 X 35, 2010.
 Xu, W. Towards optimal one pass large scale learning with averaged stochastic gradient descent. Arxiv , 2011.
 Zhang, T. Statistical analysis of some multi-category large margin classification methods. Journal of Ma-
