 The process of user interaction in collaborative writing has been the topic of many studies in re-cent years (Erkens et al., 2005). Most of the re-sources used for collaborative writing do not ex-plicitly allow their users to interact directly, so that the implicit effort of coordination behind the ac-tual writing is not documented. Wikipedia, as one of the most prominent collaboratively created re-sources, offers its users a platform to coordinate their writing, the so called talk or discussion pages (Vi  X  egas et al., 2007). In addition to that, Wikipedia stores all edits made to any of its pages in a revi-sion history, which makes the actual writing pro-cess explicit. We argue that linking these two re-sources helps to get a better picture of the collabo-rative writing process. To enable such interaction, we extract segments from discussion pages, called turns, and connect them to corresponding edits in the respective article. Consider the following snip-pet from the discussion page of the article  X  X oron X  in the English Wikipedia. On February 16th of 2011, user JCM83 added the turn : Roughly five hours after that turn was issued on the discussion page, user Sbharris added a wikilink to the  X  X istory and etymology X  sec-tion of the article by performing the following edit : This is what we define as a corresponding edit-turn-pair . More details follow in Section 2. To the best of our knowledge, this study is the first attempt to detect corresponding edit-turn-pairs in the English Wikipedia fully automatically.

Our motivation for this task is two-fold. First, an automatic detection of corresponding edit-turn-pairs in Wikipedia pages might help users of the encyclopedia to better understand the development of the article they are reading. Instead of having to read through all of the discussion page which can be an exhausting task for many of the larger arti-cles in the English Wikipedia, users could focus on those discussions that actually had an impact on the article they are reading. Second, assuming that edits often introduce new knowledge to an ar-ticle, it might be interesting to analyze how much of this knowledge was actually generated within the discourse on the discussion page.

The detection of correspondence between edits and turns is also relevant beyond Wikipedia. Many companies use Wikis to store internal information and documentation (Arazy et al., 2009). An align-ment between edits in the company Wiki and is-sues discussed in email conversations, on mailing lists, or other forums, can be helpful to track the flow or generation of knowledge within the com-pany. This information can be useful to improve communication and knowledge sharing.
In the limited scope of this paper, we will fo-cus on two research questions. First, we want to understand the nature of correspondence between Wikipedia article edits and discussion page turns. Second, we want to know the distinctive properties of corresponding edit-turn-pairs and how to use these to automatically detect corresponding pairs. In this section, we will define the basic units of our task, namely edits and turns. Furthermore, we will explain the kind of correspondence between edits and turns we are interested in.
 Edits To capture a fine-grained picture of changes to Wikipedia article pages, we rely on the notion of edits defined in our previous work (Dax-enberger and Gurevych, 2012). Edits are coherent modifications based on a pair of adjacent revisions from Wikipedia article pages. To calculate edits, a line-based diff comparison between the old re-vision and the new revision is made, followed by several post-processing steps. Each pair of adja-cent revisions found in the edit history of an arti-cle consists of one or more edits, which describe either inserted, deleted, changed or relocated text. Edits are associated with metadata from the revi-sion they belong to, this includes the comment (if present), the user name and the time stamp. Turns Turns are segments from Wikipedia dis-cussion pages. To segment discussion pages into turns, we follow a procedure proposed by Fer-schke et al. (2012). With the help of the Java Wikipedia Library (Zesch et al., 2008), we ac-cess discussion pages from a database. Discus-sion pages are then segmented into topics based upon the structure of the page. Individual turns are retrieved from topics by considering the revi-sion history of the discussion page. This proce-dure successfully segmented 94 % of all turns in a corpus from the Simple English Wikipedia (Fer-schke et al., 2012). Along with each turn, we store the name of its user, the time stamp, and the name of the topic to which the turn belongs.
 Corresponding Edit-Turn-Pairs An edit-turn-pair is defined as a pair of an edit from a Wikipedia article X  X  revision history and a turn from the dis-cussion page bound to the same article. If an arti-cle has no discussion page, there are no edit-turn-pairs for this article.

A definition of correspondence is not straight-forward in the context of edit-turn-pairs. Ferschke et al. (2012) suggest four types of explicit perfor-matives in their annotation scheme for dialog acts of Wikipedia turns. Due to their performative na-ture, we assume that these dialog acts make the turn they belong to a good candidate for a cor-responding edit-turn-pair. We therefore define an edit-turn-pair as corresponding, if: i) The turn is an explicit suggestion, recommendation or request and the edit performs this suggestion, recommen-dation or request, ii) the turn is an explicit refer-ence or pointer and the edit adds or modifies this reference or pointer, iii) the turn is a commitment to an action in the future and the edit performs this action, and iv) the turn is a report of a performed action and the edit performs this action. We define all edit-turn-pairs which do not conform to the up-per classification as non-corresponding. With the help of Amazon Mechanical Turk 1 , we crowdsourced annotations on a corpus of edit-turn-pairs from 26 random English Wikipedia ar-ticles in various thematic categories. The search space for corresponding edit-turn-pairs is quite big, as any edit to an article may correspond to any turn from the article X  X  discussion page. Assuming that most edit-turn-pairs are non-corresponding, we expect a heavy imbalance in the class distribu-tion. It was important to find a reasonable amount of corresponding edit-turn-pairs before the actual annotation could take place, as we needed a cer-tain amount of positive seeds to keep turkers from simply labeling pairs as non-corresponding all the time. In the following, we explain the step-by-step approach we chose to create a suitable corpus for the annotation study.
 Filtering We applied various filters to avoid an-notating trivial content. Based on an automatic classification using the model presented in our pre-vious work (Daxenberger and Gurevych, 2013), we excluded edits classified as Vandalism, Revert or Other. Furthermore, we removed all edits which are part of a revision created by bots, based on the Wikimedia user group 2 scheme. To keep the class imbalance within reasonable margins, we limited the time span between edits and turns to 86,000 seconds (about 24 hours). The result is a set of 13,331 edit-turn-pairs, referred to as ETP-all . Preliminary Annotation Study From ETP-all, a set of 262 edit-turn-pairs have been annotated as corresponding as part of a preliminary annota-tion study with one human annotator. This step is intended to make sure that we have a substantial number of corresponding pairs in the data for the final annotation study. However, we still expect a certain amount of non-corresponding edit-turn-pairs in this data, as the annotator judged the cor-respondence based on the entire revision and not the individual edit. We refer to this 262 edit-turn-pairs as ETP-unconfirmed .
 Mechanical Turk Annotation Study Finally, for the Mechanical Turk annotation study, we se-lected 500 random edit-turn-pairs from ETP-all excluding ETP-unconfirmed. Among these, we expect to find mostly non-corresponding pairs. From ETP-unconfirmed, we selected 250 ran-dom edit-turn-pairs. The resulting 750 pairs have each been annotated by five turkers. The turk-ers were presented the turn text, the turn topic name, the edit in its context, and the edit comment (if present). The context of an edit is defined as one preceding and one following paragraph of the edited paragraph. Each edit-turn-pair could be la-beled as  X  X orresponding X ,  X  X on-corresponding X  or  X  X an X  X  tell X . To select good turkers and to block spammers, we carried out a pilot study on a small portion of manually confirmed corresponding and non-corresponding pairs, and required turkers to pass a qualification test.

The average pairwise percentage agreement over all pairs is 0.66. This was calculated as number of annotated edit-turn-pairs, C = R 2  X  R the number of pairwise comparisons, R = 5 is the number of raters per edit-turn-pair, and v c i = 1 if a pair of raters c labeled edit-turn-pair i equally, and 0 otherwise. The moderate pairwise agreement re-flects the complexity of this task for non-experts. Gold Standard To rule out ambiguous cases, we created the Gold Standard corpus with the help of majority voting. We counted an edit-turn-pair as corresponding, if it was annotated as  X  X orre-sponding X  by least three out of five annotators, and likewise for non-corresponding pairs. Further-more, we deleted 21 pairs for which the turn seg-Figure 1: Percentage of (non-)corresponding edit-turn-pairs for various time intervals in ETP-gold. mentation algorithm clearly failed (e.g. when the turn text was empty). This resulted in 128 corre-sponding and 508 non-corresponsing pairs, or 636 pairs in total. We refer to this dataset as ETP-gold . To assess the reliability of these annotations, one of the co-authors manually annotated a random subset of 100 edit-turn-pairs contained in ETP-gold as corresponding or non-corresponding. The inter-rater agreement between ETP-gold (major-ity votes over Mechanical Turk annotations) and our expert annotations on this subset is Cohen X  X   X  = . 72 . We consider this agreement high enough to draw conclusions from the annotations (Artstein and Poesio, 2008).

Obviously, this is a fairly small dataset which does not cover a representative sample of articles from the English Wikpedia. However, given the high price for a new corresponding edit-turn-pair (due to the high class imbalance in random data), we consider it as a useful starting point for re-search on edit-turn-pairs in Wikipedia. We make ETP-gold freely available. 3
As shown in Figure 1, more than 50% of all corresponding edit-turn-pairs in ETP-gold occur within a time span of less than one hour. In our 24 hours search space, the probability to find a corresponding edit-turn-pair drops steeply for time spans of more than 6 hours. We therefore expect to cover the vast majority of corresponding edit-turn-pairs within a search space of 24 hours. We used DKPro TC (Daxenberger et al., 2014) to carry out the machine learning experiments on edit-turn-pairs. For each edit, we stored both the edited paragraph and its context from the old re-vision as well as the edited paragraph and con-text from the new revision. We used Apache OpenNLP 4 for the segmentation of edit and turn text. Training and testing the classifier has been carried out with the help of the Weka Data Mining Software (Hall et al., 2009). We used the Sweble parser (Dohrn and Riehle, 2011) to remove Wiki markup. 4.1 Features In the following, we list the features extracted from preprocessed edits and turns. The edit text is composed of any inserted, deleted or relocated text from both the old and the new revision. The edit context includes the edited paragraph and one preceding and one following paragraph. The turn text includes the entire text from the turn. Similarity between turn and edit text We pro-pose a number of features which are purely based on the textual similarity between the text of the turn, and the edited text and context. We used the cosine similarity, longest common subsequence, and word n-gram similarity measures. Cosine sim-ilarity was applied on binary weighted term vec-tors ( L 2 norm). The word n-gram measure (Lyon et al., 2004) calculates a Jaccard similarity coeffi-cient on trigrams. Similarity has been calculated between i) the plain edit text and the turn text, ii) the edit and turn text after any wiki markup has been removed, iii) the plain edit context and turn text, and iv) the edit context and turn text after any wiki markup has been removed.
 Based on metadata of edit and turn Several of our features are based on metadata from both the edit and the turn. We recorded whether the name of the edit user and the turn user are equal, the absolute time difference between the turn and the edit, and whether the edit occurred before the turn. Cosine similarity, longest common subsequence, and word n-gram similarity were also applied to measure the similarity between the edit comment and the turn text as well as the similarity between the edit comment and the turn topic name.
 Based on either edit or turn Some features are based on the edit or the turn alone and do not take into account the pair itself. We recorded whether the edit is an insertion, deletion, modification or relocation. Furthermore, we measured the length of the edit text and the length of the turn text. The 1,000 most frequent uni-, bi-and trigrams from the turn text are represented as binary features. Table 1: Classification results from a 10-fold cross-validation experiment on ETP-gold with 95% confidence intervals. Non-overlapping inter-vals w.r.t. the majority baseline are marked by  X . 4.2 Classification Experiments We treat the automatic classification of edit-turn-pairs as a binary classification problem. Given the small size of ETP-gold, we did not assign a fixed train/test split to the data. For the same reason, we did not further divide the data into train/test and development data. Rather, hyperparameters were optimized using grid-search over multiple cross-validation experiments, aiming to maximize accu-racy. To deal with the class imbalance problem, we applied cost-sensitive classification. In corre-spondence with the distribution of class sizes in the training data, the cost for false negatives was set to 4, and for false positives to 1. A reduction of the feature set as judged by a  X  2 ranker improved the results for both Random Forest as well as the SVM, so we limited our feature set to the 100 best features.

In a 10-fold cross-validation experiment, we tested a Random Forest classifier (Breiman, 2001) and an SVM (Platt, 1998) with polynomial ker-nel. Previous work (Ferschke et al., 2012; Bronner and Monz, 2012) has shown that these algorithms work well for edit and turn classification. As base-line, we defined a majority class classifier, which labels all edit-turn-pairs as non-corresponding. 4.3 Discussion and Error Analysis The classification results for the above configura-tion are displayed in Table 1. Due to the high class imbalance in the data, the majority class baseline sets a challenging accuracy score of .80. Both classifiers performed significantly better than the baseline (non-overlapping confidence inter-vals, see Table 1). With an overall macro-averaged F1 of .79, Random Forest yielded the best results, both with respect to precision as well as recall. The low F1 on corresponding pairs is likely due to the small number of training examples.
To understand the mistakes of the classifier, we manually assessed error patterns within the model of the Random Forest classifier. Some of the false positives (i.e. non-corresponding pairs classified as corresponding) were caused by pairs where the revision (as judged by its comment or the edit con-text) is related to the turn text, however the specific edit in this pair is not. This might happen, when somebody corrects a spelling error in a paragraph that is heavily disputed on the discussion page. Among the false negatives, we found errors caused by a missing direct textual overlap between edit and turn text. In these cases, the correspondence was indicated only (if at all) by some relationship between turn text and edit comment. Besides the work by Ferschke et al. (2012) which is the basis for our turn segmentation, there are several studies dedicated to discourse structure in Wikipedia. Vi  X  egas et al. (2007) propose 11 di-mensions to classify discussion page turns. The most frequent dimensions in their sample are re-quests for coordination and requests for informa-tion. Both of these may be part of a corresponding edit-turn-pair, according to our definition in Sec-tion 2. A subsequent study (Schneider et al., 2010) adds more dimensions, among these an explicit ca-tegory for references to article edits. This dimen-sion accounts for roughly 5 to 10% of all turns. Kittur and Kraut (2008) analyze correspondence between article quality and activity on the discus-sion page. Their study shows that both implicit coordination (on the article itself) and explicit co-ordination (on the discussion page of the article) play important roles for the improvement of arti-cle quality. In the present study, we have analyzed cases where explicit coordination lead to implicit coordination and vice versa.

Kaltenbrunner and Laniado (2012) analyze the development of discussion pages in Wikipedia with respect to time and compare dependences be-tween edit peaks in the revision history of the arti-cle itself and the respective discussion page. They find that the development of a discussion page is often bound to the topic of the article, i.e. arti-cles on time-specific topics such as events grow much faster than discussions about timeless, ency-clopedic content. Furthermore, they observed that the edit peaks in articles and their discussion pages are mostly independent. This partially explains the high number of non-corresponding edit-turn-pairs and the consequent class imbalance.

While there are several studies which analyze the high-level relationship between discussion and edit activity in Wikipedia articles, very few have investigated the correspondence between edits and turns on the textual level. Among the latter, Fer-ron and Massa (2014) analyze 88 articles and their discussion pages related to traumatic events. In particular, they find a correlation between the arti-cle edits and their discussions around the anniver-saries of the events. The novelty of this paper is a computational analy-sis of the relationship between the edit history and the discussion of a Wikipedia article. As far as we are aware, this is the first study to automati-cally analyze this relationship involving the tex-tual content of edits and turns. Based on the types of turn and edit in an edit-turn-pair, we have oper-ationalized the notion of corresponding and non-corresponding edit-turn-pairs. The basic assump-tion is that in a corresponding pair, the turn con-tains an explicit performative and the edit corre-sponds to this performative. We have presented a machine learning system to automatically detect corresponding edit-turn-pairs. To test this system, we manually annotated a corpus of corresponding and non-corresponding edit-turn-pairs. Trained and tested on this data, our system shows a sig-nificant improvement over the baseline.

With regard to future work, an extension of the manually annotated corpus is the most important issue. Our classifier can be used to bootstrap the annotation of additional edit-turn-pairs.
 The authors would like to give special thanks to Viswanathan Arunachalam and Dat Quoc Nguyen, who carried out initial experiments and the pre-liminary annotation study, and to Emily Jamison, who set up the Mechanical Turk task. This work has been supported by the Volkswagen Founda-tion as part of the Lichtenberg-Professorship Pro-gram under grant No. I/82806, and by the Hessian research excellence program  X  X andes-Offensive zur Entwicklung Wissenschaftlich- X  okonomischer Exzellenz X  (LOEWE) as part of the research cen-ter  X  X igital Humanities X . We thank the anony-mous reviewers for their helpful suggestions.
