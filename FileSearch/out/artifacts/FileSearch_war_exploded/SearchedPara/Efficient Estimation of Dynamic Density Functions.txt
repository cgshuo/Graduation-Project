 In this paper, we propose a new method to estimate the dy-namic density over data streams, named KDE-Track as it isbasedonaconventionalandwidelyusedKernelDensity Estimation (KDE) method. KDE-Track can efficiently esti-mate the density with linear complexity by using interpola-tion on a kernel model, which is incrementally updated upon the arrival of streaming data. Both theoretical analysis and experimental validation show that KDE-Track outperforms traditional KDE and a baseline method Cluster-Kernels on estimation accuracy of the complex density structures in data streams, computing time and memory usage. KDE-Track is also demonstrated on timely catching the dynamic density of synthetic and real-world data. In addition, KDE-Track is used to accurately detect outliers in sensor data and compared with two existing methods developed for detecting outliers and cleaning sensor data.
 H.2.8 [ Database Management ]: Database Applications-Data mining Algorithms, Experimentation, Performance Density Estimation, Interpolation, Data Streams, Outlier Detection
Data streams can be widely found in applications such as sensor network and internet management. The unbounded, rapid and continuous arrival of data streams disallows the usage of traditional data mining techniques. Therefore, the development of algorithms for processing data streams in-stantaneously becomes highly important.

This paper targets on estimating the dynamic density that comes with the evolving data streams. The estimated den-sity characterizes the underlying distribution that can be used in many applications such as online outlier detection and online clustering. Comparing with other data stream mining work, e.g., clustering, classification and frequent pat-tern mining, density estimation of data stream is much less mature. Besides the problem of estimating the density us-ing samples drawn from an unknown distribution that re-searchers face in case of stationary data, data streams have more challenging properties that complicate the estimation of the Probability Density Function (PDF). In data streams, the theoretical PDF changes dynamically in an unpredictable fashion. Therefore, PDF estimation should rely more on the recent data [8]
Approaches for estimating the density function of samples drawn from a distribution can be categorized into parametric and nonparametric methods. In this paper, we consider the non-parametric approaches as they make no assumptions on the data distribution. Kernel Density Estimation (KDE) is one of the most popular non-parametric density estimation techniques and has been shown in [13] to converge to the true density function as the number of samples drawn from the distribution goes to infinity. Although KDE is a promising technique, its high computational and space costs hinder its usage on large-size and streaming data.

Zhou et. al. [16] and Heinz et. al. [8] introduced the concepts of M-Kernel and Cluster Kernels (C-Kernels) re-spectively to minimize the space requirements of KDE. In both methods, each kernel summarizes a cluster of similar samples. When estimating the PDF of big data, they both treat samples one by one in order. Each new sample can either fall into one existing kernel or trigger a new kernel. If the number of kernels exceeds a user defined number, two kernels are merged based on a cost function value. When estimating PDF, only one sample is used to represent all samples in one cluster, which affects the estimation accu-racy. C-Kernels introduces data resampling. Regenerating all of the samples might be accurate but very costly in com-putations.
 In this paper, we build our density estimator based on KDE method due to its advantages for estimating the true density [13]. Our proposed method, called KDE-Track, mod-els the data distribution as a set of resampling points with their estimated PDF. In order to overcome the quadratic time complexity and linear space complexity problem of KDE when evaluating the PDF for each new observation, linear interpolation is used with KDE for online density es-timation. This technique was discussed in [9] and known as Kernel Polygons but for stationary data sets and using fixed number of the resampling points.

Our KDE-Track has three unique properties: (1) updating the resampling model is done online with a linear time and space complexities w.r.t. the model size; (2) estimating the PDF of a new arriving data sample is done in a time linearly proportional to the model size; (3) the adaptive sampling of PDF improves the estimation accuracy. More (less) points are re-sampled in the areas where PDF has a larger curvature (is approximately linear).
Both theoretical analysis and experimental results on syn-thetic and real-world data show the effectiveness of our ap-proach for dynamic density function estimation. We also apply the density estimation to online outlier detection. Mo-mentary outliers in the evolving data, which are vague in all observations, can be effectively reported through monitoring the dynamics of the estimated density.

The rest of the paper is organized as follows: Section 2 presents our approach KDE-Track with the KDE interpola-tion and its error bound. Section 3 presents evaluation re-sults. Section 4 demonstrates the application of KDE-Track to outlier detection. Section 5 concludes our work.
In this section, we first describe the KDE interpolation method, then analyze its theoretical error bounds that guar-antee the accuracy of density estimation, and finally present the KDE-Track method for online density estimation.
Given a set of samples, { x 1 ,x 2 , ..., x m } , KDE estimates the density at a point x as  X  f ( x )= 1 mh m m j =1 K x  X  where K (  X  ) is a kernel function, h m is a smoothing parame-ter called the bandwidth and computed from the m samples. The choice of the kernel function has no significant effects on the estimation provided that the kernel function is contin-uous with finite support [15]. We choose the Epanechnikov kernel in this paper, K ( x )= 3 4 (1  X  x 2 ) I [  X  1 , 1] tion accuracy of KDE is mainly affected by the bandwidth value [13, 15]. It is crucial to set the bandwidth value by considering the statistic properties of samples. The band-width value we used is set according to the normal rule that has been widely used and proven to be accurate enough [15]. That is, h m =1 . 06 X   X m  X  1 5 , where  X   X  is the estimated standard deviation of the m samples.

KDE stores all the data samples received so far and use them all to estimate the PDF of any given point. Thus, the space requirement for KDE is linearly proportional to the sample size and the time complexity for online density estimation will be quadratic.
We model the data stream distribution as a set of sorted resampling points and their corresponding estimated den-resampling points, and S ( i ) is an ordered pair represent-ing a point and its estimated PDF ( S ( i ) =( S ( i ) 1 , S 2 =  X  f ( S structing the set of resampling points and the corresponding estimated density values. Estimating the PDF at a point x by linear interpolation of the resampling points has the fol-lowing 2 steps: (1) find two adjacent resampling points S ( k ) 1 , 1 and (2) estimate the density at x by interpolation
KDE interpolation is efficient as it stores only the func-tion at the resampling points whose total number is in the constant order and is small compared to the sample size. The running time for estimating the PDF for all n arriving data samples will be in O ( n |S| ).
This subsection discusses the error bound of density esti-mated by linear interpolation.

Proposition 2.1. The density estimated by linear inter-polation is Compared with the KDE estimation  X  f ( x ) , the error incurred in linear interpolation has an upper bound |  X  f ( x )  X   X  f ( x ) | X 
Proof. Assume that a point x locates between S ( k ) 1 , 1 S 1 ,where S expansion as: Equations (3) and (4) into the interpolation Equation (1), we have Equation (2) that gives the relationship between  X  f ( x )and  X  f ( x ).
 When x is in the middle of the interval [ S ( k ) 1 , 1 , deviates from  X  f ( x )mostwiththemaximumerrorof
Note that this error bound is calculated w.r.t. the es-timated density using KDE instead of the theoretical true density. Hence, the density  X  f ( x ) will contain an extra prop-agated error from the KDE. However, as observed in our experimental results, interpolation can improve KDE and result in better accuracy.
From Proposition 2.1, we know that the accuracy of the linear interpolation depends on 1) the distance between two adjacent resampling points; and 2) the second derivative of the density function. To minimize the error while keeping the number of resampling points within a reasonable mar-gin, we add more resampling points in the regions where the density function has high curvature. By contrast, in the regions where the function is approximately linear, we use less number of resampling points. In this sense, we can rewrite the resampling set as S = {S (1) , S (2) , ..., S ( q ) } S ( i )  X  IR c  X  2 , c  X  1. The two columns of S ( i ) present the resampling points and their corresponding estimated PDFs, respectively. The j -th resampling point in the sublist S ( i ) is the time required for accessing the interval including x .Ac-cessing the target interval can be done by advancing an it-erator over the list instead of performing data comparisons. To estimate the density for each incoming data sample, KDE-Track only requires to access two resampling points as we use the linear interpolation technique discussed in Sub-section 2.1. The key step is thus the maintenance of resam-pling model (points and their PDF).

The resampling model is initialized by the beginning part of streaming data, e.g., the first 20K points. The resampling points within the range of initial points received so far. The PDF values S ( i ) 1 , 2 of these resampling points are computed using a traditional KDE on the batch of initial points.
Once all S ( i ) have been initialized, we can estimate the density at each arriving point x . Due to our interpolation method, the density at x can be estimated by 1) calculating the index of one resampling point who and whose successive neighbor will contribute; and 2) computing  X  f ( x )byinterpo-lation Equation (1).
 The calculation of the index k is done using the equation: where s is the equidistance between S ( j +1) 1 , 1 and S j  X  q positions. If the interval at position k has been further divided, we perform a sequential search within the internal list on c resampling points. The density estimation process of KDE-Track is described in Algorithm 1.
 Algorithm 1 KDE-Track: estimate density  X  f ( x )
As the resampling model is the basis of our density esti-mation, the PDF values of the resampling points should be updated after receiving a new data point. Updating the den-sities of resampling points in the model S should consider the evolution of the distribution. We use a sliding window strategy to catch the evolution over time. Let w denote the predefined parameter of window size, and n t denote the number of points we have received until time t . Due to the difference between w and n t , there are two different scenar-ios when updating the model S , more specifically, updating the bandwidth and density function values S ( i ) j, 2 =  X 
When n t  X  w . The received points cannot fill the whole window. The bandwidth value at time t is calculated by using all n t points by the formula  X  h t =1 . 06 X   X  t n  X  1  X   X  is the sample variance of the received data samples calcu-can be updated with a constant time at each t .

After receiving a point x t , the density at a resampling point x at time t is updated using the equation:
When n t &gt;w . In this case, the bandwidth is calcu-lated on the most recently received w points inside the win-ance  X   X  2 t can be easily updated by  X   X  2 t = 1 w  X  1 i
The density  X  f t ( x ) is updated by absorbing the new arrived point x t and deleting the old point that moved out from the window,  X  f ( x )= 1 The probabilistic properties of updated density function  X  can be proved as: (i)  X  f t ( x )  X  0 ,  X  x , due to the fact that  X  f ( x ) is a summation of nonnegative terms; (ii) the integration  X   X  X  X   X  f t ( x ) dx = 1. This is because the integration of K ( ( x  X  x j )  X 
Updating the resampling model should consider the changes in the regions of the PDF with high curvature as they change over time. We should also consider the extension of the model to cover the range of the data and shrinking the model when data from some regions are no longer available. Such changes can not be observed frequently. Checking for such changes is done after receiving a predefined number of points that represents a ratio of 5  X  20% of the sliding window size.
Based on the discussion in the Subsection 2.4, the time complexity of estimating the density for a new incoming data point is linearly proportional to the model size S regardless the number of points that have been received from the data stream. Updating the model when receiving a new point requires computing time linear to the total number of the resampling points |S| = q i =1 |S ( i ) | , since all the function values at the resampling points are updated. The overall time complexity of processing each arriving point is linear to the model size, which is usually a limited small number. The time required to online density estimation for a data stream with n points is O ( n |S| ), which linearly increase with the number of received points.

During the online density estimation process, KDE-Track only keeps the resampling model S in memory. Therefore, the memory usage is the model size |S| .
In order to evaluate our method, we run extensive number of experiments on both synthetic data and real world data from the Intel Berkeley Research Lab [2]. Figure 1: MAE incurred by KDE-Track, KDE and C-Kernels when estimating the density function of the synthetic data set  X  X yn10 X  using window size w =20 K (a) and w =2 M (b).
The synthetic data were generated by varying the mixture of several normal distributions along time. We validated our method on several synthetic data sets with various mixtures, but only present the results on a data stream with 2 million points derived from a dynamic mixture of ten normal distri-butions (named X  X yn10 X , each distribution contributes 200K points) due to space limitation.

To evaluate the accuracy of the estimation, we defined evaluation checkpoints at every 1000 samples in the data stream. At each checkpoint, 1000 evaluation points that are uniformly sampled within the range of the received data were generated. The mean absolute error (MAE) is then computed as MAE = 1 1000 1000 i =1 |  X  f ( e i )  X  f ( e
Figure 1 (a) shows the error incurred by the evaluated methods KDE-Track, KDE and C-Kernels with window size w =20 K . All methods show very small MAE values around 2 . 5  X  10  X  3 , and C-Kernels 200 has a slightly higher MAE than others 1 . The embedded subfigures show both the true dy-namic densities and the estimated densities by KDE-Track at different checkpoints. We can see that our method can capture the changes and accurately estimate the dynamic density all the time.

C-Kernels is not designed to capture the dynamic den-sity. At each evaluation checkpoint, we delete the old model created by the previous sliding window and create a new model based on the current window. This adaptation pre-serves the estimation accuracy of C-Kernels but shows to be impractical for online density estimation due to the high computational cost, as shown in Table 1.
 Figure 1 (b) compares the MAE of KDE-Track, KDE and C-Kernels when setting window size to be 2 M .Inthiscase, the underlying distribution is still dynamic but more com-
MAEs are plotted on the scale of PDF to show that errors are relatively very small compared to the density values. Table 1: Running time and memory usage of KDE-Track, KDE, and C-Kernerls on  X  X yn10 X  data plex. Our method is shown to perform very well with even smaller errors than KDE, and is more stable. The stability and better accuracy of KDE-Track are due to the incremen-tal update policy, which uses different bandwidth values for arriving samples when updating the model. C-Kernels shows bigger errors when data from a new distribution arrive. Us-ing more clusters could reduce the impact of the dynamic behavior of the data as this example shows, but increase the memory usage and processing time.
We studied the dynamic behavior of real world data sets from the Intel Berkeley Research Lab [2]. Only the results of temperature is shown in Figure 2 due to space limitations. The dynamic distribution is demonstrated in 9 subfigures, which are the snapshots of the estimated density functions at random checkpoints. This evaluation used a sliding win-dow with size w =20 K that is approximately a three-hour time window. While we cannot evaluate the estimation ac-curacy since the theoretical probability density functions are unknown, the figure shows the dynamic changes in the PDF over time. These changes should be considered when making decisions in applications like outlier detection.
We can also notice from the figures that at the end of the data stream, readings becoming inconsistent as we get many temperature values around 122. These inconsistent readings appear because of low battery power in the sensors as reported in [14]. Figure 2: Dynamic density of temperature estimated by KDE-Track.
There are many approaches for outlier detection that dif-fer in the intuition of outliers and the way reporting outliers. Statistical based approaches identify outliers that do not fit in the statistical model [7]. Distance-based outlier detec-tion method reports p as a DB (  X ,d min )-outlier if at least percentage  X  of the objects in a data set lies in distance greater than d min from p [10]. Density-based approaches report a point as an outlier if the density in its neighbor-hood is too different from the densities around its neighbors
