 MASAKI MURATA, MASAO UTIYAMA, KIYOTAKA UCHIMOTO, and HITOSHI ISAHARA, National Institute of Information and Communications Technology and QING MA, Ryukoku University, and National Institute of Information and Communications Technology ________________________________________________________________________ ________________________________________________________________________ 1. INTRODUCTION In recent years, various types of tagged corpora have been constructed and much research using tagged corpora has been done. Howeve r, tagged corpora contain errors, which anomaly detection [Abney et al. 1999; Eskin 2000]. But there are no papers that we know of regarding error correction in corpora. 1999; 2001]. In this article we use the word modality 1 in the broad sense, including tense aspect, and modality as the modality corpus . translation. In traditional appr oaches, tense, aspect, and modality have been translated by Recently, however, corpus-based approaches, such as the example-based method [Nagao 1984; Sumita 1992; Sato 1993], have also been applied [Murata et al. 1999]. The modality corpus we consider here is necessary for such machine translation; it is based on a corpus-based approach. Our modality corpus is constructed by adding tags with modality information to an existing parallel corpus. The added tags are used as supervised learning data for corpus-based approaches, and thus are necessary. When we use many kinds of potential machine learning methods with a wide variety of features as means of our proposed method.
 machine-learning methods. As machine-learning methods we tested the decision-list and maximum-entropy methods. With our method for corpus correction, we first calculate the compared several kinds of corpus-correction methods experimentally, and confirmed that our method is an effective m eans for corpus correction. Section 3; and our experiments for corpus correction in Section 4. 2. A MODALITY CORPUS FOR MACHINE TRANSLATION In this section we describe the modality corpus. A typical part is shown in Figure 1. It is composed of a Japanese-English bilingual corpus, and each English sentence can include , kono kodomo wa aa ieba kou iu kara koniku-rashii d kare ga aa okubyou da to wa omowana-katta
I &lt;v&gt; did not think &lt;/v&gt; he was so timid. c aa isogashikute wa yasumu hima mo nai hazu da
Such a busy man as he &lt;v&gt; cannot have &lt;/v&gt; any spare time. two types of tags:  X  The English main verb phrase is tagged &lt;v&gt; .  X  The English verb phrase that is not a main verb phrase and corresponds to the category of tense, aspect, and modality, e. g.,  X  X  X  and  X  X  X  indicate  X  X an X  and  X  X ast tense, X  verb does not correspond to the English main verb in the translated English sentence. The category of the verb phrase corresponding to the Japanese main verb. In this corpus, the number of examples of the present tense is large, so the symbol for the present tense is a correspond to the Japanese main verb. when a Japanese main verb does not correspond to the English main verb in the translated English verb that corresponds to the Japanese main verb by using the two kinds of tags. These categories are uniquely determined by the surface expressions of the English verb phrases, so the definitions on the tags are not ambiguous. (Categories 4 to 7 cover cases where the sentence does not have a main verb.) 1. all combinations of {present tense, past tense}, {progressive, not-progressive}, and 2. imperative mood (1 category); 4. noun phrases (one category); 5. participial construction (one category); 6. verb ellipsis (one category); 7. interjection or greeting sentences (one category); 9. the case when tagging cannot be performed 2 (one category). Japanese sentence, we should be able to tran slate the Japanese tense, aspect, and modality into English. Therefore, when studying the translation of modality expressions based on the machine-learning method, we used only the tags that indicate the categories of tense, aspect, and modality, and the Japanese sentences. Japanese tense, aspect, and modality expressi ons is that the Japanese language has many kinds of tense, aspect, and modality expressions, so we need to manually construct many kinds of rules for translation or use corpus-based approaches that do not need rules. The modality corpus constructed in this study can be used as supervised data for such corpus-which English expression is appropriate for ambiguous Japanese expressions such as  X  shite-ita  X . We placed an order with an outside company to construct a modality corpus according to the above conditions. We used 40,198 example sentences from the Kodansha Japanese-English dictionary [Shimizu and Narita 1976] as a bilingual corpus. An outside company inspected by the outside company at least tw o times. The occurrence rates for the major categories are shown in Table I. As can be seen in the table, the present tense occurs most frequently. 3. CORPUS CORRECTION METHOD In this section we describe the method used to correct errors in the manually constructed category tags only, not the  X  &lt;v&gt;  X  X r  X  &lt;vj&gt;  X  tags. 3.1 Outline of Our Corpus Correction Method An outline of our corpus correction method follows: 1. We first calculate the probabilities for each tag category (including the tag category 2. Next, we use these probabilities to judge whether the tag is correct. 3. Finally, we correct the tag if it is judged to be incorrect. This correction is done by In the next section we describe two methods: the decision list method and the maximum-entropy method, which we used to calculate th e probabilities. In Section 3.3 we describe the features that provide the context when the probabilities are calculated. In Section 3.4 we describe a method based on confidence values, which reduces the human effort. With examples of how we use machine-l earning methods for corpus correction . 3.2 Methods for Calculating Probabilities We used the maximum-entropy and decision-list methods because they can be used to calculate the tags X  probabilities. 3  X  A method based on the maximum-entropy method [Ristad 1997; 1998]. for () k j f j  X   X   X  1 using only equation (1) produces many solutions for p ( a,b ). Maximizing the entropy has for data sparseness problems.  X  A method based on the decision-list method [Yarowsky1994]. In general, it is known that the maximum-entropy method performs better than the always perform better than the decision-list method. However, in this study, we also used the decision-list method, because it offers the advantages of being very simple and easy to use. 3.3 Features In this section we describe the features that provide the context when the probabilities are calculated. In this article we used the followin g items as features; 26 (= 5 + 10 + 10 + 1) features appear in each English sentence.  X  The strings of 1-gram to 5-gram just to the left of &lt;v&gt; in the sentence, 4  X  The 1-gram string at the end of the sentence, above extraction of features was performed af ter eliminating the words between the first &lt;/v&gt; and the second &lt;v&gt; . strongly related to verb modality expressions. English sentence from a Japanese one, we may think that we should extract the features from the Japanese sentence. This would be tr ue if we wanted to infer English modalities When the category of the modality expression in the English sentence is tagged, the verb phrase in corpus correction. 3.4 A Method Based on Confidence Values: Reducing Human Effort Corpus correction must be confirmed by human beings, which is time consuming. However, when the probability for each tag can be calculated, we can define the and begin by correcting the errors for which the confidence value is highest. correction:  X  Method 2. The non-probability of the tag originally defined is used as the  X  Method 4 . The difference between the probability of the category with the highest probability from 1. Method 1 is based on the idea that a tag given to the corpus after the Method 2 is based on the idea that a tag originally given to the corpus before the corpus and Method 4 are variations, combining Methods 1 and 2. 3.5 A Method that Uses Data to Calculate Probabilities methods can be used to calculate the probabilit ies by using the machine-learning method:  X  calculating the probabilities for closed data, and  X  calculating the probabilities for open data. including the instance currently being judged. The second method does not use the calculate probabilities for the open data. In the 10-fold cross validation, a set of data was judged by using the 10-fold cross validation from the training data, and thus does not use the instance currently being judged to calculate probabilities. category of the tag defined after corpus correc tion is apt to be 1, since the calculation is many of them will have the same probability, and sorting by probabilities becomes difficult. In this case, we sort the tags by arranging those whose probability is calculated from features with many tags in descending order of confidence value. 3.6 Using Machine-Learning Methods: An Example Here, we show an example of using machine-learning methods. We use the following parallel sentence in our explanation.  X  X  X  in the first sentence is a tag indicating the category of auxiliary verb phrase  X  X e able example of an incorrect tag.  X  The strings of 1-gram to 5-gram just to the left of &lt;v&gt; in the sentence.  X  The 1-gram string at the end of the sentence. Features:  X  X 4:. X . In the above,  X  X x X  is an in dicator of a feature type. follows: equation (3) and the above parameters ( j a ,  X  ), and obtained p ( a | b ) as follows: p ( X  X e going to X  X  b ) = 0.7493 p ( X  X resent X  X  b ) = 0.0904 The category output by the system was  X  X e going to X , which has the highest value; it was not equal to the original tag  X  X e able to X . Thus the original tag was judged to be incorrect. p ( X  X e going to X  X b) was used as the probability of the category with the highest probability and p ( X  X e able to X  X b) as the probability of the original tag for using Methods 1 to 4. training data for calculating the weight ( j a ,  X  ) of each feature. obtained the values as follows: ( follows: When using the maximum-entropy method, the output category given by the system was original tag for using Methods 1 to 4. training data for calculating the values ( p ~ ( a i | f j )) of each feature. 4. EXPERIMENTS FOR CORPUS CORRECTION 4.1 Experiments and Results 4.1.1 Experiments. We carried out experiments on corpus correction by using the machine learning. In other word s, we eliminated the sentences that had the categories of noun phrases, verb ellipsis, interjection or gr eeting sentences, and the case where the data Thus, these experiments were done for 39,718 modality tags. 4.1.2 Experimental Results. The experimental results are shown in Tables II to V.  X  X op indicates the precision for 300 tags extracted randomly from among the tags corrected by the system.  X  X recision for detection X  indicates the percentage of tags for which detection for correction X  indicates the percentage of ta gs for which correction of an error succeeded in causing the tag to be corrected by our system. (Tables II to V) was done by judging manually whether the algorithm or the original tag also performed the same evaluation; that is, we judged manually whether the algorithm or tags extracted randomly while using the maximum-entropy method with the company and our results. Only one case was an error made by the outside company, the remaining 14 were our errors. (There were no cases wh ere we could not determine which evaluation was correct, since our tag definitions were not ambiguous.) The outside company experimental results shown in Tables II to V are reliable. 4.1.4 Estimation of the Error Rate for the Original Corpus. To estimate the error rate for ones. When we compared the assigned tags to the original ones, we found eight were our errors. There were no cases where we could not determine which tag was correct. So we can estimate that the error rate of the origin al corpus was about 1.33% (= 4/300). 6 4.2 Discussion of the Effectiveness of the Methods In this Study In this section we examine the effectiveness of the several kinds of methods in this study and develop a good strategy for corpus correction based on this examination. 
Table II: Precision of Corp us Correction Using the Maximum-Entropy Method. (The probabilities were calculated using closed da ta; 184 candidate erro rs were extracted) Method 1 Top 50 100% ( 50/ 50) 100% ( 50/ 50) Method 2 Top 50 88% ( 44/ 50) 88% ( 44/ 50) Method 3 Top 50 92% ( 46/ 50) 92% ( 46/ 50) Method 4 Top 50 100% ( 50/ 50) 100% ( 50/ 50) 
Table III: Precision of Corpus Correction Using the Maximum-Entropy Method. (The probabilities were calculated using open data; 694 candidate errors were extracted.) Method 1 Top 50 88% ( 44/ 50) 88% ( 44/ 50) Method 2 Top 50 72% ( 36/ 50) 72% ( 36/ 50) Method 3 Top 50 78% ( 39/ 50) 78% ( 39/ 50) Method 4 Top 50 88% ( 44/ 50) 88% ( 44/ 50) probabilities were calculated using closed data ; 383 candidate errors were extracted.) Method 1 Top 50 100% ( 50/ 50) 100% ( 50/ 50) Method 2 Top 50 88% ( 44/ 50) 86% ( 43/ 50) Method 3 Top 50 88% ( 44/ 50) 86% ( 43/ 50) Method 4 Top 50 100% ( 50/ 50) 100% ( 50/ 50) probabilities were calculated using open data; 2427 candidate errors were extracted.) Method 1 Top 50 52% ( 26/ 50) 52% ( 26/ 50) Method 2 Top 50 64% ( 32/ 50) 64% ( 32/ 50) Method 3 Top 50 68% ( 34/ 50) 68% ( 34/ 50) Method 4 Top 50 57% ( 29/ 50) 57% ( 29/ 50) 4.2.1 Comparison between Detection Precision and Correction Precision. Throughout all the experiments, the precision was almost the same for detection and correction. Thus, we detection only. hand, the following two types of benefit result if the system performs both detection and correction.  X  When the system produces a candidate tag, an annotator is be able to easily find the  X  When the system produces a candidate tag, an annotator will be able to easily find 4.2.2 Comparing the Decision-List and Maximum-Entropy Methods. In general, the maximum-entropy method produced higher precision than the decision-list method. top items was almost the same for the two methods. we used the prop_test_2 command of the octave software for the statistical test. In terms between the maximum-entropy and the decision-list methods when either the closed data maximum-entropy method is more effective than the decision-list method. calculate the probabilities, the precision for the top items is almost the same for the two methods. This indicates that the decision-list method, which is simpler and easier to use than the maximum-entropy method, can be used for corpus correction when closed data is used and only a limited number of the top data is checked. using closed data to calculate the probabilities was better than using open data. However, in terms of the number of correctly extracted and corrected errors, using the open data is better. entropy method, Method 1, or Method 2. We confirmed that in terms of the precision of the top items, the use of closed data to calculate the probabilities is better than the use of open data. data for both the decision-list and the maximum-entropy methods. Therefore, we better than the use of closed data. can use the tag of the instance currently being judged for training while the latter cannot. For example, the example-based method that outputs the tag of the instance most similar to the input instance as the answer can obtain very high precision with the method using and obtain lower precision than the method using closed data in corpus correction. Since the method using open data has lower precision than the one using closed data, the method using open data obtained more extracted candidates for corpus correction than the corrected errors using open data is larger than when using closed data. precision as shown in Tables II to IV, except for one case (Table V).
 shown in Tables II to IV, except for one case (Table V). the  X  X op 50 X , there were differences at the 0.05 significance level when Methods 1 and 4 either Method 1 or Method 4 should be used, except for one case (Table V). 4.2.5 Comparing  X  X andom 300 X  and  X  X op X X . Comparing  X  X andom 300 X  and  X  X op X X  results, we see that  X  X op X X  produced much higher precision for the top items. We found that sorting via the confidence values of corpus correction is important . that the following strategy is a good solution. 1. First perform high-quality corpus correction by using the probability calculation for 2. Next, perform corpus correction for a much larger number of tags using the 4.3 Errors by Annotators We next examined errors, extracted via our method, made by annotators. The most common error patterns (those that occurred at l east three times) are shown in Table VI. Past and present categories often became errors . We attribute the high error frequency to the high rate of occurrence (Table I). Japanese sentences. When a Japanese sentence used the word teiru , which mainly means Japanese sentence. Errors attributable to such causes were frequent. used the symbol  X  X  X  for  X  X ay X  and  X  X  X  for  X  X us t X . In this situation, an annotator might have trouble remembering that  X  X ust X  is  X  X  X , and may absent-mindedly think that  X  X ust X  annotator errors. 4.4 Evaluation Using Machine Translation instead of an uncorrected modality corpus. We used a machine-learning approach for the machine translation, which is one of the corpus-based ap proaches. We used 40,198 hence were eliminated in the corpus correction experiments. We did not use the modality corpus. The other sentences in the corpus were used for learning. The number of learning k-nearest neighborhood 93.50% (748/800) 93.38% (747/800) decision-list 92.25% (738/800) 91.88% (735/800) maximum-entropy 94.12% (753/800) 93.88% (751/800) support-vector machine 94.62% (757/800) 94.38% (755/800) data numbered 39,398. To show the effectiven ess of corpus correction, we compared the entropy method and the open data.  X  the k-nearest neighborhood method,  X  the decision-list method,  X  the maximum-entropy method, and  X  the support-vector machine method support-vector machine meth od [Cristianini and Shawe-Taylor 2000]. For more information on these methods, please refer to our previous paper [Murata et al. 2001]. sentences and all the morphemes fro m each of the sentences, e.g.,  X  omowana-katta  X  (did not think),  X  na-katta  X  (did not),  X  ta  X  (did) ,  X  kono  X  (this),  X  kodomo  X  (child). sentences, e.g.,  X  omowana-katta  X  (did not think),  X  na-katta  X  (did not),  X  ta  X  (did). the other machine-learning methods. We confirmed in advance (in our previous paper method and Feature-set 2 for the other methods. created, for the evaluation, a gold standard data set, as follows. The category of the tag in the corrected corpus was added to the correct category set. Three professional translators, working independently, each formed a newly translated English sentence from the input Japanese sentences, and the categories of the modality of the sentences were added to the correct category set. category set. The resultant correct category se ts became our gold standard data. When a correct; otherwise, it was judged incorrect. precision rates when original tags are used for learning. machine-translation software programs cu rrently on the market. With the baseline judged to be in the past tense; otherwise a se ntence was judged to be in the present tense. When a machine-translation software program could not output a sentence, the output of the baseline method was used instead. incorrect and use of the corrected tags is co rrect. We did not find any cases where use of the original tag was correct and use of the co rrected tags incorrect. We found that corpus improvement was not particularly large. The support-vector machine method provided the highest precision and the corpus correction enabled a 0.24% improvement (= 94.62% -94.38%). This improvement as a proportion of the original errors is 4.3% (=0.24/(100-among 39,718 pieces of data. The ratio of th e correction is thus 0.44% (=178/ 39718), so the improvement (0.24%) is close to half of the ratio of correction (0.44%). software programs in Table VIII. Our machine-learning method achieved similar or higher precision than the best mach ine-translation software programs. 5. CONCLUSION maximum-entropy and decision-list methods as machine-learning methods. We compared test determined which method was best. Our findings are as follows.  X  In general, the maximum-entropy method is better than the decision-list method.  X  With respect to sorting by Method 1 (using the probability of the category with the evaluation shows that machine translation ba sed on machine-learni ng methods could also be made better by improving the modality corpus used as the supervised data for learning.  X  There have been few previous papers on error correction in corpora.  X  Our method calculates the probability for e ach tag and can sort the error candidates  X  Our method uses the machine-learning method and inherits its original advantages. English translation of tense, aspect, and modality. Recently, corpus-based machine translation has been studied extensively. Sin ce the effectiveness of corpus-based machine discuss in this article should be a significant advance in this field. REFERENCES 
