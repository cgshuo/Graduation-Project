 Understanding users X  interactions with highly subjective content X  like artistic images X  X s challenging due to the complex semantics that guide our preferences. On the one hand one has to overcome  X  X tandard X  recommender systems challenges, such as dealing with large, sparse, and long-tailed datasets. On the other, several new challenges present themselves, such as the need to model content in terms of its visual appearance, or even social dynamics, such as a preference toward a particular artist that is independent of the art they create.

In this paper we build large-scale recommender systems to model the dynamics of a vibrant digital art community, Behance , consist-ing of tens of millions of interactions (clicks and  X  X ppreciates X ) of users toward digital art. Methodologically, our main contributions are to model (a) rich content, especially in terms of its visual ap-pearance; (b) temporal dynamics, in terms of how users prefer  X  X i-sually consistent X  content within and across sessions; and (c) social dynamics, in terms of how users exhibit preferences both towards certain art styles, as well as the artists themselves.
 Recommender Systems; Artistic Preferences; Markov Chains
The power of recommender systems lies in their ability to model the complex preferences that people exhibit toward items based on their past interactions and behavior. To extend their expressive power, various works have made use of features such as tempo-ral dynamics [14], social influence [17], or the content of the items themselves [9]. Yet modeling and recommendation still remains challenging in settings where these forces interact in subtle and se-mantically complex ways.

In this paper, we propose new models for the social art web-site Behance , 1 an online art community with millions of users and artistic images. We seek to model both implicit preferences, such as users navigating between items, as well as explicit preferences, such as users liking or  X  X ppreciating X  each other X  X  content. On Be-hance users are both content creators and content evaluators, mean-ing that there is a need to model who appreciates what, as well as who appreciates whom.

There are several aspects that make modeling this data interest-ing and challenging. First is the need to model content , in particular the visual appearance of items, which are both high-dimensional and semantically complex. Second is the need to model temporal and social dynamics, in terms of users X  tendency to interact with consistent content within and across sessions, and their preferences towards individual artists as well as art styles. And third is simply the scale and sparsity of the data involved; with data on the order of millions of users and items, and tens of millions of interactions we must expend considerable effort developing methods that scale; this issue is exacerbated when modeling visual content, due to the high-dimensional representations of the items involved.

Methodologically, our work primarily builds upon two meth-ods, FPMC ( X  X actorized personalized markov chains, X  [21]) and VBPR ( X  X isual bayesian personalized ranking, X  [10]). FPMC mod-els the notion of  X  X moothness X  between subsequent interactions us-ing a Markov chain, an idea that we adapt to capture the fact that users tend to browse art with consistent latent attributes during the course of a browsing session. VBPR is a recently-proposed content-aware recommender system, that models the visual appear-ance of the items being considered (primarily to recommend cloth-ing). By combining the two models, we can capture individual users X  preferences towards particular visual art styles, as well as the tendency to interact with items that are  X  X isually consistent X  during a browsing session. We also make several extensions of these mod-els, e.g. to handle longer memory than simply the previous action.
Another aspect that differentiates our model and data from tradi-tional recommendation scenarios is the need to model the content creator in addition to the content itself. Unlike most recommender systems, which model interactions between users and items, in Be-hance the items are created by the same population of users who evaluate them. Thus we need to model the social dynamics that guide users X  preferences toward particular artists. For example, a user might follow the creations of particular artists, even when their art differs from the style they normally exhibit preferences toward. Note that this particular type of social dynamics (amongst creators and evaluators) is different from traditional friendship/trust rela-tions (amongst evaluators themselves).

We perform experiments on both implicit (click) and explicit (appreciate) data, where we show that substantial performance im-provements can be gained by modeling temporal, social, and visual features in concert. Improvements are especially large for newly-uploaded art, where modeling content X  X r even the identity of the artist X  X ields improvements of up to 30% in terms of AUC.

Our model, VIsually, Socially, and Temporally-aware Artistic recommendation, or Vista for short, is the first to be simultane-ously visually, socially, and temporally aware, which proves key to modeling the dynamics of online art communities.
 Contributions We summarize our main contributions as follows: Note in particular that our proposed method can be easily adapted to cope with sequential prediction in other domains by replacing the visual features with other types of item content. Visually-aware recommender systems. In recent years, there have been some works that investigate parsing or retrieving visually sim-ilar clothing images (e.g. [11, 26, 27]), although they do not fo-cus on learning user preferences. Recent works have introduced visually-aware recommender systems where the visual rating di-mensions of users are uncovered on top of the visual signals in the system X  X roduct images. Such visual dimensions have been demonstrated to be successful at link prediction tasks useful for rec-ommending alternative (e.g. two similar t-shirts) and complemen-tary (e.g. a t-shirt and a matching pair of pants) items. This thread of work has also extended standard Matrix Factorization with vi-sual dimensions to facilitate item recommendation tasks [8, 10]. A following work [9] further considers the long-term temporal dy-namics associated with the visual preference of the communities, i.e., fashion evolution. However, none of above works focuses on predicting session-level user actions, a key recommendation task that requires the ability to model sequential data.
 Modeling Temporal Dynamics. Apart from the visual domain, in the machine learning community there have also been earlier ef-forts that investigate temporally-evolving data with algorithms such as SVMs [12], decision trees [25], instance-based learning [1], etc. Similar to ours are Collaborative Filtering models that take into ac-count temporal dynamics. In particular, early works are based on similarity-oriented Collaborative Filtering, where a time weighting scheme can be used to assign previously-rated items with decaying weights when computing similarities (e.g. [5]). In contrast, recent works are mostly based on the well-known Matrix Factorization Notation Explanation
U , I user set, item set u,i a specific user or item (resp.)
S u t the item user u interacted with at time step t o i owner/creator of item i , o i  X  X  O i owners/creators of item i , O i  X  X 
 X  latent space measuring user-item affinity  X  u latent preference vector of user u ,  X  u  X   X   X  i latent property vector of item i ,  X  i  X   X 
 X  latent space measuring user-user similarity  X  u latent vector of user u ,  X  u  X   X 
 X  latent space measuring item-item similarity  X  i latent vector of item i ,  X  i  X   X  f i explicit feature vector of item i (e.g. visual fea-technique [13]. For instance, Koren [14] showed state-of-the-art results on Netflix data using Matrix Factorization to model the un-derlying temporal dynamics. However, these works do not consider handling the complex semantics of visual and social signals. Sequential recommendation. Markov chains are a powerful tool to model stochastic transitions between different  X  X tates. X  In se-quential recommendation domains, Markov chains have been stud-ied by several earlier works, from investigating their strength at uncovering sequential patterns (e.g. [18, 29]), to directly model-ing decision processes with Markov transitions [22]. In a more re-cent paper [21], Rendle et al. proposed to combine the strength of Markov chains at modeling the smoothness of subsequent actions and the power of Matrix Factorization at modeling personal prefer-ences for sequential recommendation. The resulting model, called FPMC, has shown superior prediction accuracy by benefiting from both simultaneously. Our work extends the basic idea mainly by modeling complex visual and social dynamics and further consid-ering Markov chains with higher orders.

Notably, there is another line of work that employs (personal-ized) probabilistic Markov embeddings to model sequential data like playlists and POIs (e.g. [3, 4, 6]). These works differ from ours in terms of both the signals being modeled and the types of models. Moreover, none of them has shown to be able to handle datasets on the same scale with Behance to the best of our knowledge. Social recommendation. In the recommender systems literature, there has been a large body of work that models social networks for mitigating cold-start issues in recommender systems, e.g. [2, 7, 16, 17, 28]. The type of social signals they usually benefit from are so-called  X  X rust X  relations amongst different users, which are different from the those we are interested in. In contrast, we focus on modeling the ownership signal, i.e., the interactions between a viewer and the creator of an item, which brings a unique set of challenges.
Formally, let U = { u 1 ,u 2 ,...,u |U| } represent the set of users and I = { i 1 ,i 2 ,...,i |I| } the set of items (i.e., artistic images). Each item i  X  I is created by a certain user o i  X  U (or in some cases multiple users O i  X  X  ). For each user u , a sequential action history (e.g. items clicked/appreciated by u ) S u is known: ( S 1 , S u 2 ,..., S u |S u | ) where S u k  X  X  . The action history of all users is denoted by S = {S u 1 , S u 2 ,..., S u |U| } . Additionally, each item i is associated with an explicit feature vector f i , e.g. in our case visual features extracted from images. Given the above data, our task is to recommend items to each user based on their predicted next action.

Notation to be used throughout the paper is summarized in Table 1. Next, we will build our model incrementally which we detail in each of the following subsections.
In this paper, we are interested in modeling binary actions such as clicks, appreciates, etc. Given the previous action sequence of user u , the probability that user u will interact with item next action is P ( X u t = i | S u t  X  1 , S u t  X  2 ,..., S variable X u t is the choice u made at time step t and |S This probability can be approximated by P ( X u t = i |S u is then modeled by factorizing a personalized Markov chain (as in [21]). This follows the intuition that a user X  X  recent actions should be more predictive of their future actions than earlier ones.
Intuitively, the transition of user u from item S u t  X  1 t  X  1 ) to item i (at time step t ) can be explained from two aspects: (1) the interaction between user u and item i , which captures the long-term preferences of user u ; and (2) the interaction between the previous item S u t  X  1 and item i , which captures the short-term or temporary interest of user u . Following this intuition, we pro-pose to factorize the personalized Markov chain with the following formulation: where we use three latent spaces to capture the interactions between users and items, users and users, items and items respectively: (1) Space  X  : D 1 -dimensional vectors  X  u and  X  i are employed to cap-ture user u  X  X  latent preferences and item i  X  X  latent properties re-spectively; (2) Space  X  : Each user u is associated with a dimensional vector  X  u for measuring affinity/similarity with other users (within  X  ); and (3) Space  X  : Each item i is associated with a
D 3 -dimensional vector  X  i for measuring affinity/similarity with other items (within  X  ). Inner products of vectors from  X   X  measure the corresponding user-item, user-user, and item-item affinity/similarity respectively.

In Eq. 1, the interaction between u and i consists of two parts: how much user u appreciates  X  X r is  X  X imilar X  to X  X he creator/owner o of i (term one), and how much u likes the specific item created by o i (term two). Likewise, the similarity of i and S u t  X  1 two components as well: the similarity between their creators (term three) and the two items themselves (term four). w u is a parameter to capture the statistical short-term consistency of the actions of the specific user u . Intuitively, a bigger value of w u will favor short-term interests, which means u tends to interact with items similar to those they just interacted with, instead of those that most fit their long-term preferences.

Modeling ownership data and user interactions can help address both cold user and cold item issues in real-world recommender sys-tems: 1. For a cold (or  X  X ool X ) user u who has very few actions in the 2. For a cold item i with very few interactions in the system, Handling Multiple Creators. In certain cases an item i may be collaboratively created by multiple users in the system O In such scenarios we take the average of their associated vectors as the corresponding vectors (i.e.,  X  o that this will not affect the training efficiency as an owner sampling scheme can be used, which we will detail later.
The formulation in Eq. 1 only models a personalized Markov chain of order 1, with the assumption that a user X  X  next action (at is independent of any historical actions if given the most recent one (at t  X  1 ). However, this suffers from noise and can X  X  capture longer-term consistency (e.g. earlier clicks in a session). This inspires us to address this limitation by modeling Markov chains with higher order.

Due to the large scale and sparsity of real-world data, a light-weight yet expressive model is required. To this end, we model high order personalized Markov chains by extending our first-order formulation with a personalized decaying scheme, as shown below. The first part still measures the affinity between a user next item i with long-term memory; while the second part com-putes the weighted sum of the similarities of item i to each of the previous items:
There are two main intuitions behind the proposed formulation: (1) recent actions should be more correlated with future actions, which is why we employ a decaying term; and (2) different users may differ in behavior so that personalization should be taken into account. We model the personalized decay scheme as follows: Note that the above formulation only introduces two additional pa-rameters (i.e., a u and b u ) for each user u , which allows us to model users X  differing behavior in a light-weight manner.
Up to now, our formulation only makes use of the collaborative data, without being aware of the underlying content of the items themselves. 2 Such a formulation may suffer from cold item issues where there aren X  X  enough historical observations to learn accurate example. User features can be handled in a similar manner. representations of each item. Modeling the content of the items can provide auxiliary signals in cold-start settings and alleviate such issues.

Intuitively, content-based features of items should be informative of the two latent vectors:  X  i and  X  i . Given the explicit feature vector f i of item i , embedding techniques have been successful at incorporating (high dimensional) content-based features into the Collaborative Filtering framework (e.g. [9, 10]). In particular, we augment the vector representations of items (i.e.,  X  i ,  X  Here E  X  and E  X  are two embedding matrices that project item into space  X  and  X  respectively. The new formulation for each vec-tor in the corresponding space (  X  i ) now consists of two parts: the base part from the item content ( E  X  f i ), and the residue ( warm-start items, the residue part is expressive and can represent the item accurately; for cold-start items, the residue part will be reg-ularized (towards 0) and the base part will still be able to provide reasonably good approximations of the true representations. By substituting the augmented vector representations Eq. 4 and Eq. 5 into Eq. 2, the new formulation will be able to benefit from the content-based features to alleviate cold item issues.

Note that the two matrices are shared by all items which means that only a modest number of parameters are added to the model.
Predicting next actions can be viewed as a ranking task where the ground-truth item should be ranked as high as possible among all items. This inspires us to optimize an efficient ranking loss such
Let &gt; u,t denote the total order over the items of user step t , then i &gt; u,t j means item i is ranked higher than item user u at t given the action sequence before t . S-BPR optimizes maximum a posteriori (MAP) of all the model parameters (denoted by
 X  ) assuming independence of users and time steps: where for each user u and for each time step t , the objective goes through the pairwise ranking between the ground-truth S u negative items. The pairwise ranking between a positive ( negative ( j ) item P ( i &gt; u,t j |  X ) is estimated by a sigmoid function  X  ( b p u,t,i  X  b p u,t,j ) where the difference of the predicted likelihoods are taken as the inputs ( i.e., Eq. 2). P ( X ) is a Gaussian prior over the model parameters. Note that for Markov chains of order K , our formulation (i.e., Eq. 2) can allow t to run from 2 (instead of K + 1 ) to the last item in
Stochastic Gradient Descent (SGD) is widely employed for learn-ing in BPR-like optimization frameworks (e.g., [20, 21]). Accord-ing to SGD, our basic training procedure is as follows. First, a user u  X  U as well as a time step t  X  { 2 , 3 ,..., |S u |} formly sampled from the training corpus. Next, a negative item j  X  I ( j 6 = S u t ) is uniformly sampled, which forms a training 3 S-BPR was originally proposed to optimize sequential set data. However, the same idea can also be applied to single-item cases. triple ( u,t,j ) . Finally, the optimization procedure updates param-eters as follows: where ing rate and  X   X  is a regularization hyperparameter. Note that it is cheap to evaluate the gradient due to the additive characteristic of the proposed method (see Appendix for complexity analysis). The above procedure is suitable for training on large datasets. However, it is limited when training with the augmented version of our model (with content-based features) as updating the embed-ding matrices can be time-consuming. To speed up the training procedure, we make the following two observations and employ two modifications accordingly.
 Sampling. Matrices E  X  and E  X  are global parameters and only account for a tiny fraction of  X  (e.g. 0 . 29% for Behance ). This means that less training data is needed to accurately estimate and E  X  . In other words, they are updated more often than needed under the above scheme. As such, we lower their updating fre-quency by flipping a biased coin for each training triple to decide whether or not to update E  X  and E  X  . Likewise, we can also sam-ple a single owner and only update their associated parameters in multiple-owner cases due to the rich user interactions available. Asynchronous SGD. Notably, only a tiny fraction of parameters will be updated for each training triple ( u,t,j ) , i.e., representations of u and a few relevant items, and they are unlikely to overlap. 4 It has been pointed out that in such cases lock-free parallelization of SGD could be employed to achieve fast convergence [19].

Experimentally, this na X ve sampling and asynchronous SGD pro-cedure can help finish training on huge datasets within reasonable time on commodity machines without losing prediction accuracy.
We perform comprehensive experiments on Behance to evaluate the proposed method. We begin by introducing the dataset we work with, and then we compare against a variety of baselines. Finally, we visualize the learned model and qualitatively analyze the results.
Behance is a popular online community where millions of pro-fessional photographers, designers and artists share their work, or-ganized as projects, with others. The contents of these projects vary significantly, ranging from photographs to animation, fashion, in-terior design, paintings, sculpting, calligraphy, cartoons, culinary arts, etc. Each project is created by a user or a few users and con-sists of a collection of images (as well as videos in certain cases). The creator/owner of the project selects the most representative im-age which the website presents to all users as the cover image. On the website, users browse through large numbers of cover images, click through attractive projects, and  X  X ppreciate X  those they like.
From Behance we collected two large corpora of timestamped user actions: (1) appreciates consisting of 373,771 users, 982,002 items (i.e., projects), and 11,807,103 appreciates (i.e., explicit feed-back), and (2) clicks comprising 381,376 users, 972,181 items, and 48,118,748 clicks (i.e., implicit feedback). 52.7% users have cre-ated their own projects, and 2.3% items are created by multiple users. In our experiments, appreciates and clicks are used as two separate datasets to evaluate the efficacy of all methods on explicit and implicit datasets respectively. the embedding matrices.
For each item, we extract a 4096-dimensional feature vector from its cover image with a pre-trained VGG neural network [23] as the content-based features f i . Such features have been shown to gener-ate state-of-the-art results on visually-aware item recommendation tasks [9, 10].

Complete appreciate data and code are available on the first au-
We construct a validation set and a test set by selecting the most recent two actions of each user, one for validation and the other for testing. The remainder are used for training. All comparison meth-ods were trained on the training set with hyperparameters tuned with the validation set. Finally, the trained models are used to re-port corresponding performance on the test set.

Recall that the task is to predict which item a user will interact with given the previous action history, which means that the model in question needs to rank the ground-truth item higher than other items. Therefore for the held-out action, a reasonable evaluation would be calculating how highly the ground-truth item has been ranked for each user.

To this end, we evaluate all methods on the test set with the widely used AUC ( Area Under the ROC curve ) measure (e.g., [9, 10, 20]):
AUC = 1 |U| X where 1 (  X  ) is the indicator function, and g u is the ground-truth item of user u at the most recent time step |S u | .
We compare against a series of state-of-the-art methods, both in the field of item recommendation and sequential data prediction. Popularity (POP): always recommends popular items in the sys-tem at each time step.
 Bayesian Personalized Ranking (BPR-MF) [20]: is a state-of-the-art method for personalized item recommendation. It takes standard Matrix Factorization [15] as the underlying predictor. Visual Bayesian Personalized ranking (VBPR) [10]: is an ex-tension of BPR-MF that models raw visual signals for item recom-mendation. It captures the visual but not the temporal dynamics of binary action sequences.
 Factorized Markov Chain (MC): factorizes the |I| X |I| transition matrix to capture the likelihood that a user transits from one item to another. We used a first order model as higher orders incur a state-space explosion (we have almost one million items) and degrade the performance, especially considering the data sparsity. Factorized Personalized Markov Chain (FPMC) [21]: is a state-of-the-art personalized Markov chain algorithm to model sequen-tial data. However, FPMC is unable to capture visual and social dynamics and only models first-order Markov chains.
 VIsually, Socially, and Temporally-aware Artistic recommen-dation ( Vista ): is the method proposed by this paper in Eq. 2. Markov chains of different orders will be experimented with and compared against other methods.
 Vista +: augments Vista with the 4096-dimensional visual features extracted from cover images.

For clarity, the above methods are collated in Table 2 in terms of whether they are  X  X ersonalized, X   X  X emporally-aware, X   X  X ocially-Model Personal-ized? Temporally-aware? Socially-aware? POP 8888 BPR-MF 4888 VBPR 4884 MC 8488 FPMC 4488 Vista 4448
Vista + 4444 aware, X  and  X  X isually-aware. X  The ultimate goal is to evaluate (1) the performance of state-of-the-art item recommendation methods on our task (i.e., BPR-MF); (2) the gains from using raw visual signals especially for cold-start settings (i.e., VBPR); (3) the im-portance of modeling temporal dynamics (i.e., MC); (4) the effect of modeling personalized temporal dynamics (i.e., FPMC); and (5) the importance of modeling social dynamics (i.e., Vista ) and fur-ther performance enhancements from incorporating content-based features (i.e., Vista +).

We performed all experiments on a single machine with 8 cores and 64GB main memory. Our own most time-consuming method X  Vista + with a third-order Markov chain X  X equired around 50 hours of training time.
As analyzed in Section 3.2, the proposed model should be help-ful for cold-start settings including both cold user and cold item scenarios. Therefore, we compare all methods in terms of over-all accuracy (denoted by  X  X ull X ) as well as the two cold settings. Overall accuracy is evaluated with the full test set as introduced in Section 4.2.  X  Cold User  X  is evaluated by a subset of the full test set, consisting of only those cold users with at most 5 actions in the training set; likewise,  X  Cold Item  X  uses the subset comprising only cold items with at most 5 interactions.

In addition, we also decompose the full test set into subsets ac-cording to whether the previous item (at t  X  1 ) of the action being tested (at t ) is created by a different owner (i.e., owner transition), transition). This gives us four settings:  X  X wner Trans. X  vs.  X  X ame Owner, X  and  X  X ession Trans. X  vs.  X  X ame Session X  to thoroughly eval-uate the ability of all models under various transitioning circum-stances.
 For all methods, we try to use the same number of dimensions: BPR-MF and MC use 20 latent dimensions; VBPR uses 10 la-tent plus 10 visual dimensions; FPMC uses two 10-d vectors to represent each item and one 10-d vector to represent each user; Vista and Vista + use 10 dimensions for  X  u ,  X  u ,  X  i , and D 1 = D 2 = D 3 = 10 ). Using additional dimensions yielded only marginal performance improvement for all methods.

AUC results on the two datasets are shown in Tables 3 and 4. We make a few comparisons and analyze our findings as follows: BPR-MF vs. MC vs. FPMC. Ultimately, BPR-MF and MC fo-cus on modeling long-term and short-term dynamics respectively. BPR-MF ranks items according to what the given user likes from a long-term perspective, which makes it relatively strong when a user X  X  action differs significantly from the previous one ( X  X wner temporally partitioning each user X  X  clicks/appreciates with gaps larger than 1hr. Setting (a) (b) (c) (d) (e) (f-1) (f-2) (f-3) (g-1) (g-2) (g-3) improvement Setting (a) (b) (c) (d) (e) (f-1) (f-2) (f-3) (g-1) (g-2) (g-3) improvement Trans. X  and  X  X ession Trans. X ). In contrast, MC ranks items based on the transition matrix, i.e.,  X  X imilarity X  of the next item to the pre-vious item. Such short-term awareness makes MC strong in cases where action consistency is maximally demonstrated, i.e.,  X  X ame Owner X  and  X  X ame Session. X  Additionally, note that MC seems to suffer less from cold-start issues due to the consistency of sequen-tial actions. FPMC is inherently a combination of BPR-MF and MC, which makes it the strongest among the three, though it is not necessarily the best in all settings.
 BPR-MF vs. VBPR. Like BPR-MF, VBPR focuses on long-term dynamics, but benefits from making use of additional visual signals in the system. As expected, it alleviates cold item issues and is slightly better than BPR-MF in most other settings as well. Vista vs. FPMC. Vista is able to capture social dynamics by mod-eling ownership signals as well as gains from a fully personalized Markov chains with higher orders. As such, it beats FPMC in all settings significantly especially in cold-start scenarios. Note that Vista improves as much as 47.66% on average for cold item recom-mendation, which is a major concern when predicting sequential actions (see Section 3.2 for detailed cold-start analysis of Vista ). Vista + vs. Vista . Further augmenting Vista with content-based fea-tures, in this case visual signals, is beneficial as cold item issues are further mitigated. However, the improvement is comparatively small as such issues have already been alleviated to a large extent by modeling social dynamics (i.e., Vista ).
 Orders of Markov chains. As we increase the order of the Markov chain (from 1 to 3), the performance generally gets better as the next click is related to multiple previous clicks. Using a small order seems to be good enough, presumably since the few most recent actions capture enough information to predict future actions. Sparse vs. Dense data. Comparing the results of next-appreciate (sparse) and next-click (dense) prediction we can find that Vista outperforms other methods more significantly for sparse datasets where social and visual dynamics are forced to carry more weight. Figure 1: Performance comparison of different methods with num-ber of training epochs on Behance data. All methods are from Sec-tion 4.4. Vista and Vista + use second-order Markov chains.
Next, we demonstrate the accuracy on the full test set (i.e.,  X  X ull X  setting) of all comparison methods as the number of training epochs verge in a few epochs due to the rich interactions being modeled. Since appreciate data is inherently sparser than click data, we can find that modeling signals like social dynamics and visual data can help more significantly for appreciate prediction (as shown by the gap between (1) Vista / Vista + vs. others, and (2) VBPR vs. other baselines). In our experiments, we used a sampling probability of 5% for Vista + to update the two embedding matrices. Bene-fiting from multithreading, each epoch of asynchronous SGD takes around 20 minutes to train our third-order Vista + on click data. See Appendix for more details about the time complexity of Vista +. convergence or observance of overfitting (on the validation set). Each epoch consists of processing training samples with the size of the whole training corpus.
We proceed by visualizing the latent space  X  , which is used to measure the similarity between different items. To this end, we take the Vista + trained on Behance click data (see Section 4.4) and further use t-SNE [24] to embed the 10-d space into 2-d. Figure 2 this figure we can see that items with similar contents and styles tend to be neighbors in the latent space, e.g. culinary arts on the lower-left patch, and sports on the lower-right. Notably, items on the same patch may visually deviate from each other significantly.
On the grid view, we also demonstrate a few click sessions of a randomly selected user. The click sequence of each session is rep-resented by a directed path with a unique color (red/yellow/green). We make a few observations as follows. (1) Clicks tend to occur around a specific region in the space, near the green and red arrows. This reflects the long-term preferences of the user as people ulti-mately tend to explore items that they like. (2) Each click sequence demonstrates consistency to a certain degree (e.g. red and yellow) and encodes the transition of short-term interests (e.g. green). (3) Finally, the choice made at each click is a combination of long-and short-term preferences, due to which there are both long jumps and short jumps. Therefore, it is essential to capture both long-and short-term dynamics simultaneously in order to be successful at addressing our prediction task.
Users differ in habitual patterns especially in a dataset as large as ours. For example, for some users their short-term dynamics are more important. This means they tend to click/appreciate items similar to those they just interacted with. In contrast, there are also users whose long-term preferences are more emphasized, demon-strating less short-term consistency during a session. This charac-teristic is captured by the personalized weighting factor (and w k u in Eq. 2).

In Figure 3, we show a few sample sessions of the above two types of users, with different session lengths. Sampled sessions of users with the largest w u (i.e., arg max the horizontal dashed line, with each row demonstrating the list of items clicked during the corresponding session. We can see some consistency from these sessions: logo designs, a certain style of car-toon characters, interior designs, and fashion models respectively. On the right of each arrow is the corresponding recommendation with the highest score predicted by the Vista + model.

In contrast, below the dashed line we also demonstrate a few sessions from users with the least w u , i.e., for whom long-term dy-namics are more important. As expected, contents in each session demonstrate comparatively larger variance, though the long-term preference towards object designs, logos, cartoons, and characters (respectively) are captured by the Vista + model.
Modeling artistic preferences with complex visual, social, and sequential signals is challenging especially when it comes to the need to scale up to large real-world datasets. In this paper, we address these challenges by building visually and socially-aware Markov chains to model visual appearance and social dynamics si-multaneously. Empirically we evaluated our proposed method on two common sequential prediction tasks to test its ability to handle both explicit and implicit artistic preferences of users. Experimen-tal results demonstrated that our proposed methods significantly outperform a series of state-of-the-art baselines for both tasks on large scale datasets collected from a popular social art website, Be-hance .
