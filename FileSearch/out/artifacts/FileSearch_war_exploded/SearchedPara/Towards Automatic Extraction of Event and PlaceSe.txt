 We describe an approach for extracting semantics of tags, unstructured text-labels assigned to resources on the Web, based on each tag X  X  usage patterns. In particular, we fo-cus on the problem of extracting place and event seman-tics for tags that are assigned to photos on Flickr, a popu-lar photo sharing website that supports time and location (latitude/longitude) metadata. We analyze two methods inspired by well-known burst-analysis techniques and one novel method: Scale-structure Identification. We evaluate the methods on a subset of Flickr data, and show that our Scale-structure Identification method outperforms the exist-ing techniques. The approach and methods described in this work can be used in other domains such as geo-annotated web pages, where text terms can be extracted and associated with usage patterns.
 Categories and Subject Descriptors: H.1.m [MODELS AND PRINCIPLES]: Miscellaneous General Terms: Algorithms, Measurement Keywords: tagging systems, event identification, place iden-tification, tag semantics, word semantics
User-supplied  X  X ags X , textual labels assigned to content, have been a powerful and useful feature in many social media and Web applications (e.g. Flickr, del.icio.us, Technorati). Tags usually manifest in the form of a freely-chosen, short list of keyword associated by a user with a resource such as a photo, web page, or blog entry. Unlike category-or ontology-based systems, tags result in unstructured knowl-edge  X  they have no a-priori semantics. However, it is pre-cisely the unstructured nature of tags that enables their util-ity. For example, tags are probably easier to enter than picking categories from an ontology; tags allow for greater  X 
Also affiliated with UC Berkeley, Computer Science Dept.  X  Also affiliated with UC Berkeley School of Information. Copyright 2007 ACM 978-1-59593-597-7/07/0007 ... $ 5.00. flexibility and variation; and tags may naturally evolve to reflect emergent properties of the data.

The information challenge facing tagging systems is to extract structured knowledge from the unstructured set of tags. Despite the lack of ontology and semantics, patterns and trends emerge that could allow some structured infor-mation to be extracted from tag-based systems [11, 17, 23]. While complete semantic understanding of tags associated with individual resources is unlikely, the ability to assign some structure to tags and tag-based data will make tag-ging systems more useful.

Broadly, we are interested in the problem of identifying patterns in the distribution of tags over some domain; in this work we focus on spatial and temporal patterns. Specifi-cally, we are looking at tags on Flickr [10], a popular photo-sharing web site that supports user-contributed tags and geo-referenced (or, geotagged ) photos. Based on the tempo-ral and spatial distributions of each tag X  X  usage, we attempt to automatically determine whether a tag corresponds to a  X  X lace X  and/or  X  X vent X  (see Section 3 for definitions). For example, the tag Bay Bridge 1 should be identified as a place, and SIGIR2007 should be identified as an event. Tag usage distributions are derived from associated photos X  metadata. While the correctness of the time and location metadata for each individual photo is suspect [5], in large numbers, trends and patterns can be reliably extracted and used [9, 14].

Extraction of event and place semantics can assist many different applications in the photo retrieval domain and be-yond, including:  X  improved image search through inferred query semantics;  X  automated creation of place and event gazetteer data  X  generation of photo collection visualizations by location  X  support for tag suggestions for photos (or other resources)  X  automated association of missing location/time meta-In this work we do not apply our analysis to a specific appli-cation, but rather investigate the feasibility of automatically determining event/place semantics for Flickr tags. We use this format to represent tags in the text.
This paper represents, to our knowledge, the first attempt to extract place and event semantics for tags. Accordingly, we are exploring a number of possible methods. We in-troduce a new method tailored to event and place identifi-cation, Scale-structure Identification , and demonstrate how this method outperforms methods borrowed from other do-mains.

Furthermore, we note that our general approach to se-mantics extraction, and the methods we present as instan-tiations of this approach, can be applied to any information sources with temporal and spatial encodings from which we can extract textual terms  X  like GeoRSS blog data and geo-annotated web pages or Wikipedia articles. Additionally, the general approach of analyzing a distribution of occur-rences over a domain (in our case space and time) to infer semantics could be extended to other metadata domains like color (hue/saturation), visual features, audio features, and text/semantic features.

To summarize, the contributions of this paper are:  X  a generalizeable approach for extracting tag semantics  X  the modification, application, and analysis of existing  X  Scale-structure Identification  X  a new method for ex- X  a practical application of these methods to extract event
We formally define our problem in Section 3. Then we de-scribe the methods (Section 4) and report on our evaluation (Section 5). We begin by reviewing the related work.
We address related work from a number of relevant re-search areas, including: event detection in time-stamped data such as web queries and personal photo collections; location-based analysis of spatially distributed data such as GPS positions, demographics information, or even informa-tion on the web; and analysis of tagging systems.
Many scientific domains have studied the general problem of time-based event detection. Time Series analysis tech-niques such as ARIMA [4, 18] analyze trends in time series data with the goals of (1) explaining spikes and valleys over various time windows and (2) producing future trend fore-casts. In particular, our Na  X  X ve Scan methods (see Section 4) are similar to previous work on global event detection in web query logs [25] and access logs [13] where events are semantically defined as  X  X ursts X  (cf. [15]).

More germane to this paper is the problem of event iden-tification in personal photo collections [12, 20, 24]. A key characteristic of the personal photo collection domain is the general assumption of  X  X  single camera X , which reduces event identification to a problem of temporal segmentation. Events are considered to be a single segment of time over which a single activity was taking place, providing a coher-ent, unifying context. Prior work on this problem has ap-plied a number of techniques: some rely primarily on time [12], others use both locations and times [20, 21], and an-other looks at the text annotation associated with photos [24]. This type of event-identification is different than ours since (1) we consider multi-person collections of photos and (2) we are interested in whether tags describe events, not whether a segment of time refers to a specific event for a specific person.

Related to event identification is the extraction of mean-ingful information from location-based data. Recent efforts in ubiquitous computing systems identify meaningful loca-tions and places for GPS and other location tracking tech-nologies [1]. In epidemiology, efforts to identify and localize disease outbreaks [16] are closely related to the place iden-tification problem we address in this paper. Specifically, we borrow some techniques from the disease/outbreak analysis, where data is sparse and dependent on the underlying pop-ulation statistics, as these two properties are echoed in our data for each tag.

More semantically-rich location analysis problems have been studied in the domain of web-based information re-trieval. Specifically, the field of  X  X eoIR X  has had two thrusts relevant to this paper. First, attempts were made (e.g. [2, 6, 8]) at extracting geographic information for a web page, based on the page links and network properties, as well as geographic terms that appear on the page. Our system de-scribed here could potentially help these systems by identi-fying additional geographic terms and defining their spatial scope. The second related research effort in GeoIR focused on extracting the scope of geographic terms or entities based on co-occurring text and derived latitude-longitude informa-tion [3, 22]. With geo-annotated photos and tags, as well as any system with direct location annotation, the potential exists not only to delineate known geographic terms, but also to identify new regions of interest based on the data.
Tagging systems in general have been of increasing re-search interest. Most of the prior research has looked at de-scribing tagging systems [17], or studying trends and prop-erties of various systems [11]. Some efforts have looked at extracting ontologies (or, structured knowledge) from tags [23]  X  a similar goal to ours, yet using co-occurrence and other text-based tools that could augment the methods an-alyzed in this paper.

More directly related to this paper are research efforts that analyzed Flickr tags (and other term associated with Flickr photos) together with photo location and time metadata [9, 14]. These projects applied ad-hoc approaches to determine  X  X mportant X  tags within a given region of time [9] or space [14] based on inter-tag frequencies. However, no determi-nation of the properties or semantics of specific tags was provided. Naaman et al. created spatial models for terms appearing in geo-referenced photograph labels [19], but did not detect the location properties of specific terms.
In this section, we provide a formal definition of our data and research problem. Our dataset includes two basic ele-ments: photos and tags. Each geotagged photo has, in ad-dition to other metadata, an associated location and time. The location, ` p , (consisting of latitude-longitude coordi-nates) associated with photo p generally marks where the photo was taken; but sometimes marks the location of the photographed object. The time, t p , associated with photo p generally marks the photo capture time; but occasionally refers to the time the photo was uploaded to Flickr. Both location and time are recorded at high resolution (micro-seconds of degrees for location, seconds for time). Tags are the second basic element type in our dataset. We use the variable x to denote a tag. Note that each photo can have multiple tags associated with it, and each tag is often associated with many photos. Based on the locations and times associated with photos, we can define the location and time usage distributions for each tag x : L x 4 = { ` associated with x } and T x 4 = { t p | p is associated with x } . Using this data we address the following problem: Example place tags are Delhi , Logan Airport and Notre Dame . Similarly, example event tags are Thanksgiving , World Cup , AIDS Walk 2006 , and New York Marathon (interestingly, New York Marathon represents both an event and a place). Examples of tags not expected to represent events or loca-tions are dog , party , food and blue .

The first step in determining whether a tag refers to an  X  X vent X  or  X  X lace X  is to define these terms. We aimed for definitions that address both general human perception and the generic (i.e. socially common) semantics of  X  X vent X  and  X  X lace X  [27]. We propose that: Event Tags are expected to exhibit significant temporal Place Tags are expected to exhibit significant spatial pat-
The term  X  X ignificant X  in these definitions is intention-ally vague  X  designed to capture the idea that  X  X vent X  and  X  X lace X  are socially defined (as illustrated by the examples above). More concretely, the definition refers to the fact that a person can expect New York Marathon to appear sig-nificantly more often every year around November and in New York City; whereas dog should appear at almost any time and in almost any location. We expect a reasonable human judge to be able to determine, for any tag and the set of photos associated with that tag, whether or not the tag represents an event and/or a place.

It is important to consider both event and place tags rela-tive to some pre-defined geographic region. For example, carnival may not exhibit any patterns world wide, but does have temporal patterns if we are only considering ma-jor cities in Brazil. Similarly, Palace may have distinct location-based patterns in certain regions (say, London) but no significant patterns world wide. For simplicity, we do not introduce notation to handle the specification of geographic regions  X  we generally assume that the set of photos consid-ered by the algorithm is such that for all photos p in the set, ` is contained in the given region.

Related to regions is the concept of  X  X cale X . The basic idea is that tags may exhibit significant temporal or spatial patterns at various scales. For example, museum refers to specific locations within the San Francisco Bay Area, while California is not expected to show significant patterns if our region is limited to San Francisco. Similarly, conferences lasting multiple days (e.g. SIGIR 2007) and even holidays with significant activity prior to a specific date (e.g. Christ-mas), do not appear to be events at the hour or single day scale, but do exhibit distinctive time patterns relative to longer time scales. Accordingly, the methods described be-low search for significant patterns at multiple spatial and temporal scales.
The goal of our analysis is to determine, for each tag in the dataset, whether the tag represents an event, and whether the tag represents a place. The intuition behind the various methods we present is that an event (or place) refers to a specific segment of time (or region in space). So, the  X  X ignifi-cant patterns X  for event and place tags should be manifested as bursts over small parts of time or space. More specifically, the number of usage occurrences for an event tag should be much higher in a small segment of time than the number of usage occurrences of that tag outside the segment. The scale of the segment is one factor that these methods must address; the other factor is calculating whether the num-ber of usage occurrences within the segment is significantly different from the number outside the segment.

To simplify the discussion, we describe the methods as they pertain to event identification. The notions of segments and scales are not domain specific  X  i.e. both time and space can be divided into segments (perhaps overlapping) of various scale. Any place/space specific issues are addressed, but otherwise the translation to place-based analysis is left to the reader.

In the remainder of this section, we describe the methods in detail. We first present adaptations of two well-known techniques to the problem at hand. Then we present a new method for event and place identification: Scale-structure Identification.
At a high level, the steps for the modified, burst-detection methods are the following: 1. Scale Specification  X  Choose an ordered set of scale 2. Segment Specification  X  For each scale r k define a fi-3. Partial Computation  X  For each scale r k and each 4. Significance Test  X  Aggregate the partial computation 5. Identify Significant Segments  X  Provided a signifi-
Before describing each method, we introduce some neces-sary notation. First, we use T r ( x, i ) to denote how many times tag x was used in time segment i (the subscript in-dicates that the segment is defined in relation to scale r ). The maximum value for T r ( x, i ) is the number of photos in the segment  X  we use N r ( i ) to denote the number of photos taken during time segment i . Some of the methods below also require the total number of tag usage occurrences in a segment  X  we denote this as T r ( i ) = P x T r ( x, i ).
The Na  X  X ve Scan methods are an application of a standard burst detection method used in signal processing [25]. The method computes the frequency of usage for each time seg-ment at each scale. The method identifies a  X  X urst X  when the frequency of data in a single time segment is larger than the average frequency of the data over all segments plus two times the standard deviation of segment frequencies.
The clear majority of tags in our data have sparse usage distributions which results in low average frequencies and low standard deviations. Consequently, the standard formu-lation of this method suffers from too many false positives. To combat this problem we compute the average and stan-dard deviation values from aggregate data  X  either from all of the photos or from all of the tags combined. We further relax the condition that the number of tag occurrences be larger than the mean plus two standard deviations  X  instead requiring that the ratio of these values be larger than some threshold, which we can vary for optimal performance.
For Na  X  X ve Scan I , the partial computation (Step 3) for each tag x is specified by: T r ( x,i )  X  of { N r ( i ) | i = 1 . . . } and  X  N is the standard deviation of { N r ( i ) | i = 1 . . . } . We use a variable threshold of this statis-tic in identifying events (Step 4).

To identify the segments of time corresponding to an event for a tag (Step 5 above), we simply record the segments that pass the significance test (Step 4 above). Specifically, we record the values of i and r where the partial computation statistic is larger than the threshold.

We omit the details of Steps 1 and 2 (how to search over i and r ) since any brute force search method applies. We also remind the reader that the formulation for location-based burst detection is analogous.
 An alternative approach, which we refer to as Na  X  X ve Scan II , compares the individual tag occurrences to the total num-ber of tag occurrences, instead of the number of photo oc-currences. The reasoning behind this modification is based on the assumption that if tag x captures the important as-pects of a photo, then that photo will require few tags in addition to x .
 The partial computation statistic is T r ( x,i )  X  the mean of { T r ( i ) | i = 1 . . . } and  X  T is the standard de-viation of { T r ( i ) | i = 1 . . . } . If every photo had the same number of tags, these results would be identical to those produced by Na  X  X ve Scan I. However, as photos can have an arbitrary number of tags, with some photos using far more tags than others, the Na  X  X ve Scan II method does produce (slightly) different results.
The Spatial Scan methods are a standard application of the Spatial Scan statistic [16], a burst detection method used in epidemiology. These methods assume an underly-ing probability model of observing some phenomenon over some domain. The methods then test whether the number of occurrences of a phenomenon in a segment of the domain (e.g. segment of time) is abnormal relative to the underlying probability model. This abnormality test is performed for each segment.

To illustrate how the Spatial Scan methods work, we de-scribe an example from our data. Consider eatbrains , which refers to a slightly obscure event that took place in San Francisco (where people dressed up as zombies and walked around certain neighborhoods). Suppose: (1) over the 2+ years covered by our data, q denotes the global probability of this tag being applied to any photo; (2) all M photos tagged with eatbrains occur within a single two hour seg-ment, and (3) there are a total of N photos taken during this same two hours. If eatbrains refers to an event of any significance, M should be quite a bit larger than qN . The Spatial Scan methods are designed to test whether the value M represents a significant deviation from the global proba-bility distribution (an important note is that q is not defined a-priori, it is derived from the data.) The expression for the partial computation statistic for Spatial Scan I is: where I (  X  ) is the indicator function. For details on the derivation of this expression see Kulldorff [16].
As in the Na  X  X ve Scan methods, the significance test (Step 4) uses a single, variable threshold value  X  tags whose par-tial computation statistic exceeds this value are identified as events. Also, by storing the values of i and r where the par-tial computation statistic is larger than the threshold we can identify the segments in time when events occur (Step 5). Finally, details of Steps 1 and 2, how to search over i and r , are likewise omitted since brute force search methods are sufficient.
 Similar to the Na  X  X ve Scan II modification, we developed Spatial Scan II using the total number of tags that occur in-side segments. We omit the partial computation expression for Spatial Scan II  X  it can be produced by simply replacing occurrences of N r ( i ), the number of photos in each segment, with T r ( i ), the number of tags in each segment, in the partial computation expression of Spatial Scan I (above).
In the four methods described above, we determine the segments of time for each scale independent from the actual usage distributions of the tags. Additionally, these meth-ods can only propose a-priori time segments as the times of events. In the worst case, these segments might hide the ac-tual time of an event by splitting the usage occurrences into adjacent segments, none of which are above the significance test threshold. The next method we describe addresses the issue of a-priori defined time segments.
The Scale-structure Identification method performs a sig-nificance test (Step 4 above) that depends on multiple scales simultaneously and does not rely on a-priori defined time segments. Accordingly, the Scale-structure Identification method performs all the steps listed above except the Seg-ment Specification step (Step 2).

The key intuition behind Scale-structure Identification is the following: if tag x is an event then the points in T x time usage distribution, should appear as a single cluster at many scales. The clustering mechanism used in Scale-structure Identification is similar to the clustering mecha-nism in the scale-space method developed by Witkin [26]. However, whereas Witkin was interested in any structure that exhibited robustness over a range of scales, we are in-terested in the robustness of a single type of structure  X  a single cluster.

Consider the graph over T x where edges between points exist if and only if the points are closer together than r (recall that r is the scale variable). Let Y r be the set of connected subcomponents of this graph. The Partial Com-putation step (Step 3 above) computes the entropy of Y r for each scale r . Specifically, the partial computation statistic is defined as: E r 4 = P Y  X  X  the entropy value as a measurement of how similar the data is to a single cluster since entropy increases as data becomes more distributed. We are interested in low entropy struc-tures, Y r (note that E r = 0 when the usage distribution is a single cluster, i.e. |Y r | = 1).

For place identification we simply replace T x with L x in the calculation of E r (we compute the distance between points in L x as the L 2 distance between the points as they lie on a sphere).

A caveat to the partial computation statistic concerns pe-riodic events. Periodic events have strong clusters, at multi-ple scales, that are evenly spaced apart in time. Practically, because tags occur in bursts, we also require that a periodic tag exhibit at least three strong clusters (to rule out tags that just happened to occur in two strong temporal clus-ters but are not truly periodic). Of course, this assumption could result in some false negatives (e.g. recurring events that only appear twice in our dataset), but it is necessary due to the sparse nature of our data (to mitigate these false negatives we could check whether the two strong clusters were spaced apart at some culturally meaningful distance like one month, one year, etc.).

We check for periodic events by: (1) identifying  X  X trong X  clusters (i.e. clusters that contain at least 2% of the data), (2) measuring how far apart the strong clusters are, (3) making sure the cluster variances are not too big relative to the distances between clusters (i.e. the standard devia-tions of the usage distributions for each cluster should be, on average, smaller than 10% of the average inter-cluster distance), and (4) making sure the distances between clus-ters are  X  X ven X  (i.e. the standard deviation of inter-cluster distances is smaller than 10% of the average inter-cluster distance). If a tag X  X  temporal distribution passes all of these tests 2 , we re-compute the scale structure for this tag by treating time as modulo  X  , the average inter-cluster dis-tance. Specifically, we re-compute Y r from T 0 x 4 = { t modulo  X  | t  X  T } using the distance metric k t 1  X  t 2 k 4 = min( | t 1  X  t t  X  t 2 | , |  X  + t 2  X  t 1 | ). Intuitively, this modulo adjustment to the time dimension aligns the  X  X trong X  clusters so that they will be treated as a single cluster. For example, if a tag X  X  temporal distribution has 3 strong clusters that are on average 365 days apart, the modulo adjustment to time corresponds to the cyclical calendar year.

Finally, the significance test calculation (Step 4) aggre-gates the partial computation statistics simply by summing them over the set of scales: P K k =1 E r k . This summed value is tested against a threshold to determine if the tag is an event. By recording the scale structures at each scale, we can determine which time segments strongly characterize an event tag (Step 5). In fact, we can then characterize the tag, or rather the event it refers to, at multiple scales.
The percentage thresholds used in these tests were set em-pirically.
We implemented the methods described above, and per-formed a direct evaluation of the methods X  performances over part of the Flickr dataset. The goals of the evaluation were to establish whether any of the methods can reliably identify events/places in the tag data; compare the perfor-mance of the different methods; and evaluate the perfor-mance with varying parameters. Finally, we seek to under-stand the type of errors made by the different methods.
We begin by describing the Flickr data used in our eval-uation. We then provide details on how we generated the ground truth for the tags in the dataset, and the results of the evaluation.
The data we use in this study consists of geotagged pho-tos from Flickr and the associated tags. Location and time metadata is available for roughly fourteen million public Flickr photos (at the time this paper was written). The capture time is usually available from data embedded in the photo file by most digital cameras. While the photo location could also be provided by the camera, it is more likely to be entered by the user using maps on the Flickr web site, or possibly obtained from an external GPS device via synchro-nization software. In this paper we focus our evaluation on photos from the San Francisco Bay area. We plot the loca-tion for every geotagged photo in our dataset in Figure 1. In Figure 2, we plot the location and time usage distributions for the tag Hardly Strictly Bluegrass .

The San Francisco Bay area is currently one of the best-represented geographic regions in Flickr, increasing the like-lihood of finding significant patterns at sub-city and sub-region scales. Furthermore, San Francisco is the only such region for which we could reliably generate the ground truth (see below). We note, however, that restricting the dataset to a specific geographic region did not require any alterations to the methods or the evaluation computations.

In addition to the regional specification, we applied filters to improve the time/location metadata correctness and to ensure sufficient data for the analysis. The two filters to Figure 1: Spatial distribution of all San Francisco geotagged photos in our dataset (white markers).
 Figure 2: Location (top) and time (bottom) usage distributions for the tag Hardly Strictly Bluegrass in the San Francisco Bay Area. The zoomed in map view shows the details of the larger location cluster from the zoomed out view. improve correctness were: (1) if the photo X  X  capture time was (a) prior than 2004 or (b) not later than the upload time, the photo was removed; and (2) if the photo X  X  location resolution was too inaccurate (i.e. anything other than the two most accurate levels in the scale from 1 X 16), the photo was removed. The filter to ensure sufficient data applied to tags. Any tag that was used less than 25 times or by only one user was removed.

Our final dataset consists of 49897 photos with an average of 3.74 tags per photo (s.d. 2.62). These photos cover a total temporal range of 1015 days, starting from January 1, 2004. The average number of photos per day was 49.16 (s.d. 89.89), with a minimum of zero and a maximum of 643.
From these photos we extracted 803 unique tags. As ex-pected, and similar to previous work [9, 11], tag usage was Zipf-distributed. The maximum number of photos associ-ated with a single tag was 34325 (for San Francisco ), and the mean was 232.26 (s.d. 1305.40).

The Flickr dataset is rather new, and presents a num-ber of additional challenges. While Flickr popularity is ris-ing, the number of geo-referenced photos is still relatively low. We see sparse activity within every group of photos  X  for example, Flickr does not contain photos tagged Golden Gate Bridge for every day since January 1, 2004. Another complicating factor is the fact that the data is often un-even: more photos are likely to be uploaded with the tag Golden Gate Bridge than Bay Bridge , for example. In the time dimension, because of the growing active community on Flickr, an order of magnitude more photos were taken and uploaded during 2006 than during 2005, complicating time-based analyses.
To generate the ground truth for our evaluation we man-ually annotated each of the 803 tags. Specifically, we looked at a sample of pictures associated with each tag in our dataset, including their locations and times of capture, to determine whether the tag corresponds to an event, and whether the tag corresponds to a place. This in-depth anal-ysis was needed to eliminate errors that arise from obscure tags (e.g., eatbrains that described a relatively unknown San Francisco event), and by issues of polysemy and homo-nymy (e.g., Apple in San Francisco was mostly assigned to photos of the Apple Computer store). Examining the con-tent of the photographs was often required  X  from the photo and caption content we were often able to generalize, cor-rect, and interpolate inaccurate or sparse data.

To measure the discrepancy between common sense inter-pretations of the tags in our dataset and the ground truth, we also collected a set of labels for the tags generated by hav-ing four people vote, without access to the photos or their metadata, on whether the tag referred to an event, a place or both. This vote-based data exhibited systematic errors relative to the ground truth data: (1) obscure or un-popular events and places were often false negatives (i.e. incorrectly labeled as not being events or places), (2) generic tags like anniversary and park were often false positives (while they have clear event and place semantics within a limited scope, over the whole data set they did not refer to specific time segments or regions of space), and (3) event tags like Future of Web Apps were often not labeled as places even though many events also occur in specific regions of space. For these reasons, we omit comparison of the place and event identi-fication methods to the vote-based data.
Since all of the methods produce ranked results, we can use standard IR metrics to evaluate performance. For each tag, the methods produces a number that indicates how likely this tag is to be an event (or place). Rather than choosing a single threshold for each method to categorize the tags, we can vary the threshold dynamically and ex-amine the tradeoff in terms of recall and precision for each method.

Plots of the recall vs. precision curves are shown in fig-ure 3 for places (top) and events (bottom). The X-axis represents a recall value  X  the percentage of actual events (or places) that are identified as events (or places). The thresholds for each method were adjusted to produce this recall value. The Y-axis shows the precision  X  the percent-age of tags identified as events (or places) that are actually events (or places). For example, when the threshold for Scale-structure Identification for events is set so that recall is 50%, the precision is 82%. We can see in both figures Table 1: Precision-Recall Area, Maximum F1, and Minimum CE values for the various methods.
 Figure 3: Precision vs. recall for the place (top) and event (bottom) identification tasks. that Scale-structure Identification performs better than the traditional methods, for almost all recall values and for both event and place identification.

From these curves we computed (1) the area under the precision-recall curve (P-R area), (2) the maximum value of the F1 statistic for each method (MAX F1), a metric that balances precision and recall values, and (3) the minimum total classification error (Min CE) (cf. [7]). The results are shown in Table 1, again indicating that Scale-structure Identification performs better than the other methods.
As an alternative to searching for optimal threshold val-ues for the methods, one can simply take the top N results from the ordered lists produced by the methods (where N is variable). Table 2 shows precision and recall values for N = 50 , 100 , and 200. Table 3 lists the top 10 tags for each method for both place and event detection. Again, Scale-structure Identification performs better than the other methods.

We also studied the sensitivity of the Scale-structure Iden-tification method to the Scale Specification step (Step 1 in Section 4.1). We varied the exponential base in the scale sampling scheme from 1 . 1 to 5 . 0 (the exponents were pos-itive integers, marking the sequential position of the scale value). The results were robust to these changes. One point to note, however, is that performance slightly, but consis-tently, improved as the exponential base decreased. In other words, the Scale-structure Identification method performed Spatial Scan I 0.82, 0.17 0.68, 0.28 0.60, 0.49 Spatial Scan II 0.80, 0.16 0.69, 0.28 0.61, 0.50 Scale-structure 0.88, 0.18 0.83, 0.34 0.70, 0.58 Spatial Scan I 0.50, 0.28 0.40, 0.45 0.33, 0.74 Spatial Scan II 0.52, 0.29 0.41, 0.46 0.33, 0.74 Scale-structure 0.78, 0.44 0.53, 0.60 0.36, 0.81 Table 2: Values for (precision, recall) for different numbers of returned tags. better with denser samplings of the space of scale values, but only slightly. Accordingly, we recommend, for compu-tational gains, to sample the scale space fairly sparsely as the results are not strongly affected.

Due to space constraints, we do not include detailed re-sults from our analysis of the segment identification step (Step 5 in Section 4.1). Briefly, the parts of time and space that were associated with identified events and places were mostly accurate. The only systematic errors found were due to sparse, wrong, or missing data. For example, tags like October and summer had temporal distributions that were not representative of the true duration of these events. While more data will help for some of these tags (e.g. con-ference names), some events like seasons and months are not likely have uniform distributions over their true durations.
In terms of error analysis, we identified several classes of common errors with the Scale-structure Identification meth-od. First, the majority of false positives and false negatives for place identification were the result of sparse data. Like-wise the false positives for event identification were often due to sparse data. False negative event tags were also caused by bad data (e.g. incorrect capture time). Additional sampling and filtering techniques could potentially alleviate some of these problems.

Overall, the performance of the Scale-structure Identifi-cation method holds promise for automatic extraction of place and event semantics. The Scale-structure Identifica-tion method clearly outperforms the methods borrowed from other domains. While the difference is significant, we believe that one reason for the gain is the  X  X ingle-cluster-like X  fil-tering; the borrowed methods simply look for outlier/bursty segments without measuring or enforcing the uniqueness of the segments.
We have taken a first step in showing that semantics can be assigned to free-form tags using the usage distribution of each tag. The ability to extract semantics can improve current tagging systems, for instance, by allowing more pow-erful search and disambiguation mechanisms. Additionally, the knowledge that these methods extract can help with tasks that outside the scope of the specific system.
In particular, we have shown that location and time meta-data associated with photos and their tags enables the ex-traction of  X  X lace X  and  X  X vent X  semantics. This mapping of tags to events and locations could improve image search, serve as a basis for collection visualization, and assist in other photo-related tasks. This type of knowledge can also help create an ad-hoc gazetteer for events and locations that could be used for various tasks beyond photo man-agement. We plan to revisit the image search, visualization and gazetteer deployment in future work.

We would also like to extend the system to handle multi-regional problems. As mentioned above, the tag carnival may be event-like only in major cities of Brazil; we note above that the data analysis should be limited to specific geographic regions. Ideally, we could simultaneously gen-erate, store, and disambiguate tag semantics for different regions throughout the world.

Finally, we plan to deploy our methods to other tempo-rally and spatially encoded data, as they become exceedingly available on the web. We also look at extending the meta-data features used, beyond location and time, to verify that our methods are still effective in extracting other semantics beyond place and event. We would like to thank Shane Ahern, Simon King, Rahul Nair and Malcolm Slaney for their valueable insights, com-ments and assistance.
