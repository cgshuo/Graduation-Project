 Advances in multimedia acquisition and storage technology have led to tremendous growth in very large and comprehensive multimedia databases. Analyzing these large amounts of multimedia data to discover useful knowledge is a challenging problem. This problem has opened the opportunity for research in Multimedia Data Mining (MDM). Data mining refers to the process of finding interesting patterns in data that are not ordinarily accessible by basic queries and associated results with the objective of using discovered patterns to improve decision making. Traditionally, data mining has been applied to well-structured data, the kind of data that resides in large re-lational databases. Such data have well-defined, nonambiguous fields that makes it amenable to mining. The spatial, temporal, storage, retrieval, integration, and pre-sentation requirements of multimedia data are significantly different from those of traditional data.

Mining of multimedia data is more involved than that of traditional business data because multimedia data are unstructured by nature. There are no well-defined fields of data with precise and nonambiguous meaning, and the data must be processed to arrive at fields that can provide content information about it. Such processing often leads to nonunique results with several possible interpretations. In fact, multimedia data are often subject to varied interpretations even by human beings. Another diffi-culty in mining of multimedia data is its heterogeneous nature. The data are often the result of outputs from various kinds of sensor modalities with each modality needing sophisticated preprocessing, synchronization and transformation procedures [Adjeroh and Nwosu 1997].

None of the state of the art works in multimedia data mining utilize realistic features for mining purposes. They assume that the semantic labels can be obtained accurately. The reality is that the extracted labels and tags from different modalities are not obtained with 100% accuracy. This is due to the well known semantic gap problem. The uncertainty in the data is represented as a probabilistic confidence score, which is computed by event detectors [Dalvi et al. 2009]. Thus, we use probabilistic weighting to do mining on more realistic datasets. We illustrate the problem with an example. Multimedia systems utilize multiple types of media such as video, audio, text and even RFID for accomplishing various detection tasks. Different types of media possess different capabilities to accomplish various detection tasks under different contexts. Therefore, in reality we usually have different confidence levels in the evidence obtained based on different media streams for accomplishing various detection tasks. As shown in the Figure 1(a), there are three event detectors T 1 , events say A, B and C at different times by extracting features from three different modalities. Each observation is represented as (Event label, Start time, End time) in temporal multimedia data representation. None of the existing work considers the Probabilistic Temporal Multimedia (PTM) representation as shown in Figure 1(b). Each observation is represented as (Event label, Event Probability, Start time, End time). The PTM representation is more realistic and we can discover more useful and accurate knowledge using this data. The challenging problem is to do mining on such PTM data. The basic issues with PTM data mining are,  X  X ow to utilize and deal with associated confidence or probability of the semantic tags?  X  X ow to deal with correlation among the various media streams?  X  X ow to deal with synchronization issue due to different processing time scales of detectors, based on media stream they utilize? For example, the face identification system on video data identifies the person quicker by processing on single image frame than the speaker recognizer system identifying person using audio data. In this article, we have developed a novel framework for performing multimedia data mining on probabilistic temporal multimedia data. Sequence pattern mining aims to discover useful relations that are hidden among events. We propose a novel sequence pattern mining algorithm called Probabilistic Interval based Event Miner (PIE-Miner) for discovering frequent temporal patterns from interval based events. Our contribu-tions are:  X  X ntroduction of PTM data for mining,  X  X evelopment of a novel framework for PTM datamining,  X  X  novel sequence pattern mining algorithm with a new support counting mechanism. The rest of the article is organized as follows. Section 2 describes the literature sur-vey. Section 3 provides basic definitions and detailed problem description, Section 4 presents the design of PIE-Miner. Section 5 presents experimental results and discov-ered pattern interpretation. We conclude in Section 6 with a summary and an outline of future work. We surveyed papers from classification, clustering, association and sequence pattern mining for multimedia data. Among all the surveyed papers, we observed certain common weaknesses and that helped us understand the problem with existing data mining techniques.

Classification. Ching et al. [2006], Chen et al. [2006], and Shyu et al. [2008] present the multimedia analysis and decision tree logic based approach for the multimedia classification problem of soccer goal event detection. Their main focus was on the class imbalance problem. Lin and Hauptmann [2003] have developed a framework called  X  X eta classification X , which models the problem of combining classifiers as a classification problem itself. Their main focus was multimedia classifier fusion.
Clustering. Frigui and Caudill [2007] try to search for optimal clusters prototypes and the optimal relevance weight for each feature of each cluster. They use the clustering to extract representative visual profiles that correspond to frequent homogeneous regions, and to associate them with keywords.

Sequence Pattern Mining. The work in Zhu et al. [2005] is novel in its attempt to do sequence association mining to assign class labels to discovered associations for video indexing purpose. They first explore visual and audio cues that can help bridge the semantic gap between low-level features and video content. They do video association mining and discuss algorithms to classify video associations to construct video indexing. Once they generate the symbolic streams from different modalities, they either need to combine the streams or treat the streams separately. To find the co-occurrence of patterns that appear in multiple streams, symbol production synchronization is required for combining into single stream and find periodic patterns. The proposed association mining elegantly handles the problem but the question that arises here is, (1) generated symbols may not be accurate and (2) multimedia data streams do not generate same number of symbols in the same amount of time. Symbols from video shot and words from audio clip need to be synchronized in some way for creating the relational database for mining purposes. If we consider them as one stream, some information may be lost. Though they use visual, textual, audio and metadata features, they did not show any special usage of multimedia fusion to enhance the knowledge discovery process [Zhu et al. 2005].

Similarly in the series of papers [Shirahama et al. 2008, 2005], the aim is to show the importance of temporal constraint as temporal distance and temporal relationship. Applying Temporal Distance Threshold (TDT) and Semantic Event Boundary (SEB) constraints on extracted raw level metadata help to effectively extract Cinematic Rules and Frequent semantic events. For example, frequent patterns say SM1-SM1 repre-sents  X  X wo continuous shots with human voice, X  SM1-MV0 represents  X  X  shot with human voice and no direction of movement X  and MV0-MV0 represents  X  X wo continuous shots with no direction of movement. X  The considerably high recall values for these patterns indicate that characters talk to each other and hardly move in most of the talk event in this movie. But again the generated symbols like MV0 etc are not accu-rate. They are just labeled from the clusters obtained with certain assumptions. They extracted raw level features from audio and video shot keyframes using MP-factory and OpenCV. They cluster the raw level data and assign the labels based on clusters to discriminate the frames.
 There has been a stream of research on mining sequential patterns [Agrawal and Srikant 1995; Pei et al. 2001; Mannila et al. 1995]. These works assume that events have zero duration. However, events in many real world applications have durations, and the temporal relationships among these events are often complex. These relation-ships are modeled using a hierarchical representation that extends Allen X  X  interval algebra [shan Kam and chee Fu 2000; Wu and Chen 2007; Patel et al. 2008]. It is clear that all sequence pattern mining algorithms use certain semantic level symbols for mining purpose. The intuition behind using semantic level meta data is that, we can get some semantic level knowledge. For example, by considering the color histogram level data it is difficult to interpret the obtained knowledge for higher level semantics, but by clustering this histogram and labeling them as category (water, snow, fire, etc.), we can interpret the mined results at a semantic level.

However, none of the current research works focus on obtaining a realistic label and tag representation for mining purposes. For example, one technique is to extract the raw level feature then cluster or classify them and assign the labels to generate the categorical dataset. The derived categorical labels are approximate. Thus, these labels should have some probability associated with them to represent the approximation factor in order for it to be a more realistic data representation. There is some recent work in mining frequent patterns from uncertain data [Abd-Elmegid et al. 2010], but it is not considered from the semantic perspective of multimedia data. Another issue we observe is that there have been efforts in multimedia analysis research to discover the cross modal correlation and synergy between different modalities [Shen et al. 2008; Pan et al. 2004; Dongge et al. 2003]. But in multimedia data mining literature, there are not many examples showing the significant ways of exploiting such correlation knowledge for mining. Most works deal with low level raw data from each individual modality. Thus, considering both of the observed problems, we design a novel framework for multimedia data mining where realistic data can be mined with cross modal correlations. In this section, we first give basic definitions of terms used for framework, Table I with summary of notations used and then we define the problem of datamining on PTM dataset. We then analyze the research issues involve with mining such data. We also define the problem of sequence pattern mining on PTM data. We are trying to mine the higher level semantic events from the atomic level events dataset using sequence pattern mining. The definitions of terms used are as follows:
Event. Event is a physical reality that consists of one or more living or non-living real world objects (who) having one or more attributes (of type) being involved in one or more activities (what) at a location (where) over a period of time (when) [Atrey and Kankanhalli 2006].

Atomic Event. Atomic event is an event in which exactly one object having one or more attributes is involved in one activity[Atrey and Kankanhalli 2006]. Compound Event. Compound event is the composition of two or more different atomic events[Atrey and Kankanhalli 2006].

Higher-Level Semantic Event. Compound event with certain temporal relationships, certain frequency and associated probability is considered as higher level semantic event.

Each event E in an event list EL has a temporal relation with all the other events in the list. Table II shows the 13 temporal relations defined by Allen [1983] that can occur between any two interval-based events E i and E event E is formed when a temporal relation R is applied to two events E denote E = ( E i R E j ). The start and end times of E are given by min max { E i .e, E j .e } respectively. Temporal pattern mining of such interval based events can be very useful [Patel et al. 2008]. We present the algorithm to discover frequent sequence patterns from PTM events dataset. We use the probabilistic information to make candidate generation process more efficient for the A-priori based sequence pattern mining algorithms. It will show the advantage of having more realistic data for multimedia data mining.
 We now introduce a data representation for multimedia data which has not been explored earlier in the literature. This representation is more realistic and interesting to use for datamining purposes.

Definition ( PTM: Probabilistic Temporal Multimedia Data ). Let S be a multimedia system designed for accomplishing a set of  X  X " concept event detection tasks T {
T
M ={ M 1 , M 2 ,..., M n } .Let L ={ l 1 , l 2 ,..., l r } various detectors T .For1  X  i  X  n ,let0 &lt; p M i t j &lt; output by the detector T j based on individual i th media stream at time  X  X  X . The time duration of an event existence is represented by starting time  X  X t X  and ending time stream  X  X  X  and then by employing an detector (e.g., a trained classifier like SVM) on it for the detection task T j . The dataset generated with such multimedia system is called as  X  X TM dataset X . Thus, we obtain a set of  X  X  X  correlated labeled streams correspond to the  X  X  X  media streams: L ={ L ( l PTM data mining can be defined as, the following.

Input . Assume that we have  X  X  X  correlated multimedia streams M
L n set of symbols with p time t. The correlation among media streams influences the probabilities with which symbols are generated. The time stamps represents the temporal relationship between symbols. The time stamps for the similar symbol, generated from different streams, can be different due to different time scales of the detector in the corresponding stream. Here, we are trying to give an abstract of the PTM dataset. The dataset resembles a real-world surveillance dataset or group meeting dataset or movie dataset used for mining application.

Problem Definition PTM Data Mining . Given a PTM dataset D , the problem is to discover interesting knowledge from these streams. It can be interesting correlations among symbols or streams, frequent patterns, associations, clusters, outliers or classes hidden in given data streams.

We provide the problem description of sequence pattern mining on PTM data in the next subsection. In this article, we do not consider the other data mining problems such as classification or clustering, techniques. We will consider them in our future work. We are given a PTM dataset D as described in Section 4.1. We identify new problems for doing sequence pattern mining on dataset D by generalizing the original problem statement of sequence pattern mining given in Agrawal and Srikant [1995].
Definition ( PTMS: Probabilistic Temporal Multimedia Sequences ). Given a set of ( l s = s is called the associated probability values  X  p M j t i .

A sequence represents the items in their temporal order. Example of PTMS can be seen in Figure 2. Set of detectors are labeling different events with certain probability over a time period. The labels have certain temporal relationships which can be mined as PTMS. Following are the issues described in detail to understand the problem of se-quence pattern mining on probabilistic temporal multimedia data as shown in Figure 2.
How to Use Sequence Pattern Mining Algorithms to Work on Probabilistic Nature of Data? Given customer transaction database say D X  in Agrawal and Srikant [1995], it is clear that the rows in dataset D are not analogous to concept of transactions as in D X  . Because each modality(audio, video, etc.) has generated probabilistic symbols in D while the symbols in D X  are deterministic. So, the first problem identified is to consider the probabilistic nature of data for mining. As generalized sequence pattern methods are developed considering deterministic data, they cannot mine the patterns from probabilistic temporal multimedia dataset D .
 How to Synchronize Different Correlated Data Streams of Probabilistic Symbols to Find Valid Transaction Boundaries? As we can see in the Figure 2, event C with proba-bility 0.8 occurs in one of the detector utilizing video stream whereas a similar event C with probability 0.6 occurs in another detector utilizing audio stream. Due to different processing units and computational complexities of algorithms utilized for detectors, generated event labels of same event can be of different time periods and probabilities. Thus, the constraint as in traditional sequence mining that, no customer has more than one transaction with the same transaction time may not be satisfied here, as the time scale with which the probabilistic symbols are generated from different modali-ties are different. Thus, the second problem is to synchronize the different streams of probabilistic symbols to find a valid transaction boundary.

How to Resolve Redundant Symbols Generated from Different Modalities? The prob-lem encountered here is due to multimedia data X  X  property of redundancy. The con-straint that items can occur only once in an element of a sequence is violated for D . Different modalities might generate similar symbols with different or same prob-abilities. This problem may also lead to confusing sequence patterns like ( X , 0 . 9),( A , 0 . 5) } { ( X , 0 . 3) } { ( X , 0 . 5) }{ ties at different times but we cannot interpret them unless we incorporate the modality knowledge here. These symbols may differ in probability associated with them and def-initely the modality that has generated them. Thus, to deal with this problem we need to come up with mechanisms to incorporate these probabilities and knowledge of modalities which has generated these symbols. This also leads in direction of finding the correlation between these modalities to effectively handle the problem.
How to Find Subsequences to Calculate Candidate Support? We can see the prob-lem in defining that the sequence a 1 a 2 a 3  X  X  X  a n is a subsequence of another sequence b ered, the support for a sequence is defined as the fraction of total data-sequences that  X  X ontain X  this sequence.
 The  X  -containment mechanism can make support counting possible for PTMSs.
Definition (  X  -containment (  X  )). Given a n-PTMS P 1 =  X  )withn  X  m, and a probability difference threshold  X  ,we,saythat P in P 2 , denoted as P 1 P 2 , if and only if there exists a sequence of integers 0 &lt;  X  X  X  &lt; i (1)  X  0  X  k  X  n s 1 , k  X  s 2 , i (2)  X  1  X  k  X  n |  X  1 , k - X  2 , k | X   X 
As special cases, when condition (2) holds with the strict inequality, we say that P is strictly  X  -contained in P 2 , denoted with P 1  X  P 2 ,andwhen P say that P 1 is exactly contained in P 2 . Finally, given a set of PTMSs Ds, we say that P is  X  -contained in Ds ( P is  X  -contained into another one, P probability does not differ too much from those of its corresponding itemsets in P particular, each itemset in P 1 can be mapped to an itemset in P (A,0.3) and P 2 = (A,0.7) for given  X  = 0 . 2 does not hold the because condition 1 is satisfied (A  X  A) but the condition 2 ( satisfied. Whereas P 1 = (A,0.3) and P 2 = (A,0.4) for given property holds true. Now, frequent sequential patterns can be easily extended to the notion of frequent PTMS:
Definition (  X  -support, Frequent PTMS ). Given a set Ds of PTMS X  X , a probability threshold  X  and a minimum support threshold s min  X  [0 , 1], we define the a PTMS P as and say that P is frequent in Ds if  X  -supp(P)  X  s min . The support for a sequence P is defined as the fraction of total data-sequences P  X  that  X  X ontain X  this sequence.
It should be noted that a simple frequent sequence say X with only event labels may be frequent but not their corresponding PTMS P = (s,  X  probability values, thus not allowing any single probability value to be close (i.e., similar) enough to a sufficient number of them. Thus, we may miss many frequent patterns. Introducing probability in sequential patterns gives rise to a novel issue: the raw set of all frequent PTMS is highly redundant, due to the existence of several very similar and thus practically equivalent probabilities for the same event sequence. Example . Given the following toy database of PTMSs: (A,0.5 Overlap B,0.3 Overlap C,0.4) (A,0.6 Overlap B,0.4 Overlap C,0.3) (A,0.1 Overlap B,0.2 Overlap C,0.2) (A,0.2 Overlap B,0.2 Overlap C,0.2)
Here, (A Overlap B Overlap C) is a frequent sequence with all support values s (A,0.1 Overlap B,0.2 Overlap C,0.3) or remaining two are not frequent for s However, we can see that considering (A,0.5 Overlap B,0.3 Overlap C,0.4)  X  = (A,0.6 Overlap B,0.4 Overlap C,0.3) for  X  = 0.1 and if we have s min = 0.5 both of sequences (A,0.5 Overlap B,0.3 Overlap C,0.4) and (A,0.6 Overlap B,0.4 Overlap C,0.3) are considered frequent. Of course, (A,0.7 Overlap B,0.7 Overlap C,0.8) = (A,0.1 Overlap B,0.1 Overlap C,0.1) for and s min = 0.5. Thus, for the given  X  = 0.1 and s min = 0.5, all the four patterns turn out to be frequent. We have thus devised a novel support counting mechanism that can handle this situation. A natural step towards a useful definition of frequent PTMSs, then, is the summarization of similar probability values (relative to the same sequence) problem of discovering representative frequent PTMSs, defined as follows:
Definition ( Representative Frequent PTMSs ). Given a set Ds of PTMSs, a probability threshold  X  and a minimum support threshold s min  X  [0 , 1], and algorithm RepCand (Ds, s,  X  , s sequence P, we say that P = (s,  X  ) is a representative frequent PTMS in Ds if: Clearly, a key parameter of the definition is algorithm RepCand , that determines which annotations can be representative. In the next section the general problem of finding representative frequent PTMSs is discussed, and a reasonable solution is outlined. In particular, we define RepCand as a clustering algorithm applied to the probabilities extracted from the input dataset.
 Problem Definition: Sequence Pattern Mining for PTM Dataset . Given a PTM dataset D of data sequences, the problem of mining sequential patterns is to find all sequences whose support is greater than the user-specified minimum support. Each such se-quences represents a sequential pattern, also called frequent sequence.

At this stage, we do not consider certain user-defined constraints and parameters, like min-gap and max-gap time constraints, a taxonomy T and a user-specified sliding window size, used for state-of-the-art sequential pattern mining algorithms for trans-actional databases. Each of these parameters needs to be modified or rethought for using them on dataset D . We will detail these in the next section. PIE-Miner is designed to solve the problem described in Section 4.2. We illustrate the functioning of PIE-Miner with an example and algorithms in this section. PIE-Miner is a two stage algorithm, Stage-1 does sophisticated preprocessing for PTM event data and stage-2 does candidate generation with support counting. The example and algorithms explaining the stage-1, stage-2 are shown in Figure 3(a), Figure 3(b), and Figure 4, Figure 6, respectively. We have a stream of PTM data as shown in the Figure 3(a). PIE-Miner X  X  preprocessing stage does two tasks (1) Finds valid transaction boundaries and (2) Resolves redundant symbols using probability fusion. As shown in Figure 4, we are given with PTM data D that needs to be transformed into suitable format for mining in stage-2. In Section 4.2, we mentioned the issue to synchronize the different streams of probabilistic symbols is to find a valid transaction boundary. This issue needs to be taken care of during the preprocessing stage. It is not very straight forward to provide the solution to this problem. Selection of temporal window parameter is one of the way to handle the issue. Currently, PIE-Miner expects the user to provide the temporal window size parameter for chunking the data stream to convert it into format similar to transactions database. The complete PTM data is converted into transactions of size equal to the temporal window. 4.1.1. Probability Fusion. Once we have generated such transactions, the next step is to resolve redundant symbols . Due to the multimedia data X  X  property of redundancy, different detectors could have generated the same event labels with different probabil-ities at different times from different modalities in the multimedia data stream. Thus, we will have similar event labels but with different probabilities within a transaction. This redundancy leads to useless sequence pattern generation like ((A,0.3 overlaps A,0.5) meets A,0.4), where event A is detected from different detectors from different modalities. We solve this issue below, using the information assimilation framework proposed in [Atrey and Kankanhalli 2006].

As per the information assimilation framework, M n = { M 1 streams. The system outputs local decisions with confidence P( e 1  X  j  X  r, about an atomic event e available, they iteratively integrate all the media streams using a Bayesian approach. P( e j media streams M 1 , M 2 , ... , M i  X  1 . The updated probability P( e probability after assimilating the new stream M i , t at time instant t) was iteratively computed as given below: where  X  i is a normalization factor. They assign weights to different media streams based on their confidence information. If we have more confidence in a media stream, a higher weight is given to it. They use the LOGP (logarithmic opinion pool) since it satisfies the assumption of conditional (content-wise) independence among media streams which is essential to assimilation. And derived the assimilation model that combines the probabilistic decisions based on two sources M streams) and M i (i.e., an individual i th stream) is given as follows: where P i = P( e j atomic event e j using M i and M i  X  1 , respectively, at time instant t. p is probability of the occurrence of atomic event e j based on only i instant t. Similarly, F i  X  1 and f i (such that F i  X  1 + and M i , respectively. The computation of confidence for a group of media streams are known based on the type of event and assumed to be given to us at this stage. The is the agreement coefficient between two sources M i  X  1 and M represent full disagreement and full agreement, respectively, between the two sources. The  X  t parameter is provided by the user to PIE-Miner. From the example in Figure 5, we can see the calculation for new confidence value, new start time and new end time for fused event label. In the example, we considered the agreement coefficient value as 1 and media stream confidences F i  X  1 and f i both 0.5. Then, we applied the confidence fusion formula as shown in the Eq. (4). If there are  X  X  X  labels of an event to be fused we consider the following formula for fusing the start time  X  X  X  and end time  X  X  X  for new fused event, The example in Figure 5 shows how the confidence and temporal values are fused for redundant event labels. After the confidence fusion for atomic events, we can remove the redundant symbols from the input data stream. Thus, in turn, removing possible redundant sequence patterns in advance. The confidence fusion incorporates the corre-lation among different modalities. Thus, we have much robust data after preprocessing ready for applying the PIE-Miner for extracting the sequence patterns.
 There are two main tasks in stage-2 (1) Candidate Generation and (2) Support Counting. PIE-Miner X  X  candidate generation is similar to the A-priori based method and the support counting has the novel clustering based approach. The main problem is to find the representative frequent PTMSs. Stage-2 of PIE-Miner is iterative. As seen in the Figure 6, the algorithm iterates as long as new candidate patterns are generated for next iteration. The parameter k represents the length of sequence pattern. In each iteration, we increase the length by one. Stage-2 begins with candidate set of 1-frequent patterns obtained from the clusters with cardinality describe the details of clustering the candidates and counting their support below. GenerateCandidate () is similar to the A-priori based candidate generation [Agrawal and Srikant 1995] procedure, taking k  X  1 length patterns as input and join them suitably to create k-length patterns. The main difference is that the k patterns are taken from clusters with k  X  1 length pattern frequent clusters. These k-length patterns will be tested for required minimum support criterion and filtered as frequent k-length patterns. The generated frequent patterns are input for next iteration of algorithm to find longer sequence patterns. This is the task of candidate generation procedure. Once we have found the candidate patterns, next task is to see how many instances in dataset has this pattern. Thus, we try to find the candidate pattern as a subsequence in all the given dataset.  X   X  Containment () is the procedure for finding the subsequence using the defined  X  -containment ( matching symbols as explained with example in Section 4.2. The confidence difference threshold, which is user specified value within [0
Clustering . If the candidate pattern and mapped transaction pattern satisfy Containment conditions, then the mapped transaction pattern is added to the cluster represented by candidate pattern. We can see the clustering process in Figure 4. All the elements within the clusters will be within  X  confidence value distance from the confidence value of the corresponding cluster representative. The clusters are created for all generated candidate patterns. As we add the element to the cluster we increment their cardinality.

Support Counting . Once all the candidate patterns have generated the clusters, we compare the cardinality of each cluster against the support is greater than the support min value, we consider the cluster as frequent cluster and all the elements in the cluster are considered frequent. We add the elements from the frequent cluster to candidate pattern set. The algorithm terminates on returning a null candidate pattern set. The novelties in our new support counting mechanism are the following.  X  X urrent sequence pattern mining algorithms have support counting for every indi-vidual event label, whereas we count support for cluster of labels,  X  X ach cluster representative label contributes to patterns discovered from all the labels contained within the cluster thus it is computationally more complex.  X  X here is no other approach found in literature doing cluster sequences support counting. Temporal-interval-based event sequence mining algorithms are extensions of event sequence mining algorithms. Similarly, PTM sequence data mining algorithm is an extension of interval based event sequence mining algorithms, with probability value associated to events within the time interval. Thus, the PIE-Miner is extension of state-of-the-art sequence pattern mining algorithms. In this experimental section, we show usefulness of PIE-Miner by comparing its results with one of the event sequence pattern mining algorithm FP-Growth [Han et al. 2004] and interval based event sequence mining algorithm IE-Miner [Patel et al. 2008] and TPrefixSpan [Wu and Chen 2007]. We run experiments on synthetic dataset and real world dataset.

Synthetic Dataset generated using IBM Quest Market-Basket Synthetic Data Gen-erator [IBM]. We illustrate the generic properties and significance of PIE-Miner over other event sequence and interval based event sequence pattern mining algorithms. In particular, the evaluation of Association Rule Mining and sequence pattern mining al-gorithms is often tackled empirically using data generated by the QUEST program from the IBM Quest Research Group [IBM]. The QUEST program was originally designed for generating synthetic customer transactions dataset [Agrawal and Srikant 1995], which is an event sequence dataset. The QUEST program was modified to generate interval-based event sequences in [Patel et al. 2008] and in other interval-based event sequence mining experiments. We also use the IBM data quest generator to create a synthetic event sequences and analyze the behavior of our algorithms. We generated the PTM event sequence dataset with event label, event start time, event end time and randomly generated probability value associated with each event, maintaining the constraint that start time is greater than the end time for each event. We choose the parameter T (the number of event labels) equal to 500 for IBM data quest program. We run experiments for different value of  X  and support to analyze the behavior of the PIE-Miner.

Real World Dataset (a) TRECVID 2005 news video dataset [NIST] and (b) AMI [AMI] group meetings multimodal dataset. Using real world dataset, we will illustrate the usefulness of patterns discovered using PIE-Miner over other event sequence and interval-based event sequence pattern mining algorithms.

TRECVID 2005/2006 benchmark has typically focused on evaluating, at most, 20 visual concepts, while providing annotation data for 39 concepts. It has 277 news videos from six different news channels with a total duration of 150 hours. Columbia University has released a set of 374 semantic concept detectors [Columbia University] (called Columbia374) with the ground truth, the features, and the results of the de-tectors based on baseline detection method in TRECVID2005/2006. We use confidence score values for some of selected semantic concepts detected using Columbia374 X  X  SVM-based concept detectors for generating our PTM dataset. These concepts are detected for each of the keyframes. We use starting and ending time for these semantic con-cepts as identified with Fraunhofer Institute and Dublin City University team X  X  shot boundary detector.

The AMI dataset has rich set of manually and automatically annotated events from multiple modalities. We consider the atomic events of different Hand Gestures, Head Gestures, Spoken Words, Movements and Focus of Attention during the meeting an-notated manually from these database [AMI]. Currently we consider 4 group meetings with team of 4 members. Since we do not have the event detector X  X  probabilities, we at present randomly generate the probability associated with each event label. We use a 100-second temporal window for mining sequence patterns. The AMI group meeting rooms include capture of both audio and videos that show individuals in detail and ones that show what happens in the room in general. We can do different kinds of meeting analysis using it. It has got data for each individual person X  X  behavior during the meeting through dedicated video, audio, text and other sensor devices. It also has group level data captured in form of audio, video and text. Using sequence pattern mining we can discover different kinds of knowledge, Single Person behavior analysis: For the given Hand Gestures, Head Gestures, Spoken Words, Movements and Focus of attention. We can extract patterns like (Hand Pointing  X  X verlaps X   X  X hat X   X  X eets X  Standing), where Hand Pointing is a hand gesture,  X  X hat X  is a word and Standing is a movement. These patterns can be used to classify whether the person was actively participating in the meeting or not. These temporal patterns can help finding some interesting events like the important questions asked by someone in the meeting or answered by someone. Multiple Persons behavior analysis: The patterns that we expect to discover here are like (Person1 say Yes  X  X verlaps X  Person2 say Yes  X  X eets X  Person3 say No) which can tell us about the group dynamics of the team. We obtained four different sized synthetic dataset using IBM QUEST dataset generator. The four different datasets have different number of event sequences 475, 1376, 2345 and 4690 respectively, with average number of 3 to 15 events in each sequence. We consider three different support values as { 0 . 02 , 0 . parameter  X  are chosen for PIE-Miner as { 0 . 2 , 0 . 4 ,
In the first set of experiment to show the significance of PIE-Miner, we choose min-imum support as 0.02 and  X  as 0.2 for running PIE-Miner. We removed time interval and confidence value from four different datasets and choose minimum support as 0.02 for running FP-growth. Similarly, we removed just confidence value from four differ-ent datasets and choose support as 0.02 for running IE-Miner and TPrefixSpan. The result in Figure 7(a) shows the number of sequential pattern discovered using these algorithms. We can see that for FP-growth very large number of frequent patterns gen-erated which is a problem. It is difficult to identify useful patterns from such a large number of patterns. While the number of patterns generated by PIE-Miner, TPrefixS-pan and IE-Miner is of the order of hundreds, the number of patterns by FP-growth is of the order of hundred thousand. Another problem is that the patterns discovered using FP-growth do not have any temporal relation thus we lose important information about the temporal relationship between events. We can see that IE-Miner, TPrefixSpan and PIE-Miner generate moderate number of frequent patterns compared to FP-growth and thus it is comparatively easy to discover useful patterns. Sometimes for certain support values IE-Miner or TPrefixSpan will generate very less number of patterns but by adjusting  X  , PIE-Miner can generate moderately higher number of patterns as shown in Figure 7(b). It is an advantage of PIE-Miner over IE-Miner and TPrefixSpan that, we can choose different  X  value and can generate different number of frequent patterns for fixed support value. Also the patterns discovered with PIE-Miner has ad-ditional information regarding the confidence value associated with each event within the temporal interval, which can be useful based on application requirement. In the second set of experiments, we analyze the properties of PIE-Miner. From Figure 7(c), it is evident that as we increase the value of patterns discovered increases. But one should be careful to select the a large  X  (say 0.9) or a small  X  close to 0.0 value loses the purpose of probabilistic event labels. We observe that if  X  -containment criteria is not applied, then there are no frequent patterns discovered for data with diverse symbols. But keeping the within certain limit is important to avoid being flooded with many sequential patterns. Also Figure 8(c) shows that we can generate moderate amount of frequent patterns for different support values. Thus, we can conclude here that PIE-Miner can generate moderate number of frequent patterns compared to other state of the art algorithms and it has additional information of confidence value incorporated in patterns which is useful for multimedia application in particular as demonstrated in the experiments in the next section.
 We present experiments and analysis of results on TRECVID 2005 video dataset and AMI meeting dataset in following subsections. 5.3.1. Experiments on TRECVID 2005 Dataset. In our first experiment on TRECVID 2005 news video dataset [NIST] we created PTM dataset for each video. We got posterior probability score from three different visual feature based detectors Edged direction histogram, Gabor and Grid color moment. So we have (277  X  to 277 news videos. In each of these datasets, we choose four semantic concepts Urban, US Flag, White House and Walking. Each transaction or a row of the dataset has these four concepts detected for three consecutive shots. In other words we have a temporal window of three consecutive shots.

We have three different datasets for each video. Once we have such datasets we perform probability fusion to resolve the redundant symbols. Here, all the three dataset have same shot boundary (starting and ending time) for corresponding events. We achieve three times reduction in redundancy with such a fusion method compared to original dataset from three different modalities. Now each video will have a single dataset representing it. We have 277 dataset after the fusion for corresponding 277 news videos.

Traditionally such PTM dataset might be converted to binary decision about the positive occurrence of the event/concept if the posterior probability is above 0.5 [Aly and Hiemstra 2009]. Then, the frequent sequence patterns are discovered us-ing event sequence pattern mining or interval based event sequence pattern mining algorithms. We can see from Figure 8(a) that there are very few events remaining after considering binary decision about the positive occurrence of event/concept. Bina-rized sequence dataset that is used with traditional event sequence pattern mining and interval based sequence pattern mining algorithm just processes 15% of total data generated. Thus, we need PTM event sequence pattern mining algorithm for process-ing 100% of data. In Figure 5.2 though the number of transaction in Binarized event sequence dataset looks similar to the transactions in PTM event sequence dataset the average length of sequence is just 2 events for Binarized dataset whereas 12 events for PTM dataset. Thus, PTM dataset can discover more useful knowledge from mining a more accurate and more informative dataset. 5.3.2. Experiment on AMI Meeting Dataset. Using the AMI meeting dataset, we would like to show the semantic usefulness of the discovered frequent patterns from PTM event sequence dataset.

Defining the Usefulness Criteria . By semantically useful patterns, we mean the level of knowledge conveyed through the discovered sequence pattern. Using the existing event sequence mining algorithms, the pattern discovered are in the form of Writing Nodding  X  Pointing or ((Writing overlap Nodding) overlap Pointing) in case of interval based event sequence mining, whereas the sample patterns we discover are, (1) (Writing0.9 overlap Nodding0.2 overlap Pointing0.5) (2) (Writing0.8 overlap Nodding0.9 overlap Pointing0.7) (3) (Writing0.4 overlap Nodding0.4 overlap Pointing0.9) (4) (Writing0.1 overlap Nodding0.1 overlap Pointing0.2)
We can see that patterns discovered with PIE-Miner are more fine grained than the other sequence pattern mining algorithms. There can be many possible scenarios associated with pattern Writing  X  Nodding  X  Pointing or ((Writing overlap Nodding) overlap Pointing), which can be interpreted using PIE-Miner X  X  discovered patterns. We interpret the above sample patterns to show that discovered patterns are more meaningful. Interpretation of pattern 1 can be that when the detector labels an event as Nodding with probability value 0.2 the chances are high that the actual event occurred is Writing. The detectors may misclassify events under certain circumstances. Table III [Reiter and Rigoll 2004] shows the statistics for meeting events detectors. It appears plausible that Writing event has been misclassified as Nodding event in this scenario.
One more interesting scenario occurs when we see sample pattern 2 and 4. Confidence values for events in pattern 2 are high whereas in pattern 4 they are very low. Thus, we can discriminate these patterns as strong patterns vs weak patterns . Interpretation of a strong pattern is straightforward, but the interpretation of weak patterns can be more challenging and interesting. The weak patterns might be conveying the events for which we do not have robust event detectors in the system. Thus, getting such detailed knowledge about the new events can also help develop new detectors using these weak patterns. Also, we can say that if certain patterns have very low confidence values, then we can ignore them and that way we can generate a smaller set of candidate patterns. Such optimizations can be of great help for large datasets.

Using the AMI meeting data we discover some useful behavioral patterns. Consider the set of IS1008a meetings with four persons (A,B,C and D). We discover distinct fre-quent patterns to represent each person X  X  behavior in the meeting. The person C was discovered with the distinct pattern of questioning behavior as shown in the Table IV. There were totally 7013 frequent patterns discovered in total for person C, but among them we put the event labels which has the maximum combination of frequent pat-terns. Thus in the case of person C, he has the maximum question labeled frequent patterns. Whereas for Person B, out of 4862 patterns the majority of the patterns are concord signal0.3. It looks like he was agreeing with the speaker and others during the meeting but not many questions or words came from him. The person D had the ma-jority of patterns of looking at table and persons, thus he may be very non-interactive in the meeting. And the person A with lots of authoritative patterns like you , what, uh , etc., thus, he must be the person in charge, handling the meeting. On analyzing the results, we realize the important property of PIE-Miner that it boosts the majority pat-tern and attenuates the minority patterns. It is very difficult to differentiate between such majority frequent patterns and minority frequent patterns for traditional support counting mechanism but not with PIE-Miner ` s using majority counting mechanism. We can see that  X  -containment works as a High Pass Filter that gradually boosts the high frequency patterns and reduces the low frequency patterns. The obtained results are thus very useful in understanding the social dynamics of the meeting. In this article, we examined the importance of mining more realistic data for knowledge discovery. We are the first to introduce the Probabilistic Temporal Multimedia (PTM) dataset for data mining purpose. We have designed a novel sequence pattern mining algorithm called PIE-Miner to discover more meaningful sequence patterns from PTM data. We demonstrated the utility of discovered knowledge, which is not possible to discover through existing sequence pattern mining algorithms.

In the future, we would like to incorporate probabilistic inference and make knowl-edge discovery from PTM data much more useful. Though we were able to show the significance of PTM dataset, we want to experiment with larger real world datasets in different domains.

Currently, we have taken a temporal window-based approach for resolving the bound-ary selection issue, but in the future, we want to try more accurate ways of choosing the transaction boundary for PTM data. Obtained time intervals from detectors are not accurate, which needs to be investigated for stream synchronization. We also want to do experiment on web scale datasets for testing the scalability of the proposed algorithm. We will also work on developing classification and association algorithms for PTM data. The proposed problems are new and thus have lot of challenging and interesting issues to work on in long term.

