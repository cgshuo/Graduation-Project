 Recently a ranking view of collaborative recommendation has received much attention in recommendation systems. Most of existing ranking approaches are based on pairwise assumption, i.e., everything that has not been selected is of less interest for a user. However it is usually not proper in many cases. To alleviate the limitation of this assump-tion, in this work, we present a unified framework, named Personalized Semantic Ranking (PSR). PSR models the per-sonalized ranking and the user-generated content (UGC) si-multaneously, and the semantic information extracted from UGC can make a remedy for the pairwise assumption. More-over, utilizing the semantic information, PSR can capture the more subtle information of the user-item interaction and alleviate the overfitting problem caused by insufficient rat-ings. The learned topics in PSR can also serve as proper ex-planations for recommendation. Experimental results show that the proposed PSR yields significant improvements over the competitive compared methods on two typical datasets. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Learning to rank; recommendation; user-generated content
In recent years there have been growing concerns over the problem of information overload. To cater the users X  needs for finding right information, a lot of researches have been done on recommender systems (RS). Personalized recom-mendation involves a process of learning users X  preferences by analyzing their feedback, either in explicit or implicit for-m, and delivering the right items to each user. As one of the most well-known approaches in RS, collaborative filtering c  X  Figure 1: An illustration of user-generated content in website recommendation system. All the three websites, YouTube.com, last.fm and EASports.com, are represented by their logos respectively. The green solid lines represent  X  X election X , and the o-range dashed lines denote  X  X ecommendation X . For example, Sam tags the website  X  X ouTube X  with  X  X -ports X  and is recommended with  X  X ASports X . (CF) exploits the similarity among users and recommend items the similar users liked.

In most of real-world circumstances, implicit feedback, such as clicks, purchases, is more frequently available. A characteristic of implicit feedback is that it is one-class, i.e., only positive examples are observed. Motivated by the work in the domain of learning-to-rank, a ranking view to rec-ommendation [4, 7] provides us a good way to handle the implicit feedback. One of the most successful methods is Bayesian Personalized Ranking (BPR), which assumes that everything that has not been selected is of less interest for a user [7]. However this assumption is usually not proper in many cases. In order to overcome the limitation mentioned above, we utilize semantic information extracted from UGC to construct personalized ranking for better recommenda-tion. In the recommendation scenarios, the user-generated content is assigned by certain user to certain item in the process of user-item interaction (such as rating, purchasing, etc.). In these scenarios, UGC provides us a further clue not only on the user interest but also on the item characteristic. By incorporating UGC, recommendation systems have the potential to generate more meaningful and effective recom-mendations for users.
For ease of explanation, we take the tags in website recom-mendation systems (e.g. Delicious 1 ) as a specific example to illustrate some benefits of UGC. (1) As shown in Figure 1, we may infer that Bob prefers  X  X ASports X  over  X  X astfm X  following the pairwise assumption in BPR. Nevertheless it is obviously unreasonable to making a judgment that Bob prefers  X  X ASports X  over  X  X ouTube X . The semantic similari-ty (e.g. common tags) between  X  X ASports X  and  X  X ouTube X  can make a remedy for the pairwise assumption, whereas the semantic difference between  X  X ASports X  and  X  X astfm X  strengthen the pairwise hypothesis. (2) Utilizing the UGC is a good choice to solve the rating sparsity problem. In Figure 1, both Sam and Lucy have selected the website  X  X -ouTube X . Merely from this behavior, we may infer that they have the same interest. However, through further obser-vation of their tags on  X  X ouTube X , we realize Sam prefers  X  X ports X  video while Lucy prefers  X  X usic X  video. These be-haviors cannot differentiate users X  interests or item proper-ties while the UGC can. From the above example, we no-tice that UGC is capable to reflect more subtle information, which may not be revealed by very sparse rating behavior. (3) As the UGC captures both the user interest and item characteristic explicitly, it can help us understand user pref-erences explicitly, which makes a great difference in recom-mendation systems. After capturing the user preference, RS can demonstrate the topics user interested in, rather than describe redundantly and blindly with a lot of annoying de-tails. In the case described in Figure 1, we can recommend Sam  X  X Asports X  with proper explanation, such as,  X  X t is a popular sports site X . This adequate and persuasive explana-tion would make the recommendation more acceptable.
In this paper, we present a novel probabilistic framework, named Personalized Semantic Ranking (PSR), which joint-ly modeling the personalized ranking and UGC in a com-mon subspace. It alleviates the rigid pairwise assumption in BPR by seamlessly incorporating semantic information for recommendation. Our method captures both the collabora-tive preference and the content-based preference, whick can also alleviate the overfitting problem caused by sparse rating data. PSR can also exhibit the user interests and item char-acteristics in an explicit manner, which can be interpreted as a vector of topics discovered from UGC.
Collaborative filtering with implicit feedbacks has been steadily receiving more attention. For item prediction, [3] and [5] propose a regularized least-square optimization with case weights (WR-MF). The case weights can be used to re-duce the impact of negative examples. Despite its populari-ty, the above approaches often performs poorly compared to more recent models based on ranked loss minimization. The main reason is that all these approaches focus on the task of accurately predicting the exact rating values, while ranked loss minimization focus on accurately picking the top N rec-ommended items, which is a more practical goal. As one of the most popular methods, Bayesian Personalized Ranking (BPR) is still under a rigid assumption, that everything that has not been selected is of less interest for a user [7]. Be-sides, all the above approaches suffer from the problem of poor explanation for recommendation. http://www.delicious.com
There are several methods which integrate attribute in-formation about users and items into recommender system-s. For example fLDA [1] and CTR [9] utilize topic models [2] for recommendation. Instead of learning one representa-tion from a single document in these methods, PSR learn-s each user/item latent vector from all the relevant docu-ments, which is more appropriate for UGC. Even some gen-eral frameworks like [6] can not well utilize the UGC.
Notations In our scenario, all the observations can be denoted by G = ( U , V , E + , W ), where U = { u 1 ,...,u the user set, V = { v 1 ,...,v M } is the item set. The positive feedback is given by user-item interaction set E +  X  U  X V , and the element ( u,i )  X  E + represents that user u  X  U has purchased/clicked on item i  X  X  . All the UGC is a collection of documents denoted by W = { w u,i | u  X  U ,i  X  V} . The document w u,i is the content posted by user u to item i , and its t -th word is W u,i,t , where t  X  X  1 ,...,T u,i } . If there is no content between user u and item i , word count T u,i = 0.
Personalized Ranking from Implicit Feedback For each user, we transform the implicit feedback E + to person-alized ranking R . Instead of modeling the implicit feedback E + directly, we adopt a popular pairwise approach men-tioned in BPR [7]. The idea is to discriminate the positive items V + u = { i | ( u,i )  X  X  + } from the remaining items V\V for each user u . Let  X  X ser u prefers item i to item j  X  be specified as i u j . If an item i has been selected by user u , then we assume that the user prefers this item over all other non-observed items. This property is formulated as follows: For convenience, we employ a random variable R u,i,j to de-note the above pairwise property For any two different items i,j  X  V , we have R u,i,j = 1  X  R u,j,i = 0 (or R u,i,j = 0  X  R u,j,i = 1). In our experiments, we just take the R u,i,j = 1 ( R u,j,i = 0) into consideration. The set of all pairwise preferences can be represented as T = { ( u,i,j ) | i  X  V + u  X  j  X  V\V + u } , and the ranking set is R = { R u,i,j | ( u,i,j )  X  T} . Our model is expected to accurately preserve the ranking order.
Probabilistic Framework PSR maps both users and items to a common latent factor space R K (each dimension represents a latent factor). Each user u is associated with a factor vector U u  X  R K , which encodes the user preferences, and each item i is associated with a factor vector V i  X  R representing the item characteristics. Both W and R can be generated from the latent factors.

For constructing the ranking R , we first assume that each user-item pair has a rating score, which reflects the prefer-ence degree. Thus we have a preference score x u,i for user-item pair ( u,i ) and another score x u,j for a different pair ( u,j ). The probability that user u prefers item i to item j is p ( R u,i,j = 1), which is parameterized by the relative score x u,i,j = x u,i  X  x u,j . Here, we adopt a scoring function, which is widely used in factor models, x u,i = U T u V i . Figure 2: Graphical model of PSR. There are N users and M items. R is the personalized ranking.
 For some of the user-item pairs, there are documents extracted from the UGC. The Gaussian prior pa-rameters for U and V have been omitted for sim-plicity in this figure.

For constructing the content W , a latent representation for w u,i is introduced as  X  u,i . It is also called topic pro-portions in topic models [2], where z u,i is the topic assign-ments for each word in document w u,i and each topic  X  is a distribution over words.  X  u,i encodes not only the la-tent semantic of document w u,i , but also the user u  X  X  topic preferences on item i . Each component of  X  u,i is expected to be positively correlated with both the corresponding user factor and item factor. That is, if an item has higher val-ue of a certain factor, or a user values higher on a certain topic, the corresponding topic is more likely to appear in the UGC. In order to preserve such dependent correlation, we introduce a simple way to build a direct connection be-tween the user-item pair and document,  X  u,i =  X  ( U u + V For a K -dimensional vector x ,  X  ( x ) is logistic transforma-tion function  X  ( x ) = exp( x ) / P k exp( x k ), which makes it possible to bound x within the range [0 , 1].

In order to balance the model X  X  complexity against overfit-ting on the training data, Gaussian priors are also imposed on the factors U and V . The graphical model is depict-ed in Figure 2. The generative process for all the textual documents W and personalized ranking R is as follows: 1. For each user u , draw user factors U u  X  X  (  X  U ,  X  U 2. For each item i , draw item factors V i  X  X  (  X  V ,  X  V 4. For each triplet ( u,i,j )  X  X  , draw the ranking For ease of exposition, let  X  = [  X  U ,  X  V ,  X  U ,  X  note the model parameters,  X  = [ U , V , Z ] denote the latent variables. The joint probability distribution for the observed variables can be written as where  X  is omitted in the right for brevity.

Maximum A Posterior The objective of our model is to find the optimal latent factors U and V for accurately modeling ranking and UGC. Maximum a posterior (MAP) estimation can be used to obtain a point estimate of the pos-The negative log likelihood can be used as loss function In Equation (4), we notice that loss function consists of three parts, ranking loss L R , content loss L W and regu-larization loss L reg . The ranking loss L R , which ensures successfully preserving the ranking, will be discussed in the next section. The content loss can be denoted by L  X  P often the word W u,i,t occurred in document w u,i . If we place zero-mean spherical Gaussian priors on U and V , L reg work-s like L 2 regularization which prevent models from overfit-ting [8]. Given the model parameters  X , the optimal factors [ U , V ] should be obtained by minimization of all three loss-es. Then each score x u,i can be predicted by U T u V i . After sorting all the scores for each user, the top N items will be recommended to the user.
Datasets and Settings We evaluate our model on two published datasets: social bookmarking dataset from De-licious and scientific literature from Citation-network. In Delicious dataset, each user bookmarks a set of webpages which can be regarded as positive examples of the user X  X  in-terests. Here, the bookmark is a kind of UGC, and the task is to recommend webpages to users. In our experiments, we draw a subsample such that each user has bookmarked at least 5 webpages, each webpage has been selected by at least 3 users and each bookmark appears at least 5 times. Citation-network V 1 is a dataset released by Arnetminer. In this circumstance, we treat the paper title as a kind of UGC between the author and the publication, and our task is to recommend publications to authors. Removing papers which have no publication information, we obtain a subset of papers published from 2001 to 2010.

Baselines and Evaluation Metric We conduct com-parisons with several state-of-the-art methods, including SVD, WR-MF [3, 5], BPR-MF [7] and FM [6]. In SVD, the miss-ing is treated as negative examples. In FM, the UGC are directly treated as additional dimension in feature vector. In order to evaluate the qualities of the recommendations, we randomly select 20% of the implicit ratings to be the test set, and use the remaining entries for training. Two metrics, F1-score and Mean Average Precision (MAP), which are widely used for recommendation evaluation, are adopted here.
Result Analysis Table 1 gives the performance compar-ison with a variety of dimensionalities on the Delicious and the Citation-network datasets. From that we can see, un-der different settings of K , our models consistently outper-form the compared methods. Figure 3a is the precision-recall curve on Delicious dataset. From the results we notice that the personalized ranking methods have great superior-ity over rating prediction methods. Owing much to the se-under the percentage scale.
 Figure 3: Left panel: precision-recall curves of the Delicious dataset. Right panel: MAP with differen-t amounts of training ratings on Delicious dataset. (K=30) mantic analysis from UGC, PSR increases the performance by more than 20% compared to SVD and WR-MF. PSR achieves great improvement even compared with BPR-MF, which largely due to the semantic offset from naive pairwise assumption in BPR-MF. PSR works better than the general framework FM for well utilizing the UGC.

We further evaluate the ability of compared methods in handling different amount of training ratings (20%  X  80%). The performance comparison with K = 30 on the Delicious dataset is shown in Figure 3b. The experimental result-s indicate that PSR can obtain the best performance with varying amounts of training ratings. These improvements are largely due to the incorporation of UGC. Moreover, our method outperforms other methods more significantly when fewer ratings are provided. When we use 80% of the ratings as training set, PSR increases the performance of SVD with 130%, while given 20% ratings, PSR enhances the perfor-mance by more than 360%. The evidences show that when the rating matrix is sparse, the impact of UGC is very sig-nificant in PSR.

Another advantage of PSR is that it can explain the us-er and item latent space using the topics discovered from the user-generated content. For user u , we can find the top matched topics by ranking the entries of factor vector U u For item i , we also can rank the entries of factor vector V . The top matched topics serve as an explanation of user interest and item characteristic. Some of the topics discov-ered in the Citation-network are displayed in Table 2. For example, the table illustrates that the top words in topic 02 are  X  X etwork X  ,  X  X ensor X  etc., the most related authors of this topic are  X  X oseph P. X ,  X  X ha L.  X  etc, and the most re-lated publications are  X  X JSNet X ,  X  X OSN X  etc. Owing to the Table 2: Five topics discovered by PSR on the Citation-network dataset. Each topic is shown with the top 8 words, top 4 authors and top 5 publica-tions. (K=30) good properties of interpretation, user experience would be greatly improved in real-world recommender systems. This work is jointly supported by National Basic Research Program of China (2012CB316300) and National Natural Science Foundation of China (61403390, 61175003, 61135002, U1435221). [1] D. Agarwal and B.-C. Chen. flda: Matrix factorization [2] D. M. Blei, A. Y. Ng, and M. Jordan. Latent dirichlet [3] Y. Hu, Y. Koren, and C. Volinsky. Collaborative [4] J. Lee, S. Bengio, S. Kim, G. Lebanon, and Y. Singer. [5] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, [6] S. Rendle. Factorization machines. In ICDM , 2010. [7] S. Rendle, C. Freudenthaler, Z. Gantner, and [8] R. Salakhutdinov and A. Mnih. Probabilistic matrix [9] C. Wang and D. M. Blei. Collaborative topic modeling
