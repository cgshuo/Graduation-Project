 Domain term [1] refers to a term describing concept which is widely used in domain matic thesauri enrichment, ontology construction, keyword extraction, tag suggestion, ways hard to obtain them efficiently and precisely. 
Traditionally, domain terms are mainly given by domain experts, which is labor-fulfill the task of the domain dictionary construction, but they may be unfamiliar with experience are rarely used by researchers in practice. According to the study on Chi-readers should be emphasized. Unfortunately, it is always hard to combine the users X  needs with the terminology extraction. One of the solutions to overcome the obstacle is to take the domain corpus into account. 
In this paper, we propose a novel terminology extraction approach integrated with researcher X  X  work. Besides the short time to print and the opportunity to describe the publications formerly. The proceedings of domain conferences provide a good re-source for research on terminology extraction. 
We can learn plenty of information from linkage of authors, papers and confer-ences in domain proceedings. For any paper, the link from an important conference is better than the link from an ordinary one. Similarly, the importance of papers will also interact with the authors. Therefore, we can say that the more important a conference is, the more important the paper it accepts is, and the more important the author is. 
Our algorithm takes advantage of graph mutual reinforcement techniques to rank papers, and then use the papers X  values of importance to evaluate terms. By applying mutual reinforcement techniques in the graph, important papers will make the impor-tance of the corresponding conferences and authors increase. In turn, conferences will papers as well. For a paper, the values generated in all the iterations will be summed approaches to enhance the quality of terminologies. 
The rest of the paper is organized as follows. Section 2 reviews related study. Sec-tion 3 gives an overview about the process of terminology extraction based on graph mutual reinforcement ( GMR-based TE ). Section 4 describes the proposed paper method to evaluate terms in Section 5. Experiment results are discussed in Section 6. Finally, we conclude our work in Section 7. To accommodate the explicit demand and implicit requirement of domain terminol-Terminology extraction is defined as the task of extracting domain terminologies from steps: term selection and term evaluation [8]. (1) Term Selection matic term extraction methods have been widely studied in the past few years [9]. quency, TFIDF, word co-occurrences and n-gram, etc. (2) Term Evaluation After the selection step, each extracted term will be assigned with a score calculated nally, the top candidate terms will be recommended. 
There are two existing types of feature to evaluate terms: unithood-based tech-niques and termhood-based ones [10]. Unithood considers the integrity of a term and measures it through the attachment strength of its constituent, while termhood empha-draw the conclusion that which one performs better. 
Most research on domain term extraction takes advantage of machine learning reinforcement based on bootstrapping to sorts candidate terms and patterns, and learn terminology extraction has been recently studied in [3], which has achieved promising results. The approach utilizes the manually labeled training data to train a SVM clas-sources. and authors. If we apply the general link analysis algorithms to the conference-paper-author graph, the ranking result will be unreasonable [7], e.g. the larger the number of authors is, the more important the paper will be. 
To avoid these potential disadvantages, we propose a novel approach that based on method does not require a training set, and can be extended to other domains. Figure 1 shows the procedure of GMR-based TE method. We carry out our approach candidate terms are extracted from corpus by some statistical methods. In the second sider the top ranked candidates as domain terms. (1)Term Selection To prepare for the dataset, domain conference papers are crawled from the web. We restrict them. (2) Term Evaluation tained, we calculate the score of each term by combining the ranking scores of papers Section 5. forcement. The section starts with the description of the ranking problem in the con-ference-paper-author graph, followed by the definition of transition probability in the problem, and finished with the process of ranking algorithm. 4.1 Problem Representation papers and conferences in the domain proceedings as a tripartite graph: where Author , Paper and Conf represent the author set, the paper set and the confer-Paper to Conf , respectively. Figure 2 is an illustration of the graph. 
It X  X  evident that any vertices in the same set are disjoint but may be adjacent to the vertices in the other two sets. For example, an edge that connects a conference and a edge that connects an author and a paper represents the author has written the paper. The tripartite graph can be easily built up from a corpus of conference proceedings. 4.2 Transition Probability thors, from conferences to papers and from papers to conferences. (1) From Authors to Papers ability from author a i to paper p j . makes the importance of p j unusually high if p j has lots of authors. paper p j , the transition probability from a i to p j is calculated via: 
After normalization, for each column of T AP , the sum of all the probabilities in the tance of authors, rather than the number of authors. represents the transition probability matrix T AP generated by the above method. (2) From Papers to Authors m  X  n matrix, T by a binary function: 
Figure 3(c) shows the transition probability matrix T PA using this function. (3) From Conferences to Papers pers are given just the same as the one in function (3). (4) From Papers to Conferences transition probability is normalized so that every column in T PC sums to 1. 4.3 Paper Ranking higher than p 2 . This is similar to authors and conferences. Without loss of generality, we propose three assumptions: the corresponding authors are important. and the conferences of these papers are important. Assumption 3. If a paper is important, the authors who wrote it are important and the conference that accepts it is important. although paper p 1 and paper p 3 do not share a common author, VI can be propagated from a 3 to p 3 . Let Rank(Conf) denote the domain conference ranking vector. Each entry in conferences in the seed set S , which equal 1. 
There are 4 steps in each iteration (see Figure 2). At the end of each iteration, the ranking list of papers, authors and conferences will be updated as the VI changes. pers. The scores of conferences will be propagated to their papers with certain transi-tion probabilities at time 1. So we adjust Rank(Paper) as: where C  X  (0,1) is the damping factor which controls the downwards, the contribution from longer path of other vertices. Step 2: The ranking list of authors will have an effect on the ranking list of papers. the more important its authors will be. So we update Rank(Author) as follows: 
Step 3: As mentioned in Assumption 2 , a paper X  X  VI will also be affected by the au-thor writing it. Authors of higher ranks will have more important papers comparatively. date Rank(Conf) as follows: 
The impact of each step will be weakened gradually as the time goes. At the end of each iteration, we introduce a normalizing factor that makes all the entries of the rank-and conferences tend to be convergent. In summary, we propose the APCRanking algorithm to rank papers as follows. The algorithm takes the linkage of authors, papers and conferences as well as the seed set as the input, and produces the ranking values of papers. 
Algorithm: APCRanking begin Build T AP , T PA , T CP and T PC as mentioned in 4.2 Initial Rank 0 (Conf) according to seed set S repeat Rank n (Paper)  X  C X Rank n-1 (Conf) X T CP Rank n (Author)  X  C X Rank n-1 (Paper) X T PA Rank n (Paper)  X  C X Rank n-1 (Author) X T AP Rank n (Conf)  X  C X Rank n-1 (Paper) X T PC n  X  n+1 until  X  &lt;  X  return Rank n (Paper) end the number of iterations. terminologies appear in them. For example, a terminologies t 1 is more important than t from papers can be formulated as: dividing the number of all papers by the number of papers containing t i : wards multi-word terms. One of the most effective approaches that can handle nested proach which can extract nested multi-word terms from English corpus by combining linguistic and statistical information together. The C-value of term a is computed as: candidate terms. 
In GMR-based TE method, we pre-compute Rank(Paper) off-line using the method mentioned in Section 4. Once the task of paper ranking is done, we can evalu-ate candidates by combining the impact of paper, IDF and C-value together via: 6.1 Data Preparation papers from the top-100 conferences in Database domain collected from Libra 1 . Each conference paper contains title, abstract, keywords, conference, authors, etc. cluded in the stop word list are filtered first. Only the terms that have appeared above terms as the candidate terms. 6.2 Evaluation of Paper Ranking terms, the result of paper ranking is pivota l in the term evaluation procedure. Rather than evaluating the paper ranking result directly, we compare the conference ranking results generated in graph mutual reinforcement with several existing methods. This is papers will be propagated to conferences an d vice versa. If the conference ranking list is comparable to some known methods, it is obvious that the result of paper ranking is reasonable as well. 
We compare our result to other three meth ods, i.e. EIC [14], NUS [15] and IRank GMR-based TE, there is a big gap between the top-3 conferences (SIGMOD, VLDB and ICDE) and others, which is consistent with reality. 6.3 Comparison with Other Methods Terms [16]. We use HITS in the bipartite graph of papers and terms. In HITS algorithm, each vertex is assigned an authority value and a hub value. A good paper is a hub that contains many terms, and a good term is an authority that appears in many hub papers. The other method considers a session as several terms conducted in a special form, and extract 10,319 domain terms from them using this method. In each method, we rank all the candidates in descending order of assigned scores and select top-N as terminologies. 
Not having a complete list of terminologies of database on hand, we cannot evalu-ate GMR-based TE through a common benchmark. Instead of constructing a domain the voting of other two. We consider one method is  X  X ood X  if its top-ranked terms are N list of GMR-based TE and HITS, the scores of both GMR-based TE and HITS will term and then average the score over all terms. The performance of the three methods We only evaluate the terms in the range of top-100 and top-1000, for the reason that the candidates selected as domain terms should not be too many. There are three features that affect performance of our approach, i.e. paper impact, IDF and C-value. Words that extracted in th e work [15] are taken as the golden stan-Nevertheless, there is no significant improvement by using IDF feature. Thus we need to determine the trade-off between the cost of algorithm and the possible loss of ter-minologies in practice. Table 2 shows the top-20 multi-word terminologies list generated by GMR-based TE method. we introduce a novel approach GMR-based TE, which applies mutual reinforcement Empirical results show that GMR-based TE outperforms several competitive meth-ods, and by using different features, GMR-based TE achieves the best performance. 
In conclusion, the contributions of the paper involve: through the graph mutual reinforcement. (2) An approach to extract and rank terminologies by combining the impact of pa-pers with several classical methods. (3) A strategy to compare the results of different methods without having manually labeled golden standard terms. This work was supported by the National Natural Science Foundation of China with Grant No. 60873017 and No. 60773215, and Scientific Research Fund of Renmin University of China with Grant No. 22382074. 
