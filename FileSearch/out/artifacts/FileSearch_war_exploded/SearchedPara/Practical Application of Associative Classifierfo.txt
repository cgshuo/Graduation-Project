 An associative classifier is a classifier usi ng classification rules that are produced through a frequent pattern mining process from a training data collection. This process is the same one used in traditional data mining for large log data of transactional database. Utilizing associative classifiers in the area of classification task [1,4,12] has a relatively short history compared to other classifiers such as Na  X   X ve Bayes, k-NN, or Support Vector Machine (SVM). It seems more difficult to find a study in which an associative classifier is applied in the text classification task.
 ability to provide abundant interpretation on the classification result is often as important as the ability to classify new documents exactly. Classification by a concrete form of rules ( X  Features  X  Class  X ) has many benefits including this easy interpretability. The associative classifier is one of the rule-based classifiers. In contrast, some classifiers such as SVM or Neural Network cannot provide this easy interpretation for the classification result, though they may achieve excellent classification accuracy.
 One is that since the rules can be expressed in a very intuitive form, humans can easily understand them and can even edit them directly after the rules are produced by some inductive learning process. A human expert could delete the weak rules from the original rule set and add new rules that they carefully handcrafted. This can improve the classification accuracy remarkably with a little bit of added effort. Another is that the rules can be updated incrementally by other machine learning processes later.
 information of more than one feature as well as a single feature, while SVM or k-NN classifiers consider only the effects of each single feature. This means that in document classification tasks it is possible to use phrase occurrence information as well as word occurrence information.
 real world, however, we need to remove several obstacles encountered during the training and testing phase. One of those is a high dimensional feature space. Dataset in the area of text classification, in many cases, has a very large num-ber of features that are distinct lexical words. For example, the 20-newsgroups test collection has more than one hundred thousand lexical word features. Most documents of the 20-newsgroups have more than one hundred words; they are sparsely distributed in their word feature space. In associative classification, however, we consider all subsets of those words. Therefore, the effective number of features grows exponentially, and we cannot take into account all of them due to computational intractability.
 niques at the same time maintaining necessary performance in classification. Many well-known methods of dimensionality reduction exist. We used the mu-tual information measure of the information theory. From the training dataset we calculated the mutual information between the word and the class variables. And we selected words that have high mutual information, and used only those in classifying and neglected the others.
 sification rules that are produced in the training phase. Since using all of them is both inefficient computationally and ineffective in classifying, we should select a part of those rules that have high quality. This process has been called Pruning in associative classification. Liu et al. [7] proposed pruning by database cover-age, which is a kind of validation process using the training set for the purpose of choosing the best classification rules among others. Li et al. [6] refined the concept of the database coverage.
 ranked rules in the confidence and the support of the rules. The other is to prune the rules in which the correlation between the pattern and the class variables is weak. In this paper, we adopted the pruning methods of Li et al. X  X  and modified them to work for text classification.
 using classification rules. With a large number of rules the prediction result of a test document often shows a split decision between different classes. A method is needed to select one correct class among many in an efficient and effective way. It is not a simple problem because if we extract a relatively small portion of rules to avoid having too many contradicting rules for a document, we might lose latent candidate classes that maybe the correct answer. To handle this problem, Li et al. [6] used the weighted chi-square method. We try to resolve this problem by simple voting on the different answer classes.
 Sect. 3 we explain the overall architecture of our text classification system using association rules and addressing the issues such as rule pruning and prediction from multiple rules. Experimental results and analysis of text classification using a large dataset are presented in Sect. 4, and we conclude our works in Sect. 5. 2.1 Association Rule Mining Associative rules originate from the market basket analysis in which we seek some pattern of purchasing. The term Mining indicates that we should apply much effort to searching the log database to acquire valuable information. a transaction log database of a large modern retailing market. We want to extract some pattern of co-purchasing of product items from this database. Let a set of product items be I = { I 1 , ..., I n } and a transaction t  X  I . Then the set of transaction T = { t 1 , ..., t N } X  2 I . An association rule is composed of two item sets called an antecedent and a consequent . The consequent often is restricted to containing a single item [11]. The rules typically are displayed with an arrow leading from the antecedent to the consequent: for example, { plums, lettuce, tomatoes } X  X  celery } . For an item set A and B , Support(A) is defined as the number of t including A divided by N ,and Confidence(A  X  B) as Support(A  X  B) / Support(A) . A user provides thresholds on the support and confidence of a rule denoted as minsup and minconf respec-tively.
 Definition 1 (Association Rule). Given an item set X and an item Y ,let s be Support(X  X  Y) and c be Confidence(X  X  Y). Then, the expression X  X  Y/ ( s, c ) is an association rule, if s  X  minsup and c  X  minconf.
 that we search some level of  X  X requent X  patterns. In the training phase of asso-ciative classification, the main task is to extract association rules, in other words, frequent pattern mining . Unfortunately, as the number of items grows linearly, the number of the antecedents in the left-hand side of (1) grows exponentially. Though we can reduce the size of the subset of patterns by the two parame-ters, minsup and minconf , the search often becomes computationally intractable when we use na  X   X ve methods. Many efficient algorithms were proposed to search frequent patterns more efficiently [1,4]. We modified the algorithm by Han et al. [4], the Frequent Pattern tree growth , and applied it when we mined frequent patterns. 2.2 Associative Classifier Consider the association rule in the view of a classification rule. Let A = {
A 1 , ..., A n } be a set of attribute domains, and a data object obj =( a 1 , ..., a n ) be a sequence of attribute values, i.e. a j  X  A j , 1  X  j  X  n . Given a pattern obj is said to match pattern P if and only if, for 1  X  j  X  k , obj has value a i j in attribute A i j .
 Definition 2 (Associative Classifier). Let C = { c 1 , ..., c m } be a set of class labels. An associative classifier is the mapping R from the set of attribute values to a set of class labels According to (2), given a test data obj =( a 1 , ..., a n ) , the associative classifier returns class label c  X  C .
 the form of R : P  X  c and have a training set T = { ( P i ,c i ) } , then the learning process is to induce the rule set R for which the element has the Suppot(P  X  c)  X  minsup and Confidence(P  X  c)  X  minconf . The procedure of associative classifi-cation rule mining is not much different f rom that of general association rule mining. One difference is that in associative classification rule mining, the infor-mation of the distribution of word patterns matching each class is additionally maintained.
 to assign a new test document. First, we search for the rules of which the pattern matches the document. Next, from these rules, we perform a prediction based on some predefined decision criterion. The details are explained in Sect. 3. 3.1 Overall Architecture The overall system architecture for associative classification is shown in Fig. 1. The left-hand side of the figure denotes the training process and the right-hand side the testing process.
 training. This is called Pre-processing . We index every word of training doc-uments and test it for the quality of its contribution to classifying exactly the given training documents. Each document is converted into a word-vector format and normalized to its length.
 rules. Because the initial number of rules is very large, we select a part of them and drop the remaining rules; this process is called Pruning . Finally, we construct a classification-rule database with these selected rules.
 of words and search the database for matching rules. With the rules matched, we decide which class the test document is assigned to. 3.2 Feature Selection We cannot use all of the words that appear in the training documents due to the computational complexity. Our goal is to minimize the number of features and at the same time not to lose classification performance compared with that we may acquire when we classify without any reduction of original word features. original feature set. In the area of document classification, two types of dimen-sionality reduction exist [10]. One is term selection where we select a subset of words from the original word set. The other is term extraction where we derive new features combining several original features; the extracted set of features has a lower dimension than the original one. Considering the characteristic of pattern mining, we decided to adopt the term selection method.
 quency or Mutual Information function. Document frequency is the number of the documents in which the word of our concern appears. In general, we se-lect the words of which the document frequency is higher than some threshold. Mutual information, an Information-Theoretic measure, is defined between two random variables and indicates a degree of information gain of one variable when we know the distribution of the other variable.
 class and the word random variables. By mutual information we can estimate the degree of contribution of a word in classifying documents of the given data collection. According to the distribution model of words in a document collection, the calculation of mutual information may differ slightly [9]. In this paper we adopted the document event model, in other words, the multivariate Bernoulli model in which the count of word appearance is calculated as binary rather than the real count of appearance in a document. Denote C as the random variable for the class label, and W t the random variable for the presence or absence of aword w t in a document. The average mutual information of W t with C [3] is defined as: where H ( C | W t )istheentropyof C given W t ,and f t  X  X  0 , 1 } is an indicator variable denoting the absence or presence of the word w t .And P ( c, f t )isthe joint probability , which is calculated as the number of word occurrences of word w t that also appear in documents with class label c , divided by the total number of word occurrences.
 the class variable among total N words. In general, we select the parameter M&lt;&lt;N .
 vector format that has M dimension. Moreover, since the length of each docu-ment has much variation, we should normalize the length of document in order to reduce some biases between the assigned classes as much as possible. In this paper, we introduced a parameter L indicating the maximum length of a doc-ument (by the length we mean the count of distinct words in it). We construct a transaction record with at most L words which are sorted in the order of descending average mutual information. 3.3 Pruning Rules It is not always helpful to have a large number of rules when we classify a new test document. There is a greater chance of having more than one rule contradicting each other in the answer class. In addition, the rules may over fit the training document set. We want to have a small number of the most powerful rules. In this pruning process, duplicate rules are eliminated and rules that might produce wrong classification results are removed. We perform two types of rule pruning; the first is pruning by rule ranking and the other is by the Chi-square statistic. rule-ranking criterion is as follows: (i) The rule with a higher confidence has a higher rank than others. (ii) If the confidences are the same between two rules, then the one with a higher support has a higher rank than the other. (iii) If the supports of the two are the same as well, then the one with the fewer number of words in the left-hand side of the rule has a higher rank. In other words, we prefer  X  X hort X  rules rather than long ones if other conditions are equal. The short length of the rules means general rules, while long rules are prone to over fit. Therefore, we can reduce the test errors by adopting more general rules. pattern mining process. The minsup and minconf of the rules were taken as 3 and 60% respectively. Rule-8 has the highest rank since its confidence is the best. Though rule-6 and rule-7 have the same confidence, rule-6 is ranked higher due to the higher support.
 rule-5 is more specific than rule-4 but has a lower confidence. However, rule-2 will not be pruned off because it has a higher confidence than the more general rule-1. We can see that the third ranking criterion reflects the generality. correlation information between two random variables. We want to evaluate the quality of a rule by calculating the Chi-square statistic of the pattern and the class label that are the left-hand and the r ight-hand side of the rule respectively. We can easily calculate the Chi-square statistic of each rule during frequent pattern mining. We denote the word pattern of a rule as P and the class label as c . Then, we present the number of the documents of the four possible cases in a box in Table 2.
 uments with the class label c . D denotes the number of the documents matching pattern P ,and E denotes the number labeled with class c and matching pattern P . The values of all the other cells can be calculated using these four values. In addition, we need the expected values of the numbers of documents in the four cells located at the center of the table. We can easily calculate these values as well using the ratios of the values of the marginal column and row. Finally, the statistic is calculated as follows: where i denotes the index of four center cells in the table.
 Chi-square statistic. According to some significance level, we decide whether we selecttheruleornot. 3.4 Prediction with Multiple Classification Rules After the training process is finished, we obtain a final set of classification rules. In general, when we predict the class of a test document, we seek the rules matching the document and the system produces more than one rule to classify. Sometimes, the number of the matching rules is large, which may lead to a difficult situation. If all of the rules have identical class labels, the problem is simple; we assign that class to the document. But if we have many different classes from the extracted rules, we need to decide on one rule as the correct one.
 as matched rules of a test document. We have a split decision between class A and class C . According to the rule ranking criteria, we would select C as an answer class. However, inspecting more deeply, though the confidence of rule-2 is slightly better than the other two, the support values of the two are much higher than that of rule-2. Therefore, we know that we cannot always reliably select rule-2 as a correct answer.
 ranking system. We adopt the majority-voting method in deciding on a correct class from multiple classification rules for a test document. Assume that we have K rules which are matched to a test document and of the form of R k : P i  X  c j for 1  X  k  X  K where c j is an element of the set of the class labels of the k -th we select the class label  X  c such that: We performed some experiments of associative classification using the 20 News-groups document collection [5]. This collection is slightly multi-labeled; 541 doc-uments of the total 19,997 documents are posted to more than one newsgroup. the BOW toolkit [8]. We removed general stop words, but did no stemming. During the training process, we included only the body part and the Subject line of the articles because other parts may contain the words that may indicate the answer class directly. We reduced the dimension of word feature space of the original 20 Newsgroups to three thousands, which was originally over one hundred thousand. In Table 3, we list the words with the highest average mutual information. We normalized the length of the training documents so that they cannot contain over a certain number of words.
 on a Linux machine with a 2.2 GHz CPU and 2 GBytes of memory. The best classification results are shown in Table 4.
 current state-of-the-art research [2,13]. However, some classes show equal to or higher accuracy than those of the state-of-the-art systems. At the last column of Table 4, we show the potential accuracy that we acquired by considering the second and the third majority classes as answers as well as the first one. This fact shows that there is a big room for some improvement in the future. In addition, since the rules are expressed in th e intuitive form of word strings (refer to (2)), we can manually edit the rules and improve the classification accuracy with little effort. For example, we may add the words listed in Table 3 that could best represent the target class. This is important in a practical application of the classifier since the real performance can be varied with the characteristic of the domain and the test data.
 minutes. This is remarkable compared to the case of SVM or even Na  X   X ve-Bayesian classifiers. Let the maximum length of a document be L , the size of the selected word features M , and the number of the whole words in the training collection N . In general, we take these parameters as L&lt;&lt;M&lt;&lt;N . The time complex-ity in the training using the whole words is O (2 N ). But our training time in this paper is O (2 L ), which becomes much shorter due to the reduced dimension. In the cases of SVM, the complexity is O ( N 2 ).
 the overall accuracy. The more rules we have the higher accuracy we can achieve. However, as the number of rules increase, the classification time is increased as well. In addition, an effect of overfitting appears.
 of the classifier as well as slows the prediction process due to the longer rule matching time. If the document length L gets larger, we have more rules to classify with. Figure 3 represents the number of rules in relation to the document length L .
 associative classification. We should improve the classification performance while avoiding the increase in the number of features and hence the increase in the computational complexity. Associative classification is a new method in the area of document classification. The expression of the rule is easy and huma n-readable. Therefore, it presents an excellent interpretation on the classification result as well as considerable effec-tiveness. In addition, the construction of the classification framework is simple, and the training time of the classifier is very short. By performing the classifi-cation experiment on the large data collection, we showed that this associative classification framework could be well applied to real world applications. some areas for improvement. We plan to study in depth the feature selection method so that we can acquire satisfactory accuracy in classification. In addition, a more elaborate rule-pruning method is required. It will also helpful to improve the classification accuracy.
 This research was supported by BK21 program of Korea Ministry of Education and the grant No. R01-2003-000-10181-0 from the basic research program of the KOSEF (Korea Science and Engineering Foundation).

