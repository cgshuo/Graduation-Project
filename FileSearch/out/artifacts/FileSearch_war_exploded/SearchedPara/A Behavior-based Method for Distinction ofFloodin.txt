 Flooding Distributed Denial of Service (DDoS) attacks have been wreaking havoc on the Internet and no signs show the trend of fading [1]. What is worse, DDoS start to simulate the behaviors of normal users and hidden in the traffic of Flash Crowds (FC)[2] in order to avoid the detecting by defending systems.
 iors, therefore, it can be used to detect anomalies by modeling legitimate users behaviors. Xie et al. [3] proposed a novel method to detect anomaly events based on the hidden Markov model. This approach used the entropy of document pop-ularity as the input feature to establish model. But the input parameters are difficult to achieve through training. Oikonomou et al. [4] tried to discriminate mimicking attacks from real flash crowds by modeling human behavior. Howev-er, it is difficult to be employed for large-scale dynamic web pages. Theerasak et al. [5] proposed a discriminating method based on the packet arrival patterns. Pearson X  X  correlation coefficient was used to measure the packet patterns. Pat-terns are defined by using the repeated properties observed from the traffic flow and also calculated the packet delay. However, defining the packet patterns are difficult. Yu et al. [6] employed flow similarities to discriminate DDoS and FC and achieved a better effect. The author mainly used fixed thresholds needed craft design and professional field knowledge, so this would be little deficiencies for deploying it in practice. Saravanan et al. [7] found that during FC, human users always tried to access hot pages, but in contrast, Bots accessed pages ran-domly. It could be helpful for differentiating between DDoS and FC to some extent. Although the approach combined multi-parameters with weights to dis-criminate DDoS and FC, and achieved better results than the single parameter. Those weights were fixed and could not be updated automatically.
 and abnormal ones before years. However, the development of Reverse Turing Test makes the hacker could identify the pictures more easily without the par-ticipation in humans [8], which means Turing Test could not defend DDoS and distinguish DDoS and FC in a good way any more. Although, various methods have been proposed to detect and defend DDoS, however, there are still few researches on distinguishing Flooding DDoS and FC and there are also some deficiencies of the existing methods. In response to the above case, we propose a method of behavior analysis to solve this issue, which is not impacted by network environments, both of wired networks and wireless networks could employ it to distinguish DDoS and FC.
 rizes the features to depict the differences of two behaviors as well as detailed statement of the proposed solutions in this paper. Section 3 furthers evaluation of the proposed method as well as the analysis and comparison with traditional methods-Entropy. Section 4 is the summary of this paper. 2.1 Behavior Vector In order to solve the problem of discrimination of DDoS and FC, a few assump-tions should be considered. In this paper, our assumption is that: the number of Bots simultaneously launched attacks (active Bots) have a limitation and usually do no more than the number of legitimate clients. Otherwise, it is impossible to distinguish Bots and legitimate users by statistical approaches, according to the authors X  researches [6].
 resents time interval (  X  X  j ,j = 1 , 2 ,... ), while y-axis represents the packet size ( p i ,i = 1 , 2 ,... ) sent by each client. (  X t k ,k = 1 , 2 ,... ) represents the packets ar-rival time between two packets sent by each client. In each interval  X  X  j , it may contain DDoS and FC at the same time, or it contains one traffic type-DDoS or FC. Due to DDoS mainly derive from Botnets and Bots are controlled by pre-programmed codes, it leads the packets arrival time between two packets (  X t k ) sent by each Bot will be unchanged too much and the packet size ( p i ) follows the same pattern, it also has a stable packet size, while those patterns are totally different to FC caused by legitimate users, which sent packets at random, so the  X t i and p i are changeable. On the other hand, Bots have to send packets as many as they can so as to attain the anticipated effect. Therefore, a few traffic anomalies would be caused, which plays a major role in distinguishing DDoS and FC. In order to define the traffic behavior of each Bot or client, we proposed a concept called Behavior Vector.
 which have the same source and destination IP as one flow, calculate the related statistical features, such as packets X  size, packet arrival time difference, and label the behavior class: normal or abnormal, according to the priori knowledge. All of those could be used to make up of Behavior Vector: The first three features are used to locate the attack time, the attack Bot and the victim, the latter five features and the classified label are used for analysis and evaluation of our method. Based on the above-mentioned assumption, the number of active Bots is limit, so Bots have to spend packets as many as they can in order to attain the expected attack effect. Therefore, the number of packets sent by each Bot will larger than that of each legitimate user. where, n is the total number of unqiue IPs or clients in each interval. m i is the total number of packets sent by the ith IP or client in the interval, 0 &lt; i  X  n . ktsSize): DDoS mainly derived from Botnets, which usually launch attacks by compromised hosts with pre-programmed codes, so there are more similar be-haviors between Bots. While FC derived from legitimate users and they always have their own targets of visit, therefore, each user will have a different behavior and the size of packet is randomized. As a result, the average packet size of each Bot and that of legitimate user will be different. where, pktsSize ij : the jth packet size sent by the ith IP or client in an precise time point. Interval (stdPktsSize). Based on the above-mentioned assumption, the number of active Bots is limited. Bots have to spend packets as many as they can in order to attain the anticipated attack effect. And those Bots are controlled by pre-programmed codes to send packets. Therefore, the standard deviation of the packet size between each Bots will be much smaller than that of legitimate user. That means the similarities of packets size send by Bots are higher than that of legitimate users. stdPktsSize = { stdPktsSize i = where, stdPktsSize i : the standard deviation of packet size sent by the ith IP or client in an interval. Source IP In Each Interval (uArrivalTime): the reason like  X  X PktsSize X . where, uArrivalTime i : the average of packet arrival time of packets sent by the ith IP or client in an interval. arrivalTime ij : the jth adjacent packet arrival time difference by the ith IP or client sent. By Each Source IP In Each Interval (stdArrivalTime): the reason like  X  X tdPkts-Size X . stdArrivalTime = { stdArrivalTime i = where, stdArrivalTime i : the standard deviation of packet arrival time difference of packts sent by the ith IP or client in an interval. Vector into one class: DDoS Flow , which represents the Bot Flow; FC Flow , which represents the legitimate user flow. It can be achieved according to the priori knowledge for real traces. 2.2 Proposed Idea In this paper, we will evaluate our method on two public datasets. However, there are some difficulties for different datasets to mix. In general, different datasets are usually derived from different situations, such as different topology structure, different network bandwidth. In order to conquer those dilemmas and obtain the feature set, we do some pre-processings as follows to eliminate the existing difficulties: in each dataset. In order to solve this issue, we apply relevant statistical features instead of using IPs directly. at different bandwidths. In order to cope with this issue, we scale the interval to ensure that different datasets have the same network bandwidth in each interval on the whole. For example, assuming that the bandwidth of first dataset is 10M/s, while the second dataset is 100M/s. In order to achieve the same traffic volume in each interval-2s, we enlarge the first dataset to be 100M/s, that means to increase 100/10(ten) times of the first interval. In other words, if we assume the minimum interval to be 2s and the interval of the second dataset is 2s, then the interval of the first dataset is (100/10)*2=20s. We believe that the impact of the network bandwidth is minimized through the scaling.
 extract behavior features to evluate our method further. Based on Behavior Vector, we could map the traffic behavior of each Bot and legitimate user into points in Euclid space and lots of methods have been proposed to measure points, so we could translate the issue of distinguishing DDoS and FC into how to identify abnormal points-outliers in Euclid space. What X  X  more, we propose an idea employed Random Forest [9], which is an excellent and efficient Data Mining method, to classify abnormal points and normal points, that is to distinguish DDoS and FC. The whole procedure can be shown in Alg. 1 directly. Algorithm 1 Proposed Idea.
 In this section, we do some experiments to estimate Behavior Vector and the idea proposed on two public real-world datasets: CAIDA  X  X DoS Attack 2007 X  Dataset (CAIDA 2007 Dataset) [10] used as the DDoS data and World Cup 1998 Dataset (WC 1998 Dataset) [11] used as the FC data.
 2007-08-05 05:31:00-from CAIDA 2007 Dataset, in which the sent packet rate is about 18000 packets per second and there are a few noises in this 1 minute. Due to no additional information can achieved from CAIDA 2007 Dataset, the reason of noises produced is not clear. And select 1 hour FC data-1998-06-10 16:00:00 to 1998-06-10 17:00:00-from WC 1998 Dataset, the client request rate is about 2000 requests per second.
 FC, so we could not achieve statistical features without any pre-processings. And by the analysis of datasets pre-processings in Section 2, we should enlarge the FC interval to eliminate the effect of bandwidth. In this paper, we employ the minimal interval  X  t is 1s and after analyzed the selected data, we can find when the FC interval scale is 100 times of the DDoS interval, they will have the nearly same traffic in each interval, so we choose the scale 100. After pre-processings, the traffic per second of Bots produced in DDoS basically has the same as legitimate users produced in FC. Then, we calculate on each scaled dataset to achieve the features required and label the behavior Class-DDoS Flow or FC Flow in each interval to achieve Behavior Vector, more details can be seen in section 2. And we mix the vectors and do normalization to wipe out the effect of different scale of each feature. Finally, we could achieve input data for the latter process. 3.1 Behavior Features Estimated Once achieved the input data, we should firstly make selection of features to eliminate the redundancy because we could not assure that all the latter five features in Behavior Vector are necessary and there are not any redundancy between features. To solve this problem, we adopt Pearson X  X  Correlation Method (CorrelationAttributeEval), Gain Ratio Method (GainRatioAttributeEval) and Symmetrical Uncertainty Attribute Method (SymmetricalUncertAttributeEval) to make evaluation of features.
 of each feature (the higher, the more important) and the Rank represents the ranking value of each feature. It can be seen that the first two feature selection methods demonstrate that uPktsSize is the most important of all, while uPkts is the least important of all. It is basically consistent with our expectation, there are more similar behaviors between Bots which are controlled by the attacker with pre-defined codes in DDoS, rather than that of legitimate users in FC. And according to the Tab. 1, we could conclude that the order of importance of whole features is as follows: features with the sequence of features X  importance to find which combination is the most optimal one, and all of the combinations are as follows in Tab. 2. results can be seen in Tab. 3, which shows that the more features are combined, the more accuracy can be achieved. However, as the increasing of the number of the features, the more complexity of calculation it will take and will not achieve obvious performance improvement. Finally, we found that the combination 2 is the optimal one with high accuracy and less complexity of calculation, therefore, we use it as the input data for the evaluation of method in the future. 3.2 Proposed Idea Estimated In order to fully evaluate our method, we divide the 1 minute DDoS data into different scales by sampling technique. According to attack strength, it refers to the rate of packet sent by each Bot in each interval, while the 1 hour FC data keep unchanged. The more details of average traffic under different attack strength are shown in Tab. 4. In each sampled data, the number of Bots is kept unchanged, the only change is the amounts of traffic produced by Bots, that is the attack strength, which have become bigger with different scales from 10% to 100% by sample. Finally, when the sampled scale is 100%, it means to use the whole 1 minute DDoS data to analyze. The amount of traffic by Bots launched in DDoS is basically equal to the amount of traffic by legitimate users produced in FC.
 Accuracy, TPR and FPR all together as measure standards to evaluate the trained model and the estimated result can be seen in Tab. 5 which shows that the different sampled scales will affect the discriminated result, it means attack strength play a vital role to distinguish DDoS and FC. The more attack strength, the better discriminated accuracy, this is reasonable in the real environment. The reason is that more attack strength will lead to more obvious traffic abnormal-ities, which will enlarge the difference of different behavior between Bots and legitimate clients. However, there are a little bit difference of our results. The reason is that we sample on the DDoS data which has some noises [10] by differ-ent scales, the bigger sample rate is, the more noises will bring in. As a result, the discriminated result will have a slight change, but it will not cause a huge impact on our idea.
 iments by using another test set, 1 minute DDoS test data-2007-08-05 05:34:00 to 2007-08-05 05:35:00-randomly selected from the CAIDA 2007 Dataset and 1 hour FC test data-1998-07-03 16:00:00 To 1998-07-03 17:00:00-came from the Quarter of WC 1998 Dataset to test our trained model based on the previous train datasets.
 eliminate the impact of different dataset like the previous pre-processings-scaling the interval. After analyzed the new dataset, we could find that when the FC interval scale is 80 times of the DDoS interval, they will have almost the same traffic in each interval. So we choose the scale size is 80 and the scaled result shows that the traffic per second of DDoS is basically the same as that of FC. Based on the dataset, we extract features and use the fitted model to evaluate our method further.
 obtain more than 95.000% accuracy, further with less FPR around 0.005%and FNR around 5.000%. In addition, we use the whole features-the combination 5-to further evaluation, the result also shows the high accuracy, which means our method could also have a good effect on the new dataset.
 3.3 Experiments Analysis Why could our idea locate the precise Bot and achieve higher accuracy? After an extensive analysis of experiments, we conclude the reasons for that are at-tributed to the following aspects: First of all, we take an extensive analysis of the traffic behavior of Bots and legitimate users and conclude a new feature set to form Behavior Vector which could profile the behavior of Bots and legitimate users well and It really plays a vital role in distinguishing legitimate users and Bots. What X  X  more, we employed Data Mining to distinguish DDoS and FC, which have advantages, such as, good detecting performance and good flexible, compared with the traditional method-Entropy. In addition, once the result i-dentified attack flow, we could use the first features of Behavior Vector to locate the time of attack, the Bot and victims.
 with traditional methods. Yu et al. [12] made use of information distance, such as Sibson distance measure, Jeffrey distance measure, to discriminate DDoS and FC, which only have 65% accuracy. Bhatia et al. [13] proposed parameters to distinguish DDoS and FC, there are not any accuracy. Saravanan et al. [7] employed behavior-based detection of application layer DDoS during FC, which have 91% accuracy, all of those methods do not have higher accuracy than that of our method. In order to compare with traditional methods further, we take another experiment on the test dataset with Shannon Entropy, which is a classic and common method. With the following formula, we calculate the value of Shannon Entropy of srcIPs in each interval on the test dataset.
 indicates that it is not easy to distinguish DDoS and FC based on Shannon En-tropy of srcIPs, because their entropy values are very close, so it is very difficult to select proper thresholds to distinguish each other.
 tional methods are mainly based on thresholds which usually need to be selected elaborately but are considerably difficult to be obtained in reality. Our idea em-ployed Random Forest which could avoid the selection of thresholds in a good way. It could adjust the value of threshold flexibly but basically need no human interventions and could achieve better accuracy for distinguishing DDoS and FC. Furthermore, the Behavior Vector we proposed could also locate precisely the Bot participating attacks and time of attack and the victims with the first features of Behavior Vector. In addition, our idea is deployed on end-victim, therefore, it is easy to deploy without modifying the existing network protocols, just to deploy at the front of end-victim. In this paper, an extensive analysis is made into two widely-used datasets and a new feature set is concluded to form Behavior Vector, which is used to profile the traffic behavior of each Bot and legitimate user. Based on it, experiments have been taken to evaluate our method of distinguishing DDoS and FC. The results show that our idea could achieve high accuracy, less FPR and FNR. In addition, compared with the Entropy-based method, the results also indicate that our method can achieve not only better accuracy, but also can locate the Bot, the time of attack and victims by the first features of Behavior Vector. [1] Steve Mansfield-Devine. The growth and evolution of ddos. Network Secu-[2] Jaeyeon Jung, Balachander Krishnamurthy, and Michael Rabinovich. Flash [3] Yi Xie and Shun-Zheng Yu. A large-scale hidden semi-markov model for [4] Georgios Oikonomou and Jelena Mirkovic. Modeling human behavior for [5] Theerasak Thapngam, Shui Yu, Wanlei Zhou, and Gleb Beliakov. Discrimi-[6] Shui Yu, Song Guo, and Ivan Stojmenovic. Fool me if you can: mimicking [7] Renukadevi Saravanan, Saraswathi Shanmuganathan, and Yogesh [8] Greg Mori and Jitendra Malik. Recognizing objects in adversarial clutter: [9] Leo Breiman. Random forests. Machine learning , 45(1):5 X 32, 2001. [10] CAIDA  X  X DoS Attack 2007 X  Dataset. http://www.caida.org/data/ [11] World Cup 1998 dataset. http://ita.ee.lbl.gov/html/contrib/ [12] Shui Yu, Theerasak Thapngam, Jianwen Liu, Su Wei, and Wanlei Zhou. [13] Sajal Bhatia, George Mohay, Alan Tickle, and Ejaz Ahmed. Parametric
