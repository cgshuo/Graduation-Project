 Supporting conversational approaches in mobile recommender systems is challenging because of the inherent limitations of mobile devices and the dependence of produced recommendations on the context. In a previous wo rk, we proposed a critique-based mobile recommendation approach and presented the results of a live users evaluation. Live-user evaluations are expensive and there we could not compare different system variants to check all our research hypotheses. In this paper, we present an innovative simulation methodology and its use in the comparison of different user-query representation approaches. Our simulation test procedure replays off-line, against different system variants, interactions recorded in the live-us er evaluation. The results of the simulation tests show that the composite query representation, which employs both logical and si milarity queries, does improve the recommendation performance over a representation using either a logical or a similarity query. H.5.2 [ Information Interfaces and Presentation ]: User Interfaces  X  Graphical user interfaces (GUI), Evaluation/methodology Design, Experimenta tion, Human Factors Critiquing, mobile recommender sy stems, query representation, simulation test When searching for products and services, e-commerce web sites users are often overwhelmed by the number of options to consider. Hence they need some system support to filter out irrelevant products, compare candi dates, and select the best one(s). Recommender Systems (R Ss) are decision support tools that solve this information overload problem, by suggesting products and services personali zed to the user X  X  needs and preferences at her particular context. A research direction in the RSs field, that has received much attention, is conversational RSs. In these systems the user gets her desired items through a stru ctured human-computer dialogue [13]. Critique-based RSs are conversational RSs which, at each interaction cycle, interleave th e system X  X  product proposals with the user X  X  critiques to the proposed pr oducts [12, 2, 9, 5, 10, 6, 4, 7, 11, 3]. The user makes a critique to a recommended item when either a feature of the item does not satisfy the user or when she wants to emphasize that it is very important to her. A user's critique, for instance, may specify an unsatisfied preference, such as  X  X  want a restaurant cheaper than this X , or confirm an important preference, such as  X  X  prefer to rent a room with private bathroom X . There have recently been an increasing number of mobile RSs introduced in the literature [14, 5, 16, 15, 11]. In practice, designing an effective and usable mobile RS requires the recommendation methodology to ove rcome obstacles typically present in the mobile usage environment (e.g., smaller screens and limited input modalities) and to be suitable for mobile users' behavior. In our previous paper [11], we have presented a critique-based mobile RS that, to make user in teraction simple and fast, supports a very limited input of explicit user preferences through system questions and is mostly ba sed on critiques. When making critiques, the user also assigns th e strength (i.e., wish or must) of the expressed preference, which helps the system correctly exploit the user X  X  critique. To produce relevant recommendations, the system integrates both long-te rm and session-specific user preferences, employs a composite query representation, and exploits many sources of user related information [8]. The proposed recommendation methodology has been implemented in MobyRek, a mobile phone on-tour RS that assists on-the-go users in searching for travel produc ts (restaurant). MobyRek was evaluated with real users w ith respect to: usability (i.e., functionality, efficiency, and convenience), recommendation quality, and overall user satisfaction [11]. The objective and subjective results of the on-lin e evaluation showed that our recommendation methodology is effective in supporting on-the-go users in making product choice decisions. However, in the on-line evaluati on we could not test different system variants that employ di fferent user-query representation approaches. In particular, we would like to understand whether or not our composite user-query representation approach, which employs both logical and similarity query components, results in a better recommendation perform ance (interaction length and percentage of successful sessions) against other approaches that employs an individual query re presentation based on either logical filtering or similarity-based retrieval. If being tested in the on-line evaluation, this check-e xperiment would have required test users to use and evaluate different system variants implementing the alternative que ry models. This would have required them to spend much mo re time and effort, and would have limited the number of variants that we could compare. This is a general problem for empirical system evaluation. Therefore, we decided to design a simulati on methodology that could benefit from the interaction logs collected in the live-user test and replay such interactions with systems (slightly) different from that used in the live-user evaluation. In this paper, we describe the proposed simulation test procedure and how it has been used to validate the hypothesized advantage of a hybrid (logical and simila rity-based) query model. The simulation test procedure takes as input a dataset that comprises a historical series of recommendation sessions, where each session contains a historical sequence of user critiques. In other words, recommendation sessions, and user critiques in a session as well, are replayed in the simulation in the original order, instead of being simulated randomly. In summary, the paper makes the following contributions. The remainder of the paper is organized as follows. Section 2 discusses the product representation and the user preferences model, followed by the description of the recommendation process. The hypothesis on the use r-query representation is posed and discussed in section 3. In s ection 4, we discuss the proposed simulation procedure, apply it to test the posed hypothesis, and discuss on the observed results. In section 5, we recall the off-line evaluation approaches introduced in previous research in critique-based RSs. Finally, the conclusi ons are given in Section 6. In this section we shall briefl y recall our proposed critique-based mobile recommendation methodology , first describing the product representation and the user preferences model and then presenting how the system produces personalized product recommendations for on-the-go users [11]. A product is represented as a feature vector x= (x where a feature value x i can be numeric, nominal, or a set of nominal values. For instance, the representation of the restaurant x= (Trittico, 79, {pizzeria}, 10, {air-conditioned, parking}, {7, ( x ) is pizzeria, the average cost ( x 4 ) is 10 euros, the characteristics ( x 5 ) are air conditioned and parking, the days open ( x ) are Saturday and Sunday, and the accepted method of payment ( x 7 ) is credit card. To generate personalized recommendations, a recommender system needs a representation of the user's preferences. Preferences vary from user to user, and even from situation, i.e., context, to situation for the same user. In our approach, the user preferences model includes both contextual (e.g., space-time constraints) and product-feature (e.g., air conditioned) preferences, and incorporates bot h long-term (e.g., a preference on non-smoking room) and session-specific (e.g., a wish to eat a pizza) user preferences [8, 11]. Though the specification of initial preferences (i.e., at start-up) is supported, and optional, for users, session-specific preferences are acquired mainly through the user X  X  critiques collected dur ing the recommendation session. In a recommendation session, the user's preferences are encoded in the system X  X  user query re presentation which is used to compute the recommendation list. In our approach, the user query representation q consists of three components, q= (Q L For example, the query &lt; Q L =(x p=(?,?,{pizzeria},?,?,?,?) ; w=(0,0,0.4,0.6,0,0,0) &gt; models a user who looks for restaurants within 1 km from her position that are open on Saturday and Sunday and pr efers pizzeria restaurants. For the user the cost is most important, followed by the restaurant type, and he is indifferent to the other features. A recommendation session begins when a mobile user asks the system for a product suggestion, a nd it ends when the user selects a product or she quits the session with no selection. A recommendation session evolves in cycles. At a recommendation cycle, the system shows the recommended products (see Figure 1b) that the user can browse to see the product details and make critiques (see Figure 1c,d). After th e user has expressed a critique, the critique is exploited by the system to compute a new recommendation list that is showed to the user in the next cycle. In an overview, a recommendati on session is logically divided into three phases: initialization, interaction and adaptation, and retaining. At start-up, the user is offered with three options for the search initialization (see Figure 1a). recommendation list; (c)-Critique on a numeric feature; (d): Having the user X  X  selected an initialization option the system integrates the user X  X  initial input and long-term preferences to build the initial search query and to initialize the case that models the current recommendation session [1]. This case representation, which is updated as the recommenda tion session evolves, consists of the following components. The system exploits multiple sources of the user-related knowledge to build the initial query representation (i.e., the SYS_INIT_REP case component), including a) the user X  X  contextual information, b) the us er X  X  previous selections, c) the past selections of the users, and d) the user X  X  stated initial preferences. Basically, the logical query Q L is initialized using the user X  X  space-time constraints and initial preferences stated as must. The favorite pattern p is initialized integrating the user X  X  long-term preferences pattern a nd initial preferences stated as wish. The feature weights w are initialized exploiting the history of the user X  X  interactions with the system. More details on the query representation initialization are presented in [8, 11]. The initial query representation is then used by the system to compute the first recommendation lis t. In the computation of a recommendation, the system first discards those products that do not satisfy the logical query component Q L and then ranks the remaining products according to their similarity to ( p , w )  X  the favorite pattern and the feature weights vector components. The more similar a product is to ( p , w ) the higher it appears in the ranked list. Similarity is comput ed as the difference between the maximum similarity value (=1) and the generalized weighted Euclidean distance between the product and ( p , w ). In the recommendation computation, if no products in the catalog satisfy the logical query Q L the system finds a minimum number of constraints that if discarded from Q L make it satisfiable. In this relaxation, a constraint involvi ng a less important feature is considered for relaxation befo re another involving a more important one (see [11] for more details). The relaxed constraints are then converted to wish conditions and incorporated in the favorite pattern p . When the recommended products list is showed to the user (see Figure 1b), three situations may occu r. In the first one, the user is satisfied with a product and selects it; the session ends successfully. In the second situation, the user is not satisfied with the recommended products and quits; the session terminates unsuccessfully. In the third situati on, the user is interested in a recommended product, but not comp letely satisfied with it. Hence, the user criticizes the product to further express his preferences. The user may, for example, make a critique to say that a product is too far from his position (see Figure 1c) or to state some interested features (see Figure 1d). When making a critique to a recommended product, the user also assigns the strength (i.e., must or wish) of th e expressed preference. This help the system correctly exploit the user X  X  critique. A critique stated as a must, incorporated in Q L , makes the system zoom in a certain region of the product space. A critique stated as a wish, incorporated in p , makes the system refine the ranked list. After the user makes a critique, the system interprets and incorporates the critique in the query representation (see [11], for more details). When a recommendation session ends, whether successfully or not, it is retained by the system as a case (see the case model discussed above). Hence, th e system can exploit past recommendation sessions in ma king new recommendations for the user, and other similar ones, in future [8, 11]. In traditional approaches, often employed in information retrieval systems, user X  X  preferences are represented by a (usually conjunctive) set of logical constraints [4, 12]. The advantage of this representation approach is that the produced results are easy to understand for users, since only those products satisfying the logical constraints are retrieved and shown to the user. However, the major disadvantage of such representation is that it is very difficult to recover from failing queries (i.e., whose execution returns an empty result set). In such a case, the system needs to repair the failing query. In other approaches based on si milarity retrieval, which is typically used in instance-based learning and case-based reasoning systems, user X  X  preferences are represented by a favorite feature vector [2, 5, 6, 7]. The advantage of this representation approach is that a similarity-based retrieval always returns a non-empty result set in th e form of ranked products list. However, a recommender system using this representation approach may show a user products violating some of her preferences, since the retrieved products may have the features similar, but not necessarily identical, to those in the favorite pattern. This may decrease the us er's confidence in the system. Moreover, this representation a pproach requires the system to scan all available products, which can be a heavy task, in terms of computational resource and time, if the size of the product database is large. We hypothesize that a user query representation integrating both logical and similarity queries can better reflect the user X  X  needs and preferences, and hence better support the recommendation process, benefiting from both i ndividual representations. In particular, the logical query co mponent allows the system to zoom in relevant and (much) smaller regions whereas the similarity one helps the system ra nk all the products in a relevant region according to their similarity to the user X  X  favorite pattern. However, this hypothesis must be empirically validated since the additional complexity of a co mposite query model may cause negative impacts on the transparency of the recommendation process and on the efficiency of the implementation of the retrieval algorithm. As mentioned in section 1, the MobyRek system was initially evaluated with real users, and the log data of this evaluation, consisting of fifteen successf ul recommendation sessions, was recorded. In this section we desc ribe how we have exploited the testers X  recommendation sessions in off-line simulations to check the hypothesis posed in section 3. In particular, we have introduced three MobyRek variants employing different query representations. In this section, we first descri be the simulation test procedure together with the supported criti que-simulation methods, and then discuss the results of the simulation tests that compare the three system variants regarding the recommendation performance. In the simulation tests, the three system variants  X  X eplayed X  the testers' recommendation sessions (i.e., those recorded in the live users X  evaluation). In particular, given a tester X  X  original session in the simulation the system used the initial query representation to compute the first recommendation list, and then re-applied, one by one in the original order, the tester X  X  critiques. In order to replay a recommendation session in a simulation, we had to define different ways of re-applying the user critiques. There are two major problems to consider. First, during a simulated session the system X  X  recommendation list (at each cycle) could be different from that observed in the live user X  X  session, and also the criticized product in the original session could be not present in the output list. Second, the user query representations employed by the two system variants repLQ and repFP are different from that employed by MobyRek in the live users evaluation. Because of these reasons, it is difficult to select a unique method for replaying the user critiques. Therefore, for each system variant we have tried different critique-simul ation methods. We have finally compared the system variants, measuring for each variant the result obtained with the best criti que-simulation methods (not to bias the evaluation towards any system variant). To illustrate the different critique-simulation methods, let X  X  assume a tester made the fo llowing critiques sequence in his recommendation session: and suppose that l=(l 1 ,...,l n ) is the product selected by the tester. In this example, the first critique was made to product x first in a list of twenty products) on feature f critique, and states that the distance from the user X  X  position to the restaurant must be less than 2000 meters. The second is a wish critique to product x 7 , which is ranked second in a twelve -product list. The critique is made on feature f 5 , and says that parking and smoking room are preferred. The third is a wish critique to product x 3 , which was ranked first in a list of twelve products. The critique is made on feature f 4 , and expresses a preference for a price of about 15 Euros. Five critique-simulation methods we re tried in the simulation. During a user X  X  recommendation session, at each cycle the user X  X  criticized product and the selected one provide the knowledge about the motivation and cause of the critique made at that cycle. Basically, in a replayed session the [rpt_ctz] and [sim_ctz] methods base the critique simulation on the products actually criticized by the test user or on those similar to them, whereas the remaining methods base the critique simulation on the tester X  X  selected product or those simila r to it. Table 1 describes the combinations of system variants and critique-simulation methods that we used. 
Table 1: The ten combinations of the three system variants We note that in the simulation te sts reported here we did not run each system variant with all five critique-simulation methods. The repMR system variant employed the same query representation approach that MobyRek had used in the on-line evaluation, and hence at each cycle in a simulated session the output list was the same as that produced in the original session. Therefore, for the repMR system variant repeating the critiques seem to be the most appropriate simulation method. We introduced the [full_val_sel] method, only for the repFP system variant, in order to support a previously proposed and popular simulation method [7] used in similarity-based retrieval systems, where all the feature values of the target item can be exploited to test the system X  X  retrieval performance. The three system variants, each employing a query representation approach and different criti que-simulation methods, were evaluated by the simulation test procedure shown in Figure 2. In this procedure, the first input parameter is a set of successful sessions (i.e., those ending with an item selection) collected in the live users evaluation. The second input parameter is view_size , i.e., the number of products in a recommendation list that the simulated user is supposed to look at (i.e., the top N products). For example, view_size equal to 10 means that the simulated user is supposed to analyze only the top 10 products in every recommendation list. At Step 1, given a tester X  X  recommendation session the simulated initial query representati on is built as follows. At Step 1, given a tester X  X  recommendation session the simulated critiques list is retrieved from the USER_CTZ_SEQ case component of the original session. For the [full_val_sel] critique-simulation method, the simulated critiques list is constructed by concatenating the tester X  X  critiques sequence and the values in the selected product for the features th at had not been criticized in the tester X  X  session. At Step 2, the simulated recommendation list is produced as follows. A simulated recommendation session terminates, at Step 3, if: At Step 4, one of the five cr itique-simulation me thods discussed above is applied to simulate a critique. The simulated critique is then used by the system to adapt the query representation. The adaptation rules depend on 1) what query representation approach is used and 2) what critique-s imulation method is applied. For the repMR system variant, the adaptation rules are exactly as defined in section 2.2. In partic ular, a critique stated as a must causes an update of the respective logical constraint in Q whereas a critique stated as a wish is used to update the respective favorite element in p . For the repLQ system variant. For the repFP system variant. Input Output num_of_succ  X  0; total_cycles  X  0; 
For each session s k in S End of For 
Return { num_of_succ , total_cycles /| S |} An analysis of the logs of the testers X  recommendation sessions showed that they made their critiques to, and selected, products ranked among the first eleven positions in the recommendation lists. Therefore, we tested the te n combinations shown in Table 1 for eleven view-window sizes, from 1 to 11. We present here the results obtained for the view-window size of 5, due to paper space limit and also because most of the testers limited their browsing to the top 5 items in recommendation lists. In Figure 3, we first look at the success rates of the system variants. The results show that repMR[rpt_ctz] has success rate 36.36% higher than repLQ[rpt_ctz] . repLQ[val_sel] tends to have the highest success rate for the repLQ variant, since this combination replays the critiques using the criticized features X  values in the selected product. When compared to repLQ[val_sel] , repMR[rpt_ctz] is still 36.36% higher with respect to the success rate. The main reason why the repLQ query-representation approach has a low success rate is because of the  X  X ailing queries X  probl em. When this happens, the simulated session is considered to fail. Figure 4: Comparison on the average recommendation length, The important advantage of the repLQ representation approach is that if it can converge to the selected product, the convergence is fast (i.e., the recommendation length is short). This can be observed in Figure 4, by comparing repMR[rpt_ctz] and repLQ[rpt_ctz] with respect to the average recommendation length. In particular, the average recommendation length of repMR[rpt_ctz] is 19.76% longer than that by repLQ[rpt_ctz] . This compensates for the increment in the success rate. Similar results can be observed when comparing repMR[rpt_ctz] to repLQ[sim_ctz] and repLQ[sim_sel] . We note that the simulated recommendation dialogues are rather simple, since the selected items can be found on average within two recommendation cycles. This average recommenda tion length is (much) shorter than those found in previous ev aluations of web critique-based RSs [3, 6, 7, 12]. The reason of th at difference is that on mobile devices users tend to spend (muc h) less time and effort when searching for desired items. Comparing now the success rates of repMR and repFP (i.e., the variant represents the user preferences with only a similarity query), one can see that repMR[rpt_ctz] achieves a much higher success rate over repFP[rpt_ctz] , i.e., 87.5% higher. When comparing repMR[rpt_ctz] to repFP[val_sel] , repFP[sim_ctz] , and repFP[sim_sel] , similar large increments in the success rate are observed. Amongst the replaying methods used for repFP (see Table 1), repFP[full_val_sel] tends to have the highest success rate, since it When compared to repFP[full_val_sel] , repMR[rpt_ctz] has still a success rate 50% higher. Furthe rmore, in Figure 4 we can see that repMR[rpt_ctz] has a shorter average recommendation length compared to repFP[full_val_sel] , and an equal average length compared to the remaining repFP -based combinations. The reason why the replaying methods using the repFP query representation approach have lower success rates is because in many simulated sessions the syst em was not able to push the selected product towards the top of the recommendation list. In other words, the repFP -based combinations sometimes fail to isolate the selected product from the others. With just very few (e.g., one or two) wish critiques the system using the repFP query representation may fail in differentiating the selected product from the others. In summary, if the repLQ system converges at the selected product, the convergence is fast. However, in many cases the system faces the  X  X ailing queries X  problem that causes a recommendation failure (and this cannot be repaired as we mentioned above because only logical constraints are supported). On the other hand, the system using the repFP query representation approach has no fa iling queries, but often it makes longer recommendation sessions (i.e., more critiquing cycles) and in some cases it may fail at isolating the selected product from the others, or may not be able to push it up in the recommendation list. The repMR system, which integrates both logical and similarity queries, has the benefits of the two individual query representation approaches (logical and similarity) and seems to be immune from their main disadvantages. The repMR system, therefore, should always converge at the selected product, and the convergence is rather fast. Though a number of critique-based recommendation approaches have been introduced in the literature, only some of them have been evaluated with real users [5, 6, 9, 10] or by simulation tests [3, 7, 12]. Previous off-line tests, except the one presented in [3], have focused mainly on the recommendation length (i.e., the number of cycles, or the numbe r of products presented). In previous research, such as [7], it was assumed an unlimited number of critiques that can be si mulated in a session, that is, critiques are simulated until the target item is found in the output list. Hence, a simulated session never fails. But, in practice (mobile) users are often impatie nt, and rarely express many critiques in a recommendation session. Simulating user critiques, which pl ays a very important role in off-line evaluations of critique-based RSs, has been done in a random way. In particular, at a recommendation cycle the criticized product is randomly selected [12] or is the product in the recommendation list that is most similar to the target one [7], and also the criticized feature is randomly selected [7]. Furthermore, no off-line evaluati ons of previous critique-based RSs, except the one presented in [3], have exploited a dataset of real users X  recommendation sessions ; they have mainly exploited the product (e.g., wine, PC, or travel) catalogs, where each product is used to generate the initial query and identify the target. In a previously conducted live users evaluation we proved the effectiveness of our critique-b ased recommendation methodology for supporting on-the-go users in decision making of product selection. In this paper, we re port on an experimental study aimed at comparing different user-query representation approaches. In particular, we compared a composite query representation approach, which employs both logical and similarity queries, with two representations, each one using only one of the two queries. To perform this comparative eval uation, we defined a simulation procedure, and used it to replay the testers X  recommendation sessions recorded in the live users evaluation. The results of the simulation tests showed that th e query representation using both logical and similarity queries resulted in a better recommendation quality over a simpler query representation. The proposed simulation procedure replays r eal recommendation sessions and simulates user critiques in di fferent ways. This simulation procedure could be useful for othe r researchers who want to test their critique-based RSs off-line. As future work we want to introduce some query repair approach for the repLQ -based variant, so that we can relax failing queries in the off-line evaluations of repLQ . Moreover, the presented empirical evaluation assumes a re-application of real users X  critiques in their historical (ori ginal) order. Since different products shown may cause users to make different critiques, we plan to test other replaying strategies that will prioritize the critiquing according to user preferences. [1] D. Bridge, M. G X ker, L. McGint y, and B. Smyth. Case-based [2] R. Burke. Interactive critiquing for catalog navigation in e-[3] L. Chen and P. Pu. Preference-based organization interface: [4] Z. Jiang, W. Wang, and I. Benbasat. Multimedia-based [5] C. Y. Kim, J. K. Lee, Y. H. Cho, and D. H. Kim. Viscors: A [6] K. McCarthy, L. McGinty, B. Smyth, and J. Reilly. A live-[7] L. McGinty and B. Smyth. Adaptive selection: An analysis [8] Q. N. Nguyen and F. Ricci. User preferences initialization [9] P. Pu and P. Kumar. Evaluati ng example-based search tools. [10] P. Pu and L. Chen. Integrating tradeoff support in product [11] F. Ricci and Q. N. Nguy en. Acquiring and revising [12] H. Shimazu. ExpertClerk: Navigating shoppers buying [13] C. A. Thompson, M. H. G X ker, and P. Langley. A [14] M. van Setten, S. Pokraev, and J. Koolwaaij. Context-aware [15] Z. Yu, X. Zhou, D. Zhang, C.-Y. Chin, X. Wang, and J. [16] B. Zhou, S. C. Hui, and K. Chang. Enhancing mobile Web 
