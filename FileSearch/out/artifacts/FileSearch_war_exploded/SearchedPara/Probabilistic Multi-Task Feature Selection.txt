 Learning algorithms based on  X  1 regularization have a long history in machine learning and statistics. is the sum of the  X  2 norms of the rows and the  X  1 ,  X  norm is the sum of the  X   X  norms of the rows. Regularizers based on these two matrix norms encourage row sparsity, i.e., they encourage entire rows of the matrix to have zero elements. Moreover, these norms have also been used for enforcing group sparsity among features in conventional classification and regression problems, e.g., group LASSO [29]. Recently, they have been widely used in multi-task learning, compressed sensing and other related areas. However, when given a specific application, we often have no idea which norm is the most appropriate choice to use.
 In this paper, we study the problem of determining the most appropriate sparsity enforcing norm to the range 1 &lt;  X   X   X  to ensure that all norms in this family are convex, making it easier to are just two special cases. Using the  X  1 , X  norm, we formulate the general multi-task feature se-lection problem and give it a probabilistic interpretation. It is noted that the automatic relevance determination (ARD) prior [9, 3, 26] comes as a special case under this interpretation. Based on this probabilistic interpretation, we develop a probabilistic formulation using a noninformative prior called the Jeffreys prior [10]. We devise an expectation-maximization (EM) algorithm [8] to learn all model parameters, including  X  , automatically. Moreover, an underlying assumption of existing multi-task feature selection methods is that all tasks are similar to each other and they share the same features. This assumption may not be correct in practice because there may exist outlier tasks or tasks with negative correlation. As another contribution of this paper, we propose to use a matrix variate generalized normal prior [13] for the model parameters to learn the relationships between tasks. The task relationships learned here can be seen as an extension of the task covariance used in [4, 32, 31]. Experiments will be reported on two cancer classification applications using microar-ray gene expression data. that need feature selection, e.g., document classification, the feature dimensionality is usually very high and it has been found that linear methods usually perform better.
 The objective functions of most existing multi-task feature selection methods [24, 17, 28, 1, 2, 15, 20, 16, 18] can be expressed in the following form: der the multi-task setting, and  X  is the regularization parameter controlling the relative contribution of the empirical loss and the regularizer. Multi-task feature selection seeks to minimize the ob-jective function above to obtain the optimal parameters { w  X  , X   X  } . Two regularization functions are widely used in existing multi-task feature selection methods. One of them is based on the  X  1 , 2 norm vector and w  X  denotes the  X  th row of W . Another one is based on the  X  1 ,  X  norm of W [24, 15, 20]:  X  ( W ) = P  X   X  =1  X  w  X   X   X  .
 regularization function:
Note that when  X  &lt; 1 ,  X  ( W ) is non-convex with respect to W . Although  X  ( W ) is convex when  X  = 1 , each element of W is independent of each other and so the regularization function cannot enforce feature sparsity. Thus we restrict the range to 1 &lt;  X   X  X  X  .
 Even though restricting the range to 1 &lt;  X   X  X  X  can enforce feature sparsity between different tasks, different values of  X  imply different  X  X roup discounts X  for sharing the same feature. Specifically, when  X  approaches 1, the cost grows almost linearly with the number of tasks that use a feature, and when  X  =  X  , only the most demanding task matters. So selecting a proper  X  can potentially have a significant effect on the performance of the learning algorithms.
 In the following, we first give a probabilistic interpretation for multi-task feature selection methods. Based on this probabilistic interpretation, we then develop a probabilistic model which, among other things, can solve the model selection problem automatically by estimating  X  from data. In this section, we will show that existing multi-task feature selection methods are related to the maximum a posteriori (MAP) solution of a probabilistic model. This probabilistic interpretation sets the stage for introducing our probabilistic model in the next section.
 We first introduce the generalized normal distribution [11] which is useful for the model to be intro-duced. Definition 1  X  is a univariate generalized normal random variable iff its probability density func-tion (p.d.f.) is given as follows: where  X (  X  ) denotes the Gamma function and  X  X  X  X  denotes the absolute value of a scalar. For simplicity, if  X  is a univariate generalized normal random variable, we write  X   X   X  X  X  (  X , X , X  ) . The (ordinary) normal distribution can be viewed as a special case of the generalized normal distribu-tion when  X  = 2 and the Laplace distribution is a special case when  X  = 1 . When  X  approaches +  X  , the generalized normal distribution approaches the uniform distribution in the range [  X   X   X , X  +  X  ] . The generalized normal distribution has proven useful in Bayesian analysis and robustness studies. Definition 2 A standardized  X   X  1 multivariate generalized normal random variable z = (  X  1 ,..., X   X  )  X  consists of  X  independent and identically distributed (i.i.d.) univariate generalized normal random variables.
 If z is a standardized  X   X  1 multivariate generalized normal random variable, we write z  X   X  X  X  X  (  X , X , X  ) with the following p.d.f.:
With these definitions, we now begin to present our probabilistic interpretation for multi-task feature selection by proposing a probabilistic model. For notational simplicity, we assume that all tasks perform regression. Extension to include classification tasks will go through similar derivation. For a regression problem, we use the normal distribution to define the likelihood for x  X   X  : where  X  (  X , X  2 ) denotes the (univariate) normal distribution with mean  X  and variance  X  2 . We impose the generalized normal prior on each element of W : where  X   X  X  X  is the (  X , X  ) th element of W (or, equivalently, the  X  th element of w  X  or the  X  th element of w  X  ). Then we can express the prior on w  X  as
When  X  = 2 , this becomes the ARD prior [9, 3, 26] commonly used in Bayesian methods for enforcing sparsity. From this view, the generalized normal prior can be viewed as a generalization of the ARD prior.
 With the above likelihood and prior, we can obtain the MAP solution of W by solving the following problem: where b = (  X  1 ,..., X   X  )  X  and  X  = (  X  1 ,..., X   X  )  X  .
 We set the derivative of  X  with respect to  X   X  to zero and get
Plugging this into problem (4), the optimization problem can be reformulated as
Note that problem (5) is non-convex since the second term is non-convex with respect to W . Be-cause ln  X   X   X   X  1 for any  X  &gt; 0 , problem (5) can be relaxed to problem (1) by setting  X  =  X  X  X  2 . So the solutions of multi-task feature selection methods can be viewed as the solution of the relaxed optimization problem above. In many previous works such as [5, 27], ln(  X  ) can be used as an ap-proximation of  X  (  X   X  = 0) where  X  (  X  ) is an indicator function. Using this view, we can regard the second term in problem (5) as an approximation of the number of rows with nonzero  X  -norms. Note that we can directly solve problem (5) using a majorization-minimization (MM) algorithm [14]. For numerical stability, we can slightly modify the objective function in problem (5) by replacing concavity property of ln(  X  ) , we can bound the second term in problem (5) as follows
Thus, in the (  X  + 1) th iteration, we need to solve a weighted version of problem (1):
According to [14], the MM algorithm is guaranteed to converge to a local optimum. normal prior which can be viewed as a generalization of the ARD prior. In the ARD prior, according to [19], this approach is likely to lead to overfitting because the hyperparameters in the ARD prior are estimated via point estimation. In the following, we will present our probabilistic framework for multi-task feature selection by imposing priors on the hyperparameters. 4.1 The Model As in the above section, the likelihood for x  X   X  is also defined based on the normal distribution:
Here we use different noise variances  X   X  for different tasks to make our model more flexible. The prior on W is also defined similarly:
The main difference here is that we treat  X   X  as a random variable with the noninformative Jeffreys prior: to  X  . One advantage of using the Jeffreys prior is that the distribution has no hyperparameters. 4.2 Parameter Learning and Inference Here we use the EM algorithm [8] to learn the model parameters. In our model, we denote  X  = { W , b , {  X   X  } , X  } as the model parameters and  X  = (  X  1 ,..., X   X  )  X  as the hidden variables. In the E-step, we construct the so-called  X  -function as the surrogate for the log-likelihood: where  X  (  X  ) denotes the estimate of  X  in the  X  th iteration and y = (  X  1 1 ,..., X   X   X  show that and  X  (  X   X  y ,  X  (  X  ) )  X  Q  X   X  =1  X  (  X   X  )  X  ( w  X  (  X  )  X   X   X  ) . We then compute  X  [ 1  X   X 
So we can get In the M-step, we maximize  X  (  X   X   X  (  X  ) ) to update the estimates of W , b , {  X   X  } and  X  . For the estimation of W , we need to solve  X  convex optimization problems this becomes the conventional ridge regression problem. Here  X   X  is related to the sparsity of the will be enforced to approach 0. We use a gradient method such as conjugate gradient to optimize problem (9). The subgradient with respect to w  X  is tion.
 We set the derivatives of  X  (  X   X   X  (  X  ) ) with respect to  X   X  and  X   X  to 0 and get
For the estimation of  X  , we also use a gradient method. The gradient can be calculated as where  X  (  X  )  X   X  ln  X (  X  )  X  X  X  is the digamma function. 4.3 Extension to Deal with Outlier Tasks and Tasks with Negative Correlation An underlying assumption of multi-task feature selection using the  X  1 , X  norm is that all tasks are practice because there may exist outlier tasks (i.e., tasks that are not related to all other tasks) or tasks with negative correlation (i.e., tasks that are negatively correlated with some other tasks). In this section, we will discuss how to extend our probabilistic model to deal with these tasks. We first introduce the matrix variate generalized normal distribution [13] which is a generalization of the generalized normal distribution to random matrices.
 Definition 3 A matrix Z  X   X   X   X   X  is a matrix variate generalized normal random variable iff its p.d.f. is given as follows: where  X   X   X   X   X   X  and  X   X   X   X   X   X  are nonsingular, det (  X  ) denotes the determinant of a square matrix,  X  We write Z  X   X  X  X  X  X  X  ( M ,  X  ,  X  , X  ) for a matrix variate generalized normal random variable Z . When  X  = 2 , the matrix variate generalized normal distribution becomes the (ordinary) matrix variate normal distribution [12] with row covariance matrix  X  X   X  and column covariance matrix  X  X   X  , which has been used before in multi-task learning [4, 32, 31]. From this view,  X  is used to model the relationships between the rows of Z and  X  is to model the relationships between the columns.
 We note that the prior on W in Eq. (7) can be written as where 0 denotes a zero vector or matrix of proper size, I  X  denotes the  X   X   X  identity matrix and of W (and hence the tasks) are independent of each other. However, the tasks are in general not independent. So we propose to use a new prior on W : where  X  models the pairwise relationships between tasks.
 The likelihood is still based on the normal distribution. Since in practice the relationships between tasks are not known in advance, we also need to estimate  X  from data.
 For parameter learning, we again use the EM algorithm to learn the model parameters. Here the model parameters are denoted as  X  = { W , b , {  X   X  } , X ,  X  } . It is easy to show that
Then we compute  X  [ 1  X   X 
In the E-step, the  X  -function can be formulated as
In the M-step, for W and  X  , the optimization problem becomes where e  X  denotes the  X  th column of the  X   X   X  identity matrix. We use an alternating method to solve this problem. For a fixed  X  , the problem with respect to  X  W is a convex problem and we use conjugate gradient to solve it with the following subgradient also use conjugate gradient with the following gradient
After obtaining the optimal  X  W  X  and  X   X  , we can compute the optimal W  X  as W  X  =  X  W  X   X   X  . The update rules for {  X   X  } , {  X   X  } and  X  are similar to those in the above section. Some probabilistic multi-task feature selection methods have been proposed before [28, 2]. How-ever, they only focus on the  X  1 , 2 norm. Moreover, they use point estimation in the ARD prior and hence, as discussed in Section 3, are susceptible to overfitting [19].
 Zhang et al. [30] proposed a latent variable model for multi-task learning by using the Laplace prior to enforce sparsity. This is equivalent to using the  X  1 , 1 norm in our framework which, as discussed above, cannot enforce group sparsity among different features over all tasks. In this section, we study our methods empirically on two cancer classification applications using microarray gene expression data. We compare our methods with three related methods: multi-task task feature selection using  X  1 ,  X  regularization [20] 3 . 6.1 Breast Cancer Classification We first conduct empirical study on a breast cancer classification application. This application con-sists of three learning tasks with data collected under different platforms [21]. The dataset for the first task, collected at the Koo Foundation Sun Yat-Sen Cancer Centre in Taipei, contains 89 sam-ples with 8948 genes per sample. The dataset for the second task, obtained from the Netherlands Cancer Institute, contains 97 samples with 16360 genes per sample. Most of the patients in this dataset had stage I or II breast cancer. The dataset for the third task, obtained using 22K Agilent oligonucleotide arrays, contains 114 samples with 12065 genes per sample. Even though these three datasets were collected under different platforms, they share 6092 common genes which are used in our experiments.
 Here we abbreviate the method in Section 4.2 as PMTFS1 and that in Section 4.3 as PMTFS2. For each task, we choose 70% of the data for training and the rest for testing. We perform 10 random splits of the data and report the mean and standard derivation of the classification error over the 10 trials. The results are summarized in Table 1. It is clear that PMTFS1 outperforms the three previous methods, showing the effectiveness of our more general formulation with  X  determined usefulness of exploiting the relationships between tasks in multi-task feature selection. Since our methods can estimate  X  automatically, we compute the mean of the estimated  X  values over 10 trials. The means for PMTFS1 and PMTFS2 are 2.5003 and 2.6718, respectively, which seem to imply that smaller values of  X  are preferred for this application. This probably explains why the performance of MTFS 1 ,  X  is not good when compared with other methods.
 Table 1: Comparison of different methods on the breast cancer classification application in terms of classification error rate (in mean  X  std-dev). Each column in the table represents one task. 6.2 Prostate Cancer Classification dataset [22] for the first task is made up of laser intensity images from each microarray. The RMA preprocessing method was used to produce gene expression values from these images. On the other hand, the Welsh dataset [25] for the second task is already in the form of gene expression values. Even though the collection techniques for the two datasets are different, they have 12600 genes in common and are used in our experiments.
 The experimental setup for this application is similar to that in the previous subsection, that is, 70% are performed. We report the mean and standard derivation of the classification error over the 10 trials in Table 2. As in the first set of experiments, PMTFS1 and PMTFS2 are better than the other three methods compared and PMTFS2 slightly outperforms PMTFS1. The means of the estimated  X  values for PMTFS1 and PMTFS2 are 2.5865 and 2.6319, respectively. So it seems that smaller values are also preferred for this application.
 Table 2: Comparison of different methods on the prostate cancer classification application in terms of classification error rate (in mean  X  std-dev). Each column in the table represents one task. In this paper, we have proposed a probabilistic framework for general multi-task feature selection using the  X  1 , X  norm ( 1 &lt;  X   X   X  ). Our model allows the optimal value of  X  to be determined from data automatically. Besides considering the case in which all tasks are similar, we have also considered the more general and challenging case in which there also exist outlier tasks or tasks with negative correlation.
 Compressed sensing aims at recovering the sparse signal w from a measurement vector b = Aw for a given matrix A . Compressed sensing can be extended to the multiple measurement vector (MMV) model in which the signals are represented as a set of jointly sparse vectors sharing a common set of nonzero elements [7, 6, 23]. Specifically, joint compressed sensing considers the reconstruction of the signal represented by a matrix W , which is given by a dictionary (or measurement matrix) A and multiple measurement vector B such that B = AW . Similar to multi-task feature selection, the optimization problem of MMV can be formulated as: min W  X   X  W  X  1 , X  +  X  AW  X  B  X  2 2 . This problem is almost identical to problem (1) except that the loss defines the reconstruction error rather than the prediction error. So we can use the probabilistic model presented in Section 4 to develop a probabilistic model for joint compressed sensing. Besides, we are also interested in developing a full Bayesian version of our model to further exploit the advantages of Bayesian modeling. This research has been supported by General Research Fund 622209 from the Research Grants Council of Hong Kong.

