 Steffen Bickel bickel@mpi-inf.mpg.de Jasmina Bogojeska jasmina@mpi-inf.mpg.de Thomas Lengauer lengauer@mpi-inf.mpg.de Tobias Scheffer scheffer@mpi-inf.mpg.de Max Planck Institute for Computer Science, Saarbr  X ucken, Germany In multi-task learning one seeks to solve many clas-sification problems in parallel. Some of the classifi-cation problems will likely relate to one another, but one cannot assume that the tasks share a joint con-ditional distribution of the class label given the input variables. The challenge of multi-task learning is to come to a good generalization across tasks: each task should benefit from the wealth of data available for the entirety of tasks, but the optimization criterion needs to remain tied to the individual task at hand. Our work is motivated by the problem of predicting the therapeutic success of a given combination of drugs for a given strain of the Human Immunodeficiency Virus-1 (HIV-1). HIV is associated with the acquired immun-odeficiency syndrome (AIDS). Being a disease that claimed more than 25 million lives since 1981, AIDS is one of the most destructive epidemics in recorded his-tory. Currently there are more than 33 million people infected with HIV (UNAIDS/WHO, 2007).
 Antiretroviral therapy is hampered by HIV X  X  strong ability to mutate and develop viral quasi-species that can quickly be dominated by resistant variants. In or-der to decide on a course of therapy, virus samples taken from each individual patient are tested for a set of resistance-relevant mutations. Given this set of identified mutations together with the patient X  X  med-ication history, a medical practitioner needs to decide which combination of drugs to administer. The large number of genetic mutations and the wide array of available drug combinations render the process of pre-dicting the success of a potential therapy difficult, at best, for a human doctor.
 Historic treatment records of HIV patients cover only a small portion of all possible drug combinations. For many of these combinations, only few treatments have been recorded. This scarceness of training data pre-cludes separate training of a powerful prediction model for each combination from only records of treatments which used the same drug combination. Distinct com-binations can have similar effects when they intersect in jointly contained drugs, or when they include drugs that use similar mechanisms to affect the virus. There-fore, in order to predict the outcome of a given drug combination, it is desirable to exploit data from re-lated combinations and thereby achieve generalization over both virus mutations and combinations of drugs. We contribute a new multi-task learning model that can handle arbitrarily different data distributions for different tasks without making assumptions about the data generation process or the relation between tasks. We show that by appropriately weighting each in-stance in the pool of all examples, one can match the distribution that governs the pool of examples of all tasks to each of the single task distributions. We show how appropriate weights can be obtained by discrimi-nating the labeled sample for a given task against the pooled sample.
 The rest of this paper is structured as follows. After formalizing the problem setting in Section 2, we review related transfer learning models in Section 3. We de-vise the model for multi-task learning by distribution matching in Section 4. In Section 5 we describe the data sets and the experimental setting and report on experimental results. Section 6 concludes. In supervised multi-task learning , each of several tasks z is characterized by an unknown joint dis-tribution p ( x , y | z ) of features x and label y given the task z . The joint distributions of different tasks may differ arbitrarily but usually some tasks have similar distributions. A training sample D = all tasks. There may be tasks with no data. For each example, input attributes x i , class label y i , and the originating task z i are known. The entire sample D is governed by the mixed joint density p ( z ) p ( x , y | z ). The prior p ( z ) specifies the task proportions. The goal is to learn a hypothesis f z : x 7 X  y for each task z . This hypothesis f z ( x ) should correctly predict the true label y of unseen examples drawn from p ( x | z ) for all z . That is, it should minimize the expected loss with respect to the unknown joint distribution p ( x , y | z ) for each individual z .
 This abstract problem setting models the HIV therapy screening application as follows. Input x describes the genotype of the virus that a patient carries, together with the patient X  X  treatment history. Genotype infor-mation is encoded as a binary vector indicating the presence and absence of each out of a predefined set of resistance-relevance mutations, respectively. The treatment history can be represented as a binary vec-tor indicating which drugs have been administered over the course of past treatments. A candidate com-bination of drugs plays the role of the task z : each task has an associated binary vector z that indicates a set of drugs that a medical practitioner is currently giv-ing consideration. The binary class label y indicates whether the therapy will be successful.
 In addition to training data, we may have prior knowl-edge on the similarity of tasks which is encoded in a kernel function k ( z, z 0 ). Prediction models for differ-ent drug combinations can be similar because the sets of drugs intersect (we will later refer to this as the drug feature kernel), or because similar sets of muta-tions in the virus render the drugs in the set ineffective (mutation table kernel). One obvious strategy for multi-task learning is to learn independent models for each target task t by mini-mizing an appropriate loss function on the portion of D t = { ( x i , y i , z i )  X  D : z i = t } . The other extreme could be a one-size-fits-all model f  X  ( x ) trained on the entire sample.
 In many applications, task-level descriptions or prior knowledge on task similarity encoded in a kernel are available. Bonilla et al. (2007) study an extension of the one-size-fits-all model and find that training with a kernel defined as the multiplication of an input feature kernel and a task-level kernel outperforms a gating net-work. Task-level features have also been utilized for task clustering and for a task-dependent prior on the model parameters (Bakker &amp; Heskes, 2003). Another simple extension to the one-size-fits-all model would be to train a model for a target task from all data with weighted examples from other tasks, using one fixed uniform weight for each task. Such a model is described by Wu and Dietterich (2004).
 Our work is inspired by learning under covariate shift. In the covariate shift setting the marginals p train ( x ) and p test ( x ) of training and test distributions dif-fer, but the conditionals are identical p train ( y | x ) = p test ( y | x ). If training and test distributions were known, then the loss on the test distribution could be minimized by weighting the loss on the training distri-bution with an instance-specific factor. Shimodaira (2000) illustrates that the scaling factor has to be expression for this marginal density ratio that can be estimated  X  without estimating the potentially high-dimensional densities of training and test distributions  X  by discriminating training against test data. Hierarchical Bayesian models for multi-task learning are based on the assumption that task-specific model parameters are drawn from a common prior. The task dependencies are captured by estimating the com-mon prior. Yu et al. (2005) impose a normal-inverse Wishart hyperprior on the mean and covariance of a Gaussian process prior that is shared by all task-specific regression functions. Mean and covariance of the Gaussian process are estimated using the EM al-gorithm. A Dirichlet process can serve as prior in a hi-erarchical Bayesian model and cluster the tasks (Xue et al., 2007); all tasks in one cluster share the same model parameters. Evgeniou and Pontil (2004) derive a kernel that is based on a hierarchical Bayesian model with Gaussian prior (covariance matrix is scalar) on the parameters of a regularized regression.
 Larder et al. (2007) tackle the problem of predicting virological response to a given HIV drug combination with neural networks. Lathrop and Pazzani (1999) ap-ply combinatorial optimization to the same problem using features extracted from the viral genotype and the drugs in the combination. Altmann et al. (2007) approach the problem by including various phenotypic information and an estimate of future evolutionary de-velopment of the virus in the learning process. In learning a classifier f t ( x ) for target task t , we seek to minimize the loss function with respect to p ( x , y | t ). Simply pooling the available data for all tasks would create a sample governed by approach now is to create a task-specific resampling weight r t ( x , y ) for each element of the pool of exam-ples. The sampling weights match the pool to the target distribution p ( x , y | t ). The weighted sample is governed by the correct target distribution, but is still larger as it draws from the sample pool for all tasks. Instead of sampling from the pool, one can weight the loss incurred by each instance by the resampling weight. The expected weighted loss with respect to the mixture distribution that governs the pool equals the loss with respect to the target distribution p ( x , y | t ). Equation 1 defines the resampling weights.
 In the following, we will show that satisfies Equation 1. Equation 2 expands the ex-pectation and introduces a fraction that equals one. Equation 3 expands the sum over z in the numerator to run over the entire expression because the integral over ( x , y ) is independent of z . Equation 4 is the ex-pected loss over the distribution of all tasks weighted
E Equation 4 signifies that we can train a hypothesis for task t by minimizing the expected loss over the distri-bution of all tasks weighted by r t ( x , y ). This amounts to minimizing the expected loss with respect to the target distribution p ( x , y | t ).
 Equation 4 leaves us with the problem of estimat-ing the joint density ratio r t ( x , y ) = p ( x ,y | t ) One might be tempted to train density estimators for p ( x , y | t ) and timators for potentially high-dimensional densities is unnecessarily difficult because ultimately only a scalar weight is required for each example. 4.1. Discriminative Density Ratio Model In this section, we derive a discriminative model that directly estimates the resampling weights r t ( x , y ) = sities. We reformulate the density ratio p ( x ,y | t ) P in terms of a conditional model p ( t | x , y ). This con-ditional has the following intuitive meaning: Given that an instance ( x , y ) has been drawn at random from the pool  X  z D z = D of samples for all tasks (includ-ing D t ); the probability that ( x , y ) originates from D is p ( t | x , y ). The following equations assume that the prior on the size of the target sample is greater than zero, p ( t ) &gt; 0. In Equation 6 Bayes X  rule is applied twice and in Equation 7 p ( x , y ) and p ( z ) are canceled out. Equation 8 follows by r t ( x , y ) = The significance of Equation 8 is that it shows how the termined without knowledge of any of the task densi-ties p ( x , y | z ). The right hand side of Equation 8 can be evaluated based on a model p ( t | x , y ) that discriminates labeled instances of the target task against labeled in-stances of the pool of examples for all tasks. Intu-itively, p ( t | x , y ) characterizes how much more likely ( x , y ) is to occur in the target distribution than it is to occur in the mixture distribution of all tasks. Instead of potentially high-dimensional densities p ( x , y | t ) and p ( x , y | z ), a conditional distribution with a single vari-able needs to be modeled. One can apply any proba-bilistic classifier to model this conditional distribution. 4.2. Soft-Max Model for Density Ratio We model p ( t | x , y ) of Equation 8 for all tasks jointly with a soft-max model (the multi-class generalization of the logistic model) with model parameters v , dis-played in Equation 9. The parameter vector v is a concatenation of task-specific subvectors v z , one for each task z . With this model an estimate for p ( t | x , y ) is given by p ( z = t | x , y, v ); this is the evaluation of the soft-max model with respect to task t . Equation 9 requires a problem-specific feature map-ping  X ( x , y ). Without loss of generality we define this mapping for binary labels y  X  X  +1 ,  X  1 } in Equa-tion 10;  X  is the Kronecker delta. In the absence of prior knowledge about the similarity of classes, input features x of examples with different class labels y are mapped to disjoint subsets of the feature vector. With this feature mapping the models for positive and negative examples do not interact and can be trained independently.
 For training the soft-max model we maximize the reg-ularized log-likelihood of the data. Prior knowledge on the similarity of tasks in the form of a positive semi-definite kernel function k ( z, z 0 ) can be be encoded in the covariance matrix of a Gaussian prior N (0 ,  X ) on parameter vector v . We set all main diagonal entries of  X  to the scalar parameter  X  2 v and set the secondary diagonal entries corresponding to the covariances be-tween v z and v 0 z to k ( z, z 0 )  X  X  2 v (assuming kernel values 0  X  k ( z, z 0 )  X  1). Parameter  X  2 v specifies the variance of each element in v . k ( z, z 0 )  X  is the correlation co-efficient between elements of subvectors v z and v 0 z ; parameter  X  specifies the strength of this correlation. The covariance matrix  X  is required to be invertible and therefore 0  X   X  &lt; 1. All other entries of  X  are set to zero. When prior knowledge on the task similarities is encoded in the prior on the model parameters, then this prior knowledge dominates the optimization cri-terion for small samples while the data-driven portion of the criterion becomes dominant and overrides prior beliefs as more data arrives.
 Optimization Problem 1 Over parameters v , max-imize The solution of Optimization Problem 1 is a maximum a posteriori estimation of the soft-max model (Equa-tion 9) over the model parameters v using a Gaussian prior with covariance matrix  X . Tasks with no training examples are covered naturally in Optimization Prob-lem 1. In this case, the Gaussian prior with the task kernel k ( z, z 0 ) encoded in the covariance matrix deter-mines the model.
 For our experiments we use a kernelized variant of Op-timization Problem 1 by applying the representer theo-rem. Details on the kernelization of multi-class logistic regression can be learned from Zhu and Hastie (2002). 4.3. Weighted Empirical Loss and Target The multi-task learning procedure first determines re-sampling weights r z ( x , y ) for all tasks and instances by solving Optimization Problem 1. In this section we describe the second step of training an array of target models, one for each task, using weighted examples. With the results of Optimization Problem 1 the dis-criminative expression for the weights of Equation 8 can be estimated. Using these weights we can evalu-ate the expected loss over the weighted training data as displayed in Equation 11. It is the regularized em-pirical counterpart of Equation 4.
 An instance of Optimization Problem 2 is solved for each task independently to produce a separate model for this task. Optimization Problem 2 minimizes Equation 11, the weighted regularized loss over the training data using a standard Gaussian log-prior with variance  X  2 w on the parameters w t . Each example is weighted by the discriminatively estimated density fraction from Equation 8 using the solution of Opti-mization Problem 1.
 Optimization Problem 2 For task t : over parame-ters w t , minimize We model HIV therapy screening as a multi-task learn-ing problem. The input x to the prediction problem is given by attributes of the viral genotype and the patient X  X  treatment history. The combination of drugs z plays the role of the task. Success or failure of the therapy constitutes class-label y .
 In the next subsections we describe the data sets, ref-erence methods, and the empirical results of our study. 5.1. Data Sets and Prior Knowledge on Task We use data from the EuResist project (Rosen-Zvi et al., 2008). The data set comprises a total number of 52846 treatment records from the treatment histo-ries of 16999 HIV patients treated in hospitals in the period of 1977 through 2007.
 We use two different definitions of therapeutic success and failure to tag the data: virus load labeling and multi-conditional labeling .
 According to our virus load labeling definition a ther-apy is successful if the viral load (number of virus copies per ml blood plasma, cp/ml) drops below the established level of virus detection of 400 cp/ml during the time of the treatment. Otherwise the treatment is a failure. In multi-conditional labeling , a therapy is successful if the viral load measured in the time range between 28 and 84 days after the start of the therapy decreases by at least 2 orders of magnitude compared to the most recent viral load measured one to three months before the start of the therapy, or the viral load drops below 400 cp/ml 56 days after the start of the therapy. A drawback of this definition is that due to the strict time intervals it imposes on the measure-ments, class labels that adhere to this labeling are only available for a small number of records. The virus load labeling does not require these strict time intervals by making use of any viral load measurement during the course of therapy to label it.
 Out of all available treatment records we extract two different data sets using the two labelings. With the virus load labeling we extract 3260 and with the multi-conditional labeling 2011 treatment records with cor-responding ratios of 65.7% and 64.1% successful treat-ments. The size of these data sets is much smaller than the size of the original data due to missing viral load measurements, or missing virus sequence information. A number of 545 distinct drug combinations (tasks z ) occur at least once in the virus load data set; 433 occur in the the multi-conditional data set. The histogram over sample sizes per task is displayed in Figure 1. For many combinations, only a few examples occur in the data. For instance, in the virus load data set we observe 253 out of 545 drug combinations with only one data point and 411 with less than 5 instances. Similarly, the multi-conditional data set has 213 out of 433 drug combinations with a single data point and 331 with less than 5 observations.
 We extract two types of features for each instance: a genotypic description of the virus and information about the treatment history of the patient. We use the viral genotype taken from the patient shortly before the treatment and represent it by a binary vector in-dicating the presence of resistance-relevant mutations of the viral sequence (Johnson et al., 2007). Drug-resistant viral quasi-species evolve during the course of the treatment due to selective pressure imposed by the drug. As they remain in the patient X  X  body, the treatment history plays an important role for predict-ing the outcome of a potential treatment. Hence, we extract all drugs given to the patient in previous treat-ments and use a binary vector representation with a one entry for each drug given to the patient in the treatment history. The 82-dimensional feature vector x for each data point results from the concatenation of 65 genotypic and 17 historic treatment features. We have prior knowledge about the similarity of com-binations and encode this knowledge into two differ-ent task similarity kernels k ( z, z 0 ). The binary drug indicator vector has an entry for each drug; entries of one indicate the presence of a drug in the combi-nation. The drug indicator kernel is the inner prod-uct between the normalized drug indicator vectors of two combinations. The mutation table kernel is based on tables about the resistance-associated mutations of single drugs (Johnson et al., 2007). We construct bi-nary vectors indicating resistance-relevant mutations for the set of drugs occurring in a combination. The kernel computes the normalized inner product between such binary vectors for two drug combinations. 5.2. Reference Methods The first reference method is training of a separate logistic regression model for each task without any in-teraction ( X  X eparate X ). Tasks without any training ex-amples get a constant classifier that assigns each test example with 50% to each of both classes.
 The next baseline is a one-size-fits-all model; all ex-amples are pooled and only one common logistic re-gression is trained for all tasks ( X  X ooled X ). For the experiments with prior knowledge on task similarity we multiply the feature kernel with the task kernel values k ( x , x 0 )( k ( z, z 0 ) + 1) and train one model using this kernel (Bonilla et al., 2007). For task kernels that can have a value of zero we include a  X +1 X  term to ensure that the feature kernel does not vanish. The third reference method ( X  X ier. Bayes kernel X ) is a logistic regression with the hierarchical Bayesian ker-and Pontil (2004);  X  ( z, z 0 ) is the Kronecker delta and  X  is a tuning parameter. For the experiments with task similarity kernel the hierarchical Bayes and the task kernel are multiplied. As second hierarchical Bayesian method ( X  X ier. Bayes Gauss. proc. X ) we use the Gaus-sian process regression of Yu et al. (2005). 5.3. Experimental Setting and Results In our experiments we study the benefit of distribu-tion matching for HIV therapy screening compared to the reference methods described in Section 5.2. Op-timization Problem 1 is solved with limited-memory BFGS and Optimization Problem 2 with Newton gra-dient descent using a logistic loss. For the prior term p ( t ) required in Optimization Problem 2 we use a MAP We use RBF kernels for all methods.
 We apply a training-test split of the data consistent with the dates of the treatment records. We sort the treatment records by date and use the first 80% of the records as training data and the last 20% as test data. This procedure yields 653 and 403 test examples for the virus load and multi-conditional data set, respec-tively. The date consistent split is necessary because new drugs get approved over time, and under pressure of new drugs the viral population evolves. In such en-vironments, the prediction models should be able to learn from data seen in the past and perform well on unseen data in the future .
 We tune the prior and regularization parameters of all methods, the Dirichlet parameter  X  , and the variance of the RBF kernels on tuning data resulting from a date consistent split of the training data.
 The evaluation measure is the accuracy of predicting the correct label (success or failure of a treatment) on the test set. Table 1 shows the results of the pre-diction accuracy for all methods over both data sets without and with two different types of prior knowl-edge on combination similarity. The columns  X  X te. X  X  placed next to the accuracy columns display the stan-dard error of the differences to the distribution match-ing method.
 Multi-task learning by distribution matching outper-forms, or is as good as, the best alternative method in all cases. The improvement over the separate model baseline is about 10-14%. We can reject the null hy-pothesis that the pooled and the hierarchical Bayesian kernel baseline is at least as accurate as distribution matching in four and five cases respectively out of six according to a paired t -test at  X  = 0 . 05.
 For distribution matching, prior knowledge does not improve the accuracy. The pooled baseline benefits from prior knowledge for the multi-condition data set. For the case without prior knowledge we do not ob-serve a statistically significant difference of the two hierarchical Bayesian methods, but they are both sig-nificantly worse than distribution matching according to the paired t -test. Note that the Gaussian process baseline is a regression model; all other methods are classification models.
 Figure 2 displays the accuracy over the combinations in the test set grouped by the number of available ex-amples for the settings without and with the mutation table kernel. For instance, an accuracy of 74% for the first group  X 0-2 X  means, that only test examples from combinations are selected that have zero, one, or two training examples each, and the accuracy on this sub-set of the test examples is 74%. Each of the four groups covers about the same number of test examples. The error bars indicate the standard error of the differences to the distribution matching method. Note, that the statistical tests described above are based on all test data and are not directly related to the group-specific error bars in the diagrams.
 All methods benefit from larger numbers of training examples per drug combination. The slightly decreas-ing accuracy for the virus load data set with  X  &gt; 38 X  training examples is surprising. Further analysis re-veals that in this case there is an accumulation of test examples with history profiles very different from the training examples of the same combination.
 For all methods that generalize over the tasks the ben-efit compared to the separate model baseline is the largest for the smallest group ( X 0-2 X  and  X 0-1 X  train-ing examples respectively). We devised a multi-task learning method that cen-ters around resampling weights which match the dis-tribution of the pool of examples of multiple tasks to the target distribution for a given task at hand. The method creates a weighted sample that reflects the de-sired target distribution and exploits the entire corpus of training data for all tasks. We showed how ap-propriate weights can be obtained by discriminating the labeled sample for a given task against the pooled sample. After weighting the pooled sample, a classifier for the given task can be trained. In our experiments on HIV therapy screening we found that the distribu-tion matching method improves on the prediction ac-curacy over independently trained models by 10-14%. According to a paired t -test, distribution matching is significantly better than the reference methods for 17 out of 20 experiments.
 A combination of drugs is the standard way of treat-ing HIV patients. The accuracy to which the likely outcome of a combination therapy can be anticipated can therefore directly impact the quality of HIV treat-ments.
 Acknowledgment We thank Kai Yu for providing his Gaussian process implementation and Barbara Pogorzelska who adapted this code and conducted the experiments. We also thank the EuResist project with contract number EU-STREP IST-2004-027173 for providing the data. We gratefully acknowledge support from the German Sci-ence Foundation DFG.

