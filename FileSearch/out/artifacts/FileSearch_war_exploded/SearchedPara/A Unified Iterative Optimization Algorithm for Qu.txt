 query models, the estimation of document models and the definition of document ranking function are three key problems. Document model estimation has been well within a unified framework. 
Query modeling has attracted much attention in recent years. As the query submit-ted by a user is usually very short, it needs to be enriched. A commonly used strategy for query modeling is through feedback techniques, such as relevance (pseudo-two model-based feedback methods have been proposed in [18]: one based on a gen-erative probabilistic model of feedback documents and another on minimization of KL-divergence over feedback documents. Both of them have been proved to be effec-tive. Another commonly used approach to improve query model is to exploit term models. 
Ranking algorithm is another important factor that influences the performance of a retrieval system. In score-based retrieval, a ranking algorithm assigns relevance score to each document with respect to the query. Different methods are defined for estimating relevance scores. Similarity-based methods assume that the relevance is correlated with the similarity/distance between a query and a document [8, 15]. Prob-abilistic relevance models use a binary random variable to model relevance [7]. Learning to rank is a new family of methods that aims at training a model to rank the document in a supervised learning fashion [5]. However, all the above mentioned models make an assumption that documents are independent. The structure among studies demonstrate the advantages of considering the structure among documents. However, query model and ranking function are considered separately in their studies. can be improved with the help of feedback documents. Well ranked documents will factor that influences document ranking quality. 
In this paper, we propose a unified approach to optimize query model and ranking function simultaneously. We aim to choose the best query model and assign the most appropriate scores to documents. These tw o elements are optimized together: query model can be improved by well ranked documents, and the ranking function can be improved by a better query model. The previous approaches which fix one of the also changing the other (query model). 
To surpass this limitation, we propose an iterative optimization algorithm: Given a scores S are used as new evidence to help refine the query model. In turn, the docu-iteratively several times. Different resources, such as word relation, document relation represented as graphs. A constraint onto the smoothness of these graphs will help the optimization algorithm to determine a query model and a ranking function that satisfy the manifold hypothesis: two similar points (terms and documents) in the graph should have similar scores. 
In our approach, the above problem is formulated within the risk minimization criteria: loss function based on risk minimization framework, smoothness of word graphs and document graphs, and fidelity to the original query model. The solution to this optimization problem leads to a new way to define query model and ranking function. 
In addition, we extend our approach by incorporating user X  X  true feedback informa-tion, which encode the feedback information into a loss function, and combine it with the existing objective function. By minimizing the new objective function, a new ranking method can be derived. model and more appropriate document scores by the unified iterative optimization framework. Second, the optimization of the query model and document ranking func-tion becomes dependent by systematically incorporating the query term weight and document score as components within the sa me algorithm. Document scores provide evidence for query model refinement, and query model can influence ranking per-formance. Once one of them changes, it can be considered as a piece of new evidence query model and ranking function refinement. New resources such as implicit and true relevance feedback information can be flexibly embedded into the approach. Experimental results on four TREC collections show that our model is effective. 
The remaining sections are organized as follows. In section 2, we propose a unified iterative optimization algorithm for query model and ranking refinement with graph structure. In section 3, we further integrate user X  X  relevance judgments into our framework. In section 4, we report the experimental results of these methods. We discuss the related work in section 5. We conclude our paper in section 6. 2.1 Risk Minimization Framework The problem of query model and ranking refinement is essentially an optimization problem. This problem can be formulated within the risk minimization framework for IR [8] by the following loss function: probability distribution of all the parameters; (,,,) LDSQ  X  is a loss function, which can be defined as follows: documents. The larger i S is, the larger the contribution of i d to the global loss. 
In the context of language modeling using KL-divergence, Q and d  X  are usually represented as unigram language model. This leads to In the context of vector space modeling, Q and d  X  are represented as vectors. Within this setting, we have: In this paper, we do not change the document model  X  , but focus on the optimization of query model and ranking function. We thus define the following loss function. where  X  is the document model we selected. 2.2 Label Smoothness on Data Graph inconsistency between related points, as follows. has been shown to result in superior convergence properties than unnormalized affini-straint the above function. Points i and j in a graph can be documents, words or users. In this study, we will use word graph and document graph. 2.3 Computing the Optimal Scores In this section, we introduce our method to refine the query model and ranking func-tion within the context of language modeling and vector space modeling, respectively. 2.3.1 Query Model Refinement We define the following objective function for query model refinement in the context of language model. where f and y are query models, (| ) ii fptQ = , (| ) ii in semi-supervised learning [19], guarantees the consistency of the query model on the section 2.1, where D and S are the feedback documents and the corresponding scores; p(t|C) is the collection language model; log ( | ) ii fPtC model is from the collection language model, and 2 fi first-order partial derivative of it, which is Using the gradient decent method to optimize the objective function, let we have From Equation 7, we can see that the new query model f i has three components, corre-sponding to the three objective terms in equation 6: The first term is the original query model, the second term is obtained through score regularization on the graph, and the third term is obtained from the document model of feedback documents which is similar to the divergence minimization feedback model in [18]. The difference be-tween the above formulation and that in [18] is that our approach considers the docu-ment score j S as a component. 
Similar to the above language model, we define another objective function for vec-tor space model: q , and the other parameters are the same as in equation 6. We do not use the collection model in this objective function, because the idf value can play a similar role. Using the same manipulation as in language modeling, we have 2.3.2 Ranking Refinement In score-based retrieval, the retrieval system assigns each document a relevance score. Document ranking can be considered as a d ecision problem, which is optimized so as to minimize a loss function within the risk minimization framework. Manifold hy-pothesis implies that neighbor documents on document graph should have similar scores. So we define the following loss function for ranking refinement as follows: where a and b are two weighting parameters with a + b =1; i S is the score of document d . The first term is derived from risk minimization framework, Q is the query model; ments from the initial retrieval results. The last term guarantees the smoothness of the document scores on the graph; 2 i S
Using the gradient decent method, model respectively. 
In order to normalize the value of x i we replace x i in Equation 11 by the following normalized value: 2.3.3 The Iterative Optimization Algorithm for Query Model and Ranking We observe that the query model Q is a component for refining document scores, and the document scores s d is also a component for refining query model. We see clearly that these two elements mutually influence each other. The best solution for one ele-ment is condition to the other element. A way to solve this problem is to use an itera-tive algorithm to optimize each of them in turn. This process is expected to improve the query model and ranking iteratively and simultaneously. 
We derive two models here: one in the context of language modeling using KL-divergence, denoted by IOA-KL (Iterative Optimization Algorithm-KL ) ; another in the context of vector space model using TF-IDF weighting, denoted by IOA-TFIDF (Iterative Optimization Algorithm -TFIDF ) . To obtain a more precise and smoothed query model and document score model, IOA-KL and IOA-TFIDF start with f = y, the optimization algorithm is defined as follows: 1. Use the initial retrieval model to obtain the top ranked documents and their 2. Use equation 7 (IOA-KL) or 9 (IOA-TFIDF) to compute the new query model. 3. Use equation 11 to compute the new document scores. 4. Compute the change c between two iterations as follows: 
For the sake of efficiency, we limit the gr adient decent in steps 2 and 3 to only one iteration in our implementation. The above iterative algorithm stops when the change of document scores is smaller than some predefined threshold ((e.g. 10 -6 ). In practice, an improved query model and ranking. So we set the maximum iteration number to 5. 2.3.4 Construction of the Data Graph For every query, we construct a k-Nearest-Neighbor (kNN) document graph of all initial documents. The weight of the edge connecting two documents is measured with cosine similarity, which is the same as in [10]. We also construct a word graph tween the two words. In order to control the scale of the word graph, in each iteration, only includes the terms in the query model obtained from the last iteration. The models defined in the previous sections rely on a word graph or a document trieved results. In this section we consider a particular case in which we have true user relevance feedback. True relevance feedback is known to be effective [14, 16]. Previ-ous work using true relevance feedback focuses on query updating such as query term re-weighting and query expansion. Here, we consider such information as encoding preference orders between documents. obtained. We encode it within a matrix R as follows. relative relevance information from the implicit feedback information (clickthrough information) is used to train a model. Previous studies showed that relative relevance vance [6]. to 1: A cost function F can then be defined as follows: This cost function is similar to the loss function defined in [4] [13]. The ele-ment exp( ) ji SS  X  only contributes when its corresponding ij R is not zero, which means larger score than document j , then the value of the cost function will be small; in con-have: 1 2 () (1 ( )) Appending this cost function to the existing objective function (10) discussed in sec-tion 2.3.2 leads to a new objective function. Using the decent gradient algorithm, we have Z is used to control the learning rate. 
Based on IOA-KL, IOA-TFIDF and the relevance feedback information, we derive two new models: IOA-KL+REL and IOA-TFIDF+REL. The new models only change the method to re-compute the document scores. In Section 2, we introduce our algorithm and two instantiations: IOA-KL in language modeling and IOA-TFIDF in vector space modeling. In Section 3, we extend our models: IOA-KL+REL and IOA-TFIDF+REL, which incorporate relative relevance feedback information into IOA-KL and IOA-TFIDF respectively. We will evaluate the effectiveness of these methods empirically in this section. In this study, we fix the document model. Specifically, in IOA-KL, we use a IOA-TFIDF, we use the TFIDF value to weight terms, The TF formula used is the one based on the BM25 retrieval formula as in [18]. 4.1 Experimental Setup We evaluate the proposed method over four TREC data sets: AP (Associated Press news 1988-90), LA (LA Times), SJMN (San Jose Mercury News 1991), and TREC8 (the ad hoc data used in TREC8). They are id entical to the data sets used in [10], and are preprocessed in the same way. We used the title field of a query/topic description to simulate short keyword queries. used to retrieval the initial 3000 documents for each query. Our methods will be used to re-rank these documents. For IOA-KL, KL-divergence based on language model using Dirichlet smoothing strategy is selected as our initial retrieval model. For IOA-TFIDF, vector space model using BM25 TF is used as the initial retrieval model. 20, and ignored all terms having a weight less than 0.001. 
In all our experiments, the cutoff of relevant documents is set to 1000. The follow-ing two performance measures are used in our evaluation: (1) non-interpolated Mean Average Precision (MAP). (2) Precision at 10 documents (P@10). 4.2 Parameter Selection Our methods for query model and ranking refinement contain a set of parameters:  X  parameter b in Equation 11. In order to determine the values of these parameters, we on other test collections. The three parameters were swept over [0, 1] with a step size of 0.1. For IOA-KL+REL and IOA-TFIDF+REL, we will have five main parameters: { swept over [0,1] with a step of 0.1. We select the parameter values which optimize the MAP. The number of neighbors is set to 60 through the grid search method. 4.3 The Effectiveness of the Iterative Optimization Algorithm with other feedback model. IOA-KL is compared with KL-Divergence minimization feedback (DIV-MIN), which is a model-based feedback method used in [18]. IOA-TFIDF is compared with Rocchio feedback method [14] based on vector space model. For DIV-MIN feedback model, we varied the two main parameters: the coefficient that controls the influence of the feedback model and the noise parameter that controls used in [18]. We vary the coefficient in Ro cchio formula to tune the result to its best. 
In Table 1, we can see that IOA-KL outperforms DIV-MIN FB consistently and significantly in most cases when using the top 10 documents for pseudo-feedback. The increase in map is between 6% and 10% in most cases. IOA-TFIDF can also outperform Rocchio feedback model in most cases. 
We also compared IOA-KL with other language models: the basic KL-Divergence model with Dirchlet smoothing (KL Dir), the mixture feedback (Mix FB) model[1]  X  FB+QMWG proposed in [10], a graph-based query model smoothing method combined with mixture feedback. In order to evaluate the impact of consid-ering smoothness in word and document graphs, we remove the smoothness con-straint from IOA-KL model. This simplified model is denoted by IOA-KL*. 
In Table 2, comparing IOA-KL with KL Dir, we can see that the increase in effec-tiveness is very large. IOA-KL can also consistently outperform other existing meth-ods. This indicates that unifying multiple resources such as document graph, word graph can help improve the retrieval result s. Comparing IOA-KL to IOA-KL*, when the smoothness criterion is removed from the loss function, the retrieval effectiveness decreases. This demonstrates the importance of graph smoothness. 4.4 Effect of Considering Relevance Feedback Information In section 3, we derive a new optimization algorithm by appending relevance feed-back information, and two new document ranking refinement methods IOA-KL+REL and IOA-TFIDF+REL are derived. We will test the performance of these relevance judgments for a small set of documents. In our experiment, we provide true relevance judgments for the top 10 documents. Thus we can get relative relevance between each document pair among the top 10 documents, and encode them in the matrix R described in section 3. 
To evaluate the effect of incorporating true relevance feedback information, we compare IOA-KL+REL with DIV-MIN relevance feedback (DIV-MIN+REL) model, which also uses the relevance judgments of the top 10 documents for feedback. In the same way, IOA-TFIDF+REL is compared with the Rocchio relevance feedback (Roc-chio REL) model. For KL+REL and DIV-MIN REL model, we use the same initial retrieval method to obtain a document set for each query, and then provide relevance judgments for the top 10 documents. The same processing method is used by IOA-TFIDF+REL and Rocchio REL method. 
Table 3 shows that our IOA-KL+REL m odel can outperform DIV-MIN REL con-sistently and significantly on all the four datasets. The IOA-TFIDF+REL method can traditional relevance feedback model, the relevance feedback information is used only to update query model, and then the updated query model is used to re-rank the documents. When re-ranking the documents, the same ranking function is used, i.e. the relevance judgments did not affect the general ranking function. However, in our model, we interpret the relevance feedback information as relative relevance of our method can makes thorough use of the relevance feedback information. Risk minimization [8] provides a general framework to further improve a retrieval problem. It can unify several existing retrieval models such as KL-divergence lan-guage model and vector space model. KL-Divergence minimization feedback model described in [18] can be considered as one of its instantiation. Our approach is based on risk minimization framework. However, we take the graph structure into consid-possible to use the document score as evidence to help update query model. This allows us to unify query model and document ranking refinement within the same framework. 
Graph-based learning has attracted much a ttention in recent years [3, 9, 19]. Mani-fold ranking method is proposed in [19]. Our cost function on graph structure is simi-lar to the objective function proposed in [19]. In information retrieval, there are also lowing aspects, however, separately -document score regularization or query model. In contrast, our approach combines graph structure into the risk minimization frame-tion. We combined both word graph and doc ument graph in our approach, which can lead to a smoothed query model and ranking function. Through the iterative process, we can make use of the mutual influence between the query model and the document ranking in order to optimize both of them. 
One of the concrete instantiations of our algorithm is proposed in section 3, which is related to some learning to rank approaches [4, 13]. [4] uses user feedback information method also encodes user feedback into document preference relations, and combines the problem of relational object ranking. Our method takes the label smoothness on the formation to propagate between query model and document ranking. In this paper, we proposed a unified iterative optimization algorithm which provided a principled way to refine both the query model and the document ranking. It combines and the document graph. The combination of these multiple criteria forms a new op-timization problem. The solution to the optimization problem leads to some new methods. We derived two methods in the context of language model and vector space model respectively. Moreover, we extended the algorithm by combining user's true relevance judgments. better query model and more appropriate document scores by our proposed unified iterative optimization algorithm. Second, the optimization of the query model and document ranking function becomes dependent by systematically incorporating the query model and document score as components within the same framework. Finally, it provides a principled formulation of the query model and ranking refinement, which can serve as a general framework for systematically exploring other methods. 
The evaluated results on four test collections show that these methods are more ef-fective than the existing ones in the literature. In our future work, we will consider the problem of parameter optimization as well as the problem of document model refine-ment. Moreover, we can use extend the optimization algorithm by exploring other kind of retrieval model such as dependent ranking model. This work was supported by the National Science Foundation of China (Grants No.60736044, 60773027, 90920010), as well as 863 Hi-Tech Research and Develop-ment Program of China (Grants No. 2008AA01Z145, 2006AA010108). 
