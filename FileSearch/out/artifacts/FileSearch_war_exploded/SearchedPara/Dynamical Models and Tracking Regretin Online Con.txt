 Eric C. Hall ech11@duke.edu Rebecca M. Willett willett@duke.edu In a variety of large-scale streaming data problems, ranging from motion imagery formation to network analysis, dynamical models of the environment play a key role in performance. Classical stochastic filtering methods such as Kalman or particle filters or Bayesian updates (Bain &amp; Crisan, 2009) readily exploit dynami-cal models for effective prediction and tracking perfor-mance. However, classical methods are also limited in their applicability because (a) they typically assume an accurate, fully known dynamical model and (b) they rely on strong assumptions regarding a genera-tive model of the observations. Some techniques have been proposed to learn the dynamics (Xie et al., 1994; Theodor &amp; Shaked, 1996), but the underlying model still places heavy restrictions on the nature of the data. Performance analysis of these methods usually does not address the impact of  X  X odel mismatch X , where the generative models are incorrectly specified. A contrasting class of prediction methods is based on an  X  X ndividual sequence X  or  X  X niversal predic-tion X  (Merhav &amp; Feder, 1998) perspective; these strive to perform provably well on any individual observa-tion sequence. In particular, online convex program-ming methods (Nemirovsky &amp; Yudin, 1983; Beck &amp; Teboulle, 2003; Zinkevich, 2003; Cesa-Bianchi &amp; Lu-gosi, 2006) rely on the gradient of the instantaneous loss of a predictor to update the prediction for the next data point. The aim of these methods is to ensure that the per-round performance approaches that of the best offline method with access to the entire data sequence. This approach allows one to sidestep challenging is-sues associated with statistically dependent or non-stochastic observations, misspecified generative mod-els, and corrupted observations. This framework is limited as well, however, because performance bounds are typically relative to either static or piecewise con-stant comparators and do not adequately reflect adap-tivity to a dynamic environment.
 This paper describes a novel framework for prediction in the individual sequence setting which incorporates dynamical models  X  effectively a novel combination of state updating from stochastic filter theory and online convex optimization from universal prediction. We es-tablish tracking regret bounds for our proposed algo-rithm, Dynamic Mirror Descent (DMD), which scale with the deviation of a comparator sequence from a se-quence evolving with a known dynamic. These bounds simplify to previously shown bounds, when there are no dynamics. We further establish tracking regret bounds for another algorithm, Dynamic Fixed Share (DFS) , which scale with the deviation of a compara-tor sequence from a sequence evolving with the best sequence of dynamical models. While our methods and theory apply in a broad range of settings, we are par-ticularly interested in the setting where the dimen-sionality of the parameter to be estimated is very high relative to the data volume. In this regime, the incor-poration of both dynamical models and sparsity regu-larization plays a key role. With this in mind, we focus on a class of methods which incorporate regularization as well as dynamical modeling. The role of regular-ization, particularly sparsity regularization, is increas-ingly well understood in batch settings and has re-sulted in significant gains in ill-posed and data-starved settings (Banerjee et al., 2008; Ravikumar et al., 2010; Cand`es et al., 2006; Belkin &amp; Niyogi, 2003). In our experiments, we consider reconstructing motion imagery from sequential observations collected with a compressive camera and estimating the dynamic social network underlying over 200 years of U.S. Senate roll-call data. There has been significant recent interest in using models of temporal structure to improve time se-ries estimation from compressed sensing observations (Angelosante et al., 2009; Vaswani &amp; Lu, 2010) or for time-varying networks (Snijders, 2001; Kolar et al., 2010); the associated algorithms, however, are typi-cally batch methods poorly suited to large quantities of streaming data. This paper strives to bridge that gap. Let X denote the domain of our observations, and let  X  denote a convex feasible set. Given sequentially ar-riving observations x  X  X  X  , we wish to construct a sequence of predictions b  X  = ( b  X  1 , b  X  2 ,... )  X   X   X  b  X  may depend only on the currently available obser-vations x t  X  1 = ( x 1 ,...,x t  X  1 ). We pose our problem as a dynamic game between a Forecaster and the En-vironment. At time t , the Forecaster computes a pre-diction, b  X  t and the Environment generates the obser-vation x t . The Forecaster then experiences the loss ` ( b  X  t ), defined as follows. Let F and R denote fam-ilies of convex functions, and let f t (  X  ) , f (  X  ,x be a cost function measuring the accuracy of the pre-diction b  X  t with respect to the datum x t . Similarly, let r (  X  )  X  R be a regularization term which does not change over time; for instance, r might promote spar-sity or other low-dimensional structure in the poten-tially high-dimensional space  X . The loss at time t is where The task facing the Forecaster is to create a new pre-diction b  X  t +1 based on the previous prediction and the new observation, with the goal of minimizing loss at the next time step. We characterize the efficacy of b  X  quence  X  T , (  X  1 , X  2 ,..., X  T )  X   X  T as follows: Definition 1 (Regret) . The regret of b  X  T with respect to a comparator  X  T  X   X  T is Previous work proposed algorithms which yielded re-gret of O ( all t . Our goal is to develop an online convex optimiza-tion algorithm with low regret relative to a broad fam-ily of time-varying comparator sequences. In particu-lar, our main result is an algorithm which incorporates a dynamical model, denoted  X  t , which admits a regret bound of the form O ( bound scales with the compartor sequence X  X  deviation from the dynamical model  X  t  X  a stark contrast to pre-vious tracking regret bounds which are only sublinear for comparators which change slowly with time or at a small number of distinct time instances. In much of the online learning literature, the com-parator sequence is constrained to be static or time-invariant. In this paper we refer to the regret with respect to a static comparator as static regret : Definition 2 (Static regret) . The static regret of b  X  T is Static regret bounds are useful in characterizing how well an online algorithm performs relative to, say, a loss-minimizing batch algorithm with access to all the data simultaneously. More generally, static re-gret bounds compare the performance of the algorithm against a static point,  X   X  , which can be chosen with full knowledge of the data.
 However, this form of analysis fails to illuminate the performance of online algorithms in dynamic settings where a static comparator is inappropriate. Perfor-mance relative to a temporally-varying or dynamic comparator sequence has been studied previously in the literature in the context of tracking regret, shift-ing regret (Herbster &amp; Warmuth, 2001; Cesa-Bianchi et al., 2012), and the closely-related concept of adap-tive regret (Littlestone &amp; Warmuth, 1994; Hazan &amp; Seshadhri, 2009).
 In particular, tracking regret compares the output of the online algorithm to a sequence of points  X  , X   X  2 ,..., X   X  T which can be chosen collectively with full knowledge of the data. This is a fair comparison for a batch algorithm that detects and fits to drift in the data, instead of fitting a single point. Frequently, in order to bound tracking regret there needs to be a mea-sure of the complexity of the sequence  X   X  1 , X   X  2 ,..., X  Typically, this complexity is characterized via a mea-sure of the temporal variability of the sequence, such as If this complexity is allowed to be very high, we could imagine that the comparator series would fit the series of losses closely and hence generalize poorly. Con-versely if this complexity is restricted to be 0, the tracking regret becomes equivalent to static regret. Tracking and shifting regret are the same concept, al-though the term shifting regret is used more in the  X  X xperts X  setting, while tracking regret tends to be a more generic term.
 Adaptive regret is a related concept to tracking regret. Instead of measuring accumulated regret over the en-tire series, however, adaptive regret measures accumu-lated loss over an arbitrary time interval of length  X  , and measures performance against a static comparator chosen optimally on this interval:
R  X  , max This is a valuable metric as it assures that a process will have low loss not just globally, but also at any given moment. Intuitively we can see that an algo-rithm with low adaptive regret on any interval should also have low tracking regret and vice versa. The re-lationship between the two has been formally shown (Cesa-Bianchi et al., 2012).
 In this paper, we present tracking/shifting regret bounds which rely on a much more general notion of the complexity of a comparator sequence. In particu-lar, we could measure the complexity of a sequence in terms of how much it deviates from a given dynamical model , denoted  X  t : Ultimately, we consider a family of dynamical models, and we measure the complexity of a comparator in terms of how much it deviates from the best sequence of dynamical models in this family. (These concepts will be formalized and detailed in the next two sec-tions.) It is intuitively satisfying that this measure appears in the bound. Firstly, if the comparator actually follows the dynamics, we would imagine this complexity to be very small, leading to low tracking regret. This fact holds whether  X  t is part of the generative model for the observations or not. Secondly, we can get a dynamic analog of static regret, where we enforce V  X  (  X  T ) = 0. This is equivalent to saying that the batch comparator is fitting the best single trajectory using  X  t instead of the best single point. Using this, we would recover a bound analogous to a static regret bound in a station-ary setting.
 Concurrent related work considers online algorithms where the data sequence is described by a  X  X redictable process X  (Rakhlin &amp; Sridharan, 2012). By knowing a good estimate for the underlying process, they can create a prediction sequence that follows accordingly, reducing overall loss. However, they express their re-sults in terms of a static regret bound ( i.e., regret with respect to a static comparator) with a variation term that expresses the deviation of the input data from the underlying process. In contrast, we make no as-sumptions about the data itself, but instead on the comparator series, and form tracking regret bounds. One common approach to forming the predictions b  X  t , Mirror Descent (MD) (Nemirovsky &amp; Yudin, 1983; Beck &amp; Teboulle, 2003), consists of solving the fol-lowing optimization problem: where  X  ` t (  X  ) denotes an arbitrary subgradient of ` t  X  , D (  X  k b  X  t ) is the Bregman divergence between  X  and b  X  , and  X  t  X  0 is a step size parameter. Let  X  denote a continuously differentiable function that is  X  -strongly convex with respect to a norm k X k on the set  X  for some  X  &gt; 0; the Bregman divergence associated with  X  is defined as
D (  X  1 k  X  2 ) = D  X  (  X  1 k  X  2 ) (3a) for all  X  1 , X  2 , X  3  X   X , and the strong convexity of  X  implies The MD approach is a generalization of online learning algorithms such as online gradient descent (Zinkevich, 2003) and weighted majority (Littlestone &amp; Warmuth, 1994). Several recently proposed methods consider the data-fit term separately from the regularization term (Duchi et al., 2010; Xiao, 2010; Langford et al., 2009). For instance, consider Composite Objective Mirror De-scent (COMD) (Duchi et al., 2010): b  X  This formulation is helpful when the regularization function r (  X  ) promotes sparsity in  X  , and helps en-sure that the individual b  X  t are indeed sparse, rather than approximately sparse as are the solutions to the MD formulation. The regret of this approach has pre-viously been characterized as follows: Theorem 3 (Static regret for COMID (Duchi et al., 2010)) . Let G f , max  X   X   X  ,f  X  X  k X  f (  X  ) k , D max  X  1 , X  2  X   X  D (  X  1 k  X  2 ) and assume that  X  ,  X   X  2 =  X  X  X  =  X  T . If r ( b  X  1 ) = 0 and  X  t = Unlike the bound in Theorem 3, tracking or shift-ing regret (Cesa-Bianchi &amp; Lugosi, 2006; Cesa-Bianchi et al., 2012) bounds typically consider piecewise con-stant comparators, where  X  t  X   X  t  X  1 = 0 for all but m values of t , where m is a constant, or yield regret bounds which scale with P t k  X  t  X   X  t  X  1 k . In this pa-per, we develop tracking regret bounds which are small for much broader classes of dynamic comparator se-quences.
 In particular, we propose the following alternative to (2) and (4), which we call Dynamic Mirror Descent (DMD) . Let  X  t :  X  7 X   X  denote a predetermined dy-namical model, and set By including  X  t in the process, we effectively search for a predictor which (a) attempts to minimize the loss and (b) which is close to e  X  t under the transformation of  X  t . This is similar to a stochastic filter which al-ternates between using a dynamical model to update the  X  X tate X , and then uses this state to perform the filtering action. A key distinction of our approach, however, is that we make no assumptions about  X  t  X  X  relationship to the observed data.
 Our approach effectively includes dynamics into the COMID approach. Indeed, for a case with no dynam-ics, so that  X  t (  X  )  X   X  for all  X  and t , our method is equivalent to COMID. Rather than considering CO-MID, we might have used other online optimization algorithms, such as the Regularized Dual Averaging (RDA) method (Xiao, 2010), which has been shown to achieve similar performance with more regularized solutions. However, to the best of our knowledge, no tracking or shifting regret bounds have been de-rived for dual averaging methods (regularized or oth-erwise). Recent results on the equivalence of COMID and RDA (McMahan, 2011) suggest that the bounds derived here might also hold for a variant of RDA, but proving this remains an open problem.
 Our main result uses the following definitions: Theorem 4. Let  X  t be a dynamical model such that  X 
 X  t  X  0 . Let the sequence b  X  T be as in (5b) , and let  X  T be an arbitrary sequence in  X  T . Then the Dy-namic Mirror Descent (DMD) algorithm using a non-increasing series  X  t +1  X   X  t gives where V  X  t (  X  T ) measures variations or deviations of the comparator sequence  X  T from the dynamical model  X  t . Note that when  X  t corresponds to an identity operator, the bound in Theorem 4 corresponds to existing track-ing or shifting regret bounds (Cesa-Bianchi &amp; Lugosi, 2006; Cesa-Bianchi et al., 2012). The condition that  X 
 X  t  X  0 is similar to requiring that  X  t be a contrac-tion mapping. This restriction is important; without it, any poor prediction made at one time step could be magnified by repeated application of the dynam-ics. Additive models and matrix multiplications with all eigenvalues less than or equal to unity satisfy this restriction. Notice also that if  X  t = I for all t , the the-orem gives a novel tracking regret bound for COMID. To prove Theorem 4, we employ the following lemma, which is proven in Section 9.
 Lemma 5. Let the sequence b  X  T be as in (5b) , and let  X 
T be an arbitrary sequence in  X  T ; then Proof of Theorem 4: The proof is a matter of sum-ming the bounds of Lemma 5 over time. For simplicity denote D t , D (  X  t k b  X  t ) and V t , k  X  t +1  X   X  t (  X  R T (  X  T )  X  We set  X  t using the doubling trick (Cesa-Bianchi &amp; Lu-gosi, 2006) whereby time is divided into increasingly longer segments, and on each interval a temporary time horizon is fixed, known, and used to determine an optimal step size (generally proportional to the in-verse of the square root of the time horizon). This approach yields the regret bound: This proof shares some ideas with the tracking regret bounds of (Zinkevich, 2003), but uses properties of the Bregman Divergence to eliminate some terms, while additionally incorporating dynamics. DMD in the previous section uses a single dynamical model. In practice, however, we do not know the best dynamical model to use, or the best model may change over time in nonstationary environments.
 To address this challenge, we assume a finite set of candidate dynamical models {  X  (1) t ,  X  (2) t ,...  X  ( N ) describe a procedure which uses this collection to adapt to nonstationarities in the environment. In par-ticular, we establish tracking regret bounds for a com-parator class with different dynamical models on dif-ferent time intervals . This class,  X  m , can be described as all predictors defined on m + 1 segments [ t i ,t i +1 with time points 1 = t 1 &lt;  X  X  X  &lt; t m +2 = T + 1. For a given  X  T  X   X  m and k = 1 ,...,m + 1, let denote the deviation of the sequence  X  T from the best series of m + 1 dynamical models.
 Let b  X  ( i ) t denote the output of the DMD algorithm of Section 5 using dynamical model  X  ( i ) t . Then tracking regret can be expressed as: R T ( X  m ) = where the minimization in the second term of T 1 and first term of T 2 is with respect to sequences of dy-namical models with at most m switches, such that P tracking regret of our algorithm relative to the best sequence of dynamical models within the DMD frame-work, and T 2 is the regret of that sequence relative to the best comparator in the class  X  m .
 We choose b  X  t by using the Fixed Share (FS) forecaster on the DMD estimates of (5), b  X  ( i ) t . In FS, each expert (here, each candidate dynamical model) is assigned a weight that is inversely proportional to its cumula-tive loss at that point yet with some weight shared amongst all the experts, so that an expert with very small weight can quickly regain weight to become the leader (Cesa-Bianchi &amp; Lugosi, 2006). Our estimate is: Following (Cesa-Bianchi &amp; Lugosi, 2006), we have T and T 2 can be bounded using the method described in Section 5 on each time interval [ t k ,t k +1  X  1] and summing over the m + 1 intervals, yielding Letting  X  r =  X  t = 1 / regret is thus
R T (  X  T ) = O The last term in this bound measures the deviation of a comparator in  X  m from the best series of dynamical models over m + 1 segments (where m does not scale with T ). Here  X  is usually chosen to be m T where m is an upper bound on the number of switches, indepen-dent of T . Again, if T is not known in advance the doubling trick can be used. Note that V ( m +1) (  X  T )  X  V proach generally yields lower regret than using a fixed dynamical model. However, we incur some loss by not knowing the optimal number of switches m or when the switching times are; these are accounted for in T 1 . We use the Fixed Share algorithm as a means to amal-gamate estimates with different dynamics, however other methods could be used with various tradeoffs. The Fixed Share algorithm, for instance, has linear complexity with low regret, but with respect to a com-parator class with fixed number of switches. Other al-gorithms can accommodate larger classes of experts, or not assume knowledge of the number of switches, but come at the price of higher regret or complexity as explained in (Gyorgy et al., 2012). To demonstrate the performance of Dynamic Mirror Descent (DMD) combined with the Fixed share algo-rithm (which we call Dynamic Fixed Share (DFS) ), we consider two scenarios: reconstruction of a dynamic scene ( i.e., video) from sequential compressed sensing observations, and tracking connections in a dynamic social network. 7.1. Compressive video reconstruction To test DMD, we construct a video which contains an object moving in a 2-dimensional plane; the t th frame is denoted  X  t (a 150  X  150 image stored as a length-22500 vector) which takes values between 0 and 1. The corresponding observation is x t = A t  X  t + n t , where A is a random 500  X  22500 matrix and n t corresponds to measurement noise. This model coincides with several compressed sensing architectures (Duarte et al., 2008). We used white Gaussian noise with variance 1.
 Our loss function uses f t (  X  ) = 1 2 k x t  X  A t  X  k r (  X  ) =  X  k  X  k 1 , where  X  &gt; 0 is a tuning parameter. We construct a family of N = 9 dynamical mod-direction corresponding to an angle of 2  X i/ ( N  X  1) as well as a  X  X ynamic X  corresponding to no motion. (With the static model, DMD reduces to COMID.) The true video sequence uses different dynamical mod-els over t = { 1 ,..., 240 } and t = { 241 ,..., 500 } . Fi-nally, we use  X  (  X  ) = k X k 2 2 so the Bregman Divergence D ( x k y ) = k x  X  y k 2 2 is the usual squared Euclidean dis-tance. The DFS forecaster uses  X  = 0 . 01. Figures 1 and 2 show the impact of using DFS. We see that DFS switches between dynamical models rapidly and outperforms all of the individual predictions, in-cluding COMID, used as a baseline, to show the ad-vantages of incorporating knowledge of the dynamics. 7.2. Tracking dynamic social networks Dynamical models have a rich history in the context of social network analysis (Snijders, 2001), but we are unaware of their application in the context of online learning algorithms. To show how DMD can bridge this gap, we track the influence matrix of seats in the US Senate from 1795 to 2011 using roll call data (http://www.voteview.com/dwnl.htm). At time t , we observe the  X  X ea X  or  X  X ay X  vote of each Senator, which we represent with a +1 or  X  1. When a Senator X  X  vote is unavailable (for instance, before a state joined the union), we use a 0. We form a length p = 100 vector of these votes indexed by the Senate seat, and denote this x t .
 Following (Ravikumar et al., 2010), we form a loss function using a negative log Ising model pseudolikeli-hood to sidestep challenging issues associated with the partition function of the Ising model likelihood. For a social network with p agents,  X  t  X  [  X  1 , 1] p  X  p , where (  X  t ) ab corresponds to the correlation in voting patterns between agents a and b at time t . Let V denote the set of agents, V\ a the set of all agents except a , x the vote of agent a , and  X  a , {  X  ab : b  X  V} . Our loss function is f and r (  X  ) =  X  k  X  k 1 , where  X  &gt; 0 is a tuning parameter; this loss is convex in  X  . We set  X  (  X  ) = 1 2 k  X  k 2 2 a dynamical model inspired by (Snijders, 2001), where members of the network share a strong common con-nection, they will become connected in time. We set  X  i  X  X  0 ,. 001 ,. 002 ,. 003 ,. 004 } for the different dynam-ical models. We set  X  = . 1 and again set  X  using the doubling trick with time horizons at set at increasing powers of 10. As in (Langford et al., 2009), we find that regularizing ( e.g., thresholding) every 10 steps, instead of at each time step, allows for the values to grow above the threshold for meaningful relationships to be found. Figure 3 shows the average per round loss of each model, and the DFS estimator over a 30 year time window. We see that applying the dynamical model improves performance relative to COMID (  X  i = 0) and that DFS aggregates the predictions successfully. Figure 4 shows the moving average losses for a few Senators, where high loss corresponds to behavior un-expected in the model. Notice that John Kerry (D-MA) has generally low loss, spikes around 2006, and then drops again before a reelection campaign in 2008. Looking at the network estimates of DFS across time (as in Figure 5) we can see tight factions forming in the mid-to late-1800s (post Civil War), followed by a time when the factions dissipate in the mid-1900s during the Civil Rights Movement. Finally, we see factions again forming in more recent times. The seats are sorted sep-arately for each matrix to emphasize groupings, which align with known political factions. In this paper we have proposed a novel online op-timization method, called Dynamic Mirror Descent (DMD), which incorporates dynamical model state up-dates. There is no assumption that there is a  X  X rue X  known underlying dynamical model, or that the best dynamical model is unchanging with time. The pro-posed Dynamic Fixed Share (DFS) algorithm adap-tively selects the most promising dynamical model from a family of candidates at each time step. Re-cent work on shifting or tracking regret bounds for online convex optimization further suggest that the techniques developed in this paper may also be useful for bounding adaptive regret or developing methods for automatically tuning step-size parameters (Cesa-Bianchi et al., 2012). In experiments with real and simulated data, DMD shows strong tracking behavior even when underlying dynamical models are switching. Proof of Lemma 5: The optimality condition of (5a) implies Using this condition we can bound the instantaneous regret as follows: f t ( b  X  t )  X  f t (  X  t ) + r ( b  X  t )  X  r (  X  t ) T 3 ,  X  T T Here, (14a) follows from the convexity of f t and r , (14b) follows from the optimality condition of (5a), and (14c) follows from (3c) and adding and subtracting terms using the equivalence (5b). Each of term can be bounded, and then combined to complete the proof.
T
T where (15a) is due to the strong convexity of the Breg-man Divergence and Young X  X  inequality and (15b) is due to the convexity of  X  and the Cauchy-Schwarz in-equality. Combining these inequalities with (14c) gives the Lemma as it is stated.
 Angelosante, D., Giannakis, G. B., and Grossi, E. Compressed sensing of time-varying signals. In Intl Conf. on Dig. Sig. Proc. , 2009.
 Bain, A. and Crisan, D. Fundamentals of Stochastic Filtering . Springer, 2009.
 Banerjee, O., El Ghaoui, L., and d X  X spremont, A.
Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data. J. Mach. Learn. Res. , 9:485 X 516, 2008.
 Beck, A. and Teboulle, M. Mirror descent and nonlin-ear projected subgradient methods for convex pro-gramming. Operations Research Letters , 31:167 X  175, 2003.
 Belkin, M. and Niyogi, P. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Comput. , 15(6):1373 X 1396, June 2003.
 Cand`es, E., Romberg, J., and Tao, T. Stable signal recovery from incomplete and inaccurate measure-ments. Communications on Pure and Applied Math-ematics , 59(8):1207 X 1223, 2006.
 Cesa-Bianchi, N. and Lugosi, G. Prediction, Learning and Games . Cambridge University Press, New York, 2006.
 Cesa-Bianchi, N., Gaillard, P., Lugosi, G., and Stoltz,
G. A new look at shifting regret. arXiv:1202.3323, 2012.
 Duarte, M. F., Davenport, M. A., Takhar, D., Laska,
J. N., Sun, T., Kelly, K. F., and Baraniuk, R. G. Sin-gle pixel imaging via compressive sampling. IEEE Sig. Proc. Mag. , 25(2):83 X 91, 2008.
 Duchi, J., Shalev-Shwartz, S., Singer, Y., and Tewari, A. Composite objective mirror descent. In Conf. on Learning Theory (COLT) , 2010.
 Gyorgy, A., Linder, T., and Lugosi, G. Efficient track-ing of large classes of experts. IEEE Transaction on Information Theory , 58:6709 X 6725, November 2012. Hazan, E. and Seshadhri, C. Efficient learning al-gorithms for changing environments. In Proc. Int.
Conf on Machine Learning (ICML) , pp. 393 X 400, 2009.
 Herbster, M. and Warmuth, M. K. Tracking the best linear predictor. Journal of Machine Learning Re-search , 35(3):281 X 309, 2001.
 Kolar, M., Song, L., Ahmed, A., and Xing, E. P. Es-timating time-varying networks. Annals of Applied Statistics , 4(1):94 X 123, 2010.
 Langford, J., Li, L., and Zhang, T. Sparse online learn-ing via truncated gradient. J. Mach. Learn. Res. , 10: 777 X 801, 2009.
 Littlestone, N. and Warmuth, M. K. The weighted majority algorithm. Inf. Comput. , 108(2):212 X 261, 1994.
 McMahan, B. A unified view of regularized dual av-eraging and mirror descent with implicit updates. arXiv:1009.3240v2, 2011.
 Merhav, N. and Feder, M. Universal prediction. IEEE Trans. Info. Th. , 44(6):2124 X 2147, October 1998. Nemirovsky, A. S. and Yudin, D. B. Problem com-plexity and method efficiency in optimization . John Wiley &amp; Sons, New York, 1983.
 Rakhlin, A. and Sridharan, K. Online learning with predictable sequences. arXiv:1208.3728, 2012. Ravikumar, P., Wainwright, M. J., and Lafferty, J. D.
High-dimenstional Ising model selection using ` 1 -regularized logistic regression. Annals of Statistics , 38:1287 X 1319, 2010.
 Snijders, T. A. B. The statistical evaluation of social network dynamics. Sociological Methodology , 31(1): 361 X 395, 2001.
 Theodor, Y. and Shaked, U. Robust discrete-time minimum-variance filtering. IEEE Trans. Sig. Proc. , 44(2):181 X 189, 1996.
 Vaswani, N. and Lu, W. Modified-CS: Modifying com-pressive sensing for problems with partially known support. IEEE Trans. Sig. Proc. , 58:4595 X 4607, 2010.
 Xiao, L. Dual averaging methods for regularized stochastic learning and online optimization. J. Mach. Learn. Res. , 11:2543 X 2596, 2010.
 Xie, L., Soh, Y. C., and de Souza, C. E. Robust
Kalman filtering for uncertain discrete-time sys-tems. IEEE Trans. Autom. Control , 39:1310 X 1314, 1994.
 Zinkevich, M. Online convex programming and gen-eralized infinitesimal gradient descent. In Proc. Int.
Conf. on Machine Learning (ICML) , pp. 928 X 936,
