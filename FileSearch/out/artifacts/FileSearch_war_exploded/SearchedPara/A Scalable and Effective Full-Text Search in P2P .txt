 We consider the problem of full-text search involving multi-term queries in a network of self-organizing, autonomous peers. Existing approaches do not scale well with respect to the number of peers, because they either require access to a large number of peers or incur a high communication cost in order to achieve good query results. In this paper, we present a novel algorithmic framework for processing multi-term queries in P2P networks that achieves high recall while using (per-query) a small number of peers and a low com-munication cost, thereby enabling high query throughput. Our approach is based on per-query peer-selection strategy using two-dimensional histograms of score distributions. A full utilization of the histograms incurs a high communica-tion cost. We show how to drastically reduce this cost by employing a two-phase peer-selection algorithm. We also describe an adaptive approach to peer selection that further increases the recall. Experiments on a large real-world col-lection show that the recall is indeed high while the number of involved peers and the communication cost are low. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Search processes Algorithms, Performance, Experiments P2P search, DHT, clustering, histograms The work of this author is part of his Ph.D. research at The Hebrew University of Jerusalem. The work of this author was supported by The German-Israeli Foundation for Scientific Research &amp; Development (Grant 973 X 150.6/2007).

Search in peer-to-peer (P2P) systems can be used to find information that resides on distributed and autonomous ma-chines. Currently, the most successful fully decentralized P2P applications are for file sharing (e.g., Gnutella 1 and BitTorrent 2 ). Those systems search for files that have the given terms in their names. We consider a more general setup of autonomous peers, where each one holds a collec-tion of documents and users can search the full content.
P2P networks can be classified into structured and un-structured networks. In an unstructured network, a query is propagated between neighboring peers until matching files are found. Due to the unstructured architecture, search requests do not always return results, because there is no bound on the number of peers that a message has to pass before it reaches a peer with the requested resource.
Structured networks can guarantee that a resource (iden-tified by a unique key) will be found after at most O ( logn ) messages, where n is the number of peers. This is done by means of a distributed hash table (DHT) that facilitates the mapping of resources to peers using a hashing function that is known to all peers. In particular, the DHT views each term t (appearing in either the name or content of a docu-ment) as a resource and maps it to a specific peer p t that is responsible for keeping all the information about t .Ev-ery peer sends the information about its terms to the peers responsible for those terms.

When a conjunctive query q =( t 1 ,...,t n )isinitiatedat peer p q , the following is done. Firstly, p q uses the DHT to lo-cate the peers p t 1 ,...,p t n that are responsible for the query terms. Next, peer p q contacts each p t i and requests the post-ing list that p t i is responsible for. Based on the statistics available in those lists, p q estimates the top-K most promis-ing peers for answering the query. Then, p q sends the query to those top-K peers, and each one of them returns its own top-k results. Finally, p q finds the top-k documents among all the returned results. ( K and k need not be the same.)
The challenge is how to achieve a good recall of the top-k documents (where the reference/ground truth is defined as the top-k results among all the peers in the P2P network), while keeping at a minimum both the number of contacted peers and the overall communication cost (i.e., the number of bytes sent). Several solutions [1, 7, 4, 6, 5] proposed different granularities of the statistics about terms. These solutions include a whole range of options: coarse statistics (i.e., peer-level summaries about the occurrences of each term), very http://rfc-gnutella.sourceforge.net/ http://www.bittorrent.com/ fine-grained statistics (e.g., inverted indexes) at least about some of the terms, and in between, statistics about groups X  each consisting of several documents.

In this paper, we propose a novel solution for efficiently handling conjunctive multi-term queries, by keeping per-term statistics as score distributions using two-dimensional histograms. One dimension of the histogram reflects a clus-tering of the documents (of the given peer), and the other di-mension describes the score distribution (of the given term) in each cluster.

Our contribution is twofold. First, we give an algorithm that achieves a significantly higher recall at a cost that has the same order of magnitude as the one incurred by the state-of-the-art methods. The second contribution is an adaptive algorithm that improves recall by using the scores of already available answers in order to locate peers that are likely to have even better answers. We verify our approach on a large, real-world dataset; in particular, we show that our algorithms achieve good recall even when the communi-cation cost is low and the number of peers that are contacted is relatively small.

The paper is organized as follows. In Section 2, we present the peer-selection strategy using the two-dimensional his-tograms. In Section 3, we develop the two-phase algorithm that improves the recall at a reduced cost compared to a more straightforward approach. In Section 4, we present the adaptive peer-selection strategy. Section 5 describes the experiments that verify the effectiveness of our algorithms and includes a comparison with the state of the art. Finally, we discuss future work and conclude in Section 6.
We now describe the two-dimensional histograms for term statistics. We show how to utilize them in query processing to achieve high recall of the top-k documents that match a conjunctive multi-term query, while keeping at a minimum both the number of peers that are contacted and the com-munication cost.

The general idea is the following. Each peer p i partitions its documents into groups, which are not necessarily dis-joint. For all groups g and terms t j ,peer p i keeps the score distribution of the documents in g with respect to term t Thus, we obtain a two-dimensional histogram H ij ( g, s ) for term t j in peer p i , where rows represent document groups and columns represent score ranges. The cell ( g, s )contains thenumberofdocumentsingroup g that have scores in the range (i.e., interval) that is represented by column s .
Figure 1 shows two equi-width histograms for the terms t and t 2 in some peer. In this example, the partitioning is naively done according to the document id X  X , namely, every 100 documents form a group. The score dimension is given in ascending order with an interval width of 0.2. For ex-ample, the histogram for t 1 shows that five out of the first 100 documents have a score in the interval [0 . 6 , 0 . 8). Note that in each peer, the histograms of all the terms use the same partitioning. However, distinct peers have different documents (and, hence, different groups).

For each term t ,adocument d has a score denoted by score t ( d ). For a query q =( t 1 ,...,t n ), the score of d is denoted by score q ( d ) and is defined by some monotonic ag-gregate function f ( score t 1 ( d ) ,...,score t n ( d )). For example, f can be the sum of the scores. However, if some of the key-words of q do not appear in d ,then score q ( d )=0;thus, d is relevant to q only if it includes all the keywords of q .Now,
Figure 1: Two histograms for the terms t 1 and t 2 consider a group g of documents. Ideally, we would like to calculate the expected value of score q ( d ), where d is a doc-ument that is randomly chosen from g . A higher expected value indicates that g is more relevant to the query q .We call this expected value the score of g for the query q and denote it by score q ( g ).

Computing the exact value of score q ( g ) is impossible; in-stead, we would like to estimate it. A naive approach is to keep for each term t ,thevalue max t that is defined as the maximum of score t ( d ) over all the documents d of g .For the query q =( t 1 ,...,t n ), we can use f ( max t 1 ,...,max as an estimate of the score of g for q .

The score distributions given by the histograms can pro-vide a better estimation of the score of g as follows. Consider the query q =( t 1 ,...,t n ) and some fixed group g in peer p ; thus, we only need the row for g from each two-dimensional histogram. We assume that each histogram is divided into m score intervals. 3 In Figure 1, for example, m =4. The score intervals in each histogram are identified (from left to right) as 1 , 2 ,...,m .

Let C be the set of all tuples ( h 1 ,...,h n ), where 1  X  m ( i =1 ,...,n ). A tuple h =( h 1 ,...,h n )  X  C describes a combination of choosing one interval from the histogram of each term t i of the query. In particular, h corresponds to interval h 1 from the histogram of t 1 ,interval h 2 from the histogram of t 2 and so on. We define the score of a particular interval as its middle point (i.e., the average of the end points). The score of h , denoted by score ( h ), is defined by applying the aggregate function f to the scores of all the h i (i.e., as if ( h 1 ,...,h n ) represents a document that has the score of h j for the term t j ).

For example, consider the first group (first row) in the histograms of Figure 1. The tuple (3 , 4) represents the in-terval [0 . 6 , 0 . 8] from the histogram of t 1 and the interval [0 . 8 , 1 . 0] from the histogram of t 2 . The score of this tuple is f (0 . 7 , 0 . 9), which is 1 . 6if f is sum .

Consider some h =( h 1 ,...,h n )  X  C .Wesaythata document d of g is in h if score t j ( d )  X  h i (1  X  j  X  is, the scores of d for the terms t 1 ,...,t n are in the intervals identified by h 1 ,...,h n , respectively. It follows that if d is in h then score q ( d ) &gt; 0, because the intervals include only positive scores. In Figure 1, for example, the intervals cover the range from 0 . 2to1 . 0.

Our estimate of the score of g for the query q is given by the following expression.
In principle, m can vary from one histogram to another (even in the same peer), but for clarity of presentation, we do not consider this generalization. In other words, for each tuple h of C , we multiply the score of h by the probability that a randomly chosen document of g is in h and then take the sum over all the possible combinations (which are described by the tuples of C ). We multiply the sum by | g | to give higher scores to larger groups (multiplying by | g | modestly improved the recall in our experiments). Next, we describe how to estimate each probability in the above sum.

Consider the tuple h =( h 1 ,...,h n )andlet X j be the value of the histogram for the interval h j .Thatis, X j doc-uments of g have a score for t j that falls in the interval h For example, if the tuple (3 , 4) refers to the first group in the histograms of Figure 1, then the values are X 1 =5and X 2 =4. Let N be the total number of documents in the group g . The probability that a random document d of g satisfies score t j ( d )  X  h j is simply X j N . Assuming that distri-butions of different terms are independent of one another, the following is the probability that d is in ( h 1 ,...,h
Thus, for each h  X  C , we substitute the above product for the corresponding probability in Expression (1).

We take the score of peer p i to be the maximum score over all its groups, namely,
We can now use score q ( p ) to rank the peers and select the most promising ones for the task of executing the query.
The communication cost when using histograms can be quite high compared to methods like cdf-ctf [1], where the statistics per term contains only two numbers.

Our two-phase peer-selection algorithm combines the ef-fectiveness of histograms with the low cost of methods like cdf-ctf. It works as follows.

In the first phase, the initiating peer p q uses a method (such as cdf-ctf) that has a low communication cost in or-der to select the top- X  K most promising peers, where  X  K is larger than K but still much smaller than the number of peers in the network. In the second phase, p q contacts the peers responsible for the query terms and requests only the histograms of the  X  K peers that were selected in the first phase. Next, p q uses the histograms to select the top-K most promising peers, and sends the query to them.
The algorithms of the previous sections select the top-K most promising peers and get the top-k results from each one. A naive approach to improving the recall is simply by increasing K . In this section, we describe an algorithm that achieves a recall that is higher than the one gained by the naive approach. The algorithm increases K , but it does so in stages as follows. Initially, K = k and the algorithm selects the top-k most promising peers, and each one of them sends its top-k documents to the initiating peer. Let min k be the minimal score among the top-k documents obtained from the k  X  k results. When applying Expression (1) again, we would like to exclude all documents d that cannot have a score higher than min k . We do it as follows.

Let h =( h 1 ,...,h n ) be a tuple of C . Recall that score ( h ) is obtained by applying the aggregate function f to the mid-dle points of the h j . We similarly define high ( h ), except that f is computed over the highest endpoints of the h j ,namely, where high ( h j ) is the right endpoint of the interval h
For example, consider again the tuple h =(3 , 4) and the first group (first row) in the histograms of Figure 1. Then, high ( h )= f (0 . 8 , 1 . 0), which is 1 . 8if f is sum .
The following Lemma gives a lower bound on the score of documents that can be among the top-k (instead of some of those that are in the current top-k ).

Lemma 4.1. Let min k be the minimal score among the current top-k results. Consider a tuple h  X  C .Ifhigh ( h ) &lt; min k , then there is no document d in h that can replace any of the current top-k results.

Proof. Suppose that a document d is in h . By definition, high ( h ) is an upper bound on the score of d . Therefore, score q ( d ) &lt; min k .
 We use the above lemma as follows. When evaluating Expression (1), we eliminate from the sum all tuples h  X  C , such that high ( h ) &lt; min k . Thus, we get a better estimate of the expected score of a random document (of the given group), because we compute it only over documents that can still be among the top-k .

To summarize, the algorithm works as follows. In each stage, it selects the next top-k most promising peers by us-ing the remaining histograms (i.e., of the peers that have not yet been chosen). The selection is done by applying Expres-sion (1) as described above. After the selection is made, the initiating peer gets the top-k documents from each of the selected peers, updates its list of the top-k results, updates min k , and then continues to the next stage. The algorithm can safely terminate when high ( h ) &lt; min k holds for all the remaining h .

In practice, this termination condition is rarely reached before selecting a large portion of the peers, because high ( h ) is a very rough upper bound on the actual score of docu-ments in h .

The experiments of Section 5 show that the adaptive peer selection improves the recall. In fact, we even apply a more aggressive strategy by taking min k to be the score of the document in position k/ 2. This strategy gives, in practice, a better improvement compared to using min k .
In this section, we present experimental results on full-text search in a P2P network. Our goal is to increase the quality of the answers in a manner that reduces the overall cost in comparison to existing methods. The collection we use comprises blog data crawled from BlogSpot. 4 Altogether http://blogger.com we have 10 , 000 blogs with a total of 1 , 014 , 356 posts (doc-uments). We divided the data between 1 , 000 logical peers, resulting in about 1 , 000 documents per peer. The peers use the Lucene 5 open-source system for retrieving and ranking their documents.

We have experimented with 75 queries taken from the blog track 6 of TREC 2008. The number of terms in the queries ranges from two to seven.
We partitioned the data on each peer p i into sqrt ( | D i clusters, where | D i | is the number of documents in p i used two types of clustering. The first is a naive cluster-ing that is done by taking equal ranges of document id X  X  as the groups. The second approach is by applying the latent-Dirichlet-allocation (LDA) clustering algorithm [2]. Figure 2 shows the recall of the top-10 results vs. the num-ber of selected peers (i.e., K ) for the following five methods. The first two, hist-naive and hist-LDA, use two-dimensional histograms with score intervals of 0 . 5 in conjunction with the above two clustering techniques, respectively. Both cdf-ctf [1] and CORI [3] are methods that use peer-level (rather than group-level) statistics. The fifth method, cdf-ctf-LDA, uses the cdf-ctf information at the cluster level. The combination of histograms with LDA clustering (hist-LDA) outperformed all the other methods. For example, when selecting 20 peers, CORI and cdf-ctf achieved a recall of 0.25 and 0.33, respectively, while hist-LDA was better by more than 50% (a recall of 0 . 52). Figure 2: Recall vs. number of selected peers for CORI, cdf-ctf, cdf-ctf-LDA, hist-naive and hist-LDA
Due to space limitation, we do not show the saving in the communication cost when using the two-phase algorithm.
We now show the improvement in the recall achieved by the adaptive algorithm of Section 4. In the first round of this algorithm, we use hist-LDA to select the 10 most promising peers. After getting the top-10 answers from the selected peers, we re-rank the rest of the peers using the score of the fifth-ranked answer as min k (see Section 4 for details). We prefer this choice of min k (rather than taking min k to be the smallest score among the top-10 answers), because high ( h ) (defined in Equation (3)) is typically much larger than the score of any document d that is actually in h .

Figure 3 shows the recall of the top-10 results vs. the number of selected peers for the adaptive and non-adaptive http://lucene.apache.org http://trec.nist.gov/data/blog08.html versions of hist-LDA, using score intervals of 0 . 2. In the former, we re-rank the remaining peers after each round of getting answers from another 10 peers. When re-ranking, min k is the score of an answer that is ranked slightly lower (e.g., sixth position) than the one used in the previous round (since the new top-10 are closer to the exact top-10). Fig-ure 3 shows an increasing improvement in the recall with each additional round. For example, the adaptive hist-LDA achieves a recall of 0 . 56 after two rounds (i.e., accessing 20 peers), compared to 0 . 52 for the non-adaptive version. After five rounds (50 peers), the recall increases from 0 . 69 to 0 . 79. Figure 3: Recall vs. number of selected peers for the adaptive and non-adaptive algorithms
We presented an effective and efficient method for full-text search in an environment of autonomous peers that are organized as a structured P2P network. Our approach is based on locally partitioning the collection of each peer and using two-dimensional histograms that describe score distri-butions. The experiments showed an improvement of more than 50% in the recall compared to state-of-the-art meth-ods when accessing the same number of peers. By using the two-phase and adaptive algorithms, we can further improve the recall while reducing the communication cost.

For future work, we plan to investigate other types of his-tograms; for example, equi-depth histograms for the score dimension. Another important problem is how to efficiently maintain the histograms in a dynamic environment, where the document collections of the peers are constantly updated and peers can join and leave the network.
