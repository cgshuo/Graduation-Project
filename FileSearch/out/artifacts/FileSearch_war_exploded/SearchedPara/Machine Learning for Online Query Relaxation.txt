 In this paper we provide a fast, data-driven solution to the failing query problem: given a query that returns an empty answer, how can one relax the query X  X  constraints so that it returns a non-empty set of tuples? We introduce a novel algorithm, loqr , which is designed to relax queries that are in the disjunctive normal form and contain a mixture of dis-crete and continuous attributes. loqr discovers the implicit relationships that exist among the various domain attributes and then uses this knowledge to relax the constraints from the failing query.

In a first step, loqr uses a small, randomly-chosen sub-set of the target database to learn a set of decision rules that predict whether an attribute X  X  value satisfies the con-straints in the failing query; this query-driven operation is performed online for each failing query. In the second step, loqr uses nearest-neighbor techniques to find the learned rule that is the most similar to the failing query; then it uses the attributes X  values from this rule to relax the fail-ing query X  X  constraints. Our experiments on six application domains show that loqr is both robust and fast: it suc-cessfully relaxes more than 95% of the failing queries, and it takes under a second for processing queries that consist of up to 20 attributes (larger queries of up to 93 attributes are processed in several seconds).
 I.2.6 [ Artificial intelligence ]: Learning Algorithms, Experimentation online query relaxation, failing query, rule learning, nearest neighbor, Web-based information sources Copyright 2004 ACM 1-58113-888-1/04/0008 ... $ 5.00.
The proliferation of online databases lead to an unprece-dented wealth of information that is accessible via Web-based interfaces. Unfortunately, exploiting Web-based infor-mation sources is non-trivial because the user has only indi-rect access to the data: one cannot browse the whole target database, but rather only the tuples that satisfy her queries. In this scenario, a common problem for the casual user is coping with failing queries , which do not return any answer. Manually relaxing failing queries is a frustrating, tedious, time-consuming task because, in the worst case, one must consider an exponential number of possible relaxations (i.e., various combinations of values for each possible subset of attributes); furthermore, these difficulties are compounded by the fact that over-relaxing the query (i.e., weakening the constraints so that there are many tuples that satisfy them) may lead to prohibitive costs in terms of bandwidth or fees to be paid per returned tuple. Researchers have proposed automated approaches to query relaxation [12, 9, 7], but the existing algorithms have a major limitation: the knowl-edge used in the query relaxation process is acquired offline , independently of the failing query to be relaxed.

We introduce here an online, query-guided algorithm for relaxing failing queries that are in the disjunctive normal form. Our novel algorithm, loqr 1 , uses a small, randomly-chosen subset D of the target database 2 to discover implicit relationships among the various domain attributes; then it uses this extracted domain knowledge to relax the failing query.

Given the small dataset D and a failing query, loqr pro-ceeds as follows. In the first step, it uses D to learn decision rules that predict the value of each attribute from those of the other ones. This learning step is on-line and query-guided : for each attribute Attr in the failing query, loqr uses the other attributes X  values to predict whether the value of Attr satisfies the query X  X  constraints on it. Then, in a sec-ond step, loqr uses nearest-neighbor techniques to find the learned rule that is the most similar to the failing query. Finally, loqr relaxes the query X  X  constraints by using the attribute values from this  X  X ost similar X  rule.

For example, consider an illustrative laptop purchasing scenario in which the query loqr stands for L earning for O nline Q uery R elaxation
As we will show in the empirical validation, as long as the examples in D are representative of those in the target database TD , D and TD can be -in fact -disjoint. fails because large-screen laptops weigh more than three pounds. In the first step, loqr uses a small dataset of laptop configurations to learn decision rules such as The right-hand side (i.e., the consequent) of this rule con-sists of a constraint from the failing query, while the left-hand side specifies the conditions under which this con-straint is satisfied in the dataset D . After learning such rules for each constraint in the query, loqr uses nearest-neighbor techniques to find the learned rule that is the most similar to the failing query (for the time being, let us assume that the rule R is this  X  X ost similar X  rule).

To relax the failing query, loqr  X  X uses X  the constraints on the attributes that appear in both Q and R . In our example, the relaxed query is obtained as follows: R  X  X  constraint on CPU is ignored because CPU does not appear in Q . Q  X  X  constraint on the screen size is dropped because it conflicts with the one in R ( Display cannot be simultaneously smaller that 13 X  and larger than 17 X ). Finally, Q  X  X  price limit is increased to the value in R , which is less constraining than the original amount of $2 , 000. Note that this price increase is crucial for ensuring that Q R does not fail: as long as the constraints in Q
R , which are a subset of R  X  X , are at most as tight as those in R , Q R is guaranteed to match at least the tuples covered by R (i.e., the examples from which R was learned).
In summary, the main contribution of this paper is a novel, data-driven approach to query relaxation. Our on-line, query-guided algorithm uses a small dataset of domain examples to extract implicit domain knowledge that is then used to relax the failing query. The rest of the paper is organized as follows: after discussing the related work, we present a detailed illustrative example. Then we describe the loqr algorithm and discuss its empirical validation.
Query modification has long been studied in both the fields of databases and information retrieval [15, 18, 10, 13, 17, 4, 19, 2, 5, 3]. More recently, with the advent of XML, researchers have proposed approaches for approximate pat-tern matching [25], answer ranking [11], and XML-oriented query relaxation [1, 16, 20]. co-op [18] is the first system to address the problem of empty answers (i.e., failing queries). co-op is based on the idea of identifying the failing query X  X  erroneous presupposi-tions , which are best introduced by example. Consider the theR&amp;D department at the Audio, Inc. company X  X  . Note that this query may fail for two different reasons: either no-body in Audio, Inc.  X  X  R&amp;D department makes less than or the company does not have an R&amp;D department. The for-mer is a genuine null answer, while the latter is a fake empty answer that is due to the erroneous presuppositions that the company has an R&amp;D department. co-op , which focuses on finding the erroneous presuppositions, transforms the origi-nal query into an intermediate, graph-oriented language in which the connected sub-graphs represent the query X  X  pre-suppositions; if the original query fails, then co-op tests each presupposition against the database by converting the subgraphs into sub-queries.

The flex system [23] can be seen as generalizing the ideas in co-op . flex reaches a high tolerance to incorrect queries by iteratively interpreting the query at lower levels of cor-rectness. flex is also cooperative in the sense that, for any failing query, it provides either an explanation for the failure or some assistance for turning the query into a non-failing one. Given a failing query, flex generates a set of more gen-eral queries that allow it to determine whether the query X  X  failure is genuine (in which case it suggest similar, but non-failing queries) or fake (in which case it detects the user X  X  erroneous presuppositions ).

The main drawback of systems such as flex is their high computational cost, which comes from computing and test-ing a large number of presupposition (to identify the sig-nificant presupposition, a large number of queries must be evaluated on the entire database ). In order to keep the run-ning time acceptable, Motro [22] suggests heuristics for con-straining the search. A related approach is proposed by Gaasterland [12], who controls the query relaxation process by using heuristics based on semantic query-optimization techniques. Finally, on the theoretical side, Godfrey [14] proves complexity results for finding all/some minimal fail-ing and maximal succeeding sub-queries: finding all of them is np -hard, while finding a subset takes polynomial time.
The CoBase system [8, 6, 9, 7] is the closest approach to our loqr algorithm. Central to the CoBase approach is the concept of Type Abstraction Hierarchies ( tah s), which synthesize the database schema and tuples into a compact, abstract form. In order to relax a failing query, CoBase uses three types of tah -based operators: generalization, spe-cialization, and association; these operations correspond to moving up, down, or between the hierarchies, respectively. CoBase automatically generates the tah s by clustering all the tuples in the database [7, 21].

CoBase is similar to loqr in the sense that it uses machine learning techniques for relaxing the queries. However, the two approaches are radically different: in CoBase, the cpu intensive clustering is performed only once, in an off-line manner, on all the tuples in the database. CoBase then uses this resulting tah to relax all failing queries. In contrast, loqr customizes the learned decision rules to each failing query by applying -online -the c4.5 learner [24] to a small, randomly-chosen subset of the database.
Let us consider again the illustrative laptop purchasing domain, in which the query fails because of two independent reasons: -laptops that have large screens (i.e., Display  X  17 )weigh -fast laptops with large hard disks ( CPU  X  2 . 5 GHz HDD
In order to relax Q 0 , loqr proceeds in three steps: first, it learns decision rules that express the implicit relationships among the various domain attributes; then it uses nearest-neighbor techniques to identify the learned rule that is most similar to the failing query; finally, it uses the attribute val-ues from this most-similar learned rule to relax the con-straints from the failing query. In this step, loqr uses the small, randomly-chosen subset D of the target database to discover knowledge that can be used for query relaxation. loqr begins by considering Q 0 constraints independently of each other: for each constraint in Q 0 (e.g., CPU  X  2 . 5 GHz ), loqr uses D to find patterns that predict whether this constraint is satisfied. Intuitively, this corresponds to finding the  X  X ypical values X  of the other attributes in the examples in which CPU  X  2 . 5 GHz .
For example, consider the dataset D that consists of the laptop configurations from Table 1. In order to predict, for any laptop configuration, whether CPU  X  2 . 5 GHz is satis-fied, loqr uses D to create the additional dataset D 1 shown in Table 2. Note that each example in D is duplicated in D , except for the value of its CPU attribute. The original CPU attribute is replaced in a binary one (values YES or NO ) that indicates whether CPU  X  2 . 5 GHz is satisfied by the original example from D . The new, binary CPU attribute is designated as the class attribute of D 1 . loqr extracts the potentially useful domain knowledge by applying the c4.5 learner to the dataset D 1 ,thuslearning a set of decision rules such as Such rules can be used for query relaxation because they describe sufficient conditions for satisfying a particular con-straint from the failing query. In our example, the rules above exploit the values of the other domain attributes to predict whether CPU  X  2 . 5 GHz is satisfied.
 Besides D 1 , loqr also creates four other datasets D 2  X  D , which correspond to the constraints imposed by Q 0 to the other domain attributes (i.e., Price , HDD , Weight ,and Display ). Each of these additional datasets is used to learn decision rules that predict whether Q 0  X  X  constraints on the corresponding attributes are satisfied.

Note that this learning process takes place online ,foreach individual query; furthermore, the process is also query-guided in the sense that each of the datasets D 1  X  D 5 is created at runtime by using the failing query X  X  constraints. This online, query-guided nature of the process is the key feature that distinguishes loqr from existing approaches.
At this point, we must emphasize that the rule R 1 , R 2 , and R 3 that were learned above can be seen as the existentially-quantified statements. For example, R 1 can be interpreted as the statement  X  X here are some examples in D that satisfy the condition Consequently, if we apply Q 1 to D , Q 1 is guaranteed not to fail because it certainly matches the examples covered by R (i.e., the ones from which R 1 was learned). Furthermore, as D is a subset of the target database, it also follows that Q is guaranteed not to fail on the target database.

In this second step, loqr converts all the learned rules into the corresponding existential statements. Then it iden-tifies the existential statement that is the  X  X ost useful X  for relaxing the failing query (i.e., the one that is the most sim-ilar to Q 0 ). This  X  X ost similar X  statement is found by nearest-neighbor techniques. For example, the statement Q 1 above is more similar to Q 0 than because Q 1 and Q 2 differ only on their constraint on Price , and Q 0  X  X  Price  X  $2 , 000 is more similar (i.e., closer in value) to Q 1  X  X  Price  X  $2 , 900 than to Q 2  X  X  Price  X  $3 , 000. Likewise, Q 1 is more similar to Q 0 than which shares only the CPU constraint with the failing query.
For convenience, let us assume that of all learned state-ments from the datasets D 1  X  D 5 , Q 1 is the one most similar to Q 0 .Then loqr creates a relaxed query Q r that con-tains only constraints on attributes that appear both in Q and Q 1 ; for each of these constraints, Q r uses the less con-straining value of those in Q 0 and Q 1 . In our example, the resulting relaxed query is which is obtained by dropping the original constraint on the hard disk (since it appears only in Q 0 ), keeping the con-straint on CPU unchanged since ( Q 0 and Q 1 have identical constraints on CPU ), and setting the values in the con-straints on Price , Display ,and Weight to the least con-straining ones (i.e., the values from Q 1 , Q 0 ,and Q 1 ,respec-tively).

The approach above has two advantages. First, as Q 1 is the statement the most similar to Q 0 , loqr makes minimal changes to the original failing query. Second, as the con-straints in Q r are a subset of those in Q 1 , and they are at most as tight as those in Q 1 (some of them may use the looser values from Q 0 ), it follows that all examples that satisfy Q also satisfy Q r . In turn, this implies that Q r is guaranteed not to fail on the target dataset because Q 1 satisfies at least the examples covered by R 1 . 3
Let us now briefly consider a more complex example of query relaxation. Suppose that instead of Q 1 , the existential statement that is the most similar to Q 0 is Note that for both Price and Weight , the constraints in Q and Q 4 use the  X  X pposite X  operators  X  and  X  (e.g.,  X  in Q 0 and  X  in Q 4 , or vice versa). When relaxing Q 0 based on the constraints in Q 4 , loqr creates the relaxed query in which -the Weight is constrained to the values that are com--the constraint on Price is dropped because there are no -the other constraints are obtained exactly in the same way At this point we must make two important comments. First, the failing query Q 0 is just a conjunction of sev-eral constraints on the various attributes. In order to relax queries that are in disjunctive normal form (i.e., disjunctions of conjunctions similar to Q 0  X  Q 4 ), loqr simply considers the conjunctions independently of each other and applies the three steps above to each individual conjunction.

Second, the query-guided learning process above creates a dataset D i for each attribute that is constrained in the failing query (e.g., the five datasets D 1  X  D 5 for the query Q ). This idea generalizes in a straightforward manner for the scenario in which the user is allowed to specify  X  X ard constraints X  that should not be relaxed under any circum-stances: for each example in D , the entire set of hard con-straints is replaced by a single binary attribute that specifies whetherornot all the hard constraints are simultaneously satisfied in that particular example. This is an additional benefit of our online, query-guided approach to query relax-ation, and it is not shared by other approaches.
In this section we present a formal description of the loqr algorithm. We begin by briefly describing the syntax of the input queries, after which we discuss the algorithm itself. loqr takes as input queries in the disjunctive normal form ( dnf ). Consequently, a failing query Q 0 consists of a dis-junction of conjunctions of the form Q 0 = C 1 C 2 ... C n In turn, each C k is a conjunction of constraints imposed on (a subset of) the domain attributes:
Note that this guarantee holds only if D is a subset of the target database. If these two datasets are disjoint (see our experimental setup), Q R may fail, even though it is highly unlikelytodoso.
 Figure 1: loqr successively relaxes each conjunction independently of the other ones.
 When the context is ambiguous, the notation Constr C k ( A is used to denote the constraint imposed by the conjunction C k on the attribute A j .

Each constraint consists of a domain attribute, an op-erator, and one or several constants. For the discrete at-tributes, loqr accepts constraints of the type =, =,  X  ,or (e.g., Color = black or Manufacturer  X  X  Sony, HP } ). For the continuous attributes, the constraints use the inequality operators  X  , &lt; ,  X  ,or &gt; (e.g., Price &lt; 2000).
For a dnf query to fail, each of its conjunctions C k must fail (i.e., the query consists of failing conjunctions only); conversely, by successfully relaxing any of its failing con-junctions, one turns a failing query into a non-failing one. Based on this observation, loqr successively relaxes the fail-ing conjunctions independently of each other (see Figure 1); consequently, without any loss of generality, we focus here on the three steps used to relax a failing conjunction C : extracting the implicit domain knowledge (expressed as learned decision rules), finding the decision rule that is the most similar to C k , and using this decision rule to actually relax C k .
In this first step, loqr uses a subset of the target database to uncover the implicit relationships that hold among the domain attributes. This is done by the following strategy: for each attribute A j that appears in the failing conjunction C , loqr uses the values of the other domain attributes to predict whether A j  X  X  value satisfies Constr C k ( A j ).
As shown in Figure 2, loqr starts with a randomly-chosen subset D of the target database and creates one additional dataset D j for each attribute A j that is constrained in C Each dataset D j is a copy of D that differs from the original only by the values of A j : for each example in D j ,ifthe original value of A j satisfies Constr C k ( A j ), loqr sets A to yes ; otherwise A j is set to no .Foreach D j , the binary attribute A j is designated as the class attribute.
After creating these additional datasets, loqr applies c4.5 -rules [24] to each of them, thus learning decision rules that, for each attribute A j in C k , predict whether A j satisfies Constr C k ( A j ). In other words, these learned decision rules represent patterns that use the values of some domain at-tributes to predict whether a particular constraint in C k satisfied.
After the learning step above, loqr converts each learned decision rule into the equivalent existentially-quantified state-Figure 2: Step 1: query-guided extraction of domain knowledge expressed as decision rules. ment. This is done by simply replacing  X   X   X  X y X   X  in each rule (remember than any decision rule  X  a b c  X  d  X  X an be interpreted as the existential statement  X  X here are exam-ples in D such that a b c d  X ).

Note that the resulting existential statements have the same syntax as the failing conjunctions; i.e., they both rep-resent a conjunction of constraints on the domain attributes. Consequently, loqr can detect the existential statement that is the most similar to C k by performing an attribute-wise comparison between the constraints in C k and those in each of the learned statements (i.e., loqr finds C k  X  X   X  X earest neighbor X  among the existential statements).
 In order to evaluate the similarity between a conjunction C k and a statement S , loqr use the function in which w j denotes the user-provided (relative) weight of the attribute A j . Dist ( C k ,S,A j ) is a measure of the sim-ilarity between the constraints imposed on A j by C k and S ; it has the range [0 , 1] (the smaller the value, the more similar the constraints) and is defined as follows: -if the attribute A j does not appear in both C k and S , -if A j takes discrete values, then -if A j takes continuous values, then
Figure 3: Step 3: relaxing a failing conjunction.
After finding the statement S that is the most similar to the failing conjunction C k , loqr uses the domain knowledge synthesized by S to relax the constraints in C k . As shown in Figure 3, the relaxation works as follows: -the relaxed conjunction C Relax includes only constraints -if A j is discrete, C Relax constrains its values to the ones -if A j is continuous, there are two possible scenarios:
In this section we begin with a brief overview of the five algorithms to be evaluated, followed by the description of the datasets, the experimental setup, and the actual results.
We empirically compare the performance of loqr with that of the following four algorithms: loqr -50, loqr -90, s-nn ,andr-nn . The first two are variants of loqr , while the other ones represent two baselines.
 The baselines work as follows: for each failing conjunction C , they use the distance measure from Section 4.3 to find the example Ex  X  X  that is the most similar to C k .Then
For each continuous attribute, loqr requires the user to specify whether larger or smaller values are more desirable. In our laptop scenario, the larger the hard disk, the better; conversely, the smaller the Price the better, too. they use Ex to create a conjunction C k that has the same constraints as C k , except that the original attribute values are replaced by the corresponding values from Ex .The difference between s-nn and r-nn is that the former simply returns C k as the relaxed query, while the latter uses C relax C k as explained in Section 4.4. loqr -50 and loqr -90 represent variants of loqr that il-lustrate the trade-offs between the following strategies:  X  X en-return a (relatively) large number of tuples X  vs  X  X reate under-fail X  . Both algorithms assume that the user designates one of the attributes as being the most relevant (ideally, the con-straint on this attribute should not be relaxed at all).
For each failing conjunction C k , loqr -50 and loqr -90 run loqr , which computes the relaxed conjunction C Relax After the user selects an attribute A j from C Relax as the most relevant , the algorithms -apply Q R to the dataset D and obtain the set CT of com--determine the set V of all values taken by the attribute A -replace the value in Constr C k ( A j )by X  X hemostconstrain-
For all five algorithms above, we used equal weights ( w j 1) in the formula for dist ( C k ,S ), which measures the simi-larity between two conjunctive formulas (see Section 4.3). We evaluate the algorithms above on six different datasets. The first one, laptops , is the original motivation for this work. It consists of 1257 laptop configurations extracted from yahoo.com ;eachlaptopisdescribedbyfivenumeric attributes: price, cpu speed, ram , hdd space, and weight. The other five domains are taken from the UC Irvine repos-itory: breast cancer Wisconsin ( bcw ), low resolution spec-trometer ( lrs ), Pima Indians diabetes ( pima ), water treat-ment plant ( water ), and waveform data generator ( wave ).
In order to evaluate the performance of the five algorithms above, we proceed as follows. Given a failing query Q and a dataset D , each algorithm uses D to generate a relaxed query Q R . In order to estimate its adequacy, Q R is then evaluated on a test set that consists of all examples in the target database except the ones in D . We have chosen to keep D and the test set disjoint (which may lead to the relaxed query failing on the test set) because in our moti-vating Web-based domains the owner of a database may be unwilling to provide the dataset D . By keeping D and the test set disjoint, we can simulate (up to a certain level) the
Obviously, this strategy applies only to the continuous at-tributes. For the discrete ones, the user is asked to select a correspondingly small subset of the most desirable values. scenario in which the relaxation algorithm exploits an alter-native information source that is somewhat representative of the data in the target database.

For each of the six domains, we have seven distinct failing queries. We also consider various sizes of the dataset D 50, 100, 150, . . . , 350 examples; for each of these sizes, we create 100 arbitrary instances of D , together with the 100 corresponding test sets. For each size of D andeachofthe seven failing queries, each query relaxation algorithms is run 100 times (once for each instance of D ); consequently, the results reported here are the average of these 700 runs.
In our experiments, we focus on two performance mea-sures: -robustness : what percentage of the failing queries are suc--coverage : what percentage of the examples in the test set Figures 4 and 5 show the robustness and coverage results on the six evaluation domains. In terms of robustness , loqr obtains by far the best results: independently of the size of D , on all six domains loqr  X  X  robustness is above 90%; in fact, most of the robustness results are close or above 99% (i.e., about 99% of the queries are successfully relaxed).
In contrast, the two baselines, s-nn and r-nn , display ex-tremely poor robustness: on lrs , pima , water ,and wave their robustness is below 10%. The baselines X  best results are obtained on small-sized D (i.e., Size ( D ) = 50), where the scarcity of the training data makes it unlikely to find a domain example that is highly-similar to the failing query; in turn this leads to an over-relaxation of the query, which improves the robustness. However, as Size ( D ) increases, the performance of the two baselines degrades rapidly.
The second measure of interest, coverage , must be consid-ered in conjunction with the robustness results: even though we are interested in low-coverage results 6 , a low-coverage, non-robust algorithm is of little practical importance. Con-sequently, the low-coverage results of the two baselines (see Figure 5) must be put in perspective: after all, the vast majority of the queries relaxed by these algorithms still fail. loqr scores less spectacularly in terms of coverage :when learning from datasets of 350 examples, its coverage on the six domains is between 2% and 19%. However, by trading-off robustness for coverage, loqr -90 obtains excellent overall results: when using 350 training examples, on all domains but bcw , loqr -90 reaches robustness levels between 69% and 98%, while also keeping the coverage under 5%.
Last but not least, we are also interested in the amount of time spent relaxing a query: given that each query is processed online, it is crucial that loqr quickly relaxes the incoming queries. In Table 3, we show the cpu time (in seconds) that is spent refining the queries in the six applica-tion domains. Our results show that loqr is extremely fast:
Our motivation comes from Web-based information sources, for which high-coverage queries may be unaccept-able because of (1) the database X  X  owners unwillingness to return large chunks of the data; (2) the bandwidth problems associated with transmitting huge datasets over the Inter-net; (3) the fee that one may have to pay for each returned tuple. Consequently, we are interested in query relaxations that return only a few, highly-relevant tuples. queries that consist of at most 21 attributes are processed under 1.40 seconds; for queries that consist of 93 attributes, it may take up to 30 seconds. To put things into perspective, a human cannot even read and comprehend a 93-attribute query in this amount of time; in fact, it is highly unlikely that humans are even willing to write 93-attribute queries.
Note that the running time is influenced both by the size of the dataset D and the number of attributes in the query. The former relationship is straightforward: the larger the dataset D , the longer it takes to learn the decision rules. The latter is more subtle: as loqr creates a new dataset for each attribute in the query, it follows that the more at-tributes in the query, the longer it takes to process the query. However, not all constraints are equally time consuming; for example, if an attribute A is constrained to take a value that is out of the range of values encountered in D , then it is su-perfluous to learn from the corresponding dataset, which consists solely of  X  X egative examples X  (the constraint on A is not satisfied in any of the examples from D ).
Before concluding this paper, we must discuss two im-portant design choices that heavily influence loqr  X  X  perfor-mance: the online and the query-driven nature of the learn-ing process. The former refers to the fact that the learning step is performed at run-time, for each failing query. The latter specifies that the learning task is designed as a binary classification problem in which the class attribute represents the boolean value  X  X oes A j  X  X  value satisfy the constraints imposed onto it by the failing query? X 
In order to illustrate the advantages of our online ap-proach, we re-use the experimental setup above to compare Table 3: Running times for loqr , averaged over the runs on each of the 100 instances of D that are cre-ated for 50 and 350 examples, respectively. loqr with an offline variant, off-k . The only difference be-tween the two algorithms is that off-k performs the learn-ing step only once, independently of the constraints that appear in the failing queries. Similarly to loqr , off-k also tries to predict an attribute X  X  value from those of the other attributes; however, because it does not have access to the constraints in the failing query, off-k proceeds as follows: for discrete attributes, it learns to predict each discrete value from the values of the other attributes; for continuous at-tributes, it discretizes the attribute X  X  range of values in that it obtains a number of k intervals that have equal size.
In this empirical comparison, we use two offline versions (i.e., k = 2 and k =3)forboth loqr and loqr -90. Figures 6 and 7 show the robustness results 7 for loqr and loqr -90, respectively ( off-2and off-3denotethetwoofflinever-sions of each algorithm). The graphs show that both loqr and loqr -90 clearly outperform their offline variants, 8
Because of space limitations, we do not show the coverage results. However, they can be summarized as follows: on all six domains, the coverage of the online and offline algorithms are extremely close. On water and lrs , both loqr and loqr -90 outperform their offline counterparts, while on bcw and wave the performance is virtually the same.
Figures 6 and 7 also show that off-3 does not always out-demonstrating the superiority of the online, query-guided approach.
As we have already seen, guiding the learning process by the constraints that appear in the failing query leads to dra-matic robustness improvements. However, the query-driven approach used by loqr is by no means the only possible approach. In fact, we can distinguish four main scenarios: -no constraints: this approach corresponds to offline learn--class-attribute constraints: this is the approach used by -set of hard constraints: this scenario represents a straight--all constraints: this final scenario correspond to simultane-perform off-2. This is because the discretization of the con-tinuous attributes is made independently of the values from the failing query: as the discretization takes place offline, the values that appear in query X  X  constraints may lay anywhere within a discretized interval. Consequently, the  X  X urity X  of the discretized class that includes the query value may vary wildly (e.g., almost all values in that interval may or may not satisfy the constraint from the query), which -in turn -dramatically affects the quality of the relaxed query.
Inthispaperwehaveanalyzedthefirsttwoofthesce-narios above. The third one represents a straightforward extension of loqr that was not addressed here because of space limitations. Finally, the last scenario has both advan-tages and disadvantages over loqr . On one hand, by si-multaneously replacing the values of all attributes with the corresponding boolean values, the  X  all constraints  X  X cenario creates a single dataset D instead that one per attribute; in turn this leads to a considerable gain in terms of pro-cessing speed. On the other hand, in the  X  all constraints  X  scenario there is only one way to relax a query, namely by dropping constraints. In contrast, loqr permits both con-straint dropping and constraint relaxation (i.e., replacing the original value by a less constraining one), thus providing a significantly more flexible solution to the query relaxation problem.
In this paper we have introduced a novel, data-driven ap-proach to query relaxation. Our algorithm, loqr ,performs online, query-driven learning from a small subset of the tar-get database. The learned information is then used to relax the constraints in the failing query. We have shown empiri-cally that loqr is a fast algorithm that successfully relaxes the vast majority of the failing queries.

We intend to continue our work on query relaxation along several directions. First, we plan to extend our data-driven approach by also exploiting user preferences that are learned as the system is in use. Second, we are interested in a query visualization algorithm that would allow a user to explore the trade-offs between the various possible query re-laxations. Finally, we plan to integrate the query visualiza-tion module in a mixed initiative system in which the user interacts with the query relaxation algorithm by expressing various preferences over the domain attributes.
This material is based upon work supported by the De-fense Advanced Research Projects Agency (DARPA), through the Department of the Interior, NBC, Acquisition Services Division, under Contract No. NBCHD030010.
 We would like to thank Melinda Gervasio, Karen Myers, Maria Muslea, and Tomas Uribe for their helpful comments on this paper. We also thank Steven Minton and Fetch Tech-nologies, Inc. for providing us with the Laptops dataset. [1] S. Amer-Yahia, S. Cho, and D. Srivastava. Tree [2] R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern [3] K. Chakrabarti, M. Ortega, S. Mehrotra, and [4] S. Chaudhuri. Generalization and a framework for [5] S. Chaudhuri and L. Gravano. Evaluating top-k [6] W. Chu, Q. Chen, and A. Huang. Query answering [7] W. Chu, K. Chiang, C.-C. Hsu, and H. Yau. An [8] W.Chu,R.C.Lee,andQ.Chen.Usingtype [9] W. Chu, H. Yang, K. Chiang, M. Minock, G. Chow, [10] F. Corella, S. J. Kaplan, G. Wiederhold, and L. Yesil. [11] N. Fuhr and K. Grosjohann. XIRQL: A query [12] T. Gaasterland. Cooperative answering through [13] A. Gal. Cooperative responses in deductive databases . [14] P. Godfrey. Minimization in cooperative response to [15] J. M. Janas. Towards more informative user interfaces. [16] Y. Kanza and Y. Sagiv. Flexible queries over [17] M. Kao, N. Cercone, and W.-S. Luk. Providing [18] S. Kaplan. Cooperative aspects of database [19] D. A. Keim and H. Kriegel. VisDB: Database [20] D. Lee. Query Relaxation for XML Model .PhDthesis, [21] M. Merzbacher and W. Chu. Pattern-based clustering [22] A. Motro. seave: a mechanism for verifying user [23] A. Motro. Flex: A tolerant and cooperative user [24] R. Quinlan. C4.5: programs for machine learning . [25] A. Theobald and G. Weikum. Adding relevance to
