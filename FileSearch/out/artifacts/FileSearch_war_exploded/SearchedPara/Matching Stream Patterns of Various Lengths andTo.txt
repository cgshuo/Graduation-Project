 Continuously identifying pre-defined patterns in a streaming time series has strong demand in various applications. While most ex-isting works assume the patterns are in equal length and tolerance, this work focuses on the problem where the patterns have various lengths and tolerances, a common situation in the real world. The challenge of this problem roots on the strict space and time require-ments of processing the arriving and expiring data in high-speed stream, combined with difficulty of coping with a large number of patterns with various lengths and tolerances. We introduce a novel concept of converging envelope which bounds the tolerance of a group of patterns in various tolerances and equal length and thus dramatically reduces the number of patterns for similarity compu-tation. The basic idea of converging envelope has potential to more general index problems. To index patterns in various lengths and tolerances, we partition patterns into sub-patterns in equal length and an multi-tree index is developed in this paper.
 H.2 [ Database Management ]: Database Applications Algorithms
A time series data stream (called a data stream hereafter) is a se-quence of values [1] which can be stock prices, data monitored by various sensors such as medical facilities. Since a data stream ar-rives and expires continuously, rapidly and in real-time, it should be processed on the fly rather than be stored in a database[2]. In last decades, data stream management and processing have attracted significant attention from research communities due to the strong requirements of monitoring on changes of stocks, medical situa-tions of patients, load of electrical network, and moving objects in security systems, etc [5]. A fundamental task is to continuously and efficiently identify pre-defined fluctuation patterns. Generally, we can view that a pattern is a segment of a data stream which has a semantic meaning in a certain application domain. In real world applications, we usually need to monitor a data stream for a large number of patterns. For example, every user in a stock market can provide patterns to the monitoring system. In this situation, another prominent feature is that those patterns are not necessarily equal in length and in tolerance. This is determined by the complexity of real world phenomena and by the flexibility of user requirements.
Given a pattern and a data stream, the pattern can be wrapped by a sliding window; when the data stream flowing through the win-dow, we can imagine that the data stream is static and the sliding window moves along the time axis as shown in figure 1(a). The segment of the data stream currently falling in the sliding window is compared with the pattern. In this work, we suppose the data stream and the pattern have uniform sampling interval. Given a data stream segment ds = { ds [ t 1 ] , ds [ t 2 ] , ..., ds [ t tern p = { p [ t 1 ] , p [ t 2 ] , ..., p [ t n ] } where ds [ t of ds and p at sampling time t i , various distance functions can be used to measure the similarity distance between ds and p , denoted as sum ( ds, p ) . This work discusses l 1 -norm due to their popu-larity in data stream pattern matching [2, 7] while the proposed techniques are applicable to l p -norm. For l 1 -norm, sum ( ds, p ) = P old  X  , called tolerance of p , ds matches pattern p . This paper fo-cuses on the continuous monitoring over a data stream for a large number of patterns in various lengths and tolerances. The problem can be formally defined as follows: given a data stream DS and a set of patterns P = p 1 , p 2 , ..., p N , let the tolerance and length of pattern p i be p i . X  and p i .len respectively, the objective is to find every pattern p i  X  P for every data stream segment ds i in DS such that sum ( ds i , p i ) &lt; p i . X  .

The challenge of this problem roots on the strict space and time requirements of processing the arriving and expiring data in a high-speed stream, combined with difficulty of coping with a large num-ber of patterns with various lengths and tolerances. While real world applications usually include patterns in various lengths and tolerances, most of the previous works assume that the length and tolerance are equal [7, 6, 2, 4]. The method known as atomic wedge is proposed by [7] where the patterns are indexed by hierarchically approximating the similar ones using their bounded conservative area, called wedge; see an example in figure 1(b). For a data stream segment ds at each sampling time, its distance to the wedge w is the shortest distance. The similarity distance between ds and w is denoted as sum ( ds, w ) , and the partially computed similarity dis-tance is denoted as sum 0 ( ds, w ) , initially sum 0 = 0 . When the distance between ds and w at each sampling time is computed, the distance is added to sum 0 and sum 0 further approaches to sum . When distances at all sampling times have been added to sum sum 0 = sum . Since sum 0 &lt; sum , if sum 0 is greater than the tolerance of all patterns in w , w can be safely pruned. The method using sum 0 to avoid computing distances at all sampling times for pruning a wedge (or a pattern) is called early abandoning in [7].
As the best of our knowledge, only few works consider patterns in various lengths and tolerances [2, 3]. In work [2], based on the previous values arrived, the future trend of a stream is predicted. Based on the prediction, the distance between a pattern and a seg-ment of a data stream in the future is estimated. However, it is dif-ficult to handle a large number of patterns as indicated by [3]. The recent work [3] provides an approach, known as similar sequence matching based on intervaled sequence (SSM-IS) which utilizes R-tree in high dimensional space in order to filter out unmatched patterns before similarity computation. The basic idea is that if the difference of ds and p at one sampling time is greater than the toler-ance p. X  , the similarity distance between them, sum ( ds, p ) , must be greater than p. X  . The pruning condition of this method is safe but too tough to be satisfied. In addition, to avoid suffering from the curse of high-dimension, [3] transforms the high dimensional space to low dimensional space. This further reduces the pruning ability of the index.

In this work, we first investigate the situation where the patterns are in various tolerances and equal length. The aim is to prune wedges as much as possible and compute distances at as less as possible sampling times for pruning one wedge. There are two simple methods. One is that if at any sampling time the distance between ds and each pattern in a wedge w is greater than the pat-tern X  X  tolerance, this wedge can be pruned. The idea is similar to the pruning method used in [3]. As discussed, such pruning condition is not easy to be satisfied. The other simple method uses the maxi-mum tolerance of all patterns in the wedge. The partially computed similarity distance sum 0 ( ds, w ) is compared with the maximum tolerance. The efficiency of this method depends on the assump-tion that two patterns have the maximum tolerance and they are the upper and lower boundary of the wedge. However, we observe that is not true in most cases and thus the maximum tolerance is a loose pruning condition. This observation motivates us to propose a novel concept of wedge with converging envelope (WCE) to fully explore the distances of wedge X  X  boundary to the patterns forming this wedge in order to achieve optimal pruning power. WCE has the best possible pruning power in a given processing order of sampling times, that is, the distances are computed at the minimum number of sampling times to prune a given wedge. Along the processing order, the envelope converges. Any attempt to further narrow down the envelope may lead to miss-hits. Even though any order can be used, we follow the sequence of sampling times. In addition, we want to mention that WCE can improve the pruning power of the indexing method proposed by [7] when identifying patterns in equal length and tolerance.

Next, we investigate the situation where patterns are in various lengths and tolerances. These patterns are equally partitioned to sub-patterns. Then, these sub-patterns are in equal length and vari-ous tolerances and can be indexed with support of WCE.

The contributions of this work are on three aspects. First, WCE is proposed to identify patterns in various tolerances and equal length. WCE provides a converging envelope to each wedge in order to prune wedges as much as possible by computing simi-larity at as less as possible sampling times. Second, an index is developed to identify patterns in various lengths and tolerances. The patterns are equally partitioned to sub-patterns and these sub-patterns with equal length and various tolerances are then indexed with support of WCE. Third, the basic idea of converging envelope potentially benefits any matching problems where the objects are approximated hierarchically and the similarity between objects is measured by the accumulated distance on multiple dimensions.
We first investigate the problem when patterns are in various tol-erances and equal length. Each wedge w has two boundaries, upper boundary w.ub and lower boundary w.lb . In our method, we add an envelope to each wedge. The envelope has two boundaries as well, called envelope upper boundary we.ub and lower boundary we.lb . Recall that the similarity between wedge and data stream is l 1 -norm, that is, sum ( ds, w ) = dist ( w [ t i ] , ds [ t i ]) is the minimum distance from ds to w at t
Given w and ds , when the distance at the sampling time t is com-puted, the partially computed similarity sum 0 is updated by adding dist ( w [ t ] , ds [ t ]) to sum 0 . The updated sum 0 compares with the envelope at this sampling time to decide whether this wedge can be pruned, or the distances at more sampling times need to be com-puted and added to sum 0 . Although any processing order can be used, we use the sequence order of sampling times t 1 , t simplicity. The reason is that the same order will be used when comparing this wedge with ds . If other processing order is used, it must be recorded in the index.

At a sampling time t , if ds [ t ] is less than the wedge lower bound-ary w.lb [ t ] , the envelope lower boundary we.lb [ t ] is compared with sum 0 ; if ds [ t ] is greater than the wedge upper boundary w.ub [ t ] , the envelope upper boundary we.ub [ t ] is compared with sum The wedge can be safely pruned if sum 0 &gt; we.lb [ t ] (or sum we.ub [ t ] ). Next we suppose that ds are not inside the wedge at all sampling times.

We use the example in figure 2 to explain the basic idea on how to find the envelope for a wedge. Suppose the sampling time t been processed and d 1 = dist ( w.lb [ t 1 ] , ds [ t 1 ]) , sum d . For any pattern p  X  w at the sampling time t 1 , let d 0 tance from p [ t 1 ] to w.lb [ t 1 ] . The actual distance from ds [ t t is d 1 + d 0 1 . If d 1 + d 0 1 &gt; p. X  , p can be safely pruned. That is, d p. X   X  d 0 1 is the pruning condition of p . Both p. X  and d when the wedge containing p is created. Thus, p. X   X  d 0 1 puted during the index construction and used as the envelope lower boundary of p at t 1 . If the wedge cannot be pruned at t puted similarity distance sum 0 ( ds, w ) is d 1 + d 2 . For the pattern p , the actual partially computed similarity distance sum d safely pruned. That is, d 1 + d 2 &gt; p. X   X  d 0 1  X  d 0 2 dition of p . Similarly, p. X  , d 0 1 and d 0 2 are known when the wedge containing p is created. We can compute p. X   X  d 0 1  X  d 0 index construction and use it as the envelope lower boundary of p at the sampling time t 2 . From t 1 to t 2 , the pruning condition de-creases from p. X   X  d 0 1 to p. X   X  d 0 1  X  d 0 2 . When all sampling times are processed for p in the processing order t 1 , t 2 , ..., t lope converges as shown in figure 2(b). Note when constructing the wedge, we have no idea whether a data stream will be greater than w.ub [ t 1 ] or less than w.lb [ t 1 ] at t 1 . Thus, d 0 the smaller one of dist ( w.lb [ t 1 ] , p [ t 1 ]) and dist ( w.ub [ t It has been proved that the envelope obtained is optimal in a given processing order of sampling times. Any narrower envelope may lead to miss-hits.
Given a set of patterns with different tolerances, we select two and approximate them with a wedge. This process is repeated until all patterns are approximated using a single WCE, a tree structured index is obtained. For a data stream segment ds that falling in the sliding window, we first compare ds with the wedge in the root of the index tree. If the pruning condition is satisfied, this wedge is pruned; otherwise, the child nodes are visited and the same process is repeated. When a leaf node is visited, the similarity distance of the pattern in this node and ds is measured. A pattern is reported once the similarity distance is less than the tolerance. Now we discuss the patterns in various lengths and tolerances. For a set of patterns p 1 , p 2 , .., p N , we align the starting points of these patterns. The basic idea is to equally partition these patterns into sub-patterns. If a pattern p is divided into n sub-patterns, the tolerance of each sub-pattern is p. X /n . Then these sub-patterns of equal length and various tolerances can be indexed in the way as introduced in section 2. An multi-tree index structures (MTM) is developed in this section. We suppose all patterns can be exactly partitioned into equal sub-patterns. If some patterns of various-length cannot be equally partitioned with a given partition length, we may process the remaining part of the pattern separately.
Figure 3(a) shows six patterns in various lengths. They are par-titioned into sub-patterns in equal length. Figure 3(b) is the multi-tree index over the sub-patterns. The sub-patterns in the same par-tition interval are indexed using a tree. Thus, three index trees are obtained. Each sub-pattern is stored in a leaf node and each WCE is stored in a non-leaf node. In order to quick find each other, each sub-pattern in leaf node has pointers to other leaf node which stores sub-patterns belonging to the same pattern. For example, f are referenced to each other. Each tree is associated with a candi-date list.
Given a multi-tree index, we can identify from a data stream the patterns in various lengths. The multi-tree spans a long sliding window. This long slide window is partitioned for each tree. For example in figure 3(a), the long sliding window of the multi-tree is t ..t 3 m and the sliding window for each tree is t 1 ..t m and t 2 m +1 ..t 3 m . The data stream falling in the long sliding window are partitioned into small sliding windows which are correspond-ing to trees. For each data stream segment, the corresponding tree is browsed. If this data stream segment matches any sub-pattern in the tree, this sub-pattern is put into the candidate list associated with this tree. Suppose a pattern p has n sub-patterns. There are several situations we need to considered: (a) if all n sub-patterns appear in the candidate lists, this pattern is in the final solution; (b) if none of n sub-patterns appears in any candidate list, this pat-tern is dropped; (c) if part of n sub-patterns are in the candidate lists, this pattern p needs to be further processed to calculate the exact similarity distance with the corresponding data stream seg-ment. This refinement can reuse the similarities already computed when browsing trees.
The experiments are conducted on a Pentium V 2.0Ghz PC with 1.5GB memory, Window XP Pro. The algorithms were imple-mented in C++. Two large real datasets are tested in experiments. The first dataset consists of 960,000 data points measured from electrocardiograms (ECG) which is obtained from the MIT-BIH Arrhythmia database(www.physionet.org/physiobank/database/mitdb/).
First, we focus on the efficiency of pattern matching in a data stream where the patterns are in various tolerances and equal length. We compare the proposed WCE matching method against IT-P, MT-P. IT-P and MT-P are two simple methods which have been introduced in section 1. IT-P is based on the similarity distance at individual sampling time. MT-P uses the maximum tolerance of all patterns as the pruning condition. Next, we test the efficiency of pattern matching in a data stream where the patterns are in var-ious tolerances and lengths. The patterns are partitioned into sub-patterns of equal length. The proposed multi-tree index (MTM) is compared with the naive method and SSM-IS [3] discussed in section 1. The naive method simply tests each pattern individually with the time stream falling in the pattern X  X  sliding window. Once the partially computed similarity is greater than the tolerance, this pattern is dropped. In this experiment, the implementation of SSM-IS is based on IT-P which has same pruning methods as SSM-IS and is much easier to implement. The naive method mentioned above is also tested when patterns are in various lengths and toler-ances. The effects of two factors are tested. They are (a) the num-ber of patterns, denoted by N ; (b) the average length of patterns, denoted by L . The default settings are: N = 1000 , L = 62 . Figure 4: CPU cost(various tolerances and equal length).
For a set of patterns in various tolerances and equal length, we test the efficiency of WCE based matching algorithm against IT-P and MT-P. This experiment uses the patterns extracted from dataset ECG. The patterns have equal length which is 40 sampling times for the tests shown in figure 4(a). They demonstrates the CPU cost used to match all data stream segments in ECG of length 40. When the number of patterns changes from 500 to 3000, the CUP time increases linearly for all methods. But our method is more efficient than others by at least 5 times. Figure 4(b) test the effect of pat-tern length to the performance. When the patterns change from 40 to 160, the tolerances of patterns change proportionally. As a re-sult, more patterns will be examined and each examination involves more processing of sampling times. The CPU cost increases for all methods and the superiority of our method is demonstrated.
Figure 5(a) demonstrates the performances on different number of patterns. Along with the increase of N , the CPU cost of all meth-ods illustrates a trend to increase in a linear manner but increase rate is different. The increase rate of the naive method is the fastest since it doesn X  X  apply any optimization methods. The CPU cost of SSM-IS increases relatively slower than the naive method. Com-paring to SSM-IS, MTM is several times better due to the pruning
Figure 5: CPU cost(various tolerances and various length). power of converging envelope. The number of candidates and the number of sampling times examined in MTM is much less than those using SSM-IM. In figure 5(b), the effect of L to the perfor-mance is shown. When L increases, the performances for all meth-ods decrease. When the average length increases, the tolerances of patterns increase proportionally. Generally, more patterns will be examined and each examination involves more processing of sam-pling times.
This work provides an optimal converging envelope to minimize the computation in matching stream patterns of various tolerances. To match patterns in various-lengths, we develop the multi-tree index structure. Extensive experiments on the large real data set demonstrate that the proposed approach achieves tremendous im-provements in efficiency comparing to alternative approaches by at least five times at all settings. The concept of converging enve-lope has potential to impact more general index problems. In the agenda of our future work, we plan to do further investigation in this promising direction.
The work reported is partially supported by grants DP0773122 from the Australian Research Council, by NSTPP(2008BAJ08B08-04, 2006BAJ11B07-01, 2006BAJ06B08-03), NSF of Liaoning(20071004) and Education Department of Liaoning(2008600, 2008596), China. [1] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. Fast [2] L. Gao and X. S. Wang. Continually evaluating [3] Y.-S. M. Hyo-sang Lim, Kyu-Young Whang. Similar sequence [4] X. Lian, L. Chen, J. X. Yu, G. Wang, and G. Yu. Similarity [5] L. M.Ni, Y. Liu, Y. C. Lau, and A. P.Patil. Landmarc: Indoor [6] L. Wei, E. Keogh, H. V. Herle, A. Mafra-Neto, and R. J. [7] L. Wei, E. J. Keogh, H. V. Herle, and A. Mafra-Neto. Atomic
