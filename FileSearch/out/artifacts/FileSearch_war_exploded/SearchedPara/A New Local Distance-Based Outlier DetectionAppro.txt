 Of all the data mining techniques that are in vogue, outlier detection comes clos-est to the metaphor of mining for nuggets of information in real-world data. It is concerned with discovering the exception al behavior of certain objects [TCFC02]. Outlier detection techniques have widely been applied in medicine (e.g. adverse reactions analysis), finance (e.g. financial fraud detection), security (e.g. counter-terrorism), information security (e.g. intrusions detection) and so on. In the recent decades, many outlier detectio n approaches have been proposed, which can be broadly classified into several categories: distribution-based [Bar94], depth-based [Tuk77], distance-based (e.g. KNN) [KN98], cluster-based (e.g. DB-SCAN) [EKSX96] and density-based (e.g. LOF) [BKNS00] methods.

However, these methods are often unsuitable in real-world applications due to a number of reasons. Firstly, real-world data usually has a scattered distribution, where objects are loosely distributed in the domain feature space, e.g. like stars in the universe, forming many mini-clusters rather than a few main clusters. Only the objects which do not belong to any mini-cluster are genuine outliers. Sec-ondly, most outlier detection approaches require fine-tuning of their parameters through trial-and-error [FZFW06], which is impractical, because real-world data usually do not contain labels for anomalous objects. Top-n style outlier detec-tion methods alleviate the parameter setting problem somewhat. They provide a ranked list of objects that represent the d egree of  X  X utlier-ness X  of each object.
Top-nK th -Nearest Neighbour distance [RRS00] is a typical top-n style outlier detection approach. In top-n KNN outlier, the distance from an object to its k th nearest neighbour (denoted as k -distance for short) indicates outlier-ness of the object. Intuitively, the larger the k -distance is, the higher outlier-ness the object has. Top-n KNN outlier regards the n objects with the highest values of k -distance as outliers [RRS00].

A density-based outlier, Local Outlier Factor (LOF) [BKNS00], was proposed in the same year as top-n KNN. In LOF, an outlier factor is assigned for each ob-ject w.r.t its surrounding neighbourhood. The outlier factor depends on how the data object is closely packed in its loca lly reachable neighbourhood [FZFW06]. In recent real-world applications, resea rchers have found it more reliable to use LOF in a top-n manner [TCFC02], i.e. only objects with the highest LOF values will be considered outliers . Hereafter, we call it top-n LOF.

In this paper, we propose a new outlier detection definition which is sensitive to outliers in scattered datasets, named Local Distance-based Outlier Factor (LDOF). LDOF uses the relative distance from an object to its neighbours to measure how much objects deviate from their scattered neighbourhood. The higher the violation degree an object has, the more likely the object is an outlier. In Section 2, we illustrate and discuss the problems of top-n KNN and top-n LOF on a real-world dataset. In Section 3, we formally introduce the outlier defi-nition of our approach, and mathematically analyse properties of our outlier-ness factor in Section 4. In Section 5, the top-n LDOF outlier detection algorithm is described, together with an analysis of its complexity. Experiments are reported in Section 6, which show the superiority of our method to previous approaches, at least on the considered datasets. Finally, conclusions are presented in Section 7. In real-world datasets, high dimensionality (e.g. 30 features) and sparse feature value range usually cause objects to be scattered in the feature space. The scat-tered data is similar to the distribution of stars in the universe. Locally, they seem to be randomly allocated in the night sky (i.e. stars observed from the Earth), whereas globally the stars constitute innumerable galaxies. Figure 1(a) illustrates a 2-D projection of a real-world dataset, Wisconsin Diagnostic Breast Cancer (WDBC) 1 , which is typically 30-D. The green points are the benign diagnosis records (regarded as normal objects), and the red triangles are malig-nant diagnosis records (i.e. outliers we want to capture). Obviously, we cannot detect these outliers in 2-D space, wherea s in high dimension (e.g. 30-D), these scattered normal objects constitute a certain number of loosely bounded mini-clusters, and we are able to isolate genuine outliers. Unlike galaxies, which always contain billions of stars, these mini-clusters in scattered datasets usually have a relatively small number of objects. Figure 1(b) is a simple demonstration of this situation, where C 1 is a well-shaped cluster as we usually define in other outlier detection methods. C 2 and C 3 are comprised of scattered objects with loose boundary, called mini-clusters. These small clusters should be recognised as  X  X ormal X , even if they contain a smal l number of objects. The objects of our interest are the points lying far away from other mini-clusters. Intuitively, o 1 , o 2 , o , o 4 are outliers in this sample. We recall a well accepted informal outlier defi-nition proposed by Hawkins [Haw80]:  X  X n outlier is an observation that deviates so much from other observations as to arouse suspicion that it was generated by a different mechanism X  . In scattered datasets, an outlier should be an object deviating from any other group of objects.

The only way in which our outlier definition differs from others (e.g. in [KN98] and [BKNS00]) is that the normal pattern of data is represented by scattered objects, rather than crowde d main clusters. The neighbourhood in scattered real-world datasets has two chara cteristics: (1) objects in mini-clusters are loosely distributed; (2) when neighbourhood size k is large, two or more mini-clusters are taken into consideration. The neighbourhood becomes sparse as more and more objects which belong to different mini-clusters should be taken into account.
As discussed above, top-n KNN and top-n LOF are ineffective for scattered datasets. Take a typical example, in Figure 1(b), when k is greater than the cardinality of C 3 (10 in this case), some objects in C 1 become neighbours of the objects in C 3 . Hence, for top-n KNN, the k -distance of the object can be larger than genuine outliers. For top-n LOF, since the density of C 3 is smaller than positions. In Section 6, we will demonstrate that the two methods fail to detect genuine outliers when k grows greater than 10.

Intuitively, it is more reasonable to measure how an object deviates from its neighbourhood system as an outlier-ness factor rather than global distance (top-n KNN) or local density (top-n LOF). Thereby, we propose LDOF to measure the degree of neighbourhood violation. The formal definition of LDOF is introduced in the following section. In this section, we develop a formal definition of the Local Distance-based Outlier Factor, which avoids the shortcomings presented above.
 Definition 1 (KNN distance of x p ). Let N p be the set of the k -nearest neighbours of object x p (excluding x p ). The k -nearest neighbours distance of x p equals the average distance from x p to all objects in dist ( x, x )  X  0 be a distance measure between objects x and x .The k -nearest neighbours distance of object x p is defined as Definition 2 (KNN inner distance of x p ). Given the k -nearest neighbours set N p of object x p ,the k -nearest neighbours inner distance of x p is defined as the average distance among objects in N p : Definition 3 (LDOF of x p ). The local distance-based outlier factor of x p is defined as: If we regard the k -nearest neighbours as a neighbourhood system, LDOF cap-tures the degree to which object x p deviates from its neighbourhood system. It has the clear intuitive meaning that LDOF is the distance ratio indicating how far the object x p lies outside its neighbourhood system. When LDOF &lt;  X  1, it means that x p is surrounded by a data  X  X loud X . On the contrary, when LDOF 1, x p is outside the whole  X  X loud X . It is easy to see that the higher LDOF is, the farther x p is away from its neighbourhood system.

To further explain our definition, we exemplify it in Euclidian space. Here-inafter, let x i  X  X  = I R d ,and  X  x := 1 k x distance ||  X  || 2 , the outlier definition can be written as: Thus, LDOF k ( x p ) 1, i.e. x p lies outside its neighbourhood system, iff The same expression holds for the more general Mahalanobis distance [MKB79]. In Equation 3, the lefthand-side is the square distance of x p to its neighbour-hood centroid  X  x , and the righthand-side becomes the distance variance in N p when k 1. Therefore, Equation 6 can be understood as follows: The k -nearest neighbours of object x p form a  X  X eformed X  neighbourhood region, represented as a hyperball with radius  X  D x p , centered at  X  x . As illustrated in Figure 2(a), since the neighbours of x p are scattered, it is unclear whether x p (indicated by ) belongs to its neighbourhood system or not. Our LDOF definition, as shown in Figure 2(b), it clearly regards x p as lying outside its reformed neighbourhood region. The LDOF of x p is obviously greater than 1, which indicates that x p is an outlier. Through this example we can see that LDOF can effectively capture the outlier-ness of an object among a scattered neighbourhood. In addition, as k grows, LDOF takes more objects into consideration, and the view of LDOF becomes increasingly global. If an object is far from its large neighbourhood system (extremely the whole dataset) it is definitely a genuine outlier. Hence, the detection precision of our method might be stable over a large range of k . In the following section, we will theoretically analyse properties of LDOF ,and propose a heuristic for selecting the neighbourhood size k . Lower bound of LDOF . Ideally, we prefer a universal threshold of LDOF to unambiguously distinguish abnormal from normal objects (e.g. in any datasets, an object is outlier if LDOF &gt; 1). However, the threshold is problem dependent due to the complex structure of real-world datasets. Under some continuity as-sumption, we can calculate an asymptotic lower bound on LDOF , denoted as LDOF lb . LDOF lb indicates that an object is an inlier (or normal) if its LDOF is smaller than LDOF lb .
 Theorem 1 ( LDOF lower-bound of outliers). Let data D be sampled from a density that is continuous at x p .For N k 1 we have LDOF lb  X  1 2 with high probability. More formally, for k, N  X  X  X  such that the neighbourhood size  X  D The theorem shows that when LDOF  X  1 2 , the point is squarely lying in a uniform cloud of objects, i.e. it is not an outlier. The lower-bound of LDOF provides a potential pruning rule of algor ithm complexity. In practice, objects can be directly ignored if their LDOF s are smaller than 1 2 .Remarkably, LDOF lb does not depend on the dimension of X . This is very convenient: data often lie on lower-dimensional manifolds. Since locally, a manifold is close to an Euclidian space (of lower dimension), the result s till holds in this case. Therefore, we do not need to know the effective dimension of our data.
 False-detection probability. As discussed in Section 1, i n real-world datasets, it is hard to set parameters properly by trial-and-error. Instead of requiring prior knowledge from datasets (e.g. outlier labels), we theoretically determine the false-detection probability, given neighbourhood size k .
 Theorem 2 (False-detection probability of LDOF). Let data D be uni-formly distributed in a neighbourhood of x p containing k objects N p .For LDOF nentially small in k .Moreprecisely, The bound still holds for non-uniform densities continuous in x p ,provided N k . In particular, for c = 1 in high-dimensional spaces ( d  X  X  X  )weget  X   X  1 50 . So for k 50 the false-detection probability is very small. Note that because the bound is quite crude, we can expect good performance in practice for much smaller k . On the other hand, choosing c  X  1 2 degenerates the bound (i.e.  X   X  0), consistent with Theorem 1.

Due to space limitation, we omit the proofs of Theorems 1 and 2. Top-n LDOF. Even with the theoretical analysis of the previous section, it is still hard to determine a threshold for LDOF to identify outliers in an arbitrary dataset. Therefore we employ top-n style outlier detection, which ranks the n objects with the highest LDOF s. The algorithm that obtains the top-nLDOF outliers for all the N objects in a given dataset D is outlined in Algorithm 1. Algorithm 1. Top-n LDOF (Top-n Local Distance-ba sed Outlier Factor) How to choose k . Based on Theorem 2, it is beneficial to use a large neigh-bourhood size k . However, too large k will lead to a global method with the same problems as top-n KNN outlier. For the best use of our algorithm, the lower bound of potentially suitable k is given as follows: If the effective dimen-sion of the manifold on which D lies is m ,thenatleast m points are needed to  X  X urround X  another object. That is to say a k&gt;m is needed. In Section 6, we will see that, when k increases to the dimension of the dataset, the detection performance of our method rises, and remains stable for a wide range of k values. Therefore, the parameter k in LDOF is easier to choose than in other outlier detection approaches.
 Algorithm complexity. In Step 1, querying the k -nearest neighbours, takes the majority of the computational load. Naively, the runtime of this step is O ( N 2 ). If a tree-based spatial index such as X -tree or R  X  -tree is used [BKNS00, BKNS99], the complexity is reduced to O ( N log N ). Step 2 is straightforward and calculates LDOF values according to Definition 3. As the k -nn query is materialised, this step is linear in N .Step3sortsthe N objects according to their LDOF values, which can be done in O ( N log N ). Since the objects with LDOF &lt; LDOF lb are flushed (i.e. they are definitely non-outliers), the number of objects needed to sort in this step is smaller than N in practice. Finally, the overall computation complexity of Algorithm 1 is O ( N log N ) with appropriate index support. In this section, we compare the out lier detection performance of top-n LDOF with two typical top-n outlier detection methods, top-n KNN and top-n LOF. Experiments start with a synthetic 2-D dataset which contains outliers that are meaningful but are difficult for top-n KNN and top-n LOF. In Experiments 2 and 3, we identify outliers in two real-world datasets to illustrate the effectiveness of ourmethodinreal-worldsituations.Fo r consistency, we onl y use the parameter k to represent the neighbourhood size in the investigation of the three methods. In particular, in top-n LOF, the parameter MinPts is set to neighbourhood size k as chosen in the other two methods.
 Synthetic Data. In Figure 1(b), there are 150 objects in cluster C 1 , 50 objects which are genuine outliers. We ran the three outlier detection methods over a large range of k . We use detection precision 2 to evaluate the performance of each method. In this experiment, we set n = 4 (the number of real outliers). The experimental result is shown in Figure 3(a). The precision of top-n KNN becomes 0 when the k is larger than 10 due to the effect of the mini-cluster C 3 as we discussed in Section 2. For the same reason, the precision of top-n LOF dramatically descends when k is larger than 11. When the k reaches 13, top-n LOF misses all genuine outliers in the top-4 ranking (they even drop out of top-10). On the contrary, our method is not suffering from the effect of the mini-cluster. As shown in the Figure 3(a), the precision of our approach keeps stable at 100% accuracy over a large neighbourhood size range (i.e. 20-50). Medical Diagnosis Data. In real-world data repositories, it is hard to find a dataset for evaluating outlier detection algorithms, because only for very few real-world datasets it is exactly known which objects are really behaving dif-ferently [KSZ08]. In this experiment, we use a medical dataset, WDBC (Di-agnosis) 1 , which has been used for nuclear feature extraction for breast tumor diagnosis. The dataset contains 569 medical diagnosis records (objects), each with 32 attributes (ID, diagnosis, 30 real-valued input features). The diagno-sis is binary:  X  X enign X  and  X  X alignant X . We regard the objects labeled  X  X enign X  as normal data. In the experiment we use all 357  X  X enign X  diagnosis records as normal objects and add a certain number of  X  X alignant X  diagnosis records into normal objects as outliers. Figure 3(b) shows the experimental result for adding the first 10  X  X alignant X  records from the original dataset. Based on the rule for selecting neighbourhood size, k , suggested in Section 4, we set k  X  30 in regards to the data dimension. We measure the p ercentage of real ou tliers detected in top-10 potential outliers as detection precision 2 . In the experiments, we pro-gressively increase the value of k and calculate the detect ion precision for each method. As shown in Figure 3(b), the precision of our method begins to ascend at k = 32, and keeps stable when k is greater than 34 wit h detection accuracy of 80%. In comparison, the precision of the other two techniques are towed over the whole k value range.

To further validate our approach, we repeat the experiment 5 times with a different number of outliers (randomly extracted from  X  X alignant X  objects). Each time, we perform 30 independent runs, and calculate the average detection pre-cision and standard deviation over the k range from 30 to 50. The experimental results are listed in Table 1. The bold numbers indicate that the detection pre-cision vector over the range of k is statistically significantly improved compared to the other two methods (paired T-test at the 0.1 level).
 Space Shuttle Data. In this experiment, we use a dataset originally used for classification, named Shuttle 3 . We use the testing dataset which contains 14500 objects, and each object has 9 real-valued features and an integer label (1-7). We regard the (only 13) objects with label 2 as outliers, and regard the rest of the six classes as normal data. We run the experiment 15 times and each time we randomly pick a sample of normal objects (i.e. 1,000 objects) to mix with the 13 outliers. The mean values of detection precision of the three methods are presented in Figure 4. As illustrated in Figure 4, top-n KNN has the worst performance (rapidly drops to 0). Top-n LOF is better, which has a narrow precision peak ( k from 5 to 15), and then declines dramatically. Top-n LDOF has the best performance, as it ascends steadily and keeps a relative high precision over the k range from 25 to 45. Table 4 shows the average precisions for the three methods over 15 runs. The bold numbers indicate that the precision vector is statistically significantly im proved compared to the other two methods (paired T-test at the 0.1 level). In this paper, we have proposed a new ou tlier detection definition, LDOF. Our definition uses a local distance-based outlier factor to measure the degree to which an object deviates from its scattered neighbourhood. We have analysed the properties of LDOF, including its lower bound and false-detection probability. Furthermore, a met hod for selecting k has been suggested. In order to ease the parameter setting in real-world applications, the top-n technique has been used in this approach. Experimental results have demonstrated the ability of our new approach to better discover outliers with high precision, and to remain stable over a large range of neighbourhood sizes, compared to top-n KNN and top-n LOF. As future work, we are looking to extend the proposed approach to further enhance the outlier detection accuracy for scattered real-world datasets.
