 This paper shows how different measures of similarity de-rived from the citation information and the structural con-tent (e.g., title, abstract) of the collection can be fused to improve classification effectiveness. To discover the best fu-sion framework, we apply Genetic Programming (GP) tech-niques. Our experiments with the ACM Computing Clas-sification Scheme, using documents from the ACM Digital Library, indicate that GP can discover similarity functions superior to those based solely on a single type of evidence. Effectiveness of the similarity functions discovered through simple majority voting is better than that of content-based as well as combination-based Support Vector Machine clas-sifiers. Experiments also were conducted to compare the performance between GP techniques and other fusion tech-niques such as Genetic Algorithms (GA) and linear fusion. Empirical results show that GP was able to discover better similarity functions than other fusion techniques. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval; I.5.4 [Pattern Recognition]: Applications X  Text pro-cessing General Terms: Algorithms, Measurement, Performance, Experimentation Keywords: Classification, document similarity, Genetic Pro-gramming
In recent years, automated classification of text into pre-defined categories has attracted considerable interest, due to the increasing volume of documents in digital form and the ensuing need to organize them. Particularly, digital li-brary (DL) collections offer a number of opportunities and challenges for classification. The complex internal struc-ture of documents and metadata records in DLs provides additional information that can be used in the classification task. On the other hand, many DLs suffer from problems of quality of information. One such problem is incomplete-ness (e.g., missing information). This makes it very hard to classify documents using traditional content-based classi-fiers like SVM, kNN , or Naive Bayes. Another quality prob-lem is imprecision. For example, citation-based information is often obtained with OCR, a process which produces a significant number of errors. In this work we try to over-come these problems by applying automatically discovered techniques for fusion of the available evidence. Particularly, we investigate an inductive learning method  X  Genetic Pro-gramming (GP)  X  for the discovery of better fused similarity functions to be used in the classifiers, and explore how this combination can be used to improve classification effective-ness.
Genetic algorithms (GAs) and genetic programming (GP) [2] are a set of artificial intelligence search algorithms de-signed following the principles of biological inheritance and evolution. The solution to a problem is represented as an individual (i.e., a chromosome) in a population pool. The population of individuals evolves generation by generation through genetic transformation operations  X  such as repro-duction, crossover, and mutation  X  with the aim of creating more diverse and better performing individuals with better fitness values in subsequent generations. A fitness function is available to assign the fitness value for each individual.
To determine the similarity between two documents we used three different similarity measures applied to the con-tent of abstract, title, and abstact-plus-title of documents separately: Bag-of-Words, Cosine, and Okapi. Also, we used five different citation-related similarity measures: co-citation, bibliographic coupling, Amsler, and Companion (authority and hub). This gave us fourteen similarity mea-sures, represented as document  X  document matrices. Through GP, we intend to discover a single similarity function, for each class, that combines all or several of the similarity mea-sures described here. The overall classification framework is as follows: 1. For each class, generate an initial population of ran-2. For each class, perform the following sub-steps on train-3. Apply the recorded ( N gen * N top ) candidate  X  X imilar-4. For each class C, use b C as similarity function in a kNN 5. Combine the output of each classifier through a simple
The discovered functions only can be used to calculate the similarity between a pair of documents. In order to evaluate the performance of those functions in the classification task, we used a strategy based on a nearest neighbor classifier  X  kNN [3]. The kNN algorithm was chosen since it is simple and makes direct use of similarity information. In multi-classification problems with n classes, we effectively end up with n kNN classifiers using the described framework. In order to produce a final classification result, we combine the output of all n classifiers using a simple majority voting scheme, whereby the class of a document d i is decided by the most common class assigned by all the n classifiers. In case of ties, we assign d i to the larger class.
To test the hypotheses that GP is able to adapt itself to find the best similarity functions we ran two sets of exper-iments following the framework of the previous section on both the first level and the second level of the ACM Com-puting Classification System (CCS, http://www.acm.org/ class/1998/ ). We follow a three data-sets design [1] in our experiment. We randomly split the data into training, val-idation, and test parts. The introduction of the validation data-set is to help alleviate the problem of overfitting of GP on the training data and select the best generalizable similarity function. We used stratified random sampling to generate two sample sets, namely, 15% and 30%, for each of the top two levels of CCS.

We demonstrate the effectiveness of our classification frame-work in several ways by compari ng our experimental results with: 1) majority voting of classifiers using the best base-lines (the classification statistics of each feature in isolation) as similarity functions; 2) the results achieved through a linear combination of both the content-based and structure-based information through SVM; and 3)the results achieved through a content-based SVM classifier 1 . For completeness, we also compare our classification framework against a clas-sifier using a simple linear fusion of evidence as the similarity function and against a classifier using the similarity function discovered through GA. For content we used a concatenation of title + abstract. Table 1: Macro F1 Comparison between majority GP, Majority Voting using the best evidence per class in isolation, Linear Fusion, GA, content-based and combination-based SVM.

From Table 1, it is clear that majority GP presents bet-ter performance than the majority using the best evidence. When majority GP is compared with the combination-based SVM classifiers, the gains are even higher: we obtain a gain of 14.50% in the 15% sample and 10.03% in the 30% sample for the first level and a gain of 23.73% in the 15% sample and 18.78% in the 30% sample for the second level. The performance of content-based SVM is also worse than that of the majority GP, which suggests that we have a better classification method. Finally, when we compare majority GP against both linear fusion and GA, we see that GP is able to discover better similarity functions.
In this paper, we considered the problem of classifica-tion in the context of document collections where textual content is scarce and imprecise citation information exists. A framework for tackling this problem based on Genetic Programming has been proposed and tested. Our experi-mental results have demonstrated that the GP framework can produce better classifiers than ones using individual ev-idence in isolation as well as both traditional content-based and combination-based SVM classifiers. Comparison also showed that GP has the ability to discover better similarity functions than GA and linear fusion.

Future work will include analysis of the reasons why GP-based fusion works and exploration of parallel computa-tion to address the scalability issue. We also want to test this framework with different document collections (e.g., the Web) to assess its applicability. Finally, new terminals (fea-tures) representing additional evidence may be explored; one example is further evidence such as anchor/citation text or patterns of authorship. This work was funded in part by NSF through grants DUE-0136690, DUE-0121679, and IIS-0086227. Additional support was provided by AOL fellowship, CNPq, MCT/-FCT (grant SFRH/BD/4662/2001), and Fucapi Technology Foundation.
