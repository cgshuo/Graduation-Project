 Information diffusion and virus propagation are fundament al pro-cesses talking place in networks. While it is often possible to di-rectly observe when nodes become infected, observing indiv idual transmissions (i.e., who infects whom or who influences whom ) is typically very difficult. Furthermore, in many applicati ons, the underlying network over which the diffusions and propagati ons spread is actually unobserved . We tackle these challenges by devel-oping a method for tracing paths of diffusion and influence th rough networks and inferring the networks over which contagions p rop-agate. Given the times when nodes adopt pieces of informatio n or become infected, we identify the optimal network that bes t ex-plains the observed infection times. Since the optimizatio n problem is NP-hard to solve exactly, we develop an efficient approxim ation algorithm that scales to large datasets and in practice give s provably near-optimal performance.

We demonstrate the effectiveness of our approach by tracing in-formation cascades in a set of 170 million blogs and news arti cles over a one year period to infer how information flows through t he online media space. We find that the diffusion network of news tends to have a core-periphery structure with a small set of c ore media sites that diffuse information to the rest of the Web. T hese sites tend to have stable circles of influence with more gener al news media sites acting as connectors between them.
 Categories and Subject Descriptors: H.2.8 [Database Manage-ment] : Database applications X  Data mining General Terms: Algorithms; Experimentation.
 Keywords: Networks of diffusion, Information cascades, Blogs, News media, Meme-tracking, Social networks.
Cascading behavior, diffusion and spreading of ideas, inno va-tion, information, influence, viruses and diseases are fund amental processes taking place in networks [12, 28, 30]. In order to s tudy network diffusion there are two fundamental challenges one has to address. First, to be able to track cascading processes taki ng place in a network, one needs to identify the contagion (idea, info rma-tion, virus, disease) that is actually spreading and propag ating over the edges of the network. Moreover, one has to then identify a way to successfully trace the contagion. For example, when trac ing in-formation diffusion, it is a non-trivial task to automatica lly and on a large scale identify the phrases or  X  X emes X  that are spread ing through the Web. Second, we usually think of diffusion as a pr o-cess that takes place on a network . However, the network over which propagations take place is usually unknown and unobserved . Commonly, we only observe the times when particular nodes ge t  X  X nfected X  but we do not observe who infected them. In case of in-formation propagation, as bloggers discover new informati on, they write about it without explicitly citing the source. Thus, w e only observe the time when a blog gets  X  X nfected X  but not where it g ot infected from. Similarly, in virus propagation, we observe people getting sick without usually knowing who infected them. And , in a viral marketing setting, we observe people purchasing prod ucts or adopting particular behaviors without explicitly knowing who was the influencer that caused the adoption or the purchase.
These challenges are especially pronounced in information diffu-sion on the Web, where there have been relatively few large sc ale studies of information propagation in large networks [2, 23 , 24, 25]. In order to study paths of diffusion over networks, one essen tially requires to have complete information about who influences w hom, as a single missing link in a sequence of propagations can lea d to wrong inferences. Even if one collects near complete large s cale diffusion data, it is a non-trivial task to identify textual fragments that propagate relatively intact through the Web without hu man su-pervision. And even then the question of how information dif fuses through the network still remains. Thus, the questions are, what is the network over which the information propagates on the W eb? What is the global structure of such a network? How do news me-dia sites and blogs interact? What roles do different sites p lay in the diffusion process and how influential are they? Our approach to inferring networks of diffusion and influenc e. We address the above questions by positing that there is some un-derlying unknown network over which information, viruses o r in-fluence propagate. For simplicity, we assume that the underl ying network is static and does not change over time. We then obser ve the times when nodes get  X  X nfected X  by a particular contagio n (a particular piece of information, product or virus) but we do not ob-serve where they got infected from. Thus, for each cascade, w e only observe times when nodes got infected, and we are then in ter-ested in determining the paths the diffusion took through th e unob-served network. Our goal is to reconstruct the network over w hich cascades propagate.

Edges in such networks of influence and diffusion have variou s interpretations. In virus or disease propagation, edges ca n be inter-preted as who-infects-whom. In information propagation, e dges are who-copies-from-whom or who-listens-to-whom. In a viral m ar-keting setting, edges can be understood as who-influences-w hom.
The main premise of our work is that by observing many diffe-rent cascades spreading among the nodes, we can infer the edg es of the underlying propagation network. If node v tends to get infected soon after node u for many different cascades, then we can expect an edge ( u; v ) to be present in the network. By exploring corre-lations in node infection times, we aim to recover the unobse rved diffusion network.

Here we develop N ET I NF , a scalable algorithm for inferring net-works of diffusion and influence. We first formulate a generat ive probabilistic model of how, on a fixed hypothetical network, cas-cades spread as directed trees through the network. Since we only observe times when nodes get infected, there are many possib le propagation trees that explain the same data and we have to co n-sider all of them. Thus, naive computation of the model takes exponential time since there is a combinatorially large num ber of propagation trees. We show that, perhaps surprisingly, com puta-tions over this super-exponential set of trees can be perfor med in cubic time. However, under such model, the network inferenc e problem is still intractable. Thus, we introduce a tractabl e approxi-mation, and show that the resulting objective function can b e both efficiently computed and efficiently optimized. By exploiti ng a di-minishing returns property of the model, we prove that N ET infers near-optimal networks. We also speed-up N ET I NF algorithm by exploiting the local structure of the objective function and by using lazy evaluations [21].

Our results on synthetic datasets show that we can reliably i n-fer the underlying propagation and influence networks, rega rdless of the overall network structure. Validation on real and syn thetic datasets shows that N ET I NF outperforms a baseline heuristic by an order of magnitude and correctly discovers more than 90% o f the edges. We apply our algorithm to a real Web information pr o-pagation dataset of 170 million blog and news articles over a one year period. Our results show that online news propagation n et-works tend to have a core-periphery structure with a small se t of core blog and news media websites that diffuse information t o the rest of the Web, news media websites tend to diffuse the news f aster than blogs and blogs keep discussing about news longer time t han media websites.

Inferring how information or viruses propagate over networ ks is crucial for a better understanding of diffusion in networ ks. By modeling the structure of the propagation network, we can ga in insight into positions and roles various nodes play in the di ffusion process and assess the range of influence of nodes in the netwo rk.
We now formally describe the problem where many different cascades propagate over an unknown static network and for ea ch of them we observe times when nodes got infected but not who in-fected them. The goal then is to infer the unknown network ove r which cascades originally propagated. In the information d iffusion setting, each cascade corresponds to a different piece of in forma-tion that spreads over the network and all we observe are the t imes when particular sites mentioned particular information. T he task then is to infer the network where a directed edge ( u; v ) means that a site v tends to repeat or to mention stories after a site u .
Given a hidden directed network G  X  , we observe multiple cas-cades spreading over it. As the cascade c propagates over the net-work, it leaves a trace in the form of ( u i ; t i ;  X  i ) cascade c reached node u i at time t i with a set of features or attri-butes  X  i . Note that we only observe the time t u when cascade c reached node u but not how it reached the node u . Now, given such traces of many different cascades, we aim to infer the unobse rved directed network G  X  , i.e., the network over which the cascades originally propagated. We refer to the estimated version of the net-work as  X  G . We use the term hit time t u to refer to the time when a cascade hits (infects) a particular node u . Many cascades will not hit all the nodes  X  if a node u is not hit by a cascade, then t Thus, a cascade is fully specified by the vector t = [ t 1 of hit times, and the feature vector  X  = [  X  1 ; : : : ;  X  the properties of the contagion and the node (where n is the num-ber of nodes in G ). Note that the probability of propagation may be a complicated function of the properties of the nodes (e.g ., age, gender) and the properties of the contagion itself (e.g., pr oduct cat-egory, price). One can use the feature vector  X  to describe such properties of individual nodes and contagions.
Suppose that for a fixed cascade c = ( t ;  X  ) , we know which nodes influenced which other nodes. We assume that every node v in a cascade is influenced by at most one node u . Thus, the in-fluence structure of a cascade c is given by a directed tree T , which we assume to be contained in the directed graph G , i.e., the graph over which the cascade propagated. First, we will specify th e cas-cade transmission model P c ( u; v ) that describes how likely is that node u spreads the cascade c to node v . We will then describe the probability P ( c | T ) that the cascade c propagates in a particular tree pattern T , where tree T simply specifies which nodes influence which other nodes. Last, we will define P ( c | G ) , which is the prob-ability that cascade c occurs in a network G .
 Cascade transmission model. We build on the independent cas-cade model [13] which posits that an infected node infects ea ch of its neighbors independently with some chosen probability. As in this model the time is modeled only implicitly through the ep ochs of the propagation we fist extend the independent cascade mod el to continuous time domain. We account for the fact that informa tion can spread quickly over some edges while over others it may ta ke Figure 2: (a) Diffusion network G . (b) A cascade c on nodes u (black edges). As node u 1 does not have a parent, the  X  -edge ( m; u ) is picked. (c) The maximum directed spanning tree of a graph is obtained by each node picking an incoming edge of maximum w eight. much longer to propagate. Also note that cascades in such a mo del are necessarily trees since if a node u gets infected multiple times knowing the node that infected u first is sufficient.

First we define the probability of observing a particular cas cade c = ( t ;  X  ) of hit times and features for a fixed propagation tree T . Consider a single edge ( u; v )  X  T . Given the hit times ( u; t and ( v; t v ) c ( t u &lt; t v ) of nodes u and v in cascade c , we aim to estimate the probability P c ( u; v ) that a node u spreads the cascade to a node v (i.e. a node u influences/infects/transmits to a node v ) in the tree T . Formally, P c ( u; v ) specifies the conditional probability of observing cascade c spreading from node u to node v .
Influence can only propagate forward in time. Thus, if t u we simply set P c ( u; v ) = 0 . Generally the probability of propaga-tion P c ( u; v ) between a pair of nodes u and v is decreasing in the difference of their infection times, i.e., the farther apar t in time the two nodes get infected the less likely they are to infect one a nother. However, note that we can make the cascade transmission mode l P ( u; v ) arbitrarily complicated as it can also depend on feature vectors  X  u and  X  v that describe the properties of the contagion and the properties of the nodes. For example, in a disease propag ation scenario,  X  could include information about the individual X  X  socio-economic status, commute patterns, disease history and so o n. This allows for much more realistic cascade transmission models as the probability of infection depends on the parameters of the di sease and properties of the nodes. For simplicity, in the rest of th e paper and in all our experiments, we ignore the features and assume that the probability of transmission depends only on the time dif ference between the node hit times  X  = t v  X  t u .

Considering the model in a generative sense, the cascade c reaches node u at time t u , and we now need to generate the time t u spreads the cascade to node v . As cascades generally do not in-fect all the nodes of the network, we need to explicitly model the probability that the cascade stops. With probability (1  X   X  ) , the cascade stops, and never reaches v , thus t v =  X  . With probabil-ity  X  , the cascade continues, and the hit time t v is set to t where  X  is the waiting time that passed between the hit times t and t v . We consider two different models for the waiting time  X  , an exponential and a power-law model, each with parameter  X  : We consider both the power-law and exponential waiting time mod-els since they have both been argued for in the literature [3, 23, 26]. In the end, our algorithm does not depend on the particular ch oice of the waiting time distribution and more complicated funct ions can easily be chosen [6]. Also, we interpret  X  +  X  =  X  , i.e., if t =  X  , then t v =  X  with probability 1 .

Now that we specified the probability P c ( u; v ) that node u in-fluences node v , we define the probability of observing cascade c propagating in a particular tree structure T as where the product is over the edges of the tree T . Here, the edges of the tree T simply specify how the cascade spreads, i.e., every node gets influenced by its parent.
 Cascade propagation model. We just defined the probability of a single cascade c propagating in a particular tree pattern T , P ( c | T ) . Now, our aim is to compute P ( c | G ) , the probability that a cascade c occurs in a graph G . Note that cascade is defined only by the node infection times and the propagation tree T (who-infected-whom) is unknown. So, we combine the probabilities of individual pro paga-tion trees into a probability of a cascade c occurring in a network G . We do this by considering all possible propagation trees T , i.e., all possible ways in which cascade c could have spread over G : P ( c | G ) = X where c is a cascade and T ( G ) is the set of all the directed spa-nning trees on G . Basically, the graph G defines the skeleton over which the cascades propagate and T defines a particular possible propagation. Since we do not know in which particular tree pa ttern the cascade really propagated, we consider all possible pro pagation trees T in T ( G ) . Thus, the sum over T is a sum over all directed spanning trees in T ( G ) . We assume that all propagation trees are a priori equally likely, i.e., P ( T | G ) is the uniform distribution over all directed spanning trees.

We just computed the probability of a single cascade c occurring in G , and we now define the probability of a set of cascades C occurring in G simply as where we assume conditional independence between cascades given the graph G .
 Network inference problem. Next, we define the diffusion net-work inference problem , where we aim to find  X  G that solves the following optimization problem: where the maximization is over all graphs G of at most k edges. We add the constraint on the number of edges in  X  G for two reasons. First, the optimization problem without the constraint wou ld have a trivial solution since the fully connected graph maximize s the above quantity. Second, since real graphs are sparse, we als o seek for a sparse solution. We discuss how to choose k later.
The above optimization problem seems wildly intractable. T o evaluate Eq. (2), we need to compute Eq. (1) for each cascade c , i.e., the sum over all possible spanning trees T . The number of trees can be super-exponential in the size of G but perhaps surprisingly, this super-exponential sum can be performed in time polynom ial in the number n of nodes in the graph G , by applying Kirchhoff X  X  matrix tree theorem [15]:
T HEOREM 1 (T UTTE (1948)). If we construct a matrix A such that a i;j = P w k;j if i = j and a i;j =  X  w i;j if i 6 = j and if A is the matrix created by removing any row k and column m from A such that k + m is an even number, then where T is each directed spanning tree in A .

In our case, we set w i;j to be simply P c ( i; j ) and we compute the product of the determinants of | C | matrices, one for each cas-cade, which is exactly Equation 1. This means that instead of using super-exponential time, we are now able to evaluate Eq . 2 in time O ( | C | n 3 ) (the time required to compute | C | determi-nants). However, this does not completely solve our problem for two reasons: First, while cubic time is a drastic improvemen t over a super-exponential computation, it is still too expensive f or the large graphs that we want to consider. Second, we can use the above r e-sult only to evaluate the quality of a particular graph G , while our goal is to find the best graph  X  G . To do this, one would need to search over all graphs G to find the best one. Again, as there is a super-exponential number of graphs, this is practically i mpossi-ble. One could propose some search heuristics, like hill-cl imbing, however, due to the combinatorial nature of the likelihood f unction, such a procedure would likely be prone to local minima.
The diffusion network inference problem defined in the previ ous section does not allow for an efficient solution. We now propo se an alternative formulation of the problem that is tractable to compute and to optimize.
For each cascade c , instead of considering every possible prop-agation (spanning) tree T , we consider only the most likely propa-gation tree T :
P ( C | G ) = Y We then define the improvement of log-likelihood for cascade c under graph G over an empty graph  X  K : Note that maximizing Eq. (4) is equivalent to maximizing the fol-lowing objective function: In reality, nodes may get infected for reasons other than the network influence. For example, in online media, not all the informat ion propagates via the network, as some is also pushed onto the ne t-work by the mass media [12, 30] and thus a disconnected cascad e can be created. Similarly, in viral marketing, a person may p ur-chase a product due to the influence of peers (i.e., network ef fect) or for some other reason (e.g., seing a commercial on TV) [17] .
In order to account for such phenomena when a cascade  X  X umps X  across the network, we introduce an additional node m that repre-sents an external source that can infect any node u . We connect the external influence source m (i.e., the mass media node) to ev-ery other node u with an  X  -edge. And then every node u can get infected by the external source m with a very small probability  X  .
Putting it all together, we include the additional node m in every cascade c and we set the probability of a cascade spreading from m to any node j in the cascade c to P c ( m; j ) =  X  . Given that we are accounting for reasons other than the network influence f or a node to get infected, we assume that the  X  -edges between m and all nodes in the cascade c exist also for the empty graph  X  K . We now expand Eq. (5) as where w c ( i; j ) = log P c ( i; j )  X  log  X  is a non-negative weight which can be interpreted as the improvement in log-likeliho od of edge ( i; j ) under the most likely spanning tree T in G . This means that the most likely propagation tree T is simply the maximum weight directed spanning tree in graph G , where each edge ( i; j ) has weight w c ( i; j ) , and F c ( G ) is simply the sum of the weights of edges in T . Figures 2(a) and 2(b) illustrate the notion of a cascade on a directed graph, as well as the concept of  X  -edges. Note that since edges ( i; j ) where t i  X  t j have weight 0 (i.e., they are not present) and the node m has only outgoing edges, for a fixed cas-cade c , the collection of edges with positive weight forms a direct ed acyclic graph (DAG). Interestingly, for such a DAG, the maximum weight directed spanning tree can be computed efficiently:
P ROPOSITION 1. In a DAG G with vertex set V and nonne-gative edge weights w , the maximum weight directed spanning tree can be found by choosing, for each node v , an incoming edge ( u; v ) with maximum weight w ( u; v ) .
 P ROOF . The score of a tree T is the sum of the incoming edge weights w ( P ar for each node i , where P ar T ( i ) is the parent of node i in T (and the root is handled appropriately). Now, max Latter equality follows from the fact that since G is a DAG, the maximization can be done independently for each node withou t creating any cycles.
 This proposition is a special case of the more general maximu m spanning tree (MST) problem in directed graphs [7]. The impo r-tant fact now is that we can find the best propagation tree T in time O ( | G | ) linear in the number of edges by simply selecting an incoming edge of highest weight for each node (Figure 2(c)). By construction F C (  X  K ) = 0 , i.e., the empty graph has score 0. Also note that F C is non-negative and monotonic, It can be seen that the objective function F C is monotonic, i.e., F
C ( G )  X  F C ( G  X  ) , whenever G  X  G  X  . Hence adding more edges to G does not decrease the solution quality, and thus the complet e graph maximizes F C . However, in practice, we are interested in inferring sparse graphs, that only contain a small number k of rel-evant edges. Thus we would like to solve Naively searching over all k edge graphs would take time expo-nential in k , which is intractable. Moreover, finding the optimal solution to Eq. (6) is NP-hard, so we cannot expect to find the o pti-mal solution:
T HEOREM 2. The diffusion network inference problem defined by equation (6) is NP-hard.
 P ROOF . By reduction from the MAX-k -COVER problem [14]. In MAX-k -COVER, we are given a finite set W , | W | = n and a collection of subsets S 1 ; : : : ; S m  X  W . The function counts the number of elements of W covered by sets indexed by A . Our goal is to pick a collection of k subsets A maximizing F MC . We will produce a collection of n cascades C over a graph will be defined over the set of vertices V = { 1 ; : : : ; m } X  { r } , i.e., there is one vertex for each set S i and one extra vertex r . For each element s  X  W we define a cascade which has time stamp 0 associated with all nodes i  X  V such that s  X  S i , time stamp 1 for node r and  X  for all remaining nodes. Furthermore, we can choose the transmission model such that w c ( i; r ) = 1 whenever s  X  S and w c ( i  X  ; j  X  ) = 0 for all remaining edges ( i  X  ; j parameters  X  ,  X  and  X  appropriately. Since a directed spanning tree over a graph G can contain at most one edge incoming to node r , its weight will be 1 if G contains any edge from a node i to r where s  X  S i , and 0 and otherwise. Thus, a graph G of at most k edges corresponds to a feasible solution A G to MAX-k -COVER where we pick sets S i whenever edge ( i; r )  X  G , and each solution A to MAX-k -COVER corresponds to a feasible solution G A of (6). Furthermore, by construction, F MC ( A G ) = F C ( G ) . Thus, if we had an efficient algorithm for deciding whether there exists a graph G , | G |  X  k such that F C ( G ) &gt; c , we could use the algorithm to decide whether there exists a solution A to MAX-k -COVER with value at least c .
 While finding the optimal solution is hard, we will now show th at F
C satisfies submodularity , a natural diminishing returns property, which will allow us to efficiently find a provably near-optimal so-lution to this NP-hard problem.

A set function F : 2 W  X  R mapping subsets of a finite set W to the real numbers is submodular if whenever A  X  B  X  W and i.e., adding s to the set A increases the score more than adding s to set B . We have the following result:
T HEOREM 3. Let V be a set of nodes, and C be a collection of cascades hitting the nodes V . Then F C ( G ) is a submodular function F C : 2 W  X  R defined over subsets W  X  V  X  V of directed edges.

P ROOF . Fix a cascade c , graphs G  X  G  X  and an edge e = ( r; s ) not contained in G  X  . We will show that F c ( G  X  X  e } )  X  F F ( G  X   X  X  e } )  X  F c ( G  X  ) . Since nonnegative linear combinations of submodular functions are submodular, the function F C ( G ) = Algorithm 1 The N ET I NF Algorithm Require: C; k
G  X   X  K ; for all c  X  C do while | G | &lt; k do return G; P c  X  C F c ( G ) is submodular as well. Let w i;j be the weight of edge ( i; j ) in G  X  X  e } , and w  X  i;j be the weight in G argued in Section 3.1, the maximum weight directed spanning tree for DAGs is obtained by assigning to each node the incoming ed ge with maximum weight. Let ( i; s ) be the edge incoming at s of maximum weight in G , and ( i  X  ; s ) the maximum weight incoming edge in G  X  . Since G  X  G  X  it holds that w i;s  X  w  X  i  X  ;s w
F c ( G  X  X  ( r; s ) } )  X  F c ( G ) = max( w i;s ; w r;s )  X  w proving submodularity of F c .

Maximizing submodular functions in general is NP-hard [14] . A commonly used heuristic is the greedy algorithm , which starts with an empty graph  X  K , and iteratively, in step i , adds the edge e maximizes the marginal gain:
The algorithm stops once it has selected k edges, and returns the solution  X  G = { e 1 ; : : : ; e k } . The stopping criteria, i.e., value of k , can be based on some threshold of the marginal gain, of the number of estimated edges or another more sophisticated heu ris-tic. Considering the hardness of the problem, we might expec t the greedy algorithm to perform arbitrarily bad. However, we wi ll see that this is not the case. A fundamental result of Nemhauser e t al. [27] proves that for monotonic submodular functions, th e set returned by the greedy algorithm obtains at least a constant fraction of (1  X  1 =e )  X  63% of the optimal value achievable using k edges.
Moreover, we can acquire a tight online bound on the solution quality:
T HEOREM 4 ([21]). For a graph  X  G , and each edge e =  X  let  X  e = F C (  X  G  X  X  e } )  X  F C (  X  G ) . Let e 1 ; : : : e with  X  e in decreasing order. Then, Thm. 4 computes how far a given  X  G (obtained by any algorithm) is from the unknown NP-hard to find optimum. Figure 3: Number of cascades per edge and cascade sizes for a Forest Fire network ( 1 ; 000 nodes, 1 ; 477 edges) with forward burning prob. 0 : 20 , backward burning prob. 0 : 17 and expo-nential transmission model with parameters  X  = 1 ;  X  = 0 : 5 . Speeding-up N ET I NF . We speed-up the algorithm by orders of magnitude by considering two improvements: As we will show later, these two improvements decrease the ru n time by several order of magnitude without any loss in the sol ution quality. We call the algorithm that implements the greedy al gorithm with the above speedups the N ET I NF algorithm (Algorithm 1). Ad-ditionally, N ET I NF lends itself to parallelization to tackle even big-ger networks in shorter amounts of computation time.
We first analyze the performance of N ET I NF on synthetic and real networks. We show that our algorithm outperforms a heur istic baseline and correctly discovers more than 90% of the edges.
The goal of the experiments on synthetic data is to understan d how the underlying network structure and the propagation mo del (exponential vs. power-law) affect the performance of our a lgo-rithm. In general, we proceed as follows: we generate a netwo rk G , simulate a set of cascades and for each cascade, record the node hit times t u . Then, given the hit times, we try to recover the network G  X  .

For example, Fig. 1(a) shows a graph G  X  of 20 nodes and 23 edges. We generated 24 cascades and recovered G  X  . A baseline method (b) (described below) performed poorly while our met hod (c) almost recovered G  X  perfectly by making only two errors. Experimental setup. We consider two models of directed real-world networks, namely, the Forest Fire model [20] and the Kr o-necker Graphs model [19] to generate G  X  . For Kronecker graphs, we consider three sets of parameters that produce networks w ith a very different structure: a random graph [8] (Kronecker par ameter matrix [0 : 5 ; 0 : 5; 0 : 5 ; 0 : 5] ), a network with hierarchical community Figure 4: Score achieved by N ET I NF in comparison with the online upper bound from Theorem 4. In practice N ET I NF finds networks that are at 97% of NP-hard to compute optimal. work [22] ( [0 : 962 ; 0 : 535; 0 : 535 ; 0 : 107] ). Notice that Forest Fire generates a scale free network [4].

We then simulate cascades on G  X  using the generative model de-fined in Section 2.1 that is parameterized by  X  , which controls how quickly a cascade spreads, and  X  , that controls how far a cascade spreads. We pick cascade starting nodes uniformly at random and generate enough cascades so that 99% of the edges in G  X  partici-pate in at least one cascade.

For example, for the Forest Fire network on 1,000 nodes and 1,477 edges, we generated 834 cascades. The majority of edge s took part in 4 to 12 cascades and the cascade size distributio n fo-llows a power law (Figure 3(b)). The average and median numbe r of cascades per edge are 9.1 and 8, respectively (Figure 3(a) ). Baseline method. To infer a diffusion network  X  G , we consider the following baseline method: For each possible edge ( u; v ) , we compute w ( u; v ) = P c  X  C P c ( u; v ) , i.e., overall how likely were the cascades c  X  C to propagate from u to v . Then we simply pick the k edges ( u; v ) with the highest weight w ( u; v ) to obtain  X  G (Fig. 1(b)).
 Solution quality. We evaluate the performance of the N ET I NF al-gorithm in two different ways. First, we are interested in ho w suc-cessful N ET I NF is at optimizing the objective function that is NP-hard to optimize exactly. Using the online bound in Theorem 4 , we can assess at most how far from the unknown optimal the N solution is.

Figure 4(a) plots the value of the objective function as a fun ction of the number of edges in  X  G . In red we plot the value achieved by N
ET I NF and in green the upper bound using Thm. 4. This tells us that the value of the unknown optimal solution (that is NP-ha rd to compute exactly) is somewhere between the red and green curv e. Notice that the band between optimal and the N ET I NF is relatively small. For example, at 2,000 edges in  X  G , N ET I NF finds the solu-tion that is least 97% of optimal for synthetic data. Moreove r, also notice a strong diminishing return effect, where the value o f the objective function flattens out after about 1,000 edges. Thi s means that, in practice, very sparse solutions (almost tree-like diffusion graphs) already achieve very high values of the objective fu nction close to the optimal.
 Accuracy of N ET I NF . We also evaluate our approach by studying how many edges inferred by N ET I NF are actually present in the true network G  X  . We measure the precision and recall of our method. For every value of k ( 1  X  k  X  n 2 ) we generate  X  G k on k edges by using N ET I NF or the baseline method. We then compute precision (what fraction of edges in  X  G k is also present G  X  ) and recall (what fraction of edges of G  X  appears in  X  G k ). For small k , we expect low recall and high precision as we select the few edges that we ar e the (c) Flat Kronecker (Exp) (g) Flat Kronecker (PL) most confident in. As k increases, precision will generally start to drop but the recall will monotonically increase.

Figure 5 shows the precision-recall curves of N ET I NF and the baseline method on three different Kronecker graphs (rando m, hi-erarchical community structure and core-periphery struct ure) with 1024 nodes and two cascade transmission models. The cascade s were generated with an exponential transmission model with  X  = 1 , a power law transmission model with  X  = 2 and a value of  X  low enough to avoid generating too large cascades (i.e.  X  = 0 : 5 for hierarchical,  X  = 0 : 4 for random and  X  = 0 : 1 for core-periphery). We generated between 2,000 and 4,000 cascades so that 99% of the edges participated in at least one cascade. We chose casc ade starting points uniformly at random.

First, we focus on Figures 5(a), 5(b) and 5(c) where we use the exponential transmission model. Notice that the baseline m ethod achieves the break-even point 1 in between 0.4 and 0.5 on all three networks. However, our method performs much better with the break-even point of 0.99 over all three datasets. This is a re mark-able result as we were especially careful not to generate too many cascades since more cascades mean more evidence that makes t he problem easier. Thus, using a very small number of cascades, where every edge of G  X  participates in only a few cascades, we can almost perfectly recover the underlying diffusion netw ork G
Similarly, Figures 5(e), 5(f) and 5(g) show the performance on the same three networks but using the power law transmission model. The performance of the baseline now dramatically drops. Thi s is due to the fact that the variance of power-law (and heavy tail ed dis-tributions in general) is much larger than the variance of an expo-nential distribution. Thus the diffusion network inferenc e problem is much harder in this case. As the baseline pays high price du e to the increase in variance with the break-even point dropping below 0.1 the performance of N ET I NF remains stable.

We also examine the results on the Forest Fire network (Figur es 5(d) and 5(h)). Again, the performance of the baseline is very low while N
ET I NF achieves the break-even point at around 0.90. The point at which recall is equal to precision.

Generally, the performance on the Forest Fire network is a bi t lower than on the Kronecker graphs. However, it is important to note that while these networks have very different global ne twork structure (from hierarchical, random, scale free to core pe riphery) the performance of N ET I NF is remarkably stable and does not seem to depend on the structure of the network we are trying to infe r or the particular type of cascade transmission model.
 Performance vs. cascade coverage. Intuitively, the larger the num-ber of cascades that spread over a particular edge the easier it is to identify it. In our experiments so far, we carefully gener ated a relatively small number of cascades. Next, we examine how th e performance of N ET I NF depends on the amount of available cas-cade data. Fig. 7(b) plots the performance of N ET I NF (break-even point) as a function of the available cascade data measured i n the number of transmissions over all cascades, i.e., x = 1 means that the total number of transmission events (sum of cascade size s) used for the experiment was equal to the number of edges in G  X  values of  X  produce larger cascades, increasing the difficulty of our problem. Note that N ET I NF requires a total number of transmis-sion events between 2 and 5 times the number of edges in G successfully recover most of the edges of G  X  .
 Stopping criterion. In practice one does not know how long to run the algorithm and how many edges to insert into the network Given the results from Figure 4, we found the following heuri stic to give good results. We run the N ET I NF algorithm for k steps where k is chosen such that the objective function is  X  X lose X  to the upper bound, i.e., F C (  X  G ) &gt; x OPT, where OPT is obtained using the online bound. In practice we use values of x in range 0.8 X 0.9. Scalability. Figure 7(a) shows the average computation time per edge added of our algorithm implemented with lazy evaluatio n and localized update. We use a hierarchical Kronecker network a nd an exponential transmission model with  X  = 1 and  X  = 0 : 5 . Localized update speeds up the algorithm for an order of magn i-tude (45  X  ) and lazy evaluation further gives a factor of 6 improve-ment. Thus, overall, we achieve two orders of magnitude spee d up (280  X  ), without any loss in solution quality. Dataset description. We use more than 172 million news arti-cles and blog posts from 1 million online sources over a period of one year from September 1 2008 till August 31 2009 2 . Based on this raw data, we use two different methodologies to trace in for-mation on the Web. First, we use hyperlinks between blog post s to trace the flow of information [23]. As the use of hyperlinks to refer to the source of information is relatively rare (espec ially in mainstream media), we also use the MemeTracker [18] methodo -logy to extract more than 343 million short textual phrases ( like,  X  X oe, the plumber X  or  X  X ipstick on a pig X ). Out of these, 8 mil lion distinct phrases appeared more than 10 times, with the cumul ative number of mentions of over 150 million. We cluster the phrase s to aggregate different textual variants of the same phrase [ 18]. We then consider each phrase cluster as a separate cascade c . Since all documents are time stamped, a cascade c is simply a set of time-stamps when websites first mentioned a phrase in the phrase cl uster c . So, we observe the times when sites mention a particular phr ase but not where they copied that phrase from. For the experimen ts here we use the top 1,000 media sites and blogs with the larges t number of documents. We then consider the largest 5,000 casc ades (phrase clusters) and for each website we record the time whe n they first mention a phrase in the particular phrase cluster. Note that cascades in general do not spread over all the sites, whi ch our methodology can successfully handle.
 Visualization of diffusion networks. First we examine the struc-ture of the inferred network. Figure 6(a) shows the largest c on-nected component of the diffusion network after 100 edges ha ve been chosen. The size of the nodes is proportional to the numb er of articles on the site and the width of the edge is proportion al to the probability of influence, i.e., stronger edges have high er width. Here we used the hyperlinks to trace the spread of informatio n.
Data available at http://memetracker.org and http:// snap.stanford.edu/netinf Since news media articles rarely use hyperlinks to refer to o ne an-other, the network is somewhat biased towards web blogs (blu e nodes). There are several interesting patterns. First, not ice how three main clusters emerge: on the left side of the network we can see blogs and news media sites related to politics, at the rig ht top, we have blogs devoted to gossip, celebrity news or entertain ment and on the right bottom, we can distinguish blogs and news med ia sites that deal with technological news. As Huffington Post a nd Political Carnival play the central role on the political si de of the network, mainstream media sites like Washington Post, Guar dian and professional blog Salon.com play the role of connectors be-tween the different parts of the network. The celebrity goss ip part of the network is dominated by the blog Gawker and technology news gather around blogs Gizmodo and Engadget, with CNet and TechChuck establishing the connection to the rest of the net work. For reasons of space, we refer the reader to the supporting we b-site [1] for additional graphs.
 Insights into the diffusion on the web. The inferred diffusion net-works also allow for analysis of the global structure of info rmation propagation on the Web. For this analysis, we use the MemeTra cker phrase clusters as cascades and analyze the structure of the inferred information diffusion network.

Figure 6(b) investigates the number of links in the inferred net-work that point between different types of sites. Here we spl it the sites into mainstream media and blogs. Notice that most of th e links point from news media to blogs, which says that most of t he time information propagates from the mainstream media to bl ogs. Then notice how at first many media-to-media links are chosen but in later iterations the increase of these links starts to slo w down. This means that media-to-media links tend to be the stronges t and N
ET I NF picks them early. The opposite seems to occur in case of blog-to-blog links where relatively few are chosen first but later the algorithm picks more of them. Lastly, links capturing the in fluence of blogs on mainstream media are the rarest and weakest. This suggests that most information travels from mass media to bl ogs.
In Figure 6(c), we investigate the median time difference be -tween mentions of different types of sites. For every edge of the inferred diffusion network, we compute the median time need ed for the information to spread from the source to the destination node. Again, we distinguish the mainstream media sites and blogs. No-tice that media sites are quick to infect one another or even t o get infected from blogs. However, blogs tend to be much slower in propagating information. It takes a relatively long time fo r them to get  X  X nfected X  with information regardless whether the inf ormation comes from the mainstream media or the blogosphere.
 Solution quality. Similarly as with synthetic data, in Figure 4(b) we also investigate the value of the objective function and c ompare it to the online bound. Notice that the bound is almost as tigh t as in the case of synthetic networks, finding the solution tha t is least 84% of optimal and both curves are similar in shape to th e synthetic case value. Again, as in the synthetic case, the va lue of the objective function quickly flattens out which means that one needs a relatively few number of edges to capture most of the inform ation flow on the Web.
 Accuracy on real data. As there is not objective ground truth net-work on real data, we perform the following experiment. We cr eate a network where there is an edge ( u; v ) if a webpage on a site u linked to a page on a site v . we take the top 500 media sites and blogs in terms of number of hyperlinks and the top 4,000 hyper link in terms of number of posts links. First, we consider this as t he ground truth network G  X  . We use the hyperlink cascades to infer the network  X  G and evaluate how many edges N ET I NF got right. Figure 8(a) shows the performance of N ET I NF and the baseline. Notice that the baseline method achieves the break-even poi nt of 0.34, while our method performs better with a break-even poi nt of 0.44. Second, we try a considerably harder problem, we use th e cascades based on the MemeTracker phrase clusters to infer G Figure 8(b) shows the performance of N ET I NF and the baseline. The baseline method has a break-even point of 0.17 and N ET achieves a break-even point of 0.28. To have a fair compariso n with the synthetic cases, notice that the exponential trans mission model is a simplistic assumption for our real dataset, and N can get additional mileage with respect to the baseline choo sing a more complex transmission model.
There are several lines of work we build upon. Although the information diffusion in on-line settings has received con siderable attention [2, 11, 16, 17, 23, 24, 25], only a few studies were a ble to study the actual shapes of cascades [23, 25]. The problem o f in-ferring links of diffusion was first studied by Adar and Adami c [2], who formulated it as a supervised classification problem and used Support Vector Machines combined with rich textual feature s to predict the occurrence of individual links. Although rich t extual features are used, links are predicted independently and th us their approach is similar to our baseline method in the sense that i t picks a threshold (i.e., hyperplane in case of SVMs) and predicts i ndivi-dually the most probable links.

Network structure learning has been considered for estimat ing the dependency structure of probabilistic graphical model s [9, 10] and for estimating epidemiological networks [29]. In both c ases, the problem is formulated in a probabilistic framework. How ever, since the problem is intractable, heuristic greedy hill-cl imbing or stochastic search that offer no performance guarantee were usually used in practice. In contrast, our work provides a novel form ulation and a tractable solution together with an approximation guarantee.
Last, although submodular maximization has been previously Figure 7: (a): Average time per edge added by our algorithm implemented with lazy evaluation (LE) and localized update (LU). (b): Performance of N ET I NF as a function of the amount of cascade data. On average N ET I NF requires about two prop-agation events per edge of the original network in order to re li-ably recover the true network structure. considered for sensor placement [21] and finding influencers in vi-ral marketing [13], to the best of our knowledge, the present work is the first that considers submodular function maximizatio n in the context of network structure learning.
We have investigated the problem of tracing paths of diffusi on and influence. We formalized the problem and developed a scal a-ble algorithm, N ET I NF , to infer networks of influence and diffu-sion. First, we defined a generative model of cascades and sho wed that choosing the best set of k edges maximizing the likelihood of the data is NP-hard. By exploiting the submodularity of our o b-jective function, we developed N ET I NF , an efficient algorithm for inferring a near-optimal set of k directed edges. By exploiting lo-calized updates and lazy evaluation, our algorithm is able t o scale to very large real data sets.

We evaluated our algorithm on synthetic cascades sampled fr om our generative model, and showed that N ET I NF is able to accurately recover the underlying network from a relatively small numb er of samples. In our experiments, N ET I NF drastically outperformed a naive maximum weight baseline heuristic.

Most importantly, our algorithm allows us to study properti es of real networks. We evaluated N ET I NF on a large real data set of memes propagating across news websites and blogs. We found t hat the inferred network exhibits a core-periphery structure w ith mass media influencing most of the blogosphere. Clusters of sites related to similar topics emerge (politics, gossip, technology, et c.), and a few sites with social capital interconnect these clusters a llowing a potential diffusion of information among sites in differen t clusters.
There are several interesting directions for future work. H ere we only used time difference to infer edges and thus it would be i n-teresting to utilize more informative features (e.g., text ual content of postings etc.) to more accurately estimate the influence p robabi-lities. Moreover, our work considers static propagation ne tworks, however real influence networks are dynamic and thus it would be interesting to relax this assumption. Last, there are many o ther domains where our methodology could be useful: inferring in ter-action networks in systems biology (protein-protein and ge ne in-teraction networks), neuroscience (inferring physical co nnections between neurons) and epidemiology.

We believe that our results provide a promising step towards un-derstanding complex processes on networks based on partial obser-vations. Figure 8: Precision and recall for a 500 node hyperlink netwo rk using (a) hyperlinks cascades and (b) MemeTracker cascades . We thank Spinn3r for resources that facilitated the researc h. Manuel Gomez Rodriguez has been supported in part by a Fundacion Caj a Madrid Graduate Fellowship. The research was supported in p art by generous gifts by Microsoft, Yahoo and IBM, and under the a us-pices of the DOE by LLNL under contract DE-AC52-07NA27344, ONR N000140911044 and NSF CNS0932392 and IIS0953413. [1] Supporting website. http://snap.stanford.edu/netin f. [2] E. Adar and L. A. Adamic. Tracking information epidemics [3] A.-L. Barab X si. The origin of bursts and heavy tails in hu man [4] A.-L. Barab X si and R. Albert. Emergence of scaling in [5] A. Clauset, C. Moore, and M. E. J. Newman. Hierarchical [6] R. Crane and D. Sornette. Robust dynamic classes reveale d [7] J. Edmonds. Optimum branchings. Journal of Resesearch of [8] P. Erd  X  os and A. R X nyi. On the evolution of random graphs. [9] N. Friedman and D. Koller. Being Bayesian about network [10] N. Friedman, I. Nachman, and D. Pe X  X r. Learning Bayesia n [11] D. Gruhl, R. Guha, D. Liben-Nowell, and A. Tomkins. [12] E. Katz and P. Lazarsfeld. Personal influence: The part [13] D. Kempe, J. M. Kleinberg, and E. Tardos. Maximizing the [14] S. Khuller, A. Moss, and J. Naor. The budgeted maximum [15] D. Knuth. The art of computer programming .
 [16] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins. Structu re [17] J. Leskovec, L. A. Adamic, and B. A. Huberman. The [18] J. Leskovec, L. Backstrom, and J. Kleinberg. Meme-trac king [19] J. Leskovec and C. Faloutsos. Scalable modeling of real [20] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graphs ove r [21] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [22] J. Leskovec, K. J. Lang, A. Dasgupta, and M. W. Mahoney. [23] J. Leskovec, M. McGlohon, C. Faloutsos, N. Glance, and [24] J. Leskovec, A. Singh, and J. M. Kleinberg. Patterns of [25] D. Liben-Nowell and J. Kleinberg. Tracing the flow of [26] R. D. Malmgren, D. B. Stouffer, A. E. Motter, and L. A. [27] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis of [28] E. M. Rogers. Diffusion of Innovations . Free Press, New [29] J. Wallinga and P. Teunis. Different epidemic curves fo r [30] D. J. Watts and P. S. Dodds. Influentials, networks, and
