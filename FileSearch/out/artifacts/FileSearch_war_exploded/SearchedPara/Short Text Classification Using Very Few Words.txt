 We propose a simple, scalable, and non-parametric approach for short text classification. Leveraging the well studied and scalable Information Retrieval (IR) framework, our approach mimics hu-man labeling process for a piece of short text. It first selects the most representative and topical-indicative words from a given short text as query words, and then searches for a small set of labeled short texts best matching the query words. The predicted cate-gory label is the majority vote of the search results. Evaluated on a collection of more than 12K Web snippets, the proposed ap-proach achieves comparable classification accuracy with the base-line Maximum Entropy classifier using as few as 3 query words and top-5 best matching search hits. Among the four query word selec-tion schemes proposed and evaluated in our experiments, term fre-quency together with clarity gives the best classification accuracy. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information filtering Short Text Classification, Search and Vote
We are now dealing with much more short texts. Examples are snippets in search results, tweets, status updates, comments, and reviews from various social platforms. Short texts are in general much shorter, nosier, and sparser, which calls for a revisit of many fundamental text mining techniques including text classfiication.
Short text classification is to assign a piece of short text one or more predefined categories. Most existing approaches try to enrich the representation of a short text using additional semantics. The semantics could be derived internally from the short text collec-tion [3], externally from a collection of much longer documents in a similar domain as the short texts [5], or from much larger external sources such as Wikipedia and WordNet [1,3,4]. In [1,4], the clas-sification accuracy is significantly improved by enriching short text feature vector with relevant hidden topics derived from Wikipedia pages using topic model.

In the opposite direction of enriching short text representation, we propose to trim a short text representation to get a few most representative words for topical classification. This approach is to mimic the human labeling process. Due to the length of short text ( e.g., a search result snippet is usually fewer than 20 words, a tweet has at most 140 characters), one finishes reading a piece of short text at a glance; the category label is assigned mainly based on the few keywords observed from the short text. More specifically, given a short text, we identify one or more words that best repre-sent the short text and formulate a weighted word query using each selected word and its associated weight. Illustrated in Figure 2, this query is submitted to a local search engine for the best matching la-beled examples. Analogous to the widely used k -nearest-neighbor (kNN) classifier, the predicted category is the one receiving highest votes from the search results ( i.e., labeled short texts).
Leveraging the well studied IR techniques, the proposed approach is extremely scalable. More importantly, the lazy and non-parametric approach well accommodates fast updating of labeled examples, changes to the classification scheme ( e.g., adding a new category), as well as giving specific attention to certain groups of labeled ex-amples by changing the scoring function in the search ( e.g., a search may favor more recently added labeled examples). Note that, dif-ferent from kNN classifiers, our approach requires no computation of the nearest neighbors in the labeled data. Instead, we search for the top-H best hits using few query words. Query Word Selection . The most critical step in the proposed ap-proach is the selection of representative words from a short text as query words. Ideally, the query words should be (i) well represent-ing the main content of the short text, and (ii) topically indicative. A word is topically indicative if it is about a specific topic. With bag-of-words representation, the most widely used TF or TF . IDF weighting scheme is su ffi cient for the first requirement. For the second requirement, we propose to use clarity to measure the topical-specificity of a word. Proposed for predicting query per-formance in [2], the clarity score of a query is the Kullback-Leibler (KL) divergence between the query language model ( i.e., unigram distribution of word occurrences) and collection language model. The former is inferred from a set of documents best matching a given query and the latter from the entire collection. Given a short text data collection D . Let word w be a candidate word for se-lection, we use w as a single-term query to retrieve its top-N most Table 1: Number of training / test snippets in the 8 categories. relevant documents ( N = 20 in our experiments 1 ), denoted by Q The clarity score of word w is computed using the equation below, where V denotes the vocabulary.
 Intuitively, if w is specific to a topic, then the documents matching w share a common topic indicated by a few words with very high probabilities of occurrences against their probabilities in the entire collection. On the other hand, if the documents matching w do not share a common topic, then this set of documents is analogous to a random sample from the document collection, with similar distri-butions of word occurrences.
 Scoring and Voting . In literature, many scoring functions for rele-vance ranking have been proposed for document search. To search for the most relevant labeled examples for a given query, we use Lucene allows query word boosting, i.e., to assign weight to each query word in a multi-term query. The score computed in query word selection step is used to weigh each selected query word. Af-ter query execution, each category label of the returned documents serves as an evidence that supports the likelihood of the querying document belonging to that category. Majority voting shows better results than its weighted counterpart in our experiments.
We conducted experiments on the Web snippet dataset that has been used in [1, 4]. The dataset consists of 10,060 train and 2,280 test snippets from 8 categories, shown in Table 1. On average, each snippet has 18.07 words after indexing by Lucene.
 We evaluate four schemes to select query words: TF , TF . TF . CLARITY , and TF . IDF . CLARITY . The latter two are the prod-uct of TF and TF . IDF respectively with clarity score. For each scheme, the top {1, 3, 5, 7, 9} words with highest scores are se-lected as query words. The category label of a test snippet is voted by the top-{5, 10, 15} hits respectively. The classification accura-cies are reported in Figures 1(a), 1(b), and 1(c). Note that, as each snippet has exactly one category label, the reported accuracy is the same as Micro-Precision / Recall / F 1 . For comparison, the horizon-tal line plotted in the three figures indicates the accuracy of 0.6575 achieved by Maximum Entropy (MaxEnt) classifier as baseline [4].
From the results, we make the following observations. First, more words (from 1 word to 5 words) in query generally lead to better classification accuracy. The improvement becomes very mi-nor when more than 5 words are used in query. Observe that using 3 words, the classification accuracy voted by top-5 hits matches MaxEnt, an advanced model that has shown good classification ac-curacies in many applications. Second, using 1 word in query, more hits lead to poorer results. When more than 3 words are selected in query, more hits yield slightly better accuracy. Third, among all word selection schemes, TF . CLARITY outperforms the others in most runs when 3 or more words are used in query. For one word query, TF . IDF . CLARITY is the best scheme.

We note that the best classification accuracy achieved is bet-ter than MaxEnt, but poorer than the results reported on the same dataset using enriched short text representation [1]. The enriched representation is a combination of word feature from the short text, and topic feature from a topic space derived from Wikipedia. We argue that our approach is directly applicable to any enriched rep-resentation because each enriched feature ( e.g., a topic feature) can be selected as a query word. That is, our approach complements the approach enriching text representation.
We propose a simple, scalable, and non-parametric approach for short text classification. Using the simple TF . CLARITY to select as few as 3 words, the default Lucene scoring function, and majority voting from 5 search hits, our approach achieves comparable clas-sification accuracy with MaxEnt classifier. We also note that our approach complements the research on enriching short text rep-resentation. Moreover, the non-parametric approach o ff ers much more flexibility in handling updates in labeled examples and clas-sification schemes.

The proposed approach has great potential to achieve much bet-ter results with more research on (i) query word or phrase selec-tion, (ii) relevance ranking techniques specifically for short texts, and (iii) short text representation enrichment.
