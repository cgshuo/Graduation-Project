 Hidden term relationships can be found within a document collec-tion using Latent semantic analysis (LSA) and can be used to assist in information retrieval. LSA uses the inner product as its similar-ity function, which unfortunately introduces bias due to document length and term rarity into the term relationships. In this article, we present the novel kernel based LSA method, which uses sep-arate document and query kernel functions to compute document and query similarities, rather than the inner product. We show that by providing an appropriate kernel function, we are able to pro-vide a better fit of our data and hence produce more effective term relationships.
 Categories and Subject Descriptors: H.3.3 [Information Search and Retrieval]: Retrieval models General Terms: Experimentation, Performance Keywords: Latent Semantic Analysis, Kernel functions
Term frequency methods of information retrieval use the occur-rence of query terms in a document as the basis of a document sim-ilarity score. These methods neglect the fact that there are relation-ships between terms that could alter the relevance of a document. Understanding a language is a matter of learning term associations, therefore, a method that examines documents for query terms alone is not making any attempt at learning term associations, and there-fore is ignoring any benefit that could be obtained by understanding the language.

Latent semantic analysis (LSA) is a linear method of attempt-ing to obtain these term relationships by discovering a small set of hidden basis terms that can be used to describe the document col-lection. A measure of the relationship between each term and basis term is computed, therefore term relationships can be obtained by comparing related basis terms.

LSA has the constraint that the inner product must be used to compute the similarity between documents, and documents and queries. Unfortunately, the inner product is not a desirable docu-ment or query similarity metric since it introduces bias from prop-erties such as document lengths and term rarity. The bias leads to longer documents being ranked higher than short documents and common terms having more impact than rare terms. Similarity met-rics for document retrieval such as BM25 have been devised in an attempt to remove this bias. Therefore, these metrics should be used for the computation of hidden basis terms.

In this article, we introduce kernel based latent semantic analysis (Kernel LSA). Using Kernel LSA, we are able to choose the func-tions to use for document-document similarity computations and query-document similarity computations. By choosing appropriate similarity functions, we will assist the Kernel LSA process in its discovery of the hidden basis terms.

Research into latent semantic analysis has been very active in recent years [Efron, 2005, Kontostathis and Pottenger, 2006, Ding, 2005, Farahat and Chen, 2006, Park and Ramamohanarao, 2004]. In each of the cited articles, the methods proposed are forced to weight their term frequency data to remove the bias introduced by LSA X  X  inner product.

Recent methods have used LSA dimension reduction as a kernel for support vector machine classification [Cristianini et al., 2002]. To our knowledge, this paper presents the first study of kernel meth-ods for unsupervised information retrieval. This paper contains the following important contributions: The article will proceed as follows: Section 2 reviews related work, Section 3 introduces our novel kernel based LSA method, and Sec-tion 4 compares Kernel LSA, LSA and BM25 in terms of retrieval precision.
To our knowledge, there is no previous work examining the ef-fectiveness of using kernel based LSA for unsupervised informa-tion retrieval.

LSA is a specific version of Principle component analysis for document vectors. The earliest known application of applying ker-nels to PCA was shown in the work done on kernel Principle Com-ponent Analysis (kernel PCA) [Sch X lkopf et al., 1998]. PCA has been effectively used in many fields as a method of data smooth-ing and dimension reduction. The first work on kernel space PCA [Sch X lkopf et al., 1998] generalised PCA, allowing us to use any kernel function to compute correlations.

The application of kernels to the field of Information Retrieval document classification was first performed by Christianini et al. [Cristianini et al., 2002]. This work on Latent Semantic Kernels describes the process of computing linear kernels for Support Vec-tor Machine (SVM) document classification. Rather than using the inner product as its kernel, the SVM was used with a PCA approx-imation of the inner product called a latent semantic kernel (LSK). Using this LSK, a smoothed document similarity score could be computed. SVMs were built using the LSK to train and classify documents. There was no analysis of other kernels or application of the SVM with LSK to ad hoc information retrieval.

Our focus is the generalisation of Latent Semantic Analysis to use a kernel function rather than simply the inner product. We ex-amine the choice and application of kernels for document retrieval and not document classification. Therefore, our work is entirely different to, and not an extension of, the work by Christianini et al. .
The SVD in LSA uses an intrinsic inner product to compute the correlation matrix C containing the similarity between document vectors: which is unsuitable for term frequency vectors. The inner product introduces bias into the similarity calculations such as higher scores to longer documents and common terms.

Rather than using the inner product to compute document and query similarity, we should be using the existing similarity metrics that avoid the mentioned bias. In this section, we will show how kernel functions can be applied to LSA such that we are able to define our own similarity functions. We will also show how current information retrieval similarity functions can be used as kernels.
Kernel principal component analysis (Kernel PCA) [Sch X lkopf et al., 1998] applies the kernel trick, used with support vector ma-chines, to principal component analysis. In this section we will show how we can apply the kernel trick to LSA to perform infor-mation retrieval and hence perform Kernel LSA.

Given a query, Kernel LSA document scores are computed us-ing: where  X  q is the query vector, F is the term frequency matrix, U is the set of eigenvectors of the gram matrix K , where document similarity functions (kernels) respectively. We will now proceed with the derivation of this equation.

If we have a function  X  d (  X  ) that is able to remove the bias from our document vectors, and an associated kernel function k such that k d (  X  d m ,  X  d n ) =  X  d (  X  d m )  X   X  d function to the document vector set and compute the SVD in order to obtain the set of unbiased basis terms. Therefore, we wish to compute: where K =  X  X  T and C =  X  T  X  are the gram matrix and corre-lation matrix respectively. The matrices U and  X  2 are the set of eigenvectors and eigenvalues of the Gram matrix K respectively. Using the decomposition in equation 2, we can obtain an equation for our set of basis terms V : Many basis terms with associated low singular values are consid-ered noise. Therefore, we wish to keep the basis terms with high associated singular values and remove the noisy basis terms with low associated singular values. To select wanted basis terms and remove the noisy basis terms, we will pre-multiply V with I identity matrix with zeros inserted on the diagonal to remove the associated unwanted basis terms:
We now have an equation for V that cannot be resolved due to the unknown  X  , however, we are able to project vectors into the basis term space. To represent a document vector  X  d in the form of the unbiased basis terms, we must map the vector into the  X  (  X  d  X  =  X  d (  X  d ) ) and then into the kernel LSA space ( V ): Where k d (  X  d,F ) is the inner product of the document vector and the document matrix in the document kernel space. If we choose to map the set of document vectors into the basis term space, we use: since KU T = U T  X  2 . To compute the document score, we must map the query into the kernel space and calculate the inner product of the query and documents. The mapped query vector is: where k q (  X  ,  X  ) is the chosen document-query kernel function. To compute the document scores for query  X  q , we use the unbiased document vectors represented using basis terms ( F  X   X  ), and the un-biased query vector represented using basis terms (  X  q  X  their inner product: giving us the KLSA document scoring function of equation 1.
This implies that if we calculate the eigen decomposition of ma-trix K = k d ( F,F ) to obtain U , we are able to easily compute the score of each document in the kernel feature space.
The Kernel LSA query-document score function in equation 1 requires us to choose a document-document similarity kernel ( k in order to calculate K and then U ), and a query-document simi-larity kernel ( k q (  X  ,  X  ) ).

A sparse kernel produces zero if the input vectors have no fea-tures in common. By choosing a sparse kernel for k have to scan through a portion of the document mapping U T to compute the final document scores, and hence obtain a faster query time. By choosing a sparse kernel for k d , the Gram matrix K will contain many zeros, and hence its eigenvalue decomposi-tion is faster to compute. Kernels such as a radial basis kernel and a polynomial kernel with non-zero offset are not sparse.
In this section, we will examine the BM25 document and query similarity functions, which can be used as sparse kernel functions.
The current state of the art in query-document similarity is BM25 [Jones et al., 2000]: where document-document similarity is calculated using: k d (  X  d m ,  X  d n ) = where k 1 is a constant (usually set to 2), K m and K to normalise the document length and are computed using K k  X  (1  X  b ) + b dl i the length of document i and dl avg is the average document length, w t = log the number of documents containing term t .
For each of these similarity calculation methods and for others that have not been mentioned here, we are able to state that there exists a document vector normalisation function  X  d (  X  ) and a query normalisation function  X  q (  X  ) that are unknown, but when used in an inner product with each other, produce the wanted document-document and query-document similarity functions. Therefore: k q (  X  q,  X  d ) =  X  q (  X  q )  X   X  d (  X  d ) , k d (  X  implying that the similarity functions can be used as kernels.
Due to the nature of kernel functions and their relationship to their associated mapping function, there is little restriction on the choice of our kernel. For example, we can choose some map-document-document similarity function and k q (  X  ,  X  ) is the BM25 query-document similarity function. Therefore, we do not have best similarity functions for each task. Other forms of document-document similarity functions can be found in [Lee et al., 2005, Lewis et al., 2006, Park and Ramaohanarao, 2008]. Note that the kernels suggested are significantly different to kernels used previ-ously in Kernel PCA.
Kernel LSA allows us to combine the documents and basis terms into a document expansion: where D = U T I  X  U is a document expansion. Given an arbi-trary query kernel k q , we are unable to perform any more computa-tion until a query is supplied. Therefore the query process consists of computing the query-document kernel value for each document ( k (  X  q,F ) ) and then applying these values to the document expan-sion D . This is clearly inefficient since we have to process every document and then perform the expansion on every document be-fore we can obtain a document score, making our query time de-pendent on the number of documents in the index.

To provide acceptable query times, we propose the use of a vec-tor thresholding function top z () which sets all but the greatest z vector elements to zero. When using this thresholding function, we can compute approximate kernel LSA document scores with: When using this function, we only need to compute the top z values from k q (  X  q,F ) and use z columns of D .

In Section 4, we will examine the effect of varying z . By us-ing an information retrieval based kernel, we are able to efficiently approximate the top document kernel scores and drastically reduce the processing time required during query time.
Analysis has shown that the effectiveness of LSA reduces as the size of the document collection grows [Park and Ramamohanarao, 2009a]. To avoid this problem, smoothing is applied to the model [Park and Ramamohanarao, 2009b, 2007].

To smooth the kernel LSA model, we mix the model scores with the scores computed using the query-document similarity function:  X k q (  X  q,F ) U T I  X  U + (1  X   X  ) k q (  X  q,F ) where  X   X  [0 , 1] is the mixing parameter. We can see that the smoothing is simply modifying the contribution of each of the com-puted eigenvectors, or basis terms. Using kernel LSA, we have se-lected x basis terms by applying I  X  , which sets all of the remaining basis terms to zero. After applying the smoothing, it is as though we have introduced the removed basis terms with the weight 1  X   X  . Also note that if  X  = 0 our scoring function is simply k q
In this section we will examine the effect of kernel LSA on re-trieval accuracy. Our variables are the choice of kernel, the smooth-ing parameter  X  (from Section 3.3), and the thresholding value z (from Section 3.2). We will compare our kernel LSA methods to latent semantic indexing (LSI) and the state of the art probabilistic measure BM25. Each of our experiments using kernel LSA and LSI use the eigenvectors associated to the greatest 300 eigenvalues, as suggested in [Deerwester et al., 1990].

Each or our retrieval results will be measured using mean aver-age precision. Mean average precision (MAP) is the mean of the set of AP scores from each query. MAP is an information retrieval evaluation metric that can also be thought of as the area under the precision-recall curve of a system. A MAP score of 1 implies that all of the relevant documents were ranked higher than the irrelevant documents across all queries.

Our experiments were performed on the SMART document col-lection, containing the document sets CRAN, CISI, CACM, and MED 1 . These document sets have been used extensively to show the performance of our baseline, LSI [Efron, 2005, Kontostathis and Pottenger, 2006, Ding, 2005, Farahat and Chen, 2006, Park and Ramamohanarao, 2004]. The number of documents in each document set is 1398, 1460, 3204 and 1033 respectively.
We will examine the effect on MAP when using our informa-tion retrieval kernels (BM25 document-document kernel and BM25
Available from ftp://ftp.cs.cornell.edu/pub/smart Figure 1: Mean average precision (MAP) using Kernel LSA with a BM25 document-document kernel. The baselines shown are BM25 (shown by the gray region) and LSI. Each set of points shows the MAP produced when thresholding to z doc-uments. query-document kernel shown in equations 4 and 3 respectively) as k and k q . We have provided a plot in Figure 1 of the mean aver-age precision obtained when varying the smoothing parameter  X  , for z = 1 , 5, 10, 20 and 50. The results shown are from the CRAN document set. The results from the CISI, CACM and MED docu-ment sets all exhibited similar trends.

From this plot, we can see that we achieve the greatest mean average precision when using z = 1 with a smoothing parameter of  X  = 0 . 9 . We can see that when the smoothing parameter is set to 0.9, the MAP increases as z decreases.

We also found that our more efficient information retrieval based kernels provides us with an increase in MAP over LSI and BM25 when using only an approximation of the top document scores. This implies that we are able to use this approximation to obtain fast query times, while still benefiting from the kernel LSA rela-tionships.
LSA uses the inner product as its similarity metric; this unfortu-nately introduces bias into the basis term computation due to poor normalisation of document lengths and rare terms.

In this article, we have formalised the kernel-based LSA method for computing basis terms to be used for unsupervised document retrieval. By using kernel LSA, we are able to choose appropri-ate document-document and query-document similarity functions to allow the kernel LSA process to discover more effective ba-sis terms. Unfortunately, kernel based LSA produces infeasible query times, therefore we also presented an approximation to ker-nel based LSA that provides acceptable query times.

We examined the retrieval performance of a BM25 kernel and found that the information retrieval based kernel, used with our approximate kernel based LSA, increased the retrieval precision. Using the BM25 kernel functions, we are able to compute a set of non-linear basis terms that provide a closer fit to the document set that is unachievable using the linear basis terms found with LSA.
