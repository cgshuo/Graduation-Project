 1. Introduction
Current research trends in Multiagent Systems (MAS) include models of trust ( Sierra and Debenham, 2006 ), reputation ( Sierra and Debenham, 2009 ; Pinyol and SabaterMir, 2009 ), and argumen-tation ( Amgoud and Prade, 2009 ; Alsinet et al., 2008 )toimprove negotiating strategies ( Faratin et al., 1998 ; Kraus, 1997 ; Hindriks et al., 2008 ). Research progress in the development of these theoretical models has made them very sophisticated (based on cognitive, information or game theoretical grounds) and has enabled software agents to interact with and help humans in a more efficient and believable way. Agents are being endowed with techniques to decide how and when to interact, argue and negotiate, as well as whom to trust and why. Unfortunately, the practical impact of the models has been lower than expected. This is partly due to the fact that researchers lack rich enough use cases to compare the models. The use cases described in the MAS literature tend to be rather artificial and usually biased to a particular negotiation model. Rich enough testbeds are urgently needed to simulate the latest sophisticated models without having to oversimplify them. In particular, software agents must be able to interact not just with other software agents but also with humans and in realistic scenarios. The testbed that we present in this paper,
DipGame, is rich enough to be useful in negotiation contexts with: (1) a huge space of solutions, such that purely strategic thinking is not feasible; (2) a partially observable environment, where agents cannot observe all actions made by other agents (e.g. offers); (3) the environment changes continuously due to the actions of other agents, agents decide moves autonomously that affect our future action repertoire; and (4) decision making in time-bounded.
These properties are common in realistic scenarios and are not particular to any negotiation model.
 how they reach agreements has been since long a fascinating area of inquiry. It has been studied from many different perspectives: game theory ( Raiffa, 2002 ; Kraus, 2001 ), psychology ( Adams, 1965 ; Sondak et al., 1995 ), business ( Bazerman et al., 1992 ), neuroeconomics ( Coricelli and Nagel, 2009 ), or psychopharmacology ( Eisenegger et al., 2010 ) just to mention a few. From an artificial intelligence perspective two main approach es have been followed. First, approaches based on game theor y, where agents are assumed to look for some sort of  X  X air X  allocation. In this approach models assume perfect rationality and complete information ( Osborne and
Rubinstein, 1990 ), so that if the optimal solution is known to the players then it is adopted. These a ssumptions are, unfortunately, not very common in practice. To overcome these difficulties, negotiation strategies have been, to a large extend, based on heuristics that try to use the available information about the problem and the opponents to approximate the  X  X deal X  game theoretical results ( Faratin et al., are close to the pareto-efficient frontier without revealing all preferences ( Faratin et al., 1998 ). The heuristics are applied in negotiation frameworks with simpl e protocols (e.g. the classical alternating protocol Osborne and Rubinstein, 1990 , or slightly more sophisticated ones as in Rosenschein and Zlotkin, 1998 )andover simple negotiation domains (e.g .the X  X  X MPOvsCitydomain X  X  X n Raiffa, 1982 ). A recent comparison of these heuristics can be found in Hindriks et al. (2008) .
 psychological and cultural aspects of negotiation has been observed in the field. For instance, agent negotiation architectures inspired in human relationship building ( Sierra and Debenham, 2007 ), or analysis of cultural influences in negotiation strategies ( Gal et al., 2010 ). The community of social simulation has also studied negotiation models in as much as they help in defining policies (e.g. Hales, 2002 in an environmental setting) or norms ( Conte and
Sichman, 1995 ). These human-oriented approaches follow an ecological model of rationality ( Smith, 2003 ) based on two basic notions: everything in the world is constantly changing and not all facts can be known by an agent. This view on rationality is in line with an evolutionary approach: knowledge evolves, individuals evolve and societies evolve. Ecological rationality, observed in humans and human societies, seems also the right one when we face the design of software agents . If knowledge is dynamic and evolves along time, this will certainly be also the case for beliefs or intentions of agents that will change constantly due to the inter-action with the environment (or with evolving societies of humans).
Actually, the very same structure of the environment where agents and services appear and disappear all the time, and where every active component of the environment is not necessarily persistent in its goals or intentions, makes the view of the world imperfect and necessarily evolving along time.

We do believe that after so many years of development of negotiation models whose validation has been made in very simple toy environments the community requires a more realistic scenario where negotiation models can be tested. The problem with artificial scenarios is that the behaviour of humans is not necessarily the same as in real life. It is not the same to decide on artificial money or on real money. That is why areas like auctions have moved into more realistic scenarios like the different TAC competitions, or why areas like neuroeconomics ( Sanfey et al., 2003 ) or experimental economics in general have moved into real scenarios. Current research in negotiation proposes models far more complex than those adapted to game theoretical settings ( Hindriks et al., 2008 ) and based on an ecological rationality.
Current testbeds ( Hindriks et al., 2009 ; Gal et al., 2005 ; Wellman and Wurman, 1999 ) are rather simple and we believe that the validation of negotiation models that aim at human X  X gent inter-actions ( Amgoud and Prade, 2009 ; Alsinet et al., 2008 ; Sierra and Debenham, 2007 ) require more sophisticated testbeds as the one introduced in this paper: DipGame is a testbed that uses Diplomacy as the negotiation environment.
 We start this paper briefly introducing the rules of The
Diplomacy Game and discussing why we think that this game is ideal for testing the research work on negotiation; Sections 2 and 3. Then we introduce the negotiation language and the infrastructure, Sections 4 and 5. Then, the methodology for building negotiation agents is presented together with an exam-ple of use of the testbed, Section 6. And in Section 7 we describe how do we involve humans in the experiments. We finally end the paper with a description of the related work, Section 8, and a discussion on the future work, Section 9. 2. Diplomacy in a nutshell In Diplomacy, players negotiate with the aim of conquering
Europe. The rules of the game are unambiguous and the available information about the game is rather rich as it is a quite old game being enjoyed by several generations of players: the game appeared in 1954. It is situated on Europe at the beginning of the 20th century, before World War I. Each player is in charge of the armed forces, organised in units , of a major European power and must decide, in each turn, which movements the various units should execute. There is a maximum of one unit per province. The game ends when someone has an army powerful enough to control half of the special European  X  X rovinces X  called supply centres. This is achieved by defeating other players X  units, conquering their provinces and controlling an increasing number of supply centres that allow a player to get more units.
One of the most interesting features of Diplomacy is the absence of random movements: there are no cards and no dices. Also, this is not a turn-taking game. That is, all players move their units simultaneously: there is no advantage in a player being the first or last to move. All units are equally strong and consequently, when a unit attacks another, the winner of the battle is decided by taking only into account the number of units helping the fighting units. This feature is what makes Diplomacy so compelling for our purposes: the most relevant skills for a player are the negotiating ability, the intuition (knowing whom to trust) and the persuasive power.
The game splits in several years with two movement turns per year. In every movement turn, the players decide what move-ments their units should perform. Possible movements are: to move, to hold or to help another unit supporting its hold or move. When every player has decided their movements, those are made public at the same time and the game state is updated following the rules of the game. 1 The rules describe how to resolve conflicts that may emerge because of the concurrent announcement of movements. At the end of the year if you have a unit over a supply centre province, the supply centre becomes yours. It will be yours until a unit of another power conquers it at the end of a subsequent year period. At the end of each year, the number of units of every player is made equal to the number of owned supply centres by either building new units (when the player increased the number of owned supply centres) or removing existing units (when the player decreased the number of owned supply centres). Remember that owning half of the supplier centres of the Continent allows you to win the game. Therefore, the goal of the players is to increase the number of owned supply centres every year quicker than other players do.

All units have always the same strength. When there is an attack, it is resolved taking into account the number of supports that the attacking and defending units got from other units. Players can support the movements of other players X  units. In fact, these are the basics of the game: the players must convince other players to be their allies and to help them. This is done by negotiations that take place in parallel among all the players. In those negotiations, players ask others for help and sign deals on future plans of action like attacking together a unit of a player that they agree is a common enemy. From a player X  X  point of view, the most important aspect of the game is the negotiation process: deciding allies, selecting whom to ask for help, arguing with other players to get information about their objectives or to find out what they know, building trust and reputation, deciding when to honour a deal, maintaining relationships, and so on. 3. Diplomacy for negotiation
Diplomacy is a strategically simple game for humans to play in comparison to other classic games like Chess or Go. This is because the true complexity of the game lies in the management of the relationships among players. Relationships are constantly changing and may appear at first sight difficult to analyse. However, humans negotiate constantly in their every day life, and they are used to do it. Diplomacy is thus not perceived by humans as a difficult game to play, but it is really difficult for a computer as it cannot take advantage from massive computa-tions. The search space is huge and the key for success relies on the information obtained from negotiation rounds and on the persuasive capability of the player.
Focusing just on the possible moves that the units can perform on the board, the combinations are very large. There is an average of 30 units on the board during a game. A movement has to be assigned to each one of these units per turn. The movements that a unit can perform depend on the number of direct neighbours and neighbour units. 2 Assuming an adjacency factor of 4 and a neighbourhood factor 3 of 2, we obtain that the number of possible movements per turn is 30 15. 4 Overall, a branching factor of 450.
The branching factor of the search is thus so high that even a no-press (without negotiation) game cannot be treated by standard search mechanisms. Neither can we reasonably use game theory to strategically solve the problem. Think that the branching factor for chess is around 35. Besides that, the execution of the move-ments in Diplomacy depend on the movements done by the other units. The moves that a player performs are not independent from the ones performed by other players. All players perform their moves at the same time, hence a player cannot be sure about the outcome of a move because there can be conflicts between different players X  movements. Therefore, it is very difficult to predict the outcome of a movement without information about the opponent X  X  intentions. In fact, the essence of Diplomacy relies on the diplomatic moves that were not taken into account when analysing the complexity above. Taking every single negotiation step into consideration, the number of possible moves is simply overwhelming ( Kraus et al., 1989 ).

From the point of view of AI research, Diplomacy is a MAS environment where competitive self interested agents need to cooperate to improve the outcome. This is done by the signature of agreements where agents involved commit to do a plan of action. Agreements in such environments are reached as the result of successful negotiation processes in which agents exchange proposals and information with the aim of convincing the other agent to accept a deal, sometimes using argumentation.
Because of the repetition of negotiation dialogues, negotiations get quicker since agents can learn the preferences of others from previous discussed agreements. The agents can guess which are the beliefs, desires and intentions of other agents just analysing the past dialogues and the state of the game. And as time goes by, agents can observe how their counterparts honour up the agree-ments they sign. This information can be used to build a model of the other agents X  behaviour. This model will help in future negotiations, even to decide which agent should we negotiate with. Concepts like trust, honour, sincerity, and others can summarise the perception that we have of an agent. The reputa-tion of an agent can also be taken into account because agents can also talk (gossip) about other agents performance, promises, intentions, etc. The problem is really rich.

In 1985, Daniel Lehmann decided to work on creating a software player (bot) of the game. This ended some years later with the Ph.D. of Sarit Kraus and two master thesis ( Kraus, 1995 ).
Since then, several other researchers have also tried to build bots but without much negotiation capabilities ( Shaheed, 2004 ).
Despite this little success, we think that now is the moment to continue this work. Computer and network technologies have evolved so much in the interim that many people now accept entertainment online from their homes as a matter of course. Thus, it is now much easier to find people interested in playing
Diplomacy online against our agents. 4. Negotiation language correlated to the complexity of the language that the agent must be able to understand. The higher the language complexity the higher the richness of the models underpinning agent architec-tures. In this section we structure the expressions of increasing levels of complexity via a modular, flexible and reusable language hierarchy L . We propose it as a standard for the dialectical communication between the agents that use the testbed and provide infrastructure to support the language parsing. None-theless, other languages could be used as the testbed is quite modular and the language tools (i.e. parsers) are separated from the game engine.
 defined as an eight level hierarchy; starting from L 1 and increas-ing the expressiveness as the language level increases. Check the definition of L in Fig. 1 . The higher the language level that we use, the more complex the actions and the predicates, and thus the expressivity. If it is desired, some of the levels could be skipped, such us for instance Level 5 of sharing feelings. By this way, you can reach level 8 corresponding to argumentation without expressing any feelings. We kept a linear approach for two reasons. One for simplicity, as it gives you a clear roadmap to building ever more complex negotiation agents. Second, to follow the familiar level ordering in the languages proposed by the DAIDE community. 5 Researchers set their experiments on DipGame selecting the language level to use.
 applications. It defines the illocutions that the agents can use to communicate and the basic concepts like Agree , Desire , Feel , etc.
The language is parametric on the vocabulary for a specific application domain, described as an ontology. The undefined non-terminal symbols that appear in L should be specifically defined for each application domain. These symbols are: time , agent , action and predicate . Fig. 3 represents the ontology for the
Diplomacy Game and Fig. 4 contains the connection between the ontology and L . In this way, we allow researchers to reuse as much code as possible when applying their work to real world applications after testing it with DipGame.
 expressivity of each language level in Diplomacy. For instance,
Unit ( rus , Region ( stp , scs )) is a term meaning that  X  X here is a unit from Russia in the south coast of Saint Petersburg X , rus ]) is a predicate meaning  X  X eace between Italy and Russia X , and sup ( Unit ( rus , Region ( spa , ecs )), mto ( Unit ( ita amy )), Region ( par , amy ))) is an example of action where  X  X he unit of Russia in the east coast of Spain supports the movement of the Italian army in Marseilles to Paris X .
 agents to negotiate deals following the protocol illustrated in
Fig. 5 . The deals can be either a sequence of commitments, one for every agent involved in the deal, or a global agreement in which a set of agents agree on something, usually the truth of a predicate. Here you have two examples of sentences in L 1 : do a movement from its army in Marseilles to Paris and Russia commits to support the Marseilles italian army X  X  movement with the unit in the east coast of Spain X  6 : propose( ita , rus , Do( mto ( Unit ( ita , Region ( mar , amy )),
Do( sup ( Unit ( rus , Region ( spa , ecs )), Region ( par , amy )))))])
E.g.  X  X taly accepts to Agree with Russia that they are allied against England X : accept( ita , rus , Agree([ ita rus ], aly ([ ita rus ], eng
L 2 : Sharing information . This language level adds the ability of sharing information with other agents. It can be information about previous commitments, observed actions, beliefs, desires or deals:
E.g.  X  X taly informs England that Italy keeps a peace agreement with Russia X : inform( ita , eng , Agree([ ita rus ], pce ([ ita rus ])))
L 3 : Asking for direct information . At level three, agents can request other agents for information. Answers to queries are similar to informs:
E.g.  X  X ngland asks Italy whether Italy and Russia have a peace agreement X : query( eng , ita , Agree([ ita rus ], pce ([ ita rus ])))
E.g.  X  X taly answers England that Italy and Russia do have a peace agreement X : answer( ita , eng , Agree([ ita rus ], pce ([ ita rus ])))
L 4 : Asking for indirect information . Level four allows to inform about dialogical moves between agents: E.g.  X  X ussia asks Italy whether Italy answered to England that
Italy and Russia had a peace agreement X : query( rus , ita , Agree([ ita rus ], pce ([ ita rus ]))))
L 5 : Sharing feelings . This level is the emotional one. Feelings can be exchanged between agents.
 E.g.  X  X taly asks Russia whether Italy X  X  answer to England that
Italy and Russia had a peace agreement made Russia feel sad X : query( ita , rus , Agree([ ita rus ], pce ([ ita rus ]))) -
L 6 : Taking into account the passage of time . L 6 adds time to L .

Within L 6 we can speak about the past and make promises about the future. Time is added as an extra argument to predicates and illocutions. Time variables are considered universally quantified. In subsequent levels, L 7 and L 8 , we omit time to simplify notation. any power that Italy and Russia have a peace agreement, then
Russia will feel Angry X : nation requests. This level adds that possibility to allow agents to explain why things are like they are.

Turkey believes that there is a peace agreement between Russia and Italy makes Russia feel Angry X : rebuttals and supports between arguments.

England and Italy X  X  desire to conquer Paris together support the imminent Italian attack from Marseilles to Paris X : 5. Infrastructure a potential developer on what kind of support/help the platform offers. Readers aiming at a general understanding of the testbed can skip this section. The infrastructure is modular and freely available at http://www.dipgame.org . It is composed of: the game engine, a framework for agent development and negotiation tools.
In this section we describe them giving special attention to the negotiation tools.
 following the guidelines of DAIDE. The server is the game manager. It receives the movement decisions of the players, updates the game state and broadcasts it. Nowadays, there are two software alternatives for the server: parlance 7 and AiServer .
There are two types of clients: observers and players. Both receive the information about the state of the game but only players can send movements. Players can be autonomous (bots) or humans.
There are several bots available online but they focus on the strategy and tactics of the game rather than on the dialectic moves, that is, they do not focus on negotiation.
 provide dip , a java framework that copes with the communication with the game manager and the representation of the game state and the movements (referred in the game as orders to send to the units). dip is very easy to use, for instance, creating a player means just to implement a new class extending the abstract class Player (see Fig. 6 ) and adding the extra functionality to decide what movements to do next, as explained in Fig. 7 . The rest of the work is done by the framework itself. To illustrate how to use dip we provide ConsoleObserver and ConsolePlayer that are console appli-cations that allow a user to observe a game and play respectively.
Deciding what movement to do next usually requires to search the space of possible actions to perform. For those researchers that want to test their work and are not interested in the search process, we provide an extension of dip , called bot , that calculates the potential actions that the bot may choose based on an action evaluation function that the researcher defines. This simplifies even more the implementation of a player because it then consists basically on defining an evaluation function. This func-tion can be defined as a combination of the implementation of three class interfaces: RegionEvaluator , OrderEvaluator and Option
Evaluator . Each class interface is in fact an evaluation function itself over a different dimension (region, order and option). The combination of them is thus not optimal (as it considers them in isolation) but is a good trade-off between memory usage and solution quality. The trade-off level is fixed by the programer: the more memory the higher the solution quality. An example of bot implemented using bot is RandomBot whose evaluation function always returns 0. Figs. 6 and 7 summarise the content and use of the infrastructure.
 We also provide support for the negotiation between players.
We take the language L as a standard for this testbed and provide a parsing utility called dipNego that checks the syntax of messages and represents them in a structure of objects. In Fig. 9 we illustrate a class diagram with the most relevant classes of dipNego that are necessary to represent the messages in L is a parser available for all L language levels and the Diplomacy ontology. Nonetheless, as L is domain independent, dipNego can be used for other application domains.

The negotiation dialogues between players are handled inde-pendently from the game engine. Messages do not use DAIDE X  X  protocol, instead, players negotiate using negoServer , an instant messaging program specially created for this testbed, and nego-Client , a library that implements the functionality required to connect a client with the negotiation server. RandomNegoBot , available online, is an extension of RandomBot able to randomly negotiate with other players. We exemplify the usage of the testbed with RandomNegoBot in Section 6.
 In Section 7 we discuss the use of this testbed by humans. In that section we describe dialogueAssistant , a restricted natural language interpreter that translates the messages written by humans into L . 6. Using DipGame
Building agents capable to negotiate playing Diplomacy is quite easy with the framework and the tools introduced in the previous section. In this section we suggest a methodology for testing agents with DipGame and exemplify it describing how can we create and test a very simple agent: a random negotiator, that is, a player that performs random moves and negotiates also randomly. It is based on RandomBot  X  X  code. 9
The simple methodology consists of six steps that end with the analysis of the results and the optional improvement of the agent: 1. Download all resources from http://www.dipgame.org . The required resources will depend on the type of client that you want to create and the implementation options that you decide to use, see Fig. 7 . For our example we need the game manager called Parlance , negoServer , RandomBot  X  X  code and the libraries that it requires, that are dip and bot. 10 2. Create a client extending the corr esponding classes. Remember that to be able to negotiate you should use negoClient and dipNego in addition to the libraries specified in Fig. 7 .
We extend RandomBot  X  X  functionality adding the capability to negotiate randomly thus we also need the language parsing utility, dipNego , and the library that provides the connection with negoServer that is negoClient .From negoClient we must imple-ment the handleMessage methodindicatingwhattodowhena message is received. Our random negotiator agent would throw a coin to decide whether to accept or reject the received proposal.
And if the message is already an accept or a reject, it would do nothing. negoClient also allows us to send messages. Our random negotiator agent would throw a coin at every new state to decide 3. Complete your client adding the negotiation model function-4. Set the experiments choosing the language level, the duration of 5. Run the experiments. This means launching first the game 6. Analyse the results and extract your conclusions. At the end of 7. Optionally make the adjustments necessary in your code to from http://www.dipgame.org/downloads/RandomNegoBot.java .
It is just a simple example where the negotiation is driven taking random decisions. More sophisticated agents will take advantage of the messages exchanged, the actions performed and the state of the world observed in order to perform smart negotiations.
Those agents can compete against other agents but also against humans. 7. DipGame website enough to test negotiation models that are going to be deployed into the real world. Most of the real world applications of MAS negotiations involve people. Therefore, it should be possible to have humans taking part of our experiments. In this section we describe the problem of having people taking part in research experiments and how do we handle their recruitment.

It is very hard to organise an experiment with humans because this requires a lot of money, time and effort in coordinating everybody. To be able to perform experiments like these but with a low cost we created a web application to allow people to take part in the experiments from anywhere in the world reducing the logistic problems of gathering people. Although the game is quite popular, it is never mind difficult for a player to physically summon another six people to play a game. Playing online makes this easier and moreover allows to secretly meet with other players to negotiate and keep conspiracies under cover. By means of this web application, we join together research and entertain-ment as it was successfully done previously in other projects.
The web application interface is composed of an interactive map representing the state of the game and where players can indicate their movements clicking on the units. It is quite intuitive how to use it and there are some help facilities for newcomers to easy step into the game. In Fig. 10 we include a screenshot of an ongoing game where Italy is about to win. At the right part of the screen there is a summary of the state of the game and the turn movements. Under this summary panel there is an instant messaging tool embedded in the web page that allows the player to negotiate with the rest of players using restricted natural language. To that end, we provide a parser for restricted natural language. It is called dialogueAssistant and translates written sentences into an equivalent sentence in L . Fig. 8 illustrates the transformation. dialogueAssistant is currently only available for messages at level L 1 but is going to be upgraded in order to interpret higher language levels. For the top levels it seems that a click-based approach to build sentences would be more useful.
This approach would be something similar to the translator sheets that the face-to-face players use in international tourna-ments. 12 Also, an argumentative agent might use argument building tools, like those in http://debategraph.org/ , to structure argumentative dialogues and support decision making. 8. Related work
In this section we summarise existing work on testbeds for negotiation.
 MAGNET is the abbreviation for Multi AGent NEgotiation
Testbed. It is rather a generalised market architecture for multia-gent contract negotiation using auctions ( Collins et al., 1998 ). The required negotiation skills in MAGNET are far simpler than in DipGame.

The Trading Agent Competition (TAC) ( Wellman and Wurman, 1999 ) is a testbed where, in its classical version, agents are travel assistants that try to assemble the best travel package for their clients. To evaluate the assembling of packages they use the summation of the utilities of the clients that are in turn based on their preferences. It is a multi-issue negotiation process organised as a multi-lateral negotiation by means of auctions on every single issue. Bids take the form of pairs where a price per item and a number of items is proposed. There are also other versions of TAC problems that are similar to this: TAC/AA, CAT and TAC/SCM. Competitions are organised annually where several instances of the game are played. Although this is a consolidated testbed, the problems that it aims at are quite different to the ones we worry about. The negotiation language and protocol is highly con-strained, humans do not take part of experiments and preferences are assumed to be known and fixed.

The Coloured Trails Game (CT) ( Gal et al., 2005 ) is a research testbed for decision making in groups comprising people and agents. In every game, two or more players may negotiate to exchange chips that allow them to move from their source position to a target position over a coloured squared board. To move through the board, players must provide chips of the same colour of the squares that they want to pass over. The game is quite abstract and was defined for research purposes so humans taking part in the experiments must be instructed and are not equally motivated. The amount and type of chips and the source location of the players is different so that the initialisation of the game can benefit a player in front of others. Also the richness of the negotiation language is more limited than in the case of DipGame.

GENIUS, the Generic Environment for Negotiation with Intel-ligent multi-purpose Usage Simulation ( Hindriks et al., 2009 )isa research tool that facilitates research in the area of bilateral multi-issue negotiation. It allows the evaluation of agents playing in various negotiation scenarios where issues and preferences of each party on them must be known from the beginning and are fixed. It can be used in experiments with humans using a constrained communication protocol, but assuming that the preferences are fixed and known is something strange and difficult to find in the real world. Thanks to this, the toolbox for analysis calculates the optimal solutions and represent the evolution of the negotiation using it as a reference. Contrarily to DipGame, GENIUS is limited to bilateral negotiations, there is no relationship building among players, and there is no post-nego-tiation action verification.

The Agent Reputation and Trust (ART) testbed ( Fullam et al., 2005 ) was created with the aim of establishing a testbed for agent trust-and reputation-related technologies. Several competitions were organised where appraiser agents competed to get the higher reputation appraising paintings. It is currently still very popular although the project is no longer maintained. The expertise on completing appraisals was split between the agents and they should decide whether to request help from other appraisals, paying an amount for the info, or dealing with it by themselves. ART testbed is a good testbed for trust and reputation but it is very focused on a utilitarian view and too limited to test negotiation or argumentation models.

These testbeds provide more or less infrastructure and some have a long tradition background being now a reference to many researchers. However, they are too connected to a utilitarian approach and we wanted a scenario in which other approaches could also be tested. In particular, we think that DipGame is richer to model information exchange (due to the possibility of obser-ving public  X  the moves  X  and private  X  the offers  X  behaviour of agents) and to model trust (due to the longer time that a game lasts). No one of the related testbeds is rich enough to allow for the testing of those complex negotiation models that can be tested in DipGame. The simplest setting of DipGame is already richer and more realistic than any of the existing testbeds.
This is so because we wanted to encourage the research on negotiating agents to be capable to interoperate with people, and the other testbeds goal mostly, follows a constructivist approach as mentioned in the introduction. Among all the testbeds described above, the CT is the most compelling to work with humans. 9. Discussion and future work
Diplomacy is an ideal game for testing negotiation models because it allows for complex dialogues among agents while keeping the computational overhead to a minimum as the number of involved agents is small. Moreover, it allows testing of rich negotiation models as the game has a huge space of solutions, actions are only partially observable (e.g. some dialo-gical actions of other agents are not made public) the state changes over time and there are thousands of humans ready to play. In this paper we introduced the DipGame testbed that allows researchers to run experiments using such negotiation models over Diplomacy. We provide a platform with a complete infrastructure composed of a framework for building agents, tools for communication, interpreters for restricted natural language, and a website to summon people for the experiments.

The DipGame website is in production as beta version at http://www.dipgame.org giving access to humans to play Diplo-macy online against some of our simplest bots. Although we did not make any advertisement to the Diplomacy players commu-nity, the website gets requests from many users to play. We have a total of 185 registered users in April 2011 and there are several groups of researchers developing bots over the platform. Also, the testbed is being used for academic purposes in some master degrees (e.g. http://www.cse.unr.edu/robotics/bekris/cs483_s10/ handouts ) and by several masters and PhD students in their theses.

We will continue maintaining the website and the resources and adding functionality. Our next work will be mainly focussed on developing sophisticated negotiating agents capable of playing against humans at the different language levels of L . In fact, this testbed was needed as a step before being able to test our own work on negotiation ( Fabregues and Sierra, 2010 ). Obtaining experimental results of our negotiation model over the testbed is part of our future work.
 Acknowledgements project under contra ct CSD2007-0022 and INGENIO 2010, by the
Agreement Technologies COST Action, IC0801, and by the Generalitat de Catalunya under the Grant 2009-SGR-1434.
 References
