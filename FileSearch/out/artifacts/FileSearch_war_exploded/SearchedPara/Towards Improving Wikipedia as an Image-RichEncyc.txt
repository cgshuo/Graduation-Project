 Wikipedia is a popular web-based encyclopaedia used for searching knowledge about objects. Wikipedia presents knowledge about objects of many categories such as people, science, geography, politic, and history. In Wikipedia, knowledge related to an object is gathered into a single article that is mainly composed of text and images. Wikipedia arti-cles are edited cooperatively and constantly by volunteers. Therefore, Wikipedia always includes the most up-to-date information. Nevertheless, the quality of some Wikipedia articles is inferior [12]; some Wikipedia articles even include incorrect information [3]. Several works have been proposed for exami ning the quality or credibility of Wikipedia articles [1, 4]. However, previously presented works do not devote attention to images in Wikipedia articles despite the fact that images are interesting and helpful for un-derstanding knowledge. To improve Wikipedia as an encyclopaedia that contains an abundance of appropriate images, we aim to analyze the appropriateness of images for Wikipedia articles.

In Wikipedia, every image has a caption describing it in a few words. The caption probably includes links to other Wikipedia articles. For example, Fig. 1 depicts an im-age appearing in Wikipedia article  X  X unich iro Koizumi, X  who was the Prime Minister of Japan. Two links to articles  X  X ea Island, Georgia X  and  X 2004 G8 summit X  appear in the caption of the image. The caption indi cates to us that Koizumi met children in Sea Island, Georgia, shortly before he attended the 2004 G8 summit. The image shows a scene in which Koizumi meets chidlren. The image with its caption indicates the relation between  X  X unichiro Koizumi X  and  X  X  ea Island, Georgia, X  and that between  X  X u-nichiro Koizumi X  and the  X 2004 G8 summit. X  Similarly, for an image in article s whose caption includes links to articles t 0 ,t 1 , ..., t m , we assume the image indicates the rela-tion between s and each t j , 0  X  j  X  m . In this paper, based on the assumption, we propose an RCT model to examine the appropriateness of images for Wikipedia arti-cles by the following three aspects through analyzing relations indicated by the image: relatedness, consistency and typicality.
 Relatedness. For an image i existing in article s , we measure the relation indicated by i . If the relation is strong, then image i represents information that is strongly related to s ;otherwise, i has low relatedness with s . Assuming that only a limited number of images can be added to an article, we then should add images that are strongly related to the article rather than images having low relatedness with the article. For instance, Fig.2 depicts an image of two tattooed Japanes e people photographed in 1970. The image ap-pears in the Japanese Wikipedia article  X  X unichiro Koizumi, X  whose text describes that Koizumi X  X  grandfather was famous for sporting a full-body tattoo. The relation between Koizumi and 2004 G8 summit is expected to be stronger than that between Koizumi and Tattoo. That is, the 2004 G8 summit has higher relatedness with Koizumi than Tattoo has. Therefore, the image depicted in Fig.1 is expected to be more appropriate for the article  X  X unichiro Koizumi X  than that depicted in Fig.2.
 Consistency. If the text of an article includes no explanation or description about the relation between s and t j , then we say that image i is inconsistent with the text. Im-ages are usually difficult to interpret without description. Therefore, images that are inconsistent with the text of an article might be inappropriate for the article. For exam-ple, no description about the image depicted in Fig. 1 is included in the text of article  X  X unichiro Koizumi. X  It is difficult to understand why  X  X oizumi X  met children in  X  X ea Island X , or even why  X  X oizumi X  attended the  X 2004 G8 summit, X  by reading the article. Users might be confused about why the image appears in the article. In Section 5.2, we propose a method to examine the consistency between an image i and text by investi-gating how many descriptions about the relations indicated by i appear in the text. Typicality. As discussed above, for an image appearing in article s we assume that the image indicates the relation between s and an article t linked from the caption. Therefore, we also examine w hether an image is visually typical for representing a re-lation. For instance, the image depicted in Fi g. 1 indicates a relation between  X  X unichiro Koizumi X  and the  X 2004 G8 summit. X  Fig. 3 depicts four visually similar images show-ing the relation between  X  X unichiro Koizumi X  and the  X 2004 G8 summit X  in which Koizumi attends the 2004 G8 summit with leaders of other countries. On the web, im-ages similar to these images outnumber images similar to the image depicted in Fig. 1. Therefore, the image depicted in Fig. 1 is not typical for representing the relation be-tween  X  X unichiro Koizumi X  and the  X 2004 G8 summit. X  Zhang et al. [14] proposed a evidence-based method for searching image s representing a relation on the Web. For an image i indicating relation r , we first search a set I of images representing r on the Web using the evidence-based method. We then investigate the similarity between i and images in I to examine the visual typicality of i .

As another contribution of this paper, we propose a system for analyzing the appro-priateness of images in Wikipedia 1 .Given an image existing in a Wikipedia article, the system computes relatedness, consistency, typicality, and appropriateness for the image using the RCT model. The system also offers images retrieved from the Web that con-tain knowledge about the same relation as that indicated by the input image. Images retrieved from the Web could serve as references for users to add appropriate images or text to edit high-quality and image-rich Wikipedia articles. We discuss the system in detail in Section 2.

The rest of this paper is organized as fo llows. Section 3 introduces the method pro-posed by Zhang et al. [13, 15, 14] for analyzing, mining and searching knowledge about relations. Section 4 presents the RCT model for examining relatedness, consistency and typicality of images for Wik ipedia articles through analyzing relations based on the methods introduced in Section 3. Section 5 reports experiments used for evaluating the RCT model described in Section 4. Section 6 re views related work. Section 7 concludes this paper. We now propose the system for analyzing the appropriateness of images for Wikipedia articles. The system also offers information retrieved from the Web, which could be helpful for users to edit high-quality Wikipedia articles. Fig. 4 portrays the system in-terface, in which we examine an image in the Ja panese Wikipedia article  X  X hinzo Abe. X  The interface comprises two parts, denoted respectively as  X  X  X  and  X  X . X 
The left side of part  X  X  X  displays the input image for analysis. The right side of part  X  X  X  presents the four values of relatedness, c onsistency, typicality, and appropriateness for the input image, with respect to each re lation indicated by the input image. The four values are computed using the RCT model presented in Section 4. For example, the interface portrayed in Fig. 4 displays the four values indicated with bars for the input image, with respect to each of the three relations indicated by the image. The bars representing the four values for each re lation are depicted inside a block.
By clicking the block drawing the bars for a relation in part  X  X  X , part  X  X  X  displays images that include knowledge about the relation. These images are retrieved from the Web using the method [14] proposed by Zhang et al. The system presents captions for the images, which are extracted to help users understand the images. Users can click on an image to link to the Web page that includes the image. The system also computes relatedness, consistency, typicality and appropriateness for each image. The images are classified into different clusters according t o their visual similarity computed using the method proposed by Wang et al. [10, 7]. The system use the method proposed by Chen et al. [2] to cluster images.

The system would be useful in the following scenarios.  X  Images having extremely low relatedness are meaningless for addition to Wikipedia.  X  If the consistency of an image i in article p with respect to relation r is low, then the  X  Assuming that there is no copyright probl em, if the typicality of the input image is We propose methods for examining image appropriateness for Wikipedia articles through analyzing relations indicated by images, but first we introduce methods for an-alyzing, mining and searching knowledge about relations proposed by Zhang et al. [13, 15, 14]. 3.1 Generalized Max-Flow Model for Measuring Relations A Wikipedia information network is a directed graph whose vertices are articles of Wikipedia and whose edges are links between articles. Zhang et al. [13] model a re-lation between two objects in a Wikipedia information network using a generalized max-flow. The generalized max-flow problem [11] is identical to the classical max-flow problem except that every edge e has a gain  X  ( e ) &gt; 0 ; the value of a flow sent along edge e is multiplied by  X  ( e ) .Let f ( e )  X  0 be the amount of flow f on edge e ,and  X  ( e )  X  0 be the capacity of edge e . The capacity constraint f ( e )  X   X  ( e ) must hold for every edge e . The goal of the problem is to send a flow emanating from the source into the destination to the greatest extent po ssible, subject to the capacity constraints. Let generalized network G =( V, E, s, t,  X ,  X  ) be information network ( V, E ) with the source s  X  V , the destination t  X  V , the capacity function  X  , and the gain function  X  . Fig. 5 depicts an example of a generalized max-flow. It shows that 0 . 4 units and 0 . 2 units of the flow respectively arrive at  X  X SA X  along path (A) and path (B).
To measure the strength of a relation from object s to object t , Zhang et al. [13] use the value of a generalized maximum flow emanating from s as the source into t as the destination; a larger value signifies a stronger relation. We omit details of the model here because of space limitations. Zhang et al. [13] ascertained that the model can measure the strength of relations more correctly than previous methods [8, 6] can. 3.2 Generalized Flow Based Method for Mining Elucidatory Objects Based on the generalized max-flow model, Zhang et al. proposed a method to mine disjoint paths that are important for a relation from object s to object t in Wikipedia [15]. Zhang et al. first compute a generalized max flow f emanating from s into t on the Wikipedia information network. Flow f is then decomposed into flows on a set of paths. For example, the flow on the network depicted in Fig. 5 is decomposed into flows on two paths (A) and (B). The value of the decomposed flow on path (A) is 0.4; that on path (B) is 0.2. Finally, Zhang et al. output the top-k paths in decreasing order of the values of flows on paths to explain the relation between s and t . Zhang et al. define elucidatory objects of a relation as objects in the top-k paths, except the source and destination. Elucidatory objects of a relation r are objects constituting r ; the elucidatory objects are able to explain r . Every elucidatory object o in a path p is assigned a weight 0 &lt;w ( o ) &lt; 1 , which equals the value of the decomposed flow on path p . A high weight signifies that the elucidatory object plays an important role in the relation. 3.3 Searching Images Explaining Relations on the Web Zhang et al. [14] proposed an evidence-based method for searching sets of  X  X mage with surrounding text X  (hereafter abbreviated as IwST ) including knowledge about a rela-tion between two objects s and t on the Web. Zhang et al. first searches images related to s and t using a keyword image search engine with query  X  st . X  However, some IwST s include no knowledge about the relation between s and t . Zhang et al. [14] then infer that an IwST includes knowledge about a relation, if the surrounding text of the IwST includes many elucidatory objects of the relation. That is, elucidatory objects are evi-dence that is useful for judging whether a text includes knowledge about a relation. We present the evidence-based method below.

Input: objects s and t , integer parameters m ,and n . (1) Obtain a set O of elucidatory objects for the relation between s and t using the method discussed in Section 3.2. (2) Search the top-m images, say m = 300 , using a keyword image search engine with query  X  st . X  (3) Extract the surrounding text of each image. Let I be the set of the top-mIwST s. (4) Remove IwST s whose surrounding text includes no s or t from I .(5) O  X  O is the set of elucidatory objects appearing in the surrounding text of i ,and f ( o ) is the appearance frequency of o in i . The weight w ( s ) and w ( t ) is set to the maximum weight of all objects in O .(6) Output : the top-nIwST sin I having high scores.
Zhang et al. [14] confirmed that the m ethod is effective for searching IwST s includ-ing knowledge about relations. As discussed in Section 1, for an image in article s whose caption includes links to articles t 0 ,t 1 , ..., t m , we assume that the image indicates the relation between s and each t , 0  X  j  X  m . In this section, we present the RCT model for computing relatedness, consistency, typicality and appropriateness of an image for an article. 4.1 Relatedness Relatedness represents the strength of the relation indicated by an image. We compute the strength g ( r ) of relation r using the generalized max-flow model [13] introduced in Section 3.1. The strength of relations between two objects in Wikipedia ranges from 0 to max ( d ) ,where max ( d ) is the maximum of the number of links linking from or to an article in Wikipedia. Given an image i indicating a relation r , we normalize s ( r ) to avalue 0  X  R ( i, r )  X  1 as the relatedness of image i with respect to relation r ,using the following equation.
 To normalize R ( i, r ) to a value 0  X  R ( i, r )  X  1 ,weset  X  according to max ( d ) of the Wikipedia dataset. For the dataset used in experiments discussed in Section 5, we set  X  =5 . 8 . 4.2 Consistency Consistency represents how many descriptions about the relation indicated by an image exist in the text of a Wikipedia article. We measure the consistency of the image with the text based on the method introduced in Section 3.3 by counting how many elucidatory objects of the relation appear in the text.
 We present a method for examining consistency below.
 Input: Image i indicating relation r in Wikipedia article p . (1) Obtain a set O of elu-cidatory objects for relation r . (2) Compute a score s ( i ) using the following equation. where O  X  O signifies the set of elucidatory objects appearing in the text of article p ,and d ( o ) denotes the distance from o to image i in article p .(3) Output: Normalize s ( i ) to a value 0  X  C ( i, r )  X  1 as the consistency of image i with respect to relation r using the following equation.
 Elucidatory objects appearing in text closer to image i in article p tend to relate to i more strongly. Therefore, we assign high scores to elucidatory objects closing to i in Equation 2. The distance in Equation 2 can be defined as the path length between the nodes including o and i , respectively, in the DOM tree of article p , or number of words or sentences between o and i in the text of article p . We set the distance as the be number of words between o and i in p , in the experiments discussed in Section 5.

To normalize C ( i, r ) to a value 0  X  C ( i, r )  X  1 ,weset  X  according to the Wikipedia dataset. For the dataset used in Section 5, we set  X  =17 . 6 after several experiments. 4.3 Typicality An Image ti appearing in many web pages that contains description about a relation is typical for indicating the relation. Images which are visually similar to the image ti are also typical. Inversely, images appearing i n few web pages that contains description about a relation are untypical for indicating the relation. We observed that untypical images are inappropriate for indicating a relation or even unrelated to a relation. Given an image i and a set I of images which appears in web pages containing knowledge about a relaion, we measure the similarity among i and images in I to examine the typicality of i .

The RCT model used VisualRank [5] proposed by Jing et al. which computes the typlicality of images. VisualRank employs PageRank on a network whose vertices representing images; every edge ( u, v ) is assigned a weight which is the visual sim-ilarity [10, 7] between images u and v . Then, a score vr is obtained for every image representing its typicality. A high score vr represents that the image is similar to many other images on the network. The intuition of VisualRank is that an image is typical if images similar to the image are also typical.
 We present the method for examining typicality below.
 Input: Image i indicating relation r . (1) Obtain a set I of images representing relation r using the evidence-based method introduced in Section 3.3. (2) Construct a network including image i and images in I , and compute score vr ( i ) for i on the network. (3) Output: Normalize vr ( i ) to a value 0  X  T ( i, r )  X  1 as the typicality of image i with respect to relation r using the following equation.
 4.4 Appropriateness If any one of the three values of relatedness, consistency and typicality of an image for an article is low, then the image is probably inappropriate for addition to the article. The RCT model computes appropriateness A ( i, r ) for image i with respect to relation r , which are computed using the following equation.
 we conduct experiments to evaluate the RCT model on computing consistency and ap-propriateness by human subject. We do not evaluate the RCT model on computing relatedness because Zhang et al. [13] have confirmed that the generalized max-flow model used for computing relatedness can measure relations appropriately. Similarly, we do not evaluate the RCT model in terms of typicality because the effectiveness of VisualRank adopted for computing typicality has been ascertained by Jing et al. in [5]. 5.1 Dataset We first select 10 articles in different categories from a Japanese Wikipedia dataset (20090513 snapshot). Th e titles of the 10 articles are presented in Fig. 7. For each article, we select 10 images appearing in the article for evaluation. If fewer than 10 images exist in an article, then we compensate the shortage with manually selected images, and create appropriate captions for t he images. For example, Fig. 8 depicts 10 images selected for the article  X  X SA. X 
In the RCT model, we assume that an image of article p shows relations between p and a link in the caption of the image. The s ystem discussed in Section 2 analyzes an image with respect to all the possible relations between p and every link in the caption. For the experiments, we decided that humab subjects determine which relation is in-dicated by the image. For every image, we asked 10 participants to select one relation the image mainly indicates. Each participant independently selected one link from the links appearing in the caption of an image for article p . We then assume that the image indicates the relation between p and the link selected by most participants. For example, the captions of the images depicted in Fig. 8 are written in the column  X  X aption (Re-lation). X  The links appearing in the captions are denoted by underlined letters, among which those denoted as large bold letters are links selected by the participants. 5.2 Evaluation of Consistency We first evaluated whether the RCT model can compute the consistency of an image with an article appropriately. For each of the 10 selected articles, we asked 10 partici-pants to judge whether the text of an article includes a description about each of the 10 relations indicated by images se lected for the article. Every participant gives an integer score from 0 X 4 to each relation. A higher score represents that the text includes a better description of the relation. We then compute the average of the scores given by the 10 participants as the value of consistency obtained by human subjects.

For each of the 10 articles, we compute the P earson X  X  correlation coefficient between consistency obtained by human subjects and the RCT model. Fig. 6 depicts the coeffi-cient for all 10 articles. Except for the coeffi cient for the article  X  X etroleum X  which is inferior, the coefficients for 7 of the 10 articles are higher than 0 . 5 . Especially, the coef-ficient for article  X  X apanese cuisine X  is 0 . 92 . The average of the coefficients for the 10 articles is 0 . 53 . Therefore, we conclude that the RCT model can examine consistency of images for an article appropriately to a satisfactory degree.
 5.3 Evaluation of Appropriateness The RCT model computes the appropriatene ss of an image according to relatedness, consistency and typicality of the image, as discussed in Section 5.3. In this section, we evaluate the accuracy of the appropriateness computed using the RCT model.

We first tell participants the following question to force them to consider the ap-propriateness seriously:  X  X f only 5 of the 10 images could remain in the article, which images do you select? X  We then ask them to give an integer score 0 X 10 to 10 images according to the appropriateness for each of the 10 selected articles, where a higher score represents higher appropriateness. We then compute the ranking of the images using the average of the scores given by the 10 participants.

In Fig.7, we compare the appropriateness obtained by human subjects with those computed by the RCT model. Every cell dep icted in Fig.7 represents an image. A row including 10 cells represents 10 images for an article. Numbers on the horizontal axis indicate the ranki ngs of the images according to the a ppropriateness obtained using the RCT model for each article. A white cell signifies an image that is ranked among the top-5 according to the appropriateness obtaine d by human subjects; inversely, a black cell shows an image ranked lower than 5 th. For example, a cell denoted by alphabet  X  X  X  represents the top-1 image for the article  X  X apan, X  as ranked by the RCT model. The cell is white, therefore, the image is ranked among top-5 by human subjects. The cells in the first left-hand column are all white, except t hat of the article  X  X etroleum X . That is, the top-1 image for 9 of the 10 articles ranked by the RCT model are also ranked among the top-5 by human subjects. Most cells in the second and third left-hand columns are also white. However, 7 of the 10 cells in the first right-hand column are black. That is, images ranked lowest by the RCT model for 7 of the 10 articles are also ranked as low by human subjects. From the discussion presented above, we conclude that the RCT model can examine the appropriateness of images for an article to a satisfactory degree. Furthermore, we survey the appropriateness computed using the RCT model through a case study presented in the next section. 5.4 Case Study: Images for Article  X  X SA X  We observe the 10 images for the article  X  X SA, X  depicted in Fig. 8. The column  X  X u-man X  presents the consistency and appropriateness obtained by human subjects. The column  X  X CT Model X  presents the relatedness, consistency, typicality, and appropri-ateness computed using the RCT model. Participants assign a score of 0 as the consis-tency to the three images appearing in the 6th, 8th, and 10th rows because they could not find a description about the relations indicated by the three images in the article  X  X SA. X  However, by considering the relatedness for the image appearing in the 6th row is strong, i.e., the strength of the relation between the  X  X SA X  and  X  X he battle of Get-tysburg X  is strong, they assign score 6 . 80 as the appropriateness to the image. In the column  X  X anking, X  the figures out of parentheses and the figures in parentheses respec-tively represent the rankings of the images according to the appropriateness assigned by human subjects and the ranking obtained using the RCT model. The top-3 images and the 10 th image obtained by human subject and the RCT model are identical.
The four images ranked as 7 th, 8 th, and 10 th by the RCT model have much lower typicality than other images have. Therefore, the four images are ranked lowest by the RCT model, although the relatedness and their consistency are not the lowest. For example, the 10 th image as ranked by the RCT model i ndicates the relation between the Mayflower and the USA. We retrieved images associated with the relation on the Web using the method introduced in Section 3.3, four of which are depicted in Fig. 9. By reading the descriptions of the images, we know that the images strongly relate to the relation between the Mayflower and the USA. The 10 th image is dissimilar from most of the images retrieved from the Web, including the four depicted in Fig. 9. Therefore, the 10 th image receives low typicality. As introdu ced in Section 2, the system for analyzing the appropriateness of images displays these images retrieved from the Web. The system could be useful to find typical images indicating a relation.
 To the best of our knowledge, no method has been proposed in the literature for partic-ularly analyzing the appropriateness of images in Wikipedia. However, many methods examine the quality or credibility of Wikipedia articles. Thomas Chesney examined the credibility of Wikipedia by asking participants to read an article and to assess its credibility [3]. Chesney reports that the accuracy of Wikipedia is high; however, 13 percent of the Wikipedia articles include mistakes. Wilkinson et al. [12] observe that high-quality Wikipedia articles are disti nguished by a high number of edits, number of editors, and the intensity of cooperative behavior. Several other works measure the quality of Wikipedia articles by examining the reputations of Wikipedia editors [1, 4]. These works assume that editors gain a reputation when the editing that they perform on Wikipedia articles are preserved by subseque nt editors. They lose that reputation when their edits are modified or removed in short order. Articles edited by editors having a high reputation are then regarded as high-quality articles.

Consideration of consistency between an image and its surrounding text has not been reported before. Regarding the typicality of images, several reported works search for typical images based on a query. An image I is a typical image for query Q if Q is an appropriate label for I . Tezuka et al. [9] search typical images for a query by analyz-ing visual features of images such as color features. In contrast to those methods, we consider the visual typicality of images representing a relation. We proposed a RCT model for analyzing the appropriateness of images for Wikipedia articles. For an image in article s whose caption includes links to articles t 0 ,t 1 , ..., t m , we assume the image indicates the relation between s and each t i , 0  X  i  X  m .We then examine the appropriateness of the image in the three aspects, relatedness, con-sistency and typicality, through analyzing rel ations indicated by th e image. Our exper-iments revealed that the RCT model can examine consistency of images for an article appropriately, and the model can compute appropriateness for images to a satisfactory degree.

As another contribution, we propose a system for analyzing Wikipedia image ap-propriateness using the RCT model. Given an image appearing in a Wikipedia article, the system computes appropriateness for the image. The system also search images on the Web that contain knowledge about the same relation as that indicated by the input image. Our system could be helpful for users to judge Image appropriateness and to add appropriate images or text to edit high-quality and image-rich Wikipedia articles.
 This work was supported in part by the National Institute of Information and Commu-nications Technology, Japan.

