 Mining data streams of changing class distributions is im-portant for real-time business decision support. The stream classifier must evolve to reflect the current class distribution. This poses a serious challenge. On the one hand, relying on historical data may increase the chances of learning obsolete models. On the other hand, learning only from the latest data may lead to biased classifiers, as the latest data is often an unrepresentative sample of the current class distribution. The problem is particularly acute in classifying rare events, when, for example, instances of the rare class do not even show up in the most recent training data. In this paper, we use a stochastic model to describe the concept shifting pat-terns and formulate this problem as an optimization one: from the historical and the current training data that we have observed, find the most-likely current distribution, and learn a classifier based on the most-likely distribution. We derive an analytic solution and approximate this solution with an efficient algorithm, which calibrates the influence of historical data carefully to create an accurate classifier. We evaluate our algorithm with both synthetic and real-world datasets. Our results show that our algorithm produces ac-curate and efficient classification.
 H.2.8 [ Database Management ]: Database Applications X  data mining ; I.2.6 [ Artificial Intelligence ]: Learning X  concept learning ; I.5.2 [ Pattern Recognition ]: Design Method-ology X  classifier design and evaluation Algorithms classifier, classifier ensemble, data streams, concept drift Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00.
Mining data streams for actionable insights in real time has become an important and challenging task for a wide range of applications [7, 14, 16, 3, 12]. Compared to tra-ditional data mining, mining data streams poses new chal-lenges as data are streaming through instead of being stat-ically available [3, 7, 14, 17]. As the underlying data gen-erating mechanism is evolving over time, so are the data patterns that data mining systems intend to capture. This is known as concept drifting in the stream mining litera-ture. To cope with concept drifts, stream mining systems must update their models continuously to track the changes. Moreover, in order to make time-critical decisions for stream ing data of huge volume and high speed, the stream mining systems must be efficient enough in updating the models.
There are some na  X   X ve approaches for handling streams with concept drifts. One is to incrementally maintain a classifier that tracks patterns in the recent training data, which is usually the data in the most recent sliding window. The other is to use the most recent data to evaluate classi-fiers learned from historical data and create an ensemble of  X  X ood X  classifiers. As we will reveal in detail in this paper, both of the two approaches are subject to the same problem, namely, model overfitting, which has been known to affect the accuracy of a classifier.

Overfitting refers to the problem that models are too spe-cific, or too sensitive to the particulars of the training dataset used to build the model. We argue that the following known issues that can lead to model overfitting have become more prevalent in the data streaming environment.
In mining static datasets, the problem of overfitting usu-ally can be addressed by two approaches. First, we can enlarge the training dataset to reduce the risk of overfitting caused by insufficient training data. Second, we can use an evaluation data set to detect overfitting caused by bi-ased training data  X  if a classifier X  X  prediction accuracy relies on particular characteristics in the training data (e.g. the source IP address of the incoming packets), then the classi-fier X  X  performance will be poor on an evaluation dataset as long as the evaluation dataset does not share these idiosyn-crasies. Unfortunately, in the streaming environment, these methods are not applicable. When there are concept drifts, the enlarged part of the training dataset or the evaluation dataset may come from a different class distribution, which undermines our purpose of reducing overfitting.

In this paper, we propose a general framework that ex-ploits concept drifting patterns to solve the model overfitting problem. It is generally impossible to capture concept drifts using a deterministic model because they happen unexpect-edly. Using a stochastic model, we relate the current class distribution p with observations of the recent training data D n ,D n  X  1 ,  X  X  X  . Our problem of finding the most-likely cur-rent class distribution p is essientially the problem of finding the class distribution p that maximizes the probability of ob-serving D n ,D n  X  1 ,  X  X  X  . Using standard optimization theory, we derive a solution for the most likely current class distribu-tion. We then approximate this solution with an algorithm that combines the results of a set of classifiers trained over windows of historical training data. Our algorithm is very efficient  X  as concepts evolve over time, we only need to ad-just the weights assigned to each of the historical classifiers.
Given an ensemble of historical classifiers, we need to de-cide the weights of the classifiers in a meaningful way so that the ensemble can model the current class distribution. For simplicity, in our analysis, we assume that there are only two classes, positive and negative. Note that it is straight-forward to generalize our analysis to multi-class cases.
Historical data should be leveraged to improve the esti-mation of the current class distribution. However, giving historical data the same weight as the current data hurts classification accuracy when there is a concept drift between the time the historical data is delivered and the current time. The task of this section is to derive a model that balances the influences of historical data so that we can derive a model that reflects the most likely current class distribution.
The timestamp of a historical dataset is an important piece of information to determine its influence to the cur-rent class distribution. The possibility of class distribution change increases monotonically as the length of time be-tween the current time and the time when historical data is collected increases. However, it is generally impossible to model concept drift in a deterministic manner as con-cept drifts can happen at any point of the time between the current time and the time of the historical data. We use stochastic models to account for the uncertainty of the oc-currences of concept drifts. Hidden Markov models (HMMs) are particularly promising because I) HMMs have been used in many fields to model uncertainty [15] and have demon-strated success in practice; II) HMMs allow us to decouple the observed outcome of training samples from the posterior class distribution. In a hidden Markov model, the states rep-resent the posterior class distribution rather than observed training sample distributions. Training sample distributions follow the class distribution of the hidden state; III) HMMs allow us to make minimum assumptions as the stochastic process is embedded in the structure of the hidden Markov chain.

Another important piece of information is the density of historical data in different regions of the feature space. A classifier is less likely to be overfitted in regions where there are a large number of training records. It means predictions for samples in regions of high training data density should have a high weight. It follows that we should divide the fea-ture space into regions and model each region with a Markov chain. In other words, a classifier will be weighted by both the time of its training data, and by their regions in the feature space.

Given the two pieces of information, our task is to find the most-likely current class distribution. It is tantamount to finding the current class distribution that maximizes the probability that we observe the data in the history. In this paper, we focus on the first issue, that is, what is the optimal way of weighting classifiers by time, and assume the feature space has already been partitioned. We leave the discussion on optimal feature space partition to a future paper.
The notations we use are summarized by Table 1. First, we partition a stream into a sequence of windows, W 1 ,W 2 ,  X  X  X  ,W n ,offixedtimeinterval t ,with W n being the most recent window. Note that previous approaches partitioned the stream into windows of fixed number of in-stances [17]. We argue that the occurrence of concept drifts is more likely to be a function of time instead of the number of arriving instances. A bursty arrival of a large number of instances does not mean the underlying class distribution is changing at a fast rate. Thus, time windows are more natural in modeling concept drifts.

Second, we assume the feature space V has been parti-tioned into a set of non-overlapping regions, S 1 ,S 2 ,  X  X  X  The regions are aligned across all time windows. The trust-worthiness of a classifier learned from data in a particular window may be different in different regions of the feature space. In the stream environment, a training dataset may have certain idiosyncrasies. For example, a burst of pack-ets that arrive within a short time interval may all have the same source IP. The classifier learned from such a training data may have low authority in classifying records in other regions of the feature space. By giving different weights to classifiers in different regions, we can avoid overfitting caused by biased sampling.

In practice, there are many different ways to partition the feature space into multiple regions. We leave the discus-sion of optimal feature space partitioning to a future paper. To simplify our analysis, the partition method ensures that for records of the same region, a classifier always make the same prediction. For instance, in a decision tree, each leaf node in fact represents a region in the feature space. The class prediction for a test case that falls into a leaf node is negative cases that belong to this leaf node in the training (of a given region) (of a given region) data. This means all cases that fall into the same leaf node will share the same prediction. We also align regions across all time windows. This is done by subdividing a region until itiscontainedinacertainleafnodeofallclassifiers.

For two-class data, the class distribution in any region can be sufficiently captured by a value in [0 , 1], which represents the probability that a test case in that region is positive. We use f i to denote the positive class distribution in a region according to the classifier learned from data in W i .Inother words, f i is the prediction given by the classifier to test cases that fall in the region. Given that there are N i training cases in a region, we know there are N i f i positive samples and N i  X  N i f i negative samples in the region.
We leverage concept drift patterns to make a better use of historical data. To capture the non-deterministic nature of concept drifts in a region, we model the concept drift process as a continuous time Markov chain. Each state in the Markov chain represents a posterior class distribution at a particular point of time. The instances we observe at the time is a sample from the distribution. Concept drifts are modeled by change of states. A state can have mul-tiple ingress edges. Assume for a given state there are m such edges representing transitions of rates  X  1 ,  X  X  X  , X  spectively. We use  X  to denote the aggregated ingress tran-sition rate,  X  = m i =1  X  i . An example is shown in Figure 1, where state A has three ingress edges with aggregated rate  X  =  X  1 +  X  2 +  X  3 .
In the data stream environment, learning the structure of the Hidden Markov Model is tantamount to decoding the underlying data generation mechanism. This is itself a time-consuming task (to say the least), which makes it unrealistic for high volume, fast speed data streams. In our analysis, we assume the aggregate ingress rate of each state is the same. This actually means that the possibility of having concept drifts is distributed uniformly across the time axis. In other words, we assume that concept drifts are identically and independently distributed across the continuous time. Standard probability theory tells us that the only distribu-tion satisfying this property is a Poisson process. Figure 2: Concept drifts within a region across time windows
Figure 2 shows a region that is undergoing concept drifts across time. We model the most recent concept drift that has occurred. Let n be the timestamp of the current window. Let C i represent the event that the most recent concept drift occurs between time i and time i + 1. Given the aggregated rate of transition into the current state in the Markov model is  X  , the probability that no concept drift occurs during an x time window internal is 1  X  e  X   X xt .Thus,themost recent state transition occurs between time window i and time window i +1 is
Furthermore, if the posterior class distribution in the re-gion at time i is x , the probability that we observe N i positive instances out of the N i total instances in the region is:
Let q i be the event that a random instance drawn from the region at time i is positive. Then, P ( q i ), the probabil-ity that a random instance is positive, is the positive class distribution at time i .If C i is true, that is, no concept drift occurs after time i +1, we have P ( q i +1 | C i )= P ( q  X  X  X  = P ( q n | C i ). Finally, given C i , the probability that we observe the training samples across all the windows from W
We assume that the states before the transition C i are independent of the current state. This obviates the need for considering the structure of the whole Markov chain and allows us to focus our analysis on the current state instead. With this simplification, the first term i j =  X  X  X  Y j ( P ( q in Eq 3 is a constant with respect to P ( q n | C i ).
Based on the standard optimization theory, L i is maxi-that is, when P ( q n | C i ) equals 0 or 1. It is obvious that L i =0when P ( q n | C i ) equals 0 or 1 unless the training sam-ples are either all positive or all negative. For all other cases, L Solve the equation for P ( q n | C i ), we conclude that when L i in Eq 3 is maximized. In other words, given the observa-tions in each window W i and the assumption that the most recent concept drift occurs between time i and i +1, the most likely current class distribution is computed by Eq 4. Since P ( i C i )=1and C i C i =  X  when i = i ,wehave Substituting P ( C i )withEq1,weget
P ( q n )=
This shows that for any region, historical classifiers should be combined in the following manner. For class c , a classifier is weighted by the number of cases of class c in that region. In addition, its weight has an exponential time decay of parameter  X  .
Our algorithm keeps k classifiers C n ,  X  X  X  , C n  X  k +1 trained from data in recent time windows. The user also provides parameter  X  , the exponential decay rate. A larger  X  dis-counts historical data more heavily and is used for streams of frequently changing class distributions.

We assume that the feature space has been partitioned into a set of non-overlapping regions. We leave the discus-sion of the optimal way of feature space partitioning to a fu-ture paper. Given a test case x ,weconsultthe k classifiers.
Input : x : a test case
Output : p : a probabilistic prediction of x for each classifier C i  X  X  C n , C n  X  1 ,  X  X  X  , C n  X  k +1 for each region S i do p = w i p i / w i ; return p ; Algorithm 1: A region-based ensemble stream classifier In addition to a probabilistic prediction for x , each classi-fier C i returns the number of negative and positive training cases in the region where x falls into. Finally, we derive the probabilistic prediction and the weight based on the num-bers.
 Note that it is not necessary to consult every classifier. An improvement is to stop consulting classifiers back in the history once we are sure that they are unlikely to change final prediction (positive or negative). Since historical classifiers are heavily discounted, it can improve runtime performance. We omit detailed discussion here for lack of space.
We compare the performance of our approach, including time efficiency and classification accuracy, with previous ap-proaches. The tests are conducted on a Linux machine with a 1.7 GHz CPU and 1 Gb main memory. We create synthetic data whose concept drifting follows Poisson distribution. The class distribution is modeled by a hyperplane, which is denoted by the following equation in d -dimensional space. We label examples satisfying d i =1 a i x i  X  a 0 as positive, and examples satisfying d i =1 a i x i &lt;a 0 as negative. Hy-perplanes have been used to simulate time-changing con-cepts [14, 17]. However, previous approaches assume that the underlying concepts evolve in a smooth manner, while our testbeds simulate real life environment where abrupt changes can occur at any moment.

We generate random examples uniformly distributed in multi-dimensional space [0 , 1] d .Weights a i (1  X  i  X  d ) in Eq (6) are initialized randomly in the range of [0 , 1]. We choose the value of a 0 so that the hyperplane cuts the multi-dimensional space in two parts of the same volume, that is, a = 1 2 d i =1 a i . Thus, roughly half of the space is positive, and the other half negative. Noise is introduced by ran-domly switching the labels of p % of the examples. In our experiments, the noise level p %issetto5%.

Number of records generated within a time unit follows a normal distribution with user provided mean and variance. We study situations where data in each time unit may rep-resent biased samples from the same class distribution T . However, it is not easy to quantify such a bias. In this study, we create biased class distributions in neighboring data units as a simulation. We generate a dataset wherein s % records are sampled from the positive class in T ,and 1  X  s % are sampled from the negative class in T . The next dataset will have 1  X  s % positive records from T ,and s % negative records from T . We denote such a stream as having a sampling bias s %.

The rate of occurrence of concept drifting in the synthetic data is  X  . To create such a change, we set certain weights a in Eq. 6 to random values within [0 , 1], which is tantamount to randomly moving the hyperplane to a new position. Fur-thermore, the users can also give a parameter k to specify the total number of dimensions whose weights are changing.
We study the time complexity of our stream classifica-tion algorithm and compare it with the incrementally up-dated classifier approach [14], and the weight-by-accuray ap-proach [17]. We generate synthetic data streams where each data unit is of different average sizes. Note that both our approach and the weight-by-accuray approach train classi-fiers from each data unit. However, our approach does not apply historical classifiers on new training records in order to get weights for the classifiers. Figure 3: Training time and average partition size Fig. 3 shows the time complexity of the three approaches. The tests are performed on a stream of 32 data units, and the X axis shows the average size of each partition. The incrementally updated classifier is trained from the entire 32 data units, and it is the most costly approach with re-gard to training time, as training a classifier (e.g., a C4.5 decisoin tree) is of superlinear complexity. Fig. 3 does not take into consideration the cost of model updating, which means in reality, the incrementally updated classifier is even more time consuming. The weight-by-accuray approach im-proves the single classifier by using the divide-and-conquer approach, however, it is still quite costly in comparison with our approach, which does not weight classifiers by their per-formance on the most recent training data.

From Fig. 3, it is clear that when the average partition size is small, all of the three approaches use less training time. Unfortunately, for ensemble-based approaches, using smaller partitions often results in lower classification quality. Fig. 4 shows this phenomena.
In Fig. 4, we see that the rate of classification error in-creases when partitions become larger. This is so because in a concept drifting environment, large partitions may contain conflicting concepts, and classifiers trained on a partition ba-sis will have reduced quality. When a partition is small, the weight-by-accuray approach suffers because data in a small partition is often a biased sample from the true underly-ing class distribution. The experiment shown in Fig. 4 is conducted on synthetic data with a concept drifting rate of (  X  = 5). We also introduce a 20% sampling bias in each unit data, which contains an average of 500 records.

Next, we study the change of data arrival rate on the accuracy of ensemble-based classifiers. Since a classifier is trained on data addrived during the same time unit, the variance in training data size may lead to some siginificant classification error. Furthermor e, for the weight-by-accuray approach, the scarcity of the training data in the latest time unit may create erroneous weights for historical classifiers. In the experiment, we generate synthetic data with a con-cept drifting rate of (  X  = 5), and we introduce a 20% sam-pling bias in each unit, which contains an average of 500 records. The weight-by-accuray approach uses an ensem-ble consisting 10 classifiers, and our approach uses a decay factor of 0 . 2. In Fig. 5, the X axis denotes the standard deviation in unit data size, and the Y axis denotes the rate of classification error. It indicates that our approach has advantage over the weight-by-accuray approach when devi-ation is high, although our approach uses much less training time.
Figure 5: Error and deviation of unit data size
In Fig. 6, we study the effect of sampling bias on classi-fication accuracy. The X axis represents the sampling bias, which ranges from 10% to 40%. The avarage size of each data unit is 500, and the standard deviation is 30. The other settings are the same as that of Fig. 5. The results indicate that data in each unit, which is very likely a to be biased sample from the true data distribution, may have a strong impact on the effectiveness of the weight-by-accuray approach. Our approach is able to reduce its effect.
Data stream processing has attracted much attention re-cently due to the explosive growth of many new classes of data stream applications. There is much work in this area including modeling, querying, and mining [1, 9, 11, 7, 14, 3, 12, 6, 13, 19, 18, 5, 4].

Traditional algorithms that require multiple scans of the training samples are inappropriate for our applications be-cause our applications require real-time predications. Sev-eral incremental algorithm [10, 7, 14] refine models by con-tinuously incorporating the influence of the new training samples and eliminating that of old ones. However, it is generally difficult to determine how fast the old data should be forgotten. Yang, et. al. [19] also proposed to use con-cept drifting patterns to improve classification accuracy. We model concept drifting differently and get different results.
There are also extensive studies on using classifier ensem-bles for traditional data mining including techniques such as Bagging [2], Boosting [8]. Unlike data stream mining, the model does not change in traditional data mining.

Our previous work [17] studies how to select a set of clas-sifiers trained with data in previous time windows. In that work, we select and boost the previous classifiers based on their accuracy when they are applied to the training set in the current time window. It does not leverage concept drift-ing pattern and thus are not as accurate as the algorithm proposed in this paper.
This paper advocates exploiting concept drifting patterns to improve accuracy and efficiency of data stream classi-fiers. With stochastic models of concept drifting, we are able to formulate the classification problem as an optimiza-tion problem and derive a theoretical optimal solution. We then approximate the solution of the optimization problem by combining a set of traditional classifier. Our experimen-tal results show that this approach results in significant im-provement in terms of classification accuracy and efficiency compared to previous approaches that do not exploit con-cept drifting patterns. [1] B. Babcock, S. Babu, M. Datar, R. Motawani, and [2] Eric Bauer and Ron Kohavi. An empirical comparison [3] Y.Chen,G.Dong,J.Han,B.W.Wah,andJ.Wang.
 [4] Yun Chi, Haixun Wang, Philip S. Yu, and Richard R. [5] Yun Chi, Philip S. Yu, Haixun Wang, and Richard [6] Graham Cormode and S. Muthukrishnan.
 [7] P. Domingos and G. Hulten. Mining high-speed data [8] Yoav Freund and Robert E. Schapire. Experiments [9] L. Gao and X. Wang. Continually evaluating [10] J. Gehrke, V. Ganti, R. Ramakrishnan, and W. Loh. [11] M. Greenwald and S. Khanna. Space-efficient online [12] S. Guha, N. Milshra, R. Motwani, and [13] Sudipto Guha and Boulos Harb. Wavelet synopsis for [14] G. Hulten, L. Spencer, and P. Domingos. Mining [15] Lawrence R. Rabiner. A tutorial on hidden markov [16] W. Nick Street and YongSeog Kim. A streaming [17] Haixun Wang, Wei Fan, Philip S. Yu, and Jiawei Han. [18] Peng Wang, Haixun Wang, Xiaochen Wu, Wei Wang, [19] Ying Yang, Xindong Wu, and Xingquan Zhu.

