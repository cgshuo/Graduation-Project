 Abstract We use integrations and combinations of taggers to improve the tagging accuracy of Icelandic text. The accuracy of the best performing integrated tagger, which consists of our linguistic rule-based tagger for initial disambiguation and a tri-gram tagger for full disambiguation, is 91.80%. Combining five different taggers, using simple voting, results in 93.34% accuracy. By adding two linguistically motivated rules to the combined tagger, we obtain an accuracy of 93.48%. This method reduces the error rate by 20.5%, with respect to the best performing tagger in the combination pool. Keywords Combination of taggers  X  Integration of taggers  X  Linguistically motivated rules  X  Simple voting  X  Tagging accuracy Abbreviations DDT data-driven taggers HMM Hidden Markov model IFD Icelandic frequency dictionary LMR linguistically motivated rules 1 Introduction Icelandic is a morphologically complex language, whose main part-of-speech tagset consists of about 660 tags.
 Hrafn Loftsson
We have previously developed a linguistic rule-based tagger, IceTagger (hereafter referred to as Ice ), which achieves 91.54% average tagging accuracy. Moreover, we have used tagger integration (i.e. making one tagger use a feature or a functionality of another tagger), and a combination of three taggers, using simple voting, to achieve 92.94% accuracy (Loftsson, 2006a , b ).

In this paper, we present additional tagger integration methods and build a combined tagger using five taggers. Furthermore, we show how simple linguistically motivated rules (LMR) can improve the tagging accuracy.

Our best performing integrated tagger achieves 91.80% tagging accuracy. By combining five taggers, using simple voting, we obtain 93.34% accuracy. When adding two LMR to the combined tagger, the accuracy increases to 93.48% and reduces the error rate by 20.5%, with respect to the best performing tagger in the combination pool.

This paper is organised as follows. In Sect. 2 , we briefly describe the Icelandic language, the tagset and the corpus used. The individual taggers used in this research are described in Sect. 3 . Sect. 4 is devoted to our integration methods and Sect. 5 describes the combination methods. Evaluation results are presented in Sect. 6 , and we conclude, in Sect. 7 , with a summary and direction for future work. 2 The Icelandic language, the tagset and the corpus The Icelandic language is one of the Nordic languages which comprise the North-Germanic branch of the Germanic language tree. The language is morphologically rich, mainly due to inflectional complexity.

Due to the morphological richness of the language, the main tagset, constructed in the compilation of the Icelandic frequency dictionary (IFD) corpus (Pind, Mag-languages. Each character in a tag has a particular function. The first character denotes the word class. For each word class there is a predefined number of addi-tional characters (at most six) which describe morphological features, like gender, number and case for nouns; degree and declension for adjectives; voice, mood and tense for verbs, etc. The reader is referred to (Loftsson, 2006a ; Pind et al., 1991 ) for a more complete description of the tagset.

For the purpose of using ten-fold cross-validation, ten different disjoint pairs of containing about 90% of the tokens from the corpus, and a test set, containing about 10% of the tokens. The test corpora do not share any examples, whereas the training corpora overlap (Helgado  X  ttir ( 2004 ) describes the corpus more thoroughly). 3 Individual taggers used The data-driven taggers (DDT) used in this research are state-of-the art: fnTBL (hereafter referred to as TBL ) (Ngai and Florian, 2001 ), based on transformation-based error-driven learning; MXPOST (hereafter referred to as MXP ) (Rat-naparkhi, 1996 ), based on a maximum entropy approach; MBT (Daelemans, Zavrel, Berck, &amp; Gillis, 1996 ), based on memory-based learning; and TnT (Brants, 2000 ), based on a Hidden Markov Model (HMM). Additionally, we used the taggers Ice and Tri , described briefly below.

Ice , a linguistic rule-based tagger, uses hand-written local linguistic elimination rules (the idea is borrowed from the well known Constraint Grammar framework (Karlsson, Voutilainen, Heikkila  X  , &amp; Anttila, 1995 ), along with a list of idioms (de-rived semi-automatically from the IFD corpus), for initial disambiguation. There-after, various heuristics (algorithmic procedures) are used to force feature agreement between words, effectively eliminating more tags. At the end, for a word not fully disambiguated, the default rule is to select the word X  X  most frequent tag. In addition to a lexicon derived from the IFD corpus, Ice uses a special lexicon which mainly includes tags for irregular verb forms. When testing Ice on the IFD corpus, this has the effect that the average unknown word ratio is slightly lower than the corresponding ratio when testing the DDT, i.e. 6.79% vs. 6.84%. Ice uses an inte-grated morphological analyser, IceMorphy , to obtain the possible tags for unknown words. Ice and IceMorphy are described in detail in (Loftsson, 2006a , b ).
Tri is our re-implementation of the TnT tagger. The difference between these two scribed above, as a backup lexicon.

All taggers were trained and tested, with their default options on the IFD corpus using ten-fold cross-validation. The only exception is the MBT tagger, for which we conducted an experiment to select the optimal settings: features -p ddwfaa and -P cndFasssss , search algorithm IB1-IG ( k = 5) and the modified value distance metric ; for details consult (Daelemans, Zavrel, &amp; van den Bosch, 2003 ).

When implementing Ice , 10% of the IFD corpus, i.e. the tenth test corpus, was used to develop rules. Therefore, the accuracy figures presented for all taggers in Table 1 (and henceforth) are average figures computed using only the first nine test corpora. All differences in tagging accuracy in Table 1 (and subsequently in Tables 2 and 3 ) are significant at a &lt; 0.05, using McNemar X  X  v 2 -test as described by Dietterich ( 1998 ). 4 Integration of taggers We define tagger integration as enabling one tagger to use a feature or a func-tionality of another tagger. In this section, we describe four integration methods, all of which have resulted in an improved tagging accuracy of Icelandic text. The first two methods, which consist of integrating our morphological analyser with state-of-the-art DDT, are described in more detail in (Loftsson, 2006a ). The latter two methods are new.

First, in order to improve the relatively poor tagging accuracy of TBL for un-known words (see Table 1 ), we made IceMorphy provide TBL with an initial tag (the most probable tag from the set of guessed tags) for each unknown word. This increased the overall accuracy of TBL from 89.33% to 90.15%.
 Second, we improved the accuracy of the TnT tagger in the following manner. IceMorphy is able to generate missing tags in a tag profile for a word belonging to a particular morphological class. We used this feature of IceMorphy to generate a  X  X  X illed X  X  lexicon, to be used by the TnT tagger. Each generated missing tag is marked with the frequency 1. This improved TnT X  X  accuracy from 90.44% to 91.18%.
 The third integration method is an integration of our Tri tagger with IceMorphy . In order to improve the accuracy of this tagger, we call IceMorphy from within the Tri tagger to obtain possible tags for unknown words. Moreover, we made the Tri tagger benefit from the lexicon filling mechanism described above. This version of the Tri tagger achieves an accuracy of 91.34%.

Lastly, we integrated our linguistic rule-based tagger with the Tri tagger. By making Ice call the Tri tagger for full disambiguation (instead of simply selecting the most frequent tag for a word not fully disambiguated) the overall tagging accuracy increases from 91.54% to 91.80%. A similar approach has, for example, been used for tagging text in the highly inflected Czech language (Hajic  X  , Krbec, Oliva, Kve  X  ton  X  , &amp; Petkevic  X  , 2001 ).
 Henceforth, we will refer to the TBL+IceMorphy tagger as TBL* , the TnT+IceMorphy tagger as TnT* , the Tri+IceMorphy tagger as Tri* and the Ice+Tri tagger as Ice* . Note that all our integrated systems run like a single tagger, i.e. the text to be tagged is processed and tagged only once. The change in accuracy between the unchanged versions of the taggers and the integrated taggers can be seen by comparing Tables 1 and 2 . 5 Combination of taggers It has been shown that combining taggers will often result in higher tagging accuracy elemans, 2001 ). The reason is that different taggers tend to produce different (complementary) errors and the differences can be exploited to yield better results.
A number of different combination methods exists, e.g. simple voting, weighted voting and stacking (see van Halteren et al. ( 2001 ) for a good overview), as well as combinations using LMR (Borin, 2000 ). In this experiment, we combine taggers using simple voting and LMR.

In simple voting, each tagger gets an equal vote when voting for a tag and the tag with the highest number of votes is selected. When combining taggers using LMR the relative strength of a given tagger, in a particular linguistic context, is utilised in the combination. 6 Evaluation 6.1 Simple voting In the first tagger combination experiment for Icelandic, the MXP , TBL and TnT taggers were used in a simple voting scheme, obtaining an average accuracy of 91.54% (Helgado  X  ttir, 2004 ) (see row 1 in Table 3 ). By using Ice instead of the relatively low accuracy tagger MXP , the accuracy increases substantially, to 92.61% (see row 2). By adding the two least accurate taggers, MXP and MBT ,tothe combination pool, the overall accuracy increases further to 92.80% (see row 3).
In (Loftsson, 2006a ), we had improved the first simple voting result for Icelandic text by combining TBL* , TnT* and Ice  X  X btaining an accuracy of 92.94% (see row 4 in Table 3 ). Here, we improve this result by adding the taggers MXP and MBT to the combination pool, resulting in an accuracy increase to 93.29% (see row 5). This time, the addition of the two taggers is about twice as effective than before, mainly because of higher accuracy for unknown words. The errors made by these two taggers for unknown words are probably, in many cases, complementary to the corresponding errors proposed by TBL* (which receives  X  X  X elp X  X  from IceMorphy for unknown words), but less complementary to TBL , which was used in the combi-nation pool in row 3.

The benefit of using our integrated taggers is clear by comparing the accuracy of the combined taggers in rows 2 and 4, and in rows 3 and 5, in Table 3 .

Finally, we replaced the standard version of Ice with Ice* , i.e. Ice with the Tri tagger for full disambiguation. This slightly improved the overall tagging accuracy (see row 6 in Table 3 ).
 6.2 Linguistically motivated rules We wrote two kinds of LMR, both of which are based on specific strengths of Ice , and which are only fired if not all taggers agree.

First, we have noticed that the DDT have difficulties providing the correct tag in a particular context, whereas Ice performs considerably better for the same context. This occurs, for example, where there are  X  X  X ong X  X  dependencies between a subject and a verb and the verb has the same lexical form for 1st and 3rd person. A typical example is  X  X  e  X  g opna  X  i dyrnar, steig inn ... X  X  (I opened door, stepped inside ...). The propose a 3rd person tag. The reason is that the 3rd person tag is more frequent and the DDT have a limited context window size.

Another example of a long dependency is between a subject and a reflexive pronoun, e.g.  X  X ... sag  X  i konan og f X r  X  i sig  X  X  (... said woman and moved herself), in which the reflexive pronoun has the same lexical form in all genders.

In both these examples, Ice provides the correct tag, because of its built-in feature agreement functionality, but is outvoted by the DDT. We, thus, built a simple rule which always selects the 1st person verb tags if they are suggested by Ice , and the tags suggested by Ice for the reflexive pronouns  X  X  sig  X  X ,  X  X  se  X  r  X  X  and  X  X  s X   X  n  X  X .
For the second rule, we used a feature agreement constraint:  X  X  X f all the tags, provided by the individual taggers for the current word, are nominal tags and the current tag provided by Ice agrees in gender, number and case with the preceding (selected) nominal tag or the following (yet to be selected) nominal tag, then choose Ice X  X  tag X  X . Using this rule improves the tagging accuracy, because disambiguating using nominal feature agreement is one of the strengths of Ice .

Row 8 of Table 3 shows that using simple voting along with the two LMR results in an overall tagging accuracy of 93.48%. 7 Conclusion We have used integrations and combinations of taggers to improve the tagging accuracy of Icelandic text. Accuracy of the best performing integrated tagger, con-sisting of using IceTagger , for initial disambiguation, along with a HMM tagger, for full disambiguation, is 91.80%.

The best performing simple voting method, using five individual taggers, achieves 93.34% tagging accuracy. Furthermore, when adding two LMR to the combined tagger, the accuracy increases to 93.48%.

We envision several ways to improve the accuracy further. First, increasing the training corpus size for the DDT might be a feasible option, because our best combination method could be used for initial tagging, followed by manual correc-tions. Second, adding more taggers to the combination pool might improve the accuracy. Third, adding more linguistic knowledge to IceTagger is possible, espe-cially with the purpose of fixing frequent errors. Fourth, reducing the tagset, without too much loss of information, is worthwhile. Lastly, we would like to experiment with using stacking methods, e.g. using a memory-based method which learns from the tagged output of the individual taggers. References
