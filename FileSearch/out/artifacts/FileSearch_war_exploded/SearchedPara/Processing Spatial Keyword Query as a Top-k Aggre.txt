 We examine the spatial keyword search problem to retrieve objects of interest that are ranked based on both their spatial proximity to the query location as well as the textual relevance of the object X  X  keywords. Existing solutions for the problem are based on either using a combination of textual and spatial indexes or using special-ized hybrid indexes that integrate the indexing of both textual and spatial attribute values. In this paper, we propose a new approach that is based on modeling the problem as a top-k aggregation prob-lem which enables the design of a scalable and efficient solution that is based on the ubiquitous inverted list index. Our performance study demonstrates that our approach outperforms the state-of-the-art hybrid methods by a wide margin.
 H.3.3 [ Information Search and Retrieval ]: Search process Spatial keyword search; Top-k aggregation
The prevalence of smartphones and social network systems has enabled users to create, disseminate and discover content on-the-move. According to a recent study [2], Twitter has 164 million monthly active users accessing its site from mobile devices while Facebook has 425 million mobile users doing so. Consequently, a tremendous amount of social content, including tweets, check-ins, POIs and reviews, are generated every day and notably, these data are attached with geo-coordinates and form a large-scale geo-document corpus. Spatial keyword search is an important func-tionality in exploring useful information from a corpus of geo-documents and has been extensively studied for years [5, 13, 14, 16, 18, 22, 29, 33 X 36]. The work on spatial keyword search can be broadly categorized into two classes: distance-insensitive and distance-sensitive .

In the traditional distance-insensitive keyword search, the docu-ments are organized based on a geographical ontology [5, 13, 18, 36]. For example,  X  X niversity Ave X   X   X  X alo Alto X   X   X  South Bay X   X   X  X ay Area X  [5] is an example hierarchical path in a geo-graphical ontology. Given a keyword query with a locational con-straint, the constraint is used to restrict the document search within matching hierachies of the ontology. Thus, the query X  X  locational constraint here is used as a filtering criterion. In distance-sensitive keyword search, each geo-document is associated with a precise reference point 1 so that its spatial distance from a query location can be calculated to evaluate its relevance in terms of spatial prox-imity. Thus, the query location here is used as a ranking criterion.
Distance-sensitive keyword search has many useful applications that facilitate a user to search for nearby locations/events/friends based on some keywords with the matching results ranked in in-creasing proximity to the user X  X  location. For example, point-of-interest (POI) applications such as Foursquare and Yelp are very useful to search for nearby venues or restaurants. As another ex-ample, location-based social discovery applications such as Tinder are very useful to search for nearby users with mutual interests.
In this paper, we focus on the problem of top-k distance-sensitive spatial keyword query search: given a spatial keyword query (with a location and a set of keywords), the objective is to return the best k documents based on a ranking function that takes into account both textual relevance as well as spatial proximity. Figure 1 illustrates a simple example of distance-sensitive spatial keyword search for a corpus with seven geo-documents d 1 ,  X  X  X  , d 7 . Each document is associated with a location and a collection of keywords together with their relevance scores. Consider a spatial keyword query Q with keywords  X  X eafood restaurant X  issued at the location marked by the star. In this example, document d 2 is considered to match Q better than document d 4 because d 2 is close to the query location and it is highly relevant to the query keywords; in comparison, d does not match the query keywords well, though it is slightly closer to Q then d 2 .

The efficiency of evaluating top-k distance-sensitive spatial key-word queries becomes critical for a large-scale geo-document cor-pus. Existing methods for this problem [14, 16, 22, 29, 35] have shown that combining the spatial and textual attributes together can effectively prune the search space. These methods can be di-vided into two broad categories: spatial-first and textual-first . In the spatial-first strategy, a spatial data structure (such as an R-tree [10]) is first used to organize the geo-documents into spatial regions based on their locations. Next, each spatial region is aug-mented with an inverted index to index all the documents contained in that region. An example of a spatial-first scheme is the IR-tree [14]. On the other hand, in the textual-first strategy, the search space of geo-documents is first organized by keywords, and then for
The location information can be naturally derived from the GPS of smartphones. d d
Figure 1: An example of spatial keyword search scenario each keyword, a spatial data structure is employed to index the doc-uments associated with that keyword. S2I [29] and I 3 [35] are two schemes that follow this strategy. Recent extensive performance studies [29, 35] have demonstrated that both S2I and I 3 are signif-icantly faster than IR-tree. As such, we consider S2I and I the state-of-the-art solutions for distance-sensitive spatial keyword search.

However, there are two key limitations with the state-of-the-art solutions. First, these solutions are not sufficiently scalable to cope with the demands of today X  X  applications. For example, Foursquare has over 60 millions of venues, and the number of geo-tweets pub-lished by mobile users per day is in the hundreds of million. None of existing solutions [29, 35] have been evaluated with such large-scale datasets; indeed, our experimental study reveals that the state-of-the-art solutions do not perform well for large datasets. Sec-ond, these solutions employ specialized  X  X ybrid X  indexes that inte-grate the indexing of both textual as well as spatial attributes which present additional complexity for their adoption in existing search engines in terms of implementation effort, robustness testing, and performance tuning.

In this paper, we propose a new approach to address the limita-tions of the state-of-the-art solutions. Our paper makes three key contributions. First, we present a simple but effective approach to solve the top-k distance-sensitive spatial keyword query by mod-eling it as the well-known top-k aggregation problem. Second, we propose a novel and efficient approach, named Rank-aware CA (RCA) algorithm , which extends the well-known CA algorithm with more effective pruning. In contrast to the specialized hybrid solu-tions, our RCA algorithm is more practical as it relies only on the ubiquitous and well-understood inverted index. Third, we demon-strate that RCA outperforms the state-of-the-art approaches by a wide margin (up to 5 times faster) on a real dataset with 100 mil-lion geo-tweets.

The rest of the paper is organized as follows. We present the problem statement in Section 2, and review related work in Sec-tion 3. In Section 4, we present our new approach to model the problem and two baseline algorithms. We present our new algo-rithm, RCA, in Section 5. In section 6, we evaluate the efficiency of RCA with an extensive performance study. Section 7 concludes the paper.
We model a geo-document by a quintuple, D = h docID , x , y , terms i ; where docID denote the document id, ( x , y ) denote the (longitude, latitude) location of the document, and terms denote a collection of weighted terms. Each weighted term is of the form h term i ,  X  t ( D , term i ) i , where term i denote a term in document and  X  t ( D , term i ) denote the textual relevance score between term i . Here,  X  t denote the tf-idf textual reference scoring func-tion [9, 25].
 A top-k distance-sensitive spatial keyword query is denoted by Q = h x q , y q , w 1 , w 2 ,..., w m , k i ; where ( x q tude, latitude) location of the query, { w 1 , w 2 ,..., w set of query keywords, and k denote the number of top-matching documents to be returned for the query.

The relevance score between a document D and a query Q is evaluated by a monotonic aggregation of textual relevance and spa-tial proximity. The textual relevance is measured by a scoring func-tion  X  t ( D , Q ) that sums up the relevance score of each query key-word: If a document D does not contain any query keyword, we consider it irrelevant and set  X  t ( D , Q ) to be  X   X  to prevent it from appearing in the results. The spatial proximity is measured by  X  s ( assigns a score based on the distance between D and Q such that a smaller spatial distance yields a higher  X  s ( D , Q ) value. In this paper, we use the same spatial ranking function as in [14, 29, 35]. where d ( D , Q ) measures the Euclidean distance between the lo-cations of the query Q and document D , and  X  is a parameter to normalize  X  s ( D , Q ) between [ 0 , 1 ] which is set to be the maximum distance among all the pairs of documents. Finally, as in [14, 16, 29, 35], we define the overall ranking function  X  ( D , Q ) as a linear combination of textual relevance and spatial proximity:
Based on the ranking function  X  , we can formally define the top-k spatial keyword query as follows: D E FINIT ION 1. T op-k spatial keyword query Given a document corpus C , a top-k spatial keyword query Q re-trieves a set O  X  C with k documents such that  X  D  X  O and D C  X  O,  X  ( D , Q )  X   X  ( D  X  , Q ) .
Spatial keyword search is a well-studied problem and can be cat-egorized into two classes: distance-insensitive and distance-sensitive .
The traditional local search engines such as Google Local [1] and Yahoo! Local [3] belong to the distance-insensitive category. In these systems, location information is first extracted from web pages and organized using a hierarchical geographical ontology. Given a query with a locational constraint, the candidate documents are retrieved from the matching hierarchies in the ontology using existing information retrieval methods such as TAAT [6 X 8, 30] or DAAT [11, 31].

In [36], Zhou et al. built separate R-tree [10] and inverted in-dex for the spatial and textual attributes respectively; and evaluated a query by first searching with one of the indexes (spatial or tex-tual) followed by ranking the matching documents using informa-tion from the other index.

In [13], the locational regions are first extracted from the web documents which are then used to organize the documents using the grid file [27] or space-filling curve [19] such that spatially close documents are clustered near to one another on disk. Given a query, documents whose locational regions contain the query location are first retrieved and their textual relevance wrt the query are are then computed.

In [18], Fontoura et al. proposed query relaxation techniques to generate top-k results when there are not enough matching docu-ments in the specified region.

In [22], Hariharan et al. proposed KR*-tree, the first hybrid in-dex to handle spatial keyword query with AND-semantics, where a matching document must contain all the query keywords and its query location must intersect with the query region. In KR*-tree, an inverted index is maintained for each tree node, where both spa-tial filtering and textual filtering can be employed at the same time when accessing an index node. In [32], Zhang et al. recently pro-posed a more efficient hybrid index to process queries with AND-semantics. The index combines linear quadtree [20] and fixed-length bitmap for query processing.
In the distance-sensitive category of work [12, 14, 16, 29, 35], matching documents are ranked based on both their textual rele-vance and spatial proximity to the query.
 In [16], Felipe et al. proposed IR 2 which is a hybrid index of the R-tree and signature file; their work is based on the AND-semantics which sorts the matching documents by their distance to the query location.

Cong et al. [14] proposed IR-tree which is a spatial-first approach that integrates the R-tree with inverted index; each R-tree node is augmented with inverted lists to index documents located within that node.
 More recently, two textual-first approaches, S2I index [29] and I [35], have been proposed. S2I uses aggregated R-tree [28] for spatial relevance evaluation. The search algorithm expands from the query location in the spatial index associated with each query keyword until k best results are found. I 3 builds one Quadtree [17] for each keyword and adopts the best-first search strategy in query processing. Performance studies [29, 35] have shown that both S2I and I 3 are significantly faster than IR-tree.
In this section, we present a new approach for the top-k distance-sensitive spatial keyword search problem. Our approach is based on the simple but effective idea of modeling the problem as a top-k aggregation problem [15].
 D E FINIT ION 2. T op-k aggregation problem Consider a database D where each object o = ( x 1 , x 2 ,..., x scores, one for each of its n attributes. Given a monotonic aggrega-tion function f , where f ( o ) or f ( x 1 , x 2 ,..., x n score of object o, the top-k aggregation problem is to find a set of top-k objects in D with the highest overall scores; i.e., find O  X  D with k objects such that  X  o  X  O and o  X   X  D  X  O, f ( o )  X  f ( o
The reformulation of the top-k distance-sensitive spatial key-word search problem as a top-k aggregation problem is straight-forward. Given a query Q with m keywords, each geo-document D in a database D can be modeled as a m + 1-tuple ( x 1 , x where x i ( 1  X  i  X  m ) is the textual relevance score (defined by  X  between D and the i th query keyword, and x m + 1 is spatial proximity score (defined by  X  s ) between D and the query location. By setting the aggregation function to be  X  in Equation 3, the top-k distance-sensitive spatial keyword query problem is now reformulated as a top-k aggregation problem.

E XAMPL E 1. C onsider again the example spatial keyword search problem in Figure 1. Since all the documents contain at least a Figure 2: An example of top-k aggregation for query  X  X eafood restaurant X  query keyword, we have D = { d 1 , d 2 ,..., d 7 } . Each document D is now modelled as a three-dimensional vector ( x 1 , x 2 x is the D X  X  textual relevance to the keyword  X  X eafood X , x 2 textual relevance to the keyword  X  X estaurant X , and x 3 is the spa-tial proximity between D and the query. If we set the aggregation function to be  X  , the top-k aggregation problem for this example would return the results with the highest scores ranked by  X  which are exactly the results for the spatial keyword search problem.
By formulating the problem as a top-k aggregation problem, we are able to design an efficient solution that relies only on the simple and widely used inverted index in contrast to existing hybrid solu-tions. The rest of this section is organized as follows. We first re-view top-k aggregation algorithms in Section 4.1, and then explain how they are adapted as baseline algorithms for the top-k distance-sensitive spatial keyword search problem in Section 4.2.
In this section, we present an overview of top-k aggregation al-gorithms. A comprehensive survey of these algorithms are given in [23].

For convenience, we present the algorithms in the context of spa-tial keyword search as follows. Given a query with m keywords and a geo-location, assume that we have constructed m + 1 sorted lists, L , L 2 ,..., L m , wrt a database of geo-documents. Each L is sorted (in non-ascending order) by the documents X  textual rele-vance scores wrt the i th query keyword; and L m + 1 is sorted (in non-ascending order) by the documents X  spatial proximity to the query location. Thus, each sorted list entry is a pair of document identifier and a score (textual relevance or spatial proximity).

The first algorithm is the TA algorithm proposed by Fagin et al. [15], which consists of two main steps. 1. Perform a sorted access in parallel to each of the m + 1 sorted 2. For each list L i , let high [ i ] be the score of the last document
Although the TA algorithm has been proven to be instance op-timal, the optimality depends on the cost of random access. The algorithm does not perform well if the cost of random access is too high. Subsequently, an improved variant of the TA algorithm, the CA algorithm [15], was proposed to achieve a good tradeoff between the number of sequential access and random access.
The CA algorithm uses a parameter h to control the depth of sequential access. In each iteration, h documents in each list are sequentially accessed. h is set to be the ratio of the cost of a random access to the cost a sequential access. For each accessed document doc , let B ( doc ) denote an upper bound of the aggregated score of doc . A document doc is defined to be viable if B ( doc ) is larger than the k th best score that has been computed so far. At the end of each iteration, the viable document with the maximum B ( doc ) value is selected for random access to determine its aggregated score. The algorithm terminates when at least k distinct documents have been seen and there are no viable documents.

Besides the TA and CA algorithms, there are a number of other variants that optimizes the approach for early termination. In [21], an improved TA variant, Quick-Combine , was proposed where in-stead of accessing the sorted lists in a round-robin manner, Quick-Combine first estimates the influence of each sorted list and selects the most influential list in each iteration for random access. In [26], Marian et al. proposed the Upper and Pick algorithm to conduct random access by minimizing the upper and lower bounds of all objects.
In this section, we explain how the standard top-k aggregation algorithms described in the previous section are adapted as baseline algorithms for the top-k distance-sensitive spatial keyword search problem.

First, note that while it is possible to precompute the sorted lists for the textual attributes (i.e., L 1 , L 2 ,..., L m ) since the tf-idf scores are independent of the query, this is not the case for the list L for the spatial attribute as the spatial proximity score is dependent on the query location. Thus, the sorted list L m + 1 needs to be created at query time.

Second, since the documents matching a query X  X  keywords are generally not clustered together (i.e., their docIDs are not related), performing random access to matching documents to retrieve the overall relevance score typically incurs a large number of random disk I/O. To further minimize the number of random disk I/O for such retrievals, we introduce a simple optimization to organize the single, large document list into multiple smaller ones by maintain-ing a document list of matching documents for each keyword. By clustering the document entries that match the same keyword, this optimization helps to reduce the number of random disk I/O in-curred for document identifier lookups. However, this advantage is at the cost of additional storage for the document lists as a docu-ment X  X  information is now replicated among several lists. Figure 3: One global document list v.s. multiple small lists
E XAMPL E 2. F igure 3 illustrates how the use of multiple docu-ment lists can help reduce disk I/O. In this example, keyword w pears in documents L 1 = { 3 , 5 , 7 , 10 , 13 } and keyword w in documents L 2 = { 5 , 9 , 10 , 15 } . If we need to perform random access on all the documents in L 1 and L 2 , using a single, global document list could incur a total of 7 disk I/O (one for each distinct document); in contrast, with the use of multiple document lists, the number of disk I/O could be reduced to only 2 if each of the keyword-based document lists fits on one disk page.
While the baseline algorithms presented in the previous section could be easily incorporated into existing search engines that sup-port the ubiquitous inverted list index, the baseline algorithms have a performance drawback in that the spatial attribute list cannot be precomputed statically but need to be sorted at runtime using the query location to compute the spatial proximity values. In this sec-tion, we present an optimized variant of the CA algorithm, termed Rank-aware CA (RCA) , to address this limitation.

The key idea of our optimization is to sort the spatial attribute list offline based on an approximate spatial order preserving encoding such that the two-dimensional location attribute values are encoded into totally ordered values with the desirable property that a pair of encoded location values that are close together in the total order represents a pair of locations that are likely to be spatially close to each other. In this paper, we apply the well-known Z-order [4] to obtain such a mapping.
E XAMPL E 3. F igure 4 illustrates an application of Z-order to encode location values for a two-dimensional space that is parti-tioned into 8  X  8 cells. Applying the Z-order encoding, each cell is assigned a unique Z-order value from 1 to 64 . Since each document is located within some cell, the document X  X  location is represented by the Z-order value of its cell location. Note that the Z-order en-coding provides an approximate preservation of spatial proximity.
There are two useful properties of Z-order encoding that we ex-ploit in our RCA algorithm. First, given any rectangular region R in the location space, the top-left corner cell of R has the smallest Z-order value (denoted by R min ) and the bottom-right corner cell of R has the largest Z-order value (denoted by R max ) among all the cells in R . Thus, all the cell locations in a region R are contained in the range of Z-order values [ R min , R max ] . As an example, consider a query Q that is located in cell 51 and a region R that is centered at Q with a radius of r 1 as shown in Figure 4. We have [ R = [ 38 , 58 ] which contains the Z-order values of all the cells in R . Second, for any cell with a Z-order value c that is outside of a re-gion R centered at Q with radius r 1 (i.e., c &lt; R min or c &gt; R distance of this cell from Q must be larger than r 1 .

Based on the properties of the Z-order encoding, the RCA algo-rithm progressively accesses the documents in the spatial attribute list in iterations in a score-bounded manner. In each iteratoin, un-like conventional CA algorithm which explores a fixed number of items, our RCA algorithm accesses all the documents with spatial proximity score within a fixed-length score interval.
In this section, we elaborate on the score-bounded access of the spatial attribute lists.

Similar to the rationale for organizing a document list into multi-ple shorter lists as explained in Section 4.2, the spatial attribute list is also organized as multiple shorter lists with one spatial inverted list L w for each keyword w ; i.e., the entries in L w represent all the documents that contain the keyword w . The entries in L w in ascending order of their Z-order encodings of the document lo-cations, and these spatial inverted lists are created offline without incurring any runtime sorting overhead.

Assume that the spatial relevance scores are normalized to the range ( 0 , 1 ] by the scoring function  X  s . Let  X  s denote the maximum number of iterations to be used to access all the documents in the spatial attribute lists. Therefore, spatial score range ( 0 , 1 ] is parti-tioned into  X  s disjoint intervals (each of length 1  X  T = ( 1  X  2  X  of spatial proximity score values for the documents accessed in the i iteration. By Equation 2, it follows that for the i th iteration, we have  X  s = 1  X  d ( D , Q )  X  &gt; 1  X  i  X  eration. In other words, in the i th iteration of the score-bounded access, the search radius for that iteration is set to r i radius progressively increases over the iterations.

At each iteration of the score-bounded access, the search on a spatial inverted list is actually performed in terms of a forward-scan and a backward-scan. Consider again the example in Figure 4 where the Z-order encoding of the query location (denoted by z is in cell 51 (i.e., z q = 51). With an initial radius of r the documents located in the Z-order range I 1 = [ 38 , 58 ] as shown in Figure 4. At the next iteration when the radius is increased to r , we have the Z-order range I 2 = [ 15 , 63 ] which contains I access only the documents contained in I 2 but not in I 1 search is split into a backward-scan of Z-order range [ 15 , 37 ] and a forward-scan of Z-order range [ 58 , 63 ] .

Based on the properties of Z-order, it is possible that some of the documents accessed in the searched spatial region (specified by some range of Z-order values) could be false positives; i.e, the actual distance between the accessed document and query could be larger than the current search radius r i at the i th iteration. To avoid processing these false positives too early, we maintain  X  to temporarily store these false positive documents: a false positive document that should have been processed later in the j th (i.e., j &gt; i ) will be temporarily stored in the j th buffer. Thus, the documents in the j th buffer will be considered later during the j iteration.

E XAMPL E 4. F igure 5 illustrates an example of scored-based access for the spatial attribute. The algorithm starts from the region with radius  X  s =  X   X  3  X  s , etc. until it has found k documents with the highest scores. For the iteration with radius =  X  s , the Z-order range in this iteration is [ 38 , 58 ] and two documents { d 3 , d 4 } are accessed during the scan of the spatial list. Among them, only d 4 is a true candidate. d false positive and it is temporarily stored in the appropriate buffer to be considered in a subsequent iteration.

In contrast to the CA algorithm, which accesses a fixed number of documents in each iteration, the documents accessed by RCA is determined by a score interval corresponding to the iteration. This difference between CA and RCA is motivated by two reasons. First, the upper bound score for the ranking function  X  tion 2) relies on the minimum distance of all the unseen objects to the query location and this distance computation is complex as each Z-order range in general corresponds to an irregular polygon. Second, the upper bound score for  X  s could decrease very slowly if a fixed number of documents is accessed per iteration. This is because the Z-order encoding only preserves spatial proximity ap-proximately and spatially close objects could have Z-order values that are far apart in the linear order. For example, in Figure 4, al-though the minimum distance between cells 16 and 49 is zero, the difference in their Z-order values is 33. As another example, if RCA were to adopt CA X  X  approach of accessing a fixed number of objects per iteration, then there is actually no change in the upper bound spatial relevance score from the objects accessed in cell 49 to cell 17.
Recall that our ranking function  X  is a linear weighted combi-nation of spatial proximity and textual relevance with the weight parameter  X  . Intuitively, when the value of  X  is small, the spatial relevance is more important than textual relevance; and it is there-fore desirable to examine more documents in the spatial inverted lists than the textual inverted lists so that the upper bound textual relevance score for the unseen documents can decrease more sig-nificantly to enable an earlier termination of the algorithm.
To achieve the above property, the RCA algorithm also adopts the score-bounded access method for the textual attribute lists. Specif-ically, let  X  t denote the maximum number of iterations to be used to access the textual attribute lists. Then, the textual relevance score domain ( 0 , 1 ] is partitioned into  X  t intervals where documents whose textual relevance score is within ( 1  X  i  X  cessed in the i th iteration. In this way, our RCA algorithm enables more relevant documents to be accessed before less relevant ones. At the end of the i th iteration, the upper bound textual relevance score for the unseen documents is given by It follows that the parameters  X  s and  X  t are related as follows:
E XAMPL E 5. C onsider once more the spatial keyword query with keywords  X  X eafood restaurant X , and assume that  X  t = 4 (i.e., the length of the score interval is  X  t = 0 . 25 ). Figure 6 shows the documents that are score-bounded accessed for each of the four iterations w.r.t. the two inverted lists for the query keywords. In the first iteration, we access documents whose textual relevance score is within ( 0 . 75 , 1 ] and d 2 is accessed in both inverted lists. The upper bound textual relevance score for the unseen documents in each list is updated to be 0 . 75 . In the second iteration, no docu-ments are accessed for keyword  X  X eafood X  and only d 5 is accessed. In this way, our score-bounded approach prioritises the document retrievals to access documents that are more likely to be in the top-k results earlier. In contrast, the conventional CA algorithm will access the documents d 4 , d 3 and d 7 with low relevance scores in the inverted list of  X  X eafood X  very early.
 Figure 6: Score-bounded sequential access for keywords  X  X eafood restaurant X 
In this section, we discuss the overall approach for our RCA al-gorithm. Our approach adopts a different random access strategy and termination criteria from the traditional CA algorithm. Recall that the CA algorithm selects the viable document with the maxi-mum upper bound score for random access and the algorithm ter-minates if this upper bound score is no greater than the score of the k th best document seen so far (denoted by W k ). In contrast, our RCA algorithm does not maintain B ( doc ) to store the upper bound score for each viable document. Moreover, our random access is applied to the viable documents in the min-heap storing top-k re-sults so that W k can be increased as much as possible towards an early termination. Based on our score-bounded sequential access approach, we can also compute a tighter upper bound for a docu-ment X  X  aggregated score (denoted by B k ). Specifically, after the i iteration, B k is given by is calculated by More precisely, the upper bound of textual relevance can be fur-If B k  X  W k , we stop the sequential access on the sorted lists as it is guaranteed that that no unseen document could have an aggregated score higher than W k . However, the algorithm cannot be terminated at this point because there could be some viable documents not in the top-k heap but with a upper bound score larger than W these documents, we need to conduct random access to get their full aggregated score and update the top-k heap if we find a better result. In this way, we can guarantee no correct result is missed.
Our rank-aware CA algorithm to process top-k spatial keyword queries is shown in Algorithm 1. The input parameter L collection of textual lists sorted by  X  t values and L s is the collec-tion of spatial lists sorted by Z-order encoding values. In lines 1 and 2, a top-k heap and  X  s buffers are initialized, where buf [ i ] is used to temporarily store any false positive documents to be processed during the i th iteration. Three pointers p are used for sequential access: p t is used for the textual lists and p (resp. p b ) is used for the forward (resp. backward) scan in the spatial lists (lines 6-8). In each iteration, we perform sequen-tial access in the textual lists by calling exploreTextList (line 10) and forward/backward scans in the spatial lists by calling explore-ForwardSpatialList and exploreBackwardSpatialList (lines 11-13). The function exploreTextList accepts the parameter B t in Equation 4 so as to scan the documents whose relevance is in the range ( B t ( i ) , B t ( i  X  1 )] . Similarly, we calculate the Z-order range from the current search radius and perform forward and backward sequential access of documents within the computed Z-order range in the spatial lists. Any false positive documents are stored in the appropriate buffers in buf and examined in subsequent iterations (lines 14-15 in Algorithm 1). After the sequential access, we per-form random access on the viable documents in the top-k heap (lines 16-17 in Algorithm 1). Finally, we update B k according to Equation 6. If B k  X  W k , we stop the sequential access and for each viable document not in topk , we perform random access to obtain its complete score and update the top-k results if it is a better result.
In this section, we compare the methods derived from top-k ag-gregation with state-of-the-art indexes that combine spatial parti-tioning and textual partitioning. More specifically, we compare the performance of TA, CA and RCA proposed in this paper with S2I [24] and I 3 [35] in processing top-k spatial keyword queries. We set h = 8 in the CA Algorithm and  X  t = 20 in the RCA algo-rithm. All the methods are disk-based and implemented in Java. We conduct the experiments on a server with 48GB memory and Quad-Core AMD Opteron(tm) Processor 8356, running Centos 5 . 8.
We use a Twitter dataset for the experiments. Our collection con-tains 100 million real geo-tweets that take up to 7 . 7GB in storage in the raw data format. For scalability evaluation, we sample four sub-sets whose sizes vary from 20 million to 80 million. The statistics of these datasets are shown in Table 1, where we report the dataset size, number of distinct keywords, average number of keywords in a document and amount of disk storage for each dataset.

In Table 2, we report the disk size of our inverted index and the comparison indexes. To support Rank-aware CA (RCA), we build three inverted lists for each keyword and use MapDB 3 to store all ther reduced to  X   X   X  1  X  j  X  m s j , where s j is the score last seen in each textual list. Since the i th iteration in the j th textual list terminates when we access a document with a score s j /  X  T i , we can be assured that s j  X  B t ( i ) . http://github.com/jankotek/mapdb the lists. Since TA and CA do not need the lists sorted by z-order, we let them share the inverted lists of RCA that are sorted by tex-tual relevance and document id. As shown in Table 2, inverted in-dex consumes only slightly more disk space than S2I. Although we maintain three inverted lists for one keyword while S2I builds one R-tree for one keyword, the inverted lists have higher disk utiliza-tion than R-tree and can be easily compressed to save disk space. I allocates at least one disk page for an infrequent keyword but S2I merges them in one file. Thus, I 3 consumes the most disk space.
We use real keyword queries from AOL search engine 4 to gen-erate spatial keyword queries. First, we select hotel and restaurant as two typical location-based queries. All the keyword queries in the log containing  X  X otel X  or  X  X estaurant X  are extracted. Among them, we keep the queries whose number of keywords are from 2 to 6. After removing duplicate queries, we note that, as shown in Table 3, queries with 3 keywords are the most common and ho-tel queries are more frequently submitted by users than restaurant queries. Next, we attach to each keyword query a spatial location. The location is randomly sampled and follows the same distribution as the tweet location.
In the following experiments, we will evaluate the performance of query processing in terms of increasing dataset size (from 20 million to 100 million), varying number of query keywords m (from 2 to 6), the number of query results k (from 10 to 200) and textual relevance weight  X  in the ranking function (from 0 . 1 to 0 . 9). The values in bold in Table 4 represent the default settings. In each ex-periment, we vary one parameter and fix the remaining parameters at their default values. The performance is measured by the average latency of query processing. Given a query set with thousands of hotel or restaurant queries, we start the timing when the first query arrives and stop when the last query finishes. Thus, the query pro-cessing time includes the I/O cost to load the index into memory. We do not set a cache limit for query processing. The part of index that is loaded in memory will stay as cached until all the keyword queries are processed.
The query results are top-k geo-tweets sorted by spatial prox-imity and textual relevance. Since tweets are normally short text, we merge the tweets with the same location into one geo-document. For example, a restaurant may be checked in multiple times and the term frequency can reflect the popularity of the location. Table 5 illustrates an example of top-10 geo-tweets for a query  X  X eafood restaurant X  submitted at location ( 40 . 7312 ,  X  73 . 9977 ) , correspond-ing to Washington Square Park in Manhattan, New York City. In this example,  X  is set to 0 . 3 in favor of geo-tweets closer to the user location. If there are multiple tweets at the same location, we only select a representative one for presentation purpose. http://www.gregsadetsky.com/aol-data/
In this experiment, we examine the scalability in terms of in-creasing dataset size. We increase the number of geo-tweets from 20 million to 100 million and run the sets of 3-keyword hotel and restaurant queries (the number is 7 , 831 and 3 , 844 respectively). We report the average query processing latency of different meth-ods in Figure 7. As can be seen, the inverted-index-based solutions, including TA, CA and RCA, achieve much better performance than the hybrid indexes that combine spatial partitioning and textual par-titioning. S2I and I 3 maintain a spatial index for each keyword. Given a set of keywords, they start from the query location and expand the search region from the spatial attribute only. The docu-ments closest to the query location will be accessed first, regardless of the textual relevance. In addition, the spatial index is disk-based and the tree nodes are accessed with a large number of random I/Os. Therefore, their performance do not scale well. When the dataset size increases to 100 million, the query latency is 5 times worse than that of RCA.
TA and CA demonstrate comparable performance. Although they need to sort the lists by the distance to the query location, the performance is still around 2 times better than state-of-the-art solutions. TA terminates earlier than CA because most of the doc-
Algorithm 1: RCA ( Q , L t , L s , m , k ,  X  t ,  X  s ) uments only contain part of the query keywords. For these docu-ments, even if all the contained keywords have been accessed, their upper bound score is still higher than the real score. Therefore, B decreases slowly in CA. TA does not need to maintain the upper bound score for each document and terminates earlier. However, it incurs the overhead of a larger number of random accesses. Each random access includes at most m times of binary search on the sorted lists that have been loaded in memory and the cost of ran-dom access is moderate. Consequently, the query processing time in TA and CA is close.

RCA achieves the best performance among all the methods. Even in the dataset with 100 million tweets, it takes around 200ms to an-swer a query which is 2 times better than TA and CA. The main reason is that it does not need to sort the spatial lists online and the rank-aware expansion is effective in saving the cost of sequen-tial access. Table 6 shows the average fraction of documents se-quentially traversed by the different top-k aggregation algorithms. TA uses much smaller number of sequential access than CA but it requires a random access for each document retrieved from the sequential traversal. RCA can be considered as a compromise be-tween TA and CA with a moderate number of sequential access and random access.

Finally, restaurant queries take a relatively longer time than ho-tel queries to answer. This is not because restaurant is a more fre-quent keyword in the Twitter dataset. In fact, the average length of an inverted list for keyword that appears in restaurant queries is 53 , 967 but this number is 73 , 045 for hotel queries. Instead, our investigation shows that this performance difference is due to the memory cache. In this experiment, we run 7 , 831 hotel queries, which is much higher than the 3 , 844 restaurant queries. This means more inverted lists about hotels are cached in memory and the disk I/Os can be saved when the cached keyword appears in subsequent queries. Note that the comparison among different methods is fair enough because all of them adopt the same caching mechanism. Table 5: Example tweet results for query  X  X eafood restaurant X 
The average query latency of the various algorithms as k in-creases from 10 to 200 is shown in Figure 8(a) and 8(b). The perfor-mance of S2I and I 3 degrade more significantly than the solutions based on top-k aggregation. This is because they access the docu-ments in the order of the distance to the query location. Hence, their pruning power only relies on the spatial attribute and the textual rel-evance is not taken into account. The remaining methods consider the spatial and textual relevance as a whole and demonstrate better scalability to k . The results also shed insight on the effectiveness of search space pruning among TA, CA and RCA. In TA and CA, the query processing time include the cost to sort by spatial proximity and the cost of sequential and random access. As k increases, the overhead of sorting is fixed and the running time increases because more documents are accessed when k becomes larger. Hence, we can compare the pruning effectiveness of TA, CA and RCA from the experiment figures. As k increases from 10 to 200, the running time of RCA increases much slower than TA and CA, which means our rank-aware expansion is effective in reducing the access cost in the sorted lists.
In this experiment, we increase the number of query keywords m from 2 to 6 and evaluate the performance in Twitter60M dataset. Since a document is considered relevant if it contains at least one query keyword, the number of candidates grows dramatically as m increases. The average query latency is reported in Figure 8(c) and 8(d). As can be seen, the performance of spatial keyword query processing degrades dramatically as m increases. When the number of keywords increases from 5 to 6, the running time doubles for S2I and I 3 . This is because as m increases, the number of documents (containing at least one of the query keywords) whose locations are near the query location also increases. Though many of these documents X  relevance scores are too low to be among the top-k results, they still need to be accessed. In comparison, TA, CA and RCA scale smoothly with m ; the pruning mechanism takes into account both spatial and textual relevance which is clearly more effective.
In the last experiment, we evaluate the effect of the weight  X  in the ranking function  X  on the performance. As  X  decreases, the spa-tial relevance plays a more important role in determining the final score. We can see from Figure 8(e) and 8(f) that the performance of S2I and I 3 improves significantly as  X  decreases. This is because S2I and I 3 examine documents near the query location first while the textual relevance is ignored. When  X  is 0 . 9, the textual rele-vance dominates spatial relevance and the spatial proximity is no longer important. However, S2I and I 3 access documents based on their distance to the query location. Even if the nearby documents are not textually relevant, they need to examine all of them. When  X  decreases, the spatial relevance becomes more important and the top-k results are more likely to be located around the query loca-tion. This is advantageous for the expansion strategy of S2I and I That X  X  why the running time of  X  = 0 . 1 is nearly two times faster than that of  X  = 0 . 9.

TA and CA are not sensitive to  X  . They build inverted lists sorted by textual relevance and spatial proximity. Hence, when the rank-ing function is biased on textual relevance, say  X  = 0 . 9, the most relevant documents are likely to appear in the front of the inverted lists sorted by textual relevance. Similarly, when  X  is small, the spatial proximity is more important and the documents close to the query location will be accessed first by TA and CA algorithms. RCA, however, is affected by  X  . When  X  decreases, its perfor-mance improves because its inverted lists on the spatial attribute are not strictly sorted by the distance to the query location. When  X  is small, the top-k documents are close and the spatial expansion on the z-order list can be terminated earlier.
In this paper, we process distance-sensitive spatial keyword query as a top-k aggregation query and present the revised TA and CA algorithm for query processing. Furthermore, we propose a rank-aware CA algorithm that works well on inverted lists sorted by tex-tual relevance and spatial curving order. We conduct experiments on Twitter dataset with up to 100 million geo-tweets. Our exper-imental results show that our proposed rank-aware CA scheme is superior over state-of-the-art solutions.
This work is funded by the NExT Search Centre (grant R-252-300-001-490), supported by the Singapore National Research Foun-dation under its International Research Centre @ Singapore Fund-ing Initiative and administered by the IDM Programme Office.
