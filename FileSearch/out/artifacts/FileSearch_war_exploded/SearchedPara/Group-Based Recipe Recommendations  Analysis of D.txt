 Collaborative filtering recommendations were designed pri-marily for individual user models and recommendations. How-ever, nowadays more and more scenarios evolve, in which the recommended items are consumed by groups of users rather than by individuals. This raises the need to uncover the most appropriate group-based collaborative filtering recom-mendation strategy. In this work we investigate the use of aggregated group data in collaborative filtering recipe rec-ommendations. We present results of a study that exploits recipe ratings provided by families of users, in order to evalu-ate the accuracy of several group recommendation strategies and weighting models, and analyze the impact of switching strategies, data aggregation heuristics, and group character-istics on the performance of recommendations.
 H.5.3 [ Information Interfaces and Presentation ]: Group and Organization Interfaces Algorithms, Design, Experimentation Recipe recommendations, group recommendations, collabo-rative filtering
The vast amount of digital information highlights the emer-gent need for personalized recommendation tools, which help users to identify the most relevant items. Collaborative fil-tering (CF) is one of the most widely-used statistical rec-ommendation techniques [10, 3]. It can predict the interest level of a user for a previously unrated item by aggregating opinions of similar users, who have already rated this item. Generally, CF is designed to aggregate opinions of individual users and produce individual recommendations.

However, as the use of recommender systems increases, we face more and more scenarios and application domains, in which the recommended items are inherently consumed by groups of users rather than by individuals. Consider music selection in public places [12], tourist attractions [1], holiday destinations [13], movies [15], and TV programs [16], as ex-amples of recommendations more suited to groups than to individuals. In these scenarios, the recommendations should be tailored to the entire group, to ensure maximum satisfac-tion of each member and the group as a whole.

To implement group recommendations using CF, it was proposed to aggregate the individual user data of the group members (either preferences or recommendations) into group-based data, and then use the aggregated data in the CF recommendation process [9]. Although group recommenda-tions are not as accurate as personalized ones, they have the potential to be more accurate than the general recommen-dations, which are the natural fall back when personalized recommendations are not achievable.

In this work we investigate the applicability of CF family-based recipe recommendations, a particular case of group recommendations, for the purpose of uncovering which strat-egy is most appropriate when generating CF recommenda-tions for a group. Recipe and food consumption are good examples of a group activity, as typically all family members eat a joint meal at least once a day. Hence, a system provid-ing recipe recommendations for a family should consider the preferences of all family members, satisfy each member to the maximal extent, while not recommending a recipe that will be completely rejected by a member.

We implemented four strategies and four weighting models for aggregating individual data into family-based data. We evaluated CF recommendations generated using the aggre-gated data against real-life recipe ratings, provided by fam-ilies interacting with experimental eHealth portal. The re-sults showed that the most appropriate family-based recipe recommendation strategy should (1) aggregate individual user models rather than individual recommendations, and (2) weight individual users according to their observed ac-tivity rather than according to pre-defined assumptions. We also analyzed the impact of switching strategies [5], data aggregation heuristics [11], and group characteristics on the performance of the generated CF recommendations.

Hence, the contributions of this work are two-fold. Firstly, we evaluate the performance of several CF group recommen-dation strategies and weighting models and uncover the most appropriate group-based strategy. Secondly, we analyze the impact of switching strategies, data aggregation heuristics,
Figure 1: Recommendation generation process and group characteristics on the performance of recommen-dations.

This paper is structured as follows. Section 2 overviews related group-based recommendation research. Section 3 presents the developed strategies and models. Section 4 dis-cusses the experimental results. Finally, Section 5 concludes the paper and outlines future research directions.
Due to the large number of activities, which users carry out as part of a group rather than individually, recommender systems research has embraced the topic of group-based rec-ommendations [9]. Group-based recommendations are per-tinent to many domains and applications, such as music [12], movies or TV programs [15, 16], tourism [1, 13], online com-munities [6], and others.

To date, group recommendations have been mostly gen-erated using two strategies: aggregating individual models into group models ( aggregated models ) or aggregating indi-vidual predictions into group predictions ( aggregated predic-tions ). These strategies differ in the timing of data aggre-gation step, as depicted in Figure 1. The aggregated mod-els strategy [7] merges individual user models into a group-based model and then generates recommendations using the aggregated group model. The aggregated predictions strat-egy [11] generated individual predictions and then aggre-gates the individual predictions into a group prediction.
As highlighted in [9], the selection between the aggre-gated models and the aggregated predictions strategies often depends on external considerations, such as the ability to negotiate group preferences, priorities and social dynamics, privacy constraints, and ability to explain the recommenda-tions. However, in many scenarios either strategy is applica-ble and, to the best of our knowledge, no prior research com-pares the recommendations generated using the two strate-gies. Hence, this work focuses on empirical evaluation and comparison of group-based recommendation strategies using a dataset of recipe ratings of real families of users.
The primary aim of this work is to uncover which strategy for data aggregation data and group recommendation gen-eration is most appropriate when dealing with groups that are made up of users within a nuclear family structure. We compare the four recommendation strategies shown in Figure 1. The general strategy exploits the wisdom of the crowd and recommends the most popular items. The aggre-gated models and aggregated predictions strategies exploit the two group-based recommendation algorithms. Finally, the personalized strategy exploits a standard CF algorithm.
The general strategy recommends most popular, i.e. , most highly rated, items to users [4]. Each unrated item item i assigned a prediction score pred ( item i ) based on the ratings rat ( u x , item i ) of n users in u x  X  U , who rated item shown in equation (1).
The group-based aggregated models strategy [2] initially computes a family rating rat ( f a , item i ) for family f item i by aggregating the individual ratings rat ( u x , item of family members u x  X  f a , who rated item i , according to their relative weight  X  ( u x , f a ), as shown in equation (2). Then, CF is applied to the family model, as shown in equa-tion (3). A prediction pred ( f a , item i ) for family f rated item item i is generated by computing similarity degree sim ( f a , f b ) between f a and all other families f b  X  F and aggregating family ratings rat ( f b , item i ) of families, which rated item i , according to the similarity degree sim ( f Finally, pred ( f a , item i ) is assigned to all family members, i.e. , pred ( u x , item i | u x  X  f a ) = pred ( f a , item
The group-based aggregated predictions strategy [2] ini-tially generates individual prediction pred ( u x , item i u x and unrated item item i using the standard CF algorithm, as shown in equation (4). The prediction is generated by computing the degree of similarity sim ( u x , u y ) between the target user u x and all other users u y  X  U and aggregating individual ratings rat ( u y , item i ) of users, who rated item according to the similarity degree sim ( u x , u y ). pred ( u x , item i ) = Then, the process becomes group-focused. To generate pre-diction pred ( f a , item i ) for family f a and item item ual predictions pred ( u x , item i ) of family members u are aggregated according to their relative weight  X  ( u x as shown in equation (5). pred ( f a , item i ) = Finally, pred ( f a , item i ) is assigned to all family members, i.e. , pred ( u x , item i | u x  X  f a ) = pred ( f a , item
The personalized strategy examines users individually, users regardless of their family membership using the standard CF algorithm [10]. For each user u x , unrated item item is assigned a predicted score pred ( u x , item i ) using the CF algorithm, as shown in equation (4).

In this work we consider the task of recommending top k items, i.e. , k items having the highest predicted scores, which maximize strategy generates one list of recommendations for all users, the group-based aggregated models and aggregated predic-tions strategies generate one list for each family, and the personalized strategy generates one list for each user.
When aggregating the data of individual users, it is nat-ural to allow for some users to have more influence than others. In this way, users who are seen to have authority or who are trusted, are treated differently in order to im-pact the recommendation process. Authority and influence can be determined either through explicit ratings or through implicit contribution or consumption measures. Hence, ag-gregated group-based data can be achieved by weighting the data of individual users accordingly.

We investigate four models for weighting user data. The first two are static and assign to users pre-defined weights. The uniform model weights users uniformly, i.e. ,  X  ( u x 1. The heuristic model is role-based, where a role refers to a user X  X  function within a family: applicant , partner , or child . The model presumes that  X  ( u x , f a ) is defined solely by the user X  X  role. An applicant X  X  weight is  X  ( u x , f a ) = 0 . 5, as they are likely to be highly engaged with the content, a partner X  X  weight is  X  ( u x , f a ) = 0 . 3, as they are likely to be reasonably engaged, and a child X  X  weight is  X  ( u x , f a ) = 0 . 1, as they are not likely to be engaged.

Two other weighting models are based on the observed user interactions with the content. The weights assigned to users reflect their activity act ( u x ), i.e. , number of ratings rat ( u x , item i ), as a predictor of their degree of engagement. The role-based model weights users according to the activity act ( u x ) of users in the same role across the entire community, as shown in equation (6). The family-log model weights users according to their activity act ( u x ) in relation to other family members u y  X  f a , as shown in equation (7).
It has been shown that in individual CF recommenda-tions, no single recommendation strategy is generally supe-rior to all others. On the contrary, the best performance is achieved when several strategies are hybridized in order to better match the recommendation request [5]. The hy-bridization can be achieved in many ways, e.g. , by merging the predicted scores, user features, or recommendation al-gorithms. We posit that this observation is true also in the group-based recommendations and hybridize the strategies presented in Section 3.1.

Initial evaluation of group recommendations showed that the personalized strategy achieved highest accuracy but low-est coverage, the general strategy achieved lowest accuracy but highest coverage, while the performance of the group-based strategies was moderate [2]. To hybridize these strate-gies, we developed a switching hybridization strategy, which  X  switches between recommendation techniques depending on the situation  X  [5]. The criterion for a strategy selection is the density of the users X  data 1 . We quantify the density de-gree dens ( u x ) as the ratio between the number of items that were rated by u x and overall number of items. Hence, the switching of strategies is defined as shown in equation (8). strat ( u x ) =  X  1 and  X  2 denote the density thresholds for switching be-tween the general and the group-based, and between the group-based and personalized strategies, respectively.
In case of extremely positive or negative data, the models presented in Section 3.2 may be inapplicable. For example, consider an extremely negative recipe rating provided by a family member. Even if the ratings of other members are positive, the recipe should not be recommended as the user is not likely to eat the recommended meal. Alternatively, if a family member provided extremely positive rating for a recipe, other family members may also like this meal 2 .
To prevent such situations, we enhance the weighting mod-els by introducing two data aggregation heuristics [11]. When aggregating the individual data into group-based data, the least misery heuristics assigns e  X  ( u x , f a ) = 1 to the user, who provided the extremely negative data, and e  X  ( u y , f 0 to other family members u y  X  f a . Otherwise, a nor-mal weighting model is applied. Note that the least mis-ery heuristics is applicable when aggregating both individual ratings rat ( u x , item i ) into family-based rating rat ( f (equation 2) and individual predictions pred ( u x , item family-based prediction pred ( f a , item i ) (equation 5). The least misery heuristics is defined as shown in equation (9).  X  denotes the threshold for considering a rating as extremely negative.
Similarly, we define the most pleasure heuristic. When aggregating the individual data into group-based data, the most pleasure heuristic assigns e  X  ( u x , f a ) = 1 to the user, who provided the extremely positive data, and e  X  ( u y , f 0 to other family members u y  X  f a . The most pleasure heuristics is defined as shown in equation (10).  X  2 denotes the threshold for considering a rating as extremely positive.
An evaluation was carried out using a dataset of explicit ratings for recipes, gathered during a study observing in-teraction of families with an experimental eHealth portal.
See [5] for other switching criteria.
Cases, in which one of the ratings is extremely positive and another extremely negative are out of scope of this work. The aim of the analysis was to uncover a recommendation strategy, which would be most appropriate to implement in a group-based recommender. Specifically, we aimed to compare the accuracy of two group-based recommendation strategies, four weighting models, and assess the impact of switching hybridization, extreme case heuristics, and group characteristics on the performance of group recommenda-tions. Partial results obtained for a substantially smaller dataset of implicit browsing logs were presented in [2].
The dataset was gathered over a three week period in July 2009. During this period a dataset of explicit symbolic rat-ings on a 5-Likert scale ranging from hate to love was cap-tured from participants for a corpus of recipes sourced from the CSIRO Total Wellbeing Diet book [14]. The symbolic ratings were converted into numeric ratings ranging from 1 to 5. Figure 2 depicts the rating interface.

Table 1 summarizes the dataset. The columns represent the overall number of users, overall number of families, num-ber of families in which n=1, 2, 3, or 4 users provided rat-ings 3 , number of recipes in the dataset, number of ratings captured, and density of the data (ratio between the number of captured and possible ratings). The distribution of recipe ratings was not uniform: 883 were rated hate , 1352 -don X  X  like , 741 -neutral , 254 -like , and 75 -love .
For each user/family, a one-off similarity matrix with other users/families was computed using Cosine Similarity [10]. Using these matrices, N=5 most similar users/families were selected, leave-one-out recipe rating predictions were com-puted, and recommendations were generated. The recom-mendations were evaluated against the ratings provided by individual users using the F1 , precision@k , Mean Absolute Error ( MAE ), and coverage metrics [8].

Let us denote by V the set of positive recipes rated neu-tral , like , or love , and by R the set of recipes with positive predicted scores of 3 or higher. Hence, precision of the rec-ommendations is computed by | V  X  R | | R | and recall by When the size of R is k , the precision metric is referred to as precision@k . Combining the precision and recall metrics
Families having 1 active user were excluded from the testing set and used only in the training set. yields the F1 metric, which represents their harmonic mean with equal weights, as shown in equation 11.

MAE is computed as the average difference between the predicted and provided rating for user u x and item item i normalized by the cardinality of the range of ratings R d [1 .. 5] in the dataset, as shown in equation 12. MAE = Another metric was the coverage of the recommendations. It reflects the relative portion of items, for which an algo-rithm successfully generated recommendations (regardless of their accuracy). It is computed by dividing the number of items for which a prediction was generated by the overall number of items in the dataset.
The first question relates to comparative performance of the recommendation strategies presented in Section 3.1 and, in particular, of the two group-based strategies. Table 2 presents the average predictive accuracy MAE score, clas-sification accuracy F1 score, and coverage obtained for the four recommendation strategies: general , aggregated models , aggregated predictions , and personalized . The right-most col-umn focuses on the group-based aggregated models and ag-gregated predictions strategies and presents whether the dif-ference between the two is statistically significant 4 . Uniform weighting is applied, i.e. ,  X  ( u x , f a ) = 1 .
The results show that the aggregated models strategy out-performed the aggregated predictions strategy across all met-rics: higher F1, lower MAE, and higher coverage scores. The difference was significant for F1 and MAE, respectively, p &lt; 0.05 and p &lt; 0.01, but not significant for coverage.
A single F1 score hides too much information about the classification accuracy. We measured precision-recall scores obtained by each user for each recommendation strategy. Figure 3 depicts overall polynomial regression curves of the strategies generated form the individual user scores 5 . The graph shows that the aggregated models strategy outper-formed the aggregated predictions strategy, as the former has a greater area under the curve than the latter. The difference was significant, p &lt; 0.01.
All statistical significance results hereafter refer to a two-tailed t-test assuming equal variances.
For the sake of clarity, we omit individual precision-recall scores and plot only the regression curves.
Figure 4 depicts the average precision@k scores obtained by the recommendation strategies for k  X  [1 .. 9]. The graph shows that for any value of k the aggregated models strat-egy obtained higher precision@k score than the aggregated predictions strategy. The difference was not significant.
In summary, all the comparisons between the group-based recommendation strategies show that the aggregated models strategy is superior to the aggregated predictions strategy. This is due to the reliable models that the aggregated mod-els strategy creates, which facilitate generation of accurate recommendations. Practically, this means that group-based recommendations should be generated by aggregating indi-vidual models into group models and then using these mod-els in the recommendation process.
The second question relates to comparative performance of the weighting models presented in Section 3.2 and, in particular, of the two interaction-based models. Table 3 presents the average predictive accuracy MAE score, clas-sification accuracy F1 score, and coverage obtained for the four weighting models: uniform , role-based , family-log , and heuristic . The right-most column focuses on the interaction-based role-based and family-log models and presents whether the difference between the two is statistically significant. The evaluation used the aggregated models recommendation strategy, which was discovered to be the most appropriate.
The performance of the models can be partitioned into two groups: static uniform and heuristic models and interaction-based role-based and family-log models. The results show that the interaction-based models outperformed the static models across both accuracy metrics: higher F1 and lower MAE scores. The impact of weighting models on the cover-age was negligible. Comparison of the two interaction-based models shows that the family-log model outperformed the role-based model model across both accuracy metrics: higher F1 and lower MAE scores. The difference was significant for MAE, p &lt; 0.05, but not significant for F1.

Similar to previous experiment, Figures 5 and 6 depict, respectively, the overall polynomial regressions curves of the discrete precision-recall scores and average precision@k scores obtained by the weighting models. Figure 5 clearly differen-tiates between precision-recall curves of static and interaction-based models. The interaction-based role-based and family-log models outperformed the static uniform and heuristic models. Comparison of the interaction-based models shows that family-log model outperformed the role-based model model. The difference was significant, p &lt; 0.05.
The difference between the precision@k curves of the mod-els in Figure 6 is less pronounced. For low k , the weighting models were comparable: for k = 1 all four models obtained a similar precision score. The models separated at k = 3 , with the static models becoming less accurate. Eventually, interaction-based models outperformed the static models, with the family-log model obtaining the highest precision@k score. The difference between the family-log and role-based models was not significant.

In summary, weighting models assigning weights accord-ing to the observed user interactions are superior to models assigning static weights. Between the two interaction-based models, the family-log model is superior to the role-based model. This is due to the localized nature of the family-log model, such that the weights reflect interactions observed within the family only, rather than within the entire com-munity. Practically, this means that the weights assigned to users X  data should reflect family-based or community-based interactions (in this order of priority), while prede-fined weighting models should be avoided.
The third question relates to the impact of the switching hybridization strategy presented in Section 3.3. In order to determine the switching thresholds  X  1 and  X  2 , we used the family-log weighting model, which was discovered to be the most appropriate, and compute for each user the MAE score for the four recommendation strategies: general , aggregated models , aggregated predictions , and personalized .
Figure 7 depicts overall polynomial regression curves of the strategies generated form the individual MAE scores. The users are arranged in increasing order of data density, i.e. , left-most users provided the lowest number of ratings and right-most  X  the highest . Behavior of the strategies is inline with previous CF research [10]. The MAE of the general strategy remains roughly unchanged, while that of the aggregated models , aggregated predictions , and personal-ized strategies decrease as the data density increases. Our aim, to uncover the most appropriate switching thresholds, should lead to a reduction in the overall MAE.

Initially, the aggregated predictions strategy demonstrates the lowest MAE outperforming the aggregated models strat-egy. We posit that this happens because the aggregation of individual predictions at this level of density is more accu-rate than the aggregated model of a family. At  X  1 = 5 rat-ings (corresponds to 12% density 6 ), the aggregated family models are sufficiently accurate and the aggregated models outperforms the aggregated predictions strategy. Finally, at  X  = 8 ratings (corresponds to 19% density), the individual user models are accurate enough and the personalized strat-egy outperforms the group-based strategies. The thresholds are marked in Figure 7 with vertical lines.
In a practical recommender system a user is unlikely to rate all the items. Hence, relative density of 100% refers the highest number of provided ratings (in our case  X  42).
We applied the derived  X  1 and  X  2 thresholds as the switch-ing criteria and evaluated the performance of the switch-ing strategy. Table 4 presents the average MAE, F1, and coverage scores obtained by the aggregated models strategy with the family-log weighting model (the most appropriate group strategy), the personalized , and switching hybridiza-tion strategy. The two right-most columns focus on the switching strategy and present whether the difference be-tween it and, respectively, the aggregated models and per-sonalized strategies, is statistically significant.
The results show that the switching strategy clearly out-performed personalized strategy. The differences in the ob-tained F1 and MAE scores were significant, p &lt; 0.05. Note the improvement obtained for coverage. It increased from 85.41% to 99.03%, showing that switching successfully ap-plied the group-based strategies, when the data were in-sufficient for personalized recommendations. The difference was significant, p &lt; 0.01. As expected, the switching strategy also outperformed the aggregated models strategy. The dif-ference in F1 and MAE was significant, respectively, p &lt; 0.01 and p &lt; 0.05. The difference in coverage was not significant.
In summary, the best performing switching strategy ap-plied the aggregated predictions strategy for the lowest den-sity of users data, then the aggregated models strategy, and the personalized strategy in the majority of cases. The switching strategy was discovered to be superior to all the individual strategies across both the accuracy metrics and obtained extremely high coverage of recommendations.
The fourth question relates to the impact of the least mis-ery and most pleasure heuristics presented in Section 3.4. Since the distribution of recipe ratings was not uniform, we considered the 254 like and the 75 love (in total, 329) rat-ings as extremely positives and randomly selected 329 (out of the 883) hate ratings as extremely negatives 7 . Hence  X  1 and  X  2 = 4 . Table 5 presents the average MAE, F1, and coverage scores obtained by the aggregated models strategy with the family-log weighting model (the most appropriate group strategy), and the same strategy using, respectively, the least misery and most pleasure heuristics. The two right-most columns focus on the heuristics and present whether the difference introduced by the heuristics is statistically sig-nificant.

Overall, the least misery and most pleasure heuristics de-crease the accuracy of recommendations. The F1 score de-creases (not significant for least misery , significance for most
Personalized extremeness thresholds will be investigated in the future. MP significance LM significance MP pleasure , p &lt; 0.05) and MAE increases (significance for both, p &lt; 0.05). The coverage also decreases, but not significant for both the heuristics.

Breaking down the F1 score into precision and recall, we observed that the least misery heuristic affected the recall of recommendations. This is due to the fact that a user X  X  posi-tive rating for a recipe could be outweighed by an extremely negative rating of another family member, which prevents this recipe from being recommended and decreases the re-call. On the contrary, the most pleasure heuristics affected the precision, as some negatively rated recipes could be rec-ommended to a user due to an extremely positive rating from another family member. The decrease in recall for the least misery heuristic and of precision for the most pleasure heuristics were significant, p &lt; 0.05.

The accuracy decrease, however could be balanced by a higher user appreciation of recommendations, which is not measurable in an offline evaluation. For example, in the least misery heuristics, recipes hated by a group member are un-likely to be recommended to others, which may increase sys-tem trust. Similarly, in the most pleasure heuristics, recipes loved by a group member are likely to be recommended to others, which may increase serendipity.

In summary, the extreme case heuristics negatively af-fected the accuracy of recommendations. However, they have the potential to positively affect user appreciation and serendipity of the recommendations provided by the system, which could not be measured in our evaluation. We posit that the heuristics can be applied when the degree of confi-dence in the recommendation list is high, such that remov-ing certain items will not severely damage it, but including certain items can potentially sustain user engagement.
The fifth question relates to the differences in the per-formance of the recommendation strategies across various groups. In particular, we evaluate the impact of two group characteristics on the accuracy of generated recommenda-tions: size and homogeneity of a group. In both cases, we used the family model strategy and family logs weighting model, as it was discovered to be the most appropriate group strategy.

Firstly, we analyze the dependency between the size of a family and accuracy of recommendations. Figure 8 shows the average MAE scores obtained for various families. The families are arranged in a decreasing order of MAE, and are color-coded according to the number of members: white bars represent 2 user families, grey  X  3 user families, and black  X  4 user families. The accuracy of recommendations mainly increases with the family size. Most families with high MAE are 2 user families, while more 3 and 4 user fami-lies, i.e. , more grey and black bars, occur as MAE increases. The correlation between the MAE score and the number of family members is  X  0 . 644. Hence, the accuracy of recom-mendations improves with the number of family members and amount of data available, as the data of large families are denser than of small families.

Secondly, we analyze the dependency between the simi-larity of family members and accuracy of recommendations. Figure 9 shows the MAE scores obtained for various families as a function of the average similarity of family members. The accuracy of recommendations increases with the simi-larity of members: MAE of families having low similarity of members is high and it decreases as the similarity increases. The correlation between the MAE score and the average similarity is  X  0 . 628. Hence, the accuracy of recommenda-tions improves with similarity of members and homogeneity of families, as the data of homogeneous families are more reliable than of non-homogeneous families.

In summary, the performance of group-based recommen-dations was discovered to depend on group characteristics. Particularly, the accuracy of recommendations increases with the size an homogeneity of groups.
With the dissemination of recommender technologies, more and more scenarios evolve, in which group-based recommen-dations, addressing a group of users rather individuals, need to be provided. This work focuses on family-based CF recipe recommendations, a particular case of group recommenda-tions. The grouping of family members in this case is inher-ent, while recipes offer a natural case for group recommen-dations, as family members consume joint meals. Hence, a family-based recipe recommender should consider and sat-isfy preferences of all the members and not recommend a recipe that is likely to be rejected by some.

In this work we focused on uncovering the most appropri-ate group recommendation strategy and this was achieved in several steps. First, we focused on the most appropriate recommendation strategy and user weighting model. Our evaluation showed that the best performance of group rec-ommendations is obtained when individual user models are aggregated into group-based models, which are then used in the recommendation process. The individual data of group members need to be aggregated in a weighted manner, such that the weights reflect the observed interaction of group members, focusing on interactions observed with as local-ized as possible boundaries.

Also, we evaluated a switching hybridization strategy, which selects a recommendation strategy to apply according to the user data density. The results showed that the accuracy of the switching strategy is superior to all individual recom-mendation strategies, and it demonstrated very high cover-age score. Next, we evaluated the performance of two ex-treme case heuristics. These were discovered to decrease the accuracy of recommendations, but could potentially improve user appreciation and sustain user engagement. Finally, we discovered that the performance of group-based recommen-dations depends on group characteristics, in particular, on the size and homogeneity of the groups.

Hence, when generating group-based CF recommenda-tions, the system should initially determine the recommen-dation strategy to apply. If the available user data are sufficient, personalized CF recommendation should be ap-plied. Otherwise, a group-based strategy should be applied as follows: (1) individual user models of the group members should be aggregated into group-based models, (2) weights assigned to individual user models should reflect the ob-served importance of users, (3) the aggregated models should be used in a family-based CF recommendation process, and (4) group-based recommendations should be delivered to the group members. When aggregating individual models, ex-treme case heuristics can be applied. Although the latter can slightly decrease the accuracy of recommendations, they can increase user appreciation and system trust.

In the future, we plan to investigate sequential group-based recommendations. Often, recommendations are not provided on an ad-hoc basis, but users have prolonged in-teractions with the system. It is important to handle such interactions differently, e.g. , compensate users, whose satis-faction was low in past interactions. Also, we plan to in-vestigate group-based dynamics. Different groups may have complex social intra-group relationship. We will investigate how these relationships, e.g. , roles, dominance, and decision taking, affect group recommendations. Finally, we plan to conduct a similar evaluation in other domains to verify that the outcomes of this work are generalizable.
This research is jointly funded by the Australian Govern-ment through the Intelligent Island Program and CSIRO Preventative Health Flagship. The Intelligent Island Pro-gram is administered by the Tasmanian Department of Eco-nomic Development, Tourism, and the Arts. The authors thank Mac Coombe, Dipak Bhandari, Greg Smith, Nilufar Baghaei, and Stephen Kimani for their help with the devel-opment of the experimental eHealth portal. [1] L. Ardissono, A. Goy, G. Petrone, M. Segnan, and [2] S. Berkovsky, J. Freyne, and M. Coombe. Aggregation [3] S. Berkovsky, T. Kuflik, and F. Ricci. Distributed [4] P. Brusilovsky, G. Chavan, and R. Farzan. Social [5] R. D. Burke. Hybrid recommender systems: Survey [6] Y.-L. Chen, L.-C. Cheng, and C.-N. Chuang. A group [7] J. Freyne and B. Smyth. Cooperating search [8] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and [9] A. Jameson and B. Smyth. Recommendation to [10] J. Konstan, B. Miller, D. Maltz, J. Herlocker, [11] J. Masthoff. Group modeling: Selecting a sequence of [12] J. F. McCarthy and T. D. Anagnost. Musicfx: An [13] K. McCarthy, L. McGinty, and B. Smyth. Case-based [14] M. Noakes and P. Clifton. The CSIRO Total [15] M. O X  X onnor, D. Cosley, J. A. Konstan, and J. Riedl. [16] Z. Yu, X. Zhou, Y. Hao, and J. Gu. Tv program
