 In recent years, there has been a lot of research on wide-coverage statistical natural language processing with linguistically expressive gram-mars such as Combinatory Categorial Grammars (CCG), Head-driven Phrase-Structure Grammars (HPSG), Lexical-Functional Grammars (LFG) and Tree-Adjoining Grammars (TAG). But al-though many young researchers in natural lan-guage processing are very well trained in machine learning and statistical methods, they often lack the necessary background to understand the lin-guistic motivation behind these formalisms. Fur-thermore, in many linguistics departments, syntax is still taught from a purely Chomskian perspec-tive. Additionally, research on these formalisms often takes place within tightly-knit, formalism-specific subcommunities. It is therefore often dif-ficult for outsiders as well as experts to grasp the commonalities of and differences between these formalisms. This tutorial overviews basic ideas of TAG/ CCG/LFG/HPSG, and provides attendees with a comparison of these formalisms from a linguis-tic and computational point of view. We start from stating the motivation behind using these ex-pressive grammar formalisms for NLP, contrast-ing them with shallow formalisms like context-free grammars. We introduce a common set of examples illustrating various linguistic construc-tions that elude context-free grammars, and reuse them when introducing each formalism: bounded and unbounded non-local dependencies that arise through extraction and coordination, scrambling, mappings to meaning representations, etc. In the
