 Cloud computing represents one of the most important research di-rections for modern computing systems. Existing research e on Cloud computing were all focused on designing advanced stor-age and query techniques for static data . None of them consider the problem that data in a Cloud may appear as continuous and rapid data streams . To address this problem, in this paper we pro-pose a new LCN-Index framework to handle continuous data stream queries in the Cloud. LCN-Index uses the Map-Reduce computing paradigm to process all the queries. In the Mapping stage, it di-vides all the queries into a batch of predicate sets which are then deployed onto mapping nodes using interval predicate index .In the reducing stage, it merges results from the mapping nodes using multi-attribute hash index . In so doing, a data stream can be e ciently evaluated by traversing through the LCN-Index framework. Experiments demonstrate the utility of the proposed method. H.2 [ Information Systems ]: DATABASE MANAGEMENT; H.2.4 [ Systems ]: Query Processing Algorithms, Design Cloud, Data Stream, Index
Cloud service has drawn increasing attention in recent years. A wide spectrum of commercial applications, such as Google Docs, Amazon WebStore and Facebook, are using Cloud as their funda-mental solution for the unprecedented amount of data problem [5, 6, 9, 10, 1].

Although the successes of Cloud systems, existing research ef-forts were merely focused on static data queries in the Cloud. For many emerging applications where data appear as continuous data Figure 1: An illustration of the online tra ffi c management sys-temusedinExample1. streams , it is urgent to design stream-based query techniques for the Cloud systems.

E xample 1. Let us consider an online tra ffi c management sys-tem as shown in Fig. 1. The essential goal of the system is to pro-vide real-time tra ffi c information for all connected users. In this system, on one hand, real-time tra ffi c conditions are monitored by on-street cameras and uploaded to servers deployed in the Cloud; on the other hand, users can submit queries to the system, and get continuous real-time tra ffi c information from the system. Note that di ff erent users have di ff erent levels of services. A VIP user can get much richer information in a more friendly way than a free user, even if they both submit the same query. For example, the system will return a VIP user a virtual electronic map with some recom-mendations. In contrast, a free user can only get a textual descrip-tion.

Obviously, the above example represents a new class of data stream applications in the Cloud. Compared to traditional data stream query and distributed stream query, data stream query in the Cloud faces the following new challenges: In light of the above challenges, in this paper we design a new LCN-Index framework for the stream queries in the Cloud. LCN-Index is on the basis of the Map-Reduce computing paradigm. In the Map stage, it decomposes all the queries into a batch of pred-icate sets which are then deployed onto mapping nodes using the interval predicate index. In the Reduce stage, it merges the interme-diate results from all the mapping nodes using multi-attribute hash index. In addition, the LCN-Index can dynamically add (or delete) computing nodes during processing. In so doing, data streams can be e ffi ciently evaluated under the LCN-Index framework. Experi-ments demonstrate the utility of the proposed method.

The main contributions of the study are threefold: 1. We address a new problem of continuous data stream query 2. We propose a new scalable index framework, LCN-Index, to 3. We conduct empirical studies to demonstrate the utility of the
The rest of the paper is organized as follows. Section 2 intro-duces the LCN-Index framework. Section 3 studies the perfor-mance of LCN-Index. Section 4 conducts experiments and com-parisons. We conclude the paper in Section 5.
Consider n continuous queries Q = { Q 1 , Q 2 ,  X  X  X  , Q n on a data stream S = { T 1 ,  X  X  X  , T k ,  X  X  X } . Assume each stream tuple T has d dimensions { r 1 , r 2 ,  X  X  X  , r d } , where each r j and u j are the lower and upper boundaries. Besides, assume each query Q i (1  X  i  X  n ) spans over all the d dimensions, i.e., Q { given boundaries. The ultimate goal is to e ffi ciently evaluate all the n queries with respect to each stream tuple T k  X  S .

To achieve the above goal, we propose a new data stream query system in the Cloud as shown in Fig.2. The system consists of two components: an o ff -line index construction part, and an on-line stream processing part. In the o ff -line part, the n continuous queries are decomposed into predicate sets that are then indexed on both Mapper (using predicate index) and Reducer (using multi-attribute hash index). In the on-line part, to evaluate all the queries with respect to each stream tuple, LCN-Index first retrieves from the mapping nodes all the matched predicates, which are then merged together on the Reducer using multi-attribute hash index. Figure 2: An illustration of the data stream query system in the Cloud.
 The whole procedure of the LCN-Index framework is shown in Algorithm 1. The key step of the algorithm is to index the inter-val predicates that are deployed on the mapping nodes. An intu-itive method is to compare each attribute value with the boundaries of all the predicates, which needs O ( log ( n )) time, where n is the number of predicates. Obviously, this is time-consuming when the query number is very large. Thus, we use a new indirect index-ing approach instead. This method is based on the Standard Inter-val Unit (SIU for short) [1]. First of all, a set of SIU is predefined and labeled, and then each predicate is split into a couple of SIUs. Each predicate will be assigned a unique ID, named PredId ,which are then inserted into the Id Listes associated with the decomposed SIUs. Given an attribute value X , the search procedure can be ex-ecuted indirectly by using the SIUs. In so doing, the search time will be independent of the number of predicates, and it is unneces-sary to compare each attribute value of X with all the predicates X  boundaries.
 Algorithm 1 The workflow of the LCN-Index Framework
Now we explain how to partition each attribute of a query Q into a predicate set for e ffi cient search. For each attribute r j (1 j  X  d ) in a query, we partition r j into r / L segments, where L is a predefined length. Thus, each segment can be denoted as s i a(2 L  X  1) Standard Interval Unit(SIU) as follows: (1) Use only one SIU with length L to describe the entire segment; (2) Partition the segment into two SIUs, each having length L (3) Build four SIUs, each having a length of L / 4; (4) Each SIU have the shortest length of 1.

Fig. 3 gives an illustration of the local ID labeling on each in-terval predicate. The unit-length is set to L = 2 k . The interval is divided into unit-length segments. In each segment, 2 k  X  Figure 3: An illustration of the labeling on a predicate interval. built for indexing. The local IDs of all these SIUs range from 1 to (2
On the other hand, the Reducer merges all intermediate search results from Mappers. The merging algorithm uses the multi-attribute hash index. For each incoming stream tuple, the multi-attribute in-dex can help find all the satisfied queries e ffi ciently and accurately. In this index structure, the equality predicates are used as trigger predicates. A trigger predicate p is associated with a list of query clusters. When an equality predicate is triggered, all the queries as-sociated with the trigger predicates will be examined. In addition, a bit vector is used to record results of all predicates. The query clus-ters examine all satisfied queries sharing the same predicates. In so doing, for each incoming intermediate search result from Mapper, its attribute ID will be examined in the multi-attribute index. If all the predicates of a query are estimated TRUE, this query will be taken as matched with respect to the current stream tuple.
Fig.4 describes a query cluster for queries sharing the same e-quality predicate p . A query cluster is a vector of query structures. It consists of a collection of all predicate results and a bit vector which denotes the identifier of the query. An Entry [ i , attribute in the query cluster. If all the bit vector entries are estimat-ed TRUE, the j th attribute in query cluster will be taken as TRUE.
In this section, we analyze time and memory costs for evaluating each stream tuple. When a tuple arrives, it needs to go through the whole LCN-Index framework to answer all registered queries. Since the merging operation dominates the query time, we mainly discuss the time cost from this step.

Formally, consider a query set Q , a query cluster C generated from Q , and a multi-attribute hashing function H . The cost of merging a stream event with respect to all queries in Q needs the following three steps: (1) retrieving relevant multi-attribute index results for the incoming stream tuple. (2) hashing each indexes using H . (3) examining all mapping functions between the triggering predi-cates and queries.

To sum up, the processing time can be described in Eq. (1): sum = idx _ scanning ( H ) + where idx _ scanning ( H ) is the cost from scanning the multi-attribute indexes, hashing ( h ) is the cost from executing a hashing function h  X  H ,and sccanning ( p , Q ) is the cost from trigger predicates p .
In order to solve Eq. (1), without loss of generality, we make the following three assumptions.
 (1) retrieving the relevant indexes needs a linear time with respect to the number of Hashing Combination . (2) the hashing function takes linear time with respect to the size of the Hashing Combination . (3) examining a set of queries has a linear time complexity with respect to the number of queries.

Under these assumptions, Eq. (1) can be converted to Eq.(2), sum = | H | X  C idx + where C idx is the average size of each multi-attribute index, A ( h ) represents the size of the schema of h .  X  p represents the popularity of the trigger predicate p ,  X  p is the width of trigger predicate p ,and n is the scale size of the query set Q .

The memory cost of the merging algorithm on query set Q main-ly comes from the following two parts: (1) the cost from bu ff ering the hashing indexes. (2) the cost from storing the mapping functions between predicates and queries.

To sum up, the memory cost can be described in Eq.(3) as follow, sum = where M init is the initial memory to create an empty multi-attribute index, M insert is the space for maintaining all entries of the trigger predicates, and M mapping denotes the memory cost from storing the mapping information between trigger predicates and queries set
Our testing infrastructure consists of 16 Redhat server 5.2 sys-tems. Each machine has a 3.00GHz Inter Core2 CPU and 4G mem-ory. The last system is used as the master.
 Benchmark data Three real world data sets are used. Table 1 lists the real world data sets. Al l these data sets were crawled from Internet. Due to space limitation, we omit the detailed introduction here. All queries are generated using Zipf distribution, under which the popularity of a predicate is inversely proportional to its rank. Benchmark methods &amp; Measures A distributed multi-dimension index, which is similar to R-Tree [7, 11, 12], denoted by Dis-tributeRTree , is used as the benchmark method. Each query is taken as a multi-dimensional matrix and inserted into the tree.
Figure 5: Comparisons under di ff erent attribute numbers. Figure 6: Comparisons with respect to di ff erent (a)query num-ber, (b) Cloud size, and (c) query width.
 Experimental results In our experiments, the default node number is 100. The number of queries is set to 10 million.

Query number Fig.6 (a) shows comparisons with respect to dif-ferent query numbers. Obviously, our LCN-Index always performs better than the DistributeRTree. In LCN-Index, each stream tu-ple will be processed on multiple mapping nodes in a parallel way. However, in the DistributeRTree, the parallel search is inapplicable, because the query is represented by a matrix and has been randomly distributed in the Cloud.

Node number From Fig.6 (b), we can observe that when the number of computing node increases, LCN-Index outperforms Dis-tributeRTree. For example,in the stock data stream, when the com-puting node n equals to 1000, DistributeRTree outputs 379,166 tu-ples, whereas the LCN-Index emits as much as 772,937 tuples.
Attribute numbers Fig.5 shows the comparisons with respect to di ff erent attribute numbers. We can observe that the cost of the LCN-Index framework decrease with respect to the discrete at-tribute number. This is because LCN-Index can be estimated in a parallel way, and is impervious to the number of continuous at-tributes.

Query width The comparison results are listed in Fig.6 (c). From the results, we can come to several important conclusions: (1) LCN-Index can significantly reduce the query costs in terms of both time and memory. (2) when increasing w , the cost of Dis-tributeRTree increases faster than that of LCN-Index.
Cloud data stream query is a challenging problem. In this paper we propose a new LCN-Index framework to support a huge num-ber of complex stream queries in the Cloud. LCN-Index uses the Map-Reduce computing paradigm to organize all the queries. In so doing, a data stream can be e ffi ciently evaluated by traversing through the LCN-Index framework. Experiments on real world da-ta streams demonstrate that our approach is e ffi cient, elastic, and scalable.
This research was supported by the National Science Founda-tion of China (NSFC) under Grant No. 61003167, Basic Research Program of China (973 Program) under Grant No. 2007CB311100. [1] D.J.A.A.R.A.Abouzeid,K.Bajda-Pawlikowskiand [2] R. Avnur and J. Hellerstein. Eddies: Continuously adaptive [3] S. Babu and J. Widom. Streamon: An adaptive engine for [4] J. W. Chris Olston, Jing Jiang. Adaptive filters for continuous [5] J. W. et al. Indexing multi-dimensional data in a cloud [6] S.W.etal.E ffi cient b-tree based indexing for cloud data [7] A. Guttman. R-trees: A dynamic index structure for spatial [8] F. Y. J.Chen, D. J.DeWitt. Niagracq : A scalable continuous [9] J.Dean and S.Ghemawat. Mapreduce: Simplified data [10] P.-A.L.B.R.D.S.S.W.R.Chaiken,B.Jenkinsand [11] P. Zhang, J. Li, P. Wang, B. Gao, X. Zhu, and L. Guo. [12] P. Zhang, X.Zhu, Y. Shi, L.Guo, and X. Wu. Robust
