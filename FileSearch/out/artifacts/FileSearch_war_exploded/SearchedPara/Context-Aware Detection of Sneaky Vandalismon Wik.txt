 Khoi-Nguyen Tran 1( Wikipedia is the largest free and open access online encyclopedia that attracts tens of thousands volunteer editors 1 and tens of millions of article views every day [ 19 , 20 ]. The open nature of Wikipedia also facilitates many types of vandals that deliberately make malicious edits, such as changing facts, inserting obscen-ities, or deleting text. To combat vandalism, editors repair vandalised articles with an edit that removes the vandalised text or with a revert back to a pre-vious revision, and commonly leave a comment indicating a repair. Wikipedia distinguishes many types of vandalism on its policy articles practice guides to counter vandalism. have reduced the exposure time of vandalism and the extra work needed by editors to repair vandalism [ 8 , 11 ]. Vandalism detection research has introduced new techniques that improve the detection rate. These techniques often focus on developing features as input to machine learning algorithms [ 10 , 22 , 23 ]. A variety of features based on the metadata, editor characteristics, article structure, and content of Wikipedia articles have shown to be effective in distinguishing normal revisions and revisions containing vandalism [ 19 , 20 ]. As new vandalism detection techniques are integrated into counter-vandalism bots on Wikipedia, vandalism of article content continues to become more sophisticated to avoid detection. may be using concealment techniques such as pretending to revert vandalism while introducing vandalism, or subtle changes in the article text that aim to deceive other editors to be legitimate changes. Subtle changes can be identified as vandalism because they may break the consistency of text used in other articles or past revisions, deviate from common or correct grammatical structure, introduce uncommon word patterns, or change the meaning of a sentence. Text features used in vandalism research do not inherently capture the context of the sentences being edited as they do not consider word dependencies [ 16 ]. context-aware by considering word dependencies. Our technique focuses on a particular type of sneaky vandalism, where vandals make sophisticated modifi-cations of text that change the meaning of a sentence without obvious markers of vandalism. We use a part-of-speech (POS) tagger [ 17 ] to tag types of words in sentences changed in each edit, and conditional random fields (CRF) [ 12 , 13 ] to model dependencies between tags to identify vandalised text.
 Wikipedia, but seem normal with respect to the text features used in vandal-ism detection research. We evaluate our technique on the PAN data sets with over 62,000 edits, commonly used by related research; and the full vandalism repairs data sets with over 500 million edits of over 9 million articles from five languages: English, German, Spanish, French, Russian. As a comparison, we implement a feature engineering classifier, and analyse both classification results and the trade-offs of each type of classifier. Our results show how context-aware detection techniques can become a new state-of-the-art counter-vandalism tool for Wikipedia that complements current feature engineering based techniques. tion technique; (2) demonstrating how our technique is scalable to the entire Wikipedia data set; (3) demonstrating the cross language application of classifi-cation models and the relationships between the languages considered; (4) repli-cating our experiments on the smaller PAN data sets often used in related work; and (5) demonstrating how our technique differs and contributes to traditional feature engineering approaches. These contributions backed by our results show how context-aware detection techniques can become a new counter-vandalism tool for Wikipedia that complements current feature-based techniques. The interpretation of vandalism differs amongst Wikipedia users, which can lead to incomplete or inconsistent labelling of vandalised revisions. [ 15 ] developed two corpora by crowd-sourcing votes on whether a Wikipedia revision contains vandalism using Amazon X  X  Mechanical Turk. The PAN workshops in 2010 and 2011 held competitions to encourage development of machine learning based vandalism detection techniques.
 For the PAN 2010 data set, Mola-Velasco [ 14 ] uses a set of 21 features to detect vandalism, which resulted in a first place ranking at the PAN 2010 com-petition. Adler et al. [ 2 ] improve on this winning entry by adding metadata, text, user reputation, and language features, totalling 37 features. Javanmardi et al. [ 10 ] further improve the classification results by introducing 66 features and applying feature reduction. For the PAN 2011 data sets, West et al. [ 23 ] develop 65 features that include many of the features from the entries from the PAN 2010 competition. The PAN data sets continue to be used to evaluate van-dalism detection techniques after the workshops were held, with other types of features, such as syntactic and semantic features [ 21 ], statistical models of words and editor actions [ 5 ], or styles of words [ 9 ].
 Other vandalism techniques used their own data sets constructed from sam-pled articles and revisions, or from a smaller Wikipedia [ 4 , 22 ]. Two vandalism detection techniques that are most similar to our work look at the relationship of words over time, and co-occurrence of pairs of words. Wu et al. [ 24 ] present a text-stability approach to find increasingly sophisticated vandalism. This technique builds on ideas presented in Adler et al. [ 1 ]onthe longevity of words over time to determine the probability that parts of an article will be modified by a normal or a vandal edit. Ramaswamy et al. [ 16 ]propose two metrics that measure the likelihood of words contributed in an edit of a Wikipedia article belonging to that article with respect to the article X  X  content and topic. The numerous words and word pairs resulting the data processing mean both techniques could only be evaluated using articles sampled from the PAN 2010 data set. Our work presents a feasible approach to context-aware van-dalism detection with demonstrative evaluation on the full Wikipedia vandalism repairs data sets and all PAN data sets.
 Overall, a variety of vandalism detection techniques has been developed and evaluated on different data sets, where many techniques are now evaluated on the PAN data sets. We show in our work that one of the many problems with using small data sets (the PAN data sets contain only around 2,000 vandalised edits) is that there are insufficient numbers of vandalism cases available for our classifiers  X  both context-aware and feature engineering  X  to effectively distin-guish vandalism. Many features presented in related work show good classifi-cation performance on the PAN data sets, but they need to be evaluated on the full Wikipedia data set to truly gauge their effectiveness in distinguishing vandalism. Furthermore, while counter-vandalism bots have a strong presence on Wikipedia since 2006 [ 3 , 7 ]  X  especially in the English Wikipedia  X  they are not well represented in the PAN data sets.
 We downloaded the first Wikipedia data dump available in 2013 and use all revisions of encyclopedic articles from 2001 to December 31st 2012 (our cut-off date) for the five languages English (en), German (de), French (fr), Spanish (es), and Russian (ru). When vandalism is discovered and repaired, the edi-tor usually leaves a comment in the repaired revision with keywords indicating a repair of vandalism, such as  X  X vv X  (revert due to vandalism),  X  X andalism X ,  X ...rv...vandal... X , and analogues in the other languages.
 the size of the revision content by using the Python unified diff to obtain only the sentences (marked by a period) that were changed by an edit. We reason that changes within existing sentences are more difficult to find than additions or removals of text that are relatively easier types of vandalism to detect. For each sentence changed, we perform a sentence diff (subtracting common words) to obtain the words that were repaired in the vandalism case, and label each word with  X  n  X  (normal) or  X  v  X  (vandal).
 processing (named  X  X iki X ) for the full Wikipedia, and the PAN data sets. We map these sentences to their edits to manually verify correctness, and com-pare classification results with a text-feature based detection technique. We find approximately 1.9% of all edits on the English encyclopedic articles are repairs of vandalism, which is consistent with results from Kittur et al. [ 11 ]. The PAN data sets show a higher percentage of vandalism because they estimate all vandal edits, whereas we are interested only in edits that repair vandalism. present a running example in Fig. 1 that continues in Figs. 2 and 3 . We process the labelled sentences further and tag each word with descriptive information that allows our context-aware classifier to exploit contextual infor-mation. We use part-of-speech (POS) tags provided by the TreeTagger where the aim is to place words from a text corpus into text categories [ 17 ]. Tree-Tagger uses binary decision trees to estimate the transition probabilities of POS tags and select the most appropriate tag from the available training data. For each sentence in our data sets, a POS tagger analyses known words (trained from a large manually labelled corpus) and assigns each word the most probable tag that describes it. In sneaky vandalism cases on Wikipedia, small changes can alter the meaning of sentences while not disrupting the correctness of text patterns in words (spelling) or sentences (grammar).
 Our example in Fig. 1 illustrates this sneaky vandalism case, where in Fig. 2 , we show the output of the tagging by TreeTagger. We describe only the tags rel-evant to our example from the full English tag set documentation conjunction (CC), preposition or conjunction (IN), adjective (JJ), adjective -comparative (JJR), noun (NN), noun -plural (NNS), to (TO), verb -base form (VB), verb -past participle (VBN), verb -3rd person (VBZ). We train the CRF classifier on these tag sequences to predict the sequence of labels. Context-aware detection techniques are needed because some types of vandalism cannot be easily detected with feature engineering approaches [ 16 ]. Our running example illustrates a case of potential vandalism that would likely require a human editor to repair, because there are no clear markers of vandalism such as vulgarities, odd letter patterns in words, or radical changes to text. a probabilistic undirected graphical model for segmenting and labelling sequence data. The full development and derivation of CRF are given by Lafferty et al. [ 13 ], and additional models and discussion by Sutton and McCallum [ 18 ]. tence) and its word labels l =( l 1 ,l 2 , ..., l n ) (i.e. n or v ) and word tags t = ( t ,t 2 , ..., t n ) (given by the POS tagger). To exploit the contextual information of the sequence of word tags, we define three binary feature functions f h j  X  on the training data sets  X  for three separate experiments: f The feature functions f j , g j ,and h j return 1 when certain conditions  X  as learnt from the data set and explained below  X  are met, and 0 otherwise. This means for each tag, we define features that express some characteristics of the model only with its current label ( f j ), with the labels of the two adjacent tags ( g or the four (two on each side) adjacent tags ( h j ). We choose these number of adjacent tags to explore the benefits of context to detecting vandalised words. from the training data sets through maximum likelihood estimation. This creates a language model for each word from the surrounding words. Now, we can score a labelling l of tags t by summing the weighted features for each tag: Note that feature function f j can be interchanged with g priate function parameters. Then we transform the scores into probabilities sim-ilar to the joint distribution of HMMs [ 18 ]: where Z is a normalisation constant to keep p ( l , t ) between 0 and 1, which is cancelled in the fraction of the next step below.
 tribution as a linear-chain CRF [ 18 ]: The training phase above gives us a model of the many sentences in each Wikipedia data set. To predict the labels ( n or v ) of a new input set of tags t (e.g. POS) extracted from an unseen sentence, we compute: which gives us the predicted tags (e.g. POS), which are combined with the true labels, POS tags, and words of the sentence.
 An advantage to using CRF in our application is the diversity of word labels that allow immediate identification of vandalised words for evidence or manual verification. A disadvantage of CRF is the potential slow convergence of training models when the feature functions are complex or have strong dependencies [ 18 ]. We use an open source implementation of CRF by Kudo [ 12 ], named CRF++, to evaluate our vandalism detection technique. We process our data further as required by CRF++ and recover classification results of test sentences for each edit for further evaluation. Our resulting testing data sets resemble our example below in Fig. 3 , where we can now evaluate classification performance. We split each data set by the number of edits for 10-fold cross-validation. We perform sampling for the Wikipedia repairs data sets with different ratios of normal edits to vandal repair edits to investigate the effects of class imbalance and data sampling for context-aware classification techniques. For example,  X 2-to-1 X  means 2 normal edits for every 1 vandal repair edit.
 We present our classification results compactly by plotting the area under the precision-recall (PR) curve (AUC-PR) against the area under the receiver-operator characteristic (ROC) curve (AUC-ROC) [ 6 ]. The AUC-PR score gives the probability that a classifier will correctly identify a randomly selected pos-itive sample (e.g. vandalism) as being positive. The AUC-ROC score gives the probability that a classifier will correctly identify a randomly selected (positive or negative) sample. Both scores range from 0 to 1, where a score of 1 means 100% or complete correctness in labelling all samples considered by the measures. 6.1 CRF with POS Tags The CRF classifier in our first set of results is trained and tested on the same source and target language, or named as  X  X ithin X  language classification. CRF classification results for the PAN data sets are presented in Fig. 4 and for the Wikipedia vandalism repairs data sets in Fig. 5 .
 consistent AUC-ROC scores for each data set. The 2010 English data set (2010-en) shows consistently high results for both AUC-PR and AUC-ROC scores compared to the 2011 data sets. Combining all 2011 data sets ( X  X ll X ) shows an average of the results for each 2011 data set.
 AUC-PR and AUC-ROC scores than the PAN data sets for each ratio of sampled data sets. Non-English Wikipedias have much higher scores than the English Wikipedia, suggesting vandalism in non-English Wikipedias more often break sentence structure detectable through changes in the sequence of POS tags. The different feature functions show minor improvements to AUC-PR and AUC-ROC classification scores, similar to the PAN data sets. Combining all data sets ( X  X ll X ) shows scores highly similar to the English (en) results because of the overwhelming number of English vandalism cases as seen from Table 1 . 6.2 Reusing Models Across Languages We investigate the cross-language performance of our context-aware technique, where Wikipedia vandalism detection models are trained on one language and reused to classify on other languages. The definition of CRF does not include a model for the probability of tags p ( t ) 6 , which makes CRF suitable for classifying unseen tags [ 18 ].
 For a target language, we reuse the CRF models trained in other languages. For example, for the English (en) target language, we reuse the German (de), Spanish (es), French (fr), and Russian (ru) models, and report the average and one standard deviation of these classification scores. Our results are in Fig. 6 for the PAN data sets, and in Fig. 7 for the Wikipedia data sets.
 The PAN data sets show lower classification scores compared to classification within the same language. The range of scores varies widely, especially for the AUC-ROC scores. Reusing CRF models trained on small data sets (e.g. German (de)) does not provide any significant benefits as observed by a lower convergence of average scores and clusters of results for the sampling ratios.
 The Wikipedia data sets show higher classification scores compared to the PAN data sets, similar to within language classification. The feature functions with more adjacent tags also reduce the variance in the standard deviation, sim-ilarly to the PAN data sets, and especially for AUC-PR scores. This suggests the CRF classifier is more precise in classifying vandalism cases when it has contex-tual awareness of other tags. The non-English CRF models may be identifying sneaky vandalism that is lost within the English CRF model because of the large size difference in the training data sets. 6.3 Comparing to Feature Classification As a comparison to our context-aware technique, we implement a feature engi-neering based classifier with features in Table 2 following our previous work [ 20 ] and similar to related work [ 2 , 10 , 14 , 23 ]. We select a relevant subset of fea-tures from winning entries of the PAN workshop competitions (features to P12-LZW ), and contribute our own subset of features (features F12-WS ). We follow our previous work by extracting these features from the data sets in Sect. 3 , and use 10-fold cross-validation with the same Random Forest (RF) classifier 7 that was shown to be the most robust and generally best performing classifier. We present our comparison plots for the 1-to-1 data sampling ratio in Fig. 8 for within language classification and for out of language classification.
 results for both PAN and Wikipedia data sets. For the PAN data sets, the RF classifier performs consistently well, as expected from related work [ 2 , 10 , 14 , 19 , 23 ]. The tight cluster of RF PAN results (Fig. 8 ) suggests the features are language independent and have strong performance. The RF classifier on the full Wikipedia data sets shows similar strong classification performance. The CRF and RF Wikipedia results show trade-offs in AUC-PR and AUC-ROC scores. For out of language classification, we see a tight cluster of RF results for both the PAN and Wikipedia data sets (Fig. 8 ). This is expected as within language classification shows similar classification scores. Interestingly, the CRF and RF Wikipedia scores for the English (en) and  X  X ll X  data set have almost opposite AUC-PR and AUC-ROC scores. This shows a trade-off in precision (P) and FPR when using each classifier. The CRF classifier has higher TPR and FPR scores instead of the higher precision (P) scores of the RF classifier. In this paper, we have proposed a novel context-aware detection technique for sneaky vandalism on Wikipedia based on a conditional random fields (CRF) classifier. We evaluated this classifier on two data sets, the PAN data sets com-monly used by related works, and our own much more comprehensive vandalism repairs data set built from the complete Wikipedia edits from five languages. We used part-of-speech (POS) tagging to tag all sentences changed in edits from both data sets. Then we used the CRF classifier to train and evaluate our data sets using 10-fold cross-validation. As a comparison, we developed a set of text features and detected vandalism using a random forest classifier on the same data sets. We have shown through our results that context-aware techniques can become a new counter-vandalism tool for Wikipedia that complements current feature engineering based approaches.
 In future work, we aim to develop a language independent tag set that uses information from feature engineering approaches. Our working set of languages contains some shared POS tags, where we can unify these tags into higher level word tags that have direct mappings across languages, such as nouns, pronouns, verbs, adverbs, and adjectives. We plan to extend our linear-chain CRF to a gen-eral CRF that allows modelling of dependencies between articles, where vandals may also target adjacent internally linked articles. Our proposed novel context-aware vandalism detection technique is an exploratory step towards more com-plex detection techniques for progressively sneakier text vandalism on Wikipedia.
