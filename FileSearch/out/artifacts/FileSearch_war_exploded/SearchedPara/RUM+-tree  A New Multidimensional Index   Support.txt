 Nowadays, a wide range of applications, including goods delivery and traffic control, need to store and process the continuously changing information of moving objects. Except that, there are also lots of applica tions relying on the sampling continuous and multidimensional variables. All these applications are characterized by frequent up-dates. Usually, every sampled data value triggers an update to the underlying database server. So, it is essential to develop spatial indexes to handle large volumes of updates in an efficient manner for those scenarios. The dominant indexing technique for mul-tidimensional data with low dimensionality is R-tree [3] which is originally designed for query-intensive setting, i.e., one of the primary concerns in R-tree is to minimize the search cost of spatial queries. In R-tree, the update operation is very costly since it treats an update as combination of a deletion and an insertion. Given the fact that the MBRs (Minimal Bounding Rectangle) in an R-tree may overlap, locating the old en-try to be deleted may follow multiple paths from the root towards the leaf node and thus is expensive. Hence, it is believed that the original R-tree isn X  X  a good choice for update-intensive setting, where frequent updates are continuously generated. 
In this paper, we propose a new R-tree based index structure which efficiently sup-ports frequent updates. As it is an extension of the RUM-tree, we call our method RUM+-tree. RUM+-tree does not perform expensive traditional top-down update in R-tree. Instead, it maintains two data structures in addition to R-tree: a hash table on object ID and update memo. When an update comes, the leaf node of the indexed object can be directly located through the hash table. If the new position of the object of the object in the corresponding leaf node and the update is finished. Otherwise, utilizing the update memo, the update is turned into an insertion. The application of update memo allows multiple versions of one object to coexist in the same RUM+-significant proportion of I/O cost. We have carried out extensive experiments to dem-onstrate the efficiency of RUM+-tree. 
The rest of the paper is organized as follows: Section 2 discusses the related work on indexing moving object and supporting frequent updates for R-trees. In section 3, we present our approach. Section 4 presents the results of our performance evaluation, in which we compared RUM+-tree against several previous approaches. Finally, we conclude in section 5. In the last two decades, with the recent attention on indexing moving objects, many index structures have been proposed to index moving object. According to the type of data being stored, these data structures are divided into two categories: (1) indexing the historical trajectories of objects [4] (2) indexing current and predicted location of moving objects [1, 2, 5, 8]. All these methods must handle frequent updates. Howev-er, Traditional update algorithm in R-tree is inefficient. To support frequent updates in R-trees, a bottom-up update style is proposed in the [2, 5]. These approaches are based on the observation that some updates can be handled locally. In [2], by using a secondary index, the leaf node which contains the object involved in update query can be directly accessed. If the consecutive changes of the object are small, the update can be finished quickly. [5] polishes this idea by maintaining an in-memory summary structure to help both updates and queries. The bottom-up approach works well when the consecutive changes of objects are still in the same MBR bounding. However, when consecutive changes are large, their performance will be affected greatly. In the worst case, its performance is the same with traditional update, i.e., bottom-up update is no more applicable. On the other hand, to eliminate the traditional update adopted by R-tree, [1] proposed a memo-based updating method, called RUM-tree. When an update comes, it is assigned a timestamp. Then, along with the object ID and timestamp, new value is inserted into the tree. RUM-tree defers the deletion and the deletion is performed in a batch manner after the number of updates handled exceeds a threshold. In this section, we present a novel index structure called RUM+-tree to support frequent update in the context of indexing current position of moving object. First, we introduce the basic idea of our approach. Then, we describe the structure of RUM+-tree. 3.1 Basic Idea We use the scenario of figure 1 to illustrate the disadvantage of RUM-tree. R 1 and R 2 are MBRs on leaf nodes. R 0 is the MBR of the parent node of R 1 and R 2 . obj 1 belongs longing to R 1 and circles represent belonging to R 2 . At some point, the movement of obj 1 triggers an update. Then, RUM-tree prepares to create new version like in the figure 1(b). The leaf node is full, and this causes a split. As shown in figure 1(c), after creating new version for obj 1 , Since R 2 has reached the maximum cardinality of node, see, continuous creation of new version in the same leaf node has some drawbacks. One drawback is that it will cause node split. What is worse is that the split can prop-agate upwards. Second, when the garbage clean is triggered to remove the old ver-sions, the node may be merged again. This split and merge procedure is expensive and unnecessary. To avoid it, we equip the RUM-tree with the lazy update feature. When an update is coming, we check if the update is local. If so, only the leaf node affected by the update is modified and the update is finished. Otherwise, we are sure that the consecutive change for the object is large, and the insertion may be uniform among the leaf nodes, i.e., the insertions may not always happen in the same leaf node. Back to the above example, our algorithm does not have to handle the update figure 1(b). Because new position of an object is still in the same MBR to which the done is to update the position of the corresponding entry in the leaf node. In this case, we need only 2 disk accesses (one read R 1 and one write R 2 ) and reduce the cost by at least 2 I/Os. On the one hand, by reducing the number of new versions to be created, it can accelerate the garbage clean and update procedure. Additionally, Compared to LUR-tree, RUM+-tree eliminates traditional update like in R-tree completely. 3.2 Index Structure Based on the above observation, we propose a new index structure, called RUM+-tree. Compared to R-tree, RUM+-tree is equipped with two additional components: a secondary index and an update memo. The secondary index enables directly access to the leaf node of each object; the update memo provides two functions: to identify the latest version of the data and to keep track of the old versions. The update memo also plays an important role in finding search result. In RUM+-tree, the raw search result is a superset of the actual answer. Once the raw search result is obtained, it has to be compared with the update memo to elimin ate the false answers. In RUM+-tree, the MBR of leaf node is computed on the fly. If the object does not move out of the MBR, the update is done by modifying the position of the object. Otherwise, together with timestamp and the object ID, the new value is inserted into RUM+-tree. RUM+-tree doesn X  X  sacrifice fanout of the tree and thus sustains the search perfor-mance. The structure of RUM+-tree is shown in figure 2. In this section, we will show the results of experiments and analyze the performance of the RUM+-tree regarding to the update performance. To evaluate the proposed RUM+-tree, RUM+-tree is compared with the conventional R*-tree, LUR-tree(Lazy Update R-tree) and RUM-tree(R-tree with Update Memos)in terms of the number of page accesses. All the experiments are carried on Intel Pentium Dual-Core T2390 1.86GHz PC with 2G RAM. We implement the RUM+-tree on the basis of R*-tree [11]. We use Beckmann X  X  R*-tree source code. The development environment is VS 2005 and all algorithms are implemented using c. The size of disk page is 4KB. The periment are generated by GSTD [6]. We generate four data sets with different initial distribution and different movement pattern of object. The initial distribution and movement pattern are U-R (Uniform, Random), U-D (uniform, directed), G-R (Gaus-sian, Random) and G-D (Gaussian, Directed) respectively. There are no objects dis-appearing or no new objects appearing in the experiment. So, the secondary index can be implemented as static hash table without overflow. The working space of the ob-jects is the unit square. We keep the secondary index in main-memory. 4.1 Update Performance The number of update operations ranges from 15,000 to 150,000 and the number of moving object ranges from 1,000 to 10,000. Figure 3 gives the average I/Os for all evaluated algorithms. The average I/Os in RUM-tree are nearly stable. The reason is that the RUM-tree treats the update operation as insertion and the I/O cost of insertion algorithm is only related with the height of tree. If the overlaps of the MBR is serious, the update performance of R*-tree will deteriorate greatly. That X  X  why there are more jumps in the performance illustration of R*-tree. RUM+-tree behaves well in update operation and is less affected by objects X  movement pattern compared with LRU-tree. In the worst case, i.e., no update can be done locally, the LRU-tree is the same with R*-tree and RUM+-tree is the same with RUM-tree. In this paper, we propose a new R-tree based index, called RUM+-tree, to support the intensive update. We improve the RUM-tree by equipping it with lazy update feature to reduce production of version data. Experiments show that our approach is efficient. In some case, RUM+-tree can greatly improve the update performance compared with RUM-tree. The pure bottom-up update manner, such as used by LRU-tree will be greatly affected by the movement pattern of object. In worst case, it is the same with the update in R-tree. The RUM+-tree is much less sensitive to movement pattern of object. Furth more, the RUM+-tree eliminates the traditional update manner like in R-tree completely. 
With development of new hardware platform such as multi-core and huge RAM, porting huge volume of updates. Our future work is to develop the in-memory version of RUM+-tree or take the memory buffer into consideration. Acknowledgement. This work has been supported by the NEC Corporation and Graduate Science Foundation of Renmin University of China (No.13XNH216). The author also wants to thanks for the advice from Yubin Guo from SCAU. 
