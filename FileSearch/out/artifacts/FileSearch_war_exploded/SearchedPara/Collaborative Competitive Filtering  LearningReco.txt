 While a user X  X  preference is directly reflected in the interac-tive choice process between her and the recommender, this wealth of information was not fully exploited for learning recommender models. In particular, existing collaborative filtering (CF) approaches take into account only the binary events of user actions but totally disregard the contexts in which users X  decisions are made. In this paper, we propose Collaborative Competitive Filtering (CCF), a framework for learning user preferences by modeling the choice process in recommender systems. CCF employs a multiplicative latent factor model to characterize the dyadic utility function. But unlike CF, CCF models the user behavior of choices by en-coding a local competition effect. In this way, CCF allows us to leverage dyadic data that was previously lumped to-gether with missing data in existing CF models. We present two formulations and an efficient large scale optimization al-gorithm. Experiments on three real-world recommendation data sets demonstrate that CCF significantly outperforms standard CF approaches in both offline and online evalua-tions.
 Categories and Subject Descriptors: H.3.3 [Informa-tion filtering]; I.2.6 [Artificial Intelligence]: Learning General Terms: Algorithms, Performance Keywords: Recommender systems, collaborative-competitive filtering, behavior model
Recommender systems have become a core component for today X  X  personalized online businesses. With the abilities of connecting various items (e.g., retailing products, movies, News articles, advertisements, experts) to potentially inter-ested users, recommender systems enable online webshops (e.g. Amazon, Netflix, Yahoo!) to expand the marketing efforts from historically a few best-sellings toward a large variety of long-tail (niche) products [4, 25, 9]. Such abilities are endowed by a personalization algorithm for identifying the preference of each individual user, which is at the heart of a recommender system.

Predicting user preference is challenging. Usually, the user and item spaces are very large yet the observations are ex-tremely sparse. Learning from such rare, noisy and largely missing evidences has a high risk of overfitting. Indeed, this data sparseness issue has been widely recognized as a key challenge for constructing effective recommender systems.
A straightforward way for building recommender would be to learn each user X  X  preference based on the prior interactions between the user and the recommender system. Typically, such interaction is an  X  X pportunity give-and-take X  process ( c.f. Table 1), where at each interaction: 1) a user u inquires the system (e.g. visits a movie rec-2) the system offers a set of (personalized) opportunities 3) the user chooses one item i  X   X  X  (or more) from these Somewhat surprisingly, this interaction process has not been fully-exploited for learning recommenders. Instead, research on recommender systems has focused almost exclusively on recovering user preference by completing the matrix of user actions ( u, i  X  ) while the actual contexts in which user deci-sions are made are totally disregarded. In particular, Col-laborative Filtering (CF) approaches only captures the ac-tion dyads ( u, i  X  ) while the contextual dyads (i.e. { ( u, i ) } for all i  X  O and i 6 = i  X  ) are typically treated as missing data. For example, the rating-oriented models aim to approximat-ing the ratings that users assigned to items [22, 19, 1, 14]; the recently emerged ranking-oriented algorithms [26, 15] attempt to recover the ordinal ranking information derived from the ratings. Although this matrix-completion formu-lation of the recommendation problem has led to numerous algorithms which excel at a number of data sets, including the prize-winning work of [14], we argue here that the formu-lation is inherently flawed  X  a preference for Die Hard given a generic set of movies only tells us that the user appreciates action movies; however, a preference for Die Hard over Ter-minator or Rocky suggests that the user might favor Bruce Table 1: An example of user-recommender interac-t ions and the derived observation matrix: entries with value  X 1 X  denote the action dyads; dyads that are observed without user actions (e.g. offered by the recommender but not picked by the user) are marked with dots ( X   X ). CF trains only on the 1 en-tries while the entries are treated as missing data. CCF distinguishes between unseen entries and en-tries marked with dots.
 Willis over other action heroes. In other words, the context of user choice is vital when estimating user preferences.
When it comes to modeling of user-recommender interac-tions, an important question arises: what is the fundamen-tal mechanism underlying the user choice behaviors? As reflected by its name, collaborative filtering is based on the notion of  X  X ollaboration effects X  that similar items get sim-ilar responses from similar users . This assumption is es-sential because by encoding the  X  X ollaboration X  among users or among items or both, CF greatly alleviates the issue of data sparseness and in turn makes more reliable predictions based on the somewhat pooled evidences.

It has long been recognized in psychology and economics that, besides the effect of collaboration [5, 20], another mech-anism governs users X  behavior  X  competition [16, 18, 3]. In particular, items turn to compete with each other for the attention of users; therefore, axiomatically, user u will pick the best item i  X  (i.e. the one with highest utility) when confronted by the set of alternatives O . For example, con-sider a user with a penchant for action movies by Arnold Schwarzenegger. Given the choice between Sleepless in Seat-tle and Die Hard he will likely choose the latter. However, when afforded the choice between the oeuvres of Schwarzeneg-ger, Diesel or Willis, he X  X  clearly more likely to choose Schwar-zenegger over the works of Willis. To capture user X  X  prefer-ence more accurately, it is therefore essential for a recom-mender model to take into account such local competition effect. Unfortunately, this effect is absent in a large number of collaborative filtering approaches.

In this paper, we present Competitive Collaborative Fil-tering (CCF) for learning recommender models by modeling users X  choice behavior in their interactions with the recom-mender system. Similar to matrix factorization approaches for CF, we employ a multiplicative latent factor model to characterize the dyadic utility function (i.e. the utility of an item to a user). In this way, CCF encodes the collaboration effect among users/items just as CF does. But instead of learning only the action dyads (i.e. ( u, i  X  ) or the  X 1 X  entries in Table 1), CCF bases the learning of the factorization on the whole user-recommender interaction sessions. It there-fore leverages not only the action dyads ( u, i  X  ) but also the dyads in the context without user actions (i.e. ( u, i ) for all i  X  X  and i 6 = i  X  , or the dot entries in Table 1), which were treated as potentially missing data in CF approaches.
To leverage the entire interaction session for latent fac-tor learning, we devise probabilistic models or optimization objectives to encode the local competition effect underlying the user choice process. We present two formulations with different flavors. The first formulation is derived from the multinomial logit model that has been widely used for mod-eling user choice behavior (e.g. choice of brands) in psychol-ogy [16], economics [17, 18] and marketing science [11]. The second formulation relates closely to the ordinal regression models in content filtering [12] (e.g. web search ranking). Essentially, both formulations attempt to encodes  X  X ocal op-timality of user choices X  X o encourage that every opportunity i taken by a user u be locally the best in the context of the opportunities O offered to her. From a machine learn-ing viewpoint, CCF is a hybrid of local and global learn-ing, where a global matrix factorization model is learned by optimizing a local context-aware loss function. We dis-cuss the implementation of CCF, establish efficient learning algorithms and deliver a package that allows distributed op-timization on streaming data.

Experiments were conducted on three real-world recom-mendation data sets. First, on two dyadic data sets, we show that CCF improves over standard CF models by up to 50+% in terms of offline top-k ranking. Furthermore, on a commercial recommender system, we show that CCF sig-nificantly outperform CF models in both offline and online evaluations. In particular, CCF achieves up to 7% improve-ment in offline top-k ranking and up to 13% in terms of online click rate prediction.
 Outline:  X  2 describes the problem formulation, the back-grounds and motivates CCF.  X  3 presents the detailed CCF models, learning algorithms and our distributed implemen-tation.  X  4 reports experiments and results.  X  5 reviews re-lated work and  X  6 summarizes the results.
Consider the user-system interaction in a recommender system: we have users u  X  U := { 1 , 2 , . . . , U } and items i  X  I = { 1 , 2 , . . . , I } ; when a user u visits the site, the system recommends a set of items O = { i 1 , . . . , i l } and u in turn chooses a (possibly empty) subset D  X  O from O and takes actions accordingly (e.g. buys some of the recom-mended products). For ease of explanation, let us temporar-ily assume D = { i  X  } , i.e. D is not empty and contains exactly one item i  X  . More general scenarios shall be discussed later.
To build the recommender system, we record a collection of historical interactions in the form of { ( u t , O t , D t is the index of a particular interaction session. Our goal is to generate recommendations O  X  t for an incoming visit  X  t of user u  X  t such that the user X  X  satisfaction is maximized. Hereafter, we refer to U as user space , I as item space , O offer set or context , D t as decision set , and i  X  as a decision .
A key component of a recommender system is a model r ( u, i ) that characterizes the utility of an item i  X  I to a user u  X  X  , upon which recommendations for a new inquiry from user u could be done by simply ranking items based on r ( u, i ) and recommending the top-ranked ones. Collab-orative filtering is by far the most well-known method for modeling such dyadic responses.
In collaborative filtering we are given observations of dyadic responses { ( u, i, y ui ) } with each y ui being an observed re-sponse (e.g. user X  X  rating to an item, or indication of whether user u t ook an action on item i ). The whole mapping: constitutes a large matrix Y  X  Y |U| X |I| . While we might have millions of users and items, only a tiny proportion (considerably less than 1% in realistic datasets) of entries are observable 1 .

Collaborative filtering explores the notion of  X  X ollabora-tion effects X , i.e., similar users have similar preferences to similar items. By encoding collaboration, CF pools the sparse observations in such a way that for predicting r ( u, i ) it also borrows observations from other (similar) users/items. Generally speaking, existing CF methods fall into either of the following two categories.
 Neighborhood models. A popular class of approaches to CF is based on propagating the observations of responses among items or users that are considered as neighbors. The model first defines a similarity measure between items / users. Then, an unseen response between user u and item i is approximated based on the responses of neighboring users or items [22, 19], for example, by simply averaging the neigh-boring responses with similarities as weights.
 Latent factor models. This class of methods learn predic-tive latent factors to estimate the missing dyadic responses. The basic idea is to associate latent factors 2 ,  X  u  X  R k for each user u and  X  i  X  R k for each item i , and assume a multiplicative model for the dyadic response, where  X  denotes the set of hyper-parameters, the utility is assumed as a multiplicative function of the latent factors, This way the factors could explain past responses and in turn make prediction for future ones. This model implicitly encodes the Aldous-Hoover theorem [13] for exchangeable matrices  X  y ui are independent of each other given  X  u and  X  In essence, it amounts to a low-rank approximation of the matrix Y that naturally embeds both users and items into a vector space in which the inner-products directly reflect the semantic relatedness.

To design a concrete model [2, 21, 23], one needs to specify a distribution for the dependence. Afterwards, the model boils down to an optimization problem. For example two commonly-used formulations are: - X  2 regression The most popular learning formulation is -Logistic Another popular formulation [21, 1] is to use
N ote the subtle difference in data representation: while we record entire sessions, CF only records the dyadic responses.
We assume each latent factor  X  contains a constant com-ponent so as to absorb user/item-specific offset into  X  . min
Collaborative filtering approaches have made substantial progresses and are currently the state-of-the-art techniques for recommender system. However, we argue here that CF approaches might be a bit lacking in several aspects. First of all, although data sparseness is a big issue, CF does not fully leverage the wealth of user behavior data. Take the user-recommender interaction process described in  X  2.1 as an example (c.f. Table 1), CF methods typically use only the action dyad ( u, i  X  ) of each session while other dyads { ( u, i ) | i  X  O , i 6 = i  X  } are treated missing and totally disre-garded, which could be wasteful of the invaluable training resource because these non-action dyads are not totally use-less, as shown by the experiments in this paper.

Secondly, most existing CF approaches learn user pref-erence collaboratively by either approximating the dyadic responses { y ui  X  } [22, 19, 1, 14] or preserving the ordinal ranking information derived from the dyadic responses [26, 15]; none of them models the user choice behavior. Partic-ularly, as users choose from competing alternatives, there is naturally a local competition effect among items being of-fered in a session. Our work show that this effect could be an important clue for learning user preference.

Because latent factor models are very flexible and could be under-determined (or over-parameterized) even for rather moderate number of users/items. With the above two limi-tations, CF approaches are vulnerable to over-fitting [1, 14]. Particularly, while most existing CF models might learn con-sistently on user ratings (numerical value typically with five levels) if given enough training data, they usually perform poorly on binary responses. For example, for the aforemen-tioned interaction process ( c.f. Table 1), the response y typically a binary event indicating whether or not item i was accepted by the user u . With the non-action dyads being ignored, the responses are exclusively positive observations (either y ui = 1 or missing). As a result, we will obtain an overly-optimistic estimator that biases toward positive re-sponses and predicts positive for almost all the incoming dyads (See  X  4.1 for empirical evidences).
We present a novel framework for recommender learning by modeling the user-system interaction process. The key insight is that the contexts O t in which user X  X  decisions are made should be taken into account when learning recom-mender models. In practice, a user u could make different decisions when facing different contexts O t . For instance, an item i would not have been chosen by u if it were not pre-sented to her at the first place; likewise, user u could choose another item if the context O t changes such that a better offer (e.g., a more interesting item) is presented to her.
In this section, we describe the framework of collaborative-competitive filtering. We start with some axiomatic views of the user choice behaviors. Following that, we present the learning formulation of CCF. We then develop the op-timization algorithms and implementation techniques. We close the section with a discussion of useful extensions.
F ormally, the individual choice process (i.e. user-recommender interactions) in a recommender system can be viewed as an instance of the opportunity give-and-take (GAT) process. Definition [GAT]: An opportunity give-and-take process is a process of interactions among an agent u , a system S and a set of opportunities I ; at an interaction t :
Note that we assume the agent is a priori not aware of all the items, and only through the recommender S can she get to know the items, therefore other items that are not in O t is unaccessible to u at interaction t . This is reasonable considering that the total number of items in the inventory is usually very large. Moreover, we assume an agent u is a rational decision maker: she knows that her choice of item i will be at the expense of others i  X   X  O t , therefore she com-pares among alternatives before making her choice. In other words, for each decision, u considers both revenue and op-portunity cost , and decides which opportunity to take based on the potential profit of each opportunity in O . Specifically, the opportunity cost c ui is the potential loss of u from taking an opportunity i that excludes her to take other opportuni-ties: c ui = max { r ui  X  : i  X   X  X \ i } ; the profit  X  ui the net gain of an decision. By drawing the rational decision theory [16], we present the following principle of individual choice behavior.
 Proposition : A rational decision is a decision maximizing the profit: i  X  = arg max i  X  X   X  ui .

This proposition implies the constraint of X  X ocal optimality of user choice X , a local competitive effect restricting that the agent u always chooses the offer that is locally optimal in the context of the offer set O t .
The local-optimality principle induces a constraint which could be translated to an objective function for recommender learning: or P ( i  X  is taken) = P ( r ui  X  &gt; max { r ui | i  X  X  t
This objective is, however, problematic. First, the in-equality constraint restricts the utility function only up to an arbitrary order-preserving transformation (e.g. a monotoni-cally increasing function), and hence cannot yield a unique solution (e.g. point estimation) [17]. Second, optimization based on the induced objective is computationally intractable due to the max operator. To this end, we present two sur-rogate objectives, which are both computationally efficient and show close connections to existing models.
Our first formulation is based on the random utility the-ory [16, 17] which has been extensively used for modeling choice behavior in economics [18] and marketing science [11]. In particular, we assume the utility function consists of two components r ui + e ui , where: (1) r ui is a determin-istic function characterizing the intrinsic interest of user u to item i , for which we use the latent factor model to quan-tify r ui =  X   X  u  X  i ; (2) the second part e ui is a stochastic er-ror term reflecting the uncertainty and complexness of the choice process 3 . Furthermore, we assume the error term e is an independently and identically distributed Weibull (ex-treme point) variable:
Together with the local-optimality principle, these two as-sumptions yield the multinomial logit model [18, 17, 11]: Intuitively, this model enforces the local-optimality constraint by using the softmax function as a surrogate of max .
Given a collection of training interactions { ( u t , O t the latent factors can be estimated using penalized maxi-mum likelihood via While the above formulation is a convex optimization w.r.t. r ui as each of the objective terms in Eq.(3) is strongly con-cave, it is nonconvex w.r.t. the latent factors  X  . We post-pone the discussion of optimization algorithms to  X  3.3.
Our second formulation is based on a simple reduction of the local-optimality constraint by noting, from Eq(1), that:
P ( i = i  X  | u, O ) = P (( r ui  X   X  r ui ) &gt; ( e ui  X  e ity that u could possibly gain from the non-chosen items. Intuitively, the above model encourages that the utility dif-ference between choice and non-chosen items, r ui  X   X   X  r be nontrivially greater than random errors. Based on this notion, we present the following formulation which views the task as a pairwise preference learning problem [12] and uses the non-choices averagely as negative preferences. min This formulation is directly related to the maximum score estimation [17] of the multinomial logit model Eq(2). In-tuitively, it directly reflects the insight that user decisions are usually made by comparing alternatives and considering the difference of potential utilities. In other words, it learns latent factors by maximizing the marginal utility between user choice and the average of non-choices.
T he error term essentially accounts for all the subtle, un-certain and unmeasurable factors that influence user choice behaviors, for example, a user X  X  mood, past experience, or other factors (e.g., whether the decision is made in a hurry, together with her friends, or totally unconsciously)
Again, the optimization is convex w.r.t. r u i , but noncon-vex w.r.t. the latent factors, therefore the standard opti-mization tools such as the large variety of RankSVM [12] solvers are not directly applicable.
It is worth noting that our CCF formulations have an ap-pealing linear complexity, O ( |I| X |O| ), where the offer size |O| is typically a very small number. For example, Netflix recommends |O| = 7 movies for each visit, and Yahoo! front-page highlights |O| = 4 hot news for each browser. There-fore, CCF has the same-order complexity as the rating-oriented CF models. Note that the ranking-oriented CF approaches [26, 15] are much more expensive  X  for each user u , the learning complexity is quadratic O ( |I| 2 ) as they learn preference of each user by comparing every pair of the items.
As we have already mentioned, due to the use of bilin-ear terms, both of the two CCF variants are nonconvex optimization problems regardless of the choice of the loss functions. While there are convex reformulations for some settings they tend to be computationally inefficient for large scale problems as they occur in industry  X  the convex for-mulations require the manipulation of a full matrix which is impractical for anything beyond thousands of users.
Moreover, the interactions between user and items change over time and it is desirable to have algorithms which pro-cess this information incrementally. This calls for learn-ing algorithms that are sufficiently efficient and preferably capable to update dynamically so as to reflect upcoming data streams, therefore excluding offline learning algorithms such as classical SVD-based factorization algorithms [14] or spectral eigenvalue decomposition methods [15] that involve large-scale matrices.

We use a distributed stochastic gradient variant with av-eraging based on the Hadoop MapReduce framework. The basic idea is to decompose the objectives in Eq.(3) or Eq.(4) by running stochastic optimization on sub-blocks of the in-teraction traces in parallel in the Map phase, and to combine the results for  X  i in the Reduce phase.
 Stochastic Optimization. We derive a stochastic gradi-ent descent algorithm to solve the optimization described in Eq(3) or Eq(4). The algorithm is computationally efficient and decouplable among different interactions and users, there-fore amenable for parallel implementation.

The algorithm loops over all the observations and updates the parameters by moving in the direction defined by neg-ative gradient. Specifically, we can carry out the following update equations on each machine separately: Here  X  is the learning rate 4 . The gradients are given by:
W e carry out an annealing procedure to discount  X  by a factor of 0.9 after each iteration, as suggested by [14]. where H ( ) is the Heaviside function, i.e. H ( x ) = 1 if x &gt; 0 and H ( x ) = 0 otherwise. 5 Feature Hashing. A key challenge in learning CCF models on large-scale data is that the storage of parameters as well as observable features requires a large amount of memory and a reverse index to map user IDs to memory locations. In particular in recommender systems with hundreds of mil-lions of users the memory requirement would easily exceed what is available on today X  X  computers (100 million users with 100 latent feature dimensions each amounts to 40GB of RAM). We address this problem by implementing feature hashing [27] on the space of matrix elements. In particularly, by allowing random collisions and applying hash mapping to the latent factors (i.e.  X  ), we keep the entire representation in memory, thus greatly accelerating optimization.
We now discuss two extensions of CCF to address the fact that in some cases users choose not to respond to an offer at all and that moreover we may have observed features in addition to the latent representation discussed so far. In establishing the CCF framework for modeling the user choice behavioral data, we assumed that for each user-system interaction t , the decision set D t contains at least one item. This assumption is, however, not true in practice. A user X  X  visit at a recommender system does not always yield an ac-tion. For example, users frequently visit online e-commerce website without making any purchase, or browse a news por-tal without clicking on any advertisement. Actually, such nonresponded visits may account for a vast majority of the traffics that an recommender system receives. Moreover, different users may have different propensities for taking an action. Here, we extend the multinomial logit model to modeling both responded and nonresponded interactions, ( u t , O t , i  X  t ) and ( u t , O t ,  X  ) respectively.
This is accomplished by adding a scalar  X  u for each user u to capture the action threshold of user u . We assume that, at an interaction t , user u t takes an effective action only if she feels that the overall quality of the offers O t are good enough and worth the spending of her attention. In keeping with the multinomial logit model this means that for all i  X  O and the probability of no response is given by the remainder, that is by: In essence, this amounts to a model where the  X  X on-response X  has a certain reserve utility that needs to be exceeded for a user to respond. We may extend the hinge model in the same spirit (we use a trade-off constant C &gt; 0 to calibrate the importance of the non-responses):
I n our implementation, we approximate this by the contin-uous function 1 1+ e  X  1 00 x . This helps with convergence. Social 1 .2M 400 29M -Netflix-5star 0.48M 18K 100M -
News 3.6M 2.5K 110M 4 In previous sections, we use a plain latent factor model for quantifying utility, i.e. r ui =  X   X  u  X  i . A known drawback [1] of such model is that it only captures dyadic data (responses), and therefore generalizes poorly for completely new enti-ties, i.e. unseen users or items, of which the observations are missing at the training stage. Here, we extend the model by incorporating content features. In particular, we assume that, in addition to the latent features  X  s, there exist some observable properties x u  X  R m (e.g. a user X  X  self-crafted reg-istration files) for each user u , and x i  X  R n (e.g. a textual description of an item) for each item i . We then assume the utility r ui as a function of both types of features (i.e. observable and latent) [28]: where the matrix M  X  R m  X  n provides a bilinear form for characterizing the utility based on the content features of the corresponding dyads. This model integrates both col-laborative filtering [14] and content filtering [7]. On the one hand, if the user u or item i has no or merely non-informative observable features, the model degrades to a factorization-style utility model. On the other hand, if we assume that  X  and  X  i are irrelevant, for instance, if i or j is totally new to the system such that there is no interaction involving either of them as in a cold-start setting, this model becomes the classical content-based relevance model commonly used in, e.g. webpage ranking [29], advertisement targeting [6], and content recommendation [7].
We report experimental results on two test-beds. First, we evaluate the CCF models with CF baselines on two dyadic data sets with simulated choice contexts. The choice of sim-ulated data generated from CF datasets was made since we are unaware of any publicly available datasets directly suit-able for CCF. Furthermore, we extend our evaluation to a more strict setting based on user-system interaction session data from a commercial recommender system.
We use dyadic data with binary responses, i.e. { ( u, i, y where y ui  X  { 1 , missing } . We compare different recom-mender models in terms of their top-k ranking performance. Social network data. The first data set we used was col-lected from a commercial social network site, where a user Figure 1: Histograms of the predicted dyadic re-s ponses {  X  y ui } : while the predictions by CF (top) are over-optimistically concetrated on positive re-sponses (i.e. predicting  X  X elevant X  for all possi-ble dyads), the results obtained by CCF (bottom) demonstrate a more reasonable power-law property. expresses her preference for an item with an explicit indica-tion of  X  X ike X . We examine data collected for about one year, involving hundreds of millions of users and a large collection of applications, such as games, sports, news feeds, finance, entertainment, travel, shopping, and local information ser-vices. Our evaluation focuses on a random subset consisting of about 400 items, 1.2 million users and 29 million dyadic responses ( X  X ike X  indications).
 Netflix 5 star data. We also report results on a data set derived from the Netflix prize data 6 , one of the most famous public data sets for recommendation. The Netflix data set contains 480K users and 18K movies. We derive binary re-sponses by considering only 5-star ratings as X  X ositive X  X yads and treating all the others as missing entries.

For both data sets, we randomly split the data into three pieces, one for training, one for testing and the other for validation.
 Evaluation metrics. We assess the recommendation per-formance of each model by comparing the top suggestions of the model to the true actions taken by a user (i.e.  X  X ike X  or 5-star). We consider three measures commonly used for accessing top-k ranking performance in the IR community: AP is the average precision . AP@ n averages the precision AR or average recall is the average recall of the top-n rank nDCG or normalized Discounted Cumulative Gain is the h ttp://www.netflixprize.com . For downloadable codes and more information on Netflix experiment, please visit http://www.cc.gatech.edu/~syang46/ccf.htm Table 3: Top-k r anking performance on two binary dyadic data sets with simulated contexts.
 For all the three metrics we use n = 5 since most social net-works and movie recommendation sites recommend a similar number of items for each user visit.
 Evaluation protocol. We compare the two CCF models (i.e. Softmax and Hinge) with the two standard CF factor-ization models (i.e.  X  2 and Logistic) described in  X  2.2. For dyadic data with binary responses, the Logistic CF model amounts to the state-of-the-art [21, 1].

We adopt a fairly strict top-k ranking evaluation. For each user, we assess the top results out of a total preference order-ing of the whole item set. In particular, for each user u , we consider all the items as candidates; we compute the three measures based on the comparison between the ground truth (the set of items in the test set that user u actually liked) and the top-5 suggestions predicted by each model. For sta-tistical consistency, we employ a cross-validation style proce-dure. We learn the models on training data with parameters tuned on validation data, and then apply the trained models to the test data to assess the performance. All three mea-sures reported are computed on test data only, and they are averaged over five random repeats (i.e. random splits of the data). 7
To render the data compatible with CCF we simulate a fixed-size pseudo-offer set for each interaction. Specifically, in each step of the stochastic optimization at a positive ob-servation, e.g. y ui = 1, we randomly sample a handful set of missing (unobserved) entries { y ui  X  } i  X  =1: m . These sampled dyads are then treated as non-choices, and together with the positive dyad, they are used as the offer set for the cur-rent session. In our experiments, we choose m = 9 pseudo non-choices; in other words, we assume the offer size |O t =10.
 Results and analysis. We report the mean scores in Ta-ble 3. Since the dataset are fairly large the standard de-viations of all values were below 0 . 001. Consequently we omitted the latter from the results. As can be seen from the table, CCF dramatically outperforms CF baselines on both data sets. In terms of AP@5, the two CCF models gain about 52.8% X 53.6% improvements compared to the two CF models on the Social data, and by 37.0% X 37.8% on Netflix-5 star . Similar comparisons apply to the nDCG@5 measure. And in terms of the AR@5, CCF models outperform CF
N ote that the contextual information (the offer set O t for each interaction t ) is missing for both of the two dyadic data sets. We use the datasets with simulated contexts. Results on real interaction data are reported in  X  4.2. competitors by up to 13.5% on Social , and 30% on Netflix-5 star data. All these improvements are statistically highly sig-nificant. Note that these results are quite consistent: both CF models perform comparably with each other on both data sets; the performance of the two CCF variants is also comparable; between the two groups, gaps are noticeable.
One argument we made in this paper for motivating our work is that since the CF models disregard the context infor-mation and only learns on positive (action) dyads, they al-most inevitably yield overly-optimistic predictions (i.e. pre-dicting positive for all possible dyads). We hypothesize that such estimation bias is one of the key reasons for the in-ability of CF models in learning binary dyadic data. As an empirical validation, in Figure 1, we plot the histograms of the predicted dyadic responses  X  y ui (i.e. entries of the diffused matrices) obtained by a CF model (  X  2 ) and a CCF model respectively. 8 As we can see, the CF model indeed predicts  X  X ositive X  for most (if not all) dyads; in contrast, the results obtained by the CCF model demonstrate a more realistic power-law distribution [8]. 9
In reality, since the total number of items in the inventory is too large, each user can only afford to X  X ike X  X  few items out of the huge amount of alternatives. This power-law property is crucial for information filtering because we are intended to identify a few truly relevant items by filtering out many many irrelevant ones. A power-law recommender is desirable in a way analogous to a filter with narrow-bandwidth, which effectively filters out the noises (i.e. irrelevant items) and only let the true signal (i.e. relevant items) pass to the users. We now move on to a more realistic evaluation by applying CCF to real user-system interaction data. We evaluate CCF in both an offline test and an online test while comparing its results to both CF baselines.
 Data. We collected a large-scale set of user-system inter-action traces from a commercial News article recommender system. In each interaction, the system offers four personal-ized articles to the visiting user, and the user chooses one of them by clicking to read that article. The recommendations are dynamically changing over time even during the user X  X  visit. The system regularly logs every click event of every user visit. It also records the articles being presented to users at a series of discrete time points. To obtain a context set for each user-system interaction, we therefore trace back to the closest recording time point right before the user-click, and we use the articles presented at that time point as the offer set for the current session. We collected such interac-tion traces from logged records of over one month. We use a random subset containing 3.6 million users, 2500 items and over 110 million interaction traces. Learning an effective rec-ommender on this data set is particularly challenging as the article pool is dynamically refreshing, and each article only has a lifetime of several hours  X  it only appears once within
S imilar results obtained with other losses.
Note that the distribution starts at around 0.5 instead of 0, which is consistent with our intuitions that there is actually no truly  X  X rrelevant X  item for a user  X  any item has potential utility for a user; user choose one over another based on the relative preference rather than absolute utility. This is true especially in this era of information explosion, where a user is typically facing so many alternatives that she can only pick the one she likes the most while ignoring the others. Table 4: Offline test (top-k r anking performance) on user-system interaction data.
 a particular day, is pulled out from the pool afterward and n ever appears again.
 Evaluation protocol. We consider the following two eval-uation settings, one offline and the other offline. Offline evaluation Similar to the evaluations presented in Online evaluation We further conduct an online test. In Offline test results. In this setting, we train each model on progressive proportions of 30%, 50% and 70% randomly-sampled training data respectively, and evaluate each trained model in terms of offline top-k ranking performance. The results are reported in Table 4. The two CCF models greatly outperform the two CF baselines in all the three evaluation metrics. Specifically, CCF models gain up to 6.9% improve-ment over the two CF models in terms of average precision; up to 6.5% in terms of average recall, and up to 7.5% in terms of nDCG. We also conducted a t -test with a standard 0 . 05 significance level, which further indicate that all the improvements obtained by CCF are significant.

It is worth noting that the improvements obtained by CCF compared to CF baselines are especially evident when the training data are sparser (e.g. using only 30% of training data). This observation empirically validates our argument that the contexts contain substantial useful information for learning recommender models especially when the dyadic action responses are scarce.
 Table 5: Online test (predicted click probability) on user-system interaction data.
 Figure 2: Offline top-k r anking performance (nDCG@5) as a function of latent dimensionality (top) and regularization weight (bottom).
 The offline results obtained by CCF are quite satisfactory. For example, the average precision is up to 0.276, which means, out of the four recommended items, on average 1.1 are truly  X  X elevant X  (i.e. actually being clicked by the user). This performance is quite promising especially considering that most of the articles in the content pool are transient and subject to dynamically updating.
 Online test results. We further evaluate the online per-formance of each compared model by assessing the predicted click rates. Click-rate is essential for an online recommender system because it is closely-related to both the traffic and the revenue of a webshop. In our evaluation, for each of the incoming visits ( u t , O t , i  X  t ), we use the trained models to predict the user choice, i.e. we ask the question:  X  X mong all the offered items i  X  O t , which one will most likely be clicked? X  We use the trained model to rank the items in the offer set, and compare the top-ranked item with the item that was actually taken (i.e. i  X  t ) by user u t . We evaluate the results in terms of the prediction accuracy.

The results are given in Table 5. Because the size of each offer set in the current data set is 4, a random predictor yields 0.25. As seen from the table, while all the four mod-els obtain significantly better predictions than the random predictor, the two CCF models further greatly outperform the two CF models. Specifically, we observe 11.3% X 12.7% i mprovements obtained by CCF models compared to the two CF competitors. These results are quite significant es-pecially considering the dynamic property of the system. Impact of parameters. The performance of the two CCF models is affected by the parameter settings of the latent dimensionality, k , as well as the regularization weights,  X  and  X  U . In Figure 2 10 , we illustrate how the offline top-k ranking performance changes as a function of these parame-ters, where we use the same value for both  X  I and  X  U . Here we only reported the results with nDCG@5 measure because the results show similar shapes when other measures (includ-ing the click rate) are used. As can be seen from the Figure, the nDCG curves are typically in the inverted U-shape with the optimal values achieved at the middle. In particular, for both the two CCF models, the dimensionality around 20 and regularization weight around 0.0001 yield the best performance, which is also the default parameter setting we used in obtaining our reported results.
 Nonresponded sessions. In Section 3.4 we presented two models for encoding nonresponded interactions, e.g. a user visits the News website but does not click any of the recom-mended articles. These approaches are promising because compared to the responded sessions, the nonresponded ones are typically much more plentiful and if learned successfully, this wealth of information has a potential to alleviating the critical data-sparse issue in recommendation.
 Unfortunately, due to the data-logging mechanism of the News recommender system, we were unable to obtain such nonresponded interactions. Instead, for a preliminary test, we conducted evaluation on a small set of pseudo nonre-sponded sessions that are derived from the responded ones. In particular, we hold out a randomly-sampled subset of sessions; for each of these sessions, we hide the item being clicked by the user, and use the remaining items as a non-responded context set by assuming no click for this set. We augmented this set of derived nonresponded sessions to the training set, and train the model on the combined training data. The results from this preliminary evaluation did not show significant performance improvement. This is likely due to the fact that the surrogate distribution is invalid. A detailed analysis with more realistic data is the subject of future research.
Although a natural reflection of a user X  X  preference is the process of interaction with the recommender, to our knowl-edge, this interaction data has not been exploited for learn-ing recommender models. Instead, research on recommender systems has focused almost exclusively on learning the dyadic data. Particularly collaborative filtering approaches only capture the user-item dyadic data with explicit user actions while the context dyads are typically treated missing values. For example, the rating-oriented models aim to approximat-ing the ratings that users assigned to items [22, 19, 1, 14]; whereas the recently proposed ranking-oriented algorithms [26, 15] attempt to recover the ordinal ranking information derived from the ratings.

By exploiting past records of user-item dyadic responses for future prediction based on either neighborhood based [22,
D ue to heavy computational consumptions, these results are obtained on a relatively small subset of data. 19, 15] or latent factor based methods [1, 14, 26], collab-orative filtering approaches encode the collaboration effect that similar users get similar preference on similar items. In this paper, by leveraging the user-recommender interaction data, we show that much better recommender performance can be obtained when a local-competition effect underlying the user choice behaviors is also encoded.

The multinomial logit model we present is derived based on the random utility theory [16, 17]. The model is well-established and has been widely used for a long time in, e.g. psychology [16], economics [18, 17] and marketing sci-ence [11]. Particularly, [11] applied the model to examine the brand choice of households on grocery data; [10] showed this model is theoretically and empirically superior to the  X  regression model. More recently, the pioneering work of [9] first applied the model to characterize online choices in rec-ommender system and investigated how recommender sys-tems impact sales diversity. Following these steps, this work further employs the model to learn factorization models for recommendation.

The Hinge formulation of CCF shows close connection to the pairwise preference learning approaches widely used in Web search ranking [12]. Our model, however, differs from these content filtering models [12] in that instead of learning a feature mapping as in [12], our model uses the formulation for learning a multiplicative latent factor model.
We presented a framework for learning recommender by modeling user choice behavior in the user-system interac-tion process. Instead of modeling only the sparse binary events of user actions as in traditional collaborative filter-ing, the proposed collaborative-competitive filtering models take into account the contexts in which user decisions are made. We presented two models in this spirit, established efficient learning algorithms and demonstrated the effective-ness of the proposed approaches with extensive experiments on three large-scale real-world recommendation data sets. There are several promising directions for future research. Attention budget and position bias. When deriving the CCF model, we admit an assumption that user decides whether to take an offer solely based on the comparison of utilities. This assumption, however, neglects a factor which might be important in practice. In particular, a user might have budgeted attention such that when making choices he only pays attention to a few top-ranked items and totally disregard the others. This position bias is evident in both web search ranking and recommendation. We plan to take this into consideration for building choice models. Recommender strategy and user behavior. A key fea-ture of the current paper is that we assume the recommender adopts a deterministic strategic policy when making recom-mendations. In practice, a recommender could also adap-tively react to the users X  actions as well as its own consider-ations (e.g. inventory constraints, promotion requirement of certain brands). We would like to extend our analysis here to model the interactive process between users and recom-mender.
 Further empirical validation. Due to data collection constraints, some parts of the proposed models are not strictly evaluated in the current paper. We plan to refine the mecha-nism for data collection and conduct experiments for further e valuation.
 Part of this work was supported by NSF Grant IIS-1049694, the 111-Project B07022 and a Yahoo! faculty grant. [1] D. Agarwal and B.-C. Chen. Regression-based latent [2] E. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. [3] Y. Bakos and E. Brynjolfsson. Bundling and [4] E. Brynjolfsson, Y. J. Hu, and M. D. Smith. Consumer [5] D. E. Byrne. The attraction paradigm . Academic [6] Y. Chen, D. Pavlov, and J. F. Canny. Large-scale [7] W. Chu and S.-T. Park. Personalized recommendation [8] M. Faloutsos, P. Faloutsos, and C. Faloutsos. On [9] D. M. Fleder and K. Hosanagar. Recommender [10] D. H. Gensch and W. W. Recker. The multinomial, [11] P. M. Guadagni and J. D. Little. A logit model of [12] R. Herbrich, T. Graepel, and K. Obermayer. Support [13] O. Kallenberg. Probabilistic symmetries and [14] Y. Koren, R. Bell, and C. Volinsky. Matrix [15] N. N. Liu and Q. Yang. Eigenrank: a ranking-oriented [16] R. D. Luce. Individual choice behavior . Wiley, 1959. [17] C. F. Manski. Maximum score estimation of the [18] D. McFadden. Conditional logic analysis of qualitative [19] M. R. McLaughlin and J. L. Herlocker. A [20] M. McPherson, L. S. Lovin, and J. M. Cook. Birds of [21] K. Miller, T. Griffiths, and M. Jordan. Nonparametric [22] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [23] A. Singh and G. Gordon. A unified view of matrix [24] J. Rennie and N. Srebro. Fast maximum margin [25] T. F. Tan and S. Netessine. Is tom cruise threatened? [26] M. Weimer, A. Karatzoglou, Q. Le, and A. Smola. [27] K. Weinberger, A. Dasgupta, J. Langford, A. Smola, [28] S.-H. Yang, B. Long, A. Smola, N. Sadagopan, [29] Z. Zheng, H. Zha, T. Zhang, O. Chapelle, K. Chen,
