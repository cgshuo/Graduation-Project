 Online learning algorithms are simple, fast, and require less memory compared to batch learning algorithms. Recent work has shown that they can also perform nearly as well as batch algorithms in many settings, making them quite attractive for a number of large scale learning problems [3]. The success of an online learning algorithm depends critically upon a tradeoff between fitting the current data example and regularizing the solution based upon some memory of prior hypotheses. In this work, we show how to incorporate regularization in an online learning algorithm by constraining the motion of weight vectors in the hypothesis space. In particular, we demonstrate how to use simple learning algorithms. This process results in herding the motion of the Gaussian weight vectors to yield algorithms that are particularly robust to noisy input data.
 Recent work has demonstrated how parametric information about the weight vector distribution can be used to guide online learning [1]. For example, confidence weighted (CW) learning maintains a Gaussian distribution over linear classifier hypotheses and uses it to control the direction and scale of parameter updates [9]. CW learning has formal guarantees in the mistake-bound model [7]; however, it can over-fit in certain situations due to its aggressive update rules based upon a separable data assumption. A newer online algorithm, Adaptive Regularization of Weights (AROW) relaxes this separable assumption, resulting in an adaptive regularization for each training example based upon its current confidence [8]. This regularization comes in the form of minimizing a bound on the Kullback-Leibler divergence between Gaussian distributed weight vectors.
 Here we take a different microscopic view of the online learning process. Instead of reweighting and diffusing the weight vectors in hypothesis space, we model them as flowing under a velocity field given by each data observation. We show that for linear velocity fields, a Gaussian weight vector distribution will maintain its Gaussianity, with corresponding updates for its mean and covariance. The advantage of this approach is that we can incorporate different constraints and regularization on the resulting velocity fields to yield more robust online learning algorithms. In the remainder of this paper, we elucidate the details of our approach and compare its performance on a variety of experimental data. These algorithms maintain a Gaussian distribution over possible weight vectors in hypothesis space. In traditional stochastic filtering, weight vectors are first reweighted according to how accurately they describe the current data observation. The remaining distribution is then subjected to random diffusion, resulting in a new distribution. When the reweighting factor depends linearly upon the weight vector in combination with a Gaussian diffusion model, a weight vector distribution will maintain its Gaussianity under such a transformation. The Kalman filter equations then yield the resulting change in the mean and covariance of the new distribution. Our approach, on the other hand, updates the weight vector distribution with each observation by herding the weight vectors using a velocity field. The differences between these two processes are shown in Fig. 1. Figure 1: (a) Traditional stochastic filter-old weight vector. Eq. (1) can also be expressed in dual form, yielding the PA-II update equation: The theoretical properties of this algorithm was analyzed by [5], and it was demonstrated on a variety of tasks (e.g. [3]).
 Online confidence-weighted (CW) learning [9, 7], generalized the PA update principle to multivari-ate Gaussian distributions over the weight vectors N (  X  ,  X ) for binary classification. The mean  X   X  R d contains the current estimate for the best weight vector, whereas the Gaussian covariance matrix  X   X  R d  X  d captures the confidence in this estimate.
 Pr This particular CW rule may over-fit since it guarantees a correct prediction with likelihood  X  &gt; 0 . 5 at every round. A more recent alternative scheme called AROW (adaptive regularization of weight- X  ` h 2 ( y i ,  X   X  x i ) = (max { 0 , 1  X  y i (  X   X  x i ) } ) vector  X  and  X  1 , X  2  X  0 are two tradeoff hyperparameters. AROW [8] has been shown to perform well in practice, especially for noisy data where CW severely overfits.
 In this work, we take the view that the Gaussian distribution over weight vectors is modified by herding according to a velocity flow field. First we show that any change in a Gaussian distributed random variable can be related to a linear velocity field: Theorem 1 Assume that the random variable (r.v.) W is distributed according to a Gaussian dis-tribution, W  X  X  (  X  ,  X ) , Proof: The first property follows easily from linear systems theory. The second property is easily  X   X  Thus, the transformation U = A W + b can be viewed as a velocity flow resulting in a change of the underlying Gaussian distribution of weight vectors. On the other hand, this microscopic view of the underlying velocity field contains more information than merely tracking the mean and covariance of the Gaussian. This can be seen since many different velocity fields result in the same overall mean and covariance. In the next section, we show how we can define new online learning algorithms by considering various constraints on the overall velocity field. These new algorithms optimize a loss function by constraining the parameters of this velocity field. Our algorithms maintain a distribution, or infinite collection of weight vectors { W i } for each round i . Given an instance x i it outputs a prediction based upon the majority of these weight vectors. Each weight vector W i is then individually updated to W i +1 according to a generalized PA rule, and  X  i is a PSD matrix that will be defined shortly. In fact, we assume that  X  i is invertible and thus PD.
 Clearly, it is impossible to maintain and update an infinite set of vectors, and thus we employ a parametric density f i ( W i ;  X  i ) to weight each vector. In general, updating each individual weight-vector using some rule (such as the PA update) will modify the parametric family. We thus employ a Gaussian parametric density with W  X  X  (  X  i ,  X  i ) , and update the distribution collectively, where A i  X  R d  X  d represents stretching and rotating the distribution, and the b i  X  R d is an overall translation. Incorporating this linear transformation, we minimize the average of Eq. (3) with respect to the current distribution, We derive the algorithm by computing the expectation Eq. (4) starting with the first regularization term of Eq. (3). After some algebraic manipulations and using the first property of Theorem 1 to write  X  = A  X  i + b i we get the expected value for the first term of Eq. (3) in terms of  X  and A , Next, we focus on the expectation of the loss function in their second term of Eq. (3). 3.1 Expectation of the Loss Function We consider the expectation, In general, there is no closed form solution for this expectation, and instead we seek for an appro-priate approximation or bound. For simplicity we consider binary classification, denote the signed margin by M = y i ( W &gt; x ) and write ` (( x ,y ) , W ) = ` ( M ) .
 If the loss is relatively concentrated about its mean, then the loss of the expected weight-vector  X  is a good proxy for Eq. (6). Formally, we can define Definition 1 Let F = { f ( M ;  X  ) :  X   X   X  } be a family of density functions. A loss function is uniformly  X  -bounded in expectation with respect to F if there exists  X  &gt; 0 such that for all  X   X   X  respect M  X  f ( M ;  X  ) .
 We note in passing that if the loss function ` is convex with respect to W we always have that, E [ ` ( M )]  X  ` (E [ M ]) . For Gaussian distributions we have that  X  = {  X  ,  X  } and a loss function ` is uniformly  X  -bounded in expectation if there exists a  X  such that, E N (  X  ,  X ) [ ` (( x ,y ) , W )]  X  ` (( x ,y ) , E [ W ]) +  X  2 x &gt;  X  x . We now enumerate some particular cases where losses are uniformly  X  -bounded.
 Proposition 2 Assume that the loss function ` ( M ) has a bounded second derivative, ` 00 ( M )  X   X  then ` is uniformly  X  -bounded in expectation.
 Proof: Applying the Taylor expansion about M = E [ M ] we get, ` ( M ) = ` (E [ M ]) + tion of both sides and bounding ` 00 (  X  )  X   X  concludes the proof.
 For example, the squared loss 1 2 y  X  M &gt; x 2 is uniformly (  X  =) 1-bounded in expectation since its second derivative is bounded by unity ( 1 ). Another example is the log-loss, log(1 + exp(  X  M )) , being uniformly 1 / 4 -bounded in expectation. Note that the popular hinge and squared-hinge loss are not even differentiable at M = 1 . Nevertheless, we can show explicitly that indeed both are uniformly  X  -bounded, though the proof is omitted here due to space considerations. To conclude, Thus, our online algorithm minimizes the following bound on Eq. (4), with a change of variables from the pair ( A, b ) to the pair ( A,  X  ) , where  X  is the mean of the new distribution, In the next section we derive an analytic solution for the last problem. We note that, similar to AROW, it is decomposed into two additive terms: Eq. (7) which depends only on  X  and Eq. (8) which depends only on A . to a generalization of PA-II in Mahalanobis distances (see Eq. (2)), We now focus on minimizing the second term (Eq. (8)) which depends solely on A i . For simplicity we assume  X  = 1 and consider two cases. 4.1 Diagonal Covariance Matrix We first assume that both  X  i and A are diagonal, and thus also  X  i +1 is diagonal, and thus  X  i ,  X  i +1 Denote the r th diagonal element of  X  i by ( X  i ) r,r and the r th diagonal element of A by ( A ) r,r . The respect to ( A ) r,r we get, Figure 2: Top and center panels: element of Eq. (10) and the last equation we get,  X   X  i +1 To conclude, the update of NHERD for diagonal covariance matrices is also more aggressive than AROW as it increases the (diagonal) elements of its inverse faster than AROW.
 An illustration of the two updates appears in Fig. 2 for a problem in a planar 2 -dimensional space. The Gaussian distribution before the update is isotropic with mean  X  = (0 , 0) and  X  = I 2 . Given the input example x = (1 , 2) ,y = 1 we computed both A and b for both the full (top panel) and diagonal (center panel) update. The plot illustrates the update of the mean vector (red square), weight vectors with unit norm k w k = 1 (blue), and weight vectors with norm of 2, k w k = 2 (green). Parameter: C &gt; 0
Initialize:  X  1 = 0 ,  X  1 = I for i = 1 ,...,m do end for orthogonal to the example y i x i ; vectors close to the margin of unit 1 are modified less than vec-tors far from this margin; vectors with smaller margin are updated more aggressively then vectors with higher margin; even vectors that classify the example correctly with large margin of at least one are updated, such that their margin is shrunk. This is a consequence of the linear transformation that ties the update between all weight-vectors. The diagonal update, as designed, maintains a diagonal matrix, yet shrinks the matrix more in the directions that are more  X  X rthogonal X  to the example. We note in passing that for all previous CW algorithms [7] and AROW [8], a closed form solution for diagonal matrices was not provided. Instead these papers proposed to diagonalize either  X  i +1 (called drop ) or  X   X  1 i +1 (called project ) which was then inverted. Together with the exact solution of Eq. (10) we get the following three alternative solutions for diagonal matrices, We investigate these formulations in the next section. Finally, we note that similarly to CW and AROW, algorithms that employ full matrices can be incorporated with Mercer kernels [11, 14], while to the best of our knowledge, the diagonal versions can not. We evaluate NHERD on several popular datasets for document classification, optical character recognition (OCR), phoneme recognition, as well as on action recognition in video. We compare our new algorithm NHERD with the AROW [8] algorithm, which was found to outperform other base-lines [8]: the perceptron algorithm [13], Passive-Aggressive (PA) [5], confidence weighted learning (CW) [9, 7] and second order perceptron [1] on these datasets. For both NHERD and AROW we used the three diagonalization schemes, as mentioned in Eq. (14) in Sec. 4.3. Since AROW Project and AROW Exact are equivalent we omit the latter, yielding a total of five algorithms: NHERD { P,D,E } for Project,Drop,Exact and similarly AROW { P,D } . Figure 4: Performance comparison between algorithms. Each algorithm is represented by a vertex. The weight Although NHERD and AROW are designed primarily for binary classification, we can modify them for use on multi-class problems as follows. Following [4], we generalize binary classification and assume a feature function f ( x ,y )  X  R d mapping instances x  X  X  and labels y  X  X  into a common space. Given a new example, the algorithm predicts  X  y = arg max z  X   X  f ( x ,z ) , and suffers a loss if which replaces y x in NHERD (Alg. 3).
 We conducted an empirical study using the following datasets. First are datasets from [8]: 36 binary document classification data, and 100 binary OCR data ( 45 all-pairs of both USPS and MNIST and 1-vs-rest of MNIST). Secondly, we used the nine multi-category document classification datasets used by [6]. Third, we conducted experiments on a TIMIT phoneme classification task. Here we used an experimental setup similar to [10] and mapped the 61 phonetic labels into 48 classes. We then picked 10 pairs of classes to construct binary classification tasks. We focused mainly on unvoiced phonemes where there is no underlying harmonic source and whose instantiations are noisy. The ten binary classification problems are identified by a pair of phoneme symbols (one or two Roman letters). For each of the ten pairs we picked 1 , 000 random examples from both classes for training and 4 , 000 random examples for a test set. These signals were then preprocessed by computing mel-frequency cepstral coefficients (MFCCs) together with first and second derivatives and second order interactions, yielding a feature vector of 902 dimensions. Lastly, we also evaluated our algorithm on an action recognition problem in video under four different conditions. There are about 100 samples for each of 6 actions. Each sample is represented using a set of 575 positive real localized spectral content filters from the videos. This yields a total of 156 datasets. Each result for the text datasets was averaged over 10 -fold cross-validation, otherwise a fixed split into training and test sets was used. Hyperparameters ( C for NHERD and r for ARROW) and the number of online iterations (up to 20) were optimized using a single randomized run. In order to observe each algorithm X  X  ability to handle non-separable data, we performed each experiment using various levels of artificial label noise, generated by independently flipping binary labels. Results: We first summarize the results on all datasets excluding the video recognition dataset in Fig. 4, where we computed the number of datasets for which one algorithm achieved a lower test error than another algorithm. The results of this tournament between algorithms is presented as a winning percentage. An edge between two algorithms shows the fraction of the 155 datasets for which the algorithm on top had lower test error than the other algorithm. The three panels correspond to three varying noise levels, from 0% , 10% and 30% .
 We observe from the figure that Project generally outperforms Exact which in turn outper-forms Drop . Furthermore, NHERD outperforms AROW, in particular NHERD P outperforms AROW P and NHERD D outperforms AROW D. These relations become more prominent when labeling noise is increased in the training data. The right panel of Fig. 2 illustrates a single update of each of the five algorithms: AROW D, AROW D, NHERD D, NHERD E, NHERD P. Each of the five ellipses represents the Gaussian weight vector distribution after a single update on an example by each of the five algorithms. Interestingly, the resulting volume (area) of different ellipses roughly correspond to the overall performance of the algorithms. The best update  X  NHERD P  X  has the smallest ellipse (with lowest-entropy), and the update with the worst performance  X  AROW D  X  has the largest, highest-entropy ellipse. Figure 5: Three top rows: Accuracy on OCR (left) and text tions. This work was also supported by German-Israeli Foundation grant GIF-2209-1912. [1] Nicol  X  o Cesa-Bianchi, Alex Conconi, and Claudio Gentile. A second-order perceptron algo-[2] Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games . Cambridge Uni-[3] G. Chechik, V. Sharma, U. Shalit, and S. Bengio. An online algorithm for large scale image [4] Michael Collins. Discriminative training methods for hidden markov models: Theory and [5] K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. Online passive-aggressive [6] K. Crammer, M. Dredze, and A. Kulesza. Multi-class confidence weighted algorithms. In [7] K. Crammer, M. Dredze, and F. Pereira. Exact confidence-weighted learning. In NIPS 22 , [8] K. Crammer, A. Kulesza, and M. Dredze. Adaptive regularization of weighted vectors. In [9] M. Dredze, K. Crammer, and F. Pereira. Confidence-weighted linear classification. In ICML , [10] A. Gunawardana, M. Mahajan, A Acero, and Pl att J. C. Hidden conditional random fields for [11] J. Mercer. Functions of positive and negative type and their connection with the theory of [12] K. B. Petersen and M. S. Pedersen. The matrix cookbook, 2007. [13] F. Rosenblatt. The perceptron: A probabilistic model for information storage and organization [14] Bernhard Sch  X  olkopf and Alexander J. Smola. Learning with Kernels: Support Vector Ma-
