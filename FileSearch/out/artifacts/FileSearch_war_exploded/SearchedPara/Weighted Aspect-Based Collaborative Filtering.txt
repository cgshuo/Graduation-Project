 Existing work on collaborative fi ltering (CF) is often based on the overall ratings the items have received. However, in many cases, understanding how a user rates each aspect of an item may reveal more detailed information about her preferences and thus may lead to more effective CF. Prior work has studied extracting/quantizing sentiments on different aspects from the reviews, based on which the unknown overall ratings are inferred. However, in that work, all the aspects are treated equally; while in reality, different users tend to place emphases on difference aspects when reaching the overall rating. For example, users may give a high rating to a movie just for its plot despite its mediocre performances. This emphasis on aspects varies for different users and different items. In this paper, we propose a method that uses tensor factorization to automatically infer the weights of different aspects in forming the overall rating. The main idea is to learn, through constrained optimization, a com-pact representation of a weight tensor indexed by three dimensions for user, item, and aspect, respectively. Overall ratings can then be predicted using the obtained weights. Experiments on a movie dataset show that our method compares favorably with three base-line methods.
 H.3.3 [ Information Search and Retrieval ]: Information fi ltering Collaborative Filtering; Tensor Factorization
Collaborative fi ltering (CF), a popular technique used in rec-ommender systems, makes predictions about a user X  X  interests by collecting preferences information from other users, usually in the form of ratings of items. In most existing CF methods, overall ratings of items are used (e.g.  X  4.5 out 5 stars for iPhone 5S ") . However, ratings at a fi ner granularity may provide more detailed information and thus help improve the effectiveness of CF. For ex-ample, while a user dislikes some aspects of a movie (e.g., music and cinematography), she may still give that movie an overall rat-ing of 9/10 as she likes other aspects of the movie (e.g., plot and acting). Therefore, it is important to take into consideration the preference information on individual aspects for more accurate rat-ing prediction. Recent work by Wang et al. [10] computes aspect ratings based on the opinions expressed towards the constituent as-pect terms which are extracted by a double propagation method and organizes both the overall ratings and the ratings on aspects into a tensor, and takes a tensor factorization approach to exploring the latent structure. It has been shown that incorporating ratings on aspects can improve the effectiveness of CF.

However, a major limitation of the work by Wang et al. [10] is that they assign the same weight to all aspects, while in reality different aspects are seldom treated equally by users. We argue that the overall rating of an item is indeed a weighted combination of the ratings on different aspects, and the different weight put on the aspects by different users re fl ect their divergent preference pro fi les.
For example, consider a movie with two typical reviews by two users along with overall ratings. The fi rst user assigns a 2/5 rating, and the review reads  X  The movie has beautiful music and immac-ulate direction. However, the story has no memorable lines  X . The second user gives the same movie a 4/5 rating, states  X  The story is a bit bland, but I loved the music and the masterful direction ". Both reviews comment on the same aspects, i.e., music , direction and story , and share similar opinions on those aspects. However, their numerical ratings are different. One tenable explanation is that these two users emphasize different aspects when reaching the overall rating. That is, the fi rst user may put a heavier weight on story than the second user, whereas the second user weighs mu-sic and direction more. Clearly, the weight users put on different aspects affects the overall ratings.

In this paper, we tackle the problem of weighting the aspects to achieve more accurate prediction of overall ratings. To keep our discussion focused, we assume that the ratings on individual as-pects can be obtained directly through explicit ratings by the users, or by performing sentiment extraction from reviews when explicit ratings are not available [10]. As mentioned earlier, we believe that the overall rating comes from a weighted combination of the rat-ings for individual aspects. At a fi rst glance, it appears that given a dataset, we could easily build a regression model with the aspect ratings and the overall rating being the variables and the weights being the parameters. However, this will make the number of free parameters (one for each combination of user, item, and aspect) too big to be tractable. In addition, the data could be very sparse, preventing us from getting well-formed solutions to the regression problem. The reason is that while there usually exist many differ-ent aspects for a set of items, many reviews may touch upon only a small portion of those. Also, the explicit ratings on individual as-pects as well as the overall rating may be missing for a signi fi cant number of items, as many websites do not force the users to rate numerically out of user-friendliness considerations.

We hence propose a method based on tensor factorization, which aims to compute a concise representation of the underlying factors for weighting, taking into consideration the fact that many aspect ratings may be missing. Each element of this weight tensor cor-responds to the weight a user puts on an aspect of an item. This weight tensor can therefore be viewed as a three-dimensional ar-ray indexed along the dimensions of user, aspect, and item. We compute the decomposition of this tensor into low rank matrices, subject to the constraint that the tensor reconstructed from those matrices has to consist of the optimal parameters to a linear re-gression problem that regresses the overall rating on aspect ratings. The weighted aspect ratings can then be used to predict the overall ratings in cases where those numerical ratings are not available.
The rest of the paper is organized as follows. We review the related work in Section 2, and de fi ne the problem in Section 3. We present the new model and method in Section 4, and present the experimental results in Section 5. Section 6 concludes this paper. different aspects of an item into rating prediction for CF. How-ever, in that work, the overall ratings and aspect ratings are con-sidered equally important when they are organized into a tensor, while in practice, people have diffe rent preferences on different as-pects. The work presented in this paper improves upon that work through weighting the aspects to better re fl ect the reality.
The Latent Aspect Rating Analysis (LARA) model [8] takes a set of review texts with overall ratings and a speci fi cation of aspects as input, and discovers each individual reviewer X  X  latent ratings on the given aspects. A major limitation of LARA model is the assump-tion of pre-speci fi ed aspects by keywords. Wang et al. [9] further improve LARA by proposing a uni fi ed generative model for LARA that does not need pre-speci fi ed aspect keywords. Our work differs from theirs in that we focus on weighting the aspects for rating pre-diction, where the aspect ratings can be obtained (if not available in numerical form) using a variety of methods for sentiment extraction already proposed in the literature. [5] uses a linear regression formulation to learn author prefer-ences, but it can only be used to get author speci fi c facet prefer-ences on a particular topic. Li et al. [2] exploit the use of tensor factorization to generate latent factors, in order to model the asso-ciation among reviewers, products and text features, but this work does not consider the aspects. writing reviews on a set of items M = { m 1 ,m 2 , ..., m size I  X  J denote a user-item overall rating matrix, where the entry r ij denotes the rating of u i on m j . Normally, a user would have only reviewed a subset of items. We use a matrix S =[ s ij indictor variables s ij to represent whether r ij is observed ( s or not ( s ij =0 ).
 We assume that there are K aspects A = { a 1 ,a 2 , ..., a correspondingly K aspect rating matrices R 1 , R 2 , ..., R K , one for each aspect. We use a vector r ij of length K to represent the aspect-level ratings of user i on item j ,where r ijk is a numeri-cal rating of aspect a k . Similarly, w ij is an aspect weight vector of length K ,where w ijk is a numerical measure indicating the de-gree of emphasis on aspect a k . If an aspect a k of item j is not numerically rated or reviewed by a user i ,wehave w ijk =0 . We use a 3rd-order tensor L =[ l ijk ] I  X  J  X  K of indictor variables l ijk  X  X  0 , 1 } to denote whether r ijk is known ( l ijk =1 )ornot ( l
With the input of the overall rating matrix R and the aspect rat-ing matrices R 1 , R 2 , ..., R K , the problem we address in this paper is to learn the weight that users place on each aspect of each item. Those weights can be incorporated into the aspect rating matrices and produce weighted aspect rating matrices  X  R 1 ,  X  R 2 lar to the procedure in [10], we can aggregate the overall rating ma-trix and the weighted aspect rating matrices into a 3rd-order tensor  X  R , where the size of  X  R is I  X  J  X  ( K +1) . The ultimate goal is to predict the overall rating r ij for item m j which is not yet rated by user u i using  X  R .
One way to learn the parameters w ij is to build a separate regres-sion model for each pair of user i and item j . But since each user usually gives only one overall rating for an item and/or writes one review for an item, it is impossible to build a reasonable regression model with suf fi cient data. Another problem with this approach is that we have I  X  J  X  K parameters to estimate, which is intractable in general. Also, since each user usually rates/reviews only some aspects of a small subset of the items, the data is too sparse to obtain good estimates for those parameters.

We therefore take a tensor factor ization approach to solving the problem of computing the aspect weights. As described in Sec-tion 3, the weights can be arranged as a 3rd-order tensor W where the fi rst, the second, and third dimensions correspond to user, item, and aspect respectively, and each element in the tensor corresponds to a particular parameter w ijk . Tensor factorization is a good fi t for our problem as it is an excellent way of capturing the intrin-sic interactions between the three dimensions: users, items, and as-pect weights. Moreover, tensor factorization will greatly reduce the number of free parameters, overcoming the issues with the afore-mentioned method.

There are multiple ways of computing the factorization. We adopt the CANDECOMP/PARAFAC (CP) approach [1], which can effectively factorize a tensor into a sum of component rank-one ten-sors. We can decompose the tensor W as where R is the number of rank-one components, and in general, the best decomposition is achieved when R is equal to the rank of the tensor W ; the symbol  X  represents the vector outer product; n p and q r are the column vectors in the factor matrices N , P and Q , respectively. The sizes of N , P ,and Q are I  X  R , J  X  R ,and K  X  R , respectively. Element-wise, Eq. (1) can be written as where each row n i , p j and q k of these factor matrices correspond to the latent factors associated with each particular user, item and aspect weight. We can see that the same user factor n i is shared when computing  X  w ijk for different j and k combinations, which effectively captures the possible correlations between  X  w same user. Similarly, the sharing of aspect weight and item factors are achieved in the same way when determining  X  w ijk for different ( i, j )and( i, k )pairs.

The predicted rating  X  r ij using the model can be computed as follows from the weight vector and aspect ratings:
To compute the optimal model parameters N , P ,and Q in terms of prediction error, we seek to minimize the objective function f : subject to the following constraints: for all i =1, 2,  X  X  X  , I , j =1, 2,  X  X  X  , J , k =1, 2,  X  X  X  , K ,where g h ijk are shorthands to be used in the sequel.

Using the PHR method [6], we transform the constrained objec-tive function f into the unconstrained objective function  X  :  X = f + where v ij and u ijk are the multipliers of the equality constraints on h ij and inequality constraints g ijk ,and  X  is the penalty parameter.
Let e ij  X   X  r ij  X  r ij denote the prediction error of the model. The partial derivatives of the unconstrained objective function  X  with respect to model parameters n i , p j and q k are shown in Figure 1, where  X  represents whether u ijk +  X   X  g ijk is greater than 0 (  X  = 1 ) or not (  X  =0 ), and the symbol  X  denotes the element-wise matrix multiplication operation. These gradients allow us to use the gradient descent algorithm to compute the optimal matrices N , P and Q . With N , P and Q computed and hence W approximated using Eq. (1), the weighted aspect rating matrix  X  R k can be obtained as follows: where the matrix W (: , : ,k ) denotes the weights users give on the aspect a k of items. That is, each entry of  X  R k is computed by  X  r w
After the weighted aspect ratings are computed, one can pre-dict the overall ratings for cases where those ratings are available (e.g., users might have written textual reviews on some aspects but have not given a numerical overall rating). Similar to the method proposed in [10], we combine the overall rating matrix R (with unknown entries for ratings unavailable) with the weighted aspect rating matrices  X  R 1 ,  X  R 2 ,  X  X  X  ,  X  R K to form a new 3rd-order tensor Then we employ the CP-WOPT method [3] to factorize the tensor  X  R . Suppose that the factor matrices A , B and C are the results from the CP decomposition of  X  R . The predicted rating that u for m j can be computed by where the parameter D is a positive integer.
Experiments are conducted on a movie dataset including 186,235 reviews on 1,650 movies along with their star ratings crawled from the Internet Movie Database (IMDB). Each rating is in the range of 1-10 stars and the free-text reviews typically have a length of 200 to 500 words. Numerical aspect ratings are obtained through opinion extraction from the reviews using the same method as that in [10]. To make the computation meaningful and the performance more robust, we fi lter out the users who have posted less than 10 reviews, resulting in a smaller and denser dataset. Table 5.1 shows some statistics about the datasets before and after fi ltering, where the density is de fi ned as # reviews (#
We carry out our experiments on the fi ltered dataset. RMSE is used as the evaluation metric to evaluate the prediction accuracy. All results reported are the results of 10-fold cross validation. In order to study the effect of data sparsity, we randomly remove some data from the dataset, creating a data density from 3.1% to 1.6% at interval of 0.5%.

We compare our methods with several baselines. We use the model proposed in [10] (referred to as TF) as the fi rst baseline. For the second baseline, we use the model proposed by Moshfeghi et al. [4] (MR), which incorporates the emotion information into collaborative fi ltering. The third baseline is a widely used matrix factorization approach [7] (MF), which only uses star ratings for collaborative fi ltering.
Figure 2 shows the experimental results on datasets when we vary the data density. We can see that the baseline models TF and MR outperform the baseline model MF, which demonstrates that incorporating users X  opinions on different aspects can improve the effectiveness of CF. In addition, our model, referred to as TF-W, performs better than all three baseline methods. This validates our hypothesis that considering aspect weighting can improve the pre-diction accuracy. Figure 2 also shows that the prediction accuracy of each model decreases as the data becomes sparser. But the rate of accuracy change is different; the RMSE of TF-W increases at a lower rate than the baselines, which shows that TF-W can better adapt to data sparsity than baseline models.
Effect of the number of aspects . In order to study the impact of parameter K on the prediction quality of TF-W and TF, we carry out an experiment in which we vary the value of K from 2 to 16 with a step size of 2. We plot the RMSE at different K values in Figure 3. The data density is set at 3.1%.

We can observe from Figure 3 that the prediction accuracy in-creases as we increase K from 2 to 8, and then deteriorates as we increase K further. RMSE is minimal when K =8 . Therefore, K is set to 8 in our experiments.
Effect of R and D . Wevarythevalueof R (cf. Eq. (1)) from 1 to 10, and see how this affects the performance of the prediction. We also vary D (cf. Eq. (6)) from 3 to 5. The results are shown in Figure 4. We can see that there do exist best choices of R and D . For our dataset, the best results are reached when R is 3 or 4 depending on the value of D . weights for the prediction of overall ratings. To alleviate the prob-lems of data sparsity and model complexity, we exploit a tensor factorization approach to compute the aspect weights, with the goal of minimizing estimation errors on overall ratings. The obtained aspect weights are used in conjunction with the aspect ratings to form the weighted aspect rating matrices, which are then used to perform prediction on the overall ratings. We have performed ex-tensive experiments on a movie review dataset, and results show that the proposed method is indeed effective and outperforms the baseline methods in terms of prediction accuracy. For future work, we would like to explore how the latent factors resulting from fac-torizing the weight tensor can be used to help identify clusters in the users and show the relationships between aspects. This work was supported in part by NSFC (No. 61272092), NS-FSPC (No. ZR2012FZ004), IIFSDU (2012ZD012), the Taishan Scholars Program, and NSERC Discovery Grants. [1] E. Acar, D. M. Dunlavy, and T. G. Kolda. A scalable [2] F. Li, N. Liu, H. Jin, K. Zhao, Q. Yang, and X. Zhu. [3] M. Morup, D. Dunlavy, E. Acar, and T. Kolda. Scalable [4] Y. Moshfeghi, B. Piwowarski, and J. M. Jose. Handling data [5] S. Mukherjee, G. Basu, and S. Joshi. Incorporating author [6] R. Rockafellar. The multiplier method of hestenes and [7] G. Tak X cs, I. Pil X szy, B. N X meth, and D. Tikk. Major [8] H. Wang, Y. Lu, and C. Zhai. Latent aspect rating analysis on [9] H. Wang, Y. Lu, and C. Zhai. Latent aspect rating analysis [10] Y. Wang, Y. Liu, and X. Yu. Collaborative fi ltering with
