 Skyline is a set of points that are not dominated by any other point. Given uncertain objects, probabilistic skyline has been studied which computes objects with high proba-bility of being skyline. While useful for selecting individual objects, it is not sufficient for scenarios where we wish to compute a subset of skyline objects, i.e., a skyline set. In this paper, we generalize the notion of probabilistic skyline to probabilistic k -skyline sets (P k -SkylineSets) which com-putes k -object sets with high probability of being skyline set. We present an efficient algorithm for computing probabilistic k -skyline sets. It uses two heuristic pruning strategies and a novel data structure based on the classic layered range tree to compute the skyline set probability for each instance set with a worst-case time bound. The experimental results on the real NBA dataset and the synthetic datasets show that P k -SkylineSets is interesting and useful, and our algorithms are efficient and scalable.
The skyline of a set of multi-dimensional points consists of the points for which no other point exists that is better in at least one dimension and at least as good along every dimension. It is important for many applications involving multi-criteria decision making.

Assume that we have a dataset of n points, referred to as P . Each point p of d real-valued attributes can be rep-resented as a d -dimensional point ( p [1] ; p [2] ; :::; p [ d ]) where p [ i ] is the i th attribute of p . Figure 1(a) illustrates a dataset of eight points P = { p 1 ; p 2 ; :::; p 8 } , each representing an NBA player with two attributes: rank of points and rank of assists. Without loss of generality, we assume that small values are more preferable in this paper. Figure 1(b) shows the corresponding points in the two dimensional space where x and y coordinates correspond to the value of attributes for rank of points and rank of assists, respectively. Given two points p = ( p [1] ; p [2] ; :::; p [ d ]) and p  X  = ( p  X  in c  X  one i , p [ i ] &lt; p  X  [ i ] (1  X  i  X  d ). We can see that point p dominates point p 6 (7 ; 3) as an example of dominance. Given a set of points P , the skyline of P is the set of points in P that are not dominated by any other point in P . For an NBA coach who is interested in choosing an NBA player consid-ering both rank of points and rank of assists, the skyline of Figure 1(b) includes p 1 , p 3 , and p 7 , which offer Pareto opti-mal solutions with various tradeoffs between rank of points and rank of assists: p 1 is the player with best rank of points, p 7 is the player with best rank of assists, and p 3 may be a good compromise of the two factors. Motivation. Skyline is also meaningful on uncertain data. For example, NBA players may have different performances in different games. Assume that we have four NBA players ( O i ; 1  X  i  X  4), each player O i has two game records or in-stances ( I i;j ; j = 1 ; 2) with different probabilities as shown in Figure 2 (the eight points have the same coordinates as the points in Figure 1). There are 2 4 possible worlds that correspond to the possible states of the four uncertain ob-jects which are shown in Table 1, each with their associated probability. For each possible world, we can compute a set of skyline instances, also shown in Table 1.
 The first study on skyline queries on uncertain data by Pei et al. [23] defines the probability of an uncertain ob-ject being a skyline as the aggregated (sum) probability of the possible worlds in which any of its instances is a skyline point. It studied p -skyline problem which returns the objects with skyline probability greater than a thresh-old p . Zhang et al. [29] studied a similar problem, top k -skyline, which returns k uncertain objects with the highest skyline probabilities. For example, as shown in Figure 2, the probability of NBA player O 1 being a skyline, denoted as P sky { O 1 } , equals to the aggregated probability of pos-sible worlds that I 1 ; 1 or I 1 ; 2 is skyline. I 1 ; 1 is skyline in P W 1 ; :::; P W 8 and I 1 ; 2 is skyline in P W 15 ; P W P p ( P W i ) is the probability of possible world P W i . Similarly, P sky { O 2 } = 0 : 65 ; P sky { O 3 } = 0 : 625 ; P sky { O we set the threshold p = 0 : 6, p -skyline returns O 1 ; O If we set k = 2, top k -skyline returns O 1 ; O 2 .
While the above definitions compute individual skyline ob-jects on uncertain data, there are scenarios where we wish to compute a subset of skyline objects, i.e., a skyline set. For example, an NBA coach may wish to choose a set of k best players to compose a team. Without considering uncertain case, a k -skyline set can be simply defined as any subset of k skyline points (assuming k is smaller than the number of skyline points). For uncertain data, existing works do not consider this set notion explicitly. Intuitively, we can use p -skyline or top k -skyline notion to choose those k objects with highest skyline probability. However, this is not suitable as each individual object is considered independently while we are more interested in the set of objects with their instances being skyline points simultaneously.

In this paper, we extend and generalize the notion of p -skyline which computes individual skyline objects to proba-bilistic k -skyline sets (P k -SkylineSets) which computes sets of skyline objects on uncertain data. Similar to p -skyline, we can define the probability of a set of objects being a skyline set as the aggregated probability of the possible worlds in which the instances of the set of objects are skyline points. We can then compute k -skyline sets with skyline set prob-abilities greater than a certain threshold p . Intuitively, this gives us a set of uncertain objects that have high probabil-ities of being skyline points simultaneously in the possible worlds. This is semantically different from choosing top k -skyline which consider the objects independently. For exam-ple, If we set k = 2, top k -skyline returns O 1 ; O 2 . However, while O 1 ; O 2 have the highest probability of being a skyline object independently, P sky { O 1 } &gt; P sky { O 2 } &gt; P P sky { O 4 } , the set of O 1 ; O 2 may not have a high probability of being a skyline set, i.e., being skyline points simultane-ously in the possible worlds. In fact, if we compute the sky-line set probability, P sky { O 1 ; O 3 } &gt; P sky { O 1 0 : 425).

Another related notion on uncertain skyline by Liu et al. [22] is named U-Skyline query. U-Skyline searches for a set of objects that has the highest probability (aggregat-ed from all possible worlds) as the answer. Back to Ta-ble 1, Set { I 1 ; 1 ; I 3 ; 1 } is the answer in P W 1 and P W {
I wo subsets are returned as U-Skyline because they have the highest probability (0.175) aggregated from all possible worlds. Obviously, U-Skyline is not suitable for choosing a skyline set with fixed size because the results of U-Skyline can have various sizes.

In summary, if we treat the skyline in each possible world as a transaction and each skyline instance as an item, p -skyline and top k -skyline essentially compute the most fre-quent items, while U-skyline computes the most frequent transactions. In this paper, we generalize the notion of p -skyline to P k -SkylineSets which can be considered as com-puting frequent itemsets of size k . Obviously, p -skyline and top k -skyline are special cases of our problem for k = 1.
Given the generalized P k -SkylineSets problem, how can we compute the skyline sets efficiently? Assume that we have n objects, each object has m instances, we have N = nm total number of instances. With the possible world se-mantic, a direct approach is to compute the skyline for each possible world and aggregate the results to obtain the an-swers. Unfortunately, we have O ( m n ) possible worlds, each possible world requires O ( nlogn ) time to compute its sky-line points. Then the problem is converted to finding most frequent itemsets with fixed size k from O ( m n ) transactions which requires O ( m n C k n ). Therefore, the total time com-plexity is O ( m n nlogn + m n C k n ) which is prohibitively costly as n is an exponential term.
 This motivates us to search for more efficient algorithms. Alternatively, we can enumerate all k -object set from the n objects, and compute their probability to be a skyline set. Since each object has m instances, each object set has m k possible worlds (instance sets). In total, we need to enumer-ate C k n m k instance sets. For each instance set, we can scan all possible N instances to compute its probability to be a skyline set. Thus, a baseline implementation of this method leads to O ( C k n m k kN ) time complexity. Because k  X  n in practical applications, this is much faster than the previ-ous approach. In this paper, we investigate two efficient pruning strategies: object pruning and instance pruning, to further improve this method by reducing the search space. In addition, we propose a novel algorithm to compute the skyline set probability for each candidate instance set based on the layered range tree which achieves a worst-case time bound O ( C k n m k knlog d  X  1 N ) for the entire algorithm. This improvement is significant because N is required in baseline algorithm while nlog d  X  1 N is only required in the worst-case. Contributions. We briefly summarize our contributions as follows.
The rest of the paper is organized as follows. Section 2 presents the related work to probabilistic skyline. Section 3 formalizes the problem. Section 4 provides an overview of our proposed algorithm and the two pruning strategies. Section 5 presents the algorithm for computing skyline set probability of candidate sets. We report the experimental results and findings for performance evaluation in Section 6. Section 7 concludes the paper.
The problem of computing skyline (Maxima) is a funda-mental problem in computational geometry field [7, 8, 17, 16, 21] because the skyline is an interesting characterization of the boundary of a set of points.

Since the introduction of the skyline operator by B  X  orzs  X  ony-i et al. [9], skyline has been extensively studied in the database field [24, 20]. With regard to the concept of  X  X n-certain X , there are two series of works: uncertain prefer-ences [26, 25, 5, 6] and uncertain objects [23, 18, 3, 28, 19, 1, 27, 4, 22, 15]. Our work belongs to the latter. A-mong these works, Pei et al. [23] introduced the first proba-bilistic skyline problem, p -skyline. They presented bottom-up and top-down algorithms to return those objects with skyline probability larger than the given threshold p . Lian and Chen [18] studied the monochromatic and bichromat-ic reverse skyline search problem over uncertain databases. Atallah and Qi [3] focused on the worst-case time complex-ity to compute all skyline probabilities for uncertain data, they presented an algorithm with the worst time bound of In their journal version [4], they improved the worst-case time bound to O ( N 2  X  1 d log d  X  1 N ). In dependently, Afshani et al. [1] presented the algorithm with worst-case time com-plexity O ( N 2  X  1 d ). Zhan g et al. [28] studied the probabilis-tic skyline operator over sliding windows. [19, 27] studied the problem of finding an uncertain object with the maxi-mum expected utility. Liu et al. [22] studied the problem of searching a set of tuples that has the highest probability (aggregated from all possible worlds) as the skyline answer. Khalefa et al. [15] focused on the continuous datasets.
Our work focuses on uncertain data and is the first to study how to choose skyline sets with fixed size on uncertain data.
In this section, we introduce some preliminary knowl-edge and formally define the probabilistic k -skyline sets (P k -SkylineSets) problem.
 Skyline and Skyline Sets. We start with the original skyline definition as follows.

De nition 1. ( Skyline ). Given a dataset P of n points in d -dimensional space. Let p and p  X  be two different points in P , we say p dominates p  X  , denoted by p  X  p  X  , if for all i; p [ i ]  X  p  X  [ i ], and for at least one i; p [ i ] &lt; p is the i th dimension of p and 1  X  i  X  d . The skyline points are those points in P that are not dominated by any other point in P .
 We extend the original skyline definition to k -skyline sets as follows.
 De nition 2. ( k -SkylineSets ) A k -point set is a k -Skyline Sets ( k -SkylineSets) if those k points are all skyline points. Example 1. In Figure 1, { p 1 } , { p 3 } , and { p 7 } are 1 -SkylineSets, { p 1 ; p 3 } , { p 1 ; p 7 } , and { p 3 ; p and { p 1 ; p 3 ; p 7 } is a 3 -SkylineSets.
 Probabilistic Data Model. Given a dataset P of n un-certain objects in d -dimensional space. Without loss of gen-erality, we assume each object has m possible instances. If one object has m  X  possible instances where m  X  &lt; m , we can assume that there are m  X  m  X  instances with probability 0. We denote the i th object as O i , and the j th instance of the i th object as I i;j , where 1  X  i  X  n and 1  X  j  X  m . We use p ( I i;j ) to denote the probability of instance I i;j . We assume  X 
Example 2. Figure 2 shows a set of uncertain objects where n = 4 ; m = 2 ; d = 2 . For example, O 1 has two possi-respectively.
 Probabilistic Skyline. For uncertain data, we need to reason about the probability of an uncertain object to be a skyline object. This can be computed as the aggregated probability of each of its instances being a skyline point, since the instances are exclusive of each other. The proba-bility of an object O a being a skyline is, where P sky { I a;b } is the probability of I a;b being a skyline.
To compute the probability of I a;b being a skyline, P sky we first define the dominating set which contains all in-stances that can dominate I a;b , denoted as DS{ I a;b } ,
DS{ I a;b } = { I
The instances of O l ( l  X  = a ) in the dominating set of I is denoted as DS l { I a;b } ,
Thus, we have DS{ I a;b } = P s ( S ) to denote the aggregated probability of the instances of the same object in a set S . Therefore, the probability of I a;b to be skyline can be represented as follows.
 where p ( I a;b ) is the probability that I a;b appears, P s ( DS l { I a;b } )) is the probability that all those instances dominate I a;b do not appear.
 De nition 3. ( p -skyline [23]) p -skyline are those objects O ; 1  X  a  X  n with P sky { O a } X  p . Exampl e 3. As shown in Figure 2, O 1 has two instances I {
I 2 ; 1 ; I 3 ; 1 } , which consists of the instance(s) of O {
I 2 ; 1 } , and instance(s) of O 3 , DS 3 { I 1 ; 2 } = { I fore, I 1 ; 2 is a skyline only when I 1 ; 2 appears and the points in DS{ I 1 ; 2 } do not appear, with probability P sky { I Similarly, P sky { I 1 ; 1 } = 0 : 7 . Therefore, the probability of O being a skyline is P sky { O 1 } = P sky { I 1 ; 1 } + P sky 0 : 775 .
 Probabilistic k -Skyline Sets. Now we generalize the no-tion of probabilistic skyline to probabilistic skyline sets. Let {
O a 1 ; :::; O a k } be a set of k uncertain objects, the probability of the set being a k -SkylineSets is the aggregated probability of each of its possible instance set being a k -SkylineSets.
Given an instance set { I a 1 ;b 1 ; :::; I a k ;b k } , we can find its dominating set as follows, which is the union of the points dominating each instance in the set.
 DS{ I a all the instances are skyline points, only when each of the instances appears and all of the points in its dominating set do not appear. The probability can be represented as follows.

We note that if one instance dominates another instance within the same instance set { I a 1 ;b 1 ; :::; I a k ;b I cannot be skyline points simultaneously.

Example 4. Recall Figure 2, assume k = 2 , we show how to compute P sky { O 1 ; O 2 } . We have P sky { I 1 ; 1 ; I For the instance set { I 1 ; 2 ; I 2 ; 2 } , we have its dominating set, {
I P P 0 : 35 + 0 + 0 : 075 = 0 : 425 .
 Problem Statement. We now define our problem that aims to find P k -SkylineSets which is the k -skyline set with the highest probability of being a skyline set.

De nition 4. ( P k -SkylineSets ) P k -SkylineSets is the k -skyline set { O a 1 ; :::; O a k } with the highest probability of P
To solve the probabilistic k -Skyline Sets problem, intu-itively, we can enumerate C k n candidate k -object sets, and compute their skyline probability as defined in Equation 1. In order to compute the skyline probability for each k -object set, we need to enumerate m k instance sets since each object has k possible instances. For each instance set, we can scan all possible N instances to compute its probability to be a skyline set as in Equation 2. Thus, a baseline implementa-tion of this method leads to O ( C k n m k kN ) time complexity. Algori thm 1 Computation P k -SkylineSets
We prop ose an efficient algorithm for computing prob-abilistic k -skyline sets. It includes two heuristic pruning strategies, object pruning and instance pruning, which effi-ciently reduce the search space for candidate object sets ( C and possible instance sets of each object set ( m k ). The al-gorithm then iterate through all candidate object sets from the remaining objects, and compute its skyline probability by enumerating the possible instance sets from remaining instances and computing its skyline probability. It uses a novel algorithm for computing the skyline set probability for each instance set based on the layered range tree with worst-case time bound O ( knlog d  X  1 N ). The sketch of the algorithm is shown in Algorithm 1. Overall, our algorithm achieves a worst-case time bound O ( C k n m k knlog d  X  1 practically it can be much more efficient.

Next we present the pruning strategies in detail. In the remainder of this section, we assume that no two points in P have the same coordinates. This restriction is not very realistic, but it can be overcome with a nice trick [12].
We first observe an important property of the skyline probability. Similar to the apriori property in frequent item-set mining [2], the skyline probability of an object set never exceeds the skyline probability of its subsets. We present it as a theorem below.

Theorem 1. ( MonotoneProperty ) Given any two ob-ject (instance) subsets S 1 and S 2 of P , and S 1  X  X  2 , we
Proof. We prove this theorem from possible worlds se-mantic. For each possible world i , P sky {S 1 } i  X  P sky where P sky {S} i is the probability of S being a SkylineSets in possible world i . Therefore, we can obtain P sky {S 1 P sky {S 2 } by aggregating all possible worlds.

Based on this property, the basic idea of our pruning strat-egy is to find an object set { O i 1 ; O i 2 ; :::; O ik } prune object O i if P sky { O i } &lt; P sky { O i 1 ; O i 2 reason is that any superset of O i will have skyline probabil-ity  X  P sky { O i } , hence cannot exceed P sky { O i 1 ; O The next question is how to choose the set { O i 1 ; O i 2 pruned. To this end, our idea is to compute the skyline probability for each single object O i and select the k ob-jects with highest P sky { O i } . The intuition is that this set will likely have a high skyline set probability, although by no means it is guaranteed to have the highest probability. We summarize the pruning process in Algorithm 2. This pruning strategy proves to be very beneficial in practice as we show later in our experiments. As we recall the overall time complexity O ( C k n m k nlogN ), it is easy to see the factor C n has a large impact because O ( C k n ) ing the number of objects ( n ), although without worst-case guarantee, it can improve the time efficiency significantly in practice.
 Algo rithm 2 Object pruning
Exampl e 5. Recall the example in Figure 2, we can com-pute P sky { O 4 } = 0 : 325 and P sky { O 1 ; O 2 } = 0 : 425 . Hence, O 4 can be pruned directly.
The intuition of the instance pruning strategy is that if an instance is dominated by all possible instances of another object, then we can prune it directly. The reason is that the probability of it being a skyline point is 0, and hence the probability of any of its superset being a skyline set is also 0 based on the monotone property. The challenge is that it is time consuming to check whether an instance is dominated by all possible instances of each object. Hence, our idea is to compute a minimum bounding rectangle for all possible instances of each object. Then if an instance is dominated by its maximum corner, it is dominated by all the instances in the box. Formally, given an uncertain object O the maximum corner of the minimum bounding rectangle of O . Note that I l max is not necessarily an actual instance of O . In this case, we treat it as a virtual instance.
Theorem 2. For any instance I i;j ; 1  X  i  X  n; 1  X  j  X  m , if it can be dominated by any of I l max ; l  X  = i; 1  X  l P I i;j . Thus, P s ( DS l { I i;j } ) = 1. Therefore, P sky 0.
 Toge ther with Theorem 1, the probability of any instance set containing I i;j being a skyline set is also 0. Hence, we can prune I i;j directly. For example, in Figure 3, we com-pute the maximum corners of the minimum bounding box of O ; O 2 ; O 3 ; O 4 , which are shown as crosses. Those instances on the upper right of the four crosses can be deleted directly.
The key step of Algorithm 1 is to compute the skyline {
I a 1 ;b 1 ; :::; I a k ;b k } . A naive way is to scan all remaining O ( N ) instances after pruning to find the dominating set of the instance set which takes O ( kN ) time. In this section, we present a novel algorithm based on the layered range tree which achieves O ( knlog d  X  1 N ) worst-case time bound.
It is easy to see that the key to the probability computa-tion is Equation 2, i.e., to find those instances in the range that can dominate any of the instances in { I a 1 ;b 1 ; :::; I Going back to Figure 2, and take { I 1 ; 2 ; I 2 ; 2 } as an example. There are three instances I 1 ; 1 ; I 2 ; 1 ; I 3 ; 1 that can dominate {
I tively, we have the dominating set DS{ I 1 ; 2 ; I 2 ; 2 } summarize, the key operation here is to retrieve all instances from the range shown with bold line. In order to find the dominating instances efficiently, we use a range query data structure, layered range tree, as an index to enhance the search process. In addition, we augment the layered range tree with cumulative information in order to compute the skyline set probability efficiently.

We first provide a brief description of the layered range tree in Section 5.1. We show how to build an augmented cumulative layered range tree in two dimensional space with time complexity O ( N logN ) in Section 5.2. We then show how to compute the skyline set probability for each instance set in O ( knlogN ) in Section 5.3. Finally, we show how to extend it to higher dimensional space in Section 5.4. The reasons why we employ layered range tree rather than R-tree [14] are: i) R-tree cannot provide good worst-case guarantee, ii) it is not easy to adapt R-tree to report the cumulative in-formation which is required for the probability computation due to the irregularity of MBRs.
Layered Range Tree [12]. Let P be a set of N points in d -dimensional space. A layered range tree for P can be constructed in O ( N log d  X  1 N ) time. With this layered range tree one can report the points in P that lie in a rectangular query range in O ( log d  X  1 N + v ) time, where v is the number of reported points.
 The layered range tree of Figure 1 is shown in Figure 4. The main tree is essentially a binary search tree based on the x -coordinate of the points. Each node n i has an associ-ated structure a i . The detailed associated structure of Fig-ure 4 implemented by the fractional cascading technique [11, 10] is shown in Figure 5. Each subset of P associat-ed with a node is stored in an array which is sorted on the y -coordinate of the points. Each element in the associated structure a ( v ) of node v stores a point and two pointers: a pointer to the associated structure of the left child of node v , denoted by a ( lc ( v )), and a pointer to the associated struc-ture of the right child of node v , a ( rc ( v )). In more detail, assume that the ( i + 1) th element of a ( v ), a ( v )[ i ], stores a point p ( p x ; p y ). Then we store a pointer from a ( v )[ i ] to the element of a ( lc ( v )) storing p  X  ( p  X  x ; p  X  y ) such that p mallest one that is larger than or equal to p y . The pointer to a ( rc ( v )) is defined in the same way: it points to the element of a ( rc ( v )) storing p  X  X  ( p  X  X  x ; p  X  X  y ) such that p one that is larger than or equal to p y . ( 1 , 5) ( 3 , 8) ( 4 , 2) ( 5 , 9) ( 6 , 7) ( 7 ,
Example 6. The fractional cascading technique is shown in Figure 5. The 5 th element of the associated structure a 1 of node n 1 , denoted by a 1 [4] , has two pointers. Its left pointer points to element a 2 [1] in the associated structure a 2 of node n 2 (the left child of n 1 ) because the y -coordinate of the point p stored in a 2 [0] , denoted by a 2 [0] :p y a [0] :p y &lt; a 1 [4] :p y (2 &lt; 5) and a 2 [1] :p y = a 5) . Its right pointer points to element a 3 [3] in the associ-ated structure a 3 of node n 3 (the right child of n 1 ) because a [2] :p y &lt; a 1 [4] :p y (4 &lt; 5) and a 3 [3] :p y &gt; a
Given a range query on layered range tree, we go through the main tree to find all the nodes that are associated with the range on the x -coordinate. And then, for the corre-sponding associated structures of those nodes, we find those points in the range by the pointers of fractional cascading technique based on the y -coordinate.
Given an instance I i;j , we know that with layered range tree, we can retrieve the points (instances) in P that lies in a rectangular query range, i.e., the dominating instances of I i;j , in O ( logN + v ) time, where N is the number of instances and v is the number of reported instances. Unfortunately, v can be as large as N which leads to O ( N ) time complexity, i.e., no improvement for the worst-case time complexity be-cause we can achieve O ( N ) by scanning all the N instances. Analyzing the expression of O ( logN + v ), part logN is re-quired because we need to scan O ( logN ) nodes on the tree, part v is required if we need to report all the points in the rectangular range individually. Fortunately, we do not need to retrieve those v points individually, we just need to know the cumulative probability information of those v points, in order to compute the skyline set probability. This is simi-lar to range count, in which case, we do not need to report all v points individually, we only need to know the cumu-lative count, i.e., how many points there are. If we could build an index structure that can report those cumulative information in O ( logN ) time, then the range query can be finished in O ( logN ) time. And our goal is to build such an index structure in O ( N logN ) time. In the follows, we show how the accumulative information is defined and then show how to build the accumulative layered range tree with such accumulative information.

Recall the query processing of layered range tree. For any query range [ x; x  X  ] ; [ y; y  X  ], we need to search those nodes in [ x; x  X  ] based on the main tree in O ( logN ) time. Then we need to search [ y; y  X  ] in those O ( logN ) associated structures. Hence, if those associated structures record some cumulative information and it can be obtained in constant time, then we can finish the entire search in O ( logN ) time. Unfortu-nately, for each associated structure with N  X  elements and a random range [ y; y  X  ], there are O ( N  X  2 ) different combina-tions of elements corresponding to different combinations of y and y  X  for which we need to store the cumulative informa-tion. It is both time and space consuming to compute and store such information. Fortunately, in our problem as we will show later, we can always decompose the query range into several [ x; x  X  ] ; [0 ; y  X  ] ranges. Given a [0 ; y are only O ( N  X  ) different combinations of the elements cor-responding to different y  X  for which we need to store the cumulative information. We formally define the cumulative information of each element as follows.

De nition 5. ( Cumulative Information ). For the ( j + 1) th element of i th associated structure a i , denoted by a its corresponding cumulative information C ( a i [ j ]) is an ar-ray of n elements (recall n is the number of uncertain ob-jects) recording the aggregated probability of the points (in-stances) stored at a i [0] ; a i [1] ; :::; a i [ j ]. The l the accumulative information array records the aggregated probability of those instances corresponding to object O l
Example 7. The associated structure of the cumulative layered range tree of Figure 2 is shown in Figure 5. Each element in the associated structure stores an accumulative information array. In the root associated structure a 1 , for probability of I 2 ; 2 , p ( I 2 ; 2 ) = 0 : 5 . For the element of I a [1] , we store [0 ; 0 : 5 ; 0 : 5 ; 0] because it records the aggregated probability of two instances I 2 ; 2 and I 3 ; 1 .
In our accumulated layered range tree, in addition to s-toring the point and the pointers in each element of the associated structure, we store the accumulative information array in this element.

We now show how to build the accumulative layered range tree. The detailed algorithm is shown in Algorithm 3. Line 1-10 is similar to constructing layered range tree which can be finished in O ( N logN ) time. Line 1 constructs the asso-ciated structure, such as a 1 in Figure 5. Line 2 determines the terminal condition. P is split into two subsets P left P right by x mid in Line 5. Line 6 and 7 recursively compute the cumulative layered range tree of P left and P right . Line 8 creates the main tree by x min , such as n 1 in Figure 4. Fractional cascading technique is used in Line 9. The cu-mulative information of each element is computed in Line 11-15. For the cumulative information of each element a i we need to add the probability of the instance I l;k stored in Algo rithm 3 Build 2D Cumulative Layered Range Tree( P ) element a i [ j ] to the l th element (corresponding to object O of the cumulative information of a i [ j  X  1]. There are in total O ( N logN ) elements in the associated structures. Therefore, we can compute the cumulative information in O ( N logN ) time. Because Line 1-10 can be finished in O ( N logN ), we obtain a theorem as follows.

Theorem 3. Algorithm 3 can be nished in O ( N logN ) time.
 Figure 5: A cumulative layered range tree example.
Given the cumulative layered range tree built in Section 5.2, we illustrate how to compute the skyline set proba-show how to query the cumulative information of a range [ x; x  X  ] ; [0 ; y  X  ] in O ( logN ) time in Algorithm 4. It works by finding the nodes in the main tree corresponding to the range [ x; x  X  ], and then reporting the accumulative information in the associated structures corresponding to the range [0 ; y We search the first node v split such that x  X  v split &lt; x Line 1. If v split is a leaf node, we report its cumulative in-formation. Otherwise, we follow the path from lc ( v split x and report the cumulative information associated with its right subtrees (  X  x ). For each node v on the path, if x we report the cumulative information of right child of v and make left child of v be the new v . Otherwise, we make right child of v be the new v . If v is a leaf, we just report the cumulative information. Then similarly, we follow the path from rc ( v split ) to x  X  and report the cumulative information associated with its left subtrees ( &lt; x  X  ).
 Algori thm 4 2D Cumulative Layered Range Query From th e root to leaves, we need to scan O ( logN ) nodes: O ( logN ) to x and O ( logN ) to x  X  . To report the cumula-tive information corresponding to [0 ; y  X  ], we need to be a bit careful. If we report cumulative information of each n-ode by binary search to determine y  X  individually, it requires O ( logN ) for each node. However, by the technique of frac-tional cascading, we can use binary search to find the cumu-lative information in root node, and use the pointers to find the cumulative information in its children and grandchildren in constant time. Therefore, we obtain a theorem as follows. Theorem 4. Algorithm 4 can be nished in O ( logN ) time.
Given an instance I a;b , we can query the cumulative infor-mation of those instances in a rectangular range that domi-nates I a;b using the cumulative layered range tree as above. After obtaining those O ( logN ) cumulative information ar-rays each with n elements, we sum those O ( logN ) arrays, the l th element is the sum of all l th elements of the O ( logN ) arrays, which is equal to P s ( DS l { I a;b } ) used in Equation 2, the aggregated probability of all instances corresponding to object O l that dominate I a;b . We can then use Equation 2 to compute the skyline set probability P sky { I a;b } . Therefore, we can obtain the theorem as follows.

Theorem 5. Given any instance I a;b , P sky { I a;b } can be computed in O ( nlogN ) time.

Example 8. We show how to compute P sky { I 1 ; 2 } . Be-cause the coordinate of I 1 ; 2 is (5 ; 9) , we set the query range as [0 ; 5) ; [0 ; 9) . First, we need to query [0 ; 5) in the main tree of Figure 4. We determine v split by a binary search algorithm, which is node n 2 . Because 0 is smaller than the x -coordinate of node lc ( n 2 ) , i.e., 1 . We report the cu-mulative information of the associated structure of rc(n2) which is a 9 . Follow the algorithm, we need to report the cumulative information of associated structure a 9 , a 8 , a Follow the pointers from element of a 1 to associated struc-ture a 9 , a 8 , a 10 , we determine the cumulative information, sum is [0 : 7 ; 0 : 5 ; 0 : 5 ; 0] . Therefore, P sky { I (1  X  0 : 5)  X  (1  X  0 : 5)  X  (1  X  0) = 0 : 075 .

Given an instance set, we need to decompose the domi-nating range into multiple rectangular ranges with the re-quirement that the range of y coordinates in each rectangle begins with 0. For k instances I a 1 ;b 1 ; :::; I a k ;b of generality, assume a 1 &lt; ::: &lt; a k , then it is easy to see b &gt; ::: &gt; b k , otherwise, some point of those k points will dominate another one. We decompose the dominating range into k query ranges as [0 ; a 1 ) ; [0 ; b 1 ) then ( a 1 so on. Therefore, we can query the cumulative information associated with each range to compute the skyline set prob-ability. We can obtain a theorem as follows.

Theorem 6. Given any instance set { I a 1 ;b 1 ; :::; I a P
Example 9. We show how to compute P sky { I 2 ; 1 ; I 4 ; 1 Because the coordinates of I 2 ; 1 , I 4 ; 1 are (3,8), (7,3), respec-tively. We decompose the query range as [0,3), [0,8) and (3,7), [0,3). For [0,3), [0,8) and (3,7), [0,3), we obtain the cumulative information [0.7,0,0,0], [0,0,0.5,0], respectively. Therefore, P sky { I 2 ; 1 ; I 4 ; 1 } = (1  X  0 : 7)  X  p ( I p ( I 4 ; 1 ) = 0 : 0375 .
It is fairly straightforward to generalize two dimensional cumulative layered range tree to higher dimensional space. Let P be a set of N points in d -dimensional space. The first d  X  2 dimensions can be processed by traditional layered range tree and the last two dimensions can be handled by the algorithms shown in Section 5.2 and 5.3. Detailed discussion is omitted due to the limited space. In this section, we first study the effectiveness of P k -SkylineSets on real NBA dataset and then perform an exten-sive empirical study to examine the heuristic pruning strate-gies and the skyline set probability computation algorithm based on layered range tree on synthetic and real datasets. Since this is the first work for k -skyline sets on uncertain da-ta, our performance evaluation was conducted against base-line only. We implemented the following algorithms.
We implemented all algorithms in C++ and ran experi-ments on a machine with Intel Core i7 running Ubuntu with 8GB memory. For the layered range tree index structure, we adapted the implementation of [13]. We used both real NBA dateset and synthetic datasets in our experiments.
We first demonstrate the effectiveness of P k -SkylineSets through a small real NBA dataset. We chose 42 players with the highest skyline probability in Table 2 of Pei et al. [23]. We downloaded their recent ten years X  statistics from http://www.basketball-reference.com. Please note that the career years of some players are less than ten years and some players stopped their career several years ago. We treat each player as an uncertain object and the annual records of each player as the instances of the object. Three attributes are selected in our experiment: points (PTS), assists (AST), and rebounds (REB). The larger those attribute values, the better. We show how to choose five players to compose a  X  X old team X . Therefore, in this NBA dataset, n = 42 ; m = 10 ; d = 3 ; k = 5.

The skyl ine probabilities of the individuals and the sets are shown in Table 2 and 3, respectively. Table 2 shows the skyline probabilities of those 42 players. Because we only consider 42 players while [23] considered 1313 players, the skyline probabilities as well as the resulting p -skyline play-ers in our experiment are much higher than and different from those in Table 2 of [23]. For example, Magic John-son has the highest probability in our example because he did very well in his last ten years career while not so good between 1991 and 2005 (stopped in 1996). The probabil-ities of the sets being a skyline set are shown in Table 3. Since there are C 5 42 = 850668 candidate sets from the 42 players, we only show the first 8 sets with highest proba-bilities. We can see that the first five players ( { 0,1,3,9,21 with highest skyline probability in Table 2 compose the P k -SkylineSets with highest skyline set probability. However, P sky { 0 ; 1 ; 3 ; 10 ; 21 } is higher than P sky { 0 ; 1 ; 3 ; 7 ; 21 the only differing player Michael Jordan (ID=7) has higher skyline probability than Chris Webber (ID=10). The results verify that the set of objects with higher individual skyline probabilities does not necessarily lead to higher skyline set probability.
We use both real NBA dataset and synthetic dataset-s to study the efficiency and scalability of our methods. We downloaded recent ten years X  statistics of 1000 players from http://www.basketball-reference.com/ with two more attributes (steals (STL) and blocks (BLK)) than Section 6.2, which composes the NBA dataset. We also generated in-dependent (INDE), correlated (CORR), and anti-correlated (ANTI) datasets following the seminal work of [9]. For the uncertain case, we generalized uncertain instances following the method of [23].
 We first study the efficiency of the four algorithms on INDE dataset ( m =10, k =5, d =5). In Figure 6, we show the time cost for BL, RT, HBL, and HRT on different number of objects n . Although both RT and BL are fairly slow, RT is significantly faster than BL, which validates the efficiency of our probability computation algorithm based on layered range tree. HBL and HRT are much faster than BL and RT, which validates the benefit of our pruning strategies. In the Figure 6: The impacts of RT and BL on different n . following experiments, because the time cost of RT and BT are prohibitively high, we only compare HRT and HBL. Figure 7: The impacts of different k; d on NBA dataset.
 Study on NBA dataset. Figure 7 shows the results on different k and d . The time cost grows exponentially with k and HRT significantly outperforms HBL. We did not report the result of HBL algorithm for some figures due to the high cost when k is big. The time cost also grows exponentially with d , HRT significantly outperforms HBL when d is small. However, when d is big, the difference is small due to the effect of  X  X urse of dimensionality X .
 Study on Synthetic datasets. The results for the syn-thetic datasets are shown in Figure 8, 9, and 10. Generally speaking, the time cost for ANTI dataset is higher than INDE, and the time cost for INDE is higher than COR-R. This is easy to understand because more instances are pruned in CORR dataset by our heuristic pruning strate-gies. On the other hand, it is harder to prune instances in ANTI dataset. From the global perspective, our algorithms are shown to be efficient and scalable, most of our experi-ments can be finished in 10 6 ms.

The impacts of different n are shown in (a) of Figure 8, 9, and 10 ( m =10, k =5, d =5). Although the time complexity C m k knm &lt; C k n m k knlognm when m is small, HRT is much faster than HBL. There are two reasons: 1) the number of objects is much smaller than n after using heuristic pruning strategies, 2) the factor nlognm of HRT is the worst-case while the factor nm is required. Comparing HRT to RT in Figure 6, HRT is almost 10 4 times faster than RT. Similar improvement can be observed for HBL and BL.

The impacts of different m are shown in (b) of Figure 8, 9, and 10 ( n =1k, k =5, d =5). When m = 10 and m = 100, the time cost is fairly small because we can prune most of the instances in the heuristic pruning phase. However, when m = 1 k , HRT can finish in 10 6 ms but HBL re-quires too much time which was not reported. The reason is that when m is big, although we can prune some instances, those objects with highest probability to be a skyline can-not be pruned and each object has m instances. For ex-ample, even when n = 10 ; m = 1 k , C k n m k N = 4 : 5  X  while C k n m k nlogN = 6  X  10 9 and as we discussed before, C m k nlogN is the worst-case.

The impacts of different k are shown in (c) of Figure 8, 9, and 10 ( n =1k, m =10, d =5). The set size k has significant effect on both HBL and HRT because k is the exponential term. Again, HRT outperforms HBL significantly.

The impacts of different d are shown in (d) of Figure 8, 9, and 10 ( n =1k, m =10, k =5). They show that HRT is much faster than HBL when d is small. But the time cost of HRT grows exponentially because d is the exponential term. The time cost of HBL should increase linearly. However, in the experiment, Figure 10(d) shows that the time cost of HBL grows exponentially, the reason is when d increases, it is hard to prune instances by heuristic pruning strategies on ANTI datasets. Because most of the instances are pruned on CORR datasets, Figure 9(d) shows the time cost of HBL almost does not change for different d .
In this paper, for the first time, we studied probabilistic k -skyline sets problem on uncertain data. We show two sig-nificant heuristic pruning strategies which are efficient and simple. We adapted the classic layered range tree index structure to enhance the baseline algorithm from worst-case time bound aspect. The idea should be of independent in-terest for other problems. The experimental results on the real NBA dataset and the synthetic datasets show that P k -SkylineSets is interesting and useful, and our algorithms are efficient and scalable.
 This research is partially supported by the Air Force Of-fice of Scientific Research (AFOSR) DDDAS Program under award number FA9550-12-1-0240, the National Natural Sci-ence Foundation of China (Grant No. 11271351) and Guang-dong Science and Technology Program Fund 2013B091300019.
