 Citation recommendation is concerned with recommending papers that should be re-ferred to. When starting a work in a new research topic or brainstorming for novel ideas, a researcher usually wants to have a qui ck understanding of the exiting literatures in this field, including which papers are the most relevant papers and what sub-topics are presented in these papers. Two common w ays to find reference papers are: (1) search documents on search engines such as Google and (2) trace the cited references by start-ing with a small number of initial papers (seed-papers). Unfortunately, for (1) it would be difficult to find a comprehensive keyword list to cover all papers, especially for be-ginning researchers. It is very possible to miss important developments in areas outside a researcher X  X  specialty. For (2), an averag e paper may cite more than twenty papers. It would be quite time consuming to analyze each of the cited reference to see whether it is useful or not, especially with the increase of the tracing depth. Additionally, even a well organized paper may miss some important  X  X elated work X , due to space limitation or other reasons.

Previously, papers recommendation has been studied, for example, by exploring col-laborative filtering [7]. Our problem is relevant, but different, from this kind of work. Firstly, in citation recommendation, the user is interested in not only a list of recom-mended papers, but also the sub-topics presented in these papers. Secondly, conven-tional methods can only recomme nd papers; but cannot suggest the citation position (i.e., which sentences should refer to the citation).

In this paper, we formalize citation recommendation as that of topic discovery, topic-based recommendation, and matching citatio n sentences with the recommended papers. We propose a unified and discriminative approach to citation recommendation. This ap-proach can automatically discover topical as pects of each paper and recommend papers based on the discovered topic distribution. Experimental results show that the proposed approach significantly outperforms the baseline methods. We define notations used throughout this paper. Assuming that a paper d contains a vector w d of N d words, in which each word w di is chosen from a vocabulary of size V ; and a list l d of L d references. Then a collection of D papers can be represented as D = { ( w 1 , l 1 ) ,  X  X  X  , ( w collection D . Thus the size L of the vocabulary of references is D . Further, we consider that each paper is associated with a distribution of T topics, so is the citation. Definition 1. (Citation Context and Citation Sentence) Citation context is defined by the context words occurring in, for instance, the user written proposal. For an example, the words  X ... We use Cosine computation [x] evaluate the similarity ... X  would be a citation context. One reference paper is exp ected to be cited at the position  X  X x] X . We use c to denote a citation context. Each sentence in the citation context is called citation sentence. The position  X  X x] X  to cite the r eference paper is called citation position. Figure 1 shows an example of citation recommendation. The left part of Figure 1 in-cludes a citation context provided by the user and a paper collection. The right part shows the recommended result that we expect a citation recommendation algorithm outputs. For instance, two topics, i.e.,  X  X ext s ummarization X  and  X  X nfo rmation retrieval X , have been extracted from the citation context. For the first topic  X  X ext summariza-tion X , two papers have been recommended and for the second topic  X  X nformation re-trieval X , three papers have been recommended. Further, the recommended papers are matched with the citation sentences and the corresponding citation positions have been identified.

We see that the recommended papers are topic dependent. By nature, the problem of citation recommendation can be formalized as t opic discovery, reference papers recom-mendation, and matching of the recommende d papers with the citation sentences. At a high level, our approach primarily consists of three steps: 1. We propose a two-layer Restricted Boltzmann Machine (RBM) model, referred 2. We present a method to rank papers for a given citation context, based on the 3. We describe a method to find the correspondence between the recommended papers 3.1 The RBM-CS Model Restricted Boltzmann Machines (RBMs) [8] are undirected graphical models that use a layer of hidden variables to model a (topic) distribution over visible variables. In this work, we propose a two-layer RBM model, called RBM-CS, to jointly model papers and citations. Graphical representation of the RBM-CS model is shown in Figure 2. We see that in RBM-CS, the hidden layer h is associated with two visible layers: words w and citation relationships l , respectively coupling with an interaction matrix M and U .The basic idea in RBM-CS is to capture the topic distribution of papers with a hidden topic layer, which is conditioned on both words and citation relationships. Words and citation relationship are considered to be genera ted from the hidden topics independently.
To train a graphical model, we can consider maximization of the generative log-likelihood log p ( w , l ) . However, we are dealing with a predictive problem, our interests ultimately only lie in correct prediction p ( l | w ) , not necessarily to have a good p ( w ) . Therefore, we define a discriminative objective function by a conditional log-likelihood:
The probability p ( l j | w d ) can be defined as: where  X  ( . ) is a sigmoid function, defined as  X  ( x )=1 / (1 + exp (  X  x )) ; e are bias terms f ( w i ) are feature functions for citation relationship l j and word w i , respectively; a are bias terms for hidden variables. For simplicity, we define f ( w i ) as the count of word w i in document d . We define binary value for the feature function of citation relationship l . For example, for document d , f ( l j )=1 denotes that the document d has a citation relationship with another paper d j .

Now, the task is to learn the model parameters  X  =( M , U , a , b , e ) given a training set D . Maximum-likelihood (ML) learning of the parameters can be done by gradient ascent with respect to the model parameters ( b are bias terms for words). The exact gradient, for any parameter  X   X   X  can be written as follows: where E P 0 [ . ] denotes an expectation with respect to the data distribution and E P M is an expectation with respect to the distribution defined by the model. Computation of the expectation E P M is intractable. In practice, we use a stochastic approximation of this gradient, called the contrastive divergence gradient [4]. The algorithm cycles through the training data and updates the model par ameters according to Algorithm 1, where the probabilities p ( h k | w , l ) , p ( w i | h ) and p ( l j | h ) are defined as: where b are bias terms for words; f ( l j ) is the feature function for citation relationship. 3.2 Ranking and Recommendation The objective of citation recommendation i s to rank the recommended papers for a given citation context. Specifically, we apply the same modeling procedure to the cita-tion context. Hence, we can obtain a topic representation { h c } of the citation context c . Based on the topic representation and the modeling results, we can calculate the prob-ability of each paper being the reference paper for the citation context according to Equation (6). Finally, the papers are ranked in terms of the probabilities and the top K ranked papers are returned as the recommended papers. It is hard to specify an accurate value of K for each citation context. A simple way is to set it as the average number of citations in a paper (i.e., 11 in our data set). 3.3 Matching Recommended Pap ers with Citation Sentences The purpose of matching the recommended papers with citation sentences is to align the recommended papers with sentences in the citation context. This can be done by using each recommended paper as a keyword query to re trieve relevant citation sentences. In general, we may use any retrieval method. In this paper, we used KL-divergence to measure the relevance between the reco mmended paper and the citation sentence: where d is a recommended paper and s ci is the i th sentence in the citation context c ;the probabilities p ( h k | d ) and p ( h k | s ci ) , which can be obtained by (4). 4.1 Experimental Setting Data Set. We conducted experiments on two data sets, NIPS 1 and Citeseer 2 .TheNIPS data set consists of 12 volumes of NIPS papers (1,605 papers and 10,472 citation rela-tionships). Each paper contains full text and its citations. We removed some citations with incomplete information, e.g., consisting of only authors and publication venue, but no title. We also removed citations that do not appear in the data set. The Citeseer data set consists of 3 , 335 papers (with 32,558 citation relationships) downloaded from the Citeseer web site. As well, we removed citations that do not appear in the data set.
Each paper was preprocessed by (a) removing stopwords and numbers; (b) removing words appearing less than three times in the corpus; and (c) downcasing the obtained words. Finally, we obtained V =26 , 723 unique words and a total of 350 , 361 words in NIPS and V =44 , 548 unique words and 634 , 875 words in Citeseer. Evaluation Measure and Baseline Methods. We used P@1, P@3, P@5, P@10, Rpec, MAP, Bpref, and MRR as the evaluation meas ures. For the details of the measures, please refer to [1] [2]. We conducted the evaluation on both paper-level (without con-sidering the citation position) and sentence-level (considering the citation position).
We defined two baseline methods. One is based on language model (LM). Given a citation context c , we computed the score of each paper d by p ( c | d )= w  X  c p ( w | d ) , where p ( w | d ) is the maximum likelihood of word w in document d . We ranked papers according to this score and recommended the top K ranked papers.

The other baseline is based on RBM, which learns a generative model for papers and the citation context. Then we use KL-diverg ence to calculate a score for each paper (by a similar equation to Equation (7)). For both RBM and RBM-CS, we set the number of topic as T = 200 and the number of recommended references as the average number of thedataset,i.e. K =7 for NIPS and K =11 for Citeseer. The weights were updated using a learning rate of 0.01/batch-size, momentum of 0.9, and a weight decay of 0.001. 4.2 Experimental Results Estimated Topics. Table 1 shows two example topics discovered by RBM-CS from the NIPS data. We can see that our model can capture the topic distribution very well. Performance of Citation recommendation. Table 2 shows the result of citation rec-ommendation. We see that our proposed model clearly outperforms the two baseline models. The language model suffers from the fact that it is based on only keyword matching. The RBM uses a hidden topic layer to alleviate the problem. However, it is aimed at optimize p ( w ) , which might be inappropriate for citation recommendation. In addition, RBM cannot capture the dependencies between paper contents and citation relationships. Our proposed RBM-CS can be advantageous to optimize p ( l | w ) directly and to model the dependencies between paper contents and citation relationships.
We can also see from Table 2 that the reco mmendation performance is much better on the Citeseer data than that on the NIPS data. This means that on the sparse data, the recommendation tasks would be more difficult. How to improve the recommendation performance on the sparse data is also one of our ongoing work.

Table 3 shows the performance of citation recommendation by RBM and RBM-CS in terms of sentence-level evaluation. (As the Citeseer data contains a lot OCR errors and it is difficult to accurately extract th e citation position, we conducted sentence-level evaluation on the NIPS data only.) We can again see that our proposed model significantly outperforms the method of using LM and that of using RBM. We review scientific literatures about citation analysis and related topic models. Citation analysis usually employs a graphical model to r epresent papers and their relationships, for example Science Citation Index [3]. This index links authors and their corresponding papers. Bibliographical Coupling (BC) [6] and co-citation analysis are proposed for citation analysis, for example to measure the quality of an academic paper [3].
Recommending citations for scientific pap ers is a task which has not been studied exhaustively before. Strohman et al. [9] investigated this task using a graphical frame-work. Each paper is represented by a node and the citation relationship is represented as the link between nodes. A new paper is a node without in and out links. Citation recommendation is then cast as link prediction. McNee et al. [7] employed collabora-tive filtering in citation network to recommend citations to papers. Both of them use the graphical framework. We look at citation reco mmendation from a different perspective. We take advantages of the dependencies bet ween paper contents and citation relation-ships by using a hidden topic layer to joint model them.

Restricted Boltzmann Machines (RBMs) [8] are generative models based on latent (usually binary) variables to model an input distribution, and have been applied in a large variety of problems in the past few years. Many extensions of the RBM model have been proposed, for example dual wing RBM [12], modeling various types of in-put distribution [5] [11]. In this paper, we propose a two-layer Restricted Boltzmann Machine model, called RBM-CS, which can jointly model topic distribution of papers and citation relationships. In this paper, we formally define the problems of topic-based citation recommendation and propose a discriminative approach to this problem. Specifically, we proposes a two-layer Restricted Boltzmann Machine model, called RBM-CS, to model paper contents and citation relationships simultaneously. Experimental results show that the proposed RBM-CS can significantly improve t he recommendation performance.

There are many potential future directions of this work. It would be interesting to include other information for citation recommendation, such as conference and author information. We are going to integrate the citation recommendation as a new feature into our academic search system ArnetMiner [10] (http://arnetminer.org).

