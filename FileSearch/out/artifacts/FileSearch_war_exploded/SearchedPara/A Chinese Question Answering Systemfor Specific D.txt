 With the increasing development of mobile internet, more and more people found smartphone a handy choice to acquire knowledge and assistance in their daily life. Among many such mobile apps, Siri is one of the best example that can accept and respond with natural language sentences, such as  X   X  X  X  X  X  X  X  X   X  X  (What X  X  the weather like today) X ,  X   X  X  X  X  X  A(Call A) X . The power of Siri actually reflects the state-of-the-art results of many typical research problems. Apparently, Question Answering (QA) is one of them to answer questions like the former question above. To address the increasing needs to provide more accurate and professional response to user X  X  requests in specific areas, recently, a number of similar applications, such as Sogou Voice Assistant and Xunfei Yudian , have been launched by other companies, but more focusing on answering domain-specific natural language questions. However, the performance of those accurate question answering results for specific domains.
 ence(TREC) and the Message Understanding Conferences(MUCs) [4], some QA systems have achieved good performance [5, 6]. However, mainstream Question Answering systems only focus on English language. Natural language QA sys-tems in Chinese are almost a blank due to many reasons including the complexity and diversity of Chinese language, lack of reliable knowledge base for the back-bone of QA engine. So Chinese users have to search the answers in specific search engine, such as Soso Music , or in general search engine, which can return direct answers, but only effective when searching by keywords in the traditional way in search engine, thus lack of accuracy and understanding of user X  X  intentions, thus can only return general-purpose contents and leave the burden to find out answers to the users.
 materialized it as a publicly available Chinese interactive Question Answering system in musical domain. The solution is a combination of many practical techniques which includes: 1) natural language understanding, 2) knowledge base construction, management and query, 3) dialog system techniques. Section 2 outlines the architecture of the system; Section 3 describes the natural language understanding process; Section 4 describes the algorithm of dialog management; Section 5 introduces the knowledge base and Section 6 presented the experiments in comparison with Siri system. There are four major components in our system:  X  Dialog Management  X  Natural Language Understanding  X  Knowledge Base  X  Answer Constructor Dialog Management is the central coordinator component [7], which receives natural language questions from user, discomposes the question into subprob-lems to dispatch to other components to solve, and progressively interacts with users to understand user X  X  intention and provides direct answers. Natural Lan-guage Understanding unit (NLU) transforms questions into semantic frames via named entity recognition and patterns. Knowledge Base unit converts the se-mantic frame into SPARQL sentences and retrieves direct knowledge items to the question. Answer Constructor unit constructs answers in natural language using results from Knowledge Base unit.
 the specific targets of the user X  X  intention, and may interact with user in natural language until the target is clarified. For example, the target in the musical QA system could be a song, a singer, or an album, etc.
 edge base. The knowledge base also provides source of knowledge for Natural Language understanding units. For instance, Named Entity recognition, pattern extraction and matching all heavily depends on known entities.
 NLU unit upon the arrival of a question, which identifies the name entity, and then transforms it into predefined categories, e.g.  X   X  X  X  X   X  the pattern matching module will be invoked to retrieve the specific target of the question and converts this natural language question to an internal seman-tic frame. The Dialog Management unit hence checks the semantic frame to judge whether specific conditions are satisfied. If the condition are not satis-fied, for example, some component is missing or ambiguity is found, the Dialog Management unit will let the Answer Constructor unit ask the user to provide missing information or try to resolve ambiguities. When all conditions are met, the Knowledge Base unit will convert the semantic frame to a SPARQL sentence and get the direct answer from the knowledge base. If it can not get the direct answer, it will invoke the community QA module to get the answer. Finally, the Answer Constructor unit will give users a natural language answer. extensibility and has been successfully migrated to three domains including the original musical field, medical science and China Mobile service. Just for consis-tence, we will stick with musical domain as example throughout this paper. 3.1 Named Entity Recognition Entity database is constructed to support dictionary-based Named Entity Recog-nition. All entity lists are extracted from structured data supported by Tencent. entity aliases. When a question comes, all the possible results of Named Entity recognition are saved in order to reduce the chance of false negatives in entities. album, area, chart, drama, language, singer, song, style and type. Below is an example of Named Entity Recognition. Note that in our entity lists, there is a song named  X   X  X  X  X   X  and a singer named  X   X  X  X  X   X  as well. The result of Named Entity recognition for question  X   X  X  X  X  X  X  X  X  X  (Who sings the song  X  X  X  X  ) X  is shown as below. 3.2 Semantic Pattern Matching Main aim of natural language understanding component is to find the target of the question and convert the natural language question to a semantic frame. The semantic frame is a collection of slots, and each slot is a piece of structured information extracted from the question, which might be required to find the answer by our Question Answering system. We use semantic patterns to ex-tract semantic frame from the question. Each semantic pattern consists of three components:  X  Target : Information slot type to be extracted using the pattern;  X  Pattern : Template to be aligned with the question text to extract the target,  X  Priority : The confidence of the semantic pattern es(with longest match) are chosen. Then the matched semantic patterns are sort-ed by their corresponding priority and the sorted list are sent to the knowledge base component. For example, suppose we have a semantic pattern: { target : singer; song :  X  X  X  X  } . As there is no pattern like  X  X inger  X  X  X  X  X  X   X , though the Named Entity recognition results may suggest that  X   X  X  X  X   X  X an also be a singer, this frame is filtered by pattern matching. 3.3 Semantic Pattern Generation The semantic patterns are generated automatically as described in F Bu X  X  publi-cation [8]. The targets in the automatically generated patterns are tagged man-ually. In this way, it is easy for our system to be migrated to other domains. word with an untyped placeholder after POS tagging. Finally we count the ap-pearance of patterns over all questions. The target placeholders of these patterns are labeled manually and count of occurrences are taken as the priority of the pattern.
 question answering dataset are used to generate the semantic patterns. Dialog Management maintains the information context of the conversation be-tween human and computer. The following conversation is an example that the first question-answer pair set up the context for the next question, which implic-itly uses the previous answer as the subject.
 different topic trees. Each tree has several leaf nodes represented the information of conditions the topic needs. Leaf nodes are connected by AND and OR in order to judge whether the conditions have satisfied or not.
 information. The content of SII can be stored while the topic tree changed. semantic frame. Target means the aim of the question and the condition means the constrains.  X  Both target and condition  X  Only target  X  Only condition  X  None and leaf nodes. The inner node has two values, AND and OR , represented the relation of its children should satisfy. PP refers to the imported inner nodes. From the topic tree in Fig.3, a query (album || singer || targets. We only need to maintain a current topic tree. Upon moving to the next question, if it doesn X  X  have some target, the current topic tree just inherit the context from the previous sentence.
 conditions. We put the conditions into the trees and judge by the relation of leaf nodes. 5.1 Knowledge Base Generation In our system, knowledge is relations and facts between objects in the domain of interest. Each piece of relation or fact is represented by a triple in our knowledge base, which consists of two entities and a relation, i.e t =( s, p, o ). We regard the name entity as a subject entity s and object entity o and the target in the system as a Relation p . The following table is an example of our structured data. provides more direct access to the relation between entities. Meanwhile, the knowledge base is stored by triples which can support advanced query engines like SPARQL 1 . For complex questions, SPARQL can reduce the complexity of the statement effectively compared with traditional SQL so that it decreases the transformation difficulty from natural language to structural queries. mentioned above. In our system, we convert triples by DB2Triples can associate multiple tables in relational database and generate triples to avoid problems mentioned above. 5.2 Knowledge Base Query As mentioned above, the semantic frame consists of a target t and a group of conditions C . We define the subject entity of the question as e , and the answer as x .
 base, which is the first constraint of SPARQL.
 tion in semantic frame is defined as c =( p, o ) ,p  X  R ( elation ) ,o to a group of constraint in triples in this way.
 Examples The semantic frame of question  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  (List some songs of a female Japanese rock singer) X  is as follows: { target=song, gender=  X  (female), nationality=  X  X  X  (Japan), style=  X  X  X  (rock) 5.3 cQA module Our system has a cQA(Community Question Answering) module [2] to get the answer if direct answer cannot be retrieved from knowledge base. The cQA mod-ule is built by millions of QA pairs extracted from online QA communities, like Baidu Knows and Soso Wenwen . Baidu Knows is a Chinese language collab-orative Web-based Collective intelligence by question and answer provided by the Chinese search engine Baidu. Soso Wenwen is another community question answering provided by Tencent. When a question comes, we find the similar question in all QA pairs and get a question list. Then we get an answer list from the question list. Finally we rerank the answer list and get the best answer. 6.1 Baseline system and Our system Due to the lack of publicly available Chinese QA systems, we chose Siri as the baseline system for comparison, which is capable of Chinese Question Answering. Siri is an intelligent personal assistant and knowledge navigator in Apple Inc. X  X  iOS. Siri has both speech and text interfaces.
 messaging communication service developed by Tencent in China. We tested our question answering system in musical domain, which is publicly available. User can test our system by chatting with  X   X  X  X  X  X   X  in Official Account of WeChat. However, our system interacted with user using text only. 6.2 Dataset We randomly selected 200 questions from an internet musical QA forum. These natural language questions cover all the targets of our system, including singer, song, album, publish time, style, lyric, height, theme song and so on. of the system. We manually got the right answer of the question from internet as the golden standard answer, and tested both systems using 200 questions mentioned above, including Siri , our system, our system without cQA module and only cQA module.
 provided a question list and the testers were freely choose their way to interact with the system. After that, they filled in a system questionnaire rating their experience comparing Siri and our system. 6.3 Results Testers were asked to identify answers that they thought were right. The result is shown in Table 2. Can X  X  Answer means that the system responds the user that it cannot answer the question, while Error means that the system returns a wrong answer.
 baseline system.
 while Siri cannot gives a correct answer and played the latest song in iPhone instead. It shows that our system has more flexible semantic patterns than the Siri .
 But Siri responded a link of the movie  X  X rave Heart X  in Wikipedia. Apparently Siri failed to take use of the word  X  X lbum X  to correctly identify  X  X rave heard X  as a music album instead of a movie in Named Entity Recognition.
 These consisted of questions concerning each system to be rated on a five point scale (1-Worst to 5-Best). It evaluates the various attributes of the systems, including ease of use, response time, understanding and so on. Mean and Median for each system are shown in Table 3. Results show that although our system is not performing significantly better than the baseline system (SQ1,SQ5), users seem to find it more understanding and has more accurate answers than the baseline.
 6.4 Analysis
There are 78 questions that our system can not respond the right answers. Our system answered 20 of 200 questions incorrectly. 5 questions are due to the missing of target in our data. These questions X  targets aim at the targets that our structured data does not have. For instance, user wants to know we can not get the direct answer. We search the answer from community QA module and get the wrong answer. Other missing targets of our data include
Famous songs of singers and Part song . Apparently this type of errors could be improved by training such relations into the sysytem.
As our system is not a real-time update system, we do not have some newest data, like  X   X  X  X  X  (The fox) X . If the user ask the question answer.
 base is crawled from internet, such as Baidu Baike and Hudong Baike .Wecan not guarantee the accuracy of these data so that there are some errors in our knowledge base. For instance, the theme song of the drama  X   X  X  X  X  X  (Chinese Paladin) X  is  X   X  X  X  X  (Sha po lang) X  in fact while our knowledge base responds  X   X  X  X  X  (Chen Zhongyi) X  which is a singer instead. these 58 questions, we found that 24 questions are due to the missing of target in our data and 27 questions are due to the missing knowledge piece of our data. right, 43% can X  X  answer and 4% error. The distribution is 34%, 60%, 6% if we only use cQA module. The result shows the importance of cQA module as it can make our system answer more questions, nearly 8%, that can not be answered formerly. It is a positive component for system although it raises the error rate meanwhile. The result shows the cQA module effectively raises the recall though reduces the precision of our system to some extent.
 and dependable. Siri mostly answer the question by searching on the internet. However, some users complained that they want to our system tell them the source of the answer to help them judge the confidence, either from the knowledge base or from the cQA module. On the contrary, Users found our system lack of speech recognition so that they had to spend more time on typing. Users also think our GUI a little simple as it only responds a sentence and it reduces their experience. All of the disadvantages mentioned above need further work. musical domain than Siri , though this is intuitively as expected since it is hard for the open domain system to be optimized towards specific fields. We plan to make pattern generation in NLU unit automatically so that we can generate patterns rapidly when we change a domain. We will take advantage of a large amount of QA pairs in community QA and generate pattern by semi-supervised algorithm of machine learning. We will build a specific domain parser if possible [9, 10]. It can enhance the universality and scalability of our system. We presented a domain-specific Chinese interactive Question Answering (QA) system. The system has a dialog management model using Topic Forest to keep track of user X  X  interests. The system can understand natural language questions and transform them into semantic frame using semantic pattern matching model. We used knowledge base to store the structured data and also have a community QA module to answer questions by finding most similar question. We present this system on WeChat and users can chat with it easily on mobile phone. users. The results show our system has a significant improvement than the base-line system in terms of both accuracy and user satisfaction rates. Users found our system more understanding and have more accurate answer. They believed these could be important features in vertical domain question answering. The results were statistically significant. Although there are still some disadvantages in our system, like the GUI and lack of speech recognition, users prefer our system to the baseline overall.
 Acknowledge m ent. T his work was partly supported by the following grants fro m : the National Basic Research Progra m (973 Progra m ) under grant No. 2012CB316301, the National Science Foundation of China project under grant No. 61332007, Noah X  X  Ark Lab of Huawei T echnologies, and the T singhua Uni-versity Initiative Scientific Research Progra m (with No. 20121088071).
