 G.3 [ Probability and Statistics ]: Probabilistic algorithms; H.4.m [ Information Systems Applications ]: Miscella-neous Comments; User Profiling; News; Blogs; Topic Modeling; Collaborative Filtering; Hybrid Recommendation Systems c  X 
Online news and blog portals have emerged as convenient tools to gather information and exchange thoughts. Facility of commenting on such news and blog sites have raised the experience of users and, through active user-engagement, play a pivotal role in the hosting site X  X  popularity [ 1]. Com-ments have thus garnered much research interest, ranging from detecting spam [ 3] to summarization [4 ], ranking [5 ] and retrieval [ 6]. Instead of studying comments, in this pa-per we explore the key question of what stimulates a user to make a comment on such online media. We demonstrate that content can reveal a significant amount of knowledge about users X  commenting interests which can be leveraged to elicit further commenting through specific and personal-ized recommendations of comment-worthy articles. This is a form of recommendation aimed at enhancing user engage-ment through commenting.
 Consider a blog post reviewing Samsung Galaxy S5 , dated Feb 25, 2014 1 , with over 160 comments, shown in Fig. 1. The review discusses various features in different segments like the cover material (purple colored), the new features of fingerprint scanner (colored red), heartbeat reader (colored green), the MicroUSB support (colored blue), etc. Notice that some users commented almost entirety on the new fea-ture of heartbeat scanner, like Carl ( ..An inconspicuous way to check your pulse.. , colored green); while some commented on the MicroUSB aspect, like Bob ( ..I do hope USB 3.0 C comes out soon.. , colored blue). In the same article, some users commented on the story solely for the purpose of reply-ing to an existing comment, like Mark who replied to users Alice and Carl ( ..it will only measure your pulse rate.. , col-ored green). This demonstrates the varied nature of specific interests of users in commenting.

Investigating the user-comments of such articles, we ob-serve that a user can comment on an article mainly for four reasons, if he is interested in (1) the content of the article, (2) content of other users X  comments on the article, (3) con-tent of a specific part of the article or (4) if users with similar interests have commented on the article. While user-interest in existing comments and users is a well-known phenomenon which is realized in the form of explicit reply-to feature on most sites, the concept of commenting-interest in specific parts of articles is a recent finding [7 ]. Indeed, realizing the importance of this very behavior, recent blogging-platforms like Medium 2 and WordPress 2 have started to offer per-paragraph commenting facility, to wide-spread popularity.
ArsTechnica Gadgets: http://tinyurl.com/ktlyv6x medium.com ; wordpress.org/plugins/inline-comments
Explicitly modeling users X  commenting interests is the key component in making comment-worthy recommendations. Realize that without modeling all the above interests explic-itly, the user-article indicator matrix of comments is not fully indicative of commenting interest. Thus, traditional collab-orative filtering (CF) methods [8, 9] used to recommend ar-ticles for viewing [ 10 ] are not very effective in recommending articles to users for commenting. Moreover, such CF meth-ods [8 , 9] are known to suffer from the problem of item cold-start , new content on which no user has commented. On the other hand, state of the art hybrid models like collaborative topic regression [ 2], do not model comment-content and the varied user interests, giving unsatisfactory performance. Re-cently, an attempt was made to recommend news articles to users for commenting [1 ]. However, due to the inability to leverage article and comment content, the approach is un-able to distinguish users X  specific interests in commenting, leading to sub-optimal results. Moreover, the reliance of the approach on less informative meta-data, like tags, causes unsatisfactory performance specially in cold-start scenario which is ubiquitous in the realm of online media.

We explore the role of content in recommending comment-worthy articles and propose content-driven user profiling ai-med at elicitation of users X  commenting interests. We iden-tify that user profiles should depend on content of articles on which user previously commented, content of user X  X  previ-ous comments and the co-commenting pattern of users. The resulting problem (Section 2) turns out to be an instance of a correspondence problem between the article and com-ment content, and a collaborative filtering problem of finding co-commenting patterns. To this end, we propose (Section 3) a novel hierarchical Bayesian model, namely Collabora-tive Correspondence Topic Models (CCTM), which solve the problem by bringing together topic modeling [ 11], collabo-rative filtering [8 ] and Bayesian personalized ranking [ 9].
To tackle the challenge of modeling comment-content, we use the recently introduced concept of multiple topic vec-tors [7], to discover user interest in specific article segments and create topic profiles of users from previous comment-content . By associating each user and each segment of ar-ticle with latent offsets , we show how the topic profiles can be leveraged to model users commenting interests through a Bayesian personalized ranking approach [ 9]. Through these content-driven profiles, CCTM naturally handles cold-start problem in recommendation without relying on meta-data.
The resulting inference problem becomes non-standard due to dependency among several variables introduced thr-ough the three different modeling components and there are no off-the-shelf solutions. We develop (Section 4) an efficient stochastic Monte Carlo expectation maximization (MCEM) inference algorithm for CCTM. CCTM is used to generate article recommendations for future commenting and is rigor-ously evaluated (Section 5) on three real datasets , consisting of crawled copies of 1 popular News sites and 2 popular Blogs. We find that, on average, CCTM achieves 16% im-provement in AUC and 165% improvement in Hit-Rank@5 over state-of-the-art recommendation systems [ 1, 2].
K is the number of topics and V is number of words in vo-cabulary.  X  k is a V -dimension vector such that P V j =1 Figure 1: Examples of various commenting inter-ests of users. Article segments and comments are color coded so that they correspond to same topic.
 Dashed arrow indicates a reply-to comment. 1, popularly called as a  X  topic  X . x T y is dot product of vectors x and y . Dir denotes Dirichlet distribution, Ber denotes Bernoulli distribution, and N denotes K dimension mul-tivariate normal distribution. [ n ] = { 1 , 2 ,...,n } and | R | : cardinality of set R . I [ . ] is the indicator function,  X  means  X  X istributed as X  and 1 n is a n -dimension vector of ones.
We begin by introducing relevant notation to describe the data. An article A d , indexed by d or j  X  [ D ], is composed of S d segments (sentences or paragraphs), A d = { s da | a  X  [ S with each segment being a bag-of-words s da = { w dan [ N da ] } . Each article has a set of C d comments denoted by E d = { c de | e  X  [ C d ] } , with comment c de = { w 0 dem [ n de ] } where w 0 dem is the m th word of comment e on article d . Furthermore w dan ,w 0 dem  X  [ V ], where V is vocabulary size. The unique set of U users is indexed by user-id i  X  [ U ]. For each user i , A + i  X  [ D ] denotes the set of articles i commented on and A  X  i  X  [ D ] denotes the set he did not comment on.
Analyzing commenting interests of users is a crucial step in achieving our goal. Commenting interest of user i can be on three aspects; (1) general content of article A a specific segment s da ( a  X  [ S d ]) or (3) a subset of existing comments (  X  [ C d ]) and their corresponding users. The set R di  X  [ S d ]  X  [ C d ], for each user i , will be denoted as the set of his commenting interests in article d . If user i makes a comment being interested on any component of R di , we say that user i has made a comment on article A d .

Given article-comment pairs { ( A d ,E d ) } D d =1 , classify for every user i  X  [ U ], whether i will comment on A d , by finding the set R di of commenting interests for user i in article d .
As a glimpse of things to come, the model we propose will associate with each potential element of R di a real-valued score for each user, which is then combined to give an overall commenting-interest score of that article for the user.
The task of recommending comment-worthy articles is tightly bound with finding commenting interests. We de-scribe some key challenges below. (1) Inapplicability of supervised approaches. Explicit su-pervision about R di is generally unavailable for the user X  X  prior commenting history and creating such labeled data is costly, enforcing an unsupervised approach. (2) Low correlation between user X  X  interest and article X  X  main topic. A user may be interested in a specific part of an article (see Fig. 1) denoted by R di . The proportion over topics for R di can be very different from that of the entire article and size of R di can be as small as a sentence. That makes correlation between user X  X  interest in the article and main content of the article very low, enhancing the difficulty for statistical models. (3) Low correlation between user interest and majority of the comments. Most of the articles in a popular site will receive comments of varied topics. Although many of the comments will focus on main topic of the article, but a sig-nificant number of comments diverge from that [7 ], and a user may be interested in comments which are on different topic than most of the comments. (4) Comments are short and diverse. A key observation we make here is that the information of a user X  X  specific in-terests is hidden in his prior comment content , as can be seen in Fig. 1. However, simple textual overlap is unsuitable to discover this relation. Moreover, due to the short and noisy nature of comments, modeling comment-content is challeng-ing and approaches often rely on external text enrichment [4 , 12 ], which is impractical for ever-increasing datasets. (5) Cold-Start conditions. New online articles are gener-ated at a very rapid pace, leading to the problem referred to as cold-start . That is, finding user interest in fresh articles with no existing comments ( | C d | = 0). This prohibits use of vanilla matrix factorization [8 , 9].
Our approach lies in the literature on correspondence topic models and recommendation systems. CorrLDA [11 ] was the first topic model to model correspondence between images and their annotations. Within user modeling, [ 13 ] apply the LDA model on user X  X  view logs to predict which stories a user will view. [ 14 ] developed topic models to profile experts in community Q&amp;A. Outside topic modeling, [ 6] developed lan-guage models incorporating comment content for retrieving related news stories, but ignores user-information and per-sonalization. None of these [ 6, 13, 14 ] model commenting behavior or recommend articles for commenting.

Collaborative filtering (CF) is an active area of research with rich literature [15 , 16 ]. The most common example is probabilistic matrix factorization (PMF) [8 ], which ana-lyzes interdependencies between items and users. However, CF approaches are prone to the problem of cold-start which has led to research in hybrid CF methods. [ 5] developed a hybrid regression based latent factor model to rank com-ments on news articles, by leveraging meta-data. Recent research in hybrid CF methods, like collaborative topic re-gression (CTR)[ 2], has combined LDA and PMF for gener-ating article recommendations, by leveraging item content. Quite recently, [17 ] showed the advantage of using articles in users X  libraries to generate relevant recommendations of scientific articles. These methods [2 , 17 ] cannot model com-ment content and are unsuitable for the given task.
More germane to our work is the recent study of [ 1], who look at recommending news articles for commenting. They use a CF approach relying crucially on article tags as meta-data to handle cold-start. This has the following problems: a) Extensive editorial effort is required to ensure fine-grained tags with every new article. Indeed, the datasets that we crawled ( 5.1 ), only have generic categories like Tennis , mak-ing it impossible for the model to distinguish user X  X  commen-ting interest on any two new articles on Tennis. b) It ignores both article and comment content, making it impossible to analyze commenting interests of users. As opposed to this, our model does not rely on meta-data by modeling article and comment content.
In order to solve the problem of recommending comment-worthy articles, we propose in this section a novel hierarchi-cal Bayesian modeling approach, namely collaborative cor-respondence topic models (CCTM). Full generative process is given in Fig. 2. We describe the modeling details below.
Our objective in this paper is to analyze specific reasons behind commenting activity of users and apply that suit-ably to recommend articles for further commenting. Our ap-proach is based on four key steps; (1) create topic profiles , (2) combine topic profile with latent offsets , (3) quantify comm-enting interests and (4) finally rank the preferences. CCTM thus brings in specific correspondence modeling (step 1), col-laborative filtering (step 2 and 3) and Bayesian personalized ranking (step 4) together. We describe the steps below.
As evinced by the example of Fig. 1, articles cover multiple topics in different segments and comment content can be related to such very specific segments, which in addition may not be contiguous. Due to this fact, proportion over topics should vary across the segments within an article and CorrLDA [11 ] fails to capture this aspect. We resort to the concept of multiple topic distributions (topic vectors) [ 7].
For every article, there are J d topic vectors {  X  dt resenting its varied themes. For each word of a segment, a topic vector  X  dt is sampled from a multinomial  X  , and the topic assignment of the word is then sampled from  X  dt Contrast this to CorrLDA, where a single  X  d is fixed for the article and any random segment has same distribution as the entire article (in expectation), whereas MTV allows it to be significantly different. Following [ 7], stick-breaking process (SBP) [18 ] is used as prior for  X  . MTV thus allows us to model low correlation in topic of a comment with an article but high correlation with topic of a specific article segment.  X  For k  X  [ K ], sample topic  X  k  X  Dir (  X  1 V )  X  For each user i  X  [ U ],  X  For each article-comment pair, d  X  [ D ]  X  For articles d  X  [ D ], sample v d 0  X  X  (0 , X   X  1 v I )  X  For users i  X  [ U ],  X  For each user-article pair, ( i,d )  X  [ U ]  X  [ D ],
To relate comment content to specific segments of the ar-ticle, topic assignment of comment words is sampled from subset of segments, rather than uniformly from entire arti-cle like CorrLDA. For every comment, the subset of article-segments is sampled through selector variable  X  . Then the topic assignment of each word in comment e is generated from a mixture distribution de  X  de + (1  X  de )  X  de ; where  X  is the uniform distribution over selected segments and de user X  X  propensity to select from the article d or his own in-terests 3 ,  X  i . To capture commenting interests of users, each user is associated with topic interests defined by a distri-bution over topics,  X  i .  X  i relates user i  X  X  comment content we index user variables by comment-id for simplicity across his commenting history and allows comment-topics to vary from the article distribution based on the user X  X  other interests. Through this mechanism, we allow comments to exhibit content which is better modeled by the user X  X  diverg-ing interests from the current article. This is essential for modeling all the varied types of commenting activity and not ignore a substantial amount of comment content.
After modeling the correspondence between article and comments, we create topic profiles. For each user i , we con-struct an empirical topic distribution  X  q i from the topic as-signment of all his prior comments which can be considered a summary of user X  X  topic interests. Similarly, each article d  X  X  segment a and comment e get empirical topic distributions  X  s da and  X  c de , respectively. These topic profiles will now be refined collaboratively to model users X  commenting interests.
To model users X  commenting interests, we introduce latent offsets to the topic profiles, much in the vein of [ 2, 19 ].
We introduce latent offsets for each user i ( u i ), each seg-ment a  X  [ S d ] ( v da ) of article d and a global offset for each article d ( v d 0 ), in order to model the varied commenting interests. Following PMF approach [ 8], the latent offsets are drawn from zero-mean K -dimensional Gaussian distri-bution. These offsets will allow the topic profiles to change according to observed commenting interests.

Suppose that the user Mark (in Fig. 1) has till now com-mented on mobile apps which gets reflected in his topic-profile. However, now his comments on the related topic of health app (green article-segment), cannot be explained by the content-model alone, due to lack of his prior comment-content on this topic. The latent offset will model this be-havior by increasing the value for the health topic in the user X  X  offset and mobile app topic in the corresponding seg-ment X  X  offset, due to the commenting activity of similar users like Alice who were also interested in mobile apps but also commented on health topic in this article and other articles.
The latent offsets, thus, will serve the purpose of allowing the topic profiles to deviate according to observed comm-enting patterns. The offsets are learned from the overall commenting activity, so the more comments users make, the better idea the model gets of the value of the offsets.
Latent offsets and topic profiles will be combined to give an overall commenting-interest score ,  X  r id , for each user i on article d , by taking into account interest in each element of R di . To this end, we create content-driven user profiles, by combining topic profiles of users (content information) with the latent offset (co-commenting information) to obtain user i  X  X  profile, (  X  q i + u i ). Following Bayesian approach, by associating (zero mean) latent offsets with topic profiles, we ensure good back-off estimates to the topic profile in sparse commenting scenarios. Similar profiles are considered for article segments and comments in the following section.
A user can comment on the main article, a specific seg-ment of the article or on some existing comments. We model interest in these aspects using scores r mf , r art and r spectively. The idea behind computing these scores is that, the closer the user X  X  profile is to the profiles of these three aspects, the higher his interest is in that specific aspect.
Users like Anon in Fig. 1 are interested in the main topic or popularity of article. Similar to PMF[ 8], we capture this: where h d  X  N (0 , X   X  1 h ) is a popularity bias and v global latent offset for article. Notice that unlike vanilla PMF (which would consider u T i v d 0 ), we use the complete user profile (  X  q i + u i ) which allows the model to ensure that user X  X  interest do not deviate much from his previous con-tent interests. For a new article with no existing comments (i.e. cold-start), there is no contribution from this term.
The segment X  X  latent profile is considered as (  X  s da + v where  X  s da is the topic-distribution of the segment. This pro-file is expected to capture the topic-level popularity of this segment among users. We thus set r art ida = (  X  q i + u v da ), for a  X  [ S d ]. Now considering the maximum value we get the score for the segment with highest interest as below.
Consider a latent profile of existing comment e on A d to comment and u de is the latent offset associated with user of this comment. We thus consider the interest in comment e as r c ide = (  X  q i + u i ) T (  X  c de + u de ). Note that  X  c specific but u de is a global parameter for the user, avoiding explosion of the number of parameters to be learned (as quantity of comments can be high).

Main challenge in accounting for interest in [ C d ] is that users often don X  X  respect the reply-to relations while comm-enting [12 ]. Moreover, such relations are unavailable for ar-ticles on which user has not yet commented. To model this, let  X  ide denote a Bernoulli random variable, with  X  ide = 1 if user i  X  X  comment on d is a reply-to comment to the comment e . Thus, the expected overall interest in existing comments: where p ide = P (  X  ide = 1 | u i ,u de ,  X  c de ). The case of observed reply-to relations is trivial with p ide  X  1 for only the ob-served relations. Here we model the user as equally inter-ested in all the users he replied to. For unobserved rela-tions and uncommented articles, we use the intuition that a user i is interested in other comment if the user pro-files are similar. Thus, for this case we consider p bility model p ide , define the comment-interest part of the rating, r cmnt id . Apart from modeling content -relatedness, the cross-term of the latent offsets ( u T i u de ) models user similar-ity. Also note that r cmnt id causes the user X  X  interest in an article d to evolve with new comments received on d .
We take into account all the potential user-interests to consider an overall interest score of user i in article d : where r mf id (1) is a popularity term for user interest in the topic popularity of the article (only for warm-start), r (2) accounts for the interest in specific segments of the ar-ticle, and r cmnt id (3) accounts for the interest in the existing comment-content and co-commenters.
With the interest score defined, we need to model users X  personalized preferences for commenting. Note that the dataset consists of only positive item feedback, that is we only have access to information of which articles the user was interested in commenting on. This is a much harder problem of implicit feedback [ 9, 20 ]. We take recourse to Bayesian Personalized Ranking (BPR) [ 9, 21 ] which provides a Bayesian model for learning a personalized total ranking for each user. Given the predicted scores  X  r id and  X  r probability of user i preferring article d over article j is  X  ( X  r id  X   X  r ij ); where  X  is the sigmoid function,  X  ( x ) =
Our objective is to develop an efficient inference procedure to learn the model X  X  latent offsets (denoted by  X ) and the latent content variables associated with articles, comments and users (denoted by  X ). The task is thus to maximize the log-posterior of the model parameters p ( X  ,  X  | R,W ), where R = { ( i,d ) | i  X  [ U ] ,d  X  A + i } is the observed commenting pattern and W are the words of the articles and comments. Inference is intractable and we resort to a stochastic MCEM algorithm [ 22], an inference method that alternates between Gibbs sampling for content variables  X  (keeping  X  fixed) and gradient ascent to estimate latent offsets  X  ( X  fixed).
We develop an efficient collapsed Gibbs sampling inference for sampling the content-variables. The real-valued random variables  X , X ,, X , X , X  (Fig. 2) are marginalized out, and only discrete variables b,z,y, and  X  are inferred, leading to accelerated convergence. Sampling of y requires introducing an auxiliary binary variable  X  , with  X  = 0 if comment-word topic is sampled from article-segments  X  and  X  = 1 if sam-pled from the user X  X  topic vector  X  . Note that unlike [2 , 19 ], who add latent offsets to the document topic distributions  X  , we add latent offset to empirical topic distributions (  X  s,  X  q ), allowing us to collapse  X  and  X  , reducing the number of variables to be sampled. Derivation of conditional distri-butions is now conventional and we omit this due to space constraints. Refer to supplementary for more details.
We seek to optimize the log-posterior of latent offsets given observed user preferences R and the content variables, that is: ln p ( X  | R,  X ) = P i  X  U P d  X  A + ln p ( X  |  X ). This requires computing U  X  D 2 terms for the gradient, which is computationally infeasible. BPR [ 9], thus estimates the model parameters  X  by stochastic gradient as-cent (SGA). In each step, a user i and a commented article d are sampled uniformly from R , an uncommented article j is sampled from A  X  i and a gradient step with respect to the associated terms in the log-posterior is performed.
However, a key challenge here is that  X  r id is not differen-tiable due to the use of the max function in the r which explains users X  interest in specific segments. We over-come this by a smooth approximation of the max function: for some parameter  X   X  0. This is different from softmax but can be viewed as a weighted sum of the values a k with weights given by the softmax { a k } .
 Note that lim  X   X  X  X  diffmax corresponds to average of { a k } .

Using diffmax allows us to carry out an efficient SGA al-gorithm. The computation of the gradients is now straight-forward, details can be found in the supplementary 4 .
Before concluding this section, we remark on our choice of BPR algorithm. Apart from its success for implicit feed-back [21  X 23 ], we choose BPR as apposed to alternatives like weighted regularized matrix factorization (WRMF) [ 20 ], also used by CTR [ 2], due to practical considerations. The non-quadratic form of  X  r (4), makes WRMF impractical, as an alternating least squares method like [ 2, 20] cannot be derived. Moreover, taking an SGA approach in WRMF is inferior to the SGA approach on BPR criterion which works with item-pair level as opposed to individual item level [ 9].
Given the learned latent offsets and topic profiles of arti-cles, segments and comments, the predicted user interest in commenting on an article is given by equation (4 ). For an article with no comments, that is cold-start , this value is:
In this section, we evaluate the proposed model CCTM rigorously on three real datasets. We first show that CCTM is a good model of article-comment correspondence. Then we evaluate the main task of this paper, recommending ar-ticles to users for commenting .
We crawled 4 live news and blog sites to collect article content, corresponding comments, user information of com-ments and reply-to relations (where available).
 ATScience: We crawled 3 years of blog articles, from April 2011 to April 2014, from Science section of popular blog ArsTechnica 5 . This consists of 71 , 640 comments by 3 , 581 users on 2 , 500 articles.

ATGadgets: We crawled 102 , 087 comments by 4 , 872 users on 3 , 000 articles from Gadgets section of the site Ar-sTechnica 5 , from June 2012 to April 2014.

DailyMail: We Crawled 33 , 468 comments by 2 , 534 users on 3 , 000 articles from Sports section of this popular news
Resources: http://mllab.csa.iisc.ernet.in/recsys15 arstechnica.com/science ; arstechnica.com/gadgets site 6 , going chronologically backwards from 1 July 2013. This crawl of the dataset did not have reply-to relations.
We consider three baselines: a) TagCF [1 ]: This is the state-of-art for recommending articles for commenting. It associates tags with latent factors and uses BPR criterion. This completely ignores article and comment content. b) Collaborative Topic Regression ( CTR ) [ 2]: State-of-the-art hybrid model which models the content of the articles along with the ratings. This approach ignores the content of the comments, but promises to handle cold-start by leveraging content of articles and does not rely on meta-data like tags. c) Content-Only Method ( CoTM ): This is the content-only part of our model (section 3.2 ), equivalent to setting the latent offsets { u i ,v d 0 ,v da } = 0. We will refer to this as CoTM (Commenter Topic Model).

Improvement of CoTM over CTR will demonstrate the importance of modeling comment content and its correspon-dence to article content. Improvement of CCTM over both CoTM and CTR will demonstrate importance of modeling commenting interests explicitly. Note that all baselines ig-nore modeling of commenting interests of users.
We remove standard stop words and restrict vocabulary to 15 k words using term-frequency. Articles and users with less than 2 comments were removed since they cannot be evaluated. We used uninformative hyperparameter values for the content variables[7 ]:  X , X  u , X  = 0 . 1;  X  = 1,  X  = 0 . 1;  X  , X  2 = 1; and J d = 5. For all models, K = 150. The precision parameters for latent-offsets  X  v , X  s , X  q , X  lar parameters for baselines, were tuned on the first fold of DailyMail and the same value used for all other folds and datasets. The diffmax parameter  X  was tuned same way and found to be  X  = 10. We observed the estimation proce-dure for CTR to be sensitive to initialization, and initialized CTR with the output from LDA. We initialize CCTM ran-domly. CCTM is trained by 1000 EM-iterations, with 1k SGA updates per iteration. Due to unavailability of tags on articles, for TagCF we follow the advice of [1 ] to extract entities. We extract 10k entities by frequency (more entities did not improve performance) and do 1000k SGA updates.
We test the performance of all the models in both warm-start and cold-start scenarios, following the approach of [2 ].
Warm-Start: In this case every test article had at least one comment in training data. For each user we do a stratified 5-fold split of articles (both 1 X  X  and 0 X  X ). For each fold, we fit the models on training data and test on within-fold articles of each user (users have different sets of within-fold articles).
Cold-Start: This is the task of predicting user interest in commenting on a new article with no existing comments. Articles are split into 5 folds. For each fold in turn, we remove all comments on the articles in that fold forming the test-set and keep the other folds as training-set. The models are fitted on the training set and tested on within-fold articles (same for each users). dailymail.co.uk/sport
We perform our evaluation broadly on two aspects. First we validate CCTM X  X  ability to model correspondence be-tween articles and comments. Then, we focus on the main task of the paper, to recommend comment-worthy articles. For the second task, each model is allowed to present (hypo-thetically) each user with a ranked list of articles for comm-enting in the test set. The quality of the ranking thus pre-sented is evaluated for each user through AUC (Area Under ROC Curve) metric [ 9], using the articles in the held-out set that the user actually commented on. AUC  X  (0 , 1], measures the probability that a randomly chosen article on which user commented is ranked higher than one he didn X  X  comment on. Eventually we averaged the AUC score for each user to get an overall performance score.
Ability to effectively model correspondence relationship between the content of an article and its comments is crucial in detecting commenting interests of users. We first evaluate the ability of CCTM to model this aspect. For this purpose, we randomly select 20% articles in each dataset as test arti-cles and remove all comments on the articles. The model is then fitted on the remaining set of article-comments, and the perplexity [ 11] of comment words in test-set is evaluated. We compare with CorrLDA [11 ], which also models correspon-dence but ignores specificity and user information. CCTM achieved perplexity measure (lower is better) of 459 (Daily-Mail), 998 (AT-Science), 843 (ATGadgets); while CorrLDA achieved 647 (DailyMail), 1324 (ATScience), 1100 (ATGad-gets). This shows that CCTM is a better model of comment-content and article-comment correspondence.
We now evaluate CCTM on the main objective of rec-ommending comment-worthy articles. Table 1 shows the performance for both warm-start and cold-start conditions. Under warm-start condition, note that a content-only ap-proach (CoTM) gives almost similar performance to TagCF and state-of-art hybrid method CTR. This shows the impor-tance of leveraging prior comment-content and article con-tent through topic profiles. CCTM, by modeling comment-ing interests of users through content-driven profiles, gives significant improvements over all of these methods on all the datasets, showing that modeling commenting interest of users explicitly is crucial to generate relevant recommenda-tions for commenting.

Cold-start recommendation is a much harder problem, as evinced by the relatively lower AUC values of all mod-els. As explained earlier, TagCF particularly suffers in cold-start, with performance only slightly better than random guessing. Whereas the content-only approach (CoTM) it-Figure 3: Average reciprocal Hit-Rank@5. CCTM is 165% better (average) than [ 1, 2] self gives significant gains over CTR and TagCF. CoTM gives almost similar performance for both warm-start and cold-start which is expected as it is a content-only approach. Performance is further improved through CCTM which uses a latent offset to model user profile. Note, the only difference in this scenario between CoTM and CCTM is the presence of a latent-offset in user topic profile.
To test which model ranks comment-worthy articles much higher in the ranked list of articles, we evaluate average re-ciprocal hit-rank (HR). Given a list of M ranked articles for user i with n i test comments, let c 1 ,c 2 ,...,c h denote the ranks of h articles in [ M ] on which the user actually com-mented. HR is then defined as 1 n top ranked articles are correct. Fig. 3 shows the results for both warm and cold start with M = 5, a realistic scenario where users can only be shown 5 articles. CCTM is signifi-cantly better than CTR and TagCF in both warm ( 80% bet-ter) and cold-start ( 250% better), establishing that relevant articles are ranked much higher. TagCF performs similar to CTR for warm-start but suffers severely in cold-start. Figure 5: AUC by article X  X  commenting popularity.
Ability of CCTM to model comment content and users latent interests should give CCTM advantage in extreme conditions such as when a user has made few comments or an article has received very few comments so far. We evaluate our approach on such cases here. In the following, we focus on ATScience, other results are similar (see supplementary).
In Fig. 4 we study performance by number of comments made by users in the training data. CCTM is superior in performance for all kinds of users and largest improvements are observed for tail-users, i.e. users with 1-5 comments in the training data. This shows that modeling commenting interests gives significant information about a user X  X  comm-enting activity with as few as 5 comments made by the user.
We group articles by comment volume in training data (for warm-start) and evaluate AUC for each group. Av-erage across these groups is the stratified AUC metric [1 ]. Fig. 5 shows the results. While CCTM is substantial supe-rior throughout, largest improvements are observed for tail-articles, i.e. articles with 1-10 comments in the training data. This shows that modeling commenting interests gives signif-icant information about users commenting activity with as few as 10 comments received on the article. CCTM is also substantially superior to the content-only model (CoTM) in this respect. CoTM, performs better than CTR for tail-items but worse for highly popular items. CTR X  X  perfor-mance improves over CoTM for popular articles, showing that collaborative information dominates for high comment-volume, but CCTM is still significantly better than either.
We study a novel problem of eliciting content-driven user profiles to recommend articles which are comment-worthy of a particular user. We propose a novel hierarchical Bayesian model CCTM to solve this problem and demonstrate signif-icant advancement in generating comment-worthy recom-mendations over state of art recommendation systems [1 , 2], on three real life datasets using various metrics. There are many avenues for future work  X  incorporating comment sen-timent, users X  social information, modeling temporal nature of commenting preferences, and developing distributed and streaming inference [ 13 ] for web-scale deployment.
We are thankful to all the reviewers for their valuable comments. The authors were partially supported by DST grant (DST/ECA/CB/1101).

