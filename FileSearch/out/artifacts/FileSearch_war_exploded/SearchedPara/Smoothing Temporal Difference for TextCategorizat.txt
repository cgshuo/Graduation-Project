 A basic assumption in text categorization is that the creation time period of training data is the same as test data. When the assumption does not hold, traditional classification methods might not work well. However, it is often the case that the term distribution in the training data is different from that of the test data when the training data may drive from a different time period from the test data. For instance, the term  X  X lcindo X  frequently appeared in the documents tagged  X  X ports X  category in 1994. This is reasonable because Alcindo is a Brazillian soccer player and he was one of the most loved players in 1994. However, the term did not occur more frequently in the Sports category since he retired in 1997. The observation shows that the informative term such as  X  X lcindo X  appeared in the training data with Sports category, is not informative in the test data when training data may derive from a different time period from the test data. If we can have a large number of training documents with the same time period of test data, we can classify test documents with high accuracy. However, manual annotation of tagged new data is very expensive and time-consuming. The methodology for accurate classification of the new test data by making the maximum use of tagged old data is needed to improve categorization performance.
 In this paper, we present a method for text categorization that minimizes the impact of temporal effects. We focused on organization and person names which frequently appear in a specific category. These often appeared in specific time period, e.g. ,  X  X lcindo X  occurred in 1994, and  X  X onaldo X  first appeared in 2004 in the documents. We identified these terms in the documents and replaced these to a representative term in order to regard that these terms are equally salient for a specific category, i.e. sports across full temporal range of training documents. We call this procedure, Temporal-based Term Smoothing (TTS). Each document is represented by using a vector of terms including representative terms, and classifiers are trained. We applied boosting based transfer learning, called TrAdaboost [ 3 ] in order to minimize the impact of temporal effects, i.e. it decreases the weights of training instances that are very different from the test data.
 The rest of the paper is organized as follows. The next section describes an overview of existing related work. Section 3 presents our approach, especially describes how to adjust temporal difference between training and test documents. Finally, we report some experiments with a discussion of evaluation. The analysis of temporal aspects is widely studied since corpora from the WWW became a popular source for text processing tasks. One attempt is detection of concept or topic drift [ 6 , 13 , 16 ]. The earliest known approach is the work of [ 14 ]. They presented a method to handle concept changes with SVMs. They used  X  X  -estimates to select the window size so that the estimated generalization error on new examples is minimized. The results which were tested on the TREC show that the algorithm achieves a low error rate and selects appropriate window sizes. He et al. proposed a method to find bursts, periods of elevated occurrence of events as a dynamic phenomenon instead of focusing on arrival rates [ 11 ]. They used Moving Average Convergence/Divergence (MACD) histogram which was used in technical stock market analysis [ 21 ] to detect bursts. They tested the method using MeSH terms and reported that the model works well for track-ing topic bursts. Most of these focused just on identifying the increase of a new context, and not relating these contexts to their chronological time. Wang et al. developed the continuous time dynamic topic model (cDTM) [ 25 ]. The cDTM is an extension of the discrete dynamic topic model (dDTM). The dDTM is a powerful model. However, the choice of discretization affects the memory require-ments and computational complexity of posterior inference. cDTM replaces the discrete state space model with its continuous generalization, Brownian motion. Another attempt is domain adaptation. The goal of this attempt is to develop learning algorithms that can be easily ported from one domain to another, e.g. , from newswire to biomedical documents [ 4 ]. Domain adaptation is particularly interesting in Natural Language Processing (NLP) because it is often the case that we have a collection of labeled data in one domain but truly desire a model that works well for another domain. Several authors e.g. , Xiao et al. [ 26 ]for part-of-speech tagging, Daume [ 4 ] for named-entity, and Glorot et al. [ 10 ]for sentiment classification have attempted to improve results by using domain adaptation techniques. One approach to domain adaptation is to use transfer learning. The transfer learning is a learning technique that retains and applies the knowledge learned in one or more domains to efficiently develop an effective hypothesis for a new domain. The earliest discussion is done by ML commu-nity in a NIPS-95 workshop 1 , and more recently, transfer learning techniques have been successfully applied in many applications. Blitzer et al. proposed a method for sentiment classification using structual correspondence learning that makes use of the unlabeled data from the target domain to extract some rele-vant features that may reduce the difference between the domains [ 1 ]. Several authors have attempted to learn classifiers across domains using transfer learn-ing in the text classification task [ 2 , 22 , 24 ]. Dai et al. proposed a co-clustering based classification algorithm to propagate the label information across different domains [ 2 ]. The method first, the in-domain data provide the class structure, which defines the classification task, by propagating label information. Then, co-clustering is extended for out-of-domain data to obtain out-of-domain document and word clusters. The extension is that class labels in the in-domain data can constrain the word clusters, which is shared among the two domains. This allows each out-of-domain cluster to be mapped to a corresponding class label based on their correlation with the document categories in the in-domain data. They showed that the algorithm improves the classification performance over the tra-ditional learning algorithms including Transductive Support Vector Machines. All of these approaches mentioned above aimed at utilizing a small amount of newly labeled data to leverage the old labeled/unlabeled data to construct a high-quality classification model for the new data. However, the temporal effects are not explicitly incorporated into their models.
 based text categorization. Mourao et al . investigated the impact of temporal evolution of document collections based on three factors: (i) the class distribu-tion, (ii) the term distribution, and (iii) the class similarity. They reported that these factors have great influence in the performance of the classifiers throughout the ACM-DL and Medline document collections that span across more than 20 years [ 20 ]. Salles et al . presented an approach to classify documents in scenarios where the method uses information about both the past and the future, and this information may change over time [ 23 ]. They addressed the drawbacks of which instances to select by approximating the Temporal Weighting Function (TWF) using a mixture of two Gaussians. They applied TWF to every training document. However, it is often the case that terms with informative for a specific time period and informative across the full temporal range of training documents are both included in the training data that affects overall performance of text categorization as these terms are equally weighted in their approach. In contrast with the aforementioned works, here we propose a method for text categorization that minimizes the impact of temporal effects by using term smoothing and transfer learning techniques. Our experimental results show the effectiveness of the method, especially when the creation time period of the test data differs greatly from the training data. For reasons of both efficiency and accuracy, feature selection techniques such as  X  statistics, mutual information, and information gains are often used in order to select informative terms since the early 1990s when applying machine learning methods to text categorization. We note that the selected terms by using these feature selection techniques often include organization and person names. When the creation time period of training data is the same as test data, these terms are key features to classify test documents correctly. However, this situation is often hampered by the assumption that the test data may be derived from a different time period than training data, although these terms are still informative terms for a specific category. We then identified words with semantically related with each other, and replaced these to a representative word in order to regard that these words are equally informative across training and test sets.
 We firstly used named entities recognition programme, and extracted person name and organization name, and make a named entity list for each category. Next, we collected semantically related words. To do this, we used word2vec tool released by Google in 2013. The word2vec first constructs a term from the train-ing text data and then learns vector representation of words. It is provided two main model architectures, continuous bag-of-words and skip-gram. We used skip-gram model as it gives better word representations when the data is small [ 19 ]. The skip-gram model X  X  objective funcion L is to maximize the likelihood of the prediction of contextual words given the center word. Given a sequence of train-ing words w 1 , w 2 ,  X  X  X  , w T , the objective of the model is to maximized L : where k is a hyperparameter defining the window of the training words. Every word w is associated with two learnable parameter vectors, input vector I output vector O w of the w . The probability of predicting the word w word w j is defined as: where V refers to the number of words in the vocabulary. For larger vocabulary size, it is not efficient for computation, as it is proportional to the number of words in the V . Word2vec uses the hierarchical softmax objective function to solve the problem. The learned vector representations can be used to find the closest words for a user-specified word. For each category, we collected a small number of documents and created a training data. We applied word2vec to each training data. As a result, we obtained the number of n models where n is the number of category. Then, for each term in the named entity list Cl n ), we collected a certain number of related terms according to the similarity value, and created a set. Finally, for each set, we regarded the first order term as a representative term. If each term appeared in the documents is listed in a set, we replaced the term in the documents to its representative term. So far, we made use of the maximum amount of tagged data in temporal-based term smoothing. The final step is document categorization. We trained the model and classified documents by using TrAdaBoost [ 3 ]. TrAdaBoost extends AdaBoost [ 8 ] which aims to boost the accuracy of a weak learner by adjusting the weights of training instances and learn a classifier accordingly. TrAdaBoost uses two types of training data. One is so-called same-distribution training data that has the same distribution as the test data. In general, the quantity of these data is often limited. In contrast, another data called diff-distribution training data whose distribution may differ from the test data is abundant. The TrAd-aBoost aims at utilizing the diff-distribution training data to make up the deficit of a small amount of the same-distribution to construct a high-quality classifi-cation model for the test data. TrAdaBoost is the same behavior as boosting for same-distribution training data. The difference is that for diff-distribution train-ing instances, when they are wrongly predicted, we assume that these instances do not contribute to the accurate test data classification, and the weights of these instances decrease in order to weaken their impacts. Dai et al. applied TrAdaBoost to three text data, 20 Newsgroups, SRZZ, and Reuters-21578 which have hierarchical structures. They split the data to generate diff-distribution and same-distribution sets which contain data in different subcategories. We used TrAdaBoost as a learning technique to classify documents. We note that we used two types of labeled training data: One is the same creation time period with the test data. Another is different creation time period from the test data. We call the former same-period training, and the latter diff-period training data. In the TrAdaBoost, we replaced same-distribution data to same-period data, and diff-distribution data to diff-period data. TrAdaBoost is illustrated in Fig. 1 .  X  X d ( i =1,  X  X  X  , n ), and X d refers to the diff-period instance space. Similarly, Tr s represents the same-period training data that Tr s =  X 
X s ( i =1,  X  X  X  , m ), and X s refers to the same-period instance space. n and m are the number of documents in T d and T s , respectively. c ( x ) returns a label for the input instance x . The combined training set T = { ( x We used the Support Vector Machines (SVM) as a learner. We represented each training and test document as a vector, each dimension of a vector is a term/representative term appeared in the document, and each element of the dimension is a term frequency. We applied the algorithm shown in Fig. 1 . After several iterations, a learner model is created, and a test document is classified using a learner. We evaluated our method by using the Mainichi Japanese newspaper documents. 5.1 Experimental Setup We choose the Mainichi Japanese newspaper corpus from 1991 to 2012. The cor-pus consists of 2,883,623 documents organized into 16 categories. We selected 8 categories,  X  X nternational X ,  X  X conomy X ,  X  X ome X ,  X  X ulture X ,  X  X eading X ,  X  X rts X ,  X  X ports X , and  X  X ocal news X , each of which has sufficient number of documents. The total number of documents assigned to these categories are 787,518. All documents were tagged by using Yet Another Japanese Dependency Structure Analyzer, CaboCha [ 15 ] including named entity recognition. We selected noun words including person names and organization names.
 first fold is used for temporal-based term smoothing. We further divided second fold into three: 2 % of documents are used as the same-period training data, 50 % of documents are the diff-period training data, and the remains are used to test our classification method. When the creation time period of the training data is the same as the test data, we used only the same-period training data. Table 1 shows the number of classes (representative terms) and the average number of terms in each class.
 our method, TbTS &amp;TAB (TrAdaBoost) with five baselines: (1) SVM without TbTS (SVM/wo), (2) SVM with TbTS (SVM/w), (3) biased-SVM [ 18 ]bySVM-Light [ 12 ] without TbTS (bSVM/wo), (4) biased-SVM with TbTS (bSVM/w), and (5) TrAdaBoost without TbTS (TAB/wo). Biased-SVM (b-SVM) is known as the state-of-the-art SVMs method, and often used for comparison [ 5 ]. Similar to SVM, for biased-SVM, we merged the first two folds, i.e. 2 % of documents with the same-period and 50 % of documents with diff-period, and used them as a training data. We classified test documents directly, i.e. we used closed data. We empirically selected values of two parameters,  X  c  X  (trade-off between training error and margin) and  X  j  X , i.e. cost (cost-factor, by which training errors on positive instances) that optimized result obtained by classification of test documents. Similar to [ 18 ],  X  c  X  is searched in steps of 0.02 from 0.01 to 0.61.  X  j  X  is searched in steps of 5 from 1 to 200. As a result, we set c and j to 0.01 and 30, respectively. To make comparisons fair, all five methods including our method are based on linear kernel. Throughout the experiments, the number of iterations is set to 20. We used error rate as an evaluation measure [ 3 ]. 5.2 Results Categorization results for 8 categories are shown in Table 2 .
 Avg X  in Table 2 refers to macro-averaged error rate across categories. The results obtained by biased-SVM indicate the maximized F-score obtained by varying the parameters,  X  c  X  and  X  j  X . As can be seen clearly from Table 2 , the overall perfor-mance obtained by TAB were better than the results obtained by other methods including biased-SVM except for  X  X ulture X  and  X  X eading X , although biased-SVM were the results by using closed data. The results obtained by SVM with and without TbTS was the worst result among other methods. These observa-tions show that once the training data drive from a different time period from the test data, the distributions of terms between training and test documents are not identical.
 The overall performance with TbTS were better to those without TbTS in all methods. This shows that temporal-based term smoothing contributes clas-sification performance. Table 3 shows some examples obtained by TbTS. Each representative term is randomly selected, and each term in a class is within the topmost five terms according to the representative term. As we can see from Table 3 that semantically similar words such as car names in Economy category, and novelists in Reading category are identified. Moreover, each term is salient for a specific year. For example, Obama, Bush, and Clinton is a USA president from 2009 to 2013, 2001 to 2009, and 1993 to 1997, respectively. These terms are equally salient for a specific category, i.e. international across full temporal range of documents.
 ing against the temporal difference between training and test data. Both training and test data are the documents from 1991 to 2012. For instance,  X 5 X  of the x-axis in Figs. 2 and 3 indicate that the test documents are created 5 years later than the training documents. We can see from Figs. 2 and 3 that the results with TbTS were better to those without TbTS in all of the methods. Moreover, the result obtained by  X  X AB/w X  in Fig. 2 was the best in all of the temporal dis-tances. There are no significant differences among three methods when the test and training data are the same time period in Fig. 2 . The performance of these methods including  X  X VM X  drops when the period of test data is far from the training data in both of the Figs. 2 and 3 . However, the performance of  X  X AB X  was still better to those obtained by other methods. This demonstrates that the algorithm which applies temporal-based term smoothing and TrAdaboost learning is effective for categorization.
 Figure 4 shows the averaged error rate with and without TbTS against the number of iterations. We can see from Fig. 4 that the curve obtained by the method with TbTS was better to biased-SVM after 11 iterations. Although the curves obtained by both with and without TbTS are not quite smooth, they converge around 20 iterations. This indicates that term-based smoothing method itself does not significantly contribute to the fast convergence, while it is effective to improve overall performance of categorization. We proposed an approach for text categorization that training data may derive from a different time period from the test data. The basic idea is to minimize the impact of temporal effects in both term representation and learning techniques. The results by using Japanese Mainichi newspaper corpus show that combi-nation of temporal-based term smoothing and learning method works well for categorization, especially when the creation time of the test data differs greatly from the training data.
 There are a number of interesting directions for future work. We showed that word2vec is effective for term smoothing. However, it requires tagged corpora across full temporal range of training documents. Such corpora are often anno-tated by hand, and manual annotation of corpora is extremely expensive and time-consuming. In the future, we will try to extend our framework to address this issue. We used TrAdaboost as a learning technique which needs at least two improvements. Firstly, TrAdaboost is not explicitly incorporated temporal effects into the model as it is a discontinuous model. More precisely, once diff-period training instances are wrongly predicted, we assume that these instances do not contribute to the accurate test data classification, and the weights of these instances decrease in order to weaken their impacts. However, the weight is equally decreased regardless of the temporal difference between training and test data. Therefore, it is necessary to develop the continuous temporal model for further improvement. Secondly, as Dai et al. mentioned that the rate of con-vergence ( O ( In n/N )) is slow. Here, n is the number of training data, and N is the number of iterations. This is a rich space for further improvement. We used Japanese newspaper documents in the experiments. For quantitative evaluation, we need to apply our method to other data such as ACM-DL and a large het-erogeneous collection of web content in addition to the experiment to examine the performance against the ratio between same-period and diff-period training data.

