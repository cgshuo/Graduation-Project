 We formulate a new data mining problem called storytelling as a generalization of redescription mining. In traditional redescription mining, we are given a set of objects and a collection of subsets defined over these objects. The goal is to view the set system as a vocabulary and identify two expressions in this vocabulary that induce the same set of objects. Storytelling, on the other hand, aims to explicitly relate object sets that are disjoint (and hence, maximally dissimilar) by finding a chain of (approximate) redescrip-tions between the sets. This problem finds applications in bioinformatics, for instance, where the biologist is trying to relate a set of genes expressed in one experiment to another set, implicated in a different pathway. We outline an efficient storytelling implementation that embeds the CARTwheels redescription mining algorithm in an A* search procedure, using the former to supply next move operators on search branches to the latter. This approach is practical and effec-tive for mining large datasets and, at the same time, exploits the structure of partitions imposed by the given vocabulary. Three application case studies are presented: a study of word overlaps in large English dictionaries, exploring con-nections between genesets in a bioinformatics dataset, and relating publications in the PubMed index of abstracts. Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications -Data Mining; I.2.6 [Artificial Intelligence]: Learning General Terms: Algorithms.
 Keywords: redescription, data mining, storytelling. Redescription mining is a recently introduced data mining Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00. problem [9, 10] that seeks to find subsets of data that afford multiple definitions. The input to redescription mining is a set of objects O (e.g., books, genes) and a collection of subsets S defined over O . The goal is to view the set sys-tem as a vocabulary of descriptors and identify clusters of objects that can be defined in at least two ways using this vocabulary.

For instance, consider the set system in Fig. 1 where the six objects are books and the descriptors denote books about traveling in London (Y), books containing informa-tion about places where popes are interred (G), popular books about the history of codes and ciphers (R), books about Mary Magdalene (M), and books about the ancient Priory of Sion (B). An example redescription for this data-set is:  X  X ooks involving Priory of Sion as well as Mary Mag-dalene are the same as non-travel books describing where popes are interred, X  or B  X  M  X  G  X  Y .Thisisanexact redescription and gives two different ways of defining the singleton set {  X  X he Da Vinci Code X  } . The basic premise of redescription mining is that object sets that can indeed be defined in at least two ways are likely to exhibit concerted behavior and are, hence, interesting.

While traditional redescription mining is focused on find-ing object sets that are similar, storytelling aims to explicitly Figure 2: Example data for illustrating operation of storytelling algorithm. relate object sets that are disjoint (and hence, maximally dissimilar). Given start and end descriptors X, Y  X  X  ,the goal here is to find a sequence of descriptors Z 1 , Z 2 , where Z 1 = X , Z k = Y , and every Z i is an approxi-mate redescription of Z j ,1  X  i&lt;k,j = i +1. A re-description Z i  X  X  j is approximate if its Jaccard X  X  coeffi-story in the above dataset results when we try to relate London travel books to books about codes and cipher his-tory: Some London travel books (Y) overlap with books about places where popes are interred (G), some of which are books about ancient codes (R). This story is a sequence of (approximate) redescriptions: Y  X  G  X  R .Eachstepof this story holds with Jaccard X  X  coefficient 1 / 3. A stronger story, that holds with Jaccard X  X  coefficient 1 / 2ateachstep, is: B  X  ( G  X  M )  X  R .

Why is this problem interesting and relevant? Storytelling can be viewed as a carefully argued process of removing and adding participants, not unlike a real story. Knowing ex-actly which objects must be displaced, and in what order, helps expose the mechanics of complex relationships. Sec-ond, storytelling can be viewed as an abstraction of rela-tionship navigation for propositional vocabularies and re-veals insight into how the underlying Venn diagram of sets is organized, and how it can be harnessed for explaining disjoint connections. Finally, with the emergence of high-throughput data acquisition systems, domains such as bioin-formatics are now suffering from  X  X escriptor overload X ; story-telling promises to be a valuable tool to attack this problem and reconcile disparate vocabularies.

Why is this problem difficult? Storytelling is non-trivial because the space of possible descriptor expressions is not enumerable beforehand and hence the network of overlap re-lationships cannot be materialized statically. In particular, observe that the intermediaries Z i are not constrained to be just elements of S but can be set-theoretic expressions made up of the S i  X  X , e.g., S 1  X  X  3 , S 2  X  X  4 , S 1  X  ( S 2 ical application, we have hundreds to thousands of objects and an order of magnitude greater descriptors, with an even larger number of possible set-theoretic constructions made of the descriptors. Effective storytelling solutions must mul-tiplex the task of constructive induction of descriptor ex-pressions with focused search toward the end point of the story.
We embed CARTwheels inside an A* search procedure, using the former to supply next move operators on search branches to the latter. Each move is a possible redescrip-tion to be explored and a heuristic function evaluates these redescriptions for their potential to lead to the end descrip-tor of the story. In this paper, we focus on story length X  number of redescriptions to reach the end descriptor X  X s the primary criterion of optimality although different criteria might be more suitable in other applications. Backtracking happens when a previously unexplored move (redescription) appears more attractive than the current descriptor. The search terminates when we reach a descriptor that is within the specified Jaccard X  X  threshold from the ending descriptor or when there are no redescriptions left to explore. For ease of illustration, consider the artificial example in Fig. 2 with six descriptors {S 1 , S 2 , S 3 , S 4 , S over the universal set O = { o 1 ,o 2 ,o 3 ,o 4 ,o 5 ,o 6 alistic application, the number of descriptors would greatly exceed the number of objects). Our goal is to find a story between descriptor S 1 , corresponding to the set { o 1 } S , corresponding to the set { o 5 } ,suchthateachstepisa redescription that holds with Jaccard X  X  coefficient at least  X  =0 . 5. In this example, we set the maximum depth of decision trees used to 2.

To initialize the alternation, we prepare a traditional data-set for classification tree induction (see Fig. 3, left), where the entries correspond to the objects, the class (to be learnt) corresponds to the starting descriptor, and the boolean fea-tures are comprised of the rema ining descriptors. A classifi-cation tree can now be grown using these features and class assignments with the Jaccard X  X  coefficient as the node eval-uation criterion. Hence, at each level in the decision tree we construct, we look for a descriptor S i such that one of the blocks in its induced partition will provide the best overlap with the class we seek (in this case, S 1 ). If the maximum Jaccard X  X  coefficient value obtainable is lesser than  X  ,we choose the descriptor that provides the best value. Else, we consider all descriptors that satisfy the Jaccard X  X  threshold and, among them, greedily choose the one with the highest Jaccard X  X  coefficient with the end point of the story. The tree growth is continued until the maximum Jaccard X  X  coefficient observed at a given depth is lesser than that observed at the parent level, or the depth limit of tree growth is reached. Once the tree has been constructed, class assignments at the leaves are made by majority and paths that lead to a given class are union-ed to form redescriptions.

For instance, Fig. 4 (a) shows the decision tree we have constructed to match the partition {S 1 , S 1 } . This tree pro-vides the first step in the story to be the redescription (
S 2  X  X  3 ). In this example, we show only one possible  X  X ext tree X  for our example but in our implementation, we main-tain a number of such possible matching trees, to simulate a branching process and for potential backtracking. Note that while the current redescri ption holds with a Jaccard X  X  value of 0.5, the new descriptor does not have any overlap with S 5 .

For the next step in our story, we use the partition { ( S S ) , ( S 2  X  X  3 ) } as the classes to match and consider the dataset as shown in Fig. 3 (right). In constructing the new dataset, observe that we ignore the descriptor that is the top-most node (here, S 2 ) in the decision tree that defines the current partition. This ensures that we do not utilize the same features for matching a partition as those that define the partition! The one-level tree we learn at this stage is shown in Fig. 4 (b). The redescription of interest here is ( S 2  X  X  3 )  X  S 3 , which also holds with a Jaccard X  X  coefficient of 0 . 5. Although it introduces the element we seek ( o 5 ), the redescription to the end point of the story, obj. S 1 S 3 S 4 S 5 S 6 class o o o 3  X   X  o o 5  X   X  o 6  X   X   X   X  Figure 4: Storytelling using CARTwheels alternation. Beginning with the bottom tree in (a), the alternation systematically moves toward sequence of redescriptions: S 1  X  ( S 2  X  X  3 )  X  S 3  X  X  4 .
 S 3  X  X  5 , has only a Jaccard X  X  coefficient of 0 . 25. We hence continue the search and obtain the redescription S 3  X  X  4 which gives us the desired overlap with the target, and our final redescription, namely S 4  X  X  5 .Ourstoryisthus S
The storytelling algorithmic framework follows the outline of the working example above for a given O , S , X and Y . The parameters that need to be specified are: a threshold  X  (0 &lt; X &lt; 1) denoting the minimum required Jaccard X  X  coefficient for each connection in the story; d (depth of trees) that imposes a bias B over set expressions defined on S ;and branching factor b that restricts the maximum number of possible next states from each state in the A* search.
Our implementation can be divided into an Initialization step and an Alternation step. In the Initialization step, an empty open list ( OL )andclosedlist( IL )requiredforA* search are defined. Also, the decision tree induced by the starting class (a 1-level tree with the node X ) is added to OL along with its heuristic score obtained from the func-tion calculate heuristic score as explained later. This tree provides the classes for the first step of the Alternation pro-cess. The class of interest ( X ) is marked as the one we want to find the closest match for.

At each alternation in the Al ternation process, the first tree ( t N )in OL provides the classification C . The candidate set of features F is made equal to all except the feature used at the root of the current tree providing the classes. b distinct trees of depth d are created using these definitions of
C and F and Jaccard X  X  coefficient as the metric. For each of the decision trees constructed, the Jaccard X  X  coefficient between the current descriptor of interest and the union of the paths leading to it in the current tree is calculated. For each tree ( t j ) for which this value is higher than or equal to  X  ,the calculate heuristic score is used to compute the heuristic score h j .

If the heuristic evaluation h j for the currently picked tree t is zero, we have arrived at a tree that has sufficient Jac-card X  X  overlap with the end point of the story. We can then terminate by displaying the story by tracing back the se-quence of mined redescriptions. If h j is not zero, t j is placed in
OL and t N is moved to CL . For adding t j to OL ,the heuristic score h j is combined with cost expended so far ( g to arrive at the evaluation criterion s j .Nodesareplacedin OL in ascending order of s j . This completes one step in the Alternation process. The step outlined is repeated until thereisnotreeleftin OL or a story has been found.
The heuristic function h is designed to systematically never over-estimate the number of redescriptions remaining and takes the value of zero for a tree whose partition has an overlap of at least  X  with the ending descriptor. We now present details of h that clearly indicate its admissibility.
Table 1 outlines the approach to estimate h j for tree t j This algorithm can be understood as follows. Assume that the new descriptor Z j (provided by tree t j )has f elements in common with the target descriptor Y and e elements that do not participate in Y . This means that Z j must shed enough of the e elements and acquire enough of the | Y | X  f ele-ments in order to have a Jaccard X  X  threshold of  X   X  with Y . The goal of calculate heuristic score is to estimate the num-ber of redescriptions required to shed the requisite number among e elements and acquire some of the necessary | Y | X  elements. The procedure first conservatively estimates if the current discrepancies alr eady correspond to a Jaccard X  X  threshold of  X   X  with Y , in which case it returns zero. If this is not possible, the procedure estimates the shortest num-ber of steps in which the deletions and additions can happen by a recursive computation. Two extremes are considered at each step  X  the case where we can acquire as many of the necessary new elements as dictated by  X  without any removals, and the case where we can shed as many of the unnecessary elements as dictated by  X  without any addi-tions. This step provides us the bounds  X f max and  X e max in Table 1. We then search combinatorially within these ranges for the maximal number of deletions, for every possi-ble number of additions, such that  X  holds, akin to dynamic programming. The minimum number of redescriptions over all possibilities is then returned.
The efficient implementation of our storytelling algorithm hinges on data structures for fast estimation of overlaps (e.g., see [7, 11]). In this paper, we combine an AD-tree data structure [6] with the signature tables [1] approach for ef-ficient similarity search in categorical data. The signature table is constructed before the Initialization step mentioned earlier. Here, objects in the universal set are divided into a predefined number of clusters ( c ) on the basis of their co-occurrence frequencies, forming their signature. All descrip-tors and their co-occurrence fre quencies (used in construct-ing a decision tree of depth more than 1) are also built into an AD-tree at this stage. The descriptors at the top-level of the AD-tree are additionally linked to their signatures. When a similarity search query is issued, only nodes that correspond to signatures of interest need to be investigated. At greater depths in the AD-tree, we use a traditional AD-tree node that contains descriptor names and co-occurrence frequencies for each of the descriptors.

Using these data structures, we can reduce the number of descriptors searched against at each step and improve the speed of computation of stories. For instance, in the first call to the function construct tree , where we are looking for the best match for the class X from among the descriptor set D , we can reduce X toavectorofsize c ( X c ). Also, we keep a count of the number of objects in X that belong to each of the c clusters in the form of a frequency vector f The optimistic Jaccard X  X  coefficient ( OJ ) between X c and asignaturevector V c i corresponding to a set of descriptors can then be calculated by the formula We then compare X c to all the signature vectors and retain only those for which the optimistic Jaccard X  X  coefficient is above  X  . This narrows down our search to only those descrip-tors that have potential to provide the necessary overlap.
The significance of a story is assessed at the level of each redescription participating in the story. To assess the sig-nificance of redescription X  X  Y ,weusethecumulative hypergeometric distribution to determine the probability of obtaining a rate of co-occurrence of X and Y (over the ob-ject domain), given their marginal occurrence probabilities, and comparing it to the observed rate of co-occurrence by chance. To account for multiple hypothesis testing, the sig-nificance threshold is determined by first characterizing the distribution for all descriptors tested and determining if the given redescription has a rate of occurrence more than four standard deviations above the mean.
Our three experimental studies are meant to illustrate dif-ferent aspects of our storytelling algorithm and implemen-tation. The first study characterizes word overlaps in large English dictionaries and illustrates scalability of the imple-mentation and how the different parameter settings affect the quality of stories mined. The second study, involving gene sets in bioinformatics, showcases the constructive in-duction capabilities of CARTwheels when used for story-telling. This study and the third, which builds stories be-tween PubMed abstracts, also illustrate interesting nuggets of discovered knowledge.
In our first study, we implement storytelling for the Mor-phWord puzzle wherein we are given two words, e.g., PURE and WOOL, and we must morph one into the other by changing only one letter at a time (meaningfully). One so-lution is: PURE  X  PORE  X  POLE  X  POLL  X  POOL  X  WOOL. Here we can think of a word as a set of (letter, posi-tion) tuples so that all meaningful English words constitute the descriptors. Each step of this story is an approximate redescription between two four-element sets, having three elements in common. Note that words that are anagrams of each other (e.g.,  X  X LVIS X  and  X  X IVES X ) will not have a Jaccard X  X  coefficient of 1, since position is important. We harvested words of length 3 to 13 words from the Wordox dictionary of English words (http://www.esclub.gr/ games/wordox/), yielding more than 160 , 000 words. Con-sistent with the MorphWord puzzle, we restrict all CARTs to be of depth d = 1 and study the effect of  X  and b on the number of stories possible, length of stories mined, and time taken to mine stories. For ease of interpretation, we recast Jaccard X  X  thresholds in terms of the number of letters in common ( lc ) between two words. Although MorphWord is traditionally formulated with lc =1,weexplorehigher lc values as well. Due to space restrictions, we present our results only on 10 letter words ( L 10 ). We selected 100 , 000 pairs of words at random and tried to find stories between them, with different lc and b settings.

Fig. 5 (top left) depicts a plot of the fraction of stories (out of 100 , 000) mined with various story lengths as a function of lc , for a branching factor b = 5. In the plot, a story length of 0, rather counter-intuitively, implies that no story was found for the word pair considered. The critical story length where the majority of stories are mined steadily increases as lc is increased. This is because, as lc is increased, more overlap is required at each step of the story such that it takes longer for one word to morph into another. At the same time, the total number of stories mined decreases as lc is increased, due to the lack of viable redescriptions.

To study the effect of b on the length of stories mined, we focus our attention on lc value of 5 for L 10 . Fig. 5 (bottom left) shows a plot of the fraction of stories mined with various lengths as a function of b . As before, a path length of 0 in the plots implies that no story was found for the word pair considered. Here, the lc value chosen contributes to a high probability of longer stories. As a result the branching factor b plays a crucial role. This is evident in the case of b = 1, where the excessively greedy strategy is often rendered futile. As b increases, the chances of going down toward the target word increases and more stories are mined.
To study the effect of these parameters on the time re-quired to mine stories, we set b = 5 as before for under-standing the role of lc . We computed the average time taken to mine a story, for various story lengths, across all pairs of words considered. Fig. 5 (top right) shows the plot of this average time against story lengths, for different lc values. The plots indicate that there is a near linear increase in time required, with steeper increases for lower lc values. This is because the lower lc values cause an increase in the num-ber of possibilities (within the bound of b =5)whichmust be explored before converging on the shortest path. Also observe the higher times for story lengths of 0, indicating it takes longer to conclude that stories do not exist. Sim-ilar linear trends are observed in time versus the role of b (Fig. 5, bottom right). Here, steeper profiles are witnessed for higher b values. Once again, this is due to the increase in the number of possibilities, although these increases appear to taper off quickly. These figures clearly indicate the un-derlying tradeoff in mining stories: time versus importance of optimal story lengths.
In our second case study, we mine stories among descrip-tors defined over gene sets in the budding yeast S. cere-visiae . We draw our descriptors from various bioinformat-ics vocabularies (e.g., the Gene Ontology (GO), microarray experiment clusters, experiment ranges) as done in previ-ous work [10]. An example significant story, between the Figure 6: An example significant story among PubMed abstracts relating chemical stresses. (title, PMID and publication date provided) Figure 7: A significant story among gene sets from protein modification to hexokinase.
 GO categories protein modification and hexokinase, mined for  X  =0 . 5, b =5,and d =2isshowninFig.7. Ob-serve that the second descriptor in the story involves a set intersection performed by CARTwheels. A unifying fea-ture that links the genes in this story is their common role in nutrient control and carbohydrate metabolism, partic-ularly metabolism of glucose-phosphate. Considering the three genes in the first descriptor, YKL035W is involved in the reversible conversion of glucose-1-phosphate to UDP-glucose via UTP; YJL164C is a cAMP dependent kinase and binds both YFL033C (glucose repressed, nutrient con-trol) and YIL033C (glycogen accumulation); and YGL158W is a kinase that binds YGL115W (release from glucose re-pression). Two new genes enter the story with the first redescription, namely YCL040W (involved in phosphoryla-tion of glucose) and YFR053C (a hexokinase also involved in the phosphorylation of glucose in the glycolysis pathway). In traversing the second redescription, two additional genes appear: YDR516C is involved in phosphorylation of glu-cose and, most importantly, also binds YCL040W (which is present in earlier redescriptions). YGR052W is a mitochon-drial serine/threonine kinase of unknown function. Through the thread of the story we predict that YGR052W may also be involved in an aspect of glucose metabolism and/or nu-trient control.
For our final case study, we consider the more than 140 , 000 publications about yeast in the PubMed index and focus on finding stories between publication abstracts. Each abstract is hence a descriptor over terms/keywords. We restrict our CARTs to be of depth 1 and also adopt a weighted Jac-card X  X  measure that is more suited to measuring similarity between bags (details omitted due to space constraints). To generate keywords, we focused on the 3756 abstracts con-taining the keywords  X  yeast AND stress  X  and applied stop word removal and Porter X  X  stemming as well as manual in-spection to cluster similar words together. Over 95% of the keywords were eliminated by significance testing over the values of TF  X  IDF (corresponds to a threshold of about 7), resulting in 6821 unique words.

For this application, it is important to note that the com-putation of the heuristic value would result in a combina-torial problem since each word does not uniformly have a weight of 1 in our Jaccard X  X  calculation. For instance, elim-ination of different word subsets of equal size from a given descriptor will result in different Jaccard X  X  coefficients; hence we will have to exhaustively search all combinations for re-moval and addition of keywords to determine the theoreti-cally shortest possible storylength. To avoid this problem, we used a simpler heuristic function wherein we estimate the maximum weight we can gain/lose at each step and cal-culated the number of steps required to gain enough of the weight for the final document and lose enough weight from the current document, to reach a Jaccard X  X  coefficient above the threshold for the final document.

Fig. 6 shows an example of a significant story we mined us-ing this function with  X  =0 . 2 ,b = 5. The story begins with a high throughput experiment that links chemical stress to gene expression in Saccharomyces cerevisiae , and ends with heat stress transcription factors in tomato. The  X  X tory line X  is initiated through comparisons between oxidative and heavy metal stresses. This leads to a paper identifying a gene from Candida sp. thatwasexpressedwhenthecells are exposed to cadmium but not copper, mercury, lead or manganese. Interestingly a BLAST search for the encoded protein sequence indicates that the protein is novel. The link between tomato heat stress transcription factors and a cadmium-specific gene with no known match in the current databases is through work with Schizosaccharomyces pombe where a study looked specifically at heat and cadmium stress responses. This story hence illustrates the key players in the systems biology of related chemical stresses.
We briefly survey related research in three categories: story-telling in information visualization, approaches for topic track-ing in documents, and link mining.

In the first category, storytelling has been viewed, not in a data mining context, but as an information organization tool based on narrative struct ures from real life. Kuchin-sky et al. [4] propose an interactive approach for biological information management using three constructs  X  items, col-lections (of items), and stories. A  X  X tory editor X  is used to form an outline of the story using a template. The players (items and itemsets) are then used to fill in the template manually to complete the story.

Pertinent work in the topic tracking community, e.g., [3] focuses on post-processing search results into storylines by analyzing bipartite graphs of document-term relationships. Here a story is a thread of related documents with tempo-ral as well as semantic coherence. Although similar to our PubMed abstracts case study, these works are focused on unsupervised discovery of all threads whereas we focus on directed storylines between given start and end points. Fur-thermore, as shown in our GeneSets case study, we allow arbitrary set constructions for the purpose of positing over-laps by casting stories as a generalization of redescriptions. The definition of a  X  X hread X  is also different in this work and relies on the notion of node-disjoint directed paths.
Link mining [2] begins with data that can be modeled as a collection of links and, in this sense, storytelling can be approached as a problem of analyzing overlap relationships. However, the links used and sought by us are between sets of items rather than individual items, and these sets are not enumerated beforehand. The concept of stories is also inherently similar in spirit to relational knowledge discov-ery, e.g., [8], but observe that our vocabularies are primarily propositional in nature, and defined over a single domain of objects. In future work, we aim to generalize story telling into relational redescription mining where the stories can straddle different domains and employ relationships for nav-igating across domains.

Finally, the applications presented here suggest compar-isons to classical discovery systems such as Swanson X  X  Ar-rowsmith [13] which can be viewed as seeking stories of length two. Our stories can b e of arbitrary lengths with differing complexities of the participating descriptors.
By defining stories as chains of redescriptions, we have been able to design a storytelling algorithm as A* search around the outputs of a redescription mining algorithm. We have demonstrated the scalability of this approach using the Word overlaps case study and showcased its potential for knowledge discovery using the Gene sets and PubMed ab-stracts case studies.

In future work, we aim to investigate other metrics for evaluating stories besides story length, e.g., based on the number of objects temporarily brought into the story, the story X  X  conformance to prior background knowledge, or using overlap metrics that better mirror a domain scientist X  X  con-ception of set similarity. We also aim to explore connections to works that characterize the structure of partitions [5, 12] and investigate whether storylines can be designed around paths in such discrete structures. We also intend to gener-alize from propositional to predicate vocabularies and cast storytelling in the context of relational redescriptions. This will help provide structured stories that follow a template of connections. Our eventual goal is to establish storytelling as an important tool for reasoning with data and domain theories. [1] C.C. Aggarwal, J.L. Wolf, and P.S. Yu. A New [2] L. Getoor. Link Mining: A New Data Mining [3] R. Guha, R. Kumar, D. Sivakumar, and R. Sundaram. [4] A. Kuchinsky, K. Graham, D. Moh, A. Adler, [5] M. Meila. Comparing Clusterings by the Variation of [6] A.W. Moore and M.S. Lee. Cached Sufficient [7] A. Nanopoulos and Y. Manolopoulos. Efficient [8] J. Neville and D. Jensen. Supporting Relational [9] L. Parida and N. Ramakrishnan. Redescription [10] N. Ramakrishnan, D. Kumar, B. Mishra, M. Potts, [11] S. Sarawagi and A. Kirpal. Efficient Set Joins on [12] D.A. Simovici and S. Jaroszewicz. An Axiomatization [13] D.R. Swanson and N.R. Smalheiser. An Interactive
