 Shopping online has become increasingly popular, which severely impacts phys-ical stores. User comments play an important role in the sale model of online stores. Since potential customers ca nnot see the actual product items, other users reviews about an item are an important third party opinion they can use for reference.

On Taobao 1 or Jingdong Mall 2 , users can buy products that recommended by other consumers or from brands which have rave reviews. When they receive their products, they comment and rate the sellers based on their satisfaction with the purchases and on the seller X  X  service.

Though there are some works that analyze blogs or forum articles to obtain the opinions [1,2], these works are based on the long text in blogs and forums which have more semantic information than user comments which are restricted to 140 words or only one sentence. The following features of comments differ them from blogs or forum articles: First, the language of comments is informal with short length. Second, the texts of comments are with the strong subjectivity. Third, there are so many emoticon such as smiling face and crying face etc. Fourth, the new expressions on web such as xidapubeng , renjianbuchai in Chinese and gooooood , cooool in English, are frequently used and quickly evolving.
There are a number of studies on sentiment analysis on short text. The ap-proaches could fall into two categories. One is lexicon-based or knowledge-based [3,4,5], and the other is based on corpus-driven learning [6,7,8].

Lexicon-based approach predicts the emotional tendencies of sentence through a lexicon together with TF/IDF . Experiments show that this method has achieved a satisfying result. But there are still problems: First, different do-mains have different emotion express way s. Second, emotional expression in web environments is evolving, and a large number of new neologisms have sprung up every year.

For sentimental analysis of short text, corpus-driven learning is the predom-inant trend. The approach extracts a set of hand-designed features from the sentence, then feeds the features to a cla ssification algorithm. Pang et al. [6] took the lead in introducing machine learning into the problem of sentiment classification. Three machine learning methods (Naive Bayes, Maximum En-tropy, SVM) were employed on sentiment classification. The results showed that machine learning methods do not perform as well as on traditional topic-based categorization. A conclusion was made that sentiment classification problem is more challenging.

Based on conventional methods, [9] added the punctuation mark such as !, ?, :-), and [8] considers the external features such as star rating, emoticons and hashtags to assist the sentiment classification for Tweets in Twitter 3 .How-ever, reviews of product rarely contain th ese features. [10] uses Recursive Neural Tensor Network to train the corpus. However, the method contains the follow-ing request: first, phrases as features n eed sentiment labels; second, the corpus training should with fully labeled parse trees.

In this paper, based on semantic relevan ce of phrases, we analyze the sentiment of Chinese reviews. The sentiment analysis for English product reviews has been widely studied in recent years, followed w ith many important achievements. Due to the special language traits of Chinese, the study on Chinese product reviews is much more difficult than the former.

We propose a novel approach to deal with sentiment classification. In pre-processing, we do as little as possible. In training process, a neural network architecture based on skip-gram is used to train a positive model and a negative model respectively. At this stage, the relevance of phrases is encoded in phrase vectors. The phrase vectors make up two phrase vector sets corresponding to the two models. The predication of sentences emotional tendencies is based on the phrase vectors.
Compared with previous works, our contributions can be summarized as fol-lows: 1. We introduce Skip-gram model to train Chinese phrases, which could obtain the semantic relevance of phrases. These phrases which frequently occur together could have much similar representation. 2. Comparing to existing sentiment classification methods, our method does not need extracting a set of complex ha nd-designed features from sentence. 3. Vectors of positive data and negative data are trained independently, so the model is convenient to parallel extension.
 The rest of the paper is organized as fo llows: Section 2 gives related work. Section 3 presents how to construct the m odel, and the training of phrase vector. Section 4 presents our model of estima ting the emotional polarity of review sentence. Section 5 reports our experime nts and Section 6 concludes this paper. The model we present in this paper draws in spiration from prior work on both sentiment analysis and distributed representations.
 Sentiment Analysis. [3] proposed a lexicon-based algorithm to determine the sentiment orientation of a sentence. It was based on a sentiment lexicon gen-erated using a bootstrapping strategy with some given positive and negative sentiment word seeds and the synonyms and antonyms relations in WordNet. The sentimental orientation of a sentence was determined by summing up the orientation scores of all sentiment words in the sentence. A positive word was given the sentiment score of +1 and a negative word was given the sentiment score of -1. In [4], a similar approach was also used. Their method of compiling the sentiment lexicon was also similar. However, they determined the sentiment orientation of a sentence by multiplying the scores of the sentiment words in the sentence. Again, a positive word was given the sentiment score of +1 and a negative word was given the sentiment score of -1.

In [5], Nigam and Hurst applied a domain specific lexicon and a shallow NLP approach to assess the sentence sentiment orientation. In [7], a semi-supervised learning algorithm was used to learn from a small set of labeled sentences and a large set of unlabeled sentences. The learning algorithm was based on Expectation Maximization (EM) using the Naive Bayes as the base classifier. This work performed three-class classification, positive, negative, and other (no opinion or mixed opinion). In [8], sentiment classification of Twitter postings (or tweets) was studied. Each tweet is a single sentence. The authors took a supervised learning approach. Apart from the traditional features, the method also used hashtags, smileys, punctuations, and their frequent patterns. These features were shown to be quite effective.
 Distributed Representations. Distributed representa tions for words, where words are represented as continuous vectors have a long history. It was first proposed in [11] and has become a successful paradigm, especially for statistical language modeling. A very popular model architecture for estimating Neural Network Language Model (NNLM) was proposed in [12], where a feed forward neural network with a linear projection layer and a non-linear hidden layer was used to learn jointly the word vector representation and a statistical language model.

Another interesting architecture of NNLM was presented in [13,14], where the word vectors are first learned using neural network with a single hidden layer. The word vectors are then used to train the NNLM. Thus, word vectors are learned even without c onstructing the full NNLM. In this work, we directly extend this architecture, and focus just on the first step where the phrases vectors are learned using a simple model. Representing Sentences and Document [15] are a recent trend and received much attention. Traditional text analysis considers the whole text as a vector, and treats words as dimensions. Besides the high feature dimensionality and feature sparsity, con-sidering each word as a dimension has a drawback: the model cannot obtain the relevance of each word. The model treats terms as atomic units and there is no notion of semantic relevance between terms.

Distributed representations for terms use an elegant way to solve the problem of semantic between terms of text. For distributed representation, a term is treated as a vector. The dimensionality of a term usually set to 50 or 100, and the value of dimension is not necessary to be non-negative. Through appropriate training, the term vector can be improved, and more semantic related terms can have more similar vectors. So, using cosine function or Euclidean distance can quantitatively calculate the degree of the relevance. In this paper, we learn from distributed representation to represen t phrases of Chinese product reviews.
Before the emotional tendency analysis, we give the process of training phrases vector. It is necessary to emphasize th at our model trains phrase vectors for positive data and negative data respectively, in other words that there are two vector sets.

The model to construct should guarantee that a positive sentence has the maximum generating probability in positive model, and a negative sentence has the maximum generating probability in negative model. Expressed math-p ( S | model ( P )) &lt;p ( S | model ( N )). Here model ( P )and model ( N )arepositive and negative model respectively.

For any model, given a sentence with T phrases: t 1 ,t 2 , ..., t T ,here t i  X  V , and V is the vocabulary. p ( S ) can be defined as: p ( S )= p ( t 1 ,t 2 , ..., t T ). The
Since the long-distance words are usually less related to the current word than those closed to it, we only consider small number phrases before and after the center phrase. The number can set to 2 c , so the formula can be simplified lation, we obtain the following objective:
So, we should maximize the log probability (1) to approximately achieve our goal.

Skip-gram algorithm [13] is a preferred algorithm for us. The objective func-tion of Skip-gram is to maximize Formula (2), which is mathematically equivalent to our objective function.
In our work, we refer to [13] to construct our training model and train the phrase vectors respectively. The module o f training model is shown as left side of Fig. 1.
 4.1 Definition and Theorem In order to better express our thoughts, we give some definitions and theorems as following.
 Definition 1 : Generating Probability. Define the probability that phrase B occurred after A in a model as the generating probability of B given condition A : p ( A  X  B ) ; define the generating probability of sentence s as p s : n p ( t n  X  1  X  t ).
 Definition 2 : Define the generating probability of B given condition A in posi-tive model as p + ( A  X  B ) . Define the generating probability of B given condition A in negative model as p  X  ( A  X  B ) ; define a sentence s generating probabil-ity in positive model p + s as n p + ( t n  X  1  X  t n ) , define a sentence s generating probability in negative model p  X  s as n p  X  ( t n  X  1  X  t n ).
 Definition 3 : Define the relevancy of phrase A and phrase B as the cosine of phrase vector C A and phrase vector C B in a model: cos C A ,C B ; define the relevancy of phrase A and phrase B in positive model as positive relevancy: cos + C A ,C B , and define the relevancy of phrase A and phrase B in negative model as negative relevancy: cos  X  C A ,C B .
 Definition 4 : Define p + ( A  X  B ) as the positive relevancy of phrase A and B ; define p  X  ( A  X  B ) as the negative relevancy of phrase A and B .
 Theorem 1 : For a sentence in a training set, the generating probability is largest in the corresponding model.
 Proving : As in previous section, training of phrase vectors in a corpus is to tences in the training corpus, the phrase vector set of the corpus must be the optimal vectors for them. Two borderin g phrases in a sentence can have much more similar vector representations in the corresponding model than in other models where the two phrases could not be adjacent in a sentences. Considering the definition of generating probability, the theorem is obvious.

We have also verified the conclusion in an experiment. The experimental data is a public sentimental dataset. The dataset will be introduced in Section 5. Here based on the positive data and negative data, we first train the positive phrase vector set and negative phrase vector set r espectively, and then randomly select the training sentences to compute the generating probability based on the two vector sets (as Algorithm 1), finally choose the largest probability corresponding models emotional tendency as the sentence emotion. We calculate the accuracy of the classification. The result is given in Table 1. The result validates our theorem by experiment.
 Deduction 1 : For a review sentence, the generating probability will get the maximum value on the phrase vector set which has the same emotional tendency of the review sentence.

Intuitively, for the same products, the positive reviews will trend to the similar expression, and the negative reviews have this feature too. 4.2 Construction of Prediction Model Through the training of a mass of corpus based on training model we described previous section, the values of phrase vectors are changed iteratively, and these phrases frequently occur together can hav e the similar phrase vector. Finally, we have obtained two vector sets: the positive set and negative set respectively. We could use Definition 3 and 4 to quantitativ ely calculate the degree of relevance between two phrases. So the relevance of phrases is recording in the phrase vectors, and we could use it to predicate the emotional polarity of other sentences as Deduction 1. Based on the vector sets, we use a generative model to predicate the emotional polarity of a sentence. First, we generate the sentence based on the two sets, and then choose the emotion of the set which has the higher probability as the sentences sentiment orientation.

Based on Deduction 1, we give the algorithm of predicting the emotional tendency for a review sentence in Algorithm 1.
 Algorithm 1. Predicting the emotion tendency of a review sentence
For Algorithm 1, when a sentence only has one word, there is no generating probability for the sentence. However, this type of sentence is much easier to analyze, we only should resort to a lexicon. The module of prediction model is shown in the right side of Fig. 1. 5.1 Experimental Dataset In order to verify the reliability of our model, we perform experiments on real data which is product reviews crawled on Jingdong mall . These data contain electric appliances ( phone , notebook , household appliance ) and clothing ( clothes , shoes , accessories ). The dataset is crawled between March 1, 2014 and March 25, 2014. The reason to use the reviews of Jingdong mall is that Jingdong allows users to give star-rating when commenting the products. Specifically, when users comment about their feelings of shopping experience about the products, they need to choose 1-5 stars to express the degree of satisfaction. The more stars users give, the more satisfaction they have about the products, meanwhile the much more positive trend reviews they give.

So when crawling the reviews of products, we also record the corresponding stars reviews have. We put the reviews that have 4 or 5 stars in the positive data set, and the reviews that have only 1 or 2 stars in the negative data set. Through some preprocessing, we obtain our experimental data of Jingdong mall . The detail information is summarized in Table 2. For most customers, shopping is a pleasant experience. In Jingdong mall , positive reviews outnumbers negative reviews 22: 1.

A publicly available sentiment dataset is also employed in our study. The dataset is provided by researcher Songbo Tan 4 in Institute of Computing Tech-nology of the Chinese Academy of Sciences. It contains three small sample data sets: Book reviews of Dangdang book mall , notebook reviews of Jingdong mall and hotel review data of Ctrip . Each data set has approximately 2000 sentences for positive and negative respectively. The summary information is also listed in Table 2. 5.2 Experimental Setting and Results For each data set of Jingdong mall , we randomly choose 9/10 of sentences to construct the training data set. The rest sentences are used for testing.
Using the positive and negative training data sets, we have trained two phrase vector sets. Based on the phrase vectors s ets, we predict the emotional tendency of sentences at the rest 13135 positive reviews and 809 negative reviews, the results are shown in Table 3 before slash (/).

Through analyzing the false judgment results, we find that these misclassified reviews mostly are long sentences, which have too much weak semantic rele-vancies between phrases. A single phrase X  X  generating probability is small, but by incremental addition, they could ex ceed phrases which have large generating probability. The accumulation of weak generating probability could effect the judgment.

Fig. 2 is an example, which means  X  The phone seems okay, though the color is wrong, and is enough for older parents  X  in English. The review is a positive review, but the sentiment is predicted as negative tendency.

In order to further optimize the experiment and reduce the classification error, we add a threshold  X  on the generating probability of phrases to filter out the weak semantic relevance, and enhance the strong semantic relevance. In our experiment, we set  X  to 0.25. The optimized results are shown in Table 3, after slash. Comparing with the result before and after optimization, we can find that only add a threshold, there can be 6 percentage and 2.2 percentage improvement for predicting.

We compare our model to SVM model and Naive Bayes model. For binary classification, SVM is well known as one of the most effective methods. In spam filtering, Naive Bayes model has been successfully used. Identifying negative reviews from positive reviews can be regard as a analogy with identifying spam from normal mail, since positive reviews outnumbers negative reviews 22: 1. Considering the n-gram model is widely used in text categorization, we compare to SVM and Naive Bayes model with bi-gram features too.

The experiment is conducted on the data of electrical appliance, which in-cludes air-conditioning , washer , flat screen TV reviews. These data contain 16358 positive reviews and 61661 negative reviews. The experimental results are shown in Table 4. From Table 4, we can see that, both on the precision and training time, our model is superior to the other two models. When using the all Jingdong mall reviews data, the results of both SVM and Naive Bayes tend to be random. What is more serious is that the training time of SVM is unusually long, hardly compared to our model.

SVM is effective on small sample text classification. However, when the data volume is large, especially when the data do not belong to a particular domain (here the data contain LCD TV , washer , etc.), its emotion classification effect will reduce sharply. For Naive Bayes model, unlike its performance in spam filtering, where the more training data, the better classification effect, the accu-racy here also is not high as we expect ed. Our model X  X  accuracy is more than ten percentage points higher than Naive Bayes model and SVM model. The ex-periments illustrate that the emotion classification is different from the theme classification, more sophisticated methods are needed. The proposed model of this paper, both on the training time and accuracy has better results.
In order to more in-depth analyze the performance of our model with a vari-able sample space, we experiment on data from Jingdong mall with a number of reviews 8000, 16000, 64000, 120000, 250000, 500000, 1000000 and 2000000. Here we only display the compared results of basic SVM and Naive Bayes, since the bi-gram versions of them have similar training time and precision tendency. The results are shown in Fig. 3.

The left-hand of Fig. 3 shows the training time of the three models. The training time of our model at very low slope linear growth with the training data, though the SVM model is almost linear growth, the curve is sharply steep. Naive Bayes model has the lowest slope, but as shown in right-hand of Fig. 3, it has the least accurate. The right-hand of Fig. 3 shows how accuracy changes with data scale changes for the three mod els. The predict accuracy of our model improves continually when data scale grows. However, the other two models have no obvious improvement with data incr ease, the SVM model even decreases.
Finally, we experiment the predict accu racy and time consuming of our model and the comparing models on the three publicly available sentiment data sets. The results are shown in Fig. 4.

As shown in left hand of Fig. 4, since the data scale is small and neat, SVM model is effective. This demonstrates the ability of our model to deal with small-sample learning problems. From the figure, we can also see that our model has achieved as high accuracy as SVM model. The right hand of Fig. 4 shows that, the training and testing time of our model are much less than that of the SVM model, in an order of magnitude less time than it. That demonstrates that our model occupies preferable predication performance on small sample data too. Based on the hypothesis that sentences wi th same emotional tendency often have similar language expression and collocation in Chinese, we propose a generating probability model for sentiment classification for Chinese product reviews.
In training step, two vector sets of phr ases are trained respectively by the proposed model with positive and negative reviews corpus. The sentiment of a new review could be predicted by the probability of sentence generating from the two sets. We choose the emotion of set which has the highest generating probability as the new review emotional tendency.
 Acknowledgments. We would like to thank all reviewers for their valuable suggestions. The research is supported by 863 Program (No.2012AA011003).
