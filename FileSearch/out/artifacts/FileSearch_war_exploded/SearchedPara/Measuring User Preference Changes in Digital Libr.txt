 Much research has been conducted using web access logs to study implicit user feedback and infer user preferences from clickstreams. However, little research measures the changes of user preferences of ranking documents over time. We present a study that measures the changes of user prefer-ences based on an analysis of access logs of a large scale dig-ital library over one year. A metric based on the accuracy of predicting future user actions is proposed. The results show that although user preferences change over time, the majority of user actions should be predictable from previous browsing behavior in the digital library.
 H.3.7 [ Information Storage and Retrieval ]: Digital Li-braries X  User issues Algorithms, Measurement, Experimentation, Performance personalization, web usage mining, user preference, stability
Extracting implicit user preference feedback becomes an attractive method to obtain personalized services since the method typically do not require additional user actions and generate much more data compared to explicit feedback methods[3, 6]. Research shows that clickthrough data ob-tained from information retrieval systems has a strong cor-relation with user explicit feedback [4]. However, most user preference research to date has not dealt with measuring the changes of user preferences. These changes will typically re-sult in the need to weight document features differently over time. To study the temporal properties of user preferences, we extract implicit feedback for more than 4,000 discrete Score ( D i 2 , U ) &gt; 0). The preference vectors trained based on the implicit feedback extracted from user clickstreams can be studied as a function of time by segmenting the web access logs. For example, an one-year-long log can be split into 12 sections for each month. Therefore, the preference vectors trained on each section of logs represent the user preference in each month, and the series of preference vectors for each month capture the changes of each user information needs.

For a set of n document pairs P = { p 1 , p 2 , ..., p n } repre-senting the implicit feedback of a user, we use the preference vector that maximizes the correctly ranked document pairs of a user as the user X  X  preference vector (see Eq1).
To measure the changes of user preferences, we define a metric S of user preferences as Equation 2.

Let a ( t ) be the accuracy of using preference vector trained on access logs prior to time t to predict the user actions in accuracy for the time section from 1 to T . A is the average prediction accuracy and  X  ( A ) is the standard deviation of the series. Since the prediction accuracy is always less than 1, the metric S will be a real number between 0 and 1. According to the definition, user preferences are more stable if their average prediction accuracy is higher or the deviation is lower. As an example, given the preference vectors for three continuous time sections, if the first vector predicts 80% of the second section, and the second vector predicts 60% of the third section, the measure S is 0.636.
We analyze user preferences based on one year X  X  worth of access logs from CiteSeer [2]. CiteSeer is a large scale aca-demic digital library and search engine hosting 767,558 aca-demic documents primarily in computer science field. The users of CiteSeer are typically computer scientist including faculty and students in academia as well as researchers in re-lated research institutions. CiteSeer receives more than two million visits per day including both users and web crawlers. In our research, web crawler generated log records are fil-tered out by their identification and access behavior. The users are identified by unique IP addresses. By applying the user preference model and computing the measure S , the changes of each user preference is given as a real number that higher value represents stable user preference. Thus, the metric S can also be used as an indicator of user pref-erence changes to investigate user related problems such as ranking and recommendations. The distribution of S for about 4,000 CiteSeer users is shown in Figure 1. The dis-tribution peak is at 0.94 which indicates the majority user preferences are stable.
