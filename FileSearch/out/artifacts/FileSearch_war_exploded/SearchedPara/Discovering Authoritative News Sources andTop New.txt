 According to a recent survey conducted by Nielsen/NetRatings [12], online news-papers have enjoyed double-digit year-over-year growth last year, reaching one out of four Internet users. This should not be astonishing considering the ad-vantages of online news as said by Peter Steyn of Nielsen/NetRatings,  X . . . it provides a different perspective and grea ter depth of information  X  statistics, pictures, interactive maps, streaming video, and analyst comments X . This kind of growth spurt urges the necessity for efficient organization of large amount of news articles available online. As the traditional process of reading one news-paper after another and selecting relevant stories has become inefficient or even infeasible in this environment, the idea of assembling news articles from multiple sources and digging out the most important stories seems to be very appealing. In this paper, we tackle this challenging problem of automatically ranking news stories assembled from multiple news sources according to their importance.
It is not easy to identify important news, as each person may have his/her own interest on news events, and each news source may also have its own pref-erence when reporting news. Measuring the importance of news is inherently a subjective problem. However, one of the major advantages of assembling news from multiple sources is that it allows for the integration of different opinions and could provide unbiased perspective on the most important events currently occurring or happened during a specified period of time.

Generally speaking, important news event is usually covered by multiple news sources. Besides, important news always occupies a visually significant area on the homepage. The visual significance of a piece of news on the homepage can be regarded as the recommendation streng th of the news presented by the source. However, the authority of different sources is not the same. News sources with high reputation generally recommend news with proper strength, while oth-ers may have certain kinds of local preference. News presented by authoritative sources with highlighted visual representa tion is more likely to be important. And a news source which issues a lot of impo rtant news is expected to be authorita-tive. Thus the authority of the news sources and the importance of news exhibit a mutual reinforcement relationship, which is quite similar with the relationship between hub pages and authoritative pages in a hyperlinked environment [1].
A primary difference between our probl em and the structure of a hyperlinked environment is that news pages are always only pointed to by the homepages they belong to, which will crash the HITS algorithm. Fortunately, different news pages are not absolutely independent. They may cover the same or related news events. Based on this implicit relationship between news articles, we propose to use a label propagation based semi-superv ised learning algorithm [2] to predict a news site X  X  recommendation strength on the news articles that are issued by other sites. The local and global consistency property of this label propagation algorithm guarantees a quite smooth and precise prediction. Integration of the label propagation algorithm with the HITS like mutual reinforcing algorithm produces a reasonable ranking of assembled news articles as well as news sources.
The rest of this paper is organized as follows. In Sect.2, we introduce some related works both from commercial and academic communities. In Sect.3, we explain in detail our algorithm for ran king news articles and news sources. We describe the system TOPSTORY which is built to validate our algorithm in Sect.4. Experiment results are presented in Sect.5. Finally, we conclude in Sect.6. Many commercial news search engines are already available for indexing online news. Google news [13] gathers and indexes news information from more than 4,500 sources worldwide. In addition to keyword search, it also provides the ability to browse categories of news where headlines are assembled and ranked automatically. Besides, related news articles are grouped to better present re-ports on the same story from different organizations. Yahoo news [14] performs similar service on more than 5,000 sources. Unlike Google news, the articles and sources are hand-assembled by Yahoo editors and no clustering technique is applied. MSN has also issued its news search service known as Newsbot [15]. What set Newsbot apart from other news aggregators are the history and per-sonalization features designed to help users easily find news relevant to their own interests. However, the information on how commercial news search engines rank news articles is very limited. We only learn that many different metrics have been employed for determining the prominence of news articles such as the importance of the source, timeliness of the article and its relation to other stories in the news currently. We take in account these factors in designing our news ranking algorithm.

The problem of organizing news articles in a meaningful manner to facilitate user navigation has also been exploited in the academic scenario. A research program called Topic Detection and Tracking (TDT) [3] investigates a variety of automatic techniques for discovering and threading together topically related material in streams of data such as newswire and broadcast news. However, it doesn X  X  address the problem in the current web environment where multiple streams of data come across. And ranking is not involved in its formally defined research tasks. There are also many other works which focus on organizing news articles such as summarizing clusters of related news articles [10], providing personalized news [11] and etc.
 The first academic discussion on the news ranking problem is addressed by Gianna M. Del Corso et al. in [4]. They proposed a framework to rank a stream of news articles and a set of news sources. Quite similar to our work, they also utilize the mutual reinforcement between news articles and news sources as well as the clustering character of important news. However, they did not take in account the different visual significanc e of news items on the homepages, which is an extremely valuable metric for evaluating importance of news. In [5], the relationship between homepages, news and latent news events was modeled by a tripartite graph. A hybrid model was presented to identify important news, which combined the mutual reinforcement relationships between homepages and news articles and between news articles and news events. However, the combi-nation process can be regarded as using a very na  X   X ve method to predict a news site X  X  recommendation strength on news articles that are not issued by it. The imprecision of the prediction would degrade the overall ranking algorithm. 3.1 A Graph Model for News Articles and News Sources Generally speaking, news sources usually maintain a set of homepages which serve as portals for users to access the news articles. Accordingly, news articles are categorized and their titles are listed on the corresponding homepages. The relationship between news articles belonging to a certain category (World, Busi-ness, Sports, etc) and their sources can be represented by a graph G =( V, E ) where V = S  X  N and E = E e  X  E i (Fig. 1). S = { s 1 ,  X  X  X  ,s m } is the set of vertices corresponding to news sources and N = { n 1 ,  X  X  X  ,n n } represents news articles. E is the set of edges which indicate the relations between vertices.
The set of edges E e describe the explicit linkage relation between news sources and news articles. An simple and intuitive method for expressing this relation-ship is to use a binary function where e ij = 1 if the homepage of s i points to the news article n j ,elselet e ij = 0. This definition only captures the linkage rela-tionship and treats every link equally. However, news articles are not randomly listed on each homepage. Instead, they are usually carefully arranged by human editors who would assign different visual strength to the titles based on their evaluation of the importance of the news. The title of the most important news is usually put on the top of the page, accompanied by an image and a paragraph of abstract text, while the less important ones are only represented by the title (see Fig. 4 for example). This kind of difference in representation reflects editor X  X  recommendation and ranking of important news, which should be very helpful when considering our ranking problem. Therefore, a more meaningful manner is to use a real-valued function to characterize more accurately the relation be-tween news sources and news articles. Accordingly, we define a matrix Q m  X  n where q ij represents the recommendation strength of n j by s i .

Besides the explicit linkage, a kind of implicit relation lies between news ar-ticles. News is generally triggered by events happened in the world. Different articles from different sources may cover the same or related events. However, as news event detection in news corpus is not a simple task and has not been well resolved yet, a more reasonable method is to use similarity relation to describe this fact. The measure of similarity between text documents has been extensively studied in IR community. The more similar the news articles, the more probably they are reporting the same event. The set of edges E i represent this relationship accompanied by a matrix A n  X  n where a ij indicates the similarity between news articles n i and n j . We use the popular Vector-Space-Model (VSM) to measure the similarity in this paper. 3.2 Homepage Model While our initial focus is primarily on ranking news articles, the reputation of news sources and homepages also varies a lot. Homepages of some sources are more authoritative than others. An interesting fact is, the authority of news sources and the importance of news exhibit a mutually reinforcing relationship. News posted by more authoritative sources with prominent visual representation is more likely to be important. And authoritative sources are expected to recom-mend important news more reliably. This kind of property between news sources and news articles is extremely similar with the relationship between Web hubs and authorities identified by HITS algorithm [1]. We associate each source with a nonnegative authority weight w s i and each piece of news with a nonnegative importance weight w n i . We maintain the invariant that the weights of each type are normalized so their squares sum to 1: i ( w s i ) 2 =1,and i ( w n i ) 2 =1.Nu-merically, it is natural to express the mutually reinforcing relationship between news and sources as follows: Unlike the model in [5], we don X  X  normalize Q in (2) here, as we find out that the number of news a source presents should be an important factor when ranking homepages. Besides, according to our experiment, the ranking result of the news sources does not completely depend on the number of news articles they present even without normalization.

These two operations are the basic means by which w s and w n reinforce each other. The desired equilibrium values for the weights can be reached by applying (1) and (2) in an alternating fashion while maintaining the normalization con-ditions. It is expected that w s converges to the principal eigenvector of Q  X  Q T and w n converges to the principal eigenvector of Q T  X  Q .

Let B = Q T  X  Q with its entries b ij = m l =1 q li  X  q lj .Wenotethat b ij =0ifand only if the news articles n i and n j are issued by the same source, which is not the case for most pairs of news articles under this multi-source environment. If the news articles are arranged according to the sources they belong to, then B should be a block diagonal matrix. The eigenvectors of block diagonal matrices are the eigenvectors of the blocks, padded with zeros. As a result, only a set of news articles from a certain source have non-zero values in the principal eigenvector of B .Soisthecasefor w s . It fails to achieve our original goal of ranking news articles from multiple sources as well as ranking the sources. 3.3 Label Propagation Based Recommendation Strength Prediction The homepage model does not work out due to the sparseness of the matrix Q . It is quite similar with the data sparse problem in collaborative filtering if we regard each news source as a user who rates the importance of the news. The problem is, each piece of news is only rated by the site it belongs to and the intersection of the sets of news rated by different sites is extremely small. Fortunately, the news articles are not absolutely independent. They associate with others through the latent news events because different articles may cover the same or related affairs. We have used similarity relationship to model this property in Sect.3.1. Given a site X  X  ratings on a set of news which are the visual significance of the news on the homepage, it is possible to predict its ratings on the news articles that are issued by other sites.

Given a set of news articles N = { n 1 ,  X  X  X  ,n n } , the recommendation strength intend to predict the unknown recommendation strength on the rest pieces of news, i.e. y ( i )= y u ( i ) ,i = l +1 ,...,n by using the known label information y l and the similarity information among news articles.

Recently, Zhou et al. [2] proposed a label propagation based semi-supervised learning algorithm, which works by representing labeled and unlabeled examples as vertices in a graph, then iteratively propagating label information from any vertex to nearby vertices through weighted edges, and finally inferring the labels of unlabeled examples after the propagation process converges. This label propa-gation algorithm is motivated by a local and global consistency assumption. And the learned labels are sufficiently smooth with respect to the intrinsic structure collectively revealed by labeled and unlabeled vertices. It has been applied to many problems such as digit recognition, document classification [2] and image retrieval [6] and has been proven to work quite well. We investigate this label propagation algorithm for our recommendation strength prediction problem.
Let y 0 u ( i )=0 ,i = l +1 ,...,n . The algorithm is as follows: 1. Two news articles n i and n j are connected by an edge if n i is among n j  X  X  k 2. Form the affinity matrix W defined by w ij =exp  X  d 2 ( n i ,n j ) / X  2 if there 3. Normalize W symmetrically by L = D  X  1 / 2 WD  X  1 / 2 where D is a diagonal 4. Iterate (3) until it converges where t is iteration index and  X   X  [0 , 1]; 5. Let y  X  u denote the limit of the sequence { y t u } . Assign y  X  u as the recommen-
Here, the scaling parameter  X  2 controls how rapidly the affinity w ij falls off with the distance between n i and n j .Thematrix W fully specifies the data manifold structure. In the update scheme of (3), each piece of unlabeled news receives recommendation information from its neighbors, including both of the labeled news and other unlabeled news. The parameter  X   X  [0 , 1] is used to control the recommendation strength received from unlabeled neighbors.
This algorithm has been proven to converge to a unique solution [2]: where I is a ( n  X  l )  X  ( n  X  l )identitymatrix. L uu and L ul are acquired by splitting matrix L into 4 blocks after the l th row and column: According to (4), the initialization of y 0 u does not affect the solution y  X  u .
Although y  X  u can be expressed in a closed form, for large scale problems, the iteration algorithm is preferable due to computational efficiency. Using Taylor expansion, we have According to (6), y  X  u can be regarded as the sum of a serious of infinite terms. The first term spreads the recommendation strength of the labeled news to their nearby vertices, the second term spreads the strength further, and so does the third term etc. 3.4 Comparing with Previous Work In [5], the relationship between homepages, news and latent events was modeled by a tripartite graph, and a hybrid model was proposed which combined home-page voting model and cross-site similarity model to identify important news as shown in (7) and (8): where A is the similarity matrix as defined previously. K = diag ( k i )isanor-malization matrix with entries k i =1 / j q 2 ij . The major difference between the hybrid model ((7) and (8)) and the homepage model ((1) and (2)) lies in that in (7) a new matrix P = A  X  Q T is used to substitute the original matrix Q T be the column vectors of P . v i is the recommendation strength of the i th site on news articles with nonzero values on the news it presents and zeros on other news. The nonzero values of v i also constitute the initial labels y l that we use in our label propagation algorithm. We can regard the operation v i = A  X  v i as another method of predicting unknown recommendation strength. The compo-nents of v i are defined as the weighted sums of the known strengths where the weights are the similarities between news articles. Besides, the known strengths are also updated based on the same criteria. Comparing with the label propaga-tion algorithm, it looks quite like that this criteria stops the iteration process of (3) at t =1with  X  = 1. It is obviously not an equilibrium state and it does not possess the local and global consistency property of label propagation algorithm. We summarize our integrated ranking algorithm in Fig. 2.
 We have implemented a system named TOPSTORY to verify our algorithm (see Fig. 3). It monitors a set of news sources and crawls their homepages in a certain frequency. News pages that are linked by these homepages are also crawled when they are detected for the first time. Useful information in both homepages and news pages is extracted by parsing the crawled pages and then saved into a database.

The system could interact with users in two ways. Firstly, it periodically detects latest important news and automatically generates homepages for users to browse. Secondly, it can also been driven by users X  query. It could detect the most import news during any time period specified by the users. We also implement a simple clustering algorithm to group related news into events. These events are ranked according to the most important piece of news within them.
In the following, we describe how we extract and use the information in home-pages to compute matrix Q which indicates the visual recommendation strength. 4.1 Recommendation Strength from Homepage Each homepage is tracked by a set of snapshot pages { S t 1 ,S t 2 ,  X  X  X } with S t i denotes the homepage at a specific time t i . Each snapshot presents a set of news with different visual strength. We use a vision-based page segmentation algorithm (VIPS) [9] to analyze snapshot X  X  content structure.

Each snapshot is divided into a set of blocks such that each block is dominated by a piece of news (see Fig. 4 for example). The visual strength of a block is mainly determined by its size, position in the page and whether it contains an image. We use a simple rule to estimate it: where q ( S t i ,n j ) is the visual strength of news n j in snapshot S t i . BlockSize is the area of the block. MaxBlockSize denotes the max area of all blocks in S i . Top is the position of the top side of the block. PageHeight is the height of the snapshot page. And ContainImage indicates whether the block contains an image. Here 0 . 5 is an empirically chosen weight.

The visual strength of a piece of news may evolve over time. We need to sum-marize these snapshots to have a global view of how the homepage recommends it. The summarization rule is actually determined by users X  intention. If a user wants to browse important news during a time period, for example a week, then all snapshots in this week should be treated equally. In another case, when a user wants to know the latest important news, the latest snapshots should be more important than older ones. We asso ciate weights to snapshots in order to meet the different information needs of users: Here a sigmoid function is used to represent the decaying character of users X  interest. a and t 0 are parameters used to control time effect.

For each piece of news, its recommendation strength from a source is the weighted combination of the visual strength from the homepage X  X  snapshots that contain it: q ( s i ,n j ) is further normalized so that the maximum recommendation strength of each source equals 1. In this section, we first describe the data set we collected for our evaluation and the parameter setting in our experiment. Then we present the ranking result obtained using our algorithm as well as its comparison with other methods. 5.1 Data Set and Parameter Setting We monitored 9 continuous updated online news sites (see Table 2) for a period of half a month (from 3 / 16 / 2006 to 3 / 31 / 2006) and collected about 35 , 000 pieces of news. These news articles are classified in 7 different categories (see Table 1). And news articles are ranked within each category, as the importance of news from different category is generally incomparable. For space reason, we will only report the result of ranking the news belonging to the  X  X orld X  category in the following, considering that  X  X orld X  news is generally most popular.
 There are three parameters in the label propagation algorithm: k ,  X  and  X  . The algorithm is not very sensitive to the number of neighbors. We set k =10 in our experiment. We choose  X  =0 . 25 experimentally. And  X  is simply fixed at 0.95, which has been proven to work well in [2].
 5.2 Ranking News Sources and News Articles Table 2 shows the ranking of the news sources with respect to reporting  X  X orld X  news over the period of observation. ABC News results the most authoritative source, followed by REUTERS, CBS and YAHOO. An very interesting fact is the top two authoritative sources returned by our algorithm, i.e. ABC and REUTERS, are exactly consistent with the rating given by Newsknife [16] which rates news sites according to their appearances at Google News [13]. We observe that even without normalizing Q in (2), the ranking result is not completely determined by the number of news the sources present. For example, note that REUTERS is considered more authoritative than BBC although it posts rela-tively less news.
 We compare the ranking result of our algorithm with two other algorithms. The first one is the hybrid model proposed in [5]. We omit the normalization matrix K in (8) when applying this model so as to better focus on comparing how different prediction methods would influence the overall ranking algorithm. Another simple and intuitive method for predicting a site X  X  recommendation strength on the news that are not posted by it is to find the one-nearest neighbor of each unlabeled piece of news in the labeled set and take the product of the nearest neighbor X  X  recommendation strength and their similarity value as the recommendation strength of the unlabeled news.

We asked a group of five people to manually assess the importance of top articles returned by these algorithms. They mainly take in account the relative importance of the news events these articles report. We define three importance levels and their corresponding weight values as shown in Table 3. For each article, the average of the five labels is taken as its importance value. The ranking quality is measured using normalized discounted cumulated gain (NDCG) measure [7]. The results are shown in Fig. 5.

According to Fig. 5, the performance of the hybrid model is worst. As the frameworks of the three algorithms are quite similar, the major reason for its degradation is because its predictions on the recommendation strength of un-labeled news are not accurate. The one step weighted average of labeled values does not reflect properly how a site would recommend the news issued by other sites. Besides, the original known visual significance is also altered by this model, which should not be the case. Our label propagation algorithm performs bet-ter than the nearest neighbor method. As analyzed by Zhu et al. in [8], the semi-supervised learning is quite efficient for news data probably because  X  X he common use of quotations within a topic thread: article n 2 quotes part of article n , article n 3 quotes part of article n 2 , and so on. Thus, although articles far apart in the thread may be quite different, they are linked by edges in the graph-ical representation of the data, and these links are well exploited by the learning algorithm. X  The top ten events returned by our algorithm are listed in Table 4. In this paper, we have presented an algorithm for ranking assembled online news articles as well as news sources. We employ the visual layout information of news homepages and exploit the mutual reinforcement relationship between news articles and news sources. And we have proposed to use a label propagation based semi-supervised learning algorithm to tackle the problem of predicting the recommendation strength of a news site on the articles issued by other sites, which actually improves the structure of the relation graph between sources and new articles. This label propagation algorithm works quite effectively on news data as it naturally exploits the topic thread structure of news articles. By integration these two algorithms, the performance of our TOPSTORY system has been improved significantly.

In our future work, we intend to make our ranking algorithm work in an incremental manner, which is more consistent with the stream character of online news. And we will increase the scale of our system and make it fit better with the real web environment.

