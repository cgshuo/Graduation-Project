 Pseudo-relevance feedback via query expansion has been widely studied from various perspectives in the past decades. Its effective-ness in improving retrieval effectiveness has been shown in many tasks. A variety of criteria were proposed to select additional terms for the original queries. However, most of the existing methods weight and select terms individually and do not consider the im-pact of term-to-term relationship. In this paper, we first examine the influence of combinations of terms through data analysis, which demonstrate the significant effect of term-to-term relationship on retrieval effectiveness. Then, to address this problem, we formalize the query expansion task as an integer linear programming (ILP) problem. The model combines the weights learned from a su-pervised method for individual terms, and integrates constraints to capture relations between terms. Finally, three standard TREC col-lections are used to evaluate the proposed method. Experimental results demonstrate that the proposed method can significantly im-prove the effectiveness of retrieval.
 H.3.3 [ Information Search and Retrieval ]: Relevance feedback Algorithms.
 Integer Linear Programming, Relevance feedback Query expansion is a topic that has been studied for a long time. It is an important technique for improving effectiveness of informa-tion retrieval. As users X  queries are usually too short to describe the accurate information they need, it has received much more attention in recent years [2, 8, 12, 19, 17]. Pseudo-relevance feedback (PRF) is one of the most attractive and well-known expansion techniques. It does not require any user input and assumes that a small number of top-ranked documents in the initial retrieval result are relevant.
A variety of approaches and methodologies have been proposed to select expansion terms from these documents[3, 20, 16, 11]. These methods studied different criteria, thesaurus, web resources, linguistic features and many other aspects. While most of the ex-isting approaches generally can improve the retrieval effectiveness, the closed-form term-weighting formulas cannot easily handle rela-tions between terms. Through data analysis, we observe that com-bination of expansion terms can significantly impact the retrieval effectiveness.

In this paper, we propose a novel formulation, which converts the query expansion task into an integer linear programming prob-lem (ILP) [1]. An objective function and a number of constraints which capture the relationships between terms are specified. ILP is a well-studied optimization framework and can be used to search the entire space to select terms. The formulation provides a flexible framework for integrating different criteria as objective functions or constraints.

The major contribution of this work can be summarized as fol-lows: 1) We analyze the impact of relationships between terms and their combinations for pseudo-relevance feedback. 2) We propose a novel formulation of the query expansion task as a integer linear programming problem. 3) Expansion terms are selected as a set taking into account their relationships. 4) Experimental results us-ing three standard TREC collections demonstrate that the proposed method performs better than state-of-the-art algorithms.
This paper is organized as follows: related work and state-of-the-art approaches are reviewed in Section 2. The proposed approach is detailed in Section 3. Experimental results using TREC collections are described and discussed in Section 4. Section 5 concludes the paper.
Relevance feedback (RF) and pseudo-relevance feedback (PRF) are two main types of query expansion techniques with a long his-tory. They have received much attention due to their effective-ness in improving retrieval performance. The Rocchio formula-tion [15] is one classical RF approach. It reformulates the query in such a way that it gets closer to relevant documents and away from non-relevant documents in the vector space model. As no user input is required, pseudo-relevance feedback (PRF) has been widely studied in recent years. It usually assumes that the top  X  X  X  ranked documents are relevant to the query. Carpineto et al. [5] introduced several information-theoretic methods (e.g. Rocchio X  X  weights, Robertson Selection Value (RSV), CHI-squared and so on) for query expansion. External resources, such as WordNet [13], Wikipedia [19], and user logs [10], have also been used in various pseudo-relevance feedback methods.

Recently, some approaches that take into account term-to-term relations have been suggested. The methods proposed by Udupa et al. [17], Collins-Thompson [7] and [18] are most similar to our work. Udupa et al. claimed that the effect of including a term in an expansion set depended on the other terms in that expansion set. They proposed the use of spectral partitioning of the term-to-term interaction matrix to take into account term interactions. Collins-Thompson [7] formulated the query expansion as a convex robust optimization problem. However the risk-reward tradeoff of expansion is the main target of his work. Different with his method, we directly model the relation between terms in this work. [18] proposed the use of maximum relevance and minimum redundancy criteria to select terms as a whole. Term distributions and linguistic features are used to measure the relevance.
The objective of query expansion is to select words related to the query and use all the words rather than expanding each word separately [9]. The selected terms should be relevant to the query and subject to constraints which include the number of terms, and whether terms can be simultaneously selected. These constraints are global, and can not be adequately satisfied by selecting terms individually. Therefore, in this work, we formalize the problem as an integer linear programming (ILP) problem. This is a well-studied optimization framework and can be efficiently solved using standard optimization tools.
 Figure 1: Processing flow of the ILP-based query expansion method.

Fig.1 shows the process flow of the proposed approach. General-ly there are four phases in expanding queries: (1) select candidate terms, (2) classify individual terms according to helpfulness, (3) determine the term-to-term relations, (4) select expansion terms. These phases are detailed in the following sections.
As there are too many terms that can be extracted from the pseudo-relevant documents, we use the following score function to select top words as candidates:
Score ( t i ,q )=log where N is the total number of documents and R is the number of relevant documents. The number of documents and relevant doc-uments containing term t i are respectively represented by n r [14].
In order to determine whether the expansion terms extracted are useful for improving retrieval performance we use SVM, a super-vised learning method, for individual term selection. The training corpus is constructed according to the MAP change rate chg ( t of terms, which is described in the previous section. Terms whose MAP change rate is higher than 0.01 are selected as good expansion terms. Bad expansion terms are those that diminish performance.
Each expansion term is represented by a feature vector. Previous studies have introduced a number of useful features. In this work, we use the following features:  X  Term distribution . Term distribution in the pseudo-relevant documents has been used in many related works. In this paper, we define it as follows: where F is the set of feedback documents.  X  Document frequency . Document frequency in the pseudo-relevant documents is defined as follows: where dn ( t, F ) represents the number of documents where the ter-m t appears in the set of documents F .  X  Co-occurrence with the single query term . It has been shown that the terms that co-occur with the query terms are usually related to the query. Where C ( q i ,t | D ) is the frequency of co-occurrence of query term q and the expansion term t within text windows of the document D .  X  Dice X  X  coefficient . This is another popular association measure which has been widely studied. currences of query term q i in the document D .
As mentioned in the previous section, although each individu-al term can improve retrieval performance, their combination may have a negative impact on the final result. In order to model this, we convert the problem into a classification task. We try to identi-fy whether two terms together have a harmful or helpful effect on retrieval effectiveness.

MAP change rates, like the term classification task, can also be calculated from existing TREC collections. This is used to generate the training corpus. Any classifier can be used for the term-to-term relation classification. In the current work, we use SVM. In addition to the features used in the term classification, we also take into account the following additional feature:  X  Co-occurrence of two terms . It has been shown that co-occurrence of two terms can be described as follows: where C ( t i ,t j | D ) is the frequency of co-occurrence of the two terms t i and t j within text windows in the document D .
Integer Linear Programming (ILP) denotes a set of constrain-t optimization problems which have a linear objective function, are subject to linear equality and linear inequality constraints, and require the objective variables to be integers. With ILP formal-ization, the query expansion task is treated as a two class label-ing problem. Given a candidate set of terms S , for each term t  X  S , a term is selected as an expansion term (assign label  X 1 X  to the term), or not (assign label  X 0 X ). A vector of binary variables X =( x 1 ,x 2 , ..., x n ) is used over term t  X  D , to indicate whether the candidate term should be selected or not. When the objective function is put together with all the constraints, the ILP algorithm to select expansion terms is determined as follows:
The objective function Eq.(2) denotes the expected scores over all the words of a solution X . C =( c 1 ,c 2 , ..., c n ) is defined as the assignment value. The variable c i gives the value of labeling t a expansion term. We use result of the term classification to model the importance c i of the candidate term t i .
 In order to restrict the number of selected terms, we introduce Eq.(3) as one of the constraints. Eq.(4) ensures that the terms which have a negative influence will not be selected together. The SC ( t i ,t j ) in Eq.(4) is given through term-to-term relation classifi-cation, which is described in the section 4.3. Methods were evaluated with three TREC corpora: Disk4&amp;5 and WT10g. Three test collections, TREC 7, TREC 8, and TREC 10 Web were used in the experiments. Table 4.1 shows statistics re-lated to the collections. Disk4&amp;5 are part of NIST TREC Docu-ment Databases which are distributed for testing of IR systems. A number of TREC ad hoc tracks have used this corpus to evaluate systems. Topics 351 to 450 are used as queries. In order to evaluate our methods in a more realistic environment, we also assessed them in WT10g, used by the TREC 10 Web track. This contains more than 1.6 million documents collected from about 11,000 servers.
The SVM implementation SV M light 1 is applied to perform the classifications. For the ILP solver, we use YALMIP 2 to estimate the optimal solution from Eq.(2) to Eq.(6). The implementation of our expansion method is based on Indri 5.0 3 , where the retrieval model is based on a combination of language modeling and infer-ence network retrieval frameworks. Only the title of each TREC http://svmlight.joachims.org/ http://users.isy.liu.se/johanl/yalmip/ http://www.lemurproject.org/indri/ topic is used for the initial query. The main evaluation metric are Mean Average Precision (MAP) and the precision at top 10 (P@10) for top 1000 documents.
The main purpose of the experiment was to demonstrate the per-formance of the proposed ILP-based query expansion method. Sev-eral experiments were designed for this purpose. As the term classi-fication has already been evaluated by [4], we focused in this work on the term-to-term relation classification and the ILP-based ex-pansion method.
 Trec7 0.1810 0.2081 0.2208 0.2106 0.2465 Trec8 0.1941 0.2226  X  X  0.2199 0.3317 WT10g 0.1724 0.1819  X  X  0.1990 0.2099 Table 2: Comparison of performance using MAP for all test collections. Values in boldface indicate statistically significant improvement over the REXP-FB method. The paired  X  -test (  X &lt; 0.05) is used to measure significance.

Table 2 summarizes results for all test collections using different query expansion methods. The mean average precision (MAP) for the top 1000 documents is used as the evaluation metric. The left-hand column in the table shows the collection names. The NoExp column represents the results without query expansion using Indri. For the pseudo-relevance feedback run Base-FB , which is an adap-tation of Lavrenko X  X  relevance models, a built-in model in Indri, 20 terms are extracted from the 50 top-ranked documents. Results of method proposed by Cao et al. [4] are shown in the SVM .The REXP-FB column represents the result obtained by the state-of-the-art method REXP feedback [6]. The values in the last column ILP-FB are the results of our method.

In all three collections, the results of the ILP-based expansion method are statistically better than both the Indri baseline expan-sion method and REXP method. In TREC 8, our method shows a better than 70.8% relative improvement over the original retrieval result. The relative improvements over the state-of-the-art method REXP is also greater than 50.8%. In TREC 7 and WT10g, the im-provements of the method are also significant. This demonstrates the necessity of considering the relations between terms. Table 3: Comparison of performance using MAP and P@10 for the ILP-based method with and without term-to-term con-straints. Values in boldface indicate statistically significant im-provement over the No-Cons (no constraints) method. The paired  X  -test (  X &lt; 0.05) is used to measure significance.
Compared to previous methods, adding the term-to-term rela-tions into constraints is one of the main contributions of this work. It is then important to see whether these constraints contribute sig-nificantly. Table 3 summaries the results of ILP-based method with and without these constraints. These results show that ILP-based expansion methods with term-to-term constraints are statistically better than methods without these constraints. It also demonstrates the importance of considering term-to-term relations. Figure 2: Results of varying the number of expansion terms for all collections.

Figure 2 shows the change of MAP as the number of expansion terms varies for all three collections. We observe that MAP is im-proved when expansion terms are combined with the initial query. However, MAP does not continue to improve when more than 25 terms are used for expansion. This is mainly due to a reduction in the quality of terms. Although the best parameters are differen-t in different collections, significant improvement can be achieved when 15  X  20 terms are selected.
In this paper, we studied the impact of the relationships between terms and their combinations. In order to address the problem, we considered the query expansion task as an integer linear pro-gramming problem and used two classification models to obtain the objective function and constraints. In all three test collections, the proposed expansion method can significantly improve the re-trieval result. Experimental results also demonstrate that the pro-posed method can significantly improve performance.
The author wishes to thank the anonymous reviewers for their helpful comments. This work was partially funded by 973 Pro-gram (2010CB327900), National Natural Science Foundation of China (61003092, 61073069), Shanghai Leading Academic Dis-cipline Project (B114), and  X  X hen Guang X  project supported by Shanghai Municipal Education Commission and Shanghai Educa-tion Development Foundation (11CG05). [1] D. Alevras and M. W. Padberg. Linear Optimization and [2] J. Bhogal, A. Macfarlane, and P. Smith. A review of ontology [3] C. Buckley. Automatic query expansion using smart : Trec 3. [4] G. Cao, J.-Y. Nie, J. Gao, and S. Robertson. Selecting good [5] C. Carpineto, R. de Mori, G. Romano, and B. Bigi. An [6] K. Collins-Thompson. Estimating robust query models with [7] K. Collins-Thompson. Reducing the risk of query expansion [8] K. Collins-Thompson and J. Callan. Estimation and use of [9] B. Croft, D. Metzler, and T. Strohman. Search Engines: [10] H. Cui, J.-R. Wen, J.-Y. Nie, and W.-Y. Ma. Query expansion [11] X. Huang and W. B. Croft. A unified relevance model for [12] K. S. Lee, W. B. Croft, and J. Allan. A cluster-based [13] D. I. Moldovan and R. Mihalcea. Using wordnet and lexical [14] S. E. Robertson. On term selection for query expansion. [15] J. Rocchio. Relevance Feedback in Information Retrieval , [16] R. Sun, C.-H. Ong, and T.-S. Chua. Mining dependency [17] R. Udupa, A. Bhole, and P. Bhattacharyya. "a term is known [18] Y. Wu, Q. Zhang, Y. Zhou, and X. Huang. Pseudo-relevance [19] Y. Xu, G. J. Jones, and B. Wang. Query dependent [20] S. Yu, D. Cai, J.-R. Wen, and W.-Y. Ma. Improving
