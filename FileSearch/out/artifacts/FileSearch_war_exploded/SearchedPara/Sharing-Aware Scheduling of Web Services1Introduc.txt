 as needed in order to keep user s satisfied under varying workloads. minimizing the deviation from the deadline, that is, tardiness. 
Previous work [4, 9, 10, 11, 12, 13] on query scheduling focused on ordering of the execution of independent queries while ignoring the commonality among queries. As a result, a same work will be computed multiple times which negatively impacts user caching [3] can discover the query releva nce by identifying commonality among que-vant queries. In this paper we propose a new query scheduling framework which takes methods brings us the following two challenges: First, we need a mechanism to model minimize average tardiness.  X  and discover their commonalities. For example, the common sub-expressions between  X  We need to compute the common sub-expressions only once and cache their results. minimized and the tardiness of these three queries becomes 0 . Contributions. The main contributions of our paper are the followings:  X  monalities among queries.  X  cover commonalities among queries.  X  average tardiness while reducing redundant work at the same time.  X  proposed approach.  X  query scheduling algorithms with semantic caching techniques. Section 6 we discuss the conclusions. query scheduling. To our knowledge, no prior work considers both semantic caching and query scheduling in web databases system. 2.1 Semantic Caching The difference between our work and semantic cache is that we exploit intermediate query results. 2.2 Query Scheduling works considered sharing among queries during scheduling. Finally we X  X l formally define our problem. tasks, including implication and satisfiability which characterize query relevance. dicate implication and query satisfiability .  X  result of evaluating  X  X   X  is a subset of the result of evaluating  X  X   X  .  X  contained in  X  X   X  . Definition 3.2: We define the characteristics of a query to be (see Fig.2):  X 
Arrival Time (  X   X  ): The time when  X   X  has arrived at the database system.  X 
Deadline (  X   X  ): The ideal time by which  X   X  should finish execution.  X  adjusted accordingly.  X  slack time of query  X   X  is 0.  X  the tardiness is larger than 0. can obtain the optimal plan of each query. From these plans, we can identify common follows: process of reducing the overlapped part of the two queries. Each query contains two  X   X  X  X   X   X  X  X  X   X  X  X max  X , X   X  X  X  X  X ,  X , X   X  X  X  queries while excluding negative ones. 3.1 System Architecture Common Sub-Expressions Detector, Cache Manager and Query Scheduler. The Common Sub-Queries Detector finds all the common sub-expressions among queries. from memory. The Query Scheduler utilizes several scheduling strategies to schedule database system. 3.2 Problem Statement Next we define the query scheduling problem. Given a set of queries with the charac-optimizer of the underlying database system, we can obtain the optimal plan of each follows: (Sharing-Aware Query Scheduling Problem) Given a query set S  X   X  X  X  X   X  , 1 X  X  X  X  }  X   X   X , X   X , X , X  X  X  X  as much as possible by caching common sub-queries. common sub-expressions X  results in section 4.2. 4.1 Discovering Common Sub-expressions among Queries To discover common sub-expressions among queries, we need to determine whether a relationship. (a) Table-Indicator with minimal overhead during the scheduling.  X   X   X  is the set of output columns in the selection clause of  X  ,  X   X   X  is the set of source tables (or views) in  X  ,  X   X   X  is the set of attributes in the where clause of  X  . A them a group. (b) Query Splitting common predicates between each two queries using semantic caching method [5]. Hence there are three types of relationships between  X   X  and  X   X  (see Fig. 4). heuristics to pruning the improper ones.  X  improve the total performance.  X  cache. (c) Estimating Processing Time of Queries pling the database [14] or by machine learning (ML) based method [15].The sampling Considering that querying databases is time-consuming work, we adopt the sampling method [14] to estimate the query X  X  processing time due to its efficiency. 4.2 GASA: G reedy A lgorithm for S haring-A ware Scheduling of Web Queries Before we present the algorithm GASA , we have the following definitions. they start execution right now. where t is the current time. where t is the current time. 
The main idea of the algorithm is to pick one query Q1 from the heads of the two Algorithm 1. GASA(  X   X  ,C) Input: A set of queries with arrival time, estimated processing time and deadline. 
Output: The id of the queries to run until next scheduling point and the id of com-mon sub-expressions to cache. 1 Begin 2 for all newly arrived queries  X   X  do 3 Place  X   X  in the appropriate queue ( EDF -List or SPRT -List) 4 end for 5 resort EDF -List &amp; resort SRPT -List 6 while( EDF -List !=null and SRPT -List!=null) 7  X   X , X  X  X   X  Top (EDF-List) 8  X   X , X  X  X  X  X  X   X  Top (SRPT-List) 10 else  X  X  X   X , X  X  X  X  X  X  11 end if 12 13  X   X   X  X  X  X   X   X |  X   X , X  X   X  is disjoint X   X  and 14 j X = argmax  X   X   X  X  X   X  Q, X  X  X  X  X  X  X  X  X  X   X   X  ), ) 15 Return Q , run Q and cache Q, X  X  X   X  X   X   X  X  result 16 refresh Q  X  X   X  expression and re-estimate processing time 17 end while 18 End  X   X  run first. result. time, then return to step 1 until no more queries exist. lists. For splitting queries, we need O(N) to find common sub-expressions. In this section, we describe our experimental settings and report our results. 5.1 Experimental Settings Our experiments were conducted on the hardware configuration with 4-core 2.90GHz Intel CPU and 4GB memory running JVM 1.6.0 in Windows 7 Professional and data were stored in PostgreSQL 9.3. normal processed query number divided by the average query processing time. Each parameter with default value of 3.0. 
We conduct the comparison in both the sharing and non-sharing cases. In the shar-with EDF-Sharing, SRPT-Sharing LS-Sharing (which are EDF,SRPT and LS adapted with our greedy sharing strategies). 
The performance of all the approaches is measured in terms of two metrics: (a) av-processing time savings of the whole workload. 5.2 Experimental Results  X  Comparison with Sharing-Nothing Polices parameter  X  X 0.5 and  X   X  X  X  X   X 3.0 . ferent query workload are shown in Figure 6. As we can see, when the number of que-50.6% percent compared with ASETS* when the query number is 250.  X  Comparison with Baseline Sharing Polices average processing time savings. In this paper we proposed the problem of sharing-aware scheduling of web services. sign a strategy to discover commonalities among queries. We design a sharing-aware semantic caching techniques. 
