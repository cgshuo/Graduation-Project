 mining bridging rules between clus ters in a database, and then propose two non-linear metrics for measuring the interestingness rules (or frequent itemsets). This is because (1) bridging rules can be generated by infrequent itemset s that are pruned in association importance that includes the di stance between two conceptual clusters, whereas frequent itemsets are measured by only the support. Categories and Subject Descriptors H.2.8 [Database Applications]: Data mining; I.2.6 Learning. General Terms: Algorithms; Measurement; Theory.
 Keywords: Outlier, clustering, association rule, bridging rule, entropy. with the remaining set of the data objects. Outlier mining has wide applications [2-4] includi ng fraud detection, marketing, medical analysis and so forth. Here we define a new kind of outliers: bridging rules, the antecedent and action of which belong to different conceptual clusters. Formally, let I = {i 1 , i length transactions over I. Given a similarity measure  X  , all objects in D can be partitioned into disjoint clusters C 1 A  X  B is a bridging rule, where items in A belong to clusters C C , ..., C is ; items in B to clusters C j1 , C j2 and B are important. The importance of A  X  B can be measured by (1) The distance between {C i1 , C i2 , ..., C is } and {C (2) The association of A and B in the database D, and We name these interactions as bridging rules because they are the interactions that look like bridges linking different clusters. Bridging rules are useful in many applications. Especially in detecting insurance fraud and murd er cases, using bridging rules can produce unexpected results. The following is an example found in one of the experiments in Section 5. A local police office 2 invited us to help them analyze a case that a worker had disappeared. After making use of our algorithm, we analyzed some information of lo cal residents and mined the rule:  X  X orker (17)  X  IT clerk (21) X , where 17 represented the disappeared worker and 21 an IT clerk. We thought it to be a very valuable clue and advised the police to follow up on it. When the police investigated 21, they surprisingly found that before the worker 17 X  X  disappearance, this 21 person was already determined to be the wrong usag e of a water heater, and the insurance company was going to pay his spouse a great amount of insurance. hard investigation, they finally found out the terrible truth that the IT clerk really disappeared and the worker 17 did not disappear but was killed, and this brutal mu rder case involved this IT clerk, as well as his spouse. In fact, the IT clerk was a very bad guy. Because of gambling, he off his debt, he would possibly be killed. At this time, he met by chance worker 17, and subsequently designed a terrible plan when he unexpectedly found that worker 17 looked like himself very Firstly, he bought insurance involving a great deal of money. him into 21 X  X  home. Afterwards, they killed this poor guy and made the spot look like an accident. They wanted to get the insurance money from the insurance company and avoid those renters. these two cases that seemed to have no similarity between each other. Finally they successfully resolved both cases. The above example vividly and powerfully shows that our research was very promising in case analysis and insurance fraud detection. In addition, the fa mous association rule  X  X iapers beer X  is also a bridging rule because its antecedent and action belong to two different conceptu al clusters: alcohol and baby goods. And the antecedent and action of the rule  X  X teel chrome X  which can generate stainl ess steel belong respectively to rules can work well in many applications. the following reasons: (1) For association rules, such as  X  X read  X  butter  X  milk X , bread, These differences have indicated that we must exploit novel strategies to (a) confront an e xponential search space consisting of detect which of the itemsets can generate bridging rules; (c) identify which bridging rules are really useful for particular applications; and (d) measure the interestingness of bridging rules. The remainder of the paper is organized as follows. Section 2 approaches for mining bridging rule s. In Section 4, we design two non-linear measures for identifying bridging rules in terms of entropy. In Section 5 we evaluate our approach using groups of experiments. We summarize our cont ributions in the last section. detecting outliers. The statistical approach to outlie r detection assumes a distribution or probability model for the given data set and then identifies computing in this approach is considerable. A distance-based algorithm thinks of outliers as those objects that do not have  X  X nough X  neighbors being defined based on a distance from the given objects. It does not scale well with the dimensionality. Meanwhile, the number of exceptional patterns found depends very much on the user-speciali zed parameters. Deviation-based algorithms also exist when facing a high dimensional space. As relatively effective for data with 2-or 3-dimensions, and the latter relies heavily on parameters. Bridging rules are different from the above approaches because of our basis of conceptual clusters. Meanwhile, although bridging rules employ the same form of a ssociation rules as other patterns do, there are significant differences between them. Discovering unexpected patterns [3 ] has a subjective nature. It takes into consideration prior background knowledge that constitutes a set of expectations or beliefs about the problem domain. But its most difficult que stion is how to generate an initial system of beliefs. Mining exceptional patterns [2], which is also a subjective method, divide a ll patterns into three categories. This approach can avoid searching a ll attributes in the database so it can possibly be more effective comparing with other subjective algorithms. [4] has extended traditional associations to include association rules of forms A  X  X  X  B,  X  A  X  B and  X  A  X  X  X  B, which indicate negative associati ons between itemsets. Change mining [11] has focused on finding changes that are brought about by new data through analyzing a decision tree. Finding interesting patterns [12] is characterized by requiring the user to specify a set of patterns, making use of a fu zzy matching algorithm to match and rank the discovered patterns according to the specified pattern set. Compared to all the above approaches, bridging rules are different from the patterns generated in these approaches. As bridging rules require their antecedent and action come from different clusters, we need novel evaluation m echanisms and algorithms. In this section, we describe th e main ideas of our two algorithms: an agglomeration-based algor ithm and a weighting-based algorithm. We design the agglomeration-ba sed algorithm by improving the clustering technique  X  X HAMELEON X  [13] which considers inter-connectivity of the clusters by making use of RI(C closeness of items within the cl usters and taking advantage of RC(C i , C j ), and then defines two thre sholds TRI and TRC to find out a clustering. To discover bri dging rules between clusters, our algorithm is based on the following thresholds: T1RC, T1RI, T2RC and T2RI. Sub-clusters with RI(C i , C j ) &gt; T1RI and RC(C C ) &gt; T1RC are clustered into one cluster and those satisfying the following formula are also grouped together because there is a meaningful interaction between them: Using these thresholds to record the similarity between any two objects across conceptual clusters and identify interactions between them. Each interaction is a bridging rule that we want. We conducted some expe riments on a real-world database named zoo, including 101 records each of which consists of 18 attributes. The results are shown in Figure 1. In this graph, tuatara, alowwo rm and seasnake belong to one  X  bass X  and  X  X easnake  X  catfish X  are the bridging rules we are looking for. This strategy is a post-process de signed for transaction databases. We first find correlative items ets [14-15] based upon frequent itemsets across clusters, then pr une abundant itemsets by a set-enumeration tree [16], and finally calculate the importance of each itemset. There may be more than one bridging rule between two bridging rules. The importance  X  X M POR X  is defined as follows. be 2  X  (S), where S = {i 1 , i 2 , ..., i m }, and the weight of i define The weight of an item can be determined by, for example, the impact of the item. We have performed our algor ithm on a synthetic database including 50 transactions consisti ng of 15 merchandises that are divided into 3 clusters, as shown in Table 1. Adult Cigarette, lighter, western-style clothes, beer, tie 
Female Pregnant-women X  X  clothe s, perfume, lipstick, Baby Toy, diaper, nursing bottle Bridging rules identified in the database are as follows according to this weighting-based algorithm: 1. cigarette, lipstick, hairpin 2. cigarette, lipstick, high-heeled shoes 3. lighter, lipstick, hairpin 4. beer, diaper 5. perfume, western-style clothes effectively, including the famous rule  X  X iaper  X  beer X . The two algorithms above are efficient in mining bridging rules between clusters in a database. Th ey have some distinct features. The agglomeration-based algorith m is a clustering-like method, designed for mining relational data bases. It identifies bridging rules and generates clusters at the same time. The weighting-transaction databases. The chi-square and set-enumeration tree are used for measuring the interestingness of bridging rules. However, they have two limitations: 1. Using the same criterion for m easuring both bridging rules and the characteristics of bridging rules. 2. When measuring bridging rules, only the left and right of bridging rules are considered without the other important factors defined in Section 1. To include more important factors, below we propose two non-linear metrics based on the entropy for measuring bridging rules. Compared with other possible bridging rules between clusters in a database, objects in a bridging ru le can have a more important impact. For example, let A  X  B and H  X  L be two bridging rules over Ci and Cj, A, H  X  Ci and B, L  X  Cj; and act(X) stand for the more important impact than that in H  X  L, and A  X  B should be more important than H  X  L. On the other hand, bridging rules have different importance when straddling a vault between different clusters. For example, let Ci, Cj and Ck be three clusters. much more important than a bridging rule R2 straddling a vault between Ci and Ck. This importance can be obtained from, for example, examining the distance between two sets of clusters, or two sets. The above observations motivate us to design two non-linear database. We use similarity to measure the closeness relation between two contrasting sets of cl usters in D. Some definitions and formulas about joint entropy ( (,) H XY ), mutual information (I(X, Y)) and conditional mutual information ( (; | ) IXY Z found from Information Theory related books. Our joint-entropy-based strategy is based on the definition of joint entropy. Figure 2 shows the structure of this kind of bridging rules. In Figure 2, C 1 and C 2 are two conceptual clusters; c C and c 20 to C 2 . Furthermore, c 10  X  c 20 is a bridging rule in terms each object belongs to C 1 and associates with c 10 . We define: Figure 2. Structure of bridging rule based on joint-entropy similarity between c 10 and c 1j . Similarly, we can define Then the entropy sum of the bridging rule  X (c 10 , c 20 ) X  is: We define the minimum similarity threshold as  X  X insimi X  and the minimum joint-entropy threshold as  X  X inentro X . A bridging rule is interesting only if it satisfies both these two constraints. Since the contrasting sets of objects in a database, whereas the entropy measures the interaction (or distance) between two contrasting the closer the object associated with objects in a cluster is, and the bigger the entropy sum is, the more important the bridging rule is. It is the bridging rule (linkage) that we want to identify. This strategy is based on defin itions of mutual information and conditional mutual information below. In Figure 3, let X*, Y* be two c onceptual clusters and X, Y and Z denote object sets. X={x1, x2, ..., xn}  X  Y={y1, y2, ..., ym} and Z={x0, y0}, where X  X  X*, Y  X  Y*; x0  X  X*, and y0Y*. Z represents a linkage taken as our bridging rule, and x0 and y0 are located in two sides of the rule. Definition 1. Assuming X and Y are two random variables, the mutual information  X  X (X, Y) X  betw een X and Y is the expectation between xi  X  X and yi  X  Y, i.e., It means that the mutual information is the sum of the information amount of X given Y, which is th e same as that of Y given X. Definition 2. With a given Z, the conditional mutual information of X and Y is It shows the amount of mutual information of X and Y given Z. information of X and Y given Z. The bigger the value is, the more important the rule is. Consequently, we define the mutu al information constraint as  X  X ininfo X  and the similarity constraint as  X  X imsimi X . Then the bridging rule x0  X  y0 is interesting only if 1. Simi(x0, y0)  X  minsimi for each object and find its first k nearest neighbors. Then we use a reverse k-nearest neighbor graph [18] corresponding to x can reduce the quantity of objects in X and decrease the algorithm complexity. In addition, it can obtain the strongest impact of X on x . Similarly, we can get Y. When employing the k-nearest neighbor graph techniques, we neighbor graph, therefore, an edge between nodes is directed, and the direction can be from an object to its nearest neighbor. If  X  is a nearest neighbor of  X  , but  X  is not a nearest neighbor of  X  , then X+Y={x 1 , x 2 , ..., x n , y 1 , y 2 , ..., y m }, we have where, '*, *, * x xy ij denote the nearest neighbors of respectively. where, '*, '*, *, * x yx y ij denote the nearest neighbors of Similarly, for the object set in Definition 2: X  X  The edge between x 0 and y 0 is not labeled in any direction. This is because (1) x 0 and y 0 are nearest neighbors to each other; (2) x a nearest neighbor of y 0 but y 0 is not that of x nearest neighbor of x 0 but x 0 is not that of y 0 . One of our databases is a r eal world one downloaded from www.ics.uci.edu/~ml earn/MLSummary.html, named Zoo. We output top 10% of our bridging rules as the most interesting information to users. The other da tabase is an investigation of local people of a certain area surveyed by the local police office. We hope to find interesting bri dging rules in both databases. The Zoo database includes 101 reco rds consisting of 7 clusters that are mammal, Aves, crawler, fish, amphibian, insect and others. Every record represents an animal with 18 attributes to tell whether an animal has or not, such as hair, feathers, predator, backbone and so on. For the sake of identifying bridging rules, we delete two of these attributes: name and category. The results generated by our two metrics are listed below. Table 2. Results generated by joint-entropy-based strategy 
Thresholds Bridging rules m inisimi = 0.6 m inentro = 6 m inisimi = 0.675 m inentro = 6.25 m inisimi = 0.625 m inentro = 6.25 
Thresholds Bridging rules k =20 m inisimi=0 m ininfo=0 k =20 m inisimi=0.5 m ininfo=-7 k =20 m inisimi=0.65 m ininfo=-2 that the importance of bridging rules is changed with different clusters, the more bridging rules. Second, we can find that the bridging rules in Table 2 are completely different from that in Table 3, due to the fact that our clusters of mammal and Aves, such as penguin  X  platypus, leopard  X  rhea and ostrich  X  wallaby. However, in Table 3, the number of the involved clusters has increased. For example, the antecedent and action of the bridging rule  X  X ogfish  X  dolphin X   X  X ewt  X  pitviper X  belong to the clusters of amphibian and crawler, these of  X  X ousefly  X  worm X  belong to the clusters of insect and rest; and so on. of mammal and Aves. Commonly, we assume that the closeness of the mammal cluster and the Aves cluster is much higher than that of the mammal and crawler clusters, or that of the insect and Aves clusters. Therefore, from the two groups of bridging rules, the joint-entropy-based strategy is good at distinguishing clusters from each other, but the mutual-information-based strategy is not so good as that. For the bridging rules in Table 2, although they may relatively have both a large similarity and a joint entropy, there are no clear and joint entropy. On the contrary, for the bridging rules in Table information amount, although not a large joint entropy. One local police office invited us to help them analyze some information for a disappearance case. In this experiment, we extracted materials of 86 reside nts from a large database. As noted in Footnote 2, we are menti oning relevant data items in this experiment in a careful way to avoid violating data privacy many and complicated to analysis, we just keep 22 of them which include some basic informati on of individuals and some knowledge about life insurance. They are job, physical feature, received education, hometown, address, family background, criminal record, current situation and so on. According to the job worker, IT clerk, unemployed person, bank clerk, lawyer, teacher, from the database using our joint-entropy-based strategy and mutual-information-based strategy. In Table 4, the numbers stand fo r the resident IDs. And some We now focus on several rules that have been confirmed that they contributed towards finding out the truth of this disappearance. 1. 17  X  21 We mentioned this bridging rule in Section 1. We divided the dataset into 7 clusters according to the job attribute. Then we found out this rule and forwarded it to the police. Following up on disappearance case was a terrible murder case for insurance. This rule vividly shows that bri dging rules should have wide applications in case investigati on and insurance fraud detection. In addition, we also found two othe r bridging rules that have been useful to the insurance company for a sales promotion plan and the results were satisfactory. 2. 44  X  66 why such two persons were in a bridging rule is just because there education, economic situation, fa mily background, and income. In addition, these families are very close to each other. So we suggested that the insurance company carry out the same sales promotion plan when they decided to run a sales promotion policy salesman to this area who, with a plan suitable for these two men, finally persuaded them to buy the same kind of insurance. 3. 30  X  84 30 and 84 are an IT clerk and an insurance company clerk respectively. As they are neighbors and come from the same hometown, the insurance company decided to send 84 to persuade succeeded. So we can see that bridging rules can be used not only in insurance company design differe nt plans towards different persons. useful in many applications, for example, case analysis and insurance fraud detection. More specifically, we first designed two algorithms for mining bridging rules between clusters, and interestingness of bridging rule s. We have experimentally evaluated our algorithms and demons trated that our approach is identify bridging rules between clusters in a database. Our future work will include (1) efficient pruning techniques, (2) algorithm scalability, and (3) the influence of distance between clusters of antecedents and actions, the more the bridging rules are unexpected. But we still need experiments and theoretical analysis to confirm this possibility. (06S3011S01) . [1] J. Han and M. Kamber, Data Mining: Concepts and [2] H. Liu, H. Lu, L. Feng and F. Hussain (1999). Efficient [3] B. Padmanabhan and A. Tu zhilin (1998). A Belief-Driven [4] Xindong Wu, Chengqi Zhang and Shichao Zhang (2002). [5] V. Barnett and T. Lewis (1994). Outliers in Statistical Data . [6] M. Edwin and T. Raymond (1998). Algorithms for Mining [7] A. Arning, R. Agrawal and P. Raghavan (1996). A Linear [8] T. Johnson, I.Kwok and R. T. Ng. (1998). Fast Computation [9] Markus M. Breunig, Hans-Pet er Kriegel, Raymond T. Ng, [14] S. Brin, R. Motwani and C. Silverstein (1997). Beyond [15] S. Bay and M. Pazzani (2001). Detecting group differences: [16] S. Bay, M. Pazzani (2000). Discovering and Describing 
