
The increasing quantities of available medical resources have motivated the development of effective search tools and medical decision support systems. Medical image search tools help physicians in searching medical image datasets for diagnosing a disease or monitoring the stage of a di-sease given previous patient X  X  image screenings. Image re-trieval models are classified into three categories : content-based (visual), textual and combined models. In most of previous work, a unique image retrieval model is applied for any user formulated query independently of what retrie-val model best suits the information need behind the query. The main challenge in medical image retrieval is to cope the semantic gap between user information needs and re-trieval models. In this paper, we propose a novel approach for finding correlations between medical query features and retrieval models based on association rule mining. We define new medical-dependent query features such as image moda-lity and presence of specific medical image terminology and make use of existing generic query features such as query specificity, ambiguity and cohesiveness. The proposed query features are then exploited into association rule mining for discovering rules which correlate query features to visual, textual or combined image retrieval models. Based on the discovered rules, we propose to use an associative classifier that finds the best suitable rule with a maximum feature coverage for a new query. Experiments are performed on Image CLEF queries from 2008 to 2012 where we evaluate the impact of our proposed query features on the classifica-tion performance. Results show that combining our proposed specific and generic query features is effective for classifying queries. A comparative study between our classifier, CBA, Na  X   X ve Bayes, Bayes Net and decision trees showed that our best coverage associative classifier outperforms existing clas-sifiers where it achieves an improvement of 30%.

H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  clustering, Retrieval models
Association rules, Query features, Image retrieval models, medical images
Due to the huge quantities of available medical resources, it becomes hard for domain experts such as physicians to search for information in large medical datasets. Medical images play an important role in assisting health care pro-viders to access patients for diagnosis and treatment. The amount of digital images is increasing incredibly thanks to the medical imaging techniques such as X-Ray, magnetic resonance imaging, and ultrasound. Thus, the need for sys-tems that can provide efficient retrieval of images of parti-cular interest is becoming very high. According to Medical image CLEF 1 [16][22], queries are divided into three sets. For a specific type of queries, it was assumed that using tex-tual retrieval model provides the best retrieval performance (e.g.  X  X eptic ulcers or part of it X  ). For another type of que-ries, using content based retrieval model gives the best re-sults (e.g.  X  X oppler ultrasound (coloured) X ). Finally, for the rest of queries, combining textual and visual retrieval mo-dels performs best (e.g  X  x-ray one or more fractures X ). The main challenging task in this context is to predict the best suitable retrieval model for a given user query and to cope the semantic gap between user information needs and retrie-val models.
 Most of previous work apply the same retrieval model for any query, thus by ignoring the query characteristics. Bashir study [5] shows that there is a strong correlation between query features and bias retrieval function. Several query features have influence on improving or decreasing retrieval function results. In our work, we believe that the presence of medical terminology in the query which refers to the image modality (e.g. MRI, PET) , keywords related with the image color (e.g. black and white, coloured), dimensionality key-words (e.g. macro, gross) are potential features for predic-ting the best retrieval model for a given query. For example, images related with monitoring a brain tumour or endoscopy needs most likely visual retrieval model. Images related with a broad information need (e.g. fungus) could be associated 1. http ://www.imageclef.org/2012/medical with different body parts which needs a high level seman-tic retrieval model. Moreover, we believe that generic query features such as query specificity, ambiguity and cohesive-ness are also useful in determining the best retrieval model for a given query. For example, the query length reflects the semantics of the query where a long query emphasizes more on the semantics rather than the visual features. Our study is the first attempt for using association rule mining to correlate query features with the best suitable retrieval model. Our contributions presents the following new unique aspects : (1) we define novel medical dependent query fea-tures such as image modality and presence of medical image terminology ; (2) we combine the proposed specific query features and generic query features (e.g. query length and query ambiguity) into association rule mining ; (3) we pro-pose a best coverage-based associative classifier that asso-ciates queries to visual, textual or combined image retrieval model. The rest of the paper is structured as follows : Section 2 summarizes related work. Section 3 describes how to ex-tract specific and the generic query features given the query keywords. Section 4 details our contribution for generating association rules and classifying queries. Section 5 describes our experiments and results. Finally, Section 6 concludes the paper with some future work.
In this section, we present existing query features used for improving Information Retrieval (IR) and related work on using association rule mining.
Recently, analysing query features has received high at-tention in the IR domain [3, 6, 11, 14, 31, 34, 36]. Several features are proposed and classified according to characteris-tics of the user information needs and the expressed query. There are two approaches for grouping query features. The first one is based on specificity which depends on the granu-larity of information need behind the query, ambiguity which groups features that measure the ambiguity of query words and term relatedness which allows to measure dependencies between words.
 The second one is based on how the features are extracted, namely based on query terms, collection statistics or exter-nal resources (e.g. Wordnet [9]).
 Query features defined on the basis of query terms are defi-ned without taking into account any source other than the query itself. Among these features, we list the following :  X  AvQL (Average Query Length) [21] which is the average  X  QTN (Number of Query Terms) [6, 27] which represents The second category of query features is based on collec-tion statistics. They are defined based on the relationship between query terms and document collection. There are several measures to assess this relationship. We list the fol-lowing :  X  AvIDF (Average Inverse Document Frequency) [8, 5]  X  MaxIDF (Maximum Inverse Document Frequency) [29]  X  AvICTF (Average Frequency Inverse Term Collection)  X  SCS (Simplified Clarity Score) [12, 5] : this feature mea- X  SCQ (Collection Query Similarity)[5, 11, 37] gives the  X  AvSCQ (Averaged Collection Query Similarity) which  X  SumSCQ (Summed Similarity Query Collection) which  X  MaxSCQ (Maximum Collection Query Similarity) which  X  QS (Query Scope)[11] represents the percentage of do- X  PMI (Point wise Mutual Information)[11] computes the  X  AvPMI (Average Point wise Mutual Information) which  X  MaxPMI (Maximum Pointwise Mutual Information) which The last category of the query features is based on the use of external resources such as WordNet [9]. In the following, we detail some features :  X  AvPl (Average polysemy) [12] : This feature uses the  X  AvPath (Average Path Length) [28] which aims to mea- X  AvLesk (Average Lesk Relatedness) [4], as well as Av- X  AvVP (Average Vector Pair Relatedness) which is in-Despite the large number of existing query features, there is a lack of studies that define query features that fit the medical domain and also to link generic and specific do-main features with a retrieval model strategy. In order to fill this gap, we propose to combine medical-dependent query features and generic query features into association rule mi-ning.
In the biomedical field, association rule and class associa-tion rule mining presents promising techniques for finding hidden patterns in a medical dataset and for improving the information retrieval performance via query expansion [2, 17, 18, 32]. Association rule mining has been widely applied on a medical data for diagnosis or symptom prediction [25, 20], gene expression and cell type prediction [15] and for classification purposes. One of the classic association rule mining algorithms is the Apriori algorithm. It was first in-troduced in 1993 by Agrawal et al. [1]. Its objective is to discover all co-occurrence relationships, called associations, among data items under the form of implications if X then Y,denoted as X  X  Y, where X and Y are named the ante-cedent and the consequent of the rule respectively. Apriori attempts to find frequent itemsets that have mini-mum support where any subset of a frequent itemset must also be a frequent itemset. Given a transaction database and support threshold, standard association rule algorithm has two phases ; first phase finds all itemsets satisfying minimum support, it starts with generating frequent one-itemsets and proceeds to two-itemsets and so on, until there are no more frequent itemets. Second phase generates all rules with sup-port and confidence above specified threshold.
 One of the first algorithms to merge association rules and classification was the CBA model proposed in [19]. CBA mo-del implements the famous Apriori algorithm [1] that disco-vers frequent itemsets in a first phase then convert them into rules in a second phase. In order to improve the performance of association rule mining algorithms, extensions have been proposed to fit the characteristics of the medical domain. In [10], a method for automatic generation of suggestions of related queries submitted to search engines is proposed. The method extracts information from the log of past submitted queries to search engines using algorithms for mining as-sociation rules. In [25], association rules and decision trees are used for diagnosis prediction where search constraints are introduced to find only significant association rules and make search more efficient. The search constraints consist of pruning the search space for itemsets within a limited size and specifying the attribute values for the antecedent and the consequent of the rules. A distance-based association rule mining has been proposed in [15] for analysis of gene expression. The promoter region of a gene contains short se-quences called motifs to which gene regulatory proteins may bind. The association rules are enhanced with information about the distances among the motifs, or items, that are present in the rule. A statistical modelling technique, called Hierarchical Association Rule Model (HARM) has been pro-posed in [20]. The model predicts a patient X  X  possible future symptoms given the patient X  X  current and past history of re-ported symptoms. The core of this technique is a Bayesian hierarchical model for selecting predictive association rules. An adapted approach to classification based on association rule has been proposed in [7]. The approach is based on integrating the information gain measure in the generation of candidate itemsets and incorporating strategies for avoi-ding rule redundancy and conflicts. A classification based on greedy algorithm to generate rules is proposed in [35].The algorithm learns rules to distinguish positive examples from negative examples by using the information measure.
We propose to combine new medical dependent specific query features with generic query features for predicting the best suitable retrieval model associated with a query. Our main intuition relies on generating association rules that in-tegrate a set of query features which characterize the asso-ciated retrieval model.
 Figure 1 shows the query features extraction process used in our work.
 Figure 1: Extraction process of Query features
In the following, we present our proposed specific query features and existing generic query features that we use in our work.
Each query has specific features that are dependent of the searching context. As our work falls into the medical image retrieval field, we propose medical dependent query features which help predicting the retrieval model that best satisfies the user information need. We define specific query features based on leveraging characteristics of visual, textual and combined queries. They are defined as follows :  X  Image Modality : The first specific query feature that  X  Dimensionality : Using only modality features to de-2. http ://www.imageclef.org/2012/medical Figure 2: Modality classification according to Medi-cal Image CLEF[22]  X  V-spec : V-spec feature include a feature related with  X  T-spec : T-spec features include  X  X inding X  and  X  X atho- X  C-spec : Finally, for queries labelled  X  X  X , we propose a
In order to generate association rules, textual medical que-ries have to be presented as a combination of attribute/value. Every query should include at most one value for each at-tribute at a time. For example, each query can have only one modality among those of Radiology. The query is de-fined as an expression composed of a conjunction of attri-butes/values. Each query represents a new pattern of class label C i (V,C,T) and has the following form : ( A 1 = V 1 A n = V n j ). Where A i is the i th attribute and V i j is the j th value of the i th attribute. For example, the query  X  X oppler ultrasound (coloured) X  is labelled as visual query and has the following form according to the specific features : (Radiology=ultrasound )  X  ( V Spec = coloured )  X  ( Class = V )
This section presents generic query features that we use in our work. As mentioned in section 2.1, generic features are defined based on the document collection, the query key-words or semantic resources. In this study, we are interested in using features that depend only on query terms.
 Hauff [11] propose many features that are generic and domain-independent. However, we consider just a few features among others for many reasons. On one hand, there are features that are strongly correlated, therefore it is unnecessary to in-troduce simultaneously those which are correlated. On the other hand, in this work, we focus on the query features, independently of the collection characteristics. For that rea-son, the features that are collection-dependent are ignored. Furthermore, we look at queries before the retrieval of docu-ments. Consequently, we neglect features that treat the ran-king sensitivity. In the following, we present the set of generic query features based on specificity, ambiguity and term rela-tedness. We use measures such as the number of query terms (QTN), the average polysemy between the query terms using WordNet (AvPl) and the average path length between the query terms using WordNet (AvPath). We have chosen a single measure of each category of existing generic features in order to avoid information redundancy due to the corre-lation between query features. 1. QTN This factor is an indicator of query specificity. It 2. AvPl(Average polysemy) This feature is an indicator 3. AvPath(Averaged Path Length) This feature is an indi-The generic features belong to the category of numeric at-tributes, such that each feature had its own value indepen-dently of the others. Consequently, the feature will be asso-ciated with a huge number of values. We tackle this problem by partitioning feature values into intervals. Applying this in our study where queries are presented as combinations of feature/value, we formulate query features with a com-bination of intervals, where each interval represents a range of values for a specific attribute. For example, the query  X  X oppler ultrasound (coloured) X  will have the following form using generic features : ( QT N = 3)  X  ( AvP l  X  ]1; 1 , 5[)  X  ( Class = V ). Figure 3 sum-marizes our proposed specific and generic query features.
In this part, we briefly introduce the principle of associa-tion rules and its use in the classification process. In fact, association rules can be used to classify a new query. In the following, we present our proposed classification algorithm.
An association rule is an implication of the form X  X  Y where X and Y are disjoint itemsets.
 In the literature, many association rules algorithms have been proposed. Nevertheless, the well-known Apriori algo-rithm has been widely used to mine useful knowledge in large transaction databases. A priori includes pruning step to reflect the exponential growth of the number of candidates itemsets. The principle of pruning is based on the support measure. The support of an itemset is the percentage of transactions in the dataset that contain the itemset, whe-reas the confidence is the percentage of transactions in the dataset containing both Y given X. An itemset is kept in the pruning step if its support is greater or equal than a user-specified minimum support threshold. To apply association rule mining on our query set, queries must be represented in a suitable format. Each query is transformed into a com-bination of feature/value. The outline of our approach is described in Figure 1 as follows :  X  Step 1 : For each query, we assign a nominal value for  X  Step 2 : For each query, we assign a value for each gene- X  Step 3 : The set of specific and generic features/values  X  Step 4 : We use Apriori algorithm implemented in Weka Examples of generated rules are presented below : 1. R1 : if Radiology=x-ray and C Spec=fracture gen then 2. R2 : if QTN=3 and AvPl  X  ]0 . 5; 1 . 0[ then  X  Class=T 3. R3 : if Radiology=CT and QTN=3 and AvPl=2.0
We use the generated class associations rules for predicting the image retrieval model that best satisfies the user infor-mation need behind the query. We propose a best coverage-based associative classifier that finds the rule that best co-vers the given input query and use it to associate the query with class X  X  rule. Algorithm 1 presents the steps that we fol-lowed for the classification of unlabelled queries. For a given input query, all generated class association rules are browsed in order to find the rule that best covers the query. Coverage is defined by the number of common feature/value between the query and the rule divided by the number of query terms.
Coverage = # f eature/value between query and rule If several rules are obtained, or have the same percentage of coverage, the rule that has the highest confidence value is selected as rules are ranked in descending order of support and confidence. When there is no matching rule with the query, the default class will be assigned to the query. Algorithm 1 ARNa  X   X ve 1: Input : given query q 2: Set of rules R 3: M ax = 0 and ClassLabel = def aultClass 4: Output : ClassLabelof q 5: for each rule r  X  R do 6: if r satisfies the condition of q then 7: Insert r.class to ClassLabel 8: else if r satisfies a part of the features in q then 9: if r.coverage &gt; M ax then 10: M ax  X  r.coverage 11: ClassLabel = r.class 12: end if 13: end if 14: end for 15: return ClassLabel
We conduct experiments to evaluate the impact of com-bining generic and specific query features on predicting the best retrieval model associated with a query. We compare the performance of our best coverage-based associative clas-sifier to existing classifiers namely CBA, Na  X   X ve Bayes, J48 and Bayesian Network. We conduct experiments using Medical retrieval task of Image CLEF. More precisely, we use query sets of medical retrieval task from 2008 to 2012 [23] [24] [16] [22]. Queries in medical retrieval task have two formats : either image example or textual. In our work, we use only textual que-ries which are classified by human experts such as medical doctors, physicians and medical technicians into textual, vi-sual and combined. Indeed, a typical user does not have the expertise to specify the retrieval model that best fits the query. The annotation criterion was based on the estima-tion of the best retrieval model to use for each query. Table 1 presents the number of queries for each image CLEF da-taset. For the generic features AvPl and AvPath, we use Combined 11 9 10 14 44 Wordnet thesaurus. Obtained values for these features have real numeric values. Concerning specific features, it is pos-sible that a query does not have a value for a feature such as modality. In this case, we assign it the symbol  X ? X  which is interpreted as missing value. For the purpose of evalua-ting the impact of specific and generic query features on the classification performance, we divided the query set into two subsets : the first one is a training query set that serves for generating class association rules. The second one is a testing query set that serves for evaluating the classification perfor-mance using the generated rules. The training set is compo-sed of 2008 Image CLEF queries totalling 80 queries. The testing set is composed of image CLEF queries from 2009 to 2012 totalling 93 queries. We compare our associative clas-sifier to existing classifiers namely CBA, Na  X   X ve Bayes, J48 and Bayesian Network. We use Weka toolkit [33] for eva-luating the classification performance of existing classifiers used in our study. For the CBA classifier, we conduct a set of experiments to tune the minimum support and minimum confidence values, and we set the Minimum Support equals to 5% and Minimum Confidence equals to 70%. We evaluate the query classification performance using the accuracy rate. Accuracy is calculated by dividing the number of correctly classified queries over the total of number of queries. It is calculated as follows :
In these experiments, we evaluate separately the impact of using generic query features, specific query features or combined query features on the classification accuracy. Also, we conduct a comparative study in order to compare our associative classifier with existing classifiers, namely, CBA, Na  X   X ve Bayes, J48 and Bayesian Network. Table 2 presents the classification accuracy for each image CLEF query set using only generic features. Each row pre-sents the results of using all features except one. We can notice that using all generic features provides the best accu-racy. The combination of generic features in 2009 query set has as classification rate equals to 44%. However this value decreases to 20% by excluding QTN feature. NBQ feature has a significant positive impact on the query classification. Concerning AvPath feature, we notice that the classifica-tion accuracy did not change after excluding AvPath from the feature set which means that this feature has no impact on the query classification. Furthermore, comparing AvPath (40.9 %), QTN (22.72%) and AvPl (22.72 %) for 2012 da-taset, we notice that AvPath feature has the lowest signi-ficance. As a conclusion ignoring a generic feature decrease the classification rate while the use of all generic features is required.
 Table 3 presents the classification accuracy for each image CLEF query set using only specific query features. Each row presents the results of using all specific features except one. The results of this experiment vary widely between features, and from one query set to another. For 2009 query set, clas-sification accuracy varies between 20% when Radiology fea-ture is excluded (All-Radiology) and 72% when Microscopy feature is excluded (All-Microscopy). The combination of all features has as classification rate equals to 72%. This means that Radiology features are important features for achieving a high classification rate. Microscopy and Printed signals and Wave features have no impact on the classification ac-curacy compared to the use of all query features.
 We can assume that  X  X adiology X  feature is the most signi-ficant specific feature over all query sets. This could be ex-plained by the fact that this feature is discriminative in de-termining visual queries.
In this experiment, we evaluate the impact of combining specific and generic features on the classification performance. Results are presented in Table 4. According to the results, combining specific and generic features improves significantly the classification accuracy. This proves that specific and ge-neric features are correlated with each other and help in better predicting the associated image retrieval model for the query. We notice that Radiology is the most significant specific feature when combined with generic features. There All-Radiology 20 25 33.33 22.72 All-Dimensions 40 43.75 40 54.54 All-Microscopy 72% 50% 50 69 All-Printed signals, waves 72 50 50 69 All-V Spec 44 50 43.33 50 All-T Spec 65.38 43.75 43.33 54.54 All-C Spec 61,58 47.5 46.66 40.9
All features 72 50 50 69 are only two specific feature sets namely, Microscopy and printed signals, Wave that do not have an impact on the classification accuracy even when combined with generic fea-tures. The rest of specific and generic features have positive impact on the classification accuracy where when excluded the classification accuracy decreases. We can clearly see that specific features have higher positive impact on the classifi-cation accuracy compared to the generic features where the decrease in classification accuracy when excluding generic features is larger than what it is when excluding specific features.

The overall classification performance averaged over the testing query sets and using either specific, generic or com-bined features are presented in Figure 4. Based on Figure 4, Figure 4: Overall classification accuracy using speci-fic, generic or combined features we draw the following conclusions : 1. We first notice that specific features (60.25%) give bet-2. We also notice that combining specific and generic
MedicalCLEF dataset (%) 3. The low accuracy obtained using only generic features
In this experiment, we compare the classification accuracy obtained by our best coverage associative classifier to well known classifiers, namely CBA, Na  X   X ve Bayes, J48 and Baye-sian Network. We use combined features for all classifiers and we generate class association rules based on the combi-ned features which are used by our classifier and CBA. Table 5 presents the accuracy rate for the different classifiers. Table 5: A comparison between different classifiers
CBA 44 44 30 63.63 45.40 na  X   X ve bayes 84 25 46.66 45.45 50.27
J48 (decision trees)
Bayesian net-work Our approach 72 62.50 67 78 69.87
According to the results, our associative classifier gives the best classification accuracy (69,87%) compared to all other classifiers. Our interpretations in regards to the classifiers performance is presented below :  X  Bayes Net and decisions trees take into account fea- X  Na  X   X ve Bayes has performed better than the other clas- X  The CBA classifier has performed equally as the Bayes In order to show how well did our classifier perform for each class of queries, we calculate the classification accuracy achieved by our classifier for textual, visual and combined queries. Figure 5 compares the performance of our classifier to the Na  X   X ve Bayes classifier for each query class : textual, visual and combined. We notice that our classifier outper-forms Na  X   X ve Bayes on Combined and Textual queries while Na  X   X ve Bayes recognizes visual queries better than our clas-sifier. This could be due to the presence of common features between visual and combined queries which could not be highly captured by our class association rules. In addition, it is well known that Na  X   X ve Bayes considers features indepen-dently of each other, while, our approach allows discovering dependency relationship between features. Since a depen-dency relationship exists between the proposed features, our approach performs much better than Na  X   X ve Bayes. Figure 5: Comparison between our classifier and Na  X   X ve Bayes according to Textual (T), Visual (V) and Combined (C) classes
In this section, we present an analysis on the most signidi-cant correlations between features and image retrieval mo-dels. Figure 6 presents the percentage of each feature type in the set of rules generated for textual, visual and combi-ned queries. For each class (Visual, Textual or Combined), we consider the rules that have the class label as consequent and calculate the frequency of occurrence of each feature in the antecedent of the rules. According to Figure 6, we can clearly see that generic features (number of query terms, ave-rage path and average polysemy) and T-spec are the only features present in the set of rules that have the textual class in their consequent. This validates our assumption that ge-neric features allow capturing the semantic characteristics of a query and help in associating the query with textual image retrieval model. Visual and combined classes of que-ries present generic query features in their rules in equal importance. However, specific features allow discriminating between those two classes. Even though V-spec and Visible light photography features appear in both class rules, which is obvious since combined queries contain both textual and visual features, those two features are more dominant in the visual class rules rather than in the combined class rules. Radiology features are also common between combined and visual classes, however, it is more frequent in the combi-ned class rules. C-spec and dimension features appear only in the combined class rules which makes those two features discriminative in determining the combined queries. We can conclude that our proposed specific query features are mea-ningful and useful for predict the image retrieval model that best satisfies the user information need behind the query.
In this paper we propose new medical dependent specific query features to select an image retrieval model that best satisfies the user information need behind the query. Specific features are used in addition to generic ones for generating class association rules. The proposed specific features allows capturing visual and textual characteristics behind the query keywords. Generic features reflects how much does the query require semantics. Specific and generic features are combi-ned into class association rule mining which captures corre-lations between query features themselves and correlations Figure 6: Percentage of features in the set of rules generated for textual, visual and combined queries between the query features and the associated image retrie-val models. The generated class association rules are then used in an associative classifier that is based on the best coverage measure for selecting the rule that matches with a given query. Experiments are carried out using Medical Image CLEF queries from 2008 to 2012.
 Results show that combining generic and specific query fea-tures provides the best query classification performance. A comparative study has been conducted and showed that our classifier yield a considerable improvement in terms of classi-fication accuracy rate compared to existing classifiers, such as Na  X   X ve Bayes, decision trees, CBA and Bayes Net. Our experimental findings in regards to our contributions reveal that specific features are essential for capturing the nature of the medical information behind the query. Moreover, spe-cific and generic features are correlated to each other and also correlated to the image retrieval model that best suits the user query.
 In future work, we plan to use UMLS medical termino-logy instead of WordNet for calculating generic feature va-lues, namely term relatedness and polysemy. Query key-words could be mapped to medical concepts and seman-tic similarity and relatedness measures will be application on the concept definitions issued from UMLS. This would allow capturing semantics between medical entities rather than using a general terminology. In addition, we plan to define more specific query features that could cover the cha-racteristics of any user-formulated query in the context of image retrieval. Furthermore, we plan to exploit medical-dependent specific features defined for both documents and queries into a learning to rank technique for boosting image retrieval performance. This work was funded by ReDCAD Laboratory in Tunisia. It is also supported in part by the research grant from Na-tural Sciences and Engineering Research Council (NSERC) of Canada. We thank four anonymous reviewers for their thorough review comments on this paper.
