 Lasso regression is a widely used technique in data mining for model selection and feature extraction. In many applica-tions, it remains challenging to apply the regression model to large-scale problems that have massive data samples with high-dimensional features. One popular and promising strat-egy is to solve the Lasso problem in parallel. Parallel solvers run multiple cores in parallel on a shared memory system to speedup the computation, while the practical usage is lim-ited by the huge dimension in the feature space. Screening is a promising method to solve the problem of high dimen-sionality by discarding the inactive features and removing them from optimization. However, when integrating screen-ing methods with parallel solvers, most of solvers cannot guarantee the convergence on the reduced feature matrix. In this paper, we propose a novel parallel framework by parallelizing screening methods and integrating it with our proposed parallel solver. We propose two parallel screen-ing algorithms: Parallel Strong Rule (PSR) and Parallel Dual Polytope Projection (PDPP). For the parallel solver, we proposed an Asynchronous Grouped Coordinate Descent method (AGCD) to optimize the regression problem in par-allel on the reduced feature matrix. AGCD is based on a grouped selection strategy to select the coordinate that has the maximum descent for the objective function in a group of candidates. Empirical studies on the real-world datasets demonstrate that the proposed parallel framework has a su-perior performance compared to the state-of-the-art parallel solvers.
  X  Information systems  X  Data mining; Lasso regression, parallel computing, screening rules, coor-dinate descent, aynchronized coordinate descent
Sparse models with ` 1 -regularization are widely used to find the linear model of best fit. Many research efforts have been devoted to develop efficient solvers for the ` regularized sparse models, such as the Lasso problem [18]. Recent technological innovations lead to huge data collec-tions that keep growing rapidly. As a result, in many ap-plications, running Lasso on huge-scale data sets usually exceeds the computing capacity of a single machine run-ning single-threaded approaches. Parallelizing the learning process for the regression problem has recently drawn a lot of interest. Most of the proposed algorithms are based on Stochastic Coordinate Descent (SCD) [17] to accelerate the whole learning process. Many existing approaches, like Shot-gun [6], Parallel Block Coordinate Descent (PBCD) [13] and Thread-Greedy [16, 15], employ multiple-threaded comput-ing by utilizing multiple cores on a shared memory system. However, the curse-of-dimensionality is still a great challenge for large-scale problems. High-dimensional data in feature space means more time spent in the optimization and data synchronization in the multithreading environment.
To address this issue, screening is one of highly efficient approaches to solve the high-dimensional problem. Screen-ing pre-identifies inactive features that have zero compo-nents in the solution and remove them from the optimiza-tion. As a result, we can solve the regression problem on the reduced feature matrix, leading to substantial savings in terms of computation and memory usage. The idea of screening has achieved great success in a large class of ` regularized problems [3, 19, 24, 25, 22, 21, 23], such as Lasso regression, Logistic regression, elastic net, multi-task feature learning (MTFL) and more general convex problems.

Parallel screening is a promising strategy to solve the high-dimensional problem in big data optimization. However, the idea of using screening in a multithreading environment has not been investigated, since it is challenging to integrate screening rules with parallel solvers. Most of the published parallel solvers are based on parallelizing SCD to speedup the optimization process. The updating strategy of SCD is to randomly select one coordinate to update in each itera-tion. Parallelizing SCD allows multi-processors to update the coordinates concurrently without synchronization. Al-though it might result in the divergence of objective func-tion, parallel solvers can achieve dramatic speedup when op-timizing the regression problem in a very high-dimensional feature space. It is shown in [6] that the dimension of fea-ture space for parallel solvers should be no less than P 2  X  there are P threads, where  X  denotes the spectral radius of A T A , and A is the feature matrix. When we integrate screening methods with the state-of-the-art parallel solvers such as Shotgun, PBCD and Asynchronous Stochastic Co-ordinate Descent (ASYSCD) [11], it can result in the diver-gence of the objective function since the feature matrix is shrunk to a matrix with a small feature space after applying screening rules on it. Although we can reduce the number of threads to guarantee the convergence, it has a negative effect on the scalability of the parallel method. Since pre-vious parallel solvers cannot satisfy the constraint between the number of threads and feature space, it is essential to develop a parallel solver to optimize the problem in the re-duced feature data matrix.
 In this paper, we propose a parallel framework to solve the Lasso regression problem on large-scale datasets with huge dimensional feature space. We parallelize screening rules by partitioning the sample and feature space to accelerate the screening process. We propose two parallel safe screen-ing rules: Parallel Strong Rule (PSR) and Parallel Dual Polytope Projection (PDPP). To optimize the regression problem in parallel on the reduced feature matrix, we pro-pose an Asynchronous Grouped Coordinate Descent method (AGCD) to solve the problem of small feature space in the optimization after employing screening rules. In AGCD, we introduce competition strategy to select the candidate coor-dinates that minimize the objective function with the max-imum descent of function value. If the selected coordinate wins the competition in a group of candidates, that coordi-nate will be updated at this iteration, otherwise the update terminates. The main idea of AGCD is to reduce the fre-quency to update coordinates and select the most important candidates to update, allowing the solver to converge in a small feature space. It is different with the random selection strategy in most of the parallel solvers.

The main contributions of this study are summarized as follows:
The rest of this paper is organized as follows. Section 2 reviews the related work. Section 3 presents our proposed parallel framework. Section 4 analyzes the convergence of the proposed methods. Experimental results on the real-world biomedical datasets are reported in Section 5. We conclude the paper in Section 6.
Existing screening methods can be divided into two cate-gories: Safe Screening Rules and Heuristic Screening Rules . Safe screening rules guarantee that the predicted inactive features have zero coefficients in the solution. In other words, discarding the inactive features in safe screening rules does not sacrifice the accuracy of optimization since the corre-sponding positions in the solution vector are zero in the ground truth. SAFE [3] is a safe screening method that estimates the dual optimal solution of Lasso. Strong rules [19] are another efficient screening methods based on heuris-tic screening rules. In most of the cases, strong rules discard more features than SAFE, leading to a substantial speedup. However, strong rules cannot guarantee that discarded fea-tures have zero components in the solution. To avoid the incorrectly discarded cases, [19] proposed a method to check the KKT conditions, ensuring the correctness of screening results. To optimize the problem along a sequence of param-eter values, Enhanced Dual Polytope Projection (EDPP) [24] is an efficient and effective safe screening method and achieves significant speedup for the Lasso problem.
After we get the reduced feature matrix from screening rules, we can apply different solvers to optimize it, such as Stochastic Gradient Descent (SGD) [26], FISTA [1], ADMM [2] and SCD [17, 12, 14]. When we consider solvers in a mul-tithread environment, a lot of parallel solvers were proposed based on the SCD. Shotgun [6] is a parallel coordinate de-scent method which allows multiple processors to update the coordinates concurrently. PBCD [13] described a method for the convex composite optimization problem. In this method, all the processors update randomly selected coordinates or blocks synchronously at each iteration. The method in [9, 16, 15] are based on the greedy coordinate descent method. Recently, asynchronous parallel methods are proposed to ac-celerate the updating process. ASYSCD [11] proved the linear convergence of asynchronous SCD solver under the essential strong convexity condition. PASSCoDe [4] is an asynchronous Stochastic Dual Coordinate Descent(SDCD) method for solving the dual problem. Parallel SDCA [20] is an asynchronous parallel solver based on the Stochastic Dual Coordinate Ascent (SDCA) method. Both PassCoDe and Parallel SDCA focus on the ` 2 -regularized models.
In this section, we present the proposed parallel frame-work based on a shared memory model with multiple pro-cessors. Our parallel framework is composed of two main procedures: 1. Identify the inactive features by the parallel screening rules and remove inactive features from optimization. 2. Solve the Lasso regression on the reduced feature ma-trix in parallel.

In step one, we parallelize screening rules to identify and discard inactive features, significantly accelerating the whole learning process. We propose two parallel screening rules: PSR and PDPP.
 In step two, we propose an asynchronous parallel solver AGCD to solve the Lasso regression on the reduced data matrix in parallel.
In this paper, we consider the following ` 1 -regularized minimization problem: where A is the design matrix and A  X  R M  X  N , y  X  R M is the response vector and x is the sparse model we need to learn.  X  is the regularization parameter and  X  &gt; 0.
SAFE [3] is an efficient safe screening method. SAFE discards the i th entry of x when the following rule holds: where  X  max = max i | A T i y | , A i denotes the i th column of A .
Strong rules [19] are another efficient screening methods based on heuristic screening method. In strong rules, the i th feature will be discarded when satisfies the following equa-tion: The calculation of  X  max follows the same way in SAFE.
For large-scale problems, it is necessary to parallelize the learning process. To speedup the learning process, we paral-lelize screening rules in a multithreading environment. Sup-pose there are P processors, we partition the feature space into P parts. The j th processor holds a subset S j of feature space where S j  X  S and S = { 1 , 2 ,......,N } . To average the performance of parallel solvers, each thread holds N/P coor-dinates and the partition is non-overlapped. We summarize the Parallel SAFE rule (PSAFE) in algorithm 1.
 At the beginning, every processor generates the index set S j and S j  X  R N/P . Let us define some notations here. E is a vector and E  X  R N/P . [ W ] S of  X  th element in W where  X   X  S j if W is a vector. When W represents a matrix, [ W ] S column of W and  X   X  S j . Since  X  max = max i | A T i first need to compute E = A T b firstly. To achieve this on P processors, we partition the computation into P parts. Ev-ery processor performs [ E ] S complexity is reduced from O(MN) to O(MN/P) since no synchronization is needed between processors. E is stored as a global variable and can be accessed by all the proces-sors after updated. Then we get  X  max by k E k  X  . From the 6th line to the 11th line in algorithm 1, every processor per-forms screening rules on its own index set S j to select the active features. Since A and b are global variables, all the processors are able to calculate  X  and  X  in parallel without synchronization. In the end, we get the selected index set I and reduced feature matrix e A . Suppose I has e N elements of true values, the dimension of e A is R M  X  e N . The original optimization problem (1) can be reformulated as: Algorithm 1 Parallel SAFE rule (PSAFE) Input: Output: 1: Initialize: I = 0  X  R N . 2: In parallel on P processors. 3: Generate the index set S j for the j th processor. 4: Compute the  X  max : [ E ] S 5: Get the norm of response y :  X  = k y k 2 . 6: for each element i in the set of S j do 7: Get the norm of the i th column of A :  X  = k A i k 2 . 8: if | A T i y | X   X   X   X   X   X   X   X  max  X   X   X  9: I i = true , select i th column of A into e A . 10: end if 11: end for
After we obtain the solution vector e x  X  for problem (4), we can recover x  X  by I and e x  X  .

The implementation of PSR in parallel follows the same way of PSAFE. The only difference between PSR and PSAFE is that the computation of k A i k 2 and k y k 2 in equation (2) is not needed in PSR. We employ the same partition strategy and parallel technique to parallelize the strong rules in (3). We skip the details of implementation for brevity.
In many machine learning applications, the optimal value of the regularization parameter  X  is unknown. To tune the value of  X  , commonly used methods such as cross valida-tion needs to solve the Lasso problem along a sequence of parameter values  X  0 &gt;  X  1 &gt; ... &gt;  X   X  , which can be very time-consuming. A sequential version of strong rules was proposed in [19] by utilizing the information of optimal so-lutions in the previous parameter. Suppose we have already obtained the solution vector x (  X  k  X  1 )  X  at  X  k  X  1 where the in-teger k  X  [1 , X  ], the sequential strong rule rejects the i th feature at  X  k when the following rule holds: Although the sequential strong rule is able to predict a large proportion of inactive features, it might mistakenly discard active features that have nonzero components in the solu-tion. We need to check the KKT conditions to guarantee the correctness of the predicted results.

EDPP [24] is a highly efficient safe screening method that estimates the dual problem and geometric properties of Lasso regression, achieving significant speedups for real-world ap-plications. The implementation details of EDPP is available on the GitHub 1 . We omit the introduction of EPDD for brevity. Based on the partition strategy and parallel tech-nology employed on PSAFE and PSR, we propose a parallel safe screening rules, known as the Parallel Dual Polytope Projection (PDPP), to quickly identify and discard inactive features parallelly in a sequence of parameters.

To parallelize the screening rules, we need to partition both the feature space and sample space. In Section 2.1, this is done in the feature space, and we follow a similar http://dpc-screening.github.io/lasso.html way to partition it in the sample space. Before introducing the details about the proposed algorithm, we first introduce notations in the paper. As we discussed in Section 2.1, we use [ W ] S index set S j if W denotes a vector. When W is a matrix, we use the [ W ] S W in the index set S j . We use the same notations in PDPP. Suppose there are P processors, we partition the sample space into P parts. The j th processor holds an index set T j of sample space, where T j  X  T and T = { 1 , 2 ,......,M } . Every subset T j has M/P elements and there is no overlap among them. When W denotes a vector, { W } T the collection of every  X  th elements from W in the index set T where  X   X  T j . When W is a data matrix, { W } T the collection of every  X  th rows in W where  X   X  T j . To take { A } T set T j to construct it. So the dimension of { A } T We summarize the PDPP method in algorithm 2.
 Algorithm 2 Parallel Dual Polytope Projection (PDPP) 1: In parallel on P processors 2: Generate the S j and T j for the j th processor. 3: Compute the  X  max : [ E ] S 4:  X  = argmax i | E | , v = A  X  , v is the  X  th column of A . 5: Let  X  0  X  (0 , X  max ] and  X   X  (0 , X  0 ]. 6: if  X  =  X  max then 7: {  X  (  X  ) } T 8: else 9: {  X  (  X  ) } T 10: end if 11: if  X  0 =  X  max then 12: { v 1 (  X  0 ) } T 13: else 14: { v 1 (  X  0 ) } T 15: end if 16: { v 2 (  X , X  0 ) } T 18: { v  X  2 (  X , X  0 ) } T 19: Given  X  max =  X  0 &gt; ... &gt;  X   X  , for k  X  [1 , X  ], we make a 20: [ w ] S 21: for every element i in the set of S j do 22: if w i &lt; 1  X  1 2 k v  X  2 (  X  k , X  k  X  1 ) k 2 k A i 23: Discard the i th column from A . 24: end if 25: end for
In PDPP, all the P processors perform the computation in parallel. Firstly, the j th processor generates the corre-sponding index set S j and T j by the method we discussed previously. Then we follow the same way in PSAFE and PSR to calculate the  X  max in parallel. The dimensions of  X  (  X  ), v 1 (  X  0 ), v 2 (  X , X  0 ), v  X  2 (  X , X  0 ) are R ploy partition strategy in sample space on these variables: {  X  (  X  ) } T a result, the computation of these variables is performed in parallel. From line 19 to line 25 in algorithm 2, we employ PDPP on a sequence of parameter values:  X  max =  X  0 ... &gt;  X   X  . When performing the screening rule on  X  k  X  [1 , X  ], we need to compute w firstly, where w  X  We perform the computation of w based on the partition strategy in the feature space: Finally, for each element i in the index set S j , we will identify the i th entry of x (  X  k )  X  to be zero if the following rule holds: The calculation of k v  X  2 (  X  k , X  k  X  1 ) k 2 and k A i ilar to the calculation of k y k 2 and k A i k 2 in algorithm 1.
Overall, the time complexity of PDPP is O(MN/P). Re-gardless of the calculation and updating on the vector vari-ables, the calculation of these variables is dominant: w , {  X  (  X  ) } T these variables can be parallelized by the partition strategy in PDPP without synchronization among processors.
To address the challenge we discussed in section 2.2, we propose a novel parallel solver, called Asynchronous Grouped Coordinate Descent (AGCD), to solve the Lasso regression on the reduced feature matrix. Rather than randomly select-ing coordinates or blocks to update asynchronously among threads, AGCD adopts a grouped selection strategy; that is, chooses the candidate that minimizes the objective function with the most descent to update among a group of coordi-nates. The details of AGCD are given in algorithm 3.
In AGCD, there are two global variables d and R to store where d  X  R e N and R  X  R M . We initialize d to be zero and R to be  X  y . In each iteration, every processor randomly picks up a coordinate i from { 1 , 2 ,..., e N } to estimate and update. The calculation of the gradient for the i th coordinate, which is denotes as g ( e x ) i , can be written as: To make it more efficient, the calculation of (8) can be de-composed into the following steps:
Step1: Calculate the gradient: g ( e x ) i = e A T i R and get  X  Step2: Update R : R = R +  X  e x i e A T i .
 Since R is initialized as  X  y , R stores the information of e A i ( e Ax  X  y ) by following the above updating rules. To cal-culate  X  e x i , we apply soft thresholding function [17] to get the proximal gradient for e x i . The definition of soft thresh-olding operator  X  is given by :
In algorithm 3, L denotes the Lipschitz constant. For SCD [17, 12, 14], the Lipschitz constant is set to be k A i k updating the i th coordinate. Since SCD randomly picks only one coordinate to update, the problem has a closed-form so-lution in each iteration. When considering a multithreading environment, the way to calculate L is different. PBCD [13] employs Expectation Maximization (EM) to get an approx-imation model on L but it depends on the sparsity of the Algorithm 3 Asynchronous Grouped Coordinate Descent Input: Output: 1: Initialize: e x = d = 0  X  R e N and R =  X  b . 2: while not converged do 3: In parallel on P processors 4: Randomly pick i from the index set { 1 , 2 ,..., e N } . 5: Compute the i th gradient: g ( e x ) i = e A T i R . 7: d i =  X  ( | e x i | X  X  e x i +  X  e x i | )  X  g ( e x ) i 8: for t = ( i  X   X / 2) to ( i +  X / 2) do 9: if d i &lt; d t then 10: Return and perform the next iteration. 11: end if 12: end for 13: Update e x i : e x i = e x i +  X  e x i . 14: Update R : R = R +  X  e x i e A T i . 15: Update d i by the same way from 5th to 7th line. 16: end while feature matrix. In this paper, we employ the same method in [11] to get the Lipschitz constant from the Hassian matrix. For the Lasso problem, L can be calculated by:
The strategy of selecting potential coordinates in AGCD is to evaluate the descent of objective function for the selected candidate. If the selected coordinate i wins the competi-tion in a group of candidates, x i will be updated by  X  e Otherwise this selection fails and the update in this itera-tion is terminated. In a multithreading environment, all the processors perform this process in parallel.

Then we need to estimate the descent of objective func-tion for a specific coordinate. The descent of the objective function is stored and updated in d . For the i th coordinate, suppose that we have already obtained  X  e x i and g ( can be estimated by the following equation: where e i is a unit vector in the i th coordinate. When consid-ering the Lasso problem, d i can be rewritten as the following formula:  X  ( | e x i | X  X  e x i +  X  e x i | ) + 1 Finally, d i can be calculated by: d i =  X  ( | e x i | X  X  e x i +  X  e x i | )  X  Figure 1: Illustration of AGCD with two threads. The white blocks in each sample represent inac-tive features discarded by screening rules. Thread 1 chooses the 2 nd active feature to evaluate. Firstly, d 2 is updated and evaluated in a group of { d 1 ,d 2 ,d 3 } . d wins the competition and we follow the three steps to update x 4 , R and d 2 . Thread 2 selects the 5 th candidate. However, it fails in the competition and update is terminated for thread 2 in this iteration. previously. The value of k e A i k 2 2 is also obtained when calcu-lating the Lipschitz constant L in equation (11). Thus, the time complexity to update d i is O (1).

After d i is updated, there is a competition between the i th coordinate and a group of  X  candidates. If d i wins, will be updated. Otherwise the update of the i th coordinate in this iteration is terminated. Bradley et al.[6] showed that the number of updated coordinates is at most e N/ 2  X  in one iteration where  X  is the spectral radius of e A T e A . AGCD divides the feature space into e N/ X  groups, which means there are at most e N/ X  coordinates to be updated in each iteration. Therefore, we set the size of group  X  to be 2  X  in AGCD. If  X  is larger than e N ,  X  is set to be e N . The way we set the candidate group is to select  X  number of coordinates that are close to the i th coordinate. Specifically, the index in the group starts from i  X   X / 2 and ends at i +  X / 2. If i  X   X / 2  X  0, it starts from 1 to  X  . When i +  X / 2  X  e N , it is from i  X   X  to i . If the i th coordinate wins the competition, the update is performed by the following three steps:
Fig. 1 illustrates the process of group selection and asyn-chronous updating flowchart with two threads. Although d has already been updated at the beginning, AGCD still needs to perform Step 3 in the above updating rules because we intend to minimize the effects of un-updated winners X  d to the competition of other candidates. We still take the ex-ample in Figure 1 to illustrate this. After the 2nd coordinate wins the competition, AGCD performs Step 1 and Step 2 to update e x i and R . However, d i is not the current descent of object function since x i and R have changed. In the next iteration, if AGCD selects the 1st coordinate to evaluate, x might still not be updated since d 2 &gt; d 1 in the last iteration. Although d 1 is updated in the next iteration, x 1 still has a lower chance to be updated since x 2 is the winner last time and d 2 is the  X  X inning distance X . Because of asynchronous characteristic of AGCD, it is not guaranteed that all the d are updated to the newest one. AGCD makes all the win-ners X  d i updated to newest value to minimize the effects of winners to competitions of other candidates.
We apply atomic operations to avoid the synchronization among threads when updating x i , R and d i . Since x , R and d are global variables, it is necessary to add locks on these shared variables when multiple threads attempt to update them simultaneously. However, updating a single variable and locking all the variables is not an efficient strategy since all the other threads have to wait for one thread to finish its job. We employ atomic operations to write the global variables atomically without any locks. [11] and [4] have ob-served empirical convergence when applying  X  X tomic writes X  on updating the shared variables.

AGCD adopts a grouped selection strategy to update the solution vector by choosing the candidate that minimizes the objective function with the most descent. In the random se-lection strategy used in parallel SCD solvers, a number of processors update the solution vector asynchronously, which is more likely to result in the divergence of the optimization problem in a small feature space. In AGCD, the update of solution variables is not as frequent as in the random selection strategy. The selected coordinate has to beat a group of candidates to get the chance to update. In fact, the selected coordinates will not be updated in most of the iterations since it failed in the competition. However, this does not mean that the computation spent in a failed can-didate is a waste of time. Although x i is not updated, it updates the descent value d i for that coordinate. Suppose x is updated, it means that R is changed. As a result, all the elements in d should be updated by (14). Therefore, updating d concurrently is critical to guarantee the accurate result of competition in the grouped selection strategy.
In this section, we analyze the convergence of the proposed parallel framework. PSAFE and PDPP are safe screening rules and it is guaranteed that all the discarded features have zero coefficients in the solution. PSR is a heuristic screen-ing method but we can ensure the correctness of result by checking the KKT condition. AGCD can be safely applied on the reduce feature matrix e A to optimize the problem (4). Therefore, the proposed parallel framework will work if we prove the convergence of AGCD.

We follow the same way in [17] to rewrite the objec-tive function (1) into an equivalent problem with a twice-differentiable regularizer: where a j denotes the j th row of A and the feature space is duplicated as:  X  a j = [ a j ;  X  a j ] and  X  a j optimal solution  X  x  X  of equation (15) is obtained, we can recover the solution vector x  X  of (1) by x  X  i =  X  x We denote the objective function F ( x ) equal to (15) in the convergence analysis part.
 Definition 1. Let F ( x ) : R 2 N  X  R be a convex function. Assume that there exists  X  &gt; 0, for all x and  X  x updated in parallel, we have the following rule: We denote  X  = 1 for the square loss function and  X  = 1 4 for the logistic loss function. Let  X  d = [  X  d 1 ,  X  d 2 ,...... the potential candidates updated by (12).  X  x denotes the collective update of x in one iteration.  X  x i is equal to zero when  X  d i fails the competition where i  X  (1 , 2 N ).
When there is only one coordinate updated at the same time, we have  X  x = ( X  x i ) e i and e i is a unit vector in the i th coordinate. The process of optimization is the same as the sequential coordinate descent when one coordinate is up-dated at each iteration. It was shown in [17] that the sequen-tial coordinate descent converges by the following bound: where F ( x ( K ) ) is the output after K iterations. The conver-gence analysis of AGCD is the same as sequential coordinate descent if only one coordinate is updated in each iteration.
When there are more than one candidates winning the competition at the same time, we summarize the main anal-ysis in the following theorem:
Theorem 1. Let x  X  be the solution of F(x) and x ( K ) the output of AGCD after K iterations. Let P be the number of processors and  X  denotes the maximum number of candi-dates to be updated in one iteration. Suppose F ( x ) satisfies the assumption of Definition 1; let = ( X   X  1)(  X   X  1)  X  be the spectral radius of A T A . We have
Proof. We use a similar technique in [6] to prove this theorem. Let  X  denote the index set that collects the win-ners of competitions in one iteration and  X  = |  X  | . Based on the assumption of Definition 1, we have is bounded by  X  in terms of E i [ X ( x i ) 2 ] where i is chosen uniformly at random from { 1 ,..., 2 N } . The rest of proof followes the same way in Shotgun [6] X  X  convergence analysis to obtain the result of Theorem 1. We omit it for brevity. million ADNI dataset
In Shotgun, it was shown that the number of processors should satisfy P  X  P  X   X  N 2  X  and the experiment demon-strates that Shotgun diverges as P exceeds P  X  . As we dis- X  = 2  X  . The maximum number of updated coordinates in one iteration is  X  = N  X  which satisfy the above constraint. In the real cases, the number of updated candidates is much smaller than P since most of the updates happen in the cal-culation of d . In the grouped selection strategy of AGCD, each coordinate has a low probability to be updated among  X  candidates. As a result, P can be equal to or larger than 2  X  in the real application of AGCD. We demonstrate it in the experiment that AGCD encountered the cases that the number of processors is larger than the number of active features while AGCD still converged to the optimal value.
In this section, we conduct several experiments to evaluate the convergence and speedup of the proposed framework on the following four data sets: ADNI 2 , MNIST [7], rcv1 [8] and news20 [5]. The Alzheimer X  X  Disease NeuroimagingInitia-tive (ADNI) is a real biomedical dataset collected from neu-roimaging and genomic data from elderly individuals across North America, including 809 patients of Alzheimer X  X  dis-ease with 5,906,152 features, involving a 80 GB feature ma-trix with 42 billion nonzeros. For MNIST, rcv1 and news20, we use the training dataset obtained from LIBSVM data set repository 3 to construct the feature data matrices and response vectors. We compare our method with the state-of-the-art algorithms like PBCD [13] and ASYSCD [11]. All the experiments are carried out on an Intel (R) Xeon (R) 48-core machine with 2.50 GHZ processors and 256 GB of globally addressable memory. We employ OpenMP as the http://www.adni-info.org http://www.csie.ntu.edu.tw/  X  cjlin/libsvmtools/datasets/ parallel framework and all the methods are implemented in C++ for fair comparisons.
In this experiment, we examine the accuracy of solution vectors in the proposed method. We perform PDPP+AGCD along a sequence of 100 parameter values equally spaced on the linear scale of  X / X  max from 0.1 to 1. To make a compar-ison, we perform EDPP using SLEP [10] as the solver on the same sequence. In SLEP, we force the  X  X eastR X  function to run 500 iterations. AGCD also executes 500 iterations using 48 threads. Experiments are conducted on ADNI data sets. We choose the volume of the right pallidum as the response, including 747 samples by removing samples without labels. The volumes of brain regions are extracted from each sub-ject X  X  T1 MRI scan using Freesurfer 4 . We randomly select 0.5 million features from ADNI to construct the feature ma-trix and normalize the matrix using the  X  X score X  function in Matlab . The experimental result is shown in Table 1.
We report the result of 20 parameter values from 100 pa-rameters. The first column in both methods is the position of the parameter in the sequence. The third column shows the remaining number of features e N after applying screening rules. Table 1 shows that the optimal value obtained by the PDPP+AGCD and the number of nonzero in the solution is the same as that of EDPP+SLEP. When  X / X  max is higher than 0.8, the remaining features after screening is less than the number of threads. However, PDPP+AGCD is still able to converge to the optimal value.
In this experiment, we evaluate the convergence property of the proposed parallel methods. We conduct the exper-iment on PSR+AGCD and compare with state-of-the-art parallel solvers: PBCD and ASYSCD. We choose two dif-http://freesurfer.net/ ferent  X  value: 0 . 8  X  max and 0 . 6  X  max to estimate the conver-gence of above methods. To prevent PSR from discarding active features, we check the KKT condition to ensure the correctness of screening results. To estimate the scalability of above algorithms, the number of cores is varied from 1 to 32: 1, 2, 4, 8, 16 and 32. For different number of cores, we show the time of optimization that solvers converged to the same optimal values with 48 cores. We evaluate the effi-ciency of parallel solvers on four ADNI dataset: ADNI 1 m, ADNI 2 m, ADNI 3 m and ADNI 5 .9m where feature dimen-sion is varied from 1 million to 5.9 million. We choose the volume of hippocampus in patients as the response, includ-ing 717 samples from the original dataset. We show details of data sets in Table 2 and results of comparison in Fig. 2.
In the first and third columns of Fig. 2, we evaluate the convergence in terms of time using 48 cores. Note that we use log-scale in x-axis when  X  = 0 . 8  X  max . As observed from the figure, the objective function in PSR+AGCD converged faster than other solvers since most of inactive features are discarded. Most of time is spent in the screening part. When A DNI 1 m 1 000000 7 17 A DNI 2 m 2 000000 7 17 A DNI 3 m 3 000000 7 17
A DNI 5 .9m 5 906152 7 17  X  = 0 . 6  X  max , only part of inactive features are discarded by screening but PSR+AGCD still has superior performances.
The second and fourth columns of Fig. 2 show the time of different solvers that converged to the same optimal value of 48 cores when varying the number of cores from 1 to 32. Note that we use two y-axis when  X  equals to 0 . 8  X  PBCD and ASYSCD use the left y-axis while PSR+AGCD uses the right one. PSR+AGCD outperforms the other solvers when varying the number of cores and the running time of PSR+AGCD is reduced when there are more cores.
The advantage of the proposed parallel framework is to solve the Lasso problem along a sequence of parameter val-ues. In this experiment, we perform PDPP+AGCD along a sequence of parameter values equally spaced on the lin-ear scale of  X / X  max from 0 . 1 to 1. We vary the length of parameter sequences as 100, 200 and 400. As a compari-son, ASYSCD is performed on the same sequence. The ex-periment is conducted at three different data sets: MNIST, news20 and ADNI 2m. Detailed information about data sets is in Table 2. To evaluate the scalability of both methods, we vary the number of cores as: 1, 2, 4, 8, 16, 32 and 48. The result of comparison is presented in Table 3.

Table 3 shows that more parameters lead to higher speedup for PDPP+AGCD compared to ASYSCD. PDPP+AGCD achieved 137 folds speedup in ADNI 2m dataset, 101 folds in news20, and 40 folds in MNIST over ASYSCD with 400 pa-rameters. When using more cores, speedups of our method tend to increase. Thus, in terms of speedup, PDPP+AGCD favors more cores and sequences with more parameters.
To estimate the scalability of proposed parallel methods, we perform PSR+AGCD and PDPP+AGCD on 1, 2, 4, 8, 16, 32 and 48 cores to observe the speedup. We give the definition of speedup by the following criterion: In this experiment, we employ both methods on 5.9 mil-lion ADNI and rcv1 data sets, respectively. PDPP+AGCD is carried out along a 100 linear-scale sequence of param-eter values from 0 . 1 to 1. For PSR+AGCD, we set  X  to be 0 . 8  X  max in the optimization. Fig. 3 presents the re-sult. PDPP+AGCD is more scalable than PSR+AGCD and achieves approximate 17 and 11.5 folds speedup with 48 cores in ADNI 5.9m and rcv1 data sets, respectively. This paper proposes a parallel framework to solve the Lasso problem on huge dimensional datasets. We introduce screening rules into a parallel platform to discard the in-active features before optimization, accelerating the whole learning process significantly. Then the problem boils down to solve Lasso on a multithreading environment with a small feature space. A grouped selection strategy is proposed to select the candidates that minimize the objective function with the largest descent. Experiments demonstrate the effi-ciency and effective of proposed methods. For future works, we plan to extend our framework to a distributed platform. F igure 3: Speedup of proposed methods on 5.9 mil-lion ADNI and rcv1 data sets respectively This work was supported in part by research grants from NIH (R01 LM010730 and RF1AG051710) and NSF (IIS-0953662 and III-1421057). [1] A. Beck and M. Teboulle. A fast iterative [2] S. Boyd, N. Parikh, E. Chu, B. Peleato, and [3] L. E. Ghaoui, V. Viallon, and T. Rabbani. Safe [4] C.-J. Hsieh, H.-F. Yu, and I. S. Dhillon. Passcode: [5] S. S. Keerthi, K. Duan, S. K. Shevade, and A. N. Poo. [6] A. Kyrola, D. Bickson, C. Guestrin, and J. K. [7] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. [8] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. Rcv1: A [9] Y. Li and S. Osher. Coordinate descent optimization [10] J. Liu, S. Ji, and J. Ye. SLEP: Sparse Learning with [11] J. Liu, S. Wright, C. Re, V. Bittorf, and S. Sridhar. [12] Y. Nesterov. Efficiency of coordinate descent methods [13] P. Richt  X arik and M. Tak  X a X c. Parallel coordinate descent [14] P. Richt  X arik and M. Tak  X a X c. Iteration complexity of [15] C. Scherrer, M. Halappanavar, A. Tewari, and [16] C. Scherrer, A. Tewari, M. Halappanavar, and [17] S. Shalev-Shwartz and A. Tewari. Stochastic methods [18] R. Tibshirani. Regression shrinkage and selection via [19] R. Tibshirani, J. Bien, J. Friedman, T. Hastie, [20] K. Tran, S. Hosseini, L. Xiao, T. Finley, and [21] J. Wang, Q. Li, S. Yang, W. Fan, P. Wonka, and [22] J. Wang and J. Ye. Two-layer feature reduction for [23] J. Wang and J. Ye. Safe screening for multi-task [24] J. Wang, J. Zhou, P. Wonka, and J. Ye. Lasso [25] Y. Wang, Z. J. Xiang, and P. J. Ramadge. Lasso [26] T. Zhang. Solving large scale linear prediction
