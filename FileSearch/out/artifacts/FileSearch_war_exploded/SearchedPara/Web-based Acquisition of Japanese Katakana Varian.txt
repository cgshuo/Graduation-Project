 This paper describes a method of detecting Japanese Katak-ana variants from a large corpus. Katakana words, which are mainly used as loanwords, cause problems with infor-mation retrieval and so on, because transliteration creates several variations in spelling and all of these can be ortho-graphic. Previous works manually defined Katakana rewrite rules such as %Y ( be )and %t % X  ( ve )being replaceable with each other, for generating variants and also defined the weight of each operation to edit one string into another to detect these variants. However, these previous researches have not been able to keep up with the ever-increasing number of loan-words and their variants. With our method proposed in this paper, the weight of each edit operation is mechanically assigned based on Web data. In experiments, it performed almost as well as one with manually determined weights. Thus, the advantages of our method are: 1 )need no ex-pertise in linguistics to determine weight of each operation, and 2 )able to keep up with new Katakana loanwords only by collecting text data from Web and acquiring new weights of edit operations automatically. It also achieved 98.6% re-call and 86.3% precision in the task of extracting Katakana variant pairs from 38 year X  X  worth of corpora of Japanese newspaper articles.
 I.2.7 [ Computing Methodologies ]: Natural Language Pr-ocessing X  Language Generation Algorithms Spelling Variation, Katakana Variants, Thesaurus, Edit Dis-tance, Contextual Similarity
Katakana is a phonogram type of Japanese character set and is mainly used for expressing loanwords, personal names, and country or city names that cannot be expressed by Chi-nese characters: Kanji. The pronunciation of loanwords does not necessarily coincide with that in their original lan-guage. Therefore, transliteration creates several different orthographies for the original word as shown in Table 1. For example, we have three different orthographies for  X  X ameron Diaz X  that is a name of the movie actress.

Katakana variants cause problems with information re-trieval, information summarization, machine translation, an-d question-answering systems [6], [7]. For example, when we use %9%Q%2%C%F%# ( supageltuthi for  X  X paghetti X  )as a query in-put to search engines, we may not be able to retrieve web pages where variants are used. We found at least six differ-ent spellings for spaghetti from 38 year X  X  worth of corpora of Japanese newspaper articles, i.e., %9%Q%2 %C %F %# ( supageltuthi ), %9%Q%2%C%F%#!&lt; ( supageltuthi-), %9%Q%2%C%F%$ ( supageltutei ), %9%Q%2%F%# ( supagethi ), %9%Q%2%F%#!&lt; ( supagethi-),and %2%F%$ ( supagetei ).

We tried to find how many documents were retrieved by Google 1 when each Katakana variant for spaghetti was used as a query. The results are listed Table 2. Note that we retrieved the queries by combining Google X  X  X + X  and  X - X  op-tions to avoid partial overlapping such as %9%Q%2%C%F%# ( su-pageltuthi )and %9%Q%2%C%F%#!&lt; ( supageltuthi-).
For example, when we used %9%Q%2%C%F%# ( supageltuthi )as a Google query, 104,000 out of a total of 300,556 documents (34.6% )were retrieved. Since we can see that as each of the six variants appeared frequently on Table 2, we may not be able to retrieve many web pages where variants are used if we do not cope with Katakana variants.
 Table 2: Number of retrieved documents when we used Katakana variants of  X  X paghetti X  as a Google query.

We will first describe methods based on rewrite rules, which are described in Table 3. Henceforth,  X  denotes substitution,  X  denotes an empty string,  X  X nsertion X  means inserting a character,  X  X eletion X  means deleting a charac-ter, and  X  X ubstitution X  means replacing a character with another character.

Shishibori et al. presented a method of generating Katak-ana variants [8]. They manually defined 135 rewrite rules, such as those in Table 3, to generate Katakana variants. For example, when they inputted %Y%M%A%" ( benechia for  X  X enezia X  )into their system which applies rewrite rules, %M%D%#%" ( benetsia ), %t% X %M%A%" ( venechia ),and %t % X %M%D%#%" ( venetsia )were generated as the variants.

Kubota et al. converted Katakana words to directed grap-hs based on rewrite rules [2]. They regarded Katakana words as variants if the directed graphs contained the same labeled paths.

There have been proposed methods without rewrite rules, which are mainly based on similarities [7], [6]. The first http://www.google.co.jp/ involves spelling similarities that are calculated with a man-ually weighted edit distance and the second involves contex-tual similarities that are calculated based on cosine similar-ities. Each threshold for spelling and contextual similarities is defined manually and a pair of Katakana words is regarded as a variant pair when it exceeds both thresholds.
An ordinary edit distance [1] counts the number of oper-ations to edit one string into another. On the contrary, the manually weighted edit distance assigns a manually deter-mined weight to each operation. Henceforth, an operation will denote  X  X nsertion, X   X  X eletion, X  or  X  X ubstitution. X 
For example, when calculating spelling similarities for %j %]!&lt;%H ( ripo-to )and %l%]!&lt;%H ( repo-to ), which both mean  X  X eport, X  the ordinary edit distance counts the number of substitutions %j ( ri )and %l ( re ), but the manually weighted edit distance assigns non integer value such as 0.8. Here, the weight of substitutions %j ( ri )and %l ( re )is determined to be higher than the weight for %j ( ri )and the other character.
Both of the ordinary edit distance and the manually weigh-ted edit distance edit a character at each operation. In order to overcome this limitation of edit distance, we proposed a string penalty for editing multiple characters at each opera-tion [4] 2 . For example, when calculating spelling similarities for %\%$%9 ( boisu )and %t%)%$%9 ( voisu ), which both mean  X  X oice, X  the string penalty assigns 4 to substitutions %\ and %t%) ( vo ).

Contextual similarity is a measure used to take into ac-count contextual co-occurrence information. It is useful in distinguishing incorrect pairs of Katakana variants such %" ( se-fuuea for  X  X afe wear X ), since contextual similarity is higher when two words appear in similar contexts. Given a Katakana word, documents or paragraphs, which contain the Katakana word, are treated as document-level contexts. Generally, words are used as features in a document-level context.

The problem which is inherent in all of these methods, with or without rewrite rules, is that it is difficult to keep up with the ever-increasing number of loanwords and their variants, since they define rewrite rules manually or assign weights to the edit distance manually.

We propose a method of mechanically determining the weights of the string penalty to overcome this problem. Our string penalty is a function to assign a smaller weight to an edit operation if the edit operation tends to occur between Katakana variants. The new idea is that the string penalty for each edit operation is mechanically acquired from Web data.

We conduct a three-step method of extracting Katakana variant pairs from a large corpus. First, we collect Japanese Katakana words from a large corpus. We then extract can-didate variant pairs based on spelling similarities from the collected Katakana words. Finally, we extract variant pairs from candidate pairs based on the contextual similarities of each Katakana word.
 The remaining part of this paper is organized as follows. Section 2 describes how the weights of the string penalty is mechanically determined based on Web data. We compare our method with one involving manually determined weights [4]. Section 3 describes how Katakana variant pairs were Masuyama is currently with Yahoo! JAPAN, Roppongi Hills Mori Tower, 10-1, Roppongi 6-chome, Minato-ku, Tokyo, 106-6182, Japan. extracted from 38 year X  X  worth of corpora of Japanese news-paper articles, which we will refer to as  X  X he corpus X  from now on. This is followed by our evaluation and a discussion. Section 4 offers some concluding remarks and discusses the future work.
This section presents a method of mechanically calculat-ing the weight of the string penalty using Web data. Our method involves three steps. 1. Collect candidate Katakana variant pairs from Web 2. Extract Katakana variant pairs from the collected can-3. Calculate the string penalty, which is the weight of
We used a list of English words and Katakana loanwords, such as vodka and %&amp;%) %C%+ ( wholtuka )to extract candidate Katakana variant pairs from Web data, since most Katakana words are loanwords. The list was created by hand from four sites 3 . 14,958 distinct pairs of an English word/phrase and the Katakana loanword were created from the list.
Although there have been several studies on extracting translation information from Web data [3], we used the Google search engine to retrieve Web pages that contained candidate Katakana variants, since we wanted to use Googl-e X  X  English-to-Japanese dictionary function.

Our extraction procedure was based on two types of queri-es: 1 )the query was an English word/phrase and the answer language specification was Japanese. 2 )the query consisted of an English word/phrase and 1Q OB ( X  X nglish to Japanese X ).
From Web pages retrieved by the extraction procedure described above, we extracted candidate Katakana variant pairs based on the ordinary edit distance, which counted the number of edit operations, i.e., insertion, deletion, or substitution. In the vodka example, ( %&amp;%) %C%+ ( wholtuka ), %)%H%+ ( whotoka )), ( %&amp;%) %C%+ ( wholtuka ), %&amp;%*%C%+ and ( %&amp;%) %C%+ ( wholtuka ), %t%) %C%+ ( voltuka )) were extracted as candidate variant pairs from retrieved Web pages, since the edit distance for each pair was 1 and smaller than the threshold of 2, which is predetermined experimentally. This threshold was chosen to avoid extracting too many incorrect pairs such as ( %_%j%j %C %H%k ( miririltutoru for  X  X illiliter X ), %C%H%k ( riltutoru for  X  X iter X )) and ( %"%C%W%m!&lt;%I ( altupuro-do for  X  X pload X ), %@%&amp;%s%m!&lt;%I ( daunnro-do for  X  X ownload X )).
We extracted Katakana variant pairs from candidate pairs with the method described in Subsection 2.1 based on con-textual similarities, which are cosine similarities. Assume 1.http://homepage2.nifty.com/katakanaEnglish/ 2.http://wwwhoshi.cis.ibaraki.ac.jp/useful/useful15.html 3.http://www.ke.ics.saitama-u.ac.jp/jsgs/keywords.html 4.http://www.smalltown.ne.jp/  X  usata/pub/distfiles/skk-jisyo-extra-200307/SKK-JISYO.edict that a ( x )denotes the document-level context of Katakana word x and b ( y )denotes the document-level context of Kata-kana word y . The cosine similarity between a ( x )and b ( y ) is calculated as shown in equation (1).
Cosine similarities tend to overscore frequently appearing words. Thus, we adopted log( freq ( w )+ 1 )as the weight for each word appearing in a document-level context where freq ( w )represents the frequency of word w in a document-level context.

To obtain a document-level context, each Katakana word was used as a Google query to retrieve Web pages in which the word was contained. We used ChaSen 4 , a Japanese mor-phological analyzer, to divide sentences in articles into words and then extracted content words that consisted of nouns, verbs, adjectives, adverbs, and unknown words, except stop-words. Here, stopwords were composed of Hiragana words and single character words. We first apply the above words selection procedure to the retrieved Web pages. Then we ex-tracted words from the window of the retrieved Web pages [5]. Note that we treated 50 words on both sides of the Katakana word as the window size.

For example, the cosine similarities for ( %&amp; %) %C %+ a ), %&amp; %) %H %+ ( whotoka )), ( %&amp; %) %C %+ ( wholtuka ), 57, 0.0002, and 0.00025 respectively. We regarded these pairs as variant pairs, since their cosine similarities were larger than our threshold of 0.00006 which was determined by training data as shown in Figure 1 which shows the re-lation of F-measure and threshold of cosine similarities. In Figure 1, the horizontal axis denotes threshold of cosine sim-ilarities and the vertical axis denotes F-measure ( F ), as will be described Subsection 3.1.
 Figure 1: Relation of F-measure and threshold of cosine similarities to extract Katakana variant pairs from Web data. http://chasen.naist.jp/hiki/ChaSen/
We calculate a string penalty for each edit operation us-ing the variant pairs which we collected with the method described in 2.1 and 2.2. The more frequently an edit oper-ation tends to occur between Katakana variants, the smaller the string penalty of the edit operation should be. We treated the neighboring characters of each edit operation as a character-level context to determine the string penalty. Henceforth, we will abbreviate string penalty as SP .
We used the following five types as character-level con-texts of each character targeted by the edit operation. 1. The preceding two characters of the target character, 2. The preceding character of the target character, 3. The succeeding two characters of the target character, 4. The succeeding character of the target character, and 5. The preceding character and the succeeding character
To find the valid SP values, we first calculated the op-eration probability for each character-level context. When the edit operation for x and y is described as x  X  y and a character-level context is described as CLC , the operation probability is defined as (2).
 Here, f ( CLC )denotes the frequency of occurrences for CLC and f ( CLC , x  X  y )denotes the frequency of simul-taneous occurrences for CLC and edit operation for x  X  y in the set of variant pairs. We adopted Laplace X  X  smoothing, i.e., we added 1 to the numerator and 2 to the denominator.
From operation probabilities, we calculated the  X  CLC to maximize operation probability as (3).
Finally, we calculate SP based on the operation probabil-ity of  X  CLC as (4).

Table 4 shows several samples of the SP and edit opera-tion.
 We compared the mechanically and manually determined SP s[4].

We selected 682 candidate pairs of Katakana variants from the corpus as a test set and evaluated these by manually checking their document-level contexts. Table 5 shows the ratio of Katakana variant pairs. In Table 5,  X  Manual  X  X e-notes the manually determined SP which is calculated based on the method proposed in [4] and  X  Mechanical  X  denotes the mechanically determined SP .

For example, when SP was 2, 162 out of 207 Katakana variant pairs were extracted as correct variant pairs with the manually determined SP at a ratio of 78.3%. Also, 133 out of 148 Katakana variant pairs were extracted as correct variant pairs with the mechanically determined SP at a ratio of 89.9%.
 From Table 5, we see that the mechanically determined SP performs similarly to the manually determined SP .
We analyzed the correlation between the mechanically de-termined SP and the manually determined SP .Theresults are listed in Table 6. In Table 6, columns denote manually determined SP s and rows denote mechanically determined SP s. For example, the cell position (2,3 )means 59 can-didate pairs of Katakana variants with 2 of the manually determined SP and 3 of the mechanically determined SP . We calculated coefficient of correlation of Table 6 and the value was 0.76. Thus, we found that the correlation of the mechanically determined SP and the manually determined SP was strong. That means that Katakana variants acqui-sition system based on manually determined SP and that based on mechanically determined SP are expected to show similar performance. However, the latter is more promising because we do not need human expertise of computational linguistics to develop Katakana acquisition system. In ad-dition, the latter system can keep up with new Katakana words only by collecting more up-to-date data from the Web.
This section describes a method of extracting Katakana variant pairs from a large corpus. Our method consists of three steps that involve the following procedure. Table 6: Correlation of the mechanically determined SP and the manually determined SP .
 1. Collect Katakana words from the corpus. 2. Extract candidate pairs of variants from the collected 3. Extract variant pairs from candidate pairs based on
At Step 1, we collect Katakana words from the corpus. We used the pattern matching of a Katakana character set, !&amp; ( X  X ullet X ), !&lt; ( X  X acron-1 X ), !] ( X  X acron-2 X ), and != ( X  X a-cron-3 X  )to collect Katakana words such as %_%M%i%k%&amp;%)!&lt; %?!&lt; ( mineraruwho-ta-for  X  X ineral water X ).

At Step 2, our system extracts candidate pairs of variants which have similar spellings, from the collected Katakana words. We use string penalties as spelling similarities.
For example, our system extracts the pair %_%M%i%k%&amp;%)!&lt; %?!&lt; ( mineraruwho-ta-for  X  X ineral water X  )and %_%M%i%k%&amp; %*!&lt;%? ( mineraruuo-ta for  X  X ineral water X ), since the SP is 2 and smaller than the threshold of 4 which we determined experimentally, namely we manually tuned this threshold by randomly selecting training data.

At Step 3, our system extracts variant pairs from candi-date pairs based on contextual similarities. We use the co-sine similarities described in Subsection 2.2. We treat up to 10 randomly selected articles from the corpus as document-level contexts for each Katakana word. We divide sentences in the articles into words using JUMAN 5 , a Japanese mor-phological analyzer, and then extract content words that consisted of nouns, verbs, adjectives, adverbs, and unknown words, except stopwords. Stopwords are composed of Japan-ese Hiragana words, punctuation, numerals, and common words.

We set 0.05 as the threshold of cosine similarities, i.e., we regard candidate pairs as variant pairs when the cosine simi-larities are greater than 0.05. The threshold was tuned from randomly selecting training data. Figure 2 lists the relation of F-measure and threshold of cosine similarities. F-measure http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html was the highest when the threshold of cosine similarities was 0.05.

For example, we regarded the pair %_%M%i%k%&amp;%)!&lt;%?!&lt; ( mineraruwho-ta-for  X  X ineral water X  )and %_%M%i%k%&amp;%*!&lt; %? ( mineraruuo-ta for  X  X ineral water X  )as a variant pair, since their cosine similarity was 0.19 which was greater than the threshold of 0.05.
 Figure 2: Relation of F-measure and threshold of cosine similarities.
We conducted experiments using a corpus that had 4,678,-040 documents with 1,102,108 distinct Katakana words.
We collected candidate pairs of Katakana variants for the test set with string penalties ranging from 1 to 12. There were 3,153,185 collected candidate pairs. To create samples with correct Katakana variant data of English origin, we randomly selected 682 out of the 3,153,185 and evaluated these by manually checking their document-level contexts.
We used recall ( Re ),precision( Pr ), and F-measure ( F ) to evaluate our method. These performance measures are calculated with the following formulas.

We used both spelling and contextual similarities as de-scribed in Steps 2 and 3. Henceforth, we will describe the method with the mechanically determined SP and comtex-tual similarities as  X  Mechanical  X  and the method with the manually determined SP and comtextual similarities as  X  Ma-nual . X 
We compared the performance of Mechanical with that of Manual . The results are listed in Table 7. For example, when SP was 2, 124 out of 131 were extracted as correct variant pairs with Mechanical at a precision of 94.7%. Also, 146 out of 181 were extracted as correct variant pairs with Manual at a precision of 80.7%.
 To analyze the performance of Manual and Mechanical in Table 7, we conducted paired t-test (rejection region: 5%) for the cases of SP = 1, 2, and 3 and no significant difference is detected. We also show recall, precision and F-measure of the cases of SP = 1, 2, and 3 in Table 8. Then We found that the performance of Manual and Mechanical were almost same.
 Table 8: Recall, precision, and F-measure of Manual and Mechanical between SP 1and SP 3.

We further investigated the relation between threshold of mechanically determined SP and recall, precision, and F-measure of Table 7. Figure 3 shows relation of the mechan-ically determined SP and recall, precision, and F-measure where we used the cosine similarity threshold of 0.05 which was chosen from the result of Figure 2. From Figure 3, we found the combination of 3 of the threshold of the me-chanically determined SP and 0.05 of the threshold of cosine similarities was the best F-measure.

We also investigated the relation between threshold of manually determined SP and recall, precision, and F-measure of Table 7 as shown in Figure 4 and found that the combi-nation of 3 of the manually determined SP and 0.05 of the threshold of cosine similarities was also the best.
We investigated how many variant pairs were extracted with the six different spellings of  X  X paghetti X  described in Section 1. Table 9 lists the results for all combination pairs using Mechanical . For example, when SP was 1, Mechanical extracted seven candidate pairs and all of these were correct. Thus, the recall was 100%. As seen in Table 9, we can see that the SP of each combination pair ranges from 1 to 3 and our system extracted all combination pairs due to contextual similarities.
 Figure 3: Relation of mechanically determined SP and recall, precision, and F-measure.
 Figure 4: Relation of manually determined SP and recall, precision, and F-measure.
 Table 9: Result from six different spellings for  X  X paghetti X  described in Section 1.
 We compared the performance of Mechanical with that of Microsoft Word 2002 6 (Word), Google, and Yahoo! Japan 7 . Word is a word processing software for creating documents and Google and Yahoo! are search engines for retrieving documents. Word, Google, and Yahoo! have functions to detect Katakana variants. Note that we conducted the ex-periment in November 2004.

Table 10 compares the results for Mechanical , Word, Goo-gle, and Yahoo! in terms of detecting Katakana variants of  X  X paghetti. X  Comparing Mechanical with the others, we can see that Mechanical  X  X  performance was significantly better. Table 10: Comparing performance of Mechanical with Microsoft Word 2002, Google, and Yahoo! Japan.

As we can see from Table 8, Mechanical could not extract some correct variant pairs. We investigated these and found that their document-level contexts were different.
Mechanical could not extract the variant pair %0%j%: %j!&lt; %Y %" ( gurizuri-bea )and %0%j%:%j!&lt; !&amp; %Y%" ( gurizuri-of which denoted  X  X rizzly bear, X  since their document-level contexts were completely different. %0 %j %:%j !&lt; %Y %" bea )appeared in an article introducing animals living in Alaska and %0%j%:%j!&lt;!&amp;%Y%" ( gurizuri-!&amp; bea )appeared in an article as the nickname of Norman Schwarzkopf, the U.S. Army General who led allied forces during the Gulf War. Therefore, the contextual similarities were small. Note that %0 %j %:%j !&lt; %Y%" ( gurizuri-bea )and %0 %j %: %j!&lt; !&amp; %Y %" bea )each appeared in only one article in the corpus.
If we refer to precision in Table 8, Mechanical wrongly extracted some incorrect variant pairs. Looking closely at such cases, we found out that their document-level contexts were similar.

For example, Mechanical wrongly extracted the incorrect variant pair %5%$%s%\!&lt;%k ( sainnbo-ru for  X  X ign ball X  )and %5%$%s%]!&lt;%k ( sainnpo-ru for  X  X ign pole X ). %5%$%s%\!&lt;%k ( sainnbo-ru )appeared in articles introducing stores or sta-dium selling balls that Ichiro Suzuki, the famous baseball player, had signed. %5%$%s%]!&lt;%k ( sainnpo-ru )appeared in articles representing trade signs or trade marks in barber shops, gas stations, or electronics stores. In both document-level contexts, 4Q5R ( X  X pectator X ), 5R ( X  X ustomer X ), E9 ( X  X to-re X ), E9D9 ( X  X tore manager X ), GdE9 ( X  X hop X ), and HNGd ( X  X ale-s X  )appeared in common and thus the contextual similarities were great.
We proposed a method of mechanically determining the weight of each edit operation for identifying Katakana vari-ants, based on Web data. Unlike methods presented in pre-vious work, ours could easily keep up with the increasing http://www.microsoft.com/japan/ http://www.yahoo.co.jp/ number of loanwords. Through experiments, we found that its performance was similar to that of a method with man-ually determined weights.

We also proposed a method of extracting Japanese Katak-ana variant pairs from a large corpus based on similarities in spelling and context. Through experiments, it achieved 98.6% recall and 86.3% precision in the task of extracting Katakana variant pairs from the corpus.

In our future work, we are planning to calculate SP with a list of words in other languages and Katakana loanwords, such as the German  X  X rbeit X  ( X  X art-time job X  )and its Kata-kana rendering %"%k%P%$%H ( arubaito for  X  X rbeit X ), although there are not as many of these as there are in English. We are most grateful to Assistant Research Professor Satoshi Sekine of Computer Science Department, New York Univer-sity for his useful comments and help with the corpus used for this research. We would like to express special appre-ciation to the reviewers of SIGIR 2005 who have provided many valuable comments and criticisms. This research was partially supported by the Ministry of Education, Science, Sports, and Culture, Grant-in-Aid for Scientific Research on Priority Areas, 16016215, 2004. [1] P. A. V. Hall and G. R. Dowling. Approximate string [2] J. Kubota, Y. Shoda, M. Kawai, H. Tamagawa, and [3] W.-H. Lu, L.-F. Chien, and H.-J. Lee. Translation of [4] T. Masuyama, S. Sekine, and H. Nakagawa. Automatic [5] C.Niu,W.Li,andR.K.Srihari.Weaklysupervised [6] K. Ohtake, Y. Sekiguchi, and K. Yamamoto. Detecting [7] W. QU and K. Shirai. Katakana variants detection for [8] M. Shishibori, K. Tsuda, and J. Aoe. A method for
