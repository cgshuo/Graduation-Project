 Balaji Lakshminarayanan balaji@gatsby.ucl.ac.uk Gatsby Unit, CSML, University College London Daniel M. Roy d.roy@eng.cam.ac.uk University of Cambridge Yee Whye Teh y.w.teh@stats.ox.ac.uk Department of Statistics, University of Oxford Algorithm 1 SMC for Bayesian decision tree learning Inputs: Training data ( X,Y ) for i = 1 : MAX-STAGES do end for return Estimated marginal probability W i /M and ber of particles increases, the log marginal likelihood of prior and optimal proposals converge to the same value (as expected). In this experiment, we evaluate the sensitivity of the runtime vs predictive performance comparison be-tween SMC ( prior and optimal proposals), MCMC and CART to the choice of hyper parameters  X  (Dirichlet concentration parameter) and  X  s , X  s (tree priors). We consider only node-wise expansion since it consistently outperformed layer-wise expansion in our previous experiments. In the first variant, we fix  X  = 5 . 0 (since we do not expect it to affect the timing results) and vary the hyper parameters from  X  s = 0 . 95 , X  s = 0 . 5 to  X  s = 0 . 8 , X  s = 0 . 2 (bold re-flects changes) and also consider intermediate config-urations  X  s = 0 . 95 ,  X  s = 0 . 2 and  X  s = 0 . 8 , X  s = 0 . 5. In the second variant, we fix  X  s = 0 . 95 , X  s = 0 . 5 and set  X  = 1 . 0 . Figures 4, 5, 6 and 7 display the re-sults on pen-digits (top row), and magic-04 (bottom row). The left column plots test log p ( y | x ) vs run-time, while the right column plots test accuracy vs runtime. The blue circles and red squares represent optimal and prior proposals respectively. Comparing the results to Figure 5 (in main text), we observe that the trends are qualitatively similar to those observed
