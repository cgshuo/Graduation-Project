 LARA QUIJANO-SANCHEZ, JUAN A. RECIO-GARCIA, BELEN DIAZ-AGUDO, Most of the work in recommender systems provides recommendations for individual users. However, there are many different activities that can be performed by groups of people, like watching a movie, going to a restaurant, listening to a radio station or traveling with friends. For these activities, recommender systems have to suggest items to groups based on the individual preferences of their members.

In recent years, the number of recommender systems that deal with the challenge of making recommendations for groups of people has increased. These recommenders are based on the aggregation of the individual preferences of every member or on the generation of a model based on the group itself for providing recommendations to the group. However, most of these systems deal with every individual preference in the same way, ignoring the personality of each member and the relationships among them within the group.

In this article we describe an approach to making recommendations for groups of people connected by social network structures. Our approach proposes making recommendations to groups by using existing techniques of collaborative filtering [Schafer et al. 2007], while taking into account several social factors that improve the accuracy of the system: the composition of the group personality and the social connections among the individuals.

The set of methods proposed can be integrated into any social network to provide rec-ommendation capabilities to groups of users for activities such as going to the cinema, choosing a restaurant, planning trips, etc. For example, it is common to create events on Facebook where friends are invited to group activities. Users join the event and later decide its details. Quite often this decision consists of choosing an item or service to be consumed (movie, pub, restaurant, trip, and others). This decision is usually very tedious because it requires continuous communication among users. Our approach con-sists of automating the decision-making step by modeling the preferences of the user (as in collaborative filtering) and later aggregating these preferences to obtain a group recommendation. However, we can improve the aggregation strategies that generate the group recommendation because we are running over a social network and we can infer some social aspects about the users. These social aspects allow us to perform a more realistic simulation of the real discussion that would take place when deciding the item to consume. In our approach, personality is used to measure the users degree of permissiveness when his/her preferred items are not selected by the group. And social trust is exploited to calculate how the preferences of close friends may bias user choice.
Moreover, after we evaluate the possibilities that the personality composition of the group and the evaluation of the trust among group members offer, we study the option of introducing a system with memory to ensure a certain degree of fairness when the group recommendation process is repeated several times.

Our experiment is run with real users connected through social networks where we study how these features affect the group decision-making process. Our experiment in the movie recommendation domain compares the results of a standard group recom-mendation based on collaborative filtering and average aggregation with our improved recommenders, which use only personality, only social trust, a combination of both factors and the inclusion of a memory process.

The next section relates existing works in group recommender systems that include the features proposed in this article. Personality and social trust factors used to improve the recommendations are detailed in Section 3. Section 4 explains our proposal about a recommender system with memory, which assures fairness in group decisions. Our case study is explained in Section 5, followed by the experimental results obtained, shown in Section 6. In Section 7 we summarize the main conclusions that we obtained throughout this research. Finally, Section 8 details some of our ongoing and future work. Group recommendation approaches are typically based on generating an aggregated preference by using the users individual preferences. As stated in Jameson and Smyth [2007] the main approaches to generating the preference aggregation are (a) merging the recommendations made for individuals, (b) aggreging ratings for individuals and (c) constructing a group preference model. A wide set of aggregation functions has been devised for combining individual preferences [Masthoff 2004], the average and least misery strategies being the most commonly used.

There is a proliferation of recommender systems that cope with the challenge of addressing recommendations for groups of users in different domains. MusicFX [McCarthy and Anagnost 1998] provides recommendations about background music at a fitness centre based on the preferences provided by the users in different musical genres. Polylens [O X  X onnor et al. 2001] is an extension of Movielens for generating recommendations to groups. Users create groups and the system recommends movies for these groups while trying to satisfy, at least the less satisfied members.
Another interesting content-based recommender system is Pocket Restaurant Finder [McCarthy 2002], which recommends restaurants for groups of people based on user location and the culinary characteristics of the restaurant. YuTV [Yu et al. 2006] is a TV program recommender for groups of viewers that uses a vector space model about features of TV programs (such as genre or actors) to find relevant recommendations for the groups.
 Other examples are LET X  X  BROWSE [Lieberman et al. 1999], which recommends Web pages to a group of two or more people who are browsing the Web together, or FlyTrap [Crossen et al. 2002], a group recommender that selects music to be played in a public room. What all these recommenders have in common is that the group recommendations take the personal preferences obtained from their users into account but they consider each user equal to the others. The recommendation is not influenced by their personality or the way each one behaves in a group when joining a decision-making process. In our approach we propose to study how people interact depending on their personality or their closeness in order to improve group recommendations. Several works have focused on organizing trips and visits for groups of tourists. Travel Forum Decision [Jameson 2004] helps a group of users to plan their vacations together. The system not only takes into account the preferences of each member in order to make recommendations but interaction among members is also reflected in the recommendation. The system provides a solution and allows group members to discuss. It acts as a mediator until they reach a solution. What we propose is to simulate this discussion in order to arrive at a solution. This way, our approach requires less interaction from users and it presents an immediate solution.
 Other systems take into account the attitudes and behavior of other group members. CATS [McCarthy et al. 2006] is a conversational recommender for planning skiing holidays. The main feature of this system is that the recommendation is defined as an incremental process where users collaboratively refine the suggested recommendation by critiquing its features or discarding it. They consider that the preference of the current member partially depends on the preferences and/or anticipated behavior of other members. During the process of choosing a recommendation, users can see what other members have voted for, so they are conditioned by the opinions of other members. Our approach simulates this conditioning more thoroughly. CATS users need to read the information from other users in order to alter their initial opinion. Obviously this is only possible for users who vote later. However, our approach can simulate these alterations beforehand, by taking into account the strength of the relationships between group members.

Intrigue [Ardissono et al. 2003] plans visits for groups of tourists by weighting the preferences of different subgroups with special needs (like children or disabled people). The weight is computed using the subgroup size and its relevance within the whole group. Chen et al. [2008] propose the use of genetic algorithms to learn group prefer-ences based on the known preferences of the subgroups within a group. Although the results seem to be significant, they suppose that the groups are fixed and they have previously rated some items together.

Other works focus on the integration of the group disagreements in the recommenda-tion process. One of the most recent systems is GRec-OC [Kim et al. 2010], a book rec-ommender system for online communities. GRec-OC provides recommendations based on the books that other similar groups have purchased and tries to reduce the dis-satisfaction of individual members. Amer-Yahia et al. [2009] propose a recommender that aggregates prior member group preferences to create the recommendation. Then, preference disagreements between pairs of individuals are collected and employed to score and rank the recommended items. Finally, Masthoff and Gatt [2006] use individ-ual satisfaction and emotional contagion in order to recommend a sequence of video clips for a group. They think that a member changes the selection of her best clip according to the clip selected during the previous selection step. This change can be reflected in the recommendation algorithm as an individual satisfaction function that computes the individual affective state. This state influences the affective state of the other members, producing an emotional contagion that should be taken into account during the recommendation process. Additionally, they point out the tendency of social status to influence the selection process.

There is agreement about the need to adapt the recommendation process to group composition [Jameson and Smyth 2007; Masthoff 2004]. Recent works have focused their studies on analysing the effectiveness of group recommendations according to different aspects, such as group size and inner group similarity [Baltrunas et al. 2010], or on studying different weighting models to combine the preferences of group mem-bers according to their role within the group or their activity [Berkovsky and Freyne 2010]. Additionally, it is also known that user preferences can be affected by other members of the group [Masthoff 2004; Chen et al. 2008]. However, most of the aggre-gation strategies employed in previous works combine user preferences without taking into account either the relationships among group members or the relevancy of each members preferences. The work dealing with these issues is limited. We observed that there was a need to modify those existing strategies that consider each user of the group as equal to the others. So we focus our line of work on reflecting the individual aspects of each user in the group and reflecting how they interact with each other.
Our recent work [Recio-Garc  X   X a et al. 2009] involves the improvement of current group recommendation techniques by introducing a novel factor: the personality of every individual in the group when dealing with conflict situations. We have used a personality test to obtain the different roles that people play when interacting in a decision-making process. Besides the individual characterization of the people in the group, we are also studying other factors like the structure of the group itself and how users interact with each other.

Current research has pointed out that people tend to rely more on recommendations from people they trust (friends) than on recommendations based on anonymous ratings [Sinha and Swearingen 2001]. This factor is even more important when we are per-forming a group recommendation where users have to decide on an item for the whole group. This kind of recommendations usually follows an argumentation process, where each user defends her preferences and rebutts other X  X  opinions. Here, when users must change their mind to reach a common decision, trust among users is the major factor.
There is a huge body of work about the generation of trust models. However, the raising of the current collaborative web (Web 2.0) has boosted the idea of Web Of Trust (WOT) [Golbeck 2006b; O X  X onovan and Smyth 2005; Victor et al. 2008]. The WOT rep-resents trust among users, modeled on an online network. There are specific approaches that use a custom trust network to recommend items. One example is FilmTrust [Golbeck 2006b], which exploits a custom network of trust among users according to movie preferences. However, these specific trust networks are quite difficult to generate because they require explicit feedback from users, and that can generate rejection.
Another promising approach is to infer knowledge of trust from existing social net-works like Facebook or Twitter. These networks contain implicit information that can be exploited in order to improve the recommendation process. This option has the main advantage of being completely transparent to users. Users are not required to provide explicit information about their trust to other users because this knowledge is extracted implicitly from their daily interaction in the social network. However, it has the obvious drawback that every user involved in the group recommendation process must belong to the social network. Nevertheless, the rising popularity of this kind of Web applications minimizes this risk. Even more, it is becoming usual to organize events (like going to the cinema) through social networks, so group recommendation techniques could be integrated into these Web sites.

Recent works provide evidence that users prefer the sort of system that relies on trust in social networks because users tend to prefer recommendations from people they know and trust [Sinha and Swearingen 2001]. Golbeck [2006a] presents a study of how to infer trust relations within social networks. The computational problem of trust is to determine how much one person in the network should trust another. Certainly, trust inferences will not be as accurate as a direct rating. But in this work, Golbeck presents an algorithm for inferring trust in networks with continuous rating systems, named TidalTrust, that improves the accuracy by 10%.

Another important matter that should be taken into account is the special importance that some works give to avoid repeated recommendations or recommendations that tend to be detrimental to the same group members repeatedly. MusicFX employs a weighted random policy for selecting one of the top radio stations selected by the recommender, instead of always selecting the top category. Another solution is taking into account the history of the results produced by the recommender. For example, in FlyTrap previous selections are taken in consideration. This way, when they choose the next song to be played, abrupt changes of genre do not appear. Another system that takes previous selections into account is PoolCasting [Baccigalupo and Plaza 2007]. It uses a Case-Based Reasoning system to generate a sequence of songs customized for a community of listeners. To select each song in the sequence, first a subset of songs musically associated with the last song of the sequence is retrieved from a music pool; then the preferences of the audience expressed as cases are reused to customize the selection for the group of listeners; finally, listeners can revise their satisfaction (or lack of) for the songs they have heard.

The works presented rely on the different factors involved in our proposal: per-sonality, trust and memory. However, we have not found any work that integrates and evaluates these three factors in group recommendation processes. Therefore we consider that our approach improves them by making a more exact representation of how group argumentations take place in real life. This is the main contribution of this article. Next section describes our approach for including personality and trust in group recommenders, whereas Section 4 explains the inclusion of a long-term memory of past recommendations. Most of the previous works in group recommendation consider the preferences of ev-ery member of the group with the same degree of importance and try to satisfy the preferences of every individual. However, groups of people can have very different characteristics, like size, the relationships among their members or the distribution of people with similar or antagonistic personal preferences. Our approach presumes that the general satisfaction of the group is not always the aggregation of the satisfaction of its members.

It is a fact that when we face a situation in which peoples concerns appear to be incompatible, a conflict situation arises. Different people have different expectations and behavior in conflict situations that should be taken into account. When we started our research to improve the group recommendation process, we decided to study the different behaviors that people have in conflict situations according to their personality. In Recio-Garc  X   X a et al. [2009] we presented a method for recommendation to groups that distinguishes among the different types of individuals according to their personality.
After evaluating the different behaviors that people have when carrying out a decision-making process according to their personality, we decided to study how trust among group members will affect the recommendation process for a group. To do so, we analyzed the social factors that could reflect the trust among users.

Once we can characterize the personality of group members in conflict situations and the trust among these members, we can integrate these factors in the recommendation process. Our group recommendation method is based on the preference aggregation approaches most commonly used [Masthoff and Gatt 2006; O X  X onnor et al. 2001], which aggregate the users individual predicted ratings to satisfy the greatest number of members. Therefore, the basic building block of our group recommender is an individual recommender that predicts the preferences for a given user. However, we bias the individual predictions with the personality and trust features of the user.
The individual recommender implements the collaborative filtering algorithm de-scribed in Kelleher and Bridge [2004]. We have chosen this algorithm because it is broadly used to recommend items when the modeling of user preferences is not a valid option (as in most of real scenarios [Linden et al. 2003; Schafer et al. 2007; Sarwar et al. 2001]). This algorithm requires users to rate an initial set of items. Then, those ratings are used to estimate the predicted rating for an unrated item. The algorithm runs as follows: First, it weights all users with respect to the similarity with the active user by computing the Pearson Correlation coefficient. 1 Next, it selects a set of the most similar users as a set of predictors. Finally, it normalizes the ratings and computes a prediction from a weighted combination of selected predictors X  ratings. This individual recommender returns an estimated prediction pred ( u , i )forauser u and a given item i .
In our approach, the ratings predicted by the individual recommender are combined to obtain the predicted scoring of the item i for the group. A common way to combine average function [Masthoff 2004]: Here G is a group of users, which user u belongs to. This function provides an aggre-gated value that predicts the group preference for a given item i . Using this average function, our group recommender proposes the set of k items with the highest group pre-dicted scoring. The average aggregation strategy has been successfully applied in many recommenders like Intrigue [Ardissono et al. 2003], Travel Decision Forum [Jameson 2004] or YuTv [Yu et al. 2006], so we have chosen it as our baseline.

Our group recommendation strategy employs the basic average function using mod-ified individual predictions that include personality and trust factors.
The improvement in the accuracy of the group recommender against the baseline recommender mainly depends on the way we compute the new pred ( u , i ) values using the personality and trust values. Following sections will describe how we compute the personality value (Section 3.1), the trust value (Section 3.2) and how to combine the individual ratings with these personality and trust factors (Section 3.3). Finally, the evaluation of that improvement is detailed in Section 5. Our proposal characterizes people using the Thomas-Kilmann Conflict Mode Instru-ment (TKI) [Thomas and Kilmann 1974]. TKI is a test designed to measure the behavior of people in such situations. It is a leading instrument in conflict resolution assessment that is often used by Human Resources and Organizational Development consultants to facilitate learning about how conflict-handling styles affect personal and group dy-namics. This test describes a person X  X  behavior in conflict situations along two basic dimensions: assertiveness and cooperativeness. These two dimensions of behavior can be used to define five personality modes of dealing with conflicts: competing, collabo-rating, avoiding, accommodating and compromising (see Figure 1).

In general terms, the inclusion of personality in the group recommendation process runs as follows: assertive behaviors penalize the differences with the best choice of other members (the other choices do not satisfy her personal concerns), while cooperative behaviors reward the differences with the best choice of other members (it is not her preference choice but it will be good enough for other members and for the group).
To determine the personality, our users fill out the TKI test. It consists of 30 different situations with two possible answers. Depending on the answers, a score is assigned for each personality mode. If a score is below or above the 25 or 75 percentile according to the population, then that user is classified as having a low or high personality mode. This way the test indicates if a user has high or low competitive, collaborative, avoiding, accommodative, and compromising modes. Following the schema shown in Figure 1, if a user has a high competing and collaborative mode she is assigned a high assertive-ness value. High avoiding and accommodating personality modes are considered as low assertiveness. Following the second dimension, a high cooperativeness value is given to a user if it has a high accommodating and collaborating mode. Therefore, the Assertive-ness and Cooperativeness values are a weighted sum of the five personality modes. Details about the calculation of these values are explained in Recio-Garc  X   X a et al. [2009].
Once each user u completes it, we calculate a value that represents how selfish or cooperative she is. This value is the difference between the assertiveness and coopera-tiveness of the user. We call this value the Conflict Mode Weight and it represents the predominant behavior for that particular user according to her TKI evaluation. For the sake of simplicity, we will use p u to refer the conflict mode weight of user u ,asthis value summarizes her personality.

The p u factor is computed using the following equation:
We note that people with strong personalities have a high p u value, while a low p u value represents an easygoing personality. The p u value fits in a range of [0,1], 0 being the reflection of a very cooperative person and 1 the reflection of a very selfish one. Social network users post on their profiles a huge amount of personal information that can be analyzed to compute tie strength with other users: likes and interests, personal information, pictures, games, etc. [Golbeck 2006a; Gilbert and Karahalios 2009]. These factors are characteristic of personal social networks and they cannot be extrapolated to other kinds of networks [Wu et al. 2010]. However, previous works have reported that trust and tie strength are conceptually different but that there is a correlation between them [Levin et al. 2004]. For this reason, we decided to employ a set of ten different factors for computing the tie strength, which we will employ as a measure of trust between two users u and v in a given group. [Granovetter 1973] defines the strength of a tie as a (probably linear) combination of the amount of time, the emotional intensity, the intimacy (mutual confiding), and the reciprocal services that characterize the tie. The literature reviewed identifies these four factors as some of the major dimensions of predictive variables. With these dimensions as a guide, Gilbert and Karahalios [2009] identified 74 Facebook variables as potential predictors of tie strength. From those 74 we used 10, the ones that were most representative of each of the major dimensions and could also be extracted from any user profile on a social network (for example, inbox messages cannot be read from outside the user account). These factors are the following.  X  f 1 ( u ,v ): Distance in the social network. We check if the two users are friends; in case they are not we look to see if they have any friends in common.  X  f 2 ( u ,v ): Number of friends in common. We count the number of mutual friends they have.  X  f 3 ( u ,v ): Intensity of the relationship. We count how often their name appears on each other X  X  walls. This is the number of times that they have posted a comment, they have discussed a publication or they have commented on a picture.  X  f 4 ( u ,v ): Intimacy of the relationship. We classify relationships by finding keywords in their wall interactions. These keywords represent intimacy levels like very affec-tionate, familiar/caring, friendly, work-related, or casual.  X  f 5 ( u ,v ): Duration. We calculate how long they have known each other. To do so we read their own age and contrast it with the information related to schools, universi-ties, work, family relations, etc.  X  f 6 ( u ,v ): Reciprocal services. We count the number of videos/songs/webs posted on each others walls and we also count the games/applications shared (like Pet Society,
Mafia wars, Music challenge, among others).  X  f 7 ( u ,v ): Structural variable. We count the common interests described in their profile, like movies, books, or general interests. We also count how many groups they have both joined or become fans of.  X  f 8 ( u ,v ): Social distance. We count how many of the following sections in their personal information are shared: political beliefs, school/universities, religious beliefs and demographical situation.
  X  f 9 ( u ,v ): Status. We read the information about the relationships between users, like  X  X amily X  or  X  X elationship status. X   X  f 10 ( u ,v ): Pictures. We compute the percentage of pictures where they appear together. Some of these factors can be easily obtained from social networks. For example, Facebook directly provides the information required by factors 2, 9, or 10. However, other factors require extra analysis of the social network. More specifically, there are some factors, like privacy, that require the processing of the messages exchanged. Here, common Information Extraction techniques can be applied to extract the keywords that identify the nature of the text.

Once we choose the different factors involved in the computation of social trust, we must combine them to obtain a final value. Previously described factors may have a different impact on the recommendation process, so we have decided to combine them using a weighted average:
Note that t u ,v  X  [0 , 1]. We have measured the importance of every factor w k by using an experimental approach. The case study presented in Section 5 shows how these factors are weighted to maximize the accuracy of our recommender. The next step refers to the inclusion of personality and trust factors in our group recommendation process. As described in Section 3, our aggregation function com-bines the modified individual rating predictions pred ( u , i ) of each group member (see Equation (2)). We propose three different approaches to computing pred ( u , i ). These formulas combine individual ratings (predicted by the individual recommender) with the personality and trust factors.

The following methods (more concretely, delegation-based and influence-based pre-diction methods) take several ideas from the social sciences. One is emotional contagion : the influence of an individual X  X  affective state on that of others in the group [Masthoff and Gatt 2006; Hatfield et al. 1994; Barsade 2002]. Another important social aspect is conformity [Deutsch and Gerard 1955], whereby judgements are influenced by those of others. It means that individuals may probably give in because they trust other people X  X  judgement more that their own. Therefore, conformity may cause individuals to change both their public and private opinions. Next, we will detail our proposed methods. 3.3.1. Personality-Based Rating Prediction. The Personality based rating approach takes into account the differences in personality between pairs of individuals in the group. It is based on the modified average satisfaction employed in our previous work [Recio-Garc  X   X a et al. 2009]. This strategy reflects that assertive characters will have more influence in the aggregated scoring than cooperative characters. This factor is computed as the distance of the personality values. Our approach uses the type of personality to weight the influence of user ratings during the recommendation process. If we consider pred ( u , i ) as the individual rating predicted by the collaborative recommender for a given user u and a certain product i , the following equation computes personality-based rating prediction ( pbr ( u , i )):
In this equation, | G | represents the number of components in the group and this value is used to normalize the result. p u and p v are the conflict mode weights of users u and v . Note that the difference between p u and p v will boost the pred ( u , i ) prediction if the per-sonality of user u is stronger than user v . Otherwise, the predicted value is decreased. 3.3.2. Delegation-Based Rating Prediction. Delegation-based rating prediction is inspired by an approach previously described in Golbeck [2006a], where individual prediction is based on the estimated rating of other users. The idea behind our method is that users create their opinion based on the opinions of their friends. The average of these opinions is weighted depending on the level of trust with every friend. Additionally, the personality of every friend is also taken into account, thus modifying the base opinion. The delegation-based rating approach tries to simulate the following behavior: when we are deciding which item to choose within a group of users we ask the people who we trust. Moreover, we also take into account their personality to give a certain importance to their opinions (for example, because we know that a selfish person may get angry if we do not choose her preferred item).

Delegation-based rating prediction ( dbr ( u , i )) given an user u and an item i is com-puted in the following way:
In this formula, we take into account the estimated rating pred ( v, i ) for every individual v for the i item. This prediction is increased or decreased depending on her this formula is not normalized by group size and it uses the accumulated personality. This is the way it was originally described in Golbeck [2006a]. Therefore, this formula (and the one proposed next) could return a value out of the ratings range. This is simply managed by the recommender by choosing the closest value within the valid range. 2 3.3.3. Influence-Based Rating Prediction. Influence-based rating prediction simulates the influence that each friend has in a given person. This approach supposes that the user may modify her preference for an item depending on the rating given by her friends to the same item. For example, if our rating for an item is 3 and our friend has a 5 rating for the same item, we could think of modifying our rating to 4. Depending on the trust with this friend, we decide the level of variation for our rating (i.e. 3.5 if the trust is low, and 4.5 if trust is high). Furthermore, the variation of our rating also depends on our personality. If we have a strong personality we will not be willing to change our rating, but if we have a weak personality we could be easily influenced by other users. By combining both factors we get the following formula: pred ( u , i ) = ibr ( u , i ) = pred ( u , i ) + (1  X  p u )
In this formula, the individual rating prediction for the item ( pred ( u , i )) is modified according to its difference with the ratings predicted for other users ( pred ( v, i )  X  pred ( u , i )). This difference takes into account the trust between users ( t ,v ). Finally, the accumulated difference is weighted according to our personality in a complementary way (1  X  p u ). Until now we have focused on the specific situation where the recommender makes a recommendation just once. But frequently, a group will expect to use the system several times, thereby getting a bigger sample of recommendations. However, these novel recommendation techniques will always tend to favor the same users (because they have stronger personalities or because they are closer to each other). Therefore, we could end up with a situation where we have some dissatisfied users because we take their opinions less into account for the group X  X  sake. In order to avoid a situation of high dissatisfaction levels in the group, we should take a certain degree of fairness into account. For example, we could face a situation where a certain recommendation is very promising for the group in general, but one of the users could end up very dissatisfied with this recommendation. It would be desirable that future recommendations would favor this component of the group so that she could reach a proper level of satisfaction. To address this issue, we propose the use of a memory of past recommendations. Having recommendations with memory means that we are able to create a system that remembers all the previous recommendations for a given group. We believe that this is a necessary step when providing a whole set of fair recommendations. This way, if one member accepts a proposal that she was not interested in, next time her preferences will be prioritized in the recommendation process. This means that her opinion will have a higher weight next time. These weights will also be influenced by the different personalities of each group member as we applied in Section 3.1. For example, someone with a strong personality that has been negatively affected would be immediately compensated next time; however someone with a mild personality would not have problems giving in several times.

The process that we have followed is very similar to the Case Base Reasoning (CBR) cycle [Aamodt and Plaza 1994], sketched in Figure 2. CBR is a successful and estab-lished methodology in Artificial Intelligence that has inspired us in the implementation of our recommender with memory. In our system each recommendation provided by the group recommender will be stored as a new case that can be used later to improve the next recommendation. This fact corresponds to the retain phase in the CBR cycle. This way, we acquire the experiences that will be useful for the resolution of future recommendations because we will know which products have been recommended to a group. We also store how satisfied each member of the group is with this recommenda-tion, so we are able to adjust the satisfaction factor in future recommendations. Before making the following recommendation we will check the previous situation, which in the CBR cycle would be the retrieve phase . Once we obtain that information we can perform a new recommendation, while taking into account what we have retained (the products that we have already recommended and how satisfied each of the member of the group is). This is equivalent to the reuse phase in the CBR cycle. Last but not the least, we will modify the recommendation so that the products proposed are not repeated and so that we can assure a certain degree of fairness when we benefit the preferences of each user. This last phase, the revise one, closes the CBR cycle.
The following formulas reflect these concepts, the first one applied to the delegation-based rating prediction method and the second one to the influence-based rating pre-diction method. These formulas include a factor s v that reflects the level of satisfaction of the user v with the previous recommendations. Note that here we always take into account both the personality and trust factors because they return better results than including them separately (as we will show in Section 6). ibrm ( u , i ) = pred ( u , i ) + (1  X  p u )
The satisfaction value s v is the level of satisfaction of a user v . A user who is extremely happy with the recommendations will have this satisfaction measure value close to 1. However, the more upset with the recommendations she is, the more that this value will decrease, reaching 0 in the worst case. The computation of this value is detailed in Section 5.5, but in general terms it sorts all the items according to user preferences and checks the position of the item selected for the group. This position is inversely correlated to the s v value. Parameter  X  has been experimentally selected, and it is used to modify the impact of the use of memory in the modified rating. Moreover, the satisfaction value is weighted depending on the users personality to reflect the importance of satisfying that concrete user. Once the recommendation process has finished the s v value is updated for every user. The computation of the s v value will be described in Section 5.5, although in general terms it is updated every time a user gets a recommendation according to her preference for the item selected by the group.

It is important to note that the methods described in Equations (8) and (9) use the satisfaction of other users s v instead of the target user u to obtain a predicted rating. The use of group satisfaction is based on some results from organizational behavior and social psychology that have highlighted the concept of emotional contagion [Masthoff and Gatt 2006]. This social aspect states that the satisfaction of an individual is likely to depend on that of other individuals of the group [Barsade 2002; Hatfield et al. 1994].
Next we explain how these factors would be taken into account in a real group. For example, Peter, John, and Mary go together to the cinema for the first time. Peter and Mary are both very stubborn and they have strong personalities (for example, they have a p Peter = p Mary = 1), whereas John is very accommodating and has a mild personality (being p John = 0 . 2). Initially they all have the same level of satisfaction; this means that s = 1 for all of them. As this is the first time that they go to the cinema together, they do not have a history together so the satisfaction levels will not be taken into account. As they all have a satisfaction value of 1, the second part of the equations explained before (Equations (8) and (9)) is canceled. It means that  X   X  (1  X  s v )  X  p v = 0. Therefore the recommendation process is the same one that we have applied previously when we did not take into account either the satisfaction or the history; these equations correspond to the original processes based on delegation or influence (Equations (6) and (7)).
As a result of this process our users will be provided with a recommendation. For simplicity, we are going to focus on the best three movies that the recommender has found for the group ( Amovie, Bmovie, and Cmovie ). Let X  X  suppose they choose to watch the movie Amovie . Once we have their feedback we store the movie selected and we update the values that measure the level of satisfaction s v . To recalculate these sat-isfaction values we check the rating given by the each users individual recommender to the actual movie selected by the group. If this movie would never be recommended individually to the user, the value of satisfaction will be very low. On the other hand, if the movie would indeed be recommended individually to the user, the value s v will still be near 1.
 Lets say that Peter, who has a very strong personality, is especially dissatisfied and John, the one with the mild personality, is also dissatisfied with the recommendation, so their discontent values are updated to s Peter = 0 . 2and s John = 0 . 4, respectively. The calculation of the discontent values after each recommendation is based on how many movies preferred by the user appear in the movie list proposed by the group recommender. This process will be detailed in Section 5.5. This way, Mary will be very happy because she has managed to watch the movie that she wanted, so her satisfaction value is still s Mary = 1.

The next time that they go to the cinema together, Mary X  X  opinion of the movie will only be influenced by the trust she has in her friends and by her own personality, which for example is reflected in the delegation-based method with t u v ( pred ( v, i ) + p v ). The same fact happens to the opinions of Peter and John. However, as they were not satisfied last time, their opinion will have an increment because their level of discontent is being added in proportion to their personalities (through the  X   X  (1  X  s v )  X  p v factor in the equations). In the particular case of Peter the increment in his rating will be higher because p Peter p John  X  X s we said, p is higher when the personality is more conflictive and lower when it is more cooperative. Peter is also more dissatisfied than John, so his opinion will have a higher impact (at this moment s Peter = 0 . 2and s John = 0 . 4).
Memory-based algorithms provide a new set of item score predictions by taking into account these factors. However, the memory of past recommendations is also used in another, different way. Once the users have decided on the movie they are going to watch together, it is included in the memory of the recommender. Therefore, if the recommender proposes a movie that they have already seen (because it has a high predicted score), it is automatically rejected and the next best movie will be the recommended one.

The levels of discontent and the database of the movies watched are updated each time we get the feedback from our users. The next time that this group wants to go to the cinema together the process will start all over again with the satisfaction levels and the set of movies watched stored in the system. We can see the diagram of this process of recommendation with memory in Figure 3.

Another important issue about this approach is the scope of the memory of user satisfaction. We can update the s v value to reflect the satisfaction according to the last immediate group recommendation or to take into account previous ones. Therefore, the satisfaction value for an execution e of the recommender may depend on the satisfaction of the user with the items recommended in e  X  satisfaction ( v, G ) X  but it also depends on her satisfaction in the previous recommendation e  X  1, as reflected in the following equation: In this equation we use the  X   X  [0 .. 1] parameter to adjust the impact of previous satisfaction when updating that value. The details about this process are provided in Section 5.5.

Now that we have finished the exposition of the theoretical algorithms we will next present a case study that validates our proposals. Now that we have described our proposal, we will evaluate our algorithms using the movie recommendation domain. We chose this domain because it is a very accessible field with several datasets available and, more importantly, easy to query about to users. The specific goals of our experiments are:
G1. To study the influence of personality and trust factors in the recommendation by comparing the results obtained by the proposed algorithms: personality-based rating prediction (PBR), delegation-based rating prediction (DBR) and influence based rating prediction (IBR).

G2. To measure the robustness of the recommenders based on the proposed algo-rithms in comparison with the group size.

G3. To determine if the recommenders based on the proposed algorithms are biased by group homogeneity, according to the individual personalities.

G4. To determine if the recommenders based on the proposed algorithms are biased by the trust strength of the group, according to the trust between group members.
G5. To study the improvements obtained by including memory capabilities in the proposed algorithms.
 In order to perform our experiment in the movie recommendation domain, we created two events in two different social networks, Facebook 3 and Tuenti. 4 Fifty-eight real users participated in our experiment.

During the experiment we employed the following instruments.  X  TKI . It is a personality test [Thomas and Kilmann 1974] with 30 items. This test is used to obtain a personality profile about the way a person deals with conflict.  X  Movie listing . A list of 15 recent movies (of year 2009), which represents a movie listing from a cinema. This movie listing was chosen heterogeneously from movies from the MovieLens dataset [Bobadilla et al. 2009].  X  Movies to rate . A list of 50 movies selected from the MovieLens dataset.
The experiment was carried out as follows. (1) Every user completed three different questionnaires 5 The answers to these ques-(2) We have computed the trust value t u ,v for every pair of users with the factors (3) We have managed to form groups of users. Afterwards, we asked each group to (4) We have implemented a set of group recommender systems that follow the previ-(5) We have employed the recommenders to provide a list of recommended movies for (6) The real group favorites lists rgf G and the group favorite lists gf G have been com-
Finally, we performed an additional experiment with a recommender system based on memory. The details of this experiment are described in Section 5.5. The aim of the evaluation is to compare the results of our recommender system to the real preferences of the users (that is, what would happen in a real life situation). This evaluation has some particular features that must be taken into account. First, we are not interested in a long list of ordered movies when estimating the movies a user or group should watch. As we have previously explained, real users are only interested in a few movies they really want to watch. This fact discards several evaluation metrics that compare the ordering of the items in the real list of favorite movies and the estimated one. On the other hand, the number of relevant and retrieved items in our system is fixed. Therefore, we cannot use general measures like recall or precision. However, there are some metrics used in the Information Extraction field that limit the set retrieved. This is the case of the precision@n measure, which computes the precision after n items have been retrieved. In our case, we can use the precision@3 to evaluate how many of the movies in gf G are in the rgf G set (note that | rgf G |= 3). This kind of evaluation can be seen from a different point of view: we are usually interested in having at least one of the movies from gf G in the rgf G set. This measure is called success@n and returns 1 if there is at least one hit in the first n positions. Therefore, we could use success @3 to evaluate our system by computing the rate of recommendations where we have at least  X  X ne-hit X  in the real group favorites list. For example, a 90% accuracy using one-hit means that the recommender suggests at least one correct movie for 90% of the groups evaluated. In fact, success @3 is equivalent to having precision @3 &gt; 1 / 3. We can also define a  X  X wo-hits X  metric (equivalent to precision @3 &gt; 2 / 3), which represents how many times the estimated favorites list gf G contains at least two movies from rgf G . Obviously, it is much more difficult to achieve high results using this second measure. Next we compute the trust factor t u ,v using the factors detailed in Section 3.2. More specifically, we use the following concrete trust factors. We must note that the thresh-olds and specific values have been experimentally obtained by analyzing the profiles of the users that took part in our experiment. 6  X  f 1 ( u ,v ). Distance in the social network: 1.0 if direct friends, 0.5 if friend of a friend and 0.1, otherwise.  X  f 2 ( u ,v ). Number of common friends:  X  f 3 ( u ,v ). Intensity of the relationship: how often they write each other on their walls.  X  f 4 ( u ,v ). Intimacy of the relationship: We classify relationships by finding key-words that represent the following intimacy levels: very affectionate, familiar/caring, friendly, work-related, casual, or none.  X  f 5 ( u ,v ). Duration: how long they have known each other.  X  f 6 ( u ,v ). Reciprocal services: number of videos/songs/webs posted. In Facebook we also count the games/applications (like Pet Society, Mafia wars, Music challenge, among others) shared.  X  f 7 ( u ,v ). Structural variable: common interests described in the profile like movies, books, or general interests. From Tuenti we also count the places they go partying, and from Facebook how many groups they have joined or become a fan of.  X  f 8 ( u ,v ). Social distance: how many of the following properties are shared: political, educational, religious and demographical information.  X  f 9 ( u ,v ). Status: this value depends on the kind of status: couple (1.0), family (0.7), best friends (0.5), friends (0.3), barely know (0.1).  X  f 10 ( u ,v ). Pictures: Percentage of pictures where they appear together.
The final trust value t u ,v is a weighted average of the previous factors, as described in, Equation (4). These weights have been experimentally obtained using our group recommendation strategies by means of a genetic algorithm (GA). Our GA manages a population of vectors of weights ( w k ). These vectors are combined and mutated in order to maximize the fitness function. We have used two different fitness functions accord-ing to the strategies described in Section 3.3: delegation-based rating prediction and influence-based rating prediction. Therefore, the individuals of the GA population (vec-tors of weights) are used to compute the trust factor t u ,v required by these approaches. This fitness function is evaluated using the one-hit measure. This evaluation approach lets us explore a huge number of weights and obtain the best combination for each group recommendation algorithm. The optimal combination of weights found by the GA is shown in Section 6. The construction of the recommender runs as follows. First, we build an individual movie recommender using the jCOLIBRI framework [Recio-Garc  X   X a et al. 2008]. jCOLIBRI is currently a reference platform in the Case-Based Reasoning (CBR) community that facilities the design of different types of CBR applications, and it has a specific extension for developing recommender systems. The individual recommender follows the collaborative filtering approach described in Kelleher and Bridge [2004] based on the Pearson Correlation. It uses ratings extracted from the MovieLens database plus the ratings obtained from the second questionnaire completed by our volunteers. We select those MovieLens users who have rated at least 15 movies from the Movies to rate list and more than 3 from the Movie listing . The individual recommender returns a sorted list of movies that a user should watch individually. This list cif is a complete estimation of the users preferences for a given movie listing. However, in practice, only the first elements of this list should be taken into account because they are supposed to reflect the movies a user wants to watch (for example, we are not interested in the 12th movie the user prefers). Therefore, we select the three movies with the highest scoring and refer to this list as the individual favorites if u of auser u . This if u list can also be evaluated with the one-hit and two-hits measures previously detailed as, again, we are not interested in the exact order of these movies but are concerned with the inclusion of these movies in the set of movies selected for the group.

The next step is building the group recommender system. Each version of this rec-ommender applies a different algorithm proposed in this article.
  X  Base . This is a standard group recommender using the average satisfaction aggre-gating function (Equation (1)). It is the baseline to measure the accuracy of our algorithms.  X  Personality . It only uses the personality values and it implements the Personality-based rating prediction (PBR) approach (Equation (5)).  X  Trust-DBR . It implements the delegation-based rating prediction (DBR) algorithm proposed in Equation (6), but it only takes into account the trust values t u ,v ( p u values are set to 0).  X  Trust-IBR . It implements the influence-based rating prediction (IBR) algorithm pro-posed in Equation (7). Again, this recommender only takes into account the trust values t u ,v ( p u = 0).  X  TP-DBR . This is the full Trust+Personality DBR algorithm (Equation (6)).  X  TP-IBR . This is the full Trust+Personality IBR algorithm (Equation (7)).
The Personality, Trust-DBR and Trust-IBR recommenders let us explore the impact of both factors  X  X ersonality and trust X  independently. Then, the TP-DBR and TP-IBR are supposed to improve their results (as it is described in Section 6). We also performed an experiment with a recommender system based on memory. We implemented this recommender by using the dbrm and the ibrm methods, described in Section 4. In these experiments, we assigned  X  = 1 . 0 to simplify the comprehension of the results.

The evolution of user satisfaction over time is obtained by using the formula shown in Equation (10). We configured  X  = 0 in our case study to get a clearer picture of the impact of satisfaction. However, we plan to perform further experiments to analyze the consequences of this parameter.

To calculate user satisfaction we compare the gf G list to the estimated individual favorite movies for that user. That is, on one hand we have the list of predicted movies that a user wants to watch individually, and on the other hand we have the list of movies recommended to the group. Therefore, we can compare both lists to estimate the users satisfaction.

Regarding the list of predicted movies that a user wants to watch individually we could use the if u list. However this list only contains the first 3 movies with the highest scoring. If we compare this list to gf G we get very low values of satisfaction (because the intersection between the two lists will probably be empty). To avoid this problem, we use the complete list of movies returned by the recommender ( cif ). This list contains the estimated scoring of every movie for a concrete user. As we have used a movie listing of 15 movies, it is the size of cif and it reflects the user preferences in order. We used this complete list because it enables us to evaluate the approach by means of the Expected Search Length (ESL) measure [Cooper 1968]. This measure assumes that the ordering of the target items is not relevant (it is a  X  X eak ordered set X ) and it counts the number of nonrelevant items that a user would find until she finds a target number of relevant items. This is the case of a user when she observes the list of three movies proposed to the group ( gf G ). Users expect that the movies recommended to the group will be their individual favorites; that is, they are as high as possible in her individual favorites list ( cif ). The user does not mind the order they appear in her individual favorites list but will be more satisfied when those movies are in the first positions of her list. And this behavior is captured by the ESL measure. Moreover, this measure has the advantage of combining precision and recall, which cannot be applied here as we have a fixed retrieval set.

The satisfaction value is obtained through Equation (11): It is worth noting that in our experiments we consider that each user begins with the highest level of satisfaction ( s u = 1 . 0) and also that this satisfaction measure is different for each user with each of the groups that she belongs to. We store these measures separately as a user can be very pleased with the decisions of one group and, on the other hand, dissatisfied with the decisions of another group.

Our goal is to maximize average satisfaction (  X  S ) while minimizing the differences in satisfaction levels within the group. These differences are computed by using the standard deviation (  X  S ), which measures the uniformity of the satisfaction levels.
Therefore, the formula used to obtain the global satisfaction of the group ( gs ( G )) runs as follows: where S represents the set of satisfaction levels of every user in G .

This equation includes two parameters (  X  and  X  ) that could be used to weight the impact of both factors (average value and uniformity). Experiments are configured with these parameters set to 1, giving the same importance to the average level of satisfaction and the uniformity of these values. Our goal is to obtain very satisfied users (the best possible situation being an average of 1) and users who are equally satisfied (being the best situation a standard deviation of 0).

Finally, note that we store in our memory each movie chosen by the group from the proposed list ( gf G ). If the recommender proposes a movie that has been previously chosen it is automatically rejected.

Once we have described the case study, the next section details the results obtained. Group recommendation approaches presented in this article are based on an individual recommender. This individual recommender is only used as a basic building block for group recommenders so we are not interested in improving its performance. However, we must remark that any improvement in this system will lead to an improvement of the whole system, as the group recommender system is based on each users individual preferences. The individual recommender obtains a hit rate of 58,6% using the one-hit evaluation metric and 13,79% for the two-hits metric.

Figure 4 shows the performance of our group recommenders using the one-hit and two-hits evaluation metric. A chi-square test (p = 0.05) was employed to test the accu-racy of fit for each recommender. This test verifies whether the results obtained by our recommenders differ significantly from a randomly generated recommendation. It shows that the Base (  X  2 = 4 . 7115, df = 1, p-value = 0.02996), Personality (  X  2 = 4 . 7115, df = 1, p-value = 0.02996) and TP-DBR (  X  2 = 10 . 2671, df = 1, p-value = 0.001354) recommenders obtain significant results. The results obtained by the TP-IBR recom-mender are weakly significant (  X  2 = 2 . 735, df = 1, p-value = 0.09817, with p = 0.1). However, the hit-rate obtained by both recommenders based only on trust  X  X rust-DBR (  X  2 = 0 . 3846, df = 1, p-value = 0.5351) and Trust-IBR (  X  2 = 1 . 2927, df = 1, p-value = 0.2555) X  does not differ significantly from a random recommendation.

The most promising results are achieved by the TP-DBR recommender. It obtains the highest hit rate not only with the one-hit metric but also with the two-hits. The rec-ommender based on Personality gets similar results to the Base recommender with the one-hit metric but it obtains up to 20% with the two-hits metric. The worst results are obtained when considering only the trust factors during the recommendation (Trust-DBR and Trust-IBR). None of these recommenders beat the Base recommender in the one-hit metric, although the Trust-IBR approach has slightly better results with the two-hits metric. As we explained in Section 5.2, the two-hits evaluation metric is more difficult to achieve than the one-hit, and that is why we can see more abrupt changes in the two-hits than in the one-hit. The better the recommendation technique is, the higher the value of the two-hits measure is. The base recommender gets a 0% for the two-hits metric. The Trust-DBR algorithm does not improve the Base recommender. However, the Personality algorithm improves the Base, obtaining a 20%. The best recommender, TP-DBR, obtains 30% using the two-hits metric. The results obtained using Delegation-based approach differ from those obtained using the Influence-based approach. We can see that the Influence-based version works better than the Delegation-based one when taking into account just trust (Trust-IBR &amp; Trust-DBR). However, when dealing with personality and trust it means a great improvement in the Delegation-based method, but not so much in the Influence-based method (TP-DBR &amp; TP-IBR).

As stated in Section 5, we deal with groups of different size in order to evaluate the influence of the group size on the recommender. Figure 5 summarizes the results according to group size. Most of the recommenders achieve their best results with small groups (size = 3) as it is easier to find good items for such kinds of groups. The worst results are obtained by the Trust-IBR recommender, with only a 60% hit rate using the one-hit metric. The results get worse as the group size increases for the Base and Trust-DBR recommenders. These three recommenders follow a monotonic decrease that is explained because they have proven to be the worst recommendation strategies. Therefore, as group size grows, and it gets harder to find a good recommendation, their behavior gets worse. However, we do not notice this trend in other strategies. The Personality recommender decreases the hit rate with medium-sized groups (size = 5) but it obtains similar results with large groups (size = 9), around 70% accuracy. The TP-IBR achieves the best results for medium-sized groups but it goes down sharply with large groups, with only a 25% hit rate with the one-hit metric. These irregular behaviors should be studied in further experiments. However the most feasible explanation for the TP-IBR strategy is that taking too many influencers into account adds a lot of noise to the predicted ratings, although with a medium number of them this influence is a positive factor. On the other hand, the TP-DBR recommender is the most robust to changes in group size. It is one of the best recommenders for medium-sized groups (excluding the irregular Trust-IBR) and it remains the best with large groups, obtaining a 100% hit rate. As this strategy modifies personal predictions according to other users X  preferences, we think it maximizes the average satisfaction of every member of the group, thus explaining its excellent performance.

The analysis of group homogeneity according to individual personalities is displayed in Figure 6. Homogeneity is evaluated by using the variance of personality ( p u )inthe group. To study the impact of group homogeneity we have classified user groups into two categories: uniform and nonuniform . A uniform group has low variance, whereas a group with high variance is considered to be a nonuniform group. The threshold to determine when variance is low or high was computed by using the median of variance for all the groups in the experiment.
 The results stress that most of the recommenders work well with uniform groups. Again, the worst results are obtained by the recommenders based only on trust, with a 75% hit rate with the one-hit metric. It is worth highlighting that the best results with nonuniform groups are obtained by the TP-DBR recommender with a 90% hit rate. This is almost 20 points more than the Base and Personality recommenders and more than 25 points when compared to the recommenders using IBR. Finally, note that in uniform groups p u  X  p v ; therefore, Equation (5) collapses to Base, which explains the high performance of the personality pbr method.

These results align with the ones described in Baltrunas et al. [2010], where the authors study the effects of group size and homogeneity on group recommendations. The authors state that the effectiveness of group recommendations does not necessarily decrease when the group size grows. Moreover, they confirm that the more alike the users in the group are, the more satisfied they are with the group recommendations.
Additionally, we analyzed the recommender hit rate in comparison with the global trust strength of the group. This trust strength is the average of the trust between each pair of group members. As we did with personalities, we employed the median of trust strength for every group that participated in the experiment as the threshold to split global trust strength into high trust strength and low trust strength. Figure 7 summarizes this analysis. Surprisingly, the worst results in groups with high strength are obtained with the recommenders based only on trust (Trust-DBR and Trust-IBR). It leads us to think that trust must be combined with personality to obtain a general improvement in accuracy and is not a significant factor by itself. Both DBR and IBR strategies are rooted in the idea that users may modify their preferences to please close friends. If so, Trust-DBR and Trust-IBR should achieve higher performance. These results show that this premise is not completely realistic, leading us to think that users could modify their preferences if and only if they do not have a selfish personality. That is the reason why methods mixing personality and trust report better results. When groups have low trust strength results get worse for most of the recommenders except for the TP-DBR and the Trust-IBR. The former again shows the best performance with a 100% hit rate in groups with low trust strength. With these results we conclude that the TP-DBR recommender shows the most robust behavior because it adapts to different group configurations very well, getting high hit rates in all scenarios. However controversial results require further future work.
 Finally, we have compared the results obtained by the two algorithms proposed in Section 3.3 that combine the personality values and the trust factors of group members: DBR and IBR. Figure 8 shows that recommenders implemented using DBR obtain higher hit rates than recommenders based on the IBR approach. Only with medium-sized groups do the IBR recommenders get better results. Again, we think this occurs because a medium number of influences is a positive factor, but having too many people influencing other X  X  preferences is counterproductive. DBR does not show this irregular behavior as it tries to maximize the average satisfaction within the group. In conclusion, we can assume that the DBR approach is more robust for different group configurations than IBR.

Regarding the importance of the factors that conform the trust value, we can see in Figure 9 how they are taken into account in order to maximize the performance of our recommender. These weights ( w k ) are obtained by using the Genetic Algorithm (GA) described in Section 5.3. The most relevant factor is the number of friends in common, followed by the pictures, duration, common interests and status. These five factors almost accumulate 100% of weight (see the cumulative weight in Figure 9) when computing trust whereas the remaining factors are mostly insignificant. This conclu-sion is supported by the diagram of the top predictive variables that was presented by Gilbert and Karahalios [2009] where they show the predictive power of the differ-ent tie strength dimensions and the top three predictive variables for each dimension. The percentages that they achieve are: 32.8% for the Privacy dimension ( the number of mutual friends was one of the top three predictive variables for this dimension), 19.7 % for the Intensity dimension (the number of pictures in common represents this dimension) and in third position, duration with 16.5%.

These weights are the optimal values found for the DBR method. On the other hand, when we perform the study of the optimal weights for the IBR method, we discover that the best one is f 10 (common pictures) with 0.97% significance. We have repeated the experiment after modifying the parameters of the GA (population size, repetitions, etc) to confirm this surprising result and this value always came up high. We can explain it because this factor (the percentage of pictures in common) can summarize many other factors: if two people appear together in a lot of pictures it usually means that they have had a long relationship (duration), they are very close (status), they go together to the same places (interests), etc. In this section we detail the results obtained when including memory capabilities in the recommender systems. During these experiments we execute the proposed algorithms several times and we not only measure accuracy using the one-hit metric but also the global satisfaction of the groups as described in Section 5.5.

In the experiments with memory-boosted recommenders we are not interested in studying the personality and trust factors independently. The results of the recom-menders without memory show that the combination of both factors achieves the best performance. Therefore, it makes no sense to study the impact of personality and trust separately in recommenders with memory. Evaluation is again performed with the one-hit measure.

Figure 10 shows the accuracy results for both algorithms, ibrm and dbrm , using the one-hit metric. The ibmr algorithm has a very good initial performance. However, as long as we repeat its execution, the proposed recommendations are worse; that is, the hit rate of the recommender goes down. The dbmr follows a similar behavior. This situa-tion is coherent because we are giving priority to the long-term satisfaction of everyone in the group when proposing a movie, instead of maximizing the individual preferences for that particular movie. Here, the algorithm tries to take into account the opinions of dissatisfied users, although their preferred movies are not a good recommendation for the group as a whole.

According to the global satisfaction of the group, we can observe in Figure 11 the evolution of the gs function (Equation (12)). In both algorithms global satisfaction tends to rise (or, at least, does not decrease) when we perform the few initial recommendation to the group. Therefore, this experimental result prove our hypothesis that a memory of past recommendations can improve user satisfaction. We observe that satisfaction tends to decrease after the 4th recommendation. The reason is that during the exper-iments we do not change the movie listing. This way, the more recommendations we make, the less interesting movies we leave for the next recommendation (individually or in groups). This problem could be fixed by changing the movie listing after several recommendations, an experiment that we intent to perform soon.

We also evaluated the option of penalizing those users who were especially satisfied with one recommendation, so that their opinion would have less priority. To achieve this, we simply modified the satisfaction ( u , G ) formula (Equation (11)) to return a value higher than 1 when the individual favorites of the user if u were in the very first positions of gf G (for example, returning 1.2 if gf G are within the first 3 movies in if u ). The results obtained are very similar to the previous ones, so we can conclude that penalizing the users that were especially satisfied with one recommendation does not suppose a relevant change. In this article we have introduced a novel method for making recommendations for groups based on existing techniques of collaborative filtering, and taking into account group personality composition and the structure of the group itself. Once we showed that personality profiles can improve a recommendation for a group of people [Recio-Garc  X   X a et al. 2009], we extended this approach by reflecting the trust relationships between the users in the group in a more realistic way. We propose two approaches, named Influence-Based Rating and Delegation-Based Rating that improve existing techniques by including both the personality and social trust factors in the group recommendation process.

The trust level is measured by using a set of social factors extracted from groups of people connected through social networks. Examples of these social factors are distance wihin the social network; the number of mutual friends, the intensity, intimacy, and duration of the relationship; social distance; and the percentage of pictures where they appear together, among others.

The trust value is computed for every pair of group members by using a weighted average of the social factors. These weights have been experimentally obtained for every group recommendation strategy by means of a genetic algorithm. It gives us a collateral result: the identification of the most relevant social factor for recommenda-tion to groups. The most relevant factor is the number of friends in common, followed by pictures, duration, common interests and status.

Finally, we propose the inclusion of a memory of past recommendations to increase user satisfaction. The use of this memory lets the system increase the importance of the preferences of the most dissatisfied users in previous recommendations. This way, we keep a uniform level of satisfaction for all the users during several recommendations.
We performed an experiment in the movie recommendation domain, using data from MovieLens, and we studied the accuracy of different recommendation ap-proaches for different group compositions. In our experiment we employed 58 real users who participated in two events in two different social networks, Facebook and Tuenti.

We conclude that including only the personality factor in the recommendation process improves accuracy, but using only trust values between the group members does not yield a significant improvement. However, when combining both personality and trust we achieve the best results. We think that by using just the personality factor or just the trust factor we do not have a complete representation of human behavior; we do not have enough information, and thus, we do not get the results that take place in the real world. That is why the recommenders that use these factors in an isolated way do not render a representative difference when comparing their results with the base recommender. However when we combine both factors we manage to represent how discussions take place in real life and how some opinions have more weight than others; that is why the approaches with the combination of the personality and trust improve the base recommender. Delegation-Based Rating has yielded the best approach. With the one-hit evaluation metric we get a rate of hits that is 13.3% higher than the hit rate for the basic group recommender. Moreover, the hardest evaluation measure, the two-hits metric, returns an accuracy of 35% whereas the basic recommender has 0% success in this measure.

We have also studied several features of group composition to measure their impact on the accuracy of the group recommender. According to the influence of group size, the conclusion is that all the approaches work better with smaller groups. It is an understandable fact because with more people there are more diverse preferences and personalities, thus it is more difficult to arrive at a consensual solution. The homogeneity of group personalities is also an important factor as uniform groups get better results. Finally, we studied the impact of trust strength within the group. These results vary depending on the algorithm chosen, although the Delegation-Based Rating method again achieves one of the best results. In general, we can conclude that the Delegation-Based Rating method is the best option for different group compositions as it gets good results for different group sizes and homogeneity levels.

Regarding the inclusion of a memory of past recommendations, the results prove that this feature improves the global satisfaction of users after several recommendations. However, this memory has a negative impact on the performance of the recommender because it suggests items that fit the requirements of very dissatisfied users, instead of proposing the best items for the group.

In summary, we propose several algorithms to recommend items to groups with different sizes and personal preferences. We have proven that by introducing the trust factor, personality awareness and a memory of past recommendations we can improve system performance. Although our approach has been tested in the movie field, it is not specific to this domain and the proposed algorithms could be directly applied to other domains, like choosing restaurants or planning trips.

Our approach can be exploited to develop recommender applications for groups in any social network. According to Facebook X  X  latest statistics, 7 there are 500 million active users and the average user is connected to 80 community pages, groups and events. Therefore, it represents an impressive number of potential users and applications that could take advantage of the methods detailed in the article. In this work we have employed average satisfaction as the aggregation function to generate recommendations for groups. However there are other aggregation functions that can be employed in our recommender. We plan to evaluate the impact of these aggregation functions on the accuracy of our approach.

We studied the behavior of the recommender according to the group size. Moreover, we include an evaluation of the recommendation process in comparison with the ho-mogeneity of the personalities within the group. However, we could also evaluate the system against group homogeneity in terms of their movie preferences. To do so, we need an estimation of the similarity between users that we could obtain from the Pear-son correlation. Additionally, further evaluations are needed in order to corroborate the preliminary results obtained in this work.

Once we analyzed the behavior or recommender according to group size and per-sonalty/preference homogeneity, we were able to combine our results with the ideas proposed in Amer-Yahia et al. [2009] to propose adaptive recommenders, where the recommendation algorithm adapts itself to the personality distribution in the group, its trust strength and its size.

In addition to the trust and personality of group members, there are another factors that could be taken into account during the recommendation process. Cultural aspects or the context where the recommendation is performed may have an impact on the recommendation process. For this reason, we plan to work on how these aspects can influence the rating prediction similarly to the way that we used trust and personality factors, and to evaluate the impact of these new aspects on the group recommendation.
Although the memory of previous recommendations improves user satisfaction, the accuracy of our experiments decreases due to the use of a fixed movie listing. Experi-ments should be repeated with movie listings that are updated for every recommenda-tion. Additionally we plan to perform new studies to analyze the impact of the  X  X emory parameter X   X  from Equation (10) and reflect several degrees of previous satisfaction.
