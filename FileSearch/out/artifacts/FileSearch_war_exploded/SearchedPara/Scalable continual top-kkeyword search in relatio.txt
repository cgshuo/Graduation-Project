 1. Introduction
With the proliferation of text data availabl e in relational databases, simple ways of exp loring such information effectively are of schemas. It has attracted substantial research effort in recent years, and a number of methods have been developed [1  X  10]. In the following, we use the initial of each relation name ( P , A , and W ) as its shorthand. There are two foreign key references: W  X  A and W  X  P . Fig. 1 b illustrates the tuple connections based on the foreign key references. For the keyword query  X  James P2P  X  consisting of two keywords  X  James  X  and  X  P2P  X  , there are six tuples in the database that contain at least one of the two keywords (underlined in Fig. 1 a). These six tuples can all be regarded as the results of the query. However, they can be joined with other tuples according to the foreign key references to form more meaningful results, several of which are shown in Fig. 1 c. The arrows represent the foreign key references between the corresponding pairs of tuples. Finding such results that are formed by the tuples containing the keywords is the task of a keyword search in relational databases. As described later, results are often ranked by relevance scores evaluated by a certain ranking strategy.  X 
Most of the existing keyword search methods assume that the databases are static and focus on answering snapshot keyword queries. In reality, however, a database is often updated frequently, and the result of a snapshot query becomes invalid once the related data in the database is updated. For the database in Fig. 1 , if publication data comes continually, new publication records are inserted into the three tables. Such new records may be more relevant to  X  James  X  and  X  P2P  X  . Hence, after getting the initial top-k results, the user may demand that the top-k results reflect the latest database updates. Such demands are common in real applications. Imagine that you are a member of the quality analysis staff at an international computer seller, and you are responsible for responding immediately to customers  X  complaints collected by customer service offices all over the world.
Customers  X  complaints arrive continuously, and are stored in a relational database. Suppose you want to find the information related to Lenovo ThinkPad laptops, then you issue a keyword query  X  lenovo thinkpad  X  and use one of the existing methods mentioned above to find related information. After reviewing some answers, you may suspect that some arriving claims will also be related to the Lenovo ThinkPad, so you want to search the database continuously using the keyword query. Thus, a continual evaluation facility for keyword queries is essential in such databases. Though various techniques have been proposed for answering snapshot keyword queries, no method is available that can be directly applied to evaluating continual keyword queries in an on-line fashion due to the long time needed for query evaluation.
 the database is being updated continually. When a continual query is issued, it is evaluated in a pipelined pattern by an algorithm updated, an algorithm can maintain the top-k results by efficiently calculating the new top-k results containing the new tuples, result is calculated, by assuming the database is updated within a limited extent. This is because after the database is updated, the usedintheircalculation.Moreover,theupper bound ofrelevance scores of the results that contain a tuple canbecomputed; hence, for addition, to optimize the efficiency of the two proposed algorithms, we adopt the idea of caching to reduce the database access times and reuse the query results; and the idea of clustering to take into account the differences in result patterns. is proposed, and an algorithm which can efficiently handle database updates for maintaining top-k results is presented; (ii) by incorporating the ranking mechanisms into the query processing method, an algorithm which can compute the top-k results for keyword queries in a pipelined pattern is presented; the main techniques used in this algorithm also form the basis of the algorithm for handling database updates; (iii) two optimization methods which can highly improve the efficiency of the proposed algorithms are presented; and finally, (iv) extensive experiments are conducted to evaluate the proposed approach. The rest of this paper is organized as follows. In Section 2 some basic concepts are introduced and the problem is defined. Section 3 presents the details of the proposed method. Section 4 gives the experimental results. Section 5 surveys related work. Finally, in Section 6 we conclude the paper and discuss future extensions. 2. Preliminaries
In this section, we introduce some important concepts for top-k keyword querying evaluation in relational databases, common in most of the existing keyword search systems [4,11  X  13]. 2.1. Relational database model 2.2. Joint-tuple-trees (JTTs)
The results of keyword queries in relational databases are a set of connected trees of tuples, each of which is called a joint-tuple-tree ( JTT for short). A JTT represents how the matched tuples , which contain the specified keywords in their text attributes, are interconnected through foreign key references. Two adjacent tuples of a JTT, t i  X  r ( R i ) and t j  X  r ( R j ), are interconnected if they can be joined based on a foreign key reference defined in relational schema R i and R j in G S (either R R  X  R j ). The foreign key references between tuples in a JTT can be denoted using arrows or notation  X  . For example, the second contain the keywords. Hence, the four JTTs are valid results to the query. In contrast, p 1  X  w 2  X  a 2 is not valid because a 2 matched tuple. The number of tuples in a JTT T is called the size of T , denoted by size ( T ).

Note that although a JTT is not required to contain all the keywords of a query (i.e., we adopt the OR-semantic), the scoring method, which is introduced later, ensures that the JTTs containing all the keywords would have higher relevance scores than those containing only a portion of keywords. The OR-semantic is adopted by all the top-k keyword search studies [4,8].In contrast, the AND-semantic requires each query result to contain all the keywords of a query, and is adopted by the studies aiming to find all the results for a keyword query [2,12,13] . 2.3. Candidate networks (CNs) relation R i with respect to Q is defined as the set of tuples that do not contain any keywords of Q .In Example 1 , P F ={ p 3 keyword query. We use R i QorF to denote a tuple set , which may be either R i Q or R i F .

Each JTT belongs to the result of a relational algebra expression, which is called a candidate network ( CN ) [4,8,15,14] .ACNis obtained by replacing each tuple in a JTT with the corresponding tuple set that it belongs to. Hence, a CN corresponds to a join expression on tuple sets that produces JTTs as results, where each join clause R i QorF  X  R j QorF corresponds to an edge b R i schema graph G S , where  X  represents an equi-join between relations. For example, the CNs that correspond to two JTTs p 2 and p  X  w 1  X  a 1 in Example 1 are P Q and P Q  X  W  X  A Q , respectively. In the following, we also denote P Q  X  W  X  A Q as P Q  X  W  X  A As the leaf nodes of JTTs must be matched tuples, the leaf nodes of CNs must be query tuple sets. Due to the existence of m : n relationships (for example, an article may be written by multiple authors), a CN may have multiple occurrences of the same tuple set. corresponding to the four JTTs shown in Fig. 1 c. A CN can be easily transformed into an equivalent SQL statement and executed by an RDBMS. 1 is firstly computed using full-text indices. Then all the non-empty query tuple sets and the database schema are used to generate the of CNs should be sound/complete and duplicate-free. There is always a constraint CN max , which denotes the maximum size of CNs, to avoid generating complicated but less meaningful CNs. [16] proposed a more efficient CN generating algorithm which can avoid the isomorphism checking of the enumerated CNs. However, even a medium sized database schema graph and a medium value of CN max of CNs in a pre-processing step by assuming that all the relations have non-empty query tuple sets like in [16] . Example 2. In Example 1 , there are two non-empty query tuple sets P Q and A Q . Using them and the database schema graph, if CN max = 5, the generated CNs are: CN 1 = P Q , CN 2 = A Q , CN 3 = P Q  X  W  X  A Q , CN 4 = P Q  X  W  X  A Q  X  W  X  P Q , CN 5 = P Q  X  W  X  A F  X  W  X  P Q , CN 6 = A Q  X  W  X  P Q  X  W  X  A Q and CN 7 = A Q  X  W  X  P F  X  W  X  A Q .
 unrooted tree s according to their definitions. However, in order to achieve high efficiency in evaluating CNs, joins in CNs are always executed in certain specific orders. For example, in [12,13] , CNs are modeled as rooted trees, and joins in the CNs are executed from the leaves to the root. 2.4. Scoring method certain scoring function that will be described below. In the literature, several methods have been proposed for measuring the relevance of keyword search results in relational databases [4,7,8,17] . We adopt the scoring method employed in [4], which is an which is based on the TF-IDF weighting scheme: where t  X  T is a tuple contained in T . tscore ( t , Q ) is the tuple score of t with regard to Q defined as follows: ( average document length )in r(t) , and s (0  X  s  X  1) is a constant which is usually set to 0.2.
 the numbers of tuples of the two relations are 150 and 170, respectively. Therefore, the top-3 results are T 1 = p 2 ( score = 7.04),
T t
Q ). As shown in the following discussion, this property is critical to the existing top-k query evaluation algorithms. 2.5. Continual top-k keyword search De fi nition 1. Continual top-k keyword search instance of G S when a continual keyword query Q is firstly issued. Let S be a scoring method for query results, then the continual relevance scores computed by S for the t-th instance of G S .
 system to have a dynamic database schema. In case the database schema is changed, Q would be regarded as a new keyword query, and the database instance would be regarded as r 0 G S  X  for the new schema S  X  . 3. Continual top-k keyword search in relational databases 3.1. Main challenges and system framework database updates. Thus, we cannot neglect the JTTs that are not the current top-k results,becausesomeofthemmaybecomethetop-k
Another challenge is the shortage of top-k results, which can have two causes: (1) existing results can become expired due to deletions; and (2) the relevance scores of some results are decreased. Since the value k is rather small compared to the huge number of all the valid JTTs in a large database, the possibility of deleting a top-k result caused by one database update is rather small. In addition, new top-k results can also be formed by new tuples. Thus, if the insertion rate is not much smaller than the solution to this problem is to compute the top-( k +  X  k )(  X  k &gt; 0) results instead of the necessary k on query registration. margin value, which makes the top-k results able to stand up to  X  k deletions. Instead of analyzing the update behavior of the underlying database to estimate an appropriate  X  k value, we initially set a small value (=1) for  X  k , and then enlarge it on the top-k results shortage until the frequency of the top-k results shortage falls below a threshold.

On the contrary, after maintaining the top-k results for a long time, the number of computed top results may be larger than because we need to update the relevance scores for more results and join the new tuples with more tuples. As shown in the experimental results, such extra cost is not negligible for long-term database updates. Therefore, we need to reverse the pipelined query evaluation if there are too many computed top results.

In summary, the main features of our continual top-k keyword search system are summarized below: 1. An upper bound of the relevance score, denoted as score u , for every query result is calculated, by assuming the database is updated to a limited extent. 2. When a continual query Q is issued, it is evaluated using the proposed LP (Lattice Pipeline) algorithm in a pipelined pattern to are with score u &gt;  X  , the pipelined evaluation process is suspended. recomputed if the database update limitation is violated. Then, the JTTs that are with score u &gt;  X  are computed and the expired results are deleted. Note that the newly computed results contain not only the JTTs formed by the new tuples, but also some
JTTs whose score u are enlarged due to the re-computation of score u . back if the above number is much bigger than ( k +  X  k ). 5. At any time, the k found results which are with score  X   X  and have the k highest score s are the top-k results.
In the following, we will discuss how to implement the above features. Although the main life-cycle of a continual top-k keyword query is processed by the Maintain algorithm, which handles database updates for maintaining the top-k results, the LP when Q is first issued) needs to be computed first; and (2) the main techniques used in LP form the basis of the Maintain algorithm; and algorithm LP needs to be called in algorithm Maintain when the top-k results are insufficient. 3.2. Computing upper bounds of relevance scores we can derive the upper bound of the future tuple score for each tuple t as: avdl values are below their upper bounds. Then at each time of exceeding any ln u N df enlarged until the frequencies of exceeding the upper bounds fall below a small number.
 Example 3. Table 2 shows the tscore u values of the six matched tuples in Example 1 by setting  X  df w = 20% and  X  avdl = 10 %.
Hence, T 1 . score u = 7.42, T 2 . score u = 4.23 and T 3 . score u = 3.88. 3.3. Finding initial top-k results selecting the root as the node r such that the maximum path from r to all leaf nodes is minimized. Fig. 3 a shows the rooted tree of
CN 6 . Each node V i in the rooted tree is associated with an output buffer, denoted by V i  X  output , which contains the tuples of V can join at least one tuple in the output buffer of each child of V i . Tuples in V i  X  output are also called the output tuples of V each output tuple of a root node can form JTTs with the output tuples of the root node's descendants. Tuples are processed in a two-phase approach in the rooted tree. In the filter phase , as illustrated in Fig. 3 a, when a tuple t is processed at node W 1 tuple of the root node. The tuples that cannot pass the checking are pruned; otherwise, in the join phase (shown in Fig. 3 b), a t . In order to share the computational cost among CNs, all the rooted trees are compressed into an L -lattice by collapsing their common sub-trees. Fig. 3 c shows the lattice of the seven CNs in Example 2 , where V i Q denotes a node of the query tuple set particularly, and the dual edges between two nodes, for instance, V 1 Q and V 5 , indicate that V 5 is a dual child of V 1 Q . pipelined way, we propose the following two improvements. First, we sort tuples in each query tuple set in a non-increasing order of tscore u .Weuse V i Q  X  cur to denote the current tuple such that the tuples before its position have been processed at V i Q  X 
V
Fig. 3 (c), V i Q  X  cur s of the four nodes is denoted by arrows. Second, we need to bind the relevance scores of the un-found results, as in [4,8,11] .GivenaCN C , let the set of query tuple sets of C be { R 1 Q , R 2 Q , ... , R m Q }. For each tuple R by processing the up-processed tuples at V i Q is defined as having non-empty output buffers. This property of score u V Q i ; Q can be seen as our version of implementing the event-driven evaluation, which is first proposed in S-KWS [12,19] and can noticeably reduce the query processing cost. In Fig. 3 c, score u V of the four V i Q nodes are shown next to the arrows. For example, score u V Q 8 ; Q  X  max C  X  CN Algorithm 1 outlines the LP algorithm. Lines 1  X  4 are the initialization steps.
 Then in each iteration (lines 5  X  8), the un-processed tuple in all the V i Q nodes that maximizes score u is processed by calling containing tuple t , which are inserted into the queue L  X  topk . We will explain Insert in the following example. Algorithm 1 stops when max V Q than the relevance score of the top-( k +  X  k )-th found results.
 Example 4. In the first round, tuple V 9 Q  X  p 2 is processed by calling Insert ( V 9 Q , p 2 ). Since V 9 Q is the root node of CN p have no processed tuples that can join w 1 . Insert ( V 7 , w 7 ) adds w 7 into V 7  X  output , and then calls Insert ( V 4 , a 2 started but no results can be found, because the only one found JTT p 2  X  w 7  X  a 2  X  w 7  X  p 2 is not a valid result. After processing V 9 Q  X  p 2 , score u V Q 3 ; Q  X  3 : 82 and score u V Q 9 ; Q  X  3 : 57.
 Algorithm 1. LP (lattice  X  , the top-k value k ,  X  k ) result in the L  X  topk (suppose  X  k = 0) is larger than all the score u V Q i ; Q values. Fig. 4 shows the snapshot of L after fi top-3 results.

After the execution of LP, all the un-found results are with score u b L  X   X  . Results in the queue L  X  topk , which are with score u  X  L  X   X  , can be categorized into three types. The first type is the initial top-( k +  X  k ) results, which are with score have a large number. 3.4. Maintaining top-k results results for keyword queries. Since the main challenges faced in it and the overview of the solutions have been discussed in Section 3.1, this subsection focuses in explaining the algorithm.
 Algorithm 2. Maintain ( OP ( t ; Rt ), lattice  X  , the top-k value k ,  X  k )
Delete is provided in KDynamic too, which first removes t from V i  X  output , and then checks whether some outputted tuples of V deleted from V 5  X  output accordingly because they can only join a 3 , among tuples in V 8 Q  X  output .
 the LP algorithm (line 19) or to rollback the evaluation of L (line 21). In any case, at the end of handling the OP, we have results.

If a new matched tuple t introduces a new non-empty query tuple set R t Q , we add the new CNs involving R t Q into the lattice (line 4). Fig. 5 illustrates the process of inserting a new CN into the lattice shown in Fig. 4 , assuming the new CN is added by setting V 7 as the child of V f .If V f is a free tuple set and it does not have other child nodes (as shown in Fig. 5 ), Insert ( V undertaken in lines 16  X  17.
 score of the ( k +  X  k )-th result in  X   X  topk (line 1). Then, for each processed tuple t  X  R i Q that is of score u V Q i  X  R Q  X  processing on it is rolled back (lines 3  X  5). We use V i Q  X  cur  X  1todenotethetuplejustbefore V i Q  X  cur . Algorithm 3. RollBack (a lattice  X  , the top-k value k ,  X  k ). 3.5. Data graph caching
For a tuple t , algorithms LP and Maintain need to call Insert ( V i , t )and Delete ( V i , t ) multiple times for different nodes V Assume a new tuple w 0 is inserted into the lattice shown in Fig. 4 , then procedure Insert is called three times at V 5 , V 6 and V would incur at most eight selections that are denoted by arrows in the left part of Fig. 6 . For instance, the arrow from V 7 to V the maximal number of database accesses can be up to several hundred. In order to improve the efficiency of Insert and Delete ,inthis paper, the selections in them are implemented by data graph caching.

In the above example, the eight selections carried out in the filter phase can be expressed using two relational algebra expressions:  X  aid  X  wid  X  w 0 W  X  X   X   X  aid  X  A i A  X  X  X  and  X  pid  X  w  X  w 0 W  X  X   X   X  p  X  P j P  X  X  X  , where A i ( i = 3, 4, 8) and P the set of outputted tuples or processed tuples of the corresponding node. If we rewrite them as  X  aid  X  aid  X  A i  X  wid  X  w 0 W  X  X   X  memory, then the eight selections can be evaluated by accessing the database twice only.

Algorithm 4 shows our procedure for one kind of selection in Insert and Delete : checking whether tuple t can join at least one stored in the main memory in line 3. Then they can be reused every time when they are queried. The other selections in Insert and Delete , omitted due to the space limitation, are also evaluated in this pattern. Hence, for each tuple t , a tree rooted at t and consisting of all the tuples that can join t is created, which is denoted as T and can be seen as the cached localization information of t . The right part of Fig. 6 shows the created T for the tuple w 0 , where the dotted tuples are queried in the join phase. Since multiple T s created for different tuples can share tuples, portions of the database graph are cached in effect, which is the reason for naming the optimization method.
 Algorithm 4. CanJoinOneOutputTuple (lattice node Vi , tuple t ) recursion depths. The maximum recursion depth of Delete is  X  CN max 2  X  [18],where CN max indicates the maximum size of the generated CNs. The maximum recursion depth of Insert is CN max , which consist of  X  CN max 2  X  for the filter phase and  X  CN max join phase. Hence, the height of T is bounded by CN max .Weuse M 1 and M 2 to indicate the maximum number of adjacent relations of each relation R i and the maximum number of tuples that a tuple t of R i canjoinineach R i 's adjacent relation, respectively.
 are O ( M 2 l ) tuples. Hence, the maximum total number of tuples in T is: be referenced by a large number of paper tuples. Hence, Eq. (7) can have a huge result, which makes the efficiency of the method of caching worse than KDynamic's method of frequent evaluation of small joins. Fortunately, T is quite incomplete for the following two reasons. First, merely finding the top-k results cannot make a large number of JTTs to be found; hence, the recursion could be found. Second, the possibility of the joined tuples of a tuple t that can be found in the processed tuples of R i Q can be approximated as M 2  X  IDF  X   X  , where IDF denotes df w N (the ratio of the number of matched tuples to the number of total tuples in
R ), and  X  is the percentage of processed tuples in R i Q . IDF is small for most keywords in a relational database (  X  0.1), and a lattice node R i Q in most cases. Therefore, in fact, our method does not need to cache large amounts of data in T . time cost of handling t can be reduced to 1  X  , compared to KDynamic.
 pointers of the joined tuples in other relations. Therefore, T rooted at different tuples shares data to the maximum extent. When computing the initial top-k results, we assume the database is static; hence, the data graph cache can be reused, and then, all of temporarily and is cleared after t is handled. As shown in the experimental results, caching the joined tuples can highly improve the efficiency both in computing the initial top-k results and handling database updates. 3.6. Lattice forest constructing
According to Eq. (5), score u values of tuples in different CNs have great differences. Thus, CNs have different potentials in CNs in Example 2 are evaluated separately, tuple sets of CN 5 and CN 7 would have no processed tuples. However, as shown in Fig. 4 , V is shared by CN 2 , CN 3 , CN 6 and CN 7 in the lattice, and tuples a 1 and a 3 are processed in all these four CNs when processing themat V 8 Q , which results in redundant operations at V 2 and V 5 and two redundant results a 3 and a 1  X  w 4  X  p 4  X  w 6  X  a These redundant operations can cause further redundant operations when maintaining the top-k results. For example, we have to join a new unmatched tuple of relation P with four tuples in V 5  X  output .

In order to avoid finding the redundant results, the optimal method is merely to share the tuple sets that have the same number of processed tuples among CNs when they are evaluated separately. However, we cannot get these numbers without evaluating the CNs. As an alternative, we attempt to estimate them for the CNs according to following two heuristic rules: 1. If one tuple set is contained by two CNs, it has a larger number of processed tuples in the CN C with higher Max(C) value. 2. If two CNs have the same Max(C) values, tuple sets of the CN with the larger size have more processed tuples. where Max C  X  X  X  two lattices after fi nding the top-3 results, where the three redundant JTTs in Fig. 4 can be avoided.

We cluster the CNs using the K -mean clustering algorithm [20], which needs an input parameter to indicate the number of expected clusters. We use Kmean to indicate this parameter. The value of Kmean represents the trade-off between sharing the computation cost among CNs and considering their different potentials in producing top-k results. The CNs are not clustered when Kmean = 1 , then the computation cost is shared to the maximum extent. When Kmean = MAX , all the CNs are evaluated separately. In our experiments, we find that clustering the CNs can highly improve the efficiency of algorithm LP and Maintain, and the optimal Kmean are different with different CN max values. 4. Experimental evaluation
We conducted extensive experiments to test the efficiency of our method. We used the DBLP dataset. 3 Note that DBLP is continuously growing and is updated on a monthly basis. The reason we use DBLP to simulate a continuously updating relational dataset is because there is no real updating relational datasets in the public domain, and it is used in many studies on top-k keyword queries over relational databases, such as in [4,8]. The downloaded XML file is decomposed into relations according to the schema shown in Fig. 8 . The two arrows from PaperCite to Papers denote the foreign-key-references from paperID to paperID and citedPaperID to paperID , respectively. MySQL (v5.1.44) is used as the RDBMS with the default  X  Dedicated MySQL Server Machine  X  configuration. All the relations use the MyISAM storage engine. Indexes are built on all primary key and foreign key attributes, and full-text indexes are built for all text attributes. All the algorithms are implemented in C++. We conducted all the experiments on a PC with a 2.53 GHz CPU and 4 GB memory, running Windows 7.
 4.1. Parameter setting generated CNs; and ( 5 ) Kmean : the input parameter for the K-mean clustering algorithm. The parameters with their default values (in bold font) are shown in Table 3 . The keywords selected are listed in Table 4 with their IDF values, where the keywords in bold font are keywords popular in author names. Ten queries are constructed for every IDF value, each of which contains three selected keywords. For each l value, ten queries are constructed by selecting l keyword from the set of keywords of IDF = 0.013.
To avoid generating a small number of CNs for each query, an author name keyword of each IDF value is always selected for each query.
 maintaining the top-k results also increases because more tuples are processed and the lattice nodes have more outputted tuples.
The parameter CN max has a great effect on keyword query processing because the number of generated CNs increases exponentially with CN max . And the number of matched tuples increases as IDF and l increase. Hence, the first four parameters will impact the scalability of our method. 4.2. Exp-1: initial top-k result computation from the XML file sequentially until the number of tuples in the relations reaches the numbers specified in Table 5 . Then we ran
Algorithm 6 for the different values of each parameter while keeping the other four parameters at their default values. We used two measures to evaluate the effects of these parameters. The first is #R , the number of found results in the queue L  X  topk . The second measure is the time cost for running the algorithm. Ten queries were selected for each combination of the parameters, and the average values of the two measures are reported. In this experiment,  X  df w (=1%),  X  avdl (=1%) and  X  k (=1) all have small values because they will be enlarged adaptively for maintaining the top-k results.

Y -axis. Fig. 9 shows that the two measures increase as k, idf and CN max grow. However, they do not increase rapidly in Fig. 9 , especially the curves of the time cost, which implies the good scalability of our method. The two curves of l show that the effect of l seems more complicated: all the two measures may decrease when l increases, and they even both achieve the minimum values when l = 5. This is because the probability that the keywords co-appearing in a tuple and that the matched tuples can join is high when l is large. Therefore, there are more JTTs with large scores, which results in larger  X  and small values of the two measures. (6)  X  ), and the changes of the time cost while varying Kmean when CN max is 4, 5 and 7 (indicated by  X  Time (4)  X  ,  X  Time (5)  X  Time (7)  X  , respectively). Since the results of the K -mean clustering may be affected by the starting conditions [20], for each Kmean value, we run Algorithm 1 five times on different starting condition for each keyword query and report the average result. Note that KDynamic corresponds to Kmean = 1 since there is no CN clustering in its method. From Fig. 10 a, we can see that clustering the CNs can considerably improve the efficiency of computing the top-k results. The two measures decrease quickly while Kmean grows from 1 to 6. However, increasing Kmean from 6 to 18 cannot distinctly reduce the time cost, because the CNs Kmean grows from 18 to MAX (i.e., the CNs are evaluated separately), the time cost changes differently on different CN max values. When CN max is 6 or 7, the time cost is increased. When CN max = 5, the time cost is unchanged. When CN max = 4, the time cost is decreased to the minimum value. This is because the number of CNs is small when CN max is 4 and 5, but is large when CN max is 6 and 7; hence, sharing the time cost among CNs can achieve improvements when CN max is 6 and 7. Therefore, for a small CN max value, the CNs can be evaluated separately, each as a rooted tree; and for a large CN max value, the lattice is constructed while clustering the CNs on Kmean = 8. It is worth noting that #R continually decreases as Kmean grows, which implies the effectiveness of clustering CNs using Max ( C )  X  ln( size ( C )) values.

Fig. 10 b compares the time cost of computing the initial top-k results of algorithm LP with that of SPARK [8] and KDynamic, respectively, while varying CN max . The time cost of SPARK is plotted on the right Y -axis, which increases rapidly as CN max grows. Fig. 10 b shows that, compared to SPARK, Algorithm 6 and KDynamic are very efficient in finding the top-k results, because evaluating the CNs using the lattice can achieve a complete reduction since all the output tuples of the root nodes can form JTTs. The time costs of KDynamic in Fig. 10 b are all obtained when Kmean = 8. Hence, the difference between our approach and KDynamic reflects the effect of caching the joined tuples. We can see that caching the joined tuples highly improves the efficiency of computing the top-k results. More importantly, the improvement increases as CN max grows. The reason is that when CN max grows, the number of lattice nodes at which the procedure Insert is called for each tuple increases exponentially; hence the saved cost for storing the joined tuples increases as CN max grows.

From the curves of # R in Figs. 9 and 10 , we can see that # R is large in all the settings: about several thousands. Recall that the values. Since  X  df w ,  X  avdl and  X  k all have very small values, the number of the second kind of results, the potential top-( k + results, is very small ( b 10). Therefore, the third kind of results (with score u b L  X   X  ) are the majority, which necessitate only considering the results that are with score u  X  L  X   X  in line 5 and line 14 of Algorithm 2 . 4.3. Exp-2: top-k result maintenance
In this experiment, we studied the efficiency of Algorithm 4 in maintaining top-k results. We used the same keyword queries from the DBLP XML file. At the same time, we deleted randomly selected tuples from the database. Algorithm 2 is used to maintain the top-k results for the queries while the database is being updated. The database update records are read from the database log file; hence, the database updating rate has no direct impact on the efficiency of handling database updates.

We first added 713,084 new tuples into the database and deleted 250,000 tuples from the database. The new data is roughly 90% of the data used in Exp-1, whose composition is shown in Table 6 . Fig. 11 a  X  c show how the average execution time of Algorithm 2 in handling the above database updates changes while varying k, IDF and l . The average time cost for handling database updates of the ten default queries is smaller than 1 ms. Fig. 11 d shows the change in time cost while varying CN max , which is compared to that of KDynamic with Kmean = 8. We found that caching the joined tuples also considerably improves the difference between the time cost of KDynamic in Fig. 11 d and that reported in [13,18] is caused by the different experimental settings and definitions of the CNs. The curves in Fig. 11 a  X  d do not show rapid increases while expanding the four parameters, implying good scalability of our method. Fig. 11 e shows the changes in the time cost while varying Kmean when CN max is 4, 5, 6 and 7. The curves of Fig. 11 e show similar changing trends with the curves of the time cost in Fig. 10 a except that the curve of CN max = 6 reaches the minimum value when Kmean = MAX. Summing up, the curves in Figs. 10 a and 11e suggest separate evaluation of the CNs when CN max  X  6, and to construct the lattice while clustering the CNs on Kmean = 8 when CN max &gt;6. keyword queries. We adopted two different growing rates of  X  df w :  X  df w + =2% and  X  df w + = 5%, which meant that when additional tuples, we recorded the average occurrences of enlarging  X  df w and calling RollBack of the ten queries, the results are shown in Fig. 12 a and b. The X-axis (with units of 10 5 )in Fig. 12 a and b indicates the number of additional tuples. We do not report the occurrence of enlarging avdl because it is very small ( b 2).
 300,000 additional tuples, the maximum  X  df w of all the relations is about 15. Hence it is reasonable to set 15 as the maximum calling RollBack decreases because it becomes more and more difficult to find new results with score u  X  L  X   X  . We also redo the experiment without calling the procedure RollBack. Then, the average time cost for handling database updates increases by 45.4%, which necessitates reversal of the pipelined evaluation when the number of found top results is larger than k +  X  k . different  X  k growing rates were adopted:  X  k +=2and  X  k + = 5, which mean that when the number of results with score u &gt; L  X   X  fell below k, the corresponding  X  k value increased by 2 and 5, respectively. We recorded the average frequency of enlarging  X  k of the ten queries after deleting each 100,000 tuples, the results are shown in Fig. 12 c. The X-axis (with units of 10 number after deleting200,000 tuples, that is, after  X  k is enlarged to about 20. As indicated by thecurve of k in Fig. 12 c, a large %. k. 5. Related work
In this section, we will survey the related work from three aspects: keyword search in relational databases, top-k keyword search in relational databases, and keyword search in relational data streams. 5.1. Keyword search in relational databases
Given l -keyword query Q ={ w 1 , w 2 , ... , w l }, the task of a keyword search in a relational database is to find structural information constructed from tuples in the database [21]. There are two approaches: the schema-based approaches and the graph-based methods.

The schema-based approaches [1,2,4,7,8,12,18,22,23] in this area utilize the database schema to generate SQL queries which are evaluated to find the structures for a keyword query. They first utilize the database schema to generate a set of CNs. Then, these CNs are evaluated by sending the corresponding SQL statements to the DBMS to find the query results. [2] proposed how to generate a complete set of CNs and discussed several query processing strategies, when considering the common sub-expressions among the CNs. [1,2], all focused on finding all JTTs that contain all l keywords, with no ranking involved. In [4,8], several algorithms are proposed to achieve the top-k JTTs.
 are tuples and the directed edges are foreign key references between tuples. Fig. 1 b shows such a database graph of the example database. Then, for each keyword query, they find a set of structures (either Steiner trees [3], distinct rooted trees [5], r-radius
Steiner graphs [9], multi-centre sub-graphs [24], or r-clique [27]) from the database graph, which contain all the query keywords and are connected by the paths in the database graph. For the details, please refer to the survey papers [21,28] .Adrawbackofthe data graph model is that a graph of the tuples must be materialized and maintained. For a large size database, the size of a data graph is too large to fit into main memory. In addition, the materialized data graph should be updated for any database changes; hence, this model is not appropriate to frequently changing databases [28]. Therefore, this paper adopts the schema-based framework and can be regarded as an extension in dealing with continual keyword searches. However, the cached joined tuples for each tuple comprise a small data graph. From this perspective, our method integrates the two frameworks. 5.2. Top-k keyword search in relational databases the Global-Pipelined (GP) algorithm. For a keyword query Q ,givenaCN C , let the set of query tuple sets of C be { R 1 Q , R 2 Q testing all the combinations as ( t 1 , t 2 , ... , t s  X  1 , R s Q  X  cur , t s +1 ... , t m ), where t i is a processed tuple of C un-processed tuples in all the CNs, the GP stops and outputs the k found results with the largest relevance scores. the number of processed tuples becomes large [14] . SPARK proposes the Skyline-Sweeping algorithm, which highly reduces the number of tested combinations. However, SPARK still cannot avoid testing a huge number of combinations which cannot produce results. Our algorithms adopt the two basic principles of the query processing methods of DISCOVER2 and SPARK: (1) bounding the relevance scores of the un-found results; and (2) processing tuples in a pipelined way. 5.3. Keyword search in relational data streams
The most related projects to our paper are S-KWS and KDynamic, which try to find new results or expired results for a given keyword query over an open  X  ended, high-speed large relational data stream [21]. They adopt the schema-based framework since the database is not static. The main issue they addressed is how to reduce CPU cost (for evaluating joins) and memory overhead (for storing intermediate results) in the CN evaluation step while tuples are inserted/deleted at a high speed. The basic idea of their methods is to share the computational cost by using either operator mesh [12] or L -lattice [13]. This paper deals with a different problem from S-KWS and KDynamic, though all need to respond to continual queries in a dynamic environment. S-KWS and KDynamic focus on finding all query results. In contrast, our methods maintain the top-k results, which are less sensitive to the updates of the underlying databases because not every new or expired result changes the top-k results. In this paper, we incorporate the ranking mechanisms and the pipelined evaluation into the query processing method of KDynamic to support an efficient top-k keyword search in relational databases. 6. Conclusion and future work In this paper, we have studied the problem of finding the top-k results in relational databases for a continual keyword query. We proposed an approach that finds the answers whose upper bounds of future relevance scores are larger than the threshold. We adopted an existing scheme of finding all the results in a relational database stream, but incorporated ranking mechanisms in the query processing methods and make two improvements that can facilitate efficient top-k keyword search in relational databases. The proposed method can efficiently maintain top-k results for a keyword query without re-evaluation. Therefore, it can be used for answering continual keyword queries in databases that are updated frequently.

In the future, we would like to extend the method proposed in this paper to maintain top-k results for a large number of keyword queries. Currently, the lattices are kept in the main memory and the top-k results of different queries are maintained separately, which limits the number of top-k keyword queries that can be evaluated simultaneously. If the lattices of different queries can be integrated, considerable memory reduction will be obtained.
 Acknowledgments This research was partially supported by the National Natural Science Foundation of China (NSFC) under grant No. 61173118. Jihong Guan was also supported by the  X  Shuguang  X  Program of Shanghai Municipal Education Commission and the Fundamental Research Funds for the Central Universities. Shuigeng Zhou was supported by the Research Innovation Program of Shanghai Municipal Education Commission under grant No. 13ZZ003.
 References
