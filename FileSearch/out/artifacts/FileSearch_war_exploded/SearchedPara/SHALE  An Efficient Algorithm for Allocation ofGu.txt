 Motivated by the problem of optimizing allocation in guaranteed display advertising, we develop an efficient, lightweight method of generating a compact allocation plan that can be used to guide ad server decisions. The plan itself uses just O (1) state per guaranteed contract, is robust to noise, and allows us to serve (provably) nearly optimally. The optimization method we develop is scalable, with a small in-memory footprint, and working in linear time per iteration. It is also  X  X top-anytime, X  meaning that time-critical applications can stop early and still get a good serving solution. Thus, it is particularly useful for optimizing the large problems arising in the context of display advertising. We demonstrate the effectiveness of our algorithm using actual Yahoo! data.
 I.0 [ Computing Methodologies ]: General Algorithms, Experimentation Display Advertising, Online Advertising
A key problem in display advertising is how to efficiently serve in some (nearly) optimal way. As internet publishers and advertis-ers become increasingly sophisticated, it is not enough to simply make serving choices  X  X orrectly X  or  X  X cceptably X . Improving ob-jective goals by just a few percent can often improve revenue by tens of millions of dollars for publishers, as well as improving ad-vertiser or user experience. Serving needs to be done in such a way that we maximize the potential for users, advertisers, and publish-ers.

In this paper, we address serving display advertising in the guar-anteed display marketplace, providing a lightweight optimization framework that allows real servers to allocate ads efficiently and with little overhead. Recall that in guaranteed display advertising, advertisers may target particular types of users visiting particular types of sites over a specified time period. Publishers guarantee to serve their ad some promised number of times to users matching the advertiser X  X  criteria over the specified duration. We refer to this as a contract .

In [7], the authors show that given a forecast of future inven-tory, it is possible to create an optimal allocation plan , which con-sists of labeling each contract with just O (1) additional informa-tion. Since it is so compact, this allocation plan can efficiently be communicated to ad servers. It requires no online state, which re-moves the need for maintaining immediately accessible impression counts. (An impression is generated whenever there is an opportu-nity to display an ad somewhere on a web page for a user.) Given the plan, each ad server can easily decide which ad to serve each impression, even when the impression is one that the forecast never predicted. The delivery produced by following the plan is nearly optimal. Note that simply using an optimizer to find an optimal allocation of contracts to impressions would not produce such a result, since the solution is too large and does not generalize to un-predicted outputs.

The method to generate the allocation plan outlined in [7] relies on the ability to solve large, non-linear optimization problems; it takes as input a bipartite graph representing the set of contracts and a sample of predicted user visits, which can have hundreds of mil-lions of arcs or more. There are commercially available solvers that can be used to create allocation plans. However, they have several drawbacks. The most prominent of these is that such solvers aim towards finding good primal solutions, while the allocation plan generated is not directly tied to the quality of such solutions. (The allocation plan relies on the dual solution of the problem.) In par-ticular, there is no guarantee of how close to optimal the allocation plan really is. Hence, although creating a good allocation plan is time critical, stopping the optimizer early with sub-optimal values can have undesirable effects for serving.

For our particular problem, the graph we wish to optimize is ex-tremely large and scalability becomes a real concern. For this rea-son, and given the other disadvantages of using complex third party software, we propose a new solution, called  X  X HALE. X  It addresses all of these concerns, having many desirable properties: The SHALE solver uses the idea of [7] as a starting point, but it provides an additional twist that allows the solver to stop after any number of iterations and still produce a good allocation plan. For this reason, SHALE is often five times faster than solving the full problem using a commercial solver.
The allocation problem facing a display advertising publisher has been the subject of increased attention in the past few years. Often modeled as a special version of a stochastic optimization, several theoretical solutions have been developed [4, 6]. A similar for-mulation of the problem was done by Devanur and Hayes [2],who added an assumption that user arrivals are drawn independently and identically from some distribution, and then proceed to develop al-location plans based on the learned distribution. In contrast, Vee et al. [7] did not assume independence of arrivals, but require the knowledge of the user distributions to formulate the optimization problem.

Bridging the gap between theory and practice, Feldman et al. [3] demonstrated that primal-dual methods can be effective for solv-ing the allocation problem. However, it is not clear how to scale their algorithm to instances on billions of nodes and tens of billions of edges. A different approach was given by Chen et al. [1] who used the structure of the allocation problem to develop control the-ory based methods to guide the online allocation and mitigate the impact of potential forecast errors.

Finally, a crucial piece of all of the above allocation problems is the underlying optimization function. Ghosh et al [5] define repre-sentative allocations, which minimize the average ` 2 2 distance be-tween an allocation given to a specific advertiser, and the ideal one which allocates every eligible impression with equal probability. Feldman et al. [3] define a similar notion of fair allocations, which attempt to minimize an ` 1 distance between the achieved allocation and a similarly defined ideal.

In this section, we begin by defining the notion of an optimal allocation of ads to users/impressions (Section 2.1). Our goal will then be to serve as close as possible to this optimal allocation. In Section 2.2, we describe the notion of generating an allocation plan, which will be used to produce nearly optimal serving.
In guaranteed display advertising, we have a large number of forecast impressions together with a number of contracts. These contracts specify a demand as well as a target; we must deliver a number of impressions at least as large as the specified demand, and further, each impression must match the target specified by the contract. We model this as a bipartite graph. On one side are supply nodes , representing impressions. On the other side are de-mand nodes , representing contracts. We add an arc from a given supply node to a given demand node if and only if the impression that the supply node represents is eligible (i.e. matches the target profile) for the contract represented by the demand node. Further, demand nodes are labeled with a demand , which is precisely the amount of impressions guaranteed to the represented contract. In general, supply nodes will represent several impressions each, thus each supply node is labeled with a weight s i , leading to a weighted graph (see [7] for more details). Figure 1 shows a simple example.
An optimal allocation must both be feasible and minimize some objective function. Here, our objective balances two goals: mini-mizing penalty, and maximizing representativeness . Each demand node/contract j has an associated penalty, p j . Let u j be the under-delivery , i.e. the number of impressions delivered less than d Then our total penalty is P j p j u j .

Representativeness is a measure of how close our allocation is to some target. For each impression i and contract j , we define a target,  X  ij . In this paper, we set  X  ij = d j /S P i  X   X ( j ) s i , the total eligible supply for contract j . This has the effect of aiming for an equal mix of all possible matching impres-sions. (Here,  X ( j ) is the neighborhood of j , likewise, we denote the neighborhood of i by  X ( i ) .) The non-representativeness for contract j is the weighted L 2 distance from the target  X  proposed allocation, x ij . Specifically, where V j is the relative priority of the contract j ; a larger V that representativeness is more important. Notice that we weight by s i to account for the fact that some sample impressions have more weight than others. Representativeness is key for advertiser satisfaction. Simply giving an advertiser the least desirable type of users (say, three-year-olds with a history of not spending money) or attempting to serve out an entire contract in a few hours decreases long-term revenue by driving advertisers away. See [5] for more discussion on this idea.

Given these goals, we may write our optimal allocation in terms of a convex optimization problem:
Constraints 1 are called demand constraints . They guarantee that u precisely represents the total underdelivery to contract j . Con-straints 2 are supply constraints , and they specify that we serve no more than one ad for each impression. Constraints 3 are simply non-negativity constraints .

The optimal allocation for the guaranteed display ad problem is the solution to the above problem, where the input bipartite graph represents the full set of contracts and the full set of impressions! Of course, generating the full set of impressions is impossible in practice. The work of [7] shows that using a sample of impressions still produces an approximately optimal fractional allocation. We interpret the fractions as the probabilities that a given impression should be allocated to a given contract. Since there are billions of impressions, this leads to serving that is nearly identical.
Although this paper focuses on the above problem, we note that our techniques can be extended to more general objectives. For example, in related work, [8] described a multi-objective model for the allocation of inventory to guaranteed delivery, which combined penalties and representativeness (as above) with revenue made on the non-guaranteed display (NGD) spot market and the potential revenue gained from supplying clicks to contracts. SHALE can easily be extended to handle these variants.
In the previous subsection, we defined the notion of optimal al-location. However, serving such an allocation is itself a different problem. Following [7], we define the problem of online serving with forecasts as follows.

We are given as input a bipartite graph, as described in the previ-ous subsection. (We assume this graph is an approximation of the future inventory, although it is not necessary for this definition.) We proceed in two phases. The online allocation is the actual allocation of impressions to con-tracts given during the online phase. Our goal is to produce an online allocation that is as close to optimal as possible.
Remarkably, the work of [1] shows that there is an algorithm that solves the above problem nearly optimally. If the input bipartite graph exactly models the future impressions, then the online allo-cation produced is optimal. If the input bipartite graph is generated by sampling from the future, then the online allocation produced is provably approximately optimal.

However, the previous work simply assumed that an optimal so-lution can be found during the Offline Phase. Although this is true, it does not address many of the practical concerns that come with solving large-scale non-linear optimization problems. In the fol-lowing sections, we describe our solution, which in addition to solving the problem of compact serving, is fast, simple, and robust.
The proposal of [7] to create an allocation plan was to solve the problem of Section 2.1 using standard methods. From this, we can compute the duals of the problem. In particular, we may write the problem in terms of its Lagrangian (more formally, we use the KKT conditions). Every constraint then has a corresponding dual variable. (Intuitively, the harder a constraint is to satisfy, the larger its dual variable in the optimal solution.)
The allocation plan then consists of the demand duals of the problem, denoted  X  . So each contract j was labeled with the de-mand dual from the corresponding demand constraint,  X  supply duals, denoted  X  , and the non-negativity duals were simply thrown out.

A key insight of this earlier work is that we can reconstruct the optimal solution using only the  X  values. When impression i ar-rives, the value of  X  i can be found online by solving the equation P less than 0. Here, g ij ( z ) = max { 0 , X  ij (1 + z/V j x ij = g ij (  X  j  X   X  i ) for each j  X   X ( i ) . Somewhat surprisingly, this yields an optimal allocation. (And when the value of  X  is obtained by solving a sampled problem, it is approximately optimal.)
As mentioned in the introduction, although this solution has many nice properties, solving the optimization problem using standard methods is slower than desirable. Thus, we have a need for faster methods. An alternate approach to solving the allocation problem is the High Water Mark (HWM) algorithm, based on a greedy heuristic. This method first orders all the contracts by their allocation order . Here, the allocation order puts contracts with smaller S j eligible supply) before contracts with larger S j . Then, the algo-rithm goes through each contract one after another, trying to allo-cate an equal fraction from all the eligible ad opportunities. This fraction is denoted  X  for each contract, and corresponds roughly to its demand dual. Contract j is given fraction  X  j from each eligible impression, unless previous contracts have taken more than a 1  X   X  fraction already. In this case, contract j gets whatever fraction is left (possibly 0).

If there is very little contention (or contract j comes early in the allocation order), then  X  j = d j /S j . This will give exactly the right amount of inventory to contract j . However, if a lot of inventory has already been allocated when j is processed, its  X  j value may be larger than this to accommodate the fact that it gets less than  X  some impressions. Setting  X  = 1 will give a contract all inventory that has not already been allocated. We do this in the case that there is not enough remaining inventory to satisfy the demand of j .
The pseudo-code is summarized as follows. 1. Order all demand nodes in decreasing contention order ( d 2. For each supply node i , initialize the available weight  X  s 3. For each demand node j , in allocation order: We note that the computation in Step 3a can be done in time linear in the size of | B j | . Hence, the total runtime of the HWM algorithm is linear in the number of arcs in the graph.
Obtaining a full solution using traditional methods is too slow (and more precise than needed), while the HWM heuristic, although very fast, sacrifices optimality. SHALE is a method that spans the two approaches. If it runs for enough iterations, it produces the true optimal solution. Running it for 0 iterations (plus an additional step at the end) produces the HWM allocation. So we can easily balance precision with running time. In our experience (see Sec-tion 4), just 10 or 20 iterations of SHALE yield remarkably good results; for serving, even using 5 iterations works quite well since forecast errors and other issues generally dwarf small variations in the solution. Further, SHALE is amenable to  X  X arm-starts, X  using the previous allocation plan as a starting point. In this case, it is even better.

SHALE is based on the solution using optimal duals. The key innovation, however, is the ability to take any dual solution and convert it into a good primal solution. We do this by extending the simple heuristic HWM to incorporate dual values. Thus, the SHALE algorithm has two pieces. The first piece finds reasonable duals. This piece is an iterative algorithm. On each iteration, the dual solution will generally improve. (And repeated iterations con-verge to the true optimal.) The second piece converts the reasonable set of duals we found (more precisely, the  X  values, as described earlier) into a good primal solution.

The optimization for SHALE relies heavily on the machinery provided by the KKT conditions. Interested readers may find a more detailed discussion in the Appendix. Here, we note the fol-lowing. If  X   X  and  X   X  are optimal dual values, then 1. The optimal primal solution is given by x  X  ij = g ij 2. For all j , 0  X   X   X  j  X  p j . Further, either  X   X  3. For all i ,  X  i  X  0 . Further, either  X  i = 0 or P j  X   X ( i ) The pseudo-code for SHALE is shown below.
Our implementation of SHALE runs in linear time (in the num-ber of arcs in the input graph) per iteration.

During Stage One, we iteratively improve the  X  values by assum-ing that the  X  values are correct and solving the equation for  X  . Re-call that x ij = g ij (  X  j  X   X  i ) . Thus, we are simply solving the equa-tion P i  X   X ( j ) s i x ij = d j for  X  j . In order to find better  X  values, we assume the  X  is correct and solve for  X  using P j  X   X ( i ) The following theorem shows that this simple iterative technique converges, and yields an  X  approximation in polynomial steps.
More precisely, define d j (  X  ) = P i  X   X ( j ) s i g ij (  X   X  is determined as in Step 1 of Stage One of SHALE. (We think of this as the projected delivery for contract j using only Stage One of SHALE.) We say a given  X  solution produces an  X  -approximate delivery if for all j , either  X  j = p j or d j (  X  )  X  (1  X   X  ) d that an optimal  X  j is at most p j ; the intuitive reason for this is that growing  X  j any larger will cause the non-representativeness of the contract X  X  delivery to be even more costly than the under-delivery penalty. Thus, an  X  -approximate delivery means that every contract is projected to deliver within  X  of the desired amount, or its  X   X  X axed-out. X  We can now state our theorem. Its proof is in the appendix.
T HEOREM 1. Stage One of SHALE converges to the optimal solution of the guaranteed display allocation problem. Further, let  X  &gt; 0 . Then within 1  X  n max j { p j /V j } iterations, the output  X  produces an  X  -approximate delivery.
 Note that Stage One is effectively a form of coordinate descent. In general, it could be replaced with any standard optimization technique that allows us to recover a set of approximate dual val-ues. However, the form we use is simple to understand, use, and debug. Further, it works very well in practice.
 In Stage Two, we calculate  X  values in a way similar to HWM. We calculate  X  values based on the  X  values generated from Stage One. Using these, we calculate  X  values to give d j allocation (if possible) to each contract. Notice that in Stage Two, we must be cognizant of the actual allocation. Thus, we maintain a remaining fraction left,  X  s i , that we cannot exceed. Thus, contracts allocated latest may not be able to get the full amount specified by g fraction taken from impression i is too great.

We note that in our actual implementation, we use a two-pass version of Stage Two. In the first pass, we bound  X  j by  X  j . In the second pass, we find a second set of  X  values (with no upper bounds), utilizing any left-over inventory. This is somewhat  X  X ruer X  to the allocation produced by SHALE in Stage One, and gives slightly better online allocation.
Recall that SHALE produces two values for each contract j , namely  X  j and  X  j . Given impression i , the  X  values for eligible contracts are used to calculate the  X  i value, which is used together with the  X  values to produce the allocation. The pseudo-code is below.
 1. Set  X  s i = 1 and find  X  i such that 2. For each matching contract j , in allocation order, compute 3. Select contract j with probability x ij . (If P j  X ( i )
We have implemented both the HWM and SHALE algorithms described in Section 3 and benchmarked their performance against the full solution approach (known hereafter as XPRESS) on his-torical booked contract sets. First we describe these datasets and our chosen performance metrics and then present our evaluation results.
In order to test the  X  X eal-world X  performance of all three algo-rithms we considered 6 sets of real GD contracts booked and active in the recent past. In particular, we chose three periods of time as described in Table 1 and two ad positions LREC and SKY for each of these time periods.

We considered US region contracts booked to the aforementioned positions and time periods and also excluded all frequency capped contracts and all contracts with time-of-day and other custom tar-gets. Also, all remaining contracts that were active for longer than the specified date ranges were truncated and their demands were proportionally reduced. Next, we generated a bipartite graph for each contract set as in Figure 1; by sampling 50 eligible impres-sions for each contract in the set. This sampling procedure is de-scribed in detail in [7]. We then ran HWM, SHALE and XPRESS on each of the 6 graphs and evaluated the following metrics. 1. Under-delivery Rate : This represents the total under-delivered 2. Penalty Cost : This represents the penalty incurred by the 3. L2 Distance : This metric shows how much the generated
As we mentioned earlier, SHALE was designed to provide a trade-off between the speed of execution of HWM and the quality of solutions output by XPRESS. Accordingly in our first experi-ment we measured the performance of SHALE (run for 0, 5, 10, 20 and 50 iterations) as compared to XPRESS against our chosen met-rics. Since SHALE at 0 iterations is the same as HWM, we label it as such. Figure 2 shows the penalty cost, under-delivery rate, L2 distance and completion for HWM and SHALE run for 5, 10, 20 and 50 iterations respectively as a percentage of the corresponding metric for XPRESS, averaged over our 6 chosen contract sets. Note that the y-axis labels for the under-delivery rate and penalty cost are on the left, while the labels for the L2 distance and completion time are on the right.
It is immediately clear that SHALE after only 10 iterations is within 2% of XPRESS with respect to penalty cost and under-delivery rate. Further, note that SHALE after 10 iterations is able to provide an allocation whose L2 distance is less than half that of XPRESS. (Recall smaller L2 distance means the solution is more representative, so SHALE is doing twice as well on this metric.) Remarkably, SHALE is able to generate a high quality solution while requiring less than 20% of the time taken by XPRESS.
Next, we decided to fix the iteration count for SHALE at 20 and test its performance under varying supply levels. Specifically, for each of our 6 contract sets, we artificially reduced the supply weight on each of the supply nodes while keeping the graph structure fixed in order to simulate the increasing scarcity of supply. We define the average supply contention (ASC) metric to represent the scarcity of supply, as follows where s i represents the supply weight and d j and S j represent the demand and eligible supply for contract j . In Figure 3, we show the under-delivery rate, penalty cost and L2 distance for SHALE as a percentage of the corresponding metric for HWM for various levels of ASC. First we note that each of our metrics for SHALE is lower than the corresponding metric for HWM for all values of ASC. In-deed, the SHALE L2 distance is less than 50% of that for HWM. Also note that the SHALE penalty cost consistently improves com-pared to HWM as the ASC increases.
Recall that the allocation plan produced by SHALE or HWM in production is expected to be used not on the input graph itself but on real impressions as they arrive. Thus, the graph on which the primal solution is reconstructed could potentially be very different from the sampled graph used for optimization. Whereas a  X  X rue X  test of SHALE in production is out of the scope of this work, we did compare the robustness of SHALE (run for 20 iterations) and HWM by reconstructing the allocation plan generated be each al-gorithm on graphs different from those used for optimization. In particular, corresponding to each of our 6 contract sets, we first ran SHALE and HWM on corresponding 50 sample graphs to gener-ate allocation plans. Then, for each contract set, we generated 6 different 200 sample graphs using 6 different random seeds. We also varied the ASC in the same fashion as in Experiment 2 in each of these 6 graphs. We then reconstructed primal solutions from the plans generated by HWM and SHALE on these graphs and evaluated our chosen metrics. Figure 4 shows the comparison of under-delivery rate, penalty cost and L2 distance for SHALE as a percentage of the corresponding metric for HWM averaged over 36 graphs (6 different contract sets and 6 graphs for each contract set) for various values of ASC. Here, we can clearly see that SHALE performs significantly better than HWM on all three metrics. It turns out that the HWM allocation plan resulted in much higher under-delivery rates, penalty costs and L2 distances when recon-structed on the new 200 sample graphs as compared to the primal solution on the original 50 sample graph; whereas the SHALE allo-cation plan did not suffer such a degradation in the solution quality upon reconstruction on the 200 sample graphs. Finally, note that the L2 distance ratio, unlike penalty cost and under-delivery date is not monotonic in the ASC. We would like to point out that in fact, the L2 distance for SHALE was monotonically increasing in the ASC; whereas the L2 distance for HWM varied erratically. This caused the SHALE L2 distance as a percentage of the HWM L2 distance to be non-monotonic.
The experiments above compare how SHALE performs with re-spect to the optimal algorithm under knowledge of supply land-scape of the contracts. In this experiment we compare how these algorithms perform when the solution is used to serve real world sampled impressions from actual server logs. This experiment uses real contracts and real adserver logs (downsampled) for performing the complete offline simulation.
Here we take three new datasets which consists of real guaran-teed delivery contracts from Yahoo! active during different one to two week periods in the past year. We run our optimization al-gorithms and serve real downsampled serving logs for two hours using the solution computed. Then after collecting the serving stats we reoptimize the contracts with updated goal and supply forecasts as the contract demands would have reduced after two hours of serving. This cycle continues where we optimize, serve adlogs and update stats every two hour for the entire test period of one two two weeks.
At the end of the simulation, we look at the contracts that start and end within the simulation period and compare how metrics of under delivery and penalty across HWM, SHALE and "Optimal" algorithms. HWM algorithm is essentially SHALE algorithm with 0 iterations. The SHALE algorithms are run with setting of 5, 10 and 20 iterations. Here the "Optimal" solution is obtained by run-ning a coordinate gradient descent algorithm till the objective func-tion convergence.

We performed serving using the reconstruction algorithm de-scribed in Section 3.3.1.
The metrics include the underdelivery metric and penalty metrics as defined in Equation 4 and in Equation 5 For these set of experi-ments, we set p j to be p j = 0 . 002 + 4  X  q j where q j per delivered impression from contract j .

We also compare another metric called pacing between these al-gorithms. This captures how representative contracts are with re-spect to time dimension while delivering these contracts. Pacing is defined as the percentage of contracts that are within 12% of the linear delivery goal atleast 80% of their active duration.
Figures 5, 6 and 7 show that the under delivery and penalty cost for HWM (SHALE with 0 iterations) algorithm is the worst. Fur-ther as the number of SHALE iterations increase it gets very close to the "Optimal" algorithm. Note that even SHALE with 5 or 10 iterations performs as good or sometimes slightly better than the "Optimal" algorithm. This can be attributed to different reasons; one being the fact that there are forecasting errors intrinsic to using real serving logs. The other reason might be the fact that the ob-jective function of "Optimal" algorithm is not just optimizing for these two metrics. Figure 5: Dataset 1: Under Delivery and Penalty Cost Compar-ison
Figure 8 shows how these algorithm perform with respect to pac-ing. The pacing is pretty similar for all three datasets SHALE with 5, 10 and 20 iterations when compared with "Optimal" algorithm but HWM has better pacing than SHALE and "Optimal" for the other two datasets. The possible reasons here can be that SHALE and "Optimal" algorithm gives better under delivery and penalty cost compromising some pacing. Also note that time dimension is just one of the possible dimensions for the representativeness part f the objective function and SHALE and "Optimal" algorithm opti-mizes for all possible dimensions. Figure 6: Dataset 2: Under Delivery and Penalty Cost Compar-ison Figure 7: Dataset 3: Under Delivery and Penalty Cost Compar-ison
We described the SHALE algorithm, which is used to generate compact allocation plans leading to near-optimal serving. Our al-gorithm is scalable, efficient, and has the stop-anytime property, making it particularly useful in time-sensitive applications. Our ex-periments demonstrate that it is many times faster than using com-mercially available general purpose solvers, while still leading to near-optimal solutions. On the other side, it produces a much bet-ter and more robust solution than the simple HWM heuristic. Due to its stop-anytime property, it can be configured to give the de-sired tradeoff between running time and optimality of the solution. Furthermore, SHALE can handle  X  X arm starts, X  using a previous allocation plan as a starting point for future iterations.
SHALE is easily modified to handle additional goals, such as maximizing revenue in the non-guaranteed market or click-through rate of advertisement. In fact, the technique appears to be amenable to other classes of problems involving many users with supply con-straints (e.g. each user is shown only one item). Thus, although SHALE is particularly well-suited to optimizing guaranteed display ad delivery, it is also an effective lightweight optimizer. It can han-dle huge, memory-intensive inputs, and the underlying techniques we use provide a useful method of mapping non-optimal dual solu-tions into nearly optimal primal results. [1] Y. Chen, P. Berkhin, B. Anderson, and N. R. Devanur. [2] N. R. Devenur and T. P. Hayes. The adwords problem: online [3] J. Feldman, M. Henzinger, N. Korula, V. S. Mirrokni, and [4] J. Feldman, A. Mehta, V. S. Mirrokni, and S. Muthukrishnan. [5] A. Ghosh, P. McAfee, K. Papineni, and S. Vassilvitskii. [6] V. S. Mirrokni, S. O. Gharan, and M. Zadimoghaddam. [7] E. Vee, S. Vassilvitskii, and J. Shanmugasundaram. Optimal [8] J. Yang, E. Vee, S. Vassilvitskii, J. Tomlin, Recall that our optimization problem is Notice that we have multiplied the supply constraints by s our mathematics later.

The KKT conditions generalize the somewhat more familiar La-grangian. Let  X  j denote the demand duals. Let  X  i denote the sup-ply duals. Let  X  ij denote the non-negativity duals for x  X  j denote the non-negativity dual for u j . For our problem, the KKT conditions tell us the optimal primal-dual solution must sat-isfy the following The dual feasibity conditions also tell us that  X  j  X  0 ,  X   X  ij  X  0 , and  X  j  X  0 for all i,j . (While the primal feasibility conditions tell us that the constraints in the original problem must be satified.) Since our objective is convex, and primal-dual solution satisfying the KKT conditions is in fact optimal.

Notice that the stationarity conditions are effectively like taking the derivative of the Lagrangian. The first of these tells us that The complementary slackness condition for the  X  ij tells us that  X  ij = 0 unless x ij = 0 . This has the effect that when the ex-to make x ij = 0 . In particular, this implies The second stationarity condition shows  X  j = p j  X   X   X  j  X  0 , this immediately shows that  X  j  X  p j . Further, the com-plementary slackness condition for  X  j implies that  X  = 0 unless u plementary slackness of  X  j , we see in fact that equality must hold Hence, even when  X  j = 0 , equality must hold for an optimal  X 
Finally, the complementary slackness condition on  X  i either  X  i = 0 or P j  X   X ( i ) x ij = 1 . Putting all of this together, we see that 1. The optimal primal solution is given by x  X  ij = g ij 2. For all j , 0  X   X   X  j  X  p j . Further, either  X   X  j = p 3. For all i ,  X  i  X  0 . Further, either  X  i = 0 or P j  X   X ( i ) as we claimed in Section 3.

P ROOF OF T HEOREM 1. First, note that  X  j is bounded above by p j . We will show that  X  j is non-decreasing on each iteration. Let  X  t refer to the value of alpha computed during the t -th iteration, where  X  0 j = 0 for all j . We show by induction that d j for all t  X  0 . The base case follows by definition, since  X 
So assume for some t  X  0 that d j (  X  t )  X  d j for all j . Let  X  the value computed in Step 1 of Stage One of SHALE, given  X  We see that Further, by the way in which  X  t +1 is calculated (in Stage One, Step 2), we have that  X  t +1 j must either be p j or satisfy the follow-ing: Using the fact that for any numbers a  X  b that max { 0 ,a }  X  max { 0 ,b }  X  a  X  b (which can be shown by an easy case anal-ysis), we have That is, either  X  t +1 j = p j or Since d j (  X  t )  X  d j by assumption, this shows that  X  t +1 each j . We must still prove that d j (  X  t +1 )  X  d j . To this end, note that the  X  t +1 generated in Step 1 for the given  X  t +1 must greater than or equal to  X  t , since  X  t +1  X   X  t . That is,  X  t +1 Thus, as we wanted.

In general, we can use the fact that d j (  X  t )  X  d j for all t , together with Equation 10, to see that the  X  j values are non-decreasing at each iteration. From this (together with the fact that  X  j by p j ), it immediately follows that the algorithm converges.
To see that the algorithm converges to the optimal solution, we note that the dual values generated by SHALE satisfy the KKT conditions at convergence: for all j , either  X  j = p j or d (i.e. p j  X   X  j  X   X  j = 0 with either  X  j = 0 or u j = 0 ), with similar arguments holding for the other duals. Since the problem we study is convex, this shows that the primal solution generated must be the optimal.

As for our second claim, suppose that there is some j for which  X  j 6 = p j but d j (  X  t j )  X  (1  X   X  ) d j . Then by Equation 10, we see That is,  X  t +1 j increases (over  X  t j ) by at least  X V j at 0, is bounded by p j , and never decreases, we see that this can happen at most p j / (  X V j ) times for each j . In this worst case, this happens for every j , giving us the bound we claim.
