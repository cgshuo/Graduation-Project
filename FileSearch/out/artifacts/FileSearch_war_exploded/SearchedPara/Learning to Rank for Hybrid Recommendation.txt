 Most existing recommender systems can be classified into two cat-egories: collaborative filtering and content-based filtering. Hybrid recommender systems combine the advantages of the two for im-proved recommendation performance. Traditional recommender systems are rating-based. However, predicting ratings is an inter-mediate step towards their ultimate goal of generating rankings or recommendation lists. Learning to rank is an established means of predicting rankings and has recently demonstrated high promise in improving quality of recommendations. In this paper, we pro-pose LRHR, the first attempt that adapts learning to rank to hybrid recommender systems. LRHR first defines novel representations for both users and items so that they can be content-comparable. Then, LRHR identifies a set of novel meta-level features for learn-ing purposes. Finally, LRHR adopts RankSVM, a pairwise learn-ing to rank algorithm, to generate recommendation lists of items for users. Extensive experiments on benchmarks in comparison with the state-of-the-art algorithms demonstrate the performance gain of our approach.
 Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval X  Information fil-tering General Terms: Algorithms, Performance, Experimentation. Keywords: Recommender systems, Collaborative filtering, Learn-ing to rank, Features
Most existing recommender systems can be classified into two categories: collaborative filtering (CF) and content-based filtering . CF is based on the assumption that if users X and Y rate n items similarly or have similar behaviors, they will rate or act on other items similarly [11]. CF only uses the user-item rating matrix to make predictions and recommendations. Content-based filtering makes recommendations by finding regularities in the textual con-tent information of users and items, such as user profiles and prod-uct descriptions, where users and items are represented by a set of explicit features. To combine the advantages of the two and im-prove recommendation performance, various hybrid recommender systems [7] have been proposed in recent years, which have been found outperforming CF and content-based methods [13].
 Learning to rank for recommendation. Traditional recommen-dation systems are rating-based, where the recommendation prob-lem is reduced to the task of rating prediction. However, the ulti-mate goal of recommendation systems is to generate rankings or recommendation lists. Rating prediction is just an intermediate step towards ranking prediction and considered as an inferior ob-jective [2].

E XAMPLE 1. The objectives of rating and ranking prediction are not necessarily consistent with each other. Suppose the ground truth ratings are 5 and 4 for items A and B. While  X  X ating(A) = 4, rating(B)=5" is a better result than  X  X ating(A)=2, rating(B)=1" w.r.t. rating prediction, it is worse w.r.t. ranking prediction.
Recent efforts on ranking-based recommender systems include [5] and [10] that particularly made use of learning to rank tech-niques. Learning to rank [6] utilizes supervised or semi-supervised machine learning techniques to automatically construct a ranking model based on a given training data. It has been extensively and effectively applied to rank documents in information retrieval and Web search [4].

Same as CF, existing works on learning to rank for recommenda-tion [10, 12] only use the user-item rating matrix, where they adopt probabilistic matrix factorization [9] to represent users and items with latent features . These methods have demonstrated compara-tive advantages over their traditional CF counterparts. Learning to rank for hybrid recommendation. Existing hybrid recommender systems are not ranking-based. Existing learning to rank for recommendation methods do not use valuable content in-formation. In this study, we seek combined advantages of the two and propose LRHR, the first attempt that uses learning to rank for hybrid recommendation.

Nonetheless, it is not straightforward to adapt learning to rank to hybrid recommender systems. Unlike queries and documents in information retrieval, users and items are not directly content-comparable . In information retrieval, content similarity for query-document pairs indicates their relevance and can be used to rank documents. However, it does not make sense to compute the con-tent similarity between a user profile and an item description be-cause they are semantically unrelated.

To adapt learning to rank to hybrid recommender systems, LRHR first defines novel representations for both users and items so that they can be content-comparable. Then, LRHR identifies a set of novel meta-level features for learning purposes. Finally, LRHR adopts RankSVM, a pairwise learning to rank algorithm, to gen-erate recommendation lists of items for users. Extensive experi-ments on benchmarks in comparison with the state-of-the-art algo-rithms show that LRHR gains in rank-based performance measure of NDCG @ n .
Let U be a collection of user profiles, each depicting user X  X  at-tributes such as age and gender. Let I be a collection of item de-scriptions, each depicting item X  X  attributes such as title and release date. Each user u  X  U rates a set of items from I .Let R | be the rating matrix, where each element r p,q is a natural number indicating the rating score of item i q from user u p .
Let f be a ranking function. For a set of items I u from a single user u , f ( I u ) outputs a ranking of I u .Let f  X  be the optimal ranking function. A given loss function s ( f, f  X  ) can be used to estimate the goodness of f based on the distance between f and f  X  with respect to U .
 Ranking-based hybrid recommendation problem. Given a set of users U , a set of items I , a rating matrix R with respect to U and I , and a loss function s , the problem of ranking-based hybrid recommendation is to generate a ranking function f from U , I and R such that s ( f, f  X  ) is minimized, where f  X  is the optimal ranking function.
 Technical challenges. Ranking items for users are not as straight-forward as ranking documents for queries. In the document rank-ing problem, queries are treated as documents. They can be rep-resented using terms (i.e., pre-processed words) from the vocabu-lary of documents. Then, a set of meta-level features [1], such as term frequency (TF) and inverse document frequency (IDF), can be defined and used to measure the similarity or relevance of each query-document pair. Documents can be ranked according to their relevance to the query.

In the hybrid recommendation problem, user profiles can be con-sidered as queries and item descriptions can be considered as docu-ments. However, user profiles and item descriptions are not content-comparable. The vocabulary for user profiles and the vocabulary for item descriptions do not overlap and any content-based similar-ity between users and items would be zero and useless. Thus it is difficult to define meta-level features and adapt learning to rank to hybrid recommendation.
In this section, we represent user profiles and item descriptions to make them content-comparable. Then, we define two categories of features: meta-level features and rating-based features.
LRHR combines the vocabularies for user profiles and item de-scriptions to form a single vocabulary T . Then it adopts the bag of words model to represent users and items as vectors. In particu-lar, each user u is represented by a bag of user terms and a bag of item terms. The former contains the content information (profile) of u and the latter contains the content information (descriptions) of all items rated by u . Each item i is also represented by a bag of item terms and a bag of user terms. The former contents the content information (description) of i and the latter contains the content information (profiles) of all users who have rated i . In each representation, the frequency for each term will also be recorded.
In forming T , all the continuous values are first discretized. For (25 , 34] , etc.

E XAMPLE 2. Let u be a user who is 24, male, and a techni-cian. Let I u be a set of movies that are rated by u , containing 6 action movies, 4 adventure movies and 1 western movie. Then u can be represented by 6 terms: (18, 24](1), male(1), technician(1), action(6), adventure(4), and western(1).

E XAMPLE 3. Let u 1 and u 2 be two users who have rated movie i .Let u 1 be a 24 year-old male technician, and u 2 bea19year-old male student. Let i be an action and western movie. Then i can be represented by 6 terms: (18, 24](2), male(2), technician(1), student(1), action(1), and western(1).
Now we define a set of explicit meta-level features, inspired by term frequency TF, inverse document frequency IDF, and their combination TF-IDF.

TF-IDF is widely used for document ranking in information re-trieval. The term frequency TF t, d of term t in document d is gen-erally defined as the number of times that t occurs in d . It indicates the relevance of d to t .

The inverse document frequency IDF t of term t measures the general importance of t . It is obtained by dividing N by DF then taking the logarithm of that quotient, where N is the total number of documents and DF t is the document frequency of t , i.e., the number of documents containing t . Formally,
The TF-IDF value of a term is commonly defined as the product of its TF and IDF values.

Inspired by TF, IDF and TF-IDF that are used in learning to rank for information retrieval, we define a set of explicit meta-level fea-tures for LRHR. There are two categories of terms: user terms and item terms. Thus there are also two categories of meta-level fea-tures: user-oriented features and item-oriented features. Meta-level features for recommendation. Although conceptually we treat users as queries, items as documents, and transform the ranking-based recommendation problem into a document ranking problem in information retrieval, there are significant differences between the two. (1) In information retrieval, each document uses the same weight-ing scheme for all terms in the document. In our case, each repre-sentation has two categories of terms with different frequencies. In particular, as shown in Example 2 and Example 3, user terms in user representations and item terms in item representations have low frequencies (generally 1), which we call low-frequency terms . User terms in item representations and item terms in user represen-tations have very high frequencies, which we call high-frequency terms . Thus we need to use two weighting schemes.

In LRHR, we use the original TF for low-frequency terms, and use WF, a logarithm variant of TF, for high-frequency terms. Specif-ically, (2) While the low-frequency terms in user and item represen-tations usually have similar frequencies (generally 1), the high-frequency terms in the two kinds of representations may vary sig-nificantly. For example, a user may not have rated many movies, but a movie may have been rated by much more users (This is not reflected in Example 3. To construct a more realistic example, we would have to add many users for movie i ).
In general, the actual frequencies for the two kinds of high-frequency terms depends on the application. In LRHR, for the WF features, we use a larger logarithm base ( n ) for high-frequency terms with relatively higher frequencies, and a smaller logarithm base for high-frequency terms with relatively lower frequencies. (3) In information retrieval, queries are always shorter than doc-uments. For efficiency, the common practice for weighting queries and documents is to compute IDF for query terms and not to com-pute IDF for documents. In our case, we have two categories of terms: user terms and item terms. In LRHR, we compute IDF for user terms in user representations and item terms in item represen-tations.

E XAMPLE 4. Let u be a user represented by 6 terms: (18, 24](1), male(1), technician(1), action(64), adventure(16), and western(8). Let i be a movie represented by 6 terms: (18, 24](10,000), male(100,000), technician(1,000), student(1,000), action(1), and western(1). For the first 3 user terms in u and the last 2 item terms in i ,their TF values are 1. In this application, obviously the frequencies for high-frequency terms (user terms) in item representations are much higher than the high-frequency terms (item terms) in user representations. Thus we use a larger logarithm base (10) for the high-frequency terms in i and a smaller logarithm base (2) for the ones in u in computing WF. Specifically, the TF values for the last 3 item terms in u are 7, 5 and 4 respectively, and the TF values for the first 4 user terms in i are 5, 6, 4, 4 respectively.
Suppose the IDF values for the user terms (18, 24], male, tech-nician and student are 4, 2, 3 and 3, and the IDF values for the item terms action, adventure, and western are 2, 2 and 2. Then the TF-IDF values for the terms in u are 4, 2, 3, 14, 10 and 8. The TF-IDF values for the terms in i are 20, 12, 12, 12, 2, 2.
For each user term t in a representation for item i ,wedefinea rating-based feature, the average rating score avgScore t be the set of users who have rated the item i .Let U t i =  X 
U i be the set of users who have rated i and whose representations contain the term t .Let r k, i be the rating score assigned for i by user u
For each item i , we also define a rating-based feature, the av-erage score of the item avgScore i , which takes the average of avgScore t i values for all user terms in a representation for i .
Similarly, we also define 2 rating-based features for each user profile u : the average score avgScore t u for the item term t assigned by u , and the average score avgScore u which takes the average of avgScore t u values for all item terms in a representation for u .
In addition, for each item i ,wealsouse N i , the number of users who have rated i as a feature.
LRHR treats each user as a query, each item rated by the user as a document associated with the query, and the corresponding rating score as the relevance label.

LRHR formulates the generic ranking-based hybrid recommen-dation problem as a pairwise learning to rank problem, where item (documents) pairs are constructed based on their relevance scores. For the actual learning to rank algorithm that returns the ranking function f , LRHR uses RankSVM [4], a classic pairwise learning to rank algoirthm. RankSVM takes document pairs as instances in learning, and formulates learning to rank as classification.
In more details, let x be a document. Let f w = w  X  x be a lin-ear function where w denotes a vector of weights and  X  denotes inner product. Let x (1) i and x (2) i be two documents associated with query q i . The preference relationship x (1) i x (2) i means that x is more relevant than x (2) i w.r.t. q i , which can be expressed by w  X  x 0 . This way, the document sets with relevance labels can be trans-formed into a set of preference instances with labels y i  X  x stances are the training data for RankingSVM. The loss function of RankingSVM can be represented as follows. The LRHR algorithm. We have explained the main procedures of LRHR, we now summarize them and present the pseudocode in Algorithm 1.
 Algorithm 1 : The LRHR Algorithm
Input : A collection of user profiles U , a collection of item Output : Ranking function f
T  X  ExtractTerms ( U, I )
F  X  ExtractFeatures ( U, I, R, T ) ( U, I  X  I )  X  Formulate ( U, I, R ) f  X  LearningToRank ( U, I  X  I,F ) Line 1 extracts the vocabulary T for representing users and items. Line 2 extracts a set of features F , including meta-level features and rating-based features. Lines 3 formulates the ranking-based hybrid recommendation problem as a pairwise ranking problem, where pairs of items I  X  I associated with each user are generated based on their ratings. Line 4 learns a ranking function using a learning to rank algorithm such as RankSVM.
 Discussion. The main technical challenges in adapting learning to rank for hybrid recommendation are to represent users and items with the same vocabulary and make them content-comparable, and to define meta-level features and rating-based features for learn-ing purposes. For the actual learning to rank algorithm, many other algorithms can be considered besides RankSVM. For exam-ple, RankBoost, AdaRank and ListNet. While our experiments demonstrate initial success with RankSVM, the impact on recom-mendation quality from the various options of ranking algorithms needs to be further evaluated.
We used MovieLens 1 dataset containing 1M movie ratings. In our experiments, the dataset was partitioned into 5 parts for 5-fold cross validation, where 4 parts were used for training and 1 part for testing, and the averaged performance was reported.

We used 5 benchmark recommendation algorithms as compari-son partners. They included a hybrid recommender systems CBCF (http://www.grouplens.org/node/73 [7] (content-boosted collaborative filtering), 2 ranking-based col-laborative filtering algorithms including EigenRank [5] and CoFi-Rank [12], and 2 content-based filtering algorithms including NBCBF [8] (a conventional approach that is based on naive Bayesian text classification and adopted in CBCF) and LRCBF (our proposed learning to rank-based approach with only those content features).
Since our study focuses on improving item rankings instead of rating prediction, we employ the Normalized Discounted Cumula-tive Gain (NDCG) [3] metric for evaluation of the recommendation performance. This metric is popular in information retrieval for evaluating ranked results, where documents are assigned graded rather than binary relevance judgements.

In the context of collaborative filtering, item ratings assigned by users can naturally serve as graded relevance judgements. Specifi-cally, the NDCG metric is evaluated over some number n of the top items on the ranked item list. Let U be the set of users and r the rating score assigned by user u to the item at the p th position of the ranked list from u . The NDCG at the n th position with respect to the given user u is defined as follows.
 Forthesetofusers U , the average NDCG at the n th position is:
The value of NDCG ranges from 0 to 1. A higher value indicates better ranking effectiveness. NDCG is very sensitive to the ratings of the highest ranked items. This is modeled by the discounting fac-tor log(1 + p ) that increases with the position in the ranking. This is a highly desirable characteristic for evaluating ranking quality in recommender systems. This is because, just as in Web search, most users only examine the first few items from the recommended list. The relevance of top-ranked items are far more important than other items [5].
Figures 1 shows the performance comparison under the NDGG@1-5 measures. From the figure we can see that: (1) LRHR significantly outperformed the comparison partners on the MovieLens dataset, gaining performance improvement from 3.58% to 7.78% under NDGG@1-5. For example, LRHR achieved 0.7524 and 0.7542 on NDCG@1 and 2 while these numbers of CoFiRank are 0.6981 and 0.7091, gaining 7.78% and 6.36% re-spectively. (2) Hybrid algorithms outperformed collaborative filtering and content-based filtering. First of all, LRHR outperformed any other comparison partner including LRCBF, our proposed learning to rank-based approach with only those content-based features. Be-sides, CBCF also outperformed most of sophisticated content-based filtering and collaborative filtering algorithms, though it only adopted the most straightforward recommendation techniques such as naive Bayesian text classification for content-based prediction and Pear-son correlation coefficient for rating-based similarity measures. (3) Collaborative filtering algorithms EigenRank and CoFiRank significantly outperformed the conventional content-based filtering algorithm CBCBF . EigenRank gained performance improvement from 4.75% to 7.18% under NDGG@1-5, while CoFiRank gained from 2.66% to 7.67%.
In this paper we have described LRHR, the first attempt that ef-fectively adapts learning to rank to hybrid recommender systems, gaining combined advantages from ranking-based and hybrid rec-ommender systems. Experiments on benchmark datasets have demon-strated the promise of the approach. For future work, we plan to perform a systematic study on LRHR, investigating the various fac-tors that may affect its performance. For example, the definition of meta-level features and the selection of learning to rank algorithms. In addition, while we target recommendation quality in this study, it is important to consider efficiency as in the case of learning to rank for information retrieval.
This research was supported in part by the Natural Science Foun-dation of China (60970047, 61103151, 61173068, 71171122), the Foundation of Ministry of Education of China (20110131110028, 12YJC630211), the Natural Science Foundation of Shandong Province of China (ZR2012FM037, BS2012DX012), and the National Sci-ence Foundation (OCI-1062439, CNS-1058724).
