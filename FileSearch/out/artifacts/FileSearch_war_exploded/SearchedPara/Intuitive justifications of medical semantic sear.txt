 1. Introduction understood as answers to questions ( Roth-Berghofer and Richter, 2008 ) and often an explanatory dialogue ( Du et al., 2006 )is required to support users of a software system to make sense of its results. In this paper, we introduce the concept of intuitive explanation , which can be illustrated by means of an everyday scenario. Imagine, a 9-year-old child complains about dizziness and visits the doctor for an examination. After the examination the doctor concludes that the child suffers from M X ni X re ' s disease . The child does not know this particular disease. Thus, the doctor explains it as the child requires an explanation to understand the correlation of dizziness and M X ni X re's disease. The doctor will not elaborate on the M X ni X re's disease or use complicated termi-nology. On the contrary, she will roughly estimate the knowledge of the child and, based on that, give a short explanation. In other words, she relies on her intuition and experience with children of that age. M X ni X re ' s disease is a disease of the inner ear which causes, for instance, dizziness (probably supported by an illustration or an anatomical model of the ear) is an understandable explanation, enabling the child to process the given information and ask further questions. In contrast, the explanation that M X ni X re ' s disease is a dysfunction of the vestibular system is hardly understandable for a 9-year-old and therefore not helpful to the child. In the sense, intuitive explanations represent the fi rst explanations in an explanatory dialogue in which the explainer tries to give an understandable explanation based on a rough estimation of the knowledge of the communication partner. In addition, we assume that the situational context is unknown and hence, the explanation component has to enable follow-up questions leading to a complex explanatory dialogue. Note that intuitive explanations are not intended to be perfect, but they serve as an entrance into a dialogue.
We believe that a complex explanation need of a user can only be solved in explanatory dialogue (compare to Walton, 2007 ).
In this work, we illustrate the construction of intuitive expla-nations for the semantic search engine KOIOS  X  X  ( Forcher et al., 2010a ). KOIOS  X  X  provides keyword-based search on graph-shaped RDF data. Among other things it searches for Wikipedia articles that are annotated with medical concepts of medical structured data, namely the RadLex 2 ontology and a representa-tion of the International Classi fi cation of Diseases, Version 10 (ICD-10) ( M X ller et al., 2010 ). For example, the Wikipedia article about the shoulder blade can be annotated with the anatomical concepts  X  radlex:acromion  X  or  X  radlex:clavicle  X  . These concepts can then be used to retrieve the respective article. In this context, the search algorithm exploits the structure of the ontology to fi nd articles that are annotated with the same or adjacent concepts.
Since semantic search results are not always selfexplanatory, the explanation facility Kalliope is integrated into KOIOS  X  X  revealing a connection between search and annotation concepts and employs thesamestructureddataas KOIOS  X  X  . The constructed explana-tions are depicted as semantic networks containing various domain speci fi c concepts. As said the above intuitive explanations should be brief and contain preferably only understandable information. This applies to fi rst, labels of concepts, and second, the number of concepts. In case of RadLex and ICD10 it is possible to display concepts with more than one label. In addition, various rules can be applied to generate further connections between concepts and thus many different explanations can be constructed to justify one and the same search result. The question is only whether users can understand the connection between the concepts or concept labels or not. For instance, the statement  X  The fi nger is part of the upper limb  X  is easy to understand, but the statement  X  The acromion is part of the human body  X  may need further information (and is of questionable utility).

In this work, we present in detail the construction of under-standable justi fi cations for medical laypeople. The corresponding algorithm includes a method that is able to predict the under-standability of labels and label connections by considering their usage frequency in natural language, regarding different levels of expertise ( Forcher et al., 2009 ).

The rest of the paper is structured as follows: The next section gives an overview of relevant research on explanations and the ensuing section describes an abstract explanation generation approach. Section 4 introduces the search engine KOIOS  X  X  and motivates its explanation need. Section 5 describes user experi-ments and resulting concepts which constitute the groundwork to valuate explanations. Section 6 presents the construction algo-rithm of Kalliope in detail. The paper concludes with a summary and outlook. 2. On explanation
The notion of explanation has several aspects when used in daily life ( Passmore, 1962 ). For instance, explanations are used to describe the causality of events or the semantics of concepts. Explanations help correct mistakes or serve as justi fi cations. Furthermore, they are used to describe functionalities or to communicate practical knowledge. In the case of explaining semantic search results users are usually not interested in expla-nations of the functionalities and search algorithms. Instead, they need a justi fi cation to decide whether the search result is relevant and trustworthy.

Explanations in computer science were introduced in fi rst generation Expert Systems (ES). They were recognised as a key feature explaining solutions and reasoning processes, especially in the domain of medical expert systems such as MYCIN ( Buchanan and Shortliffe, 1984 ) where trust in results matters. Several approaches for providing explanations in expert systems were developed. XPLAIN ( Swartout, 1983 ), for instance, is a tool that helps users to build expert systems containing explanation com-ponents. For this reason, it uses domain facts for explanation purposes. The second form of input is a collection of domain principles, which are the methods or algorithms that apply to the facts. This system re fi nes the domain knowledge (preserving the knowledge) until it is at an appropriate level for the implementa-tion of an expert system. An extension is ESS (Explainable Expert System, see Swartout and Smoliar, 1987 ). Here knowledge about concepts and concept classes can be formulated. In the next section we present the requirements of Kalliope regarding various kinds of knowledge to generate explanations.

Explanation facilities were an important component support-ing the user's needs and decisions ( Swartout and Smoliar, 1989;
Swartout et al., 1991 ). In those early systems, explanations were often nothing more than (badly) paraphrased rules that lacked important aspects or too much information was given at once ( Richards, 2003 ). For that reason, Swartout and Moore formulated fi ve desiderata for expert system explanations ( Swartout and
Moore, 1993 ) which generally apply to knowledge-based systems (KBS). We considered especially the desiderata understandability and feedback. 1. Fidelity : The explanation must be an accurate representation of what the KBS really does. Hence, an explanation has to build on the same knowledge which the system uses for its reasoning. 2. Understandability : This comprises various factors such as user sensitivity and Feedback . User sensitivity addresses the user's goals and preferences, but also his knowledge with respect to the system and the corresponding domain. Feedback is very important because users do not necessarily understand a given explanation at once. The system should offer certain kinds of dialogue so that users can learn about the parts they do not understand. 3. Suf fi ciency : The system has to know what it is talking about.
This is an important factor to enable some kind of dialogue with the user. 4. Low construction overhead : It should not be too costly to integrate an explanation component into a KBS. 5. Ef fi ciency : The explanation component should not affect the performance of the whole system.

Wick and Thompson (1992) developed the Reconstructive Explai-ner (REX) and the concept of reconstructive explanations for ES.
Atrace, i.e., a line of reasoning , is transformed into a plausible explanation story, i.e., a line of explanation . The transformation is an active, complex problem-solving process using additional domain knowledge. The degree of coupling between the trace and the explanation is controlled by a fi lter which can be set to one of the four states, regulating the transparency of the fi lter. The more information of the trace is let through the fi lter, the more closely thelineofexplanationfollowsthelineofreasoning.Thisapproach enables a disengagement of an explanation component in order to reuse it in other expert systems. In a certain sense, the construction algorithm of Kalliope , using rating methods, represents some kind of fi lter that distinguishes intuitive from unintuitive explanations.
Another dimension guiding our research is the notion of explanation goals. S X rmo and Cassens (2004) describe different explanation goals for case-based reasoning systems, also applic-able to knowledge based systems in general. 1. Justi fi cation : Explain why a system's answer is a good answer.
It is used to give a simpler explanation according to the system process. 2. Transparency : Explaining how the system calculates a certain answer allows users to understand and (better) control the system. 3. Relevance : In conversational systems this goal aims at why a question asked by the software system is relevant. 4. Learning : In Tutoring Systems or Decision Support Systems it is important to teach users about the respective domain.

Focusing on each of these goals helps a software designer to focus on developing certain explanation capabilities. Explanation-Aware Software Design (EASD) looks at ways to guide software designers and engineers to a purposeful software system with explanation capabilities. Atzm X ller and Roth-Berghofer (2010) discuss further dimensions such as kinds of explanations, level of detail and presentation style, and illustrate their use in several data mining projects.
 component  X  as generic as possible  X  using formal knowledge such as ontologies for explanation provision. The focus of our work is to generate understandable and adequate explanations for knowledge-based systems. 3. Explanation generation processes main participants ( Roth-Berghofer and Richter, 2008 ): the user who is corresponding with the software system via its user interface, the originator , the tool that provides the functionality for the original task of the software (in our case, KOIOS  X  X  ), and the explainer (here, Kalliope ).
 the necessary knowledge about the inner workings of the origi-nator. In (rule-based) expert systems looking at the rule trace was the only way of accessing the originator's actions. Given that the inference mechanism is fi xed in those systems the trace was all the explainer needed.
 provide detailed information about its behaviour and solutions.
Therefore it is necessary that the originator prepares some kind of log representing the initial starting point for the explainer to generate explanations. Regarding user questions, this information is step-by-step being transformed into an understandable explanation.
The single steps or processes of an enhanced communication scenario are shown in Fig. 2 detailing the three participants of the explanation scenario. Fig. 3 shows our multi-layer explanation model in which each layer corresponds to a process transforming the results of a lower layer and providing input to the next layer.

Depending on the coupling, originator and explainer share information that is required for problem solving and for explana-tion generation as well. In Fig. 2 , this information is contained in two knowledge bases. The upper, red knowledge base is used by the originator for problem solving, the second (yellow) knowledge base, Explanation Knowledge Base (EKB), is fi lled by the originator and used by the explainer. The originator may have access to information which is hidden from the explainer and vice versa.
At least, they have to share a semantic log . As its name implies, the logging process collects all information with respect to the beha-viour of the originator for building the log. In our case, KOIOS  X  X  uses such ontologies as RadLex and ICD-10 to fi nd Wikipedia articles and adds semantic log entries to the EKB. KOIOS  X  X  does not need the log to search. The respective knowl-edge is only useful for the explainer. Kalliope on the other hand needs to know about the used ontologies to connect explanations with problem solving, i.e., search results.

Users communicate their explanation needs by keywords or in natural language. As the formal language of originator and explainer is often completely different from the user's language an interpretation process is necessary. In simpli fi ed terms, relevant parts of the semantic log and EKB must be identi fi ed and the exact explanation needs of the user must be determined. This is the task of the interpretation layer .

The interpretation layer does not necessarily represent ade-quate explanation information. Until this stage, the explainer is only aware of the users' explanation problem concerning, for instance, a possibly incomprehensible result of the originator. However, the information that solves the users' explanation problem completely has not been derived. This is the task of a construction process which is similar to the concept of reconstruc-tive explanations. To be more precise, the construction process takes the interpretation layer as an input which is transformed into the content layer containing relevant explanation information. As understandability is a very important aspect of explanation ( Swartout et al., 1991 ), this layer fi lters the information. Further-more, it takes up the knowledge of the user and reveals a connection between known and unknown information enabling the user to ask follow-up questions.

Explanation is information that can be communicated by text, charts, tables, etc. Each communication form has different applica-tion possibilities in an explanation scenario. Text can describe complicated conceptions whereas charts can reveal qualitative connections between concepts in a simple way ( Wright and Reid, 1973 ). The externalisation process of the externalisation layer trans-forms the output of the content layer into a formal description for communicating explanations. In this paper, weput a special empha-sis on semantic networks using graphs for depicting explanations. However,thislayerdoesnotincludelayoutandstyleinformation. This is the task of the presentation process which transforms the content of the externalisation layer into the presentation layer. The information of the last mentioned layer can be used by special renderer to visualise the explanation. The presentation process and the layouting of the semantic network is a very important aspect of understandability. For that reason, we developed a special layouting algorithm and described how the layout can contribute to intuitive explanations and the explanatory dialogue ( Forcher et al., 2012 ).
The main difference between this and existing approaches as presented in Section 2 is the provision of a mediation layer that is orthogonal to the others. The explainer creates some kind of meta log that is indicated by the arrow between explainer and EKB in Fig. 2 . In a way, the explainer is aware of single transformation processes and layers and thus, it knows how it explains a certain explanation problem. Consequently, the explainer knows of how explanation needs and explanation presentation correspond to each other. This knowledge is essential to continue the explana-tory dialogue and offers sophisticated interaction possibilities such as avoiding repetition of already given explanations or providing explanations from a different angle.
 In the next section we present the semantic search engine KOIOS  X  X  and illustrate the need for explanations of search results by means of a simple example. 4. Semantic search engine Koios  X  X 
KOIOS  X  X  is a semantic search engine that enables keyword-based search on graph-shaped RDF(S) data. Based on keywords KOIOS  X  X  computes a set of relevant sub-graphs with respect to the origin data. Subsequently, it renders the sub-graphs as seman-tic networks and presents them to users. The main advantage is that users do not need explicit knowledge about the query syntax or the underlying ontologies. The presented approach is based on the works of Wang et al. (2008) and Tran et al. (2009) .
For computing search results (sub-graphs), the keywords are fi rst disassembled into its constituent parts. It is a simple kind of syntactic analysis in which keywords were identi fi ed that belong together. For instance, the keywords  X  upper limb fracture article are separated into the parts  X  upper limb  X  ,  X  fracture  X  this purpose, KOIOS  X  X  computes a set of useful word combina-tions of the query, rates the combinations by means of the inverted index and selects the best combination for further processing. The result is a set of h terms T  X f t 1 ; ... ; t A T is either a single word or a multi-word expression.

To achieve a scalable search, the input data is preprocessed obtaining two main data structures. The inverted index is used to realise a mapping from terms to resources of the RDF data, for instance, the label  X  upper limb  X  can be mapped to the class
UpperLimb  X  . Note that the index does not only contain preferred labels for resources, but it also includes various synonyms. For instance, the class  X  radlex:ShoulderBlade  X  can be found by using terms such as  X  shoulder blade  X  or  X  blade bone  X  or  X  scapula optimised graph search, the RDF(S) data or graph data is repre-sented as an adjacency list.

In the second step, the keywords or keyword combinations are mapped to elements of the input RDF data. As illustrated in Fig. 4 the term  X  upperlimb  X  ismappedtotheRDFresource  X  radlex:UpperLimb  X  the term  X  fracture  X  is mapped to the resource  X  radlex:Fracture term  X  article  X  is mapped tothe class  X  koios:article  X  . This resources are called M-Resources (abbreviation forMapping-Resources)inthe rest of this work. In general, a term t i A T is mapped to a set of j M-... , R h that are used for further processing.

The resource sets R 1 to R h are distributed to h threads and in each thread Z i a graph exploration is performed on the prepared adjacency list for each M-Resource r i q A R i . Hence, many paths are determined starting from r i q . In case there is a resource r reached by any path in each thread a connecting sub-graph G the knowledge base (or EKB) can be constructed consisting of h paths. The resource r c is called the C-Resource , whereas the C stands for connection and thus, it connects all paths with one another. The outcome of the graph search algorithm is a set of weighted sub-graphs G 1 , ... , G q , whose size can be restricted by an upper weight limit and a general time limit (see Tran et al., 2009 for details on weighting).

Fig. 4 illustrates the KOIOS  X  X  search algorithm. The large arrows in the lower part of the fi gure represent the mapping process. This example assumes that every term t maps on exactly one M-Resource and thus the sets R 1 , R 2 and R 3 contain only one element. The centre part illustrates the graph exploration. There are many more paths starting from the M-Resources. The
C-Resource is a Wikipedia article about the  X  acromion  X  . The single paths are connected at this point resulting in a sub-graph of the base RDF(S) data.
 The last step is straightforward. For each sub-graph G 1 ; ... ; semantic network is constructed and presented to the user. Note that the presentation of the search results is an important issue.
Search engines should always include some hint why a particular result is relevant with respect to the keywords. Google, 3 instance, shows the title, some text snippets, and the URI of retrieved documents and highlights keywords contained therein.
This information represents some kind of explanation or justi fi cation which describes a connection between search and result.
 In the end, it can help the user to open only relevant documents. example. Fig. 5 presents a possible result of the keyword query  X  upper limb fracture article  X  . The selected result (last result) is the
Wikipedia article  X  wiki:Acromion  X  that is an instance of the class  X 
Article  X  . The presented semantic network itself can be seen as some kind of initial justi fi cation. It contains the mapping elements  X  upper limb  X  ,  X  fracture  X  and  X  article  X  and shows how they are connected. If only the result list on the left would be shown, users were probably not satis fi ed. However, the presented justi not very useful for users, especially for non-expert users.
First, the graph layout is too confusing and it needs some time to process the information. For instance, it should be made clear which resources are M-Resources and which is the result resource.
Second, the graph contains a lot of information, for instance, a relatively long path of part-of connections. The question arises whether the path can be shortened without losing the relevant content or becoming incomprehensible. Especially in case of smart phones with small displays, information reduction is an important aspect. For example, the part-of relation is transitive and thus the statement  X  The acromion is part-of the scapulae which in turn is part-of the shoulder griddle  X  can be shortened to  X  The acromion is part-of the shoulder griddle  X  . The path alternatives of the part-of relation are presented in Fig. 6 . Path alternative a 0 is the starting point and the same path as in Fig. 5 . Path variant d 0 is the shortest one, but it is questionable if it is the most useful explanation for medical laypeople.

Third, many nodes provide labels that were probably unknown for medical laypeople or at least for a 9 year old child with respect to the example in the introduction, for instance,  X  scapula  X  acromion  X  . Fig. 7 shows some alternative labelling possibilities with respect to the paths in Fig. 6 . For instance, a 1 is the same path as a 0 (same resources and connections), but the label of the resource  X  radlex:scapula  X  has changed.

Fourth, in general the search engine does not dispose of detailed user knowledge about the current user which is necessary to decide whether a certain explanation is understandable or not. It may be possible to estimate the knowledge by means of the keywords or ask the user for his level of expertise in the actual domain. However, the user is probably not willing to provide further information. As follows, the rating of understandability is not straightforward.

To summarise, there are two essential issues. The fi rst issue concerns the selection of adequate labels for graph nodes with respect to the level of expertise of the user. The second issue concerns the shortening of the graph in a way that the shortened path remains useful for users. As follows, there are many different possibilities to explain one and the same search result. But which explanation is the most useful and most understandable one for users of a certain level of expertise.

Consequently, it is necessary to de fi ne a function that can be used to rate explanations including a rating for resources and relations between resources with respect to understandability.
From a mathematical point of view, it is appropriate to weight the explanation graphs including nodes and edges. If good compre-hensibility is associated with low weight the graph with the lowest weight has to be selected. In the next section we describe our current approach to rate labels for nodes and to rate label connections for edges. 5. Estimating understandability: concepts and experiments
For rating explanations we de fi ne two functions. r  X   X  p  X  is based on Semantic Frequency Classes (SFC) and can be used to rate the understandability of a label p and thus it is possible rate a single node in an explanation graph marked with label p . The second function, r  X   X  a ; b  X  , rates the understandability of an association or connection of the labels a and b . The function makes use of
Semantic Cooccurrence Classes (SCC) and rates single edges in an explanation graph that connect two nodes whereas the source node is marked with label a and the target node is marked with label b .

SFC and SCC are calculated using a large text corpus. In our previous work ( e.g., Forcher et al., 2009, 2011a ), we used the
German Wikipedia 4 and the German corpus of the project  X  Deutscher Wortschatz  X  5 to calculate SFC and SCC as well. In this work we present new calculations using another text corpus that contains all articles of the German news magazine  X  Der Spiegel the years 1988  X  2011. This is due to the fact that Wikipedia contains many special articles and does not necessarily represent the natural language of average persons ( Forcher et al., 2011a ) which is important aspect in our approach. Furthermore, we need a large corpus to calculate SCC and thus, we could not use the corpus of the project  X  Deutscher Wortschatz  X  .
 r  X   X  a ; b  X  works out-of-the-box. No additional knowledge for both functions apart from the used text corpus is required. In this way, both functions realise our concept of intuitive explanations.
It should be noted that the functions could also be used to derive group speci fi c user knowledge. But, the knowledge alone does not allow to select the (intuitive) best explanation as we show in the following. 5.1. Rating resource labels
Classes and describe its development history starting with Fre-tion component to rate the understandability of single labels. Note, labels can be single-word-expressions as well as multi-word-expressions. 5.1.1. Frequency classes ability of labels and evaluated it in a user experiment ( Forcher et al., 2009; Roth-Berghofer and Forcher, 2011 ). The method emanates from the hypothesis that the degree of knowledge about scienti fi c terms correlates with the usage frequency in daily language ( Hayes, 1992 ). The more often a medical term is used in natural language the more users  X  know  X  that term, and, thus, the better understandable it is. Frequency classes are a useful statis-tical measure for handling the usage frequency of terms in daily language. The frequency class of a term t is de fi ned as follows ( zu Eissen and Stein, 2006 ):
De fi nition 1. Let C be a text corpus and let f(t) denote the frequency of a term t A C . The frequency class  X   X  t  X  of a term t is de fi ned as  X  log 2  X  f  X  t n  X  = f  X  t  X  X c , where t quently used term in C .
 corresponds to frequency class 0. Thus, a more uncommon term has a higher frequency class. In the following, we refer to any frequency class  X   X  t  X  X  i as  X  i . The maximum frequency class is denoted by  X  max .
 the hypothesis that the degree of knowledge of scienti fi correlates with their frequency classes with respect to a text corpus C . The experiment setting can be described as follows.
We selected randomly 200 medical German terms (single words) of the RadLex and ICD10 and determined their frequency classes.
We considered only frequency classes at a certain threshold terms with a frequency below  X  th are assumed to be generally known. All selected terms were randomly subdivided into four tests each containing a varying number of frequency classes. All test persons estimated their own knowledge of each term by giving a Personal Knowledge Estimation (PKE) on a scale from 1 to 5 (see Table 1 ).

We performed the experiment with 20 medical laypeople and could con fi rm our hypothesis: User knowledge of terms correlates with usage frequency of terms in daily language or the PKE correlates with frequency classes. The result of the experiment is illustrated in Fig. 8 which depicts an average value of the PKE as a function of frequency classes. Therefore, we build an average rating per term and based on that, we calculated the average rating per frequency class. In both cases we used the average mean as average function. Hence, we have a set D of pairs  X   X  j containing for each frequency class an average PKE rating.
One objective of the experiment was not only to verify a correlation between users' degree of knowledge and frequency classes. In fact, the intention was primarily to de fi ne a function based on frequency classes as a means of prognosis whether users with a certain level of expertise probably know a term or require supporting information. For that purpose, we de fi ned for medical laypersons the general function  X   X  t  X  that predicts the familiarity of terms by considering its frequency class  X   X  t  X  X   X  i . The function is based on three intervals of frequency classes representing a generalisation of the PKE scale. If n ; m A N and if n o m , the function  X   X  t  X  is de fi ned as follows:  X  t  X  X 
That means, an average PKE rating from 5 to 3.67 means well known , from 3.67 to 2.33 corresponds to in need of support and a rating from 2.33 to 1.0 represents completely unknown . In order to determine  X  n and  X  m we fi rst tried to fi nd an approximate function of the experiment data D . Regarding the curve in Fig. 8 we applied the exponential function y  X  ae bx and determined the following values: a  X  0 : 0591 and for b  X  7.9313. The approximate values for y  X  0 : 0591 e 7 : 9313 x of the frequency classes are shown in Fig. 9 .
With respect to the approximate values, we can de fi ne the parameters  X  m and  X  n for medical laypeople as follows:  X   X  20. In this case, the term  X  Gehirn  X  (brain) with  X   X  Gehirn  X  X  is a well-known term, in contrast to the term  X  Prosencephalon (prosencephalon) which is probably a completely unknown term for most people because  X   X  Prosencephalon  X  X   X  22 . When we com-pare the average user ratings per term with the results of error rate is about 32 percent.

Based on the function  X   X  t  X  we could select understandable labels for medical laypersons as described in Section 4 in case there are several labels for one and the same resource. 5.1.2. Semantic frequency classes for terms
The result of the experiment described above revealed some interesting outliers. The fi rst can be traced to the term Atlas .Itis an ambiguous term whose meaning in a geographical context is quite common. Its meaning as fi rst cervical vertebra is relatively unknown. The second kind of outliers can be traced to some compounds which are quite common for the German language. The meaning of those terms can easily be derived, but their occurrence in daily language is rare. Here an example is the word  X 
Nachtblindheit  X  (night blindness), which consists of the well-known words  X  Nacht  X  (night) and  X  Blindheit  X  (blindness). The third problem concerns the in fl ection of words in the German language (and in the English language as well). The term  X  Zecken  X  a signi fi cantly lower frequency class than the base word (tick), and thus it is more often used.

We tried to improve that method by handling the problems as described above. As compounds require more complex natural language processing, we only tried to handle the in fl ection and the ambiguity problem. As multiword-expressions and compounds affect the same problem we use the notion term for both single words and multiword-expressions, and we proposed Semantic Frequency Classes which can be de fi ned as follows: De fi nition 2. Let C be a text corpus, let f  X  t  X  denote the context dependent frequency of a term t A C and let t 1 ; ... ; t in fl ection forms of t . The semantic frequency class  X   X  t  X  of t de fi ned as  X  log 2  X  f  X  t n  X  =  X  f  X  t 1  X  X   X   X  f  X  t n  X  X  X c ; whereas t n denotes the most frequently used term in C .
In other words, semantic frequency classes denote how often terms and their fl exion forms are used in a certain context or meaning. For instance, it describes how often the word Atlas and its fl exion forms Atlasse and Atlanten are really used as cervical vertebra in the text corpus. Thus, the semantic frequency class of Atlas is much higher than its common frequency class. Consequently, we can de fi ne the method  X   X  t  X  that predicts the familiarity of terms by considering its semantic frequency class  X  t  X  X   X  i :  X  t  X  X 
Forcher et al. (2011a) showed that  X   X  t  X  provides slightly better results to predict the degree of familiarity than  X   X  t  X  . The evalua-tion of  X   X  t  X  can be done in the same manner as of  X   X  t  X  .We randomly selected 450 medical German terms of the RadLex and
ICD10 and determined the corresponding semantic frequency classes. Again, we considered only semantic frequency classes at certain threshold  X  th because all terms below are generally known.
Calculating semantic frequency classes requires a text corpus with a large number of content-focused documents. But the German corpus of the project  X  Deutscher Wortschatz  X  includes only one large document with millions of unsorted sets. For that reason, we constructed our own corpus that includes (daily language) articles that were published by the Spiegel Magazin 7 in the years from 1994 to 2009. Readers interested in the exact calculation of
Semantic Frequency Class can fi nd the algorithm in Forcher et al. (2011a) .

For evaluating  X   X  t  X  we developed a user experiment on a test platform. 8 From the 450 medical terms, the platform constructs tests with 30 random terms. As in the previously described experiment all test persons had to estimate their own knowledge of each term and provide a PKE on a scale from 1 to 5. An example test screen is shown in Fig. 10 . Here, the test item  X  Fieber has to be rated. In the lower part of the screenshot there are various hints about how to rate, for instance, information about the scale.

Altogether 77 tests were done by medical laypeople with at least 3 ratings for each term. The result of the experiment is illustrated in Fig. 11 which depicts an average value of the PKE as a function of the semantic frequency classes. Again, we built an average rating per term and based on that, we calculated the average rating per semantic frequency class. Hence, we have a set
D of pairs  X   X  j ; pke j  X  containing for each Semantic Frequency Class an average PKE rating. In both cases we used the median as average function. In contrast to Fig. 8 , the curve is monotonically decreas-ing and has no outliers. In order to determine  X  n and  X  m the same as for frequency classes, explained in Section 5.1.1 . In this respect again we calculated for  X   X  t  X  the values  X  n  X  14 and  X  20. But in this case now the error rate is 22 percent which means that in 8 of 10 cases the function  X   X  t  X  works correctly. 5.1.3. Semantic frequency classes for phrases
In general, labels of resources are seldom single words. Often they are descriptive phrases including several terms. In order to port semantic frequency classes to descriptive phrases Forcher et al. (2010b) de fi ned the following extension. A simple assump-tion is that an average value of all semantic frequency classes of all terms in a phrase can be used to determine the familiarity. But in this case, we face certain problems. Consider the phrase  X 
Phalange des Zeige fi ngers  X  (Distal phalanx of index fi stop words namely  X  des  X  (of) have a very low semantic frequency class which probably distort the average value. Second, medical phrases include sometimes known and unknown terms. In these cases it is not clear whether all terms in fl uence the level of familiarity in the same way, for instance,  X  Phalange  X  (phalanx) and  X 
Zeige fi nger  X  (index fi nger). In a preliminary experiment we found out that just one term in a phrase can in fl uence the understandability signi fi cantly. Considering only the maximum frequency class in this context is not useful although it has a very strong impact. However, the problem is less serious the lower the distance between the highest and the lowest semantic frequency class is.
 that calculates an aggregated semantic frequency class of several terms. The function makes use of the constant  X  c in order to stop words and it uses the function avg to calculate an average mean. The steps are as follows: 1. Detect all terms of phrase p . The result is a set of terms 2. Remove all terms t u A T where  X   X  t u  X  o  X  c . The remaining set is 3. Calculate a set of semantic frequency classes L  X  X   X   X  t 4. Determine  X   X  p  X  avg  X  L  X  .

In order to evaluate the presented algorithm we conducted another user experiment on the mentioned platform. For this experiment we again selected 450 random labels (no single words) of the RadLex ontology and the ICD10 representation whereas each test was constructed with 30 random terms. Again, test persons had to estimate their own knowledge about each term on a scale from 1 to 5 (see Table 1 ) indicating their Personal Knowledge Estimation (PKE).

The result of experiment for medical phrases is shown in Fig. 12 which depicts an average value of the PKE as a function of the semantic frequency classes. As the calculation of the semantic frequency class of phrases does not always result in a number divisible by 2, we rounded it to the nearest whole number.
Subsequently, we built an average rating per phrase and based on that, we calculated the average rating per semantic frequency class. In both cases, we use the average mean as average function. Hence, we have a set D of pairs  X   X   X  j ; pke j  X  containing an average
PKE rating for each semantic frequency class. Altogether, 54 tests were done by medical laypeople with at least 3 ratings for each phrase. If we used the median as average function in  X   X   X  p  X  we would observe the best error rate of 35 percent. In this case, the values for  X   X   X  p  X  are as follows:  X  n  X  12 and  X  m  X  16 which is based on the same calculation method introduced in Section 5.1.1 .
The result was not what we expected. An analysis of the results revealed that single unknown terms strongly interfere with the entire knowledge of labels. For this reason, there were very many labels in which users rated their knowledge as being very low. This is probably the reason why the in need of support interval is shifted to the left and is smaller than the ones before. Nevertheless, can give some hints in which labels are understandable in explanation and which are not. Just to remind the reader, it is not our intention to generate perfect explanations, but suitable fi rst explanations in an explanatory dialogue. 5.1.4. Explanatory value of labels
The function  X   X   X  p  X  for labelling resources in an explanation is very useful, if a resource has multiple labelling possibilities. However, it is not necessarily possible to compare labels of two different concepts but which is important when explanations are compared that differ only in one concept. Consider the following statements inspired from the example in Section 4 : 1. The scaphoid bone is part-of the wrist which in turn is part-of the upper limb . 2. The scaphoid bone is part-of the lower arm which in turn is part-of the upper limb .

Here, both explanations differ in the centre concepts wrist and lower arm . Both concept labels are more or less understandable and thus, the question arises, which explanation is better for a medical layperson (or a 9-year-old child). The second explanation is the better explanation because  X  wrist  X  is more precise than and thus, the explanatory value is higher. To con fi rm this hypoth-esis, we conducted another experiment (see Forcher et al., 2010b for details). We presented medical laypersons explanations that had the same structure as the examples above: A known concept, a bridge or centre concept and an unknown concept. We randomly selected 50 explanation problems of the ICD10 and for each problem we constructed three explanation alternatives, i.e., 150 explanation alternatives in total. A test set comprised 50 test items one alternative of each explanation problem. Here, every test person had to estimate the quality of an explanation on a scale from 1 to 5 (good, rather good, middle, rather bad, bad). The hypothesis is that there exists a correlation between semantic frequency classes or  X   X   X  p  X  and the quality of an explanation. If so, we could use this information to rate and compare labels of different concepts. As mentioned before, a concept label should not contain too general or too speci fi c information which is also re fl ected in the usage frequency in the daily language. General terms such as  X  disease  X  rather have a low frequency class, in contrast to speci fi c terms such as  X  idiopathic parkinsonism rather have a higher frequency class. We think that  X   X   X  p  X  of a concept label is close to the in need of support limit regarding medical laypeople.

The result of the corresponding experiment is shown in Fig. 13 which is also based on the newly constructed text corpus as introduced in Section 5.1.2 . An interesting outcome of the experiment is that people prefer labels with a low semantic frequency class whether it is quite common or not.

The fi gure shows that labels p with  X   X  p that are close to very good or useful, but only, if they are understandable and not in need of support. The usefulness rapidly gets worse the greater the  X   X   X  p  X  than  X  n is. We used the discovery of this experiment to de fi ne a new function r  X   X  p  X  to rate the explainability (and maybe usefulness) of medical phrases or medical concept labels. In order to determine an approximating function we smoothed the experi-ment data D including elements such as  X   X   X  j ; q j  X  . Here, q average quality rating per for the class  X   X  j . We applied polynomial smoothing because it is an easy-to-use method and it is very suitable for cleaning up the measurement values ( Krucker, 1996 ).
We chose a polynomial function of a degree of 3 because a degree of 4 or higher causes unstable performance ( Krucker, 1996 ):  X  p  X  X  X  a 0  X  a 1  X   X   X  p  X  X  a 2  X   X   X  p  X  2  X  a 3  X   X   X  p  X 
The polynomial smoothing was done using a web service 9 which provided the following coef fi cient values: a 0  X  6 a  X  2 : 588, a 2  X  0 : 194 and a 3  X  0 : 004. In this case, the function returns relatively high values for phrases that range in the known interval, whereas the highest values are returned for phrases that are close to the in need of support limit. In contrast, phrases that range in the in need of support or in the completely unknown get relative low values (compare to Fig. 14 ).

The function  X   X  p  X  returns values between 1 and 4.5 whereas 4.5 indicates understandable labels whereas 1.0 indicates hard to understand. With respect to the label selection problem as pre-sented in Section 4  X   X  p  X  can be used to select the most under-standable label of nodes if several labels are available. However, we have to integrate  X   X  p  X  into a further function to rate complex explanation graphs. For that reason, we de fi ne the following function to weight labels in an explanation: r  X   X  p  X  X  1 : 0  X   X   X  p  X  = 4 : 5  X  :
We normalise the value range of the function to values between 0 and 1. We take up the normalisation in the next section where we discuss the complete graph weighting strategy. The subtraction in r  X   X  p  X  is motivated by the following fact. As men-tioned above, we equate understandability of resource labels with low weight of nodes in an explanation graph. For that reason, understandable node labels have a weight close to 0.0 whereas non-understandable labels have a weight close to 1.0. 5.2. Rating label connections
In the previous subsection, we presented a new function that enables the rating of labels or phrases with respect to medical laypeople. In this section we de fi ne the function r  X   X  a enables the explanation component to rate the understandability of an edge between two nodes s (with label a ) and t (with label b ) that is based on our new concept of Semantic Cooccurrence Classes .
Here, the problem is to estimate whether the connection of two concepts (and hence of two labels) in an explanation is suitable or not. The principle intention here is to ensure that the connection of the resources is understandable in order to ensure that medical laypeople can follow the information fl ow. Consider the following statements: S1: The index fi nger is part of the hand.
 S2: The index fi nger is part of the lower arm.
 S3: The index fi nger is part of the upper limb.
 S4: The acromion is part-of the upper limb.
 S5: The acromion is part-of the shoulder blade.
 the RadLex ontology, and thus true statements. However, some of them are more or less useful in an explanation. For instance, statement S3 is true, but upper limb is a very general concept and does not help to classify the concept index fi nger more precisely. Especially this applies to concepts that are unknown to users (S4).
Moreover, when people can judge the content of an explanation as in statement S3 they possibly reject the explanation. In contrast to the statements S3 and S4 the statements S1 and S5 express direct connections between the concepts and may be more useful in an explanation than the others. It can be assumed that the concepts in a statement should not be too far apart. In general, the connectedness of concepts should be expressed in an ontology.
For instance, there should be a direct and explicit link between index fi nger and hand but not between index fi nger and upper body. However, this is not always possible due to engineering reasons.
 connectedness or closeness of concepts and according labels which affects the understandability to a high extent. The less the labels are connected, the less understandable the label connection is in an explanation. In this case, the method emanates from the hypothesis that closeness of terms is also represented in the everyday language. For instance, the terms  X  head  X  and  X   X  probably often occur together in equal semantic contexts. That means, the common occurrence of both terms in an article, is probably relatively often and the number of words in between is relatively small. In contrast, the terms  X  head  X  and  X  diencephalon  X  probably do not often occur together and the number of words in between must be relatively high.
 connections can be estimated by taking the frequency of their co-occurrence in the daily language into account. In this respect again, we build on document corpora which represent the daily language well. More precisely, we consider several words before and after the fi rst label which is called the term window of the label. The frequency of the co-occurrence of two labels roughly corresponds to the number of term windows in which both labels occur. Similar to Frequency Classes it is possible to examine single-word-labels, multi-word-labels and semantic term windows (term windows around a label with a certain context) separately. We will refrain from listing them again here and de fi ne Semantic Cooccur-rence Classes as follows:
De fi nition 3. Let C be a text corpus, let t n denote the most frequently used term in C ,let a 1 ... a h be all in fl ections of term a be all in fl ections of term b A C ,let Wa i  X  X  c 1 ; ... ; context dependent term window of a i in document D A C 4 b and let W ab be a set of all context dependent term windows Wa every in fl ection form of a in C .The Semantic Cooccurrence
Class  X   X  a ; b  X  is de fi ned as  X  log 5  X  f  X  t n  X  =  X  W
The calculation of Semantic Cooccurrence Classes is similar to the calculation of Semantic Frequency Classes . But in this case we used the base 5 logarithm in order to have fewer Semantic
Cooccurrence Classes . The fi rst factor in the denominator is used to strengthen the connectedness between the terms which means that high values for W ab and f  X  a  X  result in higher Semantic
Cooccurrence Classes . Regarding the new text corpus  X   X  a from 0 to 9 (and thus  X  max  X  9). If the value is 9 or  X  9 have no connectedness. Otherwise, they are strongly connected.
However,  X   X  a ; b  X  calculates the connectedness for terms but not for phrases. For that reason, we also de fi ne an aggregated function as  X   X   X  p  X  , that is  X   X   X  p ; q  X  : 1. Detect all terms of phrases p and q . The result is two sets of terms T p  X  X  p 1 ; ... ; p v and T q  X  X  q 1 ; ... ; q w . 2. Remove all terms t k A T p or t k A T q where  X   X  t k  X  ing sets are T x  X  X  x 1 ; ... ; x y and T z  X  X  z 1 ; ... ; 3. Calculate a set of all SCC L  X  X   X   X  x 1 ; z 1  X  ; ... ; 4. Determine  X   X  pq  X  avg  X  L  X  .

Our hypothesis is that Semantic Cooccurrence Classes or  X  can be used to determine the connectedness of values and subsequently estimate the understandability of the corresponding label connection. In order to evaluate our hypothesis we selected 450 random pairs of labels (edges) of the RadLex ontology and the ICD10 representation and constructed tests with 30 random pairs of labels. The experiment is also hosted on the mentioned test platform (see Section 5.1.2 ). Every test person had to estimate the closeness or connectedness of each pair of labels on a scale from 1 to 3 (see Table 2 ) indicating their Personal Closeness Estimation (PCE).

We performed the experiment only with medical laypeople and could con fi rm the hypothesis as described above: The perso-nal connectedness estimations correlate with Semantic Cooccur-rence Classes . The result of the experiment is visualised in Fig. 15 which depicts an average value of the PCE as a function of the Semantic Cooccurrence Class . First, we calculated the Semantic
Cooccurrence Classes of all labels and subsequently, we built an average rating per phrase and based on that, we calculated the average rating per Semantic Cooccurrence Class . In both cases we used the arithmetic mean as average function. Altogether, 33 tests were performed and each test case was done at least 3 times.
It must be noted that the curve is relative high which is not what we expected. Many pairs of labels were estimated as very close which is obvious as the terms were taken from a speci fi c ontology.
Either the test persons misjudged the connectedness or the description of the task was imperfect. Even if  X   X  pq  X  9 the average connectedness is relatively high.

However, if we choose a term window size of n  X  300 (300 words before and after the label) and the average mean for the average function in  X   X   X  p ; q  X  the correlation between PCE and SCC is monotonic decreasing as can be seen in Fig. 15 . Our hypothesis that connectedness can be estimated by means of SCC can be considered as con fi rmed.

Similar to the approach for SFC we could construct a function that fi ts the experiment data. Based on that we could calculate a PCE value for any pair of labels and thus estimate its connected-ness or understandability. However, the co-occurrence of two rather infrequent labels in a text window is not very likely what is not represented in the experiment result curve. For that reason, we de fi ned r  X   X  a ; b  X  to estimate the understandability of labels as follows:
The connectedness or the understandability of a label connec-tion becomes the smaller the higher the Semantic Cooccurrence Class of the labels is. In this respect again, the function returns values between 0 and 1 whereas 0 means understandable and 1 the other way round. The speci fi c reasons for the de fi above are discussed along with the overall explanation weighting strategy (see Section 6.1 ). 6. Constructing intuitive justi fi cations
In this section, we elucidate an implementation of the abstract explanation generation method as examined in Section 2 by means of Semantic Technologies and focus on the construction of intuitive justi fi cations with respect to the semantic search results of KOIOS  X  X  . In terms of the communication scenario (Fig. 1 ), KOIOS  X  X  is the originator and Kalliope is the explainer.
As mentioned before, explanations are generated by a set of processes resulting in a multi-layered explanation model. In order to differentiate the outputs of each single layer, we applied the technique of Named Graphs ( Carroll et al., 2004 ) and used the Resource Description Framework (Schema) (RDF(S)) to represent the entire knowledge. In the case of KOIOS  X  X  , the knowledge base contains the following ontologies: ICD10, RadLex and the ontologies of KOIOS  X  X  and Kalliope . In addition, the EKB includes rules to infer the transitive closure of the  X  rdfs:subClassOf  X  radlex:partOf  X  property. In addition, the EKB contains annotation data such as  X  wiki:Acromion rdf:type koios:Article  X  and
Acromion koios:hasAnnotation radlex:Acromion  X  . In the following, we explain the single steps in detail, along with the example introduced in Section 4 . The fi rst step or interpretation process of the explanation generation approach translates the explanation need of users into the language of KOIOS  X  X  and Kalliope , whereas the explanation need is formulated by using keywords (translation layer). Technically speaking, Kalliope maps the keywords (and other contextual keywords) of the explanation request to elements of the EKB and tries to fi nd a connection between the mapped elements (M-Resources). Hence, the interpretation step performs a semantic search as described in Section 4 returning a set of sub-graphs of the EKB. Apart from that, the interpretation process of
Kalliope is also done with KOIOS  X  X  . To keep things simple, we build on the result of the example as presented in Fig. 5 and illustrate the simpli fi cation of the sub-graph. That sub-graph is the result of the interpretation process and initial input for the construction process. A simpli fi ed illustration of that sub-graph is shown in Fig. 16 . The leaf nodes correspond to the M-Resource and the top center node represents the C-Resource. The gray nodes and according edges in the middle are the explanatory elements.
For reasons of simplicity and accessibility, some nodes contain the preferred labels of the resources and are not labelled with the QName of the corresponding resources.

In general, the originator prepares a semantic log ( Forcher et al., 2011b ) using a process language such as OWL-S ( Martin et al., 2007 ). To justify search results of KOIOS  X  X  , we use the result as outlined in Section 4 and adapt the presented sub-graph to users (construction layer). The construction consists of four sub steps: extension , multiplication , weighting and search .
Before that, all possible statements are added to the content layer results. The statements of the initial content layer results and rules of the EKB are added to a rule engine. The inferred statements in turn are added, thus extending the content layer results (see Fig. 17 ). Regarding the current example only part-of statements are added, for instance the statement  X  radlex:Acromion radlex:partOf radlex:UpperLimb  X  .

Every resource of the EKB or content layer is represented by a node and has exactly one assigned label regardless of multiple label possibilities. The multiplication creates c copies of a resource node n if there are c further label possibilities in the EKB. In addition, all incoming and outgoing edges to other nodes were copied. Exceptions to this rule are the mapping elements. If there is more than one node with more than one labelling per resource, the described process is completed for each node one after another. Fig. 18 illustrates the extension process. For reasons of clarity, there is only one alternative label for the resource Scapula  X  added.
 means of the concepts as presented in Section 5 . The weight for the node n is determined by their label and the function r  X   X  l
The weight for the edge e is determined by the labels of their nodes and the function r  X   X  l s ; l t  X  whereas s is the source and t is the target of e . We designed both methods in a way that all weights range between 0.0 and 1.0. As mentioned above, 0 means that the corresponding node or edge is probably understandable whereas 1.0 indicates the opposite. More design details are eluci-dated at the end of the section. The result of the weighting step is illustrated in Fig. 19 (note the weightings belong to German explanations).

M-Resource and the C-Resource. This kind of search is equal to the connection search as set out in Section 4 which is also called the Reconnection Search . The weight of a path (and sub-graph) with edges nodes n 1 ; ... ; n x and e 1 ; ... ; e y equals the tracked paths with the lowest accumulated weights which are probably the most understandable one. The corresponding sub-graph represents the best explanation (Fig. 21 ) and contains information of the content layer.

The simpli fi ed explanation has one concept less than the result as presented in Fig. 5 . In addition, the resource  X  radlex:Scapula labelled with  X  scapula  X  that is estimated to be a worse label than  X  shoulder blade  X  for medical laypeople. The question arises why the simpli fi ed explanation contains no direct connection between  X  radlex:Acromion  X  and  X  radlex:UpperLimb  X  which is probably a worse explanation because it does not contain any anchor point to ask further questions. The reason for this lies in the design principles of the two weighting functions. 6.1. Weighting principles an explanation (or explanation path) should be as short as possible, but it should contain as much information as possible to understand the problem. As mentioned above, the weight of an explanation path is the sum of all weighted nodes and edges contained in the path and the weightings for nodes and edges range between 0 (understandable) and 1 (very hard to under-stand). As follows, the lower the weight of an explanation path, the less elements the path contains and thus, the more understand-able it is. However, if the path contains too few information with respect to laypeople it is not understandable at all. Consider the following example. The explanation that the acromion is part of the upper limb is in fact an explanation but it does not help the user to go further. We think, users need some kind of bridging concept to understand better the location of the acromion ( Forcher et al., 2010b ). Therefore it must be possible that a path with two edges and three nodes has a lower weight in contrast to a path with one edge and two nodes. For instance, compare path d
Fig. 6 to path c 1 in Fig. 7 . The maximum weight for a path such as d is equal to 3. As a consequence, if path c 1 should be selected the weight must be smaller than 3. We decided to design this kind of weighting by means of the following function:
The function returns a very low weight for a small SCC. But if the SCC gets larger, the weight grows exponentially higher. In this way a path with two edges can have a lower total weight than a path with only one edge. If  X   X  st  X   X  max the function r  X   X  l
If  X  acromion  X  ,  X  shoulder blade  X  ,  X  upper limb  X  ) has a value of 1.62. 6.2. Remarks on Kalliope
Kalliope does not ful fi ll all the desiderata formulated by Swart-out and Moore and not all explanation goals de fi ned by S X rmo and Cassens are addressed. Regarding the fi delity desideratum,
Kalliope uses on the same knowledge as KOIOS  X  X  , but the paths between search and annotation concepts are not necessarily the same. Although both components employ the same search algo-rithm the weighting principles are different and thus the results can differ. As a consequence, the fi delity desideratum is not ensured. Kalliope only tries to justify the results of the search engine and does not make the search algorithm transparent for users (compare to explanation goals in Section 2 ). Trans-parency does not mean describing what actually happened during problem solving. Users typically are not interested in the details but want to make sense of how a result was achieved. In terms of Reconstructive Explanations, the line of reasoning and the line of explanation do not need to be identical. The construction and the weighting principles represent such a fi lter that extracts user adapted information.

The understandability desideratum, on the other hand, is very important in our current approach. The entire system is intended to give understandable explanations in an explanatory dialogue starting with intuitive explanations. In addition, the bridging concepts support the learning goal because it helps users to extend their knowledge.

The suf fi ciency desideratum is ensured by the multi-layered explanation model. Kalliope disposes about the entire knowledge base and knows how explanations were derived. Just as a quick reminder, the single layers of the model are connected via the mediation layer and thus Kalliope knows how user questions are related to explanation contents and presentations. This con-cept will enable sophisticated dialogues in future versions of KOIOS  X  X  .

In general, Kalliope is independent of KOIOS  X  X  because it just needs access to the knowledge base of the system to explain. In theory, overhead is only produced by adding additional knowl-edge. For instance, Kalliope needs rules and facts to create the explanation space. Not always are transitive rules suf fi explain search results.

Finally, the ef fi ciency of KOIOS  X  X  is not affected. KOIOS  X  X  creates logging information, but this computational effort can be neglected. Kalliope only needs the search and annotation concepts to construct a justi fi cation. It does not need to know which functions were called or which intermediate results were produced.

As mentioned above, intuitive explanations represent a suitable start into an explanatory dialogue. To continue the dialogue
Kalliope offers mouse-click events on nodes so that users can get more information about the respective concepts. Currently, these kinds of events center the corresponding node in the explanation panel showing a selection of connections to other nodes. This represents some kind of conceptual explanations and thus, they give an answer to  X  What is the meaning of ... ?  X  . Furthermore, it is also possible to expand shortened paths to their original length, to give feedback or to get another explanation in case the fi rst intuitive explanation is not understandable enough. At the moment, Kalliope does neither offer any further features nor it does analyse the interaction and feedback. Nevertheless, it should be noted that the interaction of the user is already logged.
As mentioned in Section 3 the explanation component is aware of whole explanation scenario including user problem, given expla-nation(s) and according interactions. This enables Kalliope to adapt more and more to the scenario and to generate sophis-ticated explanations by, for example, applying machine learning techniques. 6.3. Discussion on complexity be reduced to the complexity of the Steiner tree problem which is an
NP-complete problem ( Karp, 1972 ). However, our implementation includes four abort criteria, namely time limit, max path costs, max path length, and path construction limit in all threads (compare to section 4 ). In one of our biggest search scenarios (music domain) the graph consists of 25 million edges. A common server on a virtual machine (16 GB Memory, Single Core 3 GHz) evaluates several million paths (ca. 1 million) in only a few seconds (ca. 1 s). blem. As described in section 6 , the simpli fi cation comprises four subprocesses, namely extension, multiplication weighting and reconnection. The extension includes the inference of further edges that is done with a Prolog system and the addition of the edges to the graph of the interpretation layer. Internally, the system uses backtracking (depth-fi rst search) to generate answers.
In the worst case, it is an exponential problem O  X  z n  X  to solutions (search depth n and z branches starting from each partial solution) ( Carter et al., 1985 ). The number of possible edges depends on the rules and the domain itself and thus, further analysis is dif For that reason, let the resulting explanation graph be fully connected.
A fully connected (and undirected) graph with k nodes includes k n  X  k 1  X  edges. As follows, the addition of the remaining edges to the graph of the interpretation layer has a quadratic complexity O  X  k
In the multiplication step further nodes and edges have to be added to the extended graph. Let us assume that every node has t additional label alternatives and thus, there are t n k  X  m operations for adding further nodes (linear complexit y). The maximum number of further edges is m n  X  X  m  X  1  X  which is also a quadratic problem, whereas the weighting of all nodes and edges is a linear problem. However, the reconnection is also a Steiner tree problem and thus, the whole simpli fi cation problem is NP-complete.

In real scenario, people seldom use more than 4 keywords (4 leafs) and a maximum path length bigger than 5 is not very useful because the semantic connection gets worse. In addition, more than 2 alter-of the multiplication step contains 60 nodes and 3540 edges. If each edge is examined for each starting point (4 leafs and 1 root) in the reconnection step there are 5 n 3540  X  17 ; 700 operations. As a result, the simpli fi cation in practice causes less than a hundred thousand operationswhichisnotverytimeconsumingonmoderncomputers. 7. Summary and outlook
In this work, we presented our conception of intuitive justi tions that represent the fi rst explanations, i.e., starting point of an explanatory dialogue, and they do not claim to be perfect explana-tions. Further, we presented the generic explanation facility Kalliope which is integrated in the search engine KOIOS  X  X  to enable semantic search on medical Wikipedia articles. The expla-nation facility employs the same structured data as KOIOS  X  X  and uses Reconstructive Explanations in order to provide intuitive justi fi cations of medical semantic search results. We described in detail the construction process of Kalliope focusing on the selec-tion of the most understandable justi fi cation for medical lay-people. We illustrated that there are several possibilities to justify one and the same search result which is due to multiple labelling alternatives and inference of further connections between concepts (transitive closure of is-a and part-of ). We designed an explanation weighting function that builds on two fundamental concepts, namely Semantic Frequency Class and Semantic Cooccurrence Class . The fi rst one can be used to anticipate whether users know the corresponding concept and the second one can be used to anticipate whether users know connections between concepts. Both hypotheses were con fi rmed by means of various user experiments that were also described in this work.
The next step of our research is to re fi ne the proposed weighting method for evaluating not only single labels and label connections but also the explanation in its entirety. It is possible that an explanation includes single paths including more than one relation type, for instance, a mix of is-a and part-of relations. We will investigate in how far this affects the explanation capability of our approach. Furthermore, an entire evaluation of the explana-tion generation model based on Semantic Technology needs to be done. Finally, we will investigate how user interactions and feed-back can be analysed and how this can be leveraged to provide sophisticated explanation dialogues.
 Acknowledgements
This work was funded in part by the German Federal Ministry of Education and Research (BMBF) in the EMERGENT project (Grant number 01IC10S01) and in part by the German Federal
Ministry of Economics and Technology (BMWi) by the THESEUS program in the MEDICO project (Grant number 01MQ07016). The responsibility for this publication lies with the authors. References
