 Many applications often require finding a set of items of in-terest with respect to some aggregation constraints. For ex-ample, a tourist might want to find a set of places of interest to visit in a city such that the total expected duration is no more than six hours and the total cost is minimized. We re-fer to such queries as SAC queries for  X  X et-based with aggre-gation constraints X  queries. The usefulness of SAC queries is evidenced by the many variations of SAC queries that have been studied which differ in the number and types of con-straints supported. In this paper, we make two contributions to SAC query evaluation. We first establish the hardness of evaluating SAC queries with multiple count constraints and presented a novel, pseudo-polynomial time algorithm for evaluating a non-trivial fragment of SAC queries with multiple sum constraints and at most one of either count, group-by, or content constraint. We also propose a heuris-tic approach for evaluating general SAC queries. The ef-fectiveness of our proposed solutions is demonstrated by an experimental performance study.
 H.2.8 [ Database Management ]: Database Applications Algorithms Set-based query, aggregation constraints
Many database applications often require finding a set of items of interest with respect to some aggregation con-straints. As an example, consider the following database relation which stores information about places of interest: POI ( name ,price,hour, type,city ). Here, name refers to a place of interest located in city with a ticket fee of price dollars, hour refers to the recommended duration to spend at that place (in hours), and type refers to the category of the tourist place (e.g., museum, park). Suppose that Alice plans to find a tour package of places to visit from POI that satisfies the following requirements: (R1) all places are located in NY city, (R2) the total price is between $300 and $400, (R3) the expected duration is no greater than 10 hours, and (R4) the number of distinct types of places is maximized (to maximize diversity). Observe that Alice X  X  request involves a simple filtering constraint, R1, and three aggregation constraints: two sum constraints (R2 and R3) and a count constraint, R4, to be maximized. The query X  X  result consists of a collection of matching packages where each package is a set of places of interest that satisfy the four requirements.

Besides the  X  X lobal X  aggregation constraints illustrated by the above example, another very useful type of aggregation constraints are  X  X ocal X  group-by aggregation constraints that specify an aggregation constraint on specific subgroup(s) or all subgroups of the qualified sets, where a subgroup is de-fined with respect to an attribute list and optionally specific attribute values. As an example of a group-by count con-straint on a specific group, Alice could require that there must not be more than two museum places in a matching package. In contrast, an example of a group-by sum con-straint that is specified on each group is when Alice requires that the total visit duration to places of the same type does not exceed four hours.

Yet another useful type of set-based constraints are con-tent constraints to specify the presence of certain attribute values (or tuples) in each qualified set. As an example, Al-ice could specify that each matching package must contain a visit to  X  X entral Park X .

We refer to such set-based queries with any combina-tion of aggregation, group-by, and content constraints as SAC queries . The usefulness of SAC queries is evidenced by the variants of SAC queries (with different restrictions on the number and types of constraints permitted) that have been studied: OPAC queries for business optimization problems [4], student course planning in the CourseRank project [2], and item recommendations in shopping applica-tions [1].

While SAC queries have many useful applications, the queries may not be easily expressed using SQL due to the fact that the qualified sets generally have different cardinalities and the maximum cardinality of the sets is data-dependent. More importantly, even when such complex queries can be expressed and evaluated by SQL engines, their performance can be very poor as demonstrated by our experimental re-sults. Indeed, the evaluation of general SAC queries involving any combination of aggregation, group-by aggregation, and content constraints is an NP-complete problem. Although a number of polynomial [2] and pseudo-polynomial time [4, 5] algorithms have been developed for evaluating simpler fragments of SAC queries, most of the proposed evaluation techniques are heuristic methods for more general SAC query fragments [1].
 Contributions. We make two key contributions to the study of SAC query evaluation by addressing two open is-sues. First, there is the question of whether there exists other non-trivial fragments of SAC queries that can be eval-uated in polynomial/pseudo-polynomial time. Currently, there are two fragments of SAC queries that are known to be amenable to efficient evaluation. First, SAC queries with one count constraint and at most one group-by count con-straint, where the attribute(s) in the count and group-by constraint are the same, can be evaluated in polynomial time [2]. Second, SAC queries with any number of sum con-straints and at most one group-by sum constraint can be evaluated in pseudo-polynomial time [5]. An open question that arises from this fact is: what is the complexity of eval-uating SAC queries with more than one count constraint or with a combination of sum and count constraints? In this paper, we address this issue by first establishing that even for SAC queries with only two count constraints, the eval-uation problem is already an NP-complete problem in the strong sense . Given this negative result for multiple count constraints, we next show that for the SAC query fragment with any number of sum constraints and at most one of either count, group-by, or content constraint, the evalua-tion problem has pseudo-polynomial time complexity, and we present a dynamic programming approach to evaluate this non-trivial SAC query fragment. Our second contribu-tion is the proposal of a heuristic for evaluating general SAC queries with any combination of sum, count, group-by, and content constraints. The heuristic tries to find a solution that satisfies all the specified constraints but may return an approximate solution that meets only some of the con-straints.
A S et-based query with A ggregation C onstraints (or SAC query for short) can be expressed in terms of two compo-nents, Q =( Q base ,C ans ). Q base ,whichisthebasequery of Q , is a conventional relational query that retrieves a set S base of tuples, which serves as the base data for the SAC query. C ans is a set of aggregation/group-by/content con-straints such that each subset S ans  X  S base that satisfies all the constraints in C ans is a result of the SAC query Q .
The basic aggregation constraint in C ans is a numeric con-straint of the form  X  Xopc  X , w h e r e X is some expression (to be described), op is one of the standard comparison opera-tors (= ,  X  ,  X  ,&lt;,&gt; ), and c is a non-negative integer constant. The constraints permitted in C ans are of the following five types: (1) A sum constraint is a constraint on the sum of some attribute A i in S ans , denoted by sum ( A i ) op c . (2) A count constraint is a constraint on the number of distinct values of a subset A of the attributes in S ans denoted by count ( A ) op c .When A is a candidate key attribute of S ans , the count constraint becomes a cardinality constraint . (3) An optimization constraint is specified to maxi-mize/minimize an aggregated value, and there are two forms of optimization depending on whether the aggregated value is bounded. A bounded optimization constraint is of the form  X  opt ( agg ( X )) op c  X , a n d a n unbounded optimization constraint is of the form  X  opt ( agg ( X )) X . Here, opt is ei-ther minimize or maximize ; agg is an aggregation operator (sum, count); X is either a single attribute (if agg is sum or count) or a sequence of attributes (if agg is count); and op is an non-equality comparison operator. As an exam-ple, the constraint maximize ( sum ( A i ))  X  c is a bounded optimization constraint on sum ( A i ), while the constraint maximize ( sum ( A i )) is an unbounded optimization constraint on sum ( A i ). (4) A group-by constraint is of the form groupby ( A , agg, B ) op c ,where A and B are subsets of attributes in S ans and agg is an aggregation operator (i.e., sum or count). The constraint requires that if S ans is partitioned into groups of tuples having the same values for attribute(s) A ,theneach group must satisfy the aggregation constraint agg ( B ) op c . In addition to this basic form of group-by constraint where the same count/sum constraint (i.e. c ) is applied to each group, it is also possible to specify individual count/sum constraint for each group by explicitly listing the desired values of c  X  X  using the form: groupby ( A = v i , agg,B ) op c (5) A content constraint is of the form contain ( A ,V ), where A is a subset of attributes in S ans ,and V is a set of tuple values (of the same arity as the number of attributes in A ). The constraint requires that the projection of S on A must contain the set of tuples V .

In this paper, the SAC query fragment that we study al-lows C ans to contain at most one group-by constraint. For other types of constraints, C ans can contain any number of them 1 . Furthermore, the domain of the attribute involved in a sum or optimization constraint must contain non-negative values. For simplicity and without loss of generality, cardi-nality constraints are treated as a form of sum constraints (i.e., summing on a virtual attribute with a value of 1 for each tuple); therefore, we will not explicitly discuss cardi-nality constraints in this paper.

Since the problem of evaluating a SAC query is very hard in general, we focus on finding some answer for a given SAC query and leave the problems of ranking and/or finding top-k answers for SAC queries as part of our future work. We will use the tour package database illustrated in Figure 1 as our running example.

Example 1. Our example SAC query in the introduction can be expressed as follows: The base query Q base corre-sponds to the SQL query: SELECT * FROM POI WHERE city =  X  X Y X , and the aggregation constraints are specified as follows: (R2) sum ( price )  X  300 , sum ( price )  X  400 ;(R3) sum ( duration )  X  10 ;and(R4) maximize ( count ( type )) . The additional local group-by count, local group-by sum, and content constraints discussed are specified, respectively, as follows: groupby ( type = museum, count,  X  )  X  2 , groupby ( type, sum, duration )  X  4 ,and contain ( name,  X  Central Park ) .
Note that when there are multiple optimization constraints, thequerybecomesaskylinequery. Figure 1: Running Example: Place of Interest (POI) relation With the exception of two fragments of SAC queries, namely, SAC queries with one count constraint and at most one group-by count constraint [2] and SAC queries with any number of sum constraints and at most one group-by sum constraint [5], most of the proposed techniques for evaluating more general SAC queries are heuristic solutions [1]. This raises the inter-esting open question of what is the complexity of evaluat-ing SAC queries with more than one count constraint or SAC queries with a combination of sum and count constraints.
To address this issue, we first establish the following re-sult on the evaluation of SAC queries with multiple count constraints; the proof is given elsewhere [6].

Theorem 1. Consider a SAC query Q where C ans con-tains exactly two count constraints on two distinct attributes. The problem of evaluating Q is NP-complete.

Given the above negative result for SAC queries with mul-tiple count constraints, we next ask the question of whether SAC querieswithatmostonecountconstraintcanbeeffi-ciently evaluated. In this section, we show that for the SAC query fragment with any number of sum constraints and at most one of either count, group-by, or content constraint, the evaluation problem has pseudo-polynomial time com-plexity, and we present a dynamic programming approach to evaluate this non-trivial SAC query fragment. Our dynamic programming approach can also evaluate SAC query that in-cludes any number of sum constraints and one count, one group-by, and one content constraint, where the attribute(s) used in these constraints are the same.
In this section, we present a novel, pseudo-polynomial time algorithm, termed DP , for evaluating SAC queries with any number of sum constraints and at most one of either count, group-by, or content constraint. For convenience, we refer to this SAC query fragment as multi-sum SAC queries .
To simplify the presentation, we first explain how DP eval-uates a simpler subset of multi-sum SAC queries with mul-tiple sum and a single count constraints, and then briefly discuss the generalization of DP to solve the general multi-sum SAC queries in Section 3.3.

For simplicity and without loss of generality, we explain the evaluation for a SAC query Q =( Q base ,C ans )where C contains the following two constraints on two attributes A and B and the domain of A contains integer values 2 .
If the domain of A contains real values, DP approximates the real values by integer values.
P 2 t 4 Y 2 museum t P 3 t 6 Z 1 shopping Let denote the number of distinct B attribute values in S base .Recallthat S base is the set of base data retrieved by thebasequery Q base . DP is based on the following two-phase dynamic programming approach.

First, DP partitions S base using the B attribute into partitions P 1 ,  X  X  X  , P . For each partition P i , DP derives SV i = { V  X  [1 ,K ] | X  P s,i  X  P i s.t. t  X  P s,i ( t.A )= V We say that a value V  X  SV i is the representation of a set P s,i  X  P i iff t  X  P s,i ( t.A )= V . Note that in general, V can represent more than one set P s,i ; however, DP only records one set P s,i that V represents. This task is a subset-sum problem that can be solved using dynamic program-ming.

In the next step, DP selects mSV i sets and one value from each selected set SV i so that the summation of these selected values is maximized and does not exceed K .This task can be solved using dynamic programming. Without loss of generality, assume that the selected sets in this step are SV 1 ,  X  X  X  , SV m ; and the corresponding value selected in each SV i is v i , i  X  [1 ,m ]. Since each v i represents a subset P s,i  X  P i , DP unions these P s,i , i  X  [1 ,m ], as the final answer S ans . Clearly, S ans has count ( B )= m ,aseach P s,i  X  X ontributes X  a distinct B value. Furthermore, S ans has sum ( A ) maximized without exceeding K because m 1 ( v i is maximized and does not exceed K .

Example 2. Assume a user wants to find a package of places to visit from POI with the following two constraints: (1) maximize ( sum ( hour ))  X  7 ,and(2) count ( city )=2 . DP first partitions S base into three partitions, P 1 to P city attribute, as shown in Figure 2(a). DP then derives the corresponding three sets, SV 1 to SV 3 , shown in Figure 2(b). For instance, v 1 , 5 =5  X  SV 1 ,since v 1 , 5 represents for the subset P 1 ,s = { t 1 ,t 2 } ; i.e., t  X  P 1 ,s ( t.hour )=5 .
In the next step, DP selects SV 1 and SV 2 ;andchooses 5  X  SV 1 and 2  X  SV 2 where their summation is maximized and does not exceed 7 .Since 5 represents for the set P 1 { t 1 ,t 2 } and 2 represents for the set P 2 ,s = { t 4 } , DP unions P ,s and P 2 ,s to return S ans = { t 1 ,t 2 ,t 4 } . Note that S not the only solution; another possible solution is { t 4 We now elaborate on the details of DP for evaluating a SAC query involving two attributes A and B as given in Section 3.1. For simplicity and without loss of general-ity, let the domain of the B attribute values in S base be dom ( B )= { 1 , 2 ,  X  X  X  , } 3 .

For each b  X  dom ( B ), let S b base and S  X  b base be a subset of S base defined in Equations 1 and 2, respectively. Let E [1  X  X  X  , 1  X  X  X  K ] be a two-dimensional matrix, where each cell E [ b, V ] is a boolean value defined in Equation 3. Each row E [ b, . ] is a subset-sum problem that can be solved with a time complexity of O ( K | S b base | ). Therefore, the entire ma-trix E can be constructed in O ( K | S base | ).

Let D [1  X  X  X  , 1  X  X  X  m, 1  X  X  X  K ] be a three-dimensional ma-trix, where each cell D [ b, d, V ] is a boolean value defined in Equation 4.
 D [ b, d, V ]= true iff  X  S  X  S  X  b base s.t. |  X  B ( S ) | DP can find a solution if there exists a maximum value V max  X  K such that (1) D [ , m, V max ]= true ,and(2)for every value V&gt;V max , D [ , m, V ]= false . Wehavethe following recurrence relation:  X  V  X  [1 ,V ] s.t. ( E [ b, V ]=1  X D [ b  X  1 ,d  X  1 ,V  X  V ]=1)
The recurrence relation indicates that D [ b, d, V ]canbe derived from either (1) D [ b  X  1 ,d,V ] if we do not select any tuples from S b base ,or(2) D [ b  X  1 ,d  X  1 ,V  X  V ] if we select a subset of tuples S from S b base with t  X  S ( t.A )= V .
The computation of each D [ b, d, V ]requiresatmost V look up operations on the corresponding row E [ b, . ]inthe E matrix. Thus, the time to build matrix D in the worst case is O ( m K V =1 ( V )) = O ( K 2 m ).
 Deriving S ans . In addition to the main matrix D , DP uses another matrix DTrace [ , m, K ] that has the same di-mensions as D to derive S ans .Eachcell DTrace [ b, d, V ] issettoeither(1)avalue0if D [ b, d, V ] is derived from D [ b  X  1 ,d,V ], or (2) a value V &gt; 0if D [ b, d, V ] is derived from D [ b  X  1 ,d  X  1 ,V  X  V ]and E [ b, V ].

To derive a set of returned tuples S ans , DP first determines the maximum value V max  X  K such that D [ , m, V max ]= true . There are two cases to consider:
The technique to derive a set of tuples that makes E [ , V ]= true follows a standard procedure for solving the subset-sum problem. We briefly describe this procedure in the following.
In general, we can easily map an arbitrary set of values into the set { 1 , 2 ,  X  X  X  , } .

Assume that S base = { t 1 ,  X  X  X  ,t y } . To compute E [ , . ], DP builds a two-dimensional matrix F [1  X  X  X  y, 1  X  X  X  K ]withthe following recurrence equation: DP maintains another matrix, denoted as FTrace [1  X  X  X  y, 1 that has the same dimensionality as F .Each FTrace [ i, V ] keeps track of how F [ i, V ] is derived; i.e., FTrace [ i, V ]isset to either (1) false if F [ i, V ] is derived from F [ i  X  (2) true ,otherwise.
 To find a subset S of tuples that make E [ , V ]= true , DP traces from FTrace [ y, V ]. If F [ y, V ]= false ,then S is the set of tuples that makes F [ y  X  1 ,V ]= true .Otherwise, if F [ y, V ]= true ,then S is the union of { t y } and the set of tuples that makes F [ y  X  1 ,V  X  t y .A ]= true .
 Complexity. The space complexity of DP is O ( K | S base | Km ) to keep the matrices for the recurrence relations in the main memory. The time complexity of DP is the summation of the following three components: (1) partitioning S base based on B attribute (denoted by T part ), (2) computing E matrix, and (3) computing D matrix. To partition S base basedonthe B attribute, Greedy augments the base query with an ORDER BY clause on B and evaluates this derived query to obtain the set of partitions of S base .Thus, T part is the time to execute the derived query on the DBMS. The time complexity of DP is, therefore, O ( T part + K | S base K 2 m ).
 Approximation version of DP . When K and/or is large, the space required by DP mightexceedtheavailablemain memory. In these cases, DP needs to reduce the space re-quirement by scaling down the domain values of the at-tribute used with the sum constraint (i.e., A attribute) by some factor c f ;thus, K will be replaced by K/ c f .Theso-lution of DP is approximate in these cases. The DP approach can be generalized to evaluate multi-sum SAC queries when C ans includes more than one optimization constraint. The idea is to build a matrix for the dynamic programming technique similar to D and find all the  X  X ky-line X  values in this matrix. In particular, assume C ans cludes ( n +1) constraints: maximize ( sum ( A i ))  X  K i i  X  [1 ,n ], and count ( B )= m . DP builds a ( n +2)-dimensional matrix D [1  X  X  X  , 1  X  X  X  m, 1  X  X  X  K 1 ,  X  X  X  , 1  X  X  X  K n ]. To derive a result set S ans , DP finds all  X  X kyline X  X ells D [ , m, V 1 such that there does not exist any tuple of values ( V 1 where (1) D [ , m, V 1 ,  X  X  X  ,V n ]=1,(2) V i  X  V i , for all i  X  [1 ,n ], and (3) at least one of V V .

Similarly, the DP approach can be generalized to solve multi-sum SAC query when C ans includes any number of sum constraints and at most one of either content or group-by constraint. The idea is also based on a two-phase dynamic programming approach. In the first phase, DP partitions S base using attribute(s) for the content or group-by con-straints and derives SV -sets for each partition of S base respect to the content or group-by constraints. The second phase manipulates the derived SV -sets to compute the an-swer set. The details are given elsewhere [6].
In this section, we examine the evaluation of general SAC queries involving any combination of aggregation, group-by, and content constraints. By Theorem 1, it follows that this evaluation problem is NP-complete. We therefore present a heuristic solution, termed Greedy , to evaluate general SAC queries. An answer set computed by our heuristic could be suboptimal in the sense that the answer set does not satisfy all the required constraints.

For ease of presentation, our discussion is organized into three cases from the simplest to the most general case.
We first discuss the simplest scenario where all the con-straints in C ans are count constraints. For simplicity and without loss of generality, we consider a SAC query with two count constraints: count ( B i )= m i , i  X  [1 , 2], where m 1  X  m 2 .Our Greedy heuristic is based on the following result.

Lemma 1. If there exists a subset S count  X  S base that has count ( B 1 )= m 1 and count ( B 2 )  X  m 2 , then there ex-ists a subset S ans  X  S count that has count ( B 1 )= m 1 count ( B 2 )= m 2 .
 Proof of Lemma 1. Given a subset S count  X  S base that has count ( B 1 )= m 1 and count ( B 2 )  X  m 2 ,wefirstpick m arbitrary tuples in S count that have m 1 distinct B 1 values to put into S ans . The number of distinct B 2  X  X  values in S is currently not greater than m 1 and therefore is also not greater than m 2 , since our assumption is m 1  X  m 2 .Wethen need to insert some tuples from ( S count  X  S ans )into S increase the number of distinct B 2  X  X  values in S ans into m This task is accomplished by performing m 2  X  X   X  B 2 ( S ans steps. In each step, we pick a tuple in ( S count  X  S ans insert into S ans in such a way that the number of distinct B  X  X  values in the resultant S ans increases by 1.

Using Lemma 1, Greedy will derive a set S count  X  S ans that has count ( B 1 )= m 1 and count ( B 2 )isas large as pos-sible. The rationale is that if S count has count ( B 2 ) then we can derive S ans from S count satisfying all the con-straints. The details of Greedy are as follows.

Greedy first partitions S base using the values of B 1 at-tribute, and performs m 1 iterations to insert m 1 partitions of S base into S count . At each iteration, Greedy considers all potential partitions in S base , and chooses the  X  X est X  parti-tion to insert into S count such that the resultant S count the largest number of distinct B 2  X  X  values. After m 1 itera-tions, there are two cases to consider. If |  X  B 2 ( S count Greedy derives S ans based on Lemma 1 such that S ans sat-isfies all the count constraints from S count .Otherwise,if |  X  proximate result that does not satisfy the count constraint on B 2 .
 Complexity. The space complexity of Greedy is O ( | S base since in the worst case, Greedy stores all distinct B 2 values inthemainmemory. Thetimecomplexityof Greedy is O ( T part + T alg ), where (1) T part is the time to partition S base based on B 1 attribute, and (2) T alg is the time to derive S count and then S ans . Similar to DP , Greedy also augments the base query with an ORDER BY clause on B 1 and evaluates this derived query to obtain the set of partitions of S base .Wehave T alg = m 1 | S base | ,since Greedy performs m 1 iterations and basically scans all tuples in S in each iteration.

Example 3. Consider a user who wants to find a tour package consisting of places of interest from two different cities and with three different types of activities. Greedy first derives a set S count that has count ( city )=2 and count ( type ) as large as possible. For this task, Greedy partitions S base POI into three partitions using city attribute, as shown in Figure 2(a). In the first iteration, Greedy selects partition P 1 to put into S count ,since P 1 contains the largest number of distinct type values. In the second iteration, Greedy selects P 3 to put into S count ,since P 3 increases the number of dis-tinct type values in S count the most. Note that Greedy does not select P 2 , since it does not help to increase count ( type )
Since S count has count ( type )=4 , Greedy can derive the exact answer for this case. Using Lemma 1, Greedy first se-lects t 1  X  P 1 and t 6  X  P 3 to put into S ans for count ( city )=2 in S ans .Finally, Greedy puts t 2 into S ans .Thus, S ans { t Generalization. The other cases of count constraints in-volving inequality comparison operator can be reduced to the case of count constraints with equality operator. For in-stance, if the constraints are count ( B 1 )  X  m 1 and count ( B m 2 , we can use the above solution to find sets of tuples satis-fying count ( B 1 )= x and count ( B 1 )= y for 0  X  x  X  m m 2  X  y  X | B 2 | ,where | B 2 | denotes the number of distinct B  X  X  values in S base .

When there are more than two count constraints, assume these constraints are count ( B i )= m i , i  X  [1 ,k ]with m max k i =1 ( m i ). As before, Greedy partitions S base using B  X  X  X  , B k  X  1 attributes. At each iteration, Greedy selects one partition from S base to insert into S ans such that: (1) the constraints on B 1 ,  X  X  X  , B k  X  1 can still be satisfied in the sense that count ( B i )  X  m i for i  X  [1 ,k  X  1], and (2) the number of distinct B k values in the resultant S ans is the largest. Greedy terminates the iteration when none of par-titions satisfies both of these conditions.
In this section, we consider the more complex scenario when there is a combination of count and sum constraints. For simplicity and without loss of generality, we consider a SAC query with two constraints: (1) maximize ( sum ( A )) K and (2) count ( B )= m .

Our Greedy heuristic tries to satisfy the  X  X asier X  type of constraints before considering the X  X arder X  X onstraints. Specif-ically, Greedy considers the constraints in the following or-der: count, sum, and finally the optimization constraint.
To satisfy the count constraint, Greedy can select an ar-Observe that the more tuples that S count has, the more flexibility we have to select a subset of tuples from S count to satisfy other constraints. Thus, Greedy finds S count that has the cardinality as large as possible among all possible S count  X  X . For this task, Greedy partitions tuples in S base based on their B  X  X  values, and chooses m partitions that have the largest cardinalities to form S count .

To satisfy the sum constraint, Greedy partitions tuples in S count based on their B attribute values, and selects the tuple that has the smallest A value in each partition of S to insert into S ans .If t  X  S ans ( t.A ) &gt;K , it implies that any other subset of S count will not satisfy both the count and sum constraints; therefore, Greedy returns S ans as an approximate result in this case.

Finally, Greedy handles the optimization constraint by adding some tuples from ( S count  X  S ans )into S ans .This task is a subset-sum problem: select a subset of tuples from ( S It is important to note that we cannot add any tuples from ( S base  X  S count )into S ans since it would increase the number of distinct B values in S ans and violate the count constraint. Complexity. The space complexity of Greedy is O ( K | S count to maintain the matrix for dynamic programming in the last step. The running time of Greedy is O ( T part + T SSP )where: (1) T part is the time to partition S base using B attribute and select m partitions that have the largest cardinalities, and (2) T SSP is the running time of the solver for the subset-sum problem in the last step of Greedy .For T part , Greedy augments the base query with the following: a GROUP BY clause on B ,an ORDER BY clause on COUNT (  X  ), and a LIMIT clause to select the top-m highest cardinality par-titions. For T SSP , Greedy uses the conventional pseudo-polynomial algorithm to solve subset-sum problem. Thus, T
Example 4. We reconsider Example 2 and use Greedy to solve the problem that finds a package having count ( city )= 2 and maximize ( sum ( hour ))  X  7 . Greedy first partitions S base using city attribute, and derives S count = P 1  X  P 2 which has the largest cardinality from all possible S count
To satisfy the sum constraint, Greedy selects t 3  X  P 1 and t  X  P 2 , which has the smallest hour value to put into S ans Thus, we have t  X  S ans ( t.hour )=3 .

For the optimization constraint, Greedy will select some tuples from S count  X  S ans = { t 1 ,t 2 ,t 5 } that have maximize ( sum ( hour ))  X  4 to put into S ans .Thus, Greedy will put t 5 into S ans .

In summary, S ans = { t 3 ,t 4 ,t 5 } and the solution of Greedy is turned out to be optimal in this case.
 Generalization. The described algorithm can be general-ized for cases where C ans consists of any number of count and sum constraints, similar to the generalization described in Section 4.1. For instance, consider the situation with count constraints on attributes A 1 ,  X  X  X  , A k and sum con-straints sum ( B i ) &lt;K i ,for i  X  [1 , ]. Greedy first uses the described algorithm in Section 4.1 to derive S count that sat-isfies the count constraints. At the end of this step, we can view S count as being partitioned into n partitions using at-tributes A 1 ,  X  X  X  , A k . In the next step, Greedy selects one tuple in each partition of S count to put into S ans .Thekey point is how to select one tuple from each partition so that S ans satisfies the sum constraint. Observe that if every se-lected tuple t in each partition has t.A i &lt;K i /n ,for i then these selected tuples together will satisfy all the sum constraints. Thus, our Greedy heuristic selects one tuple in each partition that satisfies the largest number of conditions  X  t.A i &lt;K i /n  X  to put into S ans .
In the general case when C ans includes any combination of constraints, Greedy also follows the  X  X asier-to-harder-constraint X  principle so as to allow for more flexibility to satisfy all the constraints. In particular, Greedy considers the constraints in the following order: (1) content constraints, (2) count con-straints, (3) sum constraints, and (4) group by together with optimization constraints. The absence of any constraints (e.g., count) allows Greedy to skip the corresponding step (e.g., skip the second step for count constraints). The de-tails are given elsewhere [6].
We now switch our attention to a special fragment of SAC queries, referred to as bounded SAC queries . A bounded SAC query has a bounded cardinality constraint to bound the cardinality of the qualified sets. As a simple example, Alice might be interested only in tour packages containing at most four places to visit. Bounded SAC queries are of interest be-cause they can be processed using two existing approaches. In this section, we briefly describe these techniques, namely DirectSQL and MS , and compare these techniques against our proposed DP and Greedy in Section 6.
 Since bounded SAC queries can be expressed directly using SQL, the first alternative evaluation method, denoted by DirectSQL , is to use relational database engines. Consider a SAC query Q with Q base as  X  X ELECT  X  FROM R  X  X here there is a cardinality constraint in Q that sets the cardinality of qualified sets to a value k . Assuming that the key of relation R is an attribute id , Q can be expressed using SQL as follows:
Here, qualification refers to the predi cates that repre-sent the remaining constraints in C ans . Thus, each qualified set is returned as a tuple in the query X  X  result. We now explain how to translate the various types of constraints in C ans into SQL predicates.
 Content constraint. For each content constraint of the form content ( A, v ), DirectSQL needs to ensure that at least one instance p i of R contains a tuple t that has t.A = v .The constraint can be expressed by the following SQL predicate: ( p 1 .A = v or  X  X  X  or p k .A = v ).
 Sum constraint. A sum constraint of the form sum ( A ) &lt;K can be simply translated into the predicate: ( p 1 .A +  X  X  X  p .A &lt; K ).
 Count constraint. For a count constraint on an attribute A , we need to count the number of distinct values among p 1 .A ,  X  X  X  , p k .A . This can be achieved by using SQL X  X  case con-struct to map each p i .A value to either 0 or 1 and compar-ing the sum of the mapped values against the desired count value. Specifically, each p i .A is mapped to 1 if the value of p i .A is not equal to any of the preceding p j .A values, j&lt;i ; otherwise, it is mapped to 0. For example, the count constraint  X  count ( A )= m  X  is translated as follows: Group-by constraint. Group-by constraints are trans-lated similarly as count constraints using the case construct. For example, consider the group-by constraint groupby ( A, agg, B ). For each p i .A , i  X  [1 ,k ], the translation considers other p j .A , j = i ,thathas p j .A = p i .A and performs the aggregation function agg on B attribute w.r.t. the tuples of p and p j . Table 1: Sizes of Test Data sets (number of tuples) Optimization constraint. An optimization constraint is translated essentially by sorting the query X  X  result based on the aggregated attribute value and retrieving only the first tuple by using SQL X  X  ORDER BY and LIMIT constructs.
For bounded SAC queries where the set cardinality is con-strained to be a fixed value (e.g., count ( place )=4),asecond alternative evaluation method is to apply a recently pro-posed technique MS [8]. The MS technique was actually de-signed for solving a more general problem, specifically find-ing preference sets (with multiple optimization constraints) over fixed-cardinality sets of items. However, the technique there can be used to evaluate bounded SAC queries as well. Further comments on MS are given in Section 7.
In this section, we study the effectiveness and the effi-ciency of our proposed techniques to evaluate SAC queries. The algorithms compared include the dynamic programming approach, DP ,thatevaluates SAC queries with any number of sum constraints and at most one count, content, or group-by constraint; and Greedy , a heuristic approach for evaluating general SAC queries with any combination of constraints. In addition, we also compare DP and Greedy against two other methods for bounded SAC queries: (1) a direct approach using SQL queries, denoted by DirectSQL , and (2) the ap-proach MS proposed in [8].

We used three real data sets for the experiments: Adult 4 TPCH (with a database size of 1GB), and a music data set containing 10 , 000 , 000 songs and 500 , 000 artists 5 .Weused four test queries on Adult data set ( Q 1 to Q 4 ), two queries ( Q 5 , Q 6 ) on TPCH data set, two queries ( Q 7 , Q 8 )onthe music data set, and another two queries Q 1 and Q 1 that differ slightly from Q 1 . Among these queries, Q 1 -Q 3 Q 5 -Q 8 are multi-sum SAC queries, Q 4 is a general SAC query, and Q 1 and Q 1 are bounded SAC queries. The test data and queries are given in Tables 1 and 2, respectively. The third column in Table 2 shows the number of tuples in the query result of the base query of each SAC query.

We used PostgreSQL 8.3 for our database system, and all algorithms ( DP , Greedy , DirectSQL ,and MS ) were coded using C++ and compiled with GNU C++ compiler. Our experiments were conducted on a dual-core, 2 . 33GHz PC running Linux with 3 . 25GB of RAM and a 250GB hard disk.
This section compares DP and Greedy to evaluate SAC queries in terms of the quality of computed results and the running time. Both methods are applicable for all test queries except for query Q 4 , which is a general SAC query that consists of all kinds of constraints supported in this pa-per and cannot be handled by DP . We report the running http://archive.ics.uci.edu/ml/datasets/Adult http://musicbrainz.org/ times of these methods to return one result set for each test query.
 Quality of Computed Results. We measured the quality of a query result evaluation in terms of two metrics: (1) the number of query constraints that are satisfied by the com-puted result, and (2) the aggregate value returned for the optimization constraint. For all of our test queries, both DP and Greedy can find solutions that satisfy all the required constraints. Thus, we compare the quality of computed re-sults for these test queries using the ratio between the ag-gregated value returned by DP over the aggregated value re-turned by Greedy , referred to as relative aggregated value of DP over Greedy . Since the optimization constraint in queries Q 1 to Q 8 is maximization, the higher the relative aggregated value of DP over Greedy , the better the solution of DP is in comparison with Greedy . The relative aggregated value of DP over Greedy for queries Q 1 to Q 8 are given in the second column in Table 3.

For queries Q 1 to Q 3 , which involve small relations, DP re-turned optimal solutions while Greedy returned high-quality solutions; i.e., the aggregated values returned by Greedy are around 3% lower than the optimal values by DP .

Query Q 4 is an example of a general SAC query that con-tains all kinds of constraints supported in this paper and DP cannot handle. Thus, the DP result for Q 4 is not shown in Table 3. For this query, Greedy can find one set of tuples that satisfies all the constraints.

For queries that involve large data sets ( Q 5 to Q 8 ), since the constructed matrices for the dynamic programming are too large to fit in the main memory, DP used its approxi-mation version to scale down the domain values of the at-tributes used with the aggregated constraints (e.g., length, retail price attributes). For Greedy , with the heuristic strat-egy, Greedy first selected a set of tuples satisfying the count constraints, thus reducing the number of tuples to be con-sidered by dynamic programming for the sum optimization constraints. Therefore, the solution of Greedy can be better than DP in these cases. In fact, the results of Greedy for Q 5 and Q 6 are slightly better than DP .Forqueries Q 7 and Q , both the number of involved tuples (3727521 tuples) as well as the number of distinct values of the attribute associ-ated with the count constraint (270352 and 2003678 values, respectively) are large. Here, Greedy returns much better quality result than DP for Q 7 and Q 8 . The aggregated val-ues returned by Greedy are around 1 . 5-3 . 5 times larger than the ones by DP and are nearly equal to the maximum aggregated values required by the queries.

To study how far the aggregated values returned by Greedy and DP are from the optimal solutions, we varied the bounds on the aggregate values of queries Q 1 and Q 8 .Wereportthe results on queries Q 3 and Q 7 in Figure 3 (the same trends are observed for other queries). For Q 3 , we vary the bounded op-timal value from the set { 500 , 1000 , 2000 , 3000 , 40000 , 320000 For Q 7 , we vary the bounded value from the set { 6  X  10 10 6 , 18  X  10 6 , 24  X  10 6 , 30  X  10 6 } . The results again show that when the matrices constructed by dynamic programming can fit in the main memory, the optimal value returned by DP is slightly better than Greedy . In contrast, when the ma-trices cannot be fit in main memory, the solution of Greedy is better than DP . For all cases, the optimal values obtained by Greedy are very close (e.g., more than 95%) to the bounded optimal values, which indicates that Greedy returns high quality solutions. Query Constraints Size
Q 3 Q base =  X   X  ( adult ); maximize ( sum ( capitalloss )) 1000; 2  X  count ( occupation )  X  4; 45222
Q 4 Q base =  X   X  ( adult ); maximize ( sum ( capitalloss )) 2000; count ( nativecountry )=2; count ( race )=2 45222
Q 5 Q base =  X   X  ( part ); maximize ( sum ( retailprice ))
Q 1 Q base =  X   X   X  id  X  60 ( adult ); maximize ( sum ( edunum ))  X  50; count ( race )=2; count (  X  )= x 60
Q 1 Q base =  X   X   X  id  X  500 ( adult ); maximize ( sum ( edunum ))  X  1000; count ( race )=2; count (  X  )= x 500 Query DP / Greedy DP Greedy Table 4: The relative aggregated value of Greedy over the optimal solution Running Time. The third and fourth columns in Table 3 show the running time comparison between Greedy and DP , where Greedy runs 1 . 5 -9 times faster than DP .Theresult is expected since Greedy is a heuristic solution. In this section, we compare our proposed methods ( DP and Greedy ) against the direct approach that uses SQL queries, denoted by DirectSQL , and the method MS proposed in [8] for bounded SAC queries, which have a bounded cardinality constraint to bound the cardinality of the qualified sets. For this comparison, we used two queries Q 1 and Q 1 ,whichare variants of query Q 1 . The three methods ( DP , MS ,and Di-rectSQL ) are able to find the optimal results for both queries Q 1 and Q 1 .

First, we run these approaches for query Q 1 by varying the set cardinality constraint value from 4 to 7; i.e., x  X  [4 , 7]. The Greedy approach returns rather good results; i.e., only for the cardinality 4, the relative aggregated value of Greedy Figure 3: Optimal values obtained by DP and Greedy over the optimal solution is 0 . 8; for the other cases, Greedy achieves the optimal aggregated values (the second column in Table 4). In terms of the running time, as shown in Figure 4(a), Greedy runs the most efficiently. For the other three methods, DP runs faster than MS and much faster than the direct approach ( DirectSQL ). Note that the number of tuples selected by the base query in Q 1 is controlled to be small (i.e., 60) so that the DirectSQL approach can complete its evaluation within reasonable time. Observe that when the set cardinality value increases, the running times of DP and Greedy increase linearly; whereas the running times of MS and DirectSQL increase exponentially.

Second, we increase the maximum sum value in Q 1 to be 1000 and the number of selected tuples by the base query to be 500 to scale up the size of the matrices built by DP and the Figure 4: The running time comparison between DP , Greedy , MS and DirectSQL number of subsets to be considered by MS and DirectSQL . We denote this new query by Q 1 .For Q 1 , DirectSQL cannot finish in five hours, thus we do not record the results of DirectSQL in Figure 4(b). The relative aggregated value of Greedy over the optimal solution is in the range of 0 . 56 to 0 . 75 (the third column in Table 4). In terms of the running time as shown in Figure 4(b), Greedy still runs the most efficiently. DP runs much more efficiently than MS for this query, since the number of subsets considered by MS is large. For instance, for the case with cardinality =6,thenumber of subsets of size six considered by MS is 3800000 and the running time is 5 minutes.
We have the following conclusions from our experimental study:
Figure 5: Evaluation Strategies for SAC Queries
The related work can be classified into two categories: work that are directly related to SAC queries [2, 4, 5] whose relationship to our work ( DP and Greedy )iscapturedbythe decision tree in Figure 5, and work that are related more broadly to set-based queries [1, 3, 7, 8] which involved con-straints different from SAC queries.
 SAC Queries. Several variants of SAC queries that have been studied differ in the number and types of constraints permitted. These work together with our techniques can be classified by the decision tree in Figure 5, where each leaf node represents the best evaluation technique for the fragment of SAC queries represented by the path of internal nodes which specify the permitted constraints. Specifically,  X # contents X  specifies the number of content constraints sup-ported(0,1,or  X  2),  X # count X  specifies the number of count constraints supported (0, 1, or  X  2),  X  X roup-by X  specifies the type of group-by constraints supported (count, sum, none) and whether the attribute(s) used with group-by operators are the same (indicated by  X  X ame X ) or not (no explicit label) with the attribute(s) used with the count constraints, and  X  X ptimization X  specifies the type of optimization constraints supported (unbounded sum, other).
 KP refers to the classic knapsack problem techniques [5]: Given a set of items where each item j has a profit p j and a weight w j , the goal is to select a subset of items such that its total profit is maximized and its total weight does not ex-ceed an input capacity value. A variant of KP was studied in [4] for solving opt imization unde r parametric aggregation constraints (OPAC) query, which takes the following as in-puts: (1) a relation R ( A 1 ,  X  X  X  ,A n ,P ), (2) a set of parametric sum-aggregation constraints of the form sum ( A i )  X  c i c as a parameter, and (3) a sum optimization constraint sum ( P ) to be maximized. Given a parameterized OPAC query, [4] proposed an algorithm to construct indices to effi-ciently provide approximate answers with guarantee bound on its accuracy for any instantiated OPAC query with spe-cific values for the parameters in the sum constraints.
A second variant of KP, which corresponds to the frag-ment of SAC queries with multiple sum and a single group-by-sum constraints, is the multiple-choice Knapsack prob-lem [5]. This is useful in budgeting applications to select a set of projects to be funded such that the total cost for all projects is bounded by some limit, the total cost for projects belonging to the same department is bounded by another limit, and the total project profit is maximized. This prob-lem can be solved in pseudo-polynomial time using a two-step dynamic programming approach [5] which is similar to our proposed DP . However, the formulation of the second dynamic programming stage in our DP is more complicated, since DP needs to take into account the count/content con-straints, which [5] does not consider.

Another related work is the CourseRank (CR) project [2] which is motivated by course planning applications. CR considers constraints of the form  X  X ake at least a and at most b courses from a set S i  X , w h e r e a and b are non-negative integers and S i is a set of related courses (e.g. CS courses), and each course is associated with a use-preference score. For example, a student might be required to complete 2 or 3 courses from a given set of six math courses. Given such constraints, CR finds a set of courses that satisfies all requirements such that the number of selected courses is equal to some given value and the total score of the selected courses is maximized. A polynomial-time algorithm based on maximal flow was proposed for the CR problem [2]. Set-based Queries. There are also several work on set-based query evaluation [1, 3, 7, 8] but they differ from our work due to the types of constraints supported in the queries and/or the focus of the evaluation problem.

A related work, which is motivated by online shopping applications [1], examines the problem of recommending a set of  X  X atellite items X  (e.g., case, speaker) related to a given  X  X enter item X  (e.g., iPhone). Given a budget B and a cen-tral item, [1] finds (approximately) all maximal sets of satel-lite items associated with the central item such that the cost of each maximal set does not exceed the given bud-get B . Different from [1], we do not consider  X  X aximal set X  constraints, which will make the problem of evaluating SAC queries even harder. However, SAC queries support other constraints (e.g., count, group-by, content) which [1] does not handle.

The work on making composite recommendations of a set of items is studied in [7], where each item is associated with both a rating value and a cost. The goal is to find the top-k sets of items such that the total cost of items in each set is no greater than a given budget, and a set with a higher total rating value is more preferable. Note that when k =1, the problem setting is exactly the Knapsack problem. The problem addressed there, however, is based on an evaluation framework where the ratings of items are accessed via sorted access from some external recommending parties, while the costs of items are accessed via random access. [7] intro-duced a 2-approximation solution and a greedy algorithm to find top-k composite recommendations with the optimiza-tion goal to minimize the total access cost.

The work in [3] finds an optimal subset of a set of tuples according to a set preference, which is specified as either a TCP-net or a scoring function on a collection of set proper-ties. A set property is based on the number of tuples satisfy-ing a certain predicate (e.g., the number of tuples satisfying a predicate is greater than a given value). Two heuristic search algorithms (based on branch-and-bound and Con-straint Satisfaction Problem) were proposed in [3]. There are two main differences between [3] and our work. First, [3] focuses on cardinality constraint and does not support other types of constraints considered in our work. Second, the algorithms developed for each work are different from the other.

Finally, there is also a recent related work on finding all subsets of a given fixed-cardinality from a relation that sat-isfy some user-specified preferences [8]. There are two main differences between the work in [8] and ours. First, [8] deals with sets of fixed-cardinality , whereas the sets retrieved by SAC queries can have varying cardinality. Second, [8] allows users to specify preferences over sets and the focus is on computing the skyline query result. However, as explained in Section 5, the technique in [8] can be applied to evaluate SAC queries with a fixed set cardinality.

In summary, although several related work have examined set-based queries or special fragments of SAC queries, our work on DP is the first pseudo-polynomial time algorithm for evaluating the non-trivial SAC query fragment with mul-tiple sum and at most one of either count, group-by, or con-tent constraint. Furthermore, our Greedy approach is the first heuristic to evaluate general SAC queries with any com-bination of count, sum, group-by, and content constraints. The Greedy heuristic tries to find a solution that satisfies all the specified constraints but may return an approximate solution that meets only some of the constraints.
In this paper, we have examined the evaluation of set-based queries with aggregation constraints ( SAC queries), which are very useful for many data retrieval applications. We have presented two novel algorithms: DP , a pseudo-polynomial time algorithm for evaluating a non-trivial frag-ment of SAC queries involving multiple sum constraints and at most one of count, group-by, or content constraint; and Greedy , the first heuristic approach for evaluating general SAC queries. The effectiveness of our proposed solutions was demonstrated by an experimental performance study over real data sets. As part of our future work, we plan to inte-grate ranking/top-k pruning into SAC query evaluation. Acknowledgements This research is supported in part by NUS Grant R-252-000-453-112.
