 1. Introduction
The job shop problem with minimum and maximum time-lags (JSPTL) is a generalization of the well-known job shop problem (JSP), in which there are time constraints restricting the minimum or the maximum distance between two successive job operations. This extension is of practical importance, as maximum time lag constraints appear frequently in industrial processes such as chemical plants, pharmaceutical, and food industry ( Neumann et al., 2002 ).

The JSPTL involves a set of jobs that have to be processed on set of machines. Each job i consists of a sequence of operations; ( i , j ) denotes the j st operation of job i . Every operation must be assigned to a unique machine without interruption. The distance between constrained to belong to interval [ TL i , j , j +1 min , TL consists in sequencing all operations on the machines, such that successive operations of the same job satisfy time lag constraints and such that each machine processes at most one operation at a time. The objective is to find a schedule that minimizes the makespan. The problem can be denoted by Jm j TL i , j , j  X  1
The classical JSP is a well-addressed problem in the literature but only few articles are concerned with time-lag constraints.
Wikum et al. (1994) study single-machine problems with minimum and/or maximum distances between jobs and state that some particular single-machine problems with time-lags are polynomially solvable, even if the general case is NP-hard. Brucker et al. (1999) show that many scheduling problems (such as multi-processor tasks or multi-purpose machines) can be modeled as single-machine problems with time-lags and propose a branch-and-bound method. A local search approach can be found in
Hurink and Keuchel (2001) . Caumond et al. (2008) study the JSPTL considered in this paper. They propose an list scheduling heuristic and a memetic algorithm. Furthermore, since the JSPTL can be viewed as a special case of the resource-constrained project scheduling problem (RCPSP) with time lags, the relevant literature on this problem also apply to the JSPTL ( Kolisch and Padman, 2001; Neumann et al., 2002 ). However, in general, finding a feasible solution with time lags is an NP-complete problem for the
RCPSP. On the contrary, for the JSPTL where only time lags between successive operations of the same job are considered, a trivial solution called canonical schedule can be obtained by a greedy algorithm ( Caumond et al., 2008 ). The algorithm simply sorts jobs in an arbitrary order and, for each job taken in this order, schedules all its operations at the earliest possible time at the end of the partial schedule. For j J j jobs, there are j J j ! so-obtained  X  X  X anonical X  X  schedules with the same makespan, which is the sum of the duration of all the operations. The interest of a specific study of the JSPTL comes from this property. However, for makespan minimization, the canonical schedule may have a very poor performance. In the presence of maximum time-lags, classical JSP heuristics cannot be easily extended and finding a non-trivial feasible schedule for the JSPTL is not simple due to maximum time-lags constraints.
 feasible schedule for the JSPTL and a branch-and-bound method including new generalized resource constraint propagation techniques for solving the JSPTL. Constraint propagation is commonly used when solving decision problems from a constraint satisfaction perspective; planning and scheduling problems are not an exception to the rule (see for example Salido et al., 2008 ). The experiments show the interest of these generalized propagations compared to usual constraint propaga-tion. Moreover, our method outperforms the best-known approaches in the literature for small instances.
 job shop problem with time-lags under study and a literature review. Section 3 is dedicated to new resource constraint propagation based on generalized time constraints. The proposed method for solving the JSPTL is detailed in Section 4. This method is based on a branch-and-bound procedure, on a new insertion heuristic for the JSPTL, and on the generalized resource constraint propagation. In Section 5, we provide an experimental study to evaluate the impact of the proposed insertion heuristic and to evaluate the interest of generalized resource constraint propaga-tion for solving the JSPTL. Conclusions and future research directions are given in Section 6. 2. The job shop problem with time lags 2.1. Notations 2.2. Modeling resource sharing constraints). An integer linear program for the makespan minimization can be written as: min C max  X  1  X  s : t : :  X  2  X  ft i , j  X  st i , j  X  p i , j , 8 X  i , j  X  A T ,  X  6  X  st i , j Z 0 , 8 X  i , j  X  A T ,  X  9  X 
Constraints (3) state that the makespan is greater than or equal to the finish time of all operations of each job. Constraints (4) and (5) represent the minimum and maximum time lags between two consecutive operations of the same job i , respectively. Constraints (6) describe duration constraints. Constraints (7) and (8) must be ( i , j ) precedes operation ( k , l ), equal to 0 otherwise; and M is a  X  X  X ufficiently large X  X  constant. These two constraints state that operations competing for the same machine must be sequenced.
Due to the high number of binary variables, and also to the loose linear programming relaxation of the big-M formulation, it is easy to understand that this integer program would be intractable, even for medium-scale instances.

As an illustrative example, let consider the following JSPTL with three jobs composed of three operations described in Table 1 .
Each cell in this table gives the machine, the duration, and the maximum time-lag between this operation and its successor if it exists. In this instance, we consider that the minimum time-lags are all zero. In the following of this paper, operation durations are assumed to be fixed but this assumption does not impact our contribution. A canonical schedule corresponding to this problem is represented with a makespan equal to P  X  i , j  X  A T p 2.3. Graph representation 2.3.1. Disjunctive activity-on-node graph and operation time windows
The classical representation of the JSP is usually based on disjunctive activity-on-node (AON) graphs ( Erschler et al., 1979; Roy et al., 1964 ). This representation can be extended easily to the
JSPTL ( Caumond et al., 2008 ). The nodes are associated with operations and the arcs are partitioned into two sets: the set of conjunctive (oriented) arcs and the set of disjunctive (non-oriented) edges. The conjunctive arcs represent the time lag constraints (4) and (5). For each job i and each operation j o n there is an arc from ( i , j )to( i , j +1) valuated by p arc from ( i , j +1) to ( i , j ) valuated by ( p i , j + TL operations with zero duration, 0 and * , are introduced to represent the start and end of the schedule, respectively. Operation 0 is a predecessor of the first operation of each job through a conjunctive arc valuated by 0. Operation * is a successor of the by p i , n i . Restricting to these conjunctive arcs, the longest path between node 0 and operation ( i , j ) gives the earliest start time of the operation st i , j . The earliest completion time is then ft conjunctive graph can also be used to compute a latest start time st start time windows  X  st i , j , st i , j and end time windows  X  ft obtained.
 The disjunctive edges represent resource sharing constraints. Namely, there is a disjunctive edge between two distinct operations ( i , j ) and ( k , l ) as soon as m i , j  X  m selection is an arbitrary (complete) orientation of the disjunctive edges such that each obtained arc is valuated by the duration of the origin operation. To represent a solution, the resulting graph must be free of positive length cycles. A selection satisfying these constraints is called a feasible selection. In a feasible selection, the precedence-feasible earliest start time. The length of the longest path from 0 to * gives the makespan of the represented solution. With these definitions, the JSPTL can be stated as the problem of finding a complete feasible selection of minimum makespan. The disjunctive AON graph linked to Table 1 is depicted in Fig. 2 . Dotted edges are the disjunctive edges while plain arcs are conjunctive arcs. 2.3.2. Disjunctive time-bound-on-node graph
To represent a broader variety of time constraints in schedul-ing problems, the disjunctive time-bound-on-node (TBON) graph has been introduced ( Esquirol et al., 1995 ). The disjunctive TBON representation is equivalent to the disjunctive AON graph, but we choose to use it in the sequel since it allows the distinct visualization of the different components of the problem: duration time lags, start and finish times, although it yields a larger number of nodes.

In this representation, each operation is associated with two nodes representing its start-and finish-time. As for the dis-junctive AON graph, there are conjunctive arcs and disjunctive edges. An additional node x 0 is introduced to represent the beginning of the scheduling time. A node * can also be added to represent the end of the schedule.

A conjunctive arc linking two nodes x u and x v is labeled by the value d x u , x v linked to the minimum distance between the time graph between ( i , j ) and ( k , l ) existing when m i , j for the TBON by a pair of exclusive conjunctive arcs: a conjunctive arc from ft i , j to st k , l and a conjunctive arc from ft valuated by 0. For the JSPTL, the TBON graph conjunctive arcs can be built according to Table 2 . A complete selection consists in choosing a single conjunctive arc for each exclusive pair. In a feasible selection, the longest path from each start node (respectively, finish node) of each operation to node x 0 the latest start-(respectively, finish-) time of operations. The makespan is the longest path from node x 0 to node * .
Fig. 3 represents the disjunctive TBON graph of the example presented in Table 1 . To simplify the representation, only the disjunctions on machine m 1 , which correspond to three sets of disjunctive constraints, are represented in the figure (dotted lines). 3. Generalized constraint propagation
Constraint propagation amounts to reduce the decision variable domains and/or to explicitly generate induced con-straints, depending on the constraint propagation level, by means of an active use of constraints. In this section, the objective function is not explicitly considered. Instead, a tentative upper bound of the makespan UB is set. The purpose of the constraint propagation mechanism is to prove satisfiability of C max
Since this is an NP-complete decision problem, this mechanism is not complete, i.e.,when an inconsistency arises during constraint propagation, the problem is unsatisfiable; otherwise, the problem is not proved to be satisfiable. We will present in Section 4 how we integrate this mechanism into a makespan minimization method for the JSPTL.

We distinguish between time constraint propagation, working on a set of conjunctive temporal constraints such as the conjunctive part of the TBON graph (see Section 2.3.2) or Simple Temporal
Network in the Artificial Intelligence field ( Dechter et al., 1991 ), and resource constraint propagation tackling the disjunctive constraints or disjunctive temporal problem ( Stergiou and Koubar-akis, 2000 ). For the latter, our contribution is the propositions of generalized resource constraint propagation rules described in
Section 3.2. 3.1. Time constraint propagation
To check the global consistency of a conjunctive temporal problem one might use filtering techniques such as arc-consis-tency (AC) or path-consistency (PC) that both run in polynomial time ( Dechter, 2003 ). In PC, the consistency is relative to paths of length 3; PC then returns the loosest constraint between a pair of variables, considering the triangles formed with a third variable.
AC is a more restricted case of PC since it only updates the domain of each time point. For a conjunctive set of time constraints, the advantage of PC is that it computes the complete minimal graph of time constraints: for any two time points, PC provides the interval containing the values that are consistent with other constraints.
An inconsistency arises when a positive length cycle is detected in the graph (either by AC or by PC). PC computes in the TBON graph the longest paths length between each operation time points x and x v , denoted by a x u , x v in O ( N 3 ), where N is the number of operations. For each conjunctive arc, a x u , x v is initialized with d and the longest paths are computed progressively by maintaining Floyd X  X arshall algorithm.

Consistency (IFPC) was shown to be quite efficient on the JSP ( Planken, 2008 ). In this paper, we then consider this incremental version of path-consistency for the JSPTL. Basically, since our solving method (see Section 4) adds progressively precedence constraints to build a complete selection, IFPC algorithm reaches an O ( N 2 ) complexity for each added precedence constraint. 3.2. Generalized disjunctive constraint propagation
Baptiste et al., 2001 ), are based on operation time windows. We propose in this section a generalization of these rules to incorporate the all-pairs longest path lengths a x u , x v for time constraints, a generalization of the simplest disjunctive constraint propagation rule, called Forbidden Precedence (FP), has previously been proposed in Brucker (2002) , Demassey et al. (2005) , and Huguet et al. (2002) . We recall here this general-ization. FP propagation considers the disjunctive constraint the set of conjunctive constraints, one of the precedence constraints involved in the disjunction; if it leads to an inconsistency then this precedence is forbidden (therefore the reverse is mandatory). It yields: 8
A M , 8 X  i , j  X  ,  X  k , l  X  A T m if ft k , l st i , j o p
The generalization of FP, denoted by GFP, is based on the value of the binary constraints deduced by IFPC between the two variables st it can be proved (see Fig. 4 ) that the generalization dominates the classical formulation with the same complexity (it explores the same set of disjunctions).

Propagation based on disjunctive sets of operations : We general-ize two other disjunctive constraint propagation rules, named latest starting time of last (LSL) and earliest finishing time of first (EFF) by Caseau and Laburthe (1994) . Rule LSL aims at sequencing an operation i after a set of operations competing for the same resource. Symmetrically, EFF sequences an operation ( i , j ) before a set of operations competing for the same resource. The classical formulation of LSL is 8
A M , 8 S T m , 8 X  i , j  X  A T m \ S if max  X  k , l  X  A S u D S then S u!  X  i , j  X  :  X  13  X 
LSL can be generalized, using the same principle as FP and GFP: the generalization is based on the length of the longest path from st obtained by IFPC algorithm it corresponds to a st k , l , ft formulation is then: 8
A M , 8 S T m , 8 X  i , j  X  A T m \ S if min  X  k , l  X  A S u D S then S u!  X  i , j  X  :  X  14  X 
This generalization of LSL is denoted by GLSL. Symmetrically, the generalization GEFF can be obtained for EFF. The algorithm for applying GLSL has the same complexity as those for LSL (it explores the same set of operations).

The demonstration of this result follows the same principle as for the generalization of FP rule: a st k , l , ft length of the longest path from st k,l to ft i , j , 8 X  k , l  X 
Propagation based on energetic reasoning : We propose a new generalization of the forbidden precedence with energetic reason-ing (FPE). FPE also considers a set of operations competing for the same resource, but it also involves the minimum consumption of operations over given intervals [ t 1 , t 2 ]. For a given machine and a given operation ( k , l ) over an interval [ t 1 , t 2 ], the classical formulation of the minimal consumption is ( Erschler and Lopez, 1990; Lopez and Esquirol, 1996 ) w  X  X  k , l  X  , t 1 , t 2  X  X  max  X  0 , min  X  p k , l , t 2
Rule FPE ( Lopez and Esquirol, 1996 ) considers the disjunctive constraint between two operations ( i , j ) and ( m , n ) and computes the minimal consumption of all other operations ( k , l ) using the same resource over the interval bounded by earliest start time of ( i , j ) and latest finish time of ( m , n ): 8
A M , 8 X  i , j  X  ,  X  m , n  X  A T m , T m  X  T m \ f X  i , j  X  ,  X  m , n  X g
The generalized formulation of the minimal consumption of operation ( k , l ) can be obtained by using the longest paths computed by IFPC (see Fig. 6 ): w ext  X  X  k , l  X  , st i , j , ft m , n  X  X  max  X  0 , min  X  p ft m , n ], and when it covers the interval, respectively. Indeed a represents a lower bound of the length of interval [ st i , j expression of the last term, when the operation is right-shifted.
The generalized forbidden precedence with energetic reason-ing (GFPE) is then based on the following extension of the minimal consumption: 8 A
M , 8 X  i , j  X  ,  X  m , n  X  A T m , T m  X  T m \ f X  i , j  X  ,  X  m , n  X g where a ft
Unfortunately, there is no dominance between FPE and GFPE as it can be illustrated in the following example.
 competing for the same machine. The TBON graph of Fig. 7 synthesizes the useful data.

Let us consider the disjunctive constraint between ( i , j ) and ( m , n ). The minimal consumptions of operations ( k , l ) and ( u , v ) over the interval  X  st i , j , ft m , n are then:
For the same operations, the generalized minimal consumptions are: are p i , j  X  4 and p m , n  X  3, rule FPE (15) tests the following condition: 9 1 o 4  X  3  X  0  X  1 which is not verified then it allows no deduction. However, rule GFPE (17) provides us with the test example, rule GFPE dominates rule FPE. However, if on the same example, we change the value of the arc from x 0 to st k , l classical minimal consumptions are then: and the value of generalized minimal consumptions are:
The application of rule FPE produces the test 9 1 o 4  X  3  X  1  X  1 with rule GFPE, the test 7 o 4  X  3  X  0  X  0 does not permit any deduction. On this second example, rule FPE subsumes rule GFPE. generalized propagation rules GFP, GEFF, and GLSL. Nevertheless, an experimental validation is needed to prove their practical contribution. Indeed, the generalization is based on an IFPC algorithm which is more time-consuming than an AC-like algorithm (for instance a Bellman X  X ord algorithm). Moreover, we showed in the previous example that there is no dominance between rules FPE and GFPE.
 problems, Edge Finding (denoted here by EdFi) ( Baptiste et al., 2001 ) is generally considered as an effic ient propagation rule. Note that
EdFi produces the same conclus ions as LSL or EFF. However, at present time, EdFi does not seem to be generalizable, as EFF and LSL do. Our, objective is then to evaluate experimentally to what extend the generalized rules can also be efficiently triggered. 4. Proposed solving method constraint propagation, the propo sed formulations are included in a basic branch-and bound procedure presented in this section. We also propose a job insertion heuristic to obtain an initial upper bound. 4.1. A job insertion heuristic 4.1.1. Issues for greedy heuristics in the presence of maximum time lags rithms) obtain very quickly an approximate solution. These heuristics consider a set of candidate operations to be scheduled (i.e., the operations are ready and the machine on which they are to be performed is free). The operations are ordered considering a (static or dynamic) priority rule and scheduled so as to build a partial feasible schedule. More precisely, each operation selected with the priority rule is inserted in the partial sequence on the machine it requires without changing this partial sequence.
To solve the JSPTL, the implementation of greedy heuristics has to cope with another difficulty. Indeed, proceeding as described above may lead to an unsatisfiable solution because we can easily have cases where all insertion positions for the selected operation violate the maximum time lag constraints. 4.1.2. Principle of the proposed heuristic
Actually, for general time-lag problems (like RCPSPs with time lags), answering the question whether there exists a feasible solution is itself an NP-complete problem. As already mentioned, however, there are trivial  X  X  X anonical X  X  solutions for the JSPTL, in which jobs are sequenced consecutively.

Aware of this property, Caumond et al. (2008) have designed a list-based heuristic associated with a method for repairing partial solutions already built. The list heuristic works by selecting with a priority rule at each step an operation among the set of candidate operations (whose predecessor has already been scheduled) and the operation is appended at the end of the partial schedule. The repairing mechanism takes place when no candidate operation can be appended without violating a time lag constraint. In the worst case, this heuristic generates the canonical schedule.
We propose here a new heuristic for the JSPTL. Our idea is to take advantage of the fact that the time lag constraints occur only inside the job. Our heuristic builds a list of jobs and takes each job consecutively according to this list. At each step, the operations of the current job are all inserted in the partial schedule according to the increasing operation number.

For instance, considering again the example of Table 1 , if job J is selected, the heuristic schedules the operations (1,1) then (1,2) and then (1,3) on their respective machines while checking time-lag constraints. Once a job has been scheduled, it is considered as fixed and the start times of its operations cannot be changed.
The complete schedule of the set of operations of a job leads to idle-time intervals on the machine. During the schedule of operations of the next job, our heuristic tries to schedule these operations in the idle-time intervals (insertion positions) pre-viously created. Hence we define our heuristic as a job insertion procedure. Such heuristics were previously proposed for job-shop problems without maximum time lags ( Kis and Hertz, 2003;
Werner and Winkler, 1995 ). For the JSPTL, the situation where no insertion position exists for the current operation also occurs for the job insertion heuristic and it can be necessary to make several attempts to schedule the operations of the current job, as shown by the following example. Let us consider that our heuristic has already scheduled jobs J 1 and J 2 (see Fig. 8 ), it has now to insert job J 3 . The idle time interval on m 1 allows scheduling operation (3,1) at its earliest date on m 1 .

However, the schedule of (3,2) on m 2 cannot be done, considering simultaneously its processing time of 5, the idle times when m 2 is free, and satisfying the maximum time-lag constraint of 2 between (3,1) and (3,2) (situation displayed in Fig. 9 (a) with the representation in black of two occurrences of (3,2), before and after operation (1,3)). Job 3 insertion can be canceled and the next insertion position for (3,1) is tested, and the process is carried out until the job can be inserted (see Fig. 9 (b)).
As in the method given in Caumond et al. (2008) , in the worst case, our heuristic schedules the jobs according to the canonical schedule. 4.1.3. Algorithm
Our heuristic is based on the insertion of each job one by one in the schedule. The following static orders of jobs considered for building input jobs lists are: lexicographical and anti-lexicographical orders; ascending and descending orders of TL max i , j , j  X  1 , 8 J ascending and descending orders of P n i j  X  1 p i , j , 8 J ascending and descending orders of
Once entirely scheduled, a job u is fixed, meaning that each of its operations ( u , v ) have a fixed start and finish times ST FT u , v . We let, however, a full degree of freedom to the operations of the job being currently inserted.

For such a job i , suppose operations ( i ,1), y ,( i , j 1) have been inserted in intervals  X  I 1 , I 1 , ... ,  X  I j 1 , I j 1 tentatively inserted in some interval  X  I j 1 , I j 1 . Each I equal to 0 or to some FT u , v and each I q is also fixed and equal to 1 represented by the insertion TBON graph displayed in Fig. 10 . I I j Z p i , j ,  X  18  X  I I where ft j 1 i , j 1 is the length of the longest path from x ft i , j 1 is the length of the longest path from ft i , j 1 insertion graph resulting from ( i , j 1) insertion .
 not generate any positive length elementary cycle in the insertion graph. Since the new nodes st i , j and ft i , j are connected to the insertion graph only via nodes x 0 and ft i , j 1 , any created cycle of one elementary cycle traversing only x 0 :( x 0 , st i , j
I  X  p i , j I j which yields condition (18). There is one elementary cycle traversing only ft i , j 1 :( ft i , j 1 unfeasible. The remaining cycles traverse both nodes x 0 and ft and the largest one takes either the longest path from x 0 of length ft j 1 i , j 1 , which yields condition (19) or the longest path from ft i , j 1 to x 0 , of length ft j 1 i , j 1 condition (20). &amp;
Once ( i , j ) is inserted in  X  I j , I j , we need to compute values ft st , ft i , j ) or a path issued from ft i , j 1 and traversing only arcs from the previous insertion graph between x 0 and ft i , j 1 . Symmetri-cally, the longest path from ft i , j to 0 is either reduced to arc ( ft or going to ft i , j 1 and traversing only arcs from the previous insertion graph between ft i , j 1 and x 0 . This yields the following
O (1) update of the ( i , j ) time window: ft ft
The job insertion algorithm is displayed in Algorithm 1. For each job according to list L , the heuristic scans the operations.
Each time a feasible interval (indexed by q j ) is encountered on m for ( i , j ), the algorithm tries to insert ( i , j +1) on m interval is found for ( i , j ) then the algorithm scans again the possible intervals for ( i , j 1) starting with the interval indexed by ( q j 1 +1), and so on.

Algorithm 1. Job insertion heuristic. inserting a single job is O  X j J j m  X  , which is exponential in the number of machines. However, for some instances the number of machines may be small. To reduce the CPU time, the number of tested insertion positions may be restricted arbitrarily before reaching the canonical position for each job. However, in our experiments it has never been necessary. 4.2. Branch-and-bound procedure 4.2.1. Binary search designed to check whether a solution having a makespan lower than or equal to a given value exists or not. This B&amp;B is integrated into a binary search procedure which iterates on makespan values. The principle is as follows: 1. Compute an initial lower bound LB (by applying the selected 2. Repeat: 3. Until LB  X  UB .

For Step 2(b), a basic B&amp;B method is used whose goal is to compare the pruning power of the various studied constraint propagation rules under a common tree search scheme. This B&amp;B is limited by a maximum CPU time. Its main components are described in the following sections. 4.2.2. Branching scheme in Torres and Lopez (2000) . At each node, we consider the machine with the maximal load and, for this machine, we consider the list of the conflicting operations not yet scheduled.
This branching scheme produces one node for each partial schedule of one operation before all the others. For instance, at a given node, consider L  X  { a , b , c , d } a list of conflicting operations for the most loaded machine, the branching scheme produces four nodes corresponding to constraints a ! f b , c , d g , b ! f a , c , d g , c ! f a , b , d g and d 4.2.3. Constraint propagation
At each node of the B&amp;B, constraint propagation rules are applied to check the consistency of the subproblem. If an inconsistency arises, the node cannot lead to a solution and it is then fathomed. At each node, the constraint propagation algorithm (see Algorithm 2) starts with IFPC algorithm and follows with resource constraint propagation, until a fixed point is reached or as soon as an inconsistency is detected. In this algorithm, X is the set of decision variables and C is the set of conjunctive time constraints.
 Algorithm 2. Propagation algorithm.

C u : the new constraints at the considered node;
IFPC( X , C , C X  ); flag  X  true; while flag do end
For each node, a new set of constraints, named C u , has to be taken into account. The first step of the propagation algorithm initializes IFPC algorithm with the precedence constraints C associated to the node. IFPC algorithm propagates constraints in C to the rest of the problem ( X , C ). For each resource, the procedure the set of propagation rules R into the problem ( X , C ). These propagations lead to new constraints New _ C which will be taken into account by IFPC algorithm at the next iteration of Algorithm 2. This propagation algorithm stops when no more deduction can be done (flag  X  true). It is designed such that several combina-tions of rules which propagate resource constraints can be chosen based on those defined in Section 5.1. 5. Computational results 5.1. Experimental setting
The algorithms were coded in Ada 95 using GNAT 4.4.1 compiler. The tests were performed on a 2.33GHz computer with 4GB of RAM running under Linux Red Hat 4.4.1-2.

Instances : Our experiments were conducted on instances presented in Caumond et al. (2008) . These instances have been obtained from classical JSP benchmarks where time lags have been added. These instances are identified by their name and a minimum  X  a  X  and a maximum  X  b  X  time-lag coefficients: Name_ a _ b . Minimum and maximum time-lags are calculated for each job i with these coefficients, the duration of the job, and the number of operations of this job n i by TL min i , j , j  X  1 mum time lags are zero  X  a  X  0  X  . This is justified by the fact that only maximum time lags increase the problem complexity (since it is always possible to integrate the value of a minimum time lag in the processing time of a fictitious operation not using any resource). In the sequel, we keep the same experimental frame-work in order to provide comparable results between the different approaches. Note also that there is an identical maximum time lag for each operation in the same job.
 There are two set of instances:
Set 1: instance ft06, and la01 to la05, with b A f 0 , 0 : 25 , 0 : 5 , 1 , 2 , 3 , 5 , 10 g .
 Set 2: instance la06 to la40, with b A f 0 , 0 : 5 , 1 , 2or3 , 10 g .
In Caumond et al. (2008) , only a subset of these instances were tested: Subset 2a: instance la06 to la08, with b A f 0 , 0 : 5 , 1 , 2 , 10 g .
Combinations of resource constraint propagation rules : One of the aim of these experiments is to experimentally evaluate the efficiency of the generalized resource constraint propagation rules. Thus, we choose to test the two following combinations to compare the results with or without the generalization for resource constraint propagation: {FP,EFF,LSL} (1) and {GFP,GEFF,GLSL} (2).

We test separately the generalization of the energetic rule FPE, as no theoretical dominance could be exhibited. Therefore, we compare the three following combinations: {FP,FPE,EFF,LSL} (5) , {GFP,FPE,GEFF,GLSL} (6), and {GFP,GFPE,GEFF,GLSL} (7).

We also evaluate the impact of the edge finding (EdFi) rule, for which no generalization could be provided, for each of the above combinations: {FP,EFF,LSL,EdFi} (3) , {GFP,GEFF,GLSL,EdFi} (5) , {FP,FPE,EFF,LSL,EdFi} (8) , {GFP,FPE,GEFF,GLSL,EdFi} (9), and {GFP,GFPE,GEFF,GLSL,EdFi} (10).

For the experiments, we consider the above-defined 10 combinations of resource constraint propagation rules. 5.2. Contribution of generalized resource constraint propagation
We synthesize hereafter the results we obtain on the two sets of instances presented in Section 5.1. For instances from la26 to la40, our B&amp;B cannot improve the initial bounds. In case optimum is not proved, the algorithm was stopped after a time-out fixed to 10min (for a B&amp;B iteration).

For instance set 1, 42 instances out of 48 are solved with our method. The initial bounds for the makespan are improved on 5 out of the 6 remaining instances. The constraint propagation rule combination (9) is generally the only one to reach and prove optimality. This combination includes all the generalized rules except the energetic reasoning rule, combining with Edge Finding. No-wait instances with a maximum time lag coefficient equal to 0 are much harder to solve with our method.

For instance set 2, the B&amp;B method is only able to solve six instances to optimality out of 100 with rather large maximum time lags. For five of these instances, combination rule (9) is still the only one to obtain this result. For 26 of the 94 instances not solved to optimality, the method is able to improve the initial bounds. This occurs more often for large maximum time lags than for small maximum time lags. Detailed results are available in technical report ( Artigues et al., 2010 ).

To confirm the interest of the generalization rules, we scored the different combinations of the two sets of instances as follows: if none of the combinations finds the optimal solution, they obtain the score of 0. When some or all combinations find the optimal solution they are ordered by ascending CPU time. The first combination is given the score of 10, the second is given the score of 9, etc.

Fig. 11 represents the score (Y axis ) obtained by the different combinations (X axis) on Sets 1 and 2. It is confirmed in this figure that the best combination of rule is (9), i.e., {GFP,FPE,GEFF,GL-the combination (6) i.e., {GFP,FPE,GEFF,GLSL}. We can also note that if we compare the combinations with and without the generalization of rules FP, EFF and LSL, the combination with these generalizations obtain better scores than without.

Fig. 11 also shows that the use of EdFi rule does not cover all the propagations obtained with the generalization of rules FP, EFF, and LSL. Unfortunately, we can note that rule GFPE is not efficient enough as it increases the CPU time. 5.3. Comparison with other methods
In this section, we compare our approach with the memetic algorithm proposed in Caumond et al. (2008) . The comparisons are carried out only on the instances used in Caumond et al. (2008) (see Section 5.1): Subset 1a ( Table 3 ) and Subset 2a ( Table 4 ). In each table, the first column gives the instance name and the second one indicates either the optimum value in Table 3 ( Optimum ) or the optimum of the corresponding classical job shop (i.e.,without time lags) in Table 4 ( JS-Opt ). The optimum of the job shop problem without time lags is obviously a trivial lower bound of the job shop problem with time lags. The three next columns present the lower bound ( LB ) and the upper bound ( UB ) obtained with our method, and the corresponding CPU time in seconds. For the memetic algorithm, the results correspond to four runs per instance ( Caumond et al., 2008 ). The remaining columns present the best results obtained with this algorithm, the average time to obtain the best improvement ( Tm ) over these runs and the global average time ( TTm ) of these runs. The results written in bold correspond to the optimum results obtained.

These tables show that, on Subset 1a, we obtain better results than ( Caumond et al., 2008 ), except on the no-wait instances  X  b  X  0  X  . This is not the case with Subset 2a as shown in Table 4 .We only prove the optimum value for the less constrained instance la08_0_10 while Caumond et al. prove it for two other instances with a coefficient b equal to 10. Moreover, their upper bounds are better than those found with our method. 5.4. Efficiency of the job insertion heuristic
The proposed heuristic is based on a given order for jobs to be inserted. Several orders (see Section 4.1.3) were compared on the set of instances and the most efficient is the descending order of job durations. It reaches the best makespan value for more than 33% over all the instances (Sets 1 and 2). For the instances under study, since time lags are strongly correlated to job durations, the orders based on time lags are not more efficient than orders based on job durations, and the combination of both job durations and time lags does not improve the results. Globally, we obtain about 25% of best solutions for the descending (ascending) order of time lags, from 12% to 14% for lexicographical orders, and between 5% and 7% for ascending orders of time lags and durations.
 With our method, the CPU time for solving a given instance of Set 1 is 1.02s in average. For Set 2 (limited to la06 X  X a25), the time is of 25.17s. If we refine these results, we obtain that the method needs 1.14s for Subset 1a and 5.13s for Subset 2a.

Table 5 presents a comparison between the best variant of our job insertion heuristic (JI) and the operation insertion heuristic (OI) presented by Caumond et al. in Caumond et al. (2008) . This evaluation was limited to Subset 1a because the results obtained by the OI heuristic of Caumond et al. (2008) are only available for these instances.

For the JI heuristic, the average deviation above optimum over all instances is 33.15% whereas the average deviation of the OI heuristic is 47.63%, which represents a significant gain.
In Table 6 , we present the average gap above the optimum for both heuristics on subcategories of instances from Subset 1a. Considering the different time lags, we can notice that, for b
A f 0 , 0 : 5 , 1 g , which correspond to the most constrained time lags, we obtain an average gap of at most 35.84% while the OI heuristic obtains an average gap of at least 44.90%. On the contrary, for b  X  2, the OI average gap is only of 25.13% while it reaches of 34.84% for our JI heuristic. This result suggests that our heuristic is better suited for tight time lags than Caumond et al. X  X  one. 6. Conclusions and future work
This paper addresses the job-shop scheduling problem with time-lags (JSPTL). We presented generalizations of several standard disjunctive constraint propagation rules based on all-pair longest paths in a graph and their application for the job shop problem with maximum time lags. To exhibit the contribution of the generalized rules and to solve the JSPTL we proposed a Branch-and-Bound algorithm embedded in a binary search.
The obtained results show that the branch and bound incorporating generalized rules associated with Edge Finding solves more instances in a predetermined amount of time than the standard rules. This underlines the potential interest of incorporating the proposed generalized constraint propagation rules into commercial constraint-based scheduling solvers for a better management of time lag constraints that appear frequently in practical production scheduling problems.

For small instances, our branch-and-bound procedure outperforms a genetic algorithm from the literature. We also presented a simple heuristic based on job insertion. We conclude that our heuristic always obtains feasible schedules with a better makespan than other approaches for tight maximum time lags.
There are several further research directions. First, it could be helpful to generalize other constraint propagation rules, such as the Edge-Finding rule. Second, the solving scheme could be improved to obtain better results on the JSPTL. In particular, the worst-case complexity of the heuristic should be reduced and the branching scheme could be revised to reduce the number of explored nodes.
 Acknowledgment Toulouse) for her help on this work.
 References
