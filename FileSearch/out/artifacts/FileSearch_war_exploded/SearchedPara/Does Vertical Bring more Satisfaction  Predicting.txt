 The study of search satisfaction is one of the prime concerns in search performance evaluation research. Most existing works on search satisfaction primarily rely on the hypothesis that all results on search engine result pages (SERPs) are homogeneous. However, a variety of heterogeneous vertical results such as videos, images and instant answers are aggregated into SERPs by search engines to improve the diversity and quality of search results. In this paper, we carry out a lab-based user study with specifically designed SERPs to determine how verticals with different qualities and presentation styles affect search satisfaction. Users X  satisfaction feedback and external assessors X  satisfaction annotations are both collected to make a comparison regarding the perception of search satisfaction. Mouse click-through / movement data and eye movement informa-tion are also collected such that we can investigate the influence of vertical results from the perspectives of both benefit and cost. Finally, a vertical-aware learning-based prediction method is pro-posed to predict search satisfaction on aggregated SERPs. To the best of our knowledge, this paper is the first to analyze the effect of verticals on search satisfaction. The results show that verticals with different qualities, presentation styles and positions have dif-ferent effects on search satisfaction, among which Encyclopedia verticals, as well as Download verticals, will bring the largest im-provement. Furthermore, our proposed vertical-aware prediction method outperforms state-of-the-art methods that are designed for search satisfaction prediction in homogeneous environment. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval search satisfaction; aggregated search; benefit; cost; prediction c  X 
Search engine evaluation can be performed using metrics based on result relevance or alternative measures based on users X  search experience. Recent studies indicate that relevance-based evaluation metrics, such as MAP and nDCG [20], may not be perfectly corre-lated with users X  search experience (usually considered as the gold standard) [2, 18]. Therefore, search satisfaction has become one of the major concerns in search evaluation studies. Since satisfaction is a relatively subjective concept, several works [18, 36, 21] have tried to quantify users X  perceived satisfaction. Furthermore, some works [1, 12, 15, 16] tried to use various types of user interactions (click-through data, mouse/eye movement information) as implicit feedback to predict search satisfaction. These existing works have achieved success on how to model users X  judgements on the whole search process and how to improve search engines X  ranking strat-egy. However, most of these works rely on the hypothesis that all results on search engine result pages (SERPs) are homogeneous, which means that all search results in an SERP share similar pre-sentation style (one hyperlink with a short snippet). However, as more and more heterogeneous vertical results (videos, images, in-stant answers and so on) are aggregated into modern SERPs, a user X  X  examination and clicking behavior can be quite different [35, 38]. Because modern SERPs provide richer content than hyperlinks and short texts, the sense of fulfilling information needs during the search process may be very different from an SERP with "ten blue links." Therefore, we need to investigate users X  satisfaction percep-tion process within a heterogeneous search environment. To better describe heterogeneous SERPs, we first give a taxonomy of differ-ent search results according to their presentation styles (see Figure 1):
From Figure 1, we can see that the appearances of the vertical results can be rather different from the non-vertical results and may provide information in a completely different way. Previous works [25, 35] showed that such vertical results may have a strong effect on user behavior. These findings inspired us to investigate the ef-fect of verticals on user satisfaction. To shed light on this question, we construct a lab-based search engine system with specifically de-signed heterogeneous search result pages. We provide SERPs with verticals that vary in qualities, presentation styles and positions to users to study how their satisfaction is affected. Users X  explicit satisfaction feedback, as well as mouse click-through / movement data and eye movement data, are collected so that we can make a detailed analysis of how the vertical results affect users X  search sat-isfaction from the perspective of both benefit and cost. To avoid the subjectivity of user satisfaction feedback, we also invite exter-nal assessors to annotate the satisfaction scores of the users X  search sessions to make a comparison. Finally, we propose a vertical-aware learning-based prediction method to predict search satisfac-tion on aggregated search result pages. The results show that our proposed method outperforms state-of-the-art methods, which are not specifically designed for heterogeneous search pages.
Our contributions in this paper include:
The rest of this paper is organized as follows: Related works are reviewed in Section 2. Our lab-based search engine system and corresponding data collection process are presented in Section 3. The effect of different verticals on search satisfaction are shown in Section 4 and a deeper analysis in the benefit-cost framework is shown in Section 5. Section 6 introduces our satisfaction prediction framework and discusses its effectiveness. The paper X  X  conclusions are presented in Section 7.
The concept of satisfaction was first proposed by Su et al. [32] and was defined as  X  X he fulfillment of a specified desire or goal X  by Kelly [23]. To evaluate a search system, satisfaction can be considered as regarding not only to the whole search experience but also to some specific aspects [33], such as the precision or completeness of search results, response time and so on. Because search satisfaction is a subjective concept that is difficult to mea-sure, some existing works collected explicit feedback directly from users as the ground truth of search satisfaction, such as Guo et al. [15] who predicted user satisfaction with mouse movement infor-mation, and Feild et al. [12] who predicted user frustration us-ing query-logs. In addition to explicit search satisfaction feedback, some works [16, 18] have also tried to recruit external assessors to restore the users X  search process and make satisfaction annotations according to their own opinions. However, recent research in [34] showed that external annotations may not be a good estimator of users X  self-judgements, and a number of works (e.g, [21, 22]) have started using the benefit-cost framework to analyze the satisfaction judgement process of users. In this framework, both the benefit fac-tors (result relevance) and search cost (effort) users spend are used to estimate satisfaction. In this work, we follow the benefit-cost framework to make a deep comparison between search satisfaction from users and external assessors in a heterogeneous environment.
Recently, more and more heterogeneous search results have been aggregated into search result pages to promote users X  search experi-ences. There are also a number of existing works which are focused on this kind of federated search. Among them, most prior works fo-cused on predicting which verticals are relevant to a query (vertical selection). Diaz et al. [10] first carried out a system to collect news dynamically and aggregated them into web search results. Arguello et al. [4, 5] showed that query logs will be useful for selecting rele-vant verticals. Zhou et al. [38] presented an approach that considers both reward and risk within the task of vertical selection.
Because the presentation styles of different verticals may be rather different, a user X  X  browsing behavior may be changed when an SERP becomes more and more heterogeneous. Some existing stud-ies tried to analyze a user X  X  new behavior pattern on a heteroge-neous SERP: Wang et al. [35] found that different verticals may create examination biases on users X  search behavior. They sug-gested that images and videos will attract a user X  X  attention more than other search results. Liu et al. [25] further showed three three behavior effect in federated search, namely, the vertical attraction effect, the examination cut-off effect and the examination spill-over effect. Navalpakkam et al. [28] also showed that a knowledge graph will also influence a user X  X  attention distribution on SERPs.
Traditional search result evaluation metrics may also become in-appropriate when dealing with federated search pages. Various di-versity aware IR metrics have been proposed [7, 8, 30], which may be adjusted to evaluate heterogeneous result pages. Zhou et al. [37] introduced the concept of vertical orientation and instantiated a suite of metrics for evaluating aggregated search pages. Markov et al. [27] proposed two vertical-aware metrics based on user click models for federated search and demonstrated its effectiveness.
Despite of these existing works, how users perceive satisfaction on aggregated search pages still remains uninvestigated. In this pa-per, we incorporate vertical information into SERPs and follow the benefit-cost framework to analyze the effect of the vertical results on search satisfaction. We also propose a learning-based satisfac-tion prediction method and demonstrate the effectiveness of vertical information.
In this section, we describe the lab-based search engine system used in our work and show the process of how we collect search satisfaction scores as well as search interaction data, such as mouse and eye movements.
To investigate the effect of verticals on search satisfaction, we construct a lab-based search engine system to collect user behav-ior data as well as satisfaction scores from both users and external assessors. The entire experiment procedure is shown in Figure 2, from which we can see that four types of information are collected during the procedure: (1) mouse movements and click-through in-formation, (2) eye movements, (3) users X  satisfaction scores and (4) external assessors X  satisfaction annotations.

Before the experiment, each participant should first go through a calibration process as required by the eye tracker to make sure that reliable eye movement information is collected. The eye tracker we use in our work is Tobii X2-30. Each participant will be asked to complete 30 search tasks one by one within 1 hour during our experiment. The procedure of the experiment is shown in Figure 2. Before each task, they will first go through the search queries and corresponding explanations to make sure they know the task clearly. Then, he/she will be guided to a pre-designed SERP where query and search results are fixed. The participant should examine the search results provided by our system and click a button on the top right corner to end the task either if the search goal is completed or he/she becomes disappointed with the results. During such pro-cess, his/her mouse movement information and click-through data were logged by injected JavaScript on the SERPs, and eye move-ment information is also logged by the eye tracker. Each time the participant finishes a search task, he/she will be required to label a 5-point satisfaction score to the search session, where 5 means the most satisfactory and 1 means the least. Then, they will be guided to continue to the next search task. All participants are required to finish two warm-up search tasks first to become familiar with the experiment process.
To investigate the effect of the vertical results on satisfaction, we sample a large number of search queries based on the search logs from a major commercial search engine. We use such queries to organize our search tasks just to make sure that our experimental SERPs are consistent with the practical scenario. We selected 30 specific search tasks with corresponding on/off-topic verticals and the non-vertical results crawled from the commercial search en-gine. The queries we use in our experiment are neither long-tailed nor popular ones to avoid unnecessary biases.

The SERPs we present to users vary in three aspects that may have effects on users X  search behavior and satisfaction judgements:
To investigate the effect of the above three factors, we gener-ate seven different SERPs for each search task. The first SERP is a non-vertical one, which means that there are only ten non-vertical results shown in the result page. These non-vertical re-sults are crawled from the same commercial search engine, and kept the original orders unchanged. The remaining six SERPs are composed of one vertical result and nine non-vertical results(the last non-veritcal result from the non-vertical SERP is excluded). Two verticals are of the same presentation style but with different quality on these six SERPs, including an on-topic vertical for three of them and an off-topic one for the other three. Each vertical is in-serted at three different positions of the non-veritical result list: the first rank, the third rank and the fifth rank. Thus, we obtain seven pages for a search task: 2 quality types  X  3 position ranks (6 pages with vertical results) + 1 non-vertical page (with no verical results). Therefore, we generate 210 (30 search tasks  X  7 pages) SERPs in total.

In our experiment, each participant will go through all 30 search tasks but with different SERP settings. We adopt a Graeco-Latin square design to ensure that each SERP condition has the same opportunity to be shown to users.
We recruited 35 participants (aged 18-25) for the data collecting process. All participants are college students and have a variety of self-reported search engine usage experiences. Their majors vary, from biology, economics, social science to engineering. We did not invite computer science or electrical engineering students because they may be too familiar with the use of search engines and cannot represent ordinary search engine users. Each user completed the 30 search tasks and were paid 10 US dollars.
Considering the fact that the process of satisfaction judgement may be subjective and different users may have different opinions, we recruited several external assessors to label the satisfaction scores of users X  search sessions. All these assessors had worked in a com-mercial search engine company for at least one year and can be regarded as professionals in judging search performance and sat-isfaction. We exported the video of our participants doing their search tasks from the eye tracker, which had recorded the whole search process as well as eye/mouse movements and click-through information. We split the video into sessions and excluded the part where users labeled satisfaction scores. We showed these videos of search sessions to assessors so that they can fully restore the origi-nal searchers X  search experience and make a reasonable annotation. The assessors were also asked to give a 5-point satisfaction score so that the satisfaction scores from the two resources will be compa-rable. They were paid 10 US dollars for annotating every 60 search sessions. Each search session is annotated by two assessors, and the KAPPA coefficient of their annotations is 0.48, which means a moderate agreement according to Cohen [9].
We collected 768 search sessions in total because some partic-ipants failed to pass the calibration of the eye tracker. With these collected data, we try to compare the difference between the satis-faction scores from actual users and external assessors. Consider-ing that satisfaction judgement may be quite subjective and differ-ent users may have different opinions, we regularize the satisfac-tion scores labelled by each user/assessor to Z-scores according to equation (1), where sat i is one particular satisfaction score given by one user/assessor and Avg ( Sat ) is the average of all satisfac-tion scores he/she labelled. V ar ( Sat ) in this equation refers to the variance of the satisfaction scores of this user/assessor. We should note that in this way, a Z-score may be below zero, which may be difficult to understand. Thus, we add the same  X  1 to all Z-scores of users X  satisfaction (and the same  X  2 to all Z-scores of the external assessors) in this section to normalize the minimum value to zero to avoid confusion and to maintain the relative differences at the same time.

Figure 3 shows an overview of the effect of vertical qualities on satisfaction scores from two different resources. Different col-ors show satisfaction scores on pages with on/off-topic verticals or without verticals. We can see that both users and assessors tend to give a high satisfaction score, which indicates that commercial search engines generally provide promising results for these non-long-tailed queries. We can also see from Figure 3 that both users and assessors tend to be less satisfied when the vertical is off-topic because the percentage of sessions with the highest Z-scores (80%-100%) is comparatively lower in the off-topic case, although the difference is not very remarkable (68% for SERPs without verti-cals, 54% for SERPs with off-topic verticals in user satisfaction and 54%, 51% in assessors X  annotations, relatively). Moreover, the percentage of sessions with low Z-scores (0%-60%) is also lower in the on-topic case (6% users and 17% assessors) than that in the non-vertical case (15% users and 24% assessors), which indicates that both users and assessors tend to be more satisfied if there are on-topic verticals on SERPs.
Table 2 shows the effect of verticals with different presentation styles on satisfaction scores from both users and external assessors. The values shown in the second, third and fourth columns are the average Z-scores of all the pages X  verticals with the corresponding presentation style and quality (non-vertical, on/off-topic vertical). Values shown in parenthesis are the differences compared with that on pages without verticals. Values in the last column shows the im-provement in Z-scores from pages with off-topic verticals (in the fourth column) to those with on-topic verticals (in the third col-umn).
 Table 2: Effect of Verticals with Different Presentation Styles on
Satisfaction (* indicates statistical significance at p &lt; 0.1 level,** Users X  Satisfaction Feedback Encyclopedia 4.46 4.99 (+0.53**) 4.67 (+0.21) +0.32** D ownload 4.75 5.25 (+0.50**) 4.60 (-0.15) +0.65** External Assessors X  Satisfaction Annotation Encyclopedia 3.18 3.62 (+0.44**) 3.13 (-0.05) +0.49** D ownload 2.85 3.58 (+0.73**) 3.31 (+0.46**) +0.27**
A number of interesting findings can be concluded from Table 2: 1) Image verticals do not really bring more satisfaction to users. This is partly because information obtained from image verticals can usually also be easily obtained from the non-vertical results. It is worth noting that off-topic images may result in a remarkable decline because irrelevant images are usually conspicuous and an-noying. The fact that images bring more satisfaction to assessors may be because that assessors care more about search effort [24] and on-topic images may sometimes provide an instant answer to the query task, which will save a lot of time. 2) The encyclopedia vertical, as well as the download vertical, will bring more satisfac-tion for both users and assessors, and there is no significant decline even when the vertical result is irrelevant, which means such two kinds of vertical results are worth inserting into SERPs to improve the page quality. 3) Both on-topic and off-topic news verticals have no significant effect on users X  satisfaction. On-topic news verticals will bring a significant drop in satisfaction for assessors, which may be because relevant news verticals may attract users to click them, leading to another search result page (in our experimental environ-ment), which may be considered as a waste of time. 4) It is worth noting that encyclopedia verticals and news verticals have similar appearances (see Figure 1) but have completely different effects on satisfaction scores. This may be because encyclopedia verticals can provide users a more structured information with figures and texts describing the search target. In contrast, the figure provided by news verticals may be not so closely related to the search target and other non-vertical results can also provide as rich information as news vertical results.

Table 2 also shows some subtle differences between users and external assessors. On-topic image verticals will improve satisfac-tion scores from external assessors but have no significant effect on those from users, which may be because assessors will be more sat-isfied if the search task is finished in short time periods while users will probably be satisfied as long as their search need is met in not a very long time. Moreover, assessors will be dissatisfied when there are on-topic news verticals on SERPs while users will not, which indicates that assessors may be stricter with the wasted time caused by news verticals than users. All these findings indicate that asses-sors may care more about search effort, which is in line with the findings in [24].
We further investigate the effect of verticals at different positions on satisfaction scores from both user X  X  and assessor X  X  perspectives. The results are shown in Table 3.
 Table 3: Effect of Ranking Positions of Verticals on Satisfaction (* Users X  Satisfaction Feedback R ank 1 4.79 5.06 (+0.27**) 4.43 (-0.36**) +0.63** R ank 3 4.79 4.93 (+0.14) 4.63 (-0.16) +0.29** R ank 5 4.79 4.87 (+0.08*) 4.85 (+0.06) +0.02 External Assessors X  Satisfaction Annotation R ank 1 3.24 3.48 (+0.24*) 3.09 (-0.15) +0.39** R ank 3 3.24 3.46 (+0.22**) 3.31 (+0.07) +0.15 R ank 5 3.24 3.37 (+0.13) 3.27 (+0.03) +0.10
Verticals are placed in three different positions, namely, rank 1, rank 3 and rank 5. Values in Table 3 are organized in a sim-ilar form with those in Table 2. Different rows show average Z-scores on pages with verticals at different positions. We can see that on-topic verticals bring significant improvement to satisfaction for both users and assessors when placed at rank 1. The effect is not so significant when verticals are inserted at rank 3 or rank 5. This encourages us to insert on-topic verticals at a very top position so that they may help improve the search experience of users. Mean-while, an off-topic vertical reduces users X  satisfaction the most sig-nificantly if inserted at rank 1. Off-topic verticals at rank 3 and 5 do not exert any significant influence.
According to our experimental results and [21], users X  search satisfaction may be greatly affected by the benefit they obtain from the search result page and the cost during the information searching process. In this section, we first discuss some evaluation metrics from the perspective of benefit and cost and then investigate how verticals take effect in these metrics. In this way, we try to obtain a deeper insight into the effect of the vertical results.
We use cumulative gain (CG) and normalized discounted cumu-lative gain (nDCG@N, N=3, 5, 10 in our case) [19] as a measure of search result page outcomes, which is also used in [21]. In Equation (2) and (3), r i is the ith result on the corresponding SERP and Rel ( r i ) is its relevance score. We invite three profes-sional assessors from a commercial search engine company to la-bel a four-point-scaled relevance score for all query-result pairs in our experiment. The KAPPA coefficient of their annotation is 0.73, which can be characterized as a substantial agreement.
With the eye movement information we collected during our ex-periment process, we can exactly figure out users X  examined result list and thus measure the search benefit from users X  perspective. We use Rlist , which represents the examined result list obtained from the eye movement data, to replace the list of all results on SERPs used in equation (2) and (3) to obtain another group of met-rics for search benefit. Notice that it is different from metrics in sec-tion 5.1.1 as we only sums up the relevance scores of those results which have been exactly examined by users instead of all results on SERPs.

We set the examination threshold to 200 milliseconds, which is recommended in [26, 31]. We also tried a number of other thresh-olds ranging from 100 ms to 1000 ms, and the results were quite similar. We regard those results with an eye fixation time of more than 200 ms, as examined, and thus we obtain the users X  examined result list.
The metrics used to evaluate the cost users spend while exam-ining the search result page can be obtained from two different ways. The first group of metrics, namely, search dwell time, max-imum clicked rank and number of clicks, is obtained from users X  mouse movement log and click-through data. These three metrics are widely adopted in existing search satisfaction works [16, 21] and are demonstrated to be effective at measuring search cost. The second group of metrics is based on the eye movement data. We can obtain the number of examined results as well as the length of the examined result sequence (note that a user may examine one partic-ular result more than once, and in such case, it will be counted for multiple times). The examination threshold used here is still 200 ms.
In this section, we investigate how verticals affect search satis-faction following the benefit-cost framework. Due to the restric-tion of space, we only select out some typical metrics discussed in Section 5.1 as an example, including ( CG ) defined by Equation (2), ( nDCG ) defined by Equation (3), length of examined result sequence ( LER ) described in Section 5.1.3, and CG of examined results ( ECG ) described in Section 5.1.2. We take these metrics as examples because they are representative, reflecting the quality of SERP (CG and nDCG) or the examination behavior of users (LER and ECG). The situations of the other metrics are similar with these selected ones in general.

Table 4 shows the correlations between these evaluation metrics and users X  satisfaction judgements on SERPs with on/off-topic ver-ticals or without verticals. The results show that satisfaction has
DCG@10 (Benefit) w/ on-topic verticals Pearson 0.16 0.27 0.28 0.21 -0.42 -0.49 0.36 0.30 w/ off-topic verticals Pearson 0.21 0.22 0.25 0.25 -0.39 -0.48 0.31 0.28 a weak positive correlation with CG and nDCG, a weak negative correlation with LER, and a relatively strong positive correlation with and CG/LER. Such findings are similar with that in [21]. It is worth noting that there is a moderate negative correlation between ECG and satisfaction, which is different from that between CG (or nDCG) and satisfaction. This is reasonable because CG and nDCG are metrics which measure the result quality of a certain SERP and has nothing to do with users X  examination behavior. Usually, the better the SERP is, the more satisfied the user will feel. However, ECG calculates the information gained from the results examined by the user, and a higher ECG may come from an examination of more search results, which usually means more cost and thus will probably result in less satisfaction. The correlation between sat-isfaction and ECG per examined result (ECG / LER) is positive, which indicates that a user will be more satisfied if he can get more information with less effort. The results in Table 4 also show that the correlations for different types of verticals share similar trends but there are still some subtle differences. We will provide some insight by showing detailed distributions of these metrics across different types of verticals.

Figure 4: Distribution of LER across verticals with different
Figure 4 shows the effect of verticals on LER, which is obtained from the eye movement data and can be a signal of search cost. From this figure, we can see that on-topic image, encyclopedia and download verticals can reduce the number of examined results re-markably, which may be because such vertical results can usually provide instant answers or a direct download link. An on-topic tex-tual vertical or news vertical will not reduce the search cost, which may imply that such type of verticals can hardly improve users X  search efficiency. We assume that this is because a textual vertical is usually just a combination of information from several perspec-tives. Additionally, a news vertical just leads the user to another list of news search results, which may not be satisfying. It is worth not-ing that nearly all types of off-topic verticals will increase the num-ber of examined results, which indicates that we should be careful not to put low quality verticals on SERPs to reduce users X  cost.
Figure 5: Distribution of ECG across verticals with different
Figure 5 shows the effect of verticals on ECG, which is regarded as a metric of search benefit. The results show that ECG is lower when there is an on-topic vertical result of encyclopedia, image and download. This is reasonable because a relevant vertical may be good enough to finish the search task and thus may reduce the number of examined results, which may then lead to a decline in ECG. Relevant textual and news verticals may cause remarkably high CG because they may not be useful to users most of the time and the high relevance of such results may become a waste. The results in Figure 5 indicate that ECG may not be a positive estima-tor for satisfaction because the it is also affected by search cost. To verify this, we further develop another metric by dividing ECG by LER and the result is shown in Figure 6.

The results in Figure 6 show that for the case of on-topic down-load verticals, ECG/LER is remarkably higher that on SERPs with off-topic verticals and without verticals, which means on-topic down-load verticals help improve users X  search satisfaction and is in line with the findings in Section 4.2. The differences between ECG/LER on SERPs with other four kind of verticals and without verticals are not significant, which is slightly different from the findings in Sec-tion 4.2. This may imply that an evaluation metric defined as bene-fit divided by cost is still not perfect to model user satisfaction and a more appropriate fitting function is needed. We leave this for fu-ture work. Nevertheless, it is easy to find that all types of off-topic verticals will result in a significant reduction in ECG/LER, which implies adding off-topic verticals to SERPs may not be a good idea.
Findings in this section show that user satisfaction can be studied in the benefit-cost framework and that sometimes metrics generated by dividing benefits with costs can better estimate user satisfaction, which is the same with the findings in homogeneous environment [21]. Meanwhile, more suitable metrics are needed in the future to better model search satisfaction. In the next section, we will predict satisfaction scores from both users and external assessors with the collected information and compare the predictive power of features from different resources.
Although there are plenty of existing studies [1, 12, 15] in the prediction of search satisfaction, none of them take the existence of the vertical results into consideration. According to the findings in Sections 4 and 5, the vertical results have important impacts on the satisfaction judgements for both users and external assessors. Verticals also affect the cost and benefit of users while completing Web search tasks. Therefore, it is necessary to investigate how we can predict the satisfaction of users while facing SERPs with ver-ticals. Recent studies in [21] and findings in Section 5 encourage us to predict satisfaction with features in a benefit-cost framework. The difference between our proposed method and the existing so-lutions in [21] is that we mainly focus on the effect of verticals in addition to other interaction behaviors.

Table 5 shows the vertical-aware feature sets adopted in the pre-diction of search satisfactions. There are two major information sources. One is information related to SERP itself as well as mouse log information, which can both be easily collected at large scale. All these featues we used here are directly related to the vertical results and we denote them as Click-Through features. The other is eye movement information, which is proven to have strong ability in predicting search performance [6, 11, 13, 29] but will be hard and expensive to collect in practice. We denote them as Eye-Tracking features. Recent studies [14] also show that other interaction be-haviors, such as mouse movements, can be good substitutes for eye tracking information. We try to compare the predictive power of these two different sources of information to see to what extent we can predict search satisfaction.
 Feature Feature Description
Click-Through Features v_style the presentation style of the vertical result, in-v_position the rank position of the vertical result, values arr_time ( t _ ve  X  t _ s ) / ( t _ e  X  t _ s ) , where t _ ve refers to if_click whether the vertical result is clicked click_time ( t _ v  X  t _ s ) / ( t _ e  X  t _ s ) , where t _ v refers to the aft_time ( t _ e  X  t _ fv ) / ( t _ e  X  t _ s ) , where t _ fv refers to hover_time the mouse hover length (in second) on the ver-v_dwell_time dwell time (in second) on the vertical result if_other_click this feature will be True if there is any other
Eye-Tracking Features exam_num number of examined results exam_seq_len the length of the examined result sequence fix_arr_time ( e _ ve  X  t _ s ) / ( t _ e  X  t _ s ) , where e _ ve refers to fix_time eye fixation length (in second) on the vertical
The data set described in Section 3 is adopted in the prediction with five-fold cross validation. The learning algorithm in the pre-diction process is ridge regression [17], which is widely used in prediction tasks with continuous values. This prediction model im-proves the least squares estimation and is usually more reliable in practical use. We implement the satisfaction prediction method in Guo et al. [15] because this prediction method is a state-of-the-art method based on fine-grained mouse behavior data for predict-ing web search success. The predictive model in [21] is also used here because in this work the features are extracted in a benefit-cost framework and can estimate graded search satisfaction more accu-rately than most existing works in homogeneous environment. We incorporate vertical-aware features proposed in Table 5 to test if we can achieve significant improvement in satisfaction prediction. Note that in our experiment, there is only one query in a search task. So any feature that is related to multi-queries is not included in the implementation. We use the Normalized Root Mean Square Error (NRMSE, ranging from 0 to 1, smaller values mean better prediction) to evaluate the model performance as in most contin-uous value regression tasks [21]. The prediction performance of different feature groups is shown in Table 6. We perform a t-test to show the statistical significance on differences between methods with click-through / eye-tracking features and the original method. The results in Table 6 show a number of interesting findings: 1) The prediction performance for annotations from external assessors is much better than those from users for all types of feature com-binations. This probably means that the annotations from the as-sessors X  side are more objective and consistent with each other. 2) The involvement of vertical-aware features significantly improves the prediction performance for both click-through and eye-tracking features. This shows the effectiveness of vertical information in predicting search satisfaction on SERPs with heterogeneous ver-tical results. 3) Among the two sources of features, we can see that eye-tracking features only perform slightly better than click-through features and the performance of click-through features is quite promising since such type of features can be collected at a low cost and at scale. We achieve the best performance when all feature groups are used for predicting user satisfaction. 4) Finally, we realize that methods based on Guo et al. [15] perform better when predicting external annotations while methods based on Jiang et al. [21] perform better when predicting user satisfaction. This in-dicates that features in the benefit-cost framework can make better use of users X  search information and can estimate user satisfaction more accurately.

We have also conducted a leave-one-out ablation study to explore the contribution of different features in Table 5 on predicting sat-isfaction. Considering that the number of features is not very big, we leave one feature out each time and test the change in prediction performance to compare the contribution of each individual feature. We find that arr _ time contributed the most for the prediction of both user satisfaction and external annotation. This feature mea-sures the time when the user X  X  mouse arrives at the vertical result, which may to some extent measure the time when the user starts to examine the vertical result. Because vertical results usually have a great influence on users X  examination behavior [25, 35], arr _ time may be important for satisfaction prediction. v _ dwell _ time con-tributed the least when predicting user satisfaction, which may re-flect the fact that users may care little about the time they spend on result landing page (can be considered as search effort) and is in line with the findings in [24]. When predicting external annota-tion, the least important feature is click _ time . It may because that from the external assessors X  point of view, the snippet of a vertical result can usually provide enough information for the user and thus a click may not be necessary. All features in Table 5 are useful when predicting user satisfaction since omitting any one of them will produce a drop in prediction performance.
Satisfaction prediction is an important research issue in the eval-uation of search engine performance, and satisfaction studies on federated search pages have not been pursued. In this paper, we carry out a lab-based user study with specifically designed aggre-gated search result pages to see how verticals affect search satis-faction. We collect satisfaction scores from both users and external assessors to make a comparison because the concept of satisfaction is quite subjective. We find that on-topic Encyclopedia verticals as well as Download verticals will bring significant improvement to search satisfaction and that even off-topic ones will not result in a significant decline. Good Image verticals may not bring too much improvement but irrelevant ones will bring significant dissat-isfaction. Most users will not care about News verticals because they only provide another list of search results. Good news ver-ticals sometimes will even bring negative effects because a click leading to another SERP may be considered a waste of time. Ver-ticals will have the largest influence when they are presented at the top of a page. As the position of verticals becomes lower, the effectiveness will decline to a large extent. With the rich informa-tion collected in our experimental system, we demonstrate that a benefit-cost framework will be useful when analyzing satisfaction. We find that the vertical results will significantly affect both result benefits and search costs. We also conclude that a metric of di-viding benefit by cost will be a more appropriate estimator of user satisfaction. Finally, we propose a vertical-aware method to pre-dict search satisfaction from both users and external assessors. We verify that with features related to verticals, we can achieve signif-icant improvement in predicting search satisfaction based on state-of-the-art methods, which are effective in homogeneous environ-ment. We demonstrate that features extracted from the perspective of both benefit and effort can greatly improve the user satisfaction prediction model. We also conclude that satisfaction scores from external assessors are easier to predict probably because profes-sional assessors are usually more objective while judging satisfac-tion. Interesting directions for future work include understanding and predicting satisfaction on SERPs with multi-verticals. More-over, incorporating the effect of verticals into user behavior models will also be a challenge.
This work is supported by Tsinghua University Initiative Sci-entific Research Program (2014Z21032), National Key Basic Re-search Program (2015CB358700) and Natural Science Foundation (61472206, 61073071) of China. Part of the work has been done at the Tsinghua-NUS NExT Search Centre, which is supported by the Singapore National Search Foundation &amp; Interactive Digital Media R&amp;D Program Office, MDA under research grant (WBS:R-252-300-001-490). [1] M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if [2] A. Al-Maskari, M. Sanderson, and P. Clough. The [3] J. Arguello and R. Capra. The effects of vertical rank and [4] J. Arguello, F. Diaz, J. Callan, and J.-F. Crespo. Sources of [5] J. Arguello, F. Diaz, and J.-F. Paiement. Vertical selection in [6] G. Buscher, S. T. Dumais, and E. Cutrell. The good, the bad, [7] O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan.
 [8] C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, [9] J. Cohen. Weighted kappa: Nominal scale agreement [10] F. Diaz. Integration of news content into web results. In [11] S. Djamasbi, A. Hall-Phillips, and R. R. Yang. Serps and ads [12] H. A. Feild, J. Allan, and R. Jones. Predicting searcher [13] L. A. Granka, T. Joachims, and G. Gay. Eye-tracking [14] Q. Guo and E. Agichtein. Towards predicting web searcher [15] Q. Guo, D. Lagun, and E. Agichtein. Predicting web search [16] Q. Guo, R. W. White, S. T. Dumais, J. Wang, and [17] A. E. Hoerl and R. W. Kennard. Ridge regression: Biased [18] S. B. Huffman and M. Hochster. How well does result [19] K. J X rvelin and J. Kek X l X inen. Cumulated gain-based [20] K. J X rvelin, S. L. Price, L. M. Delcambre, and M. L. Nielsen. [21] J. Jiang, A. Hassan Awadallah, X. Shi, and R. W. White. [22] J. Jiang, D. He, and J. Allan. Searching, browsing, and [23] D. Kelly. Methods for evaluating interactive information [24] Y. Liu, Y. Chen, J. Tang, J. Sun, M. Zhang, S. Ma, and [25] Z. Liu, Y. Liu, K. Zhou, M. Zhang, and S. Ma. Influence of [26] L. Lorigo, M. Haridasan, H. Brynjarsd X ttir, L. Xia, [27] I. Markov, E. Kharitonov, V. Nikulin, P. Serdyukov, [28] V. Navalpakkam, L. Jentzsch, R. Sayres, S. Ravi, A. Ahmed, [29] M. Richardson, E. Dominowska, and R. Ragno. Predicting [30] T. Sakai and R. Song. Evaluating diversified search results [31] D. D. Salvucci and J. H. Goldberg. Identifying fixations and [32] L. T. Su. Evaluation measures for interactive information [33] L. T. Su. A comprehensive and systematic model of user [34] S. Verberne, M. Heijden, M. Hinne, M. Sappelli, S. Koldijk, [35] C. Wang, Y. Liu, M. Zhang, S. Ma, M. Zheng, J. Qian, and [36] H. Wang, Y. Song, M.-W. Chang, X. He, A. Hassan, and [37] K. Zhou, R. Cummins, M. Lalmas, and J. M. Jose.
 [38] K. Zhou, R. Cummins, M. Lalmas, and J. M. Jose.

