 We study entity ranking on the INEX entity track and pro-pose a simple graph-based ranking approach that enables to combine scores on document and paragraph level. The com-bined approach improves the retrieval results not only on the INEX testset, but similarly on TREC X  X  expert finding task.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval; Performance, Experimentation entity ranking, expert finding, graph-based retrieval
When people use retrieval systems, they are often not searching for documents or text passages in the first place, but for some information contained inside. Often named en-tities like person names, organizations, or locations play a central role in answering such information needs. The INEX entity ranking track addresses this issue with a testset of entity ranking topics and corresponding judgments on the INEX Wikipedia corpus. All topics specify a target entity type and a topic of interest in a few query terms. The target type is given as a Wikipedia category, e.g.  X  X ovies X ,  X  X rees  X , or  X  X rogramming languages X . In contrast to other entity ranking tasks, each retrieved entity in the INEX track needs to have its own article in the Wikipedia collection. Obvi-ously, this decision is only suitable for entity ranking wit hin an encyclopedia, where we can assume that most mentioned entities in fact have their own entry. In consequence, a sim-ple baseline run is given by a straightforward article rank-ing using the query terms that describe the topic of inter-est. Combined with an appropriate category filtering mech-anism that also allows articles of descendant categories, s uch a baseline can reach already a high retrieval quality [4].
However, the described baseline approach shows no tech-niques so far that are specific to entity ranking. Looking into the domain of expert finding, which can be considered as a typical entity ranking task with fixed entity type, most approaches establish connections between documents and contained mentions of entities and use these connections to propagate the relevance from initially retrieved document s towards the entities. We want to show in this paper how the relevance propagation approach can be introduced to the setting of the INEX entity ranking track. Furthermore, we will extend the existing propagation model by incorpo-rating text fragments of various sizes.
Entity mentions in Wikipedia articles are often linked to-wards their own encyclopedia entry. If we use these links to build a query-dependent entity containment graph, con-sisting of the top k initially retrieved entries and all their included linked entities, we can apply known retrieval mod-els from expert finding. Balog et al. rank expert entities according to the relevance sum of all documents mentioning the expert [1]. In our containment graph model a similar ap-proach can be expressed by calculating a weighted indegree wIDG : where  X ( e ) denotes the set of vertices adjacent to e , and w ( e  X  | q ) specifies the relevance weight of e  X  s encyclopedia en-try with respect to the query q . Notice that our weighted in-degree ranking neither requires a probabilistic scoring mo del nor normalized associations weights between adjacent en-tries as in the work of Balog et al. Initial experiments showed that this model does not improve over our initial baseline ranking. It even decreases the retrieval quality c on-siderably. In fact, the direct description of an entity give n in its own Wikipedia article is so important for the ranking that it needs to be considered in the retrieval model. Hence, we suggest the following extension of the weighted indegree : The factor  X  interpolates the initial article relevance with the summed relevance of other articles mentioning entity e . Since the above equation resembles the definition of a personalized graph centrality by incorporating the weighting of the vertices themselves, we call it personalized weighte d indegree P wIDG .
Figure 1: Influence of  X  and  X  on retrieval quality
Related work on expert finding shows that proximity fea-tures help to further improve the retrieval quality. Proximity features have been integrated either in the relevance estima-tion model itself [3], or by tightening the initially ranked text fragments [5]. Within the framework of entity containment graphs, the latter means to combine paragraph and article level relevance by simply adding vertices of both types to the graph.

Since the Wikipedia collection contains structured text, we can make use of the given paragraph segmentation and retrieve and score XML &lt;P&gt; elements as well. An entity e is then linked by other entities e  X  or paragraph vertices p when their text refers to e . For distinction, we denote the set of neighboring paragraph vertices of an entity e by  X  P ( e ), respectively  X  E ( e ) for the set of adjacent entities. In order to control the influence of both types of text fragments, a second interpolation factor  X  is introduced:
For the initial ranking as well as for the graph genera-tion the PF/Tijah retrieval system [2] was employed. We generated for each of the 46 INEX topics an XQuery that creates an entity containment graph from the top 200 ar-ticles retrieved by the title keywords. A standard language modeling retrieval model was employed for the initial scoring of text nodes.

Analyzing the introduced entity ranking models requires to study the influence of the two interpolation factors  X  and  X  . Figure 1 shows the results of two experiments combined in one graph. In a first test we only retrieved articles and were interested in finding an appropriate setting of  X  for calculating a personalized weighted indegree P wIDG . The lower two curves in the figure represent the outcome of this experiment. They show that  X  needs to be set close to 1, which clearly points out the importance of the entity X  X  own Wikipedia entry. On the other hand, combination with the scores of other articles mentioning the entity clearly im-proves the retrieval quality. For the second test, we kept  X  fixed at its best value, now varying the setting of  X  , dis-played in the two upper curves of the graph. While the mean average precision improves slightly, the precision on top of the retrieved list P@5 shows a clear maximum when article and paragraph scores are considered equally with a setting of  X  = 0 . 55. The independence of  X  and  X  assumed by the testing procedure might be not adequate and the fine-tuning on the data set can lead to unrealistic results, but the com-bination model achieves improvements even without finding the optimal parameter setting. Table 1 shows the outcome of all introduced ranking methods. Besides the INEX col-lection, we also tested the proposed entity ranking model on TREC X  X  expert finding task from 2007. Since the TREC data does not provide a text description of each expert entity comparable to the Wikipedia entries, we could only evaluate the proposal of combining document and paragraph level re-trieval scores. Using the same parameter setting of  X  = 0 . 55, we show that the found improvements are not a matter of overfitting. Our combination model yields a considerable improvement on MAP and a slighter one for P@5.
We demonstrated on the INEX entity ranking testset the advantage of combining the direct Wikipedia article score with the propagated scores from text fragments of different sizes. The outcome demonstrates the potential of our com-bination model, which beats the best performing INEX run [4] on the entity ranking task. The improving effect of using article and paragraph scores in a joined propagation model could be confirmed on a different testset and collection.
