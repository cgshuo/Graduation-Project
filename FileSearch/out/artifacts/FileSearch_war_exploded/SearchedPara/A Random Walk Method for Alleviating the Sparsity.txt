 Collaborative Filtering is one of the most widely used ap-proaches in recommendation systems which predicts user preferences by learning past user-item relationships. In re-cent years, item-oriented collaborative filtering methods came into prominence as they are more scalable compared to user-oriented methods. Item-oriented methods discover item-item relationships from the training data and use these re-lations to compute predictions. In this paper, we propose a novel item-oriented algorithm, Random Walk Recommender, that first infers transition probabilities between items based on their similarities and models finite length random walks on the item space to compute predictions. This method is especially useful when training data is less than plentiful, namely when typical similarity measures fail to capture ac-tual relationships between items. Aside from the proposed prediction algorithm, the final transition probability matrix computed in one of the intermediate steps can be used as an item similarity matrix in typical item-oriented approaches. Thus, this paper suggests a method to enhance similarity matrices under sparse data as well. Experiments on Movie-Lens data show that Random Walk Recommender algorithm outperforms two other item-oriented methods in different sparsity levels while having the best performance difference in sparse datasets.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval  X  Information Filtering Algorithms, Experimentation, Performance collaborative filtering, sparsity, random walk
Recommendation system s became an important research area with the enormous expansion of Internet services such as e-commerce sites. With the increase in diversity of prod-ucts and services, consumers have gained the opportunity to find ideal items along with the drawback of selecting among abundance of uninteresting products. As an example, Ama-zon.com provides millions of books and other products in which a typical user might have no interest. Depending on the past transactions of a user, recommending products of interest to the user may both be useful to the system and to the user. Within this concept, many online businesses such as Amazon.com and Netflix (an online movie renter) have used recommendation systems to provide personalized suggestions. Such systems are reported to boost online sales by converting shoppers to buyers and building customer loy-alty[12]. In October 2006, Netflix announced its one million dollar prize on recommendation systems which sparked re-searchers X  interests.

In a broad view, recommendation systems keep track of past purchases of customers as well as other information of product and customer profiles to make personalized recom-mendations for each customer. In the most common for-mulation, the recommendation problem is reduced to the problem of estimating ratings for the products that have not been seen by a user. However, based on the nature of the application, recommendation problem can be thought as identifying only the highest ranked products for each user instead of predicting the rating of each product for each user.
Collaborative Filtering(CF) 1 is one category of recom-mendation systems which solely relies on the past behavior (ratings, purchase history, time spent) of the users. As op-posed to content based approaches, CF does not use explicit profiles of items (i.e., keywords that describe the items, such as artists, genres, etc., for movies) and users. CF has many advantages over content-based methods such as its gener-icity and its potential to explore implicit associations. For example in some domains such as video recommendation, it might not be easy to build item profiles whereas CF meth-ods can be applied to all domains. Thus there is a wealth of empirical [6, 7, 8, 10, 17, 19, 20, 21] and theoretical [3, 9, 14, 15, 16] research on CF resulting in many successful com-mercial products such as Amazon.com and Netflix. Section 2 gives a detailed survey on that literature. We use the term CF as an abbreviation of Collaboration Filtering throughout the paper. CF methods can be classified into two common classes. The first approach, known as memory-based, is based on the assumption that each user belongs to a larger group of simi-larly behaving users. Therefore if similar users can be iden ti-fied for a particular user, a combination of the preferences o f that group gives reasonable recommendations for the user in question. Indeed this method is referred to as user-oriente d memory-based approach; an analogous method which builds item similarity groups using co-purchase history is known a s item-oriented. The second approach, referred to as model-based, assumes a model which generates the ratings and learns that model with training data. Clustering, Bayesian network models and other machine learning techniques can be listed under model-based approaches[2, 7].

The focus of this paper is on a model-based approach that especially works well in sparse data. The method described here can be viewed as an extension to the item-based top-N recommendation algorithm [8] in the sense that the way it builds and uses item similarities to infer recommenda-tions. Item-based top-N recommendations algorithms have been used in various forms since the early days of CF rec-ommender systems[21]. Although most of the successful CF methods rely on building user-user relationship, unfor-tunately these methods are not scalable since in a typical commercial system number of users can be much larger than the number of items. In [20],the authors show empirically that item based methods can perform as good as user based methods. On the other hand, our method has resemblance to Huang et al.  X  X  link analysis approach [13] in the manner that they deal with sparsity problem.

We propose a model in which users make random walks in the item space according to the similarity of items. An initial normalized item-similarity matrix, which can be ob -tained in various ways [2, 20], is interpreted as a transi-tion probability matrix. Therefore, a user enjoying an item most likely jumps to a similar item in the next step of his walk. The aggregate probability distribution of a user over the items throughout this random walk constitutes the final rating predictions for the items. This method has three key steps, which are (i) building the initial transition probab il-ity matrix, (ii) obtaining the aggregate probability distr i-butions and (iii) interpreting these probabilities to pred ict ratings. This method outperforms Deshpande et al.  X  X  item-based recommendation algorithm where the training data is less than plentiful. Furthermore, final transition proba -bility matrix obtained in this method can be used as item-similarity matrix in other item-oriented approaches when the data is sparse. The main contribution of this paper, indeed, is the method to obtain an item-similarity matrix which also takes into account transitive item associations rather than just co-purchase history.

The remainder of the paper is organized as follows: Sec-tion 2 provides the definitions and the historical review of the literature on collaborative filtering. Section 3 descri bes the model and the algorithm used to predict ratings for each item. Section 4 provides an experimental evaluation of the algorithm in different sparsity levels and shows the implica -tions of various parameters on the performance. This sectio n also gives a brief comparison against another item-oriente d approach and a method which was proposed to alleviate sparsity problem. Finally, section 5 concludes with discus -sions and possible improvements.
There exists a set of U users and a set of I items where | U | = n and | I | = m . Each user has a numeric value for each product. Some of the papers assume only binary values (e.g., good and bad) as ratings for the sake of simplicity. These whose rows correspond to user preference vectors. Addition -ally, ~ R u is the rating vector of user u , whereas ~ R i rating vector for item i . Throughout the paper, we use let-ters of u, v for indexing users and i, j for items for the sake of consistency.

Prediction Problem : Given a rating matrix R with some unknown entries, predict each missing entry such that the difference between the predicted matrix and the actual matrix is minimized.
CF is the method of making predictions on the ratings of a particular user by collecting taste information from many users. The term was first used by Goldberg et al. in the Tapestry system which relies on each user to identify simila r-minded users manually. In [10] Breese et al. , authors cat-egorized CF into two general classes of memory-based and model-based methods[7].
Memory-based algorithms[7, 19, 21] are heuristics to pre-dict a missing rating by aggregating the ratings of k users who are most similar to a particular user. This can also be seen as identifying the k -Nearest Neighbors and combining their information to predict a rating. Formally, a missing rating r u,i can be formulated as where U  X  is the set of users who are most similar to user u who have rated i , and aggr is the method of combining these values. In the simplest case, the aggregation is the average of ratings of similar users on a particular item [2].
Analogously the rating r u,i can be predicted as an aggre-gation of items similar to i and which are rated by u . The first approach is known as user-oriented whereas the latter is cited as item-oriented. In [20],the author shows that ite m-oriented approaches perform as good as the other approaches while being more scalable and efficient.

To identify the neighborhoods of users, these methods compute similarity between each pair of users. Common choices are the cosine similarity and the Pearson correlati on approaches. In the cosine based approach[7, 20], the simi-larity between u and v , s uv , is measured by computing the cosine angles between the rating vectors of users u and v . Only the items rated by both users are taken into account while computing the angles. Formally if we assume S uv is the set of items which are rated by both of the users, the similarity s uv is:
Correlation based approach uses Pearson correlation coef-ficient to measure the similarities between users [19, 21]. T he advantage of this method is that it also takes into account that different users might have different rating schemes. where r u is the average of nonzero ratings of the user u .
Second step of memory-based methods is computing the rating, r ui , using the ratings of most similar neighbors of user u . The key point is the aggregation function shown in equation (1). This function usually takes the weighted average of neighbors, which implies where N ( u, i ) is the set of closest neighbors of u who have rated i , and w uv is the weight of similarities in user-oriented approach. Analogously, the item-oriented version of ratin g interpolation can be defined as where N ( i, u ) is the set of closest neighbors of item i which are rated by u , and w ij is the weight of similarities.
Resnick et al. and Shardanand used similarity values be-tween users directly as interpolation weights in their user -oriented approaches (i.e., they assumed w uv = s uv ) [19, 21]. Later Sarwar et al. tailored this intuitive way to their item-oriented approach [20]. Recently, Bell et al. , who are the leaders in the Netflix challenge as of the writing of this paper, argued that the heuristic nature of determining inte r-polation weights needs to be addressed. Different algorithm s use different similarity measures and there is no fundamen-tal justification for the chosen similarities. The common ap -proach, using similarity values directly as weights, might ig-nore or magnify some hidden item dependencies. Thus, Bell et al. proposes a formal way to adjust these interpolation weights. Their method identifies similarity groups for each item and learns the actual weights by using the known rat-ings of users who rated all the items in that neighborhood. The problem turns into a quadratic optimization problem and this approach improves the accuracy of the k -NN sig-nificantly without increasing the computational complexit y of the overall method [6].
Model-based algorithms use the collection of ratings to learn a model, which is then used to make predictions. There are various approaches under this heading. Clustering mod-els[7, 16, 19, 22], probabilistic approaches[3, 7, 16, 14] a nd dimensionality reduction and matrix reconstruction tech-niques [4, 6, 9, 11, 5] can be listed as main model-based approaches.

Breese et al. formulated the prediction problem in a prob-abilistic manner as the estimated probability of a rating given the known ratings. To estimate this probability, they proposed cluster models and Bayesian networks. The first method clusters the like-minded users and learns the number of classes and the pa-rameters from the data. One limitation of this approach is that each user belongs to a single cluster, whereas some ap-plications may benefit from the ability to cluster users into several categories [2]. Kumar et al.[16] studied the model where there are clusters of products and each user has a probability distribution over clusters. A user first choose s a cluster by his distribution and then uniformly randomly selects an item from that cluster. This method reduces the preference matrix to the size of n  X  k where k is the num-ber of clusters. Kleinberg and Sandler [15] generalized thi s model to the case where the choice within a cluster is arbi-trary, and considered a mixture model in which each cluster is a probability distribution over all items.

Azar et al.[4] identified matrix reconstruction as central to recommendation systems. The aim is to reconstruct the whole matrix which can be approximated by a low-rank ma-trix reconstruction using SVD. 2 Drineas et al. [9] improves this result by reducing the number of samples required; but addresses only the recommendation problem instead of pre-diction problem. Their algorithm asks a small number( k ) of users about all items, and the remaining users for their preference on a small number of items. The requirement that a set of users should vote on all items is not practical in actual recommendation systems. Similarly, Goldberg et al. X  X [11] SVD-based Eigentaste algorithm uses a gauge set o f items each of which should be voted by each user. Drineas X  algorithm works only when a few severe assumptions are met. This method assumes that there are k dominant types, and that their canonical vectors are nearly orthogonal, whi ch means that their preferences don X  X  intersect. The second is gap assumption which is any non-dominant type is far less popular than dominant types. Awerbuch et al.[3] avoids these severe conditions by proposing a combinatorial algo-rithm without using SVD. Although their method also re-quires committee members who should vote for each item, it removes the severe conditions of type separability and gap assumption.
In this section, we study a class of model-based item-oriented prediction algorithms. The primary motivation be -hind these algorithms is the success of link analysis method s like Pagerank[18] on ranking items. Pagerank models the random walk of users on the entire web graph (extracted by treating web pages as nodes and the links between pages as edges). It finally assigns each page p a rank of its impor-tance. Specifically the Pagerank of a page p is the probabil-ity of visiting p in a random walk of web graph where each random step is either (i, with small probability) jumping to an arbitrary page with uniform probability or (ii, with high probability) walking through one of the outgoing links of th e current page. In our application, we develop an item graph where the nodes are items and the edges between nodes rep-resent similarities of items. Furthermore users are assume d to make a finite-length walk as a difference to Pagerank method. Thus ranking becomes dependent on the initial
SVD is an abbreviation for singular value decomposition and it has several applications including matrix approxima -tion. distribution of the user. We denote the rank of an item i for user u as rank ( u, i ). These algorithms are similar in spirit to Deshpande et al.  X  X  Item-Based top-N Recommenda-tion Algorithm [8] in the sense that both produce a ranking of items and similar to Huang et al.  X  X [13] link analysis ap-proach which is proposed to overcome sparseness.

At a high level, our algorithm consists of three main com-ponents. The first component is building the item graph which captures the similarity of items between each other. The second component computes the rank values of items for each user by simulating a random walk. Finally the last component interprets and scales the rank scores as ratings for each user-item pair. The details of the algorithm ex-plained in the rest of this section.
The model used by our algorithm is a Markov chain model where the probability of being in a state solely depends on the previous step, Pr ( X u,k +1 = i | X u,k ). X u,k is the ran-dom variable for the user u being at an item i in step k of his random walk. Furthermore this model incorporates a stopping probability to bring an end to the random walk. In each step of the walk user decides to continue his walk with probability  X  . Therefore the length of the random walks are geometrically distributed with the parameter 1  X   X  .
We build an item graph P of size m , where the weight of the edge between nodes i and j is equal to the probability of passing from item i to item j of a user.
 The normalized row vectors of the rating matrix, ~ R  X  u , rep-resent the initial distribution of the user on items, namely Pr ( X u, 0 = i ) = R  X  ui . Thus the probability of user u being in item j in step k is:
We now define the overall probability of user u being at item i which is directly proportional to the sum of probabil-ities over all steps of the random walk.
 where c is a constant. Since we won X  X  be using actual prob-abilities, we X  X l assume rank ( u, j ) equal to P  X  k =1  X  Thus the rank matrix,  X  R = P  X  k =1  X  k RP k contains the rank scores for all user-item pairs.
In this setting, rank scores  X  R can be computed in a very similar way to Item-Based Top-N Recommendation method in which rank matrix is the direct multiplication of rating matrix and the similarity matrix, namely R  X  S . The fact that motivates us to bring the idea of random walk approach is that the similarity matrices are usually too sparse to cap -ture actual dependencies between items. For example, an item i that hasn X  X  been rated by any user who has rated item j implies that the similarity score of 0 in most of the item-item similarity measures. However these items would be found as closely to each other, if there is another item t which is similar to both items. Random Walk Recommender captures these transitive associations in various levels p ro-portional to the length of the random walk. Therefore we parametrize the length of the walk according to the sparsity level of the rating matrix and fortunately experimental re-sults confirm our choice that  X  increases as the initial rating matrix becomes sparser.
 Algorithm 1 RandomWalkRecommender( R,  X  ) 1: S  X  ComputeSimilarityMatrix( R ) 2: for i  X  1 to m do 4: for j  X  1 to m do 5: P ij  X   X S ij /sum + (1  X   X  ) /m 6: end for 7: end for 8:  X  P  X   X P ( I  X   X P )  X  1 9:  X  R  X  R  X  P 10: Predictions  X  Scale(  X  R ) 11: return Predictions
The input to Random Walk Recommender Algorithm is the rating matrix, R , and the damping factor  X  . The output is the P redictions which has the same dimensions with R . The actual algorithm is quite simple. Lines 1 through 7 build the transition probability matrix of the Markov chain model . The first line computes the similarities between items ac-cording to their co-rate history. There are various meth-ods for this computation in the literature of collaborative filtering and these are explained in the next section. The following lines build the P matrix by considering a user ei-ther (i, with probability  X  ) walks through a direct neighbor with probability proportional to the similarity of items or (ii, with probability 1  X   X  ) jumps to an arbitrary item with uniform probability. Line 8 and 9 do the actual computa-tion for identifying the ranks of items for each user. Finall y the last line scales the ratings such that each row X  X  greates t item has the rating 5, namely rows are scaled independently from each other.
Transition probabilities are computed in the initializati on step of the algorithm and have a critical role in the effec-tiveness of the approach. As explained in the description of algorithm 3.1, transition probabilities basically depe nd on the similarity measures between items which are usually identified by analyzing co-rate history. We discussed two of the common approaches to measuring item similarities in section 2.2.1. The following subsections also provide th e details of the approaches we used in our implementation.
The similarity measure between items i and j is usually high if there are lots of users who have rated both of the items. The basic idea in similarity computation between i and j is to first identify the users who have rated both of the items and then to apply a similarity computation technique to determine S ij . Common approaches produce symmetric similarity matrices; but we destroy symmetry while comput-ing transition probabilities by normalizing the sum of each row to 1. If an item i is similar to only one item j whereas j has many more similar items, then a random walk from i to j happens with higher probability than the walk in the reverse direction. Breaking the symmetry makes the model to produce higher ratings for frequent items [8]. We also in-corporate a small probability to jump to an arbitrary item while computing transition probabilities.
As introduced in section 2.2.1 and in the equation (2), cosine-based similarity is the cosine of the angles between the projected rating vectors of the items on the users who have rated both of them. The item oriented version of (2) is as follows: where S  X  ij is the set of users who rated both of the items i and j .

The weakness of the cosine-based similarity is that it doesn  X  X  take into account that different users have different rating schemes. For instance a user may prefer to rate items that he didn X  X  like at all, while another user prefers to rate item s that he liked. To address this issue correlation-based simi -larity measures are introduced for the case of user similari -ties. (see equation (3)) This method doesn X  X  directly apply to item similarity since it normalizes values according to t he item rating averages which is not much meaningful.
Additionally one other weakness of cosine-based similarit y is that it considers all co-purchase of item pairs as a positi ve effect on their similarity. For instance, a user who has rated i with score 5, and j with score 1 contributes to the similarity value positively where indeed the opposite should be the case. Besides a scenario of giving rating 1 to both items should contribute as much as giving 5 to both items, as it shows the similarity of dislikedness.
Due to the weaknesses of cosine-based similarity explained in the previous section, we propose a method which both takes into account different user schemes and the effects of dissimilarity and dislikedness similarity. The adjuste d cosine-based similarity measure removes these drawbacks b y subtracting the corresponding user X  X  average degree from each co-rated pair. This method is first proposed in [20] by Sarwar et al. to our best knowledge. Formally, the simi-larity in this method is given by where  X  r u is the average of the ratings of user u . Experimen-tal results show that this scheme performs slightly better.
The rank scores  X  R ij obtained at the end of the algorithm are not the actual predictions. They are just numerical val-ues assigned to item-user pairs to sort the items for each user. The obvious usage of these results is identifying the top-N items for each user and recommending them which is realized in [8]. Alternatively these values can be scaled to 1-5 range to answer prediction problem. In our implementa-tion, we linearly scaled up each row of values such that the maximum of each row corresponds to 5.
The bottleneck for the algorithm 3.1 is computing the similarity matrix, S . As both of the similarity measures use the co-rate history of the all item pairs, the computational complexity of computing similarity matrix is O ` m 2 n  X  . The computation of the rank scores composed of two matrix mul-tiplication and an inverse operation which take significant ly less time compared to obtaining similarity matrices.
The beauty of this method is that similarity matrices can be precomputed since they don X  X  evolve quickly. Periodical ly updating these matrices would be more than enough. Fur-thermore the value of  X  P which is computed in the eight line of algorithm 3.1 can be precomputed as well. Therefore even though the rating history of a user develops, the actual pre-dictions for a user just require a vector-matrix multiplica tion which has complexity O ` m 2  X  . The value of  X  P can also be used as an item-similarity matrix in other item-oriented ap -proaches like [20, 6], which turns the proposed Random Walk Recommender algorithm into a similarity measure method.
We conducted an experiment using data from MovieLens[1], an online movie recommendation system, to evaluate the performance of the proposed algorithm. All experiments were performed on an Intel core 2 duo, 2.2Ghz, 2GBytes of memory and a Linux-based operating system.

This data set contains 1,000,209 ratings of 6040 anony-mous MovieLens users on 3952 movies. The original data also contains information about user demographics and movi e properties, however we didn X  X  use that information since ou r research is solely on collaborative filtering.
To evaluate the performance of Random Walk Recom-mender, we split data into a training and a test set by ran-domly selecting some percent of the nonzero ratings to be the part of test set and the remaining ones for training. We conducted our experiments in different training set sizes to observe how our algorithm behaves in different sparsity lev-els. Table 4.1 shows the properties of these datasets. For each dataset, this table shows the ratio of the training set to the whole data and the density of user-item matrix. In addition, the column labeled  X  X atings X  shows the number of items rated by a user in the corresponding training set, whereas the Cosine-based and Adjusted-Cosine average de-grees are the number of links per item the corresponding similarity measurement method explores.

We especially focused on sparse training sets. The first set contains only 0 . 01 of the whole data with an average of 1 . 66 item ratings per user. In this set the densities of cosine-ba sed and adjusted cosine-based item-item matrices differ signif -icantly whereas that difference decreases in other training Table 1: Properties of Training Sets and Similarity sets. This is due the fact that adjusted cosine-based method ignores ratings that have average rating value of the user an d the ratio of that kind of ratings to the size of training set is high when training set is sparse. The following five training sets were constructed with 0 . 05 ratio increments. The last two sets were generated to simulate the cases where the data is not sparse.

The quality was measured in three different methods, the first one being the hit-rate (HR) which is the ratio of the number of hits to the size of the test set. We refer a pre-dicted rating hit if its rounded value is equal to the actual value in the test set. An HR value of 1.0 implies that all the ratings are predicted correctly. One limitation of the hit-rate measure is that it is indifferent to the distance to actual rating in case of a miss. This limitation is addressed by the Mean Absolute Error, MAE, which penalizes each miss by the distance to actual rating. The last method is Root Mean Square Error, RMSE, a measure that emphasizes large errors compared to MAE measure. These measures are formulated below, where n is the number of entries in the test set and P i and A i are the predicted and actual ratings of the i th entry, respectively.
We compared our algorithm with a modified item based top-N algorithm . 3 As explained in section 3.1, the original Top-N algorithm identifies a ranking of items with a method which is a special case of our algorithm where  X  equals 0. We modified Top-N algorithm such that it generates ratings based on the ranking it finds. The third method, Default Voting, is an extension to Top-N algorithm where the sim-ilarity matrices are computed as if half of the unknown en-tries are rated with the average rating of the corresponding user. Therefore DV produces very dense similarity matri-ces regardless of the size of training set. This extension is first proposed in [7] to improve performance where the training data is too small. The results of Random Walk Recommender algorithm are gathered when the parameter  X  is optimal. Optimal  X  values are found empirically.
We use abbreviations of Top-N, DV and RWR for item-based top-N algorithm, default voting and random walk rec-ommender respectively.

Table 3 shows the results of our experiments. The qual-ity of the predictions increases as HR increases while MAE and RMSE decrease. These metrics behave as parallel to each other in our experiments so we comment only on HR values for the evaluation of algorithms. Random Walk Rec-ommender outperforms Top-N in each of the test cases re-gardless of the similarity measure used. Default Voting al-gorithm provides the same quality, 0 . 23, for all test cases. The first dataset is so sparse that Top-N produce a score very close to 0. Even though the score of RWR is relatively high, it does not perform as well as Default Voting. The optimum  X  values for the first two test cases are very close to one which makes RWR behave like Pagerank by generat-ing ratings based on popularity. The effect of  X  is discussed in the following section in detail. When training set is be-tween 10% and 25% of the entire data, RWR becomes able to perform better than DV. In dense datasets Top-N and RWR produces almost the same results (i.e.  X  becomes 0) under adjusted cosine-based similarity measure. See figure 1 for the comparison of algorithms using different similarit y measures.
Cosine-based similarity measure reveals more item rela-tionships compared to adjusted cosine-based measure since the latter one ignores the ratings that are equal to the user X  s average rating. Adjusted measure interprets these ratings as if the user is indifferent to the them. This fact reduces the density of similarity matrix more as the training data gets smaller. Therefore cosine-based measure produces bet -ter predictions in extremely sparse training sets. However , as the adjusted measure has more and more training data it learns item similarities better than the cosine-based me a-sure due to the reasons discussed in section 3.2. The graph of optimal  X  values in figure 2 also indicates that it is al-ways possible to improve the similarity matrix obtained by the cosine-based measure since  X  is close to 1 in all test cases whereas the adjusted cosine-based measure becomes optimal since  X  approaches 0 as training set gets bigger. In the overall, Random Walk Recommender algorithm com-bined with the adjusted-cosine based measure outperforms the other combinations.
The parameter  X  determines the expected length of the random walk. There is a direct correlation with the length of the random walk and the transitive associations identified b y Random Walk Recommender method. If the similarity ma-trix is good enough to describe relationships between items without necessitating transitive associations, the lengt h of the walk should be close to 0. This case usually occurs in dense data sets. However when the training data is not dense enough, similarity measures need to use transitive as -sociation to identify actual similarities. Depending on th e sparseness of the training data, a length of 2 to 10 for the random walk would be enough to explore relationships be-tween items. When it comes to very sparse data sets, where similarity measures fail to find meaningful relationships, the length of the walk could be extremely large. As the length of the walk increase, Random Walk Recommender tends to produce ratings according to the popularity of items regard -less of the user. This is analogous to Pagerank where allow-ing an infinite length walk produces a ranking independent of the initial distribution.

Figure 3 shows the  X  vs. prediction quality graph of RWR in three different training data sets. The dense data set has the training set ratio of 0 . 6. In this case, RWR gives best predictions when  X  is close to 0 under adjusted-cosine measure and the predictions get worse as  X  increases. On the contrary, RWR under cosine-based measure surprisingly produce better predictions as  X  increases. Therefore we can conclude that adjusted measure learns the data better. The sparse data set has the training set ratio of 0 . 2.  X  takes its optimal value around 0 . 42. This result confirms our ex-pectation that in reasonably sparse data sets, determining an average length of 2 to 10 for RWR gives best results. Figure 2 also shows that the reasonably sparse training sets have optimal  X  values between 0 . 92 and 0 . 42. In extremely sparse data sets where similarity measures identify very fe w dependencies, the optimal  X  values are very close to 1 and Random Walk Recommender performs significantly better than Top-N.
In this paper, we presented and experimentally evalu-ated a model-based item-oriented collaborative filtering a l-gorithm. Our results showed that Random Walk Recom-mender algorithm outperforms a slightly modified version of item based top-N algorithm in all test cases since top-N is a special case of Random Walk Recommender. The proposed algorithm performs significantly better than top-N algorithm especially when training data is sparse. Further -more, experiments show that optimal  X  values can be pre-dicted in advance according to the density of training data. Therefore most of the computations can be pre-computed which makes the algorithm have the same computational complexity with top-N algorithm. For extremely sparse data sets optimal  X  values approaches 1 whereas it approaches to 0 as data gets denser. It takes values between 0 . 2 and 0 . 9 in reasonably sparse data sets where Random Walk Recom-mender captures some transitive associations between item s.
One important contribution of this paper is that it gives rise to enhancing similarity matrices under sparse trainin g data in which typical similarity measures fail to discover a ll item relationships. These similarity matrices can be used i n typical item-oriented approaches and their performance ca n be compared to user-oriented approaches in a future work.
Lastly, the experiments reveal that adjusted cosine-based similarity measure learns the relationships as training da ta gets dense. Whereas in extremely sparse data sets, cosine-based similarity measure is able to capture more relation-ships. However Random Walk Recommender combined with the adjusted cosine-based similarity outperforms other co m-binations in all test cases.
We would like to thank GroupLens research group of Uni-versity of Minnesota for providing valuable MovieLens data . [1] Movielens data set. Available at [2] G. Adomavicius and A. Tuzhilin. Toward the next [3] B. Awerbuch, B. Patt-Shamir, D. Peleg, and [4] Y. Azar, A. Fiat, A. Karlin, F. McSherry, and J. Saia. [5] J. K. Badrul Sarwar, George Karypis and J. Riedl. [6] R. Bell, Y. Koren, and C. Volinsky. Modeling [7] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [8] M. Deshpande and G. Karypis. Item-based top-n [9] P. Drineas, I. Kerenidis, and P. Raghavan.
 [10] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. [11] K. Goldberg, T. Roeder, D. Gupta, and C. Perkins. [12] Z. Huang, W. Chung, T.-H. Ong, and H. Chen. A [13] Z. D. Huang, Z. and H. Chen. A link analysis [14] J. Kleinberg and M. Sandler. Convergent algorithms [15] J. Kleinberg and M. Sandler. Using mixture models [16] R. Kumar, P. Raghavan, S. Rajagopalan, and [17] G. Linden, B. Smith, and J. York. Amazon.com [18] L. Page, S. Brin, R. Motwani, and T. Winograd. The [19] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [20] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [21] U. Shardanand and P. Maes. Social information [22] L. Ungar and D. Foster. Clustering methods for
