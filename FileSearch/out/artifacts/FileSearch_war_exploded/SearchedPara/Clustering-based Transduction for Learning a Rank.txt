 Transductive learning is a semi-supervised learning paradigm that can leverage unlabeled data by creating pseudo labels for learning a ranking model, when there is only limited or no training examples available. However, the effective-ness of transductive learning in information retrieval (IR) can be hindered by the low quality pseudo labels. To this end, we propose to incorporate a two-step k-means cluster-ing algorithm to select the high quality training queries for generating the pseudo labels. In particular, the first step selects the high-quality queries for which the relevant doc-uments are highly coherent as indicated by the clustering results. The second step then selects the initial training ex-amples for the transductive learning that iteratively aggre-gating the pseudo examples. Finally, the learning to rank (LTR) algorithms are applied to learn the ranking model us-ing the pseudo training examples created by the transduc-tive learning process. Our proposed approach is particularly suitable for applications where there is only little or no hu-man labels available as it does not necessarily involve the use of relevance assessments information or human efforts. Experimental results on the standard TREC Tweets11 col-lection show that our proposed approach outperforms strong baselines, namely the conventional applications of learning to rank algorithms using human labels for the training and transductive learning using all the queries available. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval General Terms: Experimentation, Performance, Algorithms Clustering, Transductive learning, Learning to rank
Transductive learning [28], a semi-supervised method for classification, is utilized to deal with the problem of unavail-ability of the labeled data in learning to rank [18]. Previ-ous studies have shown the benefits brought by transductive learning for IR [24, 14, 13, 9, 17, 26, 31]. Most of these pre-vious approaches assume the top-ranked documents to be highly relevant to the given query, and is closely related to the query topic. Then a transductive learning is carried out to iteratively aggregate the pseudo examples from all the queries available, regardless of their quality. However, the hypothesis does not always hold since the sparseness of the relevant documents of some queries, from which low-quality pseudo labels may be generated during the process of trans-duction.

In this paper, a clustering-based transduction approach is put forward to generate the pseudo examples for learning to rank with limited relevance information. In particular, we propose to apply a two-step clustering approach to select the good training queries for generating the pseudo labels. In the first step, the queries of which top-ranked documents are highly coherent are selected as the training queries. By coherent we mean that the top-ranked and bottom-ranked retrieval results are well clustered into two different classes. We expect that these selected queries are able to perform better during the iterations of transductive learning, since their top-ranked documents are relatively likely to be true positive examples for learning a ranking model. Therefore, we create a training set by a small amount of labeled ex-amples, if any, and the top-ranked and bottom-ranked doc-uments extracted from these queries, which are the initial pseudo examples. The remaining documents are treated as the test set. Then, we re-rank the examples in the test set and add the most confident examples by measuring the sim-ilarity between the candidates and the existing training data to the labeled data for further training. Such a process pro-ceeds until the halting criterion is met. Through the above described transductive learning process, documents similar to the positive and negative examples, which are consid-ered highly or lowly related to the query topic, are added to the labeled data set. Finally, both the pairwise and list-wise learning to rank (LTR) algorithms, RankSVM [15, 6] and SV M map [30], are applied to learn the ranking model using the pseudo training examples created by the proposed transductive learning process, respectively. The application of the clustering-based transductive learning does not nec-essarily involve any human labels or the use of relevance assessments information. It is therefore suitable for applica-tions in enviroments where there is only little or no training data available, or there exists the cold start problem.
The major contributions of the paper are two-fold. First, we propose a clustering-based transduction method to select the high-quality training queries for generating the pseudo labeled examples. Second, the application of the clustering-based transductive learning approach provides a solution for simulating the training data without involving human labels to obtain an effective retrieval performance. Exten-sive experiments on the standard TREC Tweets11 collection demonstrate the effectiveness of our proposed clustering-based transductive learning approach. We may use LETOR 3 and 4 datasets for our experiments. However, the LETOR datasets have only a small number of labeled documents for each query. As our study concerns finding negative examples from a large set of candidate documents by transduction, we rather use Tweets11 for this study.
Learning to rank, a family of algorithms that automati-cally construct a model or function to rank objects, is widely adopted in information retrieval [18]. The major advantage of learning to rank is its flexibility in incorporating different features into the process of retrieval. Previous investiga-tions have demonstrated that learning to rank can lead to better retrieval effectiveness than the classical IR models if the learned ranking model is properly trained [11, 15, 6, 4]. On the other hand, the retrieval effectiveness of learning to rank may be affected when there is no large amount of la-beled data. Indeed, as shown by the experimental results of participants in the Microblog track of TREC 2011, the use of LTR approaches does not show clear advantage over classical retrieval models [22]. In order to talckle this prob-lem, there have been studies that attempt to apply semi-supervised approaches to learn models with limited training data and a large amount of unlabeled data available. The basic idea of semi-supervised learning is to assign relevance labels to the unlabeled data by using certain strategies and thus to increase the amount of the training data [28]. There have been studies of applying semi-supervised learning for classification [7, 2, 24, 3, 14, 13] and ranking [27, 5, 9, 26]. Besides, the semi-supervised learning algorithm is used in Twitter search, where a query-biased model is learned by applying the transductive learning [31].

Most of the previous semi-supervised approaches for IR mentioned above attempt to utilize the unlabeled data by gradually adding pseudo examples to the training set. Hence, it is natural that the quality of the pseudo examples has an important impact on the retrieval effectiveness. The query-document pairs associated to a query of poor quality can hurt the effectiveness of the transductive learning if they are included in the training set. To address this problem, a clustering-based transductive learning by adding control on the quality of the training queries is put forward, as intro-duced in the next section.
In this section, a clustering-based transductive learning algorithm, denoted by CTL, is devised to facilitate learning to rank by generating a set of training data from limited or no human labels. Particularly, we first introduce to apply a two-step clustering algorithm, which serves to select the high-quality queries, as well as the initial pseudo positive and negative training examples. Then a transductive algo-rithm iteratively generates the pseudo examples from the remaining unlabeled data to construct the pseudo training set for the learning to rank algorithms.

In IR, the pseudo labels of poor quality can be created by neglecting the queries with sparsely distributed relevant doc-uments, when the common method of transductive learning is adopted. Therefore, it is advisable to create the pseudo labeled examples with good quality training queries during the iterations of transductive learning. In this paper, a two-step k-means [19] clustering algorithm is introduced to se-lect the queries statisfying the high coherence among the top-ranked documents of the initial retrieval results. The intuition behind our proposed method is as follows. First, the transduction-based learning to rank would favor training queries for which most top-ranked documents are relevant such that a high true positive rate of the pseudo examples can be expected. Second, if the documents are represented by vectors of predifined features, the relevant documents are likely to be close to each other, and belong to a clus-ter in which the relevant ones are the majority. If both the top-ranked and bottom-ranked documents of these selected queries with coherent top-ranked documents, are chosen as training examples, they will be more benefical than those unselected.

Figure 1 presents the algorithm of selecting high-quality training queries to create the initial pseudo examples by uti-lizing the two-step clustering algorithm.

By applying the two-step clustering method, queries with high similarity among the initial retrieval results are se-lected. Figure 2 shows the clustering results of query MB001 and MB049 in Microblog Track 2011, in which the N top-ranked initial retrieval results of each query are clustered by the two-step clustering method. In the figure,  X  X luster0 X  is the cluster with most top-ranked documents and  X  X lus-ter1 X  X s the cluster with most bottom-ranked documents. We can see that the top-ranked and bottom-ranked documents of MB001 are well seperated where 63.04% of documents in  X  X luster0 X  are top 30 ranked and 92.86% of documents in  X  X luster1 X  are bottom-ranked. In contrast, each cluster in MB049 is a mixture with balanced distribution of the top-ranked and bottom-ranked documents. The top-ranked documents in  X  X luster0 X  only own the proportion of 59.09% and the bottom-ranked documents in X  X luster1 X  X wn 52.63%. Therefore, MB001 is more likely to be chosen as the train-ing query than MB049. With these high-quality queries, the second step of clustering is to select the initial training ex-amples for the transductive learning to aggregate the pseudo examples through an iterative process. Noise may still exist, even if top-ranked and bottom-ranked documents are ex-tracted from these high-quality queries. Therefore, a second step clustering is utilized to further distinguish the relevant and irrelevant documents. Similar to the idea of voting in boosting algorithm, we extract the positive pseudo exam-ples from the cluster in which posN top-ranked documents and the negative pseudo examples from the cluster in which negN bottom-ranked documents. In the two-step clustering algorithm described in Figure 2, the parameters posN and negN are arbitrarily set to 3 and 5, which is regarded as a safe setting of semi-supervised learning approaches for IR [13]. N in Figure 2 is set to 60 as reported in [1] that most relevant documents are ranked before 60  X  70.
We present a detailed description of our transductive learn-ing algorithm. The basic idea of our proposed approach is similar to that of pseudo relevance feedback [23], which hypothesis that the top-ranked documents in the initial re-trieval list obtained by applying conventional IR model is likely to be highly relevant to the given query. In contrast, the bottom-ranked documents are less informative about the current topic. Using transduction, it is not necessary to train a general model to predict the label of any unobserved point during the process of learning. Before training, it is only re-quired to predict the pseudo labels of the given test set ex-amples [10]. Besides, We introduce a consistency metric on the basis of cosine similarity to assure the likelihood among Figure 3: The proposed transductive learning algo-rithm. the pseudo examples generated through the iterations of our transductive algorithm, as follows. where tr ( q ) represents the positive examples that exist in the original training data ; d represents the most confident can-didate document that is selected from the unlabeled data; avg q represents the average similarity of the relevant docu-ments of the examples in tr ( q ). During each iteration, two candidates of the pseudo examples that are likely to be re-lated to the given query are selected to compute their simi-larity with the original exsisting positive examples and one of them with higher similar score will be removed from the unlabeled data and added to the labeled data.
 A general description of the proposed method is given in Figure 3. The method is on the basis of the initial retrieval results returned by utilizing the conventional IR model. In case of the unavailability of labeled data, the pseudo labeled examples generated by the two-step clustering algorithm are selected as the initial positive and negative examples.
In addition, the following restrictions should be followed during the iterations of our proposed transductive learning. 1. Only the N top-ranked documents in the initial retrieval list of each query is eligible to be added to the labeled data, including the positive and negative examples. 2. K1 is arbitrarily fixed to 1 and K2 is fixed to 2 to reduce the cost in the parameter tuning.

The proposed approach can be applied given limited or no human labels available. It is therefore inexpensive to deploy the proposed approach in pratice as it involves only minimal human efforts.
Among the most popular approaches [18, 11, 15, 6, 4], the pairwise Ranking SVM (RankSVM) and the listwise SV M map are chosen used as the learning to rank algorithms in this paper.The instances composed by the exploited fea-tures with the relevance lables are combining to train a rank-ing model. The relevance labels indicate the relevant degree to the given query. Different from the research [31], we ig-nore the factor of recency for the lableing strategy. In the transductive learning process, after the positive examples are appended to the labeled set, we assign the integer 1 as the relevance labels, and 0 as the relevance labels for the newly added negative examples.
We experiment on the Tweets11 collection, which is used for evaluating the participating real-time Twitter search sys-tems over 50 official topics in the TREC 2011 Microblog track and the Real-time Adhoc Twitter search systems over 60 official topics in the TREC 2012 Microblog track. Our crawl of the Tweets11 collection consists of 13,401,964 suc-cessfully downloaded unique tweets which is used for TREC 2011. Note that because of the dynamic nature of Twitter, namely the tweets may be deleted or protected, we filter the original corpus according to the file id-status.01-May-2012.gz issued by the Microblog track 2012 organizers, and use it as the corpus of TREC 2012 Microblog track.
Standard stopword removal and Porter X  X  stemmer are ap-plied during indexing and retrieval. All of the indexing and retrieval experiments are conducted using an in-house exten-sion of the open source Terrier3.0 [21]. The official measures in the TREC Microblog Track, namely precision at 30 (P30) and MAP (mean average precision), are used as the evalua-tion metrics in our experiments.
 For RankSVM and SV M map , we use implementations by Thorsten Joachims 1 and Yisong Yue 2 respectively.
It is significantly important to exploit the features to rep-resent each document of the initial retrieval results in learn-ing to rank. Our features are organized around the basic entities for each query-tweet tuple to distinguish between the relevant and irrelevant messages.Six types of features exploited in this paper, most of which have been used in previous research on Twitter Search [16, 8, 20, 31].
The aim of our experiments is to evaluate the effective-ness of the proposed clustering-based transductive learning approach. The pseudo examples generated iteratively by the proposed transductive learning is used to facilitate to learn a ranking model to produce the final ranked list for the given test queries. In particular, two learning to rank approaches, namely RankSVM and SV M map , are applied, respectively. Our proposed clustering-based transductive learning approach CTL is compared to the previous trans-ductive learning approach ( TL ) which extracts the pseudo training examples from all the queries available, as proposed in [33]. This baseline has the best effectiveness among cur-rent transduction-based learning to rank methods on the Tweets11 collection to the extent of our knowledge. We ex-amine the effectiveness of our proposed approach (CTL) by introducing a two-step clustering algorithm into the tradi-tional transduction.

We have also conducted experiments comparing TL with our transductive learning algorithm proposed in Section 3.2 using all queries available for training. Results indicate only marginal difference ( &lt; 2%) between their effectiveness de-spite the fact our algorithm in Section 3.2 leads to a rela-tively more consistent pseudo label set because of the consis-tency metric introduced. We therefore omit the comparison between the two settings. Besides, an examination on the effectiveness of our proposed approach when limited labeled examples are available is conducted. You may contact us for the full version of the comparison results. 3-fold cross-validation experiments are conducted using our proposed transductive learning approach CTL .When no labeled data is available, we create a training data set with pseudo examples by applying the devised algorithm, denoted by CTL No ,where No stands for no relevance as-sessment information used during the iteration process of transductive learning. There are four types of queries in our experiments, namely the training, validation, target and test queries. Both positive and negative examples are extracted from the training queries as the initial pseudo training data to learn a ranking model. The queries in the validation set are used to examine the effectiveness of the ranking model learned from the pseudo examples, generated from the training queries, thus the optimal number of iterations along with the parameters of the learning to rank algorithms are obtained, which will be used for the target queries to it-eratively generate the final pseudo examples. Finally, the ranking model learned from the pseudo training examples which are generated from the target queries is used to pro-duce the final list for each query in the test set. In Table 1, we give a description of the roles of the four types of queries. We arbitrarily divide the selected high-quality queries into 3 average partitions, among which, one fold is used as the training queries, one fold is used as the target queries and the others are used as a part of the validation set. At the same time, the unselected queries are also randomly split into 3 folds, and one of the 3 folds will be chosen as the re-maining part of the validation set. Thus, all the queries are divided into 3 partitions, one is chosen as the test queries in each fold. Note that there is no intersaction between the training, validation and testing sets, yet overlap between the target and test queries. Although the validation set uses hu-man labels for setting the hyper-parameters of the learning algorithms, it is a separate query set that does not overlap with the training and test sets. The training of the ranking model, and the online application for given new queries do not necessarily require human labels. Such an experimental setupisacommonpracticeinresearchonsemi-supevised learning to rank approaches, e.g. in [33, 24].
The regularization parameter C of RankSVM has an im-portant effect on its performance. In our experiments, C is set by scanning 0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 1, 3 and 4 on the validation query set. Same method is adopted for optimizing the parameter C in SV M map which controls the trade-off between regularization and training loss.
Firstly,ourproposedapproach(CTL)clusteringonthe 60 top-ranked documents obtained by applying the content-based KLIM model [1] is compared to the transductive learn-ing method (TL) which generates the pseudo examples from all the queries when no human labeled examples are avail-able. The reason for clustering on the 60 top-ranked doc-uments is due to the observation that most of the relevant documents are ranked before 70, as reported in [1]. In the following tables and figures,  X  X REC 2011 X  indicates the ex-periments are conducted for the official queries numbered from 1 to 50, which are issued by the 2011 Microblog track;  X  X REC 2012 X  indicates the experiments on the 2012 Mi-croblog track queries, numbered from 51 to 110;  X  X REC 2011 &amp; TREC 2012 X  indicates the experiments on all 110 official queries. Note that a  X  in all the following tables in-dicates a significant difference with the baseline according to the two-sided paired randomization test [25] at the 0.05 level. For example, CTL No leads to a statistically signifi-cant difference over TL No on TREC 2012 when measured by P30, as shown in the 8th row of Table 2. As shown in Ta-ble 2, we can see that the effectiveness of CTL outperforms TL when RankSVM is adopted as the learning to rank al-gorithm, especially on TREC 2012 where an up to 11.69% improvement in MAP and 9.60% in P30 over the baseline is observed. The exceptions are on TREC 2011 where the dif-ference in the retrieval effectiveness with the baseline is not statistically significant and rather minor (-0.33% in P30 and -1.88% in MAP). While applying SV M map , the effectiveness of CTL shows advantages on TREC 2012 with a significant improvement of 10.76% in MAP and 6.08% in P30. We suggest that this is because the queries of TREC 2011 are overall easier than TREC 2012, as they have higher P30 and MAP. Consequently, the top-ranked initial retrieval results on TREC 2011 convey more informative messages than those on TREC 2012, which leads to coherent top-ranked results for TREC 2011.

Besides, we investigate the impact of the number of it-erations (IN) on the retrieval effectiveness. The x-axis in the Figures 4 represents IN and CTL ITR indicates the re-trieval effectiveness on the test queries of CTL by making using of the pseudo examples created in each iteration of the proposed transductive learning. Other parameters are set to the optimized values obtained on the training and validation Table 2: Comparison of the proposed approach (CTL No) with TL No without labeled data avail-able.
 queries. This figures plot the precision at 30 our proposed method by using RankSVM with IN increases during the training process of transductive learning, when no labeled examples are used. It is evident that the retrieval effective-ness vary in a small range and the retrieval effectiveness of our proposed method is comparable with the best effective-ness with the optimal setting of the iterative count.
We have proposed an improved transduction-based learn-ing to rank approach for learning a ranking model with no training data available. In particular, a two-step clus-tering algorithm is proposed to reduce noise in the pseudo training data generated by the transductive learning. The first step selects queries with high coherence among their top-ranked documents, and the second step selects the ini-tial pseudo training examples based on the distribution of top/bottom-ranked documents in the clusters. Moreover, two popular learning to rank algorithms, namely RankSVM and SV M map are used to examine the retrieval effectiveness. Extensive experiments have been conducted on the TREC Tweets11 dataset to evaluate the effectiveness of our pro-posed approach. Results show that our proposed clustering-based transductive learning approach is able to achieve sta-tistically significant improvement over the baselines. In ad-dition, our study in this paper suggests the possibility of simulating a training data without involving human labels on given new queries, while achieving an effective retrieval performance by adding controls on the selection of training queries and the pseudo labels.

In the future, we plan to examine the effect of alternate clustering algorithms such as K-nearest neighbour on the retrieval performance of our proposed approach. We also plan to evaluate the effectiveness of our proposed approach on other test collections such as LETOR, for which it would be a challenge to carry out transductive learning over a rel-atively small number of relevant documents. The experi-mental results in this paper also indicate a robustness issue when the transductive learning is applied on top of the list-wise SV M map , which has lower tolerance to the noise in the pseudo labels than the pairwise RankSVM. We plan to address this issue by adding a quality control of the pseudo labels, for example, by approximating the loss in the evalu-ation measure, e.g. MAP and nDCG.
 This work is supported in part by the National Natural Sci-ence Foundati on of China (61103131/F020511), the Presi-dent Fund of GUCAS (Y15101FY00/Y25102HN00), and the National Key Technology R&amp;D Program of China (2012BAH23B03).
