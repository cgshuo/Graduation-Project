 Social graphs have received renewed interest as a research topic with the advent of social networking websites. These online networks provide a rich source of data to study user relationships and interaction patterns on a large scale. In this paper, we propose a generative Bayesian model for ex-tracting latent communities from a social graph. We assume that community memberships depend on topics of interest between users and the link relationships between them in the social graph topology. In addition, we make use of the nature of interaction to gauge user interests. Our model al-lows communities to be related to multiple topics and each user in the graph can be a member of multiple communities. This gives an insight into user interests and topical distribu-tion in communities. We show the effectiveness of our model using a real world data set and also compare our model with existing community discovery methods.
 H.2.8 [ Information Systems ]: Database ApplicationsData mining; G.3 [ Probability and Statistics ]: Probabilistic algorithms Algorithms Community Detection, Social Networks, Probabilistic meth-ods With the rise of online social networking websites, Social Network Analysis has gained renewed interest. A Social Network is a graph that develops with interaction between users who may be friends, acquaintances, colleagues, etc. in the real world and/or those who share similar interests, likes or dislikes.

These online social graphs provide a rich source of data for studying community and user relationships. A network feature that has been emphasized in recent works is com-munity structure i.e. the gathering of vertices into groups such that there is higher relatedness among vertices within a group. The discovery of communities in a social graph con-sisting of  X  X imilar X  users is an important problem and finds applications in many areas as diverse as sociology, biology and computer science where systems are often represented as graphs.

In this paper, we propose a generative Bayesian model for extracting latent communities from a social graph. It as-sumes that community memberships are dependent on the topics of interest amongst users and their link relationships in the social graph. Users can belong to multiple commu-nities and a community can be related to multiple topics. Further, a user may be interested in multiple topics based on his interest. This is useful in modelling user interests or roles they play in the network.

Finally, we observe that the  X  X ype X  of interactions between users can be used to emphasize their interest in topics, and thus community membership. For example, two users en-gaging in conversations related to politics (posting  X  X eplies X  to each other) would be more likely to be members of a community on politics than someone who has occasionally  X  X roadcasted X  posts on politics (for example, during the elec-tions in a country). Hence, we also model communication types. To the best of our knowledge we are the first to use all the three q: topics, social graph topology and nature of user interactions in the discovery of latent communities from a social graph.

The paper is structured as follows: In Section 2, we review some prior work on latent community discovery. In section 3, we describe the TURCM model and present Gibbs sam-pling equations to infer its parameters. In section 4, we give experiments to validate the model. Section 5 concludes.
Traditionally, community detection has dealt with a hard-partitioning of nodes in the graph and do not allow nodes (users) to have membership in multiple communities. Also, they do not account for inter-user interactions outside the graph link. Recently, with the popularity of LDA, there has been significant interest in Bayesian probabilistic models for community discovery like Simple Social Network LDA (SSN-LDA) [8], Generic Weighted network LDA (GWN-LDA) [7], Hybrid Community Discovery Framework (HCDF) [2] and Hierarchical Social Network-Pachinko Allocation Model (HSN-PAM) [6]. Although they allow for mixed community mem-berships, they too rely primarily on the link structure in a social graph to learn communities.

Some community discovery methods have tried to utilize the semantic content of social graphs. In [9] the authors pro-pose the CUT (Community-User-Topic) model which uses the semantic content to discover communities in an email social graph. Communities are modelled as random mix-tures over users who are in turn modelled by their interests (represented by the topical distribution concerning them). The model, however, does not utilize the link information in a graph while discovering communities. While models like CUT are suitable when community members communicate actively with each other, models like SSN-LDA assume that users that are inter-connected share similar interests. How-ever, this is not always true in real world scenarios. For example, in social networks there are many users who are members of communities but do not actively contribute in them. Thus, both the graph structure and the interactions between users should be used to model the formation of communities.

Recently, researchers have started looking for one inte-grated probabilistic model that combines both content and link information available in social networks. The Community-Author-Recipient-Topic (CART) model [5], was one of the first attempts to combine previous link based community discovery methods with content based community discov-ery. Though, both the CART model and our models use topics and social graph topology to model communities, the generative process in both is significantly different. While our models assume that communities are generated based on users, recipients, topics and links connecting them, the CART model generates authors(users) and recipients of a post from latent communities.

Since CART, there have been few more attempts to com-bine content and link to obtain community structures more effectively ([4] [1]). These models assume links as binary. Whereas, our model utilizes the nature of interactions be-tween users while modelling communities. This is synony-mous to using weights in a graph for community discovery.
Notation: Let U be the set of users in the social net-work under consideration. Let R i be the set of neighbors (recipients) of user (sender) u i  X  U . For a given user (sender) u i  X  U and its neighbor (recipient) u j  X  R i P ij be the set of posts (messages) sent by u i to u j . Over-all, let P i = S by user(sender) u i . Let N p be the number of words in a given post p , p  X  { S these sets (in boldface) be represented by their correspond-ing capitalized symbols. The sender u i , recipient u j , the set of words W p for each post p and the type of posts X p are observable variables, while the communities, c , and topics, z , are considered as latent variables. In this section we describe our generative model : Topic User Recipient Community Model (TURCM) for latent com-munity discovery in such networks. TURCM tries to dis-cover communities by integrating the content being discussed by users in the form of latent topics and the type of posts generated by them. User interests are modelled via topics of mutual interest to both the sender as well as the recipient. We use a mixture of unigrams approach in our work, essen-tially assuming that the entire post is on one topic. As we shall see later, this is a reasonable assumption and allows our model to scale much better. Consequently, we experi-enced a significant decrease in training time over CUT and CART. Scalability is a major issue in the application of such probabilistic approaches in Social Network Analysis.
We also use the  X  X ype X  of communication to improve com-munity discovery. The idea being that two users who share a series of posts (messages) with each other, are likely to be communicating on certain common topics, indicating similar interests and therefore, can be members of the same com-munity. The type of communication indicates the strength of association between two users and their interest in a topic. The type of interaction varies from one social graph to another. User uploads/downloads, comments, wall posts, shared photographs, tags, etc. can be considered as inter-actions in social networks. For example, in the traditional model of email, an initiated email, a reply, or a forwarded email could be types. We can also include email list sub-scriptions, bulk-emails, etc. also into types if we have the required information.

Motivated by SSN-LDA [8], we represent every user as a combination of his interaction space. Each user ( u i ) is char-acterized by a social interaction profile representing all its P i interactions (post types): SIP ( u i ) = { X 1 ...X P i social interaction profile of users is represented as random mixtures over latent community variables. Each community is in turn defined as a distribution over the interaction space. This idea is analogous to LDA, where the social interaction profile is a document, interactions are words in that docu-ment and communities are latent topics.
 The number of topics Z , and the number of communities C , to be discovered are specified apriori as model parame-ters. Let the size of the vocabulary from which the commu-nications between users are composed be V . The number of different type of communications is K . Let Dir X (  X  ) denote a X-dimensional symmetric Dirichlet with scalar parameter  X  and Mult ( . ) denote the discrete multinomial distribution. 1. For each of the topics, 1  X  z  X  Z , sample a V dimen-2. For each of the communities, 1  X  c  X  C sample a K 3. For the i th user u i , 1  X  u i  X  U :
Let W be the set of observable words in the corpus, X be the set of interaction types observed on the social graph among the U set of users (senders) and R recipients. Let Z and C be the latent topic and community assignments for every post. The generative process for the model is given below. The joint likelihood of users, recipients, posts, inter-action types, topic and community assignments given by the TURCM model is This can be factorized into: Next, we give a Gibbs Sampling based approach to infer TURCM X  X  parameters. We represent  X  W p as the set of words in a given post p , N p as the number of words in the post and N p w as the number of times a given word w occurs in p . Let C  X  p , X  X  p , Z  X  p and  X  W  X  p represent the community, post type, topic assignments and the set of words except post p . The Gibbs update equations are: P (  X  W p =  X w |  X  W  X  p , Z ) = a  X  A ) is generated from the combination of variables b 1 in the model, (1  X  b i  X  B i , 1  X  i  X  v ) excluding post p .
The topics P ( w | z ), community memberships P ( u | c ) and topic proportions for a community P ( z | c ) are estimated us-ing a Maximum Likelihood estimate. The P ( u | c ) compu-tation gives us the community as a distribution over users while P ( z | c ) gives us the topical interest in a community. In this section, we evaluate the TURCM model on the ENRON email corpus and compare it with CUT and CART models. For all our simulations, we set the number of com-munities C at 10 and topics Z at 20. These choices are later Number of 6 8 10 12 14 Communities
Table 2: Fuzzy modularity on the Enron dataset proved to be close to the optimal in Sections 4.1 and 4.2. We ran 1000 iterations in the burn-in period and took 250 samples (every fourth sample) in the next 1000 iterations. In Table 1, we list a few topics ( ~  X  z ) discovered by TURCM. We give top 5 words to visualize each topic. Here  X  X alpx X  is the California Power Corporation,  X  X ransco X  is a gas trans-portation company and  X  X ymex X  is the New York Mercantile Exchange. We see that TURCM is able to discover mean-ingful topics, thus validating the assumption that each post is often associated with a single topic.
Next, we evaluate the quality of communities discovered by the TUCM and TURCM models against the communities discovered by the CUT and the CART models.

Newman proposed modularity, a measure of goodness for community structure. Unlike most other works, it assumes that a good division of the network is not merely one in which the number of edges running between groups is small. Rather, it is one in which the number of edges between groups is smaller than expected. Since the output of all these probabilistic models(TURCM, CART and CUT) is a fuzzy community structure, in which each node has a certain probability of belonging to a certain community; we use a fuzzy version of modularity proposed in [3]. Table 2 com-pares the fuzzy modularity of the TURCM model with its peers(CUT and CART). The high modularity values sup-port our assumption that people who share common inter-ests and are inter-connected with each other in the social graph often form communities. Modularity is important as one is always interested in strong-knit communities where people know each other as well as share common interests for reasons such as networking and task assignment. Meth-ods that form communities purely on interest can end up with disparate people (who dont know each other and are disconnected in the graph) in one community. This is shown by much weaker numbers for the CUT model. The number of topics was set to 20 for these experiments.
Next, we explore the perplexity of our model. We choose two previous probabilistic models for community discovery (CUT and CART) and compare our models with them in terms of perplexity. Figure 1 gives perplexity comparison es-tablishing a significant improvements by the TURCM model. Figure 1: Perplexity comparison on the ENRON dataset Figure 2: Perplexity on the Enron dataset against the number of topics This is because the TURCM model generates topic based communities and accounts for link types which are impor-tant descriptors of the strength of relationship between users. The results also confirm to our intuition that the post top-ics should model the joint interest of the sender and the recipient. For these reasons, CUT doesn X  X  perform well.
Finally, in order to comment on the model parameters (number of topics and communities), we analyze how model perplexities behave as the model parameters are changed. Figure 2 plots the perplexities against the number of topics. The number of communities was set to 10 for this experi-ment. It can be roughly concluded that the peplexities at-tain their minimum at around 20-25 topics. Figure 3 plots the perplexities against the number of communities. The number of topics was set to 10 for this experiment. Again, it can be roughly concluded that the perplexities attain their minimum at around 10 communities. Similar insights could be obtained about the number of communities from Table 2 where the fuzzy modularities optimize around 10 communi-ties for both datasets. This analysis not only helps us in con-cluding that our model outperforms the two baselines (CUT and CART) independent of the model parameters (number of topics and number of communities) but also get an esti-mate on optimal model parameter settings.
 Figure 3: Perplexity on the Enron dataset against the number of communities
We posited that communities are formed by users who communicate on topics of mutual interest, are connected to each other in the social graph and share frequent commu-nication of certain types. Then, we argued that interaction types are important indicators of the strength of association between users and proposed a probabilistic scheme that in-corporates all these three features to discover communities more effectively. Finally, we showed superior community discovery results over our closest peers. [1] J. Chang and D. Blei. Relational topic models for [2] K. Henderson, T. Eliassi-Rad, S. Papadimitriou, and [3] J. Liu. Fuzzy modularity and fuzzy community [4] Y. Liu, A. Niculescu-Mizil, and W. Gryc. Topic-link [5] N. Pathak, C. DeLong, A. Banerjee, and K. Erickson. [6] H. Zhang. Hsn-pam: Finding hierarchical probabilistic [7] H. Zhang, C. L. Giles, H. C. Foley, and J. Yen. [8] H. Zhang, B. Qiu, C. L. Giles, H. C. Foley, and J. Yen. [9] D. Zhou, E. Manavoglu, J. Li, C. L. Giles, and H. Zha.
