 1. Introduction
In the context of city logistics, more and more municipalities envisage to keep big trucks out of their city centre by creating peripheral logistic platforms, also called satellite depots, from which smaller and environment-friendly vehicles are allowed to go downtown. For an external carrier operating from a remote main depot, this solution is also interesting since the goods can be dropped at these satellites instead of visiting a larger number of end-customers, thus saving time and money. Taniguchi and Thompson (2002) introduced such multi-level (or multi-echelon) distribution systems as a tool to reduce urban congestion, increase mobility and satisfy requirements of sustainable development.

In the most common case with two levels, their design can be modelled by the two-echelon location-routing problem (LRP-2E), a strategic and tactical problem combining vehicle routing and satellite location decisions. The LRP-2E involves two sets of vehicle trips: first-level trips serve from a main depot a set of satellite depots, which must be located, while second-level trips visit the customers from these satellites. This problem is NP-hard because it generalizes several problems known to be NP-hard:
The two-echelon facility location problem (FLP-2E), the two-echelon vehicle routing problem (VRP-2E), and the capacitated location-routing problem (CLRP).

More precisely, the LRP-2E can be defined on a complete, weighted and symmetric digraph G  X  X  V , A , C  X  . The node-set V is n final customers. Each arc ( i , j ) in the arc-set A has a travelling cost or length c ij . A capacity W s and an opening cost O associated with each satellite s A S . Each customer t A T has a demand d t . A fleet K of identical vehicles of capacity Q and fixed cost F , the primary or first-level vehicles, is based at the main depot to serve the satellites. A fleet L of smaller identical vehicles with capacity R and fixed cost G , the secondary or second-level vehicles, is shared by the open satellites to supply customers. The size of each fleet is a decision variable.

In this work, it is assumed that the main depot and the total capacity of satellites can satisfy the whole demand. A feasible solution consists of a subset of open depots, a set of primary trips and a set of secondary trips. The following constraints must hold:
Each customer must be served by one single secondary vehicle and each open satellite must be supplied by one single primary vehicle; the total amount delivered by a vehicle cannot exceed its capacity; each secondary trip must begin and end at the same open satellite; the total amount received by a satellite is completely delivered to customers (no storage). The objective function, to be minimized, is the total cost of the system, which includes the opening costs of selected satellites, the fixed costs of vehicles used, the costs of primary trips and the costs of secondary trips.
 with m  X  5, n  X  12, Q  X  18 and R  X  5. The solution on the right corresponds to a more general case in which direct deliveries to customers are allowed from the main depot. However, these deliveries must still be done by secondary vehicles, as the customers located downtown are unreachable by primary vehi-cles. This extension is easily handled by placing a fictitious satellite on the main depot, with a null opening cost and a capacity equal to the total demand.
 start iterated local search (MS-ILS) which can be enhanced by an optional path-relinking (PR) procedure. The paper is organized as follows. The next two sections present a review of literature and a mathematical model. The MS-ILS is described in Section 4 while the optional PR procedure is introduced in Section 5 . Section 6 , devoted to numerical experiments, is followed by concluding remarks. 2. Related works vehicle routing problems with two distribution echelons and/or multiple depots. The main question is how to connect the two levels and manage their interdependences.
 problem (VRP-2E), which can be viewed as a special case of LRP-2E in which all satellites are already opened and induce no cost.
Gonzalez-Feliu (2008) proposed a MIP formulation and a column generation approach for this problem. Optimal solutions can be obtained for small instances of 20 customers. Crainic et al. (2008) designed a lower bound computed by adding two lower bounds, one for each level. The same authors ( Crainic et al., 2008 ) elaborated a two-phase heuristic based on the clustering first, routing second principle. Later, they applied this method to a satellite location analysis ( Crainic et al., 2010 ).

In the truck and trailer routing problem (TTRP), each vehicle comprises a truck and a detachable trailer. Some customers can be served by complete vehicles. In areas with limited accessibility, the trailer must be detached temporarily, for instance on a parking located on a main road, to reach customers with the truck alone. This problem can be considered as a VRP-2E variant: complete vehicles and trucks without trailers correspond respec-tively to primary and secondary vehicles, while the set of possible parking locations correspond to satellite depots. However, con-trary to the VRP-2E, no capacity is associated with satellites. Efficient metaheuristics are available for the TTRP. Semet and
Taillard (1993) and later Scheuerer (2006) proposed tabu search algorithms. More recently, Villegas et al. (2011) introduced a
GRASP (greedy randomized adaptive search procedure) with evolutionary path relinking.

The VRP-2E can be also viewed as an extension of the multi-depot vehicle routing problem (MD-VRP), in which trips must be added to supply the depots from a main platform. Crevier et al. (2007) studied another extension of the MD-VRP, the vehicle routing problem with satellite facilities (VRPSF): each vehicle must still start and end its routeatthesamedepot,butitmayrefillatanydepot.

Introducing satellite depot location decisions in two-level distribution systems with truckload deliveries (each customer is served by a direct route) leads to the two-echelon capacitated facility location problem (CFLP-2E), considered for instance by Gendron and Semet (2009) and Tragantalerngsak et al. (2007) .
If the costs of arcs linking two satellites or a satellite and the main depot are null, the LRP-2E reduces to the location routing problem (LRP). This problem adds to the MD-VRP the selection of open depots among potential locations. It includes two main variants, with uncapacitated satellites or capacitated ones (CLRP). Direct delivery trips (2) (1) In the last decade, the more realistic CLRP has raised a growing interest, with the publication of efficient metaheuristics ( Duhamel et al., 2010 ; Prins and Prodhon, 2006 ; Prins et al., 2006 ; Wu et al., 2002 ), matheuristics ( Prins et al., 2007 ) and even exact methods ( Belenguer et al., 2011 ).
 The literature on multi-level lo cation-routing problems like the LRP-2E is still scarce. To our knowledge, the first work on the LRP-2E can be credited to Jacobsen and Madsen (1980) . In this early study, a satellite depot may be located at any customer and three fast constructive heuristics are descr ibed and tested on one real instance. The other references on the LRP-2E are much more recent. Gonzalez-Feliu (2010) proposed a mathematical formulation for the general case with n echelons. In Gonzalez-Feliu (2011) , the same author performed a meta-narrative analysis to survey the literature, propose a typology, and suggest research directions. Nguyen et al. (2010) implemented a GRASP metaheuristic, enhanced by a learning process, and generated two sets of benchmark problems containing 24 and 30 instances. In his PhD thesis, Sterle (2010) studied a more general version with several main depots called platforms . Like satellites, these platforms have a limited capacity and must be located. The thesis presents integer programming models, three types of instance sets, and a tabu search metaheuristic. The models with experiments with an IP solver can also be found in Boccia et al. (2011) while the tabu search was published in Boccia et al. (2010) .

This article extends and improves a preliminary multi-start iterated local search (MS-ILS) for the LRP-2E, presented in a conference paper ( Nguyen et al., 2010 ). A mathematical model and an optional path relinking procedure are added. Some critical details which were skipped due to the limited number of pages are now presented. The structure of the MS-ILS and its compo-nents have been optimized while the experiments for tuning the parameters have been completely redesigned. More statistical indicators are provided to evaluate performance. All these changes have lead to faster and more efficient metaheuristics, with several new best solutions. 3. Mathematical model
The LRP-2E can be formulated as a three-index mixed integer linear program inspired by a model given in Prins and Prodhon (2006) for the CLRP. To simplify the model, define A 1 and A subsets of valid arcs for primary and secondary routes, respec-tively. The following binary variables are used: x k ij  X  1 if primary customer t . The model also requires non-negative variables b the amount delivered to satellite s by primary vehicle k . min subject to:
X
X X
X X
X
X
X y  X 
X u st  X  1 , 8 t A T  X  8  X 
X d u st r W s z s , 8 s A S  X  9  X 
X
X
X
X
X b
X b r Q , 8 k A K  X  14  X  b r Q x
A f 0 ; 1 g , 8 X  i , j  X  A A 1 , k A K  X  16  X  y
A f 0 ; 1 g , 8 X  i , j  X  A A 2 , l A L  X  17  X  z f 0 ; 1 g , 8 s A S  X  18  X  u f 0 ; 1 g , 8 s A S , t A T  X  19  X  b
Z 0 , 8 s A S , k A K  X  20  X 
The objective function (1) includes the opening costs of selected satellites, the fixed costs of primary and secondary vehicles, and the traversal costs of the arcs in the two distribution levels. All variables are defined in lines (16) X (20).

Constraints (2) X (9) concern the second level. Constraints (2) ensure that each customer is visited. The secondary route con-tinuity constraints (3) also guarantee that a vehicle returns to its satellite of origin. In constraints (4), each secondary vehicle leaves at most one satellite. The capacity of secondary vehicles is satisfied with constraints (5). Inequalities (6) are subtour elim-ination constraints. Constraints (7) ensure that satellite s serves customer t ( u st  X  1) if there exists one vehicle l leaving s and arriving at t .As u st can be equal to 1 even if no vehicle travels from s to t , constraints (8) are added to assign each customer to a single satellite. Inequalities (9) play two roles: If satellite s is closed, no customer is assigned to it, otherwise the total demand served cannot exceed satellite capacity.

The other constraints (10) X (15) address the first level. In constraints (10), each open satellite must be visited by one primary vehicle. Constraints (11) ensure trip continuity for each primary vehicle used. Constraints (12) prevent subtours. Flow conservation at each satellite s is expressed via constraints (13): the total amount brought to s by primary vehicles must be equal to the total demand of customers assigned to this satellite (no storage). The capacity of primary vehicles is respected using constraints (14). Finally, in constraints (15), if vehicle k does not visit satellite s , the amount brought by k to s must be zero.
The mathematical program aims at specifying the problem in a compact and unambiguous way. As the LRP-2E is a NP-hard problem combining location and routing decisions, only very small instances can be solved exactly by commercial solvers, thus justifying the use of heuristic algorithms for large instances. As we shall see, the multi-start iterated local search with path relinking proposed in the sequel can tackle LRP-2E instances having up to 200 customers and 10 potential satellite locations. 4. Multi-start iterated local search for the LRP-2E 4.1. Iterated local search sequence of improved local optima for a combinatorial optimiza-tion problem, see for instance Lourenc -o et al. (2003) for a tutorial.
It requires only three components: one constructive heuristic H , one improvement procedure (local search) LS , and one random perturbation procedure Mutate , similar to the mutation operator used in genetic algorithms.
 initial solution S is computed using the heuristic and improved by local search. Then, each iteration applies mutation and local search to a copy of S . If the resulting solution S 0 (called child in the sequel) outperforms the incumbent solution S , it replaces it.
This process is repeated until a given stopping criterion is satisfied.
 search, the incumbent solution S is also the best one found since the beginning. On hard instances, many successive children can be rejected while staying on the same incumbent solution. ILS is sometimes considered as an evolutionary method, but no cross-over is used and the population is reduced to one single individual.

Algorithm 1. General structure of an ILS. in Fig. 2 . The initial local optimum is S 0 (cost 120). The first perturbation P 1 gives a solution in the attraction basin B the local search returns to S 0 . The second perturbation P another basin B 1 but its local optimum (cost 125) is not better. The third perturbation P 3 leads to a solution of cost 118 in basin
B 2 , with a descent to a better solution (113) which becomes the new incumbent solution S 1 . After one unfruitful perturbation P , the ILS jumps in B 3 and finds a new best local optimum S (cost 110). 4.2. Principles of our MS-ILS features.
 solution instead of loosing time in unproductive iterations, thus giving what we call a multi-start iterated local search (MS-ILS).
The second feature consists in using cyclically three greedy randomized heuristics, to provide each ILS execution with one good initial solution.

A third feature is that the child is accepted if its gap to the best known solution S n does not exceed a given percentage b .In other words, we prefer to move to a slightly degraded solution rather than staying on the same solution and waiting for an improving child, like in a classical ILS. Therefore, contrary to a classical ILS, the incumbent solution is no longer necessarily the best solution obtained up to now. Such loose acceptance criteria are foreseen in ILS: Lourenc -o et al. (2003) describe for instance a probabilistic acceptance, inspired by simulated annealing. In our case the threshold b is constant and the acceptance test is deterministic.

The fourth feature is the coexistence of two improvement procedures LS1 and LS2, in fact variable neighbourhood descents (VND). LS1 is applied to each child because it involves low-complexity neighbourhoods. As LS2 involves more complicated moves, it is called only for children with a given maximum gap of a percent to the best known solution S n .

The fifth feature is a kind of tabu list storing recently visited solutions. To avoid cycling, tabu search heuristics never move to a tabu solution, except when the current best solution is improved. In our MS-ILS, meeting again the same solution does not imply cycling, because the mutation applied at the second visit may generate a different child. However, this indicates that the search is not enough diversified and we penalize the ILS in progress by reducing its number of iterations by a constant a .
Then, whether a child is tabu or not, it undergoes the acceptance test described for the third feature. Hence, the only purpose of the tabu list is to shorten the current ILS when tabu solutions are met again, in order to restart more quickly from a new initial solution.

The sixth and last feature is an alternation between two search spaces, an idea which gave excellent results for the CVRP (capacitated vehicle routing problem) ( Prins, 2004, 2009 )and the CLRP ( Duhamel et al., 2010 ). The two spaces are here the
LRP-2E solutions and the travelling salesman (TSP) tours over the main depot and the customers. These tours, also called giant tours , ignore satellites and vehicle capacities. One giant tour T can be converted into one LRP-2E solution S using a splitting procedure Split( T , S ), while the inverse transformation can be done by concatenating the second-level trips of S ,using a procedure Concat( S , T ).
B The resulting metaheuristic is sketched by the flowchart of Fig. 3 . The components are detailed in the next subsections and a more precise algorithm in pseudocode is given after the components.

The first block initializes the number of starts ns to 0, the cost of the best solution S n to  X 1 , and empties the tabu list. It is followed by a main loop (the multi-start loop ) which performs maxns successive ILS on distinct initial solutions.

Each iteration of the multi-start loop increments the start counter ns and runs cyclically one of the three greedy randomized heuristics to get one solution S , improved by a local search LS2. If S is tabu, the current iteration is stopped, otherwise an ILS is launched from S ( ILS loop ).

The ILS is initialized by adding the initial solution S to the tabu list, setting the ILS iteration counter ni to 0, and building the giant tour T associated with S using the Concat procedure. Then the ILS loop is executed until the maximum number of iterations maxni is reached.

At each ILS iteration, the iteration counter ni is incremented, a new giant tour T 0 is derived from T by calling a mutation procedure (Mutate), and this tour is converted into a new LRP-2E solution S via Split. S is then improved by a local search LS1 and, if the result is close enough to S n , by a more involved local search LS2. If S outperforms S n , the best known solution is updated. If S is not in the tabu list, it is added to this list; otherwise, the current ILS is penalized by increasing its iteration counter ni by a constant a . Finally, if the solution gap of S to S n is at most b percent, S is converted by Concat into a new giant tour which replaces T for the next ILS iteration. Otherwise, ni is increased by a small constant b  X  b o a  X  . 4.3. Initial solutions
For a better diversification, the maxns initial solutions are computed by calling cyclically three greedy randomized heuris-tics described in the following. Each initial solution S is improved using the improvement procedure LS2 described in Section 4.7 . S is discarded if it is tabu, otherwise it is added to the tabu list and one ILS is executed. 4.3.1. Heuristic H1 To build the second-level trips, we randomize the extended Clarke and Wright algorithm (ECWA), described in Prins and
Prodhon (2006) for the CLRP. In ECWA, customers are assigned one by one, in decreasing order of demand, to the nearest satellite with enough residual capacity and served by a direct trip. Pairs of trips are then merged to reduce the solution cost.

If two second-level trips T and T 0 are merged (concatenated), the resulting trip may be assigned to the satellite s of T , to the satellite s 0 of T 0 , or to any other satellite s 00 , open or not. The resulting saving takes into account the edges added or removed and the satellites opened or closed by the merger: s (or s 0 ) can be first trip. The merger with the largest positive saving is executed.
This process is repeated until no merger with a positive saving is found.

In our randomized version, the g closest satellites are deter-mined for each customer in the initial assignment phase, and one is randomly selected. Once the second-level trips are ready, the classical Clarke and Wright (1964) heuristic is applied to the first level: one direct trip is built between the main depot and each satellite, then pairs of trips are merged to improve the total cost. 4.3.2. Heuristic H2
This heuristic is inspired by the nearest neighbour heuristic for the TSP. One satellite s is opened at random and a set of routes is constructed for it. Each route starts at s and is iteratively extended by joining the closest customer not yet visited and fitting the residual capacity of the second-level vehicle used. The route returns to the satellite when no additional customer can be added. Successive routes are built in this way, until satellite capacity is exhausted, in which case a new satellite is randomly opened. The algorithm stops when all customers are inserted in second-level routes. The same process is finally applied to the first level, to build a set of routes supplying the open satellites from the main depot. 4.3.3. Heuristic H3
H3 is an insertion heuristic that constructs second-level routes one by one. Each route starts with a loop on one randomly selected satellite and is grown using an adaptation of the CVRP heuristic of Mole and Jameson (1976) . When no customer can be added, the initial satellite is removed and the best possible satellite is inserted. Finally, the first-level routes are determined by a nearest neighbour heuristic, like in H2. 4.4. ILS loop
As already mentioned, a key-feature of our MS-ILS is to alternate between the space of giant tours and the space of feasible LRP-2E solutions in each ILS iteration. These transforma-tions are visible in Fig. 3 : Giant tour T -Mutate  X  T , T 0  X  tions explain the procedures involved in this cycle.
 solutions showed that the search space alternation brings a significant improvement to solution costs ( 4% on average). In our opinion, there are two main reasons for that. Firstly, the perturbations are too easily repaired by LS1 and LS2 in an algorithm working only with LRP-2E solutions. Secondly, a LRP-2E solution is often improved if its trips are concatenated to yield a giant tour, if this tour is perturbed and the result converted into a LRP-2E solution via Split. In fact, one such cycle can change several satellites simultaneously or insert them at different positions in the giant tour, while LS1 and LS2 use more local transformations like customer relocations. 4.5. Mutate procedure copy T 0 of the input giant tour T . The mutation of giant tours instead of LRP-2E solutions avoids satellite and vehicle capacity violations. Mutate considers three kinds of moves. The first move randomly selects p pairs of distinct customers and swaps them.
The second move determines the four longest edges ( weak edges ) and deletes two at random. The substring between the two selected edges is removed and a cheapest insertion in the remaining sequence is performed. The last move adds the edge linking the first and last customers and then breaks the resulting cycle by randomly deleting one of the four weakest edges. Each call to Mutate randomly selects one of these move types. Fig. 4 illustrates the two last moves. 4.6. Split procedure ject to the sequence) to split a TSP tour into CVRP trips, but without numerical results. The use of this procedure to evaluate solutions encoded as giant tours in a genetic algorithm for the
CVRP was introduced by Prins (2004) and then successfully applied to various vehicle routing problems, e.g. Prins et al. (2006) , Prins (2009) , and Villegas et al. (2011) .
 auxiliary graph H  X  X  Y , A , Z  X  which models the different ways of splitting the giant tour T . The node-set Y contains a dummy node added to the arc-set A if subsequence  X  T i , T i  X  1 , ... , T to a feasible trip. The weight of this arc is the cost of the associated trip. Finally, an optimal CVRP solution (subject to the sequence) can be deduced by computing a min-cost path from node 0 to node n in H , which can be done in polynomial time.
A figure with an example of auxiliary graph can be found in Prins (2004) .

Similar splitting procedures can be found for many routing problems but hard resource-constrained shortest path problems are raised in some cases like capacitated depots ( Duhamel et al., 2010 ) or heterogeneous fixed fleets of vehicles ( Prins, 2009 ).
As the LRP-2E involves capacitated depots (satellites), we designed a splitting heuristic to keep acceptable running times.
So, contrary to Prins (2004) for instance, an optimal giant tour (one giving an optimal solution after splitting) does not necessa-rily exist. However, as many giant tours are built, we think the
MS-ILS has a good chance of reaching a global optimum: the only condition is to fall in the attraction basin of this optimum.
The first step is to consider a subset SS of possible satellites, relax their capacities, and use them to split T into second-level trips. Compared to the CVRP, this affects only the arc cost computations in the auxiliary graph H : For a given subsequence, we evaluate the trip cost for each satellite of SS and assign the best cost to the arc that models it in H . This first step can be solved exactly, subject to the order imposed by T ,in O  X  n 2 with 9 SS 9 r m , using Bellman X  X  algorithm.

The second step repairs possible satellite capacity violations by transferring second-level trips to other satellites. The last step consists in building primary routes to serve the open satellites, with the nearest neighbour heuristic already used for the initial greedy randomized heuristic H2. This results in a new LRP-2E solution S .

Hence, to be exact, the splitting procedure has three argu-( SS ) in the first step because our first experiments produced low-quality solutions when all satellites were allowed. For an ILS iteration with an incumbent solution S and the associated giant tour T , SS is equal to the subset of satellites used in S , plus one randomly selected satellite. 4.7. Improvement procedures LS1 and LS2
LS1 uses six moves applied to the services in the first and second levels: Relocate , Exchange ,2 -Opt ,3 -Opt , Or-Opt , and Rein-sert . The two first moves respectively relocate one service and exchange two distinct services. The two next respectively remove two and three edges and add new edges to reconnect the solution.
Normally, Or-Opt consists in relocating a string of 1 X 3 consecu-tive services, but our implementation moves at least two, the case with one customer being handled by Relocate. The Reinsert move deletes the main depot in a primary trip (or the satellite of a secondary trip) to reinsert it at another position in the same trip.
Reinsert and 3-Opt operate on a single trip, while all the other moves involve one trip or two distinct trips in the same level. The neighbourhood defined by each move is browsed and the best improving move (if any) is executed. All these moves affect the routing decisions only: The status open/closed of satellites is not modified, except in the obvious case where all customers served by a satellite are transferred to other satellites.

LS2 employs the same moves as LS1, plus two heavier moves described in Prodhon (2006) for the CLRP: Best trip relocation and
Satellite status inversion . The first move considers the routes which can be transferred with a positive saving to another open satellite and performs the best transfer. The second move switches the status open/closed of a satellite. If we decide to open a satellite, some routes can be assigned to it if this results in a cost reduction.
To close a satellite, we try to transfer its routes one by one to the remaining open satellites at best cost. Since this sequence of transfers is time-consuming and may fail, LS2 is called after LS1 only if its gap to the best-known solution is below a given percentage a , i.e. if cost  X  S  X  o  X  1  X  a  X  cost  X  S n  X  .
Instead of browsing a union of neighbourhoods, we adopted an implementation known as variable neighbourhood descent or VND ( Hansen and Mladenovic  X  , 2001 ), see Algorithm 2 . The VND inspects the neighbourhoods N k , k  X  1 ; 2 , ... , k max moves explained before ( k max  X  6 for LS1 and 8 for LS2). If a neighbourhood N k yields one improving move, this move is executed and k is reset to one, otherwise the search browses the next neighbourhood N k  X  1 . The VND stops when all neigh-bourhoods are browsed without improvement. This algorithm is fast because time-consuming moves are tested only when simpler moves bring no improvement.
 Algorithm 2. VND structure for LS1 and LS2 1 k  X  1; 2 while k r k max do 3 4 5 6 7 8 4.8. Concat
In our implementation, the routes of an LRP-2E solution are ordered as if they were followed by a Eulerian walk, i.e., the primary routes P 1 , P 2 , ... , P u are browsed successively and, when arriving at a satellite, the secondary routes departing from this satellite are inserted. The Concat procedure simply consists in concatenating the lists of customers of secondary trips, in this order. In the example of Fig. 1 , the resulting giant tour includes the secondary routes T 1 , T 2 , ... , T 5 in this order. 4.9. Tabu list
As usual, the tabu list stores solution attributes instead of complete solutions. For the LRP-2E, we use the total cost and the number of trips. The list is initialized only once at the beginning and behaves like a short-term memory limited to the maxnt most recently visited solutions. As already mentioned, this memory is not used like in tabu search heuristics. In fact, the ILS is allowed to move to a tabu solution because different children can be generated at the second visit, using different mutations. However, we prefer to restart earlier from a new random solution rather than loosing too much time in an already visited region of the search space. This preference is simply implemented by reducing the number of iterations allocated to the current ILS, each time a tabu solution is met. To have enough diversification in each restart, initial solutions are refused if they are tabu. 4.10. Resulting MS-ILS The resulting MS-ILS is given in pseudocode in Algorithm 3 . Compared with Fig. 3 , the cyclic call of greedy heuristics and the role of subset SS used by Split are made visible. By playing with parameters, it is possible to reduce MS-ILS to two classical metaheuristics. If maxni  X  0, it boils down to a GRASP: the greedy randomized heuristics generate trial solutions which are improved using the local search LS2. If maxns  X  1, we obtain an ILS launched from one single initial solution.

Algorithm 3. Pseudocode of MS-ILS. 1 cost  X  S n  X   X   X 1 ; 2 TabuList  X  | ; 3 for ns  X  1 to maxns do 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 5. Path relinking 5.1. Principles
Path relinking (PR) is an intensification strategy which can be added to any metaheuristic. The method was used for a first time by Glover and Laguna (1993) to improve solutions obtained by tabu search. Its principle is to gather a small pool of elite solutions and to explore trajectories linking two solutions of the pool in the solution space, to try finding a better one. The origin and destination of the path are often called the starting solution and the target solution . The attributes of the target solution are progressively introduced in the starting solution, which generates a sequence of intermediate solutions.

For the LRP-2E, we first tried to generate trajectories between two LRP-2E solutions or two giant tours, with disappointing results. In the first case, too many intermediate solutions are infeasible, due to vehicle or satellite capacity violations. In the second case, feasibility problems are avoided by applying Split to each intermediate tour, but the path relinking becomes too time-consuming. Finally, we took an intermediate option, with partially decoded solutions called big tours . A big tour is a sequence of customers in which satellites are inserted but primary trips are still missing. Big tours have already a transient existence in Split, after the two first steps (see Section 4.6 ).
 satellite at the beginning of each second-level trip but not at the end. Consider for instance a network with two satellites (nodes 1 and 2), six customers (nodes 3 X 8), and three second-level trips (1, 3, 4, 1), (2, 5, 6, 2) and (2, 8, 7, 2). The encoding for the giant tour is (1, 3, 4, 2, 5, 6, 2, 8, 7). As our PR process swaps pairs of nodes to move from the starting solution to the target solution, intermediate big tours may have two consecutive satellites s and s 2 , which is interpreted as a loop (empty trip) on satellite s .
 ated for two given big tours, how the pool of elite solutions is built, and the possible insertions of the path relinking into the
MS-ILS algorithm. 5.2. Path generation the frequency (number of occurrences) of a satellite s in X . The PR requires two big tours A , B . All customers are included in A and B but the two tours may use different satellites or share some satellites but with different frequencies. This is corrected in lines 1 X 6 which add copies of satellites at the end of the tours to ensure same length after this processing.
 equal to the number of differences between the nodes at the same position in A and B , i.e., D  X  A , B  X  X  P i  X  1 , 9 A 9  X  A length of A and A i a B i a Boolean equal to true if A i and B
Each iteration of the while loop line 8 generates one intermediate big tour U , to reduce progressively the distance to B .
Algorithm 4. Path relinking procedure PR ( A , B ). tions in U and B (line 9). If such a customer t is found, it is swapped with another node to repair the difference (lines 10 X 11). Otherwise (lines 12 X 13), no customer is misplaced but, since is a misplaced satellite (line 14). Note that satellite U after the statements 1 X 6. Lines 14 X 16 look for an adequate exchange. Consider for instance two satellites 1 and 2, customers). We have a misplaced satellite U i  X  U 3  X  1. A swap with U j  X  U 5  X  1 would repair one difference but create another one. The correct decision is to swap U 3 and U 7 .

The big tours obtained may violate satellite or secondary vehicle capacities. To limit running time, an infeasible big tour is repaired with probability d , using a procedure called Repair , see lines 18 X 19. In line 21, a feasible big tour is converted into an
LRP-2E solution S by adding primary trips, using the nearest neighbour heuristic already called in Split and the greedy heur-istic H2. S is improved using LS1 in line 22 and added to the pool in line 24 if it outperforms A and B . The best solution S n is updated in line 25.

Fig. 5 gives one example of path relinking for m  X  2 satellites lines 1 X 6 of Algorithm 4 add one copy of satellite 1 at the end of B .
After this step, the two big tours have the same lengths, the same satellites, and the same frequencies for each satellite. The initial
Hamming distance between them is 9. Using seven swaps, A is progressively transformed into B , which generates six intermedi-ate solutions. 5.3. Integration of PR in MS-ILS
The first step to add a path relinking process in a metaheuristic is to manage a small pool of elite solutions. In our case, we prefer to store the big tours corresponding to these elite solutions, in a pool limited to maxnp big tours. In Algorithm 3 , an empty pool must be initialized at the beginning. It is then updated at each ILS iteration, between lines 21 and 22.

The incumbent solution S is converted into a big tour A by a procedure similar to Concat already used in the MS-ILS, the only difference being that the open satellites of S are kept when concatenating the second-level trips. To favour a pool with elite but diverse solutions, A is added to the pool if Cost  X  S  X  o wise, the pool is not updated. If the pool is already full (maxnp big tours), S replaces the oldest solution.

Three possible ways of calling the PR were evaluated: as an intensification step during the metaheuristic (internal PR), as a post-optimization step, or both.

The internal path relinking is done each time a new big tour A is added to the pool by the threshold acceptance rule described above. Another big tour B is randomly selected in the pool and two paths in the solution space are generated by calling PR ( A , B ) and PR ( B , A ). The feasible LRP-2E solutions found along the paths are added to the pool if they surpass both A and B and the best solution S n is updated in case of improvement.

The post-optimization is performed once the MS-ILS is com-pleted and consists of two nested loops enumerating the pairs are called to trace two paths in solution space. The solutions generated are only used to update S n : contrary to the internal PR, they are not added to the pool, to avoid enumerating the pairs of a growing set of solutions. 6. Computational evaluation 6.1. Implementation and instances
The MS-ILS algorithm and the optional path relinking proce-dures are implemented in Visual C  X  X  6.0 and tested on four sets of Euclidean instances, using a Dell Optiplex GX745 PC with a Pentium 4 processor clocked at 3.4 GHz, 1 GB of memory and Windows XP Pro.

The first set ( Prodhon  X  s CLRP instances ) contains 30 CLRP instances designed by Prodhon (2006) . Indeed, the capacitated location-routing problem (CLRP) can be easily tackled by our algorithms: we add a main depot anywhere, primary vehicles without fixed costs, and one edge with null cost between two satellites or a satellite and the main depot. The main features of CLRP instances are: Number of satellites m A f 5 ; 10 g , number of customers n A f 20 ; 50 , 100 ; 200 g , secondary vehicle capacity R  X  1 means in fact a uniform distribution of customers. The instance name format is n -m -r -e , where e  X   X  X  a  X  X  if R  X  70 and  X  X  bis  X  X , indicating two strongly separated clusters.
To obtain the second set, composed of 30 LRP-2E instances, we added primary vehicles and one main depot at coordinates (0,0) to Prodhon X  X  CLRP instances. The capacity of primary vehicles is 1.5 times the maximum satellite capacity. These instances are called Prodhon  X  s LRP-2E instances in the sequel and they have the same names as the original CLRP instances.

The third set ( Nguyen  X  s LRP-2E instances ) comprises 24 LRP-2E instances built by Nguyen et al. (2010) . Their characteristics are: number of satellites m A f 5 ; 10 g , number of customers n ondary vehicle capacity R A f 100 ; 150 g . Customer locations follow either a normal or multi-normal distribution. The file names have the format n -m -N (normal distribution) or n -m -MN (multi-normal distribution). A suffix  X  X  b  X  X  signals the instances with Q  X  850.
The fourth set was designed by Sterle in his recent PhD thesis ( Sterle, 2010 ) and reused in the conference paper ( Boccia et al., 2010 ). These instances concern a version of the LRP-2E more general than ours, with several main depots called platforms. Each platform has a limited capacity and an opening cost, like the satellites. Sterle built three sets of instances called I1, I2 and I3 and corresponding to different spatial distributions of satellites. We have discarded in each set the small instances used in Sterle (2010) to test several mathematical formulations, to focus on what Sterle calls the medium-large instances. There are 10 such instances in each set I1 X  X 3. They all use five platforms but range from eight satellites and 50 customers to 20 satellites and 200 customers. The notation used to describe instances refers to the instance set and the number of platforms, satellites and custo-mers. For example, I1-51050 refers to an instance of set I1 with five platforms, 10 satellites and 50 customers.

The three first sets can be found on the Internet ( Prodhon, 2008 ) while the fourth set was kindly provided to us by Sterle. In all instances, deliveries from the main depot are forbidden.
However, as explained in the Introduction ( Fig. 1 ), our algorithms can tackle this extension by placing a fictitious satellite on the main depot, with a null opening cost and a capacity equal to the total demand. 6.2. Tuning of parameters for MS-ILS
Tuning the parameters of a heuristic to improve its results is a common problem in optimization. The goal is to achieve the best possible performance by testing a limited number of parameter combinations on a limited set of instances. A three-step process is applied here: (a) choose the test bed, (b) select most parameter values using a simple method, (c) apply a statistical test to separate the combinations of parameters which look linked by a complex relation. The three non-parametric tests used in the sequel (sign test, Friedman test, Bonferroni X  X unn test) are detailed in textbooks like Conover (1999) and Sheskin (2000) .
They can be computed using a statistical software like SPSS and even online, e.g., see http://www.fon.hum.uva.nl/Service/Statis tics.html .

For the test bed in Step (a), we took arbitrarily the 30 LRP-2E instances from Prodhon. Concerning Step (b), beginning from a promising configuration, the MS-ILS is executed on the test bed.
Then, one or two parameters are modified and the heuristic is run again. The two sets of results are compared using the sign test ( Conover, 1999 ), based on the binomial distribution. If the new configuration is better we accept it. If the two configurations are equivalent, we move to the new one if it displays a smaller running time. The procedure stops after testing a maximum of 20 configurations. The parameter values obtained via this technique are listed in Table 1 .

Step (c) must be executed for parameters maxnt , a and b because Step (b) found two promising values for each of them.
The Friedman test followed by the Bonferroni X  X unn test can be used to choose among the h  X  2 3  X  8 combinations. The first test decides whether the combinations are equivalent (null hypoth-esis) or not but it does not indicate which combination is the best.
If the null hypothesis is rejected, the second test helps determin-ing the best combination.

Let M 1 , M 2 , ... , M 8 be the eight combinations listed in the upper part of Table 2 and N  X  30 the number of instances. For each instance, the Friedman test ranks the h heuristics to be tested, giving 1 to the best one and h to the worst. Let r rank of heuristic M i on instance j . In case of ties, average ranks are assigned. For example, imagine that two heuristics M i and M the same solution value on instance j and that they occupy the ranks 3 and 4 in the list of costs sorted in non-decreasing order. Then, by convention, r ij  X  r kj  X  X  3  X  4  X  = 2  X  3 : 5. Since h  X  8 and N  X  30 are fairly large ( h 4 4 and N 4 15), the Friedman test may be approximated by the chi-square distribution: w 2 r  X  12 Nh  X  h  X  1  X  to reject the null hypothesis, knowing that it is true. The Friedman test ran using SPSS version 11 returns chi-square and a p-value , i.e., the smallest significance level that would lead to rejection of the null hypothesis. The test yields chi-square  X  15.24 and p -value 0.035 for the costs, and chi-square  X  25.16 and p -value 0.001 for the CPU times. So we may reject the null hypothesis at the level of significance Z  X  0 : 05.
 graphically displayed in Fig. 6 . They seem to indicate that M might be the best choice regarding solution quality. Even if this heuristic is the third best choice in terms of running time, it is almost as fast as M 4 and M 8 .
 roni X  X unn test, based on pairwise comparisons of mean ranks.
According to this test, the performances of two heuristics M
M j are significantly different if the absolute value of the difference of their mean ranks is not smaller than a critical difference CD ,in other words if 9 M i M j 9 Z CD . CD is defined as follows:
CD  X  q Z statistical tables like Sheskin (2000) . For h  X  8, we have q 0 : 05  X  2 : 69 and q 0 : 10  X  2 : 45, thus CD  X  1.7 for for Z  X  0 : 10. The values of E i 6 are given in the lower part of
Table 2 . In terms of cost, we can see that M 6 outperforms M both probability levels but brings no significant improvement compared with the other heuristics. Concerning running time, M these differences.

To conclude, we selected M 6 as the best compromise between cost and CPU time: in addition to the parameters already frozen in
Table 1 , a can be fixed to 0.2, b to 0.1 and maxnt to 8. 6.3. Contributions of components
Using the parameters selected previously, the contributions of components of our MS-ILS have been evaluated by running five times different versions on Nguyen X  X  LRP-2E instances. These experiments are summarized in Table 3 , with the average gap to best solutions and the average running time. The versions that do not use the two local search procedures LS1 and LS2 are the fastest but yield low-quality solutions. Removing the tabu list or the threshold acceptance has no significant impact on solution cost but increases the running time. For instance, the metaheur-istic becomes twice slower without its tabu list.
 6.4. Tuning of parameters for path relinking
Our numerical experiences showed that the internal path relinking seems to be more effective than the post-optimization version in terms of solution quality but not in running time. Moreover, a further improvement was obtained by employing the two versions. As the path-relinking runs faster than MS-ILS, we finally decided to use the two versions simultaneously.
Following the same process as for the MS-ILS parameters, a calibration phase was executed to determine appropriate values for the parameters maxnp and m , using the 30 instances from Prodhon and the combinations PR 1 to PR 4 listed in Table 4 . The mean ranks suggest that PR 3 is the best combination and this is confirmed by the Friedman and Bonferroni X  X unn tests (chi-square  X  11.9, p -value  X  0.008). As a result, the maximal value of the pool size was set to maxnp  X  15 and the diversification coefficient m to 0.2. 6.5. Results for LRP-2E instances with one main depot
This subsection reports our results on the instances with a single main depot (Nguyen and Prodhon), while the next one concerns Sterle X  X  instances with several depots. To the best of our knowledge, no metaheuristic has been published for our version of the LRP-2E. Hence, the MS-ILS and its version with path relinking (MS-ILS PR) are compared on the same computer with two simpler methods which we presented in conferences:
GRASP LP, a GRASP reinforced by a learning process ( Nguyen et al., 2010 ), and GRASP PR, a GRASP combined with path relinking ( Nguyen et al., 2010 ).

The results are listed in a common format in Table 5 (Nguyen X  X  instances) and Table 6 (Prodhon X  X  instances). The two first columns give the instance names and the best known solutions (BKS) found by the four algorithms. Then, for each algorithm, the tables provide the best cost obtained in five runs, the gap of this cost to the BKS in percent and the average duration of the five runs in seconds. The deviation of a method A to the BKS is computed as  X  cost  X  A  X  BKS  X  = BKS 100. Costs in boldface indicate which method gives the best value.

The last six rows display for each algorithm the average gap stability ( Avg stab ), the number of best solutions found ( BKS found ), the average rank ( Avg rank ), and the mean CPU time ( Avg CPU , in seconds). What we call stability of an algorithm for one instance is the standard deviation of the gaps to the BKS, achieved over the five runs. The third row of indicators ( Avg stab ) displays the average of these gaps.

There are two main reasons for choosing five runs. Firstly, the two GRASP algorithms used in the comparison were published for five runs too. Secondly, the average stabilities indicate that our methods are relatively robust: on average, the standard deviation of the gaps to the BKS over the 5 runs is around 0.3 X 0.4%. instances described in Section 6.1 .
 achieves a smaller average solution gap (0.27%), saving 1.90% in comparison with GRASP LP and 0.53% with GRASP PR. It obtains 12 best solutions, versus one for GRASP LP and seven for GRASP PR, but the two GRASP find slightly better solutions on a few instances, e.g. 100-5Nb to 100-10N.
 since MS-ILS PR finds 23 best solutions out of 24 and reduces solution gap to less than 0.01%. The hierarchy defined by the solution gap and the number of best known solutions found is confirmed by the mean ranks, MS-ILS PR reaching 1.44/4.
MS-ILS and MS-ILS PR are on average 4.5 and 5.5 times slower than the most efficient GRASP (GRASP PR) and the maximum running time reaches 11.5 min on the largest instance 200-10MNb. However, such running times are quite reasonable for a problem involving strategic location decisions like the LRP-2E: It will be probably too costly to change the subset of open depots during a few years, so finding the best subset is worth spending a few minutes of computer time.

CLRP benchmarks (see Section 6.1 )arepresentedin Table 6 .The average solution gap and the number of BKS lead to the same hierarchy as before (MS-ILS PR o MS-ILS o GRASP PR o GRASP
LP), again at the expense of augmented running times. On average, these instances with a uniform distribution of customers or a partition of clusters look a bit easier than Nguyen X  X  instances which are based on normal and multi-normal distributions: all heuristics require less time and produce slightly reduced gaps.

For the two sets of instances, we performed a Friedman test to compare statistically the four algorithms in terms of solution costs. On Nguyen X  X  instances, the test gives a chi-square value of 58.63 and a p -value smaller than 0.001. On Prodhon X  X  instances, we get chi-square  X  73.47 and again a p -value inferior to 0.001.
Hence, the null hypothesis (the four heuristics have equivalent performances) can be rejected for significance levels 0.05 and 0.01.

In addition to their lower solution values, MS-ILS and its PR version are also more robust than the two GRASP, whether we consider the standard deviation of the gaps to the BKS over the set of instances ( Std dev in the tables) or the standard deviation of the five runs, averaged on the instances ( Avg stab ).

The ranks of the four methods are also depicted by box-and-whisker plots in Fig. 9 , see for instance http://www.physics. csbsju.edu/stats/box2.html for the principles of these plots. They show that MS-ILS PR clearly outperforms the two GRASP algorithms.

Fig. 8 provides a time-to-target plot ( Aiex et al., 2007 ) confirming the impact of PR on Nguyen X  X  instance 50-10Nb. The MS-ILS with and without PR are executed p  X  50 times, recording the time needed to reach a solution with objective function at least as good as a given target value. Like in Aiex et al. (2007) , for each metaheuristic the running times are sorted in increasing sorted running time t i . The curves display the points z i  X  1 ; 2 , ... , p , for a maximum target value 87 315 (solution cost found by the two heuristics). For instance, MS-ILS has a prob-ability of 47% of finding a solution at least as good as the target value in at most 20 s, while this probability is about 63% for MS-ILS PR.

To conclude with LRP-2E instances, MS-ILS PR looks efficient, both on instances with normal or multi-normal distributions of customers (Nguyen) and on instances with uniform or clustered distributions (Prodhon). 6.6. Results on Sterle X  X  instances (several platforms) Our MS-ILS was initially designed for one single main depot.
The comparative study with Sterle X  X  instances, suggested by a reviewer, required two modifications in the algorithms to handle the multiple platforms.

The first modification is to build the first level trips using a multi-platform nearest-neighbour method, in the heuristics H1,
H2 and H3 and in the Split procedure. One platform p is randomly selected and its routes are built one by one. A new route is initialized at p and progressively extended by adding at the end the nearest feasible and unrouted satellite. The route returns to the platform when no satellite can be added. Successive routes are built in this way, until the residual platform capacity cannot accept a new route. This process is repeated with another randomly chosen platform, until all satellites are visited by primary routes.

The second modification consists in extending the Best trip relocation and the Satellite status inversion moves to the first level, in the local search LS2. In other words, the first move can now move a complete primary route to another platform, while the second move tries to change the status open/closed of a platform. Sterle X  X  (2010) PhD dissertation and the conference paper
Boccia et al. (2010) give results on a 2.4 GHz PC for a decomposi-tion approach DA (solving a facility location problem and then a two-echelon VRP) and a tabu search tested with different sets of parameters. Table 7 lists the results obtained by DA, the best version of the tabu search called TS2 in Boccia et al. (2010) , and our MS-ILS. As TS2 performs one run, we provide the cost found by one run of the MS-ILS and, like in the previous tables, the best solution and the average running time for five runs. The best-known solution (BKS) given for each instance is the best of the four algorithms (Sterle reports the results of another tabu search version, TS1, but it is never better than TS2). We give the same statistical indicators as the ones provided for our instances, except that the average stability is meaningful only for the method with several runs (MS-ILS).
 terms of solution quality. Compared with the tabu search TS2, the one-run version saves 2.84% and finds seven best solutions instead of 3. Even if the respective computer speeds are taken into account, our algorithm is almost twice faster: on our 3.4 GHz computer, TS2 would last on average around 2257 2.4/ 3.4  X  1600 s, versus 909 for MS-ILS. Another advantage of MS-ILS is its smaller number of parameters: 9 versus 27 for TS2, according to Boccia et al. (2010) .
 achieved: the deviation to the BKS becomes 0.32%, saving 3.35% compared with TS2, and 27 best solutions out of 30 are obtained.
However, it is fair to say that the five runs last on average 5 927  X  4635 s on our computer, which is 2.9 times slower than the 1600 s of TS2. 6.7. Results for CLRP instances capacitated location-routing problem (CLRP), we provide a compar-ison with four published CLRP metaheuristics, to show that our methods still perform well on this particular case without first level. The three first metaheuristics were designed by Prins, Prodhon and
Wolfler Calvo: GRASP LP-PR, a GRASP complemented by a learning process and path relinking ( Prins and Prodhon, 2006 ), MA memetic algorithm with population management ( Prins et al., 2006 ), and LRGTS, a Lagrangean relaxation/Granular tabu search ( Prins et al., 2007 ). The fourth method (GRASP ELS) is a metaheur-istic hybridizing GRASP and evolutionary local search (ELS), recently proposed by Duhamel et al. (2010) .

The most efficient metaheuristic available today for the CLRP, both in terms of solution cost and CPU time, is LRGTS. This is a metaheuristic alternating cyclically between a facility location sub-problem and a multi-depot vehicle routing sub-problem. The location sub-problem is solved almost always to optimality, using a dual ascent procedure based on a Lagrangean relaxation, while the multi-depot VRP obtained once the depots are selected is tackled by a granular tabu search.
 This test is performed on the 30 CLRP instances built by
Prodhon (2006) . As a detailed table of results like for the LRP-2E instances would be too large (we have here six heuristics), we prefer to give in Table 8 only three indicators: the number of best known solutions found (BKS), the average deviation to these BKS and the mean CPU time. Three different computers being used, we added the running times scaled for our 3.4 GHz computer, on the basis of clock frequencies. As we kept the original CLRP file names when deriving the Prodhon LRP-2E instances, the reader can see the size of each CLRP instance in the file names of Table 6 .
In terms of average deviations to the BKS, LRGTS remains the best method but our algorithms outperform the three other published approaches. In particular, MS-ILS and MS-ILS PR take place with LRGTS and GRASP ELS among the four methods which reach a gap below 1%, even if no BKS is improved. Even if scaled times are considered, our heuristics dominate GRASP ELS both in terms of gap and time. Note that the CPU times reported by Duhamel et al. (2010) for GRASP ELS are counted only until the last improvement: the total duration is even larger. A good property of GRASP ELS is its ability to find the maximum number of BKS (18) but this is counterbalanced by a stronger dispersal of its solution costs. 7. Conclusion
In this paper, we considered the two-echelon location-routing problem (LRP-2E) with limited capacities on both satellite depots and vehicles. The problem was solved by a multi-start iterated local search (MS-ILS) which can be coupled with path-relinking (MS-ILS PR). This MS-ILS brings several improvements to classical ILS: Two search spaces (giant tours and LRP-2E solution), two VND procedures instead of a single lo cal search, and a tabu list used to stop the current ILS and restart faster from a new initial solution when a low diversity is detected. The path relinking can be added as
The proposed algorithms were tested on the LRP-2E (three sets with 84 instances in total) and the CLRP particular case (30 instances), with 1 or 5 main depots, 8 X 20 satellites and 20 X 200 customers. Even the CLRP with its single echelon is harder than the capacitated VRP (CVRP) which i s already NP-hard despite the absence of location decisions. For instance, the best exact methods available can consistently solve CVRP instances up to 100 customers, while for the CLRP the current limit is 50 customers and five depots ( Belenguer et al., 2011 ). The LRP-2E with its a dditional distribution level is even harder than the CLRP. Taking into account this difficulty, our methods are competitive si nce they outperform two GRASP algorithms and one tabu search on the LRP-2E. In a comparison with four published CLRP metaheuristics, only one (LRGTS) does better.
Our next step is to design tight lower bounds and exact methods for the LRP-2E, to better evaluate our metaheuristics. We are currently working on a preliminary branch-and-cut algorithm which could solve most instances with 50 customers to optimality. Acknowledgements This research was supported by the Champagne-Ardenne Regional Council, France.
 References
