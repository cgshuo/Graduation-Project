 Most e-commerce sites to-date have focused on helping con-sumers decide what to buy and where to buy. We study the complementary question of helping consumers decide when to buy, focusing on consumer durables. We introduce a utility-based model for evaluating different approaches to this question. We focus on how best to make use of fore-casts in making recommendations, and propose three nat-ural strategies. We establish a relationship between these strategies, and show that one of them is optimal. We con-duct a large-scale experimental study to test the perfor-mance and robustness of these strategies. Across a wide range of conditions, the best strategy obtains 90% of the maximum possible gains.
 J.4 [ Social and Behavioral Sciences ]: Economics; F.2.0 [ Analysis of Algorithms and Problem Complexity ]: General Economics, Algorithms, Experimentation Recommendation, Automated Shopping
In recent times, there has been tremendous growth in the amount of commerce conducted over the Web. The yearly retail e-commerce sales in U.S. alone are estimated to have topped $100 Billion. Nearly seven out of ten consumers say that the Internet has become important in providing them with information to help them make buying decisions and that they are likely to shop online before making an W ork done while author was visiting Search Labs. offline purchase [11]. Thus the Internet has started to play a crucial role in the decision making process of the consumers irrespective of whether they buy online or offline.
Various e-commerce sites exist to help consumers make purchasing decisions. Some websites provide product re-views to help consumers decide what to buy among similar products. Others compare prices across different retailers to help consumers decide where to buy the product. However, few sites exist to help consumers decide when to buy .
In this paper, we study the design of decision aids that help consumers decide the timing of the purchase of durable products such as household appliances and electronic goods. Such decision aids are important as consumer durables are typically expensive, and consumers experience remorse when they find out they could have bought the products at lower prices had they waited a little longer [6].

Certain websites advice consumers about potential price changes in the domain of airfare ( bing.com/travel , for-merly farecast [9]) and event tickets ( seatgeek.com ). There is a crucial difference between the domain of tickets and the domain of durable goods which we study in this paper. While both problems have to deal with the uncertainty of future prices, in the case of a durable product, there is a cost associated with waiting to buy the product due to loss of use, which has to be factored into the decision. Thus, while recommending when to buy a ticket is driven solely by potential price changes, recommending when to buy a consumer durable requires a more in-depth modeling of the utility to the consumer.

In order to make good recommendations, we must first be able to predict potential price changes. In [1], we compared and evaluated different forecasting methods incorporating prices, sales volume, seasonality, and competition for pre-dicting prices in consumer durables. We found that methods that use both the current price level and the recent price changes can generally predict product prices well. In this paper, we set out to answer the following questions:
We address the first question by proposing a utility-driven model that captures the trade-off a prospective consumer h as to make when faced with the decision of when to buy, namely between potential price drops and the loss in utility due to waiting. An essential feature of the formulation is the sequential nature of the recommendations, inspired by Markov decision processes. We address the second question by introducing three natural strategies for recommendations treating forecasts as blackboxes. We conduct a theoretical analysis to compare these strategies, and establish optimal-ity for one of them. We address the last question by conduct-ing an empirical analysis that measures the potential gains users make by following the recommendations. The analy-sis provides a foundation for building a system that helps forward-looking consumers make more informed decisions.
The rest of the paper is organized as follows. We begin with a discussion of related work in Section 2. We introduce a formal model for the recommendation problem by propos-ing a model of utility of the consumers in Section 3. We then describe three recommendation strategies in Section 4 and analyze them in Section 5. In Section 6, we present a large-scale experiment using prices in the electronic goods category that quantifies the gains to the consumers from us-ing our system. We discuss the implication of this study and future research directions in Section 7.
The decision between present and future consumption has been studied in economics as the intertemporal choice prob-lem. In his seminal work Theory of Interest , Fisher proposed that such trade-off should be captured by means of discount-ing [10]. More recent marketing studies on forward-looking consumer behavior has also been based on discounting, in-cluding [21] that estimates the discount rates for different types of products, and [18] that compares different forms of discounting. Inspired by these studies, we propose to model the loss of utility due to waiting by means of discount-ing. However, while these past proposals attempt to explain consumer behavior through discounting, we are interested in helping consumers that discount future consumption to make the best timing decision.

Our formulation of the problem of when to buy a con-sumer durable is related to optimal stopping problems stud-ied in probability theory [5]. To our knowledge, no past work has proposed a framework for analyzing this decision using optimal stopping, which we believe provide a natural formulation that allows us to compare different approaches in a formal and rigorous way. One important distinction in our work, in contrast to prior work on optimal stopping, is that the distributions of the random variables are not as-sumed to be known; rather, their distributions are observed through forecasting algorithms that may be inaccurate.
There have been a number of studies in the marketing lit-erature on the pricing of consumer durables [16, 19]. Price evolutions are often modeled from the product life-cycle point of view, where price changes are linked to stages of the life of a product. Dino applied this model for electronic products at a category level and the model fits well [7]. The methodology has also been extended to incorporating de-mand models [8]. These prior works suggest that prices for consumer durables follow definite patterns. See [3, 14] for surveys of forecasting methods.

Traditionally, recommender systems focus on suggesting to users items that they may like [15]. Recommendations may be made based on items that similar users like [20], similar items that a user likes [17], or hybrid methods that combine the two [4]. While our work is also about making recommendations to users, the recommendations are about when an item should be purchased. The recommendation is different in nature and is not amenable to a solution by existing techniques.
In this section, we present the design of our system. We first propose a formal framework for analyzing the problem of timing the purchase of consumer durables based on util-ity theory. We then describe how such a system may be implemented as part of a shopping service.
Consider a consumer who has selected a particular prod-uct to buy, and is deciding whether to buy the product right away or wait for its price to drop. We treat time as discrete, and denote the latest time until the consumer would wait as time T , which we call the consumer X  X  decision horizon .
The problem of timing when to buy is to decide the time index within consumer X  X  decision horizon at which she should buy the product. It is a sequential decision prob-lem  X  X t each time step s , she decides whether to buy the product or wait. If she chooses to wait, she will face another decision at the next time step. The problem repeats itself until she buys the product.

The consumer has a value for the product, which mea-sures the benefit she expects to derive from owning and us-ing the product. In deciding whether to buy now or wait, the consumer faces a trade-off between starting to derive the benefit right away and the loss due to potential price drops in the future. This intertemporal trade-off is com-monly modeled by discounting the value of the product if it is purchased in the future [18, 21]. We denote the discount rate of the consumer by (0 &lt; 1), and take it to be time-invariant within the consumer X  X  decision horizon. If a consumer decides to buy the product at time t , she derives a utility of t . The quantities T , , and are specific to the consumer of a given product, and may vary for different consumers and products.

Let the prices of the product from start uptil time T be ( p 0 ; p 1 ; : : : ; p T ), which we call the price path p of the prod-uct. The consumer first gets interested in buying the prod-uct at time t . For the purpose of this paper, we assume t = 0. This is without loss of generality since the prices be-fore time t cannot change the utility of the consumer, which we define momentarily. At time s , the prices up to time s ter s are called the future prices , f s = ( p s +1 ; : : : ; p sometimes write p as ( h s ; f s ).

Given a price path, a value, and a discount rate, the utility of the consumer if she buys the product at time s equals
If a consumer possesses a crystal ball that informs her of the price path of the product p , deciding when to buy is a simple matter of selecting the time t that maximizes the utility u ( t; p ; ; ). Unfortunately, at time s , the consumer has only access to the history h s , and has to make a decision without the full knowledge of p .
The role of a forecasting algorithm is to make use of the history of a product to forecast its future prices in order to help the consumer make a more informed decision.
 Definition 1. A forecasting algorithm F maps a history h s to a distribution over future prices f s . We denote by E the distribution over future prices predicted by the forecasting algorithm. We also write E as F ( h s ).

Using the forecasts over future prices, a recommendation strategy makes a recommendation to buy or to wait taking into account the consumer parameters.
 Definition 2. A recommendation strategy r maps a his-tory h s , a distribution E over future prices, a value of the product, and a discount rate to f 0 ; 1 g , where 0 is a recommendation to wait and 1 is that to buy.

As the latest time the consumer will wait before buying the product is time T , we require that r ( h T ; E; ; ) = 1 for any distribution E .

We refer to the pair ( F; r ) as a buy-or-wait recommenda-tion system , or system when the context is clear. Given a system ( F; r ), a price path p , and a discount rate , we can determine when a consumer following its advice will buy the product.
 Definition 3. Given price path p , value of the product, discount rate , and system ( F; r ), the purchase time is defined as i.e., this is the first time index the system recommends the consumer to buy.

Manufacturers actively manage their revenue through prod-uct pricing, and hence product prices often change accord-ing to some planned schedule, albeit with uncertainty due to supply, demand, and competition [7, 19]. This results in a distribution over price paths. We use D to denote this true distribution over price paths. The success of a system can be measured in terms of the expected utility the system generates for the consumer, where expectation is taken with respect to the distribution D over price paths.
 Definition 4. Given distribution D over price paths, value of the product, discount rate , the performance of sys-tem ( F; r ) for a given consumer equals i.e., the expected utility to a consumer who follows the ad-vice of system ( F; r ) over the distribution D of price paths. Putting it together, our problem can be stated as Problem Definition. Given a set of price paths sampled according to distribution D , value of the product, and discount rate , select a system ( F; r ) that maximizes per-formance ( F; r; D; ; ).
We envision the recommendation system for helping users to decide when to buy to be integrated as an alert service to existing product search portals. When a user issues a query for a product, a price chart will be displayed to the user to help her understand the historical evolution of the prices for the product. If the user is interested in buying the prod-uct, additional information related to the user choices, such as the decision horizon, the value for the product, and the discount rate, will be elicited from the user. The elicitation process can be based on techniques described in [12, 21]. The service will then monitor changes in the product prices, and alert the user when the system recommends buying the product.
In this section, we present three recommendation strate-gies as well as techniques for implementing them. These strategies take as input a consumer X  X  value for a product , her discount rate for the product, and the distribution E of future prices forecasted by algorithm F at time s taking into account the price history h s . They output 0 if the rec-ommendation at time s is to wait and 1 if it is to buy. These strategies differ in how they estimate the utility of waiting.
A natural recommendation strategy is to choose to wait if there exists a future time for which the expected utility is greater than zero. It can be formally stated as follows. Definition 5. The Expected Utility Strategy , EUS( h s ; E; ; ), outputs 1 (buy) if for all t , s &lt; t T , the expected utility buying at time t is no better than the expected utility from buying at time s . That is, it outputs 1 if and 0 (wait) otherwise.

EUS is an easy strategy to implement. First, the rhs is a fixed quantity. To evaluate the lhs of Eq (3), by linearity of expectation, max The expensive part of the computation involves computing the expected price at time t according to the distribution E . For many distributions (e.g. normal distribution and uniform distribution), this value can be computed efficiently by evaluating a closed-form formula. In general, it can be computed through sampling and taking the sample average. Example 1. We give an example of how EUS is evaluated. Suppose that s = 0, p 0 = 100, = 100, = 1, T = 2, and E , the distribution of future prices f p 1 ; p 2 g , is given as The rhs of Eq (3) equals (100 100) = 0. The lhs equals Hence, EUS recommends to buy.
Another natural recommendation strategy, motivated by options pricing theory [13], is to generate and evaluate sam-ple price paths according to the forecasted distribution. If, in expectation, there exists a future time for which the ex-pected utility is greater than the utility of buying the prod-uct now along the path, it recommends to wait. It can be formally stated as follows.
 Definition 6. The Sample Path Strategy , SPS( h s ; E; ; ), outputs 1 if the expected maximum utility of buying at some future time t , s &lt; t T , is no better than the expected utility of buying at time s , i.e., and outputs 0 otherwise.

The difference between EUS and SPS is the order in which expectation and maximization is taken. Whereas under EUS, expectation is taken separately over each time index, and the time index with the highest utility is selected, under SPS, expectation of the highest utility along an entire price path is taken. Their values could be different for some distribu-tion E . We explore this further in Section 5.
 To implement SPS, one needs to evaluate the lhs of Eq (5). Unlike EUS, the value of the lhs of Eq (5) depends on the joint distribution of future prices f s , since the expectation is taken over price paths, and hence does not lend itself to the same decomposition as in Eq (4). A parsimonious approach to implement this strategy is to sample a set of price paths and evaluate the maximum on each price path, and estimate the expectation by averaging the sampled values.
 Example 1 (cont X  X ). Under the same setting, we give an example of how SPS is evaluated. The rhs remains un-changed. The lhs of Eq (5) equals E Hence, SPS recommends to wait.
The final recommendation strategy we consider is defined recursively through self application. It makes a buy recom-mendation if the expected utility obtained from waiting at time s and following itself thereafter is no larger than that of buying the product at time s . In other words, the strategy estimates the expected utility of waiting by computing how much utility it would gain if it follows its own recommen-dation starting from time ( s + 1), i.e., applies itself at time ( s + 1), and compares the expected utility to that of buying at time s .

To give a formal definition of the strategy, we introduce a notation for conditioning the present forecast with new prices. Suppose that the present forecast over future prices f is E . If the price at time ( s + 1) equals p s +1 , then the updated forecast over future prices f s +1 , denoted by E is a distribution over f s +1 that satisfies i.e., for any future prices f s +1 , the probability of the future prices according to E j p s +1 equals the probability according to E conditioned on the price at time ( s + 1) being p s +1 Definition 7. The Self Application Strategy , SAS( h s ; E; ; ), outputs 1 if and only if the expected utility obtained from waiting at time s and following SAS thereafter is no larger than the expected utility of buying at time s , i.e., where w ( p; t; E; ; ) is defined as the utility obtained from following the recommendations of SAS after having waited for the first ( t 1) time steps. It can be written recursively as the maximum between the utility of buying the product at time t , or waiting at time t and following SAS thereafter, w ( p; t; E; ; ) = max and for time t = T , w ( p; T; E; ; ) = T p : (8) Remark 1. SAS depends on history h s only through the current price p s and the length of the history j h s j . We sep-arate these factors in the recursion to highlight how they evolve. This dependence relationship is also true for EUS and SPS. We make use of this relationship in Section 5.
Like SPS, SAS can be implemented by sampling and es-timating the expectations via sample averages. However, a direct sampling algorithm will run in time exponential in T due to its recursive nature. This is because each evalua-tion of w ( p; t; E; ; ) according to Eq (7) requires evaluating an expectation that calls the function w with different argu-ments. If k samples are drawn for estimating the expectation by sample average, a total of O ( k T  X  s ) number of evaluations of Eq (8) will be needed.

Based on experiments reported in [1], autoregressive model of order 1 is often a good fit for product prices. Under this model, prices follow a Markov process , i.e., the distribution of future prices f s depend only on the price p s but not the prices before. In this case, we can speed up the computation exponentially by backward induction .

Starting from time T , we draw k samples, and evaluate the utility of buying at time T . We then compute the value of waiting till time ( T 1) by using these values in evaluat-ing the expectations, and taking the maximum according to Eq (7). We proceed backwards in time until we reach time s . A formal description is given in Algorithm 1.
The algorithm depends on two auxiliary functions. The function Sample ( E; t ) draws a price uniformly at random from the domain of prices at time t under distribution E . The function Prob ( E; t; p; p  X  ) evaluates the transition prob-ability from price p to price p  X  at time t according to the distribution E . Prices are drawn uniformly at random from their domains to avoid factoring in the probabilities twice, as the samples are subsequently weighted by the transi-tion probabilities. Lines 1 and 2 estimate the expectations needed in Eqs (6) and (7) by sample averages ( v=s ). M ore formally, P E is a measure over the elements f s , and P | p s +1 is a measure over the elements f s +1 . For any event e measurable over the -field generated by f s +1 , P E | p s +1 P ( e j p s +1 ). For exposition, we simplify the statement and state the results as if the distribution is discrete. Al gorithm 1: SAS Evaluation by Backward Induction Input : History h s ; Dist. E ; Discount rate ; Value
Output : lhs of Eq (6), E E [ w ( p s +1 ; s + 1 ; E j p s +1
Params : Samples per time step, k /* The array entry p [ t; i ] stores the i -th sampled price for i 1 to k do end for t ( T 1) downto ( s + 1) do 1 w [ t; i ] max f t p t ; v=s g end v s 2 return v=s Alg orithm 1 produces an unbiased estimate of the lhs of Eq (6) when prices follow a Markov process, since the prob-ability of transitioning from price p t to p t +1 is independent of prices p t  X  for t  X  &lt; t . Hence, for price paths p and p E j ( p s ; p s +1 ; : : : ; p t ) equals E j ( p  X  s ; p  X  s +1
The running time of the algorithm is O ( k 2 T ), since each computation of w [ t; i ] requires a summation over k terms, which is computed once for each of the k samples per time step, and there are T time steps. Though the time is poly-nomial in k and T , the algorithm implicitly considers an exponential number of price paths p , as the final expecta-tion takes into account each combination of prices p [ t; i ] from every time index t and i from 1 to k .
 Example 1 (cont X  X ). Under the same setting, we give an example of how SAS is evaluated. The rhs remains un-changed. The lhs of Eq (6) equals E
E [ w ( p 1 ; 1 ; E j p 1 ; 100 ; 1)] = E E [max f 100 p 1 g ] = E E [max f 100 p 1 ; 0 g ] = 0 : 5(5) + 0 : 5(0) = 2 : 5 : Hence, SAS recommends to wait. We now analyze the strategies presented in Section 4. First, we study whether the recommendations made by the three strategies are related. Second, we consider an ide-alized situation where the forecasting algorithm is perfect, and determine which of the strategies works best. For ex-position, we present the results as if the distributions are discrete. The statements can be made formal for continuous distributions.
Without loss of generality, we take s = 0. When the decision is between buying now or the next period, i.e., T = 1, all three strategies makes the same recommendation. Theorem 1. When T = 1 , for any distribution E , value , and discount rate , EUS, SPS, and SAS make the same recommendation.
 Proof. When T = 1, the decision is between buying at time 0 and at time 1. It is clear from Eq (3), (5), and (6) that the rhs of the three strategies are equal. The lhs of Eqs (3), (5), and (6) are also equal, since for discrete t , if 0 &lt; t 1, t = 1. Hence, the lhs are all equal to
Wh en T 2, the strategies may make different recom-mendations. Nonetheless, the recommendations are related, and we can show that SPS is more optimistic about the value of waiting than SAS, and SAS is more optimistic about the value of waiting than EUS.
 Theorem 2. For any history h t , distribution E , value , and discount rate , if EUS recommends to wait, then SAS will also recommend to wait. If SAS recommends to wait, then SPS will also recommend to wait.

To prove this theorem, note that the recommendations made by these strategies are determined by the values of the lhs of Eqs (3), (5), and (6). These values can be inter-preted as the values of waiting estimated by the strategies. Let v EUS ( h s ; E; ; ), v SPS ( h s ; E; ; ), and v SAS denote the respective lhs of the strategies for history h We claim that for all history h s , v EUS ( h s ; E; ; ) v SAS ( h s ; E; ; ) v SPS ( h s ; E; ; ) : (9) Let v buy ( h s ; ; ) denote the value of the rhs of the strate-gies for history h s . If the claim is true, then if EUS rec-ommends to wait, so will SAS, since v SAS ( h s ; E; ; ) v
EUS ( h s ; E; ; ) v buy ( h s ; ; ). Similarly, if SAS recom-mends to wait, so will SPS, since v SPS ( h s ; E; ; ) v SAS ( h s ; E; ; ) v buy ( h s ; ; ).

To show the claim, we examine the order in which the ex-pectation and the maximum is taken under the three strate-gies. The relationship between EUS and SPS can be easily established by Jensen X  X  Inequality. The difficulty is with SAS. The proof makes use of an inductive argument and Jensen X  X  inequality to establish the desired relationship, and can be found in the full paper [2].

Recall that Remark 1 states that the three strategies de-pend on history h s only through the current price p s , and its length j h s j . Further, the value of waiting does not depend on the current price p s . Henceforth, we rewrite the function v EUS ( h s ; E; ; ) as v EUS ( s; E; ; ), and likewise for SPS and SAS.
We now consider the performances of the three strategies when the forecasting algorithm is perfect , which informally means that the forecasted distribution coincides with the true distribution D . Note that it does not mean that the price path itself is known with certainty. While it is not possible to design a forecasting algorithm that is perfect, this analysis helps us to isolate the difference in performance th at is solely explained by the choice of recommendation strategy. It also helps to develop insights as to why some of the strategies may fail to make the best recommendation despite very good forecasts.

We first define a property of forecasting algorithm about how current forecasts are related to future ones. Definition 8. A forecasting algorithm F is consistent if for all histories h s and h t where h t includes h s as its first s prices, i.e., h t = ( h s ; p s +1 ; : : : ; p t ), F ( h bution identical to the conditional distribution induced by F ( h s ), i.e., for all f t ,
Intuitively speaking, a consistent forecasting algorithm is one where there are  X  X o surprises X  when it updates its fore-cast. Given the current forecast, when a new price arrives, one just needs to condition on the latest observation to ob-tain the updated forecast.

A consistent forecasting algorithm is related to a collec-tion of distributions over price paths. Consider a consistent forecasting algorithm F . Given any history h t , it produces a distribution F ( h t ) over the price paths f t , which by consis-as a collection of distributions of price paths indexed by p Conversely, given a distribution E of price paths f t , it can be turned into a forecasting algorithm for f t +1 , such that given any price p t , it produces a conditional distribution over f t +1 . This duality between distributions and consis-tent forecasting algorithms will be exploited further in this section. For semantic clarity, we denote the forecasting al-gorithm for prices f t +1 induced by distribution E over price paths f t as [ E ].

A forecasting algorithm F is perfect for distribution of price paths D when F and D are  X  X nterchangeable X . Definition 9. A forecasting algorithm F is perfect for dis-tribution of price paths D if F is consistent, and F ( h 0 produces the same distribution as D conditional on p 0 , i.e., for all price paths p ,
Another way to interpret a perfect forecasting algorithm is that [ D ] gives the same forecasts for any p 0 as F . Note that if F is perfect, by property of consistency, for all history h , Hence, other than not knowing the distribution of the first price p 0 , F has as much information as D .

We now consider the performance of the three strategies under perfect forecasts. We start with an example that shows that EUS is not optimal.
 Example 2 (Suboptimality of EUS) . Suppose that s = 0, p = 100, = 100, = 1, T = 2. Let the true distribution D of price paths be
D ( f 100 ; 105 ; 105 g ) = 0 : 25 D ( f 100 ; 105 ; 95 g This setup is identical to Example 1, and assume that E = F ( f 100 g ) in Example 1 is a perfect forecast for D . We have shown that and EUS will recommend to buy at time 0, whereas SPS and SAS will recommend to wait. One can verify that waiting is better, since there is a 0 : 5 chance that the price will drop to 95 at time 1, at which point the consumer can buy and earn a utility of 5, and if the price goes to 105 at time 1, the consumer can choose to wait and earn an expected utility of 0 from buying at time 2.

Th is example reveals a weakness in the estimation proce-dure used in EUS, namely that it fails to take into account the sequential nature of the decisions to be made. Even though waiting and buying at the next time step may earn zero utility in expectation, one may be able to choose dif-ferently depending on the outcome at the next time step. Hence EUS may systematically underestimate the value of waiting.
 Our next example shows that SPS is not optimal either. Example 3 (Suboptimality of SPS) . Consider the same setup as Example 2, but with a change to the true distribu-tion D of price paths
D ( f 100 ; 110 ; 125 g ) = 0 : 25 D ( f 100 ; 110 ; 95 g Under a perfect forecast, the value of the three strategies are: v
EUS (0 ; F ( f 100 g ; 100 ; 1) = max f 100 102 : 5 ; 100 110 v
SPS (0 ; F ( f 100 g ; 100 ; 1) = 0 : 25(100 110) + 0 : 25(100 95) v
SAS (0 ; F ( f 100 g ; 100 ; 1) = 0 : 5(max f 100 95 ; 100 115 Now, SPS will recommend to wait at time 0, whereas EUS and SAS will recommend to buy. In this case, buying is better than waiting at time 0. If one waits, at time 1, if p 1 = 95, one can at most gain a utility of 5 by buying at time 1. But if p 1 = 110, then both waiting and buying at time 1 lead to an expected utility of 10. Combining the two, it is better to buy at time 0.

Th is example reveals a weakness in SPS, namely that it assumes it can pick out the best time to buy as if the price path is known. In the above example, it assumes that if the price path is f 100 ; 110 ; 125 g , it will buy at time 1; but if the price path is f 100 ; 110 ; 95 g , it will buy at time 2. This is an inconsistent choice, since the price histories at time 1 in both cases are identical. As a result, SPS overestimates the value of waiting.
 Remark 2. In Example 3, all three strategies produce dif-ferent estimated values for waiting. Hence, there exists dis-tributions for which the inequality in Eq (9) holds strictly.
Through these two examples, we observe that SAS ac-counts for the sequential nature of the decision problem, and ensures consistency in the choices through self applica-tion. It turns out that these are the key properties for a recommendation strategy to be optimal in expectation. The orem 3. For any distribution of price paths D , value , discount rate , if the forecasting algorithm F is per-fect, there does not exist a recommendation strategy r that has higher performance than SAS, i.e., for all strategies r , ( F; r; D; ; ) ( F; SAS ; D; ; ) .

The key to establishing this theorem is that the value SAS estimated for waiting precisely measures the performance it will obtain if it decides to wait. This is provided by the following  X  X emma X . We put this lemma in quotes because the statement of the Lemma is not sufficiently formal. A formal statement of the Lemma involves some subtlety, and is presented in the full paper.  X  X emma. X  For any , , h s for s 2 [0 ; T ) ,
Using this lemma, we can establish using an inductive ar-gument that SAS is optimal in expectation. The proof is similar in spirit to the optimality proof of using dynamic programming (Bellman equations) to solve Markov decision processes, but with added subtlety due to the semantic dif-ferences between a forecasting algorithm and a distribution. The proof can be found in the full paper [2].
We have established two theoretical results. The first re-lates the recommendations made by the three strategies, and holds for any forecasting algorithm. Theorem 1 shows that the choice of recommendation strategies does not matter when the decision horizon is over a single period. Theo-rem 2 establishes a relationship useful for post-hoc analysis of empirical performances. For example, if we observe that SPS outperforms EUS, we can infer that the system under EUS is erring on the side of making too many buy recom-mendations, as for any data set and forecasting algorithm, the set of situations where EUS makes a buy recommenda-tion is a superset of ones for SPS.
 The second result shows that when forecasts are perfect, SAS is the optimal recommendation strategy. We believe that SAS continues to be the best strategy when forecasts are imperfect, although we cannot directly establish its op-timality theoretically, as a poor recommendation may be either due to the strategy or the forecasts. We address this question by means of experiments in the next section.
We now conduct an experimental study to evaluate the performance of the three proposed recommendation strate-gies. The objective of this study is to quantify the perfor-mances under realistic settings of price changes and fore-casting errors. It also complements the theoretical analysis, which shows the optimality of SAS, by quantifying the dif-ferences in performances among EUS, SPS, and SAS.
To generate realistic distribution of price paths, we ana-lyzed price changes in four categories of electronic products X  Televisions, Digital cameras, Camcorders, and Printers. The data was obtained for prices between January 2005 and September 2008 from NPD, a firm that tracks prices reg-istered at major retail stores. We found that the average price decrease per time period for these products was about 3 : 5%, with a standard deviation of about 5%. We generate synthetic data based on these statistics, and systematically vary different factors to measure the performances of the strategies under different settings.

We consider a family of distributions to model the price paths of these products based on how persistent are unex-pected price changes, which we call shocks . Formally, sup-pose that the average decrease per time period is , we de-fine the shock at time t as the difference between the actual price p t and the expected price p 0 t . We select a parameter 2 [0 ; 1] that controls shock persistence . In more detail, from time period t to time period ( t + 1), the change in prices is sampled from a normal distribution N ( ; ). Let p and q t denote the price and the shock in time period t . The price p t +1 in time period ( t + 1) equals where d is sampled from N ( ; ).

Shock persistence is important as it models whether prod-uct prices exhibit definite patterns. When its value is low, the prices follow definite paths; when its value is high, the prices appear random. At the extremes, when = 0, shocks are transient and do not carry over from one time period to the next. This setting gives rise to a distribution where the prices of one period is independent of another, since the price p t +1 at time period ( t + 1) depends on ( p t q t ) = p 0 quantity that is independent of p t . It can be shown that the price at time period t is sampled from N ( p 0 t ; p 0 t  X  In contrast, when = 1, shocks are persistent and affect all future prices. This gives rise to a distribution of price path that resembles random walks, since the price p t +1 at time period ( t + 1) depends on p t , the sampled price of time period t .

The first decision starts at time 0 (i.e. s = 0), and the decision horizon T of the consumer is selected to be between four and eight time periods, which we believe is a reasonable timeframe for purchasing consumer durables. The discount rate is selected to be between 95 : 5% and 97 : 5%, and is comparable to the study of [21], after adjusting for techno-logical improvements. Finally, the value of the product is selected to be a multiple of the initial price p 0 , i.e., = p We vary between 1 : 0 and 1 : 1, our best guess on when a user starts to be interested in purchasing the product.
To evaluate the effect of imperfect forecasting algorithms on the performances of the strategies, we introduce two pa-rameters, err and err , that control the accuracy of the estimated mean and that of the estimated standard devia-tion of the forecasts. We assume that the forecasting algo-rithm correctly identifies the level of shock persistence, but may make (normally-distributed) errors in estimating the parameters to the distribution. For example, with = 3 : 5%, it estimates the mean to be  X  , where  X  is sampled from the distribution N ( ; err ). Likewise, a mistake may be made in estimating the standard deviation. Based on our price pre-diction experiments conducted in [1], values of err around 3% and err around 1% are consistent with the errors made by the best forecasting algorithms we evaluated.

The simulation parameters are summarized in Table 1, where we give the default choices for these parameters along with their minimum and maximum values in our sensitiv-ity analysis. In the subsequent experiments, we vary one parameter at a time between its minimum and maximum values to understand its impact on the performances. For
P arameter Default Min Max
T (decision horizon) 6 4 8 err (stdev. of estimated ) 0% 0% 4% err (stdev. of estimated ) 0% 0 : 5% 2% each combination of parameters, we sampled 100 price paths according to the true distribution, and for each path, evalu-ated each strategy 100 times on the path to obtain its aver-age performance. For imperfect forecasting algorithms, the estimated mean and the estimated standard deviation are sampled once for each run.

In reporting the results, we present the relative perfor-mances. This is done by normalizing the performance of a strategy by that of an omniscient strategy that knows all the prices on the price path and selects the optimal time to buy. The omniscient strategy is not constrained to make the same choice for the same price history. Thus, its value con-stitutes an upper bound on the utility that can be gained on each path. As it requires knowing the price path in advance, its performance is unachievable in practice. Nonetheless, it helps us to gauge how close to optimal we can achieve. We also report the performance of always buying at time 0 as a baseline. Since relative performance is scale-free and does not depend on p 0 , p 0 is not varied in the experiments.
In the first set of experiments, we focus on the case where the forecasting algorithm is perfect and shocks are transient. While we already know from the theoretical analysis that SAS is optimal for this setting, the experiments serve two important purposes. First, they serve to quantify the dif-ferences in performances between SAS and the other two strategies. Second, they identify factors that influence the performances of these strategies.

The performances with a sensitivity analysis on each of the five variables are shown in Figure 1. Key findings are (1) Across all conditions, all three strategies outperform the baseline of always buying at time 0. The performances of SAS and SPS are consistently higher than that of EUS. In 70% of the settings, SAS and SPS achieves about 90% of the maximum possible savings. The differences in per-formances are statistically significant under a paired t -tests with p -values &lt; 0 : 001 for all but one cases. Despite the visual similarity, SAS outperforms SPS in all of the cases. (2) In most of the cases, EUS recommends buying at time 0, hence its performance overlaps with the baseline. The cases where the recommendations are different are when &gt; (1 ) (Figures 1(a) and (d)). (3) As Figures 1(a) and (d) show, varying and leads to almost identical results. This is because and (1 ) are closely related. Generally speaking, when &gt; (1 ), it is better to wait, since prices are dropping faster than utility loss due to discounting; conversely, when &lt; (1 ), it is better to buy. However, when the standard deviation of the decrease is high, one could gain by waiting due to Figure 1: Relative performances under different simulation parameters price fluctuations even when is smaller than (1 ). Both SAS and SPS (correctly) recommend waiting in such cases, leading to large outperformance compared to EUS. (4) As Figure 1(b) shows, as the standard deviation of the price decrease ( ) increases, the relative performance of EUS decreases, highlighting the importance of considering more than just the expected utility. The performances of SAS and SPS keep pace with that of the omniscient strategy. (5) As Figure 1(c) shows, the relative performances are al-most constant across different decision horizons ( T ). This suggests that T is not a critical factor in the simulation. (6) As Figure 1(e) shows, the relative performances improve as the ratio of initial value to price ( ) increases. The shape of the curve is concave (downwards) due to the following rea-son. As increases, the absolute performances for all strate-gies increases due to the larger difference between (= p 0 and p 0 . On the other hand, the expected utility obtained from timing the purchase better, which applies to SAS, SPS, and the omniscient strategy, grows at a much slower pace. Hence, the curves are shaped concave downwards.
 In summary, in the majority of the experimental conditions, SAS performs within 90% of the maximum utility that can only be obtained knowing the entire price path. A consumer following SAS does better than the baseline of always buying by about 40% of the maximum utility on average.
The next set of experiments evaluates the relative perfor-mances of the strategies under different shock persistence level ( ). We single out the shock persistence as a separate experiment since its level has a profound impact on the be-havior of the price paths. As mentioned, at = 0, shocks are transient and the distribution is independent from time period to time period; at = 1, the distribution of price paths resembles that of a random walk. The results are presented in Figure 2.

We observe that SAS outperforms the other two strate-gies. However, its relative performance decreases as in-creases. This is because as the distribution of price paths becomes more like that of a random walk, timing the pur-chase without knowledge of the price path becomes difficult. For an increasing fraction of the price paths, the price shocks stay either positive or negative over the entire path. While uptil = 0 : 8, a strategy may yield a positive expected utility by recommending to wait at time 0, as increases, a larger fraction of the gains are offset by losses on price paths for which the price shocks stay positive throughout. On the other hand, since the omniscient strategy makes it choices
Figure 3: Relative perf. under imperfect forecasts knowing the price paths, it can selectively wait on ones for which waiting yields positive expected utilities, and buy on ones where waiting would have yielded negative expected utilities. These together lead the relative performances of SAS to become lower as increases.

Note that as increases, SPS performs worse and worse, and this is one of few cases where we can separate visu-ally the relative performances of SAS and SPS. The prob-lem here is that under a random-walk like price path, SPS will systematically overestimate the value of waiting as high-lighted in Example 3, leading to its recommending the user to wait when it is not advisable to do so. Hence its relative performance deteriorates faster than SAS as increases.
Based on the marketing literature surveyed in Section 2, we believe that the price evolution of durable products ex-hibit definite patterns and do not resemble random walks. Thus, the regime in which our system operates is likely to have small . Nonetheless, these experiments highlight the importance of this assumption. The shock persistence lev-els determine how well we can do for a given category of products.
The final set of experiments evaluates the relative perfor-mances of the strategies under imperfect forecasting algo-rithms. The degree of imperfection is measured by the size of the errors in estimating the mean and the standard devia-tion of the distribution. These experiments help to quantify the true performances of the system, as forecasting algo-rithms in real application do make errors. Our parameters are chosen to reflect realistic levels of errors as measured by related experiments conducted in [1]. The results un-der transient shocks are presented in Figure 3. We observe similar trends for persistent shocks.

The results depend on what kind of errors is made. When erro rs involve estimating the means of the price decreases, both SAS and SPS perform worse than when forecasts are perfect, and their performances get worse as the errors get larger. On the other hand, the performance of EUS improves for small errors. This is because at the default parameter values, = (1 ) = 3 : 5%, EUS will always recommend to buy at time 0. When there are errors in the estimated mean , some fraction of the time EUS will recommend to wait at time 0 when  X  happens to be large. EUS earns higher expected utilities for such cases, resulting in higher relative performance of EUS. However, for large errors, the noise takes over and the performance of EUS decreases.

In contrast, when errors involve estimating the standard deviation of the price decreases, all three strategies perform almost identically as if the forecasts are perfect. We found that the recommendations made by the strategies were the same as the ones made under perfect forecasts in many cases. This suggests that the strategies are tolerant to this form of estimation errors.
We addressed the question of how to design a system that helps forward-looking consumers decide when to buy durable products. We proposed a utility-based framework that dis-counts the value of the product if its purchase is deferred and incorporates the savings accruing from the potential drop in the price of the product. Rather than designing fore-casting algorithms for which a rich body of work already exists, we focused on developing recommendation strategies that employ forecasting algorithms as blackboxes. We de-vised three strategies as well as techniques for implementing them. These strategies differ in how they estimate the value of waiting. The Expected Utility Strategy (EUS) recom-mends a buy only if the maximum expected utility from buying the product in future is no better than the expected utility from buying it now. The Sample Path Strategy (SPS) recommends a buy only if the expected maximum utility of buying at some future time is no better than the expected utility of buying the product now. The difference between EUS and SPS is the order in which expectation and maxi-mization is taken. Whereas under EUS, expectation is taken separately over each time index, and the time index with the highest utility is selected, expectation of the highest utility along an entire price path is taken under SPS. The Self Ap-plication Strategy (SAS) makes a buy recommendation only if the expected utility obtained from waiting now and fol-lowing the strategy thereafter is no better than the expected utility of buying now.

We conducted a theoretical analysis of these strategies, and showed that the recommendations made by the three strategies are related X  X hen SPS recommends to buy, so will SAS; when SAS recommends to buy, so will EUS. This is due to the estimated value of waiting is related through an inequality. We also established that SAS is optimal when the forecasts are perfect. We conducted an extensive experimen-tal study to measure their performances both when forecasts are perfect and imperfect, and under different assumptions about the persistence of price shocks. The model parameters were derived from real data obtained from a data provider for durable goods. Based on the experimental study, we con-clude that the optimal strategy SAS can improve the utility of consumers under most conditions. The improvements are especially significant when the standard deviations of price changes are high, or when the value the consumer placed on the product is close to the initial price. The present work complements our past study of price prediction for consumer durables [1]. Together they suggest that across a wide range of conditions, the proposed system can deliver significant savings to prospective users.

This work opens up several research directions. First, it is a challenging and interesting problem to establish an ap-proximation bound on the proposed SAS evaluation (Algo-rithm 1). Second, we have assumed that the user has already selected which product to buy. A natural extension is when a user is interested in one of a few products (e.g., different models of TVs), and needs to decide which one to purchase as a function of time. Another question is how to improve user experience of product search through ranking functions that factor in whether it is a good time to buy the product.
