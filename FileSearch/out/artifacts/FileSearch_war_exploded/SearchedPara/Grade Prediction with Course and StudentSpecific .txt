 Data mining and machine learning approaches are being increasingly used to analyze educational-and learning-related datasets towards understanding how students learn and improving learning outcomes. This has led to the develop-ment of various approaches for modeling and predicting the success or failure of students in completing specific tasks in the context of intelligent tutoring monitor the students X  performance during the term [ 1 , 3 ], predicting how well the students will perform by analyzing their activities with the learning man-agement system (e.g., Moodle) [ 8 , 11 , 17 ], and predicting students X  term and final GPA [ 2 , 13 , 14 ].
 grade information to accurately estimate how well students will perform (as measured by their grade) on courses that they have not yet taken. Being able to accurately estimate students X  grades in future courses is important as it can be used by them (and/or their academic advisers) to identify the appropriate set of courses to take during the next term, and create personalized degree pathways that enable them to successfully and effectively acquire the required knowledge to complete their studies in a timely fashion. Existing approaches for predicting a student X  X  grade in a future course [ 4 , 6 , 7 ] rely on neighborhood-based collaborative filtering methods [ 10 ]. Despite their relative simplicity, the estimations obtained by these methods are reasonably accurate indicating that there is sufficient information in the historical student-course grade data to make the estimation problem feasible.
 In this paper we improve upon these methods by developing various future-course grade prediction methods that utilize approaches based on sparse linear models and low-rank matrix factorizations. These methods rely entirely on the performance that the students achieved in previously taken courses. A unique aspect of many of our methods is that their associated models are either specific to each course or specific to each student-course tuple. This allows them to identify and utilize the relevant information from the prior courses that are associated with the grade for each course and better address problems associated with the not-missing-at-random nature of the student-course historical grade data. We experimentally evaluated the performance of our methods on a dataset obtained from the University of Minnesota that contained historical grades that span 12.5 years. Our results showed that the course specific models outperformed various competing schemes and that the best performing scheme, which is based on course-specific regression, achieves a RMSE across the different courses of 0.632 whereas the best competing method achieves an RMSE of 0.661. The reminder of the paper is organized as follows. Section 2 introduces the notation and definitions used. Section 3 describes the methods developed and Sect. 4 provides information about the experimental design. Section 5 presents an extensive experimental evaluation of the methods and compares them against existing approaches. Finally, Sect. 6 provides some concluding remarks. Throughout the paper, bold lowercase letters will denote column vectors (e.g., y ) and bold uppercase letters will denote matrices (e.g., G ). Individual elements will be denoted using subscripts (e.g., for a vector y i , and for a matrix g A single subscript on a matrix will denote its corresponding row. The sets will be represented by calligraphic letters.
 The historical student-course grade information will be represented by a sparse matrix G  X  R n  X  m , where n and m are the number of students and courses, respectively, and g i,j is the grade in the range of [0,4] that student i achieved in course j . If a student has not taken a course, the corresponding entry will be missing. The course and student whose grades need to be predicted will be called target course and target student , respectively. In this section we describe various classes of methods that we developed for predicting the grade that a student will obtain on a course that he/she has not yet taken.
 3.1 Course-Specific Regression (CSR) Undergraduate degree programs are structured in such a way that courses taken by students provide the necessary knowledge and skills for them to do well in future courses. As a result, the performance that a student achieved in a subset of the earlier courses can be used to predict how well he/she will perform in future courses. Motivated by this, we developed a grade prediction method, called course-specific regression (CSR) that predicts the grade that a student will achieve in a specific course as a sparse linear combination of the grades that the student obtained in past courses.
 student-course matrix G the set of rows corresponding to the students that have taken c . For each of these students (rows), we keep only the grades that correspond to courses taken prior to course c .Let G c  X  R representing that extracted information, where n c is the number of students that took course c . In addition, let y c  X  R n c be the grades that the students in G obtained in course c (the y c i is the grade corresponding the student in the i th row of G c ). Given this, the CSR model w c  X  R m + for c is estimated as: where w c 0 is a bias term, 1  X  R n c is a vector of ones and  X  ization parameters to control overfitting and promote sparsity. The model is non-negative because we assume that prior courses can only provide knowledge to future courses. The individual weights of w c indicate how much each prior course contributes in the prediction and represent a measure of the importance of the prior course within the context of the estimated model. Using this model, the grade that a student will obtain in course c is estimated as where s  X  R m is the vector of the student X  X  grades in the courses he/she has taken so far.
 to more accurate predictions (see Sect. 5.1 ). In this approach, prior to estimating the model using Eq. 1 , we first subtract from each g c i,j student (GPA is calculated based on the information in G c data for each student and takes into consideration a notion of student bias as it predicts the performance with respect to the current state of a student. Note that in the case of GPA-centered data, we remove the non-negativity constraint on w c . We will refer to this model as the CSR-RC (Row Centered) model. 3.2 Student-Specific Regression (SSR) Depending on the major, the structure of different undergraduate degree pro-grams can be different. Some degree programs have limited flexibility as to the set of courses that a student has to take and at which point in their studies they can take them (i.e., specific semester). Other degree programs are considerably more flexible and are structured around a fairly small number of core courses and a large number of elective courses.
 For the latter type of degree programs, a drawback of the CSR method is that it requires the same linear regression model to be applied to all students. However, given that the set of prior courses taken by students in such flexible degree programs can be quite different, a single linear model can fail to capture the various prior course combinations. In fact, there can be cases in which many of the most important courses that were identified by the CSR model were simply not taken by some students, even though these students have acquired the necessary knowledge and skills by taking a different set of courses. To address this limitation, we developed a different method, called student-specific regression (SSR), which estimates course-specific linear regression models that are also specific to each student.
 The student specific model is derived by creating a student-course specific grade matrix G s,c for each target student s and each target course c from the G matrix used in CSR method. G s,c is created in two steps. First, we eliminate from G any grades for courses that were not taken by the target student. Second, we eliminate from G c the rows that correspond to students that have not taken a sufficient number of courses that are in common with the target student s . Specifically, if C s and C i are the set of courses for student s and i respectively, we compute the overlap ratio (OR) = |C s  X  X  i | / |C s | and if OR &lt;t , then student i is not included in G s,c . The value of t is a parameter of the SSR method and high values ensure that the set of students forming G s,c in common with s and have followed similar degree plans. Given G method proceeds to estimate the model using Eq. 1 (with G and uses Eq. 2 for prediction. 3.3 Methods Based on Matrix Factorization Low rank matrix factorization (MF) approaches have been shown to be very effective for accurately estimating ratings in the context of recommender sys-tems [ 10 ]. These approaches can be directly applied to the problem of predicting the grade that a student will achieve on a particular course by treating the student-course grade matrix G as the user-item rating matrix.
 The use of such MF-based approaches for grade prediction is postulated on the fact that there is a low dimensional latent feature space that can jointly represent both students and courses. Given the nature of the domain, this latent space can correspond to the space of knowledge components. Each course vec-tor is the set of components associated with a course and each student vector represents the student X  X  level of knowledge across these knowledge components. By applying the common approaches of MF-based rating prediction to the problem of grade prediction, the grade that student i will obtain on course j is estimated to be where  X  is a global bias term, sb i and cb j are the student and course bias terms, respectively, and p i and q j are the latent representations for student i and course j , respectively. The parameters of the MF method (  X , sb R n  X  l ,and Q  X  R n  X  l ) are estimated following a matrix completion approach that considers only the observed entries in G as where  X  is a regularization parameter and l is the dimensionality of the latent space, which is a parameter to this method.
 a set of partial observations depends on having a sufficient number of observed entries, and on these entries be randomly sampled from the entries of the target matrix G [ 5 ]. However, in the context of student grade data, the set of courses that students take is not a random subset of the courses being offered as they need to satisfy their degree program requirements. As a result, such an MF approach may lead to suboptimal prediction performance.
 torization (CSMF) approach that estimates an MF model for each course by utilizing a course specific subset of the data that is denser (in terms of the num-ber of observed entries and the dimensions of the matrix). As a result, it contains a larger number of random by sampled subsets of sufficient size.
 their grade for c (i.e., the students in S c have not taken this course yet), the data that CSMF utilizes are the following: (i) the students and grades of the G matrix and y c vector of the CSR method (Sect. 3.1 ), (ii) the students in their grades. This data is used to form a matrix X c  X  R ( n c + n t ) n c is the number of students in G c , n t = courses that have at least one grade in G c or S c . The values stored in X the grades that exist in G c and S c . The last column of X for the course c that were obtained from the students in G all the prior grades associated with the students who have already taken course c and the students for which we need to have their grade on c predicted. Matrix X c is then used in place of matrix G in Eq. 4 to estimate the parameters of the CSMF method, which are then used to predict the missing entries of the last column of X c , which are the grades that need to be predicted. 4.1 Dataset The student-course-grade dataset that we used in our experiments was obtained from the University of Minnesota which has a very flexible degree program. It contains the students that have been part of the Computer Science and Engi-neering (CSE) and Electrical and Computer Engineering (ECE) programs from Fall of 2002 to Spring of 2014. Both of these degree programs are part of the College of Science &amp; Engineering (CS&amp;E) in which students have to take a com-mon set of core science courses during the first 2 X 3 semesters. We removed from the dataset any courses that are not part of those offered by CS&amp;E departments, as these correspond to various liberal arts and physical education courses, which are taken by few students and in general do not count towards degree require-ments. Furthermore, we eliminated any courses that were taken as pass/fail. The initial grades were in the A X  X  scale, which was converted to the 4 X 0 scale using the standard letter-grade to GPA conversion. The resulting dataset consists of 2,949 students, 2,556 different courses, and 76,748 student-course grades. We used this dataset to assess the performance of the different methods for the task of predicting the grades that the students will obtain in the last semester (i.e., the most recent semester for which we have data). For this reason, the dataset was further split into two parts, one containing the students that are still active , i.e., have taken courses in the last semester ( D that contains the remaining students ( D inactive ). D active 19,089 grades, out of which 3,427 grades are for the 475 distinct classes taken in the last semester. D inactive contains 2,073 students and 57,659 grades. These datasets were used to derive various training and testing datasets for the different methods that we developed. Specifically, for the CSR method we extracted the course specific training and testing datasets as follows. For each course c that was offered in the last semester, we extracted course-specific train-ing and testing sets ( D c,  X  k train and D c,  X  k test ) by selecting from D respectively, the students that have taken c , and prior to taken c , they also took at least k other courses. The reason that these datasets were parametrized with respect to k is because we wanted to assess how the methods perform when different amount of historical student performance information is available. In our experiments we used k in the set { 5 , 7 , 9 } . That information will create the grade matrix G c , where g c i,j is the grade of the i th student on the j th course course-specific datasets for different values of k .
 the target students achieved in course c .
 and D c,  X  k test for every course to be predicted after removing the grades that the active students achieved in the courses we want to predict. We formulated the dataset in this way in order to provide the same information for training and testing to all our models.
 set of courses that were also taken by student s and the set of students whose OR with s is at least t . Figure 1 shows some statistics about these datasets as a function of t .
 corresponding dataset, as we consider them to have too few training instances for reliable estimation. 4.2 Competing Methods In our experiments, we compared our methods with the following competing approaches. 1. BiasOnly. We only took into consideration local and global bias to predict 2. Student-Based Collaborative Filtering (SBCF). This method imple-for s in c according to: where nbr is the number of students selected, r is a confidence lower limit for significance weighting,  X  g i is the average grade of the student prior taking c , and sim s,i represents the similarity of target student s with i . 4.3 Parameters and Model Selection For CSR, we let  X  1 take values from 0 to 40 in increments of 2.5 and  X  0 to 50 in increments of 2.5. For SSR, we let  X  1 take values from 0 to 10 in increments of 1 and  X  2 from 0 to 14 in increments of 2. For MF and CSMF, we let  X  take values from 0 to 6 in increments of 0.05. For SSR, the range of the tested values for overlap ratio is 0.3 to 1, in increments of 0.04. For MF and CSMF methods we tested the number of latent dimensions with the values 2, 5 and 8.
 As we could not use cross validation for the SSR, we did not apply it for any regression model, in order to be fair with our comparisons. The best models are selected based on their performance on the test set. For MF based approaches, we used the semester before the target semester to estimate and select the best parameters. 4.4 Evaluation Methodology and Performance Metrics We evaluated the performance of the different approaches by using them to predict the grades for the last semester in our dataset using the data from the previous semester for training.
 We assessed the performance using the root mean square error (RMSE) between the actual grades and the predicted ones. Since the courses whose grades are predicted have different number of students, we computed two RMSE-based metrics. The first is the overall RMSE in which all the grades across the different courses were pooled together, and the second is the average RMSE obtained by averaging the RMSE values for each course. We will denote the first by RMSE and the second as AvgRMSE. 5.1 Course-Specific Regression Table 2 shows the performance achieved by the CSR and CSR-RC models when trained using the three different datasets discussed in Sect. 4.1 . These results show that among the two models, CSR-RC, which operates on the GPA-centered grades leads to considerably lower errors both in terms of RMSE and AvgRMSE. In terms of the sensitivity of their performance on the amount of historical information that was available when estimating these models (i.e., the minimum number of prior courses), we can see that for CSR-RC, the RMSE performance of the models does not change significantly; though the AvgRMSE performance improves when going from five to nine prior courses. This indicates that training sets with more number of prior courses tend to help smaller courses. 5.2 Student-Specific Regression As one of the parameters for this problem was the overlap ratio between the courses of the target student and other students, Fig. 2 presents the behavior of the model X  X  RMSE (left) and AvgRMSE (right) as we vary the overlap ratio increased, the selected students have more courses in common with the target user and that results to better performance. In order to compare the performance of SSR against CSR-RC, Fig. 3 shows the RMSE of the best CSR-RC and SSR models. The RMSE values were computed as the subsets of the test set that was predicted by both models. If the overlap ratio is more than 0.8, then SSR is more accurate. However, the capability of this method to predict courses is very low, i.e., we can predict 50 % less courses than the CSR model for k = 9 when the overlap ratio is more than 0.8, because there are not as many students that had followed the same degree plan as the selected student. 5.3 Methods Based on Matrix Factorization The performance of the methods based on matrix factorization is shown in Table 3 for various number of latent factors. Besides the MF and CSMF schemes that were described in Sect. 3.3 , this table also shows results for a method labeled  X  X F-GB X , which is derived from the MF scheme by eliminating the global bias term (  X  )ofEq. 4 . These results show that CSMF leads to lower RMSE values when there are more than nine prior courses per student, which confirms that by building matrix factorization models on smaller but denser course-specific sub-matrices, we can derive low-rank models that lead to more accurate matrix completion. Even for the case with more than five prior courses, if we focus on denser models, the majority of courses are predicted better by CSMF* than by the best model, MF-GB. In terms of the number of latent factors, we can see that in most cases, the best performance is achieved with small number of latent factors. This should not be surprising, as the average number of grades per student is low, which does not support a large number of latent factors. 5.4 Comparison with other methods Table 4 compares the performance of the baseline approaches described in Sect. 4.2 (BiasOnly and SBCF) with the best-performing course-specific regres-sion method (CSR-RC), and the best CSMF method (two latent factors). In addition, the results labeled  X  X SMF  X   X  correspond to those obtained by CSMF in which the best-performing number of latent factors for each course can be dif-ferent and was selected based on their performance on the validation set (10 % of the training data). CSR-RC and CSMF lead to RMSE and AvgRMSE val-ues that are substantially better than either BiasOnly or SBCF. In terms of the methods that we developed, we see that CSR-RC consistently outperforms CSMF, suggesting that sparse linear regression methods are better than those based on matrix factorization for this setting. Finally, comparing the perfor-mance of CSMF  X  against CSMF, we see that even though the former achieved better performance, the difference is not very large, which suggests that CSMF X  X  performance is more consistent across its different model parameters. In this paper, we presented two course-specific approaches based on linear regres-sion and matrix factorization that perform better than existing approaches based on traditional methods. This suggests that focusing on a course specific subset of the data can result in more accurate predictions. A student-course specific approach was also developed but its accuracy in grade prediction is limited by the diverse nature of degree plans. The course-specific regression was the one with the best results compared to any other method tested.

