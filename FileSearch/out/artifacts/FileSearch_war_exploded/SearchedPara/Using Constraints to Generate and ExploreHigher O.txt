 Given a transaction data set where the transactions have class labels, discrimi-native pattern mining looks for association patterns that occur more frequently in one of the classes than the others. Although such patterns may not cover all the transactions in a data set, they can provide useful classification rules if the discrimination provided by the patterns is accurate enough for the application under consideration. One potentially useful area for discriminative patterns is medical studies that involve a set of subjects that are divided into cases (those with a specific disease) and controls (those without the disease). In such situa-tions, any discriminative patterns that a re discovered can help identify important factors in the disease and/or its development. The discovery of such biomarkers is often of great benefit.

However, finding such patterns is challenging because higher order combinations of individual variables may show high discrimination even when sin-gle variables or lower-order combinations only show little or no discrimination. To are the logical and of the indicated variables. The last row in the table shows the difference in the occurrence of ones between cases and controls. All single variables, and the pairs they form, show no discrimination between cases and controls, but the combination of all three variables does. If ones indicate the presence of a partic-ular genetic characteristic, then this ma y indicate, for example, that the presence of all three genetic factors is necessary for the development of a disease.
It is easy to construct examples of such patterns involving only two variables, e.g., let both variables have 5 ones in both cases and controls, but let the ones in the two variables overlap completely in cases and not at all in controls. However, it becomes more challenging for patterns of size 3 and higher. There may even be some question about the existence of such patterns. Examples of higher order patterns that have better discrimination than any lower order pattern composed of the same variables can indeed be found for sets of variables beyond 3, although as later discussion will show, the difference between the discriminative power of a combination of binary variables and its subpatterns decreases as the number of variables increases. 1 To address such fundamental questions concerning the nature of discriminative patterns and provide patterns for testing the perfor-mance of current discriminative pattern finding algorithms, this paper proposes a constraint-based approach to specifying and generating such higher order pat-terns. In the rest of the paper, higher order pattern will refer only to those higher order patterns having more discriminative power than any of their subsets.
Although there are synthetic data generators for ordinary association pat-terns, such as the IBM Quest Market-Basket Synthetic Data Generator described in [1], we know of no such generator for the higher order discriminative patterns we have been discussing. However, during the course of our research into algo-rithms on discriminative pattern mining, we encountered the need for such a capability. As a result, we developed the constraint based approach described in this paper. More specifically, we realized that such patterns can be defined using mathematical constraints which are then solved with widely available software that uses linear programming techniques (or extensions of it) to find solutions to resulting optimization problems. Despite the challenges in creating the proper models and limitations on the size of patterns it is feasible to produce, the de-sired example patterns can usually be generated (often in a relatively short time, i.e., usually seconds or minutes) for patterns up to size 9 or 10. 2
The insights that can be gained into the nature of higher order patterns are, however, perhaps even more important than generating higher order discrimina-tive patterns for testing discriminative pattern finding algorithms. For instance, through experimental runs and theoretical analysis, we explore the maximum discriminative power that can be expect ed of a higher order pattern for differ-ent numbers of variables. In addition, this work has resulted in a formulation of the pattern generation problem in terms of the selection of rows from a truth table. This formulation is more efficient and provides deeper insight into the process of creating higher order patterns than the formulation obtained from a straightforward translation of the desired pattern characteristics into mathemat-ical constraints. It also makes it easy to define patterns other than just those based on the conjunctive logic used by traditional association and discriminant pattern analysis. For example, it is possible to define a pattern that is present if j out of the k variables have a value of 1. It is also possible to impose additional constraints on the patterns to further tailor them to specific needs. Overview: In Section 2 we begin with a more formal definition of discriminative patterns and of the DiffSup measure that is used to evaluate the discriminative power of such patterns. Section 3 presents the basic approach to pattern specifi-cation and generation, while Section 4 describes a more powerful approach that is more efficient and more general. Experi mental results are presented in Section 5, and more formally analyzed in Sectio n 6. Section 7 summarizes the paper and the areas for future work. This section provides a formal description of discriminative patterns and the DiffSup measure that is often used to measure the discriminative power of a binary variable or a set of binary variables. This is followed by a brief overview of previous work in discriminative pattern mining. As mentioned, we are not aware of previous work in generating synthetic discriminative patterns. (Again, we are only considering those patterns whose discriminative power is greater than that of any subpattern.) 2.1 Definitions Let D be a binary transaction data set consisting of m transactions, each of which is a subset of n possible items. D can be represented as a binary data matrix, where each item is a binary variable (column of the matrix), each trans-action is a row, and the ij th entry is 1 if transaction i has item j . For instance, the transactions (rows) could be subjects in a medical study, while the binary variables (columns) represent the presen ce or absence of various genetic features in a subject. In many cases the transactions are divided into classes, e.g., cases (those subjects with a condition) and controls (those without). Without loss of generality, we only consider discriminative patterns for the binary class problem. An extension to multiple classes is described in [2].

Assume there are m = m A + m B transactions, where m A is the number of cases and m B is the number of controls. Instead of viewing an itemset, X ,asasetof items, we will find it more convenient to use an equivalent representation in which the itemset is represented as a logical conjunction of Boolean variables, i.e., as X = x i 1 x i 2 ...x i k ,where x i j is the Boolean variable associated with the j th item. Let support count A ( X )and support count B ( X ) be the number of transactions for which X is true in classes A and B , respectively. Then, the relative supports of X in classes A and B are defined as RelSup A ( X )= support count A ( X ) m
DiffSup , which was originally defined in [2] is the absolute difference of the relative supports of X in classes A and B .
 An itemset, X ,is r  X  discriminative if DiffSup ( X )  X  r . The goal of discrimina-tive pattern mining is to discover all patterns in a data set with DiffSup greater than or equal to r . However, higher order pattern s are not useful or interesting unless their discriminating power is greater than the discriminating power of their subpatterns.
 Other measures of  X  X oodness X  for discriminative patterns are sometimes used. For instance, instead of taking the difference of relative support, an alternative measure of discriminative power, the Growth Rate , can be defined as the ratio of the two supports [4]. Other variations include information gain [3], the  X  2 -test [2], the Gini index [13], the odds ratio [13], and various other measures [12]. These discriminative measures are generally not anti-monotonic as shown by [4,2,3], a fact that poses significant challenges both for pattern finding and generation. It is possible that our approach could be used to generate higher order patterns for some of these other measures, but we have not yet explored that possibility. 2.2 Previous Work in Discriminative Pattern Mining Discriminative patterns have been invest igated by a number of researchers, some-times under other names. Dong and Li [4] define emerging patterns (EP) as itemsets with a large growth rate (support ratio) between two classes. Emerging patterns have been extended to several sp ecial cases such as jumping emerging patterns [9] and minimal emerging patterns[11,10]. In [2], contrast sets (CSETs), were proposed as another possible formulation of discriminative patterns and an algorithm to mine them, CSET, was presented. In [8], contrast set mining was shown to be a special case of rule learning, where the contrast set is the antecedent of a rule whose consequent is a group. As mentioned above, vari-ous statistical discriminative measures have also been studied for discriminative pattern mining. There has also been r ecent work on the efficient discovery of low support discriminative patterns from dense and high-dimensional data sets [6]. Another approach [5] builds a decision tree with frequent patterns at each decision node that partition the data set into successively purer subsets. The starting situation is a set of k binary variables which take on some assign-ment of zeros and ones (truth values) for a set of m A cases and m B controls in asetof m = m A + m B subjects. The goal is to find one or more assignments of values to the variables that maximizes the DiffSup of the combination of all variables, while ensuring that the DiffSup of lower order combinations is less than a specified limit. A more formal definition is provided below.
 Problem Statement: Find an assignment of truth values to m instances ( m A in cases, m B in controls) of the variables, x 1 ,x 2 ,...,x k , that satisfies the following objective and constraints: maximize DiffSup ( x 1 x 2 ...x k ) subject to DiffSup ( x i 1 x i 2 ...x i j )  X  limit ,where1  X  j&lt;k This statement of the problem combines constraint satisfaction with optimiza-tion. Generating solutions for just the constraint portion of the problem would typically yield size k patterns whose DiffSup is less than that of their subpatterns and thus not interesting.

This type of constrained optimization problem, although simply stated, needs to be translated into a practical optimization model. For this purpose, we chose AMPL (A Modeling Language for Programming) [7].  X  X MPL is a computer language for describing production, distribution, blending, scheduling and many other kinds of problems known generally as large-scale optimization or mathe-matical programming X  and has a long history of use in the optimization com-munity. Although we used a commercial implementation of AMPL, along with the IBM ILOG CPLEX Optimizer as a sol ver, there are non-commercial ver-sions of AMPL (or AMPL subsets) available. For instance, GLPK (GNU Linear Programming Kit), may also provide a suitable platform for solving the problem posed above. However, we have not tried our examples on GLPK.

A key problem in the translation, and indeed, in the solution of this problem is the fact that the satisfaction of the constraints and maximization of the objec-tive depend on the combinations of all variables. This poses at least two major challenges. First, the number of the combinations is 2 k  X  1, where k is the num-ber of individual variables. Thus, the number of constraints grows exponentially with k . However, for pattern sizes of 10 or less (1023 combinations or less) we found this manageable.

The second challenge arises because the values of the combinations are, of course, functions of the variable values being sought. This functional relationship needs to be specified either implicitly or explicitly. When an implicit approach is used, the AMPL model file requires (1) defining a variable for each combination, 7 in all, and (2) defining constraints for each of the combinations. This approach generates a higher order pattern with the desired properties, but the model file rapidly increases in size. Although this file could be generated automatically, we also discovered that the solver was having difficulty producing a solution once we got to five variables. Thus, although this representation provides a relatively direct translation of the problem statement given above, it is not as compact or efficient as the approach des cribed in the next section. Given the limitations of the previous solution, we sought a new formulation that would provide a more flexible and efficient approach to specifying and generating higher order patterns, as well as providing deeper insight into the nature of higher order patterns and the ability to specify patterns other than those involving logical and .

The approach is the following. For k variables, define the truth table that gives the possible values of the variables and all the combinations of variables up to size k . For now, the combinations are assumed to be logical and . For example, a truth table for 3 variables and its combinations is shown in Table 2. The same constraint problem is solved, but the constraint solution is transformed into one of selecting, m A rows for cases and m B rows for controls, from the 2 k rows of the truth table, so that the constraints given in the problem statement above are satisfied. In this approach, the relationships between the combinations of variables and individual variables are defined explicitly and do not need to be specified as constraints. As a result, the solver has far fewer constraints to handle and runs (in our experience) far more quickly.
The model file is also much simpler and does not need to be changed as the number of variables changes. Figure 1 shows the new AMPL model file. This file is much smaller than the model file for the original approach (which is not shown in order to save space) and is not specific to any number of variables. This approach is also more flexible than the original one in several ways. First, variable combinations can be defined to be something other than logical and without changing the model file. For instance, we could define a combination of size k to be 1 if at least k  X  1 of the variables are 1. This is not to say that any truth table that can be created will be meaningful or even have a feasible solution. Second, we could choose to only use some of the rows of the truth table. Again, this may not yield a feasible solution. However, for example, it is possible to omit the 0 row (i.e., the assignment of zeros to all variables) and still obtain solutions, sometimes with a similar value of the objective function. 3
Admittedly, this approach also has a number of limitations. The table grows in size exponentially as the number of variables increases. The number of con-straints that must be solved by the solver, although fewer than in the previous approach where combinations were defined via constraints, is still exponential in k as well, specifically 2 k  X  1. (There is no escaping that unless the problem statement is changed.) In practice, we found that for a larger number of vari-ables (9 or 10), larger numbers of cases and controls (200 or more), and smaller limits on DiffSup (0.3 or less) the solver either ran out of memory (we were using 32 bit AMPL and CPLEX) or took so long to run that we stopped the job. Nonetheless, most of the other cases ran in very little time, i.e., just a few seconds or minutes.

For both approaches, it is possible to add additional constraints. For instance, we used this algorithm plus a few additional constraints to generate the spe-cialized discriminative patterns found by the algorithm described in [6]. This algorithm finds only a subset of discriminative patterns, but can find patterns missed by other discriminative mining algorithms. By specifying and generating these patterns, we gained a better understanding of the types of patterns this algorithm discovers or misses. This section presents experimenta l results that show how the optimal DiffSup value that is found varies with the DiffSup limit for the subpatterns, the number of variables, and the size of the data set, i.e., number of cases and controls. To show this for both balanced and unbalanced data sets, we used six cases. For both unbalanced and balanced data sets, m A took the values 10, 25, 50, 100, 200, and 250. For unbalanced data sets m B was double, while for balanced data sets it was, of course, the same. We summarize the results and present a few plots that support our summary.

First, the optimal DiffSup valuedoesnotvarymuchwiththesizeofthedata set for a fixed limit and number of variables. Intuitively, once the data set is large enough to achieve a certain pattern, this pattern can be repeated multiple times for larger data sets. This is true for both balanced and unbalanced data sets. This is illustrated in Figure 2 for a balanced data set with 5 variables which shows the optimal DiffSup values across different DiffSup subpattern constraint levels and numbers of cases. Because of this lack of variation, we illustrate the rest of the points we want to make by using data sets with m A = 50.

A minor point is that the optimal DiffSup value sometimes decreases slightly as m A increases from 10 to 25, e.g., for limits 0.3 and 0.5. As we will see in the next section, reducing the DiffSup values of subpatterns less than size k while maximizing the DiffSup of the size k pattern requires adding a certain number of records in cases and controls to  X  X alance out X  the occurrence of the subpatterns of size less than k . Intuitively, this is more difficult when the data set size is small. Our conjecture is that for 5 variables data sets of size 10 and 25 are both too small to perform this balancing process as well as in larger data sets, but that the balancing works more efficiently for a data set of size 10 than for a data set of size 25. However, a formal a nalysis is needed to confirm this.
The second major observation is that for a given limit and data set size, the optimal DiffSup value decreases as the number of variables increases. This is not surprising, since intuitively, there are far more constraints to be satisfied as the number of variables increases. (Recall the number of constraints is 2 k  X  1.) This is shown for both the balanced and the unbalanced cases by figures 3 and 4. These figures also show that the optimum attained in an unbalanced data set is often less than that of the corresponding balanced set, at least for smaller values of the limit. Also note that for both balanced and unbalanced, the DiffSup optimum does not change much once 9 or 10 variables are reached. Note that the results for 10 variables are shown as a dashed line, while the results for 9 variables are shown just as orange crosses, without any accompanying line. It is possible, at least in some cases, to perform a more formal analysis of this approach to determine the optimal DiffSup as the number of variables increases. We briefly sketch this approach for limit = 0 and balanced data sets. The approach is to fill out the m rows of the data file one by one. We begin by putting a row consisting of all ones in the cases. Every combination, including that of k variables, has the value 1. To achieve the goal of maximizing the DiffSup for the size k combination, while maintaining every other combination with a 0 DiffSup , it is necessary to add rows to cases and controls that  X  X ancel out X  all other combinations.

We begin by canceling out the k k  X  1 = k subpatterns of size k  X  1. This can be done by adding, for each such subpattern, the row from the truth table that contains a 1 for that pattern. For example, if k = 3, then there are 3 pairs of variables. Rows 4, 6, and 7 of Table 2 are the rows in the truth table that will cancel the net occurrence for th ese pairs when placed in controls. This accomplishes the goal that the DiffSup of the pairs is 0. More generally, canceling out the k subpatterns of size k  X  1 requires that k rows be added to controls.
However, doing this increases the occurrence of the size k  X  2 subpatterns in controls by 2. Each k  X  1 subpattern contains k  X  1 k  X  2 = k  X  1 subpatterns of size k  X  2. Thus, when k = 3, pairs contain two individual subpatterns of size 1 (which is obvious). Since there are k k  X  2 = k ( k  X  1) / 2 patterns of size k  X  2, the total occurrence in controls of a k  X  2 size pattern from the k rows just added is k ( k  X  1) / ( k ( k  X  1) / 2) = 2. More generally, adding these k rows increases the occurrence in controls of size k  X  i patterns, 1  X  i  X  ( k  X  1), by i . (Proof omitted.) For instance, when k = 3, pairs have an occurrence in controls of 1 and individual variables have an occurrence of 2.

Thus, some rows need to be added to cases to cancel out the excess count that was added to controls. This can be done by adding k k  X  2 rows from the truth table, where these rows all have a value of 1 for a particular k  X  2 size pattern, but do not have a 1 for any higher level pairs. While this reduces the DiffSup of all the k  X  2sizepatternsto0,size k  X  3 patterns now have a excess count of 1 in cases. This process continues, adding k k  X  i patterns of size k  X  i alternately to cases and control until k rows corresponding to individual variables are added to either cases or controls.

Thus, adding one row of all ones to cases requires adding many rows to both cases and controls to achieve 0 DiffSup in the subpatterns. It is possible to compute how many rows are added to cases and controls and then to compute the value of DiffSup for the size k pattern. m A = k i , i = k, k  X  2 ,..., 2 or 1 depending on whether k is even or odd, respectively, and m B = k i , i = k  X  1 ,k  X  3 ,..., 1 or 2 depending on whether k is even or odd, respectively. These values will differ by 1 and thus, to get the DiffSup of the patterns to actually cancel will require adding the row consisting of all zeros from the truth table to either cases or controls to make the data set balanced. This represents the best solution (proof omitted) for limit = 0 and thus constitutes an upper bound.

Table 3 shows the number of rows this pr ocess generates in cases and controls for each variable size (omitting the one zero row that must be added to balance the data set). This table also shows the maximum DiffSup attainable. We can make some observations (which can be more formally proven), e.g., that the m appears to hold for the unbalanced data results shown in Figure 4. This result could be used as the basis for a simple algorithm that creates optimal size k patterns for limit = 0 and balanced data sets that are multiples of size 2 k .
Although this analysis is interesting and yields some useful insights, much more analysis is possible and could well yield equally interesting results. We have presented a constraint based approach for generating higher order com-binations of individual variables which may show high discrimination even when the single variables or lower order combinations little or no discrimination. The basic approach quickly lead to a new approach based on building a data set by choosing rows from a truth table. This formulation provides more insight into the process of creating higher order patterns than does the formulation obtained from a straightforward translation of the desired pattern characteristics into mathematical constraints, as was demonstrated by the derivation of an upper bound for the DiffSup of a size k pattern for a balanced data set and limit =0. It also allows for the easy definition of patterns other than just those based on the traditional conjunctive logic used by traditional association and discrimi-nant pattern analysis. Experimental res ults and formal analysis were presented to give insight into the behavior of higher order patterns.

There are many directions worthy of further investigation. First, there are many aspects of the results presented here that remain to be addressed. One is establishing bounds on the DiffSup of size k patterns for different types of data sets, different numbers of variables, and different limits. We plan to investigate alternative approaches for analyzing the problem that may provide such answers more readily than the two approaches presented in this paper. Another task is to investigate truth tables that reflect types of logic other than logical and or that require solutions that don X  X  involve a row of all zeros. Finding larger sets of solutions, even if slightly suboptimal, might also be useful since the goal is to generate different types of discriminative patterns. Along similar lines, we could subject different subpatterns to different constraints. We could also explore other types of solution methods, either other constraint based methods or non-constraint based methods. It is even conceivable that a thorough analysis could produce a non-optimization based algorithm for generating higher order discriminative patterns. It would be especially interesting to investigate if the insights that arise from our work can lead to new or improved discriminative pattern mining algorithms. Yet another significant challenge is to investigate other measures of discrimination .

