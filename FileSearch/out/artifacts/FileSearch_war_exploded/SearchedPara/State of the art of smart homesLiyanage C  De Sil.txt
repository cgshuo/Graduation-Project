 1. Introduction
Humans interact with the environment that surrounds them, in numerous ways. They perceive the environmental conditions and act, react or adjust accordingly. If the environment can be made to reciprocate this behavior and respond to human beha-vior, it will lead to several advantages. Such behavior can auto-mate various tasks that humans have to perform manually, and also provide novel services and facilities. A smart home is a home-like environment that possesses ambient intelligence and auto-matic control, which allow it to respond to the behavior of residents and provide them with various facilities.

Thestandardapproachforbuildingsmarthomesisto computerize them. A set of sensors gather different types of data, regarding the residents and utility consumption of the home. Computers or devices with computing power (e.g.,: micro-controllers) analyze these data to identify actions of residents or events . They then respond to these actions and events by controlling certain mechan-isms that are built in to the home. A simple example for such smart behavior is turning the lights on when a person enters a room.
However, more complicated tasks such as detecting if an elderly resident is alone and not feeling well are also desired.
Smart homes have been researched for nearly a couple of decades. The pioneering work in this area are the Smart Rooms implemented by the MIT Media Lab ( Pentland, 1996 ). Thereafter, several researches have investigated this topic with a wide range of prospective applications. At the current state, there are many types of smart homes with three major application categories.
The first category aims at providing services to the residents by detecting and recognizing their actions or by detecting their health conditions. Such smart homes act as information collection testbeds to support the wellbeing of the residents of the home. These smart homes can be further divided into three types; smart homes that provide eldercare, smart homes that provide health-care and smart homes that provide childcare.

The second category of smart homes aims at storing and retrieving of multi-media captured within the smart home, in different levels from photos to experiences. One might argue that the issue of privacy of such type of information collection, but it will be a matter of acceptance in to one X  X  lifestyle with time.
The third category is surveillance, where the data captured in the environment are processed to obtain information that can help to raisealarms,inordertoprotectthehomeandtheresidentsfrom burglaries, theft and natural disasters like flood etc. A few researches attempted to combine these functions into one smart home.
Apart from the 3 types of smart homes we have discussed there is an emerging trend of a special type of smart homes which can help the occupants to reduce the energy consumption of the house by monitoring and controlling of the devices and rescheduling their operating time according to t he energy demand and supply.
With recent advances in electronics and computing, sensing technologies and computing power required to implement a smart home is now available in small sizes, low prices and energy efficiency. However, providing the ambient intelligence that is required to make decisions for smart behavior is still a challenging task. Human behavior at home is highly unstructured. Multiple sensory modalities are required to sense such behavior. Advance pattern recognition techniques are required to recognize the beha-vior of multiple residents. Privacy becomes an important issue once the systems store the data. Due to such challenges, smart room technologies at the current state are far from being matured.
This paper surveys the state of the art of smart home technol-ogies. It organizes related researches as follows. Before going into specific application categories we w ill first look at different techni-ques used in smart homes namely ; video based techniques, audio based techniques and multimodal techniques. Section 2 outlines video based techniques for human activity detection in smart environments. Section 3 covers audio-based techniques. Section 4 investigates how to combine multiple sensory modalities to recog-nize actions and events that take place in a smart home. Thereafter we will look at specific applications of smart homes. First in Section 5 we will look at smart homes applications for eldercare and childcare. Then in Section 6 we look at the energy efficient smart homes and Section 7 investigates research directions on Multimedia
Retrieval for Ubiquitous Environm ents. We conclude the paper with a brief discussion on the state of the art, and suggestions for future research directions. 2. Video-based techniques in smart homes
Video is highly prospective as an input modality for smart homes, due to its non-intrusive nature and rich information content. However, its use in a home-like environment has been sometimes questioned and argued about, due to privacy concerns.
Despite such concerns, research on vision-based activity detection in smart environments has been growing rapidly.

Many types of vision-based systems for surveillance and monitor-ing of closed environments have been described and built over the past ( Harper, 2003 ). Henry Tan and De Silva (2003) , Tan et al. (2003 ) has proposed a simple technique for human activity recognition using head movement detection. Smart environments are an immediate application of human activity detection. Alex Pentland X  X  research group at MIT Media Laboratory designed a smart room in 1991 (Pentland). This has evolved from its initial design to its matured state of five networked smart rooms in the United States, Japan and the
United Kingdom. These rooms use several machines, none more powerful than a personal computer, to identify the location, identity, facial expression and hand gestures of the persons in the room. Few more related research can be found in ( Bobick ; MIT ). Systems based on single or multiple cameras, both stationary and moving, have been designed and implemented for automatic detection, tracking and recognition of humans and their actions ( Vadakkepat et al., 2008 ).
In the paper ( Utsumi et al., 1998a , b ) the authors propose a system that analyses image sequences from multiple stationary cameras, acquired from a particular scene, to detect humans and their actions, and index the sequence according to these activities.
The image sequences are indexed using the results for faster searching. Key frames are extracted from the image sequences for each entry in the index, to facilitate visual inspection without browsing the image sequence. In addition to the index, visualiza-tions of motion paths for humans in the scene are created to provide a faster way of tracking human movements in the scene.
A camera based detection approach is given in Kainka (2003) where it involves a single camera tracking a number of people.
The system works by extracting points and identifying feature points from an image, creates a path and clusters them and finally each of these clusters corresponds to a person. The W 4 : Who?
When? Where? What? ( Haritaoglu et al., 1998 ) technique relies on the system to solely identify a combination of shapes and sizes from the image segmentation of the monochromatic imagery to identify a subject X  X  presence and its interaction and time. The system in ( Utsumi et al., 1998a , b ) uses multiple cameras to detect human motion by selecting the best viewpoints of the images to extract a maximum amount of information on the individual or multiple amounts of individuals. The results of the system are reconstructions of the human position, normal axis and body size. 2.1. Video sensor-based event recognition
In the paper ( De Silva et al., 2006 ) the authors use a state-based approach to recognize events and actions. The state diagram in Fig. 1 shows the transitions between states defined for a tracked human in the image sequence. Table 1 summarizes the rules for the state transitions.

In order to execute the various actions in the above state diagram the authors detect and track humans entering the environment. Each human entering the smart room is modelled using the detected location and motion parameters. These para-meters are buffered over a window of 10 seconds and validated against a set of decision rules to detect state transitions ( Table 1 ). 2.2. Performance evaluation of tracking using video sensors
Although tracking is an intermediate step in any activity detection system, there is no immediate method for evaluation.
In the paper ( De Silva et al., 2006 ) the authors use 20 image sequences for evaluating the performance of tracking. The results are compared with ground truth for quantitatively estimating the accuracy. On the other hand, ( de Silva, 2003 ) qualitatively evaluate their system based on user studies by residents. 2.3. Detection of unusual events and actions
It is possible that actions or events that are important to be recorded, but not specified by the rules, take place. For example, there can be a situation where a person trying to block the camera. In the paper ( De Silva et al., 2006 ) the authors keep an index to such an action as  X  X  X nrecognized X  X  to facilitate human observation to recognize the action at a later stage. If the amount of scene change occurring between two frames is substantial and the action/event cannot be recognized, the scenario is identified as an unrecognized event. Key frames showing the scene change are extracted from the image sequence.

Falling is an another unusual event that need to be investi-gated in a smart home that cater for elderly since a sudden fall can lead the person into life threatening situations. In the paper ( De Silva, 2008e ) the author describes the method of detection of such an event using a video sequence ( Fig. 2 ). 3. Audio-based techniques in smart homes
Video sensor based event detection approach has some shortfalls like it fails to cover the entire room and also event non-detection due to occlusion. Hence some authors have pro-posed audio sensor based methods for actions detection ( De Silva, 2008e ). In his paper for the separation of cough, cry and shout (vocal track generated sounds) from walk, door-open and fall (non-vocal sounds), they use pitch contour detection. This is due to the fact that vocal track generated audio signals consists of its inherent formant frequency component. They proposed a method of detecting walking action using audio signals. Events like door open and walking had been separated by using the audio intensity profiles. According to the authors of the paper walking has its inherent property of gradual increase of the intensity profile till the steps are getting closer to the microphone and then gradual decrease when walks past the microphones while the door opening is one off high pitch isolated and localized sound.
Also they combined the falling audio activity with the video based falling detection to get a higher accuracy.

Different types of events can be recognized by processing audio signals captured within a smart home. Smeaton and
McHugh (2005 ) demonstrated that a network of microphones can detect audio events that can significantly summarize a video collection from multiple cameras. The inference of this statement is that in order to extract vital information for video summariza-tion, audio events can be used as they are connected in the time domain up to some extent. Hence it is somewhat easier, for example, to follow the stepping sound of a child in a house to extract the video clips where the child is walking from room to room. In order to track the child only using video information the field of view of cameras should be overlapping. But with the use of network of microphones one can bridge the gap very easily. The
Human Speech Home Project of MIT ( Roy et al., 2006 ) investi-gated how continuously captured audio in a smart home can be used for media retrieval, early language learning, and several other applications.

A home is an environment with a number of rooms that are connected to each other, directly or indirectly. The degree of connectivity can change with opening and closing of doors. These conditions make sound source localization a prerequisite for multiple source audio analysis in a smart home. Different researches employed different techniques for this task ( Rui and
Florencio, 2003 ); Microphone arrays ( Chen et al., 2005 ) and beam-forming ( Hoshuyama et al., 1999 ) are common approaches.
Bian et al. (2004 ) employed sound source localization followed by classification to infer activities inside a smart home. Liu and Wan (2001 ) demonstrated the use of time-domain audio features with supervised learning for multi-class audio classification Fig. 3 . 4. Multimodal-based techniques in smart homes
In their paper ( Vadakkepat et al., 2008 ) addressed a scenario where a robot tracks and follows a human using multimodal techniques. The use of multimodality is to improve the accuracy of detection and tracking. A neural network is utilized to learn the skin and non-skin colors of the human in the room. The skin-color probability map is utilized for skin classification and morphology-based preprocessing. In addition to the visual cues, the tracking process considers 16 sonar scan and tactile sensor readings from the robot to generate a robust measure of the person X  X  distance from the robot. The robot thus decides an appropriate action, namely, to follow the human subject and perform obstacle avoidance. Heuristic rule is used for face-ratio analysis and Bayesian cost analysis for label classification.

Let us look at the research work related to audio-visual based approaches for human activity detection in smart homes. There are some audio-visual based attempts for human emotion recog-nition ( De Silva et al., 1997 ; De Silva and Miyasato, 1998 ; De Silva, 2004 ) which can support smart home activities as a background processing mechanism. An excellent survey of audio and video based multimodal affect recognition can be found in Zeng et al. (2009) . There have also been some attempts to use audio-visual sensors for human activity detection in the context of smart homes ( De Silva, 2008e ).

Some researches combined data from multiple sensors other than audio or video sensors, to improve the accuracy ( Demongeot et al., 2002 ; Brooks et al., 2003 ; Beigl et al., 2004 ; Petrushin et al., 2006 ; Chana et al., 2008 ).

In the next three sections we will look at specific applications of smart homes. Either one or a couple of the three techniques we have discussed in the previous three sections, audio based, video based or multi-modal are being used to achieve these specific application goals. 5. Smart homes for eldercare
Smart homes for eldercare applications are growing at a very fast phase in all parts of the world. One main requirement of such applications is the human detection and activity classification. The necessity for the development of human detection methods in the field of modern Home-care and security systems has become very popular and essential. There are many techniques currently being used for human detection using many different kinds of sensory information. It is necessary to detect the presence of the human in advance before processing the human activities such as falling, standing or walking etc. ( Kainka, 2003 ).
In Elliott et al. (2009) the authors described an experiment that extends the distributive sensing approach to identify the three-dimensional location of an object in constant motion that can be applied to human activity detection in a smart home.
Distributive sensing has previously been used in the identification of size and location of statically placed objects. Here, in their paper they propose a novel system to measure balance or sway of a human. They presented an experimental set-up which consisted of a pendulum structure positioned on a supported steel plate.
Three low-cost deflection sensors were positioned under the plate with the resulting signals used as inputs to a neural network implemented on a field-programmable gate array. The results showed that the embedded system can accurately track the pendulum position in real time with a mean tracking error of around 6% in all three dimensions. This evidence indicated that their technique is sufficiently sensitive and could be implemented in a pragmatic configuration for discriminating between balance and sway, which can be used to detect fall of an elderly in a smart home environment just before it happen.

There are numerous Smart Home projects that intend to make daily life comfortable ( Demongeot et al., 2002 ; Ogawa et al., 2002 ;
Pereira et al., 2006 ) Aware Home Project ( Abowd et al., 2002 ) for supporting elderly residents. Basic activities such as opening and closing of doors was recorded using switch-based sensors ( Ogawa and Togawa, 2000 ). Numerous types of sensors are used for tracking and detection of the persons and recognize their activ-ities. Use of cameras and image analysis for this purpose is common. In Easy Living Project ( Brumitt, 2000 ; Krumm et al., 2000 ) and Intelligent Space ( Lee et al., 1999 ), the positions of humans are detected using multiple cameras. However, alterna-tive methods such as Radio Frequency Identification (RFID) tags ( Juels, 2006 ), optical tags ( Kainka, 2003 ) and Infra-red based motion sensors ( Moore, 1999 ) have been used where image acquisition and analysis is not possible due to issues such as privacy, disk space, and computational cost.

Human detection techniques at present can be either video based or any other sensor based. Sensor based detections are such as ( Ogawa and Togawa, 2000 ; Ogawa et al., 2001 ; Lim and
Kriegman, 2004 ) where infrared sensors and carbon dioxide sensors are used to detect motion and magnetic sensors are utilized to detect the opening and closing of doors. An illumina-tion sensor is a type of sensor where once the subject is present, the sensor relies on changes in the environment caused by the subject to trigger a chain of events in the circuit. A more fascinating approach is a system called Cenwits ( Huang and
Mishra, 2005 ). Connection-less Sensor-Based Tracking Using Wit-nesses. This is a mobile system that emits a signal from time to time using RF communication. When two of these mobile sensors are close to each other, information is gathered such as time and location at that time of the subject carrying the sensor and finally all information is dumped at an access point. This system would be useful for application in a large area where it being necessary to keep track of individuals.

The paper by You et al. (2008) has two goals, one is elder care and the other is childcare support. AIST Japan under their
Digital Human project had built a Smart home for child accident prevention (AIST). 6. Smart homes for energy efficiency
In recent days we can find there are a growing number of new research proposals and findings in related to new and alternative energy technologies. However there are many easy and cheap ways to reduce energy use at our homes by efficient energy management. Most of these simply require a change in behavior of the occupants of the home. In the paper ( Lach et al., 2007 ) the authors proposed an automatic monitoring system to reduce the energy usage of a typical home by using WIFI technology enabled smart switches. Fig. 4 shows the GUI of the presented prototype system. In their project they were looking ahead to enhance this technology by adding different types of sensors to enhance the automatic monitoring and control of the environment according to the user preference based on their profiling.

In the paper by Reinisch et al. (2011 ) in their Think Home ( Fig. 5 ) they looked into the use of a multi-agent technique to reduce the energy consumption in a house. Their work puts its focus on alleviating the current problems by proposing a com-prehensive system concept that ensures the smart homes can keep their promise in the future. The system operates on an extensive knowledge base that stores all information needed to fulfill the goals of energy efficiency and user comfort. Its intelli-gence is implemented as and within a multi-agent system that also caters for the system X  X  openness to the outside world. They propose several agents such as Global goal agent, Control agent,
User agent, Auxiliary data agent, and Interface agent etc. to execute the system. Different agents contain and provide intelli-gence regarding aspects such as user preferences, auxiliary data, and control parameters. 7. Multimedia retrieval for ubiquitous environments
Automated capture of experiences taking place at home is interesting owing to a number of reasons. Home is an environment where a variety of important events and experiences take place.
Some of these, such as the first footsteps of a child, provide no opportunity for manual capture. Some others are so important that humans do not want to keep themselves out of the experience to shoot photos or video. A corpus of interactions and experiences at home can provide valuable information for studies related to the design of better housing, human behavior, etc. Other prospective applications include assistance for elderly residents and aiding recollection of things that were forgotten.

Both capture and retrieval of experiences in a home-like environment is extremely difficult due to a number of reasons. Even the simplest and the smallest of the houses are partitioned into a number of rooms or regions, making it necessary to have a large number of cameras and a fair number of microphones for complete data capture. Continuous recording of data from these devices, to ensure the capture of all important experiences, results in a very large amount of data. The level of privacy differs at different places of a house, and sometimes certain regions are shared only among certain residents.

The most difficult problems, however, arise during retrieval and summarization of the captured data. Content captured at home is much less structured compared to that from any other environment. Queries for retrieval could be at very different levels of complexity, and the results can be in various levels of granularity. Some examples are shown below (as of de Silva (2007 ):
Show the video from the camera near the entrance to the living room, from 8:30 pm to 9:00 pm, on the 1st of February, 2005.

What was our child doing between 5:30 and 6:30 pm yesterday? On which date did Jeff visit us last month?
How did the strawberry jam that I bought last week finish in 4 days?
Given the large content and the state of the art of content processing algorithms, multimedia retrieval for ubiquitous envir-onments based solely on content analysis is neither efficient nor accurate. Therefore, it is desirable to make use of supplementary data from other sensors for easier retrieval. For example, proxi-mity sensors that get activated by human presence will remove the burden of image analysis for human detection. Since ubiqui-tous environments are built with infrastructure to support cam-eras and microphones for capture, it is relatively easy to add additional sensors to acquire such data. Domain knowledge, such as the purpose of use for each room, is also helpful in the design of algorithms for retrieval. 7.1. Motivation
Investigation in to automated retrieval of experiences at home can be useful in several other aspects, in addition to the significances mentioned above. This topic encompasses the general research areas of multimedia retrieval and ubiquitous environments. However, a home is much less controlled com-pared to the other ubiquitous environments used in related research. Video captured at home are unstructured content, marking a significant contrast from news, sports or instruc-tional video which are the common inputs for automated retrieval. Therefore, the selected topic will pose several research challenges, with prospects of significant contributions to these areas. The outcomes of this research are applicable in areas with practical significance, such as automated surveil-lance, elder care, and automated video summarization. 7.2. Related research
Research on multimedia retrieval for smart homes and other smart environments has become possible due to the recent developments in storage technologies facilitating recording large amounts of data. There are several ongoing projects that work on this topic. Applications in this category include meeting video retrieval and summarization of instructional video. Some of the projects, such as CHIL ( Waibel, 2005 ), attempted to combine both the above directions by supporting user interaction real-time and using retrieval for long term support. The college of computing,
Georgia Institute of Technology ( Bian et al., 2004 ), has con-structed several smart classrooms. These rooms are equipped with multiple data projectors, cameras and active white boards, to facilitate capturing of lectures for later review by students. The classrooms are also equipped with stylus based tablets for the use of the students. Xerox PARC uses infrared beacons to provide improved user interfaces for smart rooms ( Want and Borriello, 2000 ). A graphical user interface is used to control equipment in the room, with the aid of these beacons.

The Ubiquitous Sensor Room is an environment that captures data from both wearable and ubiquitous sensors to retrieve video diaries related to experiences of each person in the room. Jaimes et al. (2004 ) utilize graphical representations of important memory cues for interactive video retrieval from a ubiquitous environment. The Sensing Room is a ubiquitous sensing environment equipped with cameras, floor sensors and RFID sensors for long-term analysis of daily human behavior. Video and sensor data are segmented into 10-min intervals and the activity in the room during each segment is recognized using a Hidden Markov Model. Matsuoka and Fukushima (2004 ) attempted to understand and support daily activities in a house, using a single camera installed in each room and sensors attached to the floor, furniture and household appliances.
In their paper ( de Silva and Yamasaki et al., 2008c , d ) presented their techniques for experience retrieval in a smart home. The smart home they have analysed was equipped with 19 cameras, 25 microphones and pressure-based sensors mounted on the house floor. Hierarchical clustering of pressure sensor data followed by video handover automatically created videos tracking residents as they walked to and from different rooms. Video summarization reduced these videos to sets of key frames, for faster viewing. Sound source localization followed by supervised machine learning facilitated video indexing by audio events. A user interface based on hierarchical media segmentation com-bined these results to enable residents to retrieve their life experiences in a fast and effective manner. The system was evaluated by a family who stayed in the smart home and used the system to retrieve their experiences six months after their stay. Fig. 6 shows the sensor arrangement of their smart home.
The functional overview of their proposed methodology is summarized in Fig. 7 . A block diagram of user interaction for retrieving a summary of movement is shown in Fig. 8 . 8. Conclusions
In this paper we looked at the research work related to smart homes from various view points; first in the view point of specific techniques and then in the last 3 sections in the view point of specific applications. Specifically we looked at computer vision based techniques in smart homes, audio-based techniques in smart homes, multimodal techniques in smart homes at first.
Then when we looked from the view point of applications of smart homes we looked at applications like eldercare and child-care, energy efficiency and finally in the research directions of multimedia retrieval for ubiquitous environments. Table 2 and
Table 3 summarize the past research works in to some specific sub topics based on application centered and technique centered.
Here we observed that some of the smart home research areas are getting saturated and some new emerging areas are taking place. For example, video based person identification and activity detection for security applications has almost come to maturity but new areas like multiple sensor integration based techniques for energy efficient applications are taking the lead.
Inthefuturewecanenvisagethatmoreandmorecompu-ter power given to smart sensors researchers will make use of them in home area distributed sensor networks. Each sensor will either report in real time to the host or they will keep the information in the memory for o ffline processing. In order to address complex situations in smart rooms, multiple agents based intelligent and distributed software/hardware frame-works have been proposed recently. Some top software companies are building applicat ion specific software targeted for smart homes so that existing infrastructure can be upgraded with added intellige nce and decision making sup-port. In the future our homes will not be the same. A simple example is our mobile phones. About 10 years ago it was just a phone that can make calls. Now the number of functions it has are countless. This analogy can be easily applied to our homes.
One day it will be a robot inside out. The house will look at us from many directions to protect us from potential dangers due to our forgetfulness or due to other physical disabilities. Then we will always have a friend to live in with us.
 References
