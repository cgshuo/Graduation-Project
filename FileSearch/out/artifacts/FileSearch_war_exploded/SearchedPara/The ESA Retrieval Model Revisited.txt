 Among the retrieval models that have been proposed in the last years, the ESA model of Gabrilovich and Markovitch received much attention. The authors report on a significant improvement in the retrieval performance, which is explained with the semantic concepts introduced by the document collection underlying ESA. Their explanation appears plausible but our analysis shows that the connections are more involved and that the  X  X oncept hypothesis X  does not hold. In our contribution we analyze several properties that in fact affect the retrieval performance. Moreover, we intro-duce a formalization of ESA, which reveals its close connection to existing retrieval models.
 Categories and Subject Descriptors : H.3.3 [Information Stor-age and Retrieval]: Information Search and Retrieval X  Retrieval models ; H.1.1 [Models and Principles]: Systems and Information Theory X  General systems theory General Terms : Performance, Theory Keywords : Explicit Semantic Analysis, Retrieval Models
The Explicit Semantic Analysis (ESA) is a retrieval model pro-posed by Gabrilovich and Markovitch [4]. It was originally in-troduced to compute the semantic relatedness of natural language texts, and it yields significant improvements compared to the vec-tor space model or hidden variable models like LSI [3]. Recently, the ESA model was applied in several applications, among others to information retrieval [2], cross-lingual information retrieval [9, 10], text categorization [1, 5], and electronic career guidance [6].
The ESA representation of a real-world document d is a vector d
ESA whose elements are the cosine similarities between d and all documents in a collection D I , called index collection here. The supposed rationale of the ESA retrieval model is that each docu-ment in D I functions as a semantic concept to which the original document d is compared: d ESA is understood as a projection of d into the concept space spanned by D I . The semantic relatedness between two documents d 1 and d 2 is computed by the cosine sim-ilarity between the ESA vectors of d 1 and d 2 . The authors of [4] attribute the retrieval performance of ESA to the fact that each doc-ument in the index collection describes exactly one concept, and that these concepts are  X  X rthogonal X . We refer to these properties as concept hypothesis . Gabrilovich and Markovitch used Wikipedia as index collection, since it fulfills these requirements because of its  X  X ncyclopedic characteristic X . However, as the following analysis shows, the concept hypothesis does not hold.
 Table 1: The correlation coefficient ac hieved with ESA based on dif-
We use the same experimental set-up as the authors in [4], a test collection consisting of 50 documents from the Australian Broad-casting Corporation X  X  news mail service [7]. 1 For this collection human similarity assessments for the 1 225 document relations are available, each resulting from the average between eight to twelve human judgments. For a pair of test documents the similarity is computed under the ESA model, using different index collections. The achieved similarities are compared to the human similarity as-sessments; the correlation is quantified with the Pearson X  X  correla-tion coefficient. The results achieved by a vector space model based on tf -weighted terms give us a baseline (see Table 1, Row 1). Experiment 1: Merged Topics. Gabrilovich and Markovitch at-tribute the success of ESA to the concept hypothesis, which claims that each document of an index collection treats a single concept. By randomly merging 10 Wikipedia articles to a single index doc-ument we compiled a topically diffused index collection X  X ithout a noteworthy performance deterioration compared to the original Wikipedia index documents (see Table 1, Row 2+3).
 Experiment 2: Reuters. The concept hypothesis also claims that an index collection should provide an encyclopedic characteristic. We observe that similar or even higher correlation values are achieved with the Reuters Corpus Volume 1, which definitely does not pro-vide this characteristic (see Table 1, Row 2+4).
 Experiment 3: Random Gaussian. Even based on a randomly built index collection where the terms in all documents are N (0 distributed X  X nstead of obeying to Zipf X  X  law or some topical correlation X  X etrieval results comparable to that of the VSM are achieved. Moreover, since for such a collection no reasonable idf -value is defined, we compare the results also to an ESA model based on the Wikipedia that relies on tf -weighted terms. Note that even these values are nearly achieved (see Table 1, Row 5+6).
This is a small document number for a retrieval experiment, but we resort to this collection for the sake of comparability. Overall: Index Collection Size. Both the accuracy and the runtime increase with the number of index documents. A reasonable accu-racy is achieved with an index collection size | D I | between 1 000 and 10 000 documents. The runtime is, as expected, linear in
The experiments show that both the topical organization and the semantic purity of the index collection is of secondary importance for the retrieval performance: the use of clean Wikipedia articles, merged articles, or Reuters documents is of negligible impact. I.e., the concept hypothesis does not hold. The fact that even a col-lection of N (0 , 1) distributed weight vectors does a nearly equally good job in the role of an index collection shows that the  X  -stability of the term weights may be the actually underlying determinant. However, the size of the index collection matters; it affects both the accuracy and the runtime.

To have a formal basis for the definition of index collection prop-erties and the analysis of the retrieval performance, the next section introduces a formalization of the ESA model. Moreover, this for-malization reveals the close connection between the ESA and ex-isting retrieval models.
Let d be a real-world document, and let d be a bag-of-word-based representation of d , encoded as a n -dimensional vector of normalized term frequency weights: || d || =1 . To ensure the com-parability between two arbitrary weight vectors d 1 and d dimensionality as well as their term order is aligned with a uni-versal term vocabulary V that contains all used terms. A set D of document representations defines a term-document matrix A where each column in A D corresponds to a vector d  X  D . A an m  X  n matrix, i.e., A D encodes a collection of m documents represented over a vocabulary of size n .

Given a document d we distinguish between its unique base representation d and a derived collection-relative representation d | D I . The former is computed solely from the local properties of d , whereas the latter relates d to a particular index collection D Definition 1 (Collection-Relative Representation) Let D and D
I be two document collections with representations D , D I term-document matrices A D and A D I . Then, the term-document matrix A D | D I of the collection-relative representation of D with respect to collection D I is defined as follows: where A T designates the matrix transpose of A . D I is called in-dex collection, A D I is called translation matrix. Each column in A
D | D I corresponds to the collection-relative representation of a document d  X  D and is denoted as d | D I .

The rationale of this definition becomes clear if one considers that || d || = || d || =1 holds for each weight vector d  X  d  X  D I . Hence, each entry in the collection-relative representa-tion d | D I of a document d  X  D is the cosine similarity between d and some vector d  X  D I . Put another way, d is compared to each document in D I ,and d | D I is comprised of the respective cosine similarities.

Between two documents d 1 and d 2 , the similarity  X  ESA ( under the ESA model is computed as cosine similarity  X  of the ESA representations of d 1 and d 2 :
The Gaussian distribution is an example for an  X  -stable distribu-tion. For details see [8].

This notation of the ESA model is inspired by the generalized vector space model, GVSM [11], which employs knowledge about term co-occurrence within the retrieval process. Under the GVSM the similarity  X  GVSM ( q, d ) between a query q and a document d is defined as follows: where G is a n  X  n term co-occurrence matrix.

The ESA model and the GVSM can be directly transformed into each other when setting D I = D : The n  X  n matrix A D  X  A T D has a nonzero value in its i-th row and j-th column if there is a document in D where both the i-th and the j-th terms co-occur; hence A D  X  A T D = G .

Analogously, the CL-ESA model [9] and the cross-lingual exten-sion of the GVSM [12] can be transformed into each other.
Contrary to accepted belief the ESA concept hypothesis does not hold: the use of clean Wikipedia articles, merged articles, Reuters documents, or even random vectors has a negligible impact on the retrieval performance of the ESA model. However, the size of an index collection matters; it affects both the accuracy and the run-time. Our evaluation provides a guideline for the adjustment of collection-relative models to the needs of a particular retrieval task: put in a nutshell, a reasonable trade-off between accuracy and run-time is achieved with a number of 1 000 -10 000 index documents.
Our formalization of the ESA model shows its close connection to the generalized VSM. It also opens a perspective to construct index collections for specific information retrieval tasks.
Part of our current work is the identification and quantization of index collection properties that correlate with the observed retrieval performance in practical applications. Based on the expected in-sights, tailored collections may be constructed for specialized re-trieval tasks (e.g., narrow domain versus broad domain) or desired retrieval behavior (e.g., accuracy versus runtime), simply by adjust-ing mathematical properties of the translation matrix A D
