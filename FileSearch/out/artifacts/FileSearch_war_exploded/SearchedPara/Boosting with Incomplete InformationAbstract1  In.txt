 Boosting is a general supervised learning technique for in-crementally building linear combinations of  X  X eak X  mod-els to generate a  X  X trong X  predicative model. It is one of the most successful and practical methods in machine learning. Over the last decade, it has attracted much atten-tion in the machine learning community and related areas such as statistics. It has been widely applied in many real-world problems such as text filtering and routing, ranking, learning in natural language processing, image retrieval, medical diagnosis, and customer monitoring and segmen-tation (Schapire, 2004).
 It is very common in real-world machine learning problems that part of the input feature vector is incomplete: either not available, missing, or corrupted. In a web-page rank-ing problem, for example, using click-though data as part of the features, we find that a small number of valid pages have click features and most do not. In the case of object recognition in computer vision, many approaches assume a part-based model. However, certain parts of the object are hard to detect reliably due to small support in the im-age, occlusion or clutter, which also lead to missing infor-mation. Handling these kinds of classification problems containing incomplete information is a very important and realistic task. Excluding popular EM algorithms for gener-ative models, some methods have been recently proposed for discriminative models (Chechik et al., 2007; Koo &amp; Collins, 2005; Quattoni et al., 2005; Shivaswamy et al., 2006; Bi &amp; Zhang, 2004) .
 In this paper, we show how to handle incomplete data under the boosting approach. We first describe the precise prob-lem we are trying to solve, then we formulate optimization problems where the loss functions consist of two parts, one using partially labeled data and the other using fully label ed data. The primal problems of the proposed optimization problems with these loss functions are provided to show their close relationship and shed light on the rationale be-hind them. We derive explicit parameter update rules of the learning algorithms by introducing auxiliary function s to bound the change of loss functions. Finally, we demon-strate encouraging results on two real-world problems to show the effectiveness of the proposed boosting approach: visual object recognition in computer vision and named en-tity recognition in natural language processing.
 Let X  X  X  be a random variable over data instances to be labeled, and Y be a random variable over corresponding labels ranging over a finite label alphabet Y . The classi-fication task is to learn a mapping from data instances X to labels Y . Assume we have a set of feature functions F 1 := f k ( x,y ) Same as in (Collins et al., 2002; Lebanon &amp; Lafferty, 2002) and without loss of generality, we assume that the range of all feature functions in this paper is [0 , 1] . These feature functions correspond to weak learners in boosting and suf-ficient statistics in an exponential family model. Suppose the target predictor can be derived from a scor-ing function written as a linear combination of feature functions t ( x,y ) = P dataset ( x 2002) that Adaboost (Freund &amp; Schapire, 1997) combines features to minimize the following exponential loss where q is called the unnormalized model, and  X  y of instance x over the empirical data. Equivalently, it has been shown (Lebanon &amp; Lafferty, 2002) that Logitboost (Friedman et al., 2000) minimizes the following log loss where p model. Optimizing the two objective functions above can be done by either parallel or sequential updates (Collins et al., 2002; Lebanon &amp; Lafferty, 2002).
 Now assume that there is a random variable h  X  X  which is hidden in some part of the training data D but has been observed in the rest of the training data D ( x j ,h j ,y j ) . Consider a second set of feature functions F 2 := f k ( x,h,y ) to
R . In many real-world applications, the number of fully observed instances is much smaller than that of partially observed instances, that is, |D ing fully observed instances is either expensive or time-consuming. To take full advantage of all available training data, we need to develop new methods, because the infor-mation cannot be fully exploited by the original boosting algorithm.
 Hereafter we use subscripts i and j to range over training data in D denote all of its F of its F The challenge in this paper is, besides using the feature set F set F for the mapping from instances to labels.
 To this end, the main object of focus is a mapping from X X H to Y , which is modeled by a conditional probabil-ity distribution p normalized model and is defined parametrically as where  X  sponding to features in F mate the parameters of the distribution, we can maximize the conditional likelihood of the training data: where  X  is used to balance the influence of the two data sources on the objective function. Let q hidden variable given an instance x , then p q puted based on p We now turn our attention to model the mapping from X X H to Y by a linear scoring function that is the ba-sis of our Adaboost type algorithms. When h is observed, the mapping is defined based on and when h is hidden, it is defined as t P h q 0 ( h | x ) t  X  ( x,h,y ) ject prior domain knowledge. To learn the parameters, we pose the minimization of the loss function E (  X  ) defined as where q The second term in E (  X  ) can be thought of as the loss in-curred for the j th instance over all possible labels, and the first term as the expected loss for the i th instance. Note that if q instances in D In the next section, we will show that there is a close re-lationship between minimizing E (  X  ) and maximizing the lowerbound  X  (  X  ) on L (  X  ) , which is derived based on Jensen X  X  inequality and defined as By extending q Furthermore, we will show a close relationship between maximizing L (  X  ) and minimizing the following lower-bound on E (  X  ) derived by Jensen X  X  inequality In the test time, depending on whether h is hidden or not, either p class label of a given instance if we use the probabilistic model. Accordingly, for the linear map, either t t ( x,h,y ) can be used.
 Our definitions of both normalized and unnormalized mod-els are similar to those in (Lebanon &amp; Lafferty, 2002). If we ignore fully labeled data in L (  X  ) , we get the hidden con-ditional random field proposed in (Koo &amp; Collins, 2005; Quattoni et al., 2005) by assuming q however, the second term in L (  X  ) should exist to take ad-vantage of D the standard boosting algorithm X  X  loss function; however, the first term is needed to take advantage of the partially observed data D primal problems for the proposed loss functions to moti-vate the rationale of optimizing them and show their rela-tionships. We then give sequential and parallel algorithms to optimize E (  X  ) and L (  X  ) in section 5. It is well known (Lebanon &amp; Lafferty, 2002) that for stan-dard boosting with no hidden information, the primal op-timization problems for Adaboost and Logitboost are the same except for the additional constraints for the latter to ensure a probabilistic model. For our boosting with incom-plete information, this relationship does not exist for the original optimization problems themselves, but rather be-tween E (  X  ) and  X  (  X  ) which is the lowerbound on L (  X  ) Let the set of non-negative measures M := { m : X X H X  Y X  R + } , and F := F 1  X  X  2 . Let r be the reference measure 1 ; however, it can be any arbitrary measure that generalizes the objective functions introduced in the prev i-ous section.
 Theorem 1. The following optimization program: is the dual of min tended KL ( p || r ) is defined as and the set S (  X  p , q Proof sketch. The key idea in this theorem is the definition of the extended KL divergence and S (  X  p , q the Lagrangian of the dual, which is a constrained opti-It will give the form of the optimal solution; plug this form back into the Lagrangian, and make the data con-sistency assumption (  X  p is the empirical probability distri-bution) P P y  X  p ( y | x ) f ( x,h,y ) = f ( x,h,y x ) obtain the optimization problem in (3) .
 Theorem 2. The following optimization program: is the dual of min tended KL ( p || r ) is defined as in Theorem 1, and The proof of this theorem is similar to that of Theorem 1 and is omitted because of space constraints. As can be seen from the theorems above, the primal optimization problems corresponding to the objective functions E (  X  ) and  X  (  X  ) the same except for the additional constraints for the later one to ensure P vergence gives the expected discrepancy between p ( y | x,h ) and the reference measure r ( x,h,y ) where the expecta-tion is taken with respect to the distribution  X  p ( x ) q Hence minimizing the extended KL subject to the con-straints forces p ( y | x,h ) to become similar to r , or in par-ticular when the reference measure is 1 or constant, to have more entropy. Convergence of boosting algorithms has been studied in various ways. Much work has been done to prove the con-vergence in terms of an optimization method, which can be categorized into two approaches: greedy function opti-mization and greedy feature induction.
 In the first approach, the boosting algorithm is viewed as a sequential gradient descent algorithm (Breiman, 1999; Algorithm 1 Parallel Updates for the Normalized Model Friedman et al., 2000; Mason et al., 2000) in function space, inspired by numerical optimization and statistical es-timation. It is a forward stage-wise additive modeling that approximates the solution by sequentially adding new basis functions without adjusting the parameters and coefficient s of those that have already been added. At each iteration, one solves for the optimal basis function and corresponding coefficients to add to the current expansion. This produces new expansion, and the process is repeated.
 In the second approach (Collins et al., 2002; Lebanon &amp; Lafferty, 2002), the boosting algorithm is described as a greedy feature induction algorithm to incrementally build random fields. The greediness of the algorithm arises in steps that select the most informative feature. In these ste ps each feature in a pool of candidate features is evaluated by estimating the reduction in the Kullback-Lieber divergenc e that would result from adding the feature to the field. This reduction is approximated as a function of a single param-eter and is equal to the exponential loss reduction or log loss increment. This approximation is one of the key ele-ments that make it practical to evaluate a large number of candidate features at each stage of the induction algorithm . Various parameter update rules can be derived By using an auxiliary function to bound the change of loss function from above, and thus convergence to the global optimal so-lution is proved.
 In this paper we take the second approach to learn the dis-criminative model. We construct an auxiliary function to bound the change of exponential loss, E (  X  + X   X  )  X  X  (  X  ) log-loss L (  X  )  X  X  (  X  + X   X  ) . Similar to (Collins et al., 2002; Lebanon &amp; Lafferty, 2002), either parallel or sequential up -dates can be used. By the same argument as in (Collins et al., 2002; Lebanon &amp; Lafferty, 2002), we can show the convergence of these updates to a local minimum of the loss function. For simplicity in presenting the results, we introduce some notation for  X  x  X  X   X  f k  X  X  2 ,g k (  X  x,h,y ) = f k (  X  x,h,y )  X  f k (  X  x,h,  X  y
C := max For the normalized model, the learning algorithm with par-allel updates is summarized in Algorithm 1 and with the sequential updates in Algorithm 2. For the unnormalized model, the update rules (parallel or sequential) are exactl y the same; the only difference is that we will use q rather than p details of the derivation of updating rules in the learning algorithms, see Appendix A.
 For ease of presentation, we have assumed that the poten-interesting and nontrivial situation that occurs in many re al-world applications, where the missing attribute h is the in-formation that requires expensive human labeling (see the experiments for example applications). However, our ap-proach can be easily extended to the cases where the data could have different missing attributes. In this more gener al setting, the i -th training datum has the form ( x missing information h ferent i  X  X  depending on which information is missing. The contribution of this datum to the log loss in the normalized model is simply  X  log p paper will go through with some minor changes. We evaluate our approach in two real-world problems: vi-sual object recognition in computer vision and named en-tity recognition in natural language processing. In both cases, we use simple and independent features, so when we calculate the values of A + can be done efficiently. For simplicity, we set  X  to be 1. In practice, this parameter can be set by cross-validation. We set our prior belief in values of the hidden variable given an Algorithm 2 Sequential Updates for the Norm. Model instance, q use parallel updates. We have tried sequential updates and find that they are much slower. Although they can achieve higher likelihood on the training data, the results on the te st data remain the same.
 We compare our proposed boosting approach with three different baseline algorithms, in both normalized and un-normalized cases. The first baseline algorithm (BL1) uses both sets of features F fully observed training data D rithm (BL2) is trained on all the training data D uses only features F involve the hidden information h . Notice that the second baseline algorithm is identical to the algorithm in (Lebano n &amp; Lafferty, 2002). The third baseline algorithm (BL3) uses all the training data D F is, it assumes all the data are in the form of { ( x tice that the third baseline algorithm is similar to the hidd en conditional random field (Quattoni et al., 2005). 6.1. Visual Object Recognition We first consider a visual object recognition task where some of the data have missing features. In this task, we attempt to classify an image based on the existence of an object of interest in the image. We test our approach on the Caltech 4 dataset: airplanes, cars, faces, and motorbikes. Common approaches to object recognition involve some form of supervision, which may range from manually seg-menting the objects (Winn &amp; Shotton, 2006), to specifying a bounding box of the objects (Viola &amp; Jones, 2001), to only indicating the existence of the objects (Fergus et al., 2003). Naturally, there is a trade-off among different leve ls of supervisions. Manually segmenting the object of inter-est in an image obviously provides very accurate informa-tion for any learning algorithm, but it is very expensive and time-consuming to annotate a large number of images. On the other hand, it is relatively easy to label an image based only on the existence of an object. In our experiment, we assume we have two sets of training images. The first set of images has only class labels associated with them; we represent them as ( x,y ) , where x refers to the image and y refers to its class label. The second set of images has both class label and the contour of the object being man-ually labeled; we represent them as ( x,h,y ) , where h the information about the contour of the object. Our learn-ing problem is then in precisely the scenario in which our proposed method is expected to be effective.
 2001) to identity regions of interest on each image. Each interest point is represented by a SIFT descriptor (Lowe, 2004) as a 128-dimensional vector. The SIFT descriptors from all the training images are then vector quantized into K visual words (we choose K = 200 in our experiment) by k -means clustering. All the images are then represented by a bag-of-words representation by counting the occur-rence of each visual word in an image. We denote an im-age as x = ( x terest points in x , and each x The information h about the object contour is represented as h = ( h 1 ,h 2 ,...,h t ) , where h i is a binary value indicat-ing whether x the  X  X ag-of-words X  model, the summation over h required for calculating A + factoring out the contribution of each interest point. Al-though bag-of-words representation ignores a lot of posi-tional information between features, previous work (Sivic et al., 2005; Fergus et al., 2005) has demonstrated that it to be quite effective in object recognition tasks.
 We define the following three sets of features for our boost-ing algorithm, based on the bag-of-words representation of images. (1) feature f visual words j in an image x if y = y  X  , and zero otherwise; (2) feature o the foreground of image x if y = y  X  , and zero otherwise; (3) feature b the background of image x if y = y  X  , and zero otherwise. Notice that features f ing image. Features o a training image does not have missing information (i.e., the manually labeled object contour). We normalize all the features by the total number of interest points in an image to make sure their values are between 0 and 1. During test-ing, we observed the image x , and we try to infer its label y based on the learned model. Although we can also in-fer y assuming both x and h are observed during testing, it is actually an unrealistic setting in our application. It re-quires a perfect figure/ground segmentation of the image x However, since figure/ground segmentation is itself a very challenging problem in computer vision, it is not reason-able to assume we could have this information during the testing. So we do not investigate this case.
 Our dataset contains more than 2000 images. We randomly split them equally into training and testing sets. We choose 30% of the training images to be fully observed and the rest to be partially observed. We compare both normalized and unnormalized models with the three baseline algorithms defined above, in terms of classification accuracy and the log-likelihood of the test data. The results are shown in Ta-ble 1. We also visualize the most discriminative patches in some sample images in Figure 1. We find that our approach is significantly superior to the three baseline algorithms, in term of both accuracy and log-likelihood on the test images. 6.2. Named Entity Recognition Named entity extraction (NEE) is a subtask of information extraction in which we try to identify names of persons, lo-cations, and organizations in a given set of documents. One approach to this problem is to do first named entity recog-nition (NER) and then named entity classification (NEC). In this section we apply our method to the NER problem and demonstrate its effectiveness compared to the baseline systems.
 We consider NER as a sequence labeling problem, that is, specifying a sequence of zero and one for a sentence to classify a word as part of a named entity or not. For each word w , its surrounding words in a window of length 5, its part-of-speech tag (when available), and previous pre-dictions represent its local context, which then used by the classifier. The part-of-speech tag is a valuable source of in -formation and is not available in some annotations of the data sets for this task, so we treat it as the hidden variable that is not observed for some portion of the training data. We could use the sequence of POS tags of the words in the current window as the hidden variable. In that case, we may use a finite state automata to characterize the eligible sequence of POS tags when we want to sum over their val-ues to speed up the training algorithms. The features that we used are summarized in Table 6.2; they are described in more details in (Carreras et al., 2003).
 We use the data set of the CONLL 2003 shared task. To re-duce the training time, we collapse the original 45 differen t POS tags into five tags as done in (McCallum et al., 2003). After training the model, we do the classification for each individual position by normalizing the prediction score of the model using the class mass normalization (CMN) pro-cedure as introduced in (Zhu et al., 2003).
 We compare our approach to the three baseline systems de-fined before. There are 5K sentences in D in experiments show the performance of our model compared to the baselines when, at the test time, only x is available (see Table 3). In the second set of experiments, ( x,h ) given at the test time (see Table 4); for this setting, BL2 and BL3 cannot be used. Our method outperforms baseline systems in both sets of experiments in terms of f-measure and log-likelihood or loss function. Originally boosting is considered as a way to boost weak learners to strong learners by: learning weak hypotheses to classify hard examples in each round, and finally com-bining these weak hypotheses. Another view to boosting is through the statistical perspective which interprets it as: optimizing some objective function via parallel or sequen-tial updates to determine the weights of all possible weak hypotheses (aka features). There is a debate between the statistic and algorithmic perspective; see (Mease &amp; Wyner, 2008) for more information. Our work takes the statistical perspective and do not engage in that debate.
 A related algorithm that takes the first perspective to boost -ing is AdaBoost with confidence-rated predictions in which a weak learner outputs a real value representing the con-fidence level (Schapire &amp; Singer, 1999). When provided with incomplete input, the weak learner X  X  contribution is its uncertainty about its vote, which is represented by the produced real number. The details of the connection be-tween our approach and confidence-rated AdaBoost will be an interesting topic to explore for future research. In this work we have presented a novel boosting approach that extends the traditional boosting framework by incor-porating hidden variables such that fully labeled data can be integrated with partially labeled data to form a power-ful strong classifier. Thus, compared with both the original boosting algorithms and hidden CRF, our model performs better in two real-world problems by fully exploiting rele-vant complete information of data resources.
 We consider only simple independent features in our model. In fact, the hidden variables may have complex dependencies that respect certain cyclic graph structure; then it may be necessary to use variational methods, such as loopy belief propagation, to compute feature expecta-tion for the values of A + and A  X  . As future work, we would like to incorporate more complex dependent features in these two applications.
 SW is supported in part by the Research Challenge Grant at Wright State University. We would like to thank Anoop Sarkar, David Blei and anonymous reviewers for their con-structive comments.
 Exponential loss We derive parallel updates for exponential loss. Let  X  + X   X  be the new parameters value. We find an upper-bound to the change of objective function E (  X  +  X   X  )  X  X  (  X  ) by an auxiliary function , and then minimize the bound. where w tor built from g g ( x,h,y ) . We find the stationary point of the auxil-iary function A (  X ,  X   X  ) with respect to  X   X  derivative and setting it to zero, which gives us the updatin g rules. The sequential updates can also be derived similarly . Log loss The objective is to minimize the objective function  X  X  (  X  +  X   X  )+ L (  X  ) . First we find an upper-bound on the objective function: The inequality holds because log x  X  x . The last expres-sion can be upper-bounded again (using a similar technique used for exponential loss), and the resultant upper-bound will be the auxiliary function. It can be shown that the up-date rules are the same to unnormalized model, but the dif-ference is to use p
