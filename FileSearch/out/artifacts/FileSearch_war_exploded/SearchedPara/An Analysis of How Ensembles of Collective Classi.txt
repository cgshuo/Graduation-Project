 We present a theoretical analysis framework that shows how ensembles of collective classifiers can improve predictions for graph data. We show how collective ensemble classification reduces errors due to variance in learning and more interest-ingly inference. We present an empirical framework that in-cludes various ensemble techniques for classifying relational data using collective inference. The methods span single-and multiple-graph network approaches, and are tested on both synthetic and real world classification tasks. Our ex-perimental results, supported by our theoretical justifica-tions, confirm that ensemble algorithms that explicitly focus on both learning and inference processes and aim at reducing errors associated with both, are the best performers. I.2 [ Computing Methodologies ]: Artificial Intelligence Collective classification, Ensemble learning
Ensemble methods have been widely studied as a means of reducing classification error by combining multiple mod-els for prediction. Much of the earlier work on ensemble techniques has focused on i.i.d. domains (where objects are independent and identically distributed, and models use ex-act inference techniques). While there has been some recent investigation of ensembles for relational domains [5, 10, 17], these previous works have a number of limitations in that: (1) there is no theoretical analysis to show the mechanism by which ensembles reduce model error in relational domains, (2) they focus on the reduction of only one type of error (due to either learning or inference), and (3) they make an assumption about the datasets having multiple relations.
In this work, we formulate a theoretical framework to compare the errors made by different relational ensembles and show the reason why some methods do better than oth-ers. Moreover, we present a relational ensemble framework that combines a relational ensemble learning approach with a relational ensemble inference approach. We use the first method for learning the ensemble, while focusing on reduc-ing error due to variance in learning. We use the second method for applying the ensemble for inference, while fo-cuses on reducing error due to variance in inference. We show how the unique combination of these methods offers the largest classification accuracy improvement, compared to various other approaches on both synthetic and real-world datasets. Furthermore, our ensemble model is applicable in domains that do not necessarily have multiple relational graphs, thereby overcoming that limitation of existing re-lational ensembles. In fact, our framework is applicable in both single-graph and multi-graph settings.

Traditional design choices for i.i.d. ensembles include meth-ods for input data treatment (see Figure 1.a) and methods for aggregating the output of the models (see Figure 1.d). The goal of the data treatment method is to ensure vari-ety among the learned models. For example, bagging ap-proaches (e.g., [3]) use resampling to generate multiple boot-straps to learn the models from, and aggregate predictions from multiple models, while boosting approaches (e.g., [2, 18, 21]) construct the models in a coupled fashion so that their weighted vote gives a good fit to the data.
In relational domains, different design choices must be considered. First, the treatment of input data must con-sider the relational data characteristics. For example, some approaches [5, 17] use the multple link types available in the network to subset the data to learn the component mod-els of a relational ensemble. Another technique [1] instead uses a feature subset approach which samples from the node features, and applies this approach in a relational setting. Second, relational or collective inference models can be used as the base component models of the ensemble, because they have been shown to improve predictions for relational data. Fire example, some recent work [13] proposed using boost-ing for learning relational dependency networks to reduce the bias component of error. Third, work on relational en-sembles that considered collective classification for the base models [5] also proposed a new approach to aggregating pre-dictions across the models during collective inference to re-duce variance in inference. Finally, aggregation of the mod-els X  predictions has been used in both i.i.d. ensembles as well as relational ensembles to reduce the variance in learning.
The goal of this work is to analyze the different error com-ponents of relational ensembles theoretically to show the Figure 1: Ensemble classification design dimensions. mechanisms by which different approaches reduce classifi-cation error. In i.i.d. domains, ensemble learning methods have been shown to reduce classification error by reducing variance (e.g., bagging [3]) or reducing bias (e.g., boost-ing [21]). However, since previous analysis has focused on i.i.d. data, the models are assumed to use exact inference techniques that have no associated error X  X hus the only er-ror is attributed to the learning process. On the other hand, collective inference models applied to relational data have been shown to have additional sources of error due to the inference process [14]. We use a bias/variance decomposi-tion for our analysis, and extend it for the ensemble setting, to consider not just a single model, but an ensemble of col-lective inference models. Specifically, we reason about two classes of ensemble models: (1) a relational ensemble model that runs the base classifiers independently for inference and aggregates the final predictions, and (2) an across-model ap-proach, which runs the component models simultaneously for collective inference and aggregates intermediate predic-tions across the models during inference. Throughout this paper, we refer to the first model as the relational ensemble model, and we refer to the second model as the interleaved model. The goal of our theoretical analysis is to decompose the errors associated with each ensemble and show how the different ensemble approaches can reduce the error of a single model. Specifically, we show that an interleaved ensemble produces the greatest error reduction due to its ability to re-duce learning and inference error without an increase in bias. To our knowledge, this is the first analytical investigation of error for relational ensembles.

Based on our analysis, we note that aggregating the base models X  predictions at the end of inference reduces error due to variance in learning, while interleaving the models X  pre-dictions during collective inference reduces error due to in-ference. We also note that the aggregation process reduces the variance in learning in proportion to the amount of true variance approximated by the learned models. This has led us to consider learning the ensemble in a way that can better approximate the true variance in relational data, to maxi-mize the reduction in learning variance, and combine this technique with the inference interleaving proposed earlier to additionally reduce inference variance. Specifically, we use a relational resampling approach to capture the increased variance in relational data, allowing the ensembles to re-duce more of the variance due to learning. We combine it with interleaved inference, which allows the ensembles to reduce more of the variance due to inference. In contrast to our proposed ensemble method, previous methods have focused on reducing errors due to variance in learning [17], or due to variance in inference [5], but not both simultane-ously. Furthermore, this combination allows our ensemble approach to be applicable for all kind of graphs regardless of the amount of infromation available. Our model is applica-ble to networks with single or multiple link types. Since we now propose to learn the ensembles from bootstrap samples from a single training graph, while the interleaved method was proposed to learn the models from different link graphs. We empirically compare our proposed ensemble approach to several baselines using synthetic and real-world classification tasks and demonstrate its superior performance.

The main contributions of this work are:
We describe the general relational learning and collective classification problem as follows. Given a fully-labeled train-ing set composed of a graph G tr =( V tr ,E tr )withnodes V and edges E tr , observed features X tr , and observed class labels Y tr ,amodel f defining a joint probability distribu-tion over the labels of V tr , conditioned on the observed attributes and graph structure in G tr is learned. Given a partially-labelled test set composed of a graph G te = ( V te ,E te )withnodes V te and edges E te , observed features X te , and partially-observed class labels  X  Y te  X  Y te , the model f is applied for collective inference to output a set of marginal probability distributions P (i.e., predictions) for each unla-beled node in V te . We assume the G tr used for learning is different from the G te used for collective inference.
We describe the general relational ensemble classification problem as follows. The input consists of a fully-labeled training set graph G tr =( V tr ,E tr )withnodes V tr and edges E tr , observed features X tr , and observed class labels Y From the input G tr , the algorithm generates a set of m sample graphs { G tr 1 , ..G tr m } ,whichwerefertoas pseu-dosamples . Then, using a relational learner, a set of models F = { f 1 , ..f m } is learned from { G tr 1 , ..G tr m } from each pseudosample graph. During prediction, each model f i  X  F is applied for collective inference to G te output a set of marginal probability distributions P i (i.e., predictions) for each unlabeled node in V te . Finally, the predictions P 1 , .., P m from the m models are aggregated and the final predictions P are generated for nodes in G te .
In this section we use bias/variance analysis to explore the differences between single collective models and the var-ious relational ensembles. Specifically, we focus on squared loss as a measure of classification performance and show the error reduction offered by the different types of ensembles. The analytical results shows how the simple relational en-semble improves performance over the single collective clas-sifier, as well as how the interleaved ensemble improves per-formance over the simple relational ensemble. To the best of our knowledge, this is the first analytical exploration of classification error for relational ensembles.
We formalize the collective classification task in order to describe the setting we use for this analysis. Let D be a population of attributed graphs G . Each sample D := [ G =( V, E ) ,X V ,Y V ]isdrawnfrom D ,where V is the set of instances in D , E is the set of links, and | V | = g .
Let f := P ( Y g | X g ,G ) represent a model of the joint dis-tribution over class labels Y of instances in a graph G ,given attributes of the instances X .Let D L  X  X  be a training graph. Let D I  X  X  be a partially labeled test graph where T X  V I is the set of labeled instances in G I .Let Y T be the set of known labels available to the inference process. For this analysis, we assume that D L and D I are drawn independently from D and that D I = D L .

The goal is to learn f from the training set D L and apply it to the test set D I to collectively predict class labels for each unlabeled instance i  X  V I/ T :
Since relational models that use collective inference have an additional source of error due to the inference process, we need to isolate the errors due to learning from the errors due to inference. To achieve this, we also consider the per-formance of an exact inference model, which does not use collective inference and simply makes a prediction for i con-ditioned on the set of Bayes-optimal values for all instances except i .Below,weuse  X  Y V I/i to refer to the Bayes-optimal prediction for all instances in the dataset D I except i .
We consider four models in our analysis: a single collec-tive inference model ( f s ), a simple relational ensemble model ( f e ), an interleaved collective inference model ( f c ), and the  X  X rue X  model ( f  X  ). We define each of these models below.
True model: We define f  X  as the  X  X rue X  model for the population D ,where P  X  is the X  X rue X  X oint distribution, which can be estimated as the expected model f s that will be learned over samples drawn from the population D :
Single model: Let f s be a single collective inference model learned from a sample D L  X  X  , which estimates P s . The model f s is then used to make predictions for each un-labeled instance i in a partially labeled dataset &lt;D I Simple relational ensemble model (RE): Let F = { f s 1 , .., f s m } be a set of m collective inference mod-els learned from { D L 1 , .., D L m } generated from D L f gives a different estimate of the true joint distribution P For a description of how { D L 1 , .., D L m } are generated from a single given D L , please see section 3.2.4.

Let f e be a simple relational ensemble model that ag-gregates predictions from F = { f s 1 , .., f s m } ,whereeach f s  X  F runs n Gibbs iterations independently for infer-ence. A prediction y i f e for an instance i is then calculated by averaging the final predictions for i from all m models F = { f s 1 , .., f s m } . Each base model makes its predictions as described for the single model above.
Interleaved ensemble model (CEC): As described above, let F = { f s 1 , .., f s m } be a set of m collective in-ference models learned from { D L 1 , .., D L m } generated from D
L .Thenlet f c be an interleaved model that aggregates predictions from the m collective inference base models in F , at each Gibbs iteration j  X  X  1 ..n } . At each iteration j , predictions made by all the base models are aggregated and used to make a prediction for each model k  X  X  1 ..m } These predictions are for V I/ T . For the instances in T use the true labels. The final prediction for an instance i is estimated from the average of the component models X  pre-dictions at the last inference iteration n . This defines the interleaved model f c =  X  f k,n .
We decompose error of collective classification models into bias, variance and noise components based on the work of Neville and Jensen [14]. Here we consider squared loss as a measure of classification performance. The loss L for model f on instance i is defined as the expected squared loss for prediction y i f given i  X  X  true label of t i : Here E refers to the total expectation, which is taken over training sets ( D  X  X  ) used to learn the model f and subsets of true labels T available for inference. For ease of reading, when it is clear from context, we drop the superscript i and the subscript f .

Note that in conventional settings, the expectation E would refer to aspects of learning and represent the effect of train-ing sets on models/predictions. However, in collective in-ference settings the relational inference process introduces another source of error [14]. Thus, to reason about the per-formance of different relational ensembles, we need to make a distinction between the expectation over learning and the expectation over inference and the expectation over both. We define these expectations below.

To analyze performance differences, loss can be decom-posed into bias, variance, and noise components, and com-pared across models. For squared loss, the decomposition is additive: L = V + B + N . We show the decomposition and define each component below.

Variance : Here variance, V = E ( E [ y ]  X  y ) 2 ,istheaver-age loss incurred by all predictions y , relative to the mean prediction E [ y ].

Bias :Herebias, B =( E [ t ]  X  E [ y ]) 2 , is the loss incurred by the mean prediction, relative to the Bayes-optimal value for instance i : E [ t ] (the expected value of the true label).
Noise :Herenoise, N = E ( t  X  E [ t ]) 2 , is the loss incurred due to noise in the labels of the data, which is independent of the learning algorithm.
We define the three types of expectations that will be used in the proofs X  X xpectations over learning , inference , and both . Note that these expectations are defined for the predictions that will be made by the single model f s for a test data set D I .

Expected learning prediction : This is the expecta-tion over learning , where the prediction for an instance i is estimated using exact inference based on the set of Bayes-optimal predictions for the rest of the graph,  X  Y V I/i
Expected inference prediction : This is the expecta-tion over inference , where the prediction for an instance i is estimated using the model f D L s learned from a single train-ing set D L :
Expected total prediction : This is the total expecta-tion over learning and inference, where the prediction for an instance i reflects the prediction that would be made from the true distribution: E
Given the framework described above, we compare the performance of the ensemble models to the single model and show how the ensembles reduce total loss. Specifically, we decompose the error of the single collective inference model f , the simple relational ensemble model f e ,andtheinter-leaved ensemble model f c . Our analysis shows that the in-terleaved ensemble results in the greatest reduction in error, through its reduction of both learning and inference variance.
We refer to y s as an arbitrary prediction from a single col-lective inference model f s , y e as an arbitrary prediction from a simple relational ensemble f e ,and y c as an arbitrary pre-diction from an interleaved ensemble model f e .Theproofs below make use of the following assumptions.

Noise equivalence : We note that the noise component of error is dependent upon the data set, and is independent of the classification algorithm. Therefore:
Dataset independence : The data graph samples {
D L s } s =1 ..m used for learning the m models and D I used for inference are drawn independently from the population of graphs D . When the datasets are independent, the total expectation can be computed from the learning and infer-ence expectations as follows:
Predictions from simple relational ensemble :Inthe simple relational ensemble f e , when the number of base mod-els m approaches  X  , the ensemble prediction y i f e approaches the expected prediction of the single model f s ,whentheex-pectation is over learning (i.e., E L [ y i s ]). But since the pre-dictions from f e are conditioned on a single labeling T ,the ensemble prediction does not approach the total expected prediction of the single model (i.e., it does not reflect the variation over inference). Predictions from interleaved relational ensemble : In the interleaved relational ensemble f c , when both the number of base models m and the number of inference it-erations n approach  X  , the interleaved prediction y i f c proaches the expected prediction of the single model f s , where the expectation is over both learning and inference ulates draws from alternative labelings T over the course of inference.
When squared loss is decomposed, the variance compo-nent is V T = E T ( E T [ y ]  X  y ) 2 . Here we consider the ex-pected total error, over both learning and inference. We now show that a simple relational ensemble reduces the variance of a single model, and an interleaved ensemble reduces the variance of a simple relational ensemble.

Theorem 1 :Let f s be a single collective inference model with variance V s , f e be a simple relational ensemble with variance V e ,and f c be an interleaved ensemble model with variance V c .Then V s  X  V e  X  V c . Proof of Theorem 1.1 V  X  V e = E T ( E T [ y s ]  X  y s ) 2  X  E T ( E T [ y e ]  X  y e ) = E T E T [ y s ] 2  X  2 y s E T [ y s ]+ y 2 s  X  E T E T [ y = E T [ y s ] 2  X  2 E T [ y s ] 2 + E T [ y 2 s ]  X  E T [ y =  X  E T [ y s ] 2 + E T [ y 2 s ]+ E T [ y e ] 2  X  E T [ y 2 =  X  E T [ y s ] 2 + E T [ y 2 s ]+ E T [ E L [ y s ]] 2  X  E =  X  E I [ E L [ y s ]] 2 + E T [ y 2 s ]+ E I [ E L [ y s ]]  X  Proof of Theorem 1.2 V  X  V c = E T ( E T [ y e ]  X  y e ) 2  X  E T ( E T [ y c ]  X  y c ) = E T E T [ y e ] 2  X  2 y e E T [ y e ]+ y 2 e  X  E T E T [ y = E T [ y e ] 2  X  2 E T [ y e ] 2 + E T [ y 2 e ]  X  E T [ y =  X  E T [ y e ] 2 + E T [ y 2 e ]+ E T [ y c ] 2  X  E T [ y 2 =  X  E T [ E L [ y s ]] 2 + E T E L [ y s ] 2 + E T [ y c ] 2 =  X  E T [ E L [ y s ]] 2 + E T E L [ y s ] 2 + E T [ E T [ y =  X  E T [ E L [ y s ]] 2 + E T E L [ y s ] 2 + E T [ y s ] 2 =  X  E I [ E L [ y s ]] 2 + E I E L [ y s ] 2 (by 11) = E I E L [ y s ] 2  X  E I [ E L [ y s ]] 2  X 
Single collective models f s have two sources of variance in their predictions X  X ariance due to learning the models from different training graphs, and variance due to apply-ing the model for inference given different labeled subsets of the test graph. Simple relational ensembles f e average mod-els predictions from different learned models and reduce the variance due to learning. Thus, V s  X  V e .

Similar to simple relational ensembles, interleaved ensem-bles f c reduce the variance due to learning. Moreover, inter-leaving predictions across the base models during each col-lective inference iteration simulates draws from alternative labeled subsets of the inference graph, and prevents any of the base models from converging to extreme state. This al-lows an additional reduction of the inference variance. Thus, V  X  V e . When squared loss is decomposed, the bias component is B
T =( E T [ t ]  X  E T [ y ]) total error, over both learning and inference. We now show that the two relational ensembles have the same bias as the single model. Since bias depends on how well the models can approximate the true model, it is not corrected by the relational or interleaved ensemble.

Theorem 2 :Let f s be a single collective inference model with bias B s , f e be a simple relational ensemble with bias B ,and f c be an interleaved ensemble model with bias B c . Then B s = B e = B c Proof of Theorem 2.1 B =( E T [ t ]  X  E T [ y s ]) 2  X  ( E T [ t ]  X  E T [ y e ]) =( E T [ t ]  X  E T [ y s ]) 2  X  ( E T [ t ]  X  E T [ E L [ y =( E T [ t ]  X  E T [ y s ]) 2  X  ( E T [ t ]  X  E T [ y s ]) =0 Proof of Theorem 2.2 B =( E T [ t ]  X  E T [ y s ]) 2  X  ( E T [ t ]  X  E T [ y c ]) =( E T [ t ]  X  E T [ E L [ y s ]]) 2  X  ( E T [ t ]  X  E T [ E =( E T [ t ]  X  E T [ y s ]) 2  X  ( E T [ t ]  X  E T [ y s ]) =0
Now, given the reduction in variance and equivalent bias, we can analyze the reduction in error that the ensembles of-fer. Recall that we define total loss as the expected error over learning and inference L = E T [( t i  X  y i f ) 2 ]andthisdecom-poses additively into variance, bias and noise components: L = V + B + N . We now show that a simple relational en-semble reduces the loss of a single model, and an interleaved ensemble reduces the loss of a simple relational ensemble.
Corollary 1 :Let f s be a single collective inference model with loss L s , f e be a simple relational ensemble with loss L and f c be an interleaved ensemble model with loss L c .Then L Proof of Corollary 1.1 L =( V s + B s + N s )  X  ( V e + B e + N e ) =( V s + B s + N s )  X  ( V e + B s + N s ) (by 10, Thm 2) = V s  X  V e  X  Proof of Corollary 1.2 L =( V e + B e + N e )  X  ( V c + B c + N c ) =( V e + B s + N s )  X  ( V c + B s + N s ) (by 10, Thm 2) = V e  X  V c  X 
Following the results of Theorems 1 and 2, and according to the definition of noise, it is straightforward to make the above conclusion about reduction in error. A simple rela-tional ensemble model will reduce the error of a single collec-tive inference model by reducing the learning variance, and an interleaved ensemble will reduce the error even further by reducing both learning variance and inference variance.
The analysis presented above applies regardless of what approach is used for learning the base models in f e or f In particular, it shows that the final prediction aggregation reduces learning variance while interleaved model aggrega-tion during inference additionally reduces inference variance. While previous relational ensembles learn the models in F from pseudosamples formed from different link graphs or random subsets of features, we focus here on resampling to generate multiple pseudosamples from the single input training graph. The benefit of using resampling is that it is applicable to all kind of graphs regardless of the amount of information available (e.g., number of features or number of link types).

The error analysis applies to ensembles constructed from either relational subgraph resampling (RSR) or the tradi-tionally used IID resampling, where instances are sampled independently with replacement. When the number of pse-duosamples m approaches  X  , the bootstrap samples approx-imate the true population distribution D and the models in F approximate P  X  . This indicates that for the ensemble model f e , assumption 12 holds regardless of the learning approach. In other words, the ensemble prediction y i f e proaches the expected prediction of the single model f s over learning (i.e., E L [ y i s ]) for both resampling methods:
However, y RSR e converges faster than y IID e  X  X ecause RSR pseudosamples more accurately reflect the correlations in re-lational data. Thus, given a finite ensemble size m ,predic-tions made by models learned from RSR pseudosamples will capture and reduce more learning variance (because RSR more accurately captures the increased variance in network data). The same argument applies to f c . Thus assumption 13 holds regardless of the resampling approach, but in finite ensemble sizes, RSR pseudosamples will capture and reduce more variance.

Our analysis illustrates the errors due to different phases of an ensemble algorithm. This understanding points to an additional way of reducing error due to variance in learning. In particular, the better the set of training samples can ap-proximate the true population variance, the more reduction in learning variance the final model aggregation can achieve. We note that using relational subgraph resampling (RSR) can more accurately capture the increased variance in rela-tional data, specifically using a small number of bootstrap samples. Following this observation, we propose to use RSR to enable the final predictions aggregation to reduce more learning variance. We combine the use of RSR with the interleaved inference aggregation (CEC) to additionally re-duce inference variance. We outline the algorithmic details in the next section.
We propose an ensemble model that uses relational sub-graph resampling (RSR) for generating the bootstrap pseu-dosamples to learn the ensembles from, and collective ensem-ble classification (CEC) for inference. RSR was originally proposed for accurate estimation of variance for network data [6]. We utilize RSR to accurately capture the learn-ing variance during ensemble construction. This enables our ensemble method to reduce more variance in learning than traditional independent resampling approaches. In addition, using CEC in our method facilitates the reduction of infer-ence error. In contrast, the majority of existing ensembles focus on reducing learning error alone. Using these two ap-proaches allows a combined reduction of learning and infer-ence variance, and extends the utility of CEC to single net-work settings. Note that, CEC was developed for domains with multiple types of relations (e.g., a network with email, phone, and SMS links) X  X nd the method requires multiple link types to learn a model from each typed subnetwork. However, using RSR for learning enables a generalization of the method to domains that do not necessarily have multi-ple link graphs. The psuedosamples we use for learning are networks sampled with replacement from a single training graph (regardless of the link types in the graph).
Given a training dataset, our algorithm uses RSR to gen-erate m bootstrap pseudosamples to learn an ensemble of m models. The models are applied for collective inference on a single test set using CEC, which iteratively interleaves the inferences across the m models. After inference is done, the predictions output by each base model are aggregated for each node independently as in traditional ensembles.
Our ensemble learning approach using bootstrap sampling is outlined in Algorithm 1, showing how an ensemble of size m models is constructed. A pseudosample G ps =( V ps ,E ps is generated by resampling from G tr (line 3) and a model F is learned from G ps (line 4). F is a joint probability distri-bution over the labels of V ps , conditioned on the observed attributes and graph structure in G ps . The ensemble set of m learned models is returned (line 6). Note that the two main components needed for an implementation of the algo-rithm are: a resampling algorithm (step 3) and a relational learning algorithm (step 4). We describe each below. Algorithm 1 Ensemble Learning: EL( G tr =( V tr ,E tr ) ,m ) 1: Ensemble  X  X  X  2: for j := 1 to m do 3: G ps j = Resample ( G tr ) 4: F j = LearnM odel ( G ps j ) 5: Ensemble = Ensemble  X  X  F j } 6: return Ensemble
RSR is an approach for resampling relational data to ac-curately capture the increased variance due to linkage and autocorrelation. RSR samples subgraphs with replacement instead of the typical independent sampling technique that samples instances (i.e., nodes) with replacement. When in-stances are resampled independently at random the resulting pseudosamples underestimate the amount of variance if the data exhibits network autocorrelation.

The RSR procedure is outlined in Algorithm 2. Given a sample relational data graph G =( V, E ), it returns a pseudosample data graph G PS =( V PS ,E PS ). A set of N S b subgraphs of size b are sampled from G .Eachof N S subgraphs is sampled using a breadth-first search from a randomly selected seed nodes. As a node v s is added to the sampled subgraph node set V s , v s s neighbors are added to a list Q , from which the next node v s is taken. This continues until the subgraph size b is reached.
 Algorithm 2 Relational Subgraph Resampling (RSR) RSR( G =( V, E ) ,b ) 1: V PS  X  X  X  ; E PS  X  X  X  2: for s := 1 to | V | b do 3: V S  X  X  X  ; E S  X  X  X  ; Q  X  X  X  4: v s = randomly select node from V 5: V S  X  V S  X  v s 6: push neighbors of v s onto Q 7: while ( | V S | &lt;b )  X  ( | Q | &gt; 0) do 8: v s =pop Q 9: V S  X  V S  X  v s 10: push neighbors of v s onto Q 11: E S = { e ij  X  Es.t.v i ,v j  X  V S } ; V PS  X  V PS + 12: return G PS =( V PS ,E PS )
Note that the sampling is with replacement from the graph, so a node may appear in multiple subgraphs, one subgraph, or none. The pseudosample node set ( V PS ) consists of all the nodes selected in the subgraphs (suitably relabeled so mul-tiple copies of the same original node are distinguishable for the learning algorithm). The pseudosample edge set ( E PS consists of all the edges within the selected subgraphs.
The key idea behind sampling subgraphs is that when autocorrelation is high (i.e., neighbors are correlated), the effective sample size is going to be closer to the number of  X  X roups X  X f correlated instances than the number of nodes in the network. To account for this, RSR attempts to sample these  X  X roups X  instead of single instances, thus it more ac-curately approximates the effective sample size of the data. Moreover, sampling subgraphs preserves the local relational dependencies among instances in the subgraph so the re-lational model is better able to utilize the interrelated at-tribute dependencies to improve classification. In the tradi-tional independent sampling technique, a node in the pseu-dosample will not necessarily have its neighbors from the original sample, and therefore the model will be less capable of exploiting the link structure. We compare to a method that uses independent sampling as a baseline. It is described in more detail the experimental section.

We learn relational dependency network (RDN) [16] mod-els as the component collective classification models. Since RDNs are selective models based on decision trees, they exhibit the instability that typically works well in bagged ensembles. RDNs use pseudolikelihood estimation to effi-ciently learn a full joint probability distribution over the la-bels of the data graph, and are typically applied with Gibbs sampling for collective inference. Note that the full joint distribution over the test data need not be estimated for accurate inference and it is sufficient to accurately estimate the per instance conditional likelihoods, which is easy to do with Gibbs sampling (i.e., has been shown to converge within 500-2000 Gibbs iterations [16]). For inference, we use collective ensemble classification (CEC). However, instead of learning the ensemble from multiple link graphs as previously proposed [5], we learn the ensemble from bootstrap pseudosamples constructed using RSR as described above. This has an additional advantage of being applicable in single-graph network settings. The CEC proce-dure is included in Algorithm 3 for completeness. CEC uses across-models collective classification for inference, which propagates predictions across the component models during collective inference.

Given a test network G with partially labeled nodes V , and m base models F 1 ,F 2 ,...,F k learned as described in section 4.1, the models are applied simultaneously to col-lectively predict the values of unknown labels (lines 5-11). First, the labels are randomly initialized (lines 1-4). Next, at each collective inference iteration, the model F i is used to infer a label for each node v conditioned on the current labels of the neighbors of v (line 8). This corresponds to a typical collective inference iteration. Then instead of using the prediction from F i directly for the next round, it is av-eragedwiththeinferencesfor v made by each other model F j s.t. j = i (line 9). This interleaves inferences across the component models and pushes the variance reduction gains into the collective inference process itself. At the end, the predictions are calculated for each model based on the stored prediction values from each collective inference iter-ation (lines 12-13). Finally, model outputs are averaged to produce the final predictions (lines 15-16).

Note that the manner in which CEC uses inferences from other models (for the same node) provides more informa-tion to the inference process that is not available if the col-lective inference processes are run independently on each base model. Since each collective inference process can ex-perience error due to variance from approximate inference, the ensemble averaging during inference can reduce these errors before they propagate throughout the network. This results in significant reduction of inference variance, which is achieved solely by CEC.

CEC assumes a collective classification model as the base component of the ensemble, we use RDNs, but any collec-Algorithm 3 Collective Ensemble Classification (CEC) CEC( F 1 ,F 2 ,...,F m , G =( V, E ) ,X,  X  Y , F m = P ( Y 1: for all iin1to m do 2:  X  Y i =  X  Y ; Y i T =  X  3: for all v j  X  Vs.t.y j /  X   X  Y do 4: Randomly initialize  X  y i j ;  X  Y i =  X  Y i  X   X  y i j 5: repeat 6: for all i =1to m do 7: for all v j  X  Vs.t.y j /  X   X  Y do 10:  X  Y i =  X  Y i  X  X   X  y i j } + {  X  y i agg j } ; Y i T = Y 11: until terminating condition 12: for all i =1to m do 13: Compute P i = { P i j : y j /  X   X  Y } using Y i T 14: P =  X  15: for all v j  X  V do 17: return P tive classification model can be used instead. However, our analysis shows that the approach will work particularly well for models that exhibit learning and/or inference variance.
We refer to our proposed ensemble as RSR-CEC. We eval-uate the ensemble method on both synthetic and real world datasets, and the results show that combining RSR with CEC significantly outperforms using either approach alone.
We use a number of baseline methods to compare the pro-posed model to alternative approaches while controlling for model representation.

A single model baseline is used to evaluate the improve-ment achieved by each ensemble approach. Here, a collec-tive classification model is learned from the original training sample and applied once on the given test set. Note that all the ensembles we discuss below, including the proposed model, generate the bootstrap pseudosamples from this orig-inal training sample, and use the same collective classifica-tion algorithm as the base component model.

This model uses IID resampling for generating the training pseudosamples and learns a relational model for each base classifier. IID resampling works by sampling instances inde-pendently at random from the network, with replacement. A link in the original sample will only appear in the pseu-dosample if both nodes it connects were selected. A simple relational ensemble (RE) approach is then used for infer-ence, where each base model is applied independently for collective inference to produce a set of probability estimates for nodes predictions. Then for each node, the base models X  predictions are averaged to get the node X  X  final prediction. We compare to this approach to evaluate the combined im-provement achieved by using RSR for resampling and CEC for inference over a method that does not use either ap-proach. The goal is to show the total variance reduction offered by RSR and CEC.
 This baseline uses RSR for constructing the ensemble and RE for inference. Comparing the performance of our pro-posed model to this approach allows us to evaluate the im-provement achieved by CEC for inference, while controlling for the resampling method (RSR) used by our proposed ap-proach.

This baseline uses IID resampling for ensemble construc-tion, and CEC for inference. Comparing the performance of our proposed model to this approach allows us to evalu-ate the improvement achieved by RSR for sampling, while controlling for the inference method (CEC) used by our pro-posed approach.
We evaluate the methods on synthetic and real world net-work data. Synthetic datasets are generated with a latent group model [15]. They are homogeneous (i.e., with a sin-gle object type) data graphs with autocorrelation due to an underlying (hidden) group structure. Each object has a boolean class label C (that is determined by the type of group to which it belongs), and three attributes. The class label C has an autocorrelation level of 0.75. We in-dependently constructed five training and test pairs of such datasets, each consisting of 500 objects.

The Facebook dataset used in this work is a sample of Pur-due University Facebook network. We construct a friend-ship graph from the links between friends. Each user has a boolean class label which indicates whether their political view is  X  X onservative X . In addition, we considered nine node features which record user profile information. We use 4 sampled networks of users (based on membership in various Purdue subnetworks): [Purdue Alum X 07, Purdue X 08, Pur-due X 09, Purdue X 10] with node sizes of: [921, 827, 1268, 1384] respectively. Then we construct 4 different training and test pairs by testing on one subnetwork and training on two sub-networks from the previous and preceding class networks. For example we learn the model from Purdue Alum X 07 and Purdue X 09, and apply the model on Purdue X 08.
The RSR algorithm uses a subgraph size b =50and b = 10 for the synthetic and Facebook experiment, respec-tively. The methods described are learned and evaluated using RDNs as the base collective classification model, us-ing 450  X  500 Gibbs iterations for collective inference. We use the following setting to compare the various approaches.
For each experiment, the proportion of the test set that is labeled before inference is specified, and for each trial a random set of nodes is chosen to label. The random la-beling process is repeated 10 times. The area under the ROC (AUC) is measured to assess the prediction accuracy of each model. The 10 trials are repeated for 4 training and test pairs, and the averages of the 10  X  4=40AUC measurements from each approach are reported. Note that, all methods are run on the same random labeling of the Figure 2: Synthetic experiments show significant ac-curacy improvement of RSR-CEC at various propor-tions of available true labels in the test graph. test set. From each training test set and for each sam-pling approach, we construct 5 bootstrap pseudosamples and learn the ensemble models (i.e., m = 5). This is repeated for 4 different labeling proportions ( l ) in each experiment. l = { 10% , 30% , 50% , 70% } denotes the x-axis in the figures, while the y-axis plots the AUC values. Figures 2 and 3 show the results of the synthetic and Facebook experiments, respectively. The main finding is that our proposed RSR-CEC approach has significantly higher classification accuracy than all the baseline comparison meth-ods at all percent labelings, and across both the synthetic and Facebook experiments. We measured significance using paired t-tests and all significance reported here correspond to p&lt; 0 . 0001 unless stated otherwise. The superior per-formance of RSR-CEC can be explained by the combined benefit of learning and inference variance reduction.
In addition, the accuracy of the single model baseline is significantly less than all the ensemble models, at all per-cent labelings for both experiments. Moreover, IID-CEC significantly outperforms IID-RE at all percent labelings for both experiments. This is because CEC reduces inference variance while RE only reduces learning variance. RE ap-plies the models independently for inference which does not reduce inference variance X  X ince prediction aggregation hap-pens after inference, possibly after inference variance has propagated through the graph. Furthermore, RSR-RE sig-nificantly outperforms IID-RE at all percent labelings for both experiments, with p&lt; 0 . 01 and p&lt; 0 . 03 for the 50% and 70% synthetic experiments. This is because RSR captures more variance in the data than IID resampling. Therefore, RE can reduce more learning variance when used with RSR. Finally, IID-CEC significantly outperforms RSR-RE at { 10% , 30% , 50% } for the synthetic experiment. This shows that CEC can reduce both learning and inference vari-ance, even when combined with IID resampling. Figure 3: Facebook experiments show significant ac-curacy improvement of RSR-CEC at various propor-tions of available true labels in the test graph.
We also ran an experiment to test the effect of increasing the number of models on performance of ensembles learned using different resampling approaches, the results shown in Figure 4 show that while controlling for the inference ap-proach, ensembles learned using IID bootstraps perform closer to those learned from RSR bootstraps, as the number of base models increase. This confirms our theoretical finding.
To summarize the empirical findings:
There are two main lines of research related to the anal-ysis we present here. Error analysis for ensemble classifiers and collective classification models, and work on relational methods that reduce bias or variance. For error analysis, earlier work has used conventional bias/variance analysis to evaluate model performance [4, 8, 9, 11]. However, the focus has been on single models and on errors in learning.
For error analysis of ensembles, Breiman [3] has shown theoretically that bagging reduces total classification error by reducing the error due to variance. However, the work is based on the assumption that the data is i.i.d. and therefore the models run exact inference. Consequently, Breiman X  X  work has focused on theoretical analysis for this type of Figure 4: Synthetic experiments show accuracy cov-ergence using IID resampling and RSR resampling as the number of base models increases. models where the error is only associated with the learn-ing process. Other work has presented an analytical frame-work to quantify the improvements in classification results due to combining or integrating the outputs of several classi-fiers [19]. Their work is based on analysis of decision bound-aries and is applied on linearly combined neural classifiers.
For error analysis of collective classification models, Neville and Jensen [14] have shown that collective classification in-troduces an additional source of error due to variation in the inference process. While other work has presented another type of error decomposition for collective classification [20], by studying the propagation error in collective inference with maximum pseudolikelihood estimation.

Some work [5, 6] has extended ensembles to improve classi-fication accuracy for relational domains. Including a method for constructing ensembles while accounting for the increased variance of network data [6], a method for ensemble classifi-cation on multi-source networks [5], and an ensemble method for reducing variance in the inference process for collective classification [5]. Other recent work [7] has showed that stacking [12] improves collective classification by reducing inference bias. This work compares to our model as it evalu-ated model performance in single source relational datasets. However, it is interesting to note that stacking reduces in-ference bias, while our method reduces inference variance.
We presented theoretical analysis that shows that an in-terleaved ensemble model reduces total loss over a simple relational ensemble model which reduces total loss over a single model (corollary 1). We showed that this is achieved by the reduction of variance (theorem 1), not bias (theorem 2). We proposed an ensemble model that significantly im-proves classification accuracy of network data by reducing errors due to variance in both learning and inference. We evaluated our ensemble model using both synthetic and real-world classification tasks and empirically showed its superior performance to alternative approaches. This research is supported by NSF under grant number(s) IIS-1149789 and CCF-0939370. The U.S. Government is au-thorized to reproduce and distribute reprints for governmen-tal purposes notwithstanding any copyright notation hereon. [1] A. V. Assche, C. Vens, H. Blockeel, and S. Dzeroski. A [2] R. S. Y. F. P. Bartlett and W. Lee. Boosting the [3] L. Breiman. Bagging predictors. MLJ X 96 . [4] P. Domingos. A unified bias-variance decomposition [5] H. Eldardiry and J. Neville. Across-model collective [6] H. Eldardiry and J. Neville. A resampling technique [7] A. Fast and D. Jensen. Why stacked models perform [8] J. Friedman. On bias, variance, 0/1-loss, and the [9] S. Geman, E. Bienenstock, and R. Doursat. Neural [10] A. HeB and N.Kushmerick. Iterative ensemble [11] G. James. Variance and bias for general loss functions. [12] Z. Kou and W. W. Cohen. Stacked graphical models [13] S. Natarajan, T.Khot, K. Kersting, B. Gutmann, and [14] J. Neville and D. Jensen. A bias/variance [15] J. Neville and D. Jensen. Leveraging relational [16] J. Neville and D. Jensen. Relational dependency [17] C. Preisach and L. Schmidt-Thieme. Ensembles of [18] J. Quinlan. Bagging, boosting and c4.5. In AAAI X 96 . [19] K. Tumer and J. Ghosh. Analysis of decision [20] R. Xiang and J. Neville. Understanding propagation [21] Y.Freund and R.E.Schapire. Experiments with a new
