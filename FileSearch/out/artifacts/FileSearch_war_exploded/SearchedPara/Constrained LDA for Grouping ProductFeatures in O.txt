 One form of opinion mining in product reviews is to produce a feature-based summary [1]. In this model, product features are first identified, and positive and negative opinions on them are aggregated to produce a summary of opinions on the features. Product features are attributes and components of products, e.g.,  X  X icture quality X ,  X  X attery life X  and  X  X oom X  of a digital camera.

In reviews (or any writings), people o ften use different words and phrases to describe the same product feature. For example,  X  X icture X  and  X  X hoto X  refer to the same feature for cameras. Grouping such synonyms is critical for opinion summary. Although WorldNet and other thesaurus dictionaries can help to some extent, they are insufficient because many synonyms are domain dependent. For example,  X  X ovie X  and  X  X icture X  are synonyms in movie reviews, but they are not synonyms in camera reviews as  X  X icture X  is more likely to be synonymous to  X  X hoto X  while  X  X ovie X  to  X  X ideo X . This paper deals with this problem, i.e., grouping domain synonym features. We assume that all the feature expressions have been identified by an existing algorithm.

Topic modeling is a principled approach to solving this problem as it groups terms of the same topic into one group. This paper takes this approach. However, we believe instead of letting a topic modeling method to run completely unsu-pervised, some pre-existing knowledge can be incorporated into the process to produce better results. The pre-existi ng knowledge can be inputted manually or extracted automatically. In this work, we extract such knowledge automatically.
Topic modeling methods can be seen as clustering algorithms that cluster terms into homogeneous topics (or clusters). In the classic clustering research in data mining, there is a class of semi-supervised clustering algorithms which allow constraints to be set as prior knowledge to restrict or to guide clustering algorithms to produce more meaningful clusters to human users [2, 3]. These con-straints are in the forms of must-links an d cannot-links. A must-link constraint specifies that two data instances must be in the same cluster. A cannot-link constraint specifies that two data instances cannot be in the same cluster.
In this paper, we incorporate these two types of constraints into the popular topic modeling method LDA to produce a semi-supervised LDA method, called constrained-LDA . To the best of our knowledge, this is the first constrained LDA model which can process large scale constraints in the forms of must-links and cannot-links. There are two existing work by Andrzejewski and Zhu [4, 5] that are related to the proposed model. However, [4] only considers must-link constraints. In [5], the number of maximal cliques grow exponentially in the process of encoding constraints. Thus, [5] cannot process a large number of constraints (see Section 2). As we will also see in the related work section, our method of incorporating the two types of constraints is entirely different from the way that they did.

Although we call them must-link and cannot-link constraints, they are treated as  X  X oft X  rather than  X  X ard X  constraints in the sense that they can be violated or relaxed in the topic modeling proce ss. The relaxation mechanism is needed because some constraints may not be corr ect especially when the constraints are extracted automatically. In our case, all constraints are extracted automatically with no human involvement. Thus, the constraints may be more appropriately called probabilistic must-link a nd cannot-link constraints.

On extracting must-link and cannot-link constraints for our application, we use two observations. First, we observed that a review sentence may comment on several product features, e.g.,  X  X  like the picture quality, the battery life, and zoom of this camera X  and  X  X he picture quality is great, the battery life is also long, but the zoom is not good X . From either of the sentences, we can see that the features,  X  X icture quality X ,  X  X attery life X  and  X  X oom X  are unlikely to be synonyms or belonging to the same topic simply because people normally will not repeat the same feature in the same sentence. This observation allows us to extract many cannot-link constraints automatically. As for must-links, we observed that two noun phrases that shared one or more words are likely to fall into the same topic, e.g.,  X  X attery life X  and  X  X attery power X . Clearly, the 2 methods for identifying constraints are not perfect, i.e., they may find wrong constraints. The constraint rel axation mechanism comes to help.

Experiments show that the proposed constrained-LDA produces significantly better results than the original LDA and the latest multilevel topic modeling method, mLSA [6] which also uses LDA. This study is related to 2 research areas, topic modeling and synonym grouping. Topic Modeling and LDA: Blei et al. [7] proposed the original LDA using EM estimation. Griffiths and Steyvers [8] applied Gibbs sampling to estimate LDA X  X  parameters. Since these works, many variations have been proposed. In this paper, we only focus on the variations that add supervised information in the form of latent topic assignments.

Blei and McAuliffe [9] introduced a sup ervised latent Dirichlet allocation (sLDA). In sLDA, the authors added to LDA a response variable associated with each document, such as document X  X  class label or document X  X  rating. Ra-mage et al. [10] proposed a labeled LDA which considers the tag information of the documents. Chang and Blei [11] developed a relational topic model by adding the link information between documents. All these studies improve LDA by adding the labeled information of documents, whereas our constrained-LDA adds supervision to individual terms.

In [4], predefined topic-in-set knowledge (which means predefined terms for certain topics) was added to supervise the topic assignment for individual terms. Compared with our model, their model only used the must-link knowledge, not cannot-links. Moreover, our model X  X   X  X opic-in-set knowledge X  is updated dynam-ically after each Gibbs sampling, rather than fixed as predefined. Probability information is also introduced to the  X  X opic-in-set knowledge X .
 In [5], must-link and cannot-link constraints were encoded with a Dirichlet Forest and were further incorporated in to LDA. However, their model has a fa-tal limitation, as illustrated in Section 3.3 of [5], namely, the number of maximal cliques Q ( r ) in a connected component of canno t-links X  complementary graph can grow exponentially O 3 | r | / 3 ,where | r | is the size of cannot-links X  comple-mentary graph. In our experiments (see Section 5), when 1/20 constraints in Table2areused, Q ( r ) are 992 and 432 on camera and phone data sets, respec-tively; when 1/5 constraints are used, Q ( r ) grow to 3,019,414 and 3,254,972, and then the program, downloaded from [5] authors X  website 1 , crashed our server computer (2 Quad-Core AMD Opteron Processors, 2.70 GHz, 16GB Memory). Synonyms Grouping: In [12], the authors proposed a method based on several similarity metrics to map discovered feature expressions to features in a given feature taxonomy of a domain. This is very different from our work as we do not have predefined feature taxonomy. The proposed method produces group-ings automatically. [13] grouped product features using WordNet synonyms with poor results. [14] extracted and clustered semantic properties of reviews based on pros/cons annotations, which is different from our work of grouping product fea-tures (also we do not have pros/cons). In [15], a semi-supervised learning method is used. However, it requires the user to provide labeled examples, whereas this study does not need any pre-labeled exam ples. It thus solves a different prob-lem. In [6], product features were grouped using a multilevel latent semantic association technique, called mLSA. At an y level of their multilevel algorithm the original LDA is directly applied. We propose constrained-LDA . The original LDA is a purely unsupervised model, ignoring any pre-existing domain knowledge. However, as it is known in the semi-supervised clustering re-search [2, 3], the pre-existing knowledge can guide clustering algorithms to pro-duce better and/or more meaningful clusters. We believe that they can help LDA as well, which is essentially a clustering algorithm. In our application domain, the prior knowledge about product features can help group domain synonym fea-tures, as explained in Section 1. In this section, we first give an introduction to LDA and then present the proposed constrained-LDA which can use pre-existing knowledge expressed as must-link and cannot-link constraints. 3.1 Introduction to LDA A variety of probabilistic topic models have been proposed, and LDA is one of the most popular topic modeling methods [16]. Similar to other methods, LDA X  X  input is a term  X  document matrix, and it outputs the document-topic distribution  X  and topic-word distribution  X  . In order to obtain the distributions  X  and  X  , two main algorithms were proposed, EM [7] and Gibbs Sampling [8]. In this study, we use the Gibbs Sampling. For Gibbs sampling based LDA, the most important process is the updating of topic for each term in each document according to the probabilities calculated using Equation 1.
 where z i = k represents the assignment of the i th terminadocumenttotopick, w i = v represents that the observed term w i is the v th term in the vocabulary of the text corpus, and z  X  i represents all the topic assignments excluding the i th term. C WT vk is the number of times that term v is assigned to topic k, and C DT dk is the number of times that topic k has occurred in document d. Furthermore, K is the number of topics (which is an input given by the user), V is the size of the vocabulary,  X  and  X  are the hyper-parameters for the document-topic and topic-word Dirichlet distributions, respectively. (  X  and  X  are set to 50/K and 0.01 by default.) After N iterations of Gibbs sampling for all terms in all documents, document-topic distribution  X  and topic-word distribution  X  are finally estimated using Equations 2 and 3. 3.2 Constrained-LDA For constrained-LDA, constraints from the existing knowledge are added, and each term in the constraints is assumed to belong to only one topic. Compared with LDA, constrained-LDA has 2 more inputs, a set of must-link constraints and a set of cannot-link constraints. The main idea of the proposed approach is to revise the topic updating probabilities computed by LDA using the probabilities induced from the constraints. That is, in the topic updating process (shown in Equation 1), we compute an additional probability q ( z i = k ) from the must-links and cannot-links for every candidate topic in 1, 2,, K, and then multiply it to the probability calculated by the original LDA model as the final probability for topic updating (see Equation 4).
 As illustrated by Equations 1 and 4, q ( z i = k ) plays a key role in constrained-LDA , because q ( z i = k ) represents intervention or help from pre-existing knowl-edge of must-links and cannot-links. In this study, q ( z i = k ) is computed as follows: For the given term w i ,if w i is not constrained by any must-links or is calculated using the following 4 steps in Figures 1 and 2.
 Step 1 -get the must-topics weight and cannot-topics weight of w i .Heremust-topics mean the topics that the term w i should be grouped into, while cannot-topics mean the topics that the term w i should not be grouped into. For the given term w i , its must-linked and cannot-linked terms are first found by querying must-links and cannot-links stores. Second, the topics of these terms are further obtained from the topic modeling. Then, we can obtain w i  X  X  must-topics and cannot-topics weights.
 For example, w i  X  X  must-linked and cannot-linked terms are M 1 , M 2 and C 1 , C , C 3 respectively. Furthermore, M 1 , M 2 and C 1 , C 2 , C 3 are assigned to topic k must-topics and cannot-topics weights are weight( w i , T k ( |{ M 1 ,M 2 }| ))=weight ( w i , T k (2))=2 and weight( w i , t k ( tively. Here, weight( w i , T k )orweight( w i , t k )istheweightthat w i should or should not be assigned to topic k; T k (2) represents there are 2 linked terms being assigned to topic k in the must category, and t k (3) represents there are 3 linked terms being assigned to topic k in the cannot category.
 Step 2 -adjust the relative influences between must-link category and cannot-link category. In extracting the two types of constraints, the qualities of must-links and cannot-links may be different from each other. We use a damping factor  X  to adjust the relative influences based on the constraint qualities. Specifically, all the must-topics X  weights are multiplied by  X  , while the cannot-topics X  weights are multiplied by (1- X  ).

Following the above example, T k (2) is adjusted to T k (2  X   X  ) while t k (3) to t (3  X  (1  X   X  )). In this study, the default value of  X  is empirically set to 0.3.
Based on the results of above two steps, Steps 3 and 4 are fur-ther proposed to convert the weights of must-topics and cannot-topics to { q ( z i = k ) | k =1 ,...,K } , as shown in Figure 2.
 Step 3 -aggregate the weights for each candidate topic. For the given term w i ,its candidate topics can fall into one of the three types, must-topics, unconstrained topics and cannot-topics. Recall must-topics mean the topics that w i should be assigned to while cannot-link means the topics that w i should not be assigned to. Thus, for calculating the probability that w i will be assigned to candidate topic k, if k is in must-topics, we add weight ( w i ,T k )to q ( z i = k )inorderto enhance the probability that w i is assigned to topic k; if k is in cannot-topics, we subtract weight ( w i ,t k )to q ( z i = k ) in order to decrease the probability that w i is assigned to topic k (lines 2 to 6 in Figure 2).

In the above example, for the candidate topic k, the weight q ( z i = k )is: Step 4 -normalize and relax the weight of each candidate topic. Since the constraints are not guarant eed to be correct especially when the constraints are extracted automatically, there should be a parameter to adjust the constraint X  X  strength to the model according to the quality of the constraints. When the constraints are completely correct, the model should treat these constraints as hard-constraints; when the constraints are all wrong, the model should discard them. In order to achieve this aim, { q ( z i = k ) | k =1 ,...,K } are adjusted by the relaxation factor as follows: Before being relaxed, { q ( z i = k ) | k =1 ,...,K } are normalized to [0, 1] using Equation5(lines8to11inFigure2).InEquation5,maxandminrepresent the maximum and minimum values of { q ( z i = k ) | k =1 ,...,K } , respectively. Then, { q ( z i = k ) | k =1 ,...,K } are relaxed by the relaxation factor based on Equation 6 (line 12 in Figure 2). The default value of is set to 0.9 in our study (see the evaluations in Section 5.6). Note that, for our application of grouping product features, each product feature is considered as a ter m. Moreover, only  X  needs to be estimated by Equation 3 to output a set of topics and each topic contains a set of terms which belong to the topic. We now come back to our application and discuss how to extract constraints automatically. The general idea has been discussed earlier. For completeness, we briefly discuss them here again.

Must-link: If two product features f i and f j share one or more words, we assume them to form a must-link, i.e., they should be in the same topic, e.g.,  X  X attery power X  and  X  X attery life X .

Cannot-link: If two product features f i and f j occur in the same sentence and they are not connected by  X  X nd X , the two features form a cannot-link. The reason for this is that people usually do not repeat the same feature in the same sentence. Features linked by  X  X nd X  are not used as our experience showed that  X  X nd X  can be quite unsafe. It frequently links features from the same topic, especially product names based features. In this Section, we evaluate the propose d constrained-LDA model in a variety of settings, and compare it with the ori ginal LDA and the recent multilevel mLSA. We do not compare with the similarity based method in [12] because their technique requires a given feature taxonomy, which we do not use. 5.1 Data Sets In order to demonstrate the generality of the proposed algorithm, experiments have been conducted in two domains: digital camera and cell phone. We used two data sets with feature annotations from the Customer Review Datasets 2 , which have been widely used by researchers for opinion mining. We selected the reviews for digital cameras and cell phones. Their feature annotations are used in our system. Since these two data sets are too small for topic modeling, we crawled many other camera and phone re views from Amazon. com. The details of each data set are given in Table 1.
 5.2 Gold Standard Since the product features in the Customer Review Datasets have already been annotated by human annotators, these annotated product features are grouped manually to form a gold standard for each data set. For the digital camera data set, we group the features into 14 topics, according to the camera X  X  taxonomy published by Active Sales AssistantTM, a product of Active Decisions, which is available at www.activebuyersguide.com [12]. For the cell phone data set, the topics published by Google products are adopted, and all the cell phone features are grouped into 9 topics. 5.3 Evaluation Measure The performance of our product features grouping algorithm is evaluated using Rand Index [17], which has been used by several researchers [14, 18, 3]. Rand Index is also the evaluation measure used in [6]. 5.4 Compared with LDA [5] proposed the most r ecent LDA model (called DF-LDA )thatcanconsider must-link and cannot-link constraints. However, as explained in Section 2.1, DF-LDA cannot process a large number of constraints. Due to DF-LDA  X  X  limitation, we only report the comparison results with the original LDA. Both the original LDA and the proposed constrained-LDA were run using different numbers of topics, 20, 40, 60, 80, 100 and 120, in the two domains. Note that LDA requires the number of topics to be specified by the user. Note also we do not report the results of using the original numbers of topics (14 and 9) for the two data sets as they were poorer (see the trends in Figure 3). Using only must-links, only cannot-links, and their combination were all experimented. The number of constraints extracted from each data set is given in Table 2. All the results are shown in Figure 3.
From Figure 3, we can see that the patterns are about the same for differ-ent methods on different data sets, which show that the results are consistent. Below we make some additional observations: ( 1 )All the constrained methods ( LDA+cannot , LDA+must and LDA+must+cannot ) perform much better than the original LDA model (LDA). For smaller numbers of topics, the improve-ments were more than 10% for the digital camera corpus, and around 7% for the cell phone corpus. With more topics, the improvements are slightly less, but still 7% for the digital camera and 4% for the cell phone. ( 2 )Both cannot-links ( LDA+cannot ) and must-links ( LDA+must ) perform well, although cannot-links are slightly more effective than must-links on average. This phenomenon indi-cates that our assumption about cannot-link is reasonable and the quality of the extracted cannot-links is good. When the number of topics is small or large, the must-links are slightly better than cannot-links. We believe the reason is that in these two ends, cannot-lin k terms were either forced into the same topics (for a small number of topics), or easily spread into too many topics. The original LDA also shows this behavior, which is fairly easy to understand. ( 3 )The combina-tion of must-links and cannot-links ( LDA+must+cannot ) consistently outper-forms each individual type of constraints alone ( LDA+cannot and LDA+must ). Although the margins of improvements were not very large, they were consis-tent. This also indicates that the must-link and cannot-link constraints are al-ready quite effective individually.( 4 )In practice, it is often more effective to use a smaller number of topics, which are easy to understand and to handle by the users. In both cases, 40 to pics seem to be optimal.

In summary, we can see that unsupervised topic modeling can be improved by adding must-link and cannot-link constraints. Note that each feature expression is considered as a term in all our experiments.
 5.5 Comparing with mLSA As mentioned earlier, the recent multileve l latent semantic association method mLSA [6] solves the same problem as we do. [6] shew that mLSA performs better than the existing methods, e.g., LDA-based and Kmeans-based algorithm. We thus only compare the proposed constrained-LDA with mLSA , but not other existing methods. The comparisons are made based on both the digital camera corpus and the cell phone corpus. The results are shown in Figure 4. We only used 40 topics, which appeared to be the optimal number among our tested topic numbers in Figure 3.

As demonstrated in Figure 4, mLSA (2: red bar) achieves encouraging re-sults by transforming the input document content before applying LDA. Our constrained-LDA model does not make any efforts to re-organize or transform the input document content, and our input is the set of original reviews. How-ever, the results produced by constrained-LDA ( LDA+cannot , LDA+must and LDA+must+cannot ) are all substantially better than those of mLSA .This observation shows the positive influence of constraints. 5.6 Influence of Parameters Compared to the original LDA model, the proposed constrained-LDA has two additional parameters, i.e., damping factor  X  and relaxation factor  X  ,asmen-tioned in Section 3.2. In this section, we discuss their influences to the overall performance.

Influence of the damping factor - X  : Recall that damping factor  X  is used to ad-just the relative influences of must-links and cannot-links on the proposed model. In Figure 5,  X  =0 means the proposed model is only constrained by cannot-links, whereas  X  =1 means that the proposed model is only constrained by must-links. That is, larger  X  values mean more influences of must-links and less influence of cannot-links. As shown in Figure 5, with increased influence of must-links over cannot-links, the performance of constrained-LDA improves slightly. However, when there is only must-links (  X  =1), the performance drops sharply to the low-est point. This illustrates the synergetic effect of must-links and cannot-links: they help each other. Since the  X  values after 0.3 produce very similar results, we used  X  =0.3 as the default for  X  . The experimental results in Figures 3 and 4 all used this default damping factor.

Influence of the relaxation factor - X  : In this study, the relaxation factor  X  represents the strength of the co nstraints on the LDA model. When  X  =0, it means that no constraint is added to the LDA model. Then, constrained-LDA reduces to the original LDA. When  X  =1, it means that both must-link and cannot-link constraints become hard constraints and cannot be violated. The influence of  X  on the overall performance is shown in Figure 6.
As shown in Figure 6, with the growth of the strength of the constraints, the performances of LDA+cannot , LDA+must and LDA+must+cannot increase considerably. This observation not only shows that the constraints clearly help the performances of topic modeling (or LDA), but also shows that the qualities of the extracted must-links and cannot-links are quite good, especially the extracted cannot-links. In fact, using both must-link and cannot-link constraints, when  X  = 1, the results are the best for both the digital camera data and cell phone data. We use  X  =0.9 as the default in the system as in general one may not be able to extract very high quality constraints. In our experiments reported earlier in Figures 3, 4 and 5, the default  X  =0.9wasused. This paper enhanced the popular topic modeling method LDA with the ability to consider existing knowledge in the form of must-link and cannot-link con-straints. In our application, we experimented with two opinion mining data sets to group product feature synonyms, and the proposed Constrained-LDA outper-formed the existing methods by a large ma rgin, which showed that constraints as prior knowledge can help unsupervised topic modeling. Moreover, this paper also proposed two methods to extract the two types of constraints automatically. Experimental results showed that their qualities were high (see Figure 6).
