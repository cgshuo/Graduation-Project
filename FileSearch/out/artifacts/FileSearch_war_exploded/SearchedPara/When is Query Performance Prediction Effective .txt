 The utility of Query Performance Prediction (QPP) meth-ods is commonly evaluated by reporting correlation coeffi-cients to denote how well the methods perform at predict-ing the retrieval performance of a set of queries. However, a quintessential question remains unexplored: how strong does the correlation need to be in order to realize an in-crease in retrieval performance? In this work, we address this question in the context of Selective Query Expansion (SQE) and perform a large-scale experiment. The results show that to consistently and predictably improve retrieva l effectiveness in the ideal SQE setting, a Kendall X  X  Tau corre -lation of  X   X  0 . 5 is required, a threshold which most existing query performance prediction methods fail to reach. Categories and Subject Descriptors: H.3.4 Information Storage and Retrieval : Information Search and Retrieval General Terms: Experimentation Keywords: Evaluation, Query Performance Prediction
Predicting the retrieval performance or the degree of dif-ficulty of a query is a challenging research area which has attracted a significant amount of attention in recent years [ 2, 4, 6]. A reliable and accurate prediction mechanism would enable the development of adaptive components within re-trieval systems. For instance, if the performance of a query is considered to be poor, remedial action can be taken by the system to try and ensure that the user X  X  information needs are satisfied. This may be performed through asking for refinement of the query, or some subsequent automatic disambiguation process. On the other hand, if the perfor-mance of a query appears sufficiently good, the query can be further improved by some affirmative action such as query expansion.

While these are the perceived benefits of developing QPP methods, current evaluations seldom consider whether a QPP method actually realizes these presumed benefits. The focus of QPP evaluations has been on producing methods which and the predicted performance. In this work we investi-gate the correspondence between the often reported rank man X  X   X  and/or Pearson X  X  r .
 correlation coefficient  X  of a QPP method and the change in retrieval performance in the operational setting of SQE when QPP is applied. The idea of SQE is to utilize pseudo-relevance feedback in a query-adaptive manner instead of applying it uniformly to all queries. The rational being, that queries which perform well are also likely to benefit from automatic query expansion (AQE), while queries that perform poorly are likely to have their result X  X  quality fur -ther decreased due to query drift [1]. Thus, if we can predict the performance of a query, we can selectively expand only the queries that are predicted to perform well according to the QPP method. Since, between one fifth and one third of queries perform worse when AQE is applied [3, 5], SQE aims to reduce any loss in the application of AQE. So our goal, here, is to estimate a lower bound for the strength of the correlation coefficient  X  that a QPP method needs to achieve in order be likely to obtain increases in retrieval e f-fectiveness when performing SQE. As a single QPP method and its SQE application is insufficient to draw conclusions about the relationship between the evaluation measure and retrieval performance, we rely on a large number of gen-erated QPP and retrieval results to perform a large-scale experiment.
Ideally, we would like to perform the following experiment: given a large number of QPP methods, a large number of retrieval approaches and a set of queries, (1) let each QPP method predict the queries X  performance and determine the method X  X  performance in terms of  X  , (2) use the predictions to determine which queries (not) to expand, (3) perform re-trieval experiments with and without AQE and finally (4) determine at what level of  X  the retrieval approaches gener-ally show improvements on their selectively expanded resul ts in comparison to the uniformly expanded results. In practic e though, this approach is not feasible for two main reasons. Most importantly, existing QPP methods only reach corre-lations of  X   X  0 . 5 [4], which would not allow us to investigate the change in retrieval performance at higher correlations . Furthermore, not all retrieval approaches may strictly ad-here to the SQE assumption of top performing queries im-proving when applying AQE, a noise factor which needs to be taken into account and controlled.

For these reasons, we relied on a X  X heoretical X  X PP method to derive predictions across a wide range of  X   X  [  X  1 , 1]. As  X  is based on ranks, we can construct predicted query per-formance rankings by randomly permutating the true per-formance ranking of a set of queries. From the full range of  X  , we investigated sixteen  X  -intervals of size 0 . 05, starting at c  X  -interval, 1000 different predicted rankings were generate d.
In order to make our results generalizable and less depen-dent on a particular retrieval approach, we utilize the runs we are not interested in the document rankings themselves, but in the performance of each run on each query, here, we consider a run to consist of a list of average precision (AP) scores. Let  X  be the percentage of top performing queries of a set of queries that perform better when applying AQE and let m be the query set size. Based on the assumptions and observations made in the literature about AQE, we created 500 pairs of unexpanded ( run base ) and AQE runs ( run qe from the pool of available TREC runs for each setting of  X  = { 50 , 66 , 75 } % and m = { 50 , 150 } , the latter being typi-cal sizes of TREC query sets.

Each run base / run qe pair was derived by sampling AP val-ues from the pool of TREC runs available for each query. In order to ensure that the generated run pairs adhere to the SQE assumptions, a valid run pair has to fulfill three restrictions: (i) the AP scores of the  X  % top performing queries of run qe outperform run base and vice versa for the remaining queries, (ii) the mean average precision (MAP) of run qe improves over run base by between 15  X  30% and (iii) the optimal SQE run X  X  performance, where for each query the better of the two runs is chosen, increases by at least 3% over the MAP of run qe .

Given the 1000 predicted rankings in each  X  -interval and the 500 run pairs, SQE is thus performed 500 , 000 times per  X  -interval. For each run base / run qe pair and predicted rank-ing, the queries that are predicted to be among the top  X  % are expanded (the run qe result is picked), while the remain-ing queries are not (the run base result is picked), resulting in QPP-based SQE runs ( run psqe ).

In a second experiment, we consider the case of slightly violating the SQE assumption; the run base / run qe run pairs are  X  X erturbed X  such that p = 10% of the top  X  % perform-ing queries of run qe are randomly assigned AP values which are lower than those of the respective queries of run base To keep the MAP constant, the difference between the old and newly assigned AP is randomly redistributed among the other queries of run qe .
The application of QPP-based SQE can be considered suc-cessful if the MAP of run psqe is higher than of run qe . The re-sults are summarized in Table 1. Reported are the minimum  X  -intervals where the MAP of run psqe is higher than of run in { 25 , 50 , 75 } % of the 500 , 000 cases. For instance, in the case of 50 queries with the expansion threshold  X  set to 50%, the first  X  -interval for which at least a quarter of the QPP-based SQE runs have a higher retrieval effectiveness than the uniformly expanded runs, is c 0 . 3 = [0 . 3 , 0 . 35). Though not shown, we observed that for  X   X  0 . 3 and m = 50, run psqe can lead to a MAP below run base , which by way of construc-tion performs at least 15% worse than run qe . This changes as m increases, the results can be considered to be more stable and the outlying instances are less extreme.
The value of m has little influence though on the big pic-ture; in order to improve 50% of all instances when applying 2 TREC-{ 6,7,8,9 } , TREC-{ 2001,2004,2005,2006 } Table 1: Minimum  X  -interval where the MAP of run psqe is higher than of run qe in { 25 , 50 , 75 } % of all instances.
 QPP-based SQE,  X   X  0 . 4; this threshold increases to  X   X  0 . 5 when using the more reliable mark of 75% improving cases. Finally, the results of the perturbed setup in Table 1 show that even a small number of perturbed queries already has great influence on the usability of a QPP method in the SQE setting. If p = 10% of the top ranked queries are perturbed, QPP methods can still lead to improvements in retrieval ef-fectiveness. However, the minimum  X  -interval where 75% of the instances improve is considerably higher:  X   X  0 . 7. When further increasing the percentage of perturbed queries, no more consistent improvements in retrieval effectiveness ca n be observed in the SQE setting, independent of the quality of the predicted rankings.
In this work, we investigated the relationship between  X  and the retrieval performance when applying QPP in the SQE setting. It was shown, that moderate to high  X  coef-ficients are required to obtain reliable improvements in re-trieval performance. However, if the assumptions behind th e application of SQE are even slightly violated, the level of  X  required increases considerably. Given that current state -of-the-art QPP methods only obtain low to moderate correla-tions, it is unlikely that they are able to realize any tangib le and consistent increases in retrieval effectiveness. Furth er-more, we need to emphasize, that our results can only serve as an estimate of the lower bound for the level of  X  , as for instance we assumed  X  to be known. Nonetheless, these findings show that realizing the potential of QPP is difficult to achieve in practice and requires considerable further re -search. As a next step, a similar analysis will be performed on other tasks that use QPP, along with considering other QPP evaluation measures (such as Spearman X  X   X  ).
