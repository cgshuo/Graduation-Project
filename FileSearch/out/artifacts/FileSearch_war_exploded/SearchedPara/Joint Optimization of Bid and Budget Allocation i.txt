 This paper is concerned with the joint allocation of bid price and campaign budget in sponsored search. In this applica-tion, an advertiser can create a number of campaigns and set a budget for each of them. In a campaign, he/she can further create several ad groups with bid keywords and bid prices. Data analysis shows that many advertisers are deal-ing with a very large number of campaigns, bid keywords, and bid prices at the same time, which poses a great chal-lenge to the optimality of their campaign management. As a result, the budgets of some campaigns might be too low to achieve the desired performance goals while those of some other campaigns might be wasted; the bid prices for some keywords may be too low to win competitive auctions while those of some other keywords may be unnecessarily high. In this paper, we propose a novel algorithm to automatically address this issue. In particular, we model the problem as a constrained optimization problem, which maximizes the ex-pected advertiser revenue subject to the constraints of the total budget of the advertiser and the ranges of bid price change. By solving this optimization problem, we can obtain an optimal budget allocation plan as well as an optimal bid price setting. Our simulation results based on the sponsored search log of a commercial search engine have shown that by employing the proposed method, we can effectively improve the performances of the advertisers while at the same time we also see an increase in the revenue of the search engine. In addition, the results indicate that this method is robust to the second-order effects caused by the bid fluctuations from other advertisers.  X 
This work was performed when the first and the second authors were interns at Microsoft Research Asia.
 H.3.5 [ Information Systems ]: Information Storage and Retrieval -Online Information Services; J.0 [ Computer Applications ]: General Algorithms, Experimentation Budget allocation, Bid optimization, Sponsored search
Sponsored search is a popular format of online advertising and is also the main revenue source for search engine com-panies. In sponsored search, a list of ads is displayed along with the organic search results in response to a given query. Sponsored search results are produced by a different mecha-nism from that of organic search, though they are displayed simultaneously and have similar appearance. Generally, the organic search results are mainly generated based on the rel-evance of each web page to the query, while the sponsored search results are generated based on an auction process [20, 2, 13].

An advertiser can create a number of campaigns under an account. In each campaign, he/she sets a campaign budget, builds several groups of ad copies (creatives), and bids on some keywords with their match types 1 for each ad group. Each keyword is an auction entry that is supposed to be trig-gered by some user queries. When a user submits a query, the search engine will first retrieve the most relevant ads as candidates according to a matching function between the bid keywords and the query. Then these candidate ads will par-ticipate in an auction, and some ads (e.g., with the largest expected revenue for the search engine) will win and be dis-played on the search result page [13]. If an ad is clicked by the user, the corresponding advertiser will be charged by the search engine. Usually, the charged amount is determined by the generalized second price (GSP) [11] auction mechanism, which means that the advertiser X  X  cost of a click depends on the bid price of the next ad in the ranking list of the auc-tion. When a campaign runs out of budget, it will not be The match type might be exact match or broad match. permitted to participate in any auctions until the budget is i ncreased or the next budget period starts. For example, if the campaign budget is set at a monthly basis, the campaign will be re-involved in the auctions next month.

As can be seen above, besides creating ad groups and se-lecting bid keywords, an advertiser should also carefully con-sider two important problems as follows: a) Bid Price Setting. Different keywords correspond to different opportunities (e.g., search volumes) and different degrees of competition. In many cases, the bids for some keywords are too low to win the auctions while the bids for some other keywords are unnecessarily high. Usually, the optimal bid price setting is very difficult for an individual advertiser to reach since he/she does not have the access to the related information (e.g., the bids of other advertisers) and his/her competitors are also adjusting their bid prices dynamically. b) Campaign Budget Allocation. Similar to the case of keywords, different campaigns also have different oppor-tunities and competition. As a result, under an account, some campaigns may run out of budget very quickly, some campaigns consume their budgets quite slowly, and the bud-gets for other campaigns may never be used at all. This will constrain the overall effectiveness for the advertiser to utilize his/her budget.

Both of the above issues are critical for advertisers, how-ever, most advertisers have not been doing well in them according to our statistics (see Section 3). This is because many advertisers are managing hundreds of campaigns and tens of thousands of keywords, which makes it very difficult for them to manually tune the campaign budget allocation and keyword bid prices. There are some third-party tools to help the advertisers tune their bids; some advertisers even build tools themselves to manage the bids automatically. However, the market information they can get is still very limited, which restricts the effectiveness of the tools. In the research community, there have also been some attempts on preforming the task automatically (see Section 2). However, these works are still not sufficient to satisfy the practical requirements. For example, many works on keyword bid price optimization only consider the bid price when ranking the ads, but do not take relevance and position bias into consideration. For another example, although people have investigated keyword bid optimization, to the best of our knowledge, there is no work on campaign budget allocation yet in the literature.

In this paper, we propose a novel method to address the aforementioned issues. In particular, we propose jointly op-timizing the campaign budget allocation and bid price set-ting. That is, for a given advertiser account with multiple campaigns and an account-level budget, we try to find the optimal allocation of the account-level budget into each cam-paign, and to set the optimal price 2 , 3 for each bid keyword in the campaign simultaneously. Here we focus on the joint
N ote that not all clicks are created equal. An advertiser will give different bids for different keywords, for they have different value per click (VPC). In this work, we estimate the VPC of a keyword based on the idea proposed in [4, 20] and use the VPC as the upper bound of the bid price.
Usually an advertiser observes the ad campaign perfor-mance and takes reactions to change the bid so as to ap-proach the campaign goal. In this work, we find the optimal bid by maximizing the campaign goal directly, so the opti-mal bid is not a randomized value. optimization instead of optimizing campaign budget alloca-tion and keyword bid setting separately due to the following reason. Suppose for some campaign, there are many high-utility keywords (in other words, these keywords contain a lot of opportunities of advertising). In order to achieve sig-nificant performance regarding these keywords, one has to put a lot of money on them. However, if we cannot increase the budget for this campaign, we will miss a lot of these opportunities.

We formulate the problem as a constrained optimization, which takes the campaign budgets and the keyword bid prices as variables and finds their optimal values by max-imizing the advertiser revenue, with the constraint of the account-level budget. To efficiently solve the optimization problem, we employ the sequential quadratic programming method. Simulation results on the sponsored search log from a commercial search engine show that the proposed technol-ogy can effectively help advertisers improve their campaign performance under several metrics like click number, cost per click, and advertiser revenue. At the same time, we can also help the search engine obtain increased revenue. In ad-dition, the proposed method is robust to the second-order effects caused by the advertisers X  dynamical bid changes.
To sum up, the contributions of our work are listed as be-low. (i) We performed a comprehensive data study on the effectiveness of current campaign budget allocation and key-word bid price setting in sponsored search, and pointed out the importance and necessity of jointly optimizing them. (ii) We proposed a novel method for jointly optimizing bid and budget allocation. As far as we know, this is the first work on campaign budget allocation in the literature of sponsored search, and it is also the first work on consider keyword price setting and campaign budget allocation simultaneously.
As mentioned in the introduction, we focus on the joint optimization of campaign budget allocation and keyword bid price setting in this paper. That is, given an advertiser account with multiple campaigns and an account-level bud-get, we determine the optimal allocation of the account-level budget into each campaign, and set the optimal bid price for each bid keyword in the campaign. As far as we know, there is no work in the literature solving exactly the same prob-lem. Instead, there is only some related work on keyword bid price optimization. We will briefly review such work in Section 2.1. Besides, there is some other work on budget allocation across different keywords [3], different search en-gines [8], or different online adverting markets [21], whose problem definitions are totally different with what we con-cern about in this paper.
Chakrabarty et al [7] defined the weight and profit of each bid keyword, and proposed a knapsack based algorithm to find the optimal price setting that can maximize the adver-tiser revenue in sponsored search. The algorithm considered both single-slot and multi-slot auctions. Kitts et al [16] pro-posed a revenue optimization model based on the marketing factors that were related to ad slot positions, in order to solve the problem of keyword bid price setting. In [12, 17], a budget optimization problem was defined, in which the target is to find an optimal bid price setting to maximize the campaign performance under a given campaign budget. In particular, Feldman e t al [12] defined the cost and click functions considering the position of an ad and the average click-through rate (CTR) on the position, and then devel-oped a landscape algorithm to solve the optimization prob-lem in approximation. Muthukrishnan et al [17] extended the above algorithm using a stochastic model, in which each keyword has a click distribution instead of an exactly known click number, in the context of single-slot auction.
In addition, the following works also discuss the problem of keyword bid price optimization, but in different scenarios from the above ones. Dar et al [10] studied how to improve the performance of broad match of bid keywords for a given query. They defined the weight and utility function of each bid keyword, and proposed a flow graph based algorithm to work out the optimal setting for keyword bid prices. Broder et al [6] pointed out that different matched queries for a bid keyword in broad match had different utilities according to their relevance to the bid keyword, and thus they should have different bid prices. They proposed a statistical ap-proach to generate the corresponding bid prices. Borgs et al [5] studied the problem of keyword bid price setting given the budget on each keyword, and proposed an method to optimize the advertiser revenue across all keywords. More parts of the work are discussing the perturbation and con-vergence in their model.
In this section, we report our data analysis on sponsored search. We have used two kinds of data obtained from a mainstream search engine in our study: the auction log that records the detailed auction processes and the advertiser database that includes the bid keywords, bid prices, and the budget for each campaign. The data was collected in half a month, which contains over ten billion auctions and more than one hundred thousand advertiser accounts.
There can be several campaigns under the same advertiser account. In general, each campaign contains a set of ads (or ad groups) with the same campaign goal. Each campaign is assigned a budget, indicating the expected expense in a pe-riod of time (e.g., one month). In practice, due to the differ-ences in the advertising settings and the market dynamics, it is quite common that some of the campaigns run out of budget while the other campaigns under the same account do not. We call this kind of accounts partially-running-out-of-budget accounts (or p-accounts for short). Here we give some statistics about the p-accounts in Table 1.
 Table 1: Statistic of partially-running-out-budget accounts.
 From Table 1 we have the following observations. (i) A lthough the number of the p-accounts is relatively small (2.6%), their contribution to the search engine revenue is considerably large (31.6%). It is clear that the individual contribution of each p-account is much larger than that of other accounts. (ii) The potential revenue of the p-accounts is as much as 164.5% of the total revenue of sponsored search. This shows that improving p-accounts can result in a significant impact on the entire advertising system. (iii) The average campaign-level budget use ratio of the p-accounts is about 45.1%, and the total budget use ratio of the p-accounts is 11.5%. The potential of further increasing the budget use ratio for the p-accounts is higher than for the other accounts. This is because the p-accounts have at least one campaign (but not all campaigns) running out of bud-get, thus we can further improve their budget use ratio by simply reallocating the residual budget to that campaign(s). However, for other accounts this strategy will not help. (iv) For a p-account, the average campaign number is 15 and the maximum campaign number is 2,423. These large numbers suggest that it is difficult to manually adjust the campaign budget.
Bid price setting is also a non-trivial task. For a p-account, the average number of bid keywords is 10,735 and the max-imum is 1,818,285. It is clearly infeasible to manually set keyword bid prices for the p-accounts. Instead, automatic keyword bid price setting is desired. The tools from the third-party usually cannot have adequate market informa-tion to aid the bid tuning. For example, we may need to con-sider the following information. (i) First, according to the commonly-used auction mechanisms in commercial search engines, higher bid prices will increase the probability of win-ning more auctions and obtaining higher ranking positions. Figure 1 shows the percentage of ads that will get at least one position up if we increase their corresponding keyword bid prices to a certain degree. In particular, 57.36% ads will get position up if their keyword bid prices are increased by 10%, and 78.84% ads will get position up if their keyword bid prices are increased by 40%. (ii) Second, higher ranking positions usually mean more attention and clicks [15], ac-cording to Figure 2, which shows the relative CTR 5 of the top ad slots in the commercial search engine. As a result, if an advertiser increases the bid price, the ad will have more opportunities to be clicked and the campaign goal of the advertiser will be better realized.

However, given the constraint of campaign budget, usually we cannot increase the bid prices for all the keywords. In-stead, we have to balance between different keywords. Note that the utility of keywords are different from each other, and the return of lifting prices on some low-utility keywords might be very small. Therefore, we should consider the key-word utility when adjusting the keyword bid prices. For those keywords with low utility, the best choice may be to decrease their bid prices and instead put more money on the high utility keywords.
The data statistics reported in the previous section show that both campaign budget allocation and bid price setting are important to advertisers, but they are non-trivial to op-
T he potential revenue is calculated by summing up all the unused budgets of the p-accounts.
The relative CTR is normalized by dividing the CTR on each position by the CTR on the first position. Figure 1: The proportion of ad volume ranking one p osition up with the increased bid price. t imize. If we want to jointly optimize them, the task may become even more difficult. However, we would like to point out that it is necessary to perform the joint optimization.
On one hand, if we only perform bid price optimization, each campaign will be optimized independently. For cam-paigns that have run out of budget, the help from bid price optimization will be limited because the potential capacity of these campaigns is constrained. For campaigns that have a lot of unused budget, bid price optimization can help achieve better performance, but it is hard to take full use of the bud-get due to the constraint of the value per click (VPC) of the bid keywords. On the other hand, if we only perform budget optimization, the unused budget will be reallocated to the campaigns that have already or tend to run out of budget, and thus their performance will be improved. However, the campaigns (no matter they run out of budget or not) will lose the opportunity to further improve their performance since their current bid price settings might not be optimal. Therefore, we had better consider both bid price optimiza-tion and campaign budget allocation simultaneously. In this way, the unused budget can be moved to the appropriate campaigns and can be effectively used on the best keyword candidates.

Note that in terms of optimizing the performances of ad-vertisers, other efforts such as ad copy improvement, bid keyword selection, behavior and demography targeting, and landing page optimization are also important and effective. However, we will not discuss them as they are not in the scope of this paper.
In this section, we introduce the proposed method for joint optimization of bid price setting and campaign budget allo-cation. The key idea is to maximize the account-level ad-vertiser revenue subject to the constraints of account-level budget. To better illustrate this idea, we first give some necessary notations including the definition of winning price interval, which serves as a basis of the following discussions. Then we adopt a probabilistic model to approximate the probability of winning a certain ad position given a bid price. After that, we define an optimization problem based on the probability model, and convert the problem to be a sequen-tial quadratic programming problem. By solving the prob-lem, we can get the optimal solution to campaign budget allocation and bid price setting.
In the joint optimization of bid price setting and cam-paign budget allocation the input is an advertiser account A = { C 1 , C 2 , . . . , C m } , where m is the number of campaigns under account A and C i ( i = 1 , 2 , . . . , m ) is the i -th cam-paign. For simplicity, we will not distinguish ad group and ad in the following discussions. 6 Accordingly, we can denote g i denotes the original periodical (e.g., monthly) budget set by the advertiser, D i denotes the set of ads, and K i notes the set of bid keywords 7 in campaign C i , respectively.
The ad set D i can be written as D i = { d i, 1 , d i, 2 , . . . , d where l i is the number of ads in campaign C i and d i,s ( s = 1 , 2 , . . . , l i ) denotes the s -th ad in the campaign. The bid keyword set K i can be written as K i = { ( k i, 1 , b (0) ( k ber of bid keywords 8 in campaign C i , k i,t ( t = 1 , 2 , . . . , n denotes the t -th bid keyword, b (0) i,t ( t = 1 , 2 , . . . , n the original bid price for k i,t , and v i,t ( t = 1 , 2 , . . . , n notes the VPC that k i,t brings. We approximately estimate the VPC based on the idea proposed in [4, 20], and regard it as the upper bound of b (0) i,t [2, 11]. In addition, we denote the minimum reserve price as  X  b , which serves as the lower bound of the valid bids.

In sponsored search, the advertiser can associate several keywords to his/her ad. When a query is issued, an auc-tion might be triggered. If one of the associated keywords of an ad matches the query by the corresponding match func-tions to the match types of the keywords, the ad (together with the matched keyword) will be involved in the auction. Therefore, the candidates in the auction is actually a tuple t = 1 , 2 , . . . , n i . We call the tuple order item . For ease of reference, for an order item  X  , we also use ( ) w to denote the attribute associate with it, such as its keyword k  X  , bid price b , and VPC v  X  .

We use  X  to denote the maximum number of ad slots in each search result page of the sponsored search system. Suppose the ads are ranked in the auction according to their rank scores, then we have the following definitions.
Definition 1 (Winning Score). For an auction  X  , its winning score at position  X   X  (denoted by  X , X  ,  X  = 1 , 2 , . . . ,  X )
I n practice, the most relevant ad in an ad group will par-ticipate in the auction.
A keyword may have different match types and different bid prices accordingly. For simplicity, we regard them as different keywords.
The same keyword with different match types are regarded as different keywords in K i . is the least rank score that can make an order item get the  X  -th ad slot  X   X  in the auction. Let 0 , X  = +  X  , then we have
Definition 2 (Winning Score Interval). For an auc-tion  X  , its winning score interval at position  X   X  is [  X , X  (  X  = 1 , 2 , . . . ,  X ) , which is the range of the rank score that can make an order item exactly get the  X  -th ad slot  X   X  in the auction.

Mainstream search engines use the product of the bid price and the quality score as the rank score in their auctions [13]. Suppose the quality score of an order item  X  in an auction  X  is r  X , X  , which can be calculated based on a group of features such as the query-ad similarity, semantic similarity, taxonomy, user query time, user query location and so on [14, 15, 19]. As indicated by the subscript, the quality score r  X , X  of an order item can be different in different auctions, due to some contextual information related to time, location, and user for the triggering query [14]. Usually such a quality score indicates the probability that an ad will be clicked after it is noticed by users. In this context, we have the following definitions of winning price and winning price interval.
Definition 3 (Winning Price). Given an order item  X  in an auction  X  with its quality score r  X , X  , its winning price at position  X   X  (denoted by  X   X , X , X  ,  X  = 1 , 2 , . . . ,  X ) is  X  -th ad slot  X   X  in the auction. Let  X   X , 0 , X  = +  X  , and we
Definition 4 (Winning Price Interval). Given an order item  X  in an auction  X  with its quality score r its winning price interval at position  X   X  is [  X   X , X , X  ,  X  (  X  = 1 , 2 , . . . ,  X ) , which is the range of the bid price that can make  X  exactly get the  X  -th ad slot  X   X  in the auction.
In order to compute the expected advertiser revenue, we need to get the probability for an order item  X  with bid price b  X  to be ranked at position  X   X  in the auctions. 9 specifically, we define a probability distribution P  X  ( b
P  X  ( b  X  ) = ( p  X  (  X  1 | b  X  ) , p  X  (  X  2 | b  X  ) , . . . , p for  X  to be ranked in slot  X   X  when its bid price is b  X  , and p (  X   X +1 | b  X  ) denotes the probability for  X  to lose the auction (i.e., to be ranked lower than  X   X  ). It is clear that, To get the above probability distribution, we apply the Bayes theorem to each element of it.
Here p  X  (  X   X  ) is the probability of any ad being displayed at position  X   X  in the auctions that  X  participates in, which can be approximately obtained by simple counting in the histor-ical auction log. p  X  ( b  X  |  X   X  ) is the probability of observing b in the winning price interval at position  X   X  in the auction
N ote that we compute this probability at the order item level but not for each individual auction, mainly because of the concern of data sparseness.  X  that  X  participates in. A straightforward way is also to obtain this value by simple counting in the historical auction log. That is, for each auction  X  of  X  (  X  = 1 , 2 , . . . ,  X   X   X  denotes the number of auctions  X  participates in.), we calculate the winning price interval [  X   X , X , X  ,  X   X , X   X  1 , X  sition  X   X  from the auction log. If b  X   X  [  X   X , X , X  ,  X   X , X   X  1 , X  say that there is an observation of price b  X  . However, the problem with this approach is that we need to go through the entire log for every possible value of b  X  , which will be too costly when we performing the optimization. Therefore we propose a new approach as described below that can be much more efficient without revisiting the entire auction logs during the optimization process. Figure 3: A case of Gaussian fitting for the bound o f the winning price intervals.

For all auctions of  X  , we can calculate their winning price intervals at position  X   X  . As mentioned above, the lower bound and upper bound of the winning price interval are actually in fluctuation in different auctions. For simplicity, we use the following Gaussian distributions 10 to model the fluctuation of the bounds.
Here x and y are the random variables for the lower bound and upper bound of the winning price interval of  X  at posi-tion  X   X  , and the superscripts L and U stand for lower bound and upper bound respectively. In addition,  X   X   X , X  and  X  are the mean and standard deviation for the lower bounds of the winning price intervals at position  X   X  for all auctions of  X  . That is,
Similarly,  X   X   X , X   X  1 and  X   X , X   X  1 are the mean and standard deviation for the upper bounds of the winning price intervals at position  X   X  for all auctions of  X  . W e have tested several possible distributions including Gaussian, Beta, and Gamma distributions, and found Gaus-sian is one of the best choices. Due to space limit, we will not show the parameter fitting for the distributions, but we can show an running example like Figure 3. As this is an approximation for the real data, we will ignore the negative values from the Gaussian distribution, just like what we usu-ally do when we assume the heights of a group of people are sampled from a Gaussian distribution.
Thus p  X  ( b  X  |  X   X  ) can be computed as below.
Here  X  ( ) represents the cumulative distribution function of the standard normal distribution. In particular, for the first ad slot  X  1 , the upper bound y is infinity. Hence p y |  X  1 )  X  1, and then,
Similarly, for  X   X +1 , the lower bound x is zero. Hence p ( x  X  b  X  |  X   X +1 )  X  1, and then,
Figure 4 uses an example to explain the calculation of the probability p  X  ( b  X  |  X   X  ). Suppose the bid of an observation is 28 (cents), then the probability p  X  ( b  X  |  X   X  ) equals to the product of the area of the left shadow (probability of lower bound &lt; 28) and the area of the right shadow (probability of upper bound &gt; 28). Figure 4: An example of the probability density dis-t ribution of the upper bound and lower bound of a winning price interval.

So far we have discussed our probabilistic model for ad ranking based on the ad auction log data. Compared with the conventional ranking models, the probabilistic model is smooth and easy to be directly optimized. Note that this model can be designed in other forms with different data formats in different scenarios.
Given the definition of the probabilistic model described in the previous subsection, we can define the expected adver-tiser revenue. To ease the illustration, we further introduce two notations as below. (i)  X   X  -the position bias at slot  X  . As discussed in Section 3.2, the relative CTR (shown in Figure 2) indicates the probability of ads in the position  X   X  being noticed. Further considering the definition of qual-ity score r  X , X  , the actual probability of an ad being clicked when ranked on the slot  X   X  will be  X   X  r  X , X  [15]. (ii) c the cost for a click on  X  in an auction  X  where it is ranked on position  X   X  . According to the GSP system, the cost can that is ranked one slot lower than  X  in the auction  X  , and b  X   X  is its bid price.

The objective of the optimization problem is to maximize the total revenue of the advertiser account, which reflects the final profit the advertiser can make from the sponsored search. The constraints are the bounds of the bid prices and the campaign budget.

For all the campaigns in an advertiser account, the total expected click number can be written as click on  X  in one auction when the bid price is b  X  .
Considering the cost of click and the VPC of each bid key-word, we can get the expected advertiser revenue as follows,
Given the above objective function, we can formulate the joint optimization as below, where g i ( i = 1 , 2 , . . . , m ) and b  X  denote the variables of campaign budgets and keyword bid prices respectively. The minimum campaign budget is  X  , for the advertiser might not like to entirely close a cam-paign by letting g i = 0.
The above optimization problem is a typical constrained optimization problem. It can be approximately solved by means of sequential quadratic programming (SQP) [9] in an efficient manner.

Suppose  X  1 = { b  X  } (  X   X  C i , i = 1 , 2 , . . . , m ) denotes the vector of bid prices for all the order items in an advertiser account, and  X  2 = { g i } ( i = 1 , 2 , . . . , m ) denotes the vector of campaign budgets. Then  X  = (  X  T 1 ,  X  T 2 ) T is the vector of all variables. We can rewrite the optimization problem as the following form. in the following forms, h h h h 3 (  X  ) = g i  X   X  g  X  0 ( i = 1 , 2 , . . . , m ) h 4 (  X  ) = b  X   X   X  b  X  0 (  X   X  C i , i = 1 , 2 , . . . , m ) h 5 (  X  ) = v  X   X  b  X   X  0 (  X   X  C i , i = 1 , 2 , . . . , m ) The above problem can be approximately solved by SQP. In SQP, a quadratic programming (QP) subproblem is solved in each iteration which is obtained by linearizing the con-straints and approximating the following Lagrangian func-tion L (  X ,  X  ) quadratically.
Here  X  = {  X  i } is the Lagrangian multiplier. The opti-mization may start from any initial  X  (0) . Suppose  X  ( j ) solution in the j -th iteration,  X  ( j ) is the corresponding La-grangian multipliers, and H ( j ) = H (  X  ( j ) ,  X  ( j ) of the Lagrangian function, then the following QP subprob-lem should be solved in the ( j + 1)-th iteration.
Here  X  denotes gradient calculus. If z ( j ) is the solution of the above QP subproblem and w ( j ) is the correspond-ing multiplier of this subproblem, then we use the following formulas to update the solution of the SQP problem.
The above iterations lead to a local approximation of the solution. The algorithm can be stabilized by line search. By solving this SQP problem, we can get the optimal campaign budgets as well as the optimal bid price for each order item.
In this section, we first introduce our experimental set-tings, including the datasets, baseline algorithms, and eval-uation measures. Then we report the experimental results on our proposed algorithm and make analysis and discus-sions.
The data used in our experiments came from a main-stream commercial search engine. There are basically two types of data: auction log and advertiser database. The auc-tion log was collected in a month of 2011, containing over one billion auction events. The log was partitioned into two parts, one for training and the other for testing. The train-ing data was used as historical data to get the probability model for ad rank and the empirical values used in our algo-rithms. The test data was used for simulation [1] in order to evaluate the performance of each algorithm. The advertiser database is a snapshot in the same month, which contains about 150 thousand sponsored search accounts.
 We sampled 400 p-accounts to study in our experiments. Accordingly, over 1.2 million related auction events were ex-tracted from the auction log. We also got the bid price for each keyword and the budget for each campaign in these accounts from the advertiser database.
The proposed algorithm jointly optimizes the bid price and campaign budget. In order to understand the benefit of performing joint optimization, we will also investigate how it works if we only optimize bid price or campaign budget. This leads to two natural simplified methods for our algo-rithm. We also compare our algorithm with two state-of-the-art algorithms for bid price optimization. In addition, using the original bid prices and campaign budget is the pure baseline. Furthermore, we adopt a bidding strategy to mimic the second order effect by the bid fluctuations, and test the robustness of our proposed method. Therefore, as a whole, we have the following seven algorithms in our ex-periments.
 Original Bid Price and Campaign Budget (ORI).
 This algorithm uses the original keyword bid prices and cam-paign budgets in the experiment. This is the pure baseline in the experiments.

Joint Optimization of Bid and Budget (JO). This is our proposed algorithm. Note that we approximately cal-culate the VPC according to the idea in [4], i.e., we ran a simulation on the auction log to get the incremental cost per click (ICPC) [4] for each keyword and use it as the estimated value for the VPC of the keyword.

Bid Price Only (BID). This algorithm uses our pro-posed algorithm, but only optimizes the keyword bid prices, without changing the campaign budgets. By comparing this method with JO, we can see the impact of joint optimiza-tion. This method can also be used to directly compare with other algorithms for bid optimization.

Campaign Budget Only (BGT). This algorithm uses our proposed algorithm, but only optimizes the campaign budget, without changing the keyword bid prices. By com-paring this method with JO, we can also see the impact of joint optimization.

Knapsack Problem (KS). This algorithm is the multi-slot auction model proposed in [7], which adapts the problem of keyword bid price setting into a multi-choice knapsack problem. We set the t in the model as one day. That is, we will change the bid price daily according to remaining budget of each campaign.

Market Optimal Bid (MOB). This algorithm refers to the optimal bid model proposed in [16]. This model is an optimization framework that maximizes the advertiser revenue. Position is also considered in this model. The difference between this model and the BID model lies in that MOB captures the best position with fixed bid prices in each position to approach the observation instead of using a probability distribution for positions.
 Joint Optimization with Advertiser Modeling (JO-AM). In the real online traffic, the advertisers would dy-namically tune their bid prices in response to the changes of their campaign performances, and thus the changes of the bid prices will lead to the changes of the action outputs. Therefore, the optimal budget allocation and bid prices cal-culated from the historical log might not be so effective as expected in the real online experiment. We adopt a bidding strategy [18] by the advertisers to mimic the dynamic bid changes, and check whether the proposed JO method can still be robust with the possible bid changes by the adver-tisers.

Note that we do not compare with the algorithms in [12, 17], for their objective is to maximize the expected click number. The number of clicks can be a good measure for the campaign performance, but it may not be a good ob-jective to optimize for the advertisers. They may care more about the quality of clicks or the value they desire from each click. In other words, the revenue might be more meaning-ful for the advertisers to optimize. We do not compare with the algorithms in [5, 6, 10] either, for they are in different scenarios with our setting.
W e used the following evaluation measures in our experi-ments.

Ad Impressions. After simulation on the test data, we can get the impressions for an advertiser account.
Expected Clicks. We use the adPredictor model [14] to calculate the probability of click, and transform the impres-sions to expected ad clicks. 11 More expected clicks mean better performance of an advertiser.

Advertiser Revenue. Since there is a cost and a VPC associated with each click, the advertiser revenue for each click can be calculated as the difference between the VPC and the cost. By summing up the advertiser revenue for all the clicks obtained by an advertiser account, we can get the overall advertiser revenue.

Search Engine Revenue. While the above measures mainly describe the performances of advertisers, this mea-sure corresponds to the performance of the search engine. Note that the search engine revenue does not equal the ex-pense of the target advertiser accounts. If the keyword auc-tion is highly competitive and there is no empty ad slot, the impression of a new ad might not increase the expected search engine revenue since there is another ad losing the auction. We study the performances of the algorithms ORI, BID, BGT, KS, MOB, JO, and JO-AM which all take the ad-vertiser revenue as the objective function. We report the performance of these algorithms with respect to ad impres-sions, expected clicks, advertiser revenue, and search engine revenue. Note that we normalized the values under each evaluation metric by dividing them by the maximum value in the corresponding results, to protect the business secrets of the search engine. Figure 5: The average ad impressions among p-a ccounts.

The average ad impressions of each algorithm are shown in Figure 5. From the figure we have the following observa-tions. (i) All the algorithms successfully achieve a lot more impressions as compared to ORI. This demonstrates that the p-accounts have large potential to improve their perfor-mance by tuning the bid prices or budget allocation. (ii) JO performs better than BID and BGT. Therefore, although BID and BGT can help improve the ad impressions, jointly optimizing both bid and budget will help achieve more. This shows the necessity of adopting our proposed method. (iii)
T he adPredictor model performs quite well on our data and has a predict error of less than 10%.
 The performance of JO-AM is hurt by the advertiser dynam-ics on bid changes. However, it is still comparable with the second highest performer KS. It shows the proposed method is robust against the second-order effects from the advertiser dynamics. Figure 6: The average expected clicks among p-a ccounts.

Figure 6 depicts the number of expected clicks in the sim-ulation period for the seven algorithms. From the figure we have the following observations. (i) BID, BGT, KS, MOB, JO and JO-AM all improve the click number as compared to ORI. This shows that using advertiser revenue as the op-timization objective can also help improve the click number. (ii) BID performs better than MOB, indicating that our pro-posed ways of optimizing bid prices is more effective than some previous work. (iii) Further considering the budget al-location, JO performs the best. (iv) JO-AM is comparable with the second highest performer KS, again showing the robustness of the proposed method against the second-order effects. Figure 7: The average advertiser revenue among p-a ccounts.

In Figure 7, we evaluate the advertiser revenue, which is just the optimization objective of these algorithms. From the figure we have the following observations. (i) All the al-gorithms improve the advertiser revenue significantly. Though BID and BGT perform slightly worse than KS and MOB, by combining the advantages of BID and BGT, JO achieves better performance as compared to KS and MOB. It shows that the advertisers can benefit a lot from the joint optimiza-tion of bid price setting and budget allocation. (ii) JO-AM gets the second highest position in advertiser revenue. It even outperforms KS, showing that the proposed method is a good choice for the advertisers in practice when facing the bid dynamics. Figure 8: The average search engine revenue among p -accounts.
The performances in terms of search engine revenue are shown in Figure 8. From the figure, we can see that search engine can earn more money by using all the algorithms as compared to ORI. Among these algorithms, and JO still performs the best. Therefore, the joint optimization method can in return help the search engine improve the income.
To sum up all the aforementioned experimental results, we can get the following conclusions. (i) Bid price optimiza-tion (BID) can lead to high improvement on the ad impres-sions and expected clicks, and thus can largely increase both the advertiser revenue and the search engine revenue. (ii) Campaign budget optimization itself (BGT) seems not to perform as well as bid prices optimization (BID) in terms of the evaluation measures like expected clicks and advertiser revenue, however, it can ensure that only a very small num-ber of advertisers will have worse performance than before after the optimization. (iii) By jointly optimizing both bid prices and budget allocation, JO perform the best among all the algorithms in all evaluation measures. This clearly demonstrates the effectiveness of our proposal for both the advertisers and the search engine.
In this paper, we studied the joint optimization of cam-paign budget allocation and bid price setting. For this pur-pose, we proposed a probability model for ad ranking, and proposed an integer optimization problem to maximize the expected advertiser revenue. We show that the problem can be approximately solved by means of alternately work-ing on a binary integer optimization problem and another constraint optimization problem. Experimental results have shown that our proposed algorithm can increase the perfor-mance of advertisers in terms of several evaluation measures, as well as the search engine revenue.

For future work, we plan to further study like the following problems. For example, we will refine our model to perform the optimization for multiple accounts simultaneously. For this purpose, we need to consider the inter-competition be-tween accounts, which will make the optimization problem much harder to solve. Furthermore, we want to apply the proposed method in online traffic to test its performance.
