 Most collaborative filtering (CF) algorithms only make use of the rating scores given by users for items. However, it is often the case that each rating score is associated with a piece of review text. Such review texts, which are capable of providing us valuable information to reveal the reasons why users give a certain rating, have not been exploited and they are usually ignored by most CF algorithms. Moreover, the underlying relationship buried in users and items has not been fully exploited. Items we would recommend can often be characterized into hidden groups (e.g. comedy, horror movie and action movie), and users can also be organized as hidden communities. We propose a new generative mod-el to predict user X  X  ratings on previously unrated items by considering review texts as well as hidden user communities and item groups relationship. Regarding the rating scores, traditional algorithms would not perform well on uncovering the community and group information of each user and each item since the user-item rating matrix is dyadic involving the mutual interactions between users and items. Instead, co-clustering, which is capable of conducting simultaneous clustering of two variables, is able to take advantage of such user-item relationships to better predict the rating scores. Additionally, co-clustering would be more effective for mod-eling the generation of review texts since different user com-munities would discuss different topics and vary their own wordings or expression patterns when dealing with different item groups. Besides, by modeling as a mixed membership over community and group respectively, each user or item can belong to multiple communities or groups with varying degrees. We have conducted extensive experiments to pre-dict the missing rating scores on 22 real word datasets. We  X  also investigate the performance of discovering the topics in the review texts in order to reveal the topics usually dis-cussed by each user community for each item group. The experimental results demonstrate the superior performance of our proposed model comparing with the state-of-the-art methods.
 H.3.3 [ Information Search and Retrieval ]: Text Mining Collaborative Filtering; Co-clustering; Topic Model; User Community; Item Group
With the rapid development of E-commerce, more and more people tend to give sentimental rating and write re-view text for the product item they have bought. Such con-sumers X  ratings and comments have increasingly played an important role to help make decisions when people buy a product. However, the overwhelming amount of opinionat-ed information poses difficulty for people to wade through all the information of interest. To address this problem, rec-ommendation systems, which seek to automatically produce a list of personalized recommended product items for users based on their past purchased behaviors, have been widely studied [15]. The most prominent approach to generating recommendations is collaborative filtering (CF), which has been widely used by commercial companies and is applicable in many domains such as movies, books, and food. Normal-ly, the input of CF consists of rating scores provided by some users for certain items. Such rating information can be represented by a user-item rating matrix which is typ-ically partially filled. The goal is to predict user X  X  ratings on previously unrated items by the assumption that users, who bore similar taste in the past, will have similar taste in the future. Among all the CF algorithms, the latent factor model proposed by Koren et al. [40] is one of the success-ful approaches. Typically each user and each item would be modeled as a latent factor vector with the same dimen-sion which can be inferred from the user-item rating matrix by matrix factorization. The predicted ratings for previous-ly unrated items are estimated by the dot product between the corresponding user latent factor vector and item latent factor vector. Recently much work has been done to improve the scalability and accuracy of such latent factor models [18, 1].
Many CF algorithms only take the user-item rating s-c ores as input as described above. In fact, many modern E-commerce sites such as Amazon, eBay, and Epinions, con-tain review texts in addition to rating scores. Such review texts can serve as an additional source providing more infor-mation to explain why the user gives this rating. A rating score can indicate user X  X  sentimental satisfaction for the item but cannot reveal the reasons. It is often the case that users give the same level of rating due to different reasons. For example, in the domain of clothings, a user may be attract-ed by the low price and gives a 5-star rating, while another user may give the same 5-star rating just due to the nice appearance. However, most existing CF works [31, 32, 1] for recommendation have not taken this valuable text infor-mation into consideration.

Recently, McAuley et al. [18] proposed an improved latent factor model named HFT to achieve better predictive accu-racy for user X  X  ratings on items of interest with the help of incorporating the review texts. However, one major limita-tion of their HFT model is that the underlying community and group relationship buried in the users and items have not been explicitly exploited. Specifically, items we would recommend can often be characterized into different hidden groups (e.g. comedy, horror movie and action movie), and users can also be organized as different hidden communities. The members within the same group or community should bear high feature similarity. But in the HFT model, each user and each item is just characterized by a latent factor vector, and these latent factors are inferred by approximat-ing the observed rating score with the inner product between the corresponding user latent factor vector and item latent factor vector. As a result, such model does not explicitly consider any underlying user community and item group in-formation. Another limitation of existing latent factor mod-els is that both users and items are modeled by the same number of factors. On the contrary, the complexity embed-ded in users should differ from that of items. An inappro-priate constraint for the number of latent factors would lead to overfitting or underfitting problems.

In this paper, we tackle the CF problem with observed rating scores and the associated review texts as input. We develop a new generative model, known as  X  X o-clustering collaborative filtering Model with Review text X  (CMR), to predict user X  X  ratings on previously unrated items by effec-tively exploiting review texts as well as the hidden user com-munity and item group information. Regarding the rating scores, since the input user-item rating matrix is dyadic in-volving the mutual interactions between users and items, traditional algorithms would not perform well on uncovering the community and group information of each user and each item [11]. Instead, co-clustering [16], which is capable of con-ducting simultaneous clustering of two variables, is able to take advantage of the user-item relationships leading to bet-ter prediction of rating scores [7]. Additionally, co-clustering would be more effective for modeling the generation of re-view texts since different user communities would discuss different topics and vary their own wordings or expression patterns when dealing with different item groups. For exam-ple, a user community, who cares more about the quality and the comfort of clothings, would use wordings such as  X  X om-fortable X ,  X  X urable X  and  X  X ood quality X  for the t-shirt item group. In contrast,  X  X eautiful X ,  X  X ice X  and  X  X ashion X  would be the common terms appearing in the reviews written by the user community concerning the style and appearance of t-shirts. Precisely, each community-group pair corresponds to a co-cluster, which is characterized by a rating distribu-tion in exponential family and a topic distribution. Given the community-group co-cluster of a certain entry in the user-item rating matrix, the corresponding observed rating score would be sampled from the rating distribution in ex-ponential family of the given co-cluster. Likewise the corre-sponding review texts would be generated by a topic model which is governed by the same community-group co-cluster. Besides, most of the works [12, 39, 36] on co-clustering as-sumes that each element of a variable belongs to only one cluster, which is too restrictive. For example, a user may be a basketball fan as well as a football fan. Consequent-ly, in our model, each user and item is modeled as a mixed membership over community and group respectively. There-fore, each user or item can belong to multiple communities or groups with varying degrees. It should be noted that the number of hidden communities can differ with the number of hidden groups in our model to allow more flexible modeling.
Extensive experimental results on 22 real world dataset-s demonstrate that our proposed model CMR outperforms the state-of-the-art latent factor models for the recommen-dation task. The results also clearly illustrate that review texts provide valuable information to help improve the rec-ommendation performance. It is effective to consider hid-den user community and item group information. Moreover, we also show that the learned number of user communities should differ with the number of item groups.
The latent factor model is one of the most successful meth-ods for collaborative filtering (CF). Its major idea behind is that preferences for users are determined by a small number of unobserved factors [32]. One of the simplest implemen-tation for the latent factor model is low-rank matrix factor-ization [26, 2, 3, 23]. By taking the user-item rating matrix as input, the goal of low-rank matrix factorization is to in-fer the user matrix and item matrix, whose dot product can approximate the input matrix with minimal sum-squared loss. Then, the inferred user matrix and item matrix can be employed to predict the user X  X  ratings on previously un-rated items. These methods have been popular in recently years. Bell et al. [30] noticed that the neighborhood-based technique focuses more on patterns at local scale while SVD-like matrix factorization technique performs better at high-er, regional scale. Hence, they proposed a CF method by integrating these two complementary models to improve the performance. Koren [40, 41] then proposed a more accurate SVD++ algorithm which benefits from exploiting both ex-plicit and implicit feedbacks by the users. Srebro et al. [29] developed a simple and efficient EM algorithm to approx-imate the target user-item rating matrix. Subsequently, they [28] proved the generalization error bound of rating prediction. Some other works [27, 24, 20, 8, 25] focus on low-rank matrix factorization based on the maximum mar-gin principle. In addition, Salakhutdinov et al. [31, 32] pro-posed probabilistic matrix factorization models to capture the uncertainty associated with each user-item rating.
Several existing works also incorporated review texts for recommendation tasks. Ganu et al. [10] harnessed the pre-dictive ratings for recommendation based on the manually discovered aspects of the reviewed item from review texts. Agarwal el al. [6] proposed a matrix factorization method n amed fLDA model to improve the predictive accuracy, by treating the review texts associated with each user and item as regularizers. Another work proposed by Wang et al. [5] recommends scientific articles to users by taking advantage of the users X  historic published articles and the other user-s X  ratings. McAuley et al. [18] developed the HFT model for rating prediction. Essentially, HFT can be regarded as a combination between traditional latent factor model and the topic model. The latent factor model is utilized to charac-terize each user and each item while the topic model is em-ployed to model the corresponding review text. Then they build a connection to link the user or item factor vector and the topic distribution vector generated by topic model. As a result, their predictive ratings can be adjusted to achieve less sum-squared loss by fitting the rating score as well as review text probabilistic likelihood. Our work differs from HFT significantly. Apart from taking the review text into consideration, our model is capable of capturing the hid-den community and group information buried in the user and item collection, which is modeled by the co-clustering technique. Moreover, HFT assumes that the number of user factors is the same as the number of item factors whereas, in our approach, the number of user and item latent factors can be specified as different dimensions facilitating better modeling.

There are also some works capturing the user and item internal relationship for recommendation. Shan et al. [11] treated the user-item rating matrix as a dyadic matrix, where each entry captures a relation between two entities of inter-est. They proposed a Bayesian co-clustering model , i.e., simultaneously clustering of the users and items in the user-item rating matrix, to predict user X  X  ratings on previously unrated items. Additionally, Beutel et al. [1] developed a unified Bayesian approach for CF. They not only uncover a co-clustering of users and items, and also are able to auto-matically learn the most approriate number of user clusters and item clusters by Chinese Restaurant Process. In con-trast with our work, both of the above models ignore the valuable information from review texts.
The problem we investigate in this paper slightly differ-s with the traditional collaborative filtering (CF) problem which only considers the rating score provided by a user for an item. Normally such rating information can be rep-resented by a user-item rating matrix, which is typically partially filled. In addition to such rating information, we also take the review texts associated with each rating score as input. Formally, let U = { 1 , 2 ,...U } be the set of user-s and V = { 1 , 2 ,...V } be the set of items. Each user-item pair ( u , v ) corresponds to a rating score r uv  X  R + and asso-ciates with a piece of review texts d uv . The objective of this problem is to predict rating scores on the previously unrated items. Some major notations we use throughout the paper are defined in Table 1.

It is common that the rating score is discrete and ordi-nal (e.g 1-5 stars). For each community-group co-cluster, we output a rating probabilistic distribution in exponential family. Such kind of rating distribution output has also been adopted [4, 1, 11] because it can provide us more insightful Symbol Description U user collection
V item collection r u v rating score given by the user u f or the item v d uv review text written by the user u f or item v w uvn the n t h word in the review text d uv z uvn the topic for the n t h word in the review text d uv  X   X  c uv user community of d u v and r uv g uv item group of d u v and r uv  X   X   X  k word distribution for the topic k i nformation. In our case, it allows for each community-group co-cluster to output rating scores with varying degrees of rat-ing uncertainty. Such rating distribution, instead of a single rating value, can allow better representation for the rating habit of each community-group co-cluster. We also output a topic distribution for each community-group co-cluster to uncover topics commonly discussed by a user community for an item group. The graphical model of our proposed model is depicted in Figure 1. Each node represents a variable. The shaded n-odes represent the observed variables and non-shaded nodes are the hidden variables to be inferred. The arrows indicate the dependency among the variables. The two outer rect-angle plates represent the replication for a user and a item respectively. The overlapping region indicates the rating s-cores and review texts associated with user-item pairs. The inner rectangle plate corresponds to each word in a review text.
 As mentioned in the previous section, our proposed model CMR exploits the review texts and the hidden user commu-nity and item group information. Co-clustering technique is employed to effectively capture the relationship between users and items. In our model CMR, given K 1 community for users and K 2 groups for items, there are in total K 1 community-group co-cluster. The user u  X  U is charac-terized by a K 1 -dimensional community mixed membership vector  X  c u . Each item v  X  V is similarly represented by a K Each vector component denotes the probability belonging to a certain user community or item group. For example, a to the community 1, 2, and 3 with the probability 0.5, 0.1, and 0.4 respectively.  X  c u , u  X  U and  X  g v , v  X  V are assumed to be generated by the Dirichlet prior distribution Dir(  X  ) and Dir(  X  ) respectively. For a user-item pair ( u , v ), i.e. an entry in the user-item rating matrix, the user community c uv and the item group g uv , which are sampled from the Multinomi-al distribution Multi(  X  c u ) and Multi(  X  g v ) respectively, would determine one of the co-cluster ( c uv , g uv ). This co-cluster is modeled by a rating distribution in exponential family p ( r uv |  X  c item pair ( u , v ) is associated with an observed rating score and the observed review texts. Regarding the generation of rating score, since the true rating score commonly takes on discrete integer (e.g. 1-5 stars) [4], p ( r uv |  X  c simply modeled as Multinomial distribution Multi(  X  c where T -dimensional vector  X  c distribution over each possible rating score. We also put a Dirichlet distribution Dir(  X  ) as a prior on the rating distri-bution of each co-cluster. As a result, the observed rating score r uv would be generated by Multi(  X  c other hand, the generation of each word in d uv is modeled by the popular Latent Dirichlet Allocation (LDA) model [9] with the topic distribution  X  c  X  of K topics.

The generative process for all the rating scores and review texts is as follows:
In contrast with the traditional latent factor models such as [31, 32, 18, 30, 40], our model is capable of capturing more realistic situations. Particularly, the user community X  X  rat-ing behaviour and the commonly reviewed topics can vary with different item groups. For instance, a user communi-ty, who is keen on the sports, tends to give high ratings for the product items of some famous brands such as Nike and Adidas while it gives relatively low ratings for those unknown brands. On the other hand, regarding a certain t-shirt group, terms such as  X  X omfortable X ,  X  X urable X  and  X  X ood quality X  would frequently appear in the reviews writ-ten by the user community, who cares more about the qual-ity and the comfort of clothing, whereas the user commu-nity concerning the style and appearance of t-shirts would provide comments including key terms such as  X  X eautiful X ,  X  X ice X  and  X  X ashion X . Besides, in traditional latent factor models, the feature vector for each user and each item has typically the same dimension. In other words, the number of factors for characterizing each user is the same with that of each item. However, the number of user modeling factors should differ from the number of item modeling factors. The reason is that the hidden community partitions in the users would be more complicated and can vary with different in-fluencing factors. For example, if the clothings are assumed to form three groups including t-shirt, pants and underware, due to the interest overlapping in different communities, the users can be clustered into more than three communities X  a community who tends to buy t-shirt, a community who tends to buy pants, a community who tends to buy t-shirt and pants, and a community who tends to buy pants and underware, etc.. Additionally, some communities cannot be represented by common group partition of items. If a us-er community is the fans of David Beckham, they would like to buy the clothings endorsed by Beckham. However, in common E-commerce sites, there is usually no specific item category related to Beckham endorsed clothings. Con-sequently, discriminating the modeling of user latent factor and item latent factor is a better approach.
Exact inference for the CMR model is intractable. We employ the collapsed Gibbs sampling algorithm to perfor-m approximate inference. Gibbs sampling is a special case of Metropolis-Hastings algorithm which is one of Markov Chain Monte Carlo methods [33]. It is used to obtain a sam-ple approximated from a joint distribution when only the conditional distributions of each variable can be efficiently computed [13, 14]. Variables considered in Gibbs sampling are sequentially sampled from the distribution conditioned on all the other variables. Due to the Markov property, the chain of the model states would converge to a stationary sample from the joint distribution. Typically, when Gibb-s sampling is employed to do inference for LDA, Griffith-s et al. [37] proposed a collapsed Gibbs sampling method to demonstrate that we just need to sample the topic as-signments z in that the dependency on topic distribution  X  and word distribution  X  can be analytically integrated out. Therefore, for our CMR model, we only sample the assign-ments of user communities c , item groups g and the topics z by integrating out the community mixed membership vec-tors  X  c , the group mixed membership vectors  X  g , the rating distribution  X  , the topic distribution  X  and the word distri-bution  X  .

For Gibbs sampling with our CMR model, we need to compute the conditional distribution below, where z  X  X vn , c  X  X vn , g  X  X vn are vectors of the topic assign-ments, the user community assignments, and the item group assignments without considering the n th word of the review text written by the user u for the item v . r and w are the vectors representing all the rating scores and all the words in associated review texts respectively. l , m and k are the assignment of user community, item group, and topic re-spectively for the current considered word. We begin with the joint distribution of our model and collapse out all the intermediate latent variables including  X  c ,  X  g ,  X  ,  X  and  X  . It should be noted that similar with the time stamp shared by all the words in the documents in TOT (Topic Over Time) model [38], each word of d uv in our model can have the same community-group co-cluster ( l,m ) and rating score. Once updating the topic assignment of each word, the cor-responding community and group should also be updated synchronously. Given that the considered n th word in the review text d uv is denoted by s , and the associated rating score is represented by t , we present the final conditional probability in Eq. 1 with the help of the chain rule as fol-lows.
  X   X  Here, we have introduced a major notion h for word count-ing. h t,k,s, X  X vn u,v,l,m indicates the number of words whose topic assignment is k and has word index of s , and that appear in the review text d uv with the rating score of t and belongs to the co-cluster ( l,m ). There are in total 7 dimensions and any (  X  ) operator represents the counting of the words with-out considering the corresponding dimension. Assume that the number of words written by the user u and attached with number of words for describing the item v and attached with ber of words generated by the co-cluster ( l , m ) and attached ber of words generated by the co-cluster ( l , m ) but requiring the topic assignment of k . The last counter h (  X  ) ,k,s, X  X vn represents the number of words whose topic assignment is k and the word index is s .

The community mixed membership vector for the user u and the group mixed membership vector for the item v can Algorithm 1 G ibbs Sampling for CMR Model Input: A collection of rating scores r uv given by the users u  X  U for the items v  X  V . Each rating score r uv is associated with a review text d uv .
 Output: Latent variables  X  c u ,  X  g v ,  X  ,  X  ,  X  , c uv
Initialize c uv , g uv , z uvn randomly for all the words for iter = 1 to Max iter do end for be estimated by a sample of such Markov chain as follows,
Moreover, the posterior estimates for the rating distribu-tion  X  , the topic distribution  X  and the word distribution  X  can be computed below,
The Gibbs sampling procedure can be performed using E-qs. 2 to 7. After a random initializing, during the process of Gibbs sampling, we take an interval of L iterations be-tween subsequent read-outs to obtain a steady approximate solution [37]. The detailed algorithm is described in Alg. 1.
We demonstrate the effectiveness of our model by conduct-ing extensive experiments on 22 real world datasets cover-ing different product categories. We also compare with the state-of-the-art approaches.
We use 22 datasets 1 crawled from Amazon 2 in a wide range of product categories. Such datasets have also been h ttp://snap.stanford.edu/data/web-Amazon.html www.amazon.com utilized in [18, 17, 19]. In particular, each dataset is a coll ec-tion of review comments from a set of users for the product items, and each review text is accompanied with a rating score (e.g. 1-5 stars) to show the user X  X  overall satisfactory level for the reviewed product item. Note that we randomly sample a portion of some very large datasets (e.g. over G-B) by limiting the number of items up to 5000. A detailed summary of the entire datasets is reported in Table 2.
The HFT proposed by Mcauley et al. [18] demonstrates its the state-of-the-art performance to predict the user X  X  rat-ing by exploiting the review texts. Thus, we compare with this method. Note that there are two versions of HFT. HFT(item) is to associate each item latent factor with the topics expressed in the review texts related to each item while HFT(user) conducts similar procedure for each us-er. Since HFT(item) has been shown better performance than HFT(user) [18], we compare our CMR model with HFT(item) in our experiment. Moreover, we conduct com-parision with the state-of-the-art probabilistic latent factor methods including probabilistic matrix factorization (PM-F) and its Bayesian version (BPMF). However, these two methods just consider the rating information.

Beutel et al. [1] pointed out that minimizing the mean square loss is a mainstay in CF, but there are a number of other better metrics. For example, [24, 35] treat CF as a preference ranking problem rather than directly predict the rating score. Distance similarity [22] is also utilized to evaluate the performance of CF. Besides, in order to con-sider the uncertainty and discrete characteristic (e.g. 1-5 stars) of the rating score, [4, 1, 11] introduce the discrete rating probabilistic distribution, and employ the (negative) log-likelihood to measure the fit of their model. Similarly, we employ the negative rating log-likelihood called NLL in E-q. 8 as a metric to measure our model X  X  fit for the observed rating. Smaller NLL indicates a better rating prediction performance.
 We implement the general exponential distribution family by simple multinomial distribution for modeling the rating score.

In fact, the traditional latent factor model can be alterna-tively treated as a Gaussian noise model [4]. The observed rating r uv is estimated by a Gaussian distribution with the mean of the predictive rating  X  r uv . Therefore, we obtain r uv  X  N ( X  r uv , X   X  1 ), i.e.  X  log P ( r uv |  X  r uv ) =  X  where  X  is the precision of the Gaussian distribution. How-ever, it is common that the real rating score r uv is a dis-crete integer. Hence, it is more appropriate to model the observed ratings by normalized exponential family model. Given the rating score belongs to the common 1-5 stars, i.e. Y = { 1 , 2 ,..., 5 } , the corresponding Gaussian distribution can be reformulated in Eq. 10.
 Consequently, Eq. 9 can be improved by Eq. 11 to compute the NLL for HFT, PMF and BPMF.  X  log P ( r uv |  X  r uv ) =  X  2 ( r u v  X   X  r uv ) 2 +log
A dditionally, in order to examine the performance of fit-ting the review texts, we also compute the commonly used word perplexity by Eq. 12 for HFT and our model CMR. A lower word perplexity leads to a better explanation for the given rating score. Note that it is inappropriate to calculate the word perplexity for PMF and BPMF since these two methods do not use review texts. Eq. 12 depicts the word perplexity calculation formula. where T denotes the held-out test dataset and N uv repre-sents the number of words in the review d uv . In our model CMR, we prepare the word likelihood by Eq. 13 for comput-ing the word perplexity.
 Clothings Pet S upplies Gourmet F oods Health Kindle S tore (a) Varying K 2 i n Clothings
We perform pre-processing on these data sets by remov-ing punctuations, stop words from a standard stop word list as in [34], and converting the words into lower cases. In our experiment, the number of maximum iteration of the Gibbs sampler is set to 1000, and the inferred latent vari-ables would be computed every 100 times. In other words, Max iter = 1000 and L = 100 in Alg. 1. In order to perfor-m fair comparision with HFT, for each dataset in Table 2, we randomly select 80% of the reviews to form the training set by limiting the maximum reviews up to 2 millions, and then uniformly divide the remaining part into validation set and test set. Each component of hyperparameters are spec-ified equally by the following values :  X  l = 0 . 5 K  X  and K will be described below.
In our model, we fix the number of topics K as 5, which is similar done in [18], and perform the grid search for the num-ber of user community K 1 and item group K 2 in the range of [1 , 15] and [1 , 10] respectively using the validation set. For each dataset, we choose the K 1 , K 2 with the lowest NLL on the validation set, and then calculate the corresponding NLL on the test set. For the comparative methods, we use the parameter setting in their papers [18, 31, 32], and also calculate the NLL on the same test set.

The results in terms of the NLL are reported in Table 3, where the best performance is bolded. In general, our model CMR achieves the best performance on all the 22 dataset-s except for  X  X aby X ,  X  X ell Phones Accessaries X  and  X  X u-sical Instrument X . The best improvement is achieved for  X  X lothings X  and  X  X hoes X . These results are reasonable be-cause any people would buy the products of  X  X lothings X  and  X  X hoes X . Users would subjectively reveal their feelings or attitude towards the items they reviewed in their own way. Besides, there are also apparent item groups for  X  X lothings X  and  X  X hoes X . As a result, by capturing this hidden user community and item group, our model CMR can improve the rating prediction performance significantly. Moreover, it can be observed that our model CMR and HFT perfor-m better than that of PMF and BPMF demonstrating the effectiveness of considering review texts.

On the other hand, for the categories of  X  X aby X ,  X  X el-l Phones Accessaries X  or  X  X usical Instrument X , there is no obvious user community derived from the rating scores and review comments, leading to the inferior performance of CM-R. For example, most customers of  X  X aby X  products are  X  X -oung mothers X . They have already formed a special commu-nity of the entire set of users for this product category, and therefore when reviewing  X  X aby X  products, they would give similar ratings as well as comment on similar aspects.
The number of user community K 1 and item group K 2 are the major parameters in our CMR model. We investigate the effect of these two variables on the NLL by varying one of them and fixing another in  X  X lothings X  and  X  X hoes X  using the test set. with varying item gruops shown on the right.
Firstly, we set K as 5. We fix K 1 by 1, 2, 5, 10 respec-tively, and vary K 2 in the range of [1,10]. Other parameters are specified according to the experimental setup in Sec-tion 4.3. As we can see in Figure 2a, HFT is represented by a straight line since this method would not be influenced by K 1 and K 2 . When we treat users as a single commu-nity, i.e. K 1 = 1, the performance of our CMR model is inferior comparing with HFT. The reason is that there are multiple types of users in the  X  X lothings X  dataset. How-ever, when increasing K 1 to two, we can obviously notice that several points are located lower than the straight line of HFT indicating the superior performance of CMR than HFT. Subsequently, we continue to increase K 1 to obtain the most appropriate number of user communities and item groups i.e. K 1 = 10 and K 2 = 4 as indicated by the red ellipse in Figure 2a. Moreover, we also find that when K 1 increases, the NLL becomes less sensitive with the various K 2 . The reason is that when its value approaches to the most appropriate value, the number of user community K 1 plays the major role and larger number of item group K 2 becomes redundant. Next, we similarly fix K 2 by 1, 2, 4 and 8 respectively, and examine the NLL results by varying K 1 with the range of [1,15]. Other parameters are the same. As we can see in Figure 2b, CMR can outperform HFT with a larger K 1 . In addition, for any given number of item group K 2 , the performance of CMR becomes better with increas-ing number of user community K 1 at the first stage. After reaching the most appropriate K 1 = 10 and K 2 = 4 denoted by the red ellipse in Figure 2b, the resulting line becomes gentle and placid with a small perturbation. The reason is that for such rigid demand products, users would inherently f orm a number of communities. Before attaining this most appropriate value, the performance improves, and after that, the additional number of user communities will also become redundant. Figure 2c and Figure 2d illustrate similar results for the Shoes dataset.
Since each user-item co-cluster is characterized by a dis-crete rating distribution as well as a topic distribution in our CMR model, we examine the performance of discover-ing topics measured by the word perplexity for CMR and HFT. We choose the best K 1 and K 2 pair generated by the grid search in Section 4.4, and vary the the number of top-ics K from 5 to 50 with the step of 5, for the test datasets of  X  X lothings X  and  X  X hoes X . Recall that the lower the word perplexity, the better the topic discovery performance is. Figure 5a and Figure 5b depict the word perplexity of HFT and CMR. Obviously, by incorporating the user community and item group co-clustering relationship, CMR achieves a superior ability to discover the topics buried in the review collections. Table 4a and Table 4b exhibit the discovered topics, which is quite indicative to be interpreted and easy to discriminate.
In our model CMR, a topic distribution  X  cg and a rating distribution  X  cg would be inferred for each community-group co-cluster ( c,g ), which provides valuable information for dis-covering the commonly reviewed topics and rating habit for user communities and item groups. With the most appro-priate K 1 = 11 and K 2 = 6 on the Shoes dataset, Figure 3 depicts the topic distribution (TD) and rating distribution (RD) of different co-clusters. Firstly, we fix the item group to 6 with different user communities, namely, 1, 2, 6, and 9. As we can see in Figure 3a and Figure 3b, different us-er communities concern different aspects of the item group, and have different rating habits. For example, depending on the topics shown in Table 4b, the users of c = 2 usually com-ment on the  X  X ppearance X  of the  X  X oots X  and tend to give low ratings on this item. On the other hand, the users of c = 6 and c = 9 focus more on the X  X ize X  X nd X  X ervice X  X f the  X  X oots X , and feel satisfied by giving high ratings. Secondly, we fix the user community to 4 with varying item groups 1, 2, 5, and 6. Figure 3c and Figure 3d illustrate that when dealing with different item groups, a certain user community also tends to vary its wordings and expression patterns as well as the rating habit. Specifically, for the item group of g = 1, the considered user community comments more about its  X  X ize X  and tends to give a descent rating, while this user community writes more about the leather shoes and boots in his reviews, and usually gives a relatively high rating for the item group of g = 5.
The inferred community mixed membership vector  X  c u and group mixed membership vector  X  g v can be regarded as the low-dimensional representation for the user u and the item v . As defined in [11], co-embedding represents the low-dimensional feature vectors  X  c u , u  X  U and  X  g v , v  X  V since these vectors preserve the interdependency between users and items in the user-item rating matrix. With the most appropriate K 1 = 10 and K 2 = 4 on Clothings dataset, we visualize the user embedding i.e. all the user community vectors  X  c u , u  X  U and item embedding i.e. all the item group vectors  X  g v , v  X  V by employing the ISOMAP [21] to further reduce the dimension to 2 as depicted in Figure 4a and Figure 4c. We can see that the users and items are obviously divided into four and three clusters respectively, which can be treated as a further clustering for 10 user com-munities and 4 item groups. Besides, we also investigate the rating feature of each cluster. For each user cluster, we cal-culate user X  X  average ratings for each item group. Similarly, for each item cluster, we also calculate the item X  X  average ratings received from each user community. As shown in Figure 4b and Figure 4d, it is easy to discriminate the rat-ing feature of different clusters. For example, in Figure 4b, the user cluster of C1 exhibits apparent preference for the item group of 1 by giving nearly 5-star rating score, and tends to gives a descent rating for the item groups of 2, 3, and 4. On the contrary, the user cluster of C2 does not feel satisfied with the item group of 1 but likes the item group of 3 most. In Figure 4d, it can be observed that the ma-jority of user communities give similar ratings for the item group of C1 while for the item group of C2 and C3, different user communities have their own rating criterion and show relatively greater variance in ratings. F igure 5: Effects of the number of topics on topic discovery. Lower values indicate better results
We have proposed a new generative model CMR to predict user X  X  ratings on previously unrated items by incorporating the review texts and hidden user community and item group information into a collaborative filtering method. Due to the dyadic characteristic of the input user-item rating matrix, co-clustering technique is employed to model the relation-ship of hidden user communities and item groups. We have performed extensive experiments on 22 real-world datasets. The experimental results show that our model CMR outper-forms the-state-of-the-art methods on the task of predicting missing ratings. Moreover, several qualitative analyses have been reported to further demonstrate the effectiveness of our model CMR. [1] A.Beutel, K.Murray, C.Faloutsos, and A.J. Smola. [2] A.Paterek. Improving regularized singular value [3] B.Sarwar, G.Karypis, J.Konstan, and J.Riedl.
 [4] C.Tan, E.Chi, D.Huffaker, G.Kossinets, and A.Smola. [5] C.Wang and D.M. Blei. Collaborative topic modeling [6] D.Agarwal and B.C.Chen. flda: matrix factorization [7] D.Agarwal and S.Merugu. Predictive discrete latent [8] D.DeCoste. Collaborative prediction using ensembles [9] A.Ng D.M.Blei and M.I.Jordan. Latent dirichlet [10] G.Ganu, N.Elhadad, and A.Marian. Beyond the stars: [11] H.Shan and A.Banerjee. Bayesian co-clustering. In [12] I.Dhillon, S.Mallela, and D.Modha.
 [13] I.Titov and R.McDonald. A joint model of text and [14] I.Titov and R.McDonald. Modeling online reviews [15] J.Bobadilla, F.Ortega, A.Hernando, and A.Guti  X errez. [16] J.Hartigan. Direct clustering of a data matrix. Journal [17] J.McAuley and J.Leskovec. From amateurs to [18] J.McAuley and J.Leskovec. Hidden factors and hidden [19] J.McAuley, J.Leskovec, and D.Jurafsky. Learning [20] J.Rennie and N.Srebro. Fast maximum margin matrix [21] J.Tenenbaum, V.Silva, and J.Langford. A global [22] J.Weston, S.Bengio, and N.Usunier. Wsabie: Scaling [23] J.Lafferty K.Yu, S.Zhu and Y.Gong. Fast [24] M.Weimer, A.Karatzoglou, Q.V.Le, and A.Smola. [25] A.Karatzoglou M.Weimer and A.Smola. Improving [26] N.Aizenberg, Y.Koren, and O.Somekh. Build your [27] N.Srebro, J.D.Rennie, and T.Jaakkola.
 [28] N.Srebro, N.Alon, and T.Jaakkola. Generalization [29] N.Srebro and T.Jaakkola. Weighted low-rank [30] R.Bell, Y.Koren, and C.Volinsky. Modeling [31] R.Salakhutdinov and M.Andriy. Probabilistic matrix [32] R.Salakhutdinov and M.Andriy. Bayesian probabilistic [33] S.Geman and D.Geman. Stochastic relaxation, gibbs [34] S.Lacoste-Julien, F.Sha, and M.Jordan. Disclda: [35] S.Yang, B.Long, A.Smola, H.Zha, and Z.Zheng. [36] T.George and S.Merugu. A scalable collaborative [37] T.L.Griffiths and M.Steyvers. Finding scientific topics. [38] X.Wang and A.McCallum. Topics over time: a [39] Y.Cheng and G.Church. Biclustering of expression [40] Y.Koren. Factorization meets the neighborhood: a [41] Y.Koren, R.Bell, and C.Volinsky. Matrix factorization
