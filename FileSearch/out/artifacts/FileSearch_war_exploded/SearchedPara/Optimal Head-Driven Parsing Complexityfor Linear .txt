 Linear Context-Free Rewriting Systems (LCFRSs) (Vijay-Shankar et al., 1987) constitute a very general grammatical formalism which subsumes context-free grammars (CFGs) and tree adjoining grammars (TAGs), as well as the synchronous context-free grammars (SCFGs) and synchronous tree adjoin-ing grammars (STAGs) used as models in machine erty of CFGs that grammar nonterminals rewrite independently, but allow nonterminals to generate discontinuous phrases, that is, to generate more than one span in the string being produced. This important feature has been recently exploited by Maier and S X gaard (2008) and Kallmeyer and Maier (2010) for modeling phrase structure treebanks with discontinuous constituents, and by Kuhlmann and Satta (2009) for modeling non-projective depen-dency treebanks.

The rules of a LCFRS can be analyzed in terms of the properties of rank and fan-out . Rank is the number of nonterminals on the right-hand side (rhs) of a rule, while fan-out is the number of spans of the string generated by the nonterminal in the left-hand side (lhs) of the rule. CFGs are equivalent to LCFRSs with fan-out one, while TAGs are one type of LCFRSs with fan-out two. Rambow and Satta (1999) show that rank and fan-out induce an infi-nite, two-dimensional hierarchy in terms of gener-ative power; while CFGs can always be reduced to rank two (Chomsky Normal Form), this is not the case for LCFRSs with any fan-out greater than one.
General algorithms for parsing LCFRSs build a dynamic programming chart of recognized nonter-minals bottom-up, in a manner analogous to the CKY algorithm for CFGs (Hopcroft and Ullman, 1979), but with time and space complexity that are dependent on the rank and fan-out of the gram-mar rules. Whenever it is possible, binarization of LCFRS rules, or reduction of rank to two, is there-fore important for parsing, as it reduces the time complexity needed for dynamic programming. This has lead to a number of binarization algorithms for LCFRSs, as well as factorization algorithms that factor rules into new rules with smaller rank, with-out necessarily reducing rank all the way to two. Kuhlmann and Satta (2009) present an algorithm for binarizing certain LCFRS rules without increas-ing their fan-out, and Sagot and Satta (2010) show how to reduce rank to the lowest value possible for LCFRS rules of fan-out two, again without increas-ing fan-out. G  X  omez-Rodr  X   X guez et al. (2010) show how to factorize well-nested LCFRS rules of arbi-trary fan-out for efficient parsing.

In general there may be a trade-off required between rank and fan-out, and a few recent pa-pers have investigated this trade-off taking gen-eral LCFRS rules as input. G  X  omez-Rodr  X   X guez et al. (2009) present an algorithm for binarization of LCFRSs while keeping fan-out as small as possi-ble. The algorithm is exponential in the resulting fan-out, and G  X  omez-Rodr  X   X guez et al. (2009) mention as an important open question whether polynomial-time algorithms to minimize fan-out are possible. Gildea (2010) presents a related method for bina-rizing rules while keeping the time complexity of parsing as small as possible. Binarization turns out to be possible with no penalty in time complexity, but, again, the factorization algorithm is exponen-tial in the resulting time complexity. Gildea (2011) shows that a polynomial time algorithm for factor-izing LCFRSs in order to minimize time complexity would imply an improved approximation algorithm for the well-studied graph-theoretic property known as treewidth. However, whether the problem of fac-torizing LCFRSs in order to minimize time com-plexity is NP-hard is still an open question in the above works.

Similar questions have arisen in the context of machine translation, as the SCFGs used to model translation are also instances of LCFRSs, as already mentioned. For SCFG, Satta and Peserico (2005) showed that the exponent in the time complexity of parsing algorithms must grow at least as fast as the square root of the rule rank, and Gildea and  X  Stefankovi  X  c (2007) tightened this bound to be lin-ear in the rank. However, neither paper provides an algorithm for finding the best parsing strategy, and Huang et al. (2009) mention that whether finding the optimal parsing strategy for an SCFG rule is NP-hard is an important problem for future work.
In this paper, we investigate the problem of rule binarization for LCFRSs in the context of head-driven parsing strategies. Head-driven strategies be-gin with one rhs symbol, and add one nontermi-nal at a time. This rules out any factorization in which two subsets of nonterminals of size greater than one are combined in a single step. Head-driven strategies allow for the techniques of lexicalization and Markovization that are widely used in (projec-tive) statistical parsing (Collins, 1997). The statis-tical LCFRS parser of Kallmeyer and Maier (2010) binarizes rules head-outward, and therefore adopts what we refer to as a head-driven strategy. How-ever, the binarization used by Kallmeyer and Maier (2010) simply proceeds left to right through the rule, without considering the impact of the parsing strat-egy on either time or space complexity. We examine the question of whether we can efficiently find the strategy that minimizes either the time complexity or the space complexity of parsing. While a naive algorithm can evaluate all r ! head-driven strategies in time O ( n r !) , where r is the rule X  X  rank and n is the total length of the rule X  X  description, we wish to determine whether a polynomial-time algorithm is possible.

Since parsing problems can be cast in terms of logic programming (Shieber et al., 1995), we note that our problem can be thought of as a type of query optimization for logic programming. Query optimization for logic programming is NP-complete since query optimization for even simple conjunc-tive database queries is NP-complete (Chandra and Merlin, 1977). However, the fact that variables in queries arising from LCFRS rules correspond to the endpoints of spans in the string to be parsed means that these queries have certain structural properties (Gildea, 2011). We wish to determine whether the structure of LCFRS rules makes efficient factoriza-tion algorithms possible.

In the following, we show both the the time-and space-complexity problems to be NP-hard for head-driven strategies. We provide what is to our knowl-edge the first NP-hardness result for a grammar fac-torization problem, which we hope will aid in under-standing parsing algorithms in general. In this section we briefly introduce LCFRSs and de-fine the problem of optimizing head-driven parsing complexity for these formalisms. For a positive in-teger n , we write [ n ] to denote the set { 1 , . . . , n } As already mentioned in the introduction, LCFRSs generate tuples of strings over some finite alphabet. This is done by associating each produc-tion p of a grammar with a function g that takes as input the tuples generated by the nonterminals in p  X  X  rhs, and rearranges their string components into a new tuple, possibly adding some alphabet symbols.
Let V be some finite alphabet. We write V  X  for the set of all (finite) strings over V . For natural num-bers r  X  0 and f, f an equation of the form Here the x and ~ X  = h  X  g  X  X  argument variables and symbols in V . We say that g is linear, non-erasing if ~ X  contains exactly one occurrence of each argument variable. We call r and f the rank and the fan-out of g , respectively, and write r ( g ) and f ( g ) to denote these quantities. Example 1 g input a tuple with two strings and returns a tuple with a single string, obtained by concatenating the components in the input tuple. g strings and wraps around these strings with sym-bols a, b, c, d  X  V . Both functions are linear, non-erasing, and we have r ( g and f ( g A linear context-free rewriting system is a tuple G = ( V N , V T , P, S ) , where V N and V T are finite, disjoint alphabets of nonterminal and terminal sym-bols, respectively. Each A  X  V a value f ( A ) , called its fan-out . The nonterminal S is the start symbol, with f ( S ) = 1 . Finally, P is a set of productions of the form where A, A erasing function.

Production (1) can be used to transform the r ( g ) string tuples generated by the nonterminals A ated by A . The values r ( g ) and f ( g ) are called the rank and fan-out of p , respectively, written r ( p ) and f ( p ) . Given that f ( S ) = 1 , S generates a set of strings, defining the language L ( G ) .
 Example 2 Let g let g the productions p and p 1 . We have L ( G ) = { a n b n c n d n | n  X  1 } . For in-of the following bottom-up process. First, the tuple h  X ,  X  i is generated by A through p 3 . We then iterate three times the application of p h a 3 b 3 c 3 d 3 i is generated by S through application of p .
Existing parsing algorithms for LCFRSs exploit dynamic programming. These algorithms compute partial parses of the input string w , represented by means of specialized data structures called items. Each item indexes the boundaries of the segments of w that are spanned by the partial parse. In the special case of parsing based on CFGs, an item con-sists of two indices, while for TAGs four indices are required.

In the general case of LCFRSs, parsing of a pro-duction p as in (1) can be carried out in r ( g )  X  1 steps, collecting already available parses for nonter-minals A these into intermediate partial parses. We refer to the order in which nonterminals are merged as a pars-ing strategy, or, equivalently, a factorization of the original grammar rule. Any parsing strategy results in a complete parse of p , spanning f ( p ) = f ( A ) segments of w and represented by some item with 2 f ( A ) indices. However, intermediate items ob-tained in the process might span more than f ( A ) segments. We illustrate this through an example. Example 3 Consider a linear non-erasing function duction p : A  X  g ( A nonterminals involved have fan-out 2. We could parse p starting from A A first three nonterminals, we have obtained a partial parse having fan-out 4, that is, an item spanning 4 segments of the input string. Alternatively, we could first merge A finally merge the two obtained partial parses. This strategy is slightly better, resulting in a maximum fan-out of 3. Other possible strategies can be ex-plored, displayed in Figure 1. It turns out that the best parsing strategy leads to fan-out 2.
The maximum fan-out f realized by a parsing strategy determines the space complexity of the parsing algorithm. For an input string w , items will require (in the worst-case) 2 f indices, each taking O ( | w | ) possible values. This results in space com-based on CFGs and TAGs, this provides the well-known space complexity of O ( | w | 2 ) and O ( | w | 4 ) respectively.

It can also be shown that, if a partial parse hav-ing fan-out f is obtained by means of the combi-nation of two partial parses with fan-out f respectively, the resulting time complexity will be an example, in the case of parsing based on CFGs, nonterminals as well as partial parses all have fan-out one, resulting in the standard time complexity of O ( | w | 3 ) of dynamic programming methods. When parsing with TAGs, we have to manipulate objects with fan-out two (in the worst case), resulting in time complexity of O ( | w | 6 ) .

We investigate here the case of general LCFRS productions, whose internal structure is consider-ably more complex than the context-free or the tree adjoining case. Optimizing the parsing complexity for a production means finding a parsing strategy that results in minimum space or time complexity.
We now turn the above optimization problems into decision problems. In the M IN S PACE S TRAT -EGY problem one takes as input an LCFRS produc-tion p and an integer k , and must decide whether there exists a parsing strategy for p with maximum fan-out not larger than k . In the M IN T IME S TRAT -EGY problem one is given p and k as above and must decide whether there exists a parsing strategy for p such that, in any of its steps merging two partial parses with fan-out f tial parse with fan-out f , the relation f + f holds.

In this paper we investigate the above problems in the context of a specific family of linguistically mo-tivated parsing strategies for LCFRSs, called head-driven. In a head-driven strategy, one always starts parsing a production p from a fixed nonterminal in its rhs, called the head of p , and merges the remain-ing nonterminals one at a time with the partial parse containing the head. Thus, under these strategies, the construction of partial parses that do not include the head is forbidden, and each parsing step involves at most one partial parse. In Figure 1, all of the dis-played strategies but the one in the second line are head-driven (for different choices of the head). For an LCFRS production p , let H be its head non-terminal, and let A nonterminals in p  X  X  rhs, with n + 1 = r ( p ) . A head-driven parsing strategy can be represented as a per-mutation  X  over the set [ n ] , prescribing that the non-head nonterminals in p  X  X  rhs should be merged with there are n ! possible head-driven parsing strategies.
To show that M IN S PACE S TRATEGY is NP-hard under head-driven parsing strategies, we reduce lem, which is a decision problem over (undirected) graphs. Given a graph M = ( V, E ) with set of ver-tices V and set of edges E , a linear arrangement of M is a bijective function h from V to [ n ] , where | V | = n . The cutwidth of M at gap i  X  [ n  X  1] and with respect to a linear arrangement h is the number of edges crossing the gap between the i -th vertex and its successor: p : A  X  g ( H, A 1 , A 2 , A 3 , A 4 ) g ( h x H,e x x The cutwidth of M is then defined as one is given as input a graph M and an integer k , and must decide whether cw ( M )  X  k . This problem has been shown to be NP-complete (Gavril, 1977). Theorem 1 The M IN S PACE S TRATEGY problem restricted to head-driven parsing strategies is NP-complete.
 P ROOF We start with the NP-hardness part. Let M = ( V, E ) and k be an input instance for M { v 1 , . . . , v n } there are no self loops in M , since these loops do not affect the value of the cutwidth and can therefore be removed. We construct an LCFRS production p and an integer k  X  as follows.

Production p has a head nonterminal H and a non-head nonterminal A H generate tuples with a string component for each edge e ingly, we use variables x denote the string components in tuples generated by H .

For each v edges impinging on v of v components for each e x note the string components in tuples generated by A positions, respectively; see below).

We set r ( p ) = n + 1 and f ( p ) = q , and define p by A  X  g ( H, A g ( t H , t A tuple of variables for H and each t tuple of variables for A specified as follows. Let v of e i , with v s , v t  X  V and s &lt; t . We define Observe that whenever edge e v , then the left and right strings generated by A and associated with e erated by H and associated with the same edge. Fi-nally, we set k  X  = q + k .
 Example 4 Given the input graph of Figure 2, our reduction constructs the LCFRS production shown in Figure 3. Figure 4 gives a visualization of how the spans in this production fit together. For each edge in the graph of Figure 2, we have a group of five spans in the production: one for the head nontermi-nal, and two spans for each of the two nonterminals corresponding to the edge X  X  endpoints.
Assume now some head-driven parsing strategy  X  for p . For each i  X  [ n ] , we define D  X  partial parse obtained after step i in  X  , consisting of the merge of nonterminals H, A Consider some edge e for any D  X  nals A of p is associated with a single string, and therefore contributes with a single unit to the fan-out of the partial parse. On the other hand, if D  X  one nonterminal between A nent is associated with two strings and contributes with two units to the fan-out of the partial parse.
We can associate with  X  a linear arrangement h of M by letting h From the above observation on the fan-out of D  X  we have the following relation, for every i  X  [ n  X  1] : We can then conclude that M, k is a positive instance if p, k  X  is a positive instance of M IN S PACE S TRAT -EGY . This proves that M IN S PACE S TRATEGY is NP-hard.

To show that M IN S PACE S TRATEGY is in NP, consider a nondeterministic algorithm that, given an LCFRS production p and an integer k , guesses a parsing strategy  X  for p , and tests whether f ( D  X  k for each i  X  [ n ] . The algorithm accepts or rejects accordingly. Such an algorithm can clearly be im-plemented to run in polynomial time.

We now turn to the M IN T IME S TRATEGY prob-lem, restricted to head-driven parsing strategies. Re-call that we are now concerned with the quantity f 1 + f 2 + f parse D , f is the fan out of the partial parse resulting from the merge of the two previous analyses.

We need to introduce the M ODIFIED C UTWIDTH problem, which is a variant of the M IN C UT L IN -EAR A RRANGEMENT problem. Let M = ( V, E ) be some graph with | V | = n , and let h be a linear ar-rangement for M . The modified cutwidth of M at position i  X  [ n ] and with respect to h is the number of edges crossing over the i -th vertex: The modified cutwidth of M is defined as In the M ODIFIED C UTWIDTH problem one is given as input a graph M and an integer k , and must decide whether mcw ( M )  X  k . The M ODIFIED C
UTWIDTH problem has been shown to be NP-complete by Lengauer (1981). We strengthen this result below; recall that a cubic graph is a graph without self loops where each vertex has degree three.
 Lemma 1 The M ODIFIED C UTWIDTH problem re-stricted to cubic graphs is NP-complete.
 P been shown to be NP-complete when restricted to graphs of maximum degree three by Makedon et al. (1985), reducing from a graph problem known as bisection width (see also Monien and Sudborough (1988)). Specifically, the authors construct a graph G  X  of maximum degree three and an integer k  X  from an input graph G = ( V, E ) with an even number n of vertices and an integer k , such that mcw ( G  X  )  X  k  X  if and only if the bisection width bw ( G ) of G is not greater than k , where bw ( G ) = min with A  X  B =  X  , A  X  B = V , and | A | = | B | .
The graph G  X  has vertices of degree two and three only, and it is based on a grid-like gadget R ( r, c ) ; see Figure 5. For each vertex of G , G  X  includes a com-ponent R (2 n 4 , 8 n 4 +8) . Moreover, G  X  has a compo-nent called an H -shaped graph, containing left and right columns R (3 n 4 , 12 n 4 + 12) connected by a middle bar R (2 n 4 , 12 n 4 + 9) ; see Figure 6. From each of the n vertex components there is a sheaf of the component to 2 n 2 distinct degree 2 vertices in the middle bar of the H -shaped graph. Finally, for each edge ( v necting a degree 2 vertex in the component corre-sponding to the vertex v the component corresponding to the vertex v integer k  X  is set to 3 n 4 + n 3 + k  X  1 .

Makedon et al. (1985) show that the modified cutwidth of R ( r, c ) is r  X  1 whenever r  X  3 and c  X  4 r + 8 . They also show that an optimal lin-ear arrangement for G  X  has the form depicted in Fig-ure 6, where half of the vertex components are to the left of the H -shaped graph and all the other ver-tex components are to the right. In this arrangement, the modified cutwidth is attested by the number of edges crossing over the vertices in the left and right columns of the H-shaped graph, which is equal to where  X  denotes the number of edges connecting vertices to the left with vertices to the right of the H -shaped graph. Thus, bw ( G )  X  k if and only if mcw ( G  X  )  X  k  X  .

All we need to show now is how to modify the components of G  X  in order to make it cubic. Modifying the vertex components All vertices x of degree 2 of the components corresponding to a vertex in G can be transformed into a vertex of degree 3 by adding five vertices x nected as shown in the middle bar of Figure 5. Ob-serve that these five vertices can be positioned in the arrangement immediately after x in the order x The resulting maximum modified cutwidth can in-crease by 2 in correspondence of vertex x the vertices of these components, in the optimal arrangement, have modified cutwidth smaller than the maximum modified cutwidth of the entire graph, which is 3 n 4 + O ( n 3 ) .
 Modifying the middle bar of the H-shaped graph The vertices of degree 2 of this part of the graph can be modified as in the previous paragraph. Indeed, in the optimal arrangement, these vertices have mod-ified cutwidth smaller than 2 n 4 + 2 n 3 + n 2 , and an increase by 2 is still smaller than the maximum cutwidth of the entire graph.
 Modifying the left/right columns of the H-shaped graph We replace the two copies of component R (3 n 4 , 12 n 4 + 12) with two copies of the new component D (3 n 4 , 24 n 4 + 16) shown in Figure 7, which is a cubic graph. In order to prove that rela-tion (2) still holds, it suffices to show that the modi-fied cutwidth of the component D ( r, c ) is still r  X  1 whenever r  X  3 and c = 8 r + 16 .

We first observe that the linear arrangement ob-tained by visiting the vertices of D ( r, c ) from top to bottom and from left to right has modified cutwidth r  X  1 . Let us now prove that, for any partition of the vertices into two subsets V 4 r 2 , there exist at least r disjoint paths between ver-tices of V tinguish the following three cases.  X  Any row has (at least) one vertex in V 1 and one  X  There exist at least 3 r  X  X ixed X  columns, that is,  X  The previous two cases do not apply. Hence, Observe now that any linear arrangement partitions the set of vertices in D ( r, c ) into the sets V V , consisting of all the remaining vertices. Since there are r disjoint paths connecting V must be at least r  X  1 edges passing over every vertex in the arrangement which is assigned to a position between the (4 r 2 + 1) -th and the position 4 r 2 + 1 from the right end of the arrangement: thus, the modified cutwidth of any linear arrangement of the vertices of D ( r, c ) is at least r  X  1 .

We can then conclude that the original proof of Makedon et al. (1985) still applies, according to relation (2).
 We can now reduce from the M ODIFIED C UTWIDTH problem for cubic graphs to the M IN T
IME S TRATEGY problem restricted to head-driven parsing strategies.
 Theorem 2 The M IN T IME S TRATEGY problem re-stricted to head-driven parsing strategies is NP-complete.
 P
ROOF We consider hardness first. Let M and k be an input instance of the M ODIFIED C UTWIDTH problem restricted to cubic graphs, where M = ( V, E ) and V = { v 1 , . . . , v n } . We construct an LCFRS production p exactly as in the proof of The-orem 1, with rhs nonterminals H, A also set k  X  = 2 k + 2 | E | + 9 .

Assume now some head-driven parsing strategy  X  for p . After parsing step i  X  [ n ] , we have a partial parse D  X  H, A  X  (1) , . . . , A  X  ( i ) . We write tc ( p,  X , i ) the exponent of the time complexity due to step i . As already mentioned, this quantity is defined as the sum of the fan-out of the two antecedents involved in the parsing step and the fan-out of its result: tc ( p,  X , i ) = f ( D  X  i  X  1 ) + f ( A  X  ( i ) ) + f ( D
Again, we associate with  X  a linear arrangement h As in the proof of Theorem 1, the fan-out of D  X  is then related to the cutwidth of the linear arrange-ment h From the proof of Theorem 1, the fan-out of nonter-minal A noted by | E ( v equation in terms of our graph M :
The following general relation between cutwidth and modified cutwidth is rather intuitive: mcw ( M, h  X  , i ) = Combining the two equations above we obtain: Because we are restricting M to the class of cubic graphs, we can write: tc ( p,  X , i ) = 2 | E | + 9 + 2 mcw ( M, h  X  , i ) . We can thus conclude that there exists a head-driven parsing strategy for p with time complexity not greater than 2 | E | + 9 + 2 k = k  X  if and only if mcw ( M )  X  k .

The membership of M ODIFIED C UTWIDTH in NP follows from an argument similar to the one in the proof of Theorem 1.

We have established the NP-completeness of both S
TRATEGY decision problems. It is now easy to see that the problem of finding a space-or time-optimal parsing strategy for a LCFRS production is NP-hard as well, and thus cannot be solved in polynomial (de-terministic) time unless P = NP. Head-driven strategies are important in parsing based on LCFRSs, both in order to allow statistical modeling of head-modifier dependencies and in or-der to generalize the Markovization of CFG parsers to parsers with discontinuous spans. However, there are n ! possible head-driven strategies for an LCFRS production with a head and n modifiers. Choosing among these possible strategies affects both the time and the space complexity of parsing. In this paper we have shown that optimizing the choice according to either metric is NP-hard. To our knowledge, our results are the first NP-hardness results for a gram-mar factorization problem.
 SCFGs and STAGs are specific instances of LCFRSs. Grammar factorization for synchronous models is an important component of current ma-chine translation systems (Zhang et al., 2006), and algorithms for factorization have been studied by Gildea et al. (2006) for SCFGs and by Nesson et al. (2008) for STAGs. These algorithms do not result in what we refer as head-driven strategies, although, as machine translation systems improve, lexicalized rules may become important in this setting as well. However, the results we have presented in this pa-per do not carry over to the above mentioned syn-chronous models, since the fan-out of these models is bounded by two, while in our reductions in Sec-tion 3 we freely use unbounded values for this pa-rameter. Thus the computational complexity of opti-mizing the choice of the parsing strategy for SCFGs is still an open problem.

Finally, our results for LCFRSs only apply when we restrict ourselves to head-driven strategies. This is in contrast to the findings of Gildea (2011), which show that, for unrestricted parsing strategies, a poly-nomial time algorithm for minimizing parsing com-plexity would imply an improved approximation al-gorithm for finding the treewidth of general graphs. Our result is stronger, in that it shows strict NP-hardness, but also weaker, in that it applies only to head-driven strategies. Whether NP-hardness can be shown for unrestricted parsing strategies is an im-portant question for future work.
 The first and third authors are partially supported from the Italian PRIN project DISCO. The sec-ond author is partially supported by NSF grants IIS-0546554 and IIS-0910611.
