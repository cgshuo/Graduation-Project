 Metasearch engine, Comparison-shopping and Deep Web crawling applications need to extract search result records enwrapped in result pages retu rned from search engines in response to user queries. The s earch result records from a given search engine are usually formatted based on a template. Precisely identifying this template can greatly help extract and annotate the data units within each record corr ectly. In this paper, we propose a graph model to represent record template and develop a domain independent statistical method to automatically mine the record template for any search engine using sample search result records. Our approach can identify both template tags (HTML tags) and template texts (non-tag texts), a nd it also explicitly addresses the mismatches between the tag structures and the data structures of search result records. Our experimental results indicate that this approach is very effective. H.3.5 [ Information Storage and Retrieval ]: Online Information Services  X  Commercial Services, Web-based Services.
 Algorithms, Performance, De sign, Experimentation. Information extraction, wrappe r generation, search engine. There are primarily two types of search engines, the first is text search engines that search web pa ges or other text documents and the second is Web databases that s earch structured data stored in database systems, including most e-commerce search engines. In this paper, we will uniformly ca ll them as search engines. When a search engine returns resu lts in response to a user query, the results are presented as s earch r esult r ecords (SRRs). SRRs are usually enwrapped with HTML tags in dynamically generated web pages by script programs. Usually, each SRR contains information pertinent to a real world entity. For example, an SRR from a book search engine contai ns information about a book. Figure 1 shows two sample SRRs from two different search engines, the first from a text s earch engine and the second from a web database. To be user friendly, search engine designers make SRRs neatly arranged and clear ly distinguishable from other content unrelated to the user query on result pages. Although search engines as well as the result pages they produce are designed for human users to consume, more and more web applications require automatic extraction of SRRs from search engine result pages, such as deep web crawlers [20], shopping agents, large-scale metasearch engines [18, 23], etc. An SRR usually consists of multip le data units with each having a particular meaning. For example, for the SRR in Figure 1a, its data units include the title of the web page, a short summary (snippet), the URL of the page, etc., and for the book SRR in Figure 1b, the data units include the book title, the author, the publisher, etc. In general, for S RRs returned from the same search engine, the data units in these SRRs are laid out and formatted similarly following a certain pattern. In other words, there exists an SRR template that is followed by all SRRs from the same search engine. Each SRR is an instance of the SRR template. world entities but not formatting a nd template information. For example, in Figure 1b,  X  X ur Price X  is part of the template and  X $138.50 X  is a data unit. Some times, we use  X  X ttributes X  to represent the meaning of a data unit or a set of data units. For instance,  X  X ur Price X  is the attribute of  X $138.50 X . In this paper we study the problem of how to automatically identify the SRR template for any given search engine. Based on our observation, we believe the following three factors make automatic SRR template extraction a difficult problem: 1. Data structure and tag structure mismatch . As part of a 2. Optional/disjunctive component . An SRR may contain 3. Template tags and template text . The SRR template may 
Figure 2. The data structure and tag structure (tag tree and While there are several reported works on data extraction from web pages, including both data reco rd (i.e., SRR) level and data unit level extraction, the current techniques are inadequate in precise and automatic template extraction (please see detailed comparison with related work in section 2). In this paper, we propose a novel solution to the automatic SRR template extraction problem that explicitly addresses the above factors. The main contribution of this paper is the development and evaluation of a new SRR template mining algorithm for any given search engine. Our algorithm has the following novel features. First, we introduce a directed acyclic graph (DAG) template model to help solve the optiona l/disjunctive component problem. Second, we consider the identifi cation of both template tags and template texts. Specifically, we develop a solution to identify decorative tags that are the main non-template tags; we also develop a technique to identify template texts so non-template texts can be extracted as data units. These solutions are domain independent and search engine independent, meaning that they can be applied to the SRRs from any search engine in any domain. Third, we explicitly study the mismatch problem between the tag structures and data structures of SRRs. We show that identifying decorative tags help solve the mismatch that one data unit is encoded in multiple tags and identify template texts help deal with the mismatch that multiple data units are encoded in one tag. Fourth, we also introduce a clustering and voting based method to generate SRR templa tes and this method tends to generate more robust SRR template s. This means that even when the input SRRs may contain false SRRs which may lead to outliner tags and texts, our method can still obtain the correct template. Fifth, our method is fully automatic except a one-time, domain independent and search e ngine independent training of the components for identifying decorative tags and template texts. We also evaluate our solution experimentally and the results indicate that our solution is quite effective. The rest of the paper is organized as follows. We review related works in section 2. In section 3, we present the template model and the overview of our method. Section 4 gives the major steps of our algorithm. Section 5 presents the experimental results. Finally section 6 concludes the paper. Information extraction from web pages is an active research area. Researchers have been devel oping various solutions from all kinds of perspectives. Readers may refer to [6, 13] for surveys about early and recent works in this area. Many web information extraction sy stems [1, 3, 9, 10, 11, 12, 16, 19, 26] rely on human users to provide marked samples so that the data extraction rules could be learned. Because of the supervised-learning process, those semi-aut omatic systems usually have higher accuracy than fully automatic systems that have no human intervention. But semi-automatic methods are not suitable for large-scale web applications [18, 20, 23] that need to extract data from thousands of web sites. Also web sites tend to change their web page formats frequently, which will make the previous generated extraction rules invalid, further limiting the usability of semi-automatic methods. That X  X  why many more recent works [2, 4, 5, 7, 8, 14, 15, 17, 21, 22, 25, 27, 28] focus on fully or nearly fully automatic solutions. Web information extraction can be at the record level or data unit level. The former treat each data record as a single data unit while the data records. Record level extraction generally involves identifying data regions that contain all the records, and then partitioning the data regions into individual records. Since the records within a data region are usually highly homogeneous and the data regions are often constructed simply by a list of records, the record level extraction is easier than the data unit level extraction. Some recently proposed fully automatic extraction methods on record level extraction achieved satisfying performances [14, 21, 27]. On the other hand, the data unit level extraction is more complicated, and the performance of proposed fully automatic methods are not satisfactory. Omini [4], IEPAD [5], MDR [14], ViNTs [27] and the method in [8] are record-level data extraction tools incapable of performing general data unit level extracti on. RoadRunner [7], EXALG [2], DeLa [22], DEPTA [25], NET [15], ViPER[21] and the method in [28] and [17] are more relevant to this paper, because they all have the ability to extract data at data unit level. DeLa and the method in [28] and [17] also studied the automatic data unit annotation problem. RoadRunner extracts data template by comparing web page pairs. One page is considered as initial template, and the other page is compared with the template, wh ich is updated when there are mismatches. The algorithm tries to produce a template that fits all input web pages. EXALG extr acts template by analyzing equivalence classes, which are sets of tokens that have the same frequency of occurrence on all i nput web pages. Templates are generated from large and frequently occurring equivalence classes (LFEQs). DEPTA uses an edit distance based tree matching technique to align tag trees for data extraction. Tags are considered as templates while text s are data to be extracted. NET extends DEPTA by supporting nested records extraction. Similar to IEPAD, DeLa builds suffix trees to detect patterns in web page string. DeLa X  X  multi-level pattern extraction algorithm enables it to extract data with nested schema on the web page. ViPER improves MDR by providing a better sub-tree comparing method that allows consecutive data reco rds with various lengths. ViPER also introduces a multiple sequence alignment algorithm that aligns maximal unique ma tches at different levels to extract the template of data records. Instead of aligning template, the method in [17] aligns data text between template tokens directly by comparing the features like content, presentation style, type, etc. The method in [28] combines the record extraction and attribute labeling to let them benefit from each other. Many works [7, 15, 21, 25] ignore the problem of mismatches between the data structures and the tag structures of SRRs by assuming that HTML tags are templa te tokens and text tokens are data items to be extracted. The method in [28] simply assumes that the visual elements (with the exception of  X  X oise X ) are data attributes to be labeled. The authors of EXALG noticed that HTML tags might appear in da ta while texts might contain template tokens. But their e quivalence classes based method considers only tokens that have c onstant number of occurrences in different web pages as template tokens. Thus its ability to differentiate the different roles of tags and text tokens is limited. Our work reported in this paper does not deal with record-level extraction even though we mention SRRs frequently. Instead, our work takes already extracted SRRs as input and tries to find the SRR template based on the SRRs returned from a search engine. We build our system to work on the SRRs extracted by ViNTs [27], which is a fully automatic record-level extraction tool. However, we recognize that ViNTs is not perfect, and as a result, incorrect SRRs may be extracted by it and these SRRs may be part of the input to our algorithm. In this paper, we focus on mining the SRR template. Even though extracting data units is not our dir ect objective as we try to tackle the more fundamental template extraction problem, by identifying the SRR template for the SRRs of a search engine, data units in these SRRs can be extracted easily. Therefore, this paper is closely related to data unit leve l extraction. Our method differs from other solutions as we deal with the three factors (i.e., data structure and tag structure mismatch, optional/disjunctive component, and template tags and template text) more explicitly than existing works. Also the performance of our system is significantly better than that of contemporary works. A fully automatic web informa tion extraction tool should be robust to outlier inputs. Because it is not practical to simply assume that the inputs consist only of the desired data. Especially when we consider a working environment that is as complex as the World Wide Web. Our sta tistical method also has the advantage that is robust to outlier inputs which may be caused by the existence of false SRRs due to the use of an imperfect SRR extraction tool. The authors of [24] showed that the problem of inferring unambiguous schemas (templates) fo r web data extraction is NP-complete. Thus it is understandable that all current efficient web information extraction tools, including ours, are based on heuristic solutions. An HTML web page mainly consis ts of two types of elements: HTML tags and texts. We us e the term tag and HTML tag interchangeably in this paper because we only work with HTML encoded web pages. A tag refers the name of any HTML tag that is encompassed by special characters  X &lt; X  and  X &gt; X  in the HTML encompassed by  X &lt; X  and  X &gt; X . When we consider a web page as a string of tokens (tag tokens and text tokens), an SRR is a sub-string of the token string of the entire web page that contains the SRR. The creation of the HTML code pieces of an SRR can be considered as using a template to enwrap the data units of an SRR. An SRR template consists of template strings and data slots that hold data units. Once we have the template, we can apply it to an SRR to identify the data units in the SRR. The embedding nature of tags enables a well-formed HTML document to be converted to a tree structure, which contains two types of nodes: tag nodes and text nodes. We use the term tag tree to represent the tree structure of an HTML document in this paper. With the tag tree view of a web page, an SRR is part of a tag tree. In general, an SRR corre sponds to a sub-forest located in a tag tree under a specific tag node. Due to the loose HTML gramma r, many web pages on the web are not well formed. However, a good browser can still  X  X orrectly X  build the tag trees for a majority of ill-formed web pages. Note that by a pre-order traversal of the tag tree, we can always get a well-formed HTML document, which is equivalent formed HTML code generated by tag tree traversal. Thus an SRR also corresponds to a tag string that is equivalent to its tag forest. We call an SRR X  X  tag forest (or the equivalent tag string) the tag structure of the SRR, while the composition of the data units in the SRR the SRR X  X  data structure . In the tag string, HTML tags partition the texts in an SRR into small text fragments. Thus one may be tempted to extract data units based on this partition. Such a na X ve method may work ok for search engines that arrange their SRRs in a tabular manner, e.g. each row represents an S RR and each column corresponds to a data unit. But based on our obser vation, most search engines do not arrange their SRRs in tabular format and in these cases the text fragments are often different from the data units. Because HTML is a language for data presentation, although the tag structure of an SRR is generated according to the data structure of the SRR, the tag structure of an SRR is often considerably different from that of the SRR X  X  data structure. Figure 2a and 2b&amp;2c show such an example. There is no direct mapping between a node on the tag tree and a data unit: on the one hand, multiple nodes may match to one data unit, and on the other hand, one node may correspond to multiple data units. An SRR represents an instance of the SRR template on a web page. There are two types of strings in the HTML code of an SRR: the template strings and data strings. To generate an SRR, the search engine X  X  script progr am enwraps data strings using template strings, which are token strings that are not content of any data units in an SRR. We introduce the concept of data slots , which are the carriers of the data units of SRRs. We define the SRR template based on data slot s. An SRR template actually represents the relationshi ps between data slots. ds represents the space that holds a data unit of an SRR (note that ds is not the data unit itself), lt ( rt ) is a template string that bounds (right) bound. A data slot may ha ve empty left or right bounds. In Figure 2, the data slot that holds the data string  X  X X Olympic Winter Games 2006 in Turin X  has a template string &lt;A&gt;&lt;IMG&gt;&lt;/IMG&gt;&lt;/A&gt; -... X  as right bound. data slot DS j = &lt;lt j , ds j , rt j &gt; , the right bound of DS represented as a sequence of data slots and we use dss(SRR) to denote this sequence. Definition 2 (SRR template) . For a given search engine S, its SRR template, denoted SRRT(S), is a directed acyclic graph (DAG), called a template graph , denoted TG(S), where each node in the graph represents a data slot and an edge from data slot ds which ds 1 appears right before ds 2 . In addition, for any valid SRR produced by S, there is a full directed path in TG(S) that is the same as dss(SRR), where a full direct ed path starts with an origin node (which has no incoming edges) and ends with a destination node (which has no outgoing edges). In general, we also require the template graph to be mini mum (in terms of the number of nodes and edges) which means id entical nodes and edges have been merged. In general, TG(S) may have multiple origin nodes and multiple destination nodes. If the template graph of a search engine has just one full path, this means the SRRs of the search engine have a rigid layout format and ever y SRR has the same sequence of data slots. If there is an optional data slot that some SRRs have and some SRRs don X  X  have, then the template graph will have a fork. Figure 3a shows an optional da ta slot B between data slot A and data slot C. Figure 3b illustra tes two disjunctive data slots, B and C, between A and D, i.e., after A, either B or C, but not both, may follow, and both of them will be followed by D. Figure 3c shows a template graph with 4 full paths. The method we present in this paper can automatically generate the graph representation of SRR template from a set of result pages that contain SRRs returned by a search engine. To correctly restore the SRR X  X  data structure from its tag structure, we must be able to solve the problem of the mismatches between the data structure and th e tag structure. There exist two major types of mismatches: a single data unit matches multiple nodes in the tag structure, and multiple data units match a single node in the tag structure. Figure 1a shows an example of a Type 1 mismatch. The text  X  X X Olympi c Winter Games 2006 in Turin X  is a single data unit, but it corresponds to four nodes in the SRR X  X  tag structure: text  X  X X X , text  X  X ames 2006 in Turin X , tag  X  X  X  and its child text  X  X lympic Winter X  (see the tag structure in Figure 2b). Figure 1b shows an example of a Type 2 mismatch: the text string  X  X cGraw-Hill, Published 1997, ISBN 0070428077 X  contains three data units corres ponding to the name of a publisher, the year the book was published and the ISBN number of the book, respectively, but the entire text string is contained in a single text node in this SRR X  X  tag structure. Let X  X  examine the example in Figure 1a and Figure 2 more closely. It is the HTML tag  X  X  X  that splits the single text string into three pieces. Highlighting certain words in an SRR is actually a general phenomenon because We b page designers often use special HTML tags to embellish certain pieces of information to make them special. For example, they may want to highlight the query terms, use hyperlink to indicate further information is available, or, insert a small pict ure to make the web page more lively, etc. We call such kind of HTML tags Decorative Tags . For the purpose of data extraction, we don X  X  consider the tags that embellish a complete data unit as decorative tags, because these tags actually facilitate the data extraction. We are interested in those tags that embellish a portion of a data unit. By identifying and removing them, we would be ab le to restore the wholeness of the data units. Definition 3 (Decorative Tag) . A decorative tag is an HTML tag that appears within a single data unit of an SRR and is designed to embellish a portion of the data unit. In other words, a decorative fragments with each corresponding to a different node in the tag structure of the SRR. Because decorative tags only embellish a portion of a data unit, their occurrences would accomp any the occurrences of the information that is being embellished. For example, the occurrences of query terms in the SRRs are embellished (Figure 1a.). In general, we observed that decorative tags tend to have random occurring patterns because the texts to be decorated may appear randomly in an SRR, wh ile non-decorative tags tend to have more regular occurrence patte rns. This property enables us to employ a machine learning appr oach to identify the decorative tags. We will introduce our neural network based decorative tag detector in section 4.1. To help users correctly understand the data in an SRR, there usually exist some special text t okens in the text that contains multiple data units to separate th ese data units. For example, the string  X , Published X  and  X , ISBN X  in Figure 1b are the text tokens that separate the text into thr ee data units  X  X cGraw-Hill X ,  X 1997 X  and  X 0070428077 X . Note that  X  X ublis hed X  and  X  X SBN X  actually correspond to semantic labels (or attribute names using database terminology) that give meanings to data units. We call text tokens that separate different data units in a string as Template Texts . Note that a template text can be as simple as a punctuation symbol like a comma or a semi-colon. Definition 4 (Template Text) . A template text is a non-tag token that is not (part of) any data un it (or attribute values) in the SRR that contains the token. The problem of template text detection is to differentiate template texts from non-template texts. A significant characteristic of template texts is their high occurring frequency because they tend to appear in almost all (with the exception of optional data units) SRRs that are returned by the same search engine. But some non-template may also have hi gh occurring frequencies, like punctuations, and words like  X  X h e X  and  X  X  X . Further observation indicates that the template te xts and non-template high frequency texts have different occurring pa tterns: the latter tend to have random occurring patterns while the former have more regular occurring patterns. Our solution will explore these special features. We introduce our neural network based template text detector in section 4.3. Our SRR template mining algorith m includes two neural network classifiers: the decorative tag detector (DTD) and the template text detector (TTD). Their de sign and training details will be given in sections 4.1 and 4.3, respectively. Once we have the DTD and the TTD, we can plug them into the SRR template mining algorithm. Figure 4 shows the main steps of our algorithm. The decorative tag detector (DTD) and template text detector (TTD) will be trained in advance. The algorithm works as follows. The input is a set of sample result pages that contain SRRs returned by a search engine. First we apply ViNTs [ 27] on these sample pages to extract the SRR at the record level. Then we apply DTD on the tag forests of the SRRs to detect and remove decorative tags from the tag forests. We transfer the SRRs X  tag forests into equivalent tag strings and extract data strings from them. The data strings are considered as candidate data units of the data slots in the SRR template and a candidate data unit may contain multiple real data units due to the existence of template texts in it. Next we apply a hierarchical clustering algorithm to cluster candidate data units extracted from all input SRRs. The next step is to apply TTD to each candidate data unit cluster to identify the template texts for this cluster. Then we use a refini ng step to separate the candidate data units in each cluster into data units using the newly identified template texts. This effectively creates multiple (including just one) data unit clusters out of each candidate data unit clusters. The last step is to build the SRR template graph. We map each data unit cluster to a vertex (a data slot) on the SRR template graph, and then use all SRRs to vote for the edges on the graph. We delete edges and vertices (dat a slots) with very small supports so that the final SRR template graph is robust and reliable. As mentioned in section 3.4, we apply ViNTs [27] to the input result pages that are to be used to mine the SRR template. The output of ViNTs is a set of SRRs represented by their tag forests. ViNTs is a fully automatic but it does not guarantee that the SRRs extracted by this tool are 100% co rrect. The existence of incorrect SRRs brings some noise to the S RR template extraction process. The following sub-sections presen ts all modules described in Figure 4 other than the SRR extractor. The existence of decorative tags in the tag structure (Tag tree) causes the Type 1 mismatch problem. To solve the problem, we introduce a DTD, which is a neural network classifier, to identify the decorative tags, so that they could be removed from the tag structure of SRRs. DTD takes a tag, which is represente d by its statistical features, in SRRs X  tag forests as input. The output is a number indicating if the input tag is a decorative tag or not. An input tag is not merely name that occurs in the similar lo cations of all SRRs returned by the same search engine. It is advisable to combine SRRs on different result pages of a search engine to extract a tag X  X  features. &lt;B&gt;, etc. It is possible that one occurrence of a tag is a decorative tag while another occurrence of the same named tag is not a decorative tag. In other words, di fferent occurrences of the same named tag may play different roles in SRRs. Because the tag forests of SRRs returned by the same search engine have similar structures, tags with the same name and appearing in the same specific locations of the tag struct ures of different SRRs are very likely to play the same role. We use Tag Path [27] to specify the location of a tag on the tag forest. A tag path consists of a sequence of path nodes . Each path node pn consists of two components, the tag name (i.e., a tag node) and the direction , which indicates whether the next node  X  X  X , called S node) or the first child of pn (indicated by  X  X  X , called C node). Since we need to compare the tag locations on SRRs, we don X  X  need the absolute tag paths that start from the tag tree root &lt;HTML&gt;. We work on relative tag paths that start from the root nodes of SRRs. As an exam ple, the (relative) tag path of &lt;LI&gt;C&lt;DIV&gt;C&lt;A&gt;C&lt;#TEXT&gt;S. The tag structures of different SRRs returned by the same search engine generally are not exactly the same. As a result, the tag paths of different occurrences of a node that plays the same role in different SRRs are likely to be different. We convert a tag X  X  tag path into compact format following the method reported in [27], which is equivalent to the original tag path for locating a tag. By removing unimportant  X  X oise X  path nodes, a compact tag path can be more robust to represent a location on the tag forest of SRR than the original tag path. Thus a ta g in the tag forest of an SRR is tag path of this tag on the tag forest of the SRR. We discussed that one important property of decorative tags is that they have a random occurring patterns. A careful analysis reveals more: decorative tags are designed to embellish texts, which are leaf nodes on the tag structure. Thus the decorative tags parents of the text nodes embellished by them. Also certain types of tags are likely to be used as decorative tags than others, for example, &lt;B&gt;, &lt;I&gt; are more likely than &lt;TABLE&gt;. We extract the 9 features (in Table 1) of an HTML tag that appears in the tag forest of SRRs. Features 1 and 2 capture the randomness of a tag X  X  distances to its leaf descendants. Feature 2 is the estimated standard deviation of the distances of the tag (in occurrences on different SRRs) to its leaf.
 Features 3, 4, 5, 6, 7 and 8 capture the randomness of a tag X  X  occurring patterns under its direct pa rents. The feature 4, 6 and 8 are all standard deviations. All appearances of a tag directly under a common parent node together ar e considered as an occurring pattern. Feature 9 is the prior-p robability of the tag name as decorative tags. The DTD is a three layer backpropagation neural network layer consisting of 4 units, and an output layer consisting of 1 unit. A tag is considered as deco rative tag if the output has a value greater than 0.5. 
Feature # Description 1 Average distance to leaves 2 Deviation of distance to leaves 3 Average occurring number 4 Deviation of occurring number 5 Average first occurring position from left 6 Deviation of first occurring position from left 7 Average first occurring position from right 8 Deviation of first occurring position from right 9 Prior-probability of being a decorative tag To collect sample tags for a search engine, we collect N result pages returned by the search engine. Then we use an automatic SRR extraction tool to extract the SRRs from the N result pages. Let X  X  assume n SRRs are extracted. We extract all HTML tags from the tag forest of each SRR. Note that a tag is represented as a tag name and tag path pair. By extracting the occurrence pattern of each tag in each SRR, we can get the statistics features (1-8). At training stage, feature 9 is obtained by human users by manually marking the samples. Then we store the prior-probability values in a hash table, so that we can find the prior-probability of a tag quickly when the trained DTD is applied to detecting decorative tags. We should point out that to train the DTD, we should collect sample tags (both positive and negative) from many search engines in different domains so th at more varieties are taken into consideration. However, the training uses all the collected sample tags and is done only once. There is no separate training for each individual search engine. In othe r words, the training is domain-independent and search engine independent, and the trained DTD is also domain-independent and s earch engine independent. As a result, once the DTD is trained, it can be applied to any search engine to identify the deco rative tags in its SRRs. We should also note that when the trained DTD is applied to classifying the tags to extract the SRR template for a particular search engine, we need to collect sample tags from that search engine (see section 4.1.3 for more details about this). Once the DTD is trained, we are ready to use it in the SRR template mining algorithm. After we applied the SRR extraction tool on the sample pages returned by a search engine, we have a collection of SRRs. We check all SRRs to collect HTML tags and their occurring pattern statistics fro m the SRRs X  tag forests. Thus We already have a prior-probability table for tag names obtained from DTD training. The feature 9 of a tag can be obtained by a simple table looking-up. A neutral 0.5 is assigned to tags that do not exist in the prior-probability table. We feed the statistical features of each tag into DTD. An output greater than 0.5 indicates the i nput is a decorative tag. Once all decorative tags are identified. We traverse the tag forests of all SRRs again to remove the decorative tags from them. To remove a node from a tag forest, we simply take its immediate children to replace the node itself in the tag forest. Figure 5 shows an example. The node C in the tag tr ee in Figure 5a is a decorative tag. After it is removed, the tag tree becomes the one in Figure 5b. After the decorative tags are removed from the tag forest of an SRR, we pre-order traverse the tag forest to generate the tag string (Figure 2c shows part of a tag string). We partition the tag string into segments by the alternatively occurring tags and texts, such that no segment contains mixture of tag and text, and, each segment is maximized. Since decora tive tags have been removed, the segments that consist of ta gs are considered as template strings, while the segments that consist of texts are considered as represent a template string, and ts = { t 1 , d 2 , t t } be a tag string. Because of the existence of possible Type 2 mismatch, there might be template texts in d i . Thus a general data string may be a combination of multiple data units plus template texts that bound them. Before we can detect the template texts, we need to group the data strings that are data units of the same semantic meaning (e.g., values of the attribute) in different SRRs, so that we can exploit the statistical properties of template texts. Previous works [2, 5, 15, 21, 22, 25] developed sophisticated alignment techniques to group data strings. One problem of alignment-based techniques is that they are too sensitive to outliers. The existence of data th at are extracted from false-SRRs (due to the imperfect nature of the SRR extraction tool used) will significantly degrade the quality of the outcome. Since we cannot guarantee that the SRRs we have are 100% correct when using a fully automatic tool, more robust method for grouping semantically related data strings is necessary. Our method uses a hierarchical clustering algorithm to group the data strings. Generally, a data string is bounded by two template strings on a tag string. Thus a data string can be represented as D = &lt; t While d represents the data string itself, t L and t and right bounding template strings respectively. Note that t t might be empty. Ideally, a data string with left and right bounds is an instance of a data slot in the SRR template. But at this point, we need further processing to get more reliable results. A data string d is a text string, which mi ght be a hyper link, a date value, a numeric value, etc. We define several text types of data strings to capture the different nature of text strings. Current prototype system defines the fo llowing 5 text types: NUMBER, DATE, HYPER LINK, PRICE and TEXT. The type  X  X EXT X  refers to the text that can X  X  be recognized as any of other types. Let length ( d ) = 1 and length ( t ) = 1. Thus the length of a tag string ts is defined as pos ( d i ) = i / length ( ts ). Let DT ( t i , t j ) represent the distance between template strings t t distance matrix of types is used) between d i and d j d ) = | pos ( d i ) -pos ( d j )|. Let DD ( D i , D between two data strings: D i = &lt; t Li , d i , t Ri To avoid one cluster contains two data strings from the same otherwise, the followi ng formula is used: DD ( D i , D j ) = We apply a bottom-up hierarchical clustering algorithm on all data strings extracted from all SRRs of the same search engine. The distance between two clusters is computed by single link . A distance threshold is set up to te rminate the clustering process. TTD is designed to identify te mplate texts from data string clusters. For each cluster, we first identify high frequency texts. Intuitively, a template text tends to have a high occurring frequency, but not all texts that occur frequently are template texts. Some common tokens, like  X  X he X ,  X  X f X  and punctuations, also tend to have high frequenc ies in most text strings. The TTD is a neural network classifier that classifies high frequency text strings into two cat egories: template texts and non-template texts. Before introduci ng the TTD design, we would like to describe how to extract hi gh frequency texts from a cluster first. Suppose we have a data string cluster c , which contains n data strings. The high-frequency texts are sub-strings of data strings in text tends to occur in a relatively fixed position in data strings, we do not use the simple term frequency. Instead, we introduce a position-weighted voting algorithm to find out the high-frequency texts. The basic idea is that the same token occurring at the same position in different data strings is more likely to be a template text. Figure 6 shows the algorithm for extracting high-frequency texts from a data string cluster. A data string d of length m consists of m tokens d = { tk m }. Each token tk i has a relative position, which is defined as Ptk = i / m . Thus the position distance be tween two tokens can be computed as DPT ( tk i , tk j ) = | Ptk i  X  Ptk j |. We pick up k data strings by randomly sampling the data strings in C as seeds. For each seed data string, we take its tokens as the seed tokens. All seed tokens have an initial weight of 0. Then tokens. E.g., if a token tk in d is the same as a seed token tk weight of tk s is updated as W  X ( tk s ) = W ( tk s ) + (1-DPT ( tk After the voting, for each seed data string, we group maximum consecutive tokens that have a we ight higher than a threshold as the high-frequency texts. We take all high-frequency texts extracted from the k seed data strings as the samples for TTD . Algorithm High_Freq_Text ( C ) H  X   X  ; 
S  X  sampling data strings in C; for s  X  S do for tk s  X  s do for d  X  C and d  X  s do if tk s = tk d end for; end for; put  X  ss into H; end for; return H ; Similar to DTD, TTD is also a neural network classifier, which can identify template texts from high-frequency texts extracted from a data string cluster. The inputs of TTD are the statistical features of high-frequency texts. Table 2 shows the 7 features used in current TTD. 
Feature # Description 1 Average occurring number 2 Deviation of occurring number 3 Average first occurring position from left 4 Deviation of first occurring position from left 5 Average first occurring position from right 6 Deviation of first occurring position from right 7 Prior-probability of being a template text Features in Table 2 have the similar meanings as their counterparts in Table 1. Features 1-6 are used to capture the randomness of the occurring pattern s of a high-frequency text in data strings. Feature 7 is the highest value of the prior-probabilities of the tokens in the high-frequency text to be a template text. The TTD is a three-layer backpropagation neural network classifier, with an input layer c onsisting of 7 units, a hidden layer with 3 units and an output layer with 1 unit. We use the training samples extracted from the same result page set that is used to train DTD to train TTD. The sample high-frequency texts are collected as follow: after SRRs are extracted from result pages, apply DTD to detect and remove d ecorative tags, and then cluster data strings and collect high-fre quency texts and their features from the clusters as the samples for TTD. Similar to DTD, TTD also needs to be trained only once and the trained TTD is domain-independent and search engine independent so it can be applied to any search engines. We perform the data string cluste ring to group data units of the semantic type together. To reduce the effect of outliers (false-SRRs), small clusters with their numbers of members smaller than a threshold are discarded. We ex tract high-frequency text strings from every cluster using the method in section 4.3.1. Then the occurrences of each high-frequency text in every data string in the cluster are checked to collect the statistical features (1-6). The prior-probability of the high-frequency text is obtained by a table look-up. The highest prior-probability of all tokens in the high-frequency text is used as the pr ior-probability of the text. A probability table. Each high-frequency text is fed into TTD. An output larger than 0.5 indicates the input is a template text. All identified template texts are used to further partiti on the data strings. The template texts on the left and right boundaries are merged into their template string neighbors. We cluster the newly generated data strings again using the method described in section 4. 2. After removing the small clusters, all kept data strings are used to generate template graph. A data string cluster of size N contains N data strings from N different SRRs. An SRR, on the other hand, contains M data strings that belong to M different clusters. Ideally, each data string cluster represents a data slot in the SRR template. Note that the order of data strings in an SRR represents the relationship of the data slots corresponding to the cl usters that contain the data strings in the SRR. Consider an SRR r consisting of data strings &lt; d ..., d m &gt;, while each data string belongs to cluster c c each cluster c i , 1  X  i  X  m, represents a data slot ds the SRR X  X  template graph. Thus any adjacent data string pair &lt; d d i+1 &gt; in r implies that there exists an edge between ds the SRR X  X  template graph. The SRR r implies that there is a path ds , ds 2 , ..., ds i , ds +1 , ..., ds m in the template graph. Due to the optional and disjunctive data units, a single SRR can only provide a partial view of th e template graph. However, the combination of multiple SRRs wi th all possible unit variations can provide the complete view of the SRR template graph. Because of the existence of false SRRs (outliers), errors in the DTD, TTD and the data string cl ustering algorithm, not all SRRs provide the correct information a bout the template. We design an algorithm to let SRRs vote for the te mplate graph. The idea is that as long as a majority of SRRs provide correct information, the algorithm will generate the corr ect template graph. Figure 7 shows an example of the voting process. Figure 8 shows the template graph voting algorithm. A vertex in a template graph represents a data slot in the SRR template. We consider each data string cluster as a data slots initially, and then let all SRRs vote for the relationshi ps between the data slots. In essence, an SRR template graph represents the data slots and their relationship in SRRs. Algorithm Build_Temp_Graph ( S SRR ) 
G ( V , E )  X   X  ; for r  X  S SRR do for &lt; d i , d i+1 &gt;  X  r do If v i = null Create v i and add v i to V ; if v i+1 = null Create v i+1 and add v i+1 to V ; if e = null Create e and add e to E ; end for; end for; for e  X  E do if W ( e ) &lt; T e remove e from E ; end for; for v  X  V do if W ( v ) &lt; T v remove v from V ; end for; break cycles in G by removing edges with lowest weight in cycles; return G ; At first we have an empty template graph. Then for each SRR, we check its consecutive data string pairs d i and d algorithm in section 4.2 ensures th at two data string pairs belong to two different clusters. We get the data string clusters c that d i and d i+1 belong to. The next step is to ensure that there are two data clusters, and the weight of the edge from v increased by 1. After all SRRs voted for the template graph, we check the graph to remove low weight edges and vertexes. They are considered as false because of their low supports . In some cases there might be cycles in the generated template graph, which is contradictory to the assumption that a template graph is a DAG. We break the detected cycles by removing the edges with the lowest weights in them. The outcome is the SRR template graph. We implemented a prototype SRR template mining system based on the proposed method. The system contains a DTD trainer, a TTD trainer and an SRR template builder. The DTD trainer and TTD trainer are used to train the neural network based Decorative Tag Detector and the Template Text Detector. As introduced in section 3.3, The SRR template builder consists of an SRR extraction module, a DTD, a data string clustering module, a TTD and a template generating modul e. With pre-trained DTD and TTD, the SRR template builder is a fully automatic template building system. It takes a set of result pages that contain SRRs as input; the output is a template graph that can be used to extract the detailed data units from th e SRRs. The prototype system shows that the proposed method is both effective and efficient. On a laptop with a Pentium M 1.3G processor, it can build the SRR template from a set of 10 result pages within 5 to 30 seconds. We present the experimental resu lts in two parts. Section 5.1 presents the performance of DT D and TTD as neural network classifiers; section 5.2 presents the performance of the SRR template builder with the DTD and TTD embedded. Accordingly, pages downloaded from 57 search e ngines, while part 2 consists of sample pages downl oaded from 50 search engines. These two sets of search engines are disjoint. For each search engine, we collect 5 to 10 sample result pa ges by manually submitting probe queries. Since a typical search engine result page contains 10 or more SRRs, we usually have more than 50 SRRs to collect statistic features for tags a nd high-frequency texts for DTD and TTD. We use the first 57 search engines to train DTD and TTD. We implement the DTD and TTD based on Joone engine 1.2.1 [29]. Both DTD and TTD consis t of three sigmoid layers. Training samples for DTD are HTML tags extracted from the tag forests of SRRs. We use the method introduced in section 4.1.2 to collect the sample tags and their features. A total of 923 sample tags are collected from the 57 search engines in testbed part 1. The training samples for TTD are high-frequency texts. They are collected by the method introduced in section 4.3.1. From the result pages of the 57 search engines, a total of 943 high-frequency texts are collected as the training samples for TTD. We use 5-fold cross validation to measure the performance of DTD and TTD. The results Tabl e 3 show that the proposed features and the design of the neural network classifiers can effectively identify the decorative tags as well as template texts. Before we test the SRR template builder on testbed part 2, we train the DTD and TTD on all samples collected from testbed part 1. The testing of SRR template builder on each search engine is fully automatic, without any human involvement. The 50 search engines in testbed pa rt 2 consist of a wide variety of search engines: 20 e-commerce search engines, which are usually Web databases that search structured data, 15 news search engines, 10 medical search e ngines and 5 others. Among the 50 search engines, only three arrange their results in tabular format. We use a method similar to EXALG [2] to measure the performance of the SRR template builder. We first manually check the SRRs of each search engine to identify the data units in the SRRs. Then the data slots in the generated template graph are checked against the manually iden tified data units. We count the numbers of data slots that matc h and mismatch the data units. Finally the recall and precision of data units are used to measure the performance of the SRR template builder. The manual identification of data units from semi-structured SRR is a somewhat subjective process. We follow the following basic guidelines in doing the identification. First we do not extract data that is presented in the attributes of HTML tags, such as the HREF attribute of a hyper link. Thus the functional links like  X  X ached X  and  X  X imilar pages X  are considered as templates instead of data. Second, a date is consid ered as a single data unit instead of a composition of month, day a nd year. Third, a complete hyper link is considered as a single data unit, etc. Another thing worth noting is that we don X  X  differentia te the optional and disjunctive data units from other data units wh en computing the statistics. Category Actual Extracted Correct Recall Precision Table 4 shows the summary of the test of the SRR template builder. The column with header Category lists the search engine categories. The column with head er Actual, Extracted and Correct list the actually number of data units in the SRRs for each search engine, the number of data slots in the generated SRR template for each search engine, and the number of data slots in SRR template that match the corresponding data units for each search engine, respectively. The last two columns list the recall and precision. Each row presents the performance of the SRR template builder on a search engine category, except for the last row, which presents the performance over all 50 search engines. We can see that the proposed method is generally effective, with a recall of 92% and precision of 88.9%. We compare our performance with EXALG [2], which is currently the best automatic web data template extraction tool in the literature. EXALG correctly extracted 80% of data units from a collection of 45 web sites. Our recall is signi ficantly higher although different datasets are used in these expe riments. EXALG didn X  X  report its precision. The fairly even performance among th e search engines in the four categories shows the proposed me thod works almost equally well on a wide varieties of web data bases and search engines. We missed 8% of data units during the test. The major reason is that some data units have almost exactly the same values in all SRRs on result pages of some sear ch engines (for example, there are two sets of data units in th e SRRs of officedepot.com, one set is for  X  X nits X  and the other is for  X  X vailability X ; on all result pages we collected, the value of  X  X nits X  is always  X  X ach X , and the value of  X  X vailability X  is always  X  X n St ock X ). Thus those data units were incorrectly identified as templates by the system. Another reason is the failure of TTD, which sometimes incorrectly put two or also generated, which prevented a higher precision. This is mostly caused by the failure of DTD, which may sometimes incorrectly split a data slot into more data slots. This seems to imply that the 57 search engines that were used to train DTD cannot represent the 50 search engines in part 2 very well. In fact, the majority of search engines in testbed part 1 are Google like document search engines, while the search engines in part 2 have a wider variety. We expect a larger training se t would improve the performance. Knowing the precise template of SRRs can greatly help applications that need to interact with search engines. For example, the template can help extract data units from the SRRs, which is a critical step in SRR annotation. In this paper, we proposed a new technique to extract the precise SRR template for any search engine automatically. As mentioned in the introduction section, this soluti on has quite a few novel features. For the first time, we systematically identified the factors that make the extraction of SRR temp late difficult and proposed novel solutions to address them explicitly and specifically. Even though our solution involves training in order to build the decorative tag detector and the template text detector, the training only needs to be carried out once and the trained detectors can be applied to any search engines, including those that are not used in the training. Our experimental results indicate that our solution is significantly more accurate than an existing state-of-the-art solution. Our experiment revealed that our statistics-based solution does have an inherent weakness in deali ng with attributes that have the same or nearly the same values (data units) in all SRRs. These data units will be mistakenly r ecognized as template texts. We plan to investigate how to overcom e this weakness. One idea is to supplement our solution with a di fferent solution. For example, one phenomenon we observed about th ese data units is that they often have their annotation labels ne xt to them (usually in front of identical, and if the data units are not completely identical, these labels (they are template texts) can be recognized as the labels for the data units following them by the common prefix annotator proposed in [17, 22] and consequently the data units are also recognized correctly. But this still does not solve the problem when all the data units are identical so new solutions are still needed. This work is supported in part by the following NSF grants: IIS-0414981, IIS-0414939 and CNS-0454298. [1] B. Adelberg. NoDoSE  X  A Tool for Semi-Automatically [2] A. Arasu, H. Garcia-Molina. Extracting Structured Data [3] R. Baumgartner, S. Flesca and G. Gottlob. Visual Web [4] D. Buttler, L. Liu, C. Pu. A Fully Automated Object [5] C. Chang, S. Lui. IEPAD: Information Extraction based on [6] C. Chang, M. Kayed, M. R. Girgis and K. F. Shaalan. A [7] V. Crescenzi, G. Mecca, P. Merialdo. RoadRunner: Towards [8] D. Embley, Y. Jiang, Y. Ng. Record-Boundary Discovery in [9] A. Hogue and D. Karger. Thresher: Automating the [10] C. Hsu and M. Dung. Generati ng Finite-State Transducers [11] U. Irmak, and T. Suel. Interactive Wrapper Generation with [12] N. Kushmerick, D. Weld, R. Doorenbos. Wrapper Induction [13] A. Laender, B. Ribeiro-Neto, A. da Silva, J. Teixeira. A [14] B. Liu, R. Grossman and Y. Zhai. Mining Data Records in [15] B. Liu and Y. Zhai. NET  X  A System for Extracting Web [16] L. Liu, C. Pu and W. Han. XWRAP: An XML-Enabled [17] Y. Lu, H. He, H. Zhao, W. Meng, C. Yu. Annotating [18] W. Meng, C. Yu, K. Liu. Bu ilding Efficient and Effective [19] I. Muslea, S. Minton, C. Knoblock . A Hierarchical Approach [20] S. Raghavan, H. Garcia-Molin a. Crawling the Hidden Web. [21] K. Simon, and G. Lausen. ViPER: Augmenting Automatic [22] J. Wang, F. Lochovsky. Data Extraction and Label [23] Z. Wu, V. Raghavan et al. To wards Automatic Incorporation [24] G. Yang, I. V. Ramakrishna n and M. Kifer. On the [25] Y. Zhai, B. Liu. Web Data Extraction Based on Partial Tree [26] Y. Zhai, B. Liu. Extracting Web Data Using Instance-Based [27] H. Zhao, W. Meng, Z. Wu, V. Raghavan, C. Yu. Fully [28] J. Zhu, Z. Nie, J. Wen, B. Zhang, W. Ma. Simultaneous [29] http://www.jooneworld.com/. 
