 Textual Entailment (TE) has been proposed as a unifying generic framework for modeling lan-guage variability and semantic inference in dif-ferent Natural Language Processing (NLP) tasks. The Recognizing Textual Entailment (RTE) task (Dagan and Glickman, 2007) consists in deciding, given two text fragments (respectively called Text -T , and Hypothesis -H ), whether the meaning of H can be inferred from the meaning of T , as in:
The RTE problem is relevant for many different areas of text processing research, since it repre-sents the core of the semantic-oriented inferences involved in a variety of practical NLP applications including Question Answering, Information Re-trieval, Information Extraction, Document Sum-marization, and Machine Translation. However, in spite of the great potential of integrating RTE into complex NLP architectures, little has been done to actually move from the controlled scenario pro-posed by the RTE evaluation campaigns 1 to more practical applications. On one side, current RTE technology might not be mature enough to provide reliable components for such integration. Due to the intrinsic complexity of the problem, in fact, state of the art results still show large room for im-provement. On the other side, the lack of available tools makes experimentation with the task, and the fast prototyping of new solutions, particularly dif-fi cult. To the best of our knowledge, the broad literature describing RTE systems is not accompa-nied with a corresponding effort on making these systems open-source, or at least freely available. We believe that RTE research would signi fi cantly bene fi t from such availability, since it would allow to quickly set up a working environment for ex-periments, encourage participation of newcomers, and eventually promote state of the art advances.
The main contribution of this paper is to present the latest release of EDITS (Edit Distance Textual Entailment Suite), a freely available, open source software package for recognizing Textual Entail-ment. The system has been designed following three basic requirements: Modularity . System architecture is such that the overall processing task is broken up into major modules. Modules can be composed through a con fi guration fi le, and extended as plug-ins ac-cording to individual requirements. System X  X  work fl ow, the behavior of the basic components, and their IO formats are described in a compre-hensive documentation available upon download. Flexibility. The system is general-purpose, and suited for any TE corpus provided in a simple XML format. In addition, both language depen-dent and language independent con fi gurations are allowed by algorithms that manipulate different representations of the input data. Figure 1: Entailment Engine, main components and work fl ow Adaptability. Modules can be tuned over train-ing data to optimize performance along several di-mensions ( e.g. overall Accuracy, Precision/Recall trade-off on YES and NO entailment judgements). In addition, an optimization component based on genetic algorithms is available to automatically set parameters starting from a basic con fi guration. EDITS is open source, and available under GNU Lesser General Public Licence (LGPL). The tool is implemented in Java, it runs on Unix-based Operating Systems, and has been tested on MAC OSX, Linux, and Sun Solaris. The latest release of the package can be downloaded from http: //edits.fbk.eu . The EDITS package allows to:  X  Create an Entailment Engine (Figure 1) by  X  Train such Entailment Engine over an anno- X  Use the Entailment Engine and the Model to
EDITS implements a distance-based framework which assumes that the probability of an entail-ment relation between a given T-H pair is inversely proportional to the distance between T and H ( i.e. the higher the distance, the lower is the probability of entailment). Within this framework the system implements and harmonizes different approaches to distance computation, providing both edit dis-tance algorithms, and similarity algorithms (see Section 3.1). Each algorithm returns a normalized distance score (a number between 0 and 1). At a training stage, distance scores calculated over an-notated T-H pairs are used to estimate a threshold that best separates positive from negative exam-ples. The threshold, which is stored in a Model , is used at a test stage to assign an entailment judge-ment and a con fi dence score to each test pair.
In the creation of a distance Entailment Engine, algorithms are combined with cost schemes (see Section 3.2) that can be optimized to determine their behaviour (see Section 3.3), and optional ex-ternal knowledge represented as rules (see Section 3.4). Besides the de fi nition of a single Entailment Engine, a unique feature of EDITS is that it al-lows for the combination of multiple Entailment Engines in different ways (see Section 4.4).
Pre-de fi ned basic components are already pro-vided with EDITS, allowing to create a variety of entailment engines. Fast prototyping of new solu-tions is also allowed by the possibility to extend the modular architecture of the system with new algorithms, cost schemes, rules, or plug-ins to new language processing components. This section overviews the main components of a distance Entailment Engine, namely: i) algo-rithms, iii) cost schemes, iii) the cost optimizer, and iv) entailment/contradiction rules. 3.1 Algorithms Algorithms are used to compute a distance score between T-H pairs.

EDITS provides a set of prede fi ned algorithms, including edit distance algorithms, and similar-ity algorithms adapted to the proposed distance framework. The choice of the available algorithms is motivated by their large use documented in RTE literature 2 .

Edit distance algorithms cast the RTE task as the problem of mapping the whole content of H into the content of T. Mappings are performed as sequences of editing operations ( i.e. insertion, deletion, substitution of text portions) needed to transform T into H, where each edit operation has a cost associated with it. The distance algorithms available in the current release of the system are:  X  Token Edit Distance: a token-based version  X  Tree Edit Distance: an implementation of the Similarity algorithms are adapted to the ED-ITS distance framework by transforming measures of the lexical/semantic similarity between T and H into distance measures. These algorithms are also adapted to use the three edit operations to support overlap calculation, and de fi ne term weights. For instance, substitutable terms in T and H can be treated as equal, and non-overlapping terms can be weighted proportionally to their insertion/deletion costs. Five similarity algorithms are available, namely:  X  Word Overlap: computes an overall (dis- X  Jaro-Winkler distance: a similarity algorithm  X  Cosine Similarity: a common vector-based  X  Longest Common Subsequence: searches the  X  Jaccard Coef fi cient: confronts the intersec-3.2 Cost Schemes Cost schemes are used to de fi ne the cost of each edit operation.

Cost schemes are de fi ned as XML fi les that ex-plicitly associate a cost (a positive real number) to each edit operation applied to elements of T and H. Elements, referred to as A and B, can be of dif-ferent types, depending on the algorithm used. For instance, Tree Edit Distance will manipulate nodes in a dependency tree representation, whereas To-ken Edit Distance and similarity algorithms will manipulate words . Figure 2 shows an example of cost scheme, where edit operation costs are de-fi ned as follows: Insertion(B)=10 -inserting an element B from H to T, no matter what B is, always costs 10; Deletion(A)=10 -deleting an element A from T, no matter what A is, always costs 10; substitution(A,B)=0 if A=B -substituting A with B costs 0 if A and B are equal; substitution(A,B)=20 if A ! = B -substituting A with B costs 20 if A and B are different.
 In the distance-based framework adopted by EDITS, the interaction between algorithms and cost schemes plays a central role. Given a T-H pair, in fact, the distance score returned by an al-gorithm directly depends on the cost of the opera-tions applied to transform T into H (edit distance algorithms), or on the cost of mapping words in H with words in T (similarity algorithms). Such interaction determines the overall behaviour of an Entailment Engine, since distance scores returned by the same algorithm with different cost schemes can be considerably different. This allows users to de fi ne (and optimize, as explained in Section 3.3) the cost schemes that best suit the RTE data they want to model 3 .

EDITS provides two prede fi ned cost schemes:  X  Simple Cost Scheme -the one shown in Fig- X  IDF Cost Scheme -insertion and deletion
In the creation of new cost schemes, users can express edit operation costs, and conditions over the A and B elements, using a meta-language based on a lisp-like syntax ( e.g. (+ (IDF A) (IDF B)), (not (equals A B))). The system also provides functions to access data stored in hash fi les. For example, the IDF Cost Scheme accesses the IDF values of the most frequent 100K English words (calculated on the Brown Corpus) stored in a fi le distributed with the system. Users can create new hash fi les to collect statistics about words in other languages, or other information to be used inside the cost scheme. 3.3 Cost Optimizer A cost optimizer is used to adapt cost schemes (ei-ther those provided with the system, or new ones de fi ned by the user) to speci fi c datasets.
The optimizer is based on cost adaptation through genetic algorithms, as proposed in (Mehdad, 2009). To this aim, cost schemes can be parametrized by externalizing as parameters the edit operations costs. The optimizer iterates over training data using different values of these param-eters until on optimal set is found ( i.e. the one that best performs on the training set). 3.4 Rules Rules are used to provide the Entailment Engine with knowledge ( e.g. lexical, syntactic, semantic) about the probability of entailment or contradic-tion between elements of T and H. Rules are in-voked by cost schemes to in fl uence the cost of sub-stitutions between elements of T and H. Typically, the cost of the substitution between two elements A and B is inversely proportional to the probability that A entails B.
 Rules are stored in XML fi les called Rule Repositories, with the format shown in Figure 3. Each rule consists of three parts: i) a left-hand side, ii) a right-hand side, iii) a probability that the left-hand side entails (or contradicts) the right-hand side.

EDITS provides three prede fi ned sets of lexical entailment rules acquired from lexical resources widely used in RTE: WordNet 4 , Lin X  X  word sim-ilarity dictionaries 5 , and VerbOcean 6 .
Figure 3: Example of XML Rule Repository This section provides basic information about the use of EDITS, which can be run with commands in a Unix Shell. A complete guide to all the pa-rameters of the main script is available as HTML documentation downloadable with the package. 4.1 Input The input of the system is an entailment corpus represented in the EDITS Text Annotation Format (ETAF), a simple XML internal annotation for-mat. ETAF is used to represent both the input T-H pairs, and the entailment and contradiction rules. ETAF allows to represent texts at two different levels: i) as sequences of tokens with their asso-ciated morpho-syntactic properties, or ii) as syn-tactic trees with structural relations among nodes.
Plug-ins for several widely used annotation tools (including TreeTagger, Stanford Parser, and OpenNLP) can be downloaded from the system X  X  website. Users can also extend EDITS by imple-menting plug-ins to convert the output of other an-notation tools in ETAF.
 Publicly available RTE corpora (RTE 1-3, and EVALITA 2009), annotated in ETAF at both the annotation levels, are delivered together with the system to be used as fi rst experimental datasets. 4.2 Con fi guration The creation of an Entailment Engine is done by de fi ning its basic components (algorithms, cost schemes, optimizer, and rules) through an XML con fi guration fi le. The con fi guration fi le is divided in modules, each having a set of options. The fol-lowing XML fragment represents a simple exam-ple of con fi guration fi le: This con fi guration de fi nes a distance Entailment Engine that combines Tree Edit Distance as a core distance algorithm, and the prede fi ned IDF Cost Scheme that will be optimized on training data with the Particle Swarm Optimization algorithm ( X  pso  X ) as in (Mehdad, 2009). Adding external knowledge to an entailment engine can be done by extending the con fi guration fi le with a reference to a rules fi le ( e.g.  X  rules.xml  X ) as follows: 4.3 Training and Test Given a con fi guration fi le and an RTE corpus an-notated in ETAF, the user can run the training procedure to learn a model. At this stage, ED-ITS allows to tune performance along several di-mensions ( e.g. overall Accuracy, Precision/Recall trade-off on YES and/or NO entailment judge-ments). By default the system maximizes the over-all accuracy (distinction between YES and NO pairs). The output of the training phase is a model : a zip fi le that contains the learned threshold, the con fi guration fi le, the cost scheme, and the en-tailment/contradiction rules used to calculate the threshold. The explicit availability of all this in-formation in the model allows users to share, repli-cate and modify experiments 7 .

Given a model and an un-annotated RTE corpus as input, the test procedure produces a fi le con-taining for each pair: i) the decision of the system (YES, NO), ii) the con fi dence of the decision, iii) the entailment score, iv) the sequence of edit oper-ations made to calculate the entailment score. 4.4 Combining Engines A relevant feature of EDITS is the possibility to combine multiple Entailment Engines into a sin-gle one. This can be done by grouping their def-initions as sub-modules in the con fi guration fi le. EDITS allows users to de fi ne customized combi-nation strategies, or to use two prede fi ned com-bination modalities provided with the package, namely: i) Linear Combination, and ii) Classi-fi er Combination. The two modalities combine in different ways the entailment scores produced by multiple independent engines, and return a fi nal decision for each T-H pair.

Linear Combination returns an overall entail-ment score as the weighted sum of the entailment scores returned by each engine: In this formula, weight i is an ad-hoc weight parameter for each entailment engine. Optimal weight parameters can be determined using the same optimization strategy used to optimize the cost schemes, as described in Section 3.3.

Classi fi er Combination is similar to the ap-proach proposed in (Malakasiotis and Androut-sopoulos, 2007), and is based on using the entail-ment scores returned by each engine as features to train a classi fi er (see Figure 4). To this aim, ED-ITS provides a plug-in that uses the Weka 8 ma-chine learning workbench as a core. By default the plug-in uses an SVM classi fi er, but other Weka algorithms can be speci fi ed as options in the con-fi guration fi le.

The following con fi guration fi le describes a combination of two engines ( i.e. one based on Tree Edit Distance, the other based on Cosine Similarity), used to train a classi fi er with Weka 9 . To give an idea of the potentialities of the ED-ITS package in terms of fl exibility and adaptabil-ity, this section reports some results achieved in RTE-related tasks by previous versions of the tool. The system has been tested in different scenarios, ranging from the evaluation of standalone systems within task-speci fi c RTE Challenges, to their inte-gration in more complex architectures.

As regards the RTE Challenges, in the last years EDITS has been used to participate both in the PASCAL/TAC RTE Campaigns for the En-glish language (Mehdad et al., 2009), and in the EVALITA RTE task for Italian (Cabrio et al., 2009). In the last RTE-5 Campaign the result achieved in the traditional  X 2-way Main task X  (60.17% Accuracy) roughly corresponds to the performance of the average participating systems (60.36%). In the  X  X earch X  task (which consists in fi nding all the sentences that entail a given H in a given set of documents about a topic) the same con fi guration achieved an F1 of 33.44%, rank-ing 3rd out of eight participants (average score 29.17% F1). In the EVALITA 2009 RTE task, EDITS ranked fi rst with an overall 71.0% Accu-racy. To promote the use of EDITS and ease ex-perimentation, the complete models used to pro-duce each submitted run can be downloaded with the system. An improved model obtained with the current release of EDITS, and trained over RTE-5 data (61.83% Accuracy on the  X 2-way Main task X  test set), is also available upon download. As regards application-oriented integrations, EDITS has been successfully used as a core com-ponent in a Restricted-Domain Question Answer-ing system within the EU-Funded QALL-ME Project 10 . Within this project, an entailment-based approach to Relation Extraction has been de fi ned as the task of checking for the existence of en-tailment relations between an input question (the text in RTE parlance), and a set of textual realiza-tions of domain-speci fi c binary relations (the hy-potheses in RTE parlance). In recognizing 14 re-lations relevant in the CINEMA domain present in a collection of spoken English requests, the system achieved an F1 of 72.9%, allowing to return cor-rect answers to 83% of 400 test questions (Negri and Kouylekov, 2009). We have presented the fi rst open source package for recognizing Textual Entailment. The system offers a modular, fl exible, and adaptable working environment to experiment with the task. In addi-tion, the availability of pre-de fi ned system con fi g-urations, tested in the past Evaluation Campaigns, represents a fi rst contribution to set up a collabo-rative environment, and promote advances in RTE research. Current activities are focusing on the de-velopment of a Graphical User Interface, to further simplify the use of the system.
 The research leading to these results has received funding from the European Community X  X  Sev-enth Framework Programme (FP7/2007-2013) un-der Grant Agreement n. 248531 (CoSyne project).
