 We introduce a new problem, the Online Selective Anomaly Detection (OSAD), to model a specific scenario emerging from research in sleep science. Scientists have segmented sleep into several stages and stage two is characterized by two patterns (or anomalies) in the EEG time series recorded on sleep subjects. These two patterns are sleep spindle (SS) and K-complex. The OSAD problem was introduced to de-sign a residual system, where all anomalies (known and un-known) are detected but the system only triggers an alarm when non-SS anomalies appear. The solution of the OSAD problem required us to combine techniques from both data mining and control theory. Experiments on data from real subjects attest to the e ff ectiveness of our approach. Sleep EEG Anomalies, Dynamic Residue Model
Research in human sleep condition has emerged as a rapidly growing area within medicine, biology and physics. A defin-ing aspect of sleep research is the large amount of data that is generated in a typical sleep experiment. One of the key tools in sleep research experiments is polysomnography, which consists of overnight recordings of a range of measures,of ahumansubject,inastateofsleep.Polysomnographyad-dresses a subject X  X  eye movement, muscle tone, and neural activity recorded with electroencephalography (EEG) [ 20, 5]. A typical full night EEG time-series, recorded between 4-64 locations on the scalp, at 200 Hz, for eight hours, will generate approximately 300MB of data. A typical clinical study may use 10 X 50 subjects, which results in very large data sets. Surprisingly vast majority of sleep clinics still use amanualprocesstoanalyzetherecordedEEGtime-series. Hence there is considerable interest in automating the anal-ysis of EEG generated from sleep experiments.

Scientists have segmented sleep into several stages based on the responsiveness of the subject and other physiological Figure 1: Sleep spindles (SS) along with K-complexes (KC) are defining characteristics of stage 2 sleep. Both SS and KC will show up as residuals in an LDS system. The OSAD problem will lead to a new residual time-series where SS will be automatically supressed but KC will remain una ff ected. features.(See Appendix B for more information regarding sleep stages). Of particular important is what is termed as stage 2 (moderately deep sleep). This stage is character-ized by two phenomenon that occur in the EEG time series. These are sleep spindles ,whicharetransientburstsofneural activity with a characteristic frequency of 12 X 14 Hz, and K-Complexes ,whichareshort,large-amplitudevoltagespikes. Both phenomena are implicated in memory consolidation and learning, but the physiology and mechanisms by which they occur are not yet fully understood, see [ 5, 10, 20, 9].
The physiological mechanisms and functional roles of K-complexes and sleep spindles is under investigation, but ana-lyzing their properties requires identifying them in the EEG, which is a significant challenge for several reasons. Sleep spindles and K-complexes typically last less than 1 s, and there are only on the order of 100 of these events over the course of an entire night. Identification of these events is further complicated by the presence of artifacts in the data, which are often caused by movement of the subject, but which can also occur due to electrical noise or loose elec-trode connections. These artifacts must be ignored when attempting to identify sleep spindles and K-complexes. Be-cause the electric fields produced by the brain are quite weak (the induced electrical potential is on the order of 50  X  V), the signals also contain a significant noise component. Fi-nally, a typical full-night EEG time-series consists of eight hours of data sampled at 200 Hz.
 In this paper we introduce the Online Selective Anomaly Detection (OSAD) problem which captures a particular sce-nario in sleep research. As noted above, around 100 sleep spindles will occur during the course of a night. The number of K-Complexes is much fewer. For some experiments scien-tists are interested in identifying both sleep spindles and K-Complexes but only want to be notified with an alert when a non-spindle anomaly occurs (for example K-Complexes).
The solution of the OSAD problem combines techniques form both data mining and control theory. Data Mining is used to model and infer the normal EEG pattern per sub-ject. Experiments have shown that model parameters do not transfer accurately across to other subjects. In our case we will use a Linear Dynamical System (LDS) to model the EEG time series. Then based on frequency analysis, we infer the sleep spindle (SS) pattern and integrate the pattern as a disturbance into the LDS. The control theory part is used to design anewresidualwhichsuppressesSSsignalsbutfaith-fully represents other errors generated by the LDS model. Thus by selectively suppressing SS pattern, the objectives of the OSAD problem are achieved.

For example, consider Figure 1.Thetopframeshowsa typical EEG time series with both the SS and KC high-lighted. The middle frame shows a typical residual time series based on an LDS model. The bottom frame shows a new residual designed to solve the OSAD problem. Notice that the error due to the presence of SS is suppressed but the residual due to the appearance of KC remains una ff ected.
The main contributions of the paper are:
The rest of the paper is as follows. In Section 2, we rig-orously define the OSAD problem. In Section 3 we present our methodology to infer the parameters of the LDS and use control theory to design a new residual system. In Section 4, we apply our approach to real sleep data and evaluate our results. We overview related work in Section 5 and conclude in Section 6 with a summary and potential ideas for future research.
In this section we present our problem statement for se-lective anomaly detection.

The starting point is an observed time series of N points y = { y i } N i =1 where each y i  X  R m .Furthermore,weas-sume that the y measures the output of a system which is generated from a latent variable x  X  R n .Therelationship between x and y is governed by a standard Linear Dynamic system (LDS) model [ 27]whichisspecifiedas Here A is an n  X  n state matrix which governs the dynam-ics of the LDS while C is an m  X  n observation matrix. The modern convention is to represent the LDS as graphi-cal model as shown in Figure 2.Thestateofthesystem, x ,evolvesaccordingtoLDSbeginningattime t =0,with value x 0 .Thestandardlearningproblemisasfollows.
Problem 1 (Learning Problem). Given an observ-able time series { y i } N i =1 and assuming that the observed y and the latent x are governed by an LDS, infer A and C . The standard LDS inference problem has been extensively studied in both the machine learning and control theory lit-erature. Several algorithms have been proposed including those based on gradient descent, Expectation Maximization, subspace identification and spectral approaches [ 28, 30, 17, 4]. Several extensions of LDS to include non-linear relation-ships as well as to include stochastic disturbances have been proposed. However, for sleep analysis, the above LDS will su ffi ce. For the sake of completeness, in the Appendix we will describe a simple but e ff ective approach for inferring A and C based on a spectral method [ 4].

The standard approach to detect outliers using an LDS is to use the inferred A and C matrices to compute the latent and observed error variables as: where  X  x and  X  y are estimated using LDS. Then given a thresh-old parameter  X  ,ananomalyisreportedwhenever, e ( t ) &gt;  X  . However, our objective is not to report all anomalies but suppress some known user-defined patterns or even known anomalous pattern. We now formalize the notion of pattern.
Definition 1. A pattern P is a user-defined matrix which operates in the latent space.

In our context, we will design a specific matrix P for a sleep spindle. The matrix P is integrated into the LDS as We are now ready to define the design part of the OSAD problem.

Problem 2 (Design Problem). Given an LDS, a pat-tern P in the latent space, design a residual r ( t ) such that Here S is suitably defined linear transformation on e ( t ). Notice that the residual r ( t )dependsbothonthelatent error $ ( t )andtheobservederror e ( t ). In practice, r ( t )will never be exactly zero when the pattern P is active but will have small absolute values.
In this section we propose a method based on statistical inference and control theory to provide a solution of the OSAD problem. Using the LDS, we first develop a Dynamic Residue Model (DRM). Then we will show how to adjust the DRM parameters in order to design a residual r ( t )which will satisfy the constraints of the problem, i.e. the selected anomalous pattern will be canceled (or projected out) in the generated residual space.
Assume data is generated by an LDS. Any deviation of the state from its expected value can be captured by a struc-tured error model. Intuitively, the discrepancy between the observed error e ( t )andlatenterror  X  ( t )ismodeledbythe same LDS (because of linearity):
The above error model can be used to detect changes oc-curring in the latent space.

We design a feedback loop (as shown in Figure 3)toe ff ect the output of the error model. In particular a function of the residual will be used to manipulate the changes in the error. The design objective will be to map the anomalies generated by the P pattern into the null space of the new residual. The DRM based on this feedback design is developed as follows:
To design the feedback we define two transformation ma-trices W and F for error values to be weighted as: F will be used as the feedback gain matrix and maps the error to the feedback vector u ( t ), and W is the residual weighting matrix that generates the new residual r ( t ). Now feeding back u ( t ) into the LDS (as shown in Figure 2), with u ( t ) , the residual dynamic model will be:
Notice that since the residual is a linear transformation of the error, its rank (suppose r ( t )  X  R p )cannotbelarger than the observation dimension, i.e., p  X  m .

We are now able to define the dynamic of the latent error as: and the residue r ( t )isobtainedas: We therefore have the following dynamic model for the latent error: Notice that the observed residue r ( t )isgovernedbystateer-ror  X  ( t )throughmatrix WC while it evolves in time through A  X  FC .
 To simplify the notation, denote C f = WC and A f = A  X  FC .TheDRMisthendefinedas: The graphical diagram for this error model is shown in Fig-ure 3.
In this section we address the problem of designing the F and W matrix with objective of making the DRM insensitive to anomalies generated by P .Theoverarchingdesignis shown in Figure 4 and is related to the use of control theory for fault diagnosis [ 23, 24, 6]. A typical LDS model will output the observed error e ( t ). However, the OSAD model has a feedback loop which takes W and F matrices as input and return a variable u ( t )whichisfedbackintothemodel. The observed error is also transformed by a W matrix. The F and the W matrices satisfy the constraints which involve the A , C and the P matrices. then calibrated by W to generate a new residual space r ( t ).
Since the model is time-dependent, we follow a standard approach and map the model into the frequency domain using a Z -transform to design the W and F matrices. In the frequency domain, it will be easier to design matrices W and F such that WC ( A  X  FC )=0and WCP =0.

Definition 2. The Z-transform of a discrete-time sequence x ( k ) is the series X ( z ) defined as
Observation 1. Two important (and well known) prop-erties of the Z-transform are linearity and time shifting:
Applying Z-transform Z () to the DRM yields: and: transfer gain between  X  and R : Thus if G  X  would be zero, the residual R ( z )isindependent of the  X  ( z ). In the other word, to make R ( z )independentof  X  ( z ), one must null the space of G  X  ( z ). Then whenever P occurs it is transferred by a zero gain to the residual space. To find the null space G  X  ( z )=0,weexpanditas: The su ffi cient conditions for G  X  ( z )tobenulledare C f 0andeither C f A f =0or A f P =0. Thuswehavethefol-lowing result.

Theorem 1. For a DRM, a su ffi cient condition for G  X  ( z )= 0 is
Now as C f = WC ,for C f P =0itissu ffi cientthat WC be orthogonal to P .Furthermorefor C f A f =0,itissuf-ficient to design a matrix A f such that its left eigenvectors corresponding to the zero eigenvalue are orthogonal to P . Similarly, for A f P =0,itissu ffi cienttodesignamatrix A f ,suchthattherighteigenvectorscorrespondingtothe zero eigenvalues are orthogonal to P .SeeAppendix A.
Now, it design a system which operates in an online fash-ion we proceed as follows. From the definition of residue: Using the Z-transform, the computational form of the resid-ual will be: Since C f A f =0: Replacing this result to the above R ( z ) equation: Applying the inverse Z-transform, the equation will be: This clearly says that the residual can be represented di-rectly in terms of the observations. This property is crucial to make the anomaly detection system operate in near real-time.
In this section we explain the eigenpair assignment prob-lem and its solution which is used for designing the matrix F .RecallfromTheorem1,thatwerequireeither C f A f =0 or A f P =0.

Problem 3. Given a set of scalars {  X  i } and a set of n-vectors { v i } (for i =1 , 2 ,...,n ), find a real matrix A such that the eigenvalues of A o are precisely those of the set of scalars {  X  i } with corresponding eigenvectors the set { v Given the residue model transition matrix A f = A  X  FC , the problem is to find a matrix F such that this matrix has the eigenvalues {  X  i } corresponding to eigenvectors { v Figure 4: The complete diagram of OSAD. Using parameters W and F the residue space r ( t )iscalibratedtocancelthe impact of P  X  ( t ).
 Algorithm 1 Find F such that the set {  X  i ,v i } be the eigen-pairs of A  X  FC 1: Input A,C ,  X  i =0  X  i and v i = P (: ,i ). 2: Output F such that ( A  X  FC ) P = 0 . 3: for i =1: n do 4:  X  i = null 5: Find an element [ v i q i ] #  X   X  i 6: end for 7: F =  X  or: Define q i :=  X  F v i ,then: The implication of the above statement is of great impor-tance: The vectors #
A  X   X  i IC # The matrix F now can be obtained as: where  X + X  stands for pseudoinverse. The whole procedure is summarized in Algorithm 1.
There is an an important constraint that the matrix P must satisfy for the DRM approach to be valid solution of the OSAD problem. As the WCP =0,anecessarycondi-tion is that In the other word, the e ff ective number of independent per-turbations generated by the matrix P is bounded by the e ff ective number of independent measurements governed by the observation matrix C ,see[ 24]. For example, if C is the independent matrix on an LDS where the state vector has dimensionality n ,thentherankofthe P matrix must be less than ( n  X  1).
The OSAD model is predicated on the existence of a P matrix. This matrix can be provided by a domain expert or can sometimes be inferred from data. For example, in the case of sleep spindle, frequency analysis shows that sleep spindles occur in the interval twelve to fourteen Hz. The exact frequency can change from one subject to another. The signature for K-Complexes is more a function of the amplitude of the signal rather than the frequency.
We now show how to construct a P matrix from data. For example, suppose there exists a frequency/peridicity T = f  X  1 in the EEG time series or: Replace this in linear dynamics: Applying z-transform: Using Tailor expansion we expand z T around z =1: where  X  =0 . 5 T ( T  X  3),  X  =0 . 5 T ( T  X  1) and  X  =  X  T ( T  X  2). An approximation by this expansion will be: Returning to the time-domain, we obtain
To summarize, the solution of the OSAD problem requires the availability of the following matrices: We will now give a concrete example. Assume we have an LDS system given as Assume have identified the A and C matrices as Now, to form the OSAD model, we have to identify W and F such that: 1. W is in the null space of CP and 2. A  X  FC has its left eigenvectors (corresponding to the Since C is the identity matrix, an example of W is Similarly, an example of F matrix is As mentioned, the residual matrix is given by
We now report on the experiments that have been car-ried out to test the e ff ective of the proposed OSAD solution on sleep data. Our particular focus will be determining if OSAD can recognize sleep spindle and K-Complex anoma-lies and selectively raise an alert for non-Spindle anomalies.
Our data set consists of EEG time series from four health controls (age 25-36) as described in [ 12]. Recordings were made with an Alice-4 system (Respironics, Murraysville PA, USA) at the Woolcock Institute of Medical Research, at Syd-ney University, using 6 EEG channels with a sampling rate of 200 Hz, and electrodes positioned according to the Interna-tional 10-20 system, see Figure 5.Anotchfilterat50Hz(as provided by the Alice-4 system) was used to remove mains voltage interference. No other hardware filters were used.
Sleep spindles were labeled for the Cz electrode during sleep stages 2 X 4 using a previously developed automated de-tection routine [ 1]. In summary, the spindles are detected by applying an 11 X 16 Hz bandpass filter to the EEG time series, then squaring and downsampling to 10 Hz. This pro-cessed signal is large when sleep spindles are present, and a threshold for spindle detection is determined based on this signal. In this limited data set, K-complexes were identified visually. Our first task is to learn the A and C matrices from the LDS for each subject. Others have reported, and our exper-iments confirm, that EEG of each subject tends to di ff erent and separate models need to learnt per subject. For each subject we took a sample of size 2000 (10 seconds) of EEG Figure 5: The position of scalp electrodes for EEG experi-ment follows the International 10-20 system [20 , 5]. Figure 6: The RMSE error obtained from both methods are comparable. Notice the RMSE increases as the rank of LDS is reduced. time series which did not contain either sleep spindle or K-Complex. We then formed a 2000  X  6datamatrix, O .The columns of the O matrix are time series associated with the six channels of EEG. We used both subspace and spectral methods to infer the matrices A and C .Boththesemethods are based on SVD decomposition of the O matrix and re-quire as input the rank required of the inferred matrices. We evaluated the inferred matrices using RMSE and the results are shown in Figure 6a and Figure 6b.Boththesubspace and spectral methods have similar performance and RMSE goes up significantly when the rank falls below five. We se-lected a rank six matrix (maximum possible rank) for both A and C .Intermsofrunningtime,thetwomethodsare comparable as we have to carry out an SVD of a relatively small 6  X  6matrix.
For each of the four subjects, statistics of the labeled sleep spindles and K-Complexes and those detected by the LDS are shown in Table 2.ForLDSdetection,weusedathresh-old derived from CUSUM which automatically adjusts for mean and standard deviation of the observed residual time series e ( t ). To specify a CUSUM threshold we applied the alpha and beta approach in [ 18]andwesettheprobabili-ties of a false positive and a false negative to 10  X  4 and the change detection parameter to 1 sigma, in all subjects. Table 2: Summary statistics of results. LDS is quite accu-rate but tends to over-predict the number of anomalies. Table 3: Summary statistics for spindles. LDS has higher precision than recall and total length of predicted interval is higher than the length of labeled intervals.

In all four subjects, the LDS residual slightly under pre-dicts the number of spindles and K-Complexes. Since each labeled and predicted SS and K-Complex spans a time-interval, we have modified the definitions of precision and recall to account for the intervals. For a given subject, let { [ a be the intervals of the labeled anomalies (spindles or K-and
Here, | [ a i ,b i ] | ,isthenumberofpointsinthetimeinterval [ a ,b i ]. With these definitions in place, Table 3 and Table 4 show the precision and recall SS and K-Complex across alls the subjects. In general both precision and recall are high across subjects, but precision is significantly more higher than recall. For SS, the recall varies more than precision ranging for 71.24% to 97.18%. Also notice that the length of detection of both SS and K-Complex is higher compared to their labeled lengths. We now investigate the transfer properties of the inferred LDS across subjects. That is, we learn the A an C matrices on one subject and evaluate it against an another. We just focus on the anomaly. The recall and precision results are shown in Table 5 and Table 6 respectively. The diag-onal of the table corresponds to the results in Table 3 and Table 4.Itisclearthatthereisasubstantialreductionin accuracy and that indeed the EEG of subjects varies sub-stantially. We have also computed the  X  X verage X  A and C Table 4: Summary statistics for K-Complex. Both precision and recall are high. Total length of predicted interval is higher than labeled intervals.
 Table 5: Recall across subjects. A substantial reduction in accuracy when model of one subject is evaluated against the EEG of another.
 Table 6: Precision across the subjects. Again, a substan-tial reduction in accuracy when model of one subjected is evaluated against another.
 Table 7: Recall and Precision on each subject evaluated against an averaged model. Again, a substantial reduction in accuracy compared to individual models.
 matrix and evaluated against all the four subjects. The re-sults are shown in Table 7. While there is an improvement compared to results in Table 5 and Table 6,theabsoluteper-formance is still quite low compared to the situation where the learning was customized per individual subject.
In this section we evaluate whether the new residual r ( t ) satisfies the design criterion. Recall, r ( t )wasdesignedto suppress the signal whenever a sleep spindle (SS) appears and behave like the observed error e ( t )inotherwise. Fig-when t is in (and not in) the predicted SS interval [ a ! some j .Itisclearthatthedistributionwhen t is in a pre-dicted SS interval is towards the right compared to when it is not in the interval. This is because in an SS interval, r ( t ) will have a small absolute value (by design). In a non-SS in-Figure 7: Comparison of the distribution of the norm of r ( t )  X  e ( t )forSSandnon-SSintervals.Inallfoursubjects the designed residual suppresses spindles as designed as the norm is higher for SS intervals.
 Table 8: Delay statistics. The lag between appearance and prediction of SS is, on average, a fraction of a second. This behavior is observed across subjects suggesting that in all cases that r ( t ) is behaving as designed.
OSAD detects anomalies in near real time. We now dis-cuss the lag between the appearance of a SS and before it is reported by the LDS. Figure 8 presents the delay distri-butions for subject 1 and subject 4 who experienced 164 and 132 labeled sleep spindles, respectively. In general, the predicted SS interval are longer and contain the actual inter-vals. This is confirmed in Figure 9 which shows one specific example of the location of the labeled sleep spindle and the predicted interval. In this case (which is typical), the pre-diction of SS begins before and ends later than the labeled spindle. Table 8 shows the results of the mean delay be-tween matched intervals. Thus a mean of ( a i ,a # i ) equal to -0.0678 implies that on average, there was a delay of 1/200 second before LDS reported an anomaly. On the other hand for subject 2 there the SS was, on average, reported before it showed up in the labeled sequence. As noted in [ 12], this is consistent with the observation (and confirmed by double-blind scoring) that the labeling of SS is more conservative i.e., SS are labeled for a shorter duration than what they should be. Figure 8: OSAD provides near real time detection. The delay between the actual appearance of a spindle and the predicted appearance is a fraction of a second. Similarly the lag between when the actual spindle disappears and it is reported to disappear is very small too. The x-axis is in seconds. Figure 9: Top: Cz data and a typical sleep spindle labeled. Bottom: Residual and detected sleep spindle. In general the predicted spindle interval is longer than the labeled interval. The predicted interval tends to include the labeled interval, i.e., it begins earlier and finishes later. The EEG shows that the labeled intervals are actually quite conservative.
Automatic detection of sleep spindles is now an important topic in biomedical research. Di ff erent techniques including FFTs, wavelet analysis and autoregressive time series mod-eling have been applied for sleep spindle detection [ 25, 11, 14]. Attempts to integrate SVM to detect sleep spindles have also been explored [ 2]. There seems to be a large variability between sleep EEG across subjects. In our experiments we have also observed this phenomenon. This combined with the large amount of EEG noise has resulted in low level of agreement on the exact profile of sleep spindle [ 21].
The use of linear dynamical systems (LDS) to model time series is ubiquitous both in computer science [ 27]andcontrol theory [ 30, 17, 19, 8, 16]. Expressing LDS in the language of graphical models and connections with HMM have been extensively examined in machine learning. The use of LDS for anomaly detection has also been investigated in network anomaly detection, among other areas [ 29]. The use of sub-space identification methods for inferring the parameters of LDS have been discussed by Overschee [ 30]. Subspace meth-ods estimate LDS parameters through a spectral decompo-sition of a matrix of observations to yield an estimate of the underlying state space. Subspace methods have low compu-tational cost, are robust to perturbations and are relatively easy to implement. The recently introduced spectral learn-ing methods are variations of the subspace method [ 4, 13]
The use of eigenstructure assignment to alter the resid-ual of an LDS has been investigated in the control theory literature especially in the context of fault diagnosis [ 3].Our approach closely follows the work Patton et. al. [22 ]who have used eigenstructure assignment for altering the LDS model using feedback. Other variations of LDS and fault diagnosis are discussed in [7, 23, 6, 24].
In this paper we have introduced a new problem, the On-line Selective Anomaly Detection (OSAD) to capture a spe-cific scenario in sleep research. Scientists working on sleep EEG data required an alert system, which trigger alerts on selected anomalies. For example, sleep stage two is char-acterized by two known anomalies: sleep spindle and K-complex. The requirement was to design a system which detected both anomalies but only generated an alert when a non sleep spindle anomaly appeared. We combined methods from data mining, machine learning and control theory to design such a system. Experiments on real data set demon-strate that our approach is accurate and produces the re-quired results and is potentially applicable to many other situations. We also note that data from sleep EEG provides afertilegroundtoapplyexistingdataminingmethodologies and potentially design new computational problems and al-gorithms.
This work is partially supported by NICTA 1 .NICTAis funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program. Sanjay Chawla would also like to acknowledge CRC for Alertness, Safety and Pro-ductivity for access to the data set. [1] R. G. Abeysuriya, C. J. Rennie, P. A. Robinson, and [2] N. Ac X r and C. G  X  uzeli  X  s. Automatic recognition of sleep [3] A. Andry, E. Shapiro, and J. C. Chung.
 [4] B. Boots, S. Siddiqi, and G. Gordon. Closing the [5] G. Buzsaki. Rhythms of the Brain .OxfordUniversity http://nicta.com.au/ [6] C. Chen and R. Patton. Robust Model-Based Fault [7] J. Chen and R. Patton. Optimal filtering and robust [8] J. H. Cochrane. Asset Pricing .PrincetonUniversity [9] T. T. Dang-Vu, S. M. McKinney, O. M. Buxton, J. M. [10] S. Diekelmann and J. Born. The memory function of [11] A. L.  X  DRozario, J. W. Kim, K. K. Wong, D. J. [12] F. Duman, A. Erdamar, O. Erogul, Z. Telatar, and [13] D. Hsu, S. M. Kakade, and T. Zhang. A spectral [14] E. Huupponen, G. G  X  omez-Herrero, A. Saastamoinen, [15] C. Iber, S. Ancoli-Israel, A. Chesson, and S. F. Quan. [16] G. Kitagawa. Non-gaussian state space modeling of [17] L. Ljung. System Identification . John Wiley &amp; Sons, [18] D. Montgomery. Introduction to Statistical Quality [19] O. Nelles. Nonlinear System Identification: From [20] E. Niedermeyer and F. L. da Silva.
 [21] A. Nonclercq, C. Urbain, D. Verheulpen, [22] R. Patton and J. Chen. Robust fault detection using [23] R. Patton and J. Chen. Observer-based fault detection [24] R. J. Patton and J. Chen. On eigenstructure [25] L. B. Ray, S. M. Fogel, C. T. Smith, and K. R. Peters. [26] A. Rechtscha ff en and A. Kales. Amanualof [27] S. Roweis and Z. Ghahramani. A unifying review of [28] R. H. Shumway and D. S. Sto ff er. An approach to [29] A. Soule, K. Salamatian, and N. Taft. Combining [30] P. van Overschee and L. de Moor. Subspace
Theorem 1. For a DRM, a su ffi cient condition for G  X  ( z ) to be zero, is
Proof: Let the set {  X  i =0 ,v i } ,for i =1: n ,betheleft eigenvectors and corresponding eigenvalues of A f , i.e.
If one chooses v 1 as the rows of matrix [ WC ], then:
The matrix A f = A  X  FC ,soitissu ffi cienttochose F so that the set {  X  i =0 ,v i =[ CW ] # } to be assigned as left eigenpairs of ( A  X  FC ).

In the other side, suppose If the columns of P are the right eigenvectors of A f corresponding to zero-values eigen-vectors, then
So it is su ffi cient to chose the matrix F so that the set {  X  i =0 ,v i = P } to be assigned as right eigenpairs of ( A  X  FC ).

To keep the paper self-contained we give a brief descrip-tion to sleep segmentation. Sleep researchers often classify sleep into one of several sleep stages that provide a qualita-tive overview of subject responsiveness and sleep physiology at di ff erent points throughout the night [ 15, 26]. Broadly, sleep can be divided into REM sleep during which dream-ing occurs, and non-REM sleep, which is further divided into sleep stages S1, S2, S3 and S4 that approximately cor-respond to how deeply asleep the subject is. A subject X  X  arousal state is classified on the basis of some or all of the measures in the polysomnogram, and EEG plays a key role in this process.

In wake sate with eyes closed, the EEG signal is domi-nated by the alpha rhythm, an oscillation at approximately 8 X 12 Hz depending on the individual, which is superimposed on a background signal whose power approximately scales as 1 /f . Sleep typically begins with a short period of S1 sleep, which is a transition stage corresponding to very light sleep, during which time the alpha oscillation disappears. Sleep then deepens into stage 2, which is accompanied by an in-crease in low frequency activity and the appearance of two transient phenomena in the EEG time series, sleep spindles and K-complexes. Sleep spindles originate in the thalamus, and are believed to play a role in memory consolidation and learning. The K-complex is a short, high amplitude voltage spike that occurs spontaneously during sleep stages 2, 3 and 4, but can also be evoked by sensory stimulation such as an audio tone. The role played by K-complexes is astillunderinvestigation,butrecentworksuggeststhatK-complexes help to suppress arousal due to sensory stimulus during sleep. Sleep stages 3 and 4 correspond to deep sleep, where the EEG is dominated by very low frequency oscil-lations ( &lt; 3Hz), and the low frequency part of the power spectrum approximately scales as 1 /f 2 or even 1 /f 3 .Sleep spindles and K-complexes may be present, although they typically occur less frequently than in S2 sleep.
Stage REM sleep is typically accompanied by EEG fea-tures similar to S1, but with the addition of eye movement, changes in muscle tone, and the presence of vertex waves, which are similar to K-complexes but are smaller in ampli-tude and shorter in duration. Normal sleep cycles between non-REM and REM sleep occur several times over the course of the night.
