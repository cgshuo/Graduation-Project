 Finding the linear least squares fit to data is a well-known pr oblem, with applications in almost ev-ery field of science. When there are no restrictions on the var iables, the problem has a closed form solution. In many cases, a-priori knowledge on the values of the variables is available. One example is the existence of priors, which leads to Bayesian estimato rs. Another example of great interest in many applications is when the variables are constrained t o a discrete finite set. This problem has many diverse applications such as decoding of multi-inp ut-multi-output (MIMO) digital com-munication systems, GPS system ambiguity resolution [15] a nd many lattice problems in computer sum problems which have applications in cryptography [11]. In contrast to the continuous linear least squares problem, this problem is known to be NP hard.
 This paper concentrates on the MIMO application. It should b e noted, however, that the proposed method is general and can be applied to any integer linear lea st-square problem. A multiple-input-multiple-output (MIMO) is a communication system with n transmit antennas and m receive anten-nas. The tap gain from transmit antenna i to receive antenna j is denoted by H the MIMO channel a vector x = ( x A according to the data to be transmitted, so that x  X  X  n . A standard example of a finite set A in MIMO communication is A = { X  1 , 1 } or more generally A = { X  1 ,  X  3 ,...,  X  (2 k +1) } . The received vector y is given by: statistically independent Gaussians with a known variance  X  2 I . The m  X  n matrix H is assumed to be known. (In the MIMO application we further assume that H comprises iid elements drawn from a normal distribution of unit variance.) The MIMO detec tion problem consists of finding the unknown transmitted vector x given H and y . The task, therefore, boils down to solving a linear system in which the unknowns are constrained to a discrete fin ite set. Since the noise  X  is assumed to be additive Gaussian, the optimal maximum likelihood (ML ) solution is: However, going over all the |A| n vectors is unfeasible when either n or |A| are large. A simple sub-optimal solution is based on a linear decision t hat ignores the finite set constraint: and then, neglecting the correlation between the symbols, fi nding the closest point in A for each symbol independently: This scheme performs poorly due to its inability to handle il l-conditioned realizations of the matrix H . Somewhat better performance can be obtained by using a mini mum mean square error (MMSE) Bayesian estimation on the continuous linear system. Let e be the variance of a uniform distribution over the members of A . We can partially incorporate the information that x  X  X  n by using the prior Gaussian distribution x  X  X  (0 ,eI ) . The MMSE estimation becomes: and then the finite-set solution is obtained by finding the clo sest lattice point in each component independently. A vast improvement over the linear approach es described above can be achieved by using sequential decoding: This algorithm, known as MMSE-SIC [5], has the best performa nce for this family of linear-based algorithms but the price is higher complexity. These linear type algorithms can also easily provide between the detection performance of the MMSE-SIC algorith m and the performance of the optimal ML detector.
 Many alternative structures have been proposed to approach ML detection performance. For exam-using the sequential Monte Carlo framework [3] and methods b ased on semidefinite relaxation [17] have been implemented. Although the detection schemes list ed above reduce computational com-plexity compared to the exhaustive search of ML solution, sp here decoding is still exponential in the average case [9] and the semidefinite relaxation is a high-de gree polynomial. Thus, there is still a need for low complexity detection algorithms that can achie ve good performance.
 This study attempts to solve the integer least-squares prob lem using the Belief Propagation (BP) paradigm. It is well-known (see e.g. [14]) that a straightfo rward implementation of the BP algorithm to the MIMO detection problem yields very poor results since there are a large number of short cycles in the underlying factor graph. In this study we intro duce a novel approach to utilize the BP paradigm for MIMO detection. The proposed variant of the BP a lgorithm is both computationally efficient and achieves near optimal results. Given the constrained linear system y = H x +  X  , and a uniform prior distribution on x , the posterior probability function of the discrete random vector x given y is: The notation  X  stands for equality up to a normalization constant. Observi ng that k H x  X  y k 2 is single-variable potentials: such that where h pairs, we obtain a Markov Random Field (MRF) representation [18]. In the MIMO application the (known) matrix H is randomly selected and therefore, the MRF graph is usually a completely connected graph.
 In a loop-free MRF graph the max-product variant of the BP alg orithm always converges to the most likely configuration (which corresponds to ML decoding in ou r case). For loop-free graphs, BP is essentially a distributed variant of dynamic programming. The BP message update equations only involve passing messages between neighboring nodes. Compu tationally, it is thus straightforward to apply the same local message updates in graphs with cycles . In most such models, however, this loopy BP algorithm will not compute exact marginal dist ributions; hence, there is almost no theoretical justification for applying the BP algorithm. (O ne exception is that, for Gaussian graphs, if BP converges, then the means are correct [16]). However, t he BP algorithm applied to loopy graphs has been found to have outstanding empirical success in many applications, e.g., in decoding LDPC codes [6]. The performance of BP in this application may be attributed to the sparsity of the graphs. The cycles in the graph are long, hence the graph have tree-like properties, so that messages are approximately independent and inference may be perform ed as though the graph was loop-free. The BP algorithm has also been used successfully in image pro cessing and computer vision (e.g. [4]) where the image is represented using a grid-structured MRF that is based on local connections between neighboring nodes.
 However, when the graph is not sparse, and is not based on loca l grid connections, loopy BP almost always fails to converge. Unlike the sparse graphs of LDPC co des, or grid graphs in computer vision applications, the MRF graphs of MIMO channels are completely connected graphs and therefore the associated detection performance is poor. This has prev ented the BP from being an asset for the MIMO problem. Fig. 1 shows an example of a MIMO real-value d system based on an 8  X  8 matrix and A = { X  1 , 1 } (see the experiment section for a detailed description of th e simulation set-up). As can be seen in Fig. 1, the BP decoder based on the MR F representation (7) has very poor results. Standard techniques to stabilize the BP iteration s such as damping the message updates do not help here. Even applying more advanced versions of BP (e. g. Generalized BP and Expectation Propagation) to inference problems on complete MRF graphs y ields poor results [12]. The problem here is not in the optimization method but in the cost functio n that needs to be modified yield a good approximate solution.
 There have been several recent attempts to apply BP to the MIM O detection problem with good results (e.g. [8, 10]). However in the methods proposed in [8 ] and [10] the factorization of the probability function is done in such a way that each factor co rresponds to a single linear equation. This leads to a partition of the probability function into fa ctors each of which is a function of all the unknown variables. This leads to exponential computati onal complexity in computing the BP messages. Shental et. al [14] analyzed the case where the mat rix H is relatively sparse (and has perform well. As an alternative method they proposed the gen eralized belief propagation (GBP) algorithm that does work well on the sparse matrix if the algo rithm regions are carefully chosen. There are situations where the sparsity assumption makes se nse (e.g. 2D intersymbol interference (ISI) channels). However, in the MIMO channel model we assum e that the channel matrix elements are iid and Gaussian; hence we cannot assume that the channel matrix H is sparse. Our approach is based on an approximation of the exact probab ility function: gorithm is optimal on loop-free factor graphs (trees) a reas onable approach is finding an optimal tree approximation of the exact distribution (9). Chow and L iu [2] proposed a method to find a tree approximation of a given distribution that has the mini mum Kullback-Leibler distance to the actual distribution. They showed that the optimal tree can b e learned efficiently via a maximum spanning tree whose edge weights correspond to the mutual in formation between the two variables corresponding to the edges endpoints. The problem is that th e Chow-Liu algorithm is based on the (2-dimensional) marginal distributions. However, finding the marginal distribution of the probability function (9) is, unfortunately, NP hard and it is (equivalen t to) our final target.
 To overcome this obstacle, our approach is based on applying the Chow-Liu algorithm on the distri-bution corresponding to the unconstrained linear system. T his distribution is Gaussian and therefore it is straightforward in this case to compute the (2-dimensi onal) marginal distributions. Given the Gaussian tree approximation, the next step of our approach i s to apply the finite-set constraint and be efficiently globally maximized using the BP algorithm. To motivate this approach we first apply a simplified version to derive the linear solution (4) descri bed in Section 2.
 It can be easily verified that p ( x | y ) (9) can be written as: where f ( x ; z,C ) is a Gaussian density with mean z and covariance matrix C (to simplify notation we ignore hereafter the constant coefficient of the Gaussian densities). Now, instead of marginalizing marginals of the Gaussian density f ( x ; z,C ) : From the Gaussian approximation (11) we can extract a discre te approximation: Input: A constrained linear LS problem: H x +  X  = y , a noise level  X  2 and a finite symbol set A .
Goal: Find (approx. to) arg min
Algorithm: Taking the most likely symbol we obtain the sub-optimal line ar solution (4).
 Motivated by the simple product-of-marginals approximati on described above, we suggest approx-f ( x ; z,C ) . Although the Chow-Liu algorithm was originally stated for discrete distributions, one can easily verify that it also applies for the Gaussian case. Let be the mutual information of x the correlation coefficient between x of free Gaussian distribution on x applying a monotonic function on the graph weights does not c hange the topology of the optimal tree. Hence to find the optimal tree we can use the weights  X  2 tree, therefore is one that maximizes the sum of the square co rrelation coefficients between adjacent nodes. following approximation: to find its most likely configuration. An optimal BP schedule r equires passing a message once for each direction of each edge. The BP messages are first sent fro m leaf variables to the root and then back to the leaves. We demonstrate empirically in the experi ment section that the optimal solution of  X  p ( x | y ) is indeed nearly optimal for p ( x | y ) .
 a similar way we can consider a Bayesian version of the propos ed Gaussian tree approximation. We can partially incorporate the information that x  X  X  n by using the prior Gaussian distribution such that E ( x | y ) = ( H  X  H +  X  2 finite-set constraint. We show in Section 4 that the Bayesian version indeed yields better results. To summarize, our solution to the constrained least squares problem is based on applying BP on a Gaussian tree approximation of the Bayesian version of the continuous least-square case. We dub this method  X  X he Gaussian-Tree-Approximation (GTA) Al gorithm X . The GTA algorithm is summarized in Fig. 3. We next compute the complexity of the GT A algorithm. The complexity of computing the covariance matrix ( H  X  H +  X  2 algorithm (based on Prim X  X  algorithm for finding the minimum spanning tree) is O ( n 2 ) and the complexity of the BP algorithm is O ( |A| 2 n ) . In this section we provide simulation results for the GTA alg orithm over various MIMO systems. We assume a frame length of 100, i.e. the channel matrix H is constant for 100 channel uses. The channel matrix comprised iid elements drawn from a zero-mean normal distribution of unit performance of the proposed algorithm is shown as a function of the variance of the additive noise  X  number of variables,  X  2 is the variance of the Gaussian additive noise, and e is the variance of the uniform distribution over the discrete set A ).
 Fig. 3 shows the symbol error rate (SER) versus SNR for a 10  X  10 , |A| = 8 , MIMO system and for a 20  X  20 , |A| = 4 , MIMO system. Note that the algorithm was applied in Fig. 3 to a real world practical application (MIMO communication) using real wor ld parameters. Unlike other areas (e.g computer vision, bioinformatics) here the real world perfo rmance analysis is based on extensive simulations of the communication channel. Note that a 20  X  20 fully connected MRF is not a small problem and unlike the Potts model that is defined on a grid MRF , the BP and it variants do not work here. The performance of the GTA method was compared to t he MMSE and the MMSE-SIC algorithms (see Section 2). The GTA algorithm differs fr om these algorithms in two ways. The first is a Markovian approximation of f ( x ; z,C ) instead of a product of independent densities. The second aspect is utilizing the optimal tree. To clarify t he contribution of each component we modified the GTA algorithm by replaced the Chow-Liu optimal t ree by the tree 1  X  2  X  3 ,...,  X  n . We call this method the  X  X ine-Tree X . As can be seen from Fig. 3 , using the optimal tree is crucial to obtain improved results. Fig. 3b also shows results of the non-Bayesian variant of the GTA algorithm. As can be seen, the Bayesian version yields bette r results. In Fig. 3a the two versions yield the same results. It can be seen that the performance of the GTA algorithm is significantly better than the MMSE-SIC (and its computational complexity is much smaller). Figure 4: Comparative results of MMSE, MMSE-SIC and the GTA a pproximation followed by the sum-product and max-product variants of the BP algorithm. T he alphabet size is |A| = 8 and the results are shown as a function of the matrix size n  X  n .
 Fig. 4 depicts comparative performance results as a functio n of n , the size of the linear system. The alphabet size in all the experiments was |A| = 8 and as in Fig. 3 each experiment was repeated 10 SIC algorithms (see Section 2). In Fig. 4a the noise variance was set to  X  2 = 2 . 5 and in Fig. 4b to  X  2 = 0 . 25 . In all cases the GTA was found to be better than the MMSE-SIC. The GTA algorithm is based on an optimal Gaussian tree approximation followed by a BP algorithm. There are two variants of the BP, namely the max-product (MP) and the sum-p roduct (SP). Since the performance is measured in symbol error-rate and not frame error-rate th e SP should yield improved results. Note that if the exact distribution was loop-free then SP would ob viously be the optimal method when the error is measured in number of symbols. However, since th e BP is applied to an approximated distribution the superiority of the SP is not straightforwa rd. When the noise level is relatively high the sum-product version is better than the max-product. Whe n the noise level is lower there is no significant difference between the two BP variants. Note tha t from an algorithmic point of view, the MP unlike the SP, can be easily computed in the log domain. Solving integer linear least squares problems is an importa nt issue in many fields. We proposed a novel technique based on the principle of a tree approximati on of the Gaussian distribution that cor-responds to the continuous linear problem. The proposed met hod improved performance compared to all other polynomial algorithms for solving the problem a s demonstrated in simulations. As far as we know this is the first successful attempt to apply the BP p aradigm to completely connected MRF. A main concept in the GTA model is the interplay between d iscrete and Gaussian models. Such hybrid ideas can be considered also for discrete infere nce problems other than least-squares. One example is the work of Opper and Winther who applied an ite rative algorithm using a model which is seen as discrete and Gaussian in turn to address Isin g model problems [13]. Although the focus of this paper is on an approach based on tree approximat ion, more complicated approxima-tions such as multi-parent trees have potential to improve p erformance and can potentially provide a smooth performance-complexity trade-off. Although the pr oposed method yields improved results, the tree approximation we applied nay not be the best one (find ing the best tree for the integer con-approximation for the constrained linear least squares pro blem.

