 ORIGINAL PAPER F. C. Ribas  X  L. S. Oliveira  X  A. S. Britto Jr.  X  R. Sabourin Abstract Inthiswork,algorithmsforsegmentinghandwrit-ten digits based on different concepts are compared by eval-uating them under the same conditions of implementation. A robust experimental protocol based on a large synthetic database is used to assess each algorithm in terms of cor-rect segmentation and computational time. Results on a real database are also presented. In addition to the overall per-formance of each algorithm, we show the performance for different types of connections, which provides an interesting categorization of each algorithm. Another contribution of this work concerns the complementarity of the algorithms. We have observed that each method is able to segment sam-ples that cannot be segmented by any other method, and do so independently of their individual performance. Based on this observation, we conclude that combining different segmenta-tion algorithms may be an appropriate strategy for improving the correct segmentation rate. 1 Introduction In spite of the efforts made over the past two decades, the recognition of handwritten digit strings is still an open prob-lem. One of the main bottlenecks in this kind of system is the segmentation module, which reads a string of characters (usually digits, but sometimes non-digits can appear, in bank check processing systems, for example) and segments them into isolated characters. The main problem is a lack of con-text, that is, usually we do not know the number of characters in the string and so the optimal boundary between them is unknown.

Segmentation algorithms can be divided into two classes: segmentation X  X ecognition, and recognition-based [ 2 ]. In the former, the segmentation module provides a single sequence hypothesis where each sub-sequence should contain an iso-lated character, which is submitted to the recognizer. In the latter, the algorithm yields a list of segmentation hypotheses and then assesses each of them through the recognition pro-cess. The literature shows that this kind of approach produces good results, but is computationally expensive, since all the hypotheses generated must be evaluated. Moreover, the rec-ognition module has to discriminate different patterns, such as fragments, isolated characters, and connected characters. In this strategy, segmentation can be explicit or implicit. In the explicit methods, segmentation is performed prior to rec-ognition, which producing candidate characters for the rec-ognizer. In contrast, in the implicit methods, segmentation is embedded in the recognition process and is performed simul-taneously with recognition (Fig. 1 ).

In recent years, several algorithms have been proposed for explicit segmentation. They normally take into consider-ation a set of heuristics and information of the foreground these, [ 3 , 15 ] in order to generate potential segmentation cuts. The main drawbacks of most of these algorithms are the large number of cuts, which must be evaluated by the recognition algorithm, and the number of heuristics that must be set. A way to reduce the number of segmentation cuts has been proposed by Vellasques et al. [ 22 ].
In order to avoid explicit segmentation and the complexity of setting several heuristics, some authors have tried implicit segmentation to recognize strings of digits [ 1 , 17 ]. The litera-ture has shown that explicit segmentation has achieved better results, but implicit segmentation offers very interesting per-spectives. The main drawback of implicit segmentation is its high sensitivity to slanted images, which makes the use of a pre-processing step obligatory, in order to correct the slant. Figure 2 depicts the various methods for the segmentation and recognition of digit strings.

In reviewing the literature, we find various algorithms for handwritten digit segmentation. A direct comparison, though, is not a trivial task. On the contrary, it may not even be feasible. The main obstacle in this case is the database used during the experiments, which can range from specific forms, to the bank checks of different countries (Canada, France, Brazil, USA, etc.), to subsets of publicly available databases such as NIST-SD19, CEDAR, and so on. Moreover, the num-ber of data used can range from a few hundred to thousands. Also, the computational cost, which can be expressed by the number of segmentation hypotheses produced by the algo-rithm, is very often neglected. In some cases, especially in real-time applications, this is a very important issue that can determine the success or failure of an handwriting recogni-tion system.

In this work, we compare various explicit segmentation algorithms. In order to avoid implementing a huge number of algorithms, we selected those we deemed the most different, in terms of the features and ideas used to produce the segmen-tation cuts. We then assess them for performance, number of segmentation hypotheses produced, and processing time.
Regarding performance, we are interested not only in the global performance, but also the performance of each algo-rithm on the different types and locations of connections. We believe that this categorization will be a useful contri-bution to the development of more intelligent segmentation algorithms. For example, if we know a priori the type of con-nection we are dealing with, we can choose the most suitable segmentation algorithm. To make this kind of investigation possible, we created a database of 79,966 images of touching pairs, and manually labeled them with respect to the type and location of the connection. These images were extracted from the synthetic database proposed in [ 14 ], and they represent realistic scenarios of connected handwritten digits where cur-sive writing is usually involved. To demonstrate the usability of the synthetic data for research purposes, we applied the segmentation algorithms on a real database, composed of 2,369 images of connected pairs extracted from NIST SD19. We show that the results on both real and synthetic data are very similar.

The second aspect we investigate here concerns compu-tational cost. Very often, promising results are reported in the literature, but important details, such as the number of segmentation cuts produced, the number of heuristics, and the amount and complexity of the features used to yield the cuts, are omitted. Besides this comparative study, we also show that the use of different features provide a high degree of complementarity which can be used to build more reliable segmentation systems. The experimental results show that all the algorithms combined can produce a correct segmentation rate of 99.57% considering the ideal case based on an oracle.
This paper is structured as follows. Section 2 surveys sev-eral different segmentation algorithms reported in the litera-ture. Section 3 presents the database in which the algorithms were assessed. Section 4 shows the assessment methodology we have applied. Section 5 reports all the experimental results and discusses them. Finally, Sect. 6 concludes this work. 2 Segmentation algorithms In this section, we review several segmentation algorithms proposed in the literature in the last few years. We show how the algorithms fit into the taxonomy depicted in Fig. 2 and report the number of images used for testing and their accu-racy. More aspects of the algorithms are reported at the end of this section in Table 1 . We believe they provide a good coverage of the main underlying algorithmic approaches.
Fujisawa et al. [ 9 ] propose a recognition-based algorithm that detects all the connected components (CC) of the image and classifies each of them as an isolated digit or into a string of digits. This classification is based on the horizontal length of the CC. In other words, if the horizontal length of the CC is greater than a threshold T , then it is considered as a string of digits (  X  2). To segment touching digits, the algo-rithm first splits the contour information into upper and lower contours. Then it computes an approximate measure of verti-cal width and assigns potential segmentation points to those locations where this measure exceeds a given threshold h t This algorithm treats images with touching loops differently, such as  X 0 X 0 X ,  X 8 X 8 X , and  X 0 X 9. X  It divides the inner loops into two groups (left and right) and computes the distance between them. If this distance is greater than a threshold D , the algorithm produces a segmentation cut.

All segmentation cuts are produced using line segments connecting the segmentation points. Thereafter, all segmen-tation points are used to build a segmentation graph. The best segmentation hypothesis is the shortest path of the graph, which is computed using some thresholds on the size of the CCs. The authors have tested their algorithm on a proprietary dataset composed of 46 most frequent touching pairs. Twenty samples per class were considered summing up 920 images. Pairs of digits with touching multiple times were not used. The authors reported a correct segmentation rate of 95%.
The method proposed by Shi and Govindaraju [ 19 ] con-sists of segmentation followed by recognition, based on the observation that touching points and ligatures between two digits reveal that the chaincode contour makes significant right turns at each point of touching. The segmentation cuts are then defined by the most significant right turn points, along with their opposite contour point. The method assumes that the touching pair is free of slant. The final segmentation point is then determined using a vertical histogram and a set of heuristics. This method was evaluated on a database of 1,966 images of pairs of digits from the CEDAR database. The authors reported a correct segmentation rate of 78%.
Fenrich and Krishnamoorthy [ 8 ] used a very simple rec-ognition-based algorithm based on two primitives, namely, vertical histogram projection and contour information (peaks and valleys). These primitives inspired other authors [ 11 , 12 , 15 , 20 ]. The algorithm first attempts to segment the string using vertical histogram projection. The column with the minimal value becomes a candidate for a vertical split through the component. If the minimal value is larger than a stroke width threshold or the candidate cut crosses two or more vertical runs, the cut is aborted. If the histogram produces no segmentation cuts, then the second part of the algorithm uses upper and lower contours of the components to define the segmentation cuts. If a peak of the lower con-tour and a valley of the upper contour can be connected with a line segment that satisfies slope thresholds, then a piece-wise linear split is made. If they cannot be connected, then a straight line is used to produce the segmentation cut. The authors reported a correct segmentation rate of 94.9% on 450 images of ZIP Codes.

An alternative approach to segmenting touching digits has been presented by Chen and Wang in [ 3 ]. The algorithm they describe also uses a segmentation/recognition approach, theirs combining background and foreground analysis to segment handwritten numeral strings that touch single or multiple times. The foreground and background regions on the image of connected numeral strings are first thinned, and the feature points on foreground and background skeletons are extracted. Several possible segmentation paths are then constructed and ligatures are removed. Finally, the parame-ters of the geometric properties of every possible segmenta-tion path are determined, and these parameters are analyzed by a mixture of Gaussian probability functions to decide on the best segmentation path or rejection of a path. Similar approaches can be found in [ 4 , 13 ]. The authors used 4,178 images from the NIST SD19 database and another 322 pro-prietary images. The main drawback of this kind of approach is the computational cost, since both background and fore-ground skeletons should be created. The authors report a cor-rect segmentation rate of 96% on 4,500 images of the NIST Database.

The segmentation/recognition algorithm presented by Yu and Yan [ 23 ] uses the morphological structural technique to segment strings of digits. The preprocessing step involves smoothing,linearizationanddetectionofthestructuralpoints of the image contours, which are used to define the segmen-tation cuts. If a string contains more than two numerals, the region of the left two numerals of this string is determined first. In this way, the process of separating a string consisting of more than two numerals is reduced to that of separating a string of two numerals. After a separation, the separated string is processed with the same method until there is no region left that contains at least two numerals. The algorithm is implemented with a huge set of rules and a considerable number of heuristics. The algorithm was assessed on 3,287 images extracted from the NIST database. The correct seg-mentation rate ranges from 85 to 95%, depending on the string length. Another approach using similar features is pre-sented by Kim et al. [ 10 ].

The method proposed by Pal et al. [ 16 ]issimilartothe previous methods, in that, it first classifies the image into isolated or touching digits. It also uses a segmentation/rec-ognition strategy. Since they use background information, no preprocessing is necessary. The rationale behind this algo-rithm is that, when two digits touch each other, they create a large space, also known as a  X  X eservoir, X  between the dig-its. According to the authors, such a space is very important because it concentrates the extraction of cutting points essen-tially around the reservoir, reducing the search area. First, the positions and sizes of the reservoirs are analyzed and a res-ervoir is detected where touching occurs. Considering the type (top or bottom reservoir) and its features, the touching position (top, middle, or bottom) is ascertained. Then, based on the touching position and the analysis of the profile of the reservoir, the initial feature points for segmentation are deter-mined. Considering closed loops, reservoir heights, and the distance from the component center, the initial feature points are ranked and the best feature point (highest ranking point) is noted. Finally, based on touching position, closed loop posi-tions and the morphological structure of the touching region, the cutting path is generated. As a result, the algorithm pro-vides one segmentation cut for a touching pair. The algorithm was evaluated on a database of 2,250 images extracted from a French bank cheque database. The performance reported was a 94.8% rate of correct segmentation.

Elnagar and Alhajjb [ 6 ] designed a segmentation/recogni-tion algorithm to split pairs of digits that takes a binary image as input and then applies normalization, preprocessing, and thinning processes prior to segmentation. The authors argue that, although thinning is computationally expensive, it is essential to obtain uniform stroke width that simplifies the detection of feature points. Since all thinning algorithms cre-ate spurious points, a noise reduction technique is needed to filter out some of these points. Segmentation is performed using features extracted from the skeleton and contour. A set of heuristics is defined to determine the most probable segmentation cuts. As a result, the algorithm produces a sin-gle segmentation cut. The author tested their algorithm on images from the CEDAR and NIST databases, and reported a correct segmentation rate of 96%. The number of images used in the tests was not mentioned.

Suwa and Naoi [ 21 ] proposed a segmentation/recogni-tion algorithm to segment strings of digits, which takes as input the skeleton of the image. From this skeleton, edges and vertices are extracted and the pattern is represented as a connected graph. Potential segmentation points are located based on the peaks and valleys of the upper and lower parts of the skeleton. The segmentation path is computed through graph theory techniques and heuristic rules. The algorithm is designed to detect and remove ligatures using the algorithm described in [ 6 ]. According to the authors, the segmented dig-its have a more natural shape than can be achieved using algo-rithms that split patterns using straight lines or line segments. Experimental results on 2,000 images from the NIST SD19 database were used in their experiments, and they achieved a correct segmentation rate of 88.7%.

Sadri et al. [ 18 ] describe a combination of a recogni-tion-based algorithm and a genetic algorithm. After gener-ating various segmentation hypotheses, the search algorithm attempts to identify the most suitable one according to a pre-defined fitness function. Before detecting the segmentation points, the algorithm classifies the connected components into three classes: parts of digits, isolated digits, or pairs of digits. A connected component is considered a touching digit if it is considerably larger than higher. Segmentation cuts are generated based on the skeleton. Both the fore-ground and the background skeleton are used to construct the segmentation paths. Thereafter, all segmentation hypoth-eses are combined into a segmentation graph, and a genetic algorithm is used to search among all the possible outputs of such a graph. The authors report a performance of 96.5% on 5,000 touching pairs extracted from the NIST SD19 data-base.

Table 1 summarizes the segmentation algorithms dis-cussed in this section. The following aspects are considered:  X  Primitives: main primitives used to build segmentation  X  Ligatures: identifies and removes ligatures between dig- X  Pre-processing: involves all thetools usedbeforesegmen- X  Pre classification: identifies algorithms that detect if a  X  X  X  2: indicates that the authors are reporting results for  X  Over segmentation: algorithm that produces several seg- X  Approach: Recognition or Segmentation/Recognition.  X  Data: Database considered.  X  Size: Number of images used in the experiments.  X  Perf: Correct segmentation rate reported. 3 Database The database used in this work was first introduced by Oliveira et al. in [ 14 ]. It was generated based on 2,000 isolated digits extracted from the hsf_0 series of NIST SD19. The main goal of this database was to provide a common cat-alog for evaluating segmentation algorithms, but, in the long run, it could be useful for training a segmentation-free system like the one proposed in [ 5 ]. It is important to mention that the 2,000 images used to create it were correctly recognized by the classifier described in [ 15 ], a multi-layer perceptron that uses a 132-dimensional feature vector based on con-cavities and contour information. This issue is relevant for assessing the segmentation, and it will be further discussed in subsequent sections. The algorithm responsible for building the synthetic database is very simple, and is based on two rules: 1. It connects only digits produced by one writer. The infor-2. The reference axis along which the digits slide is the
The aim of these rules is to avoid unreasonable connec-tions (e.g., very small digits connected to very big ones) and make the synthetic data more real. As depicted in Fig. 3 , the touching pairs represent realistic scenarios of connected handwritten digits where cursive writing is usually involved.
In addition to the image, the algorithm also produces its ground truth, which contains the label of the image, and the starting and ending coordinates of the optimal segmentation paths ( P ={ p 1 , p 2 ,..., p n } ). Figure 4 a shows an example of the ground truth file. The first line indicates the label of the image, while the second and third indicate the starting and ending coordinates of the optimal segmentation paths ( p 1 and p 2 in this case). Figure 4 b shows the points in the corresponding image.

Besides, the image were labeled to identify the type of touching, following the classification technique proposed by Chen and Wang [ 3 ] (Fig. 5 ). However, the algorithm pro-posed in [ 14 ] does not generate samples with ligatures (type IV), since they do not belong to the digit itself.
In very few cases, though, do we have anything resem-bling a ligature, as depicted in Fig. 6 . As we can see, this stroke is not really a ligature, since it clearly belongs to the digit  X 0 X . After connecting the two digits, it looks like a lig-ature. The few cases where this was observed were labeled as type 1 connections.

Figure 7 a shows how the 79,966 samples in the database are distributed into the 100 classes of touching pairs, which correspond to the possible combinations of two digits. Some of the classes involving the digit 1 still contain fewer samples than other classes. Owing to the American style of handwrit-ing, the digit 1 is very often with the other digit in the pair. Figure 7 b illustrates this problem with samples that were manually removed from the database.

Table 2 shows the distribution of the database based on the type of connection. This database is available upon request for research purposes. 1 4 Evaluation methodology As reported in Sect. 2 , several different segmentation algo-rithms have been proposed in the literature.

The ideal comparative study would involve having access to the source code of all the algorithms. We tried that without success, however. Some algorithms were developed a long time ago and others were developed by companies with no interest, for obvious reasons, in sharing their source code. Instead of comparing all the algorithms found in the litera-ture, we decided to implement those that use different fea-tures or strategies to generate the segmentation points. In this context, the algorithms selected were the ones proposed by Fujisawa et al. [ 9 ], Shi and Govindaraju [ 19 ], Fenrich and Krishnamoorthy [ 8 ], Chen and Wang [ 3 ], Pal et al. [ 16 ], and Elnagar and Alhajajj [ 6 ]. It is worth noting that the algo-rithms were implemented based on the information provided by the authors in their respective publications. Very often the heuristics used by the algorithms are not discussed in the works, however, and in those cases, we defined them empir-ically using a validation set composed of 500 images. The remaining 79,466 were used for testing. 4.1 Assessment criteria As stated before, we are interested in comparing the perfor-mance of the algorithms in terms of correct segmentation and also computational cost. Since we have the coordinates of all the optimum segmentation cuts, it seems obvious that we should compare the segmentation points produced by the algorithms with the ground truth. However, depending on the way this comparison is performed, we may face problems. Consider, for example, the touching pair depicted in Fig. 8 a. In this case, the ground truth is composed of six segmentation points (three segmentation paths). Now, a segmentation algo-rithm can produce a single segmentation path (Fig. 8 b) that is able to split the 2-digit string into two isolated digits. In spite of the fact that this segmentation is different from the ground truth, both digits can be classified as the number 3.
It is clear, therefore, that using only the ground truth infor-mation is not ideal for assessing the segmentation cuts. To overcome this problem, we used a classifier to recognize the segmented pieces.

To guarantee that the digits are correctly classified when the segmentation algorithm produces the best segmentation path (the closest to the ground truth), we used only isolated digits that are correctly classified by the classifier to build the database of touching digits. In addition, we performed a visual inspection to guarantee that errors caused by the OCR engine are not introduced at this level. In this analy-sis, we checked for both Type I and Type II errors. In the first case, we looked for instances where the classifier gave the incorrect recognition for the correct segmentation, while in the second case, we looked for cases where the classi-fier gave the correct recognition for the incorrect segmenta-tion.

We are interested in knowing whether or not the seg-mentation cuts produced by the algorithms are good ones, independently of their number. For the algorithms based on the segmentation/recognition approach, this task is straight-forward, since there is only one hypothesis to be assessed. For those algorithms based on over segmentation, we have to evaluate all the cuts. If we find two digits among the hypotheses (using classification) corresponding to the ground truth, we consider that the segmentation was suc-cessful. If we send only the best (the closest to the ground truth) segmentation cuts for classification, that is, the ones closest to the ground truth, we will risk classification issues, since digits produced by a bad segmentation cut can be recognized with a higher probability/score by the classifier than those generated by the correct (ground truth) segmentation cut. We believe that the assessment strategy adopted here is fair, since the deficiencies of the classifier will not penalize the segmentation algo-rithms.

Regarding cost, the metric used was the computational time. Since we implemented all the algorithms using the same coding standard and the tests were performed on the same hardware, we believe this is a valid metric that can provide good insight into the complexity of each algo-rithm. Even if we do not assess all the segmentation cuts, in the case of over segmentation, we provide the num-ber of segmentation cuts produced by those algorithms, which is the important information for recognition-based systems. 5 Experiments and discussion All the algorithms were implemented in C++, and the exper-iments were performed on a PC with an Intel Core 2 Duo, a speedof1.6Ghz,2GbofRAM,andUbuntuLinux8.04.With respect to the computational time, in this work, we are inter-ested only on the time spent to produce the segmentation cuts. In the following paragraphs, we present some implementa-tion details, as well as the performance of each algorithm. For all the algorithms, we report the overall performance, as well as the performance for each type of segmentation, remembering that Type IV connections are not considered in the database. In all the experiments, the number of digits contained in each piece of test data is assumed to be known.
The method presented by Fujisawa et al. [ 9 ] classifies the image into isolated or touching digits before segmentation. Since we have only touching digits in our database, this step was skipped. The algorithm uses a threshold called H x to identify touching-region candidates. In our experiments, we used H x = 17 (the value defined empirically on the vali-dation set). The overall performance of this algorithm was 89.85%, and it achieved 95.45, 91.27, 83.57, and 63.72% for Type I, II, III, and V connections respectively. It generates 3.66 (  X  0.6) segmentation cuts in 0.4ms, on average, which makes it one of fastest of the algorithms we implemented. Incidentally, the authors argue that this algorithm was not designed to segment Type V connections.

The worst overall performance was achieved by the method proposed by Shi and Govindaraju [ 19 ]. In this work, the authors use a threshold ( THR ) to identify a significant right turn, and hence the potential for segmentation. In our experiments, THR = 75 was used (a value defined empiri-cally on the validation set). The performance for Type I, II, III, and V connections were 68.31, 59.72, 60.35, and 25.44% respectively. The average performance of this algorithm was 59.30%. The average time to produce a segmentation cut is 1.2ms.

The algorithm described by Fenrich and Krishnamoorthy [ 8 ] produces 4.07 (  X  0.5) segmentation cuts in 3.9ms, on average. In spite of its simplicity, this algorithm achieves an interesting overall performance of 92.37%. The performance for Type I, II, III, and V connections was 97.54, 93.79, 99.45, and 65.57% respectively. However, it is surpassed by other segmentation algorithms for certain connection types.
The segmentation algorithm proposed by Chen and Wang [ 3 ] produces the best overall performance, but it is the most expensive in terms of computational time and the num-ber of segmentation hypotheses. It generates, on average, 45.4 (  X  24) segmentation cuts per image in about 74.8ms. Unlike the other algorithms discussed so far, the computa-tional time varies considerably, depending on the type of connection. For Type V, for example, it takes about 100ms on average. Besides, this method makes extensive use of the skeletonization process (background and foreground), which contributes to the high computational cost. In order to select the best segmentation hypothesis, the authors trained a mix-ture of Gaussians using 823 images, although this filtering process was not implemented in our experiments. The Chen and Wang algorithm achieves the best overall performance of 93.80%, and its performance for Type I, II, III, and V con-nections was 97.87, 94.23, 97.55, and 76.76% respectively.
Themostinnovativesetoffeaturesdevelopedrecentlywas proposed by Pal et al. [ 16 ]. The authors use the concept of the reservoir. The method is quite fast, finding the optimal seg-mentation point in about 0.7ms on average. Like the method presented by Fujisawa et al. [ 9 ], this method also classifies the image into isolated or touching digits prior to segmenta-tion. As before, this process was not considered. The average performance of this algorithm was 71.21%, while the per-formance for connections of Type I, II, III, and V was 73.96, 74.69, 80.09, and 41.52% respectively.

The algorithm proposed by Elnagar and Alhajajj [ 6 ] achieved an overall performance of 67.54%. It attempted to find the segmentation points using the skeleton of the image. To do so, they used 32 different configurations of a mask, and this has a considerable impact on the computational time (7.5ms to segment an image). The authors argue that this pro-cess can be parallelized, though. The performance for con-nections of Type I, II, III, and V was 63.88, 71.51, 56.40, and 58.73% respectively.

In Fig 9 a, the performances of all the algorithms. for each connection type are compared, and in Fig. 9 , their average processing times are compared. Table 3 summarizes these algorithms.

As stated before, recognition-based algorithms such as the ones described in [ 3 , 8 , 9 ] produce better , but their process-ing time should be multiplied by the number of segmentation hypotheses, which increases exponentially as a function of the number of segmentation cuts. Figure 10 exemplifies this problem: The segmentation algorithm produces four cuts, leading to 15 classifier calls.

For this reason, some authors have investigated the use of filters to reduce the number of segmentation hypotheses [ 22 ]. As mentioned before, Chen and Wang [ 3 ] trained a mix-ture of Gaussians to reduce the huge number of segmentation hypotheses created by their algorithm. Of course, there is a cost involved in filtering these points, but it should be con-siderably less expensive than using the classifier to assess all the segmentation hypotheses.
To put this into context, consider the algorithm proposed by Chen and Wang [ 3 ]. Using their filter, which ultimately provides onlyonesegmentationhypothesis, that is, theclassi-fier has to evaluate only two digits. For the sake of simplicity, we are abstracting all the complexity and processing time of such a filter. Consider also the algorithm proposed by Fenrich and Krishnamoorthy [ 8 ] which is considerably faster than the one proposed in [ 3 ]. However, the former yields about four (3.6) segmentation cuts, which means 15 classifier calls as against two yielded by the latter. Considering the classi-fier used in our work, which takes about 28ms (using the hardware specified above) to classify a given image, the final processing time required to segment and classify a connected pair of digits would be 423ms and 130ms for Fenrich and Krishnamoorthy and Chen and Wang respectively. Of course, the classification process can be parallelized and the classi-fier optimized. Nevertheless, this is an important issue that should be considered during specification of a recognition system.

So far we have compared the algorithms in terms of per-formance and cost. However, there is another facet of these results that can be explored, which is combining the seg-mentation algorithms. As we can see in Fig. 9 a and Table 3 , some algorithms are better than others, depending on the connection type.

In this context, Table 4 shows the number of images cor-rectly segmented given a number of algorithms. For exam-ple,  X 2/6 X  means that 2,976 images are correctly segmented by only two of the six segmentation algorithms used. The label  X 0/6 X  means that no algorithm was able to segment 344 images (i.e., 0.43% of the images). Table 4 presents this analysis for each type of connection.

In the last line of Table 4 , the label  X  X racle X  means that at least one algorithm was able to segment a given image. As we can see, by combining all segmentation algorithms, we can reach a correct segmentation rate of 99.57%, which is considerably better than the best algorithm. This result shows thatthealgorithmsrelyoncomplementaryfeaturesandthere-fore can be further combined to yield a more reliable segmen-tation. Concerning complementarity, Table 5 details the line  X 1/6 X  of Table 4 where the images were correctly segmented by only one algorithm.

Table 5 allows us to observe that, independently of their individual performances, each algorithm is responsible for correctly segmenting a specific subset of images of the data-base. Another interesting point worth noting is that, even though it achieves the worst individual performance, the algorithm proposed by Elnagar and Alhajajj [ 6 ] performs well for a subset of images. Of the 1,233 images correctly segmented by only one algorithm, this one is responsible for 22.71% of them. As in the classification task, where weak classifiers can be used to build more reliable ensembles, the experiments reported here show that combining segmenta-tion algorithms can also contribute to building more efficient handwriting recognition systems.

The results presented in Tables 4 and 5 can be seen as an oracle, in the sense that if a suitable combination scheme is employed, this would be the upper limit for this database using these algorithms. This combination can be made to be static, by cascading all the algorithms, or dynamic, by using the information about the nature of the touching in the pairs to select the best algorithm. Of course, this is not a trivial task owing to the huge variability of the algorithms; how-ever, it could be an interesting way to create more reliable and efficient segmentation modules.

After analyzing the experiments reported so far, one ques-tion arises: Do the synthetic data present the same degree of segmentation difficulty that we find in real databases? To answer this question, we designed an experiment where the six algorithms were used to segment 2,369 images of touching pairs extracted from the well-known NIST SD 19 database. Table 6 shows the distribution of the con-nection types for the real data. For the sake of compari-son, we show the numbers presented in Table 2 as well. As stated before, the synthetic data does not have Type IV connection.
 The results of the correct segmentation are reported in Table 7 . As we can see, the performance achieved in this dataset is similar to the performance reported in Table 3 .The slightly better performance achieved on the real dataset by most algorithms can be justified by the fact that it contains more images of Type I, which are easier to segment. 6 Conclusion In this work, we have compared various segmentation algo-rithms of the explicit type. We selected those algorithms that we deemed most different, in terms of the features and ideas used to produce the segmentation cuts. Then, these algo-rithms were assessed for performance and cost using the same experimental protocol on 79,966 synthetic images and 2,369 real images extracted from the NIST_SD19 database. The proposed evaluation criteria provided the global per-formance of each algorithm, as well as their performance on four different types of connections. The experimental results show that these algorithms achieve similar perfor-mances on both databases, which qualifies the synthetic data-set as a viable alternative for benchmarking segmentation algorithms.

During the evaluation, we observed that, independently of the overall performance, each method is able to segment some samples that cannot be segmented by any other method. It corroborates the argument that even a method with low overall performance can contribute to building a more reli-able segmentation system.

As we have demonstrated, this kind of analysis also con-stitutes a useful contribution to identifying complementar-ity among the segmentation algorithms, which can be used to develop more intelligent systems. The main challenge in building such an intelligent system lies in the correct identifi-cation of the connection types, which certainly is not a trivial task.
 References
