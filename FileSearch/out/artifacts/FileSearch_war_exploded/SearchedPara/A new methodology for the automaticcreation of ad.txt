 Department of Computer Architecture, Facultad de Inform  X  atica, Universidad Polit  X  ecnica de Madrid, Madrid, Spain Instituto Cajal, Consejo Superior de Investigaciones Cienti fi cas, Madrid, Spain 1. Introduction
Evolutionary Algorithms are powerful optimization techniques that have been applied to many different problems, from complex mathematical functions to real-world applications. However, the selection of the most appropriate Evolutionary Algorithm (EA) for a given optimization problem is a dif fi cult task, sometimes considered an optimization problem by itself [6]. Even though the No Free Lunch Theorem asserts that  X  any two algorithms are equivalent when their performance is averaged across all possible problems  X , in practice, and being constrained to certain types of problems, the performance of some particular algorithm is better than others. In most of the cases, the selection of the most appropriate algorithm is carried out by the execution of several alternative algorithms (advised by the literature or the own experience) and then choosing the one reporting the best results.

Supported by these arguments, hybrid evolutionary techniques are a promising alternative to deal with these situations. Over the last years, the best results for many practical or academic problems have been found by hybrid metaheuristics [3,10,14,20]. By combining different heuristic optimization approaches, hybrid algorithms also hold the hypothesis that the appropiate combination of several techniques can outperform the sole usage of its composing algorithms due to the potential synergies that could arise from the combination.

There are several approaches to carry out the combination (as detailed in [20]). One of the most popular approaches in th e literature is the High-level Relay H ybrid (HRH) or memetic combination. In this strategy the algorithms are self-contained and applied in sequence one after another iteratively. Two models can be used with a HRH combination: static or adaptive. In the static model, the combination scheme of the algorithms is fi xed and does not change between executions (e.g., execute a local search step after 10 steps of the main algorithm). In the adaptive model, some heuristics use the values of some measures to determine the execution sequence of the algorithms. For example, a combination heuristic could decide to execute an exploitative algorithm until the population diversity fell below a threshold value and then, change to the explorative algorithm. Another example is a heuristic which, based on the scores of the last solutions, determines the number of evaluations that each algorithm could consume for the next step. These combination schemes have the disadvantage that need to be handcraftedly designed by the developer of the algorithm that needs to carefully select the measures (as well as the appropriate thresholds) and the heuristic for conducting the combination.

This paper introduces a different perspective, bare ly explored in the literature of hybrid algorithms: to analyze the results from past executions to induce the most appropriate hybridization strategy. This is particularly useful in those scenarios in which an optimization problem is solved multiple times. These multiple executions could include slightly different conditions that actually have an in fl uence in the position of the optimal value, but do not change the main characteristics of the fi tness landscape in which this optimization process searches. Many industrial problems have this characteristic in which the fi tness function is mainly the same, but the particular conditions or other input parameters are changed at each execution, e.g., the optimization of engineering struc tures evaluated under different stress conditions.
Aratherna  X   X  ve solution to this issue is the design of an alternating strategy, based on the generation number or the fi tness values. An example of this simple strategy is represented in Table 1. Nevertheless, this idea does not consider that reaching a given fi tness value or a particular generation number is achieved via a stochastic process. This process does not ensure that the same generations or the same fi tness values reached by an algorithm actually represent the same situation of the search process in two different executions. Any successful strategy would need both the general parameters and other statistical or introspective information of the evolving population, in order to identify a situation similar to one previously learned.

This paper presents a new methodology that mines previous executions in order to learn a model of the best combination of techniques, according not only to their performance but also to other sta-tistical/informative parameters o f the evolved population, and uses it as the combination strategy of a new adaptive HRH algorithm. This algorithm has been evaluated using a well-known benchmark of continuous optimization functions and its results have been validated using statistical tests.
The rest of the paper is organized as follows: Section 2 presents an overview of several hybrid algorithms. Section 3 details the proposed algorithm. In Section 4 the experimental scenario is described in detail. Section 5 presents and comments on the results obtained and lists the most relevant facts from this analysis. Finally, Section 6 contains the concluding remarks obtained from this work. 2. Related work
The HRH terminology was introduced in [20], one of the fi rst attempts to de fi ne a complete taxonomy of hybrid metaheuristics. This taxonomy is a combination of a hierarchical and a fl at classi fi cation structured into two levels. The fi rst level de fi nes a hierarchical classi fi cation in order to reduce the total number of classes, whereas the second level proposes a fl at classi fi cation, in which the classes that de fi ne an algorithm may be chosen in an arbitrary order. From this taxonomy, the following four basic hybridization strategies can be derived: (a) LRH (Low-level Relay Hybrid): One metaheuristic is embedded into a single-solution metaheuris-(b) HRH (High-level Relay Hybrid): Two metaheuristics are executed in sequence. (c) LTH (Low-level Teamwork Hybrid): One metaheuristic is embedded into a population-based (d) HTH (High-level Teamwork Hybrid): Two metaheuristics are executed in parallel. 2.1. HRH algorithms
In the last years there has been an intense research in HRH algorithms. In particular, the DE algorithm is one of the Evolutionary Algorithms that has been recently hybridized using this kind of strategy, considerably improving some of its inherent fl aws: slow convergence and stagnation of the population.
Some of the HRH algorithms employ a static strategy in which one of the algorithms is applied at the end of every (or some) step(s) of the main algorithm. In [7], the PSO algorithm is executed as the main algorithm but, from time to time, the DE algorithm is launched to move particles from already explored areas to new positions. Gao and Wang [4] proposed CSDE1, a memetic DE, to optimize thirteen 30-dimensional continuous problems. CSDE1 uses simplex (Nelder-Mead method) to carry out the Local Search (LS) using also chaotic system s to create the initial population. CSDE1 applies the Local Search only to the best individual in the population at each generation. DE has also been combined with Evolutionary Programming (EP) in [23]. The EP algorithm is executed for each trial vector created by the DE algorithm which is worse than its associated target vector. In the MDE-DC algorithm [14], a DE algorithm is combined with the fi rst of the local searches of the MTS algorithm. In this algorithm, a number of local search iterations are applied after a certain number of generations of the DE. However, if the execution of each of these iterations does not improve the best results, the remaining ones are cancelled.

Other HRH algorithms have followed an adaptive strategy in which the execution of each algorithm depends on a measure that varies along the evolution. In [17], the authors propose two adaptive strategies, one heuristic and one stochastic, to adapt the participation of several local searches when combined with a Genetic Agorithm (GA). In both strategies, there is a learning phase in which the performance of each local search is stored and used in later generations in order to select the local search to apply. In [3,24] several local searches are combined with a metaheuristic algorithm using also an adaptive scheme. The application of each algorithm is based on a population diversity measure which varies among the studies. In [10], an adaptive HRH algorithm, based on the MOS framework [9] is proposed. In this algorithm, the fi rst local search of the MTS algorithm is applied after a DE algorithm. For each step, there is a fi xed number of evaluations to distribute between both algorithms. Based on the score of the generated individuals of the last step, a participation function determines the ratio of the total number of evaluations that each algorithm is allowed to spend at the next step. This algorithm was presented for the special issue  X  X calability of Evolutionary Algorithms and other Metaheuristics for Large Scale Continuous Optimization Problems X  of the Soft Computing journal and obtained the best overall results among all the presented algorithms (including several hybrid approaches) and the IPOP-CMA-ES algorithm. 1 2.2. Of fl ine learning algorithms
Few works have focused on applying an of fl ine learning method as a complementary mechanism for metaheuristics. In the fi eld of hyper-heuristics, several studies have been conducted on the use of of fl ine learning approaches where the idea is to gather knowledge from a set of training instances that would hopefully generalize to the process of unseen instances. In [2], a Case Based Reasoning (CBR) approach was used to select the best heuristic at each step for arti fi cial timetabling problems. In this work, a problem solving framework was developed to provide good solutions for a variety of timetabling problems. In [13,19], the XCS Learning Classi fi er System was applied to a bin-packing problem to learn about the solution process rather than to solve individual problems. The system was able to create and develop feasible hyper-heuristics that performed well on a large collection of benchmark data sets. and timetable problems. Here, each labelled point represents a speci fi c state of the problem and stores the heuristic that could potentially obtain the best results for that state. To evaluate each solution of labelled points, the algorithm starts with the initial state of the timetable problem and repeatedly carries out the following steps: (i) to fi nd the nearest label point and (ii) to apply the heuristic until a complete solution is built. In [22] a GA was used to construct a potentially good sequence of heuristics for solving a set of 2D-regular cutting stock problems. In this a pproach, the solution doe s not take into account the problem state to execute the sequence of heuristics. In [16], the authors propose a hyper-heuristic in which the basic heuristics are selected by a procedure inspired by Reinforcement Learning. Only in [11], a learning mechanism was applied to control the behavior of a hybrid Evolutionary Algorithm. In this work, Reinforcement Learning techniques were applied to a HTH algorithm to control the participation of the involved algorithms, i.e., the amount of new individuals of the new population that each algorithm could generate. First, the algorithm carries out several executions to learn the hybridization model. Then, for each step and based on the actual state (a set of discretized values the model selects the best action to perform, i.e., the selection of algorithms to generate the offspring population. 3. Contribution
In this study, we propose the hypothesis that it is possible, based on the analysis of the behavior of previous executions, to learn a hybridization strategy for the algorithms of a HRH algorithm by means of data mining techniques in order to select the most appropriate algorithm for each iteration of the execution.

Normally, when developinga new adaptive HRH algorithm, the researcherneeds to design the heuristic to conduct the combination as well as the measures that the heuristic is going to use. For example, to develop the MOS algorithm [10], an intensive study of both the measures and how their in fl uence on the participation of the algorithms was carried out.
In this work, a new methodology for creating adaptive HRH algorithms from the analysis of past exe-cutions is proposed. With this methodology, a potentially good heuristic for conducting the combination is automatically learned by means of a speci fi c set of measures that describe the algorithm behavior. This methodology has the advantage that it automatically selects the measures and the strategy to conduct a potentially good combination of algorithms. The aforementioned studies in the hyper-heuristic domain try to achieve a similar objective. However, they have only been tested in combinatorial domains, using only a small number of measures that are also domain-dependent with a restricted set of values to model the state of the algorithm and using simple deterministic heuristics. In this contribution, the approach is more general and challenging since it deals with stochastic algorithms that need several executions for evaluating their performance with domain-independent measures that could be applied to any kind of problem and over continuous domains in which the state can not be easily discretized. When compared to the reinforcement-based strategies for learning a combination model, the proposed approach has the bene fi t that it takes out from the expert the burden of selecting a set of measures and discretize them in reasonable values in order to be able to apply the reinforcement learning algorithm. 3.1. Proposed methodology
Brie fl y, the methodology de fi nes a process for  X  X bserving X  the execution of a HRH algorithm to store some information about each state of the execution (a set of measures) along with the information (for that state) of the performance of the algorithms involved in the hybrid algorithm. With this information, the methodology speci fi es how to construct a model and use it as a hybridization strategy of a new HRH algorithm, named smartHRH which will try to select the most appropriate algorithm for each state found.
The main steps of the methodology are depicted in Figs 1.a and 1.b. As previously mentioned, the process starts with the execution of a HRH algorithm (it could be any HRH algorithm) which, as all hybrid algorithms, has a hybridization strategy that determines the sequence of algorithms, from a set of algorithms A , involved in the combination. Let S i be the state when i evaluations have been consumed. The state represents not only the tentative solutions for that precise moment of the evolution but also every characteristic related to the state (e.g., maximum age, population diversity, ... )aswell as the characteristics of the execution (e.g., number of evaluations without improvement, number of evaluations of each algorithm, ... ). For each state, the methodology compares the performance over a period of evaluations for all the composing algorithms. Therefore, it executes each algorithm for M evaluations over the same starting state S algorithms are stochastic, this process needs to be repeated several times in order to obtain a more reliable measure of the performance. After N repetitions, the global number of best scores for the state S i can be generated. Equations (1) and (2) de fi ne this number.

Here, BS j the state indenti fi ed by the number of evaluations i whereas ( bs j obtained the best score among all the algorithms. With this information, the proposed process generates a data record that stores the information of the values of the measures in state S i together with the number of best scores of each of the algorithms. Then, the execution continues with the state of the chosen algorithm (the one selected by the hybridization strategy at state S i ) of the last repetition. This process is continued until the stop criterion is satis fi ed.

After a number of executions, a broad data set of records, which store the performance of the algorithms over different states, is obtained. Then, the following steps are applied:  X  First, the records are preprocessed, fi ltering out those which have the same number of best scores  X  For each of the remaining records, a new instance is created by adding a class attribute which  X  The resultant data set is used as input for a machine learning algorithm (C4.5 in this study), which  X  Finally, this model is used to construct the proposed adaptive HRH algorithm (named smartHRH). 3.2. baseHRH
Although the proposed process can be started with any HRH algorithm, a HRH algorithm that tries to select the best combination sequence of algorithms has been used as the initial algorithm. This algorithm, called baseHRH, follows a similar scheme to the one presented earlier in Fig. 1.a. For each state S i , it analyzes the global performance over a number of evaluations for each of the composing algorithms. Then, it continues the execution with the algorithm with the highest number of best scores, i.e., arg max j BS j from both algorithms have been included (e.g. ratio of the total number of evaluations of one algorithm and the equivalent value of the other algorithm), a small percentage of evaluations is always executed for the algorithm not chosen so that the measures do not contain indeterminate values. As previously mentioned, any HRH algorithm could be used for learning the best hybridization patterns. However, by selecting the baseHRH algorithm as the starting algorithm, the initial dataset of records is assured to come from a potentially good sequence of algorithms. Furthermore, this algorithm supposes a harder challenge for our proposed methodology, since it has to learn an of fl ine hybridization strategy that can equal or even outperform the results of an online strategy that uses the future information to select the best algorithm at each step. 3.3. smartHRH
As previously mentioned, this algorithm uses the information learned from previous executions of the baseHRH algorithm (stored in the corresponding model) to select the most appropiate algorithm for each possible state found. Therefore, it tries to apply a similar combination sequence than the one of the baseHRH executions but without having to execu te several repetitions for determining the best algorithm. Due to this fact, it follows a similar scheme where, for each state, the chosen algorithm is executed for a period of M evaluations minus a small percentage assigned to the other algorithm.
Since the proposed methodology can be applied to any HRH algorithm, the described process can also be successively applied to the obtained smartHRH algorithm in order to iteratively re fi ne the learned model. Although the model can be improved by this iterative process, there is no guarantee that the models generated from this process will converge to any particular model. 4. Experimental scenario
A total of 19 continuous optimization functions have been considered for this experimentation. The fi rst 6 functions were originally proposed for the  X  Special Session and Competition on Large Scale Global Optimization  X  held at the CEC 2008 Congress [21]. This set of functions plus 5 new more functions were proposed for the Workshop on Evolutionary Algorithms and other Metaheuristics for Continuous Optimization Pr oblems  X  A Scalability Test held at the ISDA 2009 Conference. Finally, the last 8 functions were proposed by the organizers of the ISDA 2009 Workshop in [12]. These are non-separable hybrid functions built by combining two functions belonging to the set of functions f 1  X  f 11 . The description of the combination function is detailed in Fig. 2 and both simple and hybrid functions in Tables 2 and 3, respectively.

Both the algorithms for conducting the combination and their parameters have been selected based on the MOS algorithm presented in [10], an adaptive HRH algorithm that obtained the best overall results on the benchmark. The idea for this selection was to demonstrate that the proposed methodology is able to develop a combination strategy that could outperform the results of the best adaptive HRH algorithm for these problems. Table 4 displays the selected values for all the parameters of the algorithm.
The two selected algorithms for the combination are: DE and LS1, the fi rst local search of the MTS algorithm. The DE algorithm is one of the recent algorithms that, due to its results, has quickly gained popularity on continuous optimization. In the last I EEE competitions on continuous optimization, a DE-based algorithm has always r eached one of the best thr ee positions. Neverth eless, DE is subject to stagnation problems that could heavily in fl uence the convergence speed and the robustness of the algorithm [8]. The MTS algorithm was designed for multi-objective problems but it has also obtained very good results with large scale optimization problems. In fact, it was the best algorithm of the CEC X 08 competition [21]. Therefore, the idea of combining them is to assist the explorative power of DE by an exploitative local search which has proved to obtain some of the best results.

Regarding the de fi nition of the state, the following set of representative measures, which register several characteristics of the execution and the hybridization strategy, have been selected:  X  bestscore ( S i ) : Best score of the solutions  X  maxage ( S i ) : Maximum age of the solutions  X  nevals ( S i ) : Number of evaluations consumed  X  nevalswithoutimprovement ( S i ) : Number of evaluations without improvement  X  nevals alg : Number of evaluations of algorithm alg  X  avgevals  X  nevals alg  X  avgevals  X  scoreincrement alg  X  scoreincrement alg  X  scoreincrement alg
To compare the results, the following algorithms were executed over the benchmark: the DE algorithm, the LS1 algorithm, a random HRH algorithm made up of both the DE and the LS1 algorithms, which distributes uniformly the total number of evaluations between both algorithms, the baseHRH algorithm used to obtain the fi rst model described in Section 3, the MOS algorithm which has previously obtained the best overall results in the benchmark and the smartHRH algorithm. Up to fi ve versions of smartHRH algorithms were iteratively obtained to re fi ne the model.
The results reported in this work are the average of 25 independent executions. The experimentation has been conducted with the computer con fi guration displayed in Table 5. For each function, 4 different numbers of dimensions have been tested: D = 50, D = 100, D = 200, D = 500, with a maximum number of Fitness Evaluations fi xed to 5000  X  dimension . Due to the constraints of the framework employed, the maximum reachable error without loosing precision is 1 e  X  14 and, thus, all the values below this threshold have been rounded to zero. 5. Results and discussion
Tables 6, 7, 8 and 9 present the results of the average distance to the optimum of the 25 executions in 50, 100, 200 and 500 dimensions respectively. The best values for each function are highlighted in the tables. It can be seen that the smartHRH algorithm obtains the best results in 15 out of 19 functions in 50, 100 and 200 dimensions and in 16 functions in 500 dimensions, reaching the global optimum in 14 of those functions.

Regarding the combination strategy, for some functions, the smartHRH decides to execute only one of the algorithms (the best one for that function) whereas for others it combines them in order to reach better solutions or to obtain more stable results. For example, in f 5 and f 6 , both the DE and the LS1 algorithms are able to reach the global optimum in some of their executions, whereas the smartHRH algorithm achieves this goal in all of its executions.

In order to obtain a better comparison per function, each algorithm was compared against each other using the non-parametric Wilcoxon signed-rank test. Each cell D i,j in Table 10 displays the functions 0.05. Here, the smartHRH algorithm is also the clear winner obtaining the best results among all the functions.

When compared against the baseHRH algorithm, it can be seen that, not only the smartHRH is able to mimic the best behavior of this algorithm, which uses the knowledge of the future evaluations to select the best option at each step and executes ten times more evaluations during each execution, but is also able to signi fi cantly improve it in some functions ( f 12 and f 13 on 50D and f 2and f 4 on 500D). Therefore, the proposed procedure is able to detect better hybridization patterns than an algorithm that, at each step, analyzes both options through several attempts.
Furthermore, the proposed automatically generated hybridization strategy is able to obtain signi fi cantly better results than the best algorithm of the benchmark, the MOS algorithm, in four functions in 50D and 200D ( f 2, f 8, f 13 and f 17) and three functions in 100D ( f 8, f 13 and f 17) and 500D ( f 2, f 8and f 13). It must be taken into account that the MOS algorithm is able to reach the global optimum in 14 out of 19 functions, leaving only fi ve functions for possible improvements. From these functions, only in f 3, the proposed methodology was unable to improve the MOS algorithm in any dimension. Figures 3, 4, 5 and 6 display the evolution in these functions in 200D of the average score for the 25 executions of the smartHRH and MOS algorithms together with each of the composing algorithms (DE and LS1). In f 2and f 8 the strategy of the smartHRH algorithm decides to execute only the LS1 algorithm which enables it to obtain quicker and better results than the adaptive approach of the MOS algorithm. In f 13 and f 19, the behavior is completely different. Here, both composing algorithms (DE and LS1) need to be combined properly to reach the best solutions. The strategy followed by the MOS algorithm obtains quality than those r eached by the smartHRH al gorithm in the long term.

Only in functions f 2, f 3and f 8 the smartHRH algorithm obtains worse results than another algorithm of the comparison. For functions f 2and f 8, the learning process is able to detect the best execution strategy (execute only the LS1 algorithm) but, due to the minimum number of evaluations that each algorithm executes at each step (5% of the total), the results are signi fi cantly worse than the sole execution of the LS1 algorithm. Only in f 3, a hybrid algorithm is able to apply a better combination strategy (random in this case). However, it must be taken into account than both the baseHRH and the MOS algorithm suffer from the same problem in this function, probably due to the size of the period of evaluations which unables them to detect the best patterns.

In order to provide a global quantitative comparison among the algorithms, both the average ranking according to the Friedman test and the nwins procedure [15] have been applied to the average results in all the functions and dimensions. The nwins procedure conducts a pairwise comparison of every two algorithms with the Wilcoxon signed rank test. One algorithm is said to be the winning algorithm in such a comparison if the Wilcoxon Signed Rank test reports a p  X  value lower than a pre-established threshold (normally 0.05), whereas the other algorithm receives the name of losing algorithm. Through all these comparisons, the winning algorithm is granted  X  + 1 wins X , whereas the losing one obtains  X   X  1 wins X . At the end of the nwins procedure the algorithms are ranked according to their number of wins. For this comparison it has also been included one of the reference algorithms in continuous optimization, the IPOP-CMA-ES algorithm. As it can be seen in Table 11, the best global results in both nwins and average ranking procedures are obtained by the hybrid smartHRH algorithm whereas the IPOP-CMA-ES exhibits very poor results, proba bly due to the high dimensionality of the considered functions. Table 12 presents the p  X  values of the Wilcoxon test of the comparison of the smartHRH algorithm with the other algorithms. The adjusted p  X  value of the multiple pair-wise comparisons of the new algorithm with the remaining algorithms is also shown in this Table. This correction, computed as described in [5], avoids the Family-Wise Erro r that the multiple compar isons can introduce. In this Table, we can observe that the test fi nds statistical differences between the smartHRH algorithm and all the remaining algorithms except for the baseHRH algorithm. This seems logical since the smartHRH algorithm learns its combination strategy from the baseHRH algorithm and, although it has improved its results on some functions, the number is not enough for obtaining signi fi cant differences.
From these results it seems clear that the proposed methodology is able to learn bene fi cial hybridization patterns that allow the adaptive smartHRH algorithm to obtain the best overall results among all the analyzed algorithms. An example of the evolution of a single execution, in which its hybridization strategy has obtained the best results, is depicted in Fig. 7. It can be seen that the hybrid strategy decides the DE, which is able to explore in m ultiple dimensions, a nd, once the DE reaches de basin of attraction of the optimum, it decides to re fi ne the best solution with the LS1 algorithm. As it was shown in Table 8 and Fig. 6, this behavior allows the smartHRH algorithm to reach systematically better solutions than other combination strategies (MOS and randomHRH) and than the composing algorithms by themselves. For an example of the rules generated by the Machine Learning algorithm considered, c4.5 in this work, Table 13 displays an extract of the rules set generated by the algorithm. It is shown that the learning algorithm is able to detect and use the state measures that better characterize the circumstances under which a different algorithm must be applied.
 Finally, we analyze the scalability be havior and the computational overhead of the proposed algorithm. In general, the algorithm exhibits a good scalability behavior solving 13 functions in all dimensions and 1( f 18) in three dimensions. Only fi ve functions (Schwefel 2.21, Rosenbrock, Schwefel 1.2, f 13 and f 17) are not solved in any dimension. Figure 8 depicts the increment of the average error for these functions. It can be seen that, for most of the functions, the order of magnitude of the average error increment seems to remain constant, whereas for Schwefel 2.21 and Schwefel 1.2 it is linear. Schwefel X  X  problem 2.21 presents large neutral areas, as the fi nal fi tness of a solution is heavily biased by the value of one single dimension (the one with the highest absolute value). The effect of this characteristic is more pronounced as the number of dimensions increases. Furthermore, the dimension with more in fl uence in the fi nal fi tness value can change from one solution to another or when a solution is modi fi ed, so this information can not be exploited by the search algorithm, which makes more dif fi cult to fi nd an optimal solution. Both characteristics could explai n the scalability be havior of the proposed algorithm on this function. Considering now Schwefel X  X  problem 1.2, we can see that, as shown on its function de fi nition Eq. (4), a small change in some components (the fi rst ones, in particular), has a considerable effect in the fi nal fi tness value since the error with respect to the equivalent global optimum coordinate is accumulated in the remaining dimensions ( N  X  i times for dimension i ). Therefore, the same error in the fi rst coordinates dramatically penalizes the quality of a solution in the higher dimensional versions of the function.

Regarding the computational overhead of the proposed method, it must be mentioned that the extra cost of obtaining the measures, learning the model and checking the rules at each step of the evolution is not signi fi cant if compared with the longest execution time of the composing algorithms ( &lt; 1%). Therefore, no optimization techniques such as the reduction of the dimensionality, have been applied to the learning process, although these may be required with a higher number of measures and evaluations. As mentioned in Section 3, since one of the algorithms is a stochastic algorithm, several repetitions at each step were needed in order to obtain a reliable measure of its performance. This implies an extra cost of Nx where N represented the number of repetitions carried out. Therefore, with computationally demanding domains, this number must be carefully selected in order to avoid unnecessary evaluations. 6. Conclusions
In this work, a new methodology for automatically learning effective combination strategies for HRH algorithms has been presented. This learning process uses the information of several parameters of the population, the hybridization process and the performance of the algorithms in past executions to create a hybridization strategy for a new HRH algorithm.

For the experimentation, a standard benchmark made up of 19 functions on 50, 100, 200 and 500 di-mensions has been considered. The results have been analyzed and compared with statistical tests. The experimental results show statistical evidence that the learned hybridization strategy can boost the performance of the new HRH algorithm compared to each composing algorithm and several hybrid algorithms including the best-performance algorithm of the benchmark, the MOS algorithm, and the reference algorithm in continuous optimization, the IPOP-CMA-ES algorithm.

Finally, even though the smartHRH algorithm has obtained the best results, it could be argued that a performance comparison between traditional EAs and smartHRH is not fair, as the latter takes advantage of the results obtained in previous executions. However, the interest of this research is not only to state whether a hybrid algorithm with a combination strategy learned from past results can obtain better results This could be of useful application to real-world problems that have to be solved hundreds of times with slightly different input data such as the optimization of engineering structures evaluated under different stress conditions or problems where, although the instances are different, the best combination patterns remain the same. Examples of these kind of problems are timetable problems [2,18], bin packing and cutting stock problems [19,22].
 The proposal could also be applied to especially dif fi cult problems with unknown global optimum. Without an appropriate hybrid combination, several executions could converge prematurely at local optima. By learning from these executions, a better strategy could be found and applied to obtain better results. An example of these kind of problems is the set of trajectory design problems of the European Space Agency (ESA). These continuous problems are known to contain an enormous number of local optima and to be strongly deceptive for local optimizers [1].
 Acknowledgments
This work was supported by the Madrid Regional Education Ministry and the European Social Fund and supported by the Cajal Blue Brain Project. The authors thankfully acknowledge the computer resources, technical expertise and assistance provided by the Centro de Supercomputaci  X  on y Visualizaci  X  on de Madrid (CeSViMa) and the Spanish Supercomputing Network. A. LaTorre gratefully acknowledges the support of the Spanish Ministry of Science and Innovaton (MICINN) for its funding throughout the Juan de la Cierva program.
 References
