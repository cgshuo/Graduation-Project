 In this paper, we reveal a common deficiency of the current retrieval models: the component of term frequency (TF) normalization by document length is not lower-bounded prop-erly; as a result, very long documents tend to be overly penalized. In order to analytically diagnose this problem, we propose two desirable formal constraints to capture the heuristic of lower-bounding TF, and use constraint analysis to examine several representative retrieval functions. Anal-ysis results show that all these retrieval functions can only satisfy the constraints for a certain range of parameter values and/or for a particular set of query terms. Empirical results further show that the retrieval performance tends to be poor when the parameter is out of the range or the query term is not in the particular set. To solve this common problem, we propose a general and efficient method to introduce a suffi-ciently large lower bound for TF normalization which can be shown analytically to fix or alleviate the problem. Our ex-perimental results demonstrate that the proposed method, incurring almost no additional computational cost, can be applied to state-of-the-art retrieval functions, such as Okapi BM25, language models, and the divergence from random-ness approach, to significantly improve the average precision, especially for verbose queries.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models Algorithms, Theory Term frequency, lower bound, formal constraints, data anal-ysis, document length, BM25+, Dir+, PL2+
Optimization of retrieval models is a fundamentally im-portant research problem in information retrieval because an improved retrieval model would lead to improved perfor-mance for all search engines. Many effective retrieval models have been proposed and tested, such as vector space mod-els [16, 18], classical probabilistic retrieval models [13, 8, 14, 15], language models [12, 20], and the divergence from randomness approach [1]. However, it remains a significant challenge to further improve these state-of-the-art models and design an ultimately optimal retrieval model.
In order to further develop more effective models, it is necessary to understand the deficiencies of the current re-trieval models [4]. For example, in [18], it was revealed that the traditional vector space model retrieves documents with probabilities different from their probabilities of relevance, and the analysis led to the pivoted normalization retrieval function which has been shown to be substantially more ef-fective than the traditional vector space model. In this work, we reveal a common deficiency of existing retrieval models in optimizing the TF normalization component and propose a general way to address this deficiency that can be applied to multiple state-of-the-art retrieval models to improve their retrieval accuracy.

Previous work [4] has shown that all the effective retrieval models tend to rely on a reasonable way to combine mul-tiple retrieval signals, such as term frequency (TF), inverse document frequency (IDF), and document length. A major challenge in developing an effective retrieval model lies in the fact that multiple signals generally interact with each other in a complicated way. For example, document length normalization is to regularize the TF heuristic which, if ap-plied alone, would have a tendency to overly reward long documents due to their high likelihood of matching a query term more times than a short document. On the other hand, document length normalization can also overly penalize long documents [18, 4]. What is the best way of combining mul-tiple signals has been a long-standing open challenge. In particular, a direct application of a sound theoretical frame-work such as the language modeling approach to retrieval does not automatically ensure that we achieve the optimal combination of necessary retrieval heuristics as shown in [4].
To tackle this challenge, formal constraint analysis was proposed in [4]. The idea is to define a set of formal con-straints to capture the desirable properties of a retrieval function related to combining multiple retrieval signals. These constraints can then be used to diagnose the deficiency of an existing model, which in turn provides insight into how to improve an existing model. Such an axiomatic approach has been shown to be useful for motivating and developing more effective retrieval models [6, 7, 2].
In this paper, we follow this axiomatic methodology and reveal a common deficiency of the current retrieval models in their TF normalization component and propose a general strategy to fix this deficiency in m ultiple state-of-the-art re-trieval models. Specifically, we show that the normalized TF may approach zero when the document is very long, which often causes a very long document with a non-zero TF (i.e., matching a query term) to receive a score too close to or even lower than the score of a short document with a zero TF (i.e., not matching the corresponding query term). As a result, the occurrence of a query term in a very long docu-ment would not ensure that this document be ranked above other documents where the query term does not occur, lead-ing to unfair over-penalization of very long documents. The root cause for this deficiency is that the component of TF normalization by document length is not lower-bounded properly, i.e., the score  X  X ap X  between the presence and ab-sence of a query term could be infinitely close to zero or even negative. In order to diagnose this problem, we first propose two desirable constraints to capture the heuristic of lower-bounding TF in a formal way, so that it is possible to apply them to any retrieval function analytically. We then use constraint analysis to examine several representative re-trieval functions and show that all these retrieval functions can only satisfy the constraints for a certain range of param-eter values and/or for a particular set of query terms. Em-pirical results further show that the retrieval performance tends to be poor when the parameter is out of the range or the query term is not in the particular set.

Motivated by this understanding, we propose a general and efficient methodology for introducing a sufficiently large lower bound for TF normalization, which can be applied di-rectly to current retrieval models. Constraint analysis shows analytically that the proposed methodology can successfully fix or alleviate the problem.

Our experimental results on multiple standard collections demonstrate that the proposed methodology, incurring al-most no additional computational cost, can be applied to state-of-the-art retrieval functions, such as Okapi BM25 [14, 15], language models [12, 20], and the divergence from ran-domness approach [1], to significantly improve their average precision, especially when queries are verbose. Due to its ef-fectiveness, efficiency, and generality, the proposed method-ology can work as a  X  X atch X  to fix or alleviate the problem in current retrieval models, in a plug-and-play way.
Developing effective retrieval models is a long-standing central challenge in information retrieval. Many different re-trieval models have been proposed and tested, such as vector space models [16, 18], classical probabilistic retrieval models [13, 8, 14, 15], language models [12, 20], and the divergence from randomness approach [1]; a few representative retrieval models will be discussed in detail in Section 3.1. In our work, we reveal and address a common  X  X ug X  of these re-trieval models (i.e., TF normalization is not lower-bounded properly), and develop a general plug-and-play  X  X atch X  to fix or alleviate this bug.

Term frequency is the earliest and arguably the most im-portant retrieval signal in retrieval models [15, 18, 12, 20, 17, 1, 4, 10]. The use of TF can be dated back to Luhn X  X  pioneer work on automatic indexing [9]. It is widely recog-nized that linear scaling in term frequency puts too much weight on repeated occurrences of a term. Thus, TF is of-ten upper-bounded through some sub-linear transformations [15, 18, 12, 20, 1, 2, 10] to prevent the contribution from re-peated occurrences from growing too large. Particularly, in Okapi BM25 [14, 15], it is easy to show that there is a strict upper bound ( k 1 + 1) for TF normalization. However, the other interesting direction, lower-bounding TF ,hasnotbeen well addressed before. Our recent work [11] appears to be the first study that notices the inappropriate lower-bound of TF in BM25 through empirical analysis, but there is no theoretic diagnosis of the problem. Besides, the approach proposed in [11] is not generalizable to lower-bound TF nor-malization in retrieval models other than BM25. In this paper, we extend [11] to show analytically and empirically that lower-bounding TF is necessary for all representative retrieval models and develop a general approach to effec-tively lower-bound TF in these retrieval models.

Document length normalization also plays an important role in almost all existing retrieval models to fairly retrieve documents of all lengths [18, 4], since long documents tend to use the same terms repeatedly (higher TF). For example, both Okapi BM25 [14, 15] and the pivoted normalization retrieval model [18] use the pivoted length normalization schema [18], which uses the average document length as the pivoted length to coordinate the normalization effects for documents longer than this pivoted length and documents shorter than it. The PL2 model, a representative of the di-vergence from randomness models [1], also uses the average document length to control document length normalization. A common deficiency of all these existing length normaliza-tion methods is that they tend to force the normalized TF to approach zero when documents are very long. As a re-sult, a very long document with a non-zero TF could receive a score too close to or even lower than the score of a short document with a zero TF, which is clearly unreasonable. Although some exiting studies have attempted to use a sub-linear transformation of document length (e.g., the squared root of document length [3]) to heuristically replace the orig-inal document length in length normalization, they are not guaranteed to solve the problem and often lose to standard document length normalization such as the pivoted length normalization in terms of retrieval accuracy. Our work aims at addressing this inherent weakness of traditional document length normalization in a more general and effective way.
Constraint analysis has been explored in information re-trieval to diagnostically evaluate existing retrieval models [4, 5], introduce novel retrieval signals into existing retrieval models [19], and guide the development of new retrieval models [6, 2]. The constraints in these studies are basic and are designed mostly based on the analysis of some com-mon characteristics of existing retrieval formulas. Although we also use constraint analysis, the proposed constraints are novel and are inspired by our empirical finding of a common deficiency of the existing retrieval models. Moreover, al-though some existing constraints (e.g., LNCs and TF-LNC in [4, 5]) are also meant to regularize the interactions be-tween TF and document length, they tend to be loose and cannot capture the heuristic of lower-bounding TF normal-ization. For example, the modified Okapi BM25 satisfies all the constraints proposed in [4, 5], but it still fails to lower-bound TF normalization properly. In this sense, the proposed two new constraints are complimentary to existing constraints [4, 5].
In this section, we discuss and analyze a common defi-ciency (i.e., lack of appropriate lower bound for TF normal-ization) of four state-of-the-art retrieval functions, which re-spectively represent the classical probabilistic retrieval model (Okapi BM25 [14, 15]), the divergence from randomness ap-proach (PL2 [1]), the language modeling approach (Dirichlet prior smoothing [20]), and the vector space model (pivoted normalization [18, 17]).

An effective retrieval function is generally comprised of two basic separable components: a within-query scoring for-mula for weighting the occurrences of a term in the query and a within-document scoring formula for weighting the occurrences of this term in a document. We will represent each retrieval function in terms of these two separable com-ponents to make it easier for us to focus on studying the document side weighting: where S ( Q, D ) is the total relevance score assigned to doc-ument D with respect to query Q ,and G (  X  )and F (  X  )are within-query scoring function and within-document scoring function respectively. In Table 1, we show how this general scheme can be used to represent all the four major retrieval models. Other related notations are listed in Table 2. Note that most of the notations were also used in some previous work, e.g., [4], and will be adopted throughout our paper.
The Okapi BM25 method [14, 15] is a representative re-trieval function that represents the classical probabilistic re-trieval model. The BM25 retrieval function is summarized in the second row of Table 1. Following work [4], we modify theoriginalIDFformulaofBM25toavoidtheproblemof possibly negative IDF values. The within-document scoring function of BM25 can be re-written as follows: where k 1 is a parameter, and tfn D t is the normalized TF by document length using pivoted length normalization [18]. where b is the slope parameter in pivoted normalization.
When a document is very long (i.e., | D | is much larger than avdl ), we can see that tfn D t could be very small and approach 0. Consequently, F BM 25 will also approach 0 as if t did not occur in D . It can be seen clearly in Figure 1 (1): when | D 2 | becomes very large, the score difference between D 2 and D 1 appears to be very small. This by itself, would not necessarily be a problem, but the problem is that, the occurrence of t inaverylongdocument D fails to ensure D to be ranked above other documents where t does not occur. It suggests that the occurrences of a query term in very long documents may not be rewarded properly by BM25, and thus those very long documents could be overly penalized, which as we will show later, is indeed true.
The PL2 method is a representative retrieval function of the divergence from randomness framework [1]. In this pa-per, we use the modified PL2 formula derived by Fang et al. [5] instead of the original PL2 formula [1]. The only difference between this modified PL2 function and the orig-inal PL2 function is that the former essentially ignores non-discriminative query terms. It has been shown that the mod-ified PL2 is more effective and robust than the original PL2 [5]. The modified PL2 (still called PL2 for convenience in the following sections) is presented in the third row of Table 1, where  X  t = N c ( t,C ) is the term discrimination value, and tfn D t is the normalized TF by document length: where c&gt; 0 is a retrieval parameter.

We can see that, when a document is very long, tfn D t could be very small and approach 0, which is very similar to the corresponding component in BM25. What is worse is that, when tfn D t is sufficiently small, the within-document score F PL 2 will be a negative number surprisingly. How-ever, as shown in Table 1, even if the term is missing, i.e., c ( t, D )=0, F PL 2 can still receive a default zero score. This interesting observation is illustrated in Figure 1 (2). It sug-gests that a very long document that matches a query term Figure 1: Comparison of the within-document term scores, i.e., F ( term t against different document lengths, where we assume c ( t, D Figure 2: Comparison of retrieval and relevance probabilities against all document lengths when us-ing BM25 on short (left) and verbose (right) queries. may be penalized even more than another document (the length can be arbitrary) that does not match the term; con-sequently, those very long documents tend to be overly pe-nalized by PL2.
The Dirichlet prior method is one of the best performing language modeling approaches [20]. It is presented in the fourth row of Table 1, where  X  is the Dirichlet prior.
It is observed that, the within-document scoring func-tion F Dir is monotonically decreasing with the document length variable. And when a document D 2 is very long, say 50  X  avdl , even if it matches a query term, the within-document score of this term could still be arbitrarily small. And this score could be smaller than that of any average-length document D 1 which does not match the term. This is shown clearly in Figure 1 (3). Thus, the Dirichlet prior method can also overly penalize very long documents.
The pivoted normalization retrieval function [17, 4] repre-sents one of the best performing vector space models. The detailed formula is shown in the last row of Table 1, where s is the slope parameter. Similarly, the analysis of the piv-oted normalization method also shows that it tends to overly penalize very long documents, as shown in Figure 1 (4).
Our analysis above has shown that, in principle ,allthese retrieval functions tend to overly penalize very long docu-ments. Now we turn to seeking empirical evidence to see if this common deficiency hurts document retrieval in practice .
Inspired by Singhal et al. X  X  finding that a good retrieval function should retrieve documents of all lengths with simi-lar chances as their likelihood of relevance [18], we compare the retrieval pattern of different retrieval functions with the relevance pattern. We follow the binning analysis strategy proposed in [18] and plot the two patterns against all docu-ment lengths on WT10G in Figure 2, where the bin size is set to 5000. Due to the space reason, we only plot BM25 as an example. But it is observed that other retrieval func-tions have similar trends as BM25. The plot shows clearly that BM25 retrieves very long documents with chances much lower than their likelihood of relevance. This empirically confirms our previous analysis that very long documents tend to be overly penalized.
A critical question is thus how we can regulate the inter-actions between term frequency and document length when a document is very long so that we can fix this common deficiency of current retrieval models?
To answer this question, we first propose two desirable heuristics that any reasonable retrieval function should im-plement to properly lower bound TF normalization when documents are very long: (1) there should be a sufficiently large gap between the presence and absence of a query term, i.e., the effect of document length normalization should not cause a very long document with a non-zero TF to receive ascoretooclosetoorevenlowerthanashortdocument with a zero TF; (2) a short document that only covers a very small subset of the query terms should not easily domi-nate over a very long document that contains many distinct query terms.

Next, in order to analytically diagnose the problem of over-penalizing very long documents, we propose two for-mal constraints to capture the above two heuristics of lower bounding TF normalization so that it is possible to apply them to any retrieval function analytically. The two con-straints are defined as follows:
LB1: Let Q be a query. Assume D 1 and D 2 are two documents such that S ( Q, D 1 )= S ( Q, D 2 ). If we refor-mulate the query by adding another term q/  X  Q into Q , where c ( q,D 1 )=0and c ( q,D 2 ) &gt; 0, then S ( Q  X  X  q S ( Q  X  X  q } ,D 2 ).

LB2: Let Q = { q 1 ,q 2 } be a query with two terms q 1 and q 2 . Assume td ( q 1 )= td ( q 2 ), where td ( t ) can be any reasonable measure of term discrimination value. If D 1 and D 2 are two documents such that c ( q 2 ,D 1 )= c ( q 2 ,D 2 c ( q 1 ,D 1 ) &gt; 0, c ( q 1 ,D 2 ) &gt; 0, and S ( Q, D 1 )= S ( Q, D S ( Q, D 1  X  X  q 1 } X  X  t 1 } ) &lt;S ( Q, D 2  X  X  q 2 } X  X  t and t 2 such that t 1  X  D 1 , t 2  X  D 2 , t 1 /  X  Q and t
The first constraint LB1 captures the basic heuristic of 0-1 gap in TF normalization, i.e., the gap between presence and absence of a term should not be closed by document length normalization. Specifically, if a query term does not occur in document D 1 but occurs in document D 2 ,andboth documents receive the same relevance score from matching other query terms, then D 1 should be scored lower than D no matter what are the length values of D 1 and D 2 .In other words, the occurrence of a query term in a very long document should still be able to differentiate this document from other documents where the query term does not occur.
In fact, when F (0 , | D | ,td ( t )) is a document-independent constant, LB1 can be derived from a basic TF constraint, TFC1 [4]. Here, F (0 , | D | ,td ( t )) is the document weight for a query term t not present in document D , i.e., t  X  Q but t/  X  D . This property is presented below in Theorem 1.
Theorem 1. LB1 is implied by the TFC1 constraint, if the within-document weight for any missing term is a docu-ment independent constant.
 Proof: Let Q be a query. Assume D 1 and D 2 are two documents such that S ( Q, D 1 )= S ( Q, D 2 ). We reformu-late query Q by adding another term q/  X  Q into the query, where c ( q,D 1 )=0and c ( q,D 2 ) &gt; 0. If D 2 is another document, which is generated by replacing all the occur-rences of q in D 2 with a non-query term t/  X  Q  X  X  q } ,then c ( q,D 2 )=0and S ( Q, D 1 )= S ( Q, D 2 )= S ( Q, D 2 ). Due to the assumption that the document weight for the missing term q is a document independent constant, it follows that S ( Q  X  X  q } ,D 1 )= S ( Q  X  X  q } ,D 2 ). Finally, since | and c ( q,D 2 )=0 &lt;c ( q,D 2 ), according to TFC1, we get S ( Q  X  X  q } ,D 1 )= S ( Q  X  X  q } ,D 2 ) &lt;S ( Q  X  X  q }
However, when the document weights for missing terms are document dependent, LB1 will not be redundant in the sense that it cannot be derived from other constraints such as the proposed LB2 and the seven constraints proposed in [4]. For example, the Dirichlet prior retrieval function, as shown in Table 1, has a document-dependent weighting func-tion for a missing term, which is log  X  | D | +  X  . As will be shown later, the Dirichlet prior method violates LB1, although it satisfies LB2 and most of the constraints proposed in [4].
The second constraint LB2 states that if two terms have the same discrimination value, a repeated occurrence of one term is not as important as the first occurrence of the other. LB2 essentially captures the intuition that covering more distinct query terms should be rewarded sufficiently, even if the document is very long. For example, given a query Q = {  X  X omputer X ,  X  X irus X  } ,iftwodocuments D 1 and D 2 with identical relevance scores with respect to Q both match  X  X omputer X , but neither matches  X  X irus X , then if we add an occurrence of  X  X irus X  to D 1 to generate D 1 and add an oc-currence of  X  X omputer X  to D 2 to generate D 2 , we should ensure that D 1 has a higher score than D 2 . This intuitively makes sense because D 1 is more likely to be related to com-puter virus, while D 2 may be just about other aspects of computer.

LB1 and LB2 are two necessary constraints to ensure that very long documents would not be overly penalized. When either is violated, the retrieval function would likely not per-form well for very long documents and there should be room to improve the retrieval function through improving its abil-ity of satisfying the corresponding constraint.
BM25 satisfies TFC1 [4], and the within-document weight for any missing term is always 0. Therefore, BM25 satisfies LB1 unconditionally according to Theorem 1.
 We now examine LB2. Due to the sub-linear property of TF normalization, we only need to check LB2 in the case when c ( q 1 ,D 1 ) = 1, since when c ( q 1 ,D 1 ) &gt; 1, it is even harder to violate the constraint. Consider a common case when | D 1 | = avdl . It can be shown that the LB2 constraint is equivalent to the following constraint on | D 2 | :
This means that LB2 is satisfied only if | D 2 | is smaller than a certain upper bound. Thus, a sufficiently long doc-ument would violate LB2. Note that the upper bound of |
D 2 | is a monotonically decreasing function with both b and k . This suggests that a larger b or k 1 wouldleadBM25to violate LB2 more easily, which is confirmed by our experi-ments.
In Fang et al. X  X  work [5], the TFC1 constraint is regarded equivalent to that  X  X he first partial derivative of the formula w.r.t. the TF variable should be positive X , which has been shown to be satisfied by the modified PL2 [5]. However, the PL2 function is not continuous when the TF variable is zero, and what is worse is that, which shows that even the modified PL2 still fails to satisfy TFC1. So we cannot use Theorem 1 for PL2.

We thus check both LB1 and LB2 directly. Since the optimal setting of parameter c is usually larger than 1 [4], we consider a common case when | D 1 | = c 3  X  avdl . Similar to the analysis on BM25, we only need to examine LB2 for c ( q 1 ,D 1 ) = 1. The LB1 constraint is approximately equivalent to and LB2 is approximately equivalent to Due to space limit, we cannot show all the derivation details.
We can see that both LB1 and LB2 set an upper bound for document length, suggesting that a very long document would violate both LB1 and LB2. However the upper bound introduced by LB1 is always larger than that introduced by LB2. So we focus on LB2 in the following sections.
The upper bound of document length in LB2 is mono-tonically increasing with both c and  X  t . It suggests that, when c is very small, there is a serious concern that long documents would be overly penalized. On the other hand, a more discriminative term also violates the constraint more easily. These analyses are confirmed by our experiments.
With Dir, the within-document weight for a missing term is log  X  | D | +  X  , which is document dependent. So Theorem 1 is not applicable to the Dirichlet method. We thus need to examine LB1 and LB2 directly.

First, we only check LB1 at the point of c ( q,D 2 )=1, which is the easiest case for LB1 to be violated. By consid-ering the common case that | D 1 | = avdl ,theLB1constraint is equivalent to the following constraint on | D 2 | :
It shows that the Dirichlet method can only satisfy LB1 if |
D 2 | is smaller than a certain upper bound, sugge sting again that a very long document would violate LB1. And this up-per bound is monotonically decreasing with both p ( q | C )and  X  . On the one hand, a non-discriminative (i.e., large p ( q term q violates LB1 easily; for example, if  X   X  p ( q | C )=1,the upper bound appears to be as low as (2  X  avdl +  X  ). Thus, the Dirichlet method would overly penalize very long docu-ments more for verbose queries. On the other hand, a large  X  would also worsen the situation according to Formula 9. These are all confirmed by our experimental results.
Next, we turn to check LB2, which is equivalent to where n  X  X  1 , 2 ,  X  X  X } . Interestingly, this inequality is always satisfied, suggesting that the Dirichlet method satisfies LB2 unconditionally . We thus expect that the Dirichlet method would have some advantages in the cases when other re-trieval functions tend to violate LB2.
It is easy to show that the pivoted normalization method also satisfies LB1 unconditionally.

We now examine LB2. Similar to the analysis on BM25, we only need to check LB2 in the case of c ( q 1 ,D 1 )=1. By considering a common case when | D 1 | = avdl ,weseethat LB2 is equivalent to the following constraint on | D 2 | :
This means that LB2 is satisfied only if | D 2 | is smaller than a certain upper bound. And this upper bound is a monotonically decreasing function with s . So, in principle, a larger s would lead the pivoted normalization method to violate LB2 more easily, which can also explain why the optimal setting of s tends to be small [4]. Of course, if s is set to zero, LB2 would be satisfied, but that would be to turn off document length normalization completely, which would clearly lead to non-optimal retrieval performance.
The analysis above shows analytically that all the state-of-the-art retrieval models would tend to overly penalize very long documents. In order to avoid overly penalizing very long documents, we need to lower-bound TF normalization to make sure that the  X  X ap X  of the within-document scores sufficiently large. However, we do not want that the addi-tion of this new constraint changes the implementations of other retrieval heuristics in these state-of-the-art retrieval functions, because the implementations of existing retrieval heuristics in these retrieval functions have been shown to work quite well [4].

We propose a general heuristic approach to achieve this goal by defining an improved within-document scoring for-mula F as shown in Equation 12, where  X  is a pseudo TF value to control the scale of the TF lower bound, and l is a pseudo document length which is document-independent. In this new formula, a retrieval model-specific, but document-independent value F (  X , l, td ( t ))  X  F (0 ,l,td ( t )) would serve as an ensured  X  X ap X  between matching and missing a term: if c ( t, D ) &gt; 0, the component of TF normalization by doc-ument length will be lower-bounded by such a document-independent value, no matter how large | D | would be.
It is easy to verify that F ( c ( t, D ) , | D | ,td ( t )) is able to satisfy all the basic retrieval heuristics [4] that are satis-if F ( c ( t, D ) , | D | ,td ( t )) satisfies TFCs, F ( c ( t, D ) , constraint in exactly the same way as F ( c ( t, D ) , | D duced components are document-independent, they raise no problem for LNCs and TF-LNC.

The proposed methodology is very efficient, as it only adds a retrieval model specific but document-independent value to those standard retrieval functions. For a query Q ,weonly need to calculate | Q | such values, which can even be done offline. Therefore, our method incurs almost no additional computational cost.

Finally, we can obtain the corresponding lower-bounded retrieval function through substituting F ( c ( t, D ) , | for F ( c ( t, D ) , | D | ,td ( t )) in each retrieval function,
Take BM25 as an example. Obviously F (0 , | D | ,td ( t )) = 0. In F (  X , l, td ( t )), since l is a constant document length vari-able used for document length normalization, its influence canbeabsorbedintotheTFvariable  X  ,wethusset l = avdl Clearly parameter k 1 canalsobeabsorbedinto  X  ,andthe derive a lower-bounded BM25 function, namely BM25+ , as shown in the following Formula 13.
Similarly, we can derive a lower-bounded Dirichlet prior method ( Dir+ ), a lower-bounded pivoted normalization method ( Piv+ ), and a lower-bounded PL2 ( PL2+ ), which are pre-sented in Formulas 14, 15, and 16 respectively.

Next, we check LB1 and LB2 on these four improved re-trieval functions.
It is trivial to verify that BM25+ still satisfies LB1 uncon-ditionally. To examine LB2, we apply an analysis method that is consistent with our analysis for BM25 in Section 5.1. The LB2 constraint on BM25+ is equivalent to which can be shown to be satisfied unconditionally if
Clearly, if we set  X  to a sufficiently large value, BM25+ is able to satisfy LB2 unconditionally, which is also confirmed in our experiments that BM25+ works very well when we set  X  =1.
We only need to check LB2 on PL2+, since it is easier to violate than LB1. With a similar analysis strategy as used for analyzing PL2, the LB2 constraint on PL2+ is equivalent to cannot show all the derivation details in this section.
We can see that, given a  X  , the right side of the Formula 19 (i.e., the upper bound of | D 2 | ) is minimized when  X  1 . 73  X   X  0 . 27 . This suggests that, in contrast to PL2, the upper bound of | D 2 | is not monotonically decreasing with  X  t interesting difference is shown clearly in Figure 3. Thus, if we set  X  to an appropriate value to make the minimum upper bound still large enough (e.g., larger than the length of the longest document), PL2+ would not violate LB2.
It is easy to show that Dir+ also satisfies LB2 uncondi-tionally. We analyze Dir+ in the same way as analyzing Dir, and obtain the following equivalent constraint of LB1: We can see that, although Dir+ does not guarantee that LB1 is always satisfied, it indeed enlarges the upper bound of document length as compared to Dir in Section 5.3, and thus makes the constraint harder to violate. Generally, if we set  X  to a sufficiently large value, the chance that very long documents are overly penalized would be reduced. Figure 3: Comparison of upper bounds of document length in PL2 and PL2+ to satisfy LB2.
 It is easy to verify that Piv+ also satisfies LB1. Regarding LB2, similar to our analysis on Piv, the LB2 constraint on Piv+ is equivalent to which is always satisfied if This shows that Piv+ can be able to satisfy LB2 uncondi-tionally with a sufficiently large  X  .
We use four TREC collections: WT2G, WT10G, Ter-abyte, and Robust04, which represent different sizes and genre of text collections. WT2G, WT10G, and Terabyte are small, medium, and large Web collections respectively. Ro-bust04 is a representative news dataset. We test two types of queries, short queries and verbose queries, which are taken from the title and the description fields of the TREC top-ics respectively. We use the Lemur toolkit and the Indri search engine (http://www.lemurproject.org/) to carry out our experiments. For all the datasets, the preprocessing of documents and queries is minimum, involving only Porter X  X  stemming. An overview of the involved query topics, the average length of short/verbose queries, the total number of relevance judgments, the total number of documents, the average document length, and the standard deviation of doc-ument length in each collection are shown in Table 3.
We employ a 2-fold cross-validation for parameter tuning, where the query topics are split into even and odd number topics as the two folds. The top-ranked 1000 documents for each run are compared in terms of their mean average precisions (MAP), which also serves as the objective function for parameter training. In addition, the precision at top-10 documents (P@10) is also considered. Our goal is to see if the proposed general heuristic can work well for improving each of the four retrieval functions.
In both BM25+ and BM25, we train b and k 1 using cross validation, where b is tuned from 0 . 1to0 . 9inincrements of 0 . 1, and k 1 is tuned from 0 . 2to4 . 0inincrementsof 0 . 2. Besides, in BM25+, parameter  X  is trained using cross validation, where  X  is tuned from 0 . 0to1 . 5inincrementsof 0 . 1, but we also create a special run in which  X  is fixed to 1 . 0 empirically (labeled as BM25+ (  X  =1 . 0)). The comparison results of BM25+ and BM25 are presented in Table 4.
The results demonstrate that BM25+ outperforms BM25 consistently in terms of MAP and also achieves P@10 scores better than or comparable to BM25. The MAP improve-ments of BM25+ over BM25 are much larger on Web collec-tions than on the news collection. In particular, the MAP improvements on all Web collections are statistically signif-icant. This is likely because there are generally more very long documents in Web data, where the problem of BM25, i.e., overly-penalizing very long documents, would presum-ably be more severe. For example, Table 3 shows that the standard deviation of the document length is indeed larger on the three Web collections than on Robust04.

Another interesting observation is that, BM25+, even with afixed  X  =1 . 0, can still work effectively and stably across collections and outperform BM25 significantly. This empir-ically confirms the constraint analysis results in Section 6.1 ally. It thus suggests that the proposed constraints can even be used to guide parameter tuning.

We further plot the curves of MAP improvements of BM25+ over BM25 against different  X  values in Figure 4, which demonstrates that, when  X  is set to a value around 1 . 0, BM25+ works very well across all collections. Therefore,  X  can be safely  X  X liminated X  from BM25+ by setting it to a default value 1 . 0.

Regarding different query types, we observe that BM25+ improves more on verbose queries than on short queries. For example, the MAP improvements on Web collections are of-ten more than 5% for verbose queries and are around 2% for short queries. We hypothesize that BM25 may overly-
Table 5: Optimal settings of b and k 1 in BM25. Figure 5: Comparison of retrieval and relevance probabilities against all document lengths when us-ing BM25 (left) and BM25+ (right) for retrieval. It shows that BM25+ alleviates the problem of BM25 that overly penalizes very long documents. penalize very long documents more seriously when queries are verbose, and thus there is more room for BM25+ to boost the performance. To verify our hypothesis, we collect the optimal settings of b and k 1 for BM25 in Table 5, which show that the optimal settings of b and k 1 are clearly larger for verbose queries than for short queries. Recall that our constraint analysis in Section 5.1 has shown that the like-lihood of BM25 violating LB2 is monotonically increasing with parameters b and k 1 . We can now conclude that BM25 indeed tends to overly penalize very long documents more when queries are more verbose.
 So far we have shown that BM25+ is more effective than BM25, but if it is really because BM25+ has alleviated the problem of overly-penalizing very long documents? To an-swer this question, we plot the retrieval pattern of BM25+ as compared to the relevance pattern in a similar way as we have done in Section 3.2. The pattern comparison is pre-sented in Figure 5. We can see that the retrieval pattern of BM25+ is more similar to the relevance pattern, especially Table 6: Comparison of PL2 and PL2+ using cross validation. Superscripts 1 / 2 / 3 / 4 indicate that the corresponding MAP improvement is significant at the 0 . 05 / 0 . 02 / 0 . 01 / 0 . 001 level using the Wilcoxon test. for the retrieval of very long documents. This suggests that BM25+ indeed retrieves very long documents more fairly.
In both PL2+ and PL2, we train parameter c using cross validation, where c is tuned from 0 . 5to25(27values).Be-sides, in PL2+, parameter  X  is also trained using cross vali-dation, where  X  is tuned from 0 . 0to1 . 5inincrementsof0 . 1. Also we create a special run of PL2+ in which  X  is fixed to 0 . 8 empirically without training. The comparison results of PL2+ and PL2 are presented in Table 6.

The results show that PL2+ outperforms PL2 consistently, and even if we fix  X  =0 . 8, PL2+ can still achieve stable improvements over PL2. Specifically, PL2+ improves signif-icantly over PL2 for about 10 % on verbose queries, yet it only improves slightly on short queries; PL2+ appears to be less sensitive to the genre of collections, since it also improves significantly over PL2 on news data (verbose queries). We hypothesize that, PL2 may overly-penalize very long docu-ments seriously on verbose queries but works well on short queries, and thus there is more room for PL2+ to improve the performance on verbose queries than on short queries. To verify it, we collect the optimal settings of c in PL2 and show them in Table 7. We can see that the optimal settings of c are  X  X uge X  for short queries as compared to that for ver-bose queries, presenting an obvious contrast. As a result, recalling the upper bound of document length in Formula 8, Table 8: Comparison of Dir and Dir+ using cross validation. Superscripts 1 / 2 / 3 / 4 indicate that the corresponding MAP improvement is significant at the 0 . 05 / 0 . 02 / 0 . 01 / 0 . 001 level using the Wilcoxon test. verbose queries would be more likely to violate LB2 even if a document is not very long (e.g., a news article), while short queries would only have a very small chance to violate LB2 even if a document is very long. Again, we can see that our constraint analysis is consistent with empirical results.
In both Dir+ and Dir, we train parameter  X  using cross validation, where  X  is tuned in a parameter space of 12 values from 500 to 10000. Besides, in Dir+, parameter  X  is also trained, the candidate values of which are from 0 . 0to0 . 15 in increments of 0 . 01. Similarly, we also create a special run in which  X  is fixed to 0 . 05 empirically without training. The comparison of Dir+ and Dir is presented in Table 8.
Overall, we observe that Dir+ improves over Dir consis-tently and significantly across different collections, and even if we fix  X  =0 . 05 without training, Dir+ can still outperform Dir significantly in most cases. Note that, similar to BM25+ and PL2+, Dir+ works more effectively on verbose queries, which is consistent with our constraint analysis that Dir is more likely to overly penalize very long documents when a query contains more non-discriminative terms. In addition, we further compare Dir+ and Dir thoroughly by varying  X  from 500 to 10000. It shows that Dir+ is consistently better than Dir no matter how we change the  X  value.

Moreover, comparing Table 8 with Table 4 and 6, we can see that Dir works clearly better on verbose queries than BM25 and PL2. One possible explanation is that Dir satis-fies LB2 unconditionally, but BM25 and PL2 do not.
In both Piv+ and Piv, we train s using cross-validation, where s is tuned from 0 . 01 to 0 . 25 in increments of 0 . 02. Table 9: Comparison of Piv and Piv+ using cross validation. Superscripts 1 indicates that the corre-sponding MAP improvement is significant at the 0 . 05 level using the Wilcoxon test.
 Besides, in Piv+, parameter  X  is also trained, the candidate values are from 0 . 0to1 . 5inincrementsof0 . 1. The compar-ison results of Piv+ and Piv are presented in Table 9.
Unfortunately, Piv+ does not improve over Piv signifi-cantly in most of the cases, which, however, is also as we expected: although there is an upper bound of document length for Piv to satisfy LB2 (as shown in Formula 11), this upper bound is often very large because the optimal setting of parameter s is often very small as presented in Table 10. Nevertheless, Piv+ would work much better than Piv when s is large, as observed in our experiments.
Our experiments demonstrate empirically that, the pro-posed general methodology can be applied to state-of-the-art retrieval functions to successfully fix or alleviate their problem of overly-penalizing very long documents.
We have derived three effective retrieval functions, BM25+ (Formula 13), PL2+ (Formula 16), and Dir+ (Formula 14). All of them are as efficient as but more effective than their corresponding standard retrieval functions, i.e., BM25, PL2, and Dir, respectively. There is an extra parameter  X  in the derived formulas, but we can set it to some default values (i.e.,  X  =1 . 0 for BM25+,  X  =0 . 8 for PL2+, and  X  =0 . 05 for Dir+), which perform quite well. The proposed retrieval functions can potentially replace its corresponding standard retrieval functions in all retrieval applications.
In this paper, we reveal a common deficiency of the current retrieval models: the component of term frequency (TF) normalization by document length is not lower-bounded prop-erly; as a result, very long documents tend to be overly-penalized. In order to analytically diagnose this problem, we propose two desirable formal constraints to capture the heuristic of lower-bounding TF, and use constraint analy-sis to examine several representative retrieval functions. We find that all these retrieval functions can only satisfy the constraints for a certain range of parameter values and/or for a particular set of query terms. Empirical results further show that the retrieval performance tends to be poor when the parameter is out of the range or the query term is not in the particular set. To solve this common problem, we propose a general and efficient method to introduce a suf-ficiently large lower bound for TF normalization which can be shown analytically to fix or alleviate the problem.
Our experimental results on standard collections demon-strate that the proposed methodology, incurring almost no additional computational cost, can be applied to state-of-the-art retrieval functions, such as Okapi BM25 [14, 15], language models [20], and the divergence from randomness approach [1], to significantly improve the average precision, especially for verbose queries. Our work has also helped re-veal interesting differences in the behavior of these state-of-the-art retrieval models. Due to its effectiveness, efficiency, and generality, the proposed methodology can work as a  X  X atch X  to fix or alleviate the problem in current retrieval models, in a plug-and-play way.
We thank the anonymous reviewers for their useful com-ments. This material is based upon work supported by the National Science Foundation under Grant Numbers IIS-0713581, CNS-0834709, and CNS 1028381, by NIH/NLM grant 1 R01 LM009153-01, a Sloan Research Fellowship, and a Yahoo! Key Scientific Challenge Award.
