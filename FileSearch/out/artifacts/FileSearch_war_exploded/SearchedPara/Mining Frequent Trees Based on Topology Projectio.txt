 Frequent patterns mining is an important problem in data mining domain. It involves mining transactions, sequences, trees and graphs. Methods for mining frequent trees are widely used in domains like bioinformatics, web-mining, chemical compound structure mining, and so on. For instance, in web usage mining, it can be used to mine user access patterns from web logs and mine useful information from hyperlinks, and it can also be used to mine common tree structures from XML documents. In bioinformatics, researches can find important topology from known RNA structure and use this information to analyses new RNA structure. 
Frequent tree discovery has been studied popularly in recent years. Most of them are reminiscent of the level-wise Apriori [1,2] approach: Wang and Liu developed an algorithm to mine frequent subtrees in XML documents [3]; Asai presented FREQT method for mining frequent labeled ordered trees [7]; Chi proposed FreeTreeMiner algorithm for mining free unordered trees[4]. An apriori heuristic is used to reduce the number of candidate patterns: every sub-pattern of a frequent pattern is also frequent. Whereas, as indicated in previous itemset mining [5], if there are many complex which degrades performance dramatically. Furthermore, their work deals with traditional induced subtrees. 
Zaki and Asai respectively proposed a very useful rightmost expansion schema to generated candidate tree patterns [6,7]. In [6], Zaki presented two algorithms, TreeMiner and PatternMatcher, for mining embedded subtrees from ordered labeled trees. PatternMatcher is a level-wise algorithm similar to Apriori. TreeMiner performs scope-list, for fast support counting. TreeMiner is the fastest method among the published method to mine embedded subtrees. Whereas, using intersection of scope-list to count support is still a bottleneck of this method. 
Researches have indicate that depth-first search based, pattern growth method, such as FP-growth [5], H-mine [8], for frequent itemset mining, and PrefixSpan [9] for sequential pattern mining, be very efficient for mining frequent patterns. Our previous work also found that method based on static IS+-tree [10] was more efficient than that based on dynamic created FP-trees. Then, with combination of pattern growth method mining frequent tree patterns? 
In this paper, we systematically study the problem of frequent tree pattern mining and develop a novel and efficient algorithm, TG to tackle this problem. The key contributions of our work are as follows: (1) We introduce array-based method to represent trees and forest in order to (2) The rightmost path expansion method is assimilated in our approach to form the (3) We develop a framework to form the projected database systemically at every (4) We design and implement a novel method, TG, for frequent embedded subtrees. We contrast TG with TreeMiner and experimental results show that TG outperforms TreeMiner by a factor of 4-15 while the mining results are the same. number of nodes in T , denoted as |T| . A collection of trees is a forest. A database D is just a forest. When r is not unique, it X  X  a free tree , which we do not deal with in this paper. u a node order number, according to its position in the pre-order traversal of the tree. If the last node of T(r) is w according to its node order, the path from r to w is called the scope of node u contains all its descendants. The concepts of rightmost path and the scope interval play an important role in constructing topology projection. embedded subtrees. A tree with k nodes denoted as a k -tree. Usually, S is a pattern we mapping node u X   X  N in T . All the mapping nodes of S in T are called an occurrence of S in T. Given a tree database D , the support of a tree T is the number of trees in D such that SUP w (S) = weighted support means the percentage of the number of all occurrences of S over the total number of trees in D . i.e., sup w (S)=SUP w (S) / D . Definition 1 (Frequent tree). Given a minimum support threshold  X  , a tree S is called a frequent tree pattern if sup(S)  X   X  , or for some other users, sup w (S)  X   X  . growth method is transforming the problem from mining frequent patterns to finding generate a unique new pattern. Whereas, a tree can has many nodes with same label, and tree X  X  topology makes it have many possible growing points, and adding one node at different growing point will generate different trees. Thus, it is a non-trivial work to determine a correct and efficient pattern growth framework to mining frequent trees. There are three obstacles of using pattern growth method for mining frequent trees: method? Secondly, how to form a complete and non-redundant pattern growth space? Thirdly, how to grow a frequent k -tree pattern into frequent ( k+1 )-tree patterns? 3.1 Topology Encodings of T rees and ForestAccess the Springer There are two schemes to construct project ed database. One is to reallocate space dynamically for it,, where there are no useless nodes in it. The other is that the projected previous study shows that the later is more efficient both for space and time [10]. TG adopts static projection method. Since array has the good property of random access, a array-based topology encoding method of trees and forest is presented in this paper. Definition 2 (Topology Sequence). Given a tree T(r) , a label sequence can be constructed by arrange the node label in node order. We refer to a label sequence added with extra level information as topology sequence. Let the last node of T(r) is w , then top(T) . Property 1 (Rightmost Path). Let top(T) refer to the topology sequence of T(r) , and path of T(r) . Lemma 1 (The uniqueness of topology sequence). Given a tree T 1 ( r 1 , N 1 , B 1 ) and a tree T function f  X  N 1  X  N 2 , for each node u  X  N 1 , having u = f(u) and l u  X  l f(u) . Example 1  X  Figure 1 shows a database D used throughout the paper as a sample database. The labels of each tree taken from a set L ={ A,B,C,D }. We use n i to denote the ( n n 2 n 3 ), in T 3 is ( n 3 n 5 n 6 ). If sup=2, then S is a frequent subtree in D . 
As scope interval plays important role in constructing projection, it was added into the denotation of a node, in order to be computed once and used everywhere. For scope the l = i +1. Thus, we can only record r . Definition 2 (Topology Encoding). The definition of topology encoding is as follows: (1) Each node of a tree consists of three fields: label , level , and scope (equal to r ). (2) A tree is an array of nodes. The subscription associated with a node implies its node (3) A forest is an array of trees. 3.2 Construct Pattern Growth Space Using Rightmost Path Expansion Users enumeration search space [6,7]. The method adds new nodes only on the nodes of the rightmost path of a tree. They had proved that the enumeration space is complete and A non-redundant. Whereas, in [6,7], the rightmost path expansion method is used to generate candidate patterns. Totally different with that, we use rightmost path rightmost path. number of growing point is, g =| p |. Lemma 2 (The completeness of pattern growth space). Suppose T(r) is a frequent by adding child node on some node of its rightmost path of S(r s ) . obtained by downward growing of some frequent 1-subtree. Suppose when n = k -1, the lemma holds. For the induction, when n=k , by pre-order traversing T(r) , we get the last some node of the rightmost path of a ( k -1)-subtree, otherwise, w can X  X  be the last node can get that unique frequent ( k -1)-subtree. 3.3 Pattern Growth Framework Based on Topology Projection Definition 5 (Projection and projected database). Suppose S(r s ) be a frequent path of S(r s ) is p . Then: (1) For downward growing point w , the projection at w of S(r s ) on T(r) is determined 
The set of all pieces of projections at growing point p(i) forms the projected database at p(i) of S(r s ) . downward grow into &lt;B0A1X2&gt;, and rightward grow into &lt;B0A1X1&gt;, where X denotes any possible label. Based on the definition of topology projection, the projected database of the later one is the parts under the arc in T 1 and T 2 . 
Whereas, how to handle the cases where a subtree S has multiple occurrences in some T tree in D  X  The key to handle repetitive labels in projected database is: when once if their tree ID is the same. However, the algorithm should record every occurrence of it in order to project it later; otherwise, information of some pattern may be lost. The case of weighted support is an easier context where each associated counter is just simply accumulated when meets a label. Definition 6 (A framework of Pattern Growth) For a ( k -1)-subtree pattern S(r s ) ready to grow, its rightmost path p is first determined based on its topology structure; for each growing point p(i) on p , each projection of p(i) is determined by occurrences of S(r s ) ; then, all pieces of projection form the projected database at p(i) . The problem of mining frequent subtree is then transformed to finding frequent nodes in the projected database at p(i) of S(r s ) . Let the number of all frequent nodes in projected database be m  X  if each of them is added at p(i) and become its child node, then S(r s ) grow into m framework of frequent subtree pattern growth based on to pology projection . A A: 3, 4 B: 3, 7 C: 3, 4 D: 3, 4 refer to the rightmost path. Circles with shadow denote projected database. Pattern growth is started with frequent nodes in D , which form frequent 1-subtrees. Adding all frequent k -subtrees. TG Algorithm tries to use pattern growth method to mine frequent embedded subtrees in pattern growth space. 
It X  X  clear that in order to get the projected database at any growing point of a frequent tree ready to grow, the algorithm should record following information: (1) the position and scope of any node of any tree in the forest; (2) the support and topology structure of a pattern and a list of all its occurrence. The first kind of information is recorded in topology encodings of trees and forest. The second kind of information is recorded in a concise structure called header table. The entries in the header table record all frequent nodes and their (weighted) supports in the projected database, pointing the lists of their occurrence by link. For example, in sample database D , let sup =2. At beginning, the pattern ready to grow is  X  , its head table is just like figure 5-(a). It includes four frequent nodes. 
For each frequent ( k -1)-subtree S ready to grow, the algorithm first determines its rightmost path p based on its topology structure. Then it creates a header table for every &lt;B0&gt; can be induced. The algorithm uses two-scan strategy to fill this header table. In the first scan, the supports are counted, and all frequent nodes are found and are filled in header table. At the same time, the occurrence list of each entry is filled. In the end, each entry in the header table is added at the grow point of &lt;B0B1&gt; and become the rightmost node of a new frequent pattern which ready to grow. 
The header table structure can be more conc ise. Since in the recursive procedure of algorithm, only the rightmost path of a tree plays role, the algorithm can only record the mapping nodes on the rightmost path. Based on above analyse, we presents algorithm TG. Algorithm: TG ( D ,  X  ) Input: Database D ; the minimum support  X  Output: All frequent subtrees in D Steps: begin end Function: TreeGrow ( header ) begin for each growing point of P , do: end 
The completeness of algorithm TG can be proved. It is omitted for limited space. In this section, we compare the performance of TG with TreeMiner. All experiments are performed on a 466-MHz Celeron PC with 256 megabytes main memory, running on Windows XP. All programs are written in C++ with STL and compiled by visual C++ .net. We get the source code from the author of TreeMiner. After trivially modified, we recompiled it by visual C++ .net. 5.1 Synthetic Datasets We wrote a synthetic data generation program to output all the test data. There are 5 one node in the tree to generate children, ( P ); the data size of synthetic trees, ( N ); the actual height of each tree is determined by the Gaussian distribution having the average of H, and the standard deviation of 1. The default parameters are: S = 100, p = 0.5, L = 10, N = 10000, H = 8, F = 6. In order to compare with TreeMiner, the format of original dataset is the same as [5]. The algorithm transforms it to topology sequence encodings after reading it. 5.2 Performance Comparison Figure 5 shows the experimental result, TreeMiner called TM for short. Except for figure 5-(f), Y axes figures have been processed as logarithm. 
At first, we consider the performance variance with descending minimum support of the two algorithms. Figure 5(a) shows the result, where  X  is set from 0.02 to 0.003, and all other parameters are set to default value. In this case, TG is about 5 to 8 times faster than TreeMiner. 
Figure 5(b) shows how the algorithms scale with increasing number of trees in the database D , which changes from 10,000 to 50,000 trees, with other parameter in default value and  X  with 0.01. The running time of both algorithms increases linearly, though TG continues to be 5 to 10 times faster than TreeMiner. Figure 5(c) and figure 5(d) show how the algorithm performs with variant tree size. fanout from 4 to 7,  X  with 0.01 and other parameter in default value, as shows in figure 5(c). In the beginning, both algorithms have good performance. With the growth of fanout, the performance margin between them becomes wider and wider. When F=7, TG is 15 times faster than TreeMiner. If we vary the average height of trees with other parameters in default value, as figure 5(d) shows, we get similar result. When H=9, TG is 10 times faster than TreeMiner. It X  X  outstanding that when the fanout changes from 6 Comparing the numbers of frequent patterns at those cases, as figure 5(e) and figure 5 (f) show, we found that the numbers increase sharply from 12081 to 170688, and from 41971 to 126018, and most of them are very complex. Thus we expect that TG will outperform TreeMiner by a wider and wider margin if the tree size becomes larger. 5.3 Result Analysis These experiments clearly indicate the superiority of pattern growth method based on topology projection for mining frequent trees, especially as patterns become long and complex. There exist three main reasons for this: Firstly, array-based representation of determining the static projected database; Secondly, the search space is non-redundant; recording position, which greatly reduces the complexity of the algorithm. 
Note that both TG and TREEMINER are memory-based mining method. TG needs transform the original database into topology encodings, which are static structures and Header table is a dynamic structure, whose size is proportion to search depth, that is, the size of the pattern. TREEMINER should create a scope list for each node, which is a static data structure, and its size is as much as a copy of database. In addition, in the process of depth-first search, it generates dynamic scope list for candidate patterns, just like header table. Experimental results show that the two algorithms spend similar amount of memory. We present a efficient pattern growth algorithm based on topology projection for mining frequent embedded subtrees. Experimental results show it is efficient both for space and time. 
Whereas, when potential frequent tree patterns are very complex, the users are often confused by the significant magnitudes of complete set of frequent patterns. One solution is to mine frequent maximal trees or frequent closed trees. A tree pattern M is called maximal if there does not exist a super set M X  of M  X  that M X  is also frequent. A support. All frequent patterns can be deduced from max mal frequent patterns, and frequent closed patterns have same power as complete frequent patterns. The number of maximal or closed patterns can be orders of magnitude smaller. It X  X  a challenge to mine maximal or closed embedded subtree patterns. Method form mining frequent has been successfully used in classifying XML documents [14]. Yan has adopted frequent structure-based approach for graph index and query, which achieves good performance querying XML document.
 Acknowledgements. We would like to express our thanks to Mr. Zaki for his sending us the source code of TreeMiner. 
