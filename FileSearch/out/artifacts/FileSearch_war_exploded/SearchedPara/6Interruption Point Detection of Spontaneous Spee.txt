 Spontaneous speech is a fundamental means of communication by human beings. With the exponential growth in computing power and progress in speech recognition technology, high-performance automatic speech recognition (ASR) has been achieved for read speech. However, the recognition performance for read speech differs greatly from that for spontaneous speech. One important feature of spontaneous speech is disfluency, which is inevitable because humans make utterances while thinking about what to say, and the processing pipeline is commonly clogged. Speakers prolong the pronunciation of fillers (e.g.,  X  X H X  and  X  X M X ) as they maintain their turn to speak. Spontaneous speech usually includes several forms of disfluencies, including interrup-tions, corrections, and ungrammatical sentences. Such disfluencies are handled easily by human listeners but their presence makes the transcriptions of spontaneous speech useless for most relevant applications, such as automatic terminal information service. Therefore, the detection of disfluencies is an important research topic. A famous work-shop, The Rich Transcription (RT) Evaluation Project, which was conducted by the National Institute of Standards and Technology (NIST), provides rich corpora for a public exercise to evaluate the current state-of-the-art technologies in automatic speech transcription. The ultimate goal of this exercise series is to evaluate  X  X ich transcription X  X  X  process that not only converts audio into a stream of words, but also captures other information such as disfluencies in spontaneous speech.

Rich transcription is expected to make speech transcriptions more useful to both human beings and downstream process [Banerjee 2009]. Based on Simple Metadata (SimpleMDE) Annotation Specification [Strassel 2004], edit disfluency refers to por-tions of speech in which the speaker X  X  utterance is not complete or fluent; rather, the speaker corrects or alters the utterance, or abandons it entirely and starts over. Edit disfluency is classified into the following two broad categories. (1) Fillers, including filled pauses (e.g.,  X  X M X  and  X  X H X ) and discourse markers (e.g., (2) Edit disfluencies, including repair, repetition, and restart, by which speakers try Fillers can be recognized as individual words in input speech. Edit disfluencies, in contrast, are difficult to deal with. They are illustrated in repetition: The speaker repeats one or more words or a portion of an utterance in a way that is not justifiable by grammar rules, as shown in Figure 1(b). (1) Repair: A corrected portion replaces the abandoned constituent to modify its mean-(2) Restart: The speaker abandons an utterance or a constituent and then starts again Clearly, edit disfluencies have a more complex internal structure than fillers. A tem-plate of edit disfluency, comprising four essential components: reparandum, interrup-tion point (IP), editing term, and correction, can be represented as:
In this representation, an IP, indicated by  X   X   X , is the point at which speakers inter-rupt the original utterance and then repeat, repair, or restart their utterances. The reparandum is the portion of the utterance that precedes the IP and will be corrected or abandoned wholly. Since the IP is the point at which the speaker breaks off the reparandum with an edit disfluency, this portion will be discarded when disfluencies are removed in a cleaned-up transcription. In the template, the original utterance is indicated by parentheses. The editing term is optional and comprises one or more par-ticles such as  X  X n X  and  X  X h X . The correction is the part of the utterance that corrects the original reparandum and will remain following the transcript has been cleaned up. Of these components, the IP is the key feature in disfluent speech detection and recognition. In the above examples, an ill-formed structure in a sentence usually wors-ens the recognition performance for applications. Therefore, IP detection is useful for obtaining important information for disfluent speech recognition.

Research on automatic disfluency detection can be divided into two categories ac-cording to the knowledge sources employed X  X  text-based approach and an approach that uses textual and acoustic information. Bear et al. [1992] proposed a two-stage method of the first category for processing speech repair. The lexical pattern matching approach integrating information such as syntactic, semantic, and acoustics provided reasonable coverage of repair types but only detected speech repairs with predefined patterns. Charniak and Johnson [2004] proposed a language model (LM)-based approach to detecting speech repair in all instances. Core and Schubert [1999] proposed a framework for handling speech with repairs. A parser, based on gram-mar and syntactic structure, can correct some errors following repair identification. Heeman and Allen [1999] proposed a statistical LM, which identifies part-of-speech tags, discourse markers, speech repairs, and intonational phrases. Yeh et al. [2007] used a CRF-based clean-up language model (LM) to correct disfluent speech. Nakatani and Hirschberg [1994] presented the  X  X epair interval model X  of the second category using acoustic-prosody cues, relying less on word transcription. They utilized hand-transcribed prosodic-acoustic features such as duration of silence, energy, and pitch. Snover et al. [2004] employed transformation-based learning for detecting disfluencies based on the assumption that most disfluencies can be detected using lexical features with limited prosodic features. Shriberg et al. [2000] conducted experiments on dis-fluency detection using a prosody model, an LM, and a combination of the two. They found that the prosody model alone outperformed an LM in detecting false starts. Kim et al. [2004] applied a decision tree to obtain structural metadata. Liu et al. [2006] fo-cused on the automatic detection of several helpful structure events in speech. Several methods, including hidden Markov Model (HMM), Maximum Entropy (MaxEnt) and CRF for combining knowledge sources involving both textual information and prosodic cues, were examined. An early work on the detection of edit disfluency [Yeh and Wu 2006] used a Gaussian mixture model (GMM) to develop potential IP hypotheses for the duration of silences and a cleanup LM with an alignment model between deletable region and correction part for correction. Lin and Lee [2009] proposed a latent prosodic model, borrowing heavily from probabilistic latent semantic analysis (PLSA), to detect edit disfluencies in the transcription of spontaneous Mandarin speech. Liang et al. [2008] used the CRF to model the prosodic feature sequence for detecting IPs without transcription. Recently detection-based ASR [Lee 2004] has been proposed to address some of the limitations of HMM-based ASR and bridge the significant gap between the recognition performance of read speech and that of spontaneous speech. In this field, a bank of speech event detectors provides an opportunity to effectively and method-ically incorporate expertise of linguistics and acoustic phonetics into speech recogni-tion. When the IP position has been detected using detection-based ASR, the reparan-dum term can be corrected to the correction term using the alignment model [Yeh and Wu 2006].

This work concerns the speech event detection of the interruption points based on inter-syllable boundary-based prosodic features for further rich transcription for spon-taneous speech recognition. The first process is to obtain the inter-syllable boundaries using the combined acoustic models (AMs) and the recognition confidence of the ASR output. Next, a probability distribution of the prosodic features is estimated at the current potential IP, which is an inter-syllable boundary. The CRF model, which uses the clustered prosodic feature sequence, outputs the IP likelihood. To eliminate the problem of using these prosodic features in the feature functions of CRF, various clus-tering algorithms are employed to cluster the scattered prosodic features into clustered prosodic features for modeling. Finally, the recognition confidence, the probability dis-tribution of the prosodic features and the CRF-based IP likelihood are integrated to determine the optimal IP sequence. Pitch reset and lengthening information are fur-ther exploited to improve the IP detection performance.

The rest of this article is organized as follows. Section 2 briefly introduces a framework of the proposed approach. Section 3 applies various clustering algorithms to cluster the prosodic features for the CRF. Both confidence degree of recognized speech and probability distribution of prosodic features are also described in Section 3. Section 4 presents the experiments that were performed to evaluate the proposed model. Finally, Section 5 draws conclusions. Figure 2 presents an overview of the framework for the proposed probabilistic IP detection model. This framework focused on three major components, illustrated as parallelograms: recognition confidence, probability distribution, and CRF-based IP likelihood measure. These three measures will be combined in a probabilistic model to determine the IP output. First, in the detection procedure, the combined AMs are constructed considering subsyllable and syllable recognition units for recognition con-fidence estimation of spontaneous speech. Second, in the probabilistic IP detection model, the probability distribution of the observed prosodic features is estimated at the hypothesized IP position. The Praat tool [Boersma and Weenink 2009], which is a well-known scientific software for analyzing speech phonetics, is used to extract approximately 200 prosodic features consisting of pitch-related, duration-related, and energy-related features of the speech signals in an empirically optimized window of 400ms, centered at each inter-syllable boundary [Huang et al. 2006]. The prosodic features for the preceding and succeeding inter-syllable boundaries of the current po-tential IP are also extracted as a prosodic feature set. In contrast to the decision tree approach [Liu et al. 2006], a feature transformation approach, based on such cluster-ing algorithms as K -means and Fuzzy c -means [Duda et al. 2001], is developed. The clustering algorithms are employed to transform the scattered prosodic features into clustered prosodic features for CRF modeling. Thirdly, the CRF model is employed to provide a measure of the likelihood for an hypothesized IP at inter-syllable boundaries, based on the sequence of prosodic features. Finally, the confidence of the recognized speech, the probability distribution of the prosodic features, and the CRF X  X ased IP likelihood are combined to determine the optimal IP sequence output over all possible IP sequences, given the input speech. The goal of this article is to determine the optimal interruption point sequence IP * over all possible IP sequences, given input speech X . If the IP sequence is represented as speech events embedded in X , then IP can be detected using the joint probability of IP sequence and the input speech: where IP i denotes the i -th possible IP sequence, obtained from the i -th possible syllable sequence S i , over all possible IP sequences, denoted as IP . Mandarin speech is a syllabic language, and each syllable comprises two subsyllables X  X n optional Initial (consonant) followed by a Final (vowel). Therefore, in the detection process, a speech signal X is represented by the acoustic feature sequence A and the i -th recognized syllable sequence S i in all possible syllable sequences, denoted as S . Accordingly, the recognized syllable sequence S i and acoustic feature sequence A are substituted for the speech signal X in the following equation, rewritten from Equation (1). After the information on the inter-syllable boundary has been obtained from the recog-nizer, the prosodic features of the speech signals within a window of 400ms centered at an inter-syllable boundary are extracted. The prosodic feature sequence F i of the i -th syllable sequence S i consists of the extracted prosodic features that are estimated at the inter-syllable boundaries before and after the current candidate IP position in the input speech X . Hence, Equation (2) is modified as: The joint probability can be re-written using the following equation, based on the chain rule in probability theory.
 The acoustic features A are assumed to be represented by the recognized syllable se-above equation can thus be simplified, such that the above equation becomes where P ( IP i | S i , F i ) represents the conditional probability of the IP sequence given the syllable sequence S i and the prosodic feature sequence F i ; P ( F i | S i ) is the con-ditional probability of prosodic feature sequence F i given the syllable sequence S i , and P ( S i | A ) is the confidence in the recognized speech, given the acoustic feature sequence A . In practical implementation as shown in Figure 2, the N -best syllable sequences are first obtained using the speech recognition engine and output the recog-nition confidence P ( S i | A )ofthe i -th possible syllable sequence S i . Each inter-syllable boundary in these possible syllable sequences is then regarded as a potential IP to the optimal IP sequence IP*. Although significant efforts have been made in read speech recognition, a large per-formance gap exists between the read speech and the spontaneous speech. The errors that arise from pronunciation variations (e.g., syllable-contraction) and disfluencies (e.g., fillers like  X  X reath X  and edit disfluencies like  X  X N X  and  X  X H X ) in spontaneous speech are inevitable because HMM-based AMs are not sufficiently robust to detect the boundary between two adjacent subsyllables [Toledano et al. 1998]. In this work, the combined AMs, which incorporate subsyllable units to model normal pronuncia-tion and syllable units to capture contracted syllables, are employed to improve ASR performance. In previous work, subsyllables were usually employed as the recogni-tion units for Mandarin speech. However, fast speech degrades spontaneous speech recognition performance because it is associated with syllable contraction. Therefore, syllable-based AMs are employed to accommodate syllable-contracted words, selected from the MCDC corpus, for speech recognition. A speech recognition engine based on the combined AMs constructed herein is employed to output the recognition confi-dence P ( S i | A ) and the corresponding inter-syllable boundary information (ISBI) for all possible syllable sequences S . Based on the inter-syllable boundary information, the prosodic features for the detected inter-syllable boundaries are obtained. Spontaneous speech usually contains pronunciation variations and disfluencies. inter-syllable boundary between two adjacent syllables due to imperfect speech recognition may lead to the incorrect extraction of prosodic features. Accordingly, the probabil-ity p ( F i | S i ) in Equation (5) is estimated to model the probability distribution of the prosodic features. as shown in Figure 3, prosodic feature sequence F i = { F i , l | 1  X  l  X  L } for the i -th syllable sequence S i . L denotes the number of inter-syllable boundaries, which is also the length of the prosodic feature sequence, used in a sliding window for IP detection and l represents the l -th inter-syllable boundary in the i -th syllable sequence S i . In this figure, the length of prosodic feature sequence is three including one boundary for the hypothesized IP, IP H 0 , another for the preceding boundary, and the third for the succeeding boundary. Because the prosodic feature sequence F i , l is ex-tracted within a window of 400ms centered at an inter-syllable boundary, each prosodic feature sequence F i , l comprises T frames { f i , l , t | 1  X  t  X  T } and each frame comprises M the feature vector F i , l is estimated at the current potential IP position, IP H 0 . however, the adjacent syllables are so diverse that the prosodic features cannot be modeled well even the prosodic features are similar to each other. Herein, the probability P ( F i | S i ) can be obtained from the speech recognition models. If all types of feature are mu-tually independent and identically distributed, the probability distribution P ( F i | S i )of the prosodic feature sequence F i given the i -th syllable sequence S i is modeled as where N m is a gaussian mixture distribution model of the m -th type of prosodic fea-which is a hypothesized IP position. In this study, a GMM was basically trained to fit each type of prosodic feature extracted from those inter-syllable boundaries labeled as IPs instead of a universal GMM. p ( F i | S i ) is approximated as p ( F i , l =IP the probability distribution of the observed prosodic features is estimated at the hy-pothesized IP position. The prosodic features at other inter-syllable boundaries are not included for the estimation of the probability distribution p ( F i | S i ). In this work, CRF is adopted for IP likelihood estimation. For CRF modeling, only discrete data are acceptable as the input features. Accordingly, a clustering algorithm is desirable to cluster the prosodic features into a set of cluster centroids. In data clus-tering, more features close to the decision hyperplane strongly degrade the clustering performance, as may occur in a decision tree-based approach [Liu et al. 2006]. In this article, several clustering algorithms are employed to cluster the prosodic features into a compact space to solve the data separation problem shown in Figure 4.

The K -means algorithm is by far the most popular clustering method that is used in data mining. It partitions a data space by minimizing the following function. where d m n represents the n -th training datum of the m -th type prosodic feature set D m and  X  m k represents the k -th centroid of the m -th type feature set. The K -means algo-rithm is popular because it is simple and easy to implement with the standard norm; means algorithm is that the result strongly depends on the initially guessed centroids of the clusters. Therefore, the fuzzy c-means algorithm is employed instead to cluster the prosodic features. The membership functions of the fuzzy c-means algorithm are useful in modeling the training data for those vague features. It involves the mini-mization of the following objective function where r n , k is the degree of membership of f n in centroid k and  X  is a real number that exceeds one and is used as a weighting index of the membership degree. dist ( d m n ,  X  m k ) can be any norm that expresses the similarity between any measured datum and the centroid. Fuzzy c -means involves by iterative optimization of the objective function shown above. Membership r n , k and the cluster centroid  X  m k are updated according to
From the membership of fuzzy c -means, if the observation is not sufficiently close to one centroid, then the one-to-many membership can be taken into account during model training. The conditional random field [Lafferty et al. 2001] is a useful probabilistic framework for labeling and segmenting sequential data based on the conditional probability over label sequences given a particular observation sequence. Recently, the CRF model is one of the state-of-the-art approaches to information extraction that takes advantage of sequential characteristics. It has been used for speech tagging with satisfactory per-formance. In this article, IP detection is regarded as an automatic tagging problem. According to the properties of disfluent speech described in Section 1, IP events typ-ically occur after a reparandum component. Furthermore, each word in an utterance can be  X  X ept X  or  X  X eleted X  to yield the recognition output without reparandum compo-nent. In the example in Figure 5, if the example utterance is  X   X   X  ( (is)  X  X   X  (import) *  X  (en)  X  X  (export)  X  (Mandarin question particle) X  and the corresponding fluent ut-terance is  X   X  (is)  X  X  (import)  X   X , where star symbol  X * X  represents the interruption point, then the word  X   X   X  (import) X  in the original utterance is a reparandum com-ponent with repair category and should be deleted in the speech recognition output. Since Mandarin is a syllabic language, the IP events occur only at the inter-syllable boundaries. The boundary can be tagged as  X 0 X  for Non-IP and  X 1 X  for IP and the optimal IP sequence in this example is  X 001000 X . In this article, the IP detection prob-lem can be simplified as a tagging problem which can be solved using the CRF model. Another reason for the suitability of the CRF model is that the elements in the obser-vation sequence can be considered as a whole. For example, a hypothesized sequence is  X 010 X , not  X 0 X ,  X 1 X , and  X 0 X  separately.

The CRF model in this article considers the prosodic feature sequence F i and the syllable sequence S i to estimate the likelihood for a candidate IP sequence. The prob-ability associated with an IP sequence is estimated as l for the clustered prosodic feature sequence  X  F i , l , the index m represents the feature observation sequence with the states preceding and succeeding IP position l .Figure6 reveals that the clustered prosodic features are employed in the observation functions O the clustered feature  X  f i , l , t , m . The transition feature function thus models successive clustered features. The term  X  m represents the weight of the transition feature func-tion T m (  X  ),  X  m is the weight of O m (  X  ), and Z is a normalization factor with
The likelihood measures of the label sequences of a prosodic feature sequence are ob-tained using the CRF model with a set of weights, =(  X  m ,  X  m ). A well-known strength of the CRF model is that it can solve the label bias problem [Lafferty et al. 2001] by adopting an exponential model of the joint probability of the whole label sequence given the observation. The bias problem refers to the fact that higher frequency la-bels are more overwhelming than those with low frequency. Additionally, the CRF retains a conditional nature and allows more flexibility in capturing non-independent and interactively correlated features.

The CRF++ tool [Kudo 2009] is adopted to implement the CRF model to estimate the optimal coefficients of the linear combination for feature integration, that is, the weighted sum of observation feature function O m (  X  ) and transition feature function T S , F i ) for a given training set. With reference to the approach in Sha and Pereira [2003], the most likely sequence IP can be found using the forward-and-backward al-gorithm during parameter estimation. To solve the over-fitting problem, a Gaussian prior [Chen and Rosenfeld 1999] with a zero mean is employed to penalize the para-meters, and is optimized based on a development data set. To lower the computation cost in CRF training, the L-BFGS algorithm [Liu and Nocedal 1989] is used in imple-mentation.

Finally, the three aforementioned measures are integrated equally and the objective function of IP detection, defined in Equation (5), is rewritten as
The IP sequence with the highest integrated measure is selected as the final IP sequence output.

Even though the IP can be detected using the above equation, some phonetic char-acteristics at potential IP positions can be further adopted to improve the detection performance. For example, a speech event (e.g., lengthening) usually arises before the IP when the speaker changes his or her mind in mid-sentence. In such a case, the FINAL part of the Mandarin syllable before the IP is lengthened. Hence, the sylla-ble sequence S in P ( IP | S , F ) can be used to indicate the FINAL part of a Mandarin syllable. Furthermore, each Mandarin word comprises one or more syllables but the syllable length of a Mandarin word can be roughly determined using the pitch reset [Tseng and Lee 2004; Sun 2002]. Hence, such a phonetic characteristic is also useful for IP detection. Several experiments will be carried out to evaluate the performance achieved by adopting these phonetic characteristics. The Mandarin Conversational Dialogue Corpus (MCDC) [Tseng and Liu 2002], a pop-ular conversational speech corpus that was collected from 2000 to 2001 at the Institute of Linguistics of Academia Sinica, Taiwan, is composed of 30 digitized conversational dialogues, numbered from 01 to 30, with a total length of 27 hours. Sixty subjects who lived in Taiwan were randomly chosen to collect the conversational dialogues. The annotation of the MCDC concisely explains each tag and operationally defines it in detail. To illustrate the speech characteristics of MCDC, eight of the dialogues, 01, 02, 03, 05, 09, 10, 25, and 26, listed in Table I, were annotated for further detailed analysis. In each dialogue, two interlocutors talked about the topics such as family, economy, school, etc. Consistent with SimpleMDE, utterances with disfluencies such as repetitions, repairs, restarts were treated as those with potential IPs. A total of 1,806 sentences from the labeled data were divided into a training set of 1,606 sen-tences and a test set of 200 sentences.

SimpleMDE can be used to find edit disfluencies (repair, restart, and repetition) in Mandarin and other languages. However, Mandarin is a syllabic language in which each syllable comprises up to two subsyllables. Therefore, 153 normal subsyllable AMs (consisting of 115 right-context-dependent (CD) INITIALs and 38 context-independent (CI) FINALs), 37 particle models (  X  X N X ,  X  X A X , and  X  X U X ), and 13 filler models for Man-darin speech were used. All the experiments described in this work were performed using the Hidden Markov Model Toolkit (HTK)-based speech recognition system (base-line system). For robust AM training, a read speech corpus, TCC-300 [Association for Computational Linguistics and Chinese Language Processing ACLCLP], was used for normal seed model construction, and then the MCDC corpus was used for MLLR-based adaptation. Words with syllable contraction, pronounced at a high speaking rate, are usually common words, and most of them are the frequently used terms. Thus, the 47 most frequently used syllable-contracted words in MCDC were selected to construct the syllable-based AMs. In Figure 2, both subsyllable-based (e.g.,  X   X  X  /zh e e nul y yang/ X ) and syllable-based (e.g.,  X   X  X  /jiang/ X ) AMs are included in the pronunciation lexicon for HTK-based ASR and consequently the ASR word-level output can com-prise the outputs from these two sets of acoustic models. The HMM topology is left-to-right without skips with three states for the INITIAL subsyllable, five states for the FINAL subsyllable, and at most 32 mixtures in each state. The input speech was pre-emphasized with a coefficient of 0.97. The acoustic features comprise 12 MFCCs plus energy, their delta and acceleration for a frame size of 32 ms (512 samples) with a frame shift of 10.625 ms (170 samples). As in AM training, the LM was estimated from the TCC-300 corpus and adapted using the MCDC corpus. Since IP events only occur at inter-syllable boundaries, the boundary information was used to extract the prosodic features. As shown in Figure 3, for each inter-syllable boundary, hundreds of prosodic features, including duration, pitch, and energy related features, can be extracted using the Praat tool. In this work, only 199 types of prosodic feature ( M = 199) were em-ployed for IP detection. Appendix A presents examples of prosodic features. Note that only those prosodic features extracted from the inter-syllable boundaries labeled as IPs will be treated as the training data for probability distribution estimation. During the decoding process, the N -best ( N = 5) syllable sequences are first obtained using the speech recognition engine. Each inter-syllable boundary in these possible syllable se-quences is also regarded as a potential IP and the proposed approach will be employed to verify the potential IP one by one using inter-syllable based prosodic features to obtain the joint probability for IP detection. Finally, only the inter-syllable boundary with the maximum probability estimated by the proposed approach is regarded as the detected IP. Prosodic features, which are the most important features in the characterization of spoken language, are closely related to various types of linguistic and non-linguistic information, including prosodic structure, speaker X  X  intention, emotion, and others. Moreover, unlike spectral features, some prosodic features (e.g., duration) are largely invariant under changes in channel characteristics. Therefore, they have an important role in human speech communication. Figure 7 displays several kinds of spontaneous speech event. Silence (e.g.,  X  X il X ) and filler words (e.g.,  X  X N X ) are the most common speech events. For example, the filler word  X  X n X  is a syllable lengthening event, and commonly appears when speakers change their mind in the middle of a sentence. Pho-netic pitch reset occurs at boundaries between adjacent speech units that are word segments, such as prosodic words or prosodic phrases in the prosodic structure. Such speech units may have different pitch levels in a speech utterance [Tseng and Lee 2004]. In Mandarin, a prosodic word/phrase is defined as a group of syllables that are uttered closely and continuously. An important result is that IPs in a sentence usually are present between two prosodic words/phrases. Hence, the prosodic features are im-portant in the detection of IPs in disfluent speech. Furthermore, the duration of the vowel parts in Mandarin speech are sometimes lengthened before an IP. The lengthen-ing features are also useful in IP detection. Unlike the approaches in related work, one benefit of the CRF is that the importance of each type of prosodic feature X  X iven by the weight of the observation functions in CRF X  X an be estimated in model training. As in earlier work [Liu et al. 2006; Lin and Lee 2009], pitch-related and energy-related features are more important than the duration. A speaker may lower pitch and inten-sity when he or she is unsure in producing text. However, duration-related prosodic features are useful when syllables are lengthened. In the experiments, IP detection was regarded as an IP sequence tagging problem in which inter-syllable-based prosodic feature sequences of various lengths are tagged with a binary label along with a specified probability. The shortest length of a prosodic feature sequence was three, for example, P IP S (representing one boundary before and one boundary after the hypothesized IP position). MaxEnt, HMM, and the pro-posed probabilistic approaches were evaluated and compared. In the HMM-based approach, another HTK-based IP recognition engine was constructed. As shown in Figure 8, prosodic features Fl of all types were applied to train the model without clus-tering, because the Gaussian mixture splitting in HMM training is a form of feature clustering. The MaxEnt-based approach was employed to model the sequence of the clustered features in a manner similar to the LM training in conventional ASR. The re-sults of the following evaluations were obtained using various context lengths where K represents the number of clusters in K -means clustering; F denotes the cluster num-ber used in fuzzy c -means clustering and M is the mixture number of an HMM state. The standard norm was employed in both K -means and fuzzy c -means algorithms.
Not only was the accuracy of the subsystem CRF-based IP likelihood measure em-ployed to evaluate the effect of individual subsystems, but also the NIST RT-04F IP error rate [NIST 2004] and F -measure [Van Rijsbergen 1979] were obtained for the entire IP detection system. For the accuracy of CRF-based IP likelihood measure, once the alignment of reference IP sequence has been found, the number of substitution errors ( N Sub ), deletion errors ( N Del ), and insertion errors ( N Ins ) can be calculated. The percentage accuracy of CRF-based IP likelihood measure is defined as: where N Lab is the total number of labels in the reference IP sequence. For the eval-uation of the entire IP detection system, lower NIST RT-04F measure and higher F -measure are better. The overall percentage IP detection error rate defined in NIST RT-04F is estimated from the average number of missed IP detections and falsely de-tected IP events per reference IP: where N Miss  X  IP and N FA  X  IP are the numbers of missed detections and false alarms, respectively, and N IP denotes the number of reference IPs. Moreover, based on the type I and type II error of statistical hypothesis test,  X  Miss  X  X nd X  False Alarm  X  are negatively related to  X  Recall  X  X nd X  Precision  X , respectively. Recall and precision are common measurements in information retrieval. Thus, if precision and recall are of equal importance, then the percentage F -measure is defined as, 4.4.1 Evaluation of Subsystems. In addition to the baseline performance of the pro-posed speech recognition engine, the other two components of the proposed probabilis-tic IP detection model X  X he probability distribution of the prosodic features and the CRF-based IP likelihood measure X  X ere individually evaluated. Table II shows the classification accuracy using the probability distribution of the prosodic features based on the GMM with different mixture numbers. In this evaluation, the current potential IP position, IP H 0 , was directly employed to estimate the probability distribution. A comparison of these results reveals that four mixtures used in GMM achieved the best performance, with a classification accuracy of 78.82%. Therefore, the GMM with four mixtures was chosen in the probabilistic IP detection model. Second, Table III presents the results of CRF-based IP likelihood measures using various lengths of prosodic fea-ture sequence against single CRF. For example, the length of prosodic feature sequence labeled as P IP S is three and the length of PP IP S is four. This experiment evaluated the effect of various lengths of prosodic feature sequence and the number of clusters ( K for K-means clustering and F for fuzzy c-means). As shown in Table III, incorporat-ing more preceding prosodic clusters improves IP detection because IP events usually occur when speakers suddenly change their minds in the middle of a sentence or are unsure in the production of speech. Therefore, the preceding inter-syllable bound-aries contain more information than the succeeding ones, and therefore evaluations with more preceding inter-syllable boundaries were used. These results reveal that the system with three preceding boundaries and one succeeding boundary, PPP IP S, performed the best with an accuracy of 87.31% with four membership functions in the fuzzy c -means algorithm. The evaluation demonstrates that the fuzzy c-means mostly outperforms the K -means, except in only a few cases, such as P IP S. Compared to the one-best ASR output for IP detection, N -best ASR output for IP detection can gain about 1% improvement. If the recognition accuracy for spontaneous speech can be fur-ther improved, N -best speech recognition result can greatly benefit the performance for IP detection. 4.4.2 Evaluation on Various Context Lengths. Based on the best probability distribution, the probabilistic IP detection model was evaluated for various context lengths (the aforementioned variable L ), as presented in Table IV. As revealed by the CRF-based IP likelihood measure, the fuzzy c -means with four membership functions ( F =4) in the row labeled PPP IP S yielded the best performance. The fuzzy c -means-based cluster-ing with eight membership functions underperforms other approaches, because more membership functions produce more unnecessary decision boundaries. Consequently, some data that are associated with the correct centroid are aligned to a wrong cen-troid. The proposed approach outperforms HMM (the group labeled M) and Maximum Entropy (the column labeled MaxEnt) based approaches, in IP detection with various context lengths. For the MaxEnt-based and HMM-based approaches, the improvement is derived from the label bias problem, that is, most of inter-syllable boundaries are annotated as non-IP. 4.4.3 Evaluation on the Effect of Final Part Lengthening. As in the lengthening example in Figure 7, speakers commonly lengthen utterances when they are unsure or suddenly change their mind about the production of the next speech utterance. Hence, a length-ening speech event frequently arises before or after an IP in a speech utterance. The effect of lengthening was evaluated over the duration of the FINAL part because the FINAL part can be recognized more accurately than the INITIAL part. In this case, the potential IP position was assumed probably to be embedded in an inter-syllable boundary, if the duration of the FINAL part right before the IP is longer than its two neighboring FINAL parts. The results in Table V support this assumption. Moreover, although the assumption concerning the duration of the FINAL part of S improves the performance, the editing terms, especially the particles (such as  X  X N X ), and those utterances that the speakers were unsure about producing the next utterance ( X  X hat, that, is that an apple? X ) were also associated with improved performance. However, based on the assumption, 12.17% of inter-syllable boundaries with tagged IPs were still missed. 4.4.4 EVALUATION OF PITCH RESET. Phonologically, pitch reset can be used to detect a prosodic word. In Mandarin, a prosodic word is defined as a group of syllables that should be uttered closely and continuously. Therefore, we examined the IP at the inter-syllable boundaries that were associated with a pitch-reset event. Herein, the pitch reset at the end of an utterance is excluded from the assumption. Table VI shows the results of IP detection based on pitch reset without the assumption of FINAL part lengthening. The results outperform not only in the cases of no additional assumption like pitch-reset and lengthening, but also in the case of FINAL part lengthening. Both measurements reveal an improvement of approximately 10% by comparison with or without an additional setup. The improvement follows from the fact that only 2.71% of boundaries that were actually tagged as IPs were missed. The assumption of pitch reset yields more reliable IP detection results than that of lengthening.

Additionally, Figure 9 shows the comparison results of the CRF model using pitch reset and lengthening. The binary feature  X 0 X  denotes Non-lengthening/Non-reset case and  X 1 X  denotes lengthening/reset case. These two binary features are inserted into the feature vectors directly in CRF model training and testing because prosodic fea-ture clustering is not needed. Moreover, the results obtained from the context length PPP IP S and four membership functions are usually better than other cases. Thus, comparison experiment was only conducted in this case. Detection results of the exper-iment using phonological assumptions, including FINAL part lengthening (F), Pitch-reset (P), Both of two assumptions (B), and the experiment using extra binary features, consisting of FINAL part lengthening (BF), Pitch-reset (BP), and Both of two binary features (BB) are demonstrated for comparison. The results for additional phonologi-cal assumptions are better than those for extra binary features because the number of missed IP in the case of using extra binary features is larger than additional phono-logical assumptions. The result obtained from the case of using both phonological assumptions has no significant improvement to the case of using individual assump-tion because only several IPs of FINAL part lengthening occur at the missed IP in the assumption of FINAL part with pitch reset. 4.4.5 Comparison. The following evaluation is the comparison between the proposed approach and the related work proposed by Liu et al. [2006]. In Liu X  X  work, edit word detection using CRF, IP detection using HMM, and word-fragment (e.g.,  X  X  /jinkou/ is fragmented as /jink/ ) detection using pruned decision tree of prosodic features were integrated into an event detection system. These three detection tasks mostly adopted the textual information instead of acoustic or prosodic information. Low recognition performance of spontaneous speech will dramatically degrade the performance for the detection tasks. From the comparison results shown in Figure 10, the proposed ap-proach using the context length PPP IP S and four membership functions in the fuzzy c -means algorithm achieved a better result than Liu X  X  work. The comparison result confirms that the prosodic features play a better role for IP detection compared to the textual information. 4.4.6 Evaluation of Speech Recognition with/without IP Detection. Some experiments were performed using 100 randomly selected speech utterances which contain the IPs from the MCDC corpus to test the proposed approach based on the assumption of pitch re-set. Table VII presents the results. The results in the table were obtained in four-level experiments under different conditions. The aforementioned HTK-based speech recog-nition engine was used in these experiments. The row labeled  X  X aseline X  presents the performance in terms of complete utterance recognition, as in the recognition of  X   X   X  X   X  *  X   X   X  X   X . Therefore, the baseline does not involve IP detection. The selected speech materials were manually split according to the annotated IP in the following two experiments. First, the performance denoted as  X  X anual with Edit X  refers to the manual splitting of the test utterances and reservation of the editing term in the for-mer part of test data to retain the IP information, as in  X   X  X  X  *  X   X . Then, the second performance, labeled as  X  X anual without Edit X  was designed to evaluate the recogni-tion of speech utterances without any disfluency. The test utterances were split into the former (e.g.,  X   X  X  X   X ), the second part (e.g.,  X   X  X  X   X ) and the editing term (e.g.,  X   X   X ). Removing the editing term yields the best performance because the clauses pre-ceding and succeeding the editing term have higher LM score than the probability of the entire sentence. Syllable accuracy of the experiment  X  X anual with Edit X  includes disfluency (i.e., editing term) in the reference transcription. Finally, the experiment  X  X SR with IP detection X  was performed to evaluate the effect of IP in speech recog-nition. Actually, the final experiment is an experiment in which the test speech data will be automatically segmented according to the detected IP and keep the editing term in ASR output illustrated in Table VII. In other words, the experiment is  X  X u-tomatic with Edit X . Hence, compared to the baseline, the LM contributes a great im-provement in the final experiment. Figure 11 shows the two-stage spontaneous speech recognition results using the proposed probabilistic IP detection. The test speech data were used to obtain the prosodic feature sequence and the ASR output by the prosodic feature extraction and the HTK-based speech recognition engine components. If any IP is embedded in the test data, then the segmentation component is used to split the test data into segments. These segments are recognized again until no IP is detected. Spontaneous speech recognition can benefit from the correctly detected IPs. Moreover, any editing term embedded in ASR output can be used for further processing in future work. This work proposed an approach to detecting interruption points in spontaneous speech using inter-syllable boundary-based prosodic features. The prosodic features around the inter-syllable boundaries are extracted. To apply these prosodic features in system modeling, two clustering methods, K -means and fuzzy c-means, were em-ployed for feature clustering. Confidence degree of the recognized speech, probability distribution of the prosodic features and the CRF-based IP likelihood are combined to determine the IP sequence output. In the experiments, NIST RT-04F measure and F -measure were utilized to evaluate the performance of the proposed probabilistic IP detection mechanism. Pitch reset and lengthening were also integrated for IP detec-tion. Finally, an experiment on speech recognition was carried out to evaluate the improvement in performance of systems with IP detection over that of systems with-out IP detection. The experimental results reveal that the proposed model can satis-factorily detect the IPs and also contribute to the performance of spontaneous speech recognition.

