 Online advertising has become a key source of revenue for both web search engines and online publishers. For them, the ability of allocating right ads to right webpages is crit-ical because any mismatched ads would not only harm web users X  satisfactions but also lower the ad income. In this paper, we study how online publishers could optimally se-lect ads to maximize their ad incomes over time. The con-ventional offline, content-based matching between webpages and ads is a fine start but cannot solve the problem com-pletely because good matching does not necessarily lead to good payoff. Moreover, with the limited display impressions, we need to balance the need of selecting ads to learn true ad payoffs (exploration) with that of allocating ads to generate high immediate payoffs based on the current belief (exploita-tion). In this paper, we address the problem by employing Partially observable Markov decision processes (POMDPs) and discuss how to utilize the correlation of ads to improve the efficiency of the exploration and increase ad incomes in a long run. Our mathematical derivation shows that the belief states of correlated ads can be naturally updated us-ing a formula similar to collaborative filtering. To test our model, a real world ad dataset from a major search engine is collected and categorized. Experimenting over the data, we provide an analyse of the effect of the underlying pa-rameters, and demonstrate that our algorithms significantly outperform other strong baselines.
 I.2.6 [ Computing Methodologies ]: Artificial Intelligence X  Learning ; I.2.8 [ Computing Methodologies ]: Artificial Intelligence X  Problem Solving, Control Methods, and Search Algorithms, Design, Performance computational advertising, revenue optimisation, correlation, POMDPs, value iteration
Online advertising has received blooming development in recent years. The volume of the industry has grown from $8.1 billion in 2000 to $26 billion in 2010 with a new record every year [1]. Online advertising is vitally important for both web search engines and online content providers and publishers because it provides them with major sources of revenue. For example, Google search engine was serving 7.2 billion page views per day in 2011 [9] and its revenue is mainly driven by advertising products like AdWords, Dou-bleClick, and AdMob. Similarly, online content providers such as Yahoo! and news agencies such as New York Times increasingly choose advertising as the smarter alternative to conventional subscription based services.

Online publishers can make profit by selling impressions (an instance of an ad being seen on users X  monitors). A fun-damental problem faced by publishers is that given limited display impressions and ad slots, how to maximize their ad incomes over time. It is a complex problem because in prac-tice publishers usually need to make decisions considering various aspects. First, they have to decide whether to deal private contracts with advertisers or agencies directly, or to participate in public ad networks or exchanges to reach more demands. In [14] a queuing system was proposed to find the optimal policy of selecting advertisers to make private con-tracts, whereas in [6, 20], the focus is on pricing ads properly in either of the two settings. Second, the payment scheme is different and the publishers need to choose between pay-per-view, pay-per-click, and possibly other models. A balance can be established in a static setting as reported in [21, 13, 19]. Lastly and most importantly, a decision has to be made on which page [8, 33] and which users [31, 28] these ads should be matched with, probably in a real-time fashion us-ing text summaries [3]. Traditionally the matching is done by ad networks and advertisers are allowed to choose which keywords they intend to bid. Now publishers are getting more involved and can actively switch in real-time between different pricing schemes and different networks in order to increase their ad incomes, as demonstrated in the Google DFP Small Business system [15] and some ad exchanges like AdBrite ( http://www.adbrite.com/ ).

This essentially allows online publishers to integrate the above decisions all together in a more general framework to optimize their ad revenue. Yet, the following challenges re-main unsolved because of its dynamic settings: First, the prior analysis of the matching between content and ads pro-vides a fine start but a good payoff is not necessarily guaran-teed by a good matching and need to be verified over time. With the limited display impressions, we also need to bal-ance the need of selecting ads and their pricing schemes to learn the true payoffs (exploration) with that of allocating ads to generate high immediate payoffs based on the cur-rent belief (exploitation). Second, online publishers have more opportunities to explore from different ad networks and pricing schemes provided ads are correlated. A key question is how to make use of the correlations embedded in the data to improve the efficiency of the exploration and increase the ad incomes in a long run. In this paper, we study the above two issues and formulate the sequential ad selection problem by applying Partially observable Markov decision processes (POMDPs). To provide a basic under-standing of publisher revenue problem when dealing with multiple ads or ad sources, we do not distinguish between various trade mechanisms and pricing models, but instead consider them essentially the same and focus on their pay-offs. Moreover, to make our study focused, we formulate our problem by considering the correlation of ads, while bearing in mind that the same principle and result can be applied to the correlation of webpages and users. Our mathematical derivation shows that the belief states of correlated ads can be naturally updated using a formula similar to collabora-tive filtering. We examine the model on a carefully collected dataset, and the results show that our models, particularly with the new belief updates, outperform other strong base-lines.
 The remainder of the paper is organized as follows: in Section 2 we provide a discussion about related work and in Section 3 we present the proposed model and its approxi-mate solutions. The experiments are given in Section 4 and conclusions are presented in Section 5.
Previous research on publisher revenue optimization has been mainly focused on display ads and their (private) con-tracts. Traditionally the research question is limited to how to choose advertisers to make (private) contracts with, as elaborated in [12, 14, 26]. In [14] the authors used a queueing system to accommodate advertisers and added constraint that advertisers are impatient and would leave if their ads cannot be displayed right way. A dynamic programming solution was provided in [26] by combining the available ad inventories and dynamically delivery of promised advertising contract to the viewers. Although our model also optimizes publisher revenue over time, the settings are different: we focus on contextual advertising, where ads can be specified using keywords or categories, and study how the matching between webpages and ads can be established w.r.t. payoffs over time. We introduce a simple yet general dynamical pay-off model that helps to address the inventory management problem while taking into account the correlation of ads.
An interesting variation of ad inventory management prob-lem is to find the optimal pricing models. The pay-per-view and pay-per-click models were discussed in [17]. In [21], the study concluded that a combination of pay-per-view and per-per-click pricing models may be the most optimal for an advertiser who has to choose between them. The same choice problem has later been studied in [13] and the au-thor concluded that the optimal choice for a price taking publisher is either pay-per-view or per-per-click but not a combination of those two pricing models. Recently similar conclusion was reported in [19], in which the competition between two models was discussed but limited to a static setting: a single period of planning horizon. Similarly in [14] the authors assumed that the publisher could choose ad networks to utilize remnant impressions after fulfilling con-tracts. Our goal is similar to those papers since we are also targeted to find optimal ad sources. However, our model is focused on real-time impression-based setting; we also uti-lize the correlation of ads to accelerate the discovery process, and provide an analyse of the optimization problem over time. For instance, different from [13] we do not make any assumption on market elasticity; neither do we constraint the publisher to a contract-first setup [14].

Another aspect of publisher revenue optimization is ad scheduling with the constraint of geometrical features of website, uncertainty of advertisers and available ad inven-tory (impressions) [18, 26, 30]. If the publisher fails to deliver promised impressions a good-will penalty would be incurred. In [30] the ad scheduling problem was modelled in video games and a dynamic algorithm was developed. When considering pricing models, e.g. pay-per-click, pub-lishers need to understand the webpage content and user preferences to achieve a better scheduling. Because now dis-playing ads may not earn the publisher anything if ads are not relevant or users are not interested therefore no clicks. Traditionally optimizing matching between webpages and ads belongs to the field of contextual advertising research [8, 24]. In [8] a system utilizing both semantic and syntactic features was proposed to address the problem. Similarly the correlation of user-ad (behaviour targeting) has also been studied previously in [32, 11], focusing on improving adver-tising effectiveness by modelling attitude and feedback from users. Our study can be consider as a dynamical extension of the above works. The contextual matching can be used as a prior belief in our model and it can be updated and verified using our update formulas sequentially.

In terms of techniques, our work is closely related to multi-arm bandit with dependent arms discussed in [23] as we also face a multi-period selection problem with an explo-ration and exploitation dilemma. In [23] the dependencies of candidates are modelled by clustering them first; after that, a multi-arm bandit algorithm runs twice: first se-lects a cluster and then a candidate in that cluster. Our paper is different in that we directly model the dependen-cies using a covariance matrix. The impact of correlation is well formulated and illustrated by rigorously deriving the belief updates once other correlated ads have been selected. Specifically, the problem is formulated by applying Partially Observable Markov Decision Processes (POMDPs) with dis-crete action (selection of ads), continuous observations (pay-offs), and continuous hidden states (performance of ads). Our model is a special case of continuous POMDPs [10, 29], where two-stage Gaussian generative processes and no tran-sit of hidden states are considered during the planning hori-zon. To provide an optimal ad selection, similar with [29, 27], we follow the Monte Carlo sampling approach to deal with continuous observations and to approximate a Dynamic Programming solution in the finite planning horizon. As a complement of the approximation approach, we also extend an Upper Confidence Bound algorithm [4] by integrating it with our belief update method.
In this section we formulate the sequential ad selection problem for a publisher-side system. Suppose there is an online publisher who wants to put ads on their hosting web-pages to generate profits. The ads could be obtained from various sources either by making contracts with advertisers directly, by registering with ad networks, or by employing a supply-side-platform [15]. We now formally introduce the se-quential payoff model to describe how the publisher revenue is earned from ads. Suppose there are N ads from various ad networks or exchanges available for the publisher. For each display impression, the publisher needs to decide which ad should be selected. Without loss of generality, we consider to make our selection decisions every M impressions and de-note the decision times as t  X  [1 ,...,T ]. To stay focused, we consider the impression has only one ad slot, while bearing in mind that the scenario of multiple ad slots per impression can be addressed by incorporating user click-through models (for pay-per-click ads) to remove rank bias [25] or consider them from different impressions (for pay-per-view ads). For each time step t  X  [1 ,...,T ], we define as the available information up to time t , where s ( t )  X  N denotes the decision, i.e. the index of ad selected for the time step t . We use the random variable X ( t ) to denote the payoff gained at time step t and x ( t ) its realization.
Let  X  be an arbitrary choosing policy according to the information obtained so far. We define To simplify our notation, we use them exchangeably in the rest of the paper. The cumulative payoff over time T with certain policy  X  is Our goal is to choose an optimal policy to maximize R  X  ( T ). However, we do not observe any future x s ( t ) ( t ) (where t  X  t before making a decision about s ( t ) (at t = t 0 ). For a given webpage, we assume two generative processes to gen-erate the payoffs as shown in Figure 1. First, we consider the matching between ads and the webpage and denote the true but unknown payoffs of ads over a webpage as  X  , a N -dimension vector. This vector is generated from a mul-tivariate Gaussian distribution governed by mean vector  X  and covariance matrix  X  as the following where  X  and  X  are the parameters of the model and can be estimated beforehand from data. Meanwhile, considering the fact that the payoffs are affected by either the visit-ing users, some unexpected factors, or the uncertainty that has not been well modelled from the Gaussian, the observed payoffs are generated from the true payoffs by Figure 1: The payoff model illustrated by an in-fluence diagram representation with generative pro-cesses of a finite horizon POMDP. In this diagram the non-filled circular nodes represent variables in-cluding belief states; the shaded nodes represent rewards as well as observations of the system; the black point nodes represent non-random values; and the non-filled square rectangular nodes represent ac-tions. The dotted lines indicate indirect dependency and intermediate nodes are not drawn. Note that s (  X  ) also depends on  X  2 0 but lines are not drawn for simplicity. where X is a N -dimension observed payoff vector and I is the identity matrix. A simple variance  X  2 0 is used to model the noise. Note that our treatment of the uncertainty from the underlying users is basic that we use a universal con-stant to describe the possible noise. We will show in our experiments that the noise factor, although simple, plays an important role in controlling the sensitivity of our model. For a more advanced treatment about user modelling, we refer to [28]. Given the two-stage process, the objective of the publisher is to find the optimal policy which maximizes the expectation of the overall ad income through the period, i.e. where we drop M from Equation 3 because the decision is  X   X  s ( t ) |  X ( t ), denoting the estimated expectation of  X  time step t giving all available information  X ( t ). It presents our belief at time t . Our formulation is in fact a special case of continuous POMDPs [10, 29], where  X  is the hidden state and X is the observation over time and our belief about  X  would be sequentially updated using a posterior probabil-ity. Our next task is to provide the estimation  X  each time step t after an ad has been selected and its payoff has been observed. We are particularly interested in the up-date for correlated ads, which will be discussed in the next section.
At each time step the publisher makes a decision, observes the payoff, then updates expected payoffs of all ads. In or-der to calculate the expected payoffs the publisher needs to calculate the value of  X  ( t + 1) and  X  ( t + 1) according to observation x s ( t ) ( t ) and previous belief. In this section we derive the update equation using Bayesian inference. Let us first look at the brief update of the same ads. Suppose the publisher has two ad candidates. The 1st ad was selected at time step t and received a payoff of x 1 ( t ). With Bayes X  theorem and marginalizing  X  1 out, we obtain the p.d.f. of X 1 conditioned on the new observation x 1 ( t ) and previous available information  X ( t ): where we know and by inspecting the exponent part, we can find the poste-rior distribution of  X  1 as where similarly we write  X  2 i ( t ) as the shorthand for  X 
Substituting the posterior of  X  1 into Equation 7 gives the expected payoff of the selected ad as where recall that we assume the prior noise  X  2 0 is known. In a real world situation the payoffs of ads are correlated. Similar products, using similar creative, or targeting similar potential customers will generate similar payoffs. By consid-ering the correlation of ads the publisher could find a more efficient way of identifying best candidates because not only the beliefs of the selected ads themselves can be updated us-ing Equation 10, but so do the other correlated ads. Again with Bayes X  theorem and marginalizing  X  1 out, we obtain the p.d.f. of X 2 conditioned on the observation x 1 ( t ) and previous available information  X ( t ) where p (  X  2 | x 1 ( t ) ,  X ( t ))
With the covariance known, we have the conditional dis-tribution of  X  1 on  X  2 as where  X  1 , 2 is the covariance of {  X  1 , X  2 } . Substituting them into Equation 12 gives
Similarly substituting the posterior of  X  2 from Equation 14 to Equation 11 we obtain the expected payoff of the non-selected ad as
Note the correctness of the equation can be verified by setting the 1st and 2nd ads equal  X  if we have  X  and  X  2 1 =  X  2 2 =  X  1 , 2 , then Equation 14 becomes exactly Equation 9. Therefore we take Equation 14 as the unified equation covering both self and correlated updates. The objective function in Equation 6 is now completed with the belief update formulas (constraints), all of which are now summarized together as the following subject to
It is worth noticing that the update in Equation 17 is closely related to the  X  X ord of mouth X  heuristic adopted in collaborative filtering [7, 16]. In the collaborative filtering approaches, particularly, the user-based ones, the rating of a target user is estimated by looking at other similar users; The more similar a user is, the more contribution he or she would have to the prediction. Using the heuristic, the fi-nal rating prediction is a weighted average across all similar users [16] and the similarity is usually measured by cosine similarity or Pearson X  X  correlation coefficient and user means are used to remove the bias of mean ratings among users [7]. In this paper, using a simple Gaussian model, we naturally derive a collaborative update mechanism across correlated ads. The major difference is that the update is in a sequen-tial way. As seen in Equation 17, the similarity measure here is the correlation normalized by the variance, and  X  s ( t +1) and  X  s ( t ) ( t ) are used to remove the bias from the mean pay-offs between different ads. Moreover, Equation 18 naturally provides the confidence of the predictions.

Optimizing Equation 16 leads to the exploration and ex-ploitation dilemma. The publisher would like to earn more with higher variances might potentially have higher payoffs and are also required to be selected in order to gather the feedback. Not selecting the local best may result in a loss of the immediate reward, but the loss, however, could be compensated if any better alternatives can be found in later stages. Besides, we can see from the model that the chang-ing dataset problem is dealt with naturally: the new coming ads could be simply assigned high variances to encourage the exploration on them.
Our revenue optimization problem in Equation 16 could be solved exactly following a value iteration approach using Dynamic Programming [5]. Recall we use  X  and  X  to denote the belief of N ads true payoffs before t = 1. Let V  X  (  X  ,  X  ,T ) denote the max possible revenue the publisher could gain in T time steps. We have the following statement and the Bellman equation [5].

Lemma 1. For any given priori  X  and  X  , there exists an optimal policy  X   X  to the problem in Equation 16, and V (  X  ,  X  ,T ) is achievable. More over V  X  (  X  ,  X  ,T ) satisfy the following condition
V  X  (  X  ,  X  ,T ) = max
By solving this equation recursively we find the optimal policy. If T = 1, we write the optimal revenue as which indicates that the publisher should simply choose the ad with highest expected payoff. This choice is straight-forward because no more time steps exist, thus no need of exploration.
 For T = 2 the optimal revenue is written as
V  X  (  X  ,  X  , 2) = max = max = max
The difficulty lies in the last integral as it depends on the max operator. Using Chasles relation, it could be expanded to several regional integrals according to the random vector  X  (2). For instance, if the publisher has to choose from only two ads, and by solving  X  1 (2) &gt;  X  2 (2) the following answer is obtained which indicates the publisher should choose the 1st ad when the observation from the 1st time step is bigger than some value k . Then the last integral of Equation 21 could be broken into two regional integrals with exact solution
The above equation could be easily extended to N ads cases provided the solution of N inequalities for vector  X  , where the only variable considered as unknown is the obser-vation from the last time step. For simplicity we define that a region is dominated by some ad when the ad should be selected if the observation falls in the region. This is similar with [27] where the value function is expressed as a linear combination of  X  -functions. Formally we denote the region dominated by i -th ad at time step t as [ m i,t ,n i,t general case of N ads, Equation 21 is written as V (  X  ,  X  , 2) = max where the regional integral could be solved as where  X  ( x ) is the c.d.f. for the Gaussian random variable X . Note that for some ads at some time steps, their dominant regions could be empty, simply indicating the ads would never be selected under such circumstances.
We give an example to demonstrate the sequential se-lection mechanism with embedded correlated belief update. Assume a publisher have 2 ads to select from. The Gaussian noise from users is given by
Random state  X  is defined by a bivariate Gaussian, i.e. where Considering only one time step gives the expected revenue
Now consider T = 2. Suppose the 1st ad at the 1st time step is selected, which yields the following update for time step 2 which gives
Thus, the optimal reward for t = 2 when choosing s (1) = 1 could be derived as A small defect is that variable x stands for the payoff ob-served from the 1st time step and it cannot be smaller than zero. However, due to the Gaussian assumption, when calcu-lating V  X  , we integrate x over the Real space and sometime result in a negative expected reward. But such policy would vanish in later comparisons due to its low value and has little effect on our decision process.

Similarly selecting the 2nd ad at the 1st time step yields the following update for step 2 which gives Thus we have
Finally the maximum expected payoff over two time steps is and the corresponding optimal policy is  X   X  = { s (1) = 2 ,s (2) = 1 if x 1 (1) &lt; 1 ,s (2) = 2 otherwise }
From the result, we can see that the optimal policy is different from a myopic one, which tries to maximize the immediate reward only. Following the myopic policy the publisher would choose s (1) = 1 and receive a smaller pay-off. One of the reasons of selecting the 2nd is because it has a higher variance (taking into account the correlations as well). We will show in the experiments that such high variance is ordinary in real world data.
In order to understand approximations we write the ob-jection function as a combination of immediate reward es-timation and exploration function, which utilizes the avail-able information up to the decision time step, denoted by  X  ( X ( t ) ,i ) for the i -th candidate. The decision criteria is to maximize some the objective value function V s ( t ) ( X ( t )), i.e. Algorithm 1 The vi-cor algorithm using value iteration with Monte Carlo sampling. function ValueFunc (  X  ,  X  ,t ) end function Algorithm 2 The ucb1-normal-cor algorithm using multi-armed bandit with correlated update. function Plan (  X  ,  X  ,  X ( t )) end function
For example, the exploration function in Equation 19 is  X  = of which the computation is expensive due to recursive call-ing and integral. In this section we present two approximate methods.
For T  X  3 the solution for N inequalities cannot be ob-tained easily. Instead we use Monte Carlo sampling to deal with the integral and avoid solving the inequalities. The exploration function is written as where S is the sample set and M 0 is the normalizing factor from sampling. The algorithm for a general T  X  3 case is represented in Algorithm 1. We refer to this algorithm as vi-cor in our experiments.
The multi-armed bandit is a popular approach dealing with exploration-exploitation dilemma in sequential opti-mization problems [4]. Similar to the problem discussed above, in the multi-armed bandit scenario a player must decide which arm to play at each time step to maximize the cumulative reward over the entire planning horizon.
Most multi-armed bandit algorithms reduce the compu-tational cost by approximating the exploration function. In this paper we base on the deterministic policy ucb1-normal [4] and improve its performance by adding the correlated up-date. The original algorithm assumes the Gaussian distri-bution of the reward, independence between arms, and un-derlying mean and variance for reward distribution are un-known but fixed. The exploration function of ucb1-normal is written as where q i is the sum of squared reward obtained from i -th arm, and t i the times i -th has been played so far. We ex-tend the algorithm for our problem by adding the correlated updates. The exploration function would remain the same form, but  X  ( t ) at each time step is updated according to Equations 17 and 18, instead of only updating the selected candidate. The algorithm, referred to as ucb1-normal-cor in our experiments, is represented in Algorithm 2.
We collected our test data set from Google AdWords ser-vice [2]. We consider the scenario that advertisers deploy campaigns through an advertiser (demand) side platform, whereas online publishers retrieve ads and earn revenue from a related publisher side platform. Generally, online pub-lishers share the ad revenues with their chosen ad networks or exchanges with a fixed percentage. For instance, with Google AdSense online publishers gain 68% of advertisers X  spending, where the ratio has not changed since 2003 [22]. Thus, it is reasonable for us to consider online publishers X  ad revenue to be proportional to the corresponding revenue of Google AdWords and also the corresponding cost of the advertisers.

The test data was collected from 12/2011 to 5/2012 The Google AdWords Traffic Estimation service provides real-time data to help advertisers to adjust budgets and se-lect appropriate keywords. When given a keyword, budget, and various targets, the service will return a list of fields on a daily basis including clicks, global and local impressions, average position, average cost-per-click, and total cost. In addition, we also separated the US and UK markets using the geographical targeting option of the service. We have collected keywords across the Google Sponsored Search and Display Networks and do not make a distinction between the types of ads and their specific payment schemes. This al-lows online publishers to fully concentrate upon the revenue optimisation task. During the collection period 521 differ-ent keywords from various categories were collected and 310 have non-zero mean payoffs. As shown in Table 1, we man-ually categorized the keywords into 8 categories to reflect that fact that it is not necessary for online publishers to try out all the available ads; instead they should specify their target categories (based on hosting webpages content) and
The dataset is publicly available at http://www. computational-advertising.org .
 Table 1: Categorisation of the collected 310 key-words with non-zero mean payoffs. make optimal decisions within the targeted categories. In our experiments, ads associated with the collected keywords were considered as candidates and decision making was on a daily basis.
The baselines used in our experiment are:
And our algorithms are:
For each candidate we have about 150 daily payoff data points (some candidates have less due to later start of col-lection). For each category (except Uncategorised ) we se-lect candidates with close mean payoffs to form a dataset, emphasizing the challenge of planning with matching can-didates. In order to test the statistical significance of algo-rithms performance, we divide daily payoff time series into 8 chunks for each dataset (with overlap). For each chunk, we use 20% as the training set to get the prior belief of ad performances, i.e.  X  (0) and  X  (0). Then we go over the re-maining 80% with each algorithm reporting the cumulative reward at each time step. Besides, we report the averaged results with Wilcoxon signed-rank test for the significance of the best algorithm outperformed the second best within each dataset.
We compared our two algorithms with the baselines over the 10 selected datasets. In order to compare performances across categories we normalize the cumulative revenues against the golden solution (always picking up the best ads) to give a better representation due to the different scales of means from different categories. The results are summarized in Table 2 and are compared in Figure 2. We can see that, within the 10 different datasets, the proposed vi-cor gorithm performed the best for 8/10 with 5/8 significantly better. The ucb1-normal-cor algorithm performed the best for 1/10 and was significantly better in that trail. With the  X  X hopping-1 X  dataset, the ucb1 algorithm performed the best, but the vi-cor had the comparable performance and the difference was not significant.

In Figure 2 we give daily performance comparison on  X  X d-ucation X  and  X  X eople &amp; Organization X  datasets where algo-Table 3: The sample correlation matrix for  X  X eo-ple &amp; Organization X  category. The high correlations made the UCB1 and UCB1-Normal inefficient. rithm were run on entire payoff data series. We cannot rep-resent all 10 figures due to the space limit; the performances were however consistent across all datasets. We discuss our findings in the following subsections.
Firstly we study the importance of exploration. Figure 2 compares the daily accumulated revenues over time. As il-lustrated in Figure 2(a), in the beginning (between day-0 and day-10) the myopic policy achieved excellent result and its cumulative payoff was the best until day-65. This is ex-plained by the fact that there is no exploration involved in this policy and it exploits the current belief directly. How-ever our algorithms with exploration quick outperformed it in the late stage as more profitable ads have been discovered from the exploration from the early stage. In the end, the myopic policy failed to win due to no exploration in the be-ginning, and later stuck to suboptimal ads. It is similar in Figure 2(b) where the myopic policy outperformed others between day-25 and day-35, but was caught up and passed very soon. These conclude that the exploration is valuable and important in the ad selection task. Note that we only show categories  X  X ducation X  and  X  X eople &amp; Organization X  only, while the algorithms behaviours were consistent across all datasets.
Recall we consider the Gaussian noise constant for all web-pages and users. The consequence is that X 1 and X conditional independent when we know  X  1 and  X  2 . We can further derive the relationship between covariances of X 1 and X 2 and that of  X  1 and  X  2 as, which enables publishers to use either of correlations within the model. In experiments we used cov[ X 1 ,X 2 ].
Like most multi-bandit machine approaches, the ucb1 al-gorithm assumes independence between candidates. There-fore when candidates have relatively low correlations, e.g. in the  X  X hopping-1 X  dataset, the algorithm would perform well. This was confirmed by the observation that the ucb1-normal-cor algorithm reported only 0.3% improvement over ucb1-normal in that dataset. But in the situation where the correlation of ads are high such as the  X  X eople &amp; Organization X  category (a sample correlation matrix is shown in Table 3), our algorithms utilizing the correlation during planning showed better results. For instance the vi-cor algorithm showed 22.4% improvement over the ucb1 and the ucb1-normal-cor showed 31.9% improvement over the ucb1-normal in the  X  X eople &amp; Organization X  dataset. In Figure 2(b) it was clear that ucb1-normal-cor discov-ered the better options much quicker than the ucb1-normal did. The same conclusion is obtained by comparing the vi-cor with the myopic solution. From Figure 3, we can see a significant improvement by utilizing correlation of ads. The maximum improvement was obtained with  X  X roduct &amp; Ser-vice X  (43.3%) and on average it was 22.2% across all exper-iments. 4.3.3 The Impact of the Noise Factor  X  2 0
The introduction of the noise factor  X  2 0 is essential to the success of our model. On one hand, it helps capture the un-certainty which is unforeseeable and has not been properly modelled by the underlying  X  and  X  as we discussed be-
Figure 2: Comparison on accumulated payoffs. fore. The assumption about the Gaussian distribution may not be true in practice. This can be seen from Figure 4(a) and Figure 4(b). The noise factor provides us with a cer-tain flexibility of tuning our algorithms towards the specific situations. In our experiments, we obtained the noise factor by tuning using training datasets.

On the other hand, the noise factor is also a control of the sensitivity of the algorithms towards the unexpected daily payoff fluctuation. From Equations 17 and 18 we see that the noise factor is in the denominator and a high noise factor leads to a steady policy while a low one leads to a highly responsive (sensitive) policy. A smaller value, for example  X  0 = 0 . 01, would make the algorithm switch probably too much, whereas a larger value would not be able to capture the fluctuation of the data. We found from the data that sometimes strong and short bursts may happen and be led by unexpected commercial activities. For instance, in the beginning of May, 2012 the Sumsang Galaxy S III and Nokia 808 PureView were presented for pre-ordering or purchasing, and both claimed to be the  X  X est X  on the market. The com-petition of commercial campaigns caused the daily payoff of  X  X est phones X  became very high between 15/04/2012 and 05/05/2012 (Figure 4(b)). In order to response to such a short and strong abnormal activity a small noise factor is required. From Figure 4(c) we see that with  X  2 0  X  40 the Figure 3: Comparison on accumulated payoffs on the 10 datasets. VI-COR always performed better than better than UCB1-NORMAL across all datasets. vi-cor algorithm was able to identify and switch to  X  X est phones X  when the burst happened; but with  X  2 0  X  60 the al-gorithm was not able to switch, resulting in a loss of payoff.
It is worth noticing that, as illustrated in Figure 4(c), the setting of the noise factor is algorithm-dependent as well. By contrast, the ucb1-normal-cor approach requires a large noise value to deal with the burst  X  the best cumulative pay-off was obtained at  X  2 0 = 40, and as the value of the noise factor decreased the performance dropped greatly. The dif-ferent behaviour of two algorithms is due to the different structures of the exploration function. As shown in Equa-tion 29, the exploration function of the ucb1-normal-cor contains the squared expectation of the payoffs in the past, indicating that the candidate with a history of low payoffs would not be favoured especially with a sudden burst. Using a high noise value would increase the chance of selecting and exploring such candidates.
In this paper, we have presented a model of optimally se-lecting ads in an online setting. Based on POMDPs, we formulated the belief updates by taking the correlation of ads into account. We mathematically showed that the be-lief update across ads is similar to the  X  X ord of month X  principle employed in collaborative filtering. Making use of the belief update, two approximate methods were proposed: one was derived from the Value Iteration and Sampling ap-proach, whereas the other was based on the Upper Con-fidence Bound solution. In empirical experiments we com-pared our algorithms with various baselines using a collected real world dataset and showed that the Bayesian inference with correlations made the exploration more efficient and significantly improved the revenue optimization.

In the future, we intend to extend the basic model by con-sidering the correlations between webpages as well to further improve the exploration. A further study is also needed in order to incorporate the user click-through model and re-move rank bias on the same webpage [25]. candidates with a sudden change. (c) The impact of the noise factor  X 
