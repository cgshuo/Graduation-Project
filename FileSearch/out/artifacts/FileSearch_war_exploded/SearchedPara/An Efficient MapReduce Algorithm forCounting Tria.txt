
Triangle counting problem is one of the fundamental prob-lem in various domains. The problem can be utilized for computation of clustering coefficient, transitivity, trianglu-lar connectivity, trusses, etc. The problem have been exten-sively studied in internal memory but the algorithms are not scalable for enormous graphs. In recent years, the MapRe-duce has emerged as a de facto standard framework for pro-cessing large data through parallel computing. A MapRe-duce algorithm was proposed for the problem based on graph partitioning. However, the algorithm redundantly generates a large number of intermediate data that cause network over-load and prolong the processing time. In this paper, we pro-pose a new algorithm based on graph partitioning with a novel idea of triangle classification to count the number of triangles in a graph. The algorithm substantially reduces the duplication by classifying triangles into three types and processing each triangle differently according to its type. In the experiments, we compare the proposed algorithm with recent existing algorithms using both synthetic datasets and real-world datasets that are composed of millions of nodes and billions of edges. The proposed algorithm outperforms other algorithms in most cases. Especially, for a twitter dataset, the proposed algorithm is more than twice as fast as existing MapReduce algorithms. Moreover, the performance gap increases as the graph becomes larger and denser.
H.3.3 [ Information Search and Retrieval ]: Search process Graph; triangle; MapReduce
With the rapid growth of the Internet technologies and the social network services, the field of graph analysis is re-ceiving significant attention from both academia and indus-try. Graphs are used extensively to model numerous types of networks, such as social networks, peer-to-peer networks, and the World Wide Web. In many cases, the graphs for these networks can be enormous because these networks usu-ally involve numerous relationships among numerous enti-ties. For example, in the popular social network Facebook, there are more than 1.1 billion users and over 69 billion friendships[1, 24]. Therefore, it is essential to extract only the useful information from a graph, but it is not trivial to analyze an enormous graph to determine patterns and trends within the graph.

Counting the number of triangles in a graph is an impor-tant function in graph analysis. In the field of graph anal-ysis, the clustering coefficient[25] and transitivity ratio[20], which are highly relevant to the number of triangles, are re-garded as important measures that quantify the degree of clustering in a graph. These measures have been used for various applications such as detecting fake accounts in social networks[27], finding malicious pages on the Web[6], uncov-ering hidden thematic layers on the Web[13], and detecting communities[7].

The problem of counting the number of triangles has been studied extensively over the past few years due to the nu-merous applications related to the problem. Thus far, the research has focused primarily on internal memory[15, 17, 21]; however, as a result of the enormity of recent graphs, it is effectively impossible for the internal memory algorithms to count the number of triangles in the graphs. One of the methods to manage such enormous data is to exploit the parallel computing paradigm. MapReduce[11], and its open source version Hadoop[26], has emerged as a de facto stan-dard framework for processing large data through parallel computing. A number of researchers have employed MapRe-duce to enable their algorithms to be scalable[16, 23, 9, 19].
Suri and Vassilvitskii[22] proposed a MapReduce algo-rithm, called Graph Partition (GP) algorithm, and it uses a graph partitioning technique to count the number of tri-angles in enormous graphs. The GP algorithm partitions a graph into overlapping subgraphs in order that every trian-gle in the graph is present in at least one subgraph. Then, it counts the number of triangles in each subgraph in parallel. However, the GP algorithm generates a large number of in-termediate data that cause network overloads and increase the processing time.

In this paper, we propose a new MapReduce algorithm using a graph partitioning technique to count the number of triangles in an enormous graph. When a graph is parti-tioned, every triangle can be classified into one of three types according to the number of subgraphs in which the nodes of the triangle are placed. In the GP algorithm, if two or three nodes of a triangle are in the same subgraph, the triangle is calculated redundantly. In particular, when all nodes in a triangle are included in the same subgraph, the triangle is calculated in proportion to the square number of subgraphs.
Our algorithm substantially reduces the number of calcu-lations by using different processes for each type of triangle and partitioning a graph in a different manner to that of the GP algorithm; thus, our algorithm computes far fewer triangles during the process than the GP algorithm.
Contributions. Our significant contributions are sum-marized as follows.
Paper Organization. In Section 2, previous works rel-evant to the problem of counting the number of triangles are reviewed. The problem of counting the number of trian-gles and a set of frequent notations are formally defined in Section 3. In Section 4, we describe the proposed algorithm and proves its efficiency with theoretical bounds. In Section 5, we give the experimental evaluation and conclusions are made in Section 6.
In this section, we first provide an overview of the trian-gle counting algorithms for internal and external memory. Then, we outline the flow of the MapReduce because our algorithm is a MapReduce algorithm. Finally, we introduce the existing MapReduce algorithms for counting the number of triangles. The notations that are used are listed in Table 1.
The triangle counting problem has been studied exten-sively for internal memory algorithms. Here, we provide an overview of the existing internal memory algorithms.
G ij = ( V ij ,E ij ) Induced subgraph of G on V i  X  V j
G ijk = ( V ijk ,E ijk ) Induced subgraph of G on V i  X  V
The simplest method of counting the number of triangles is to investigate all possible triples of nodes whether the nodes in a triple are fully connected to each other. There are two foundational algorithms for this: the node-iterator algorithm and the edge-iterator algorithm. For each node n in V , the node-iterator algorithm counts every pair that has an edge between them in N ( n ). For each edge ( n,v ) in E , the edge-iterator algorithm computes the intersection of N ( n ) and N ( v ), and then counts the number of nodes in the intersection. These two algorithms have the same upper bound O ( d 2 max n ) where d max is the maximum degree of nodes [21]. Moreover, the two fundamental algorithms output each triangle three times.

The forward algorithm eliminates the output duplication and improves the edge-iterator algorithm by ordering the nodes. It returns a triangle  X ( u,v,w ) if and only if u  X  v  X  w where  X  is a total order on all of the nodes. Usually, the nodes are ordered by the degree of nodes. The compact-forward algorithm is a refined version of the forward algo-rithm. It reduces the usage of space from  X  (3 m + 3 n ) to  X  (2 m + 2 n ) [17].

There is another approach for the triangle counting prob-lem that utilizes a matrix multiplication. If A is the adja-cency matrix representation of input graph G , the number of triangles is computed simply by calculating A 3 . The AYZ algorithm [4] uses the matrix multiplication. This algorithm is known as the fastest algorithm for counting triangles: its running time is O ( m 1 . 41 ) with the fast matrix multiplication [10]. However, the AYZ algorithm uses O ( n 2 ) space, which is a prohibitive space cost for computing enormous graphs.
This section briefly introduces the triangle counting algo-rithms for external memory. Dementiev [12] proposed an ex-ternal version of the node-iterator algorithm, called the ex-ternal node-iterator algorithm. The node-iterator algorithm for internal memory uses an adjacency matrix representation of a graph in order to test the adjacency of two nodes in a constant time. In order to avoid the adjacency matrix repre-sentation, the external node-iterator algorithm uses a sorted edge list to verify the adjacency of two nodes. Furthermore, it reduces the number of computations by employing de-gree ordering. Menegola [18] proposed an external version of the compact-forward algorithm, called external compact-forward algorithm. In the compact-forward algorithm for internal memory, the node processing order should be re-spected. The external compact-forward algorithm guaran-tees the processing order using a mapped index containing the order of each node. Chu and Cheng [8] proposed graph partitioning algorithms for the external memory. These ex-ternal graph partitioning algorithms have a common base framework and vary according to the partitioning methods: sequential partitioning, dominating set based partitioning, and randomized partitioning. The external graph partition-ing algorithm framework partitions the graph and classifies triangles. The concept of this external graph partitioning algorithm is similar to our algorithm, but the two algo-rithms have significant differences. In the external graph partitioning algorithm, each partition is extended to include all neighboring nodes in the partition. By doing so, every triangle is listed without exception. However, if a node has many neighbors, a partition including the node cannot fit in the memory. In contrast, our algorithm does not extend partitions so that every partition remains within the mem-ory size. Our algorithm guarantees that every triangle is in at least one partition using a different method; moreover, our algorithm is a MapReduce algorithm not an external memory algorithm. Hu et al. [14] proposed a state-of-the-art algorithm for counting triangles in the external memory. This algorithm loads certain size edges in the memory and finds all triangles containing one of these edges by traversing every node.

External memory algorithms are devised in a different en-vironment, in which massive parallel and distributed com-puting is not available, so they are not in the scope of this paper. Figure 1: MapReduce example, word counting
MapReduce is a programming framework for processing large data using parallel computation. The name and con-cept of the MapReduce are from the  X  X ap X  and  X  X educe X  operations in functional programming languages. With the MapReduce framework, programmers can easily utilize dis-tributed machines in order to process large data in parallel by writing scripts for the Map and Reduce function. There are three steps in the MapReduce framework: Map, Shuffle, and Reduce.
 Map Step. A Map function that is scripted by a program-mer is copied to each machine and each copied Map function is called a Map instance. In the Map step, each Map instance receives a line as input from a file and outputs a number of  X  key ; value  X  pairs in response to the input. The number of output pairs may be zero. Figure 2: the input graph and partitions in our run-ning example Shuffle Step. The output pairs from the Map step are bound by keys in the Shuffle step. That is, pairs that have the same key are combined as  X  key, { value 1 ,value 2 ,... } X  . Reduce Step. A Reduce function that is scripted by a pro-grammer is copied to each machine and each copied Reduce function is called a Reduce instance. Each Reduce instance receives one of the output pairs  X  key,valueSet  X  from the Shuffle step as input and outputs a number of  X  key ; value  X  pairs.
 Figure 1 shows a word counting example.
Recently, two MapReduce algorithms used to count the number of triangles were proposed. Cohen[9] proposed the first MapReduce algorithm, called the Cohen algorithm, to enumerate triangles. This algorithm is based on the node-iterator algorithm. As mentioned above, the node-iterator algorithm outputs triangles redundantly. In order to avoid the duplication, the algorithm applies an ordering technique; any ordering factor can be applied, e.g. numerical ordering of node numbers. The author chose the degree of nodes as the ordering factor. Using the degree ordering, the process-ing time of the algorithm is O ( m 3 2 ), which is the optimal bound for enumerating triangles. However, the algorithm diminished as the average degree of nodes increases. More-over, if a node has a very high degree, a Reduce instance whose input key contains the node cannot accommodate the values related to the key.

Suri and Vassilvitskii[22] proposed a MapReduce algo-rithm for the triangle counting problem, which is the current state-of-the-art MapReduce algorithm. It resolves the mem-ory capacity problem of the Cohen algorithm through the use of a graph partitioning technique. Suri and Vassilvit-skii X  X  algorithm can modulate the input sizes of the Reduce instances. However, the algorithm generates numerous du-plicate edges during the process, which increase the network overload, and calculates triangles redundantly. We review the algorithm in detail in Section 4 because the algorithm is closely related to our algorithm.
Let us consider a simple undirected graph G = ( V,E ) where V is the set of nodes and E is the set of edges. Let n and m be the size of nodes | V | and edges | E | , respectively. An edge between two nodes u and v is represented as ( u,v ). Let N ( v ) be the set of directly adjacent nodes(neighbors) of A triangle, denoted by  X ( u,v,w ), is a set of three nodes { u,v,w } X  V such that ( u,v ) , ( u,w ) , ( v,w )  X  E . Then, the triangle counting problem is formally defined as follows:
Definition 1. (Triangle counting) Given a graph G , the triangle counting problem is to count the number of all tri-angles in G .

We also define the following important terms that are used to describe our algorithm throughout the paper. Note that the term partition is used informally as a subgraph instead of following the standard mathematical definition in order to be consistent to usual terms for graphs in the MapReduce area.

Definition 2. (Partition or 1-partition) Given an integer  X  , a partition (or 1-partition) , denoted by G i = ( V G j = ( V j ,E j ), is a subgraph of G such that V i  X  V where 0 &lt; i &lt; j  X   X  , and Then,  X  is the number of partitions.

Definition 3. (2-partition and 3-partition) Let G i , G j G k be three different partitions complying with Definition 2. Then a 2-partition, denoted by G ij = ( V ij ,E induced subgraph of G on V i  X  V j . Similarly, a 3-partition, denoted by G ijk = ( V ijk ,E ijk ), is an induced subgraph of G on V i  X  V j  X  V k .

When an input graph is divided into  X  partitions, the number of all possible 2-partitions and 3-partitions are  X  and  X  3 respectively. Figure 2 shows an input graph and partitions. There are four partitions( G 1 , G 2 , G 3 and G six 2-partitions( G 12 , G 13 , G 14 , G 23 , G 24 and G four 3-partitions( G 123 , G 124 , G 134 and G 234 ). G 1 posed of three nodes 1, 2 and 3, and three edges (1 , 2), Similarly, G 2 , G 3 and G 4 are induced subgraphs of respectively. G 12 is a 2-partition which is com-posed of six nodes { 1 , 2 , 3 , 4 , 5 , 6 } and eight edges is a 3-partition which is composed of nine nodes
In this section, we propose a novel MapReduce algorithm to count the number of triangles in a graph. It is essen-tially a graph partitioning algorithm that divides a graph into multiple overlapping subgraphs that together cover all triangles in the graph. Suri and Vassilvitskii [22] also pro-posed a partitioning algorithm for counting triangles; how-ever, their algorithm generates numerous duplicated edges during the process and performs redundant computations when counting triangles. First, we introduce the previous GP algorithm [22]; then, we propose our algorithm and an-alyze its efficiency.
Suri and Vassilvitskii [22] proposed a MapReduce algo-rithm, called graph partition (GP) algorithm, to count the number of triangles in a graph. The first step of the algo-rithm is to partition the nodes of a graph into  X  partitions, G i = ( V i ,E i ) where 0 &lt; i  X   X  , so that each partition has almost the same number of nodes. The algorithm counts the number of triangles using an internal memory algorithm for each 3-partitions G ijk where 0 &lt; i &lt; j &lt; k  X   X  .
Certain triangles appear multiple times during the pro-cess, which produces redundant results. Consider a trian-gle  X ( u,v,w ) where u , v , and w are included in the same partition G x . The triangle  X ( u,v,w ) is present in every 3-partition G ijk where x = i or x = j or x = k . For example, in Figure 3, the triangle  X (1 , 2 , 3) whose nodes are in the same partition G 1 appears three times in G 123 , G 124 G 134 . Similarly, the triangle  X (4 , 5 , 6) also appears three times in G 123 , G 124 and G 234 . For two nodes of a trian-gle in the same partition, e.g. u and v are in G x and w is in G y , the triangle appears in every 3-partition G ijk where { x,y }  X  { i,j,k } . For example, in Figure 3, the triangle  X (3 , 4 , 6) whose two nodes 4 and 6 are in the same partition G 2 appears twice in G 123 and G 124 . In order to correctly count such triangles, the algorithm corrects the duplicated triangles by reporting each triangle as 1/(number of the du-plicates). For example, in Figure 3, the triangle  X (1 , 2 , 3) is reported as 1/3. Since the triangle  X (1 , 2 , 3) is reported three times, the sum of the reported numbers for the triangle is 1.

The above procedure is realized in a MapReduce algo-rithm by implementing a Map function and a Reduce func-tion. The Map function takes an edge ( u,v )  X  E as an input and outputs  X  ( i,j,k ) , ( u,v )  X  pairs such that u and v are included in G ijk . The Reduce function counts the tri-angles using an internal memory algorithm and corrects the number of triangles.
The primary drawback of the GP algorithm is the redun-dant computation of triangles. In particular, triangles that are included wholly in a partition are computed in O (  X  time. Our observation is that the primary cause of the redundant computation of triangles is the duplicate edges output from the Map function. The output edge size is also O (  X  2 ) for an edge ( u,v ) if the u and v are in a partition. These edges lead to network overload and delay the Shuffle step of MapReduce.
We propose a new MapReduce algorithm, named the Tri-angle Type Partition (TTP). The algorithm substantially rectifies the duplication problem in the GP algorithm.
When a graph is partitioned, a triangle can be classified into one of three types according to the number of partitions in which its nodes are positioned.

Definition 4. (Types of Triangle) The three types of tri-angles are defined as follows: Type-1. If the three nodes u , v , and w of a triangle  X ( u,v,w ) are placed in the same partition, the triangle type is Type-1. Type-2. If the two nodes of a triangle belong to one parti-tion and the remaining node belongs to a different partition, the triangle type is Type-2.
 Type-3. If the three nodes are in different partitions, the triangle type is Type-3.

For example, in Figure 2, the triangles  X (1 , 2 , 3) and  X (4 , 5 , 6) are Type-1 triangles. The triangle  X (3 , 4 , 6) is a Type-2 tri-angle. The triangles  X (3 , 6 , 7) and  X (6 , 7 , 10) are Type-3 triangles.

Let an edge ( u,v ) be an inner-edge if the nodes u and v belong to the same partition, and the edge be an outer-edge if the nodes u and v are in different partitions. For example, (7 , 8), (7 , 9), (10 , 12) and, (11 , 12) are inner-edges and the others are outer-edges. As mentioned above, the GP algo-rithm redundantly processes Type-1 and Type-2 triangles. In order to reduce these duplications, the TTP algorithm utilizes the fact that Type-3 triangles are only composed of outer-edges, i.e. there are no inner-edges in Type-3 tri-angle. This suggests that Type-3 triangles can be counted correctly without inner-edges. Then, our strategy is to dis-sociate the Type-1 and Type-2 triangles from the Type-3 triangles. A 3 X -partition, denoted by G 0 ijk , is a subgraph of a 3-partition without inner-edges. In Figure 5, there are examples of G 0 ijk for the graph in Figure 2. The TTP al-gorithm counts Type-1 and Type-2 triangles in 2-partitions and Type-3 in 3 X -partitions. Type-2 triangles are counted in 2-partitions because every Type-2 triangle is present in one of the 2-partitions; the TTP algorithm also counts Type-1 triangles in the 2-partitions because every Type-1 triangle also appears in the 2-partitions. In Figure 4, the Type-2 tri-angle  X (3 , 4 , 6) appears only in G 12 and The Type-1 triangle  X (1 , 2 , 3) also appears in G 12 , G 13 , and G 14 . The algorithm does not count Type-1 triangles in 1-partitions because there is no advantage by doing so. That is, the algorithm should compute triangles in 2-partition even when Type-1 triangles are already counted; thus, Type-1 and Type-2 triangles are processed at the same time.
 Algorithm 1: Triangle Type Partition algorithm
Map : input  X   X  ; ( u,v )  X  for a  X  [0 , X   X  2] do 2 for b  X  [ a + 1 , X   X  1] do 3 if { P ( u ) ,P ( v ) } X  X  a,b } then 4 emit  X  ( a,b ) ; ( u,v )  X  ; if P ( u ) 6 = P ( v ) then 6 for a  X  [0 , X   X  3] do 7 for b  X  [ a + 1 , X   X  2] do 8 for c  X  [ b + 1 , X   X  1] do 9 if { P ( u ) ,P ( v ) } X  X  a,b,c } then 10 emit  X  ( a,b,c ) ; ( u,v )  X  ;
Reduce : input  X  ( i,j,k ) ; E ijk  X  or  X  ( i,j ) ; E ij  X   X   X  Find all triangles on G t ; foreach ( u,v,w )  X   X  do 14 if P ( u ) = P ( v ) = P ( w ) then 15 emit  X  ( u,v,w ) ; 1  X   X  1  X  ; 17 emit  X  ( u,v,w ) ; 1  X  ;
The pseudo code for the TTP algorithm is shown in Al-gorithm 1. The algorithm is composed of a pair of Map and Reduce functions. Each edge of input graph is sent to one of map instances. The Map instance takes an edge ( u,v ) as input. Let P ( v ) be a hash function that returns an in-teger within [0 , X   X  1] such that the integer corresponds to a partition. For example, in Figure 2, P (1) = 1, P (3) = 1, P (4) = 2, P (7) = 3, P (11) = 4 and so on. If the input edge is an inner-edge, the Map instance outputs pairs  X  ( a,b ) ; ( u,v )  X  for each a,b  X  [0 , X   X  1] satisfying { P ( u ) ,P ( v ) }  X  { a,b } (Lines 1-4). This means that the algorithm includes the edge ( u,v ) in G ab satisfying such a condition. Let us consider an edge (1 , 2) in the running example (Figure 2). If the edge is the input of a Map instance, the Map instance (1 , 2)  X  . If the input edge is an outer-edge, the Map instance outputs pairs in common with an inner-edge. In addition, It also outputs pairs  X  ( a,b,c ) ; ( u,v )  X  for each a,b,c  X  [0 , X   X  1] satisfying { P ( u ) ,P ( v ) }  X  { a,b,c } (Lines 5-10). For exam-ple, if the outer-edge (3 , 4) in Figure 2 is the input of a Map instance, the Map instance will output pairs  X  (1 , 2) ; (3 , 4)  X  , stances finish their tasks, the MapReduce framework gathers values that share the same key. Then it assigns the values with the key to a reduce instance. In this algorithm, each key corresponds to a 2-partition or a 3 X -partition. For exam-of a Reduce instance, it implies that G 0 234 contains edges (6 , 7), (6 , 10) and (7 , 10), and the Reduce instance receives G 234 . In summary, each Reduce instnace takes a 2-partition or a 3 X -partition as input and counts the number of triangles in the 2-partitions or 3 X -partitions. Note that any internal memory algorithm for counting the number of triangles can be used in the Reduce function.
In this section, we analyze the network/space usage and the processing time of the proposed algorithm. We first show the correctness of the algorithm.

Lemma 1. All triangles in a graph are counted correctly by the TTP algorithm.

Proof. Each Type-3 triangle  X ( u,v,w ) appears only in a 3 X -partition G 0 ijk where u  X  G i , v  X  G j and w  X  G thus, Type-3 triangles are counted correctly. Without loss of generality, on behalf of all Type-2 triangles, let us consider a triangle  X ( u,v,w ) where u and v are in the same partition and w is in another partition. The triangle appears only in a 2-partition G ij where u,v  X  G i and w  X  G j and does not appear in any 3 X -partitions because the triangle has an inner-edge but there are no inner-edges in every 3 X -partition; thus, Type-2 triangles are counted correctly. Each Type-1 triangle  X ( u,v,w ) whose u , v and w belong to a partition G i appears in 2-partitions G ij where j  X  [0 , X   X  1] and i 6 = j . Then, the number of G ij is  X   X  1; it implies that each Type-1 triangle appears  X   X  1 times. The algorithm counts each Type-1 triangle as 1  X   X  1 ; thus, Type-1 triangles are counted correctly.

We analyze the network and space usage of the TTP al-gorithm.

Lemma 2. The expected size of inner-edges is m  X  and the size of outer-edges is (1  X   X  ) m  X  . Then, the expected size of output from all Map instances is m (  X   X  1) = O ( m X  ).
Proof. If an input edge for a Map instance is an inner-edge in G i , it is output to G ij for each j  X  [0 , X   X  1] and i 6 = j . It implies that every inner-edge is output  X   X  1 times. Let us consider an inner-edge ( u,v ). The probability for two nodes u and v to belong to the same partition is 1  X  and the number of edges is m ; thus, the number of inner-edges is stochastically. Therefore, the size of output inner-edges is  X  (  X   X  1).

If an input edge for a Map instance is an outer-edge which lies between G i and G j , it is emitted to G ij and G 0 ijk k  X  [0 , X   X  1] and i 6 = j 6 = k , i.e. the outer-edge output 1 + (  X   X  2) =  X   X  1 times. The number of outer-edges is Then, the size of output from outer-edges is  X   X  1  X  m  X  (  X   X  1). Finally, the total size of output is
We analyze the memory usage of each reduce instance in the TTP algorithm.

Lemma 3. Each reduce instance receives input of O ( m  X  2 size on average.

Proof. Each Reduce instance receives one of two types of input:  X  ( i,j ) ; E ij  X  and  X  ( i,j,k ) ; E 0 ijk 2-partitions and edges of 3 X -partitions. In the former case, a 2-partition E ij contains both inner-edges and outer-edges. The probability that an edge belong to a specific partition  X  2 , because the probability equals to the probability that both of two nodes of the edge belong to a specific partition. In a 2-partition, there are two 1-partitions so the expected size of inner-edges in a 2-partition is 2 m  X  2 . Similarly, the expected size of outer-edges in a 2-partition is m  X  2 . Therefore, when the input of a Reduce instance is edges of a 2-partition, the expected input size is 3 m  X  2 = O ( m  X  2 ). In the latter case, a 3 X -partition E 0 ijk contains only outer-edges and the size of outer-edges in a 3 X -partition is
Therefore, regardless of the input type, the expected size of the input to an reduce instance is O ( m  X  2 ). (a) Effect of the partition size  X  on shuffled data size.
Lemma 2 shows that the network and the space usage is proportional to the partition size  X  . Lemma 3 shows that the memory usage of each reduce instance decreases as the partition size increases. The two Lemmas shows that both the total space/network usage and the memory usage of each reduce instance depend on the partition size  X  and the algo-rithm can mediate between them by modulating the  X  .
Theorem 1. The total amount of work performed by all reduce instances is O ( m 2 3 ) where  X   X 
Proof. The running time on each Map instance depends on the size of its edges output. Outputting an edge can be done in O (1). Lemma 2 shows that the total number of edges output is O ( m X  ) and it becomes O ( m 3 2 ) when  X  be less than or equals to size of any reduce instance is O ( m  X  2 ) and the partition size is O (  X  3 ). In addition, the running time of the best algorithm for counting triangles is O ( m 3 2 )(See Section 2). Therefore, the total processing time of reduce instances is Theorem 2. In the Map step, the GP algorithm outputs O ( m X  ) more than the TTP algorithm does.

Proof. First, we consider the case in which the two al-gorithms use the same number of partitions  X  . For Map instances of the GP algorithm, if the input edge is an inner-edge, the edge is emitted  X   X  1 2 . If the input edge is an outer-edge, the edge is emitted  X   X  2. By the Lemma 2, the expected size of inner-edges and outer-edges are m  X  and is
In addition, the Map step of the TTP algorithm outputs m (  X   X  1) by the lemma 2. Then, the difference between the two output sizes is
We now consider a case in which two algorithms use different  X  to use same memory size in each reduce instance. The number of input edges of the GP algorithm is
In the above expression, the first term represents the num-ber of inner-edges and the second term represents the num-ber of outer-edges in a reduce instance. Lemma 3 shows the number of input edges of the TTP algorithm is 3 m  X  2 . Suppose that the GP algorithm uses  X  and the TTP algorithm uses  X  2 then  X  2 = the output sizes of the two algorithm is Figure 7: Effect of density with synthetic data. The edge size is fixed.
In this section, we present the results from a comprehen-sive experimental evaluation to verify the performance of the proposed algorithm.
We use both real world datasets and synthetic datasets to evaluate our algorithm. We first generate synthetic datasets according to the preferential attachment model[5]. Graph sizes vary from 200 thousand nodes to 2 million nodes with 20 million edges. The web-BerkStan, as-Skitter and Live-Journal datasets are from SNAP[2] and the twitter dataset is from [3]. The directed graphs are converted into undi-rected graphs by deleting duplicate edges. In other words, if there is even one directed edge between two nodes, we con-sider that there is a both-way edge between the nodes. The real-world datasets are listed in Table 2.
We implement our algorithm and the compare algorithms in hadoop framework that is the de facto standard imple-mentation of MapReduce. All the experiments are con-ducted on a cluster server with 47 nodes. Each node has 4 Gbyte of memory size. The compact-forward algorithm is used in reduce function of our algorithm and the GP al-gorithm. The hash function P ( x ) is implemented as the modular hash function.
In this section, we present our experimental results.
Figure 6 shows the experimental results for varying the partition size  X  . As proved in Lemma 2, the total output size of map instances, which is the size of shuffled data, is O ( m X  ). Moreover, the difference of the shuffled data size between our algorithm and GP algorithm is also O ( m X  ). This indicates that the shuffled data size and the difference are directly proportional to the partition size  X  when the edge size m is fixed. Figure 6(a) shows the proportional difference between two algorithms. For counting the number of triangles in the Twitter dataset, 2.1 Tbyte data is shuffled on the GP algorithm(  X  = 45) while 1.3 Tbyte data is shuffled on the Figure 8: Effect of the graph size with induced sub-graphs of twitter data TTP algorithm(  X  = 40) over reducing 0.8 Tbyte (Table 5). Figure 6(b) shows the running time for varying partition sizes  X  . In every case, the TTP algorithm outperforms the GP algorithm. Both experiments are conducted with the LiveJournal dataset. Note that the GP algorithm yields a memory buffer overflow when the  X  is 5.
Effect of density. For the experiments, synthetic datasets, which comply with the preferential attachment model[5], are used. The data model enables the control over the number of nodes n and the density of the graph, which are repre-sented as  X  . The  X  decides the number of edges m when the number of nodes n is determined. Figure 7 shows the exper-imental results for varying  X  and n while m is fixed. In other words, the result shows the influence of the density of the graphs when the input data size is fixed. The experiments are conducted with graphs which have 20 million edges and whose data file size is about 250 Mbyte. For the TTP and GP algorithms, the value of  X  is chosen as 15 and 16 respec-tively with which the performance of the algorithms is the best. The GP algorithm takes more time for counting tri-angles than the TTP algorithm on all occasions regardless of  X  . The Cohen algorithm is better when  X  is lower than aproximately 8 but the performance gradually declines as the density increases. Note that most graphs have  X  greater than 8 including what we used. The  X  of web-BerkStan, as-Skitter, soc-LiveJournal1, and Twitter are 9.70, 6.47, 8.96, 28.6 respectively. Especially, the  X  of Facebook is more than 80. As we mentioned in Section 2, The reason why the run-ning time of Cohen increases as  X  increases is that the out-put size of the first MapReduce phase is proportional to the Figure 9: the ratio of the running time with real world datasets degree of nodes in the algorithm. As  X  increases, the num-ber of nodes decreases so that the degree of nodes increases because the number of edges is fixed.

Effect of graph size. For the experiments, twitter data [3] is used. We generated induced subgraphs of the twitter graph on 1, 2, 4, 8, 16, 24 and 32 millions nodes. The gen-erated datasets are listed in Table 3. Figure 8 shows the experimental results for varying graph sizes. The TTP al-gorithm outperforms other algorithms in most cases. Espe-cially, the performance gap between the algorithms increases as the data size increases. For the TTP and GP algorithms, the value of  X  is chosen as 15 and 16 respectively where the node size is lower than 25 million, and the value is chosen 31 and 32 respectively in the other cases because of the memory buffer overflow.
We conduct experiments on real datasets to check the pro-posed algorithm is feasible for real world data. Figure 9, Ta-ble 5 and Table 4 show the results. The running time of each algorithm is listed in Table 4. In order to show the speed-up of our algorithm comparing to other algorithms, Figure 9 shows the ratio of the running time. In the figure, the run-ning time of each algorithm is divided by the running time of our algorithm. For all datasets, The TTP algorithm out-performs other algorithms. Especially for twitter dataset, the TTA algorithm is more than twice as fast as the others.
Counting the number of triangles is a fundamental prob-lem in various domains such as social networks, P2P net-works, world wide web, and road networks. In order to solve the problem in enormous graphs, prior researchers pre-sented algorithms that operates on MapReduce framework; Cohen[9] proposed a MapReduce algorithm, called Cohen algorithm, based on node-iterator, and Suri and Vassilvit-skii[22] proposed another MapReduce algorithm, namely GP algorithm, based on graph partitioning. However, previous algorithms have weaknesses. The performance of Cohen al-gorithm is diminished as the average degree of the graph becomes greater. The GP algorithm generates much inter-mediate data redundantly that cause network overload and prolong the total running time. In this paper, we propose a Table 4: The running time of all algorithms (min) Table 5: The shuffled data sizes of all algorithms (GB) new MapReduce algorithm based on graph partitioning like as the GP algorithm for counting the number of triangles in enormous graphs. The TTP algorithm substantially re-duces the duplication by classifying the type of triangles and processing triangles by the type. The experimental evalu-ation shows that the TTP algorithm outperforms provious MapReduce algorithms in most cases. Especially, for a twit-ter dataset, the proposed algorithm is more than twice as fast as existing algorithms. Moreover, the performance gap increases as the graph becomes larger and denser.
This work was supported by the National Research Foun-dation of Korea grant funded by the Korean government (MSIP) (No. NRF-2009-0081365). [1] http://newsroom.fb.com/Key-Facts. [2] http://snap.stanford.edu/. [3] http://an.kaist.ac.kr/pub date.html. [4] N. Alon, R. Yuster, and U. Zwick. Finding and [5] A.-L. Barab  X asi and R. Albert. Emergence of scaling in [6] L. Becchetti, P. Boldi, C. Castillo, and A. Gionis. [7] J. W. Berry, B. Hendrickson, R. A. LaViolette, and [8] S. Chu and J. Cheng. Triangle listing in massive [9] J. Cohen. Graph twiddling in a mapreduce world. [10] D. Coppersmith and S. Winograd. Matrix [11] J. Dean and S. Ghemawat. Mapreduce: simplified [12] R. Dementiev. Algorithm engineering for large data [13] J.-P. Eckmann and E. Moses. Curvature of co-links [14] X. Hu, Y. Tao, and C.-W. Chung. Massive graph [15] A. Itai and M. Rodeh. Finding a minimum circuit in a [16] U. Kang, C. E. Tsourakakis, and C. Faloutsos. [17] M. Latapy. Main-memory triangle computations for [18] B. Menegola. An external memory algorithm for [19] J. Myung and S.-g. Lee. Matrix chain multiplication [20] T. Opsahl and P. Panzarasa. Clustering in weighted [21] T. Schank and D. Wagner. Finding, counting and [22] S. Suri and S. Vassilvitskii. Counting triangles and the [23] C. E. Tsourakakis, U. Kang, G. L. Miller, and [24] J. Ugander, B. Karrer, L. Backstrom, and C. Marlow. [25] D. J. Watts and S. H. Strogatz. Collective dynamics of [26] T. White. Hadoop: The definitive guide . O X  X eilly [27] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao,
