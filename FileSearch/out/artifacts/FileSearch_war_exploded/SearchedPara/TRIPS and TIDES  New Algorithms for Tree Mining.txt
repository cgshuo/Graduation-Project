 Recent research in data mining has progressed from mining frequent itemsets to more general and structured patterns like trees and graphs. In this paper, we address the prob-lem of frequent subtree mining that has proven to be vi-able in a wide range of applications such as bioinformatics, XML processing, computational linguistics, and web usage mining. We propose novel algorithms to mine frequent sub-trees from a database of rooted trees. We evaluate the use of two popular sequential encodings of trees to systemat-ically generate and evaluate the candidate patterns. The proposed approach is very generic and can be used to mine embedded or induced subtrees that can be labeled, unla-beled, ordered, unordered, or edge-labeled. Our algorithms are highly cache-conscious in nature because of the compact and simple array-based data structures we use. Typically, L 1and L 2 hit rates above 99% are observed. Experimen-tal evaluation showed that our algorithms can achieve up to several orders of magnitude speedup on real datasets when compared to state-of-the-art tree mining algorithms. H.2 [ DATABASE MANAGEMENT ]: Database Appli-cations X  Data Mining Algorithms Tree mining, Prufer sequences, Depth first order codes, Fre-quent patterns, Embedding lists
Data mining or knowledge discovery deals with finding interesting patterns or information that is hidden in large Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00. datasets. Recently, researchers have started proposing tech-niques for analyzing structured and semi-structured datasets. Such datasets can often be represented as graphs or trees. This has led to the development of numerous graph mining and tree mining algorithms in the literature[24, 9, 11, 25, 15, 17, 21]. In this article we focus on the development of efficient algorithms for mining trees.

Mining for frequent subtrees has been shown to be useful in various applications. For example, mining user browsing andaccesspatternsontheworldwidewebcanbenefitfrom frequent subtree mining [25, 5]. Also, researchers [15, 28] have applied frequent subtree algorithms for solving bioin-formatic tasks like finding the similarity of phylogenetic trees. We have demonstrated that mining embedded sub-trees can be helpful in estimating selectivity of XML twig queries and in summarizing the XML documents [22]. Several re-searchers have developed association rule mining algorithms, and structure classifiers for XML documents based on their subtree structures [16, 26]. Design of network multicast routing algorithms can also benefit from frequent subtree discovery [6]. Wang et al [23] have also shown that, in the context of movie documents, mining for typical structures (trees) can reveal substantial information about the data.
In this work, we develop a novel method for mining in-duced or embedded subtrees from various types of rooted trees (ordered, unordered, labeled, unlabeled, edge-labeled etc.) [25, 10, 17, 21]. The proposed approach relies on a sequential encoding of the database trees. Specifically we examine the use of Pr  X  ufer sequence and Depth First order Sequence ( DF S ) based encodings for this purpose. Our ap-proach exploits the structure of the sequence encoding to generate candidate subtrees efficiently and to compute the support of said candidates in the database easily. It lever-ages embedding lists in generating a set of complete and non-redundant candidate patterns. One of the major advan-tages of our approach is that the sequential encoding allows us to operate on an array based representation of trees. This results in very efficient and cache-conscious algorithms that can suitably leverage the features of modern and emerging architectures [7].

Our experimental results show that the proposed approach is significantly faster than competing strategies on both real and synthetic datasets (up to 355 times speedup). A more in-depth analysis revealed that the proposed approach is extremely cache conscious (L1 hit rate: 99 . 6, L2 hit rate: 99 . 94, Cycles Per Instruction ( CPI ): 0 . 72) when compared to TreeMiner [25] (L1 hit rate: 96 . 59, L2 hit rate: 99 . 96, CPI: 1 . 2). We find that, on the real and synthetic datasets we evaluated, the Pr  X  ufer sequence based encoding shows a marginal yet consistent performance improvement over the DFS based encoding schemes.

Specifically, we make the following contributions in this article: First , we propose a new algorithm to mine frequent subtrees based on sequence encoding strategies (Pr  X  ufer and DFS codes), that are very efficient on real datasets. Second , we develop a novel methodology for generating complete and non-redundant candidate subtrees that is based on sequen-tial encodings of trees. Third , we show that the proposed algorithms are generic in nature and can be adopted to mine different types of trees.
There exist several algorithms in the literature that focus on mining various types of trees such as free trees, rooted trees, and ordered trees. Chi et al [3] present an excellent overview on frequent tree mining. One of the first algo-rithms in this area, TreeMiner , was proposed by Zaki [25]. TreeMiner mines for embedded subtrees from a forest (set) of rooted, ordered, and labeled trees. Influenced by the design of Eclat [27], TreeMiner represents trees in vertical format and uses scoping to prune the search space and efficiently mine for frequent sub-trees. A limitation of this method is that it uses pointer-based dynamic data structures and uses a lot of memory as we demonstrate in our experimental evaluation.
 Wang et al [21] have recently proposed two algorithms, Chopper and XSpanner to mine frequent embedded sub-trees. Chopper recasts subtree mining into sequence mining and uses PrefixSpan [12] to compute the set of frequent se-quences. These frequent sequences correspond to candidate subtrees that are evaluated against the database and those sub-trees that are infrequent are pruned away. A limitation of this method, as pointed out by the authors, is that it will only be effective if the set of candidate patterns (from the sequence mining step) contains few false positives. Unfortu-nately in many real datasets this is not the case. XSpanner falls under the category of algorithms, which generate fre-quent patterns without explicit candidate generation, draw-ing inspiration from FPgrowth [8]. It recursively projects the database and generates frequent subtrees. A potential problem with this approach is that the recursive projection may again lead to a lot of pointer chasing and poor cache behavior.

There exist various other algorithms which deal with a slightly different problem. Very recently, Tan et al [17] have proposed IMB3-Miner that mines embedded subtrees us-ing Tree Model Guided enumeration. This algorithm uses occurrence match support instead of traditional transaction-based support (definition that is used in frequent itemset mining). Asai et al [1] have proposed an algorithm Freqt that enumerates frequent ordered induced subtrees in a set of ordered trees. CMTreeMiner [4] proposed by Chi et al dis-covers all closed and maximal frequent subtrees from a set of rooted unordered trees. Termier et al have proposed two algorithms viz. Dryade and DryadeParent [19, 20] to mine closed frequent subtrees. They assume that no two siblings of a tree node can have the same labels. This assumption makes the complex subtree mining very simple and it might not be applicable in many real-world scenarios. Nijssen et al [10, 11] have proposed an efficient graph mining algorithm, Gaston . Gaston (and also other well known graph mining algorithms like g -Span ) can mine for special instances of graphs i.e., paths and trees. Gaston mines for free trees; moreover, it can only mine induced subtrees. Extension of such approaches for mining embedded subtrees is not trivial.
Sequential representations have been used by many re-searchers in several areas. For example, Pr  X  ufer sequences are used by Rao et al in the context of tree indexing [14]. They have proposed a holistic method, PRIX, to efficiently in-dex XML documents by transforming the tree isomorphism problem into subsequence matching. Basagni et al [2] have used pr  X  ufer sequences to efficiently encode the Steiner trees resulting from multicast groups, in their dynamic source multicast protocol.
Subtrees :A graph , G =( V, E ) consists of set of vertices (or nodes) V , and set of edges E  X  V X V .A tree is a connected graph that has no cycles. A rooted tree is a tree in which a vertex is distinguished from other vertices that is known as the root of the tree. Tree S =( V i ,E i )issaid to be an induced subtree of T =( V, E )if S is connected, V  X  V ,and E i  X  E .Inotherwords,  X  e =( v p ,v c )  X  E i , v is the parent of v c in T .Tree S =( V e ,E e )issaidtobean embedded subtree of T =( V, E )if S is connected, V e  X  V , and  X  e =( v a ,v d )  X  E e , v a is the ancestor of v d in T .For a given subtree S , each occurrence of S in T is known as the embedding of S in T . By embedding we mean the set of vertices of T , which are matched with vertices in S .
Tree Traversal: In post-order traversal , a node is tra-versed or visited only after all of its children are visited. In pre-order traversal , a node is visited before any of its chil-dren are visited. The node with the post-order traversal number (PON) 1 is referred to as the left-most leaf. The node with the largest pre-order traversal number is known as the right-most leaf. The unique path from the root to the left-most leaf is known as the Left Most Path (LMP) and the unique path from the root to the r ight-most leaf is referred as the RightMostPath (RMP). Pre-order traversal on the tree explores nodes in depth-first manner. We hence refer to the sequence generated by pre-order traversal as Depth First order Sequence (DFS).
 Pr  X  ufer Sequences :Pr  X  ufer sequences were first used by Heinz Pr  X  ufer to prove Cayley X  X  formula in 1918 [13]. Pr  X  ufer sequences provide a bijection between the set of labeled trees on n vertices and the set of sequences of length n  X  2onthe labels 1 to n . A simple iterative algorithm can be used to construct the pr  X  ufer sequence of a tree with n vertices. The algorithm starts with an empty sequence. At each step, the leaf with the smallest label is removed and its parent is ap-pended to an already constructed partial pr  X  ufer sequence. This process is repeated until only two vertices remain, i.e., it is repeated for n  X  2 iterations. In the resulting sequence, ( p 1 ,p 2 , ..., p n  X  2 ), p i is the parent of a node with the i est label. We extend this construction by repeating the pro-cedure for n iterations to produce a sequence of length n . When the last vertex is removed we leave the corresponding entry in the pr  X  ufer sequence empty, denoted by  X - X . Inter-estingly, for a given sequence S of length n  X  2 on the labels 1to n , there is a unique labeled tree whose Pr  X  ufer sequence is S . This can be proved fairly easily by induction on n .
In the above construction, labels are assumed to be unique i.e., there can exists at most one vertex with any given label. In practice, this is rarely true as multiple nodes in a tree can share the same label. Therefore, a unique labeling system is needed for our purpose with which pr  X  ufer sequences can be constructed. For a given tree in the database, we use the post-order traversal numbers of vertices as the unique set of labels over which the pr  X  ufer sequence is constructed. We refer to the pr  X  ufer sequence constructed from post-order traversal numbers as the Numbered Pr  X  ufer Sequence (NPS) . Furthermore, the Label Sequence (LS) of a tree is given by the sequence of labels of leaf nodes, which are deleted at each step. Precisely, NPS denotes the pr  X  ufer sequence rep-resented using post-order numbers, and LS denotes the la-bels of leaf nodes which are deleted. Both NPS and LS are ordered by the post-order number ( PON ). We jointly re-fer to these sequences as our Consolidated Pr  X  ufer Sequence CPS ( T )=( NPS,LS )( T ). Figure 1 (b) shows the example pr  X  ufer sequences for two trees, T 1 and T 2 .

Lemma 3.1. ( NPS , LS ) uniquely represents a rooted, la-beled tree.
 Problem Statement :Let D = { T 1 ,T 2 , ..., T n } denote a database of rooted trees and the support of a subtree S with respect to a tree T is given by: We define the support of S with respect to a database D as pattern if sup ( S, D ) is greater than or equal to a user-defined threshold minsup .Otherwise, S is said to be an infrequent pattern. Given a database of trees D and the minimum sup-port threshold minsup , the goal is to mine all frequent em-bedded or induced subtrees i.e., { S/sup ( S, D )  X  minsup If D contains rooted ordered (or unordered) trees, the goal of the subtree mining task is to mine for all frequent (em-bedded or induced) ordered (or unordered) subtrees. The definition of support can also be devised such that it takes the number of embeddings of S in T into account [17].
Broadly, tree mining algorithms can be categorized into two types, Apriori-based and Pattern-growth approaches. C-andidate generation and support counting are the two key steps in each algorithm. In Apriori-based algorithms, can-didates are generated level-wise. At level i , all candidate subtrees of length i are generated using frequent subtrees found in level i  X  1. Pattern-growth algorithms partition the search space into equivalence classes . They start with a node (a seed pattern) and generate all the frequent subtrees with that node as the root. The set of all subtrees resulting from a seed pattern is referred to as an equivalence class . In support counting step, generated candidate subtrees are evaluated for frequency. The challenge in candidate gener-ation is to traverse the exponential search space efficiently. All algorithms leverage the anti-monotone property of fre-quent patterns in efficiently pruning certain branches in the search space. According to thi s property, no super pattern of an infrequent pattern can be frequent. The challenge in support counting is posed by the isomorphism problem es-pecially in the case of embedded trees.
Our scheme is based on the pattern-growth approach. It first transforms the database trees into sequences. Specific properties of these sequences are then exploited to efficiently generate the candidate subtrees. For a given subtree S ,the sequences of all the trees in which S occurs are scanned to find the edges with which S can be extended. Each such edge together with S defines a new candidate subtree. Candidate subtrees with support greater than or equal to minsup are then processed recursively to generate bigger subtrees. The proposed method for generating candidates is non-redundant as the process is guided by database tree sequences (Section 4.1). Our novel method for candidate generation renders support counting step to be simple. Both candidate gener-ation and support counting with respect to S can be done simultaneously in one scan of the sequences in which S oc-curs. This generic approach can be applied to any type of sequential encodings as long as they exhibit some specific properties (described later). In the following sections we will show how our approach can be applied to pr  X  ufer sequences and depth-first order sequences. We first describe our TRee mIning algorithm using Pr  X  ufer Sequences ( TRIPS ). We then point out the changes to be made for applying similar ap-proach to depth-first order sequences.
In this section, we present our novel pr  X  ufer sequence based candidate generation technique. The pattern-growth ap-proach is employed to systematically generate the candi-date patterns (or subtrees). Hereafter, the terms  X  X attern X  and  X  X ubtree X  are used interchangeably. Assume we want to grow a subtree S with an edge e . Note that, growing S with an edge and growing S with a vertex are synonymous. The number of ways in which e can be added to S are very large. e can be attached to any node in S and for a given node v , e can be at any position in the list of v  X  X  children To avoid such large number of possibilities, we restrict the positions at which e can be attached. Suppose the left most path (LMP) in S is P = v r v 1 ...v m ,where v r is the root of S and v m is the left-most node. We allow e to be attached only to those nodes that are on the LMP of S .Further-more, e is always added as the first child. By following such an orderly mechanism we restrict the number of possibilities in which S can be grown with e .Itisfairlysimpletosee that this mechanism indeed generates every possible subtree in the search space and generates each subtree only once ;this is because the tree mining approach starts from frequent 1-node subtrees and generates (frequent) subtrees of 2 nodes, 3 nodes, etc., recursively (see Section 4.4).

Each candidate pattern generated from S is denoted by the tuple ( l, p ), where l is the label of the node that is being attached to S and p is the position at which l is attached. In other words, p gives the PON of the node in S to which l is added as the first child. We refer to each such pair ( l, p ) as an extension point of S .
 Example : Consider Figure 1 (a), which shows two patterns color. In S 1 ,theedge e =( A, B ) forms the left most path; hence, the new edge can be attached to any one of the two nodes of e . Therefore, S 11 ,S 12 are valid extensions from S 1 and their extension points are ( A, 3) and ( A, 1) respectively. In S 21 ,node B is added to node A , which is on the LMP of
If the trees are unordered then there is exactly one way in which e can be attached to v . tension point is ( B, 3). Note that, even though S 21 contains S 1 as a subtree it cannot be generated from S 1 ,asnode D is not on the LMP of S 1 .

It is worth noting that the extension points are defined with respect to a particular embedding of S in T ,atreein the database. Assume S has two embeddings E 1 and E 2 in a database tree T .Anextensionpointof S in T with respect to E 1 might not be a valid extension point of S in T with respect to E 2 . This is because the two embeddings might not have any node in common. An extension point with respect to one embedding might not even be connected to a node in another embedding. Even when two embeddings have a common node, the position of the common node might not be the same. Hence, an extension point must always be defined with respect to a particular embedding .

We explore the interesting relation between the LMP-based growth mechanism and pr  X  ufer sequences to develop a method that can efficiently generate the set of candidate patterns by taking the structure of database trees into ac-count. This relationship is captured in the following lemma:
Lemma 4.1. Let S denote a pattern and its sequences are given by CPS ( S )=( NPS,LS ) .Extensionpoint ( l, p ) of S corresponds to a prefix in the pr  X  ufer sequence of the resulting pattern, R = S  X  ( l, p ) .
 Proof. Please refer to [18].

The LMP-based candidate generation is systematic, but it does not deal with the problem of exponential search space efficiently. Though it uses the anti-monotone property of frequent patterns to prune the search space, it can still po-tentially generate redundant candidate patterns. A pattern is considered redundant if its support is zero. Consider the example database and patterns in Figure 1. Both S 11 and is zero as they do not occur either in T 1 or in T 2 . Therefore, generating S 11 and S 12 is redundant and should be avoided. On the other hand, S 21 is not only a valid extension of S 2 but also a subtree of T 1 .Thus, S 21 , whose support is 1, is not a redundant pattern. To avoid false positives like S 11 and S 12 , the candidate generation technique should take the topology of database trees into account. Such schema-conscious can-didate generation is not new and has been used in several algorithms like Gaston [11] and IMB3-Miner [17]. This can be achieved by using a special data structure called Embed-ding Lists . For a given pattern S and a database tree T ,the embedding list stores the information about all the embed-dings of S in T . This information can be used to quickly find the vertices with which S can be grown such that the resulting pattern is supported by T . We use a simple array-based embedding structure (section 4.1.1) that makes our algorithm cache-conscious and facilitates efficient implemen-tation. Since extension point, ( l, p ) is generated in schema-conscious manner, S  X  ( l, p ) corresponds to a subtree in at least one tree in the database.

Theorem 4.1. Consider extending a pattern S whose em-bedding is E in T , a database tree. Say, v is a node that is on the left of E in CPS ( T ) .If v is connected to a node u that is part of E ,then v defines a valid extension for S in T with respect to E .
 Proof. Please refer to [18].
 Theorem 4.1 plays a critical role in determining the nodes with which S can be extended to generate larger subtrees. For simplicity, consider the case of induced subtrees. Ac-cording to the theorem, it is sufficient to check the nodes which are on the left of E when finding extensions with re-spect to E . For each node that is on the left of E (say v whose label is l ), we need to check if v  X  X  parent is part of E or not. Precisely, we need to check whether LS [ NPS [ v ]] is part of E or not. We refer to this check as connectivity check . The position at which v is connected to E (i.e., p )canbe computed by maintaining a simple counter that is updated while traversing E .Extensionpoint( l, p ) thus generated uniquely defines a new subtree. When evaluating a node v , connectivity checks need to be carried out against each of the embeddings that is on the right of v in CPS ( T ). Since ex-tension points are gene rated by traversing the CPS of trees in D , false positive (or redundant) patterns are avoided.
This method can only mine for induced subtrees as the connectivity check is performed only for the parent of v . When mining for embedded subtrees, node v is considered as an extension point if any of its ancestors is part of the em-bedding. Hence, connectivity checks need to be carried out foreachancestorof v and against each embedding. As soon as an ancestor that is part of some embedding E is found, the connectivity check for v with respect to E needs to be stopped. Essentially, connectivity check finds parent-child relationships (in case of induced subtrees) and ancestor-descendant relationships (in case of embedded subtrees). Example : Consider the running example in Figure 1 (b), assume pattern S is being extended to generate the exten-sion points. The embeddings of S in T 1 and T 2 are marked we denote a node as [ l , n ], where l is the label of the node and n is its PON. In T 1 , search for extension points should be carried out from [ D, 5] to [ B, 1] (Lemma 4.1). Consider the node v =[ D, 5], whose parent is [ C, 6]. LS [ NPS [ v ]] = C is part of embedding E 1 and hence v is a valid extension to S (Theorem 4.1). v is attached to E 1 at position 1 (the PON of D  X  X  parent in S ). Hence, ( D, 1) defines an exten-sion point for S in T 1 with respect to E 1 . Consider the node [ F, 4], whose parent [ D, 5] is not part of any of the two em-beddings. However, F  X  X  ancestor [ C, 6] is part of E 1 .As aresult,( F, 1) is a valid extension point. Note that, ( F, 1) is not an extension point when mining for induced subtrees because the connectivity check stops with F  X  X  parent, [ D, 5]. Node [ B, 3] is attached to E 1 at position 2 (the PON of B  X  X  parent in S ) generating an extension point ( B, 2). Though [ C, 2] is part of E 2 , it must be evaluated against E 1 as it resides on the left of E 1 . Therefore, one node can be part of multiple embeddings but at different positions. Similarly, [ B, 1] gives an extension point ( B, 1) with respect to E 2 . Note that, evaluating [ B, 1] involves a connectivity check with respect to both E 1 and E 2 ,because[ B, 1] is to the left of both E 1 and E 2 in CPS ( T 1 ). Since [ B, 1] is not connected to E 1 , it does not generate any extension point with respect to E 1 . Thus, the algorithm generates four extension points, ( D, 1), ( F, 1), ( B, 2), and ( B, 1) by scanning T 1 . Similarly, the algorithm generates ( D, 1) and ( B, 2) by processing T 2 .
We now briefly describe the structure of our array-based embedding lists. As mentioned earlier, this structure stores the information of all the embeddings of a pattern S in the given database tree T . This structure is maintained in a per tree basis. Each entry in the embedding list corresponds to anodein T that is matched with a node in S .Theseentries are of the form ( m, ptr )where m is the PON of the matching node and ptr is the pointer to the parent node in the pat-tern. The matching nodes of the two different vertices are separated by a special entry, (0 ,  X  2). Entries corresponding to the nodes, which are matched to the root of a pattern, have their ptr set to a value of  X  1. This is because they are the initial nodes which were added to the embedding list. Please note that the number of nodes in the last section of the embedding list (between last two separators) is equal to the number of embeddings of the pattern. Each node in the last section together with nodes pointed to directly or indirectly by them defines the LMP of the embedding. Therefore, when a pattern is being extended, the traversal of the embedding list is constrained only to the LMP of the embedding. Figure 2 (a) shows the example embedding lists for the database trees in Figure 1 (b) with respect to the pattern shown. Please refer to [18] for more details.
Such an array-based structure is simple and gels well with the recursive structure of our algorithm. To illustrate the point, assume the pattern A  X  C has two extension points, B and D .First A  X  C is extended with B (say, the resulting pattern is P ) to generate all the subtrees extending from P . Once the mining with respect to P is completed, A  X  C needs to be extended with D . At this time, the matching nodes of C in the embedding list can be replaced with the matching nodes of D as C  X  X  matchings nodes are no longer required. Hence, our array-based embedding list not only is simple but also facilitates efficient recursive implementation of our algorithm.

The space overhead incurred by embedding lists needs special mention as their maintenance demands a non-trivial amount of memory. The amount of overhead is directly de-pendent on the distribution of distinct labels ( L )overtheset of nodes ( N )ofagiventree( T ). If | L | and | N | are compara-ble in number, then the number of matches in T for a given pattern would be very few. This results in small embedding lists. Instead, if | L | &lt;&lt; | N | then the number of matches for a given pattern would be large. Let us consider the worst case scenario where all the | N | nodes in a given tree has the same label (i.e., | L | =1),say v . This tree results in matches for a one-node pattern (every node in the tree is a match). When the pattern has two nodes (edge v  X  v ), the number of matches can be up to | N | X  X  N  X  1 | .Addto that, when the dataset contains a very large number of such trees, the overhead incurred in maintaining the embedding lists of all trees increases tremendously. Such extreme but rare scenarios demand algorithms which do not require to maintain embedding lists.
The candidate generation mechanism makes the support counting step trivial, normally a costly step. This is done by maintaining a hash table H ,knownas Support Structure that stores the counts for each of the extension points found. Whenever a new extension point ( l, p ) is generated, H is probed to see if ( l, p ) is already present in H or not. If ( l, p ) H , then the count associated with ( l, p ) is incremented by 1 to reflect its new support. If not, the new entry is added to H with a count of 1. Once all the trees are scanned for extension points, H contains the set of extension points and associated supports. The resulting set of patterns is given by, R = S  X  X  ( l, p ) / ( l, p )  X  H  X  support (( l, p )) Each pattern in R is considered again by the candidate gen-eration algorithm to generate larger patterns. Figure 2 (b) shows the example support structure. Please refer to [18] for more details.
Though TRIPS is based on pr  X  ufer sequences, the idea of extending sequences for candidate generation can be applied to other sequence encodings. In this section, we describe such an application by devising Tree mIning algorithm using DEpth first order Sequences ( TIDES ). TRIPS and TIDES differ only in their candidate generation step. The support counting step is the same for both the algorithms. Method of candidate generation in both the algorithms is quite sim-ilar in its spirit except for a few differences. While TRIPS restricts the growth points to the Left Most Path of the pat-tern, TIDES restricts them to the Right Most Path (RMP). Therefore, an extension point ( l, p ) now refers to the addi-tion of a node with label l at a node whose depth first order number is p . Use of RMP instead of LMP is motivated by the relation between RMP and depth first order sequences that is similar to the relation between LMP and pr  X  ufer se-quences. Hence, similar to Lemma 4.1 and Theorem 4.1, we can prove the following lemmas in the context of depth first order sequences.

Lemma 4.2. Let S denote a pattern with depth first order sequence DF S ( S ) .Extensionpoint ( l, p ) of S corresponds to a postfix in the depth first order sequence of the resulting pattern, R = S  X  ( l, p )
Theorem 4.2. Consider extending a pattern S whose em-bedding is E in T , a database tree. Say, v is a node that is on the right of E in DF S ( T ) .If v is connected to a node u that is part of E ,then v defines a valid extension for S in T with respect to E .

Since the depth first order sequences are based on pre-order traversal of trees, growth on the right most path is the same as growing the sequence on the right hand side. The embedding list in TIDES keeps track of the nodes, which form the RMP of the pattern at hand.
 Comparison of TRIPS and TIDES: TIDES can of-fer certain optimizations, which are difficult to achieve in TRIPS . In the candidate generation step, TRIPS scans the entire sequence that is to the left of embedding. This in-volves processing of nodes, which are not in the subtree of the pattern. Consider the example shown in Figure 1 (b) and assume the pattern being extended is an edge A  X  D . In T 1 ,only[ B, 3] and [ A, 4] are valid candidates, as they are present in the subtree of the pattern. In TRIPS , the connec-tivity check is performed not only on these two nodes but also on [ B, 1] and [ C, 2], as they are on the left of embedding of the pattern. TIDES can avoid such redundant processing by making use of scope data structures similar to the ones described in [25]. Scope structures enable us to focus only on nodes that are part of the subtree of the pattern. This benefit comes at the cost of higher space overhead that is incurred by storing the scope values (two integers) for every match. In other words, every embedding now needs to be associated with the scope. This overhead can be quite high if the number of embeddings of a pattern in the tree is very large (e.g. large trees with very few distinct labels). TIDES also has certain drawbacks when compared to TRIPS .The connectivity check on a node v involves traversing all the ancestors of v i.e., exploring the path from v to the root of the tree. Such a traversal is straight forward in TRIPS ,as pr  X  ufer sequences are constructed based on parent-child rela-tionships. To derive such relationships efficiently in TIDES , explicit pointers to parent nodes must be created for each node in the depth first order sequence.

In a nutshell, our sequence based candidate generation technique can be applied to any type of sequential encod-ing schemes as long as one can relate the growth in the trees to the growth in the corresponding sequences. This in-volves building relationships similar to the ones mentioned in Lemma 4.1 and Lemma 4.2. We now consolidate our main contributions in the next section. Algorithm 1 Subtree Mining Algorithm Require: D = { T 1 ,T 2 ,...,T N } ,minsup 1: F 1 = readTrees ( D ) 2: for all v in F 1 do 3: mineTrees ( NULL ,( v ,  X  1), D ) 4: end for
In this section, we abstract out the ideas that are inher-ent in both TRIPS and TIDES to summarize our subtree mining algorithm (Algorithm 1). During the first scan of D , frequent nodes are identified ( F 1 ). For each node v in F 1 ,the procedure mineTrees (Algorithm 2) is called to recursively mine the equivalence class of v , i.e., all subtrees whose root is v . mineTrees is a recursive procedure that applies the candidate generation algorithm on the given pattern, pat . At every level of recursion, a new pattern newpat is gen-erated by extending pat with an extension point ( l, pos ). tidlist provides the projection of database with respect to pat . It contains the identifiers of trees in which pat occurs as a subtree. When extending pat , only the sequences of trees in tidlist need to be scanned. For a given pattern and an extension point, mineTrees first identifies the location of ( l, pos )ineachtreeof tidlist and updates the corresponding embedding list (lines 3-8 in Algorithm 2). At the same time, newtidlist is constructed to include the identifiers of trees in which newpat has an embedding (line 6). Once the all em-beddings of newpat are found, the candidate generation al-gorithm is applied to find the extension points with respect to newpat (lines 10-13). For each frequent extension point, mineTrees is called recursively to mine larger patterns (lines 14-18). Note that, Algorithm 2 shows two different loops in lines 3 and 10: one for finding the embedding of newpat and the other for extending the embedding. In the actual implementation, these two loops can be combined so that only one scan on the tidlist is performed. Thus, our algo-rithm, for a given pattern, can generate and find the patterns simultaneously , in a single scan of pr  X  ufer sequence.
As described in section 4.1, our algorithm can easily be adopted for mining both induced and embedded subtrees. Induced subtrees can be mined by adjusting the range of nodes for which the connectivity check is performed. Though the algorithm described deals with labeled trees, it is fairly easy to see that it is applicable even if the trees which are Algorithm 2 Mining a given pattern mineTrees ( pat ,( l , pos ), tidlist) 1: newpat =extend( pat , l , pos ) 2: newtidlist = NULL 3: for all T in tidlist do 4: if ( l , pos ) is an extension point for pat in T then 5: update embedding list of T 6: add T to newtidlist 7: end if 8: end for 9: H = NULL 10: for all T in newtidlist do 11: Scan T for extension points of newpat 12: Add generated extension points to H 13: end for 14: for all h in H do 15: if h.support  X  minsup then 16: mineTrees ( newpat ,( h.l , h.pos ), newtidlist ) 17: end if 18: end for not labeled . Moreover, it can be modified to handle edge labels by making simple extensions to the algorithm while maintaining the simplicity in representation. Each pair in CPS ( T ) i.e., ( NPS [ v ] ,LS [ v ]) represents an edge in T .Ifthe edges are labeled, a new sequence can be incorporated into CPS to provide the edge label for each pair in the pr  X  ufer sequence. Note that, this change in the representation is minimal and we cannot do better than this.
 Our algorithm can also be used to mine unordered trees . The only change that is required in Algorithm 2 is at line 11, scanning T for extension points. Assume, a node v in the tree T is matched with the pattern X  X  root node. Since the children of v are unordered, connectivity check needs to be performed for every descendant of v (not just the descen-dants of the left-most child of v ). We thus need to start the scan from a position that is immediately to the left of v , while searching for extension points. The modified pattern growth mechanism can potentially yield duplicate patterns. To avoid the generation of duplicates, a strict total order must be enforced on the set of labels, e.g., lexicographic or-dering. Furthermore, we have shown that our algorithms canbeappliedto any type of sequence encodings that follow specific properties (last para of section 4.3). Hence, our ap-proach is generic with respect to the representation of trees as well as the type of subtrees to be mined.
In this section, we present the experimental evaluation of the proposed approach on both synthetic and real datasets shown in Table 1. We compare the performance of our ap-proach against TreeMiner [25]. All the experiments were performed on an Itanium 2 based system with 4 GB of main memory and a 1.3GHz processor. In the following discus-sion, dataset sizes are expressed in terms of number of trees, and minsup refers to the absolute support rather than the fraction, as defined earlier. In the first set of experiments, we evaluate our TRIPS algorithm on four different synthetic datasets. As shown in Table 1, the synthetic datasets DS 1and DS 2 are gener-ated using the PAFI toolkit developed by Kuramochi and Karypis ( PafiGen ) 2 . The datasets DS 3and DS 4aregen-erated from the tree generator created by Zaki ( T reeGen ) The table also shows the parameter settings used for creat-ing these datasets. Since PafiGen can create only graphs, we have extracted spanning trees from these graphs and used in our analysis. Please note that the input parameters are just the guidelines to the generator (especially to T reeGen ). Actual data that is created might not have the exact same statistics as the parameters provided. In the following, no-tation D  X  num refers to a dataset D with num trees.
The performance of TRIPS against TreeMiner on the syn-thetic datasets is shown in Figure 3 (a) and (b). TRIPS is clearly scalable and continues to perform better as the dataset size increases. It achieves a speedup of 11 . 6on DS 1-40 K and a speedup of 8 . 6on DS 4-100 K . Wehaveobserved that the skewness of the dataset directly affects the min-ing time. If the dataset is skewed, most of the frequent subtrees are produced from a small number of equivalence classes ( F 1 in line 2 of Algorithm 1). This results in smaller mining times. The trees generated from PafiGen are less skewed compared to the trees from TreeGen . Therefore, the mining times of the PafiGen datasets are large, even when the datasets are small. For example, on the datasets with 40 , 000 trees, TRIPS ( TreeMiner ) spent 790 (8042) seconds in mining trees in DS 1 whereas it spent only 315 (2711) sec-onds in mining trees in DS 4. Higher speedups from the Pafi datasets shows that TRIPS can handle the difficulty posed by (lesser) skewness better than TreeMiner .

Figure 3 (c) and (d) depict the effect of minsup on the mining time and the number of frequent patterns found in the PafiGen datasets. Not surprisingly, the execution time and the number of patterns increases as minsup decreases. Notably, the performance difference between TRIPS and TreeMiner continuously goes up with the decrease in min-sup .On DS 2-40 K ,asthevalueof minsup decreases from 5 to 1, the number of frequent patterns increases by 339 times. In this case, the execution time of TreeMiner in-creased by 65 times, whereas the execution time of TRIPS increased only by 15 times. This is because of two reasons: large number of join operations; large number of false pos-itive patterns. First ,atlowsupportlevels, TreeMiner has to perform costly join operations on a very large number of scope lists . Though TRIPS has to perform more connec-tivity checks (at low minsup ), the increase in run time is not very high. The time taken for a connectivity check, in general, is very small because it is performed only on nodes present on LMP. Moreover, for a given pattern the set of = 1) (a &amp; b) Speed up (c &amp; d) Effect of minsup nodes for which the connectivity check is performed does not depend on the support level. It only depends on the tree size and the matching nodes of the pattern (Theorem 4.1). Whereas in TreeMiner , the number of scope lists and hence the number of joins performed is highly dependent on the value of minsup . Second , TreeMiner naively performs the join operation on scope lists and hence it has the poten-tial for generating a large number of false positive patterns. For example on DS 1-10 K ,at minsup =1, TreeMiner pro-duced 1041 million candidates out of which only 173 mil-lion (approximately 16%) are frequent. On the other hand, TRIPS will never generate a redundant candidate pattern as the candidate generation is guided by the topology of the database trees. Thus, the strategies adopted by TRIPS enable us to mine large datasets at very low support levels efficiently . The performance of TIDES is similar to that of TRIPS on all synthetic datasets.
In the second set of experiments, we evaluated the pro-posed algorithms on two different real datasets CSLOGS and TREEBANK . CSLOGS 4 contains web logs collected over a month in the Computer Science Department at the Rensse-laer Polytechnic Institute. It contains 59 , 691 user browsing access patterns for 13 , 361 different web pages. On average, atreein CSLOGS dataset has 12 . 94 nodes and the largest tree is of 428 nodes. The TREEBANK dataset 5 is made up of language treebanks, which have been widely used in computational linguistics. Treebanks are XML documents, which capture the syntactic structure of English text and provide a hierarchical representation of the sentences in the text by breaking them into syntactic units based on part of speech. TREEBANK has a total of 52 , 581 XML docu-ments, which are narrow and have deep recursion of element names. The largest tree in this dataset has 648 nodes and the average number of nodes in a tree is 68 . 03.
Figure 4 (a) presents the run time comparison of our al-gorithms against TreeMiner on CSLOGS .Theoverallper-formance trend is similar to the one observed in synthetic datasets, but the speedup achieved is much larger in case of real datasets. At minsup = 800, TreeMiner spent 8748 . 5sec-onds in mining the frequent patterns, whereas TRIPS spent only 24 . 61 seconds giving a speedup of 355 . 43. When min-sup is decreased, time spent by TreeMiner increases much more quickly than TRIPS and TIDES . With the decrease in minsup from 1000 to 900, quick rise in mining time in all the algorithms is due to the presence of frequent patterns inside very large trees (which were not frequent at minsup = 1000). The mining time of TreeMiner increased by 300 times, while it is increased only by 6 times in TRIPS .

Figure 4 (b) shows the amount of virtual memory (Res-ident Set Size) used by the algorithms. TIDES memory consumption is slightly higher compared to TRIPS because of the extra pointers to the parent nodes (for traversing RMP efficiently). If TIDES employs the scope values for each embedding, the difference in memory usage would be much higher. At low support levels the amount of mem-ory consumed by our algorithms is much lower compared to TreeMiner .At minsup = 800, TreeMiner used 2505 MB of memory and TRIPS completed the mining process by using just 60 . 84 MB of memory. Furthermore, the memory space consumed by TreeMiner raises exponentially with decrease in minsup . We suspect that this is because of the trees with large number of nodes and very few distinct labels. As mentioned in section 4.1.1, in such trees the number of em-beddings for a given pattern would be high. This results in large scope lists (in TreeMiner ) and large embedding lists (in our algorithms). Since an entry in embedding list is a lot simpler and smaller than an entry in scope list, TreeMiner experiences a quick rise in memory usage. At minsup =700, TreeMiner was aborted after 54 hours with memory usage more than 4 GB ( TRIPS : 300 . 27 seconds &amp; 335 . 97 MB). At very high support values (for example, 1200 in the fig-ure), both TRIPS and TIDES use slightly more memory compared to TreeMiner because of the embedding lists.
Similar conclusions can be drawn from experiments con-ducted on the TREEBANK dataset (Figure 4 (c &amp; d)). The time spent in mining and the amount of virtual memory used increased very sharply when using TreeMiner . For our algorithms, increase in execution time and virtual memory is slower when compared to TreeMiner , but is faster when compared to the increase observed on CSLOGS (Figure 4). This can be attributed to the narrow and deep structure of the XML trees in the TREEBANK dataset. Even in this case, our algorithms exhibit excellent performance in terms of both execution time and memory consumption. At a sup-port level of 40 , 000, TreeMiner ran for 7 . 3 hours consuming 2 . 2 GB of virtual memory. TRIPS , on the other hand, spent only 266 seconds with memory usage of 221 MB, resulting in a speedup of 98 . 93. Please note that for the experiment at minsup =30 , 000, TreeMiner was ran on a Itanium 2 based system with 12 GB of main memory. This system has been used only for this experiment.
 Finally, a note on the performance differences between TRIPS and TIDES : as shown in Figure 4, TRIPS performs marginally better than TIDES . In terms of memory con-sumption, TIDES uses more memory than TRIPS for the reasons presented in the above discussion. We ascribe the difference in execution times to the structure of database trees and frequent patterns. Tr ee and frequent pattern struc-tures govern the number of connectivity checks performed and affect the execution time. The difference in run times is higher on the CSLOGS dataset than the TREEBANK dataset. However, in all cases both TIDES and TRIPS per-form several orders of magnitude better than TreeMiner .
We use the Intel VTune Performance Analyzers 6 to per-form cache performance analysis of our algorithms. This tool profiles the program execution at the level of source code and provides performance characteristics for each func-tion in the implementation. Results presented in this sec-tion are obtained using the TREEBANK dataset at min-sup = 45000. Both TRIPS and TIDES exhibit excellent cache performance with ( L 1hitrate, L 2hitrate, CPI ) Whereas, TreeMiner produced hit rates and CPI of (96 . 59, 99 . 96, 1 . 2). We observed that TreeMiner has slightly lower L 1 hit rate. It also suffers from memory management is-sues. 49% of TreeMiner  X  X  time is spent in the library, libc -2 . 3 . 4 .so which contains several memory management rou-tines like malloc() and free(). TRIPS and TIDES ,onthe other hand, spent only 2 . 3% and 3 . 7% of time in that library. The simple array-based data structures (sequence encodings and embedding lists) we use facilitate efficient memory man-agement and make our algorithms cache-conscious. On the other hand, TreeMiner  X  X  pointer-based dynamic structures make the memory management a difficult task. This prob-lem worsens with decreasing values of minsup because of the exponential increase in memory size that is occupied by scope lists.

In all the three algorithms, candidate generation is the most expensive step. TreeMiner spent about 75 seconds (22 . 8% of run time) in scope-list joins (functions check ins , check outs ,and compare ). Both TRIPS and TIDES spent only about 31 seconds (63 . 7% of execution time) in travers-ing the embedding list and performing the connectivity chec-ks. High percentage of time spent in user-level code depicts the better CPU utilization by TRIPS and TIDES . Similar results are observed on synthetic datasets [18]. For example, CPU utilization of TRIPS (TreeMiner) is 99 . 3% (90 . 0%) and 99 . 3% (72 . 5%) on DS 1  X  50 K and DS 4  X  1 M , respectively.
As part of our analysis, we also compared our approach against XSpanner [21], using the binary provided by the au-thors. Please note that the following results are obtained on an Intel P4 based system with a 2 . 4GHz processor and 4 GB of main memory. While we expected our approaches to outperform XSpanner, we also expected XSpanner to out-perform TreeMiner as demonstrated in [21]. The results we obtained are surprising in that XSpanner achieves perfor-mance that is typically much worse than that of TreeMiner for many datasets. One possible explanation for this behav-ior is the fact that the memory footprint can be very large for such pattern-growth projection based approaches, poten-tially resulting in memory thrashing and large I/O costs [7]. Additionally, XSpanner is likely to suffer from poor cache performance due to the complexity of the pseudo-projection step. For example, on DS 1 XSpanner took 1166 seconds whereas TreeMiner has taken only 38 . 31 seconds. On DS 3, the mining time of XSpanner and TreeMiner are 245 and 3 . 1 seconds, respectively. On all the datasets, TRIPS ran faster than TreeMiner even on this architecture ( DS 1 : 24 seconds and DS 3:1 . 1 seconds). We observed similar results on both DS 2and DS 4. All the results were obtained from datasets with 50 , 000 trees and at minsup = 25. Only on some toy datasets with 5 to 10 trees, the run times of XSpanner are comparable to TreeMiner . We could not evaluate XSpanner on the two real datasets because XSpanner binary expects the number of distinct labels to be less than 10 , 000. In the CSLOGS and TREEBANK datasets, the maximum label number is 13 , 361 and 1 , 387 , 266, respectively.
In this paper, we have proposed new algorithms for mining frequent induced or embedded subtrees from rooted trees. Novel sequential encoding based strategies are proposed, which facilitate the fast generation of complete and non-redundant set of candidate subtrees. We evaluated the pro-posed algorithms against TreeMiner on various synthetic and real datasets. We show that our approach achieves several orders of magnitude im provement on real datasets, when compared to state-of-the-art algorithms. Specifically, we obtained speedup of 355 and 98 on the CSLOGS and TREEBANK datasets, respectively. Our algorithms make use of simple array-based data structures and show excellent cache and memory performance. We also have demonstrated that our techniques are generic and can easily be adopted to mine various types of trees i.e., ordered, unordered, labeled, unlabeled, edge-labeled, etc.

In the future, we would like to extend the proposed ap-proaches to devise parallel algorithms for tree mining. We would like to develop algorithms which do not employ em-bedding lists as the overhead incurred by them can poten-tially be prohibitive. We also want to characterize different tree mining algorithms in terms of their cache behavior and the type of datasets on which they perform well.
 Acknowledgments. This work is supported by NSF grants CAREER-IIS-0347662, RI-CNS-0403342, and NGS-CNS-0406386. We would like to thank authors of TreeM-iner and XSpanner for providing us the source code or bi-nary. We also thank Amol Ghoting, Greg Buehrer, and Qian Zhu for the insightful discussions and valuable suggestions.
