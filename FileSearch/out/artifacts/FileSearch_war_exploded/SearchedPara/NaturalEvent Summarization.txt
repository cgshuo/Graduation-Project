 Event mining is a useful way to understand computer sys-tem behaviors. The focus of recent works on event mining has been shifted to event summarization from discovering frequent patterns. Event summarization seeks to provide a comprehensible explanation of the event sequence on certain aspects. Previous methods have several limitations such as ignoring temporal information, generating the same set of boundaries for all event patterns, and providing a summary which is difficult for human to understand.

In this paper, we propose a novel framework called natu-ral event summarization that summarizes an event sequence using inter-arrival histograms to capture the temporal rela-tionship among events. Our framework uses the minimum description length principle to guide the process in order to balance between accuracy and brevity. Also, we use multi-resolution analysis for pruning the problem space. We demonstrate how the principles can be applied to generate summaries with periodic patterns and correlation patterns in the framework. Experimental results on synthetic and real data show our method is capable of producing usable event summary, robust to noises, and scalable.
 Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications-Data Mining General Terms: Algorithms, Experimentation, Performance Keywords: Event Summarization, Minimum Description Length, Wavelet Transformation Many system applications produce and process temporal events (i.e., event sequences with associated time-stamps), for example, system logs, HTTP requests, database queries, network traffic data, etc. These events capture system states and activities over time, and mining historical event data is a useful way to understand and optimize system behaviors. By examining event patterns, system administrators can set up event and incident management rules to eliminate or mit-igate IT risks. It has become a standard way to manage large scale distributed systems in IT companies like IBM [13] and HP [3].

Most existing event mining research efforts focus on episodes mining or frequency pattern discovering [2, 16, 19]. These methods simply output a number of patterns that are in-dependent to each other, so they fail to provide a brief and comprehensible event summary revealing the big pic-ture that the dataset embodies. Obtaining insights from the huge number of patterns remains to be a daunting task for practitioners.

Instead of discovering frequent patterns, recent works on event mining have been focused on event summarization, namely how to concisely summarize temporal events [14, 15, 25]. Current state-of-art event summarization techniques are based on sequence segmentation where an event sequence is first split into disjoint segments and patterns are then generated to describe events in each segment. Kiernan and Terzi [14, 15] model the set segmentation problem as an optimization problem that balances between the shortness of the local models for each segment (i.e., the summary) and the accuracy of data description. Their method re-veals the local patterns of the sequence but fails to pro-vide the inter-segment relationships. Based on their work, [25] provides a more sophisticated method that not only de-scribes the patterns in each segment but also learns a Hidden Markov Model (HMM) to characterize the global relation-ships among the segments.
Example 1. Figure 1 shows an event sequence contain-ing 4 event types, where event type A denotes  X  X n event created by an antivirus process X , event type B denotes  X  X he firewall asks for the access privilege X , event type C denotes  X  X  port was listed as an exception X , event type D denotes  X  X he firewall operation mode has been changed X . The ap-proach presented in [25] segments the sequence into 4 seg-ments based on the frequency changes of the events. For each segment, the approach further clusters the event types according to the frequency of each event type. Finally, an HMM is used to describe the transactions between intervals.
The result of [25] can produce a comprehensive summary for the input sequence. However, these frequency-based methods have several limitations: (1) They only focus on the frequency changes of event types across adjacent seg-ments and ignore the temporal information among event types within a segment. As a result, the generated summary Fi gure 1: A motivating example. Event type A de-notes \an event generated by antivirus monitor", event type B denotes \ rewall asks for the access privilege", event type C denotes \a port was listed as an exception", event type D denotes \ rewall op-eration mode has been changed". fails to capture the temporal dynamics of event patterns. (2) They generate the same number of event patterns with the same boundaries for all event types. The unified pattern boundary requirement is impractical since different event types can have different underlying generating mechanisms. Consider in a distributed system, events may come from thousands of hosts that are not related to each other, forc-ing global segmentation means a simple event episode can be split to many segments because other events do not occur uniformly during the period; this yields a large number of small segments that may unnecessarily inflate the event sum-mary. Having different boundaries for different event types could improve the event pattern identification and lead to better summaries. (3) Their generated summary (e.g., event distributions or HMMs) is difficult for system administrators to understand and take actions.
In this paper, to address the above limitations, we take a novel approach called natural event summarization ( NES for short) which first uses inter-arrival histograms to capture temporal relationships among same-type and different-type events, then finds a set of disjoint histograms to sum-marize the input event sequence based on minimum descrip-tion length principle (MDL) [12], and finally represents the generated summary using event relationship networks. Us-ing inter-arrival histograms allows for different boundaries for different event types. Moreover, inter-arrival histograms provide a conducive way to describe two main types of event patterns: the periodic patterns and the correlation patterns . These patterns capture the temporal dynamics of event se-quences and can be used to generate the summaries. Many action rules can be derived almost directly from the gener-ated summary. Figure 2 shows the output summary gener-ated by our natural event summarization for Example 1. In the example event sequence, events of type C; D always ap-pear after B for a short delay in both the second and fourth segments. Similarly, events of type C; D always appear af-ter B for a long delay in both the first and third segments, Therefore, two correlation patterns: B  X  C; B  X  D are identified. The change of periods implies that there may exist ill-configuration of the firewall. For events of type A , they appear regularly throughout the whole sequence, so all the instances of event type A belong to only one segment. Since event type A is the antivirus monitoring process event, its stable period shows that the antivirus process works nor-mally. Note that in this paper we only consider pairwise cor-Fi gure 2: Output summary of our proposed ap-proach. relations for events, since they are critical in understanding system behaviors. Discovering of correlation among three or more event types (two or more events trigger one event) is quite time-consuming and is one of our future works.
The framework of natural event summarization is shown in Figure 3. Our framework is based on inter-arrival his-tograms which capture the distribution of time intervals be-tween events. These histograms provide a concise way to describe periodic patterns (of the same event type) and cor-relation patterns (of different event types). In this paper, we only focus on summarization on the aspect of temporal patterns of the events, since such information tells most of the story of the running status of the system.

The event summarization problem is formulated as finding a set of disjoint inter-arrival histograms, each representing a certain periodic pattern or correlation pattern, to approx-imate the original input sequence using MDL. MDL is an elegant theory to naturally balance the accurateness and the conciseness of the summarization information.

Although MDL has been used in previous event summa-rization methods for encoding the event segments, it is used here for encoding the inter-arrival histograms and for identi-fying the set of disjoint histograms for summarization. The problem of finding a set of disjoint histograms can be solved optimally in polynomial time by seeking a shortest path from the histogram graph that represents the temporal relations among histograms. To improve the efficiency of event sum-marization, we also explore an efficient alternative by using the multi-resolution property of wavelet transformation to reduce the size of the histogram graph. The final summary of our natural event summarization can be described as an easy-to-understand event relationship network (ERN) where many actionable rules are readily available.

In summary, our contributions are: (1) We propose a sys-tematic and generic framework for natural event summariza-tion using inter-arrival histograms . Through natural event summarization, an event sequence is decomposed into many disjoint subsets and well-fitted models (such as periodic pat-terns and correlation patterns) are used to describe each sub-set. Inter-arrival histograms demonstrate clear event pat-terns and capture temporal dynamics of events. To the best of our knowledge, this is the first work of using inter-arrival histograms for event summarization. (2) We formulate the event summarization problem as finding the optimal combi-nation of event patterns using MDL principle . The usage of MDL principle automatically balances the complexity and the accuracy of summarization and makes our framework parameter free. (3) We present the encoding scheme for his-tograms and cast the summarization problem as seeking a shortest path from the histogram graph. (4) We also pro-pose a boundary pruning algorithm that greatly accelerates 1 1 1 1 1 1 1 1 the event summarization process by taking advantage of the multi-resolution property of wavelet transformation.
The rest of this paper is organized as follows. We present the interval histogram model for event summarization and its encoding scheme in Section 2 and 3 respectively. In Sec-tion 4, we introduce the algorithm of finding the best sum-marization solution. Then in Section 5, we present the seg-ments boundary pruning algorithm that greatly improves the efficiency of our framework. In Section 6, we present our experiment evaluation. Finally, we discuss the related work in Section 7 and conclude in Section 8.
An event sequence D comprises of a series of event in-stances in the form of ( e; t ) ordered by their timestamps: D = ( &lt; t 1 ; e 1 &gt;;  X  X  X  ; &lt; t n ; e n &gt; ), where t and e i is the type of the event. Each instance belongs to one of the m types E = { e 1 ;  X  X  X  ; e m } . We first describe the inter-arrival histograms used in our framework to represent the inter-arrival distribution of time interval between events.
Given two event types x and y , let S be the subsequence of D that only contains events of types x and y . Suppose S is split into k disjoint segments S = ( S 1 ; S 2 ; :::S We use an interval histogram (or inter-arrival histogram) h xy ( S i ) to capture the distribution of time interval between events of type x and type y in S i . Specifically, the bin h xy ( S i )[ b ] is the total number of intervals whose length is b . Let next ( t; y ) denote the timestamp of the first type y event that occurs after t in S i .

Definition 1. Inter-arrival histogram: where t i denotes the timestamp of e i .

If x  X  = y , then the inter-arrival histograms capture the time intervals for the events of different types; for the case of x = y , they capture the time intervals of events of the same type. Given an interval histogram, we can use a standard histogram to approximate it. The standard histogram is formally defined with definition 2.

Definition 2. Standard Histogram is a special kind of interval histogram with one or two non-empty bin and all these non-empty bins have the same value # intervals n # intervals indicates the number of intervals and n non in-dicates the number of non-empty bins. We use  X  h xy ( S i denote the corresponding standard histogram of h xy ( S i
Note that the two types of event relationships: periodic patterns and correlation patters can be easily described using standard histograms. The periodic patterns and correlation patters is formally defined in definition 3.

Definition 3. Periodic pattern and Correlation pat-tern: A pattern is a 5-tuple ( t s , t e , x , y , P ), where (1) t and t e denotes the start position and end position of the event sequence described by the pattern respectively. (2) x and y denote the types of events involved in the pattern, (3) P contains the periodic parameters. The pattern can contain 1 or 2 period parameters, which indicate the inter-arrival value between event x and y . Moreover, if x = y , this pat-tern is a periodic pattern , otherwise, it is a correlation pattern .

Example 2 provides a detailed illustration about how to utilize standard histogram and periodic/correlation patterns to summarize a given event sequence.

Example 2. Given an event sequence D , the timestamps for e a , e b and the related subsequences are listed in Table 1 ( S for event type a; b is the same as D ). There is only one segment in S and there exists a periodic pattern for e a and a correlation pattern between e a and e b . The segment are described by inter-arrival histograms h aa ( S ) and h ab Figure 4 and are approximated by two standard histograms in Figure 5. Fi gure 4: (a) inter-arrival histogram h aa ( S ) ; (b) inter-arrival histogram h ab ( S ) .
 Fi gure 5: (a) standard histogram that best approx-imate h aa ( S ) ; (b) standard histogram that best ap-proximate h ab ( S ) .

It is obvious that the histograms demonstrate clear pat-terns. However, the total number of different histograms can be large for datasets with many events. The 2 histograms shown in Figure 4 and their corresponding standard his-tograms in Figure 5 are just one of many possible histogram combinations that depict the event relationships/patterns hidden in Example 2. For example, we can use two his-tograms to respectively depict the first and the second half of e a . Hence one challenge is how to find the most suitable combination of histograms to describe the event sequence. In our framework, we use MDL principle to find out the best set of disjoint segments and the corresponding standard his-tograms to summarize the event sequence.
In this section, we propose an information theoretic method to describe the histogram, i.e., encoding the histogram in bit s. [22] proposed an encoding scheme for histograms with fixed number of bins and fixed number of bin elements (the total value of all bins). However, for the histograms used in event summarization, neither the number of bins and the number of bin elements is fixed beforehand. To the best of our knowledge, there is no encoding scheme that can be di-rectly used in our scenario. Based on such situation, we first describe the scheme for encoding standard histograms (e.g., periodic patterns and correlation patterns). Then given an inter-arrival histogram, we show how it can be approximated using standard histograms. Finally, we formulate our event summarization problem. It should also be pointed out that, although MDL has been used in event summarization for en-coding the event segments [14, 25], our work is the first one that uses MDL to encode the inter-arrival histograms and to identify the set of disjoint histograms for summarization.
Given an event subsequence S of event types x and y with disjoint segments S = ( S 1 ; S 2 ; :::S i ; :::; S k standard histogram  X  h xy ( S i ), the following four components need to be encoded. These components are necessary and enough to describe the histogram.
 Event type depicted by the histogram. Each histogram should be associated with one or two event types depending on the type of the relationship it depicts. Given the set of event types E , it is enough to use L ( m ) = log |E| bits to represent each event type.
 Boundaries of S i . The relationship depicted by an interval histogram has two boundaries indicating where the corre-sponding segment is. Each boundary requires L ( b ) = log bits to encode its information.
 Information of non-empty bins in the histogram.
 This piece of information can be encoded using L ( bin ) = log +log i max +log | S | +
The coding length consists of five terms. The first term uses log bits to encode the largest interval i max in S i denotes the allowed largest interval. In our framework it is set as the number of seconds in one day. The second term uses log i max bits to encode the number of non-empty bins n non . The third term uses log | S | bits to encode the length of S i . The fourth and fifth terms encode all the indices (1 to i m ax ) and the number of elements contained in the n bins respectively.

Putting them all together, the bits needed for encoding a standard histogram  X  h xy ( S i ) is
Given an inter-arrival histogram h xy ( S i ), we want to mea-sure how well it can be represented by event patterns, or equivalently, how well it can be approximated by standard histograms.
 Histogram distance. Histogram distance describes how much information is needed to depict the necessary bin ele-ment movements defined in [6] to transform  X  h ( S i ) into h ( S (To make notations uncluttered, we drop the subscripts xy and they should be clear from the context.). The code length of the distance can be calculated as: where N on is the union of the indices sets of non-empty bins in both histograms, be i and bs i denote the value (number of elements) of bin i in h [ S i ] and  X  h [ S i ] respectively. For each element at bin i , we can assign a new bin index to indicate where it should be moved. Equation 2 measures the bits of information needed by summing up the elements in unmatched bins.

In summary, the amount of information required to de-scribe an inter-arrival histogram h ( S i ) using an event pat-tern  X  h ( S i ) equals to the summation of the code length for  X  h ( S i ) and the distance between h ( S i ) and  X  h ( S may be multiple standard histograms, we define the code length for an interval histogram h ( S i ) as follows: where  X  H ( S i ) is the set of all possible standard histograms on S i .
Given an event sequence D , for each subsequence S con-taining event types x and y , the minimum coding length L ( S ) for S is defined as
Since the boundaries for different subsequences are inde-pendent, then the minimum description length for the input event sequence D is He nce the event summarization problem is to find the best set of segments { S 1 ; S 2 ; :::; S k } as well as the best approxi-mated standard histograms to achieve the minimum descrip-tion length .
In this section, we first introduce a heuristic algorithm that can find the best set of segments of S in polynomial time. Then we present the method of generating ERN using the event patterns.
The problem of finding the best set of segments can be easily reduced to the problem of finding a shortest path from the generated histogram graph G . The histogram graph G is generated as follows: 1. Given S , let n xy be the number of inter-arrivals be-2. Add edge ( a; b ) from vertex v [ a ] to vertex v [ b ] for each
After generating the histogram graph, we can use the clas-sical shortest path algorithm (e.g., Dijkstra algorithm) to output the vertices on the shortest path from v [1] to v [ n Figure 6 shows an example histogram graph and Algorithm 1 illustrates the summarization process of our natural event summarization framework ( NES for short). In line 4, the al-gorithm generates a set of event subsequences from D , there are m subsequences for the same event type (i.e., x = y ) and m 2  X  m subsequences for different event types (i.e., x  X  = y ). Line 6 generates the directed acyclic histogram graph for each subsequence S and uses Dijkstra algorithm to find the shortest path P = ( v [ i 1 ] ; v [ i 2 ] ; :::; v [ i segmentation solution contains the segments &lt; v [ i 1 ] ; v [ i ; &lt; v [ i 2 ] ; v [ i 3 ] &gt;; :::; &lt; v [ i p  X  1] ; v [ i sent each segment using the best fitted event patterns (i.e., the best standard histograms), and put them into the set R Al gorithm 1 The NES Algorithm 1 . input: event sequence D . 2. output: all relationships R . 3. Identify m from S , relationship set R X  X  X  ; 4. Separate D into a set of S ; 5. for all S do 6. Generate directed graph G ; 7. Use Dijkstra( G ) to find shortest path P ; 8. Generate relationships R from P ; 9. R X  X  10. end for 11. return R ; F or each histogram graph G , Dijkstra algorithm requires O ( | E | + | V | log | V | ) = O ( | S | 2 ) time. Therefore, the total running time is O (( m + m ( m  X  1)) | S | 2 ) = O ( | D | 2
Although the set of event patterns can be described in text, we show that they can be used to construct an easy-to-understand event relationship network (ERN) [26] which produces a concise yet expressive representation of the event summary. ERN is a graph model that represents the rela-tionship between event types. The procedure for building ERN is straightforward: it first generates the vertices for each event type involved in any event patterns, and then adds edges for event patterns and stores necessary informa-tion (e.g., segmentation, periods and time intervals) onto the edges.

Figure 7 shows an example ERN graph. It contains two periodic patterns: A p 1  X  X  X  A , B p 2  X  X  X  B and five correlation For simplicity, the ranges of segments are ignored.
The NES algorithm described in Section 4 finds the best segmentation by checking all positions in S , which is com-putational intensive. In fact, given an event subsequence S , boundaries should only locate at positions where inter-arrival times change rapidly, because segmentation at smooth places would waste encoding bitsj. Based on this observa-tion, we propose an effective pruning algorithm which is able to prune a large part of boundaries that are unlikely to be the boundaries of segments. This algorithm greatly acceler-ates the summarization process by reducing the size of the histogram graph. By utilizing the multi-resolution analysis (MRA) of wavelet transformation, the pruning can be done in linear time in the worst case. For ease of pruning, some preprocessing steps are needed. Given an event subsequence S , we preprocess it as follows: 1. Obtaining inter-arrival sequences : given S = ( &lt; e; t 2. Padding : Append 0 X  X  to the tail of sequence until the 3. Transforming : Use Haar [4] wavelet as the the wavelet
The resulting W contanis the wavelet coefficients of the inter-arrival sequence, which is the input of our pruning al-gorithm.
Due to the multi-resolution analysis (MRA) property of wavelet transformation, the deviation of inter-arrivals in V can be viewed from W at different resolutions. Since wavelet transformation captures both the resolution and the location information, for each W [ i ], we can quickly locate the corre-sponding segment in V . For example, if | V | = 1024, the elements W [1] and W [2] contain the averaging information and the diff information of the highest resolution (in this ex-ample, resolution 1024) of original series respectively. The elements W [3] and W [4] contain the information of V at res-olution 512. Specifically, W [3] corresponds to the first half of V and W [4] corresponds to the second half of V .
By taking advantage of such a property, our pruning al-gorithm identifies the inter-arrival deviation in a top-down manner. The basic idea of algorithm is as follows: it checks the element W [ i ], starting from i = 2, which contains the deviation of inter-arrival for the whole sequence V . There are three possible cases:
Case I: If W [ i ] is small, it means the corresponding subse-
Algorithm 2 provides the pseudocode for BoundaryPrun-ing . The parameter level (initialized as log | W | ) denotes the current level of resolution that the algorithm checks, and i denotes the current position in transformed result W (i.e. W [ i ]) to be checked. The algorithm calculates the corre-sponding threshold as W [1] age deviation of inter-arrival at resolution 2 level and changes dynamically according to the level .

Example 3 uses a small dataset to illustrate how the prun-ing algorithm works.
 Al gorithm 2 Algorithm of BoundaryPruning 1 . input: W; level; i . 2. output: Boundary set B after pruning. 3. Set B  X  X  X  ; 4. threshold  X  W [1] 5. spectrum  X  W [ i ]; 6. if spectrum &lt; threshold or reaches to the lowest reso-7. Add corresponding boundaries to B ; 8. else 9. i 1 = 2 i  X  1 ; i 2 = 2 i ; 10. B 1  X  BoundaryPruning( W; level  X  1 ; i 1 ); 11. B 2  X  BoundaryPruning( W; level  X  1 ; i 2 ); 12. B  X  B  X  B 1  X  B 2 13. end if 14. return B ;
Exam ple 3. An input inter-arrival sequence V is shown in Figure 8. The algorithm starts from the highest reso-lution. It finds that W [2] = 3 is too large, so the whole inter-arrival sequence cannot be segmented with only one segment. At a lower resolution, the algorithm finds that W [4] is small enough, so the corresponding subsequence &lt; the element W [3] =  X  2 representing the first half of V , it is still too large and the corresponding subsequence &lt; ment. Hence the algorithm drills down to a lower resolution to do the same check task. Finally, the algorithm divides V into 5 segments, and 6 boundaries are recorded and the re-maining 11 boundaries are pruned. Figure 9 shows the effect of BoundaryPruning in reducing the size of the histogram graph.
 Fi gure 8: Segments information in wavelet spectrum sequence. Fi gure 9: Before pruning, the histogram graph con-tains 17 vertices and 136 edges, after pruning, the histogram graph contains only 6 vertices and 14 edges.

The pruning algorithm only scans W once. In general cases, the algorithm does not need to check all the elements in W . If the inter-arrival sequence is smooth enough, the algorithm would stop checking at a high resolution. Only in the worst case, the algorithm has to check every elements in W . Since | W | = | V | = | S | X  1, the algorithm runs in o ( for the average case and O ( | S | ) in the worst case.
In order to investigate the effectiveness and efficiency of our proposed approach, we design two sets of experiments to evaluate our algorithm on both synthetic and real datasets. There are two reasons that we evaluate our algorithm on synthetic data: 1. There is no ground-truth summarization result for real 2. The real world event sequence is generated automati-
With synthetic data, we can freely set the parameters of dataset such as the number of patterns of each type, the location of each patterns, the level of noise, and the size of dataset. Since we know the ground-truth of the synthetic data, we are able to investigate the capabilities as well as limitations of our algorithm by comparing its output with the ground-truth.

Our tasks in synthetic data experiments part are trying to answer the following answers: (1) Can our event summa-rization framework indeed discover the hidden relationships from the event sequence and effectively summarize them? (2) Is our framework efficient in handling event summa-rization task? (3) Is the approximation algorithm precise enough that covers most of the relationships comparing with the optimal counterpart?
For the real world data experiments part, there are two tasks: (1) Does our algorithm find out any useful patterns from the real world data? (2) Is the summarization result more meaningful and friendly than the counterparts?
The whole framework along with the experiments code is implemented in Java 1.6. All the experiments are conducted on a machine with Intel Core2 CPU @2.83GHz, 2G main memory and running on Windows XP SP2. We use the open source library JWave 1 for wavelet transformation and Jung 2 for ERN visualization.

We preprocess the datasets by transforming all event in-stances into a predefined format inst = &lt; event ty pe; date , time , source , category; event I D &gt; . Since different event types generated by different programs may share the same event I D in some systems like Windows series operating system, it is not enough to distinguish the events just by their ID. We map each distinct tuple &lt; event ty pe; source; category; event I D &gt; as unique event type e .
We generate several groups of synthetic datasets to eval-uate our approach, each group consists a set of datasets generated by changing a particular parameter and fixing the remains. The meaning of each parameter is listed in Table 2. For each dataset, we intentionally plant some re-h ttp://code.google.com/p/jwave/ http://jung.sourceforge.net/ la tionships/patterns and add the noise indicated by noise level 3 to simulate the real scenario.

We use NES-Prune to represent summarization with Bound-aryPruning , NES to represent summarization without Bound-aryPruning .

Accuracy of the approaches. The first goal of ex-periments on synthetic data is to check whether our ap-proach can really discover the correct hidden patterns from the data. We generate 5 datasets by fixing n = 15000 ; m = 150 ; n p = 50 ; n c = 50 ; l = 100 and iterate the noise lev-els from 0 : 1 to 0 : 5 with an increment of 0 : 1. Fore each dataset, we generated 50 periodic and 50 correlation pat-terns respectively with distinct period parameters and dis-tinct event types. Then we randomly order these patterns to build the synthetic dataset. Table 3 shows the result of how many planted patterns are found via NES and NES-Prune respectively. In this table, N ES p and N ES c denote the proportion of planted periodic and correlation patterns found by NES , N ESP p and N ESP c denote those found by NES-Prune .
 Table 3: Accuracy for synthetic datasets, n = 15000 ; m = 150 ; n p = 50 ; n c = 50 ; l = 100 F rom the result, we observe that both NES and NES-Prune can discover most of the relationships. We only count the relationships that with the exact same event type, the exact periodical parameters and more than 95% overlap with the ground-truth patterns we plant in, so the criterion is quite demanding.

Compression ratio. We evaluate the quality of event summarization by compression ratio CR with the formula L ( A ) denotes the code length achieved by A and L ( direct ) denotes the code length of directly encoding the event se-quence.

Figure 10 shows the compression ratio of our two algo-rithms as a function of noiselevel . For this experiment, we use the same datasets of the accuracy experiments. As expected, CR increases as the noiselevel increases. It is rea-sonable because more extra bits are required to describe the noise.

The proportion of planted patterns in the datasets is an-other factor that affects CR . We define the proportion of
W e set the noise levels as the probability of inter-arrival deviation, e.g, if noise level is 0 : 2, then with the probability of 20% the inter-arrival time will be shifted by a random value. Fi gure 10: CR vs. noise, n = 15000 ; m = 150 ; n p = 50 ; n c = 50 ; l = 100 of events belonging to the injected patterns. We run the experiment on 6 datasets by fixing n = 5000 ; m = 50 ; l = 100 ; noiselevel = 0 : 1 and ranging the proportion of pat-ters from 10% to 60% with an increment of 10%. Figure 11 shows that CR decreases as the pattern proportion increases. The result is straightforward because as the proportion of patterns increases, more events can be well fitted by event patterns, which results in shorter description length for the event sequence.

It should be pointed out that our NES summarizes an event sequence from different aspects simultaneously using event patterns with the goal of providing natural, inter-pretable and comprehensive summaries. It is quite possible that some events may belong to multiple correlation patterns and their coding length might be counted multiple times. So CR might not be the criterion to measure the quantity of summarization for our approach. This phenomenon also explains why NES leads to longer code lengths than NES-Prune .

Performance and scalability. We generate 8 datasets by fixing m = 100 ; n c = 0 ; noiselevel = 0 : 1 to evaluate the scalability of our approach. The length of event sequence for the datasets ranges from 2500 to 20000 with an increment of 2500, and n p is set proportional to the length of sequence. Figure 12 shows the scalability results. As expected, NES-Prune runs much faster than NES and it shows better scal-ability, since BoundaryPruning prunes a large number of boundary candidates.

The number of event type m is an important factor that affects the running time, we use 6 datasets to do the eval-uation by fixing n = 4096 ; n c = 0 ; noise level = 0 : 1 and set m from 4 to 128 with an increment of a power of 2. Figure 13(a) shows that as m increases, the running time of NES decreases but the running time of NES-Prune in-creases. This is because the running time of NES procedure NES , the running time is dominated by | S | . By fixing n , the average length of S decreases as m increases, therefore the running time of NES decreases. For NES-Prune , since the input is pruned, the average length of S does not affect running time. Hence, the running time is dominated by m and would increase as m increases,
The proportion of patterns is another important factor that affects the running time. We generate 8 datasets by fix-ing n = 5000 ; m = 50 ; l = 100 ; noiselevel = 0 : 1 and ranging the proportion of patterns from 10% to 80%. Figure 13(b) shows that as the proportion of patterns increases, the run-ning time of NES-Prune decreases, but the running time of NES is independent of the proportion of patterns. This is because as the proportion of patterns increases, more bound-aries are removed using BoundaryPruning . And without BoundaryPruning , the size of input for NES is independent of the proportion of patterns. ( a) Running time vs. m , n = 4096 ; noiselevel = 0 : 1
In order to explore whether our framework can really help system administrators, we test our approach with real log datasets recorded in Windows event viewer.

The real datasets consist of application log , security log and system log . The detailed information of the three datasets with their running times and compression ratios are listed in Table 4.

Our methods show a significant improvement over previ-ous approaches. The algorithm in [15] needs more than a thousand seconds to find the optimal summarization solu-tion while our methods just need 1 = 10 of the time. Due to inherent difficulty of event summarization, our methods are still not efficient enough. Further improvement in efficiency is needed and this is one of our future works.

Note that our algorithm utilize MDL to summarize the event sequence on the aspect of period pattern and correla-tion pattern, we successfully compressed the pattern infor-mation to just several percent of the original amount without loss any information.

Our algorithm finds and summarizes a lot of interesting event relationships. For example in system log, we find event &lt; 35, W32Time &gt; occurs every 3600 seconds. This event type is a well known periodic event that synchronizes the com-puter time with the remote server. We also find that there P eriod 09/10-02/11 11/10-12/10 09/10-02/11 Time range (secs) 12,005,616 2,073,055 12,000,559 Ev ent instances 5634 21850 3935 Ev ent types 100 17 50 Run ning Time (secs) NES 1 73 3102 108 NES -Prune 22 56 4 Com pression Ratio CR ( A ) NES 0 .0597 0.0312 0.0454
NES -Prune 0.0531 0.0216 0.0464 exi st correlation relationships among the event types &lt; 6005, description on EventID.NET 1 verifies that such results are meaningful. Moreover, we find several important relation-ships from security log and application log. Figure 14 shows the whole ERN graph for the security log which includes 15 vertices and 36 edges. In this figure, the labels of vertices denote the event types and the labels on edges denote the relationships in form of C [ param 1 ; param 2], where C or P denotes the type of relationship and param 1 ; param 2 denote the time interval parameter of the relationship.
ERNs like the one shown in Figure 14 are immediately useful for managing computer systems. A system admin-istrator can devise automatic event handling for each pat-tern type. For example, in the context of security monitor-ing, periodic event patterns with a short period like the one formed by event type 861 is usually caused by a malicious or ill-configured program that attempts to exploit security holes. Once such a pattern is identified, a security response process should be triggered. A correlation pattern usually represents an episode of an evolving problem going through various phases. One can devise proactive event-condition-action rules to prevent serious incidents from happening.
Moreover, after we applying clique finding algorithm [5] to find all the cliques of this ERN by ignoring the directions, we further find larger patterns by combining the pairwise patterns. There are 4 sets of event groups found: Firewall related events (6 types), network access events (4 types), h ttp://www.eventid.net process management events (2 types) and antivirus monitor-ing events (1 type). The detailed information for discovered cliques are listed in Table 5.
Event Summarization. Event Summarization is a rela-tively new research area that combines the area of data min-ing and computer systems. It can be deemed as an extension of frequent itemset mining [1, 7] and frequent episode min-ing [9, 16, 20, 21]. These frequent pattern mining techniques can reveal some interesting patterns by identifying the cor-relations of discrete events and are the building blocks of event summarization. Event summarization has attracted a lot of research attention recently [14, 15, 25, 24]. Peng et al. [24] proposed an approach to find the patterns in the event logs by measuring inter-arrivals of the events. Kiernan et al. [14, 15] proposed a summarization method by segment-ing the event sequence according to the frequency changes of events. Based on the work of Kiernan, Wang et al. [25] fur-ther improved the summary by proposing a Hidden Markov Model to describe the transition of states among sequence segments. However, since they are either too general or too hard to be understood by data mining outsider, none of the results provided by these works are helpful enough for the system administrators.
 Minimum Description Length. Minimum Description Length Principle (MDL) [12] is a general method for induc-tive inference. It is effective for generalization, data com-pression, and de-noising. In data mining community, it has been successfully used for temporal pattern mining [7], clus-tering [29], graph mining [10], trajectory outlier detection [17] and social network analysis [30]. Although MDL has been used in event summarization for encoding the event segments [14, 25], our method is the first one that uses MDL to encode the inter-arrival histograms and to identify the set of disjoint histograms for summarization.

Wavelet Transformation. Wavelet transformation is a useful tool for dividing up data, functions, or operators into different frequency components and then studies each component with a resolution matched to its scale [11, 18]. It has been widely used in many data mining tasks such as clustering [28], similarity search [27] and visualization [23]. The most relevant application to event summarization is wavelet-based time-series analysis [8, 27] where wavelet tools are used to measure the similarity of time-series in a global perspective. used in event summarization. In this pa-per, we use wavelet transformation as a subroutine to find the possible boundaries of the patterns hidden in an event sequence. We rely on its multi-resolution property to im-prove the efficiency of our approach.
In this paper, we propose a framework called natural event summarization and an algorithmic solution to the prob-lem of summarizing event sequences that are generated by system logger. Our framework summarizes the event se-quence from the perspective of depicting the event patterns by capturing the temporal relationships among same-type and different-type of events. The framework finds the best set of disjoint histograms to summarize the input event se-quence based on MDL. Moreover, to improve the efficiency, we present a heuristic boundary pruning algorithm to prune th e unlikely boundaries and reduce the size of the histogram graph. Finally, we use ERN to present the final event sum-mary in a more interpretable way.

There are several directions for the future work. Firstly, there is still a long way to go for the efficiency improve-ment. Secondly, one limitation of our current solution is the fixed time interval across time. In the future, we should also consider the pseudo temporal patterns for summarization. Moreover, many of the event logs in modern distributed systems are in form of streams, but our current event sum-marization is designed based on the static event log. One immediate goal is to design a new framework that is able to handle stream event sequences. Finally, we plan to build a whole event summarization system, which includes mod-ules like event log structure extraction module, event sum-marization module, summarization postprocess module and summarization visualization module.
 The work is partially supported by NSF CAREER grant IIS-0546280.
