 Coherence is perhaps the most fundamental property of probability estimation. Coherence will be formally defined later, but in essence a coherent probability assessment is one that exhibits logical underlying structure of the space, and so can X  X  be extended to a complete probability distribution [1, 2]. From a decision theoretic standpoint, treating assessments as odds, incoherent assessments result in guaranteed losses to assessors. They are dominated strategies, meaning that for every incoherent assessment there is a coherent assessment that uniformly improves the outcome for the assessors. Despite this fact, expert assessments (human and machine) are vulnerable to incoherence [3]. Previous authors have used coherence as a tool for fusing distributed expert assessments [4, 5, 6]. The focus has been on static coherence in which experts are polled once about some set of events and the responses are then fused through a geometric projection. Besides relying on arbitrary scor-ing functions to define the  X  X ight X  projection, such analyses don X  X  address dynamically evolving assessments or forecasts. This paper is, to our knowledge, the first attempt to analyze the problem of coherence under Bayesian belief dynamics. The importance of dynamic coherence is demonstrated in the following example.
 Consider two uncertain events A 1 and A 2 where A 1  X  A 2 (e.g. A 2 = { NASDAQ  X  tomorrow } and A 1 = { NASDAQ  X  tomorrow  X  10 points } ). To be coherent, a probability assessment must P ( A 1 ) = P ( A 2 ) = 0 . 5 which is coherent. Next, suppose there is some binary random variable indicator function). The believed dependence between Z and A i is captured by a likelihood model P ( Z | A i ) that gives the probability of observing Z when event A i does or doesn X  X  occur. For the P ( A 2 | Z = 0) = 0 . 5 . The belief update has introduced incoherence! 1.1 Motivating Example Concerned with their network security, BigCorps wants to purchase an Intrusion Detection and Pre-vention System (IDPS). They have two options, IDPS 1 and IDPS 2 . IDPS 1 detects both distributed denial of service (DDoS) attacks and port scan (PS) attacks, while IDPS 2 detects only DDoS attacks. While studying the NIST guide to IDPSs [7], BigCorps X  CTO notes the recommendation that  X  X rga-nizations should consider using multiple types of IDPS technologies to achieve more comprehensive and accurate detection and prevention of malicious activity. X  Following the NIST recommendation, BigCorps purchases both IDPSs and sets them to work monitoring network traffic.
 witnesses an interesting behavior. IDPS 2 is registering an attack probability of 0 . 1 while detector of those detected by IDPS 2 , the probability assigned by IDPS 1 should always be larger than that assigned by IDPS 2 . The dilemma faced by our analyst is how to reconcile the logically incoherent outputs of the two detectors. Particularly, how to ascribe probabilities in a way that is logically consistent, but still retains as much as possible the expert assessments of the detectors. 1.2 Contributions of this Work This work introduces the concept of dynamic coherence, one that has not been previously treated in the literature. We suggest two possible forms of dynamic coherence and analyze the relationship between them. They are implemented and compared in a simple network modeling simulation. 1.3 Previous Work Previous authors have analyzed coherence with respect to contingent (or conditional) probability assessments [8, 9, 10]. These developments attempt to determine conditions characterizing coherent subjective posteriors. While likelihood models are a form of contingent probability assessment, this paper goes further in analyzing the impact of these assessments on coherent belief dynamics. In [11, 12] a different form of conditional coherence is suggested which derives from coherence of a form of conditional coherence, certain specially structured event sets and likelihood functions will produce coherent posterior assessments.
 Logical consistency under non-Bayesian belief dynamics has been previously analyzed. In [13] conditions for invariance under permutations of the observational sequence under Jeffrey X  X  rule are developed. A comparison of Jeffrey X  X  rule and Pearl X  X  virtual evidence method is made in [14] which shows that the virtual evidence method implicitly assumes the conditions of Jeffrey X  X  update rule. Let  X  = {  X  1 ,  X  2 , . . . } be an event space and ( X  , F ) a measurable space. Let  X  :  X   X   X  be a the world. X  Also, let Z i :  X   X  Z be a sequence of measureable random variables; consider Z i to the pre-image of  X  (resp. Z i ). Since the random variables are assumed measureable,  X   X  and  X  Z measureable sets (i.e. elements of F ), as are their countable intersections and unions. For i = 1 , 2 , . . . , N , let A  X  i be a subset of  X  , let A i =  X  {  X   X  A  X  assessment is defined as An individual probability assessment P : A  X  [0 , 1] maps each event under assessment to the unit interval. In an abuse of notation, we will let P , (joint) probability assessment. A coherent assessment (i.e. one that is logically consistent) can be described geometrically as lying in the convex hull of the columns of  X  , meaning  X   X   X  [0 , 1] J s.t. P i  X  i = 1 and P =  X  X  .
 We now consider a sequence of probability assessments P n defined as follows: P n is the result of mass functions over the observations: one conditioned on A and the other conditioned on  X  A (where  X  A denotes the complement of A ). We will make the simplifying assumption that the likelihood model is static , i.e. p n ( z | A ) = p ( z | A ) and p n ( z |  X  A ) = p ( z |  X  A ) for all n . In this paper we assume belief revision dynamics governed by Bayes X  rule, i.e.
 for all i, j (i.e. no observation determines absolutely whether any event obtains). Then by induction the posterior probability of event A after n observations is: when n i is the number of observations z i . For a single assessor revising his estimate of the likelihood of event A , let the probability model the ratio  X  i = n i n and for simplicity assuming P 0 = 0 . 5 (although the analysis holds for general P 0  X  (0 , 1) ). Substituting yields Note that 1)  X  is the empirical distribution over the observations, and so converges almost surely (a.s.) to the true generating distribution, and 2) the convergence properties of P n are determined by the quantity between the square brackets in (2). Specifically, let L  X  is commonly referred to as the likelihood ratio, familiar from classical binary hypothesis testing. L  X  &gt; 1 then P n  X  0 ; if L  X  = 1 then P n  X  1 2 . 3.1 Matched likelihood functions Assume that the likelihood model is both infinitely precise and infinitely accurate, meaning that when A (resp.  X  A ) obtains observations are generated i.i.d. according to  X  (resp.  X  ). Assume that A obtains; then L  X  = by assumption  X  6 =  X  . Since L  X  &lt; 0  X  L  X  &lt; 1 , this implies that when the true generating distribution is  X  , P n  X  1 a.s.
 Similarly, when  X  A obtains, we have and P n  X  0 a.s. 3.2 Mismatched likelihood functions Now consider the situation when the expert assessed likelihood model is incorrect. Assume the observation generating distribution is  X  = P ( Z i = z ) where  X  6 =  X  and  X  6 =  X  . In this case, L P in which P n a.s. converges to 1 2 ).
 [16] and references therein). Composite hypothesis testing attempts to design tests to determine the truth or falsity of a hypothesis with some ambiguity in the underlying parameter space. Because of this ambiguity, each hypothesis H i corresponds not to a single distribution, but to a set of possible distributions. In the mismatched likelihood function problem, composite spaces are formed due to H i  X  X  i then Bayes X  rule (under the specific likelihood model) is an asymptotically perfect detector. In Section 3 we analyzed convergence properties of a single event under assessment. Considering multiple events introduces the challenge of defining a dynamic concept of coherence for the assess-ment revision process. In this section we suggest two possible definitions of dynamic coherence and consider some of the implications of these definitions. 4.1 Step-wise Coherence We first introduce a step-wise definition of coherence, and derive equivalency conditions for the special class of 2-expert likelihood models. Definition 1 Under the Bayes X  rule revision process, a likelihood model p ( z |A ) is step-wise coher-ent (SWC) if P n  X  convhull (  X  )  X  P n +1  X  convhull (  X  ) for all z  X  X  .
 Essentially this definition says that if the posterior assessment process is coherent at any time, it will remain coherent perpetually, independent of observation sequence. We derive necessary and sufficient conditions for SWC for the characteristic matrix given by all n and all coherent P 0 . Proceeding inductively, assume P n is marginally SWC, i.e. P n ( A 1 ) = P ( A 2 ) =  X  . Due to the continuity of the update rule, a model will be SWC iff it is coherent at the ately, for  X  given by (4), the model will be SWC iff  X  i 1  X  4.2 Asymptotic coherence While it is relatively simple to characterize coherent models in the two assessor case, in general SWC is difficult to check. As such, we introduce a simpler condition: Definition 2 A likelihood model p ( z | A ) is weakly asymptotically coherent (WAC) if for all obser-e is the i th unit vector.
 Lemma 1 Step-wise coherence implies weakly asymptotic coherence.
 Assume that a model is SWC but not WAC. Since it X  X  not WAC, there exists a  X  s.t. Z i drawn IID from  X  a.s. results in P n  X   X  P where  X  P  X  { 0 , 1 } N is not a column of  X  and is therefore coherently. Then, by a separating hyperplane argument, there must exist some n (and therefore the likelihood model is SWC. Therefore any SWC model is also WAC. We demonstrate that the converse is not true by counterexample in Section 4.2.2. 4.2.1 WAC for static models Analogous to (3), we define For a given  X  , define the logical vector r (  X  ) as Lemma 2 A likelihood model is WAC if  X   X  s.t. lim n  X  X  X  P n  X  X  0 , 1 } N ,  X  i s.t. r (  X  ) =  X e i . Define the sets P i = {  X  | r (  X  ) =  X e i } . Lemma 2 states that for a WAC likelihood model, {P i } partitions the simplex (excluding unstable edge events) into sets of distributions s.t.  X   X  P i  X  P between sets are linear. 4.2.2 Motivating Example Revisited Consider again the motivating example of the two IDPSs from Section 1.1. Recall that IDPS 1 detects analyzed in Section 4.1. Therefore (5) gives necessary and sufficient conditions for SWC, while (7) gives necessary and sufficient conditions for WAC.
 Suppose that both the IDPSs use the interval between packet arrivals as their observation and as-sume the learned likelihood models for the two IDPSs happen to be geometrically distributed with index denoting the IDPS. We will analyze SWC and WAC for this class of models.
 Equation (8) will be satisfied iff x 1 y sufficient condition for SWC.
 Now, we turn to WAC. Forming T as defined in (6), we see that Comparing the conditions for SWC (8) to those for WAC (10), we see that any parameters satisfying satisfy (8), but do satisfy (10). Thus WAC is truly a weaker sense of convergence than SWC. As shown in Sections 3 and 4, a WAC likelihood model generates a partition {P i } over the obser-vation probability simplex such that  X   X  P i  X  P n  X   X e i . The question we now address is, given a WAC likelihood model and finitely many observations (with empirical distribution  X   X  n ), how to revise an incoherent posterior probability assessment P n so that it is both coherent and consistent with the observed data.
 The principle of conserving predictive uncertainty states that in revising an incoherent assessment P n to a coherent one whether the observations are being generated by a distribution in the corresponding element of the partition {P i } (and therefore whether P n is converging to  X e i ). Given a uniform prior over generating distributions  X  and assuming Lebesgue measure  X  over the parameters of the generating distribution, we can write This suggests the following approximation method for determining a coherent projection of P n : conserving predictive uncertainty can even be effectively applied to non-WAC models. 5.1 Sparse coherent approximation so solving for  X  directly using (11) may be computationally infeasible. The following result sug-gests that to generate the optimal (in the sense of capturing to most possible weight) O ( N ) sparse approximation of  X  we need only calculate the O ( N 2 ) reverse i-projections.
 Let  X  be determined according to (11) and let {P i } be as defined in Section 4. Assume wlog that  X  of one (and only one) assessor X  X  probability assessment has changed. The size of the neighborhood is thus less than or equal to N .
 weighted partition element is the one that contains the empirical distribution. It can be shown that 2  X  X  ( P 1 ) , and thus recursively that  X   X  i  X  in calculating the i = N largest weights is bounded by estimates the probability that his unique outcome has occured knowing exactly one has occurred. Suppose each event is a priori equally likely, and a sequence of iid observations is generated with gions shown in Figure 6(a). Marginal estimation introduces incoherent convergence regions (6(b)); but for well-calibrated models, the empirical distribution is exponentially unlikely to lie in an in-coherent region. However, miscalibrated models (6(c)) may lead to the true distribution lying in an incoherence region. WAC-approximation can ameliorate such miscalibration. The results of a  X   X   X  Figure 2: (a) Decision boundaries for optimal joint estimator; (b) Decision boundaries for marginal estimator; (c) Decision boundaries for miscalibrated observation model; (d) WAC approximation Monte Carlo implementation of this miscalibrated estimation is shown in Figure 3. The top line (blue) shows the average error for accepting the posterior assessments generated by the miscali-brated observation models. The next line (green) corresponds to renormalization at each time step, equivalent to projecting the posterior into the coherent set with a divergence-based objective func-tion. Next (red) shows the error generated by standard (L2) projection of the miscalibrated posterior into the coherent set. Finally, in cyan is shown the WAC approximation. Figure 3: Comparison of mean-square errors as a function of the number of observations under four different estimation techniques This paper has introduced the problem of dynamic coherence and analyzed it when the dynamics are induced by Bayes X  rule. First, we demonstrated how under subjective event likelihood models (potentially unmatched to the true underlying distributions) Bayes X  rule results in a partition over the observation probability simplex. Then we introduced two concepts of dynamic coherence: step-wise coherence and weak, asymptotic coherence. Next we suggested a principle of conservation of predictive uncertainty, by which observation-based incoherence can be mitigated (even in incoherent models). Finally, we briefly analyzed the computational impact of coherent approximation. [1] V.S. Borkar, V.R. Konda, and S.K. Mitter. On De Finetti coherence and Kolmogorov probabil-[2] Bruno de Finetti. Theory of Probability , volume 1-2. Wiley New York, 1974. [3] Daniel Kahneman, Paul Slovic, and Amos Tversky, editors. Judgment under uncertainty: [5] D.N. Osherson and M.Y. Vardi. Aggregating disparate estimates of chance. Games and Eco-[6] P. Jones, S. Mitter, and V. Saligrama. Revision of marginal probability assessments. In the [7] K. Scarfone and P. Mell. Guide to intrusion detection and prevention systems (IDPS). Tech-[8] D.A. Freedman and R.A. Purves. Bayes X  method for bookies. The Annals of Mathematical [9] D. Heath and W. Sudderth. On finitely additive priors, coherence, and extended admissibility. [10] D.A. Lane and W. Sudderth. Coherent and continuous inference. The Annals of Statistics , [13] P. Diaconis and S.L. Zabell. Updating subjective probability. Journal of the American Statis-[14] H. Chan and A. Darwiche. On the revision of probabilistic beliefs using uncertain evidence. [15] Joy Thomas and Thomas Cover. Elements of Information Theory . Wiley Interscience, 2nd [16] M. Feder and N. Merhav. Universal composite hypothesis testing: A competitive minimax
