 The Web has been rapidly  X  X eepened X  by myriad searchable data-bases online, where data are hidden behind query interfaces. As an essential task toward integrating these massive  X  X eep Web X  sources, large scale schema matching ( i.e. , discovering semantic correspon-dences of attributes across many query interfaces) has been actively studied recently. In particular, many works have emerged to ad-dress this problem by  X  X olistically X  matching many schemas at the same time and thus pursuing  X  X ining X  approaches in nature. How-ever, while holistic schema matching has built its promise upon the large quantity of input schemas, it also suffers the robustness prob-lem caused by noisy data quality. Such noises often inevitably arise in the automatic extraction of schema data, which is mandatory in large scale integration. For holistic matching to be viable, it is thus essential to make it robust against noisy schemas. To tackle this challenge, we propose a data-ensemble framework with sampling and voting techniques, which is inspired by bagging predictors . Specifically, our approach creates an ensemble of matchers, by ran-domizing input schema data into many independently downsam-pled trials , executing the same matcher on each trial and then ag-gregating their ranked results by taking majority voting. As a prin-cipled basis, we provide analytic justification of the effectiveness of this data-ensemble framework. Further, empirically, our experi-ments on real Web data show that the  X  X nsemblization X  indeed sig-nificantly boosts the matching accuracy under noisy schema input, and thus maintains the desired robustness of a holistic matcher. H.2.5 [ Database Management ]: Heterogeneous Databases; H.2.8 [ Database Management ]: Database Applications X  Data Mining Algorithms, Experimentation, Performance Grants IIS-0133199 and IIS-0313260. Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the author(s) and do not necessarily reflect the views of the funding agencies.
 Copyright 2005 ACM 1-59593-135-X/05/0008 ... $ 5.00.
 data integration, deep Web, schema matching, ensemble, bagging predictors
With the prevalence of online Web databases, large scale inte-gration has become a pressing problem. In particular, we have witnessed the rapid growth of databases on the Web, or the so-called  X  X eep Web. X  A July 2000 survey [4] estimated that 96,000  X  X earch cites X  and 550 billion content pages in this deep Web. Our recent study [7] in April 2004 estimated 450,000 online databases. With the virtually unlimited amount of information sources, the deep Web is clearly an important frontier for data integration.
To enable the integration of the deep Web, it is critical to dis-cover matchings among attributes across large scale sources. On the deep Web, numerous online databases provide dynamic query -based data access through their query interfaces , instead of static URL links. Each query interface accepts queries over its query schemas ( e.g. , author , title , subject , ... for amazon.com ). Schema matching ( i.e. , discovering semantic correspondences of attributes) among many query interfaces is essential for mediating queries across deep Web sources.

In particular, with the proliferation of sources in various do-mains, we often face the challenges of integrating and thus match-ing  X  X lternative X  sources in the same domain ( e.g. , Books, Air-fares). For instance, we may build a comparison shopping service for books or airfares, e.g. , purchasing a book with lowest price among book sources or a flight ticket with the best trade-off be-tween price and number of connections among airline sources. To enable such integration scenarios, we need to discover either sim-ple 1:1 matchings, e.g. , subject = category in Books, or complex m : n matchings, e.g. , passengers = { adults , seniors , children , infants } in Airfares.

While schema matching has been a central issue in data integra-tion [3, 18], the large scale sets new requirements on the match-ing task. Traditional schema matching works ( e.g. , [17, 8, 16, 13, 15]) are developed for small scale and static integration sce-narios, in which automatic matching technique is often an option to reduce human labor, as an aid to manually configured seman-tics. Schema matching under such scenarios is abstracted as find-ing pairwise attribute correspondences between two sources and thus cannot scale well. In contrast, in large scale data integration scenarios, the matching process needs to be as automatic as pos-sible and scalable to large quantities of sources, as the large scale mandates.

The challenge of large scale lends itself to a novel opportunity for automatic large scale schema matching X  Many recent works [9, 11, 10, 19] have emerged to address schema matching  X  X olistically X  by matching many schemas at the same time and finding all match-ings at once. Such holistic schema matching relies on large scale data quantity to discover semantic correspondences of attributes and thus essentially pursues a  X  X ata mining X  approach in nature. In particular, statistical model discovery [9], clustering [11, 19] and correlation mining [10] approaches have been developed to  X  X ine X  matchings. Therefore, holistic schema matching can be abstracted as taking a set of schemas as input and outputting a ranked list of matchings, as Figure 1 shows.

However, while holistic schema matching leverages the oppor-tunity of large data quantity, it also suffers the inherent problem of noisy data quality, which has not been extensively noticed and studied. Specifically, as the large scale mandates, to automate the matching process, the gathering of schemas ( i.e. , extracting schemas from a set of query interfaces in HTML format) should also be automated X  If the schemas are to be manually prepared, it would certainly defeat the purpose of automatic schema matching, espe-cially for large scale integration. Although automatic schema ex-traction has been proposed recently [21, 12], as existing holistic schema matching works all adopt manually extracted schemas, the integration of these two  X  X ubsystems X  remains unstudied. In par-ticular, since errors are inevitable in automatic schema extraction, the input schemas of holistic schema matching are in fact noisy. As Section 2.1 will discuss, the noises made by schema extraction can compromise the matching performance to as much as 30%, render-ing holistic matching almost unusable. Therefore, without essen-tially addressing the issue of data quality, holistic schema matching does not sustain itself as a viable technique.

We are thus facing a practical and challenging problem: For holistic schema matching, how do we meet the opportunity of holis-tic quantity with the challenge of robust quality ? While large scale integration enables us to embrace the  X  X lessing X  of holistic quan-tity,  X  nothing comes for free X  it also challenges us with the  X  X urse X  of non-robust quality, as data are inevitably noisy. Our goal is to maintain the robustness of a holistic matcher with the presence of noisy input schemas. In particular, as our design objective, we are searching for a solution that is: 1) deployable : We would like the solution to build upon an existing matching approach to maintain its robustness, instead of redesigning a new algorithm; 2) general : We would like the solution to make minimal assumption of specific matching approaches so that it can be widely applicable to different holistic matchers.

As a result, our solution builds on the critical insight that while large scale schema matching poses the robustness problem, the so-lution lies in the holistic nature itself. In particular, we observe that holistic schema matching only needs sufficient but not all schema data. As attribute information are repeatedly used across large scale deep Web sources, e.g. , with enough book sources presenting at-tributes author , title , ..., a subset of schemas may still contain suf-ficient information to represent the complete data set. Thus, we in fact need only sufficient correct schemas, instead of all of them, to execute a holistic matcher.

While this insight is promising, how to develop a principled framework to realize it? The key challenges exist on both the input and output sides of the solution. On the input side, as we cannot generally differentiate noisy schemas from correct ones, it is in-feasible to identify and remove noises. Thus, our approach has to essentially account for the presence of noisy data in the input. On the output side, our approach should give a predictable guarantee on the expected robustness, e.g. , how robust it can be when some characteristics of the schema data and the holistic matching algo-rithm are known.

To tackle these challenges, we develop a data-ensemble frame-work by exploiting sampling and voting techniques (Sections 3, 4). In particular, on the input side, we take an ensemble of multiple matchers, where each matcher is executed over an independent ran-dom sampling of the input schemas. On the output side, we take majority voting to aggregate the ranked results of all the matchers into a merged list of ranked matchings, which can alleviate the im-pact of noises and more accurately reflect the correct ranking of matchings. We build an analytic model to help us justify the effec-tiveness of this framework and predict its robustness.

We note that, our data-ensemble idea is inspired by bagging pre-dictors [6] in machine learning X  That is, we are essentially applying bagging techniques in a new scenario of mining matchings. Bag-ging predictors is a method for maintaining the robustness of  X  X n-stable X  classification algorithms where small changes in the train-ing set result in large changes in prediction. In particular, it creates multiple versions of a classifier, trains each classifier on a random redistribution of the training set and finally takes a plurality voting among all the classifiers to predict the class. Therefore, our data-ensemble approach has the same foundation as bagging predictors on exploiting majority voting to make an algorithm robust against outlier data in the input. In Section 3, we will further compare the difference of our framework with bagging predictors.

We evaluate the data-ensemble framework over our motivating integration scenario, i.e. , to make a holistic matcher robust against the noisy input from a schema extractor (Section 5). Our goals are twofold: (1) Verify our motivating observation that noises made by schema extraction can significantly affect the matching perfor-mance. (2) Validate the effectiveness of the data-ensemble frame-work over real Web data.

In our development, we also observe some open issues that war-rant further research. Can we develop a systematic and principled method to determine the configuration of this data-ensemble frame-work? How to solve the uncertainty problem of matching result? What is the applicability of this framework? We discuss these open issues in Section 6.

In summary, the contributions of this paper are:  X  As our problem , we identify noisy data quality as an inherent  X  As our solution , we develop a data-ensemble framework with
The rest of the paper is organized as follows: Section 2 reports issues we find in integrating schema extraction and holistic schema matching, and then motivates the data-ensemble framework. Sec-tion 3 models the data-ensemble framework and provides analytic justification of its effectiveness. Section 4 discusses technical de-tails. Section 5 reports our experiments. Section 6 discusses several further opportunities and open issues and then concludes the paper.
As Section 1 discussed, toward building large scale schema in-tegration systems, it is critical to integrate holistic schema match-ing with automatic schema extraction. This system integration in-evitably raises a new challenge of noisy data quality, which has not been extensively investigated. In particular, what we have ob-served, when integrating schema matching with extraction, is the problem of error cascade  X  That is, the inevitable errors made by automatic schema extraction may cascade to holistic schema match-ing and thus significantly affect the matching performance. In this section, we first define, by way of brief summary, the two  X  X ubsys-tems X  ( i.e. , schema extraction and holistic schema matching) to be integrated, based on which we observe the error cascade phenom-enon in putting them together (Section 2.1) and further motivate the insight of our solution (Section 2.2).
 Schema Extraction [Subsystem SE ]:
The subsystem SE extracts the schema information of a Web query interface in its HTML format. For instance, given the ad-vanced book search of amazon.com , SE will extract its schemas as a set of query conditions, as shown in Figure 2. In particular, [ Author ; { contain } ; text] means the value of attribute author can be filled with any text; [ Format ; { = } ; { hardcopy, paperback, ... } ] the value of attribute format has to be selected from a give set of options.

Recent works [21, 12] developed automatic techniques for such schema extraction. Reference [21] introduces a parsing approach by hypothesizing the existence of hidden syntax, which connects attribute semantics of a query interface to its visual layout in the Web page. Reference [12] proposes a two-step extraction algorithm by first translating the HTML text into an internal interface expres-sion (or IEXP) and then recognizing attribute semantics ( e.g. , label-ing of attribute name and grouping of elements) from the translated IEXP based on some rules.
 Holistic Schema Matching [Subsystem SM ]:
Given a set of schemas, the schema matching subsystem is to dis-cover semantic correspondences ( i.e. , matchings) among attributes. Some recent schema matching works specifically focus on discov-ering matchings among a set of query interfaces [9, 11, 10, 19]. Unlike traditional schema matching, which mostly targets at small scale integration by finding pairwise attribute correspondences be-tween two schemas [17, 8, 16, 13, 15], these works match schemas in a  X  X olistic X  way by taking many schemas as input and outputting all the matchings among the input schemas. Since for any holis-tic matcher, regardless its matching techniques, each discovered matching is quantified with a  X  X onfidence X  score, its output is thus a ranked list of scored matchings. Therefore, we abstract a holistic matcher as a module whose input is a set of schemas and output a ranked list of matchings, as Figure 1 shows.

Sharing the same abstraction of holistic schema matching, there are different realizations. In particular, the MGS approach [9] ab-stracts schema matching problem as hidden model discovery by hy-pothesizing the existence of a hidden schema model, which gener-ates schemas with probabilistic behavior. The DCM approach [10] tackles the problem of finding complex matchings with a correla-tion mining approach, based on the observation that co-occurrence patterns across schemas often reveal complex semantic relation-ships. Reference [19] pursues a clustering-based matching approach by exploring the  X  X ridging X  effect among schemas. WISE [11] is a comprehensive query interface integrator, which combines multiple matching techniques such as clustering.

As Section 1 discussed, integrating SE and SM subsystems is a critical step toward building large scale schema integration sys-tems. In our development, we choose the Schema Extractor we proposed in [21] and the DCM matcher we developed in [10] as our testbed subsystems to integrate. Our goal is to see whether SE can sustain the schema matching task SM with extraction errors. In particular, given Web pages containing query interfaces in the same domain as the input, we use the Schema Extractor to extract the schema of each interface and then execute the DCM matcher on all the extracted schemas to discover matchings.

While we must integrate the two complementary subsystems to build a complete system for automating holistic schema match-ing, can the  X  X ccuracy X  of SE sustain the demand of data qual-ity for SM ? As [21] reported, when studied in isolation, SE de-livers 85-90+% accuracy X  thus it will make about 1-1.5 mistake for every 10 query conditions to extract. While seemingly satisfac-tory, putting in the context of the integrated system, is this accuracy good enough? As our experiment shows in Section 5, with noisy input, the accuracy of the holistic matcher may degrade up to 30%, comparing to the results reported in [10], which shows that errors indeed cascade along the execution of subsystems.

The performance degradation results mainly from the negative impact of the noisy input on the right ranking of matchings in the output of SM . When input schemas are noisy, the ranking of match-ings is likely to be affected ( i.e. , incorrect matchings maybe ranked higher than correct ones). Consequently, the ranking is less reliable for the  X  X onsumer X  applications of SM to select correct matchings. For instance, an application-specific matching selection step is of-ten introduced after SM to choose the most promising subset of matchings among all the discovered ones. Since such a selection naturally relies on the ranking of matchings, it is critical to make SM still output a good ranking with the presence of noises.
While large scale data integration brings forward the inherent problem of noisy quality in schema extraction, the large scale also lends itself to an intriguing potential solution. An interesting ques-tion to ask is: Do we need all input schemas in matching their at-tributes ? In principle, since pursuing a data mining approach, holis-tic schema matching exploits  X  X tatistics-based X  evaluation ( e.g. , clus-tering, correlation mining) in nature and thus needs only  X  X uffi-cient observations. X  As query interfaces tend to share attributes, e.g. , author , title , subject , ISBN are repeatedly used in many book sources, a subset of schemas may still contain sufficient informa-tion to  X  X epresent X  the complete set of schemas. Thus, the holistic matcher in fact only needs sufficient correct schemas to execute, instead of all of them. This insight is promising, but it also brings a new challenge: As there is no way to differentiate noisy schemas with correct ones, how should we select the schemas to guarantee the robustness of our solution?
Tackling this challenge, we propose a data-ensemble framework, with sampling and voting techniques, to build upon and extend an existing holistic matcher, and meanwhile maintain its robustness. To begin with, we consider to execute the holistic matcher on a ran-domly sampled subset of input schemas. Such a downsampling has two attractive characteristics: First, when schemas are abundant, it is likely to contain sufficient correct schemas to be matched. Sec-ond, by sampling away some schemas, it is likely to contain fewer noises and thus has more chance to sustain the holistic matcher.
Further, while a single downsampling may (or may not) achieve good result, as a randomized scheme, the expected robustness can only be realized in  X  X tatistical X  sense X  Thus, we propose to take an ensemble of multiple matchers, where each matcher is executed over an independent downsampling of schemas. We expect the ma-jority of these matchers have better results than directly running the matcher on all the schemas. Thus, by taking majority voting among these matchers, we can achieve a much better matching accuracy.
As Section 1 discussed, this data-ensemble idea essentially ap-plies bagging techniques [6] in machine learning. However, our ap-proach is different from bagging predictors in several aspects. First, setting : We apply the idea of the ensemble of randomized data for unsupervised learning ( e.g. , in our scenario, holistic schema match-ing with statistical analysis), instead of supervised learning, which bagging predictors is developed for. Second, techniques : Our con-crete techniques are different from bagging predictors. In particu-lar, in the sampling part, we take a downsampling other than ran-dom redistribution with replacement; in the voting part, we need to aggregate a set of ranked lists, which is more complicated than ag-gregate a set of labels in bagging predictors. Third, analytic model-ing : We build an analytic modeling specific to our holistic schema matching scenario (Section 3), which enables us to validate the ef-fectiveness of a particular configuration.

The following two sections will discuss in details about this data-ensemble framework. In particular, we first more formally model this framework and analyze its effectiveness (Section 3). Then we will present the technical details we developed for the data-ensemble framework (Section 4).
In this section, we present our modeling of the data-ensemble framework (Section 3.1), based on which we can more formally analyze its effectiveness (Section 3.2).
We develop a general modeling to formalize the data-ensemble framework motivated in Section 2.2. In particular, a schema extrac-tor outputs a set of N schemas, denoted by I = { Q 1 , Q 2 We denote the SM subsystem as an abstract module A . A holis-tic matcher A thus takes I as input and outputs a ranked list of matchings, denoted by R A I . Figure 3(a) illustrates the  X  X ase frame-work X  of simply concatenating SE and SM , which suffers the error cascade problem and thus needs to be enhanced. Unlike the base framework in Figure 3(a), the data-ensemble framework views the matching module A as a black box base algorithm and extends it by exploiting sampling and voting techniques. Therefore, we need to first model the  X  X ehavior X  of A and then the setting of the data-ensemble framework.
 Overall, the essential goal of A is to generate matchings M n in a correctly ranked order under the impact of imperfect data quality. In our modeling, we will focus on the impact of noises on a single matching M . As we will discuss later, our analysis should generally assume a representative  X  X orst-case X  matching, based on which our analysis for a single matching can also cover all the matchings.

Specifically, given a set of N schemas I as input, assume there are W problematic schemas ( i.e. , noises) that affect the ranking of M . Suppose the holistic matcher A can correctly rank M if one trial draws no more than K noises ( K &lt; W ) X  i.e. , in which case, M as a correct matching can actually be ranked higher.

Next, we need to model the data-ensemble framework, which consists of two steps: multiple sampling and rank aggregation , as Figure 3(b) shows. First , in the multiple sampling step, we con-duct T downsamplings of the input schemas I , where each down-sampling is a subset of independently sampled S schemas from I . We name such a downsampling as a trial and thus have trials in total. We denote i th trial as I i ( S ) (1  X  i  X  T ) executing the base algorithm A over each trial I i ( S ) ranked list of matchings R A step aggregates ranked matchings from all the trials, i.e. , (1  X  i  X  T ) , into a merged list of ranked matchings, which we de-note as R ( R A aggregate ranking R A thus is better than R A I .

Since W is determined by  X  X nherent X  characteristics of input schemas I and K by the holistic matcher A , we name them as base parameters . Unlike W and K , the sampling size S and the number of trials T are  X  X ngineered X  configurations of the data-ensemble framework and thus named as framework parameters .
Our goal of analysis is to justify, given estimation of the base parameters, W and K , which characterize the data quality and the base algorithm, can certain configuration, in terms of S and the data-ensemble framework achieve robustness?
In particular, given our modeling, we can derive the probability to correctly rank M in a single trial, which we name as hit prob-ability , i.e. , the chance of  X  X it X  a correct ranking of trial (and as we will discuss later, we will do more trials to enhance the overall hit ratio). Given base parameters W and K of probability is a function of S (and not T as it is for a single trial) and thus denoted as  X  the probability that there are exactly i noises in a single trial, de-noted by Pr ( k = i | S ) , i.e. , with i noises out of W correct ones out of N  X  W :
As our model assumes, M can be correctly ranked when there are no more than K noises. We thus have:
Next, we are interested in how many times, among T trials, can we observe M being ranked correctly? This problem can be trans-formed as the standard scenario of tossing an unfair coin in sta-tistics: Given the probability of getting a  X  X ead X  in each toss as  X 
M ( S ) With this equivalent view, we know that the number of trials in which M is correctly ranked ( i.e. , the number of tosses to observe heads), denoted by O M , is a random variable that has a binomial distribution [2] with the success probability in one trial as We use Pr ( O M = t | S, T ) to denote the probability that correctly ranked in exactly t trials. According to the binomial dis-tribution, we have
Pr ( O M = t | S, T ) = T !
Since our goal is to take majority voting among all the trials (in rank aggregation), we need a sufficient number of trials to ensure that M is  X  X ery likely X  to be correctly ranked in the relative ma-jority of trials. As an analogy, consider the coin tossing: Even the probability to get a head in each toss is high, say 0.8, we may not always observe 0 . 8  X  T heads in T trials; the actual number of heads may even be a minority of trials X  And our goal is to design a T such that  X  X he number of heads X  is very likely to be the majority. We thus need a sufficient number of trials to enable the majority voting. We name the probability that M can be correctly ranked in the majority of trials ( i.e. , more than half of trials) as voting con-fidence . Voting confidence is a function of T (as just intuitively observed) and S (as it also depends on  X  denote the voting confidence as  X 
As a remark, in Equation 4, we constrain T as an odd number
Our modeling essentially captures the functional relationship of the sampling size S and the number of trials T to together achieve a desired voting confidence. The interpretation of Equation 4 is: Given S and T , we can use Equation 4 to evaluate how effective the framework is. In particular, we illustrate with Example 1 as a basis of understanding how the framework works. 1 When T is odd, the notion of majority is always well defined, as there are no ties (of equal halves). Figure 4: The binomial distribution of O M , with T = 99  X 
M ( S ) = 0 . 55 Example 1: Assume there are 50 input schemas ( i.e. , N = 50 As characteristics of the data quality and the base algorithm, sup-pose a matching M cannot be correctly ranked because of 6 noisy schemas ( i.e. , W = 6 ); on the other hand, suppose M can be cor-rectly ranked if there are no more than two noisy schemas ( i.e. , = 2). Also, as the configuration of the data-ensemble framework, suppose we want to sample 20 schemas in a single trial and conduct 99 trials ( i.e. , S = 20 and T = 99 ).

According to Equation 1, in any single trial, we have 0.04 prob-ability to get no noisy schema, 0.18 probability with one and 0.33 probability with two. Together, we have 0.04 + 0.18 + 0.33 = 0.55 probability to correctly rank M in one trial ( i.e. ,  X 
Further, Figure 4 shows the binomial distribution of O M . Going back to the coin tossing analogy, this figure essentially shows, if the probability to get a head in one toss is 0.55, after tossing 99 times, the probability of observing a certain number of heads. For instance, we have Pr ( O M = 50 | S, T ) = 0 . 05 , which means the probability to observe 50 heads in 99 tosses is 0.05. According to Equation 4, we have 0.84 voting confidence to correctly rank (or observe heads) in more than 49 trials (or tosses) ( i.e. , = 0.84). Therefore, even  X  example, with sufficient number of trials, it is still very likely that M can be correctly ranked in the majority of trials.

Finally, while our analysis above focuses on a single matching, there are multiple matchings, M 1 , M 2 , ..., M n , to discover. We note that our analysis can generally assume a representative  X  X orst-case X  matching, based on which the analysis will also cover all the matchings. Specifically, the above modeling can be applied to any M i with its corresponding W i and K i values. We then assume there is a  X  X orst-case X  matching M  X  with base parameters M likely to correctly rank all the matchings M 1 , M 2 , ..., majority of trials with the same setting.

We show that the base parameters of the imaginary  X  X orst-case X  matching M  X  can be set as W  X  = max W i and K  X  = min K i 1  X  i  X  n . Intuitively, the higher W is, the lower  X  M ( S ) because we have more noises in the input schemas I ; on the other hand, the lower K is, the lower  X  algorithm A is less robust against noises. More formally, we can show that  X  and monotonically increasing with respect to K . (The derivation is straightforward and thus we do not provide a proof here.) There-fore, if we assume a matching M  X  with base parameters W  X  as the maximal value of W i and K  X  the minimal value of K i , we have  X 
Further, we can show that all the matchings also have higher vot-ing confidence than M  X  . Intuitively, if a matching M has higher hit probability, M should be more likely to be observed in the majority of trials, which means it also has a higher voting con-fidence. In particular, we can show that  X  ically increasing with respect to  X  tion is straightforward and thus we do not provide a proof here.) Therefore, since  X   X  we can find an appropriate setting of S and T to correctly rank in the majority of trials with high confidence, we will have even more confidence to correctly rank all the matchings in the majority of trials with the same setting of S and T .
Section 3 modeled and analyzed the data-ensemble framework in an abstract view; in this section, we discuss the technical details in our development. First, the multiple sampling step is straight-forward and the only thing we need to consider is to determine the sampling size S and the number of trials T . As we will discuss in Section 4.1, in our current development, we empirically choose S and T values that can achieve the best performance. Second, we need to develop a rank aggregation strategy to aggregate the match-ing results from all the trials into a merged ranked list of matchings. We discuss this issue in Section 4.2.
The first phase of the data-ensemble framework is to choose ap-propriate sampling size and number of trials. On one hand, we want to reduce unnecessary downsampling. A very small S value may not be able to collect enough schemas to represent the com-plete input data and consequently degrade the accuracy of the base matching algorithm. However, a larger S may contain more noises and thus also affect the accuracy of the matching result. Therefore, it is important to choose an appropriate S value to achieve good matching performance. (Our experiment in Section 5 also reflects this observation.) On the other hand, we want to reduce unnecessary trials. As Section 3.2 discussed, the more trials we have, the higher voting confidence will be. Considering the execution time of the data-ensemble framework, we do not want to be over-tried; therefore, within all the settings that can produce acceptable performance, we prefer the one with a smaller T .

In our development, we empirically determine the S and T val-ues that achieve the best performance, as Section 5 will illustrate. We notice that systematically choosing the best ( S problem that deserves further investigation, since the best setting may be various in terms of different input data and base matching algorithms. In Section 6, we will discuss our future plan of devel-oping a more principled approach to choosing S and T .
The second phase of the data-ensemble framework is to aggre-gate rankings R A list of ranked matchings R A this phase is thus to develop a rank aggregation strategy that can make R A R
We notice that the rank aggregation in our situation is slightly different from the traditional rank aggregation problem. Traditional rank aggregation assumes all voters share the same set of candi-dates and only rank them in different orders. In contrast, in our scenario, no candidates are given before executing the base algo-rithm and each trial outputs its own matching result. Therefore, before aggregate rankings, we need to have a candidate selection step to select matching candidates.

Consequently, the rank aggregation phase consists of two sub-steps: 1) Candidate selection: To select candidates from each to form a common pool of candidates C . 2) Rank aggregation: To aggregate the T rankings PR A where PR A will discuss below.
 Candidate Selection We select candidates based on the intuition that if a matching is only discovered by a minority of trials, M is more likely to be a false matching. Therefore, we consider a matching as a candidate if it appears in the majority of T rankings, R A thus pruned.
 Let C denote the union of all the candidates in each R A candidate selection, we will remove the non-candidate matchings from each R A dates; the corresponding new ranked list, which can be viewed as a  X  X rojection X  of R A noted as PR A Example 2: Assume we execute the base algorithm A on three tri-als, i.e. , T = 3 , and the outputs are thus three ranked lists R M 3 &gt; M 4 in descending order, R A I 2 ( S ) outputs M M 3 &gt; M 5 , and R A I 3 ( S ) outputs M 3 &gt; M 1 &gt; M pruned. In particular, M 5 is pruned; other matchings, M 1 and M 4 , all at least occur twice and thus are selected as matching candidates. Therefore, we have C = { M 1 , M 2 , M 3 , M 4 The projected rankings are thus RR A M M 2 &gt; M 4 . In particular, M 5 does not appear in PR A I it has been pruned.
 Rank Aggregation In rank aggregation, we need to construct an ordered list for the candidates in C , based on the individual ranks PR which has been extensively studied as a particular voting system in social science [14, 5]. In the literature, many rank aggregation strategies have been proposed, such as Borda X  X  aggregation [5] and Kemeny optimal aggregation [14]. There does not exist an aggrega-tion strategy that can beat other strategies in all aspects X  Different strategies have different strength and weakness.

Before discussing concrete aggregation strategies, we first need to solve the partial list problem. Specifically, since the output of one trial may not contain all the candidates in C , PR A only a partially ordered list. To be able to apply the aggregation strategy (as we will discuss below), it is necessary to also assign ranks to the candidates not in the list. In our development, given a trial with a partial list, we assign all the uncovered candidates with the same lowest rank. Therefore, in one trial, a covered candidate is always ranked higher than an uncovered one, and two uncovered candidates are equally ranked.

Although essentially any rank aggregation strategy can be ap-plied in our scenario, in our development, we choose Borda X  X  ag-gregation [5]. A primary strength of Borda X  X  aggregation is that it is computationally very efficient: It can be implemented in linear time. Also, it satisfies the properties called anonymity, neutrality, and consistency in the social science community [20].

Specifically, in Borda X  X  aggregation, given a candidate M r ji be number of matchings ranked lower than M j in PR A I borda score of M j , denoted as B ( M j ) , is defined as the sum of all r , i.e. , B ( M j ) = P T thus the descending ordering of all the candidates with respect to their borda scores.
 Example 3: Continue on Example 2, after candidate selection, we first complete the partial lists. In particular, since PR partially ranks the four candidates, we assign the lowest rank to the uncovered candidate M 4 , i.e. , we rank M 4 as the 4 th candidate in
Next, we compute the borda score for each candidate and then apply Borda X  X  aggregation. In particular, since M 1 is ranked higher than 3 candidates in PR A borda score for M 1 is 3 + 2 + 2 = 7. Similarly, the borda scores for M 2 to M 4 are 6, 5, 0 respectively. The final ranking R A I ( S,T ) M 1 &gt; M 2 &gt; M 3 &gt; M 4 .
We evaluate the data-ensemble framework over our motivating integration scenario in Section 2.1, i.e. , to make a holistic matcher robust against the noisy input schemas from a schema extractor. In particular, we implement the framework in Python 2.4 and test all the experiments on a Windows XP machine with Pentium M 1.6GHz CPU and 512M memory. We integrate concrete match-ing and extraction subsystems, and test both the base and data-ensemble frameworks over the integrated system with real query interfaces as input.

In particular, we test our approach over real query interfaces in two domains: Books and Airfares. First, we test the base frame-work by directly running a holistic matcher on the real data, which on one hand shows the error cascade problem, and on the other hand sets the baseline result we will compare to. Second, we run the data-ensemble framework over the real data and compare its accuracy with the baseline result. The result shows that our frame-work can significantly improve the accuracy of a holistic matcher. Third, to help us find the optimal configuration setting, we execute the data-ensemble framework under various parameter values. Sec-tion 5.1 discusses our experiment setup and Section 5.2 shows the experimental result.
As discussed in Section 2.1, we integrate the Schema Extrac-tor developed in [21] and the DCM matcher in [10]. This inte-grated system naturally becomes our testbed of the data-ensemble framework over real data. In particular, the DCM matcher discov-ers not only simple 1:1 matchings but also complex m : n match-ings, e.g. , author = { last name , first name } , with a correlation mining approach. As a mining approach in nature, DCM takes a set of schemas as input and outputs a list of discovered matchings ranked by a correlation measure, which fits our general modeling of a holistic matcher and is thus a qualified testbed.

To test the effectiveness of the data-ensemble framework over real data, we apply our approach to deep Web sources in two rep-resentative domains, Books and Airfares, in the TEL-8 dataset of the UIUC Web Integration Repository [1]. For each source, we use the Schema Extractor to automatically extract schemas from Web query interfaces. Then, for each domain, we use the DCM matcher to discover matchings among the extracted schemas.

To have a fair comparison of the matching results, we adopt the matching selection step and accuracy metrics developed in [10]. First, a greedy selection strategy is proposed in [10] to select a sub-set of most promising matchings among all the discovered ones. As the final matching accuracy is evaluated on selected matchings, to fairly compare the results of the data-ensemble framework and the base framework, we apply the same selection strategy to choose a subset of matchings from the aggregate ranking R A
Second, to evaluate the accuracy of selected matchings, we adopt the same metric, target accuracy , as DCM was validated. In partic-ular, to compare selected matchings, denoted by M h rect matchings written by human experts, denoted by erence [10] introduces a new term, closenym : Two attributes are closenym if they have one of the synonym, hyponym and hyper-nym relationships. Given an attribute A j , its closenym set is the set of attributes that are closenyms of A j with respect to a matching result M , denoted as Cls ( A j |M ) . The target precision and target recall of M h with respect to M c are defined as:
In the above definitions, the precision and recall of each individ-attribute A j in the dataset ( i.e. , its number of occurrences in differ-ent schemas). The baseline result: The baseline result we will compare to is the result of executing the base framework (Figure 3(a)). The fourth and fifth columns in Figure 5 show the result, where the fourth col-umn is the target precision and the fifth column the target recall. Comparing to the result reported in [10], where the input schemas are perfectly extracted, the accuracy of the base framework signif-icantly degrades due to the error cascade problem. To make the comparison more illustrative, we list the corresponding accuracies of [10] in the second and third columns. We can see that the degra-dation of target accuracy is up to 30%. This accuracy degradation is mainly because the existence of noises affects the ranking of match-ings and thus the result of matching selection.
 The result of the data-ensemble framework: Next, we test the data-ensemble framework on the two domains with empirically ob-tained optimal parameter settings. In particular, for Books, we set the sampling size S as 20 and the number of trials T as 41; for Airfares, we set S as 16 and T as 41. As Section 6 will discuss, one of our future work is to find a systematic and principled way to determine S and T , probably building upon our analytic modeling in Section 3.

As the data-ensemble framework is essentially a data-randomized approach (with multiple random trials), it is  X  X on-deterministic X  X  We thus measure the distribution of its performance. Specifically, we execute the framework 100 times on Books with the same set-ting S = 20, T = 41. Similarly, we execute it 100 times on Airfares with the same setting S = 16, T = 41. To quantify the comparison with the baseline result, we measure two suites of target accura-cies: the average target accuracy ( i.e. , the average precision and recall of the 100 executions) and the best target accuracy ( i.e. , the best precision and recall of the 100 executions).

The results of both average and best accuracies are listed in Fig-ure 5 (columns 6-9). We can see that, comparing to the baseline result, both the precision and recall are improved. In particular, in most executions, the data-ensemble framework achieves better ac-curacy than the baseline result. For instance, Figure 6 shows the 100 target precisions of the 100 executions over Books and Air-fares. We observe that, although accuracies may be various in dif-ferent executions, most precisions in both Books and Airfares are better than their corresponding baseline precisions. Similar result can also be observed in Figure 7 for target recall. (Figure 7 looks more regular than Figure 6 because for recall, only the value on nu-merator is changing, while for precision, values on both numerator and denominator are changing.) Hence, this experiment indicates that the data-ensemble framework can indeed boost the matching accuracy under noisy schema input, and thus maintain the desired robustness of a holistic matcher.

The execution time of the data-ensemble framework is also ac-ceptable. The 100 executions on Books take 118 seconds and on Airfares 109 seconds. Therefore, the average time for one execu-tion is about only 1 second.

From Figure 6, we also observe an interesting phenomenon: It seems that there is an upper-bound of precision, which the data-ensemble framework cannot exceed. (The same phenomenon also exists in the recall part in Figure 7.) The existence of such an upper bound is because, in essence, there are two types of data quality problems, noises and missing data, and the data-ensemble frame-work can deal with noises, but not missing data.

First, noises are some observed data that ideally should not be observed, i.e. , they are outliers . Although noises may affect the ac-curacy of the base algorithm, they are minority in quantity. Down-sampling is thus a good approach to filtering them out and conse-quently, the majority voting can be effective.

Second, missing data are some data that ideally should be ob-served, but in reality are not. For this missing data case, sampling and voting techniques will not help, since when the entire dataset has missing data, all the trials will also have missing data and their aggregate result thus cannot fix the problem.

Therefore, the accuracy affected by missing data cannot be fixed by the data-ensemble framework. The accuracy upper-bound of the data-ensemble framework is thus 1 - X  , where  X  is the accuracy degradation caused by missing data.
 The result under various configuration settings: The purpose of this set of experiments is to help us empirically find the optimal parameter setting of S and T .

First , we measure the accuracy of the data-ensemble framework with different sampling sizes on the two domains. In particular, we fix T at 41 and let S progressively increase from 10 to 55 with an increment size 5 ( i.e. , 10, 15, 20, ..., 55) for Books and from 10 to 40 with an increment size 3 for Airfares. For each sampling size, we execute the data-ensemble framework 30 times and compute the average precision and recall. Figure 8 shows the experimental result.
 From Figure 8, we can observe the same trend in both domains X  That is, when sampling size increases, the target precision mostly keeps on decreasing, while the target recall goes up first and then goes down at some point. We give the explanation as below: A small sampling size may miss some attributes in downsampling and thus discover less matchings, which results in trivially high preci-sion but low recall. With larger sampling size, we are able to cover more attributes and thus discover not only more correct matchings, but also a few false matchings. Consequently, the precision de-creases and recall increases. When the sampling size is too large, a downsampling is likely to have many noises and thus the recall starts to decrease again.

The best sampling size we should take is thus some values in the middle. We choose the F -measure, which combines precision P and recall R as F = 2 PR From Figure 8(a) shows, we can see the best range of sampling size for Books, according to F -measure, is around 20. Similarly, from Figure 8(b), the best range of sampling size for Airfares is around 16. Therefore, we choose these two values as our optimal settings for S in Books and Airfares respectively.

Second , we measure the accuracy of the data-ensemble frame-work with different numbers of trials on the two domains. In par-ticular, we fix S at 20 for Books and 16 for Airfares. We change T from 5 to 49 with increment size 4 for both domains. For each T , we again execute the framework 30 times and compute the av-erage precision and recall. Figure 9 shows the experimental result. From the result, we can see that, in both domains, both the pre-cision and recall become more and more flat and stable when increases. This result indicates that with as long as the not very small, we can have roughly the same performance and thus the decision on T is not a critical factor. Specifically, according to Figure 9, setting T as 41 is good enough to obtain stable result in both domains.
In our study for the data-ensemble framework, we also observed some open issues that warrant further research. First, in our cur-rent development, we empirically set sampling size S and number of trial T ; thus, we naturally want to know whether it is possible to develop a principled method to automatically derive the appro-priate S and T values. We notice that our analytic modeling in Section 3 can be a promising guidance for such a derivation. In particular, according to Equation 4, we can ask the question: Given an objective voting confidence c, what are the appropriate values of S and T we should take to ensure  X  M ( S, T ) &gt; c ? The ( pairs that satisfy the above requirements are our setting candidates. However, we need to solve two problems: 1) How to enumerate the space of all valid ( S , T ) pairs; 2) As the space often contains many (
S , T ) pairs, how can we evaluate whether a pair is a good setting or not. We plan to study this problem in our future work.
Second, since exploiting sampling techniques, the matching re-sult of our framework may be various in each time; it is thus valu-able to develop some strategy to address this uncertainty problem. In particular, we can again exploit the statistical voting strategy: Instead of running the framework only once, we execute the frame-work multiple times and choose the most frequently discovered matching result as the final output. On one hand, in a statistical sense, such a strategy should be able to deliver more stable match-ing result; on the other hand, since in most cases, the data-ensemble framework achieves better accuracy, such a strategy should also give a good matching quality, although may not be the best one.
Third, while this paper focuses on integrating holistic schema matching with schema extraction, to generalize, we believe the data-ensemble framework will be more widely applicable to the system integration of other large scale integration tasks. Our study is a first step toward understanding the system integration issue of building an integration system, which are often overlooked when we focus on well-abstracted and isolated tasks. Although this work addresses the noisy input problem in the context of integrating holis-tic schema matching with interface extraction, as our modeling and techniques are rather generic, we believe it will be more generally applicable beyond the holistic schema matching task. In our future work, we plan to apply this data-ensemble idea for other holistic matchers as well as other integration tasks.

In summary, this paper identifies robust quality as an inherent challenge for leveraging holistic quantity in large scale schema matching. Such a robustness issue inevitably arises in integrat-ing holistic schema matching with automatic schema extraction. As the solution, we develop a data-ensemble framework with sam-pling and voting techniques, inspired by bagging predictors. We are essentially applying bagging techniques in a new scenario of mining semantic correspondences among attributes. Both the ana-lytic justification and experimental result show the promise of our framework. [1] The UIUC web integration repository. Computer Science [2] D. R. Anderson, D. J. Sweeney, and T. A. Williams.
 [3] C. Batini, M. Lenzerini, and S. B. Navathe. A comparative [4] M. K. Bergman. The deep web: Surfacing hidden value. [5] J. C. Borda. M  X  emoire sur les  X  elections au scrutin. Histoire de [6] L. Breiman. Bagging predictors. Machine Learning , [7] K. C.-C. Chang, B. He, C. Li, M. Patel, and Z. Zhang. [8] A. Doan, P. Domingos, and A. Y. Halevy. Reconciling [9] B. He and K. C.-C. Chang. Statistical schema matching [10] B. He, K. C.-C. Chang, and J. Han. Discovering complex [11] H. He, W. Meng, C. Yu, and Z. Wu. Wise-integrator: An [12] H. He, W. Meng, C. Yu, and Z. Wu. Automatic extraction of [13] J. Kang and J. F. Naughton. On schema matching with [14] J. G. Kemeny. Mathematics without numbers. Daedalus , [15] Y. Lee, A. Doan, R. Dhamankar, A. Halevy, and [16] J. Madhavan, P. A. Bernstein, and E. Rahm. Generic schema [17] E. Rahm and P. A. Bernstein. A survey of approaches to [18] L. Seligman, A. Rosenthal, P. Lehner, and A. Smith. Data [19] W. Wu, C. T. Yu, A. Doan, and W. Meng. An interactive [20] H. P. Young. An axiomatization of borda X  X  rule. J. Economic [21] Z. Zhang, B. He, and K. C.-C. Chang. Understanding web
