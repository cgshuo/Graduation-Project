 Mining high-speed data streams has become an important topic due to the rapid growth of online data. In this paper, we study the prob-lem of active learning for streaming networked data. The goal is to train an accurate model for classifying networked data that arrives in a streaming manner by querying as few labels as possible. The problem is extremely challenging, as both the data distribution and the network structure may change over time. The query decision has to be made for each data instance sequentially, by considering the dynamic network structure.

We propose a novel streaming active query strategy based on structural variability . We prove that by querying labels we can monotonically decrease the structural variability and better adapt to concept drift. To speed up the learning process, we present a net-work sampling algorithm to sample instances from the data stream, which provides a way for us to handle large volume of streaming data. We evaluate the proposed approach on four datasets of dif-ferent genres: Weibo, Slashdot, IMDB, and ArnetMiner. Experi-mental results show that our model performs much better (+5-10% by F1-score on average) than several alternative methods for active learning over streaming networked data.
 H.2.8 [ Database Management ]: Database Applications X  Data Mining ; I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Experimentation Active Learning; Data Streams; Network Sampling
With the availability and massive amount of streaming data in online social networks and social media, mining streaming data has become an important topic. One challenge for mining stream-ing data is the lack of labeled data due to rapid changes in data Figure 1: Streaming Networked Data: when a new instance y arrives, new edges (dash lines) are added to connect the new instance and existing instances. { G i }  X  i =0 are snapshots of the streaming network. distribution and high costs of labeling efforts. Active learning can alleviate this problem, by actively querying as few  X  X nformative X  instances as possible so as to build an accurate model. In existing literature [28, 6, 5, 29], active learning for streaming data has been studied. However, these studies ignore an important factor  X  net-work correlation among the data instances. Some other research indeed studied the active learning problem for networked data [23, 25, 3, 4, 10, 27, 8, 22]. However, their methods target static net-works, and cannot be directly adapted to streaming networked data. In this paper, we particularly focus on investigating the problem of active learning for streaming networked data. As far as we know, this problem has not been extensively studied before.

One example of streaming networked data is illustrated in Figure 1. Instances arrive in a streaming fashion. When a new instance arrives, edges are added to connect the new instance to existing instances. In this way, we form a streaming network that evolves dynamically over time.

The problem of active learning for streaming networked data is extremely challenging, in practice. The first challenge is how to adapt to concept drift in data streams, i.e., the fact that the distri-bution of input data changes over time. The second challenge lies in the use of network correlation. In the networked data, there is correlation among instances. How to model the correlation in the streaming data is a challenging problem. One natural method is to use graphical models to model the networked data. However, graphical models tend to be computationally expensive, and we need to make a trade-off between efficiency and the model perfor-mance. The third challenge is that we must decide whether to query an instance at the time of its appearance, which makes it infeasible to optimize a global objective function.

In this work, we propose an active learning approach to address the above questions. We propose a novel streaming active query al-gorithm for querying labels of instances by minimizing structural variability . We analyze our algorithm and justify that our proposed method can leverage the network correlation for classification and better adapt to concept drift. Further, to handle large volume of streaming data, we design a streaming network sampling algorithm to sample instances into a reservoir for model learning and predic-tion. We consider the loss incurred by discarding an instance in both spatial and temporal dimensions. We evaluate the proposed approach on four different genres of datasets: Weibo, Slashdot, IMDB, and ArnetMiner. As illustrated in Figure 2, our active query method Minimum Variability (MV) performs much better (+5-10% by F1-score on average) than several alternative methods for active learning for streaming networked data.

Our major contributions are as follows: (a) formulate a novel problem of active learning for streaming networked data; (b) pro-pose a streaming active query algorithm based the structural vari-ability; (c) design a streaming network sampling algorithm to han-dle large volume of streaming data; (d) empirically evaluate the effectiveness and efficiency of our proposed approach over four datasets of different genres.
 Organization. Section 2 formulates the problem; Section 3 in-troduces the model and learning method; Section 4 describes our approach; Section 5 presents the experimental results; Section 6 discusses related work; and Section 7 concludes the work.
In this section, we first give several necessary definitions, and then formulate the problem addressed in this paper.

Let  X  = {  X  i }  X  i =0 denote a data stream and each datum be de-noted as a 4-tuple  X  i = ( x i ,t i ,  X  i ,y i ) , where x stance (represented as a feature vector); t i corresponds to the time when  X  i arrives in the data stream;  X  i = { ( y i ,y j ) | t set of undirected edges connecting y i to earlier arrived instances { y j } ; and y i  X  Y is an associated label to represent the category of instance x i . In different practical applications, the output space of y i can be defined in different ways. For simplicity, we focus on the binary case (i.e., Y = { +1 ,  X  1 } ) here, but the problem and the framework proposed later are flexible and can be extended to multi-class case. In our problem setting, the value of y i is unknown until we actively query for it.

In data streams, the distribution of the input data usually changes over time. This problem is referred to as concept drift [28]. For-t . The probability distribution may be different at different time stamps. Given this, we can formally define our problem addressed in this paper.
 Problem 1. Active Learning for Streaming Networked Data. Our input is a data stream  X  . At any time t i , we maintain a classi-fier C i learned from the arrived instances. For a new instance x we first predict its label and then we can choose to query its label y i +1 to incrementally update the learned classifier C i . Our goal is to use a small number of queries, so as we can learn a high accurate classifier to predict the labels of the coming instances.
The problem has two unique characteristics that make it quite different from the traditional active learning or streaming data min-ing. First, as the data arrives in a streaming manner, we need to make the decision whether to query the label of a new instance when it arrives, which means the traditional pool-based active learning for networked data (e.g. [23]) does not work here. Sec-ond, the data instances are connected with each other. This means that we need to not only consider processing each data instance sequentially, but also consider the dynamic network structure. In the rest of this paper, we first introduce a model to model the net-worked data, and then propose our approach for actively learning the streaming data.
In our problem, instances are connected with each other, and thus, at any time t i , we can construct a time-dependent network G i by all the arrived instances before and at time t we can derive a network G i = ( X i ,E i , y L i , y U i matrix, with an element x ij indicating the j th feature of instance x ; E i = { e l = ( y j ,y k ,c l ) } records all edges between instances and c l is the edge type of e l ; y L i denotes a set of labels of instances that we have already actively queried before and y U i denotes a set of unknown labels for all the other instances.
 Now, our first challenge is how to model the networked data. Graphical models are appropriate for modeling networked data be-cause they are capable of capturing correlation between instances. Typically, there are two types of graphical model: directed and undirected model [21]. In this work, we focus on the undi-rected graphical model, also referred to as Markov Random Field (MRF) [11]. According to MRF, we can define two sets of poten-tial (factor) functions respectively on the instances and the edges between instances.
In the above functions,  X  = (  X  ,  X  ) are model parameters we seek to estimate. We let  X  y represent the true label configuration of y , and  X  y j the true label of y j . By combining the two types of factor functions, we can write the energy of the network G i as:
In the above definition, we do not give the instantiation of the two factor functions f ( . ) and g ( . ) . In general, they can be defined in different ways in different applications. The only constraint is that f (  X  ) should be differentiable w.r.t.  X  and g (  X  ) should be differ-entiable w.r.t.  X  .
 Model Inference. Suppose we have a learned parameter configu-ration  X  . Then we can apply the model to predict the label of a new instance y i +1 . The task is to assign labels to instances in y that the energy function Q G i is minimized, i.e., It is usually intractable to directly solve the above problem. A number of approximate algorithms can be considered, such as Loopy Belief Propagation (LBP) [16] and Mean Field [24]. Here we consider a dual decomposition method [17], which provides a flexible approach for deriving and solving tight dual relaxations for our problem by decomposing the original (intractable) prob-lem into a set of tractable subproblems. Let y U l e and y j  X  y U i } ,  X  y L l = {  X  y j | y j  X  e l and y I j = { e l | y j  X  e l and e l  X  G i } . The dual optimization prob-lem is as follows where  X  is a set of dual variables. By optimizing the inner min-imization of the above problem, we find a label configuration for all unlabeled instances. Specifically, we solve the optimization in Eq. (3) by the projected subgradient method [13]. We omit the presentation of subgradients here due to space limit. Let  X  y local minimizer for y j of each subproblem on e l . Let  X  y predictive labels for y U i . We use voting to obtain  X  y the major label of  X  y l j among all edges I t i j .
 Max-margin Learning. In learning, our task is to estimate the unknown parameters  X  . Let D y ( y 1 , y 2 ) be a dissimilarity measure between two possible label configurations y 1 and y 2 . Following [12], we assume that the dissimilarity measure can be factorized onto vertices and edges. More formally, where j and k are indices of instances in the graph, and d d are dissimilarity measures on vertices and edges respectively; Notation y m,j represents label of the j th instance in y
Following the max margin Markov network [20], given unla-beled instances y U i , the parameter  X  should satisfy a property that the energy of the MRF model with labeled instances  X  y than the energy with any other label configuration y L i by at least D y (  X  y i , y i ) , where  X  y i =  X  y L i  X  y U i , and y a slack variable  X   X  , the constraint can be written as
The objective function is written as a combination of the slack variable and a regularization term, where  X  is a tunable factor. According to Eq. (6), the slack variable can be written as:
Because both the energy function Q G i and the dissimilarity mea-sure D y can be factorized onto vertices and edges, we can leverage dual decomposition to relax problem (8). For concise notation, we let  X  y j and y j both denote y j  X  y Us i . Similar to model inference, the dual optimization problem becomes
L  X  = min where  X  and  X  are sets of dual variables.  X  e l = (  X  y j e = ( y j ,y k ,c l ) . y L l = { y j | y j  X  e l and y j  X  y optimization problem becomes which could also be solved by the projected subgradient method. We can write the subgradient w.r.t.  X  and then update by  X  =  X   X   X d  X  , where  X  is the learning rate. For more details of the projected subgradient method, please refer to [13]. Now we discuss how to perform active learning for the above MRF, when the data arrives in a streaming fashion. In our set-ting, instances in the networked data arrives one by one. All the arrived data (instances) are unlabeled until we choose to query its label. For querying one instance X  X  label, we need to make the de-cision immediately. When making the decision, we consider the instance X  X  feature x i , and its connections (edges) to the earlier ar-rived instances. If we decide not to query, we will not be able to query the label of the instance again. As the network structure is dynamically changing, traditional pool based active learning al-gorithms [23, 25] are not applicable here. Existing active learning algorithms for independent vector based streaming data [28, 6] also do not work because they cannot model the network correlation.
We propose to use structural variability as the query criterion and design an algorithm for streaming active query. Algorithm 1 gives the framework of the proposed streaming active learning method. There are mainly four steps in the framework: (1) MRF-based inference for networked data, (2) streaming active query, (3)
Algorithm 1: Framework: Active Learning for Streaming Net-worked Data Input : The data stream  X 
Output : Predictive labels {  X  y i }  X  i =1 1 initialize  X  ,  X  , and  X  2 initialize G 0 3 while  X  not the end do 4 Step 1: MRF-based inference: 5  X  i  X  new datum from  X  6 insert y i and the associated edges into G i  X  1 to form G 7 initialize  X  8 while not convergence do 9 search local minimizers  X  y l j in Eq. (3) 10 update  X  by projected subgradient 11 predict  X  y i by the label in  X  y U i 12 Step 2: Streaming active query by Algorithm 2 13 Step 3: MRF-based parameter update: 14 create components in  X  and  X  for y i and the associated 15 while not convergence do 16 search local maximizers  X  y l j in Eq. (9) 17 update  X  ,  X  and  X  by projected subgradient 18 Step 4: Network sampling by  X  4.2 MRF-based parameter update, and (4) network sampling. The first and third steps have already been described in  X  3, and the fourth step (network sampling) is to enhance the learning framework by sampling instances from the data stream, as it is inefficient to keep all arrived instances for learning the MRF model. We will explain the sampling strategy in  X  4.2. Herein, we focus on describing the streaming active learning algorithms.
In our problem, as labels of instances are unknown until we choose to query, the resultant MRF can be considered partially labeled. For actively querying instances from the streaming net-worked data, we propose a novel criterion, structural variability, to measure the potential effects of the unlabeled instances.
Let y Q i represent the set of queried labels before time t be the total number of instances in the data stream. The streaming active query problem is to make a tradeoff between the number of queried labels | y Q N | and the structural variability for each snapshot graph.
 Structural Variability. We define the structural variability for an MRF. According to Algorithm 1, when we predict the label  X  y we need to infer the unknown labels  X  y U i , by minimizing the energy of the MRF. If we can control the gap between the energy of the inferred configuration and that of any other possible configuration, the effects of the unlabeled instances on the energy of the MRF can be controlled. Based on this idea, we define the structural variabil-ity as follows,
The structural variability can effectively capture both instance-based and edge-based information. First, if the structural variability is small, the unknown labels do not significantly affect the model energy and thus future prediction, so we do not need to query the labels of unknown instances. Second, the structural variability can, to some extent, help adapt to concept drift, which will be detailed in the following sections. Theoretically, the structural variability defined in Eq. (11) has the following properties: monotonicity , normality , and centrality .

P ROPOSITION 1. (Monotonicity) Suppose y L 1 and y L 2 are two sets of instance labels. Given  X  , if y L 1 ( y L 2 , then we have P ROOF . See appendix.
 P ROPOSITION 2. (Normality) If y U i =  X  , we have
P ROOF . Because y U i =  X  , we have Q G i (  X  y L i Q
G i (  X  y L i , y U i ;  X  ) . Therefore, by definition, V
P ROPOSITION 3. (Connection to centrality) Suppose G is a star graph with ( n + 1) instances. The central instance is y y is connected to y 0 with an edge e j and no other edges exist. Given the parameter  X  , suppose for each e j , g ( e j ;  X  ) = w if y j = y 0 = +1 ; g ( e j ;  X  ) = w  X   X  0 if y j = y 0 otherwise g ( e j ;  X  ) = w 0  X  0 . If w + 6 = w  X  , then there exists a positive integer N , such that for all n &gt; N , we have P ROOF . See appendix.

Proposition 1 guarantees that the structural variability will not increase when we label more instances in the MRF model. Propo-sition 2 shows that if we label all instances in the graph, we incur no structural variability at all. Proposition 3 gives the connection between the structural variability and network centrality. Under the given conditions, to minimize the structural variability leads to querying instances with high network centrality. Further, we define a decrease function for each instance y i , given  X  , as which could be viewed as the decrease of the structural variability by querying y i .

Based on the above propositions and the decrease function, our objective of active learning becomes to query for the labels of a sub-set of the unlabeled instances that can result in the most decrease in structural variability.
 Active Query Algorithm. Our proposed streaming active query algorithm is based on Eq. (12). Specifically, we use thresholding to select instances to query. Given the constant threshold  X  , we query y if and only if  X  i is greater than or equal to  X  . However, the computation of  X  i is in general intractable due to the exponential complexity of computing the exact structural variability defined in Eq. (11).

To approximate the decrease function, we estimate the structural variability after querying y i by where P  X  (  X  ) represents the true probability of an event. In this way,  X  V  X  is the expectation of the structural variability V i  X  ( y Now the problem becomes how to compute the true probability P (  X  ) and the structural variability V i  X  ( y L i ) . P intractable because we never know the true probability of an event. Algorithm 2: Streaming Active Query
Input : The threshold  X  , the set of queried labels y Q i  X  1
Output : The updated set of queried labels y Q i 1 compute P (  X  y i =  X  1) using Eq. (14) 2 set y i to be unknown 3 initialize  X  4 while not convergence do 5 search local maximizers  X  y l j in Eq. (15) 6 update  X  using Eq. (16) 7 compute the dual structural variability V i  X  (  X  ) using Eq. (11) with local maximizers  X  y l j 8 set y i to be +1 and repeat Lines 3 -7 9 set y i to be  X  1 and repeat Lines 3 -7 11 if  X  i  X   X  then 13 else Therefore, we assume the probability that an instance y j as y  X  Y can be represented by an exponential-linear function [9, 14]. Given the parameter  X  at time t i , we first label the instance to be y i = +1 , and calculate the energy function Q i +1 (1). We then label its y i to be  X  1 , and again calculate the energy function as Q i  X  1 . Finally, the true probability P  X  (  X  y proximated by
To compute the structural variability V i  X  ( y L i ) (Eq. 11), we again leverage dual decomposition to relax the problem. Following the routine introduced in  X  3, the dual optimization problem becomes,
L  X  = min where  X  are sets of dual variables.  X  e l = (  X  y j ,  X  y ( y j ,y k ,c l ) . For conciseness, here  X  y j refers to  X  y instance y j . Let  X  y l j be the local maximizer for y j e . The subgradients can be written as d X  l j (  X  ) = I [ X  y  X  ] . The update rules are as follows: where  X  is the learning rate and df (  X  ) represents the difference of f (  X  ) from the last iteration. The active query algorithm is summa-rized in Algorithm 2.
 Analysis and Discussions. We further compare the proposed structural variability with other typical active learning criteria and convey the essential difference between different query criteria. We begin with a toy example, as illustrated in Figure 3. Suppose, at Figure 3: How our method adapts to concept drift and utilizes network correlation: compare different criteria with an exam-ple. the very beginning, there are two clusters of instances in the MRF model, one positive and the other negative. Instances are connected with edges within each cluster. Soon, there comes a wave of con-cept drift, and a drastically increasing number of negative instances are connected to the positive cluster. We call this a concept drift because in our previous concept, the upper cluster is learned to be positive and the lower cluster negative, while for now a number of negative instances are connected to the upper cluster. In this case, the previously learned classifier (concept) does not apply any more.
Active query can be used to alleviate this problem. Without active query, the model would classify all the new instances into the positive category because they are closely connected to the up-per cluster. However, all the newly arrived instances are negative, which means the model would suffer from a high error rate. In our active query setting, we could choose to query one instance at each time stamp. If we query by random sampling, we will probably be unlucky and query the instance in the blue box, which is isolated from other newly arrived instances and would not be helpful for updating the MRF model. If we query by uncertainty measure, we will choose the instance in the black box to query because it is con-nected to positive and negative instances at the same time. How-ever, it is not really an ideal choice because it cannot significantly affect other newly arrived instances through network structure. Finally, consider query by minimizing the structural variability. By proposition 3, to minimize the structural variability, we will choose the central instance in the red box. The basic intuition is that by fixing the label for the central instance, connections among unlabeled instances are reduced and thus the structural variability will be relatively small. In this way, more instances will be affected because the queried instance takes an important position in the net-work. Since more instances will be affected, we expect the model can adapt to the new concept with less iterations. Different from naive degree based criteria, by optimizing a global objective (11), our method can effectively manage and distribute the labeling bud-get (i.e., queried instances will not be closely connected). Also, as stated above, minimizing the structural variability will control the effects of unknown labels and we do not need to query the unknown labels for future prediction. In practice, it is inefficient to store all the data for learning the MRF models. We present a streaming network sampling algorithm to enhance the learning process. The basic idea is to maintain an instance reservoir of a fixed size (denoted as n ), and update the reservoir sequentially on the arrival of streaming data. Formally, at time t i , we reserve a subgraph G s i = ( y Ls i , y Us i such that | y Ls i  X  y Us i | does not exceed the memory budget n . The rest of the graph G i \ G s i will be removed from the graphical model.
When a new instance arrives, we first add it into the instance reservoir to predict its label. This operation will possibly make the size of reservoir exceed the budget n . To handle this, we se-lect one instance in the reservoir and remove it from the reservoir, along with its associated edges. Which instance should we dis-card? Straightforwardly, we can discard early-arrived instances so as to adapt to concept drift. The method may work when instances are independent. However, in our problem, instances are correlated and dependent. Simply discarding early-arrived instances may de-grade the network correlation. Thus, instead, we consider the loss of an instance in two dimensions, spatial and temporal . For spatial, we consider the loss in a snapshot graph based on network correla-tion deterioration; and for temporal, we integrate the spatial loss of snapshot graphs over time.
 Spatial Dimension. We first consider the sampling strategy in the dual optimization problem (Eq. 3). When we remove an instance y j from a graph G i , we remove all associated edges I same time. The dual variables  X  related to the neighbors of y no long satisfy constraint (4). We use dual variables as indicators of network correlation. To measure the deterioration of network correlation in a spatial dimension, we define the violation for each instance y k as follows:
In this way, the spatial loss function of y j at the current time stamp t i can be defined as the sum of violation over its neighbors, where N t i j is the set of neighbor instances of y G \ y j indicates the remaining graph after y j and its related edges are removed. The intuition behind the definition of the spatial loss function can be interpreted from two aspects. For one thing, as dual variables can be interpreted as the message sent from the edge fac-tor to each instance [17], we define the loss function to reduce the loss of such messages. For another, the more serious the constraint (4) is violated, the more we need to adjust the dual variables; i.e., the network correlation is more seriously affected.
 Temporal Dimension. Because the streaming network is evolving dynamically, we should not only consider the current spatial loss, but also consider the loss in a temporal dimension, by estimating spatial loss for successive time stamps. To proceed, we assume that for a given instance y j , dual variables of its neighbors  X  a distribution with an expectation  X  j for y k  X  e l and e that the dual variables are independent. We obtain an unbiased es-timator of  X  j based on the sample mean on current snapshot graph G . Specifically, we have
At time t i , for an instance y j , we consider the spatial function from t i to t j + T m , where T m is a constant term to restrict the maximum time span for all instances. Then the loss of removing y from G i is defined as the expectation of the spatial loss of y integrated from t i to t j + T m . More formally, we have
P ROPOSITION 4. Suppose edges are added according to pref-erential attachment [2]; i.e., We have,
The proof of the above proposition is given in the appendix. We then use Eq. (19) to estimate  X  j , and rewrite the loss function of y as where C is a constant, whose value does not affect our sampling decision.
 Network Sampling Algorithm. Based on loss function (22), we can formulate our sampling strategy. At time t i , we receive a new datum  X  i from  X  , and append y i and the associated edges into the MRF model. If the number of instances exceeds the reservoir size n , we remove the instance with the least loss function and its asso-ciated edges from the MRF model.
 Interpretation. We provide more intuitive interpretation for the loss function in Eq. (22). The loss function of an instance is deter-mined by two terms:  X  t i ( y j ) and (( t j + T m ) 3 2  X  t  X  i ( y j ) enables us to leverage the spatial loss function in the net-work G i . It is consistent with the intuition that instances that are important to the current model are also likely to remain important in the successive time stamps. The second term (( t j + T indicates the preference towards reserving late-arrived instances. As T m and t i are constants for the current time stamp, instances with larger t j are reserved. In this manner, our sampling proce-dure has implicitly handled the problem of concept drift, because later-arrived instances are more relevant to the current concept [28]. We see that by combining the two terms, our proposed sampling strategy incorporates the current spatial loss and concept drift in a unified representation.
In our implementation, we empirically set the parameter T 3 nT a , where T a is the average time interval between two consec-utive data instances and n is the reservoir size. In real world ap-plications, it is easy to estimate T a , by sampling consecutive data streams.

Following [12], we use Hamming loss as the dissimilarity mea-sure between label configurations D y (  X  ) . Following the convention of graphical models [14], we use linear factor functions, where the local factor function is formulated as f ( x i ,y i ,  X  ) =  X  and the edge factor function is defined as g ( e l Here f ( x i ,y i ) is the local feature vector and g ( e feature vector. Moreover, we set  X  = 1 in Eq. (7).

The reservoir size n (resp. the query threshold  X  ) is a tunable parameter for tradeoff between model performance and efficiency. the shuffled data. The high the better. reservoir. The higher the better.
 Datasets. We evaluate the proposed method on four different gen-res of networks: Weibo, Slashdot, IMDB, and ArnetMiner. Table 1 lists statistics of the four networks.

Weibo 1 is the most popular microblogging service in China. We use a dataset from [26]. We view the retweeting flow as a stream. Given a microblog, each user at a given time stamp is viewed as an instance. Our task is to predict whether a user will retweet the microblog. We view every second as a time stamp. Three types of edge factor functions are defined: friends; sharing the same user; and sharing the same tweet.

Slashdot 2 is an online social network for sharing technology re-lated news. In 2002, Slashdot introduced the Slashdot Zoo which allows users to tag each follow relationship as  X  X riends X  or  X  X oes X  (enmity). We treat each follow relationship as an instance. Our task is to classify the relationships into friends and foes . Instances are generated only if two users comment on the same post, and are sorted by the time of the latest comments. We view every second as a time stamp. Three types of edges are defined: appearing in the same post; sharing the same follower; and sharing the same followee.

IMDB 3 is an online database of information related to movies and TVs. Each movie is treated as an instance, and edges indi-cate common-star relationships between movies. We view every day as a time stamp. Our task is to classify movies into categories Romance and Animation .

ArnetMiner 4 is an academic social network. The dataset is from [19]. Each publication is treated as an instance, and edges indi-the higher the better.
 cate co-author relationships between publications. We view every month as a time stamp. Our task is to classify publications into categories such as Data Mining and Machine Learning .
 Evaluation Aspects. To quantitatively evaluate the proposed ap-proach, we consider the following aspects:
Active Query. We focus on evaluating the active query method by keeping all arrived instances in the reservoir. We compare dif-ferent streaming active query algorithms with varied labeling rates (the ratio of queried labels).

Network Sampling. We focus on evaluating the effectiveness of the network sampling algorithm. We fix the active learning al-gorithm and vary the reservoir size to compare different network sampling algorithms. We also measure the efficiency improvement achieved by network sampling.

Hybrid. We combine the streaming active query and the network sampling algorithms, and evaluate its performance. We evaluate all comparison methods in terms of F1-score.
We first suppress the network sampling method by keeping all arrived instances in the reservoir, and focus on testing the effec-tiveness of the active query algorithm.
 Comparison Methods. We compare the following active query algorithms.

Minimum Variability (MV): it is our approach proposed in Al-gorithm 2. We adjust the threshold  X  to achieve different labeling rates.

Variable Uncertainty (VU): it is a variant of uncertainty sam-pling proposed by [29]. According to [29], we set the adjusting step to 0.01, and the initial labeling threshold to 1. We compute the predictive probability using Eq. (14).

Feedback Driven (FD): it was proposed in [5]. According to [5], we set the parameter = 0 . 1 . We adjust the threshold value Q th to have different labeling rates. Again, we compute the pre-dictive probability using Eq. (14).

Random (RAN): it is the simplest strategy for active query. In this method, we randomly select instances for query.

We also implement the naive algorithm that queries instances with highest degrees. However, the performance is even worse than random so we do not include this method in our discussion. Results. Figure 2 shows the results of different methods on the four datasets. In each subgraph, the x-axis indicates the labeling rate and the y-axis represents the F1 score. It can be easily seen that our proposed active query algorithm significantly and consistently outperforms other comparison method on all the four datasets. Since VU and FD are methods adapted from vector-based stream-ing active learning, the result justifies that vector-based streaming active learning strategies are not applicable to active learning for streaming networked data. In general, by actively labeling mere 10% of the instances, our approach achieves a performance com-parable to the result obtained with all labels. For example, in the ArnetMiner dataset, the F1 with 10% labels is 91.2% of the F1 with 50% labels, a significant improvement over alternative methods (+ 10.7%).
 Concept Drift. To further cast insight into the difference between different algorithms, we split the data streams into data chunks and analyze the performance on each data chunk. We also randomly shuffle the data streams and run the same algorithms on the data. The experimental results are plotted in Figure 4, where we set the size of each data chunk as equally 1000. The x-axis is the index of the data chunk and the y-axis represents the F1 score of the pre-diction in the corresponding data chunk. The upper row shows the results in the original order while the lower row illustrates the re-sults on the shuffled data. We clearly find some evidence about the existence of concept drift. The most significant phenomenon comes from the Weibo dataset. With the original data stream, the F1 scores fluctuate drastically over time; in the shuffled data, the F1 scores are much more stable among different data chunks (ex-cept VU). This is because random shuffle eliminates the effect of concept drift in the original data stream. Similar phenomena can be detected in the other datasets, though less significant. For example, in the IMDB dataset, the concepts in posterior data chunks seem much more difficult to learn and all methods suffer slow decrease over time; the situation does not happen in the shuffled data.
Our proposed algorithm is robust in that it not only better adapts to concept drift (as demonstrated in the upper row), but also per-forms well even without concept drift (as demonstrated in the lower row). An outlier here is VU, which obtains good results in prior data chunks but relatively poor prediction accuracy in posterior chunks. This results from the imbalance of the distribution of Figure 7: Speedup performance by network sampling. The x-axis indicates the reservoir size, and the y-axis represents the running time  X  the lower the better. queried instances. VU uses most of its label budget in the prior data chunks because it is insensitive to the concept drift and net-work structure evolution in the data stream. This is consistent with our analysis in  X  4.1 that uncertainty sampling is not suitable for active learning for streaming networked data.
We test the effectiveness of the network sampling algorithm. We run our streaming network sampling algorithm by varying the reser-voir size n and compare with the original method that does not use the sampling method (thus, performance of the method that does not consider sampling can be considered as an upper bound of dif-ferent sampling strategies). We plot the experimental results in Fig-ure 5. The x-axis represents the labeling rate and the y-axis denotes the F1 score with the corresponding reservoir size. Figure 7 shows the speedup performance obtained by streaming network sampling. In most datasets, the decrease of the reservoir size leads to minor decrease in performance but significantly less running time. For ex-ample, in the IMDB dataset, if we set the reservoir size to be 2,000, we can obtain a 6  X  speed up with the decrease of F1 less than 2%. We further demonstrate the effectiveness of our proposed algorithm by comparison. We fix the labeling rate to be 0.1, and compare the performances of different streaming network sampling algorithms with variable reservoir size.
 Comparison Methods. We compare the following sampling methods.
 Minimum Loss (ML): it is our approach proposed in  X  4.2.
Sliding Window (SW): it was first proposed by [28] under the streaming settings. This approach keeps the latest instances in the reservoir.

Partially-Induced Edge Sampling (PIES): it is a two-phase sampling method proposed by [1].

Minimum Degree (MD): it is similar to ML, but each time we discard the instance with minimum degree. The basic idea of this method is that high-degree instances are incorporated in more fac-tor function computation.
 Results. We report the F1 score on each dataset in Figure 6, where the x-axis indicates the reservoir size and the y-axis shows the F1 score. We observe that our proposed algorithm outperforms alternative methods significantly. This further justifies our analy-sis in  X  4.2 that our streaming network sampling algorithm incor-porates both spatial and temporal dimensions, and thus is able to consider the evolving characteristics of the streaming network. SW is competitive in Weibo and Slashdot, and MD is competitive in IMDB and ArnetMiner, while ML performs consistently well on four datasets. The result is expected because MD aims to preserve the network structure with preference to high degree instances; SW reverses the most recent instances to capture the current concept; our method (ML) combines advantages of the two by a unified representation (Cf.  X  4.2) and therefore yields consistently better performance. PIES can be regarded as random sampling; our ex-periment shows that sampling by recency or structural centrality is better than random.
In this section, we fix the reservoir size at 1000, and the label-ing rate at 0.1. We consider all possible combinations of compar-ison methods of streaming network sampling and streaming ac-tive query. The experimental results are shown in Table 2. Our approach outperforms all other combinations over four datasets, which demonstrates the effectiveness of our active learning algo-rithms. We can also demonstrate that both two parts of our ac-tive learning algorithms are important to the classification accu-racy, because replacing any part with another comparison method will lead to a decrease in performance. Also, some combinations other than our approach may achieve relatively good results in spe-cific datasets, such as VU-MD in Weibo and RAN-ML in Slashdot. However, such combinations do not perform consistently well on different datasets. Active Learning in Data Streams Different from pool-based ac-tive learning [23], active learning in data streams needs to make the query decision online. [28] first addressed the problem of active learning from data streams, and proposed a classifier-ensemble-based framework. [6] considered the unbiasedness property in the sampling process, and minimized the variance in the stochastic pro-cess. [5] presented a framework for stream-based multi-class active learning. [29] explicitly handled concept drift in their active learn-ing framework. However, none of them handles networked data, where instances are correlated and dependent.
 Active Learning for Networked Data [3] proposed an active learning algorithm for networked data. [4] studied active learning on trees and graphs. [10] studied active learning on graphs using variance minimization. [27] leveraged Gaussian fields for active learning on graphs. However, they do not consider streaming data. [8] studied online active learning on graphs. [22] proposed a my-opic active learning method for graph search. Again, those methods cannot be directly applied to streaming data.
 Streaming Network Sampling [7] provided a comprehensive tu-torial, covering diverse methods and applications of network sam-pling. [15] compared and evaluated several sampling methods with novel measures. [1] designed a family of sampling methods for streaming graphs. Their works are different from ours, int that they focused on persistent graph structure rather than instance correla-tion.
In this paper, we study a novel problem of active learning for streaming networked data . We first frame the classification prob-lem for the streaming networked data using a Markov random field. We define a novel query criterion for active query with theoretical justification and provide novel techniques for computation. Then we propose a streaming network sampling algorithm to handle large volume of streaming data by considering the loss of instance removal in both spatial and temporal dimensions. Our methods sig-nificantly outperform alternative methods on four different genres of datasets.
Building an effective learning model for streaming data  X  in par-ticular, streaming networked data  X  is very important for mining big data, and represents a new and interesting research direction. As for future work, it would be interesting to further improve the efficiency of the proposed algorithms. It is also interesting to ex-tend this work to the social network and incorporate social factors such as social influence [18] into the proposed model.
 Acknowledgements. The work is supported by the National High-tech R&amp;D Program (No. 2014AA015103), National Basic Research Program of China (No. 2014CB340500), Natural Sci-ence Foundation of China (No. 61222212), and Beijing key lab of networked multimedia. which concludes the proof.

