 Blog feed search aims to identify a blog feed with a recur-ring interest in a given topic. In this paper, we investigate the  X  X seudo-relevance feedback X  for blog feed search task, where its unit of relevance judgment is not based on a blog post but a blog feed (the collection of all its constituent posts). This paper focuses on two characteristics of feed search task, blog feed X  X  topical diversity and multifaceted property of query. We propose a novel feed-level selection of local posts which uses only highly relevant local posts in each top-ranked feed, in order to capture the correct and diverse relevant information to a given topic. Experimen-tal results show that the proposed approach outperforms traditional feedback approaches. Especially, the proposed approach gives 2% further increase of nDCG over the best performing result of TREC  X 08 Blog Distillation Task. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval  X  Retrieval models, Relevance feedback General Terms: Algorithms, Experimentation, Performance Keywords: Blog distillation, Feed search, Pseudo-relevance feedback
With the number of blog users increasing, weblogs or blogs are gaining popularity as a medium to vocalize their opin-ions and thoughts. As a result, the need for a customized elaborate search system for these weblogs, such as blog post search or blog feed search, is growing. The Blog Distillation task of TREC 2007 and 2008 Blog track [ ? , ? ] reflects in-creasing interest in feed search service. There have been several research works on blog feed search, however, the pseudo-relevance feedback model has not been discovered well, despite of its importance.
 The relevance judgment made in the feed search is  X  X eed-Level X (the collection of all its constituent posts), not document-level. Apparently, humans make use of feed information rather than individual documents to subscribe the feed. How-ever, traditional feedback approaches are based on the document-level judgment. Thus, a remaining and open research issue is to find an effective method for the pseudo-relevance feed-back on blog feed search.

One approach is an X  X ll-Posts X  X pproach which chooses all posts in top ranked feeds as feedback documents. However, All-Posts has a high risk of including many irrelevant terms in a resulting expanded query, because it does not concern a blog feed X  X  topical diversity  X  most feeds consist of many different topics in their posts. Even if a feed is relevant, it does not always mean that all of its posts are relevant to a query but generally mean that subset of its posts is relevant. These non-relevant posts may decrease the precision of the feedback information.

Another approach is a  X  X ost-Level X  approach that uses document-level selection like traditional feedback approaches. The Post-Level first performs a post-level retrieval and uses the resulting top-ranked posts as feedback documents. Un-like the All-Posts, the Post-Level does not have trouble with the low precision of expansion terms. However, feedback in-formation can be under a bias toward a dominant aspect within top-ranked posts. In other words, the Post-Level suf-fers from the  X  X spect recall X  [ ? ], one of important properties which determines feedback quality.

To mitigate above problems, we propose a novel feed-level selection of local-posts , having two important characteristics capable of handling problems of two naive approaches; 1) Lo-cal selection : It uses only highly relevant local set of posts for each top-ranked feed, not using entire posts, which can alleviate the problem of topical diversity of a blog feed. 2) Feed-level selection : It collects more diverse relevant infor-mation from as many feeds as possible, and thus enables to learn much more relevant facets than Post-Level selection.
The proposed approach, selectively choosing highly rele-vant local posts from various feed sources, can improve the precision and aspect recall of feedback information. Our method corresponds to the passage-based feedback [ ? ] in the ad-hoc retrieval. Considering the high effectiveness of passage-based feedback on ad-hoc retrieval, it is expected that our approach provides performances improvement.
Experimental results show that the proposed method sig-nificantly outperforms the state-of-the-art methods. To our best of knowledge, our work is the first successful feedback approach for the feed search in the  X  X losed setting X  using only test collection.
The topical diversity is a problem not only of the feed re-trieval task, but also of the ad-hoc retrieval task at the level of document. One of the effective approaches for overcom-ing this problem is to use a passage-level evidence, in which the relevance score of a document is complemented by an additional score estimated using the passage-level evidence.
The passage-level evidence has turned out to significantly improve the baseline method which uses only traditional document-level evidence [ ? , ? , ? , ? , ? ]. In addition, it has also been successfully investigated in the pseudo-relevance feedback staring from the Allan X  X  work [ ? ]. He proposed the passage-based feedback which uses passages as context to select expansion terms instead of using entire document context. The passage-based feedback resulted in significant improvements over the document-level feedback based on an entire context of document [ ? , ? ].

Inspired from the passage-based feedback, we propose a similar method for the feed retrieval by conceptually mak-ing correspondences between a document and a feed, and a passage and a subset of posts within the feed. We regard the subset (local set) of posts as a  X  X ocal evidence X  for blog feed search, corresponding to the  X  X assage-level evidence X  for the ad-hoc retrieval. Similar to the success of the passage-level evidence for ad-hoc retrieval, we believe that using the local evidence of a blog feed improve the performance of the blog feed search. Regarding the characteristics of queries of blog feed search, Elsas et al. [ ? ] addressed as follows:  X . . . Given the nature of feed search, queries may describe more general and mul-tifaceted topics, likely to stimulate discussion over time .  X 
Due to this multifaceted property of queries, X  X spect-recall X  problem of blog feed search can be more severe than that of the ad-hoc retrieval task. Therefore, Post-Level approach cannot be a desirable solution, as discussed in Section 1, since top N ranked posts selected from Post-Level are easily biased to a dominant aspect within them.

Note that all (unknown) facets of a query are scattered over all relevant feeds, and their relevant posts. Blog posts from different blog feeds may present different perspectives or facets to a topic, given a query, according to blogger X  X  interest or inclination, although they address the informa-tion about the same topic. Therefore, we construct feed-back information from top K ranked blog feeds to learn more diverse information for the pseudo-relevance feedback. Contrast with Post-Level approach, we call these approach  X  X eed-Level X  approach.

Based on the passage-based feedback, we propose the feed-level selection of local-posts which first selects as many feeds as possible for feedback, and gathers the most highly-relevant local posts within each of them. It is designed to use more accurate relevant content from its local evidence for increas-ing the precision of feedback information, and to use more diverse relevant contents from its feed-level approach for im-proving the aspect recall.
Motivated from Section 2, we now describe our approaches for the pseudo-relevance feedback: Fixed Feed Based Selec-tion and Weighted Feed Based Selection.
Fixed Feed Based Selection uses top K ranked feeds to construct feedback documents. FFBS considers top K ranked feeds as equally relevant to a given query regardless of their relevancy to the query indicated by the relevant score. Let F B F be the collections of documents chosen by using FFBS. We can define F B F as follows: where D m,k indicates m th relevant blog post within the k ranked feed. In this paper, FFBS-K -M indicates a F B F with K and M .
Similar to FFBS, Weighted Feed Based Selection also uses top K ranked feeds to construct feedback documents. How-ever, WFBS chooses a different number of blog posts from each blog feed according to its relevance score. To achieve this, we assign scores to top K feeds in the order of their relevancy as follows: where W F i indicates the weight score of i th ranked blog feed. W F i is inverted measure respect to i , that is a blog feed with the highest score has weight of K and K th feed has weight of 1.

Let N be the total number of feedback documents, and let F B W be the collections of documents chosen by using WFBS. We can define F B W as follows: where M k indicates the number of documents selected from each feed, and we define M k as follows: In practice, M k should be an integer number. We round it off to make it an integer. WFBS-K -N denotes a F B W with K and N . TREC Blogs06 Collection [ ? ] was used for experiments. For the evaluation, we used the 45 topics and relevance judg-ments from the TREC 2007 Feed Distillation task, and 50 topics and relevance judgments from the TREC 2008 Feed Distillation task.

We only used the permalink documents (blog posts) for the experiments. All blog posts were parsed to discard the HTML tags, and stemmed by the Porter stemmer. We did not apply any spam filtering techniques.
We use two baseline models to experiment our feedback approaches, GEM+LEM and LD (Large Documnet Model (LD). GEM+LEM is a combined model of Global Evidence Model and Local Evidence Model, which showed the best performing result at TREC X 08 Feed Distillation task [ ? ]. Let R ( Q, F ) be the relevance score between a given query Q and a feed F . The score function of GEM+LEM is as follows: where R G and R L are the relevance score of global-evidence and local-evidence for feed F , respectively. We use the top 2 highest relevant posts from each feed as local-evidence.
LD views a blog feed as a single and large document rep-resented by a concatenation of all posts within it. LD was used as the baseline of many systems at the TREC 2007 and 2008 Feed Distillation task [ ? , ? ]. We use the KL-divergence language model [ ? ] as relevance score function between large document for a feed and a given query.
Each baseline model (GEM+LEM or LD) is used to gen-erate an initial top ranked list of feeds, and to perform a subsequent retrieval based on the expanded query model.
Let  X  Q and  X  Q  X  be a original query language model and a new query language model obtained from feedback, respec-tively. To update the query language model, we used the model based feedback [ ? ]. where  X  F controls the influence of the feedback model, and the feedback model  X  F is estimated by using a generative model of feedback documents.

We used the mean average precision (MAP), the precision at rank 10 (Pr@10) and the normalized discounted cumula-tive gain (nDCG) as the evaluation measures. The nDCG measure was evaluated for only 08 topics.
We made several feedback document sets to evaluate per-formance according to respective approaches to choose feed-back documents. For all document selection approaches, we selected 10 documents as feedback documents. The docu-ment sets used for feedback are as follows:
Table ?? shows the performances of each selection meth-ods, in which the left-part (a) and the right-part (b) indi-cate the results using GEM+LEM and LD as the baseline, respectively. As shown in Table ?? , our feed-based selec-tion approaches (FFBS and WFBS) significantly and consis-tently improve baselines, for both of GEM+LEM and LD. In GEM+LEM baseline setting (the left-part), FFBS and WFBS increase about 2%  X  3% of MAP over the baseline on both of 07 and 08 topics. Similarly, in the LD baseline setting (the right-part), FFBS and WFBS archive improve-ments with large margins over LD, showing maximally more than 5% increase of MAP on both of 07 and 08 topics. To check whether our methods show statistically significant im-provements over the baseline, we performed the Wilcoxon signed rank test at 0.05 significance level for each metric, and attached symbol  X  to the performance number of FFBS and WFBS, only when they show significant results over the baseline. As shown in Table ?? , almost all runs of FFBS and WFBS show statistically significant improvements over the baseline on MAP. It means that the feed-level approaches (FFBS and WFBS) are clearly improved feedback methods.
Also, FFBS and WFBS yield better performances than two naive approaches  X  All-Posts (Feed3All-Posts and Feed5All-Posts) and Post-Level (TOP-10)  X  on both of topics and both of baselines. To see whether the improvement is statis-tically significant, we again performed the Wilcoxon signed rank test, and attached  X  and  X  only when they show signif-We found that majority of runs of FFBS and WFBS show statistically significant improvements over both of two naive approaches.

The results of All-Posts and Post-Level are different ac-cording to each baseline. In the setting of GEM+LEM base-line, All-Posts and Post-Level methods do not show reliable performances. Only Feed3All-Posts and Feed5All-Posts out-perform the baseline for 07 topics, but they do not make any improvements for 08 topics. TOP-10 does not show any im-provement over the baseline. From these results, we can verify our motivations mentioned in Section 2. First, the failure of All-Posts for 08 topics is a good evidence to sup-port our previous discussion about the topical diversity of a blog feed. The initial performances for 08 topics are rel-atively low. It means that the top K feeds are likely to contain many non-relevant feeds. Thus, as K is increasing for 08 topics, the feedback documents constructed using the All-Posts include too more non-relevant documents to im-prove the performance from feedback. Actually, when using K = 5, the performance deteriorated more seriously than when using K = 3. This result explains why we need to use the local evidence for the pseudo-relevance feedback. Sec-ond, the failure of Post-Level method supports our motiva-tion towards the feed-level selection. To our view, Post-Level suffers from its low aspect recall so that it covers only few relevant aspects of a query. In contrast, our feed-level ap-proaches enable the system to increase aspect recall, since feedback documents are chosen from various feeds so that they cover diverse aspects of a query. Finally, this leads to the improved performance of the feedback model.
 Different from the results of GEM+LEM, All-Posts and Post-Level methods showed some improvements in the set-ting of LD baseline. Nonetheless, All-Posts and Post-Level are limited, not reaching to the performances of FFBS and WFBS. These results show that the two issues motivating FFBS and WFBS, the topical diversity of feed and the mul-tifaceted query topic, should be importantly considered, in order to achieve better performance.

Finally, comparing with the best performing run of TREC same K . That is, FFBS-5-2 and WFBS-5-10 were compared with Feed5All-Posts  X 08 Distillation Task at the row titled with  X  X REC  X 08 X , our feedback methods such as FFBS-3-3 provide about 2% increase over the TREC  X 08 best run, at all measure (MAP, Pr@10, and nDCG).
In this paper, we investigated on the pseudo-relevance feedback method for blog feed search. Our key concerns are topical-diversity of a feed and multifaceted query topic. Motivated from the passage-based feedback which addresses similar issues to ours, we proposed a novel feed-based selec-tion of local posts, which constructs feedback documents by gathering the most-relevant top M local posts from each of top K ranked feeds. Despite of its simplicity, the current re-sult is notable, because it is the first successful work without any external knowledge on the pseudo-relevance feedback for blog feed search. This work was supported in part by MKE &amp; IITA through IT Leading R&amp;D Support Project and also in part by the BK 21 Project in 2008. [1] J. Allan. Relevance feedback with too much data. In [2] J. P. Callan. Passage-level evidence in document [3] J. L. Elsas, J. Arguello, J. Callan, and J. G. Carbonell. [4] M. Kaszkiel and J. Zobel. Passage retrieval revisited. [5] M. Kaszkiel and J. Zobel. Effective ranking with [6] O. Kurland, L. Lee, and C. Domshlak. Better than the [7] J. Lafferty and C. Zhai. Document language models, [8] Y. Lee, S.-H. Na, J. Kim, S.-H. Nam, H.-Y. Jung, and [9] C. Macdonald, I. Ounis, and I. Soboroff. Overview of [10] C. Macdonald, I. Ounis. The trec blogs06 collection : [11] S.-H. Na, I.-S. Kang, Y.-H. Lee, and J.-H. Lee. [12] S.-H. Na, I.-S. Kang, Y.-H. Lee, and J.-H. Lee. [13] I. Ounis, C. Macdonald, and I. Soboroff. Overview of [14] G. Salton, J. Allan, and C. Buckley. Approaches to [15] C. Zhai and J. Lafferty. Model-based feedback in the
