 User satisfaction is often dependent on providing accurate and diverse recommendations. In this paper, we explore scalable algorithms that exploit random walks as a sam-pling technique to obtain diverse recommendations without compromising on accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP 3 that re-ranks items based on 3-hop random walk transition probabilities. We show empirically, that RP 3 provides ac-curate recommendations with high long-tail item frequency at the top of the recommendation list. We also present scal-able approximate versions of RP 3 and the two most accu-rate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with increasing number of samples. Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Information Filtering Keywords: top-N recommendation; item ranking; diver-sity; long-tail; bipartite graph; random walks; sampling
Users increasingly rely on recommender systems to choose movies, books, restaurants and other items. These systems are usually based on the assumption that users prefer items similar to those they previously liked or those liked by other users with similar preferences. However, this approach has some deficiences. Pariser [18] introduced the term  X  X ilter bubble X  to describe how personalized recommendations can isolate people from diverse viewpoints or products. This has also led to the concern that recommender systems may reinforce the blockbuster nature of media [8] due to their promotion of already popular products. Also, the focus on the predictive accuracy of recommender systems can lead to a bias towards popular items over more specialized items. In other words, systems that are optimized for accuracy tend to produce unsurprising and boring recommendations.
User satisfaction depends on many factors such as vari-ety, new experiences and serendipitous discovery which are not captured by accuracy metrics. These factors depend on finding suitable long tail items, which raise user satisfac-tion and, in turn, profitability [11]. Hence, a recent trend is to build recommender systems that do not only focus on optimizing the accuracy but also consider the diversity of recommendations [1, 2, 23, 24]. However, these can be con-flicting goals as increasing diversity may produce irrelevant recommendations.

Recently, it was shown that approximations based on ran-dom graph walks can be used for accurate recommenda-tions [6]. These algorithms are more accurate than pre-viously presented vertex ranking methods (e.g., [9]) with the additional benefit of being computationally e cient and scalable. In this paper, we explore scalable algorithms that exploit random walks as a sampling technique to obtain di-verse recommendations without compromising on accuracy . Specifically, our contributions are: First, we introduce RP 3 , a simple item popularity dependent re-ranking pro-cedure of P 3 [6]. We show using three implicit feedback datasets (two public, one enterprise) that RP 3 augments long-tail item recommendations while keeping accuracy high. Second, we empirically compare the performance of vertex ranking algorithms [9, 6, 23] including our own RP 3 with traditional state-of-the-art methods. We find that some ver-tex ranking algorithms achieve comparable or better perfor-mance than the traditional ones. Third, we present scalable approximation algorithms for RP 3 ,P 3  X  [6], as well as H [23] based on random walk sampling. In a detailed evaluation we show that these methods converge to the performance scores of exact calculations. Last, we analyze the trade-o  X  between sampling size (i.e., number of performed random walks) ver-sus accuracy and diversity performance and find that RP 3 provides a useful trade-o  X  between accuracy, diversity, and sample size.

The remainder of this paper begins with a description of our data model and notations. We present a literature re-view in Section 3. We then describe our method RP 3 and our approximations for P 3  X  ,RP 3 , and H . The experimental results are presented in Section 6 followed by conclusions.
The recommendation algorithms studied in this paper try to rank the items in the training set for each user in the test set by decreasing appreciation. The algorithms are based on walks over the graph G =( V, E ) constructed from the users X  feedback on items ( user-item-feedback graph ). The vertices V of G represent the union of the two entity sets users U and items I (i.e., V = U [ I ) in the training data. If user u 2 U implicitly rated item i 2 I in the training phase (e.g., by accessing the item) then the graph X  X  edge set E  X  U  X  I contains the edge e = { u, i } .As E contains no other edges, G is bipartite. All edges in the graph are unweighted/undirected and no parallel edges exist. Edge weights or parallel edges (e.g., based on rating values or the number of interactions) could be used for a more accurate representation of the users preference profile, but we do not consider this extension in the presented work.

The square matrix A 2 { 0 , 1 } | V |  X  | V | is the adjacency ma-trix of G . Since edges of G are undirected, A is symmetric. The entry a ij of A is 1 for two connected vertices i and j , and 0 otherwise. D | V |  X  | V | is the diagonal degree matrix of G with d ii = are non-zero (i.e., no unconnected vertices), its inverse D is given by ( d 1 ii ), and hence cheap to compute. A random walk process on G can be seen as a discrete Markov chain, where a walker starts on a vertex v (0) and at each time step moves to one of its neighbors chosen ran-domly. After s steps, the sequence of vertices visited by the walker h v (0) ,v (1) ,...v ( s ) i forms a Markov chain. The prob-ability of transitioning from a vertex i to j is p ij = a Hence, the corresponding transition matrix P | V |  X  | V | step ( s = 1) random walks is given by P = D 1 A . Further-more, we obtain the s -step random walk transition proba-bility matrix (we refer to its elements with p s ij )with
Since we want to rank items i for users u , this paper con-siders random walks starting at user vertices and ending at item vertices (i.e., having an odd number of steps). To de-note transition probabilities estimated using random walk samples (see Section 5), we write  X  p s ij . In general, an esti-mate of a random variable X is represented as  X  X .
In this section we discuss previous work on vertex ranking algorithms, sampling techniques, and diversity.

Graph based algorithms: The use of a graph-based model for recommendations was first introduced in [3]. To apply a bipartite user-item-feedback graph G was proposed in [14] and several projects [4, 5, 6, 9, 12, 15, 16, 22] ex-tended this approach. We classify them as vertex ranking algorithms because their main idea is to rank the vertices in the graph based on their similarities with the target user and use the ranking to generate recommendations. Fouss et al. [9] introduced the idea of using random walks on G to rank the vertices. Vertices are ranked or scored based on quantities like hitting time, average commute time or the entries in the Moore-Penrose pseudo inverse of the Lapla-cian matrix of the graph (L + ). ItemRank [12] also scores vertices based on random walks on the graph, but uses a graph representing item correlations.

Random walk approximations: Cooper et al. [6] pro-posed three new methods called P 3 ,P 5 , and P 3  X  based on random walks on G . They rank vertices based on transition probabilities after short random walks between users and items. P 3 and P 5 perform random walks of fixed length 3 and 5, respectively, starting from a target user vertex. P which raises the transition probabilities to the power of  X  , is more accurate than the methods proposed in [9] and [12]. They also show that approximating the P 3 and P 5 rankings with time-and memory-e cient random walk sampling is more scalable compared to methods based on matrix calcu-lations, i.e., the methods can be applied to larger datasets.
Diversity in recommendations: The erstwhile focus of recommender systems research on improving accuracy (how well the system can predict future user behavior) was criti-cized as being detrimental to the goals of improving user ex-perience and sales diversity [7, 17]. A recent trend, therefore, is to focus on the diversity of recommendations along with accuracy. Notions of novelty and diversity in recommender systems, as well as measures to quantify, and methods to im-prove them have been described by various authors [1, 2, 13, 21, 24]. Optimizing only for diversity will cause highly varied but irrelevant recommendations. Therefore it is necessary to find diverse recommendations that are also accurate. Zhou et. al [23] use vertex ranking algorithms to improve diversity and accuracy. Specifically, they describe a hybrid method (Hybrid or H ) that combines the ranking of an accurate with the ranking of a diverse algorithm.

In this work , we focus on the task of generating di-verse and accurate recommendations with vertex ranking algorithms using scalable random walk sampling. To the best of our knowledge, this is the first work to bring to-gether the three streams reviewed above: graph-based ap-proaches, random walk approximation, and diversity. There are di  X  erent notions of diversity in recommendation lists. Following [2, 23], we use three top-k measures to evaluate recommendation quality in terms of diversity: personaliza-tion, item-space coverage, and surprisal. Surprisal assures inclusion of long-tail items at the top of recommendation list, item-space coverage assures that varying long-tail items are considered, and personalization measures how much the recommendation list di  X  ers between users. We introduce RP 3 , a novel algorithm to optimize the accuracy and di-versity trade-o  X  by re-ranking the P 3 item ranking. RP benefits from the good scalability of approximating P 3 with random walk sampling. Also, we present approximations for H and P 3  X  with the same sampling approach.
In our experiments, we observed (see Section 6.3) that the ranking of items according to the transition probability matrix P 3 is strongly influenced by the popularity (i.e., ver-tex degree) of items. Hence, for most users the well known blockbuster (or high-degree) items dominate the recommen-dation lists. To compensate for the influence of popularity and to leverage recommendation of items from the long-tail, we introduce a simple re-ranking procedure dependent on item-popularity. The original score of item i for user u given by p 3 ui (the transition probability after a random walk of length three from u to i ). We re-weight the score with For two items i , j ( i 6 = j ), a user u with p 3 ui = p probability of reaching the items from the user in a three-step random walk), and d ii &lt;d jj ( i has a lower degree), the e  X  ect of our re-weighting is that i is ranked higher than j (  X  p uj &lt;  X  p 3 ui ). These items would have received equal scores without the re-weighting. We refer to this recommendation algorithm as RP 3 . When we set the parameter =0 . 0, then RP 3 produces the same score as P 3 as d =0 ii =1.
In a recent paper, Cooper et al. [6] compare two ap-proaches to calculate vertex transition probabilities: by ex-act calculations using matrix algebra and by approximation via random walk sampling. It is shown that the latter ap-proach is time-and memory-e cient, allowing the applica-tion on larger datasets with only limited impact on accu-racy. However, they do not describe a sampling procedure for their algorithm P 3  X  . Similarly, H , a vertex-ranking al-gorithm that increases both recommendation accuracy and diversity [23], could also be made more scalable with a sam-pling procedure instead of exact calculations with matrix algebra.

This section introduces a novel random walk sampling procedure for both of these two algorithms as well as our reranking algorithm RP 3 .
In order to estimate transition probabilities for user u us-ing samples, we start multiple s -step random walks from u . We store the number of times each item i is visited by walks at the s th step. For reasons of e ciency, we would like to estimate the probabilities only based on these counts and the degrees of vertices traversed by the path. This sampling procedure can be modeled as a Bernoulli process as follows:
Denote the path traversed by the r th random walk of length s starting at u as  X  r,s u . Then define I s r ( u, i )= c if i is the s th vertex in path  X  r,s u ,i.e.,if  X  r,s u [ s ]= i , and I ( u, i ) = 0 otherwise. The quantity c rw (  X  r,s u ) is a function of the vertices X  degrees in the path (and varies for di  X  er-ent algorithms). For simplicity, we use I r ( u, i ) for random walks of a fixed given length (e.g., s 2 { 3 , 5 } ). Next, define  X  ( u, i ) as the score of item i for user u and  X   X  ( u, i )asits estimator. When sampling N random walks starting from u , the estimator can be defined as  X   X  ( u, i )= 1 N Given the law of large numbers, the expected value for  X   X  ( u, i ) is E [ X   X  ( u, i )] =  X  ( u, i ). Also, walks are independent and I 2 [0 , ] is i.i.d, where is the maximum possible value for c rw .

Similar to [20], we can use Hoe  X  ding X  X  inequality to show that the rate of convergence is exponential. Furthermore, using Union bound, the probability of the  X  -approximate estimate for any user being less than is given as: P ( 9 u 2 U, |  X   X  ( u, i )  X  ( u, i ) |  X  )  X  2 | U | exp ( This provides a lower bound for N as 2 2  X  2 log 2 | U | .Fora fixed  X  and , the number of walks required increases with , which depends on the algorithm in use and degree distri-bution of the graph (due to di  X  erent forms of c rw ).
For our method RP 3 (Section 4), c rw (  X  r,s u ) is simply 1 /d hence, =1 / argmin as described above. For P 3  X  and H , c rw (  X  r,s u ) takes more complicated forms, which we discuss below. Hereafter, we denote a path simply as  X  .
Ordering items in descending order according to the tran-sition probabilities of random walks of length three ( P 3 3) is an accurate recommendation strategy, named P 3 in [6] and ProbS in [23]. The accuracy of this algorithm can be further improved by raising each entry of the transition prob-ability matrix P 1 ( s = 1) to the power of a parameter  X  2 resulting in an algorithm called P 3  X  by [6]. It follows from (1) that entries of the matrix P 1 raised to the power of  X  are calculated as p 1 ui  X  =( p 1 ui )  X  =( a ui /d uu )  X  , where a (entry in adjacency matrix) and d uu 2 D (entry in degree matrix). The transition probability p 3 ui  X  2 P 3  X  from user u to item i after a random walk of length three is obtained by: p Since the graph G defined in Section 2 is both bipartite (there are no edges from users to users or from items to items) and all entries in the adjacency matrix A are either 0 or 1, we can simplify (3) as: The term a uj a jv a vi in (4) is 1 if a path of length three starting from user u , through item j and user v ,toitem i exists in the graph G and is 0 otherwise. Hence, p 3 ui the aggregate of all paths of length three between user u and item i , where each path  X  = h U u ,I j ,U v ,I i i contributes c user u to item i .

When approximating (4) with random walk sampling, one needs to take into account that some walks are more likely to be followed randomly than others. The probability of following the path from u via the item j and user v to item i in a random walk is dependent on three decisions. First, at user u , one needs to follow the edge that connects u to item j . The probability of randomly picking this edge is equal to the inverse of the degree of u : Pr( u ! j )= 1 d same procedure needs to be repeated at j and v , resulting in Pr( j ! v )= 1 d three  X  X hoices X  are independent, the probability Pr (  X  ) that one follows the path  X  is equal to
Pr(  X  ) = Pr( u ! j ) Pr( j ! v ) Pr( v ! i )= 1 Hence, when approximating with random walks, we are more likely to follow paths traversing vertices of low degrees than to follow paths traversing vertices of high degrees. Since an exact calculation of (4) requires following each path ex-actly once, random walk sampling needs to discount the contribution of paths with high probabilities (as we may by chance follow them many times), and boost the contri-bution of paths with low probabilities (as we may by chance follow them only few times). Consequently, to approximate the transition probability  X  p 3 ui  X  , we weigh a path contribution c  X  with the inverse of its occurrence probability (Pr(  X  ) resulting in an overall weight c  X  P 3  X  rw for a random walk: We can simplify c  X  P 3  X  rw to ( d jj d vv ) 1  X  since d value for all random walks of the target user u and, hence, does not influence the item ranking order. Algorithm 1 Estimating item scores of  X  P 3  X  ,R  X  P 3 ,or with random walk sampling.
 Require: v u is the vertex representing user u 1: function EstimateItemScores ( v u ) 2: m an associative array with default value 0 3: while !Converged ( m ) do 4: v c GetRandomNeighbor ( v u ) 5: d jj GetDegree ( v c ) 6: v c GetRandomNeighbor ( v c ) 7: d vv GetDegree ( v c ) 8: v c GetRandomNeighbor ( v c ) 9: d ii GetDegree ( v c ) 10: m [ v c ] m [ v c ]+ c rw 11: end while 12: return m 13: end function
Algorithm 1 shows the general principle of how to im-plement a random walk sampling approximation procedure. With this algorithm we obtain  X  P 3  X  item scores by assigning c rw to the random walk contribution c rw in line 10. Note that for  X  = 1, the random walk contribution is ( d jj and degenerates to 1. Hence, the sampling procedure  X  P 3 (same as  X  P 3  X  =1 ) is computationally less demanding, since updating the score of the destination item i of a random walk consists only of incrementing the count of i by one.
To estimate the item ranking of RP 3 with random walk sampling, we can either first obtain  X  P 3 item scores and apply the re-ranking described in Section 4, or replace the random walk contribution c  X  P 3 rw =1by c R  X  P 3 rw =1 /d ii and omit the re-ranking. Hence, Algorithm 1 also fully describes R  X  P
Zhou et al. [23] define H as a scoring procedure of items using a weighted linear aggregation of scores from two algo-rithms: HeatS, which is analogous to heat di  X  usion across the user-item graph and ProbS, which is the same as P 3 . W H + P with dimension | I |  X  | I | is the transition matrix for H and f u 2 { 0 , 1 } | I | is the preference profile of target user u , where f u i , the i th entry of f u , is equal to the correspond-ing entry a iu in the adjacency matrix A . Then, the item scores for user u are calculated as e f u = W H + P f u . A single entry of W H + P is calculated according to where 2 [0 , 1] is the hybridization parameter for the two basic methods. If we set =0or = 1, the ranking of H is equal to the ranking of HeatS or ProbS, respectively. Furthermore, d ii denotes the degree of item i and d vv the degree of user v . The score of item i for the target user u can also be determined according to: e f
We can apply the same rationale for the deduction of a random walk simulation algorithm of H as used for P 3  X  : the term a ju a jv a iv in (8) is 1 if a path of length three from user u to item i exists in the graph G and 0 otherwise. Hence, is the aggregate of all paths of length three between user u and item i , where a single path contributes c H  X  = 1 to the score of item i for user u . Because (8) (similar to (4) for P 3  X  ) requires that each path contribution c H  X  is counted once, we need to weight c H  X  by the inverted path probabil-ity Pr(  X  ) 1 . The random walk path contribution c  X  H rw the random walk sampling approximation algorithm (  X  H )is calculated according to: Again, we can further simplify c  X  H rw to d the same value for all random walks for the target user u , and hence does not influence the item ranking order. With Algorithm 1 we obtain  X  H item scores by assigning c  X  H rw c
This section provides a succinct introduction to the exper-imental methodology and then turns to the main questions of the paper: First, it explores if RP 3 improves accuracy and diversity. Then it explores a general comparison be-tween vertex ranking and traditional algorithms. It closes with a thorough comparison between P 3  X  ,RP 3 , and H and our approximate versions  X  P 3  X  ,R  X  P 3 , and  X  H . Datasets: We used the MovieLens-M 1 , iPlayer, and Book-Crossing [24] datasets (see Table 1 for properties). Whilst Movie-Lens-M and BookCrossing are public, the iPlayer train-ing dataset consists of the viewing logs of the BBC VoD system from the week of February 15-21, 2014, and the test data of the following week X  X  logs, where only interactions with a single show longer than 5 minutes were considered. From the log data of the test week, we randomly selected 5 X 000 users that were also active during the training week. Since this work addresses recommendation generation based on implicit user feedback, we neglected the rating values available in MovieLens-M and BookCrossing for training and testing of the evaluated recommenders.

Set-Up: We extended the Java port of the MyMediaLite [10] recommender system framework 2 with (i) a set of met-rics (see the following paragraphs) to measure recommen-dation performance according to the diversity dimensions
MovieLens-M: grouplens.org/datasets/movielens
Java port: github.com/jcnewell/MyMediaLiteJava Table 2: Accuracy and diversity of all algorithms (ordered by decreasing AUC). Parameterized algo-rithms are represented by parameter values result-ing in maximal AUC and Prec@20 performance.
 Top 3 numbers per metric highlighted (results from Perfect and Random recommender not considered). introduced in Section 3 and (ii) a component implementing graph vertex ranking algorithms. Given our focus on im-plicit feedback we only employed the framework X  X  positive-only feedback components. All computations where exe-cuted on a cluster of 16 machines running LINUX with 128 GB RAM and two Intel  X  Xeon  X  E5-2680V2 processors (25 MB Cache, 2.80 GHz base frequency, 10 cores, 20 threads). Accuracy Metrics: We used both the Area Under the ROC curve (AUC) and precision at k (Prec@k). Referring to relevant items (in the test set) as hits , AUC is equal to the probability that randomly chosen items are ranked higher than non-hits. Prec@k counts the number of hits among the top-k items of the recommendation list divided by the cut-o  X  level k. Given that users typically only see few rec-ommendations, we chose k = 20. Higher values of AUC and Prec@k indicate better accuracy.
 Diversity Metrics: We used coverage (Gini-Diversity, GiniD@k), personalization (Pers@k), and surprisal (Surp@k) as diversity metrics and extended the MyMediaLite frame-work accordingly. Given the already explained rationale, we used k = 20. Again, greater values indicate better diversity.
We measure coverage by calculating GiniD@k for the top-k recommendations of all test users [2]. In contrast to the original Gini coe cient, where greater values indicate a more dispersed distribution, GiniD@k increases for a more uni-form distribution. GiniD@k is equal to 1 if the frequency in the aggregated recommendation lists is the same for each item, indicating a good coverage.

Pers@k [23] measures the distinctness of the top-k recom-mendations based on the number of common items averaged over all pairs of generated recommendation sets. A value of Pers@k=1 indicates that none of the items appear more than once among the top-k items of any two recommenda-tion lists, meaning greater personalization.

Surp@k [23] is calculated separately for each recommen-dation list and averaged over all users. This metric follows the rationale that recommendations of items of low popu-larity are perceived by the users as unexpected or surprising (unexpectedness given by the self-information of items).
Evaluated Recommendation Algorithms: We com-pared the performance of our methods with various algo-rithms proposed in the literature (and listed in Table 2, ex-cept for (iii)). These can be divided into the following cate-gories: (i) Parameter-free vertex ranking algorithms: #3-Paths (ranks items by the number of paths of length 3 starting at the target user) [6, 14], L + (ranks items by the entries in the Moore-Penrose pseudoinverse of the Laplacian matrix) [9], P 3 [6, 23], and P 5 [6]. Due to computational limitations we could not obtain results for P 5 and L + for the iPlayer dataset. (ii) Parameterized vertex rank-ing algorithms :P 3  X  [6], H [23], and our RP 3 . (iii) Ap-proximated/Sampled vertex ranking algorithms  X  P 3  X  , R  X 
P 3 , and  X  H . (iv) Other algorithms: MostPop (global item popularity), Random (random item ranking), weighted (WI-kNN) and unweighted (I-kNN) k-nearest neighbor item-based collaborative filtering using cosine distance as item similarity measure, and BPRMF [19] (a recommender based on a latent factor model obtained with matrix factorization)  X  all available in MyMediaLite. To facilitate performance comparison, we also calculated the performance of the per-fect recommender (Perfect) that places all test items of a user in random order at the top of the recommendation list.
Parameter Tuning: We empirically tune the parame-ters for parameterized algorithms to maximize the two ac-curacy metrics. For I-kNN and WI-kNN with MovieLens-M and iPlayer we tested neighborhood sizes k 2 { 10 , 50 , 100 , 150 , 200 } . For the BookCrossing I-kNN was tested for k 2 { 10 , 50 , 100 , 150 , 200 , 400 , 800 , 1600 } and for WI-kNN we additionally tested k = 3200. Similarly, BPRMF was tested with the latent factors d 2 { 10 , 50 , 100 , 150 , 200 } for Movie-Lens-M and BookCrossing. Due to computational limita-tions, BPRMF could only be tested with d 2 { 10 , 50 } for of 0.1. For RP 3 , we tested values of 2 [ 0 . 2 , 1 . 2] in steps of 0.1. H was tested with values of 2 [0 , 1] in steps of 0.1. The best performing parameters with respect to accuracy can be found in parentheses in the results Table 2.
The goal of the first set of experiments is to evaluate our re-ranking procedure RP 3 . To that end we compare it with
Other parameters for BPRMF: 30 stochastic gradient as-cent iterations for training, no item bias, iteration length of 5, learning rate  X  of 0.05, regularization parameter for positive item factors of 0.0025, regularization parameter for negative item factors of 0.00025, and regularization param-eter for user factors of 0.0025. the parameter value where P 3  X  gives the same item ranking as P the other algorithms evaluated and especially explore its per-formance compared to P 3  X  and H .

As Table 2 shows, the RP 3 re-ranking increases both ac-curacy and diversity for all datasets compared to its P 3 sis. Measured by AUC, RP 3 is the most accurate algorithm for MovieLens-M and second most accurate algorithm af-ter H for iPlayer and BookCrossing. For Prec the results are less favorable: while the performance of RP 3 is best for MovieLens-M and second best for iPlayer, WI-kNN, I-kNN, and H clearly outperform RP 3 for BookCrossing. This is possibly due to the lower number of average ratings per item, which may distort our boosting of low degree items.
Cooper et al. [6] show that P 3  X  improves accuracy over P Our experiments confirm this claim but the accuracy im-provements achieved with RP 3 are even greater than with P  X  for both AUC and Prec. Furthermore, at parameter val-ues corresponding to maximum accuracy, RP 3 achieves bet-ter GiniD, Pers, and Surp scores than P 3  X  . This shows that RP 3 gives a better trade-o  X  between accuracy and diver-sity, i.e., at parameter values that achieve highest accuracy it produces more diverse results.
 The results do not suggest a winner between RP 3 and H . In terms of AUC and Prec, RP 3 has advantage over H for MovieLens-M but not for iPlayer and BookCrossing. For BookCrossing the maximal achieved precision of H is much better than that of RP 3 . At parameter values corresponding to maximum accuracy, the diversity metric scores for RP 3 are better for H for MovieLens-M and iPlayer. Again, RP 3 underperforms compared to H on BookCrossing. Figure 1 graphs the AUC and Surp for P 3  X  ,RP 3 , and H for the whole parameter ranges. It shows that the maximally achieved Surp by RP 3 is better (for MovieLens-M and iPlayer) or comparable (for BookCrossing) to H . The plots for the other accuracy and diversity metrics show similar results as AUC and Surp, respectively, but are omitted due to space considerations. Note that we measured the performance of H only in the originally defined parameter interval ( 2 [0 , 1]). We assume that the diversity performance of H increases further for &lt; 0 at the cost of accuracy.
We can conclude that the new method RP 3 is a vertex ranking algorithm with top-class accuracy and diversity per-formance. Tuning of its parameter allows the trade-o  X  between recommendation accuracy and top-k long-tail item frequency to be controlled.
In this sub-section we compare the performance of vertex ranking to other recommendation algorithms.

As Table 2 shows, in accordance with [6], P 3 is the most accurate algorithm among the measured parameter-free rec-ommenders (MostPop, P 3 ,P 5 , #3-Paths, and L + ). In par-ticular, P 3 is more accurate than the computationally more expensive L + algorithm, which was found to be the most accurate algorithm in an earlier study [9].
 For AUC, the parameterized vertex ranking algorithms RP 3 and H outperform the non-vertex ranking recommen-dation algorithms I-kNN, WI-kNN, and BPRMF. For Prec, the scores of RP 3 are high for the MovieLens-M dataset but low for the BookCrossing dataset; the opposite is true for H . WI-kNN, the best performing non-vertex ranking algo-rithm, performs more consistently and archives comparable results to the best vertex ranking algorithm in terms of Prec.
The parameter free vertex ranking algorithms P 3 ,P 5 , and #3-Paths clearly show lower diversity scores than I-kNN, WI-kNN, and BPRMF in all datasets. This is surprising considering the fact that I-kNN, WI-kNN, and BPRMF are more accurate for some of the datasets (e.g., MovieLens-M). Hence, the better diversity performance of the non-vertex recommenders is not explained by more randomness in their recommendations. Exploring the recommendation lists of P ,P 5 , and #3-Paths reveals that ranking is strongly bi-ased by the item X  X  degree (i.e., favoring blockbusters), re-sulting in rankings similar to MaxPop. The parameter free L + generates diverse recommendations at the cost of low Prec (worse than MostPop for BookCrossing). In terms of AUC it is almost as good as P 3 .

Parameterized vertex ranking algorithms provide, besides better accuracy, improved diversity compared to parameter free algorithms. Comparing the diversity performance of the most precise vertex (RP 3 for MovieLens-M and iPlayer, H for BookCrossing) and non-vertex (WI-kNN for all datasets) ranking recommendation algorithms reveals WI-kNN as the clear winner for BookCrossing: WI-kNN is not only slightly Figure 2: Accuracy and diversity performance of the sampling algorithms parameter values.
 Table 3: Percentage of performance deviation be-tween P 3  X  , RP 3 ,and H and  X  P 3  X  , R  X  P 3 ,and  X  H after 1 m or 5 m random walks per user for parameter values of maximal AUC performance. more precise than H but also has higher diversity scores. For iPlayer RP 3 is slightly more precise than WI-kNN and achieves higher diversity scores. No clear winner can be found for the MovieLens-M dataset: RP 3 shows better pre-cision and surprisal scores but WI-kNN succeeds in terms of GiniD and Pers performance.
The goal of our second experiments is to investigate the performance of our sampling algorithms dependent on num-ber of samples (i.e., number of random walks).

We determined the performance of our sampling algo-rithms  X  P 3  X  ,R  X  P 3 , and  X  H with parameter values of maxi-mal AUC according to the non-sampling original algorithms whilst varying the number of random walks N 2 { 1 X 000, 2 X 500, 5 X 000, 10 X 000, 25 X 000, 50 X 000, 100 X 000, 250 X 000, 500 X 000, 1m,2.5m,5m } per user. Figure 2 shows the rate of con-vergence as well as the performance of the exact algorithms as indicated by the callouts near right edge of each graph. As expected the sampled algorithms X  performance converge to that of the exact ones with increasing N . To illustrate the closeness of the results we computed the percentage devia-tion d =( | m  X  m | )  X  100 /m between the sampling procedures X   X  m and exact calculations X  m performance metrics for 5 mil-lion random walks for MovieLens-M and 1 m random walks for iPlayer and BookCrossing. The results of this procedure, listed in Table 3, show that the sampled algorithms usually deviate less than 1% from the exact ones, less than 3% in all cases but for  X  H for MovieLens-M. Despite the greater number of random walks, d is greater for the MovieLens-M dataset than for the iPlayer or BookCrossing datasets. We hypothesize that this is due to the greater number of dis-tinct paths of length three starting at a given user existing in the graph G for MovieLens-M dataset as indicated by the high average vertex degree of 71.8 (compared to iPlayer: 7.1, BookCrossing: 11.6).

Furthermore, Figure 2 clearly indicates that  X  P 3  X  requires less samples to converge than R  X  P 3 , which in turn converges faster than  X  H . Since these algorithms can be computed using Algorithm 1 and di  X  er only in c rw , we hypothesize that c rw controls the e ciency of sampling. As a result  X  is the most accurate sampling algorithm for small values of N . For slightly greater N ,R  X  P 3 is more accurate than in the MovieLens-M and iPlayer datasets. If we increase N even further,  X  H becomes the most accurate recommender for the iPlayer and BookCrossing dataset.

Considering recommendation accuracy, diversity, and the sample size required to obtain acceptable accuracy, our re-sults suggest the following: On data with moderate spar-sity and balanced user and item degrees (MovieLens-M) one should use  X  P 3  X  if computing resources are scarce, i.e., N&lt; 250 0 000, because of the algorithm X  X  better precision and otherwise R  X  P 3 which provides best accuracy and diver-sity (at comparable level of accuracy). For sparser data with more ratings per item than per user on average (iPlayer), R  X 
P 3 is probably the best choice since it reaches almost the maximal accuracy but gives better diversity (at compara-ble level of accuracy) and converges quicker than  X  H .Fora sparse dataset with an average item degree smaller than the average user degree (BookCrossing)  X  H is the best choice given that computing resources are plenty ( N&gt; 25 0 000), since it gives better precision and diversity (at comparable level of accuracy). In the case of limited computing power however, the choice is not obvious due to the poor accuracy of R  X  P 3 and  X  H and very poor diversity of  X  P 3  X  .
In this paper, we studied accuracy and diversity of vertex ranking algorithms using random walk sampling techniques and thereby bring together three streams of earlier presented work. Specifically, we introduced RP 3 , a novel graph ran-dom walk based recommendation algorithm based on a re-ranking of P 3 that gives better recommendation accuracy and diversity than previously proposed vertex ranking algo-rithms. We showed that re-ranking improves the accuracy performance over P 3 and its parameterized version P 3  X  and pushes  X  X allflowers X , i.e., long-tail items, closer to the top of the recommendation list. Our method is also competitive with another graph-based recommender H that optimizes the accuracy diversity trade-o  X  . We also showed that RP is competitive with traditional algorithms.

Additionally, we presented scalable random walk sampling implementations of the three best vertex ranking algorithms. We showed empirically that these algorithms converge to their exact counterparts with increasing number of samples. The sampling procedures have the favorable property of be-ing anytime algorithms: a recommendation list of low accu-racy can be generated after a short processing time, while longer computations, i.e., gathering more random walk sam-ples, improve the accuracy of the recommendation list.
In future work we hope to investigate the sensitivity of the convergence of the sampling algorithms to domain char-acteristics and further explore convergence behavior for dif-ferent datasets and algorithms. Also, we would like to take detailed run-time measurements to ascertain wall-clock time advantages and trade-o  X  s.

Our results indicate that the goal of scalable, accurate, and surprising recommendations could be achieved with ver-tex ranking algorithms using random walk sampling. Acknowledgements: We would like to thank the Hasler Foundation for their generous support under grant # 11072.
