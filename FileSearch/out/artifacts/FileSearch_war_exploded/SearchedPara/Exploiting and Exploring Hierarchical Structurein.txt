 As the fast development of the Internet, users are inundated with choices, e.g., there are usually thousands of different types of products for the users to choose in an E-commerce web site or music service. Thus providing appropriate guid-ance and recommendation is very important to enhance users X  satisfaction and loyalty. Driven by this demand, recommender systems (RecSys) which provide personalized services are becoming more and more popular in the latest two decades. The well-known Internet ser vice providers such as Amazon, Google, Yahoo! and Netflix have adopted such recommendation engines.

The goal of music recommendation is providing a list of songs for listeners which they are more likely to enjoy. Deploying music recommendation engines huge potential commercial profits. Therefore, it is very meaningful to conduct music recommendation and actually ther e are many successful music Recsys in our lives, such as Yahoo! Music, Pandora, Last.fm, Ping and so on.

In additions, many institutes and researchers have worked out various ap-proaches to advance music recommendation performance. Among these meth-ods, collaborative filtering (CF) based m odels which use interactions between users and items are more effective and popular. CF based methods make rec-ommendations only employ users X  explicit feedback (e.g., ratings, thumbs up or down) and implicit feedback (e.g., purchasing histories, watching or listening records) of the past, then will get accurate recommendation lists without relying on item attributes and domain knowl edge too much. Therefore, CF has been successfully applied in the practical systems such as Amazon, Netflix and so on.
However, CF usually faces several issues in practical applications. Among them, one distinct problem is that users X  feedback data is severe sparse and it brings about great difficulty to make accurate recommendation on them. There-fore, utilizing appropriate approaches to mitigate sparsity issue will observably improve the recommendation performance.

This paper attempts to explore the characteristics of music itself to miti-gate the severe sparsity problem in CF based recommendation. We observe that music possess plenty of useful information. One distinctive feature that music entities are multi-typed, except for the lyrics, rhythms, pitch, timbre and others, there are some hierarchical structure in the music. Usually, music items can be categorized by their types into: tracks, albums, artists and genres. The items in different types are tied together through hierarchical links, e.g., each album belongs to a specific performing artist, and it might have several tracks and sev-eral possible genres. Our approach mainly utilize the hierarchical structure from two aspects. On one side, we exploit the hierarchical links to find more reliable neighbors; on the other side, we explore the effect of hierarchical structure on users X  potential preferences. In a furthe r step, we incorporate two aspects into an integrated model which could take in the advantages of both sides.
It is noteworthy that our models are not only limited to music recommenda-tion,but also can be effectively used in any situations with hierarchical informa-tion. E.g., they can be used in movie s recommendation, in which we can find hierarchical links among actors, directors and movie genres.
 The rest of this paper is organized as follows. Related work is introduced in Section 2. We present our approach in Sect ion 3, and evaluate related models in Section4. Finally, we conclude in Section 5. The approaches for music recommendations can be generally divided into two categories: content based methods and CF based methods. As there is plenty of useful information in the music, such as genre, lyric, timbre, pitch, rhythm and so on, various content based methods hav e been explored. E.g., signal filtering based methods are often us ed to make recommendations [1] as a song is relatively short and has regular rhythm. Among these methods, Mel-Frequency Cepstral Coefficients (MFCC) [2] which is designed to capture short-term spectral-based features and establish item-to-item similarity matrix is highly popular. Demo-graphic information and discography (e.g., Last.fm and Pandora) also have been used for music recommendations [3]. Some o ther researchers also try to use con-text information, item textual attributes, social tags and other annotations to provide recommendations [4].

Because content based recommendation methods do not consider users X  his-tory behaviors, they could not meet user s X  personal needs enough. Therefore, CF methods which directly build models on users X  behaviors are more popular and effective. Users usually expr ess their preferences in two ways: explicit feedback (ratings, purchase histories) and implicit feedback (listening histories, browsing histories). Ratings based CF methods [5,6,7] are most popular in the past 20 years, especially as Netflix Prize contest X  X  successful holding. Implicit feedback [8] methods also attract many attentions recently as most of the time users inter-act with systems through clicking, browsing or listening, while they are reluctant to give ratings. Generally speaking, CF models include neighborhood models and latent factor models [9].

Neighborhood models mainly concern the similarities between items (users), and then make predictions based on the ratings of the k-nearest neighbors. Neigh-borhood models can also be categorized into two types: user-based neighborhood (user-knn) and item-based neighborhood (item-knn). Compared to user-knn, item-knn is more effective in many situations, such as in the Netflix [10] and Movielens movie ratings [5], because usu ally users X  numbers are far more than that of items. In addition, item-based neighborhood has better scalability [10] and is more capable to explain the recommendation reasons, so item-knn is more popular. The key step in neighbor based models is how to calculate the simi-larities between users (items), and a be tter method named Pearson Correlation Coefficient (PCC) [5] is often used to com pute similarities. The prediction of user u  X  X  possible rating for item i is taken as a weighted average ratings of u  X  X  (or i  X  X ) neighbors [5]. Some other neighborhood methods such as the interpolated-weight item-based neighborhood model [10] and temporal item-based neighbor-hood model [6] were shown even better predication accuracy in the Netflix prize contest.

Latent factor models try to disclose the latent features that can explain the observed ratings, and it shows better ability to overcome sparsity than that of neighbor based methods [7]. One of the most common latent factor model is known as Singular Value Decomposition (SVD). In this model, each user u is tied with a user-factor vector p u , and each item is related with an item-factor vector q i , the predication for user u on item i is made by taking the inner product of vector p u and q i : X  r u,i = p T u q i . Since Simon Funk published a detailed implementation of a regularized SVD with separate feature update [11], many other SVD extension algorit hms have been created which show much better predication accuracy, such as NSVD [12], RISMF [13], Biased-SVD [7] and so on.
Biased-SVD was proposed by Koren in the Netflix contest through adding user and item bias into the original SVD. The rating predication by user u on item i is given by: where  X  is the average value of all the known ratings, b u and b i are user and item bias respectively.

Various solutions have been explored to mitigate the severe sparsity problem in CF based recommendations. Earlier work [14] try to fill in missing ratings to make the rating matrix denser, while it relies on imputation which will become more costly as the data growth and the prediction results are instable. In [15], the authors incorporate CF and music acoustic contents together to improve similarity measurement accuracy, while it relies too much on the music feature extraction technologies. Some other researchers also consider the affect of music taxonomy information on users bias and items bias [16,17], yet they ignore the internal links of music hierarchical structure and its effect on users X  latent inter-ests. The KDD-Cup 2011 contest which aims for predicting users X  preferences on music attracts thousands teams to participate in [18], while most of the teams only use existing methods and try to ensemble more models to get more accu-rate results[19,20]. Therefore, in this paper, we mainly focus on exploiting the hierarchical structure to find more reliable neighbors and exploring its affect for users X  potential preference for the lat ent related items tha thehasnotrated. 3.1 Preliminaries We denote u, v for users and i, j for items, and r ui is the known value that user u rates for item i . To distinguish with the known ratings, we denote  X  r ui for the set R = { ( u, i ) | r ui isknown } . V and T indicate the validation ratings and test ratings respectively. R ( u ) is defined as the item sets that u has rated and the item ratings are known. To reveal music taxonomy information and music hierarchical structure, we denote type( i )isitem i  X  X  type, which represents as type ( i )  X  X  track, album, artist, genre } . For each item i whosetypeistrack, we denote album ( i ), artist ( i )and genre ( i ) as its album, artist and genre set respectively, we denote similarly for other types. For each user u ,wedenote album ( u ) are the items that u might have interests in which generated by the album sets he has rated. 3.2 Hierarchical Structure Based Neighborhood Model As we have introduced in the above sections, music has plenty of useful char-acteristics. For the music taxonomy information, we can classify it into four categories: track, album, artist and genre. Based on the records that the artists have released, we can deduce several hierarchical links from them. E.g., given one album, we can know its performing artist, tracks it contains and its possible genres. We can refine the hierarchical relationship among the four different types in more details, shown in Fig.1: Based on the hierarchical tree, we can t race a node X  X  ancestors, brothers and children, and then we could find more related items. For example, from the al-bum  X  X ing Of Pop X  which is released by Michael Jackson, we can know its artist, albums and its genres, and find more Michael X  X  related albums and tracks. We can also find more tracks and albums with similar styles. Therefore, we can exploit the hierarchical structure to find more reliable neighbors and make rec-ommendations based on them. In this way, we could mitigate the negative affect which is caused by severe sparse ratings.

As there are two steps for item based neighborhood model: compute item-item similarities and make predications. We introduce the hierarchical structure based neighborhood model for each step. For th e four different item types, we find their neighbors and calculate the similarities separately. We assume a node X  X  directly linked nodes are most similar with it, and we calculate other nodes X  similarity with it based on the hierarchical links as follows.

From the hierarchical structure tree, we could know that each track i X  X  pos-(albums), which share the common album, artist and genres with i .There-fore, when calculating the similarities between i and other items ( track or al-bum ), there are three factors we should consider: whether they have common artist, album and genres or not. So we calculate the similarities in the following equation: Where gen sim ( i, j ) is the similarities between genre ( i )and genre ( j ), and  X  items which have no common album and artist with i .Weuse  X  =2/3 in this as follows: For each album i , we can compute its similarities in the similar method as that of each track. The similarity equation is shown as follows: When considering the similarities about genres and artists, we should differenti-ate them from before as they are on the top layers of the hierarchical tree. The relations between artists and genres ar e relatively weak when we trace from the hierarchical links, so we do not consider th e artists X  related genres when comput-ing their neighbors, and also ignore similarities between artists. For each artist i , we can get its related albums and tracks easily from the hierarchical, while it is a little difficult to determine their similarities, so we do not differentiate neighbors X  weights and set the similarities as 1.0. Besides, we sort i  X  X  neighbors in descending order by their popularity. For the genres, we deal with them in the same way as that of artists. In addition, we also consider two genres are similar if they belong to a track X  X  (album) genre sets together.

If we only calculate similarities based on the hierarchical links, the specific values are not very accurate. To make the similarities more reliable, we can in-corporate i  X  j s confidence into the original equation and revise it in the form of: In this equation, we do not consider users X  specific ratings, yet only utilize the item-item pairs X  relative co-occurring frequency. So the sparse ratings have less impact on the confidence calculation. In this way, we could also compute the sim-ilarities between artists whose albums and tracks have common genres through incorporating their confidence, as sometimes a artist might be affected by other artists with similar styles .

In the stage of making predication for item candidates, we take account of other users X  impact for the predicted item i and use item-mean-centered method knn model. The rating predication frame work for all the refereed item-knn mod-elsareshownasfollows: Where NH u ( i )isitem i s neighbors which are rated by u and computed through hierarchical structure. In a further step, we could eas ily combine the hierarchy based neighborhood model and the rating item based neighbor into one inte-grated framework: Here  X  is a constant used to adjust the weight of the two parts, the value is in (0 , 1] and trained from the training data. 3.3 Hierarchical Structure Based Latent Factor Model In the prior section, we utilize the hierarchical links to find more reliable neigh-bors for each item. Furthermore, we could explore the hierarchical structure more to model their effect on users X  potential interests. Suppose the scenario that if a user likes one album very much, there might be several possible factors con-tributing for it: Maybe he prefers some of the tracks in the album very much, or he is a fan of the album X  X  performing artist, or because of the associated genres. E.g., if a user loves the album  X  X ike a virgin X  released by Madonna very much, he might also prefer the song  X  X ngel X  or  X  X ike a virgin X  in that album, or he might be a fan of Madonna, or he might loves Pop or Rock very much. On the other side, if we know one person dislikes the album, we could conclude similar reasons causing it.

We can know whether one person likes one album or not from the explicit feedback-ratings he gives for the album. However, according to our analysis above, it is not important whether he rates the albums high or low, so we just use the binary value for the albums and build the AlbumSVD model as follows: Where b ui =  X  + b i + b u , album ( u ) is the items u might potentially prefer and has not rated yet, it is generated by the albums he has rated.

The album ( u ) is generated in the following way: for each album i that u have rated, we select top-k tracks with highest popularity belongs to i .Wealsocount the frequency of related artist and genres, and choose the artists and genres whose frequent numbers no less than the threshold. The values of top-k and threshold are determined by validation ratings.

For the artists and genres, we could deduce in the similar way as that of al-bums. Although the correlated relations between artists and genres are relatively weak, yet for the users side, we could consider their mutual influence through that of the AlbumSVD. For the rated artists, we firstly select the top-k support albums and tracks released by each artist whom u has rated. We also select the most frequent genres related with the tracks and albums belong to the artists he has rated.
Through the above analysis, we could easily incorporate the affect of artists, albums and tracks for users into one integrated model named AGTSVD, leading to the following framework: Where N au = album ( u ) +1, N tu = artist ( u ) +1and N gu = genre ( u ) +1.  X  1 ,  X  2 and  X  3 are constants used to control the weights of three aspects, and they are determined by validation data set.

We could also take the effect of implicit f eedback into accoun t, incorporate the items that users have rated into AGTSVD model, and extend it to AGTSVD++ model : Here N ru = R ( u ) + 1. To solve this model, we only use the observed ratings and minimize the prediction errors on them. The optimization object is in the following form: In this model,  X  is a regulation parameter used to avoid overfitting, and it is tuned on the validation data. To solve the model, we use stochastic gradient descent technique which is very popular, effective and efficient. 3.4 Hierarchical Structure Based Integrated Model In the prior two sections, we introduced hi erarchical structure based neighbor-hood model and hierarchical structure based latent factor model. On one side, we utilize hierarchical links to find more reliable neighbors. On the other side, we explore hierarchical structure X  X  impa ct for users X  potential preferences. Fur-thermore, we could take account of both aspects simultaneously and incorporate them into a integrated framework in the form of : Here, the framework consists of two parts: latent factor model and neighbor-based model X  X  effect on the residuals of th e latent factor model for the original ratings. R k ( i ; u )areitem i s top-k most similar items which have been rated by u , and they are determined by the ratings. H k ( i ; u ) also are item i s top-k most similar items while they are determined through the hierarchical links. feedback.

As usual, we could learn the related parameters through minimizing the reg-ularized squared error function similarly as (10), and use gradient descent solver to modify the parameters in the opposite gradient direction until convergence, yielding: b b  X  b p q  X   X  j  X  album ( u ): a  X  j  X  H k ( i ; u ): h  X  X  R k ( i ; u ): w c learning rate (  X   X  ) and regularization (  X   X  ) could be tuned by the validation ratings. 4.1 Data Set We use yahoo! music rating dataset to evaluate our approaches in this paper. yahoo! music rating dataset is released in the track1 of the kdd cup 2011. in the dataset each user has at least 20 ratings while 4 items for each user in validation ratings and 6 items for each user in the test ratings. the composition of the dataset is shown in table 1:
From Table 1, we can know the scale of ratings is very large and the sparsity is about 99.6%, even sparser than that of Netflix dataset whose sparsity is 98.9%. The rating value is integral number between 0 and 100 , thus the large range brings much bigger mistakes when compared with the Netflix rating value which is integer between 1 and 5. So it is more challenging to make predications on the Yahoo! Music dataset.
 The rating items consist of 4 different types: tracks, albums, genres and artists . track, it belongs to a unique album and artist, while it might have several possible genres. For each album, it also belongs to a unique artist, and it might contain tens of tracks and several possible genres. The statistics for the links and item numbers that each type includes and each type X  X  rating numbers are shown in Table 2. From this table, we can conclude that the hierarc hical links are very plentiful, and they could be modeled effectively. We could als o see that tracks and artists receive more ratings compared to albums and genres, so utilizing their hierarchical information will contribute more for improving the prediction performance. The numbers of the four types and their ratings are also shown in Table 2. We can also draw each type rating numbers for the users with different total ratings in Figure 2. From it, we could see that for the users whose rating number is small, artists and genres take up more in the items. While as the users X  rating number grows, the tracks and albums occupy more. Therefore, we could effectively utilize the hierarchical links effectively model users X  potential preferences. 4.2 Evaluation Metric We use root mean squared error (RMSE) to evaluate our approach in this paper. Compared to MAE, RMSE gives more weights for predictions with bigger errors and is used more in recent years. The evaluation rule is in the form of: RMSE = 4.3 Experiment Results and Analysis In this part, we evaluate the performance of our approach by comparing with the traditional models which take no account of hierarchical structure. HierKNN. Before comparing the performance of each related neighborhood models, we tune the parameter  X  in the confidence hierarchical neighborhood (ConfHierKNN) and rating based item neighborhood (ItemKNN) integrated model (ConfHierInteg) on the validation data set. We tried different number of neighbors respectively to find the best  X  , and got  X  =0 . 53 for the ConfHier-Integ model. The evaluation results are shown in Table 3.

From Table 3, we could conclude that neighborhood models are absolutely much better than user average, item average and global average model. When comparing between item confidence based neighborhood model (ItemConfKNN) and rating based neighborhood model (UserPCC / ItemPCC), we could easily find that utilize users X  specific ratings which reflect their explicit feedback are more effective than ignoring the values. In the Yahoo! Music rating data, we also find ItemPCC is better than that of UserPCC, as user numbers are much more than item numbers. For HierKNN, we could find that it is less effective than ItemPCC as the item-item similarities are not very accurate. However, it has outperformed UserPCC which use users X  e xplicit feedback. Moreover, through incorporating item-item confidence into the original hierarchy similarities, the performance of ConfHierKNN is improved greatly, and it is more effective than that of ItemPCC. So we conclude that through adding the items X  confidence, more reliable neighbors could be found. For the model ConfHierInteg, we can also see that by combining the two aspects of hierarchical structure and ratings, ConfHierInteg will substantially utilize both of the advantages and the prediction accuracy improve observably.
 HierSVD. When mentioned to the hierarchical structure relat ed latent factor model, there are several factors we should consider: Firstly, in the generation process of album ( u ), artist ( u )and genre ( u ), two parameters need to be tuned. Through the training on the validation data, we set top-k =10 for AlbumSVD and GenreSVD, and top-k =20 for AristSVD; we choose threshold =0.3 for the three models. In that way the models could trade off better between performance and computation cost. Secondly, we should learn the related learning rates(  X   X  ) and regulation parameters(  X   X  ), we use APT2 method which can be classified as one two-way cross folder method, and the details can be found in [21]. The related parameters are set as:  X  1 =0.002294,  X  1 =0.005,  X  2 =0.08149,  X  2 =0.005,  X  =0.00007,  X  3 =0.015,  X  4 =0.003052,  X  4 =0.015,  X  5 =0.0001,  X  5 =0.015. Lastly, we tune  X  1 - X  4 and set as:  X  1 =0.15,  X  2 =0.4,  X  3 =0.3,  X  4 =0.3.
Based on the conditions mentioned abov e, our models are compared with the original Biased-SVD and SVD++ accordingly. To show the effectiveness of our models, we execute all the models with varying factor dimensions, and the de-tailed comparison results can be found in Fig. 3(a) and Fig. 3(b).
 As both of the figures show that our models outperform the SVD and SVD++ ac-cordingly in each factor dimension. From Fig. 3(a) we can see that the AGTSVD decreases the RMSE by about 0.75, and as shown in Fig. 3(b), it also per-forms better than SVD++. Therefore, wh en there are not enough ratings, the AGTSVD will perform even better than the SVD++ model, as the AGTSVD only concerns about the items that users have not rated. From Fig. 3(b), we verify that through incorporating implicit feedback into AGTSVD model, predication errors will be decreased even more. We ca n also notice that when making compar-ison among the AlbumSVD, GenreSVD and ArtistSVD, or the AlbumSVD++, GenreSVD++ and ArtistSVD++, both of the artist related models work better than the other two models. It is because that artists locate in the highest level of he hierarchical structure tree, thus when considering their feedback, it has more related items to select from, which users might be interested in. So we get a con-clusion that the higher level of the item s, the more important they are. We can also see that the RMSE of hierarchical structure related models decrease more steadily than that of the original models as the factor dimensionality increases. HierInteg. Furthermore, we conduct several experiments for the state-of-the-art model which incorporates both aspects of t he hierarchical structure characteris-tics. When evaluating HierIntegModel, we set neighbor size with 100, as we find increase it bring little RMSE decrease, and we use the following values for the referred meta parameters:  X  6 =0.000035,  X  6 =0.000328,  X  7 =0.0001,  X  7 =0.00001. Table 4. summarize the evaluation r esults, we can find the RMSE decrease by 1.03 comparing to SVD, and through the comparison with AGTSVD++ , we verify that incorporating hierarchical based neighbor model into AGTSVD++ could decrease the prediction errors even more, and the integrated model could make use of the advantages of both aspects adequately.
 Sparsity Analysis. To verify the hierarchical structure based model can ef-fectively overcome the sparsity issue, we evaluate related models with different sparsity levels of training data while keeping the validation data and test data. We sample the original by the order of users X  rating time with varying training data size N , and execute the related models under the same circumstance (KNN with best performance, SVD related models with f =50). The experimental re-sults are listed in Table 5.

From Table 5, we could clearly find that compared with neighborhood mod-els, latent factor models have much stronger ability to overcome rating sparsity problem. HierRateKNN performs much better than that of ItemPCC as it relies less on the numbers of training data. For model APTSVD++, it outperforms SVD++ and SVD on each training data size, and the superiorities are much more obvious when the ratings are even sparser. We could also observe that HierIn-tegModel can utilize the advantages of both HierRateKNN and APTSVD++, and improve the prediction performance steadily for each training data size. Through the comparison, we can get the conclusion that our approach indeed mitigate the sparsity problem effectively. In this paper, we propose a music hierarchical structure based model to mitigate the rating sparsity problem, which heavily affects the recommendation methods X  performance. We utilize the hierarchical structure in two ways. Firstly, we exploit it to find more reliable neighbors through the links between items with different types. Then, we explore the effect of hier archical structure on users X  potential preferences and find more rela ted items that they might be interested in. Finally, we incorporate both aspects into a integrated framework. Experimental results show our model could significantly improve the recommendation performance. Furthermore, we evaluate related models o n different sparsity levels of the train-ing data, and conclude that our approach can effectively mitigate rating sparsity issue.

In the future work, we will explore rat ing temporal effect on improving rec-ommendation performance, and integrate it with the framework proposed in this paper.

