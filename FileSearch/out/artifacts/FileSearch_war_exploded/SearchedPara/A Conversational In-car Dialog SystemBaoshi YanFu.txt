 As a constant stream of electronic gadgets such as navigation systems and digital music players en-ters cars, it threatens driving safety by increasing driver distraction. According to a 2005 report by the National Highway Traffic Safety Administration (NHTSA) (NHTSA, 2005), driver distraction and inattention from all sources contributed to 20-25% of police reported crashes. It is therefore impor-tant to design user interfaces to devices that mini-mize driver distraction, to which voice-based inter-faces have been a promising approach as they keep a driver X  X  hands on the wheel and eyes on the road.
In this demonstration we present a conversational dialog system, CHAT, that supports music selection, restaurant selection, and driving navigation (Weng et al., 2006). The system is a joint research effort from Bosch RTC, VW ERL, Stanford CSLI, and SRI STAR Lab funded by NIST ATP. It has reached a promising level, achieving a task completion rate of 98%, 94%, 97% on playing music, finding restau-rants, and driving navigation respectively.
Specifically, we plan to present a number of fea-tures in the CHAT system, including end-pointing with prosodic cues, robust natural language under-standing, error identification and recovery strate-gies, content optimization, full-fledged reponse gen-eration, flexible multi-threaded, multi-device dialog management, and support for random events, dy-namic information, and domain switching. The spoken dialog system consists of a number of components (see the figure on the next page). In-stead of the hub architecture employed by Commu-nicator projects (Seneff et al., 1998), it is devel-oped in Java and uses flexible event-based, message-oriented middleware. This allows for dynamic regis-tration of new components. Among the component modules in the figure, we use the Nuance speech recognition engine with class-based n -grams and dynamic grammars, and the Nuance Vocalizer as the TTS engine. The Speech Enhancer removes noises and echo. The Prosody module will provide addi-tional features to the Natural Language Understand-ing (NLU) and Dialog Manager (DM) modules to improve their performance.

The NLU module takes a sequence of recognized words and tags, performs a deep linguistic analysis with probabilistic models, and produces an XML-based semantic feature structure representation. Par-allel to the deep analysis, a topic classifier assigns n -best topics to the utterance, which are used in the cases where the dialog manager cannot make any sense of the parsed structure. The NLU module also supports dynamic updates of the knowledge base.
The DM module mediates and manages interac-tion. It uses an information-state-update approach to maintain dialog context, which is then used to inter-pret incoming utterances (including fragments and revisions), resolve NPs, construct salient responses, track issues, etc. Dialog states can also be used to bias SR expectation and improve SR performance, as has been performed in previous applications of the DM. Detailed descriptions of the DM can be found in (Lemon et al., 2002) (Mirkovic and Cave-don, 2005).

The Knowledge Manager (KM) controls access to knowledge base sources (such as domain knowl-edge and device information) and their updates. Do-main knowledge is structured according to domain-dependent ontologies. The current KM makes use of OWL, a W3C standard, to represent the ontological relationships between domain entities.

The Content Optimization module acts as an in-termediary between the dialog management module and the knowledge management module and con-trols the amount of content and provides recommen-dations to user. It receives queries in the form of se-mantic frames from the DM, resolves possible ambi-guities, and queries the KM. Depending on the items in the query result as well as configurable properties, the module selects and performs an appropriate op-timization strategy (Pon-Barry et al., 2006).
The Response Generation module takes query re-sults from the KM or Content Optimizer and gener-ates natural language sentences as system responses to user utterances. The query results are converted into natural language sentences via a bottom-up ap-proach using a production system. An alignment-based ranking algorithm is used to select the best generated sentence.

The system supports random events and dy-namic external information, for example, the system prompts users for the next turn when they drive close to an intersection and dialogs can be carried out in terms of the current dynamic situation. The user can also switch among the three different applications easily by explicitly instructing the system which do-main to operate in. This work is partially supported by the NIST Ad-vanced Technology Program.

