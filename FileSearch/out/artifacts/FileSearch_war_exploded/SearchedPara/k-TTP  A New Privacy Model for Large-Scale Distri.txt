 Secure multiparty computation allows parties to jointly com-pute a function of their private inputs without revealing anything but the output. Theoretical results [2] provide a general construction of such protocols for any function. Protocols obtained in this way are, however, inefficient, and thus, practically speaking, useless when a large number of participants are involved.

The contribution of this paper is to define a new privacy model  X  k -privacy  X  by means of an innovative, yet natural generalization of the accepted trusted third party model. This allows implementing cryptographically secure efficient primitives for real-world large-scale distributed systems.
As an example for the usefulness of the proposed model, we employ k -privacy to introduce a technique for obtaining knowledge  X  by way of an association-rule mining algorithm  X  from large-scale Data Grids, while ensuring that the pri-vacy is cryptographically secure.
 H.2.8 [ Database Management ]: Database Applications -Data Mining Algorithms, Security Privacy, security, data mining, privacy-preserving data min-ing, distributed data mining, association rule mining  X 
We thank Intel Corporation and the Mafat Institute for Re-search and Development for their generous support of this research. We thank Yehuda Lindell for his advice and en-couragement.
 Copyright 2004 ACM 1-58113-888-1/04/0008 ... $ 5.00.
The objective of large scale distributed database systems, such as the Data Grid, is to maximize the availability and utilization of data that was often obtained through the in-vestment of much labor and federal capital. Maximal uti-lization would be achieved if the owners of different data (resources) were able to share it with each other and with the research community at large  X  i.e., make it available for everyone. Nevertheless, this is frequently prohibited by le-gal obligations or commercial concerns. Such restrictions usually do not apply to cumulative statistics of the data. Thus, the data owners usually do not object to having a trusted third party (such as a federal agency) collect and publish these cumulative statistics, provided that they can-not be manipulated to obtain information about a specific record or a specific data source. Trusted third parties are, however, difficult to find, and the procedure involved is nec-essarily complicated and inefficient.

This scenario is most evident in the health maintenance business. Health Maintenance Organizations (HMOs) have a high interest in sharing medical data, both for public health reasons, such as plague control and the evaluation of different medical protocols, and for commercial reasons, such as detecting medical fraud patterns or medical miscon-duct. Similar examples can be found in the financial domain where, for instance, account information should be shared in order to detect money laundering. However, sharing data is very problematic: it is legally forbidden to expose specific records  X  i.e., a patient X  X  medical record  X  and it is commer-cially undesirable to expose statistics about a single HMO  X  e.g., mortality rates or the average expenditure per client.
Distributed data mining allows data to be shared with-out compromising privacy. On the one hand, data mining techniques have been shown to be a leading tool for data analysis, and as such they are likely to satisfy researchers X  needs as an interface to the data stored in a Grid. On the other hand, the models produced by data mining tools are statistical and thus satisfy the privacy concerns of the data owners. As a result, different HMOs can choose to reveal their databases not for direct reading but rather to a dis-tributed data mining algorithm that will execute at the dif-ferent sites and produce a statistical model of the combined database. That the algorithm produces statistics still does not guarantee privacy: an HMO also has to make certain that the data mining algorithm itself does not leak infor-mation. For instance, an algorithm in which each HMO computes its mortality rate and then sends it to a polling station which computes the global statistics would not meet this criterion because the polling station would be informed of the mortality rate for each HMO. This calls for a specific type of distributed data mining algorithm that is privacy-preserving .

The common approach [3, 9, 5] for privacy-preserving data mining is to replace each message exchange in an or-dinary distributed data mining algorithm with a crypto-graphic primitive that provides the same information with-out disclosing the data of the participants: for example, replacing a sum reduction with a cryptographically secure sum reduction in which the participants learn only the total sum and not each other X  X  partial sums.

When practiced well, this approach guarantees the privacy of both single records and source statistics. However, all of the algorithms which have taken this approach so far have failed to scale above a few computers. They all rely on cryptographic primitives that are both global  X  requiring all-to-all communication patterns  X  and rigid  X  requiring that the primitive be evaluated all over again if the data changes even slightly or a node joins or leaves the system. That would be unacceptable in a Data Grid system which is expected to scale to hundreds or even tens of thousands of nodes. (There are hundreds of HMOs in the US alone and a typical HMO uses the services of hundreds of independent laboratories, clinics, and medical specialists, all of which have their separate databases.)
When dealing with very large systems, it is often rea-sonable to permit learning partial combined statistics, pro-vided they include a minimal number of participants X  inputs. The contribution of this paper is to formalize this approach, defining k -privacy as the privacy attained when no partici-pant learns statistics of a group of less than k participants. k -privacy is defined in terms of k -TTP  X  a powerful, yet nat-ural novel generalization of the trusted third party model. k -TTP captures practical privacy measures which are ac-cepted by HMOs today [8]. Using k -privacy, we can imple-ment efficient cryptographically secure primitives that do not require all-to-all communication, and are thus practical for real-world large-scale distributed systems.

As an example for the usefulness of the proposed model, we use k -privacy to address the problem of preserving pri-vacy while distributively mining association rules from large number of database partitions. In the proposed solution, k -privacy is the basis for a cryptographic privacy-preserving association rule mining algorithm in which the cryptographic primitives involve only pairs of participants and are thus scalable. We use a non-private association rule mining algo-rithm as a foundation, and replace the messages that were sent by resources with encrypted versions which the recip-ient cannot decrypt. Using k -privacy, our algorithm offers a tradeoff between the privacy attainable (measured in the minimal size of the population on which statistics are eval-uated) and the computational effort required to attain it.
Assume that n participants P = { P 1 ,P 2 ,...,P n } , each owning a private input x i , wish to jointly compute the out-put f ( x 1 ,x 2 ,...,x n ) of some common function f , without revealing anything but the output. They do so by running aprotocol  X  . The participants are said to follow the honest-but-curious (also called semi-honest or passive )model[1]if they are assumed to follow the protocol exactly but may ob-serve it in order to glean additional knowledge. Otherwise, the participants are said to follow the malicious model [1].
Assume a trusted third party (TTP) T exists. This is referred to as the ideal model . Inthiscaseprivacypreserv-ing protocol exists, both in the honest-but-curious and the malicious models: the participants send their private inputs to
T , which computes and returns the output. Clearly, no participant other than T learns anything from the protocol but the result.

Trusted third parties are, however, difficult to find, es-pecially when the number of participants increases. Thus, different solutions are required. Still, it is customary to use the ideal model to define the privacy attained by a protocol: In the case of honest-but-curious participants, a protocol  X  that computes f is said to be private if its results can be simulated in the ideal model. In other words, the protocol is private if any knowledge that is obtained by an honest-but-curious adversary attacking the protocol in the real world can also be obtained by it in the ideal model. In the case of malicious participants, a private protocol is called secure .
Known theoretical results show that private and secure protocols exist for any function [2]. However, the proto-cols obtained by this general construction are inefficient and useless in the case of a large number of participants. The reason for this inefficiency is the all-to-all communication op-erations required during the protocols. Such operations are very costly in large-scale distributed networks. Several effi-cient solutions for specific problems, in various fields, have been proposed (see [6] for a comprehensive lists of refer-ences), but none of them is practical for a very large number of participants. A method for constructing efficient peer-to-peer secure multiparty protocols for a limited set of functions was presented in [10]. It is based on using an untrusted third party.

We now describe the problems that a large number of participants introduces to the ideal model. We then define our generalization of this model.
Consider the problem of privately computing the joint sum of the inputs: f ( x 1 ,...,x n )= i x i . A private (or al-ternatively, secure) protocol will allow the honest-but-curious (or malicious, respectively) participants to learn only the fi-nal sum and not each other X  X  partial sums. However, when dealing with very large systems, it is often reasonable to al-ter the TTP model and permit participants to learn partial sums, provided they include a minimal number of partic-ipants X  inputs. The intuition is that it would suffice for one to  X  X ide X  in the combined statistics of a group of par-ticipants, instead of  X  X iding X  in the combined statistics of all the participants. We formalize the above by defining k -privacy ( k -security ) as the privacy attained when no par-ticipant learns combined statistics of a group of less than k participants, in the presence of honest-but-curious (mali-cious) participants. k -privacy ( k -security) is a powerful, yet natural generalization of the accepted trusted third party model, which captures practical privacy measures accepted in the real world [8]. It also provides a tradeoff between protocol efficiency and the level of privacy, by means of the privacy parameter k .

In the TTP model all participants behave the same. They all send their inputs to the TTP and receive the same out-put. This is not the case in the k -privacy model were differ-ent participants may be given different outputs. Colluding participants can infer additional information by comparing the outputs they received. For example, if one has the sum of the inputs of a group V and the other of V  X  X  i } ,they can deduce the input of i .

Therefore, in k -privacy the ideal model is augmented with a collusion model. This collusion model is very liberal, al-lowing collusion, for instance, of any subgroup of the partic-ipants or even no collusion at all. As we shall see, the com-plexity of secure protocols increases as the collusion model becomes more liberal. We formalize this by defining C X  2 P  X  X he collusion set : the set of all subgroups of possibly col-luding participants. In the worst case, when any collusion is possible, C =2 P . In the opposite case, when no collusion is possible, C = {{ P 1 } ,..., { P n }} .
Consider the previous example of privately computing the joint sum of the inputs. Suppose the sum was privately computed once and it equals S . Now suppose the sum is computed again, and this time it equals S . Assume that an attacker finds out that only one specific participant changed its input between the computations. The attacker can then learn the change in that participant X  X  input. This situa-tion is common in many real life applications. Consider, for example, computation which take place every hour among businesses with different opening hours. Therefore, the use-fulness of the TTP model is severely limited [4] in such appli-cations. k -privacy provides a natural framework for taking care of such potential privacy breaches: it is required that the inputs of at least k participants change before revealing combined statistics.
We now formalize the above discussion by defining a new general framework we denote as k -TTP :
Definition 2.1. [ k -TTP ]Let P = { P 1 ,...,P n } be the set of honest-but-curious (malicious) participants. Let C X  2
P be the collusion set. A k -TTP that privately (securely) computes a function f with n inputs, under the collusion set C , is an honest, event-based entity, such that: k -TTP defined as above preserves k -privacy. To see this, we observe that the k -TTP does not provide output for queries from participant i about a group V , if the colluding gang of i can manipulate this output and the outputs they previously received for jointly learning the output f ( W )for agroup W of less than k participants.

Using a k -TTP, it is straightforward to define k -private computation in various settings. Let us recall the example of privately computing the joint sum of the inputs. This time, suppose the collusion set C is defined as a partitioning of the participants into groups based on geographic locations. In this setting, the k -TTP can be fully distributed: Because participants collude only with members of their group, it is enough to require that the members of each group direct their queries to the same local k -TTP. The real world imple-mentation of the distributed k -TTP may still be elaborated. Yet, as we will demonstrate, locality of the collusion set can be used to implement efficient secure protocols.
We now slightly shift the focus of the discussion with the purpose of demonstrating how k -TTPcanbeusedtoim-plement a highly scalable secure association-rule mining al-gorithm. We consider the most restrictive collusion model, C = {{ P i }| P i  X  X } . The input of i , x i , is a single bit, and the function the k -TTP evaluates is the majority vote among the participants of a provided set V . As shown in [11], ma-jority computations can be used to implement a distributed association rule mining algorithm. Hence, we describe a k -private majority voting algorithm, and show how it can be used to implement a k -private distributed association rule mining algorithm.
Data Grid Model. A Data Grid is composed of a group of resources, each maintaining a database partition. Each resource is composed of two entities: the broker  X  through which the resource communicates with the rest of the Data Grid, and the controller , which tells the broker when to send messages and when to further develop the mined model. We denote V t the set of resources at time t . Communication between the resources takes place through the exchange of messages via an overlay network. We assume that an under-lying mechanism maintains a communication tree that spans all the resources. We denote E u t the set of edges colliding with a resource u at time t .

Association Rule Mining Model. The association rule mining (ARM) problem is traditionally defined as fol-lows: Let I = { i 1 ,i 2 , ..., i m } be the items in a certain do-main. An itemset is some subset X  X  I . A transaction t is also a subset of I , associated with a unique transac-tion identifier. A database DB is a list that contains | transactions. Given an itemset X and a database DB , Support ( X, DB ) is the number of transactions in DB which contain all the items of X and Freq ( X, DB )= Support ( X,DB Forsomefrequencythreshold MinFreq  X  [0 , 1], we say that an itemset X is frequent in a database DB if Freq ( X, DB ) MinFreq and infrequent otherwise. For two distinct frequent itemsets X and Y , and a confidence threshold MinConf  X  [0 , 1], we say the rule X  X  Y is confident in DB if MinConf Freq ( X, DB )  X  Freq ( X  X  Y, DB ). We call confident rules between frequent itemsets correct . The solution of the ARM problem is R [ DB ]  X  all the correct rules in the given database.
Database Model. We assume the database is updated over time (for instance, in the HMO application, patient records are accumulated), and hence, DB t will denote the database at time t and R [ DB t ] the rules that are correct in that database. In distributed association rule mining the database is partitioned among the resources. We denote the union of partitions belonging to a group of resources V  X  by DB V t ; that is, DB t equals DB V t t . When the number of resources is large and the frequency of updates high, it may not be feasible to propagate the changes to the entire system at the rate they occur. Thus, it is beneficial to have an incre-mental algorithm that can quickly compute interim results and improve them as more data is propagated. Such algo-rithms are called anytime algorithms . We denote  X  R u [ DB the interim solution known to the resource u at time t .We further assume that no transactions will be deleted. This assumption can be made without loss of generality, because deleting a transaction can be simulated by adding a  X  X egat-ing X  transaction instead (as is customary in logging).
Privacy Model. A distributed ARM algorithm is said to be k-resources-private if it is k -private when the resources (clinics of the HMOs, for example) are considered as the par-ticipants in the k -TTP definition. The algorithm is said to be  X  k -transactions-private if it is k -private when the trans-actions (patients records, for example) are considered the participants. For simplicity, in this paper we set k and  X  be equal and define an algorithm as k-private if it is both k-resources-private and k-transactions-private .
The work presented here relies on two bodies of research: a scalable algorithm for association rule mining which does not require global communication and a cryptographic technique called oblivious counters.
In a previous paper [11] we describe Majority-Rule  X  X  highly scalable distributed ARM algorithm (non-privacy-preserving). The algorithm is based on two main inferences: That the distributed ARM problem is reducible to a se-quence of majority votes, and that if the vote is not tied, majority voting can be done by a scalable algorithm  X  which we also present in that paper. Since it turns out that the frequency of an overwhelming number of candidate itemsets is significantly different from MinFreq (i.e., the vote is not tied), the outcome of these two observations is a local, and thus highly scalable, distributed ARM algorithm.

The input to the Scalable-Majority algorithm is a bit at each node u and a globally known majority threshold  X  . Nodes communicate by sending pairs s, c to each other, and keep records of the last message sent to each neighbor v  X  sum uv , count uv  X  and the last received  X  sum vu , count We represent the input bit as a message from  X  .Wethusde-note N u t as E u t  X  X  X  u } . Thus, sum  X  u equals one if the input bit is set and zero otherwise, and count  X  u equals one. u will compute  X  uv =( sum uv + sum vu )  X   X  ( count uv  X  count vu sage to v upon first contact with it and in the case that ( X  uv  X  0  X   X  uv &gt;  X  u )  X  ( X  uv &lt; 0  X   X  uv &lt;  X  u ), and will reevaluate the condition on every change in  X  u and  X  uv . In both cases the message will equal the sum of the mes-sages received from other neighbors: wu = vu  X  N u set sum vu to s and count vu to c. It is easy to see that when Scalable-Majority terminates (i.e., no more messages are to be sent) all nodes compute the same sign for  X  u ; that is, they agree on the majority.

To see how Scalable-Majority translates into an associa-tion rule mining algorithm Majority-Rule , consider a major-ity vote in which the transactions vote over every candidate itemset, with each transaction voting one if it contains the itemset and zero otherwise, and with  X  set to MinFreq .A positive majority would mean that the itemset is frequent. Similarly, to decide whether a rule is confident, the trans-actions again must vote. This time only transactions that include the left-hand side of the rule vote, and their vote is one if they contain the right-hand side and zero otherwise;  X  is set this time to MinConf . Naturally, with databases containing many transactions, sum  X  u and count  X  u are set according to the agglomerated vote.
 Candidates generation is done using a generalization of Apriori X  X  [7] criterion, and is described in [11].
Let ( E, D ) be a public-key cryptosystem from Z N : E ( m ) is the encryption of a given plain text m  X  Z n using the encryption key, and D ( c ) is the decryption of a given cipher text c using the corresponding decryption key. ( E, D )is probabilistic if the encryption process involves a random el-ement, such that two ciphers encrypting the same plain are seemingly nonrelated. We denote E ( x )  X  the rerandomiza-tion of E ( x )  X  a cipher such that D E ( x ) = D ( E ( x )).
A public-key cryptosystem ( E, D, A + ,A  X  ) is called ad-ditively homomorphic if there exist efficient algorithms A and A  X  that allow the encryption of x + y or x  X  y to be ef-ficiently calculated, given E ( x )and E ( y ), without knowing the decryption key. That is, for all E ( x ), E ( y ):
In this work we use an additively homomorphic proba-bilistic public-key cryptosystem, which has the additional property that A + and A  X  do not require knowledge of the encryption key. Such a cryptosystem can be easily con-structed from any two homomorphic cryptosystems: mes-sages are first encrypted using the first cryptosystem, then their encryption is signed using the second. We use such a cryptosystem for implementing oblivious counters by which one can add two ciphers without knowing their plain, and without knowing either the encryption or decryption keys. Furthermore, by using A + iteratively, one can easily calcu-late E ( m  X  x )from E ( x )forsome m  X  N .Intheinter-and  X  E ( x i )for A + ...A + A + ( E ( x 1 ) ,E ( x 2 )) ,E ( x
We now describ e Private-Majority-Rule ,a k -private dis-tributed association rule mining algorithm. The master plan of Private-Majority-Rule is similar to that of Majority-Rule : the resources perform majority votes over candidate rules to decide whether they are frequent and confident. How-ever, in Private-Majority-Rule the candidates are counted in the local database by the broker, which then encrypts the count into oblivious counters using a public encryption key. The broker does not know the corresponding decryp-tion key. This ensures that a broker cannot discover the data in messages it receives from its neighbors. Only controllers can decrypt the oblivious counters. However, a controller will never be given the oblivious counter directly. Instead, whenever a broker has to decide whether to send a message to its neighbor, it performs a secure protocol with a con-troller, by the end of which the broker learns whether the message should be sent and the controller learns nothing. Finally, whenever new candidates should be generated, the broker performs a similar protocol with a controller, by the end of which the broker learns the new candidate set and nothing more and the controller learns nothing.

The algorithm maintains k -privacy. k specifies the least size of a group for which our algorithm allows learning com-bined statistics (majority vote of the participants in this group). We achieve this by making sure that as long as data gathered for a rule is not based on at least k additional database portions and at least k additional transactions than in the last query, the resource behavior is independent of the data and therefore does not disclose anything about it. Consider a system composed of brokers running Majority-Rule with all votes, and consequently all messages, encrypted by the broker in oblivious counters. Instead of maintaining sum uv , count uv , sum vu , count vu , X  u ,and X  uv ,abroker will maintain their encrypted versions: sum uv enc , count tions. But, in order to maintain k -resources security, we also need to count resources. For this purpose we add a resource counter, num , and likewise maintain num uv and num vu . When the broker needs to send a neighbor a message that sums the votes provided by the rest of its neighbors, it will use the A + algorithm to sum the counters.

A problem arises when a broker needs to evaluate a counter; for example, when it needs to learn whether the value it hides is greater than zero (that is, the value X  X  sign). For this, it must consult with the controller. Nevertheless, it is essential that the controller not learn the value of x .Thisis a standard secure function evaluation (SFE) problem [2] be-tween two participants where the input of the broker is the encrypted oblivious counter, the input of the controller is the decryption key, and the function, whose output should be re-vealed to the broker only, is the sign of the value encrypted by the counter. In [2], and in many later papers, general techniques for such evaluations are given. For our specific problem, evaluating the sign of an encrypted counter, several ad hoc solutions can be employed with higher performance. A broker will use such an SFE primitive on two occasions. The first is when a broker u in Majority-Rule evaluates the Majority-Rule condition on  X  u and  X  uv to decide whether a message should be sent to a neighbor v . In this case the Algorithm 1 Private-Scalable-Majority -Algorithm for a broker of resource u Input: A rational majority ratio  X  =  X  n / X  d and a candi-date rule r this voting instance represents.
 Local variables: The set E u t of edges colliding with u ,the privacy parameter k , and the common encryption (public) key.
 Definitions: N u t = { X } X  X  v  X  V t : uv  X  E u t } ,  X   X   X   X  sum vu Output () : Return the output of SFE with the controller of u , where the condition to be evaluated (revealed to the broker only) is: Cond ( x 1 ,x 2 ,x 3 )= x 1  X  k last  X  k 1 and k last 2 are maintained by the controller of u , both initialized to zero, and at the end of the SFE are set to the given x 1 and x 2 respectively.
  X  MajorityCond ( v ) : Return the output of SFE with the controller of u , where the condition to be eval-uated is: Cond ( x 1 ,x 2 ,x 3 ,x 4 )= x 1  X   X  k last 1 &lt;k x 2  X   X  k last 2 &lt;k ( x 3 &lt; 0 x 4 &lt; 0) ( x 3  X  0 x as the inputs x 1 , x 2 , x 3 , x 4 respectively.  X  k last maintained by the controller of u , both initialized to zero, and at the end of the SFE are set to the given x 1 and x 2 respectively.
 On initialization for each uv  X  E u t , or on join of a neighbor v : Set sum vu enc , sum uv enc , count vu enc On receiving sum , count ,num from v : Set sum vu enc  X  sum , count vu enc  X  count , num vu enc  X  num .
 On change in sum  X  u enc from s enc to s enc : Set sum  X  u to s enc  X  + E (1), s enc  X   X  E (1), s enc  X  + E (1), and s after each assignment call OnChange (). Finally, set sum  X  to s enc and call OnChange ().
 On a change in sum  X  u enc or count  X  u enc or on a call to OnChange () : For each v  X  E u t :if MajorityCond ( v ), call Update ( v ). broker will initiate SFE with the controller, where the con-dition to be evaluated ( true means that a message should be sent) is: For the candidate rule considered, either the Majority-Rule condition over  X  u enc and  X  uv enc evaluates true, or the difference between the current and previous values encrypted by  X  v  X  N u are less than k new transactions than in the last query), or the difference between the current and last values encrypted Algorithm 2 Private-Majority-Rule -Algorithm for a bro-ker of resource u Inputs of resource u : The set E u t of edges colliding with u , the set of items I , the frequency threshold MinFreq ,and the confidence threshold MinConf .
 Output of resource u : The interim set of rules  X  R u [ DB Local variables: X  X  Y,  X  denotes a candidate-rule X  X  Y with desired majority threshold  X  . C is a set of can-didate rules together with counters r.sum enc and r.count both initially set to E (0).
 Initialization: Set C  X  X   X  X  X { i } , MinFreq | i  X  I } . Repeat the following continuously:  X  For each rule r  X  C for which there is no active
Private-Scalable-Majority instance, initiate one using  X  Cyclically, read a few transactions from the database DB u t . For each transaction T ,andrule r = X  X  Y,  X   X 
C which was generated after T was last read: If X  X  T , increase r.count .If X  X  Y  X  T , increase r.sum .  X 
Once every few cycles:  X  Set  X  R u [ DB t ] to the set of rules r  X  C which their cor- X  For each r =  X  X  X  X, MinFreq  X   X  R u [ DB t ], i  X  X :if  X  For each r 1 = X  X  Y  X  X  i 1 } , X  ,r 2 = On receiving a Private-Scalable-Majority message relevant to rule r = X  X  Y,  X  , from a neighbor v : If r  X  C ,additto C .If r =  X  X  X  X  X  Y,  X   X  C ,add r to C as well. In any case, forward the message to the appropriate local Private-Scalable-Majority instance. k new database partitions than in the last query).
The second occasion is when u needs to generate new can-didates. In this case it will initiate SFE with the controller in order to discover, for each candidate whose oblivious coun-ters have changed, whether the rule is correct. The condi-tion to be evaluated in that case is that the value encrypted by  X  u enc is at least zero, and the differences between the current and last values encrypted by  X  v  X  N u  X  didates according to the criterion defined in the Majority-Rule algorithm.

Algorithm 1  X  Private-Scalable-Majority  X  X ivestheprivacy-preserving majority voting procedure we use. Algorithm 2  X  Private-Majority-Rule  X  is the main privacy-preserving dis-tributed mining algorithm presented in this paper.
Cryptography research offers a wide toolset which can be used to build provenly secure algorithms. However, the defi-nitions on which these tools are based are in some cases unfit for privacy-preserving data mining. The reasons for this are twofold: either the definitions improperly address common scenarios (e.g., multiple computations with minute changes in input), or they overstate the required privacy and by that enforce algorithms that are too computationally demanding to be implemented in a realistic setting.

In this paper we present an alternative for one of the fundamental cryptographic definition  X  trusted third party (TTP). Our alternative definition  X  k -TTP  X  naturally gen-eralizes TTP. Hence, it is possible to use cryptographic meth-ods, leveraging their full power, subject to the new defini-tion. On the other hand, a k -TTP is far more flexible than a TTP. Therefore, it is permissive for scalable algorithms which are suitable for modern distributed systems such as emerging Data Grids. This is demonstrated by describing a k -secure distributed association-rule mining algorithm.
Further research will extend our definitions to other areas of cryptography, and present other private and scalable data mining algorithms. [1] O. Goldreich. Secure multi-party computation, 2002. [2] O. Goldreich, S. Micali, and A. Wigderson. How to [3] M. Kantarcioglu and C. Clifton. Privacy-preserving [4] Y. Lindell. Lower bounds for concurrent self [5] Y. Lindell and B. Pinkas. Privacy preserving data [6] H. Lipmaa. Survey of Secure Multiparty [7] R. Srikant and R. Agrawal. Fast algorithms for mining [8] L. Sweeney. k-anonymity: A model for protecting [9] J. Vaidya and C. Clifton. Privacy preserving [10] J. Vaidya and C. Clifton. Leveraging the  X  X ulti X  in [11] R. Wolff and A. Schuster. Association rule mining in
