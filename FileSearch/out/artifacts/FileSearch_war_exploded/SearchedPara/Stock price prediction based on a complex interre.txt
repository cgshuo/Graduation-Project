 Kanghee Park, Hyunjung Shin n 1. Introduction
Interests on the stock price prediction have been continued according to the public understanding in stock investment. Many studies on stock price prediction employ various economic factors such as oil prices, exchange rates, interest rates, stock price indexes in other countries, domestic/global economic situations, etc. ( Huang et al., 2008 ; Liu et al., 2009 ; Amilon, 2003 ; Chen et al., 1986 ). Methods for stock price prediction are diverse. Time series analysis is one of the most frequently adopted methods:
Jeantheau (2004) predicted stock prices using an ARCH model, and Amilon (2003) and Liu et al. (2009) proposed a prediction method using a GARCH model based on the Skewed-GED Dis-tribution for Chinese stock markets ( Liu et al., 2009 ; Amilon, 2003 ). These methods assume that the future data will be varied as similar to those of the past. It is true, and a reasonable result can be obtained from time series analysis if given time series data are originated from natural phenomena, such as the numbers of sunspot, rain-falls, temperature, and so on. However, if data are given from economic or financial factors, it is difficult to expect reasonable prediction performance because of reciprocal and complex influences among the factors.
 For example, Fig. 1 shows a case which considers KOSPI and Won-Dollar exchange rate to predict the stock price of Hyundai
Motors. In Span A, the stock price of Hyundai Motors shows a similar pattern as rising and falling of exchange rate. In other words, this span is largely affected by exchange rate. However, in
Spans B and D, the stock price of Hyundai Motors appears to be similar to a pattern of rising and falling in KOSPI rather than exchange rate. In the meantime, in Span C, it is difficult to find interrelations between KOSPI, exchange rate and the stock price of Hyundai Motors. This means that the stock price for Hyundai
Motors is affected not only by these two indexes but also by other external indexes. Like this, stock price may be affected by various indexes. But influences by any specific index are not persistent. In addition, the influence by a stock price affects other financial X  economic indexes and often returns to the stock price itself. This phenomenon also occurs for other financial X  X conomic factors.
With time series analysis, however, there are methodological limitations to implement the reciprocal and complex influences among the factors into model formulation ( Kim, 2003 ; Park et al., 2011 ). On the other hand, many studies on the stock price prediction have also been conducted in the machine learning domain. The artificial neural network (ANN) and support vector machine (SVM) methods have been frequently used as a typical model ( Huang et al., 2005 ; Cao et al., 2005 ; Chen et al., 2003 ). Tay and Cao (2001) proposed a method that introduces financial time series data to the SVM, and Kanas (2003) attempted the predic-tion of the S&amp;P500 index using the ANN model ( Tay and Cao, 2001 ; Kanas, 2003 ). Also, Yang et al. (2001) proposed an early warning system of commercial bank loan risks using the ANN model, and Bekiros and Georgoutsos (2008) analyzed that how uncertain news, which show a difficulty in identifying bullish and bearish factors, affect the NASDAQ index using the ANN model ( Yang et al., 2001 ; Bekiros and Georgoutsos, 2008 ; Tsang et al., 2007 ). The methods using ANN and SVM may include the interrelation between the stock price and these factors in model-ing. However it is still insufficient to explicitly formalize the mutual and complicated interrelation between the factors. As shown in Fig. 2 (a), ANN and SVM can represent how interest rates, exchange rates, and oil prices affect stock prices primarily.
However, it is somewhat difficult to express how the interests rates affect the exchange rates and then how these changes affect the next situation, i.e., how the second, third, and additional higher order interrelations affect the stock prices eventually. In addition, it is not easy to identify how the changes in stock prices caused by such a sequential process re-affect these factors later.
To solve this limitation, therefore, we propose to employ semi-supervised learning (SSL) which is a most recently emerged category of machine learning algorithms ( Zhu, 2005 ; Shin et al., 2010 ). SSL defines the interrelation between factors to a network as illustrated in Fig. 2 (b). SSL can consider the reciprocal and complex interrelation between factors based on a network. It connects individual factors via edges weighted by similarities between factors. Reciprocal and cyclic influences are delivered through the edges, and finally reach to the target factor  X  stock prices. The proposed SSL model is validated on the stock prices of 200 individual companies listed to KOSPI from January 2007 to August 2008.

This paper consists of five sections. Section 2 describes the methodology of SSL. Section 3 proposes a method of applying SSL to stock price prediction problem. Section 4 represents experi-ments and the results. Finally, Section 5 shows the conclusion of this study. 2. Semi-supervised learning (SSL)
Most recently, a category of machine learning algorithms, known as semi-supervised learning (SSL) has emerged, the main strength of which is that it allows taking advantage of the strengths of both supervised learning and unsupervised learning ( Chapelle et al., 2006 ; Zhu, 2008 ). The primary goal of supervised learning is to build accurate classifiers or regressors using labeled data. On the other hand, unsupervised learning is usually employed to dis-cover data structure from unlabeled data. In semi-supervised learning, meaningful representation of complicatedly structured data is identified from unlabeled data, and then the decision or regression function is achieved on both labeled and the unlabeled data, which is smooth with respect to the underlying geometry.
SSL is regarded as a more pragmatic learning scheme since many practical domains are in such a situation that there is a large supply of unlabeled data but limited labeled data which can be expensive, difficult, and time-consuming to generate. Many related researches have shown validity of SSL in a number of application domains such as spam filtering ( Zhu, 2005 ), document categorization ( Shin and Tsuda, 2006 ), video surveillance ( Shin et al., 2007 ), text classification ( Subramanya and Bilmes, 2008 ), text chunking ( Ando and Zhang, 2005 ), gene expression data classification ( Gong and Chen, 2008 ; Bair and Tibshirani, 2004 ), webpage classification ( Liu et al., 2006 ), etc. In those literatures,
SSL is often compared with the representative models of super-vised learning, and shows its superiority over them thanks to its capability of learning from only a few labeled data utilizing a large amount of unlabeled data. There has been a whole spectrum of interesting ideas on how to learn from both labeled and unlabeled data, e.g., the expectation-maximization based approach ( Nigam et al., 1999 ), self-training ( Yarowsky, 1995 ), co-training ( Blum and Mitchell, 1998 ), Transductive support vector machines ( Joachims, 1999 ), and the graph-based approaches such as graph mincuts ( Blum and Chawla, 2001 ), harmonic approach ( Zhu et al., 2003 ), local and global consistency ( Zhou et al., 2004 ), etc. Among several types of SSL algorithms, a graph-based SSL is employed in our study ( Shin et al., 2010 ; Shin et al., 2007 ).

In graph-based SSL algorithm, a data point x i A R M ( i  X  1, represented as a node i in a graph, and the relationship between data points is represented by an edge where the connection strength from each node j to each other node i is encoded as w of a weight matrix W ( Zhou et al., 2004 ). The labeled nodes have tion,?) have zeros y u  X  0( u  X  L  X  1, y ,L  X  U ). Fig. 3 presents a graphical representation of SSL.

A weight w ij can take a binary value (0 or 1) in the simplest case. Often, a Gaussian function of Euclidean distance between points with length scale s is used to specify connection strength: w  X  8 &lt; :  X  1  X 
Usually, an edge i j is established when node i is one of k-nearest neighbors of node j or node i is within a certain Euclidean distance r , k x i x j k o r . The algorithm will output an n -dimensional real-valued vector f  X  X  f T l f T u T  X  X  f 1 , ... , f L , f be thresholded to make label predictions on f L  X  1 , y , f learning. It is assumed that f i should be close to the given label y labeled nodes (loss condition) and overall, f i should not be too different from its adjacent nodes f j (smoothness condition). One can obtain f by minimizing the following quadratic functional:
Min
Laplacian, is defined as L  X  D W ,D  X  diag  X  d i  X  ,and d first term corresponds to the loss function in terms of condition (a), and the second term represents the smoothness of the predicted outputs in terms of condition (b). The parameter m represents trades between loss and smoothness. The solution to (2) is obtained as f  X  X  I  X  m L  X  1 y ,  X  3  X  where I is the identity matrix. 3. Proposed method
To apply the graph-based SSL to time series prediction, we design a method of graph representation for time series data, and a procedure for obtaining predicted values from the graph.
Assume that many stock prices are given as the input for the prediction problem for that of Hyundai Motors: the stock prices of
LG Chem and KIA Motors, WTI intermediate oil price, other external factors, etc . To apply SSL to this problem, the original SSL graph in Fig. 3 is re-designed to a graph as in Fig. 4 .
The nodes in the graph represent the factors that influence the stock price of Hyundai Motors, which are all time series variables.
Then the edge between any two nodes i  X  j stands for the similarity of the two sets of time series, represented as  X  w ij A W  X . The label  X  y on each node presents either  X  X p X  (  X  1) or  X  X own X  ( 1) of the time series at time point t . In the graph of Fig. 4 , the labels of Hyundai
Motors are not known yet at time point t , and hence are unlabeled. To estimate the label f t , the similarity matrix of SSL was calculated at time point t 1, W t 1 .

At time t information for the factors would not be enough to calculate similarities among them. Therefore, in order to make a prediction at the current time point, the similarity matrix is structured by using the dataset at the previous time point which holds the nearest and newest information. Fig. 5 represents the process of generating W t 1 , and using it for the prediction for the time point t .

Based on this set-up, we explain how to measure the similarity  X  w ij  X  of a weight matrix W and how to set the value for label  X  y  X . 3.1. Similarity matrix
The design of the similarity matrix W plays a critical part in the aspect of performance when using SSL ( Shin et al., 2010 , 2007 ). In the matrix W, each element represents how strongly the two nodes are related, with larger elemental value being associated with greater nodal similarity. In the proposed method, the time-series data are transformed by building technical indicators (TIs).
TIs are frequently used in financial forecasting as they offer the advantages of removing the noise (oscillatory noise) inherent in time series and illustrating the underlying structure, i.e., the tendencies and structural factors affecting variation ( Kim, 2003 , 2006 ; Park et al., 2011 ; Shin et al., 2007 ). Stock prices and other economic indices exist as time series data by the nature of the variables, and each of them is defined as a sequence as X  X f x 1 , x 2 , ... , x i , ... , x t g ,  X  4  X  where t represents the current time point, and x t is the corre-sponding value. The existence of X t as time series data induces several problems in the direct application of SSL to the data. As shown in Fig. 2 , each of the nodes on the graph has its own time series, as shown in (4) . For instance, the Hyundai Motors node has X t and the LG chem mode also has X LGchem t . The problem is that it is difficult to draw the similarity between them directly from the two sets of series data. Therefore, individual time series are transformed into structural characteristics of time and factors for variation of individual series. Table 1 summarizes the TIs used in this study. The similarity between the two nodes is measured by using the seven-tuple vector S t  X  { s 1 , s 2 composed of MA, BIAS, OSC, ROC, K, D, and RSI. In other words, all nodes in Fig. 4 are represented by seven-tuple vectors, resulting in
Fig. 6 . The values of similarities between the nodes are calculated in the form of seven-tuple vector by following Eq. (1) .
Using the TIs enables the time series data to be transformed into TIs-type data, while maintaining the time associations of the series, and thus eases their application to SSL. 3.2. Label
The label on the node in the SSL graph in Fig. 4 is designed to explain whether the predicted value of the corresponding variable is thumbs-up or down. It can be formulated as follows: y  X  sign  X  x t MA 5  X  x t  X  X  :  X  5  X 
For instance, if the total amount of the Hyundai Motors X  stock price ( t ) exceeds the 5-day moving average, (5) will give a  X  y  X  X  1 X  label. On the contrary, the node is labeled as  X  y t for the opposite case. And  X  y t  X  0 X  if there is no information about the movement of the corresponding time series at time point t ; the label is to be predicted. In the proposed method, we set the label of the target variable to  X 0 X . Given label y t , Eq. (3) provides the predicted value f t for every node, which can take on a real number unlike the values of label y t .

If  X  f t 4 0 X , it means the stock price will increase relative to the average of the MA(5), therefore one can take the position of  X  X  X uy X  X  , s , s , s , s , s for the stock. On the other hand, one can take the position of  X  X  X ell X  X  otherwise. This procedure is described in Fig. 7 . 3.3. Process summary
The proposed model is summarized as following. First, the stock price and financial X  X conomical indexes are collected by the time t .
Here, indexes whose values are known at time t are used for input variables and other unknown variables become target variables which are to be predicted. Second, each index is converted into seven-tuple vector by technical indicators transformation. Third, similarity matrix is structured by calculating Eq. (1) in the form of seven-tuple vectors. The matrix is calculated based on the dataset up to the previous time point ( Section 3.1 ). Fourth, the labels of the indexes whose values are known at time t are calculated ( Section 3.2 ). Finally, the up/down movements of the unknown indexes are predicted using the similarity matrix and the labels. Fig. 8 briefly shows the procedure mentioned above. 4. Experiment 4.1. Data
The data used in this experiment was presented by a total of 403 daily data points from January 2007 to August 2008. The factors employed as variables were the major global economic indexes, such as Dow-Jones average (DOW), National association of securities dealers automated quotations (NASDAQ), Japanese stock market index (NIKKEI), Hang seng index (HSI), Shanghai composite index (SSE), Taiwan stock exchange corporation (TSEC), Financial times security exchange (FTSE), Deutscher aktien index (DAX), continuous assisted quotation index (CAC), Bombay stock exchange portmanteau of sensitive and index (BSE_SENSEX), Indice bovespa (IBOVESPA), Australia all ordinaries index (AORD), Korea composite stock price index (KOSPI), exchange rate (KRW-USD), the west Texas intermediate oil price (WTI), and the certificate of deposit (CD). Also, the stock prices of 200 companies listed to KOSPI200 were included. Table A1 ( Appendix A ) shows the list of these 200 companies. Fig. 9 shows a summary of these companies based on 18 different industry sectors.

A total number of 216 time series variables were employed in this study: 200 companies listed to KOSPI200 and 16 financial X  economical indexes. Assuming that 16 financial X  X conomical indexes were known at time t, they were used as input variables and the remaining individual stock prices were set as target variables. Note that similarities between the 216 indexes were calculated using the datasets up to the previous time point t 1. 4.2. Experimental setting
The SSL model proposed in this experiment was compared with the ANN and SVM models. The ANN model used a 3-layered MLP-structure. The SVM model used an RBF kernel function that has been known as an excellent performance model relatively. More details on SVM and ANN are described in Appendix B . A total of 403 daily data points were used for experiment.
From January 2007 to May 2007, 103 daily data points were determined as training and validation sets. 20% of the random data points from the period were used for the specifications of the models and parameters. From June 2007 to August 2008, 300 daily data points were reserved for out-of-sample (test) evalua-tion and comparison of performances among the three models ( Kim, 2003 ; Huang et al., 2005 ; Liu et al., 2009 ; Han and Kamber, 2006 ; Pai and Lin, 2005 ). For the test period, the performance of
SSL was measured using a rolling forecast method which predicts a point of t  X  1 using the data from 1 to t , and similarly makes one-step-ahead predictions by moving forward the window (of size t ) to the end of the test period ( O X  X onnor et al., 2000 ). For the ANN and SVM models, the training set is very insufficient if the rolling forecast is applied. And both models are known to show better performance when the training set gets larger. Therefore, instead of removing the oldest data point from the training window, it was appended to the training set whenever the one-step-ahead prediction was made. As shown in Fig. 10 , the training period employed in ANN and SVM was gradually increased, whereas that of SSL was fixed to the window size of t . The test period was dissected into 30 sections which have 10 test daily data points. The result will be shown for each of 30 test sections.
The parameters that are to be determined for the SSL model are kand m and these parameters represent the number of neighbor node presented in Eq. (1) and the loss-smoothness tradeoff presented in Eq. (2) , respectively. Also, the parameter values used in this experiment were determined as an optimal combination for the validation set presented in the range of f k , m g A f 2 , 3 , 4 , 5 g the hidden node in ANN was determined in the range of {3 X 50} ( Kim, 2003 ) and the parameters of kernel width (gamma) and misclassification tradeoff ( C ) in SVM were determined as an optimal combination of the values in the range of f gamma , C g
A ( Burges, 1998 ). 5. Results 5.1. Comparison of accuracy
To measure the prediction performance, the area under the curve (AUC), which is defined as the area under the receiver operating characteristic (ROC) curve, is used ( Hanley and McNeil, 1982 ; Gribskov and Robinson, 1996 ). The ROC curve plots true positive rate as a function of false positive rate for differing classification thresholds as shown in Fig. 11 . The AUC measures the overall quality of the model for all possible values of threshold rather than the quality at a single value of threshold. The closer the curve follows the left-hand border and then the top-border of the ROC space, the larger value of AUC the model produces; i.e., the more accurate the model is.

Fig. 12 shows the graph of the values of AUC for the three models used in the 30 test sections. Points presented in the graph represent the average section values of AUC in which a section has 10 daily data points. The average AUC values in SVM and ANN for the total 30 sections were 0.58( 7 0.08) and 0.51( 7 0.01), respectively, but the value in SSL was 0.72( 7 0.05). Although ANN represented low volatility based on the standard deviation of 0.01, the AUC value was small compared to the other models. In the case of SVM, although it showed partially higher AUC values than SSL, it represented a very high deviation in its accuracy, whereas, SSL showed high accuracy in most sections compared to that of ANN and SVM. A t -test was applied to verify the significance that SSL represents better performance statistically than that of SVM and ANN. As a result, the difference in the performance between them showed statistical significance as shown in the upper right box in Fig. 12 .

The outperformance of SSL model to other ones comes from its adaptable structure to changes in relations depending on time. In other words, the relations shown in Fig. 4 between financial X  economic factors may vary at each of the 300 time points and whenever it varies the similarity matrix for SSL reflects it. This is proved by looking into the immediate changes in weight values for the 300 time points. Fig. 13 exemplifies the typical changes in weight of 10 companies (out of 200 companies) including Hyun-dai Motors and other 9 companies, POSCO, Samsung Electronics,
LG Chem, Hyundai Mobis, Hyosung, Ottogi, Bing-Grae Co., Hyun-dai Development, and Lotte Samkang Co. The value in the right side of the subfigure is a mean of weight ( m ) during the period while the upper and the lower lines indicate m 7 3 s . As shown in the figure, the weight varies at every time point, but the width of the changes is bounded within m 7 3 s . This implies that the relations are changing and yet stable. On the other hand, both
ANN and SVM have difficulties to address the varying relations due to its innate model structure. 5.2. Comparison of profit
A stock price prediction model has to ensure both accuracy and earning rate while the stock price prediction model is on real investment ( Barber et al., 2001 ). To calculate ROI, the benefit (return) of an investment is divided by the cost of the investment; the result is expressed as a percentage or a ratio. ROI measure is calculated by the following: ROI  X  sell order price buy order price buy order price 100  X  %  X  :
Fig. 14 shows Hyundai Motors X  buy and sell strategy as an example out of KOSPI200 listed companies. The upper panel in the figure shows the stock price and 5-day movement average value. Also, the lower actual sign represents the values calculated by Eq. (5) through reflecting the number of crosses in two lines. The lower panel shows actual sign and the predicted sign by SSL. The transaction was implemented according to such prediction values using the  X  X  X ne-point buy and sell strategy X  X  presented in Fig. 7 ( Jang and Lai, 1994 ). Table 2 shows the comparison of ROI according to the prediction values of the three models. ROI is calculated by each 30 test sections. Among the stock prices of 200 companies, the ROIs of the 10 companies mentioned above are presented ( Table 2 shows only four companies X  result and the other results are attached in Appendix C ). In the table, the ROI of the Buy-and-Hold (BH) is used as a reference earning rate of which position is maintained without any transactions after the purchase at the start point. The lowest on-line commission 0.015% was considered as the trading commission when calculat-ing ROI. Table 3 summarizes 10 companies X  average ROI. The average of 10 companies X  earning rates of the SSL, SVM,
ANN and the BH were  X  16.33%, 1.18%, 4.14%, and 4.78%, respec-tively. Comparing ROI by sections and companies, SSL showed the best ROI 158 times, SVM showed the best ROI 73 times, and ANN showed the best ROI 69 times. Thus, it was verified that SSL showed excellent performance in its earning rates. 6. Conclusions
In this study, a stock prediction method using time series data to SSL was proposed. The proposed method has the advantage that does not predict stock prices by considering the time series characteristics of the stock price in businesses like the conven-tional models but makes possible to predict the stock price using a network based on the fluctuation in other companies X  stock prices and the economic index that affect the change in stock prices. Regarding the technical issue in the proposed method, the method used SSL and that leads to improve its predictability by including not only the influences on input variables and target variables but also the interrelation between input variables. Based on the combination of these advantages, it was possible to obtain the values of AUC and ROI as 0.72 and 16.33% respectively. The earning rate of the proposed method was compared using a  X  X  X ne-point buy and sell strategy X  X  that has been considered as the simplest investment method. In future, it is expected that the earning rate will be improved as more various investment strategies are considered based on these results. In addition, the method proposed in this study can apply for predicting the fluctuation in stock prices for various stock items. Therefore, it is possible to expect profits and stabilities in investments as the results obtained in this study are combined with a portfolio optimization method.
 Acknowledgments
The authors would like to gratefully acknowledge support from Post Brain Korea 21 and the research Grant from National
Research Foundation of the Korean Government (2010-0007804/ 2012-0000994).

Appendix A see Appendix Table A1 .
 Appendix B Artificial neural network (ANN)
An ANN is an analytical system inspired by the structure of biological neural networks and their way of encoding and solving problems. We employed a well-analyzed and frequently used ANN architecture known as multi-layer perceptron with back-propagation algorithm. The ANN comprises of three types of layers: the input layer, hidden layers, and the output layer. The nodes in the input layer supply input signals (activation patterns from outside the system) to the nodes in the hidden layer via weighted connections. The overall result of the model is repre-sented by the nodes in the output layer which send output signals (a weighted sum of the signals from the hidden nodes) on the basis of a transfer function. In ANN, the accuracy of the model often depends on the structure, i.e. the number of hidden nodes, and the initial weights associated with the connections between the nodes. Generally, the number of hidden nodes is selected by a trial-and-error fashion and the initial weights are randomly chosen. ANN is used to determine a set of weights w that minimize the total sum of squared errors: E  X  w  X  X  1 2
Note that the sum of squared errors depends on w because the predicted class is a function of the weights assigned to the hidden and output nodes.
 Support vector machine (SVM)
SVM involves finding an optimal decision boundary i.e., max-imizing the margin by finding the largest achievable distance among the separating hyperplane and the data points on either side. The classification can be represented by considering a set of i  X  1, y ,  X  . Here x A X and y A Y where  X  Y  X  represents the set of class labels, e.g., for binary classification Y  X  X  { 1,  X  1}. In a typical binary classification, training data points from two differ-ent classes are separated by a hyperplane. The separating hyper-plane can be linear or non-linear. For linear classification, SVM computes the linear decision function in the central gap of the two classes by correctly classifying all the training data points and placing the decision function as far from the given data points as possible, to lessen the possibility of false prediction for the unseen data points. If classes are not linearly separable because of noisy data (measurement errors, uncertainty in class membership, etc.), we can still use the linear classifier with an error tolerance. In such a case, the aim is to find a balance between margin maximization and misclassification minimization. SVM solves the following quadratic programming problem to produce the maximum margin between the two classes: min Y  X  w ! , x  X  X  1 2 J w ! J 2  X  * s : t : y i  X  w ! : F  X  x ! i  X  X  b  X  Z 1 x i , x i Z 0 , i  X  1 , ... :: , M :  X  B1  X 
The parameter C in Eq. (B1) is the penalty for misclassifying a data point. The higher the value of C , the more the SVM training is compelled to avoid classification errors. The parameter x non-negative slack variable, which allows a certain level of misclassification for an inseparable case. If the data points are separated by a non-linear hyperplane because of some intrinsic property of the problem, it is more appropriate to map the input feature space to a high-dimensional feature space where the data points are separated by a linear hyperplane. This mapping process j is conducted by kernel functions. Among many types of kernel functions, the RBF kernel k  X  -used. The parameter values of the tradeoff C and the kernel width g are specified by users, and affect the performance of SVM.
Appendix C see Appendix Table C1 .
 References
