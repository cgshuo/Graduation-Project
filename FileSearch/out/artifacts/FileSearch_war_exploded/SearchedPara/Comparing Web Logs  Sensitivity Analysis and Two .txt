 Different works describe the results of the user studies centered on the search behav-ior on the Web which analyze different search engines logs (e.g. [1, 2, 5]), and some metrics of the search behavior reported in these studies have the same name (session compare these results to evaluate the differences between the user interactions with different engines. However, no work is devoted to the techniques of the Web log analysis and to the comparison techniques. As a result, we cannot be sure that a direct comparison of the reported results of the differently conducted studies is well grounded. We can X  X  be sure that the differences discovered in the comparative analy-sis are not artifacts resulting from the differences in the methods used in the compared studies. This paper tries to fill this gap. 
The differences of the results may be caused by the combinations of the features of interfaces, query languages and search methods used by the different search engines, the differences in the contexts, the cultural differences, and the differences between the techniques used in different studies . The latter instrumental factor has been out of a rigorous investigation so far. If this factor may explain only minor differences (i.e. those smaller than the differences between the reported results) we may confine our-selves to comparison of the reported results. On the contrary, if the method varying differences, then (1) the role of this factor should be taken into account in the com-parison of the reported results, and (2) this is a sound reason to conduct a cross-analysis of the logs. 
In the Web log analysis, the sources of the results differences are controllable vari-ables assigned by the researchers. These are a client discriminator to exclude non-human users (agents) and multi-user clients (local networks), and a temporal cut-off to segment a time series of user transactions into temporal sessions. Sensitivity of the calculated metrics to these variables is investigated in Chapter 4. For each log we investigate the effect of the controllable variable s on the considered metrics. Since this influence is significant we should us e approaches alternative to the direct com-parison of the reported results. 
In Chapter 5, we consider the cross-analysis of the logs , in which the same tool un-der the same conditions analyses logs of di fferent search engines. However, the direct cross-analysis of the logs is an expensive procedure and its applications are limited by the fact that the explored logs of not all search engines are available. 
In Chapter 6, we describe another approach  X  to take into account the values of controllable variables used in the different log studies and to compare the accordingly corrected reported results rather the reported results themselves. This indirect cross-analysis of the reported results is an easy-accessible procedure based on the reported results: if each study reports the values of the controllable variables we can use corre-sponding values of the correction factors to correct and to compare the cognominal metrics reported in these studies. The sensitivity analysis allows to estimate the inter-val values of the correction factors. The knowledge about the user search behavior that can be obtained from the Web transaction logs radically differs from the knowledge extracted from the logs of ear-lier non-HTTP-based information retrieval systems. The limits of the Web log analy-sis result of: 1) impossibility to reliably detect an individual human user; 2) the Web logs contain transactions rather than queries segmented into search sessions. 
To avoid these problems the Web log analysis uses two controllable variables: 1) a client discriminator (usually measured in transactions) to exclude local networks and agents conducting more transactions than a client discriminator ( CD ) value and 2) a temporal cut-off ( TCO ) to segment a client transactions into temporal sessions. These controllable variables are arbitrary and differently set in different Web log studies. about two TCO values (30 min and 1 hour). In turn, the CD values used in the differ-ent log studies seem to be incomparable: CD may be measured either in unique que-ries or in transactions, it may be assigned to the entire observation period, while observation periods may vary from few hours to weeks, so CD values assigned for the whole periods are incomparable. In this paper, we distinguish unique queries submitted by a client during some time interval (e.g. during the whole observation period) and transactions . While transac-tions are frequently referred to as queries we avoid doing this. We consider only one of possible session classes, a temporal session as any sequence of the single user transactions with the same search engine cut from the previous and successive ses-sions by TCO interval. To analyze logs we developed the Crossover mobile programs. This pack is used in both the sensitivity analysis and the direct cross-analysis of logs. The main program of the Crossover is adjustable to the specific search engine query languages and log formats. 
The logs of two search engines were used: the Russian-language Yandex (7 days, 2005, 175,000 users accepted cookies), and the Excite : 1999 log fragment (8 hours, 537,639 clients) and 2001 log sample (24 hours, 305,000 clients). The Excite data were used to elaborate the results comparable with both (a) the Yandex results yielded by the same analyzer and (b) results previously yielded on the same logs . 
The observation periods of different log samples are different. When CD is meas-ured in unique queries, it creates a problem. E.g., what a compatible CD value should be assigned to the week sample if 10 unique queries are set for the 8-hour sample? To overlook this problem we use the sliding temporal window technique. We select a sliding window size T (not longer than the smallest observation period), assign certain client discriminator N (measured in unique queries or transactions) to this window and slide the window over time series of the client transactions comparing a number of client X  X  queries transactions covered by the window with N . If in some position of the window this number is bigger than N we exclude this client as an agent. 
In this paper, CD is measured in unique queries covered by 1-hour sliding window. The metrics used in the Web log analysis are divided into 2 classes: (1) depending on both CD and TCO , and (2) depending only on CD . The  X  per transaction  X  metrics (a query length or fractions of some kind of queries, e.g., Boolean queries, queries con-taining quotations, etc.) don X  X  depend on TCO . The same metrics considered  X  per unique query  X  also don X  X  depend on TCO when we consider unique queries per client but these metrics depend when  X  X nique queries per session  X  are considered. 
All the metrics depend on the CD variable. Fig. 1 shows how several TCO -independent metrics are changed over unique queries (left) and transactions (right) submitted during the entire observation period: the metric value m(n) on the figure corresponds to all clients the number of queries (transactions) submitted by whom is not bigger than n . The behavior of the fraction of AND-queries is surprising, espe-cially as a function of the number of transactions. 
Table 1 reports the  X  X nit X  values of some metrics corresponding to the combination &lt; TCO =15 min, CD =1 unique query per 1-hour sliding window&gt;. We use these unit values to normalize the values corresponding to combinations of longer TCO s and bigger CD s. For example, if the  X  X verage session length X  metric equals to 1.53 trans-actions for &lt; TCO =15 min, CD =1 unique query per 1-hour sliding window&gt; and it equals to 2.11 transactions under &lt; TCO =30 min, CD =3 u. q. per 1-hour window&gt; combination then the normalized value of this metric is 2.11/1.53 = 1.38. Table 2a shows the normalized values of  X  X ransactions per temporal session X  metric, which depends on both TCO and CD . Table 2b shows values of TCO -independent metrics. TCO (min) 
CD (unique queries) 1 1 1.03 1.05 1 1.03 1.04 1 1.04 1.07 2 1.19 1.25 1.28 1.21 1.26 1.29 1.16 1.23 1.28 3 1.31 1.38 1.44 1.35 1.42 1.47 1.28 1.37 1.45 5 1.44 1.53 1.61 1.52 1.62 1.70 1.43 1.57 1.67 
The influence of TCO is predictable: the greater th is cut-off value, the longer a temporal session and the greater are corresponding metrics. On the other hand, as seen from Table 2a this influence is small. Thus, we can directly compare the reported results of the studies, which differ only by the TCO values. However, the results sig-nificantly depend on the assigned CD value (Tables 2a and 2b). 
The variations of two controllabl e variables, especially the CD may explain 30-50% of the differences between metric values. These variations are of the same order of magnitude as the differences between the results of the Excite , AlataVista , Fireball and FAST logs studies, which are considered as significant [3, 5]. 
The results of the sensitivity analysis show that the direct comparison of the re-ported results of the different log studies is unreliable. This is a reason for conducting a direct cross-analysis of the logs . On the other hand, the sensitive analysis suggests a way of comparison of the reported results more reliable than the direct comparison. Undoubtedly reliable results are produced by a cross-analysis of logs , in which the same tool under the same or maximum similar conditions analyzes the logs. To con-duct the cross-analysis Crossover study we use our Crossover tool. Tables 1 and 3 2005 logs. The Yandex users (Table 1) use Boolean operators very rarely but we should take into account a usage context : the Yandex help recommends the users not to use Boolean operators. When compared, the results of the Crossover study and the results of the Excite project produced on the same Excite logs (Table 3) appear to be close within the limits induced by controllable variables. terms/query 2.4 2.40 2.46 2.49 2.52 2.6 2.51 2.60 2.64 2.69 AND 3% 2.8% 3.0% 3.1% 3.1% 10% all 8.3% 9.2% 9.4% 9.6% 
PLUS 2% 2.1% 2.3% 2.5% 3.0% Boolean 2.1% 2.8% 2.9% 3.3% quotations 5% 5.8% 6.3% 6.5% 6.9% 9% 6.4% 7.2% 7.7% 8.4% As mentioned above, the sensitivity analysis suggests a way to compare the reported results: to re-calculate the results as if they had been calculated under the same com-bination of controllable variables. Let some metric m be estimated for two combina-directly compares m ( TCO 1 , CD 1 ) and m ( TCO 2 , CD 2 ). Alternatively, the indirect cross-m ( TCO 2 , CD 2 )/ c m ( TCO 2 , CD 2 ), where c m ( TCO , CD ) is a conversion function analogous to functions tabulated in Tables 2a and 2b. While the stability of these functions esti-mated on the different logs is an issue, the values estimated on the 8-hour Excite -99 fragment and the week Yandex sample are surprisingly similar (Tables 2a and 2b). 
Let X  X  consider an example. Let one study report 5% of queries containing PLUS , and the other speaks about 4%. The studies use correspondingly the 5 and 1 unique query per 1-hour sliding window CD values. Since CD =5 corresponds to [1.28; 1.60] interval value for the PLUS -fraction metric (Table 2b) we should compare 4% with the interval value [5/1.60; 5/1.28]  X  [3.1; 3.9]. Thus, a fraction of the PLUS queries is bigger in the study reported the smaller value. To make a step to valid comparison of the different search engines logs we introduced and applied the techniques of the sensitivity analysis and two types of the cross-analysis . The sensitivity analysis shows significant varying of the metrics values depending on the controllable variables of the Web log analysis. The differences caused by controllable variables are of the same order of magnitude as the differences between the metrics reported in different studies. The direct comparison of the re-ported results is an unreliable approach. To overcome the method-dependency of the direct comparison of the reported results we introduce and evaluate an expensive cross-analysis technique of the direct comparison of the logs and an easy-accessible indirect comparison of the reported metrics , which corrects the reported values of the metrics accordingly to the used values of the controllable variables. Acknowledgements. Finally, the author feels obliged to thank Ilya Segalovich, Ian Ruthven and anonymous reviewers for helpful comments. 
