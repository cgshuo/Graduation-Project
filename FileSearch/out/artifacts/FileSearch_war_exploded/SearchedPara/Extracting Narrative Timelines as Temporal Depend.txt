 There has been much recent interest in identifying events, times and their relations along the timeline, from event and time ordering problems in the Temp-Eval shared tasks (Verhagen et al., 2007; Verhagen et al., 2010), to identifying time arguments of event structures in the Automated Content Extraction pro-gram (Linguistic Data Consortium, 2005; Gupta and Ji, 2009), to timestamping event intervals in the Knowledge Base Population shared task (Artiles et al., 2011; Amig  X  o et al., 2011).

However, to date, this research has produced frag-mented document timelines, because only specific types of temporal relations in specific contexts have been targeted. For example, the TempEval tasks only looked at relations between events in the same or ad-jacent sentences (Verhagen et al., 2007; Verhagen et al., 2010), and the Automated Content Extraction pro-gram only looked at time arguments for specific types of events, like being born or transferring money .
In this article, we propose an approach to temporal information extraction that identifies a single con-nected timeline for a text. The temporal language in a text often fails to specify a total ordering over all the events, so we annotate the timelines as tem-poral dependency structures, where each event is a node in the dependency tree, and each edge between nodes represents a temporal ordering relation such construct an evaluation corpus by annotating such temporal dependency trees over a set of children X  X  stories. We then demonstrate how to train a time-line extraction system based on dependency parsing techniques instead of the pair-wise classification ap-proaches typical of prior work.

The main contributions of this article are:  X  We propose a new approach to characterizing  X  We produce an annotated corpus of temporal  X  We design a non-projective dependency parser The following sections first review some relevant prior work, then describe the corpus annotation and the dependency parsing algorithm, and finally present our evaluation results. Much prior work on the annotation of temporal in-formation has constructed corpora with incomplete timelines. The TimeBank (Pustejovsky et al., 2003b; Pustejovsky et al., 2003a) provided a corpus anno-tated for all events and times, but temporal relations were only annotated when the relation was judged to be salient by the annotator. In the TempEval compe-titions (Verhagen et al., 2007; Verhagen et al., 2010), annotated texts were provided for a few different event and time configurations, for example, an event and a time in the same sentence, or two main-clause events from adjacent sentences. Bethard et al. (2007) proposed to annotate temporal relations one syntactic construction at a time, producing an initial corpus of only verbal events linked to events in subordinated clauses. One notable exception to this pattern of incomplete timelines is the work of Bramsen et al. (2006) where temporal structures were annotated as directed acyclic graphs. However they worked on a much coarser granularity, annotating not the order-ing between individual events, but between multi-sentence segments of text.

In part because of the structure of the available training corpora, most existing temporal informa-tion extraction models formulate temporal linking as a pair-wise classification task, where each pair of events and/or times is examined and classified as having a temporal relation or not. Early work on the TimeBank took this approach (Boguraev and Ando, 2005), classifying relations between all events and times within 64 tokens of each other. Most of the top-performing systems in the TempEval competitions also took this pair-wise classification approach for both event-time and event-event temporal relations (Bethard and Martin, 2007; Cheng et al., 2007; UzZa-man and Allen, 2010; Llorens et al., 2010). Systems have also tried to take advantage of more global in-formation to ensure that the pair-wise classifications satisfy temporal logic transitivity constraints, using frameworks such as integer linear programming and Markov logic networks (Bramsen et al., 2006; Cham-bers and Jurafsky, 2008; Yoshikawa et al., 2009; Uz-Zaman and Allen, 2010). Yet the basic approach is still centered around pair-wise classifications, not the complete temporal structure of a document.

Our work builds upon this prior research, both improving the annotation approach to generate the fully connected timeline of a story, and improving the models for timeline extraction using dependency parsing techniques. We use the annotation scheme introduced in more detail in Bethard et. al. (2012), which proposes to annotate temporal relations as de-pendency links between head events and dependent events. This annotation scheme addresses the issues of incoherent and incomplete annotations by guaran-teeing that all events in a plot are connected along a single timeline. These connected timelines allow us to design new models for timeline extraction in which we jointly infer the temporal structure of the text and the labeled temporal relations. We employ methods from syntactic dependency parsing, adapt-ing them to our task by including features typical of temporal relation labeling models. The corpus of stories for children was drawn from the fables collection of (McIntyre and Lapata, 2009) 1 and annotated as described in (Bethard et al., 2012). In this section we illustrate the main annotation princi-ples for coherent temporal annotation. As an example story, consider: Figure 1 shows the temporal dependency structure that we expect our annotators to identify in this story.
The annotators were provided with guidelines both for which kinds of words should be identified as events, and for which kinds of events should be linked by temporal relations. For identifying event words, the standard TimeML guidelines for anno-tating events (Pustejovsky et al., 2003a) were aug-mented with two additional guidelines:  X  Skip negated, modal or hypothetical events (e.g.  X  For phrasal events, select the single word that
For identifying the temporal dependencies (i.e. the ordering relations between event words), the anno-tators were instructed to link each event in the story to a single nearby event, similar to what has been observed in reading comprehension studies (Johnson-Laird, 1980; Brewer and Lichtenstein, 1982). When there were several reasonable nearby events to choose from, the annotators were instructed to choose the temporal relation that was easiest to infer from the text (e.g. preferring relations with explicit cue words like before ). A set of six temporal relations was used:
Two annotators annotated temporal dependency structures in the first 100 fables of the McIntyre-Lapata collection and measured inter-annotator agree-ment by Krippendorff X  X  Alpha for nominal data (Krip-pendorff, 2004; Hayes and Krippendorff, 2007). For the resulting annotated corpus annotators achieved Alpha of 0.856 on the event words, 0.822 on the links between events, and of 0.700 on the ordering rela-tion labels. Thus, we concluded that the temporal dependency annotation paradigm was reliable, and the resulting corpus of 100 fables 2 could be used to train a temporal dependency parsing model. We consider two different approaches to learning a temporal dependency parser: a shift-reduce model (Nivre, 2008) and a graph-based model (McDonald et al., 2005). Both models take as input a sequence of event words and produce as output a tree structure where the events are linked via temporal relations. Formally, a parsing model is a function ( W  X   X ) where W = w 1 w 2 ...w n is a sequence of event words, and  X   X   X  is a dependency tree  X  = ( V,E ) where:  X  V = W  X  X  Root } , that is, the vertex set of the  X  E = { ( w h ,r,w d ) : w h  X  V,w d  X  V, r  X  R =  X  ( w h ,r,w d )  X  E =  X  w d 6 = Root , that is, the  X  ( w h ,r,w d )  X  E =  X  (( w 0 h ,r 0 ,w d )  X  E =  X   X  E contains no (non-empty) subset of arcs 4.1 Shift-Reduce Parsing Model Shift-reduce dependency parsers start with an input queue of unlinked words, and link them into a tree by repeatedly choosing and performing actions like shifting a node to a stack, or popping two nodes from the stack and linking them. Shift-reduce parsers are typically defined in terms of configurations and a tran-sition system, where the configurations describe the current internal state of the parser, and the transition system describes how to get from one state to another. Formally, a deterministic shift-reduce dependency parser is defined as ( C,T,C F , I NIT , T REE ) where:  X  C is the set of possible parser configurations c i  X  T  X  ( C  X  C ) is the set of transitions t i from  X  I NIT  X  ( W  X  C ) is a function from the input  X  C F  X  C are the set of final parser configura- X  T REE  X  ( C F  X   X ) is a function that extracts a Given this formalism and an oracle o  X  ( C  X  T ) , which can choose a transition given the current con-figuration of the parser, dependency parsing can be accomplished by Algorithm 1. For temporal depen-dency parsing, we adopt the Covington set of transi-tions (Covington, 2001) as it allows for parsing the non-projective trees, which may also contain  X  X ross-ing X  edges, that occasionally occur in our annotated corpus. Our parser is therefore defined as: Algorithm 1 Deterministic parsing with an oracle. c  X  I NIT ( W ) while c /  X  C F do end while return T REE ( c )  X  c = ( L 1 ,L 2 ,Q,E ) is a parser configuration,  X  I NIT ( W ) = ([ Root ] , [] , [ w 1 ,w 2 ,...,w n ] ,  X  )  X  C F = { ( L 1 ,L 2 ,Q,E )  X  C : L 1 = { W  X   X  T REE (( L 1 ,L 2 ,Q,E )) = ( W  X  X  Root } ,E ) ex-The oracle o is typically defined as a machine learn-ing classifier, which characterizes a parser configu-ration c in terms of a set of features. For temporal dependency parsing, we learn a Support Vector Ma-chine classifier (Yamada and Matsumoto, 2003) using the features described in Section 5. 4.2 Graph-Based Parsing Model One shortcoming of the shift-reduce dependency parsing approach is that each transition decision made by the model is final, and cannot be revisited to search for more globally optimal trees. Graph-based models are an alternative dependency parsing model, which assembles a graph with weighted edges be-tween all pairs of words, and selects the tree-shaped subset of this graph that gives the highest total score (Fig. 2). Formally, a graph-based parser follows Algorithm 2, where:  X  W 0 = W  X  X  Root }  X  S CORE  X  (( W 0  X  R  X  W )  X  &lt; ) is a function  X  S PANNING T REE is a function for selecting a Algorithm 2 Graph-based dependency parsing E  X  X  ( e, S CORE ( e )) : e  X  ( W 0  X  R  X  W )) }
G  X  ( W 0 ,E )
The S PANNING T REE function is usually defined using one of the efficient search techniques for find-ing a maximum spanning tree. For temporal depen-dency parsing, we use the Chu-Liu-Edmonds algo-rithm (Chu and Liu, 1965; Edmonds, 1967) which solves this problem by iteratively selecting the edge with the highest weight and removing edges that would create cycles. The result is the globally op-timal maximum spanning tree for the graph (Geor-giadis, 2003).

The S CORE function is typically defined as a ma-chine learning model that scores an edge based on a set of features. For temporal dependency parsing, we learn a model to predict edge scores via the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; Crammer et al., 2006) using the set of features defined in Section 5. The proposed parsing algorithms both rely on ma-chine learning methods. The shift-reduce parser (SRP) trains a machine learning classifier as the or-acle o  X  ( C  X  T ) to predict a transition t from a parser configuration c = ( L 1 ,L 2 ,Q,E ) , using node features such as the heads of L 1 , L 2 and Q , and edge features from the already predicted temporal relations in E . The graph-based maximum spanning tree (MST) parser trains a machine learning model to predict S CORE ( e ) for an edge e = ( w i ,r j ,w k ) , using features of the nodes w i and w k . The full set of features proposed for both parsing models, de-rived from the state-of-the-art systems for temporal relation labeling, is presented in Table 2. Note that both models share features that look at the nodes, while only the shift-reduce parser has features for previously classified edges. Evaluations were performed using 10-fold cross-validation on the fables annotated in Section 3. The corpus contains 100 fables, a total of 14,279 tokens and a total of 1136 annotated temporal relations. As Feature SRP MST
Word
Lemma
Part of speech (POS) tag
Suffixes
Syntactically governing verb
Governing verb lemma
Governing verb POS tag
Governing verb POS suffixes
Prepositional phrase occurrence
Dominated by auxiliary verb?
Dominated by modal verb?
Temporal signal word is nearby?
Head word lemma
Temporal relation labels of a i and its leftmost and rightmost dependents
Temporal relation labels of a i  X  1  X  X  leftmost and rightmost dependents
Temporal relation labels of b 1 and its leftmost and rightmost dependents only 40 instances of OVERLAP relations were an-label matched, for evaluation purposes all instances of these relations were merged into the temporally coarse OVERLAP relation. Thus, the total number of OVERLAP relations in the corpus grew from 40 to 258 annotations in total.

To evaluate the parsing models (SRP and MST) we proposed two baselines. Both are based on the assumption of linear temporal structures of narratives as the temporal ordering process that was evidenced by studies in human text rewriting (Hickmann, 2003). The proposed baselines are:  X  LinearSeq : A model that assumes all events  X  ClassifySeq : A model that links each pair of The Shift-Reduce parser (SRP; Section 4.1) and the graph-based, maximum spanning tree parser (MST; Section 4.2) are compared to these baselines. 6.1 Evaluation Criteria and Metrics Model performance was evaluated using standard evaluation criteria for parser evaluations: Unlabeled Attachment Score (UAS) The fraction of events whose head events were correctly predicted. This measures whether the correct pairs of events were linked, but not if they were linked by the correct relations.
 Labeled Attachment Score (LAS) The fraction of events whose head events were correctly pre-dicted with the correct relations. This measures both whether the correct pairs of events were linked and whether their temporal ordering is correct. Tree Edit Distance In addition to the UAS and LAS the tree edit distance score has been recently in-troduced for evaluating dependency structures (Tsar-faty et al., 2011). The tree edit distance score for a tree  X  is based on the following operations  X   X  = DELETE delete a non-root node v in  X  with  X   X  = INSERT insert a node v as a child of u in  X   X  = RELABEL change the label of node v in  X  Any two trees  X  1 and  X  2 can be turned one into an-other by a sequence of edit operations {  X  1 ,..., X  n } . LinearSeq 0.830 0.581 0.689 0.549 ClassifySeq 0.830 0.581 0.689 0.549 MST 0.837 0.614  X  0.710 0.571 SRP 0.830 0.647  X  X  0.712 0.596  X  Taking the shortest such sequence, the tree edit dis-tance is calculated as the sum of the edit operation costs divided by the size of the tree (i.e. the number of words in the sentence). For temporal dependency trees, we assume each operation costs 1.0. The fi-nal score subtracts the edit distance from 1 so that a perfect tree has score 1.0. The labeled tree edit distance score (LTEDS) calculates sequences over the tree with all its labeled temporal relations, while the unlabeled tree edit distance score (UTEDS) treats all edges as if they had the same label. 6.2 Results Table 3 shows the results of the evaluation. The unlabeled attachment score for the LinearSeq base-line was 0.830, suggesting that annotators were most often linking adjacent events. At the same time, the labeled attachment score was 0.581, indicating that even in fables, the stories are not simply linear, that is, there are many relations other than BEFORE . The ClassifySeq baseline performs identically to the LinearSeq baseline, which shows that the simple pair-wise classifier was unable to learn anything beyond predicting all relations as BEFORE .

In terms of labeled attachment score, both de-pendency parsing models outperformed the base-line models  X  the maximum spanning tree parser achieved 0.614 LAS, and the shift-reduce parser achieved 0.647 LAS. The shift-reduce parser also outperformed the baseline models in terms of labeled tree edit distance, achieving 0.596 LTEDS vs. the baseline 0.549 LTEDS. These results indicate that de-pendency parsing models are a good fit to our whole-story timeline extraction task.

Finally, in comparing the two different depen-dency parsing models, we observe that the shift-reduce parser outperforms the maximum spanning tree parser in terms of labeled attachment score (0.647 vs. 0.614). It has been argued that graph-based models like the maximum spanning tree parser should be able to produce more globally consistent and correct dependency trees, yet we do not observe that here. A likely explanation for this phenomenon is that the shift-reduce parsing model allows for fea-tures describing previous parse decisions (similar to the incremental nature of human parse decisions), while the joint nature of the maximum spanning tree parser does not. 6.3 Error Analysis To better understand the errors our model is still mak-ing, we examined two folds (55 errors in total in 20% of the evaluation data) and identified the major categories of errors:  X  OVERLAP  X  BEFORE : The model predicts the  X  Attach to further head : The model predicts  X  Attach to nearer head : The model predicts the Table 4 shows the distribution of the errors over these categories. The two most common types of errors, OVERLAP  X  BEFORE and Attach to further head , account for 76.4% of all the errors.

The most common type of error is predicting a BEFORE relation when the correct answer is an OVERLAP relation. Figure 3 shows an example of such an error, where the model predicts that the Spendthrift stood before he saw , while the anno-tator indicates that the seeing happened during the time in which he was standing. An analysis of these OVERLAP  X  BEFORE errors suggests that they occur in scenarios like this one, where the duration of one event is significantly longer than the duration of an-other, but there are no direct cues for these duration differences. We also observe these types of errors when one event has many sub-events, and therefore the duration of the main event typically includes the durations of all the sub-events. It might be possible to address these kinds of errors by incorporating auto-matically extracted event duration information (Pan et al., 2006; Gusev et al., 2011).

The second most common error type of the model is the prediction of a head event that is further away than the head identified by the annotators. Figure 4 gives an example of such an error, where the model predicts that the gathering includes the smarting , in-stead of that the gathering includes the stung . The second error in the figure is also of the same type. In 65% of the cases where this type of error occurs, it occurs after the parser had already made a label classification error such as BEFORE  X  OVERLAP . So these errors may be in part due to the sequen-tial nature of shift-reduce parsing, where early errors propagate and cause later errors. In this article, we have presented an approach to tem-poral information extraction that represents the time-line of a story as a temporal dependency tree. We have constructed an evaluation corpus where such temporal dependencies have been annotated over a set of 100 children X  X  stories. We have introduced two dependency parsing techniques for extracting story timelines and have shown that both outperform a rule-based baseline and a prior-work-inspired pair-wise classification baseline. Comparing the two depen-dency parsing models, we have found that a shift-reduce parser, which more closely mirrors the incre-mental processing of our human annotators, outper-forms a graph-based maximum spanning tree parser. Our error analysis of the shift-reduce parser revealed that being able to estimate differences in event dura-tions may play a key role in improving parse quality.
We have focused on children X  X  stories in this study, in part because they typically have simpler temporal structures (though not so simple that our rule-based baseline could parse them accurately). In most of our fables, there were only one or two characters with at most one or two simultaneous sequences of actions. In other domains, the timeline of a text is likely to be more complex. For example, in clinical records, descriptions of patients may jump back and forth between the patient history, the current examination, and procedures that have not yet happened.

In future work, we plan to investigate how to best apply the dependency structure approach to such domains. One approach might be to first group events into their narrative containers (Pustejovsky and Stubbs, 2011), for example, grouping together all events linked to the time of a patient X  X  examination. Then within each narrative container, our dependency parsing approach could be applied. Another approach might be to join the individual timeline trees into a document-wide tree via discourse relations or rela-tions to the document creation time. Work on how humans incrementally process such timelines in text may help to decide which of these approaches holds the most promise.
 We would like to thank the anonymous reviewers for their constructive comments. This research was partially funded by the TERENCE project (EU FP7-257410) and the PARIS project (IWT SBO 110067).
