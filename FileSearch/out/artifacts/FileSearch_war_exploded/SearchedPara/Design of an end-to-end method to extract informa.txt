 ORIGINAL PAPER Ana Costa e Silva  X  Al  X   X pio M. Jorge  X  Lu  X   X s Torgo Abstract This paper plans an end-to-end method for ex-tracting information from tables embedded in documents; input format is ASCII, to which any richer format can be converted, preserving all textual and much of the layout information. We start by defining table. Then we describe the steps involved in extracting information from tables and analyse table-related research to place the contribution of different authors, find the paths research is following, and identify issues that are still unsolved. We then analyse cur-rent approaches to evaluating table processing algorithms and propose two new metrics for the task of segmenting cells/columns/rows. We proceed to design our own end-to-end method, where there is a higher interaction between dif-ferent steps; we indicate how back loops in the usual order of the steps can reduce the possibility of errors and con-tribute to solving previously unsolved problems. Finally, we explore how the actual interpretation of the table not only allows inferring the accuracy of the overall extraction pro-cess but also contributes to actually improving its quality. In order to do so, we believe interpretation has to consider context-specific knowledge; we explore how the addition of this knowledge can be made in a plug-in/out manner, such that the overall method will maintain its operability in dif-ferent contexts.
 Keywords Information extraction  X  Table recognition and understanding  X  Unstructured document conversion 1 Introduction Companies worldwide have the legal obligation of produc-ing and publishing, at least on a yearly basis, financial state-ments where they account for their activities over the pe-riod. These documents vary considerably in length (from 10 to over 100 pages) and style (one or more columns, many or no charts), depending on how important the image of the company with the public is for the authors. The information contained in these reports is valuable to the decision-making of a variety of agents. However, much of the relevant infor-mation is contained in a heterogeneous set of tables and is currently extracted mainly by manually by all interested par-ties. We propose to create an integrated end-to-end method to allow automatic extraction of the information from spe-cific tables contained in these documents. The method is designed to handle a broad range of input that we simply convert to ASCII; and to operate in diverse contexts. scribe research related to extracting information from tables in various formats in Sect. 3, by following the steps of the in-formation extraction process. How to evaluate table-related methods is described in Sect. 4. In Sect. 5, our own method is described in detail, and supporting experimental evidence is provided when available.
 end, obviously; but it can also be read in an encyclopaedic manner, whereby the reader can choose only those sections that address the task(s) he or she is most interested in in Sects. 3, 4 and 5. 2 What is a table? A lot of discussion has been made over the years on what a table is. The extent of the discussion could induce us to think that hardly there is a clear-cut answer. However, more recent researchers have added little to the definitions presented in a somewhat distant past.
 there exist simultaneously linear visual clues in the form of columns and rows that represent logical connections; as such there is a relationship between the relative position of the items and their conceptual relationship.
 presented on the header row on the top are classified accord-ing to the set of characteristics we have on the leftmost col-umn. To understand the data presented in the remaining cells of the table, one must connect them with cells on the header row and on the leftmost column with which they are aligned. table? and horizontally. Besides, there is meaning in the horizon-tal alignment between the numbers and the words, since the number describe one characteristic of the keywords, their lo-cation, even if no header row is shown. So, one can say such an index is a  X  X able. X  and the numbers, we still have an index but is it still a table? The vertical alignment of the numbers is lost, so there is no linear clue that they play the same role in all lines of the index (there are other clues, but they are not linear). So what we have is a list.
 a table is the existence of only one column or of more than one column. Nonetheless, lists represented in columnar for-mat do exist; the example in Fig. 3 is such a case: it is the absence of logical connections that dictates this is not a table and a purely graphical analysis would not be able to distin-guish it. So what discriminates tables from lists is the ab-sence of either linear visual clues OR logical connections behind the linear visual clues presented.
 sentation of the relationships between different components of an organization. On top, come the highest elements in the hierarchy; horizontally aligned components that are not connected with lines typically have the same power but are otherwise unrelated to each other; horizontally aligned con-nected elements typically provide support to the items they are connected to. Similar elements are combined in groups, e.g. under the heading  X  X rasil X  are elements that share that location characteristic; within each group the elements may or may not be hierarchically organized. Relationships of power between different elements are depicted with colour and indentation but in particular with the use of lines and adjacent numbers that quantify the degree of power. linear visual clues to describe logical connections between the elements; however, the contents of the cells and their alignment are not enough to understand the idea transmitted, line art is essential for that understanding. As such, this is not a table, it only looks like one, it is a diagram.
 table and a diagram is that in a diagram the presence of clues other than the content of the items and their relative position is essential to the understanding of the relations being transmitted; as such, a diagram is a more irregular manner of conveying information.
 that is repeated thousands of times. On top of this template, users add handwritten or machine-printed data that can over-lap the template. Forms may or may not contain tables. How-ever, the almost compulsory presence of line art to delimit each cell in a table form and the overlapping of user-written data with the template make it a different research problem from that of tables embedded in non-form like documents. tion of table that captures the essence of Cameron X  X  view by establishing verifiable properties: Definition A table is a graphical grid-like representation of a matrix M i , j , where: 1. each element i, j of the matrix is atomic; 2. there are linear visual clues, i.e. the elements of each 3. linear visual clues describe logical connections ,i.e. 4. eventual line art does not add meaning otherwise not So is Fig. 5 a table? No, it is a diagram. 3 Table related research AccordingtoHurst[ 21 ], several models can be used to rep-resent a table. These may be the output of common table-related tasks (Fig. 5 ).
 ent research fields. For example, physical models are usually required for document analysis, but a graphical model may be sufficient. For information retrieval functional models are sufficient. Information extraction usually requires tables to be represented structurally or semantically. Authors from all of these fields have often studied tables with the purpose of converting them into a model that can be used in their own areas. As such, it is only natural that more authors have focused on the basic table-related tasks than on the more knowledge based ones. In Fig. 6 we position selected papers along the span of tasks they have addressed (we use a diago-nal line to mark the papers that only partially address a task). one task, treat table-related tasks independently and sequen-tially. Exceptions occur mostly in approaches to location and segmentation: while most authors begin by finding the whole table, then search for its lines and columns and finally assign the cells to the formats thus built  X  a top X  X own approach, a few follow bottom-up approaches, i.e. expressions (or in image files word bounding boxes, wbb for short) are joined into columns and lines and these, when appropriate, into ta-bles. Some authors also follow a mixed approach, e.g. begin by finding columns, then gather them in tables and finally search for cells.
 will not approach in this paper, e.g. table compression [ 3 ], table clustering (identifying tables that present related information, usually by analysing their attribute cells) and table merging ( X  X epresenting related tables as one large table X ) [ 45 ].
 how selected authors have dealt with the five tasks identi-fied above: restricted as each was by the input available, we will see what sort of approach they followed, the features they recurred to and the classifiers utilized. 3.1 Location whether a given area on a page is a table or not. This task is relevant in image (I) or simple text (T) but also in poorly or unevenly tagged formats such as many HTML (H) or XML (X) can be. Below, we present in chronological order how several authors have dealt with the problem for the four types of input considered (T, I, H, X). In Table 1 ,wewillclassify each author under a set of characteristics according to the in-put they work with, the features on which a decision is based, the classifier chosen and whether or not their method recurs to predefined or user-defined parameters. We will not repro-duce their evaluation results, since these are affected by the homogeneity or variety of the documents the authors tested their methods on. For example,  X  X ables from scientific jour-nals were easier to locate than financial tables [ ... ](which) layout is substantially more varied and harder to detect with current algorithms X  [ 44 ]. A block of text is characterized as a table if it has columns separated by white space (blank characters),  X  X olerating ir-regularities within (user) specified error bounds, X  and if the contents of the cells in each column are lexically stable. (T) Douglas et al. [ 9 ]. Each block of characters that is sur-(I) Green and Krishnamoorthy [ 12 ]. Users provide a model (I)Tupajetal.[ 44 ]. A similar heuristic to Douglas et al. (I) Shamillian et al. [ 37 ]. Again a model-based system, (T) Pyreddi and Croft [ 33 ]. Taking a group of k lines, a (I) Science Application International Corporation [ 36 ]. (X) Ferguson [ 11 ] and Kornfeld and Wattecamps [ 29 ]. (I) Tersteegen and Wenzel [ 42 ] present an interesting (T/I) Kieninger [ 26 ]. More interested in segmentation than (T) Ng et al. [ 31 ]. Using a decision tree induction algorithm (T/I) Hu et al. [ 15 ]. Each group of lines is tested for its (H) Chen et al. [ 7 ]. After excluding table tagged areas (T) Klein et al. [ 28 ]. Working within the context of med-(I) Cesarini et al. [ 5 ] created a table location method that (I) Wang et al. [44 X 46]. After detection of large blank (H) Cohen et al. [ 8 ]. Tables are located with a trained classi-(H) Wang and Hu [ 49 ]. Each occurrence of a table tag in (T) Pinto et al. [ 32 ] begin by assigning a label to each (H) [ 34 ] agree with Klein et al. [ 28 ] that  X  X ifferent per-proaches to location are top-down; analysis of poorly tagged HTML/XML files are reasonably recent; few methods re-quire knowledge from outside the system (such as some form of user-supplied table model), and these are already in a more distant past; space distribution is almost always analysed but it is assessed through different means, al-though character alignment charts are more outdated, prob-ably because they are less appropriate for non-Manhattan like table columns; similarity/cohesion among different cells/lines/columns is a common form of features; few meth-ods perform semantic analysis; the use of some sort of pa-rameter is common, but most are predefined; rule or heuristic based classifiers were predominant until 2000; application of data induced or probabilistic models is quite recent but most of the more recent works apply this sort of automatic classifiers.
 Unsolved issue : Most methods have difficulty in distin-guishing two tables that are similar in terms of number and appearance of columns/rows, if they are verti-cally/horizontally aligned and reasonably close (see Sect. 5.4). In these cases merging errors will occur. Such tables can only be adequately split if some sort of functional analysis is performed that allows the identification of header rows in the middle of the table and poses the question of whether these header rows mark the beginning of a new table. So using the results of functional analysis to improve location is a lane of opportunity. 3.2 Segmentation The purpose of segmentation is basically to give a physi-cal description of the table, i.e. identify its cells and their relative positions, as well as its rows and columns. We will summarize the approaches of different authors to this task. Krishnamoorthy [ 12 ]. The user provides a table model with the characteristics of the relevant tables. This model includes the characterization of the delimiters that separate the table X  X  different areas, down to its columns, rows and cells. Accordingly, the table is sequentially subdivided into the smaller levels of the model; and each subdivision is named as the concatenation of its own name with that of each of the previous divisions. The output is an X X  X  tree. (T) Douglas et al. [ 9 ]. Having followed a mixed approach in (T)Tupajetal.[ 44 ]. Vertical corridors of white space (I) Shamillian et al. [ 37 ]. In the user-supplied model table (I) Science Application International Corporation [ 36 ]. (X) Ferguson [ 11 ] analyses column header rows to (I) Tersteegen and Wenzel [ 42 ]. After identifying the table (T) Kieninger [ 26 ]. At the end of his location algorithm, (T) Ng et al. [ 31 ]. Column separators are expected to occur (I) Handley [ 13 ] begins by detecting whether the cells in (T) Hurst [ 22 , 23 ]. The method implies having a model (T) Hu et al.1 [ 6 ]. A hierarchical clustering algorithm is (I) Wang et al. [ 47 ]. A vertical projection of the word In summary :Table 2 presents a classification of the segmen-tation methods outlined above in terms of the type of input each author works on, the features taken into account, the method used to reach that decision and the output produced. As can be seen: few methods require knowledge from out-side the system, such as some form of table model, and these are already in a farther past; few methods use semantic in-formation; space distribution is very commonly applied and is assessed through different means, although relative word position has become the most common, probably because they are the most appropriate for non-Manhattan tables; use of some sort of parameter is still common, but all are prede-fined; application of data induced or probabilistic models is still rare, most methods are still highly heuristic-based. since more recent papers have focused their attention on poorly marked-up documents types (present on the web), which typically hold a good cell/column/row segmentation. However, two main issues are still unsolved. Unsolved issues : most approaches are still not generalist enough to derive the physical model of Table 3 ,ifnogrid-lines are available and cell (1,1) contains more than one dis-tinguishable word. An exception would be Hurst [ 22 , 23 ]. Rather than using relative word position as a first step to col-umn identification (as would Tupaj et al. [ 44 ] or Kieninger [ 26 ]), this author begins by using a language model to con-catenate different words into cells, with which columns and rows are searched for. This makes his method less likely to mistake casual space character alignment with a col-umn delimiter, making it less permeable to ghost columns. Notice that Handley [ 13 ] works with cell estimates rather than words to find columns (and for that matter also Ram-mel (2003) in the location task), but his heuristic approach to spanning cells identification makes his method less general.
 not count on the presence of line art or existing mark-up, fail to attribute to their rightful columns those cells which  X  X xtent only spans a subset of the values that its interpreta-tion must be applied to X  [ 23 ]. However, this is quite likely to happen in attribute rows. We propose a possible solution to this problem in Sect. 5.5.2. 3.3 Functional analysis Functional analysis aims at classifying a table area, be it a line, column or individual cell, according to the function it performs in the table: it either holds the data the table is conveying or the attributes that describe that data. We be-lieve other elements, such as the table X  X  titles and footnotes are not a part of a table but rather are attributes of it, even if they may facilitate the understanding of the information it contains.
 the function of each cell is determined by a set of heuristics based on the coordinates of each cell, the semantic type of its content within the context X  X  specific language, and a Boolean for whether there is a semantic connection between the content of each cell and the table X  X  title.
 the table maps relationship between each relevant table area (column, row, or cell) and its function.
 a set of heuristics classifies each line as attribute or data by comparing it with average characteristics taken from all table line. The comparison is based on the line sizes, alignment and gap structure. Whether the line contains mostly numbers or strings, and the number of columns it holds is also taken into account.
 heuristic classifies as attribute the first line which has all (or all but the first) column filled in.
 they measure the cohesion among different cells within rect-angular areas of the table, to evaluate whether each area could be an instantiation of one of the table models. With those areas that have enough cohesion, a tiling is built that covers the whole table with no overlaps. Evaluation revealed poor results.
 German business letters into non text and text regions and these are presented to an OCR. The text is skimmed for context-specific keywords (which are related in a look-up dictionary) and for content-type characterization; keywords X  relative position is noted. An area of up to three lines is drawn around each keyword. If an area holds too few key-words, it is disregarded; otherwise, the area with the maxi-mum number of keywords is classified as table header. heuristics (considering the physical model of the table, the semantic types of its content, and a comparison of the con-tent with the text in the document), a Na  X   X ve X  X ayes clas-sification (with physical and content-related attributes de-rived from comparison with surrounding text and titles) and a pattern-based classification (which implies a definition of physical patterns for each cell on the basis of its surround-ing cells, a mechanism to compare new examples against these predefined patterns and a voting mechanism to choose a classification for the cell based on all the patterns that ap-ply to it); he also makes several combinations of the three methods. Heuristic approaches showed rather low recall but good precision.
 location task (see Sect. 3.1) is now applied to compare each line against the last table line (that is clearly identifiable since the input is HTML); if the number of similar lines is above a threshold and the first line is dissimilar from the rest, then it is classified as an attribute line. The same is applied to columns. In tables with spanning cells, these are first used to cut the table into sub-tables and an independent classifi-cation is made in each sub-table. More than one row/column of attributes will not be found if there are no spanning cells.
 be categorized into nine types, X  the Expectation Maximiza-tion Algorithm is used to calculate the probability of a table following one of the nine types, given an ontological analy-sis of its strings.
 is a header. Then up to five rows will be compared with the remaining for content type consistency X  X nconsistent rows will be classified as headers; the presence of spanning cells serves to detect header hierarchy.
 Random Fields were used to automatically label each line of a document according to the role of the line (header, sub-header, data, separator, etc.).
 In summary :Table 4 presents a classification of the func-tional analysis methods outlined above in terms of the type of features taken into account and the method used to reach a decision. Although a good number of methods still rely on space distribution and consistency measures as features, it is interesting to notice that the relative weight of some sort of user defined table models is more common for this task than for any of the two before, which is indicative of the com-plexity this task involves. It is also noticeable that machine-learning methods have not yet been applied to this task. We believe there are two main reasons for this: (a) many of the authors that have applied data-induced models to tables are still dealing with the first tasks; and (b) the classification of each unit is potentially dependent on the classification of each of the elements that surround it in all directions, which makes it an intricate problem of interdependent classifica-tion Table 4 . 3.4 Structural analysis all attribute cells that characterize it, thus grouping those cells that have to be read conjointly. The groups formed constitute each data cell X  X  reading path. After each has been identified, the output can be stored in a relational table, which can be utilized for information extraction.
 attribute cell above and next to it. Semantic webs are built on the content of attribute cells. Heuristics attempt the connection of each attribute cell to those above or aside it. pendently within each sub-table identified; each data cell is connected to the attribute cells above and/or next to it; if no attribute line or column exist, each cell is connected to the first cell in its column. In the result, one data cell can have more than one attribute and one cell can have attribute and data in different pairs; in this case, transitivity properties apply.
 cells in its line and column.
 In summary : As demonstrated in these works, a simple heuristic approach is sufficient to guarantee very good results in this task. 3.5 Interpretation knows how to read the information in the table, but one does not yet know what is being said (in Fig. 1 , for instance, we already know that  X  X ife, X   X  X ild buckwheat X  and  X  X nnual X  have to be read conjointly, but we do not yet know that  X  X ild buckwheat lives for a year, X  much less do we know that wild buckwheat is a plant. This information is added through in-terpretation. A deep interpretation of the table will almost always require context-specific knowledge.
 can be performed before interpretation becomes context-specific.
 are members of the same category. For example, in the ad-jacent table, the categories would be { States.q, States.r {
Sequence, Probability } , { E,B } . The author details an algorithm for deriving these categories; however, different outcomes, eventually all valid, can be obtained depending on the options taken along the process.
 between cells. This author proposes several different types of relationships:  X  nominal super-type, e.g. [Car, Ford]; or qualitative super- X  partitive, e.g. [Car, Wheel]  X  units of measure [Turnover, EUR]  X  quantitative [Turnover, 1 million] sification of relationships, based on the semantic types of the contents (dates, numbers, units of measure, years), as well as the comparison of the table X  X  contents with the rest of the text in the document and the presence of certain keywords.
 oped context-specific solutions for the problem of extracting information from American companies X  financial statements published on the internet in a poor XML-based format (the SEC filings). In this accounting context, there are several constraints the information must fulfill, for example, subto-tals are often presented that must equal the addition of its parcels. If these constraints are not satisfied either the table contained a mistake to begin with (which was measured to happen in only 2% of the cases), or the information was wrongly extracted. Therefore, these authors rely on the satis-faction of these arithmetic rules and, in the case of Kornfeld and Wattecamps [ 29 ], also on indentation to identify parti-tive relationships between the contents of cells. With these, a hierarchical tree can be built with the attributes of the ta-ble. This tree is then compared word by word with a manu-ally built collection of all possible alternatives to name the concepts they wish to extract. The top of the tree is compared first and thus restricts the search space of the hierarchically lower members.
 formation extracted by comparing the result of the extraction of items that appear in different tables (e.g. profit or loss for the financial year); verifying that certain ratios built with the information extracted have reasonable values; inferring the unit of measure of a table from comparison with the scale of the items presented in other tables where the unit was identified. By ranking mechanism of the different tables in the document according to their likelihood of being one of those they wish to extract, the method can proceed to analyse a second best choice if the first choice failed to comply with the restrictions of the context. Awareness to titles is also an important asset.
 In summary : A few authors have actually targeted the in-terpretation task. However, those who have either avoided committing themselves to a specific context and hence not exploited the full potential of interpretation [ 20 ]; or have taken interpretation to deep levels (including in terms of the guarantee it can give of the quality of the results achieved) but to do so have made their systems dysfunctional in any context other than their own limited one (to use Ferguson X  X  [ 11 ] or Kornfeld and Wattecamps [ 29 ] method on financial statements that do not abide North American accounting dis-closure practices, great adaptations would be necessary!). Unsolved issue : No author has yet found a way of making interpretation general, i.e. fully interpreting a table and being able to do so in any or many contexts. 4 Evaluating table-processing systems As seen in Sect. 3, table-processing methods suggested by different authors have had different targets. One of the main difficulties in comparing their performance is that they deal with so many subtasks that one sole measure cannot provide a full-length evaluation. As an example, consider an end-to-end table processing method that aims at extracting information from tables (e.g. our method). Obvious performance measure would be whether the ex-tracted information actually is the required (this measure-ment was actually used by Ferguson [ 11 ] and Kornfeld and Wattecamps [ 29 ] and how much time the process takes. Such end-result evaluation is fundamental as overall perfor-mance often depends on the interaction between the differ-ent steps rather than on the performance at each individual step.
 each of its intermediate tasks as well. This allows us to re-fine each of the steps independently and to compare their achievements with those of other authors. There are nonethe-less difficulties in comparing the results of different authors, which we encapsulate under the heading Diversity.  X  Diverse document types: Take for instance the location  X  Diverse test domains: Domains exist where tables follow  X  Diverse table definitions: There are examples of table- X  Diverse measurement levels: Recall (degree of correct 4.1 Metrics for segmentation Segmentation is a particularly intricate task to evaluate, be-cause unlike location and functional analysis, which basi-cally involve classifying a given element into two or more categories, segmentation involves  X  X utting X  or  X  X luing X  a level of elements to form another, so the number and type of the elements at the output of the task can be quite differ-ent from what you started with.
 ing the ability of the segmentation task in deriving the table X  X  columns and lines. In the ground truth generation stage, each cell is linked with those with which it has vertical and hori-zontal adjacency, while respecting some constraints, to form columns and row. Recall and precision are measured on the system X  X  ability to accurately detect those cell-to-cell links. However, we believe the use of this metric alone may be misleading for a method X  X  performance since an error made in the assignment of one cell to its column may compromise the interpretation of the entire column and ultimately of the table, particularly if the mistake separates data cells from their attributes.
 evaluating segmentation, which seems to aim at this gap. The  X  X able recognition evaluation X  considers as an  X  X mis-sion [ ... ] those cases where there is a logical connection between two cells but they are not aligned. X  However, the method seems to require the ground-truthing of the func-tional and structural models of the table to evaluate the accu-racy of its physical model. Moreover, it also takes the mea-surement too close to cell level, which has the effect of di-luting the errors made in one or two among many correctly identified cells.
 propagate to their entire row or column and precision and recall should be measured on the accurately detected link threads that traverse the whole table vertically or horizon-tally, i.e. its columns and rows. Basically, we believe that in the gluing and splitting of different elements to form others two main types of errors can occur: either two (or more) dif-ferent elements are glued together so the detected element is impure, or one individual element is split in two (or more), and thus the detected elements are incomplete. This reason-ing can be applied to both column, row and cell detection. to Hurst X  X   X  X roto-link evaluation; X  one can calculate these measurements with the sheer knowledge of the table X  X  phys-ical model (that any HTML provides). To illustrate our pro-posed metrics, we will use the example in Fig. 7 that was presented in Hurst [ 23 ]. There are 16 rows and 6 columns. is somewhat particular: the total number of elements being qualified (25) differs from the total number of real elements in the table (22); this number in particular does not show on the contingency table, but still should be presented pro memoria. The difference between the total number of de-tected elements and the total number of real elements, if pos-itive, means ghost elements were generated (in Hurt X  X  exam-ple there were three ghost columns), although exactly how many is tricky to count; if negative a greater number of ele-ments were glued together than ghosts were created. columns were completely and correctly identified, the first and the fifth, which contain all the cells they are supposed to and none they are not supposed to. Seven columns did not have all the cells that belonged to one sole true column in the real table, of which three were ghost columns (25 de-tected columns  X  22 real columns) and one column merely lost the cell  X  X ollars in thousands. X  We call this sort of mis-take a splitting error, the opposing, when the cells in differ-ent columns intertwine, is a gluing error. Gluing errors cause the resulting element to be impure; splitting errors cause the resulting element to be incomplete.
 to correctly identify all the elements (and is measured in relation to the total number of existing elements), precision indicates how accurate the given result is (and is measured in relation to the total number of detected elements). In the example, recall equals 18/22 = 82% and precision 18/25 = 72% (smaller but more realistic than the  X  X able recognition evaluation X  and the  X  X roto-link evaluation X ). However, with these two measurements, we do not know which sort of problems occurred. Besides, because this is not a classification but rather a detection problem, the trade-off between precision and recall is lost.
 completely identified elements w.r.t the total number of real elements, to be a relevant measure. Notice that in order to be completely identified, a line (or a column) must contain all of its cells. In this case, completeness is 18/22 (it happens to equal recall because there are no impure columns or rows).
 purity of the detected elements, where a pure detected element is one whose cells belong to only one original element. Therefore, purity is defined as the proportion of pure detected elements w.r.t. all the detected elements. For the above example, purity is 25/25 = 100%. This value of 100% indicates that the error of having cells from different elements mixed on the same detected element did not occur. pure and cared not about completeness, we could place each cell in its own column and row, creating a large number of ghost columns and rows; inversely, if we cared only about completeness, we could throw all the cells in a single col-umn/row, but purity would be 0%. Clearly, there is a trade-off between both measurements, which is a positive aspect in evaluation measures; different costs can be attributed to the two types of mistakes; to compare different methods, an efficiency border can be defined and different methods can be preferred by users who have different utility functions. For information extraction, we consider incompleteness to be a far less serious problem than impurity.
 examples of splitting/gluing different elements to form new elements. For example, in the task of splitting lines into cells, pure cells only have the characters of a single true cell; and complete cells hold all the elements of a given true cell. We will see an example of these metrics in action in Sect. 5.2.1.
 4.2 Metrics for other tasks Hurst [ 20 ] measures the results of functional analysis by computing performance and recall on the classification of cells as attributes or data; because attribute cells tend to be less frequent in tables but mistakes in their recognition are more serious, the author suggests normalizing the two us-ing the relative weight of attribute and data cells in the test set. Aiming at information extraction, Ferguson [ 11 ] takes those measurements on the number of tables that are prop-erly handled by their extraction system; and Silva et al. [ 39 ] on the number of lines that belong to those tables holding the information to be extracted.
 uate location Hu et al. [ 15 ] and Cesarini et al. [ 5 ]take X  X  measure of the similarity of two documents (the recognized document and its ground truth) in terms of their table struc-ture. X  Both measures are positively correlated with the total areas that are correctly identified as tables and negatively correlated with the total area of non-tables that is identified. However, being similar to Hu et al. X  X  teval, Cesarini et al. X  X  Table Evaluation Index does not associate costs to the differ-ent possible errors in table detection; therefore, when used in the table location competition proposed in [ 24 ] it was com-plemented with the number of found, missed, split, merged and false tables detected.
 resistant to the difficulties in ground-truthing tables and that can be used on other table-related tasks. A graph model of the table is the output of their table analysis method; in par-allel, a ground truth graph model of each table is manually created. Three classes of questions are asked to both graphs and the percentage of agreement is measured. The first class of questions aims at evaluating the quality of the physical model derived by the method with questions like  X  X ow many columns does the table contain? X ; the second set evaluates the tables functional model, e.g.  X  X ow many attributes cells contain the word OpenT; the third set aims at the structural model and mimics database-type queries. Wang et al. [ 48 ] propose to combine three measures that are similar to Hu et al. X  X  by weighing them by the costs of the errors made in the graphical, functional and physical models of the table. Hurst [ 23 ] calls this sort of approach  X  X unctional X  in opposi-tion to the  X  X bsolute X  approach followed in Sect. 4.1. 5 Our method Overview: We are currently developing an integrated method to allow extracting information from tables contained in ASCII documents. We are applying it within the context of companies X  financial statements. Although some finan-cial statements are rather plain, others are characterized by high heterogeneity of the layout styles used by authors to display information on page and can contain several diverse elements, such as graphics and organizational charts. For ex-amples, please refer to Auto Industrial [ 1 ]andEDP[ 16 ]. Our aim is to extract from them key financial information that is usually presented in tables. This information obeys certain predefined arithmetic rules imposed by its account-ing context, which is often country-specific, that we want to integrate in order to assert and improve the quality of the extracted information.
 the schema is shown in Fig. 8 , takes as input an ASCII docu-ment and locates within it the existing tables [ 39 ], segments these into cells, distinguishes the cells that describe the con-tent of the table and relates them to those that contain the data; finally it interprets the results to identify the relevant items and extracts these to a database. As we said in Sect. 3.5, full interpretation is almost always context-specific. However, we aim at  X  X ontextualizing X  the method in a  X  X en-eralist X  way, by letting the user plug-in and out the relevant knowledge base. For accounting, XBRL (extensible Busi-ness Reporting Language) jurisdictional taxonomies are an excellent encoding of each area X  X  national accounting envi-ronment [ 41 ].
 possible, so we allow the treatment of any sort of untagged document, that we simply convert to ASCII, 1 although in the future we would like to exploit the extra information image files contain, namely font information.
 Process : the method does not work linearly, the different tasks being inter-connected such that the information gath-ered at each step is used to improve the decision of the previ-ous steps. This contributes to: (a) increasing the confidence of the decisions taken, all the way to the final result; (b) re-visiting previous decisions under the light of new informa-tion, allowing the method to correct its own mistakes; (c) reducing the search space of subsequent (eventually more complex) tasks by restricting them to portions of the docu-ment that are most likely to contain the information to be extracted. To facilitate the improvement of the decisions, flags are left behind every time a decision seems risky. Each flag signals a decision that could be the subject of especially crafted data-induced classification methods; for each a like-lihood of accuracy can be measured.
 or adapted from existing ontologies, and will be a plug-in to the method, such that: if absent, it will still be able to obtain the output, eventually with smaller confidence levels; if changed, it will interpret the results under the light of the new ontology. To this end, we will construct the different steps of the process in the most general way possible. If the method finds an item that does not abide the constraints that apply to it under the knowledge base, it will move on to the next best candidate; the output the best result found. dence in a result is too low, the user shall be alerted and shown the location of the best result in the original docu-ment; if no result is obtained at all, the user will be given a choice to supply the location of the table that contains the item, if any; however, if confidence is high enough, the method will not require user intervention. Any parameter the system encloses should be accessible to the user, so that he can personalize the performance of the method, which is even more important when no knowledge base is available. Output : the output of the method will be a set of (eventually interrelated) items chosen by the user and extracted from the document. These will satisfy, to an adequate extent, the constraints the knowledge base imposes in terms of its rela-tionship to other items in the document. The information can then be extracted to a database (for diverse analysis purposes as detailed in [ 41 ]); or converted to the terms of the ontol-ogy (in the accounting context, items can, for example, be converted to XBRL, for a more user-friendly downloadable transmission through the internet).
 steps of the schema above. We will not describe in detail the plans for the five basic table-related tasks, to which we will apply a combination of the methods described in the bibliographical analysis.
 tween these tasks, trying to show how we can benefit from the information gathered in each to (a) improve the quality of the remaining, and (b) work on the unsolved issues iden-tified in Sects. 3.1, 3.2, 3.3 and 3.5. 5.1 Location I Goal : Skim the document to identify those lines that are more likely to belong to tables, so as to considerably reduce the search space for the subsequent more computer intensive tasks, while keeping the large majority of table lines. Input : The ASCII is imported into a relational table where each record is a full line of the original document; in the ex-perimental phase for this step, we have worked with 19 pdf files downloaded from the web and converted into ASCII us-ing a pdf-to-txt utility; our resulting training set had 87,843 lines.
 Process : The process followed in location I has been detailed in Silva et al. [ 39 ]. It begins by analysing, through some basic descriptive statistical measurements, the distribution within the document of the number of interior spaces per line. From these, it estimates a threshold for pre-classifying each line as being in a table or not. In those pages with a high enough percentage of above-threshold lines, the presence of n close enough such lines determines their neighbourhood to be inspected. The size of the neighbourhood is measured in terms of the number of non-empty lines between each two lines (in this context it is customary to have large gaps of empty lines in the middle of a table) and is a function of the percentage of above-threshold lines in each page; the func-tion, however, can be manipulated by the user. Table lines are simply those with any white space or that are narrow. Each individual table area is assigned an ID number (the existence for instance of a relatively long text line with no interior spaces causes the identifier to change).
 Overview : Through this process, the decision on each line depends on the perceived specific characteristics of its source document, of its page, and of the lines that surround it; it is this dependency that makes the method capable of adapting its performance in those documents with more var-ied error-prone layouts (as EDP 2001 is).
 Output : Individualized table candidate areas, where each record is a line of the document.
 Evaluation : We have conducted a twofold evaluation. On the one hand, setting the parameters to aim at capturing all sorts of tables, we have measured the total number of document lines discarded ( economy ) versus the total number of lines accurately kept ( recall, ) both presented as percentages of the total number of lines in the document. On the other hand, be-cause our final goal is to extract information, we have taken those same measurements on the total number of relevant lines, after adjusting the parameters to the tables we wish to extract, i.e. on the total number of lines that belong to tables that contain information we wish to extract.
 Results : Empirical evaluation was made on the training data and indicates that more than 95% of all table lines (and 99% of those table lines that contain information to be extracted) are selected after discarding on average 62% (70%) of them. All relevant tables are at least partially detected. User manipulation of parameters was necessary for one table containing one column with very long vertically spanning cells. Evaluation was also taken on the unseen data, a set of three financial statements with 9,470 lines; recall was always above 99% and economy was between 70% and 79% in the context-specific evaluation and 58%, 67%, 68% in the generic evaluation.
 Errors : In an end-to-end method, it is often not as important to know how many records you got right but rather whether the records you got wrong can be corrected later on. To this end, we try to typify the mistakes made and plan the solution for them.
 mistaken for the beginning of a subsequent table and head-ings were sometimes mistaken with the end of previous tables X  X e will solve this in Sect. 5.3; two columns of text separated by an usually large (for the document) column separator organizational charts or graphics with legends (on the dots or axis) were also mistaken for a table X  X o be solved in Sect. 5.3.
 header lines of others can be missed as well portions of the table which have too narrowly filled-in X  X e will solve this in Sect. 5.3; very narrow tables or tables with less than three lines can be totally missed X  X his sort of table is not com-monly relevant in the accounting context, for now we will live with this disadvantage; tables with very different font sizes may be problematic (to be solved in future work, when image files are integrated into the method), small differences in the fonts used on a page however are handled, especially if the table itself has similar or the same font X  X ee Fig. 9 . columns as likely tables, non-table areas that are in horizon-tal alignment with tables are still present; this aspect will be solved in step 5.3. No more can be obtained without trans-forming the data, i.e., moving to a different table model. On the other hand, tables that are not separated by at least one long line of text will have been merged, which we will solve in Sect. 5.3 or 5.4. 5.2 Segmentation I Goal : The purpose of this step is to identify and delimit the cells in the tables areas obtained in Sect. 5.1 and assign them to their correct beginning and end columns. We believe we should find cells before we try to find columns so as to avoid an accidental space alignment resulting in the detection of false columns. Therefore, we will divide this step in two sub-steps. 5.2.1 Segmenting lines into cells Goal : Cut each line into its respective cells.
 Input : Individualized table candidate areas, where each record is a line of the document.
 Process : In our approach, we have adapted tokenizing tech-niques: we search for space characters and delimit words when there are three or more spaces between them; in the case of numbers, however, the presence of a single space be-tween two digits is analysed to decide whether it is a cell delimiter or a thousands/decimal separator; in these cases, or when a single space separates a number from text (or vice versa), a flag is left to signal the riskier decision, so that the method can reanalyse it at posterior stages.
 Overview : Although we generally agree that using a lan-guage model to decide whether or not to group two words with a particular graphical arrangement into one cell is a more general approach [ 22 ], we suspect it is computationally more expensive than simply taking a graphical approach. This aspect is relevant to us since our final aim is to extract information from specific tables in long documents that con-tain several other tables, most of which hold not the informa-tion sought for; we want to skim the tables before scan them. On the other hand, a language model would not help much when segmenting numbers into cells and numeric tables not only account for the majority of tables in the accounting con-text but also for a good part of tables in general. Luckily, finding a number is a rather deterministic problem, which a carefully crafted set of rules can solve quite well. Hurst X  X  approach [ 22 ] to cell segmentation, properly ad-justed to handle numbers, against saving it for the text cells in Sect. 5.5 and the few problematic cases identified in Sect. 5.2.2 and using now a more simplistic approach.
 Output : Each cell is horizontally segmented the start and end positions of its content have been determined, tentative col-umn placement may be added if we simply accumulate the number of cells found per line.
 Evaluation : We will measure purity and completeness, the evaluation metrics presented in Sect. 4.1, on our ability to clip lines into cells. For completeness, we will also show precision and recall. We will again make a twofold evalua-tion; we will measure the percentage of cells that were cor-rectly segmented in tables that hold numeric data and the same in tables that also hold text.
 Results : Due to time limitations, we have taken a small sam-ple of examples, all deriving from the document we have had more trouble treating during Location I. The document con-tained 104 tables, of which 84 presented mostly numbers. After demarking the vertical delimiters of the table by man-ually, we have applied our segmentation method to it and then corrected all mistakes.
 nomials were presented, of the sorts of  X 15 + 19; X  and one happened when by mistake the author left out the thousand delimiter dot in 1 584.786,95 (under the continental number representation convention).
 Errors : This rule-based procedure has been able to work well in examples of tricky tables, such as Fig. 10 , where the pdf-to-txt converter turned to one space the separators be-tween the numbers in the first and last two lines of data and between columns 3 and 4. Although space is also used as the thousands delimiter, the rule managed to accurately segment the cells horizontally. The divider between the third and the forth columns was obviously not identified, but a flag sig-nalled it.
 different content types should result in the identification of a new cell or merely a signalling flag. The first alternative would actually solve the only segmentation errors in Fig. 10 and would probably be more prudent in the accounting con-text, but it would produce bad results in the first column of Fig. 11 . Obviously, a careful evaluation of this aspect will be made, but the answer may differ from context to context. In our opinion, however, the issue is often not how many mis-takes are made, but which and whether the method can in later stages solve them, for which flagging is the first step. The only segmentation error in Fig. 11 was that the cell end-ing with  X 55 X  was merged together with the one starting with  X  X lectrica. X  This aspect will be solved in Sect. 5.2.2. 5.2.2 Grouping cells into columns Goal : Attribute each cell to its respective beginning and end column while correcting eventual cell segmentation errors. Overview : Our first idea for identifying the beginning and end positions of table columns was to assume that the max-imum number of cells per line indicates the number of columns in the table; then we would take the lines with most cells, and estimate the column delimiters from the position of the contents of their cells. The chart below shows in dark blue the minimum, maximum and median start position of the cells in the lines with a maximum number of cells and in light grey the same measurements taken from hand-marking all the cells in a small sample of examples.
 the table have all cells filled in; a few heuristics can be used to correct some of the possible mistakes of this assumption. It can work well in contexts with uniform tables, such as that of journals or books and some industrial applications [ 2 ], as itwouldinFigs. 11 and 12 . However, these are only a por-tion of existing tables. It is true that the portion is not small and it is also true the approach is general enough to accom-modate spanning cells, but in the accounting context several examples can be found where it is not general enough, as it is not for Fig. 11 or Table 3 : (since no lines have four filled-in columns).
 Process : After segmenting the table into cells we will ap-ply a method similar to Hurst X  X  [ 23 ] except we will only be linking together those cells that are vertically aligned, not horizontally. We will only segment rows in Sect. 5.5.1. the same column, but the respect for some constraints will be guaranteed here when dealing with ambiguous overlaps, which may lead to the disregard of a vertical overlap, the merging of cells together but also the splitting of a cell that was flagged in the previous step. Thus, in Fig. 10 after notic-ing that the third column (where the numbers got merged with the text in the fourth column) is quite wide and spans over the contents of the header columns which in turn are not vertically aligned with each other; and/or when notic-ing that there is an accumulation of flags alerting to the change from number to text, and that all these flags were left at approximately the same position; all of these aspects will lead to questioning the decision made before, eventu-ally to splitting the cells into two columns and to validat-ing the constraints again. In Fig. 11 , the fact that these are two textual columns and that the method for segmenting tex-tual cells into columns is more error-prone and the fact that there is only one spanning cell while all the others are well segmented apart will lead to wondering whether these two should also be split. We may consider validating this deci-sion in the light of a language model. For each of these more ambiguous decisions, a flag will be signalled so that a cell that is attributed to a given column but could also belong in another is properly identified.
 ment by measuring the percentage of cells that share (or have close) beginning, middle or end position (using a metric sim-ilar to the one applied by Tersteegen and Wenzel [ 42 ]). Output : The potential table areas have been segmented into cells and these were attributed to their lines and columns, i.e. their contents have been situated.
 Evaluation : We will measure our ability to group cells in the same column using precision and recall both at cell level, as suggested by Hurst [ 23 ], and at column level, by measuring recall and precision on the total number of proto-links crossing the whole table that were correctly identified (Sect. 4). We consider more expensive to assign a cell to a column it does not belong to than to split columns, creating ghost columns that can be rejoined later. Cells spanning several columns have been partially detected. Errors : Cells for which content reaches less far than their interpretation applies to will be dealt with in Sect. 5.5.2. tables or for instance a table and a chart were not separated yet, the number of columns for the area will equal or be big-ger than the total number of columns of the area with more real columns; and in the area with less real columns, more spanning cells will be found. This aspect will be solved in Sect. 5.3.2. 5.3 Location II Goal : With the current partial physical model of the table, we want to remove the remaining non-table cells/columns/rows from the process and recapture any lines that were improperly lost after Location I. 5.3.1 Improving the identification of table areas X  vertical delimiters Goal : Improve the identification of the table X  X  vertical de-limiters.
 Overview : After Location I, sometimes false positives, i.e. non-table lines that were wrongly detected, were simply nar-rowly filled-in lines adjacent to real table lines, such as head-ings or a page X  X  header or footer [ 6 ] has an interesting ap-proach for identification of recurrent headers and footers and other background patterns, which we will consider in future work.
 tected table lines, belonged to tables that were only partially detected because they had a set of relatively narrow lines. This can happen in header rows, which are known for not having the first and often wider column filled in, but also in the middle of true tables (as is the case in Fig. 13 ); in the later case, splitting errors are likely to occur. The con-sequences of these mistakes may be rather serious in what interpretation is concerned.
 should be sensitive to a wide array of aspects, since tables make themselves noticeable to readers in more ways than one and not all occur simultaneously. In Sect. 5.1, we chose as table candidates those lines with more contiguous inte-rior spaces than an adaptable threshold; around these candi-dates we defined a neighbourhood in which we applied to each line a simple classification rule; the lines in this neigh-bourhood that were not candidates originally are considered more error-prone than the remainder of the table. Also, be-cause of the simplicity of the rule, the neighbourhood did not expand to include other lines, even if all the lines in the neighbourhood were classified affirmatively. Lines around detected areas are also considered more error-prone. is not new, authors like Hu et al. [ 18 ] and Wang et al. [ 48 ] follow a similar approach.
 Process : We will inspect the first and last lines of each de-tected table area to see if they obey the regular column struc-ture detected for the table (in Sect. 5.2). If these validate positively, then we will expand the neighbourhood and con-tinue to validate new lines until the alignment configuration is lost.
 have spanning cells. We may develop a machine learning approach to help us decide what to do when normal table alignment is only partially respected; the approach would consider how many column delimiters are lost and the posi-tion of the potential table line within the detected table areas. 5.3.2 Identifying false tables Goal : Use graphical characteristics to identify areas that were mistaken for tables in Sect. 5.1.
 with unusually large space separators for their document. These elements may or may not have been vertically or hor-izontally merged with real tables.
 Process : For this task, a combination of the methods out-lined in Sect. 3.1 will be used. Wang and Hu [ 49 ] measured the consistency of the columns and rows of each table in terms of: the content type of each cell (numerical, date, al-phabetical or other) and the content length; they also con-sidered the average and standard deviation of the number of filled in cells per row and column, to decide whether a can-didate table area was a table or not. Even if we appreciate these measures, we cannot take them over the overall de-tected table (this risk is mostly absent in Wang and Hu [ 49 ] HTML inputs).
 close, much in the way that is done in [ 34 ]. We will then analyse these blocks individually to determine their likeli-hood of being a table block. Douglas et al. [ 9 ]dothisby analysing the width of the space between two blocks ver-sus each block X  X  width X  X e expect that the false columns of graphics tend to have narrower  X  X olumns X  and wider gaps than tables and false text columns just the opposite. We will also analyse intra block consistency in terms of relative lo-cation and alignment, as Rammel (2003) does, but also the content type and content length as Wang and Hu [ 49 ] do. These intra-consistency measurements will be presented to a classifier that will determine for each block how likely it is that it is a true table block.
 gether into tables, by analysing their row/column mapping. For Douglas et al. [ 9 ], two blocks should be joined together if the non-empty cells in one correspond to non-empty cells in the other. Also, if a block has fewer cells filled in than those around it, it might not belong to the table all together or it might belong to a different table. We may also consider average and standard deviation of the number of columns and rows that are filled in each block and the degree of hori-zontal or vertical overlapping between them. Inter-consistent blocks will be joined together to form inter-consistent tables; the result may be the division of an original table area into two or more tables or the removal of non-table areas from the focus of the method.
 Overview : There are many features on which decisions in Location II will be based. Balancing them and incorporat-ing them into an appropriate classification scheme or more than one is important. We may recur to different classifiers ensembles of classifiers.
 Output : A set of cells assigned to their lines and columns. Virtually all non-table lines and columns have been re-moved. Most adjacent tables have been unmerged (when two or more tables had been mistaken for one) or un-split (when one table had been mistaken for two or more).
 Evaluation : Precision and recall measured on the basis of the number of cells that actually belong to tables. Errors : Two tables with no lines of text in between them and with inter consistent columns would not have been separated (e.g. Fig. 15 ). This aspect will be solved in Sect. 5.4. 5.4 Functional analysis Goal : Distinguish those rows/columns that contain data from those that describe data. We will assume that functional areas are rectangular.
 Process : A combination of the methods outlined in Sect. 3.3 will be used. One important feature we will take into account will again be consistency measured for each of the table X  X  columns and rows. We intend to use different classifiers and combine their results through voting or another committee-based strategy. We consider it important to study data in-duced models for this task. We believe this step to be one of the most crucial in the entire process, since errors made in identifying table attributes will be difficult to detect in pos-terior phases but their consequences may condemn an entire table to be undetected or misinterpreted in the later stages. Overview : It is only after functional analysis that the last step of location will be fulfilled. Until now, two tables with no lines of text in between them and eventually the same number of columns would not have been separated. The same would have happened with similar horizontally adjacent tables. By identifying a header line/column in the middle of such a table area, we will consider separating it into two or more tables, possibly not before (lexically) comparing the headers.
 split into two vertically adjacent tables after Location I (for holding one long text-like line with no inner spaces) can be remerged, since the two parts will be considered physically similar, their distance will be small and the second part will not have a header row.
 systems (as we discussed in Sect. 3.1) that we believe func-tional analysis can help solve.
 Output : Each cell of the input is characterized in terms of its function in the table as data or attribute. Similar but in-dependent tables have been unmerged and dependent areas remerged.
 Evaluation : Precision and recall in terms of the total number of attribute cells and data cells accurately identified; these two measures may be normalized as suggested by Hurst [ 20 ].
 say Location has been complete, it is now appropriate to use either Hu et al. X  X  teval, or Cesarini et al X  X  Table Evaluation Index complemented by the number of found, missed, split, merged and false tables detected, to evaluate the full-length of the location task. 5.5 Segmentation II Goal : Delimit spanning cells. We consider that this prob-lem deserves different approaches for cells spanning several lines or cells spanning several columns. 5.5.1 Cells that span several lines We distinguish two different situations in treating cells that span several lines: (a) detection within data lines and (b) de-tection within attribute lines.
 Process : (a) Hu et al. X  X  [ 16 ] simply join those lines with no data with the previous line to form the table rows. Applied in Fig. 16 , this simple heuristic would cause the line containing  X  X erdas relatives a empresas associadas X  to be wrongfully joined with the following two. Besides, data cells can also span several lines. We consider Kieninger X  X  [ 26 ] approach to be more general: the segmentation of the table into rows will obey the row structure of those columns which only contain one string per cell, special care being taken to first inspect  X  X he blocks of interest [ ... ] for words that might as well have fitted at the end of a preceding line [ ... ] since modern word processors try to fill up lines as much as possible. X  Other cares would also be taken, attention to character type and punctuation is important. As such, the three lines in Fig. 16 would not be joined together because if we added the word  X  X mortizasc  X   X  oes X  to the previous cell, its total length would still be below the length of the widest cell in the column. In Fig. 17 , apart from that indicator there is also that (a) the contents of the first two end in  X : X , (b) they are not all written in the same type of letter.
 tic approach or using Hurst X  X  [ 22 ] language model to row segmentation instead. For textual tables and more gener-ally for all tables where no columns contain only one string per cell, we will also revert to Hurst X  X  language model. to develop even a simple language model of the sort of that described in [ 22 ] and as such combine physical character-istics with linguistic ones. Only such an approach will lead us to recognise that  X (Escudos) X  and  X  X mortizasc  X   X  oes X  be-long to different cells but  X  X mortizasc  X   X  oes e provisoes X  (i.e. depreciation, amortization and provision X ) go together. 5.5.2 Cells that span several columns All methods mentioned in Sect. 3.2 which cannot count on the presence of line art or existing mark-up fail at attributing to their columns those cells which  X  X xtent only spans a subset of the values that its interpretation must be applied to X  [ 23 ]. This problem is quite unlikely to happen in data rows but is particularly likely in attribute rows. Let us focus on Fig. 17 : the cells containing  X 2000 X  and  X  X scudos X  actu-ally also span its two adjacent columns; on the other hand, the expression  X  X otas X  is contained in a unitary cell. A human user does not need special accounting knowledge to know this. We believe a distinction can be accomplished by combining information on column alignment and function. Process: 1. Take the attribute lines with less columns filled in than 2. For each cell in those lines, identify the content X  X  align-3. Expand the cells, i.e. join the filled-in cells with adjacent cells on either side, context knowledge would be required to reach a decision, e.g. in the case of dates, more recent dates are likely to span over more columns than more dis-tant dates; and a cell containing  X  X otas X  or  X  X ota X  will most likely only span over itself. Hurst X  X  [ 22 ] language model may also be useful in these situations, as it captures context specific expressions and can be trained.
 Output : The full physical and functional models of each ta-ble have been derived.
 Evaluation : The total number of spanning cells accurately delimited in terms of the columns/rows they span. This is an interesting moment to reapply Hurst X  X  [ 22 ] physical model evaluation metric at cell and column/row levels (see Sect. 4) and see how it has improved over the obtained after Segmen-tation I. 5.6 Structural analysis I Goal : The purpose of this task is to connect each data cell to all attribute cells that characterize it, thus grouping those cells that have to be read conjointly.
 Process : In structural analysis, we use the same sort of heuristic approach that was described in Sect. 3.4. Output : Data X  X ttribute groupings, i.e. the reading paths of each data cell has been defined. The reading paths of those data cells with empty values in the header column may be incomplete.
 Evaluation : To assert the quality of the derived structural model of the table, we will use recall and precision based on the database-type queries similar to proposed Hu et al. [ 16 ]. This evaluation, however, will only be conducted after Structural analysis II (Sect. 5.7.5). From this step onwards we will divert to an end result evaluation, at the end of the method.
 Error : The simple heuristics used will not allow us to infer that the number 2.455.535 appearing in the last line of the balance sheet in Fig. 17 really refers to the concept  X  X mobi-liza56es incorporeas X  (intangible assets) shown in the sec-ond cell of the header column. We will have to come back to this during the interpretation stage. 5.7 Interpretation Goal : Pair the Items we want to extract with the respective Data extracted from the document.
 Overview : Only so much can be done in terms of table in-terpretation without reaching for world or context-specific knowledge. This is also valid for human users: one has to have some knowledge of accounting to fully understand the information contained in a financial report and the intrinsic links connecting the items displayed.
 terpretation of the information presented in the tables, taking full advantage of the set of constraints the data must obey within its context, while maintaining the method X  X  operabil-ity in other contexts. This goal can be obtained if:  X  the system can function with or without a knowledge  X  the knowledge source is an independent component, 5.7.1 Opportunities and risks to information extraction within accounting Accounting information holds a large set of partitive rela-tions, where the addition of several elements must equal other elements, which in turn can be added together to form yet other elements placed higher in the hierarchical tree of accounting concepts. In accounting, most tables are numeri-cal and in this sort of tables, whenever the leaves of a concept are presented, their root is also displayed. On the other hand, some items (e.g. profit and loss of the accounting year) ap-pear with the same value in different tables of the statement. This sort of constraints provides a powerful tool to:  X  guarantee the coherence of the information extracted;  X  improve risky decisions made in previous steps, because As risks, it should be stated that different accounting items may have the same or very similar names but appear in dif-ferent positions in the table and in the tree of hierarchical concepts (e.g. accruals and deferrals exist both on the As-sets and Liabilities side of the Balance sheet).
 accounting knowledge into an ontology that can be used by the method, especially if we consider that accounting rules differ from country to country. Luckily, the work is already being done by professional accountants.
 extension of XML to the specific field of financial report-ing. XBRL taxonomies that describe the national (or juris-dictional) specific accounting rules are or have been cre-ated in the United States, Germany, United Kingdom, Spain, Belgium, among other countries, the list is getting bigger. An XBRL taxomomy comprises: these taxonomies to insure they comply with a minimum set of best practices. Taxonomies encompass a clear view of accounting concept hierarchy and permit identifying which items should be added up to compose others (calculation linkbase); they also permit a clear view of the order each item is expected to appear in the statement and items are grouped according to the tables that normally contain them (presentation linkbase). Furthermore, taxonomies encom-pass specifications of the relationships that hold amongst the items of different tables, by naming those items with the same element ID. As such, they are a powerful tool for sup-plying the method with knowledge on the context at hand. 5.7.2 Listing the items we wish to extract The user will provide the method with a list of all the items it should extract, by selecting items from the taxonomy. The method will generate and append to the list each item in whichever number of ways it is likely to appear in a financial statement. It will do the same for all the items that are likely to appear in the same table. We hope to resort not only to the label linkbases but also to Wordnets for help in this area, although with a large enough set of examples Accounting Wordnets could be derived. An XBRL tag will univocally identify each item.
 sentation linkbase and will contain a numerical column that identifies each item sequentially. We will henceforth refer to this attribute as Key.
 counting context, once a financial statement is presented to the method and the proper taxonomy is identified (eventu-ally these two steps can be done by a crawler rather than the user himself). In other contexts, the user can still operate if he builds the list manually, or adapts other ontologies for the purpose. 5.7.3 Reduction of the search space Goal : At this point, we will use a probabilistic approach to sort the tables in the document according to their likelihood of containing the information we wish to extract. This will limit the application of the remaining computationally more expensive steps to those tables where the effort is more likely to be rewarded. We treat those tables with higher likelihood first and only handle less likely if the first do not contain the desired information after all.
 Overview : The precise location of this step within the overall method has to be carefully evaluated, eventually we would apply it right after Location I.
 Process : We intend to derive the general document structure by identifying headings against any indexes the document may have and possibly the portion of the knowledge base that can identify the content of usual headings in the doc-ument; within the accounting context, we will recur to the main headings of the presentation linkbase. Measurement of the probability takes into account a number of features, such as the position of the identified tables within the document structure as indicated by heading identification; how precise we believe the document structure that has been derived is; the existence and content of any table titles; the presence of keywords; the approximate number of columns and rows (e.g. a balance sheet will always have more than five lines). Evaluation : This is a classification problem with multiple categories; standard classification evaluation metrics will be applied. 5.7.4 Identifying relationships between cells Goal : The main purpose of this step is to further assert that the table under analysis is indeed one of the tables that con-tain information for extraction. The method for doing this will depend on how certain the system is of having found one of the desired tables, in Sect. 5.7.3.
 Overview : There are two main behaviours of relationships types in the accounting context. One of the tables we would like to extract contains a list of characteristics of those com-panies that are held by the company the document is about. XBRL taxonomies do not cover this sort of table. In these tables, among the types of relationships identified in Hurst [ 20 ] and seen in Sect. 3.5, qualitative super-type and nomi-nal super-type relationships are the most common for non-numeric data cells (e.g. in Fig. 18 , Matosinhos is the location of the headquarters,  X  X ede X  (its nominal super-type) and a characteristic of the company Portgas (its qualitative super-type)).
 ble (identifiable, for example, because it has a high concen-tration of company names) this simple heuristic will allow good results in distinguishing both types: for a given non-numeric data cell, the relationship with its column header will be nominal super-type and with its row header it will be qualitative super-type. Moreover, since relationships involv-ing a number (other than a year) are either value (in Fig. 18 , the value of  X % de Capital detido X  is 46,63%) or measure-ment ( X % de Capital detido X  is measured as a percentage), if we properly identify measurement units, all quantitative relations will have been treated.
 in any table where a hierarchy can be detected in the main attribute column, we must also consider partitive relationships, e.g. intangible assets are a part of assets. The calculation linkbases of XBRL taxonomies address this sort of tables and allow a clear identification of partitive relationships in the calculation taxonomy.
 Process for sufficiently high probabilities in Sect. 5.7.3 :If the probability is high enough, we are quite sure of which information the table at hand contains. As such, instead of comparing the items of the table with all the items in the list, which can be computationally expensive, we can make a greedy search: 1. Detect concept hierarchy within the contents of the 2. Improve the hierarchy by verifying arithmetic rules. 3. Follow a top X  X own approach to string match the table X  X  Process for insufficiently high probabilities in Sect. 5.7.3 : 1. Take the content of all the attributes of the most likely 2. Otherwise , take those list items that maximize the simi-3. Otherwise, identify the table of the list to which more ta-4. Verify that the arithmetical rules that hold on list ele-5. Improve the pairs of extractable list item X  X able attribute list not only the attributes in the attribute column but rather the concatenation of all attributes of a given cell except the dates and measurement units, even because XBRL label linkbases often include such concatenations.
 should degrade gracefully: if too few arithmetical rules are verified (the definition of  X  X oo few X  will depend on the list-table at hand), the method should give up on the table and take the next most likely table; if not all rules are found, there is cause to doubt past decisions, namely the full location of tables (previously disregarded surrounding lines should be inspected), or segmentation of cells (the presence of flags to identify more doubtful decisions will be of help), or the at-tribution of cells to wrongful columns or lines (alternative arrangements should be tried). If these alternatives do not solve the problem and the arithmetic difference is of a mate-rial amount (within the accounting materiality is defined by standard auditing best practice), the user should be asked to intervene.
 are different from those outlined by Ferguson [ 11 ]and Kornfeld and Wattecamps [ 29 ]. They created methods that are best applicable to reports produced under Anglo-Saxon accounting standards, where the labels used on each item are not stable. However, under Continental accounting standards a comparison between labels is much more reliable as labels are much more consistently applied by companies, so the first step to detect partitive relations does not have to be the computationally consuming verification of mathematical relationships. The specific order of string matching/arithmetical relationship verification will be decided on an experimental basis, for those two types of accounting backgrounds and for other contexts.
 Output : Pairs of extractable list item X  X able attribute item. 5.7.5 Structural analysis II Goal : The output of Sect. 5.7.3 left the reading paths of those data cells with empty values in the header column incom-plete. The detection of hierarchies done in the previous step allows the reading paths to finally be completed.
 Process : Take all lines with data but no attribute in the at-tribute column. If there is more than one line in that situ-ation, for example the first part of Fig. 17 is such a table, knowing that the value 2.455.535 is the summation of the values in the same column in preceding rows, which form its hierarchical group, its attribute would be searched in the first attribute line that holds no data and is on the opposite end of the hierarchical group. If there is only one line in that situation, the attribute may be the table X  X  heading itself. Output : Pairs of extractable list item X  X able attribute item X  data item.
 Evaluation : Recall and precision based on database-type queries aimed at asserting the quality of the derived struc-tural model of the table, similar to the proposed table in [ 16 ]. 5.7.6 Identifying units of measure Goal : Accurately identifying the unit of measurement of nu-merical data; in the case of currencies, a multiplier should be derived such that the data can be saved in a single database in a single currency.
 Process : Two major types of units are likely to appear in an accounting context: percentages and currencies. In our data set, currencies were often stated in subtitles to each table, but sometimes they were only presented in the bigger tables and for smaller tables the unit had to be inferred from the previous (which is in fact what a human user would do). As such, the system will record the location of all expres-sions in the document that may refer to currencies and their multipliers (e.g. thousand, million). Each table will be clas-sified under the currency that is stated closer to it, preferably above the table on the same page and not embedded in text. The currency thus obtained will be tested: arithmetic rela-tions among items of different tables will be verified and the coherence of certain ratios will be accompanied (in a way similar to that outlined by Ferguson [ 11 ]).
 the database is in EUR, the method may perform the conver-sion by including a table with the daily currency conversion ratios, which it updates over the internet.
 Output : Pairs of extractable list item X  X able attribute item X  data item X  X nit of measure. This output can be saved in a relational database.
 Evaluation : Percentage of list items accurately extracted; the time the end-to-end process took was recorded. This is an end-result evaluation. 6Conclusion We have designed the basic characteristics of an end-to-end method for extracting information from tables. After delim-iting our research area by defining what a table is, we have identified the major tasks such a method should address. We have conducted a thorough bibliographical analysis aimed at characterizing the solutions found by different authors for those tasks. An important contribution of this paper is not only in drawing the path that research in this area has been taking, but also highlighting some key issues no author has accurately solved so far.
 uation approaches and its difficulties. We propose two new complementary metrics to evaluate the capacity of segment-ing different table elements, be it columns, rows or cells in a method; we believe these metrics fulfil one important gap in current evaluation approaches.
 cessing method and presented its main components. It re-ceives a simple input, ASCII, to which virtually any doc-ument type can be transformed. The fist step, table loca-tion, adapts its performance to the assessed difficulties of a given document, grounding decisions on a number of di-verse features, which makes it more robust. Within a sam-ple of 22 different documents with over 90,000 lines in to-tal, it managed to reduce search space by between 50% and 70% while keeping between 95% and 99% of the relevant information. In general, the overall method does not work linearly: we use the output of later steps as input to ear-lier ones, thus taking advantage of the extra knowledge each stage provides to improve the quality of the previous. For example, the functional model of a table has the potential to: (a) improve segmentation of spanning cells which content does not encompass all cells it is vertically aligned with; and (b) unmerge similar vertically/horizontally aligned ta-bles; so we return to location and segmentation after func-tional analysis. Throughout the method, flags are left be-hind to signal decisions that are considered to be more error-prone.
 Specifically we have seen how increasingly common XML-based context-specific taxonomies can be adapted as a knowledge source to the method, functioning as an inde-pendent component that can be replaced. Because of this aspect and because the tasks before interpretation are con-ducted in the most general way possible, the method may be easily adapted to different contexts. The constraints that the context imposes on the results can be used to assert the ac-curacy of the extraction performed; more importantly, they provide the method with ways to detect its own mistakes and correct them by following the flags left behind in previous stages; finally, user intervention can be requested when the constraints are not met by a significant amount.
 the steps outlined and conduct a thorough evaluation of the results. We will pursue the search for better alternatives for each step but also for the integration of the different steps. References
