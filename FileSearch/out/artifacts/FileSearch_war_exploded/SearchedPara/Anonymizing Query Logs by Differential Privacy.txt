 Query logs are valuable resources for Information Retrieval (IR) research. However, because they are also rich in pri-vate and personal information, the huge concern of leaking user privacy prevents query logs from being shared from the search companies to the broad research community. Both-ered by the lack of good research data for years, the au-thors of this paper are motivated to explore ways to gener-ate anonymized query logs that can still be effectively used to support the search task. We introduce a framework to anonymize query logs by differential privacy, the latest de-velopment in privacy research. The framework is empiri-cally evaluated against multiple search algorithms on their retrieval utility, measured in standard IR evaluation met-rics, using the anonymized logs. The experiments show that our framework is able to achieve a good balance between retrieval utility and privacy.
 Privacy-Preserving Information Retrieval, Query Log Anonymization, Differential Privacy
Query logs are essential research resources for Informa-tion Retrieval (IR), especially for the field of Web search. However, releasing query logs without proper anonymiza-tion may lead to serious violations of users X  privacy. This was the case in 2006 when American Online (AOL) released an insufficiently anonymized version of their query log [1]. Table 1 shows a sample of this AOL query log.

Existing work on query log anonymization has attempted to protect the privacy of search logs in many ways. For in-stance, [1, 3] used clustering techniques and k-anonymity, which assumes each query to be issued by at least k dif-ferent users, to anonymize query logs. The limitation of a k-anonymity approach is that its privacy guarantee can be easily broken when an adversary knows information about the users from an unexpected source. When an adversary knows about the user more than what the k-anonymity al-gorithm assumes, the adversary could join the unexpected Table 1: A Sample of the AOL Query Log during March 2006, from User 2178.
 source with existing ones and break the privacy guaran-tee. A stronger privacy notation is thus needed in query log anonymization.

In this paper, we propose to use differential privacy [6, 8] to anonymize a query log. Differential privacy is the state-of-the-art approach which provides a strong privacy notion. It has been widely used in the database and data mining communities. Differential privacy provides guarantees which can be theoretically proved that every individual user in the datasets would not be identified. Unlike k-anonymity, differential privacy does not make assumptions about the amount and scope of an adversary X  X  background knowledge.
A query log anonymization mechanism A ( Q ) satisfies ( , X  ) -differential privacy if for all neighboring query logs Q and Q 2 , and for all possible outputs Q  X  the following in-equality holds: Pr [ A ( Q 1 ) = Q  X  ]  X  e  X  Pr [ A ( Q 2 where and  X  are two model parameters related to the level of privacy guarantees. The smaller their values, the better the privacy guarantee. Specifically, a differentially private algorithm achieves -differential privacy if  X  = 0, which is even stronger than ( , X  )-differential privacy.

In addition, most existing work in query log anonymiza-tion [8] measured the utility of the anonymization output in terms of the size of the remaining logs, without measuring a utility that is directly related to retrieval performance. It is thus difficult to tell how much utility is left in the query logs after anonymization in terms of how useful the logs is when we use them to retrieve relevant documents in a Web search algorithm. In this paper, we propose the retrieval utility function from the viewpoint of a search engine to re-port the actual usefulness of query logs after anonymization by differential privacy. Our approach achieves -differential privacy with  X  = 0.

To evaluate our approach, we experiment on the task of document retrieval with the anonymized query log using two Web search algorithms, a query-click model [4] and an im-plicit feedback model [2]. We then calculate the utility of the anonymized query log using retrieval effectiveness measures such as nDCG [7]. The results show that our framework is able to generate anonymized query logs that maintain a good level of retrieval utility. In another experiment on the
Qu ery Counts Qu ery Clicked-through URL Counts Qu ery Next Query Counts weather 13826 w eather http://www.weather.com 4190 w eather aol weather 44 ... .. . . .. tradeoff between privacy and utility, the framework is shown to be able to achieve a good balance between the two.
This section presents our formulation of the query log anonymization problem.

Query Log Q : Query log Q is a textual document that records query data between the search engine and its users. Usually, it contains a record for each user including the user X  X  id, the query, a ranked list of URLs that the search engine returns to the user, click-through information, and times-tamps for all user actions.

Web Search Using Query Logs: Given a query q and a query log Q , the task of Web Search is to provide a ranked list of documents or URLs D that is relevant to q , from a set of documents or URLs that are built into a pre-indexed corpus C . Most Web search algorithms fit into this set-ting. User clicks, query reformulations, time spent exam-ining the returned documents, and clicked documents on similar queries shared by multiple users are often the key elements used in a modern Web search algorithm.

The Task of Query Log Anonymization: Given an input query log Q , the task is to produce a version of the log in which the identifiable data is removed and the remaining data is adequately anonymized so as to reduce the likeli-hood of re-identification of users. The output of this task is an anonymized query log Q 0 , with a guaranteed degree of privacy.

Privacy Function A : An anonymized query log Q 0 is generated by applying a privacy function A on the original query log Q . That is, Q 0 = A ( Q ). Usually, A is parame-terized to indicate the level of privacy that Q 0 can achieve. For example, in differential privacy, is the parameter in A , i.e., Q 0 = A ( ,Q ). Smaller values indicate higher levels of privacy protection.

Utility Function U : In privacy-related research, the re-maining utility of the data after applying a privacy function on it is an indispensable part of the research. Usually, a utility function U needs to be domain specific to be able to evaluate the usefulness of the data in a domain. The utility function can be applied on both the original data U ( Q ) and the anonymized data U ( Q 0 ) to compare the utility deduc-tion.

Utility Function for Web Search: In the context of information retrieval, a utility function U could be a two-step process  X  the first is to use the query log for document retrieval, i.e., to retrieve a set of ranked documents D for any q  X  Q , where D = R ( q ) ,q  X  D and R is a retrieval algorithm. The second is to use IR evaluation metrics E to measure how good the retrieved document list D is with respect to each q being evaluated; that is E : E ( D ). There-fore, the utility function of a query log Q can be represented as U ( Q ) = E ( R ( Q )), where E is a retrieval effectiveness measure for search results generated by R .

Goal: The goal of a successful query log anonymiza-tion algorithm is to have | U ( Q )  X  U ( Q 0 ) | &lt;  X  , where  X  is kept small. At the same time, a successful query log anonymization algorithm should ensure that the privacy level : Q 0 = A ( ,Q ) is small enough to provide high privacy guarantee.
In order to improve the privacy level of query logs to match the specifications of differential privacy, a search record might be removed or modified into a set of statistics. However, we need to be aware that such changes made on the original data only make sense if the remaining logs can provide enough information to be useful, in our case, to still be able to support Web Search. This section explains the output format of query log anonymization in our framework.
Firstly, we need to keep queries, which are central in query logs. They are kept in the textual format as they are. Low-frequency queries are removed since they are too unique and greatly increase the chance to break privacy guarantee if they stay. Next, the click-throughs are also key data in a query log. However, they can only be released in a sta-tistical format in order to apply differential privacy on the log. Therefore, we aggregate all the click-throughs and show them as summary counts (see Table 1). Furthermore, highly identifiable features such as the user ids are removed dur-ing anonymization. Therefore, they are not shown up in the output log. Finally, we also maintain query transitions in a query log, allowing researchers to develop more advanced web search algorithms for multiple search queries in sessions.
The following format is proposed for an anonymized query log (shown in Table 2). Each anonymized query log Q 0 con-sists of three parts. The first part contains the released search queries and their corresponding frequencies in Q . No-tice that all queries in Q 0 are in plain text, allowing re-searchers the opportunity to develop full-text retrieval algo-rithms. The second part contains click through data for each of the released query-URL pairs. Each line shows a query, a clicked URL for this query, and the number of clicks for the query-URL pair. The last part of Q 0 contains information about the query transitions in Q . Each line shows a pair of adjacent queries and the frequency of this query transition. To achieve differential privacy [6], all of the statistics in Q could be modified with Laplacian noise [10].
We care about both the privacy levels and the utility it re-mains after being private. On the privacy side, our query log anonymization algorithm is a significant improvement upon [8] where their approach provides an ( , X  )-differential pri-vacy while we can achieve -differential privacy. We achieve this by making use of an external stochastic query pool to expand the query set. On the utility side, we are probably the first to use the IR evaluation metrics to measure the utility of an anonymized query log.

The main steps of anonymizing a query log Q are: 1) Remove Sensitive Data. We remove unique queries (frequency less than 5) or queries containing unique terms. This is to filter out sensitive data such as SSN or bank ac-count numbers. 2) Limit User Activities. We only keep the first q f number of queries and the first c f number of URL clicks for a user who has been logged in Q . The remaining set of search records forms Q clean . 3) Expand the Query Set. We define a query pool Q p as the collection of poten-tial queries to add into a query log. Query log owners, such as search engine companies could extend a to-be-released query log with more queries sampled from search records outside of this to-be-released log. Theoretically, every suf-ficiently frequent query gets a chance to be included in the expanded set. In this paper, we simulate this process by us-ing high-frequency n-grams in general English [5]. We refer the combined set of queries as Q + , where Q + = Q clean + Q 4) Select Final Set of Queries. We use Lap ( b ) as the Laplacian noise with parameter b [6]. We define the fuzzed query counts as the original query counts plus the corre-sponding Laplacian noise. We choose to release a query q when its fuzzed query counts ( M ( q,Q + ) + Lap ( b )) is greater than a threshold K . Here M ( q,Q + ) is the frequency of the query q in Q + . Note that the added queries can also be released with fuzzed query counts if the counts are greater than the threshold. The final query set generated after this step is referred to as Q reduced . 5) Generate Log Statis-tics. As presented in section 3, we release the query counts and click counts for each URL. All counts are fuzzed with Laplacian noise. 6) Generate Query Transitions. We also release the query transition information to preserve se-quential information of the query logs. We release adjacent query transitions from Q clean with fuzzed counts, if both queries are included in Q reduced .
As we defined in Section 2, the utility function of a query log Q in the context of IR is U ( Q ) = E ( R ( Q )), which is a nested function of two parts, retrieval and IR evaluation. Part 1: Retrieval The first part is to use the query log Q for document retrieval, i.e., to retrieve a set of ranked documents D for any q  X  Q . This step produces ranking lists which we denote as R ( Q ). In this preliminary work, we test our approach of generating Q 0 using two click-based Web search algorithms. One is a random walk algorithm based on the query-click graph, and the other uses clicks as implicit feedback. Both of them do not require access to document content.

The first retrieval algorithm is based on a random walk model, a variation of a popular web search algorithm pro-posed by Craswell et al. [4]. In the graph, nodes are queries and documents (URLs), while the transitions include clicked documents from a query, adjacent queries in the original log, and self-loops to a node itself. The transition probability P ( k | j ) from a query node j to a document node or another Table 4: Utilities with Random Walk. Two-tailed t-tests ( p &lt; 0 . 01 ) show that no significant difference of utility scores before and after anonymization.
 query node k is calculated by: where, C jk is the weight between node j and k given by Q and s is the self-transition probability. If both nodes j and k are query nodes, weight C jk is defined as the query transition counts from j to k in Q 0 ; otherwise, if j is a query node while k is a document node, weight C jk is defined as the click-through counts for this query-document pair in Q 0 . In our approach, we set the self loop probability s = 0 . 1. Consid-ering the cost of computation, each time step we start from a test query node, random walk three steps before stopping. After that, we can rank documents in descending order by the probability of being the stopping node.

The second retrieval algorithm we implemented is based on implicit feedback from user clicks, which is a variant of [2]. Given a query q , the relevance score S ( d ) for each document d is calculated as: where  X  is a parameter to weight the importance of user click. O d is the original rank which is ranked using the order of click-through counts of document d with the query q , according to Q 0 . I d is the rank of d from Q Test when the user made the click. In our approach, we empirically set  X  = 0 . 6. Finally, the documents are ranked in the descending order of S ( d ) scores for each individual query q .
 Part 2: IR Evaluation The second part is to apply IR evaluation metrics on those retrieved documents and to generate a final set of numerical scores to indicate the level of retrieval utility. We apply the evaluation metrics E to the ranked list R . We evaluate the search results using standard IR evaluation metrics such as nDCG [7] and MAP (Mean Average Precision) [9].
We use the AOL query log [1] for our experiments. Ta-ble 3 presents the major statistics of AOL query log. For each parameter setting, the experiments are conducted in the following order: (1) A 5-fold cross validation is used to partition the data. In each run, we use 80% of the data as the training set Q and the remaining as the test set Q Test ; (2) Table 5: Utilities with Implicit Feedback. Two-tailed t-tests ( p &lt; 0 . 01 ) show that no significant dif-ference of utility scores before and after anonymiza-tion.
 Figure 1: Relationships between noise b , query cut-off K and utility score nDCG @10 .
 The proposed -differentially private query log anonymiza-tion framework is applied to anonymize the query log. (3) Documents are retrieved using the algorithms as described in Section 5 for queries in Q Test ; (4) These retrieval algorithms are also run on the original log Q to compare their perfor-mance against that when the anonymized log Q 0 is used. We report the utility scores in nDCG@10 [7], Precision@5,@10, and MAP.
We first compare retrieval results using the original query log ( Q ) and the anonymized query log ( Q 0 ). Table 4 com-pares the performances of the Random Walk algorithm on query logs before and after anonymization while Table 5 compares the performances of the Implicit Feedback algo-rithm on query logs before and after anonymization. The anonymized query log used in both tables is the same and was generated with the settings = 29 . 99, query counts threshold K = 500, and noise scale b = 10. Within each of the two tables, statistical significance tests (two-tailed t-tests, p &lt; 0 . 01) show that the performances on query logs before and after anonymization are not significantly differ-ent from each other. This confirms that the retrieval effec-tiveness of our anonymized query log is comparable to the retrieval effectiveness of the un-anonymized version.
More privacy guarantee would consume more utility of an anonymized query log. Here we also study the privacy-utility tradeoff with different parameter settings. Figure 1 shows the utility score (measured in nDCG@10) for the Implicit Feedback algorithms using Q 0 with different values for the query cutoff threshold K and the noise level b . Fixing all the other parameters including the log size, we range both K and b from 10 to 500. Figure 1 plots the trends between the utility scores and the parameter values. Each data point represents the average from a 5-fold cross-validation exper-iments. We observe that as the noise level b increases, the utility scores nDCG @10 decreases. We also observe that the utility score is less sensitive to b when b is much smaller than K . This matches our intuition that larger noise (com-paring with K ) will reduce retrieval performance and cause decreased utility.
In this paper, we introduce a framework for anonymizing search query logs and evaluating their Web search utility. We apply differential privacy, which is a strong privacy no-tation, to anonymize the logs. The experiments show that the Web search algorithms using the anonymized logs do not perform significantly different from those using the orig-inal logs. Since the high-level privacy has been guaranteed by our -differentially private anonymization algorithm, we suggest that search engine companies might be able to use less strict parameter settings and still maintain high util-ity. By proposing a new query log anonymization algorithm and a novel utility evaluation framework, our work makes an important step towards releasing Web query logs. This research was supported by NSF grant CNS-1223825, NSF grant IIS-145374, and DARPA grant FA8750-14-2-0226. Any opinions, findings, conclusions, or recommen-dations expressed in this paper are of the authors, and do not necessarily reflect those of the sponsor.
 [1] E. Adar. User 4xxxxx9: Anonymizing query logs. In [2] E. Agichtein, E. Brill, and S. Dumais. Improving web [3] C. Carpineto and G. Romano. Semantic search log [4] N. Craswell and M. Szummer. Random walks on the [5] M. Davies. N-grams data from the corpus of [6] C. Dwork. Differential privacy: A survey of results. In [7] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated gain-based [8] A. Korolova, K. Kenthapadi, N. Mishra, and [9] S. Robertson. A new interpretation of average [10] R. Sarathy and K. Muralidhar. Evaluating laplace
