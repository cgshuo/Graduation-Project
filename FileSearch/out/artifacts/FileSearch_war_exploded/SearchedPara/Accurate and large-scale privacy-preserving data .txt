 1. Introduction broad applications in areas related to market research, as well as to financial and scientific research. Despite the potentials for offering valuable services, there have been concerns about the handling and use of sensitive information by data mining systems [3,4]. The problem is even more intense nowadays with the proliferation of the Web and ICT technologies, and the progress in network, storage and processor capacity, where an enormous pool of sensitive digital data can be easily gathered, or inferred from massive collections of public data such as in social networks, by using well-known data mining techniques. Even when access to sensitive data is controlled, public data can sometimes be used as a path towards private data [4]. data mining task may be also increased when data are collected from various locations. With distributed databases , data may be horizontally or vertically partitioned among a set of sites, where each site may hold similar data about different people or distributed setting, also known as Client to Server (C2S) [5], customers may be on hold of their own collections of sensitive data. Such data may need to be correlated with other clients X  data, for example in order to provide some useful service. From a security point of view we note that, in both settings, sites and clients may be mutually mistrustful. As a result, the tradi-tional warehousing approach, where dispersed data are gathered into a central site for building the mining model, raises pri-vacy concerns. The trivial approach of performing data mining at each site independently and then combine the results (e.g., [6]) cannot always be accurate [7,8] or even possible (e.g., in the C 2 S setting).

Furthermore, organizations and people are often reluctant to share their private data due to law, compliance, ethics, com-tistical information (e.g., sum, count, average, entropy, information gain, etc.) without compromising the privacy of the individuals [12], the need for privacy can also be viewed from a different angle: it would enable collaboration between data privacy concerns may prevent improving the accuracy of data mining models. To this end, privacy-preserving data mining (PPDM) has been evolved as a new branch of research [13].

Traditionally, the use of cryptographic primitives has also been well studied by the database security community [14].In the PPDM setting, recent results have exemplified the inherent trade-off between the privacy of input data and the accuracy of the data mining task. Contrary to other strategies, modern cryptographic mechanisms usually do not pose such dilemmas and offer formal definitions, clearly stated assumptions and rigorous proofs of security. Frequently however, such mecha-nisms may be rather inefficient. In the distributed setting for example, where sites may also be mutually mistrustful, much setting however, there is a need for solutions that are both efficient and rigorous. Challenges increase when we also desire scalability, where a large number of clients (e.g., thousands or millions) may participate in the mining process. 1.1. Our contribution
In this paper we work at a high level and discuss design and security requirements for large-scale PPDM in the C 2 S set-ting. We also explore whether it is possible to use efficient cryptography at the application layer to fulfill our requirements and perform PPDM in statistical databases, while maintaining the accuracy of the results. To this end we argue in favor of borrowing knowledge from a broad cryptographic literature for Internet elections. We discuss similarities and differences with our system requirements and refer to generic privacy-preserving models for large-scale elections. We argue in favor of using a variation of the classical homomorphic model [16] as a framework for large-scale PPDM in C 2 S statistical dat-abases. More specifically we consider some recent extensions of the classical model, proposed in [17,18] , for multi-candidate tributed customer databases and discuss its security, efficiency, and possible extensions. Furthermore, we discuss some weaknesses and describe an attack on a recent scheme of Yang et al. [1] which was the first work that used the homomorphic encryption primitive [16] for PPDM in the C 2 S setting. Finally, we use our PPDM approach as a building block to obtain a Random Forests classifier over a set of homogeneous databases with horizontally-partitioned data, and present experimental results. The preliminary idea of this work has been published in [19]. 2. Related work
A very common approach in the PPDM literature has been data perturbation , where original data are perturbed and the data mining model is built on the randomized data. For example, data perturbation has been used for classification [20] and requiremen ts: the privacy of the individual data and the accuracy of the extracted results [12,23 X 25] . In addition, there are cases where the disclosure of some randomized data about a client may reveal a certain property of the client X  X  private infor-mation, a situation known as a privacy breach [21,25] .

Following the line of work that begun with Yao X  X  generic secure two-party computation [26], and extended to general-purpose Secure Multiparty Computation (SMC) (e.g. [15]), most proposals in the cryptographic literature for PPDM are based on what is also known as the collaborative approach (e.g. [3,7,27 X 29,10] ). This approach involves special-purpose protocols that belong to the SMC family of privacy-preserving protocols. These are interactive protocols, run in a distributed network by a set of entities with private inputs, who wish to compute a function of their inputs in a privacy-preserving manner; pri-vacy here means that no more information is revealed to an entity than can be inferred from its own input and output, and from the output of the joint computation [30]. The collaborative approach has been used for mining association rules on both systems as they require multiple communication rounds among the participants and are efficient as long as the number of participants is kept small. With larger scales and data sets, privacy usually comes at a high performance cost [31].
Another cryptographic tool that has been used in the PPDM literature is the homomorphic encryption primitive that ex-ploits an interesting algebraic property of several encryption functions, where for example there is an operation defined on the message space and an operation defined on the cipher space, such that the  X  X  X roduct X  of the encryptions of any two private inputs equals the encryption of the  X  X  X um X  of the inputs:
Although the primitive has been used in some recent schemes for collaborative data mining [28,29,34,10] , none of these ap-proaches can be used in the C 2 S setting for large-scale PPDM. To this end, in this paper we will discuss the use of the homo-morphic encryption primitive in view of the design and security requirements that will be defined in Section 3. Very close to our research has been the work of Yang et al. [1] which, to our best of knowledge, was the first scheme that used the homo-morphic encryption primitive in order to build a privacy-preserving frequency mining algorithm in the C 2 S setting. The algo-rithm is then used in [1] as a building block to design a protocol for naive Bayes learning. The authors in [1] also discuss applications to other data mining techniques such as decision trees and association rule mining. We will review the scheme of [1] separately in Section 5.
 security for database systems [12,4] , such as authorization and information flow control (e.g., multilevel and multilateral techniques [39]. We consider these areas as orthogonal and rather concerning aggregate data in more or less controlled environments. 3. Design and security requirements for PPDM in the C2S setting 3.1. Design requirements 1. Statistical databases: We consider data mining systems that extract statistical information (e.g., sum, count, average) from 2. C2S setting: The transaction database is horizontally partitioned and each client is on hold of its own collections of per-3. Large-scale systems : We consider a very large-scale setting where hundreds or even thousands of clients may participate 4. Efficient systems : We require computation and communication efficiency for both clients and miners. No inter-client com-3.2. Threat model honest but curious )or malicious [31]. In our threat model we consider both kinds of adversaries. Semi-honest adversaries are legal participants that follow the protocol specification. They behave the way they are supposed to, they do not collude or sabotage the process, but instead try to learn additional information given all the messages that were exchanged during the protocol. We note that the assumption of a semi-honest adversary has also been seen as a strong assumption (e.g., [40]). structure, in order to distort the system or infer private information. As a miner, Int will try to decrypt partial results and violate the privacy of a (set of) participant(s). We also assume that Ext will attempt to impersonate authorized users and submit forged messages to the system. In our threat model however, we assume that Ext cannot coerce honest clients to re-veal their private inputs or compromise more than t miners, where t is an appropriate security parameter. Furthermore, we permit collusion of up to a certain number  X  t 1  X  of (compromised) miners. 3.3. Security requirements the C 2 S setting. 1. Eligibility : Only eligible clients are able to submit a message to the mining system. 2. Accuracy : Input messages cannot be altered, duplicated or eliminated from the system. 3. Privacy : A crucial aspect of privacy is the unlinkability between input data and the identity of the client who submits it. 4. Verifiability : All clients are able to verify that the output of the mining system is a correct function of the submitted 5. Robustness : The system is secure despite any failure or malicious behaviour by a (reasonably sized) coalition of clients, miners or outsiders.

Note 1 . Stronger notions of privacy, namely receipt freeness or uncoercibility [41,42] could also be introduced in PDDM, under the malicious threat model. Receipt freeness dictates that no client should be able to prove her input to others (even if she wants to). With uncoercibility, no party should be able to coerce a client into revealing her input. While in this paper we do not consider such threats, we take the occasion to note that future research may also consider stronger definitions for PPDM in the malicious threat model. 3.4. Basic building blocks 3.4.1. Threshold cryptosystems
Threshold cryptography [43] has been proposed to establish robustness in distributed protocols. At a high level and for any  X  n ; t  X  threshold cryptosystem, the decryption power can be divided among a set of n independent miners as follows: First, a key generation protocol is executed so that the n miners possess shares of the private decryption key that corresponds to the public encryption key of the system. Second, a decryption protocol where a subset of t 6 n honest miners coopera-tively decrypt a message, without reconstructing the private key. The miners may also prove, in zero-knowledge, correctness of their computation, so that the protocol is robust against any coalition of less than t malicious miners. 3.4.2. Zero-knowledge (ZK) proofs
ZK proofs are prover X  X erifier interactive protocols, where the prover proves a statement and the verifier learns nothing from the prover that he could not learn by himself, apart from the fact that the prover knows the proof [44]. ZK proofs will result in slower computation either at the client or at the miner side, depending on where they are used. In normal operation, they take the form of interactive protocols, however, it is also possible to transform these proofs into non-interactive proofs (public signatures) [45]. 3.4.3. Bulletin boards
A bulletin board was introduced in [46] to allow authenticated communication between pairs of processes in a distrib-uted system. All communication supported by the board is authenticated, each process is assumed to have its exclusive part on the board and messages cannot be erased or tampered with. All public data pertaining to the system (e.g., public keys of miners), may also be published on the board. Boards can be implemented based on an existing PKI and on replicated servers (to deal with Denial-Of-Service attacks). An implementation of the primitive was proposed in [47]. 4. PPDM in view of the election paradigm
We argue that research for large-scale PPDM in the C2S setting could borrow knowledge from the vast body of literature on Internet voting systems [48]. These systems are not strictly related to data mining but they exemplify some of the diffi-culties of the multiparty case. Such systems fall, to a large extent, within our design requirements and also tend to balance well the efficiency and security criteria, in order to be implementable in medium to large-scale environments. In an Internet election for example, an election authority receives several encrypted 1-out-of-2 votes (e.g., either Yes  X  1or No  X  1) and ity for the election result. 4.1. Unlinkability in the homomorphic election model
This model is a general framework for the usage of any encryption scheme with specific algebraic properties in order to protect the privacy of the encrypted votes and establish accuracy and verifiability of the decrypted results. The encryption scheme has to be randomized , to preclude chosen-plaintext [49] attacks on the published encryptions. If this is the case then, without decrypting single votes. 4.1.1. The classical election model of Cramer et al. [16]
In [16] votes are encrypted using a variation of ElGamal encryption [52] with addition as group operation of the message h , according to a threshold version of the ElGamal cryptosystem [16]. Each voter (from a set of c voters) chooses a random ators of G q and all the operations are modulo p . The voter then prepares a ZK proof [16] that the vote is valid, i.e., that m 2f 1 ;  X  1 g without revealing m i ; Otherwise it would be easy for a malicious voter to manipulate the final tally. The voter then signs and publishes the encrypted vote and the proof of validity on the bulletin board. At the end of the voting period, privacy is reduced to the Decisional Diffie Hellman (DDH) assumption (the reader may refer to [16] for formal security arguments).

Privacy is established in a strong cryptographic sense and the homomorphic property of the encryption scheme makes easy to establish universal verifiability for the final results, simply by performing a multiplication of the encrypted inputs and comparing the encrypted aggregate to the value published on the board. Robustness and fault-tolerance are ensured with threshold decryption, where a set of honest authorities cooperate and decrypt the encrypted aggregate. 4.2. Other generic models for unlinkability ability [53]. In the Mix-net model (e.g., [42]), encrypted votes are shuffled (e.g., re-randomization and re-ordering of the votes) by a set of mix servers who prove, in ZK, the correctness of their computations. Finally, in the blind signature model by the voter and a validated vote is submitted to the authority, using an anonymous channel.
 ments. For example, the homomorphic model allows for Yes = No voting and supports efficient tallying, whereas the Mix-net model allows for plaintext votes but is less efficient in the tallying stage, because of the ZK proofs of correct mixing. 4.3. PPDM and the homomorphic (election) model semi-honest model there may be no need for clients to construct complex ZK proofs on the correctness of their inputs. If we consider the malicious model, there have been some efficient constructions for ZK proofs of validity (e.g., [17,18] ). In addi-struct and choose among lightweight versions of some well-known cryptographic schemes that follow the homomorphic model, and adopt them to our PPDM setting. In Section 6 we will describe a simple scheme for PPDM, based on the classical homomorphic model. 5. Review of the Yang et al. [1] scheme sesses his own data. We briefly describe the PPDM protocol of [1], where a miner mines a large number of client data sets to compute frequencies of values. Let G be a group where the Discrete Logarithm problem is hard. All operations are done modp , where p is a publicly known and sufficiently large prime number. In a system with c clients, each client possesses two pairs of ents in the system use a variant of the ElGamal encryption scheme [52]. For correctness and privacy analysis, please refer to [1].

Observe that in the scheme of [1], as well as in the scheme of [16], the computation of the tally (i.e., the result d that equals the sum of the plaintext inputs) involves a brute-force attack on the value g d modp , and specifically O  X  entiations in order to find the discrete logarithm. This stands because there are no trapdoors to compute d from g d in ElGamal variants. In settings with only two candidates (e.g., yes/no ) this is a relatively easy computation, at least for a moderately ing the result would be O  X 
We briefly describe two issues concerning the protocol. The first one refers to the need that each client must choose new x and y i values after each execution of the protocol. This is actually a requirement in every randomized encryption scheme, where new randomness is used to increase the cryptographic security of the encryption process against chosen-plaintext this as a scalability issue: Prior to the execution of each run of the protocol (e.g., possibly during a key setup phase) each a fully distributed and large-scale scenario, where a very large number of system clients hold their own records, it may be difficult to pre-compute and/or publicize these values, turning the key setup phase into a complex procedure, especially in cases where the number of participants is not constant through different runs of the system.
 In [19] we also argue that a single client may be able to disrupt the system. Indeed, in a system with say three clients U ; U 2 ; U 3 , let us assume that U 2 does not send her input, because of a system crash. Then the protocol executes as in Fig. 2 and a result cannot be found. One could argue that in the semi-honest threat model, all clients will adhere to the pro-tocol specification and will not abstain from the protocol, however this may be considered as a strong assumption, especially in large-scale protocols (e.g., 10,000 clients in the experimental results in [1]). Furthermore, the semi-honest model does not preclude non-malicious system crashes or network failures. Observe that a client does not know a priori who will participate in the protocol, so the obvious fix of constructing the values X and Y as a function of the number of active participants will not work. 6. A generic PPDM approach for large-scale C 2 S systems
For large-scale PPDM in the C 2 S setting we adopt a variation of the classical homomorphic model. More specifically, our approach will be based on some efficient extensions of the homomorphic model, where 1-out-of - X  or k-out-of - X  selections are allowed (e.g., [17,18] ). 6.1. Background
In the usual ( 1-out-of-2 ) setting (e.g., either Yes  X  1or No  X  1), a client who does not want to participate may give false to participate, although we may consider this as a privacy violation. As a result, the null input should also be considered in distributed mining protocols. Furthermore, knowledge cannot always be represented with a Yes/No decision. For example, a client may have to answer which group (e.g., among  X  age groups) her age belongs to. As a result we are interested in multi-candidate schemes, where in the simplest 1-out-of - X  case each client makes one selection out of  X  candidates and sends this privately to a frequency miner, as shown in Fig. 3 .

Multi-candidate protocols have been first investigated in [50] and further studied in [16], where the computation of the final tally grows exponentially with the number  X  of candidates. Baudron et al. [17] proposed the use of the Paillier crypto-system [55] for conducting homomorphic elections with multiple candidates. The Paillier scheme provides a trapdoor to di-rectly compute the discrete logarithm, thus making the computation of the tally efficient, even for large values of c and  X  . They also presented a threshold version of the Paillier cryptosystem, as well as a ZK proof of validity for an encrypted mes-sage. We briefly recall the Paillier cryptosystem, leaving out some details on key generation and decryption [55]. Let N  X  pq be an RSA modulus where p and q are two large primes, and g be an integer of suitable order modulo N 2 . The public key is  X  N ; g  X  while the secret key is the pair  X  p ; q  X  . To encrypt a message m 2 Z n , choose a random x 2 Z n and compute tosystem has the homomorphic encryption property as in Eq. (1). 6.2. Assumptions homomorphic encryption property (e.g., the Paillier scheme). All questions to a database can be reduced to a set of 1-out-protocol has already taken place and the system X  X  parameters and the public encryption key of the miners is published on the bulletin board, while the miners possess the matching shares of the private decryption key, according to a threshold version of the cryptosystem. 6.3. A simple frequency miner 1. A client j who wishes to select the i th answer, encrypts a message with the public key of the election authorities. For 2. When a deadline is reached, the miners check the proofs of validity and compute the homomorphic  X  X  X roduct X  of the generality we adopted the notation of [17] for 1-out-of - X  selections and assumed Paillier encryption, however any trapdoor discrete logarithm with the homomorphic encryption property can be used instead (please refer to [17] for a list of candidate cryptosystems). 6.4. Security considerations
The above approach, if instantiated with Paillier encryption provides computational privacy under the Decisional Compos-ite Residuosity Assumption (DCRA), which is required to show that a Paillier encryption is semantically secure [17]. If non-interactive proofs of validity are employed, the same result holds under the random oracle model. For verifiability, a client is able to check whether its encrypted input is valid and has been taken into account by the mining system. Each client is also able to compute the homomorphic product of the elements on the board and thus verify the accuracy of the mining process. In the presence of malicious or faulty miners, robustness is a result of the setup for a threshold cryptosystem. The reader may also refer to [17] for formal arguments concerning the threshold version of the Paillier cryptosystem and the ZK proofs. 6.5. Efficiency considerations
In the (simplest) semi-honest case, where ZK proofs and threshold decryption are not considered, each client performs two public-key operations, one for encrypting and one for digital signing the selection before uploading to the board. This firmed using O  X  c  X  multiplications. The communication complexity is linear in the size of the Paillier modulus and the number c of clients. A message consists of one ciphertext and one signature accompanied with a digital certificate. Assuming that the similar signature modulus. The computation cost for the miner(s) is O  X  c  X  multiplications and one decryption operation. Com-pared to the scheme in [1], which is limited to 1-out-of-2 selections, our approach has more efficient key generation and tal-lying process, while the client computation and total communication costs are similar.

For a full scheme with practical complexity, even in the malicious threat model, we propose the adoption of the general-ized Paillier encryption as proposed in [18]. Compared with [17], efficiency is improved as the ballot size is reduced to system. The reader may refer to [18] for further details and formal arguments. 6.6. Mining with k-out-of- X  protocols
Protocols for 1-out-of - X  selections can easily be adapted to support k-out-of - X  selections, where k 6  X  . An easy general-ization, with some loss of performance, would be to send k encrypted messages [18]. Another trivial solution is to encode all possible  X  -bit numbers as separate candidates, thus producing a set of 2  X  candidates. Fig. 5 depicts the trivial approach in the C 2 S setting, where the problem of allowing k-out-of - X  selections from one record with  X  features is reduced to a 1-out-of -2  X  multi-candidate protocol.
 crypted messages to the miner, where R is equal to the rows of the table in his partition. In the semi-honest model however, the above trivial approaches are as secure as the 1-out-of - X  scheme, however this assertion needs to be supported by future work.
 7. Case: PPDM in Random Forests (RF) classification 7.1. Introducing standalone RF motivation that underlies this trend is the need for higher prediction accuracy of the task at hand. Random Forests [56] are a combination of tree classifiers such that each tree depends on the value of a random vector, sampled inde-pendently and with the same distribution for all trees in the forest. The generalization error depends on the strength of the individual trees in the forest and the correlation between them. Using random selection of features to split each node yields error rates that compare favorably to Adaboost [57], and are more robust with respect to noise. While tra-ditional tree algorithms spend a lot of time choosing how to split at a node, Random Forests put very little effort into this.
 randomization. The leaf nodes are labelled by estimates of the posterior distribution over data class labels. Each internal to every tree and by aggregating the reached leaf distributions. The process is depicted in Fig. 6 . Randomness can be injected at two points during training: either in sub-sampling the training data so that each tree is grown using a different subset or in selecting the node tests. In our approach, we shall discuss the former situation, and argue that by using privacy-preserving protocols in randomly selected instances we support the creation of robust RF, thus allowing for effective mining in horizon-tally-partitioned data sets. 7.2. Privacy-preserving RF for horizontally-partitioned (HP) data their data among each other. Thus, we enroll a collaborative approach where data need to be shared in a secure manner, and the final model will predict class labels without knowing the origin of the test instance. Similar to previous approaches such as [27], classification is performed individually, on each party X  X  site, but the main contribution on the field is that during training, data from other parties are used in order to enhance randomness, thus increase the obtained classification accuracy.
However, an assumption needs to be taken into account: data are sharing a common distribution. For example, suppose we distribution among banks, meaning that if one bank owns data on a specific group of customers (e.g., professors) and the others own data about a totally different group (e.g., farmers), the obtained accuracy would be severely deteriorated. We exploit the two strengths of RF i.e., randomness and voting. The former deals with the issue of premature termination of the tree learning process while the latter confronts data sparseness problems in an effective manner. In this work, we con-sider a protocol that allows for injecting randomness into trees during learning and allow voting over the majority class among all parties at classification time. More specifically, we shall discuss Random Input Forests (RI) learning from HP data base parties.
 7.3. Random input forests
Our privacy-preserving approach, used for training Random Forests at each party X  X  side by inserting randomness from the other ones, is consisted of two distinct phases. In the former one, each party is collaborating using the procedure proposed by next phase, where each party will require a certain number of instances from the others (again, we note that more than three parties are needed). The complete algorithm is as follows: Each party selects K trees to grow :
Build each tree by:
To classify a new, unseen instance X , collect votes from every tree of the forest of each party and use a general majority voting scheme to decide on the final class label.
 algorithm mentioned before is significantly reduced. More specifically, instead of each party generating random instances and ask other parties to vote in order to reveal if someone else owns this example, the Data Miner asks all parties to submit votes on their data set. By using the PPDM approach explained in Section 6 the Data Miner can obtain the number of each instance co-occurrence within the whole data set. Therefore, at learning time, each party initially uses its own data and then asks the Data Miner to reveal which K other instances have frequency larger than a given threshold s within the total data set. As depicted in the next section, this approach allows for building more robust classifiers based on RF, yet using PPDM pro-tocols in order not to reveal which party owns each data instance.

The advantage of such a classifier is based on the improved manner of inserting randomness to the core classification trees during training time, yet protecting private information of data records. Since recent trends in classification systems deal with the use of ensemble methodologies, we argue in favor of a novel distributed algorithm that makes use of random-ness in order to improve the internal prediction model. Potential applications that could benefit from such an implementa-tion include financial institutions, insurance vendors, medical institutions and sectors of government infrastructures. 7.4. Experimental evaluation of PPDM using RF
We implemented our privacy-preserving Random Forests algorithm in Java, by augmenting an existing implementation of the Paillier homomorphic cryptosystem, 1 in order to match with the variation described in Section 6.6. Furthermore, we used the WEKA machine learning algorithm platform for generating two different random binary data sets, consisting of 10 and 20 iments on a Dual Core 2 GHz PC with 2GB of memory under Netbeans. As for the RF builder, we incorporated the WEKA li-brary that deals with RF tree classifiers within our project. In our experiments, the length of the modulus for Paillier encryption was 512 bits. We randomly assigned generated data to three different parties (i.e., the Partial Set ) without posing strict HP data set restrictions (i.e., an instance could belong to more than one party). The key-generation time (only per-formed once) was 1.5 s. As mentioned in the RI Forest protocol, each party encrypted its Partial Set and sent in to the Data Miner. The Data Miner received all encryptions and by performing the operations described in Section 6.3, obtained the num-ber of votes that reveal how many times a given instance is found within the total data set. The former operation has com-putational time less than 1 ms for each instance while the Data Miner X  X  computations are somewhat longer but still quite ties and 1000 examples within the Total Set, it took approximately 2.1 s to learn the counts of each instance. Nevertheless, these values can be pre-computed off-line, prior to the RI forests learning phase. We empirically set each party to ask for 70 more instances from the Miner, having a threshold frequency of 1 (i.e., each party adds an instance if it is owned by at least one other party). Upon creation of the new, enhanced data set, each party classified its Original Partial Set, using 10-fold cross validation and also classified its new, augmented Partial Set in order to evaluate the performance of RF when random-ness is injected. Fig. 7 portrays the classification performance in terms of F-measure (which is the harmonic mean of preci-sion/recall metrics) for party A, on the two generated data sets, using the initial Partial Set and the augmented data set from the aforementioned privacy-preserving protocol. ples, more robust RF are built, able to better classify data, by a varying factor of 2 X 4.5% . 8. Future work the trade-off between efficiency and security. Future work will also show how cryptography-based approaches for PPDM can be combined with techniques for controlling access to individual entries in statistical databases, in order to further improve the security of the mining process. For future work, we intend to extend our simple scheme in order to build the confidence and support metrics on a distributed system for mining association rules, where the transaction database is fully distributed among the clients of the system. In addition, we intend to further implement the training methodologies and applying them to real-world, large-scale databases for evaluation. We are particularly motivated by recent trends towards multi-processor systems and parallelization, that could significantly improve the performance of the system.

References
