 The world-wide aviation system is one of the most complex dynamical systems ever developed and is generating data at an extremely rapid rate. Most modern commercial aircraft record several hundred flight parameters including informa -tion from the guidance, navigation, and control systems, the avionics and propulsion systems, and the pilot inputs into the aircraft. These parameters may be continuous measure-ments or binary or categorical measurements recorded in one second intervals for the duration of the flight. Currently, most approaches to aviation safety are reactive, meaning that they are designed to react to an aviation safety inci-dent or accident. In this paper, we discuss a novel approach based on the theory of multiple kernel learning to detect po-tential safety anomalies in very large data bases of discret e and continuous data from world-wide operations of commer-cial fleets. We pose a general anomaly detection problem which includes both discrete and continuous data streams, where we assume that the discrete streams have a causal influence on the continuous streams. We also assume that atypical sequences of events in the discrete streams can lead to off-nominal system performance. We discuss the appli-cation domain, novel algorithms, and also discuss results o n real-world data sets. Our algorithm uncovers operationally significant events in high dimensional data streams in the aviation industry which are not detectable using state of the art methods.
 C.4 [ Performance of Systems ]: Reliability, availability, serviceability; H.2.5 [ Heterogeneous Databases ]: Data Translation; H.2.8 [ Database applications ]: Data mining; H.4.2 [ Types of Systems ]: Decision Support Algorithms, Human Factors, Performance, Reliability Aeronautics, Anomaly Detection, Prediction, Prognostics
On January 31, 2000, a McDonnell Douglas MD-83 was enroute from Puerto Vallarta, Mexico to Seattle, Washing-ton when it experienced a catastrophic failure resulting in the death of 89 passengers and flight personnel as it dived from about 18000 feet into the Pacific Ocean. Analysis of data from the Flight Data Recorder (FDR) and the wreck-age indicated that the probable cause of the accident was  X  X  loss of airplane pitch control resulting from the in-fligh t failure of the horizontal stabilizer trim system jackscrew as -sembly X  X  acme nut threads. The thread failure was caused by excessive wear resulting from Alaska Airlines X  insufficien t lubrication of the jackscrew assembly. X  [4] The precursors t o this accident and other accidents due to mechanical issues and human factors are often evident in large data sets from Flight Data Recorders as well as textual reports written by the flight crew and other persons involved in flight opera-tions. Indeed, an informal study at NASA of FDR data from similar aircraft showed that a multivariate query on certain parameters in the FDR could uncover aircraft with similar mechanical problems.

Boeing recently completed a comprehensive statistical sur -vey of commercial aircraft accidents worldwide [19] which shows a dramatic drop in the accident rate, the fatal ac-cident rate, and also the hull-loss accident rate as shown in Figure 1. These advances have been due to a signifi-cant investment in near-term technologies to improve air-craft safety. However, assuming that air traffic continues to grow at a modest rate of only 3% per year, over the next two decades that will lead to nearly doubling the air traffic within the U.S. The increased density of operations, com-bined with increased demands on service and availability of aircraft can lead to a significant number of aviation accident s even with the current extremely low accident rate.
In 2007, NASA established an archive that contains data from flight data recorders from most of the major carriers in the U.S. The archive, known as the Distributed National Figure 1: This figure from Boeing X  X  Statistical Sum-mary of Commercial Jet Accidents in 2007 shows that the fatality rate of accidents in the United States has dropped significantly over the past five decades.
 FOQA (Flight Operations Quality Assurance) Archive (DNFA) contains over two million flights today and covers over 10 major carriers. Typical FOQA parameters consist of both continuous and discrete (categorical) data from the avionic s, propulsion system, control surfaces, landing gear, the cock-pit switch positions, and other critical systems. These data sets can have up to 500 parameters and are sampled at 1 Hz. For a moderate sized fleet that operates 1000 flights per day, these FOQA data sets become very large. Due to pro-prietary and legal issues, these data are not shared between airlines or directly with the government. Thus, in the DNFA architecture, each carrier has its own data repository, and a primary requirement of the DNFA is that the data from multiple carriers not be centralized. Data in the DNFA is anonymized so that flight numbers and marks identifying pilots and crew are removed. In this paper, we discuss the problem of detecting anomalies in FOQA data that may be indicative of safety issues due to mechanical or human fac-tors issues. We present the results of our anomaly detection algorithms on real FOQA data from a regional carrier. This work is part of a comprehensive plan within the NASA Inte-grated Vehicle Health Management (IVHM 1 ) project to an-alyze numerical data from DNFA and text reports from Dis-tributed National ASAP (Aviation Safety Action Program) Archive (DNAA) to assess the health of large commercial fleets of aircraft.
This paper addresses the problem of detecting anomalies in high-dimensional, multivariate data streams containin g both discrete and continuous channels. We assume that we are given data from a data generating process that can be http://aeronautics.nasa.gov/programs avsafe.htm/ Figure 2: This figure shows our overall approach to addressing safety issues in the aviation system. The automatic identification and causal analysis of hazards from continuous and discrete data streams is the subject of this paper [1]. functionally described by the following equations: We assume that the function  X  determining the evolution of the hidden system state h t is unknown. We also assume that the function  X , which governs the evolution of the continu-ous state vector is also unknown. We assume that the vector x is an N dimensional state vector, and x  X  t  X  1 is its history The quantity u t is the observed system input, and y t is the observed system output which can contain discrete, cate-gorical, and continuous features. We assume that the entire data that is available, covering both inputs and outputs, is given by the set ( U , Y ).

In real-world flight operations, the pilot inputs U are de-termined by standard-operating procedure: for a given air-port, aircraft, weather conditions, instructions from air traf-fic control, and other contextual elements of the flight, the flight procedures are well determined. However, while we can assume that all pilots are attempting to follow the stan-dard operating procedures, some may deviate from these procedures which could lead to a different input sequence U resulting in a different set of observed flight characteristi cs Y . The evolution of Y  X  over time will necessarily be differ-ent than that of the nominal case. This does not imply that the pair U  X  , Y  X  is an unsafe flight X  it is simply not typically observed. Our goal in this paper is to develop algorithms that can detect if the discrete pilot inputs U , combined with the observation vector Y are nominal or off nominal and to diagnose the reason why such a potential anomalous event was so designated.
Data-driven anomaly detection is an active area of re-search (see [7] for details). For example, there are many anomaly detection methods that identify anomalies in the vector space. However to the best of authors X  knowledge, SequenceMiner [5] is the only algorithm that can analyze dis-crete sequences. Preliminary experiments with SequenceM-iner on data from commercial aviation indicate that it is able to find examples of mode confusion, in which a pilot loses track of autopilot mode changes and therefore initi-ates anomalous switching behavior in order to determine the autopilot mode. Because cockpit switch behavior is repre-sented mostly by sequences of discrete switches, SequenceM-iner is a natural algorithm for finding anomalies in such se-quences. Some details on SequenceMiner will be provided in Section 3.3. Other anomaly detection methods, such as Orca [3] and the Inductive Monitoring System (IMS) [12], find anomalies in multivariate continuous data. Both Orca and IMS are distance-based anomaly detection methods, in that they use a metric related to distance, such as the aver-age Euclidean distance to its k-nearest neighbors, to assess the anomalousness of a point. Clearly, the value of this metric is greater for a data point that is more anomalous. In principle, one could use Orca and IMS with heteroge-neous data X  X ata containing both discrete and continuous variables. However, in IMS the discrete variables X  contrib u-tions to the Euclidean distance may not reflect their true importance, and finding the appropriate way to incorporate distances in the discrete and continuous spaces into a com-mon metric is a problem with no clear solution. Addition-ally, Orca and IMS do not learn the sequential dependencies between points in the training data. Here we would like to identify an anomaly detection method that incorporates both continuous and discrete sequences and is able to iden-tify anomalies within each separately but also across the tw o types of data.

Kernel methods [17] have been used for many different types of data with various types of features such as graphs [13] and multiple feature types in computer vision such as color [8] , shape, texture [20], and graphs based on image segmenta-tions [10]. Kernel functions map pairs of objects to the similarity between those objects, with a value of 1 indi-cating maximum similarity and 0 indicating no similarity. Therefore, subject to Mercer X  X  conditions [6], one can de-vise a kernel function measuring similarity among objects of any type and incorporate this into kernel methods for classification, regression, or anomaly detection. This flexi -bility to incorporate kernel functions of different types mot i-vates the question of whether multiple such kernel functions can be incorporated simultaneously. This question brought about the field of Multiple Kernel Learning (MKL) [2, 14]. MKL replaces individual kernel functions with combinations of kernel functions, thereby allowing the kernel method to use multiple kernels simultaneously. MKL was initially used with multiple copies of the same kernel function with differ-ent hyperparameter settings. However, MKL has been found most effective in cases where the different kernel functions use different attributes, such as in computer vision where Support Vector Machines (SVMs) that use a convex combi-nation of kernels using multiple feature sets such as color, shape, and texture, have been found to outperform SVMs that only use one of the kernels [10].

MKL appears to be a promising way to satisfy our re-quirement of incorporating both discrete and continuous se-quences in anomaly detection. We use the kernel anomaly detection method known as one-class Support Vector Ma-chines [18, 16]. We incorporate a kernel over discrete se-quences which is based on the normalized Longest Common Subsequence (nLCS) measure used in SequenceMiner and a kernel over continuous sequences that makes use of the Sym-bolic Aggregate approXimation (SAX) [15] representation. We demonstrate that this Multiple Kernel Anomaly Detec-tion (MKAD) algorithm outperforms Orca and SequenceM-iner at finding operationally significant anomalies in aviati on safety data. To our knowledge, MKL has never been used with sequences or within one-class SVM prior to our very recent poster which shows preliminary results of an earlier version of our algorithm on synthetic data only [9].
We first give a brief but general description of multiple kernel learning based detection technique. Then we describe the two kernels that we use within our model.
As mentioned earlier one of the major advantage of ker-nel based methods compared to other techniques is their ability to combine information from multiple data sources. The way the improved knowledge about the problem can be incorporated in the core optimization problem is very simple yet meaningful. The resultant kernel K can be a convex combination of all kernels computed over multiple features i.e. K ( ~x i , ~x j ) = P n p =1  X  i  X  k p ( ~x P puted data points x i and x j , and  X  i are to weight individ-ual kernels. Here we take advantage of the multiple kernel learning approach to incorporate more knowledge in the de-cision process so that we can achieve an improvement in detecting anomalies in complex heterogeneous systems that involve various data sources and data structures. Since we are interested in anomaly detection we have used the classi-cal one-class SVMs [16] as our core algorithm. A one-class SVM is a semi-supervised learning method that finds a set of outliers using a decision boundary. Below we will provide a brief description of some of the properties of the mapping function and briefly describe the optimization problem of a one-class SVM.

One-class SVMs construct an optimal hyperplane in the high dimensional feature space by maximizing the margin between the origin and the hyperplane. This is done by solving an optimization problem [16]. The dual form of the optimization can be written as, minimize Q = 1 subject to 0  X   X  i  X  1 where  X  i is Lagrange multiplier,  X  is a user specified param-eter that defines the upper bound on the training error, and also the lower bound on the fraction of training points that are support vectors,  X  is a bias term and k is the kernel ma-trix. Once this problem is solved at least  X  X  training points with non-zero Lagrangian multipliers ( ~ X  ) are obtained and The selected points can be marginal I m = { i : 0 &lt;  X  i and non-marginal I nm = { i :  X  i = 1 } support vectors. Once ~ X  is obtained, SVMs compute the following decision function.
If the decision function predicts a negative label for a give n test point x j , then it is classified as an outlier. Test examples with positive labels are classified normal.
In this research our kernel takes the form of, where K d is a kernel over discrete sequences, K c is a ker-nel over discretized continuous time series, and  X  is used to weight the two kernels (in this paper, we always use  X  = 0 . 5). We have 2 where l ~x is the number of symbols in sequence ~x . Given two sequences X and Z , Z is a subsequence of X if removing some symbols from X produces Z . Z is a common subse-quence of sequences ~x i and ~x j if Z is a subsequence of both ~x i and ~x j . The longest such subsequence of ~x i and ~x called the longest common subsequence (LCS) and is de-is a useful metric for measuring similarity between discret e sequences for two reasons. First, it is not restricted to a location-based one-to-one match X  X he LCS can be located within different parts of the two original sequences. Second, the LCS length has an optimal substructure property which is the foundation of a well-known dynamic programming al-gorithm. In particular, the algorithm builds up a table L such that entry L ( i, j ) is the length of the LCS of the first i symbols in ~x i and the first j symbols in ~x j . Entry L ( i, j ) only depends on entries of L for lower values of i and j . Details on the Hunt-Szymanski algorithm which we used to calculate LCS can be found in [11].

The continuous kernel K c ( ~x i , ~x j ) is inversely proportional to the distance between the SAX representations [15] of ~x and ~x j . Briefly, ~x i and ~x j are first divided into some number w bins along the time axis. That is, if both vectors have v variables for n consecutive time points each, then they are divided into w consecutive bins with all v variables and of mostly equal time length (all but the last one contain  X  n/w  X  consecutive time steps and the last bin contains the remainder). The mean value of each variable in each frame is then calculated. So, for example,  X  ~x iab is the mean of the values in the b th time interval of the a th variable of ~x
In all equations related to the discrete and continuous ker-nels, we assume that the discrete and continuous parts of the data points ~x i and ~x j are selected. To reduce notational clutter, we will not include operators to select the discret e or continuous parts of the data points. where ~x iak is the k th time point in the a th variable of ~x Then, for each variable, we fit a normal distribution to all the training data, choose a number of bins c a , and then find equiprobable bins with breakpoints  X  a, 1 ,  X  a, 2 , . . . ,  X  that the area under the normal density function for x  X   X  x  X  [  X  a,k ,  X  a,k +1 ] for all k  X  { 1 , 2 , . . . , c a x  X   X  a,c a  X  1 are each 1 /c a . We assign each bin a discrete label (e.g., letters A, B, C, etc.). We replace  X  ~x iab corresponding discrete label.

So ~x i and ~x j started off having v continuous variables and n time points per variable, and are replaced by a new ma-trix that still has v variables but has w discrete symbols per variable representing the means of that variable in the w consecutive time windows. The advantages of implementing SAX are that both the time and amplitude discretization result in reduction of the noise content as well as reduced dimensionality of the data. The distance between the SAX representations of ~x i and ~x j is simply the nLCS length as shown above in equation (7). Looking at empirical formu-lation of the similarity measure and how the above kernels are constructed it is pretty straightforward to understand that both K d and K c are symmetric positive semi-definite matrices.
Both Orca and SequenceMiner have been chosen as the baseline algorithms. Orca [3] is a K-nearest neighbors ap-proach outlier detection algorithm with a modified pruning technique. For continuous data, Orca takes a nominal refer-ence data set and calculates the nearest neighbors X  using Eu -clidean distance to all test points in the original vector sp ace. For discrete data points the Hamming distance is used. Each data point is scored independently and therefore anomalies in the temporal domain are undetectable. SequenceMiner computes outliers by comparing a set of sequences using the normalized longest common subsequence as the similarity metric. Sequences that are similar are clustered together. Outliers are sequences that have a very low similarity values with the clusters X  medoids. Since SequenceMiner takes into account the order of the discrete switches it has the abil-ity to identify anomalies in the temporal domain, however it is unable to handle continuous data and therefore does not have the ability to detect anomalies in continuous pa-rameters. Among the baseline algorithms, SequenceMiner has been open sourced 3 while Orca 4 is freely available for non-commercial use.

To test the robustness of the MKAD method, synthetic data was generated with various types of seeded faults. This allowed the algorithm to demonstrate its ability to detect each anomaly for comparison against the existing state-of-the-art algorithms. Finally the MKAD method was com-pared with the combined performance of Orca and SequenceM-iner. https://dashlink.arc.nasa.gov/algorithm/sequenceminer-algorithm/ https://dashlink.arc.nasa.gov/algorithm/orca/
To simulate an aircraft system it was assumed that the pilot inputs (the discrete switches) are used to influence the measured continuous output parameters. Therefore the data parameters were chosen with this assumption in mind. Ten binary parameters were simulated with three fundamen-tal behaviors: random flipping, constant throughout, and predefined switching. One parameter was set to randomly switch between 0 and 1, while two parameters never changed states. For the predefined switching six channels would hold a value at their initial state and change to the alternate sta te when a separate channel toggled from 0 to 1.

With the binary parameters generated, the underlying system state can be used to generate continuous data. To construct the continuous data, each continuous parameter was assigned a set of binary parameters as input variables. A set of Gaussian distributions was defined for each possible binary state corresponding to the continuous parameter. Fo r example: if a given continuous parameter was dependent on 2 binary parameters 4 distributions would be generated, if 3 binary parameters, 8 distributions and so forth (see fig-ure 3). At each time step the continuous parameters would draw from its defined distribution for the given state of the binary parameters. This method allows the continuous pa-rameters to vary directly with the state of the binary inputs and therefore have the desired relationship assumed for thi s problem.
 Figure 3: The figure demonstrates a sample distri-bution for a single continuous parameter that is de-pendent on 2 binary parameters.
 This method was repeated for each flight in the data set. A total of 300 flights were synthesized (150 for training and 150 for testing) 5 . Each flight is 1000 sample points long. Four different fault types, three examples of each, were in-jected into randomly chosen flights.
 Fault type I: The first type of fault involves missing switches
The synthesized data set can be downloaded from https://dashlink.arc.nasa.gov/topic/multiple-kernel-learning-based-heterogeneous-algorithm/ Table 1: The table represents the summary of the performance of all three algorithms in detecting the faults in the synthetic data for each fault category. A total of 12 faults have been randomly injected, out of which 3 are continuous and 9 are discrete. MKAD was the only algorithm to detect all fault types. Fault type II: The second kind of fault involves extra switch-Fault type III: The final kind of discrete fault describes out Fault type IV: Apart from all the above three, abnormal
After the data was generated some preprocessing steps are required before the algorithm can be executed. The details of the preprocessing steps have been discussed in a later section. Here we propose to conduct a proof-of-concept study that demonstrates the feasibility of using the propos ed MKAD algorithm in detecting a variety of anomalies such as those injected in the synthetic data set.

Table 1 shows the summary of the outcomes. Since the actual fault injection incidents are known, we are able to evaluate the performance of all algorithms in detecting tho se faults. Out of twelve injected faults, Orca was able to find the three continuous anomalies. Even though Orca can han-dle both discrete (binary) variables and continuous variabl es, the algorithm is unable to detect sequential anomalies where the ordering of transitions is embedded in some form. Se-quenceMiner, using one standard deviation threshold cal-culated from the reference set, was able to detect most of the discrete anomalies and clearly missed all the continuou s anomalies. Whereas the MKAD technique stands out across all the algorithms since it was able to identify all twelve fa ult types (both discrete and continuous).
The real world data set chosen for analysis is from a re-gional carrier in the U.S. All aircraft analyzed were of the same fleet and type (narrow body jet), with a subset of flights that landed on the same runway at a single airport for an entire year, resulting in approximately 3500 total flights . Each flight consists of 160 parameters sampled at 1 Hz with the average flight length approximately 1.7 hours. Due to privacy reasons, each pilot X  X  identity is kept confidential by the airline industry.
Data analysis was focused on the portion of the flight below 10,000 ft. Mean Sea Level (MSL) to landing, using the deployment of the thrust reversers as a means to deter-mine touchdown. To account for parameters that recorded bad data, such as noisy sensors or sensor values reaching cut-off value or unreasonable data values, a conservative data quality filter was applied to all 3500 flights, return-ing approximately 2500  X  X leaned X  flights. Since the filtering was conservative, to ensure that significant anomalies were not removed, some flights that partially contained bad data were not eliminated from the data set. An aggressive data quality filter was applied to the remaining flights to deter-mine a nominal set for training (returning approximately 500 flights). For parameter selection a domain expert provided a list of 39 relevant continuous parameters that were extracte d for analysis. The flap position parameter was continuously recorded, however it is categorical. Using input from the domain expert and statistics from the data the flap parame-ter was decomposed into 3 binary state variables which were combined with landing gear and ground spoilers for sequence analysis.

The working data set consists of approximately 2500 flights with varying lengths and each of these flights are multidi-mensional heterogeneous time series. For continuous data, the mean and standard deviation are calculated for each pa-rameter across all training flights. These statistics are th en used in both training and testing to z-score normalize each parameter and flight to maintain consistency.
When using Orca to analyze the flights, the z-score nor-malized temporal features of all the flights corresponding t o both the test and the training set were concatenated. The discrete inputs to Orca are in standard binary format and the number of nearest neighbors was set to the default value (k=5). For SequenceMiner the binary states (of the dis-crete variables) were translated into state transitions wh ere only the bit changes (switching) were logged as a sequence of transitions. Figure 4 represents a snapshot of ten such flights representing sequential data. The SequenceMiner model builds clusters in the sequence space and the num-ber of clusters were determined to be 3 for this analysis. This is because we observed three distinct clusters in the reference set.
 Figure 4: This figure represents a snapshot of a typi-cal sequences generated from the binary input. Each sequence represents an unique flight. Examples of similar sequence (Flight 5 and Flight 6) and dissim-ilar sequence (Flight 7 and Flight 9) are shown.

For the MKAD algorithm, once the sequences are gen-erated (Figure 4) the discrete kernel is computed pairwise across all possible flight combinations in the training set. For the continuous data, each time series was SAX transformed using the technique described in Section 3.2. In the original version of SAX, the z-score normalization is an integral par t of the algorithm. However in this research, we normalized each time series (only once) before it is SAX transformed. We are able to maintain consistency in choosing the alphabet size for both reference and test sets. The window size was also kept fixed throughout the analysis. The window size and alphabet size were both set to 10. Once the SAX repre-sentations are obtained, another kernel is computed pairwi se across for all possible flight combinations. Each element of this kernel is the average of the pairwise comparison across the parameters of any two flights. In the optimization, we have set the  X  parameter of one-class SVMs to 0 . 1. For testing, the support vectors are used to calculate the pair-wise similarity between all testing flights. The discrete an d continuous kernels for test data were generated in a similar fashion as the training.
The MKAD method reported a total of 227 anomalous flights and assigned an appropriate anomaly score to each of these flights. A simple post-processing method is used to rank the anomalous flights and decompose the anomaly score of individual flights in terms of discrete (parameters) and continuous (parameters) contributions. This results i n three distinct categories, a list of flights with anomalies i n ei-ther discrete parameters or continuous parameters or in bot h (i.e. heterogeneous). The MKAD algorithm detected 19 dis-crete, 94 continuous and 114 heterogeneous anomalies. We have observed that the majority of the top ranking anomalies belong to the heterogeneous category. Some of these hetero-geneous anomalies have distinct discrete-continuous inte rac-tions i.e. a sequence of unexpected events in the discrete parameters results in some abnormal effects in the continu-ous variables or a series of abnormal event in the continuous parameters prompts some necessary changes in the states of the discrete variables. We will elaborate on this using examples in the analysis section.
Using the feedback from the domain expert we identi-fied a good number of anomalous flights which are opera-tionally significant while the majority are due to low oc-currence events. Most of the flights in the list of discrete anomalies and some from the heterogeneous category were identified anomalous because they fall outside the distribu -tion of (most) observed values. This does not necessarily mean that the detected anomaly is operationally significant . Table 2 represents a typical distribution of the deployment of landing gears as a function of flap settings. According to the domain expert there is nothing unusual in deploy-ing the landing gear before flap-1 setting (10  X  ). In fact it is acceptable if the pilot slows down the aircraft by deploy-ing the landing gear while transiting from cruise to descent . Such an example was picked up as a low occurrence anomaly due to the fact that it is a low occurrence event. For simi-lar reason, we have observed a number of anomalous flights
The source code of SAX can be obtained from the authors X  website at http://www.cs.ucr.edu/ eamonn/SAX.htm.  X   X  20  X  flaps 20  X   X  45  X   X  below No full flaps deployed with either flap-1 setting before 10 , 000 ft of altitude and/or full-flap not at all deployed during landing. Table 2 pro-vides the statistics of various flap settings as a function of altitude. The other important category of anomalies which resulted from this analysis are clusters of flights with a com-mon set of bad data sources (bad sensors) having common tail numbers which is valuable maintenance information.
In this section we will present some examples identified as operationally significant by a domain expert. The first anomalous flight is a go-around (where the pilot aborted the landing, climbed, circled around, and landed) and is classi -fied by the algorithm as a heterogeneous anomaly. The top anomalous continuous parameters are plotted in Figure 5. All continuous parameters show abnormally high deflections during the maneuver. The anomalies found in the discrete sequence confirmed the maneuver by identifying the extra switching due to the pilot retracting the landing gear and flaps during the climb and redeploying for landing on the second approach.

The second anomalous flight is also identified as hetero-geneous anomaly with unusually high air speed when com-pared to a set of reference flights. Figure 6 shows the rela-tionship between air speed and altitude with the air speed remaining high at 2500 ft MSL. The anomaly identified in the sequence indicates the landing gear was deployed before the flaps. The domain expert said that this ordering may not be unusual but the pilot could be using the landing gear to bleed off air speed, which is evident after the landing gear is deployed. This behavior demonstrates an interac-tion between the continuous and sequential variables, i.e. due to the aircraft X  X  high speed at a low altitude the pilot was prompted to deploy the landing gear, which in return resulted in a delayed effect of lower air speed.

The third anomalous flight is also identified as a hetero-geneous anomaly with indications of gusty winds. The top contributing parameters are plotted in Figure 7, with the exception of wind speed, since it was not analyzed by the algorithm. The domain expert saw the large swings in drift angle and concluded that there may have been high winds. The wind speed plot shows that there were indeed high gusts of up to 70 mph during the approach, which is also appar-ent in the control column/wheel and lateral accelerations. The anomaly identified in the discrete sequence was that flaps fully deployed at 45 degrees was not present at land-ing. The domain expert said that landing with flaps set at 20 degrees is considered an approved landing flaps setting for this particular aircraft and may not indicate an anomaly, however during high cross wind conditions full flaps pro-vide additional lift that can make it hard for the pilot to maintain the aircraft X  X  course, and therefore the pilot may not have deployed full-flaps because of these environmental conditions.

The fourth anomalous flight is an abnormal approach and the only one identified as a continuous anomaly (refer Figure 8). The flight shows high control column and fuel flow fluc-tuations beginning slightly before 10 miles to landing, whi ch coincides with the altitude fluctuations. The domain expert said this is an interesting flight since the pilot had abnorma l altitude deflections and was under glide slope, however the pilot was still able to line up on glide slope at 5 miles to landing, which is required to maintain a stable approach. By definition, glide slope is a 3  X  approach vector used to guide aircraft in for landing.
 Figure 5: Top anomalous parameters associated with a go-around. The top left plot shows the con-trol column and wheel positions associated with the maneuver. The top right plot shows high fuel flow consumption related to the climb. The bottom left plot shows the high acceleration in the longitudinal direction. The bottom right plot shows the 3 dimen-sional track of the aircraft (the go-around maneuver is denoted by the dotted lines)
It is important to note that the combined anomaly lists from Orca and SequenceMiner were able to detect some but not all of the 4 anomalies just discussed. For the go-around and air speed anomalies SequenceMiner is able to detect the anomalies, however Orca did not. Both the anomalies have components that are sequential in nature (the go-around having additional flaps and landing gear switches, and the air speed anomaly deploying the landing gear early to bleed Figure 6: For the high airspeed anomaly the top anomalous parameter (airspeed) is plotted against altitude. The speed limit threshold at 10,000 ft. is denoted by the dashed line at 250 knots.
 Figure 7: Top anomalous parameters associated with the gusty wind anomaly. The top left plot shows the control column and wheel positions. The top right plot shows the high drift angle. The bot-tom left plot shows high lateral (side-to-side) ac-celerations. The bottom right plot shows the wind speed gusts. off speed) and, therefore it makes sense that SequenceMiner detects the anomaly while Orca treating all points indepen-dently, did not. In the case of the gusty winds and abnormal approach anomalies, neither Orca nor SequenceMiner were able to detect them.

Baseline results were obtained by running Orca, SequenceM-iner and comparing the results with those obtained from the MKAD method on the FOQA data set described above. It has been observed that the average flight length (average flight time expressed in sample points during services, from take-off to landing) is approximately 1500 sample points in this data set. Based on this information we allowed Orca to report back the same number of sample points (  X  350 , 000) which is equivalent to those 227 flights identified by MKAD. Any flight that had less than 1% of the average flight length labeled anomalous was ignored and doing so Orca reported Figure 8: Top anomalous parameters associated with the abnormal approach anomaly. The top left plot shows the high control column position. The top right plot shows the large swings in fuel flow ac-tivity. The bottom plot shows the altitude vs. the distance to landing with the glide slope and glide slope deviation superimposed. 674 anomalous flights in total. For SequenceMiner we have calculated a 2  X  sigma threshold from the reference set and considered any sequence that was above that threshold in the test set as an outlier, resulting in 72 anomalous flights.
Table 3 shows the overlap between the baseline algorithms and MKAD. As expected Orca performs well at detecting mostly the continuous anomalies found by MKAD, while Se-quenceMiner identifies anomalies related to discrete and/or heterogeneous anomalies found by MKAD. However MKAD still finds a significant number of anomalies that the com-bined baseline set does not detect. From the proof of con-cept study we have observed these limitations of Orca and SequenceMiner in identifying anomalies which are respec-tively discrete and continuous in nature. This is due to the fundamental nature of the baseline algorithms. However the MKAD is able to compress and appropriately combine the information from both discrete and continuous domain, to detect anomalies. This has also been reflected in the analy-sis of the real world data set, where the baseline algorithms missed some of the operationally significant anomalies de-tected by MKAD.
The current state-of-the-art algorithms have both strengt hs and shortcomings in detecting a variety of anomalous con-ditions, as discussed in the detection of the 4 real world anomalous flights. The vector space based techniques were unable to detect sequential anomalies, whereas SequenceM-iner was not able to identify anomalies in continuous data. The MKAD method aims to combine both strengths into a single approach to allow for detection of a variety of anoma-lies. This is not to say the proposed algorithm is able to find all possible anomalies in the data, but rather that it is robust enough to find a significant overlap with the cur-rent state-of-the-art methods while also detecting additi onal operationally significant anomalies in heterogeneous data sources. Other approaches such as exceedance queries can be very efficient in detecting specific anomalies, however the goal is not to continue to find anomalies that are already be-combined outcome of Orca and SequenceMiner.
 ing studied, but to develop a novel method that  X  ..can find the unknown unknowns...  X  while analyzing the FOQA data set. This project was supported by the NASA Aviation Safety Program, Integrated Vehicle Health Management Project. The authors would like to thank Robert Lawrence for his invaluable domain expertise and Dr. Irv Statler for his in-sightful discussions. The authors also thank Dr. Kanishka Bhaduri for valuable discussions and suggestions. The au-thors also thank the reviewers for providing input to improve the paper. [1] I. C. Statler, The Aviation System Monitoring and [2] F. R. Bach, G. R. G. Lanckriet and M. I. Jordan, [3] S. D. Bay and M. Schwabacher, Mining [4] National Transportation Safety Board, Loss of Control [5] S. Budalakoti and A. N. Srivastava and M. E. Otey, [6] C. J. C. Burges, A tutorial on support vector machines [7] V. Chandola, A. Banerjee and V. Kumar, Anomaly [8] O. Chapelle and P. Haffner, Support Vector Machines [9] S. Das, B. L. Matthews, K. Bhaduri, N. C. Oza and [10] Z. Harchaoui and F. R. Bach, Image classification with [11] J. W. Hunt and T. G. Szymanski, A Fast Algorithm [12] D. L. Iverson, R. Martin, M. Schwabacher, L. [13] H. Kashima, K. Tsuda and A. Inokuchi, Kernels for [14] G. R. G. Lanckriet, N. Cristianini, L. El Ghaoui, P. [15] P. Patel and E. Keogh and J. Lin and S. Lonardi, [16] B. Sch  X  olkopf, J. C. Platt, J. Shawe-taylor, A. J. [17] B. Sch  X  olkopf and A. Smola, Learning with Kernels , [18] D. M. J. Tax and R. P. W. Duin, Support Vector [19] Aviation Safety Team, Statistical Summary of [20] H. Zhang, A. C. Berg, M. Maire and J. Malik,
