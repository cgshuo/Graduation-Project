 Many real-world datasets are imbalanced, in which most of the cases belong to a larger class and far fewer cases belong t o a smaller, yet usually more interesting class. Examples of applications with such datasets include searching for oil spills in radar images [1], telephone fraudulent detection [2], credit card fraudulent detection diagnosis of rare diseases, and network intrusion detection. In such applications, the cost is high when a classifier misclassifies the small (positive) class instances.
 sification systems tend to optimize the overall accuracy without considering the relative distribution of each class. As a result, these systems tend to misclassify minority class examples when the data is highly skewed. Techniques have been proposed to handle the problem. Approaches for addressing the problem can be divided into two main directions: sampling approaches and algorithm-based ap-proaches. Generally, sampling approaches include methods that over-sample the minority class to match the size of the majority class [3, 4], and methods that under-sample the majority class to match the size of the minority class [1, 5, 6, 7]. Algorithmic-based approaches are designed to improve a classifier X  X  performance based on their inherent characteristics.
 tor Machines (SVMs) on imbalanced data sets. SVMs have gained success in many applications, such as text mining and hand-writing recognition. However, when the data is highly imbalanced, the decision boundary obtained from the training data is biased toward the minority class. Most approaches proposed to address this problem have been algorithm-based [8, 9, 10], which attempt to adjust the decision boundary through modifying the decision function. as ensemble techniques to improve SVM X  X  performance. First, our observation indicates that using over-sampling alone as proposed in previous work (e.g. SMOTE [10]) can introduce excessive noise and lead to ambiguity along de-cision boundaries. We propose to integrate the two types of sampling strategies by starting with over-sampling the minority class to a moderate extent, followed by under-sampling the majority class to the similar size. This is to provide the learner with more robust training data. We show by empirical results that the proposed sampling approach outperforms over-sampling alone irrespective of the parameter selection. We further consider using an ensemble of SVMs to boost the performance. A collection of SVMs a re trained individually on the processed data, and the final prediction is obtained by combining the results from those individual SVMs. In this way, more robust results can be obtained by reduc-ing the randomness induced by a single classifier, as well as by alleviating the information loss due to sampling. Sampling is a popular strategy to handle the class imbalance problem since it straightforwardly re-balances the data at the data processing stage, and there-fore can be employed with any classification algorithm [1, 3, 4, 5, 6, 7]. As one of the successful oversampling methods, the SMOTE algorithm [11] over-samples the minority class by generating interpolated data. It first searches for the K -nearest-neighbors for each minority instance, and for each neighbor, randomly selects a point from the line connecting the neighbor and the instance itself, which will serve as a new minority instance. By adding the  X  X ew X  minority in-stances into training data, it is expected that the over-fitting problem can be alleviated. SMOTE has been reported to achieve favorable results in many clas-sification algorithms [11, 12]. Algorithm-based approaches include methods in which existing learning algorithms are tailored to improve the performance for imbalanced datasets. For example, some algorithms consider class distributions or use cost functions for decision tree inductions [6, 13, 14].
 chine learning tasks. The class imbalance issue has also been addressed in the literature. Through empirical study, Wu et al. [9] report that when the data is highly imbalanced, the decision boundary determined by the training data is largely biased toward the minority class. As a result, the false negative rate that associates with the minority class might be high. To compensate for the skewness, they propose to enlarge the resolution around the decision boundary by revising kernel functions. Furthermore, Veropoulos et al. [8] use pre-specified penalty constants on Lagrange multipliers for different classes; Akbani et al. [10] combine SVMs with SMOTE over-sampling and cost sensitive learning. In contrast, Japkowicz et al. [15] argue that SVMs are immune to the skewness of the data, because the classification decision boundary is determined only by a small quantity of support vectors. Consequently, the large volume of instances belonging to the majority class might be considered redundant. In this paper, we will demonstrate that the decision boundary changes as imbalance ratios vary, and discuss its implications.
 been reported to be effective in the cont ext of imbalanced data. This strategy usually makes use of a collection of individually trained classifiers whose predic-tion results are integrated to make the final decision. The work in this direction includes that Chen et al. [6] use random forest to unite the results of decision trees induced from bootstrapping the training data, and that Guo et al [4] apply data boosting to improve the performance on hard examples that are difficult to classify. However, most current studies are confined to decision tree inductions instead of other classifiers, e.g, SVM. Mor eover, decision-tr ee-based algorithms might be ill-suited for the class imbalance problem as they favor short trees. 3.1 Support Vector Machines In this section we briefly describe the ba sic concepts in two-class SVM classifi-cation. Assume that there is a collection of n training instances Tr = { x i ,y i } , where x i  X  X  N and y i  X  X  X  1 , 1 } for i =1 ,...,n . Suppose that we can find some hyperplane which linearly separates the positive from negative examples in a fea-ture space. The points x belonging to the hyperplane must satisfy w  X  x + b =0, where w is normal to the hyperplane and b is the intercept. To achieve this, given a kernel function K , a linear SVM searches for Lagrange multiplier  X  i ( i =1 , ..., n ) in Lagrangian such that the margin between two classes 2 || w || is maximized in the feature space [16]. In addition, in the  X  i optimizing process, Karush Kuhn Tucker (KKT) con-ditions which require n i =1  X  i y i = 0, must be satisfied. 1 To predict the class label If the sign function is greater than zero, x belongs to the positive class, and the negative otherwise.
 set. They lie closest to the decision boundary; thus form the margin between two sides. If all other training data wer e removed, and training was repeated, the same separating hyperplane would still be constructed. Note that there is a Lagrange multiplier  X  i for each training instance. In this context, SVs correspond to those points for which  X  i &gt; 0; other training instances have  X  i =0.Thisfact gives us the advantage of classifying by learning with only a small number of SVs, as all we need to know is the position of the decision boundary which lies right in the middle of the margin; other training points can be considered redundant. Further, it is of prime interest in the class imbalance problem because SVMs could be less affected by the negat ive instances that lie far away from the decision boundary even if there are many of them. 3.2 Effects of Class Imbalance on SVMs We conducted a series of experiments to investigate how the decision boundaries are affected by the imbalance ratio, i.e., the ratio between the number of negative examples and positive examples. We start with classifying a balanced training dataset, and detect that the real decision boundary is close to the  X  X deal bound-ary X , as it is almost of equal length to both sides. We then reform successive new datasets with different degrees of data skewness by removing instances from the positive and add instances to the negativ e. Figure 1 reflects the data distribution when imbalance ratios vary from 10:1 to 300:1, where crosses and circles repre-sent the instances from positive and ne gative classes respectively. From Figure 1 (a), we find that if the imbalance ratio is moderate, the boundary will still be close to the  X  X deal boundary X . This observation demonstrates SVMs could be robust and self-adjusting; and is thus able to alleviate the problem arising from moderate imbalance. Nonetheless, as the imbalance ratio becomes larger and larger, as illustrated in Figure 1 (b) and (c), the boundaries get evidently biased toward the minority class. As a consequence, making predictions with such a system may lead to a high false negative rate. We have shown that SVMs may perform well while the imbalance ratio is mod-erate. Nonetheless, their performance could still suffer from the extreme data skewness. To cope with this problem, in this section, we study the use of sampling techniques to balance the data. 4.1 Undersampling Under-sampling approaches have been reported to outperform over-sampling ap-proaches in previous literatures. However, under-sampling throws away poten-tially useful information in the majority class; it thus could make the decision boundary trembling dramatically. For example, given the imbalance ratio as 100:1, in order to get a close match for the minority, it might be undesirable to throw away 99% of majority instances. Figure 2 illustrates such a scenario, where the majority class is undersampled to keep the same size as the minority, but a considerable amount of SVs lie far away from the ideal boundary y =1. Accordingly, predicting with such SVMs may lead to low accuracies. 4.2 Oversampling Considering that simply replicating the minority instances tends to induce over-fitting, using interpolated data is often preferred in the hope of supplying addi-tional and meaningful information on the positive class. SMOTE is the method that has been mostly cited along this line.

However, the improvement of integrating SVMs with the SMOTE algorithm can be limited due to its dependence on the proper selection of the number of nearest neighbors K as well as imbalance ratios. Basically, the value of K deter-mines how many new data points will be added into the interpolated dataset. Figure 3 shows how the decision boundary will change with different K values. Figure 3 (a) shows the original class distribution while the imbalance ratio is 100:1. Figure 3 (b) demonstrates that th e classification boundary is relatively smoothed when K has a small value; nonetheless, it is still biased toward the minority class. This is due to SMOTE actually providing little information of the minority; hence the oversampling in this case should be considered as a type of  X  X hantom-transduction X . When the interpolated dataset is considerably en-larged as K increases, as shown in Figure 3 (c), ambiguities could arise along the current boundary, because SMOTE makes the assumption that the instance be-tween a positive class instance and its near est neighbors is also positive. However it may not be always true in practice. As a positive instance is very close to the boundary, its nearest neighbor is likely to be negative, and this possibility may increase as K and imbalance ratio become larg er. Consequently, the new data instance, which actually belongs to the negative class, is mis-labeled as positive, and the induced decision boundary, as shown in Figure 3 (c), could be inversely distorted to the majority class. 4.3 Combination of Two Types of Samplings To address the problems arising from using each of the two types of sampling approaches alone, we integrate them together. Given an imbalance ratio, we first over-sample the minority instances with SMOTE to some extent, and then under-sample the majority class so that both sides have the same or similar amount of instances. To under-sample the majority class, we use the bootstrap sampling approach with all available majority instances, provided that the size of the new majority class is the same as that of the minority class after running SMOTE. The benefit of doing so is that this approach inherits the strength of both strategies, and alleviates the over-fitting and information loss problems. boundary, we choose to filter out the  X  X mpure X  data firstly before sampling. In this context, an instance is defined to be  X  X mpure X , if and only if two of its three nearest neighbors provide different class labels other than that of itself. This idea is motivated by the Edited Nearest Neighbor Rule [7], which was originally used to remove unwanted instances from the majority. In our work, however, to further reduce the uncertainty from both classes, such a filtering process is taken on each side. In this section, we present a method th at uses an ensemble of SVM classifiers integrated with a re-balancing technique that combines both over-sampling and under-sampling. Re-balancing is still necessary in this context since in learning from extremely imbalanced data, it is ver y likely that a bootstrap sample used to train an SVM in the ensemble is composed of few or even none of the minority instances. Hence, each component learn er of the ensemble would suffer from severe skewness, and the improvement of using an ensemble would be confined. Our proposed method, called EnSVM , is illustrated in Figure 4. As described in Section 4.3, we start re-balancing the data by filtering out impurities which may induce ambiguities. Then, the minority class is over-sampled with the SMOTE method to smooth the decision boundary. That is, for each positive instance, it finds the K nearest neighbors, draws a line between the instance and each of its K nearest neighbors, and then randomly selects a point on each line to use as a new positive instance. In this way, K  X  n new positive instances are added to the training data, where n is the number of positive instances in the original training data. After that, we under-sample the majority class instances N times to generate N bootstrap samples so that each bootstrap sample has the same or similar size with the over-sampled positive instances. Then, each bootstrap sample (of the majority class) is combined with the over-sampled positive instances to form a training set to train an SVM. Therefore, N SVMs can be obtained from N different training sets. Finally, the N SVMs are combined to make a prediction on a test example by casting a majority vote from the ensemble of SVMs. In our experiments reported below, we set N to be 10. In this section, we first introduce the evaluation measures used in our study, and then describe the datasets. After that, we report the experimental results that compare our proposed approach with other methods. 6.1 Evaluation Measures The evaluation measures used in our experiments are based on the Confusion Matrix . Table 1 illustrates a confusion matrix for a two class problem with pos-itive and negative class values. With this matrix, our performance measures are expressed as follows: G-mean is based on the recalls on both cla sses. The benefit of selecting this metric is that it can measure how balanced the combination scheme is. If a classifier is highly biased toward one class (such as the majority class), the g-mean value is low. For example, if a + =0and a  X  = 1, which means none of the positive examples is identified, g-mean =0. In addition, F-measure combines the recall and precision on the positive class. It measures the overall performance on the minority class. Besides, we utilize the ROC analysis [17] to assist the evaluation. A ROC curve demonstrates a trade off between true positive and false positive rates provided with different classification parameters. Informally, one point in ROC space is superior to another if it is closer to the northwest corner (TP is higher, but FP is lower). Thus, ROC curves allow for a visual comparison of classifiers: the larger th e area below the ROC curve, the higher classification potential of the classifier. 6.2 Benchmark Data We use five datasets as our testbeds. Four of the datasets are from the UCI Ma-chine Learning Repository and another dataset is a medical compound dataset (mcd) collected by Nation al Cancer Institute (NCI) for discovering new com-pounds capable of inhibiting the HIV virus. The four UCI datasets are spambase, letter-recognition, pima-indians-diabetes and abalone . Each dataset in this study is randomly split into training and test subsets of the same size, where a strati-fied manner is employed to ensure that the training and test sets have the same imbalance ratio. Table 2 shows the characteristics of the five datasets. The first three datasets (letter, pima, and spambase) are mildly imbalanced, while the next two (abalone and mcd) are very imbalanced. These datasets were carefully selected to (1) fulfill the requirements that they are obtained in real applications, (2) distinct from feature characteristics, and vary in size and imbalance ratio, and (3) maintain sufficient amount of instances in each individual class to keep the classification performance.
 6.3 Experimental Results In this section, we compare the performance of our proposed EnSVM method with those of five other methods: 1) single SVM without re-sampling the data, 2) single SVM with over-sampling using SMOTE [10] (without applying cost functions), 3) random forest with balanced training data from under-sampling [6], 4) random forest with our combined sampling method, and 5) single SVM with our combined sampling method. In our experiments, for all the SVMs, we employed Gaussian RBF kernels of the form K ( x i ,x j )=exp(  X   X  | x i  X  x j | 2 )of C-SVMs. For each method we repeated our experiments ten times, computed average g-mean values and F-measures.
 SVM method with the original training data, SMOTE represents oversampling the minority class and then training a system with single SVMs, RandForest 1 de-notes undersampling the majority class and then making an ensemble with C4.5 decision trees, RandForest 2 denotes sampling data with our combined method, followed by forming an ensemble with C4.5, AvgSVM denotes the average perfor-mance of 10 single SVMs with our sampling method, and EnSVM is our ensemble method with the combined sampling method. For the first two datasets, the K values for SMOTE and EnSVM can only be set to be 1 since their imbalance ratio is 2:1. For each of other datasets, we test two K values: the smallest value, which always equals to 1, and the highest value. The latter will depend on the imbalance ratios of three datasets, which are 9, 39, and 99 respectively. From the results we can see that EnSVM achieves the best results on all the datasets except on the spam dataset for which RandForest 2 is the best. 2 find that EnSVM deserves the highest value on all five datasets. In particular, a big improvement is made on the datasets where the imbalance ratios are large. By comparing the results from the four SVM methods, we can see that (1) using SMOTE to over-sample the data is better than SVM without sampling; (2) using our combined sampling method with single SVMs is better than using only over-sampling with SMOTE; and (3) using the ensemble method together with the combined sampling method achieve the best results. By comparing the two Random Forest methods, using the combined sampling method is better than using only the under-sampling method on most datasets. Moreover, between the Random Forest method and the ensemble of SVMs method, the latter performs better.
 prediction accuracy of SMOTE and EnSVM . To make a better understanding, we present a ROC analysis result with the spambase dataset. This dataset is considered since it has a moderate imb alance ratio and instance volume. The original spambase has an imbalance ratio of 10; therefore, in this experiment, we test K from 1 to 9, and depict the ROC curves of the two approaches in Figure 5. Clearly, compared to simply over -sampling the minority instances, EnSVM generates a better result. We also test how the g-mean value may change with different K sin SMOTE and EnSVM .The abalone and mcd datasets are used in this case as they hold large imbalance ratios and allow K to vary in relatively large ranges. We set parameter K tovaryfrom1to39forthe abalone dataset and from 1 to 99 for the mcd dataset. As shown in Figures 6.3 (a) and (b), the prediction performance of EnSVM is superior to simply applying the SMOTE algorithm with respect to each K value. Moreover, we can see that the optimal K value can be difficult to determine in both SMOTE and EnSVM .For EnSVM , when K is small, we get better neighbors for the oversampling process, so the prediction performance can be dramatically improved. Further, when K is big, more noise is likely to be introduced, but a larger training data set is generated using EnSVM and less information is lost. Consequently, it becomes a trade off between inducing more noise and losing less information. Nonetheless, our method is better than SMOTE with all K values. This paper introduces a new approach t o learning from imbalanced datasets through making an ensemble of SVM classifiers and combining both over-sampling and under-sampling techniques. We first show in this study that using SVMs for class prediction can be influenced by the data imbalance, although SVMs can adjust itself well to some d egree of data imbalance. To cope with the problem, re-balancing the data is a promising direction, but both undersam-pling and oversampling have limitations. In our approach, we integrate the two types of sampling strategies together. Over-sampling the minority class provides complementary knowledge for the training data, and under-sampling alleviates over-fitting problem. In addition, we make an ensemble of SVMs to enhance the prediction performance by casting a majority vote. Through extensive experi-ments with real application data, our p roposed method is shown to be effective and better than several other methods with different data sampling methods or different ensemble methods. We are now working on a method for automatically determining the value of K based on the data set characteristics in order to optimize the performance of EnSVM .

