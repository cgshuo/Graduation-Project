 Many queries, especially those in the form of longer ques-tions, contain a subset of terms representing key concepts that describe the most important part of the user X  X  infor-mation need. Detecting the key concepts in a query can be used as the basis for more effective weighting of query terms, but in this paper, we focus on a method of using the key concepts in a translation model for query expan-sion and retrieval. Translation models have been used pre-viously in community-based question answering (CQA) sys-tems in order to bridge the semantic gap between questions and the corresponding answer documents. Our method uses the key concepts of a question as the translation context and selectively applies the translation model to the secondary (non-key) parts of the question. We evaluate the proposed method using a CQA collection and show that selectively translating key and secondary concepts can significantly im-prove the retrieval performance compared to a baseline that applies the translation model without considering key con-cepts.
 H.3.3 [ Information System ]: Information Search and Re-trieval translation model; query term classification; query expan-sion; answer passage retrieval
Statistical translation models have been used for query term expansion in a number of previous studies (e.g., [2, 10]) and have been shown to be particularly effective for re-trieving answer passages in collaborative question answering (CQA) systems [12, 11]. One of the challenging issues in us-ing translation models for expansion is incorporating more of the query context into the translation process. For exam-ple, Figure 1 shows two example questions that include the c  X 
Translation models have been used as a query term ex-pansion method for both document and answer passage re-trieval [7, 11, 12]. The models estimate probabilities that terms in documents are translated into terms in queries. We employ Xue et al X  X  translation model [12] for CQA retrieval as follows: where t j is a term in a document D , P ( t j | D ) represents the probability that a term t j is generated by a document D and that a document term t j is translated into a query term q i and vice versa. Note that, since we are focusing on CQA, we use  X  X uestion X  instead of  X  X uery X  in the rest of the paper.
In this translation model, Xue et al investigated the is-sues of self-translation and bi-directional translation. In a translation model for a single language, every word has some probability to translate into itself. In order to prevent low self-translation probabilities from assigning low weights to matching terms and high self-translation probabilities from nullifying the effect of the translation approach, Xue et al separate self-translation from the general translation model and use the parameter  X  to control the impact of self-translation. They use different parameter values  X  1 and  X  2 according to the directions of translation P ( t j | q i ) and P ( q i | t j ).

In order to estimate the translation probabilities P ( t j | q i ) and P ( q i | t j ), IBM model 1 was used. Higher-order versions of the IBM model were proposed to take into account other features such as the order of words, the length of aligned words in source and target expressions, etc. Because the number of sentences in questions and answer passages (or documents) vary widely and the goal of the translation is to generate expansion terms, these higher-order IBM models are not appropriate for this study.

Instead of using the higher-order models, some previous studies [8, 11] have used a simpler approach in which a sen-tence is converted to a sequence of term pairs. For example, a sentence  X  A helicopter gets its power from rotors or blades  X  is converted to (helicopter-gets) (gets-power) (power-rotors) (rotors-blades) to estimate the translation probabilities be-tween adjacent term pairs. Without formulating translation models for specific types of linguistic features, Surdeanu et al. model translation between different types of text rep-resentations such as bags of words, n-grams, syntactically dependent pairs of terms and predicate-argument pairs of semantic labels. We use this approach to generate a key concept-based translation table. For a given question, we assume one of the terms is the key concept of the question. We generate a set of term-pair sequences in which we treat each term in a question as the key concept of the question. For example, for a question  X  A helicopter gets its power from rotors or blades  X , we generate four pair sequences in which each one of the question terms is used as the key concept of the question as follows: function for secondary concepts  X  ( q i ) is used to selectively apply the translation model to question terms. In the next section, we will explain how to predict  X  Q and  X  ( q i ) in detail.
In our approach, we classify question terms as key con-cepts and secondary concepts. Key concepts are used as the context of translation and secondary concepts are used to se-lectively apply the translation model for query term expan-sion. For this purpose, we use a machine learning method to classify question terms [6]. For the classifier, training data consists of triplets as follows: in which n is the number of question terms. k i and s i are the labels of a question term q i for key concepts and secondary concepts, respectively.

The definition of key concepts can differ according to their intended use. Bendersky and Croft [1] annotated the key concepts of queries to assign higher weight to the most im-portant terms in queries. Lee et al. [10] used the TextRank algorithm in which the importance of terms is measured by the PageRank scores of terms. Lee et al [9] proposed a method to empirically select important query terms that maximizes the mean average precision of retrieval results. In our case, for the training labels of key concepts, we select k i values according to the effectiveness of the translation model when we use q i as the key concept of a question  X  Q . The training label of secondary concepts s i is selected ac-cording to the improvement in retrieval effectiveness when we apply the translation model to q i . We select only one key concept per question, although there can be more than one term which can improve the effectiveness of the key concept-based translation model.

We use three types of features for identifying key concepts and secondary concepts: lexical features, syntactic features and semantic features. The aim is to estimate how likely a given term is to be a key concept or a secondary concept given these syntactic and semantic characteristics.
 of the characteristics of an individual term. the role of a given term in a question.
 Secondary 6,759 1,521 435 Key + Secondary 5,307 2,646 762 Table 3: The number of question-answer pairs for which retrieval results are unchanged, improved, and decreased by the translation-based model with key and secondary concepts. the test data, the baseline system retrieved the answers at the first rank for 4,150 (47.6%) of questions. As another baseline, we use the translation-based model from Eq. 1 ( TM ) that does not use key concepts. We do not have a pseudo-relevance feedback baseline (such as the RM3 model provided in Galago) because the Xue et al model has already been shown to be superior to pseudo-relevance feedback for this type of data [12].

Secondary is the experimental results of the translation-based model that applies the translation only for the sec-ondary concepts of question terms. By translating only secondary keywords in questions, we potentially reduce the number of non-relevant translation results. Key+ Secondary shows the results when we translate the secondary concepts of questions using the key concepts as context.

As we can see, considering key concepts as the context for translation significantly improves the performance of the system. To analyze this further, we compare the experi-mental results of the baseline system and the translation-based model for individual questions. Table 3 shows the number of question-answer pairs for which retrieval results are unchanged, improved and decreased by using key con-cepts and secondary concepts for the translation model. The translation-based model without the key concepts affects fewer retrieval results. This model introduces expansion terms related to a range of possible contexts, which conse-quently has less effect on ranking. Using the predicted key concepts as context, the translation model generates more precise translation results. However, the ratio of questions for which results were decreased by the translation-based model with key and secondary concepts is also higher than when only using the secondary concepts. This shows that, if the selection of key concepts is inaccurate, using them as context can have a negative impact on effectiveness.
In this paper, we proposed the key concept-based transla-tion model for query expansion. Key concepts represent the most important part of the users X  information needs. We use the key concepts of questions as the context of translation. In addition, we also classify question terms as secondary con-cepts to selectively apply the translation model. Key con-cepts can improve the effectiveness of the query expansion by constraining the translations of question terms within the contexts of questions. By translating only secondary concepts, we can also reduce the non-relevant translation results. The key concept-based translation model signifi-cantly improved the effectiveness of translation-based query expansion for finding answers in a CQA collection.

For future work, we plan to apply the proposed method to passage retrieval in documents. Because of the lack of
