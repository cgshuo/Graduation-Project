 1. Introduction
The present industrial market is witnessing a faster  X  X  time-to-market  X  X  while maintaining or enhancing its product quality scenario for continuously shortening life-cycle products. This is because products that are launched earlier capture the whole market and so achieve phenomenal success ( Kotler, 2003 ). Among the many tools that accelerate the product development process, concurrent engineering (overlapping of stages) has evolved as the most prominent option for efficient and effective product devel-opment ( Smith and Reinertsen, 1998 ). The significance of this strategy has been reinforced more by its successful implementa-tion in developing airplanes ( Sabbagh, 1996 ) and software ( Cusumano and Selby, 1995 ). Overlapping involves the concurrent execution of two successive stages and allows the second stage to begin before the first stage is finished. Here, the first stage is called upstream and the second stage downstream. Overlapping facilitates the two leading purposes of any organization, i.e., lead-time compression and quality control. The first objective is achieved by parallel execution of upstream and downstream stages while the latter results from the release of rudimentary information from upstream. In this way, engineers can step ahead to identify any mistakes and then can enact preventive action rather than letting the problem accumulate and so be forced to revise the situation extensively ( Cantamessa and Villa, 2000 ). This is contrary to the traditional sequential approach, in which commencement of the next stage occurs only when the previous stage has ended completely and has transferred the final information.

Serious risks, however, are associated with the transfer of rudimentary information because of its inherent uncertainty.
Therefore, in order to reduce any associated risks, cross-functional teams communicate through a number of meetings known as pre-communication before the project X  X  start. For the purpose of uncertainty reduction, a team of overlapped groups update information regularly until the upstream stage is finished. This information is exchanged through the active participation of teams that require additional time and cost. An exchange of updated information through sporadically held meetings is termed as the communication policy, and it plays a vital role in reducing the uncertainty inherent in rudimentary information ( Loch and Terwiesch, 1998 ). This continuous refinement of avail-able information at the upstream stage, from rudimentary to final before the complete execution of the stage, is termed as  X  X  informa-tion evolution  X  X  and leads to modifications ( Krishnan, 1996 ). Thus, the upstream stage faces modifications after each meeting and provides these changes to the downstream stage, which started earlier on the basis of rudimentary information. This may result in reduced product development lead time, but at a trivial amount of additional cost for rework ( Terwiesch and Loch, 1999; Roemer et al., 2000 ).
 stream stage generates the required information and accommo-dates all changes through rework. If the upstream stage transfers the individual change as soon as it appears, the downstream stage will have to iterate each time to accommodate changes. This will lead to gigantic additional time at a smaller rework cost. On the other hand, if updated information is not transformed frequently, then this situation may lead to developing a product with poor quality with less communication time, at a higher cost for rework.
As a result, it is necessary to investigate the cost-time trade-offs involved in overlapped product development process, so as to enhance performance. Otherwise, its application may result in a higher number of downstream iterations, i.e., rework, thereby augmenting both time and cost ( Lin et al., 2010 ). For this reason, the amount of pre-communication, along with the communica-tion policy and the extent of overlapping stages, should be decided meticulously, so as to achieve the desired goals. optimal value of decision variables (i.e., number of pre-commu-nication meetings, amount of overlapping of each group of over-lapped stages, and communication policy for each group of overlapped stages involved in a complete project) with an aim to minimize the lead time and cost. The aforesaid decision variables are estimated by addressing the issue of target cost and time. Owing to the significance of objectives (i.e., product development lead time and product development cost) the under-lying problem is considered as an example of a multi-objective optimization problem. The incommensurate nature of these objectives constrains their explicit summation. Therefore, the fuzzy goal programming concept, because of its flexibility in the modeling of multi-objective problems, is introduced to add these objectives. Third, a novel meta-heuristic optimization approach,  X  X  X aussian Adaptive Particle Swarm Optimization (GA-PSO), X  X  is proposed to find the optimal/near-optimal solution of the pro-blem at hand.

In this meta-heuristic approach, random numbers are not generated by applying the uniform distribution function. Instead, the Gaussian probability distribution function is applied. This offers the advantage of enhanced search capability while main-taining adequate exploitation capability. Two other variants have been applied that employ Cauchy distribution and Random numbers (RNs) generators, and the results are thoroughly ana-lyzed to draw useful insights. Additionally, a novel parameter automation strategy is applied that includes time-varying accel-eration coefficients (TVACs) strategy apart from the time-varying inertia weight (TVIW). The advantage of TVACs is to make the algorithm more robust while exploring the whole search area in the initial phase and to approach nearer-optimal solution in a later phase.

Depending on the newness of the company and market opportunities, McDermott (1999) and Hauser et al. (2006) defined two types of innovation in product development (namely, incre-mental and radical). Incremental innovation refers to the inclu-sion of some new features or to the improvement of existing features, whereas radical innovation refers to the introduction of a product with a set of original features. Most radical innovations are generally incremental types of innovations. This is due to the fact that major portion of so-called newly launched products is virtually build by strategically exploiting the knowledge, technol-ogies, processes and resources of already existing products ( Hauser et al., 2006 ). It is very unusual for an organization to introduce a product to the market that does not have some common features or technology with contemporary products. C
Mag the goal of product development cost decided by l t profit due early launching of product l r rework cost or unit time cost of rework l b set-up time for communication per meeting
Z set-up cost per meeting r rework rate at downstream stage ( T US ) non-negative average rate of modifications 0 level of technical uncertainty at beginning of project
B the organization X  X  ability to reduce uncertainty dur-
D n downstream stage progress at any time t p percentage of downstream work affected by each d number of modifications at any time t ( T + T DS ) actual working time for actual working cost T Max maximum amount of overlapping T Min minimum amount of overlapping Decision variables
C pre-communication time m amount of overlapping for each group n * maximum number of information burst in a group of
CP communication policy for each group of overlapped Thus, an incremental type of innovation is the major factor used to estimate the success of any organization. Keeping this in mind, this paper targets the incremental innovation of products.
The rest of this paper is organized as follows. The next section reviews the relevant literature related to overlapping and com-munication policy. Section 3 discusses the background of the fuzzy goal programming approach. Section 4 offers the fuzzy goal programming model formulation of the objective function, com-prised of product development lead time and cost. Section 5 details the proposed optimization strategy Gaussian Adaptive Particle Swarm Optimization (GA-PSO). Section 6 provides an illustrative example, and Section 7 details the implementation procedure of the proposed algorithm. Section 8 reports computa-tional results and discussions, and Section 9 summarizes the entire paper. 2. Literature review
In this era of acute competition among firms,  X  X  X ime-to-market X  X  has to be minimized without affecting product quality. A plethora of papers in the literature propose methods to reduce product development lead time ( Millson et al., 1992; Droge et al., 2000; Langerak and Hultink, 2005 ). Concurrent Engineering is one of the prominent tools often employed to expedite the process of introducing a product to market ( Voss et al., 1995; Smith and Reinertsen, 1998 ). Generally, there are two types of concurrency: time concurrency and information concurrency, differentiated by Blackburn (1991) . These types of concurrency, respectively, refer to the stages performed in parallel and the percentage of information shared by them. However, the traditional approach of  X  X  X ver the wall X  X  is the opposite of both types of concurrency (time and information). This approach involves the sequential execution of development stages and the transmission of information. The latter is channeled from the upstream stage to the downstream stage when the prior is finished completely.

Imai et al. (1985) and Takeuchi and Nonaka (1986) were the first authors to advocate the importance of implementing the time concurrency of stages with a view to reducing product development lead time. On the other hand, Clark and Fujimoto (1991) and Wheelwright and Clark (1992) focused on the infor-mation-sharing strategy for the same purpose in the automobile industry.

Despite the popular belief of time saving, the applicability of this tool is not justified in every product development project (PDP). Researchers also have found evidence through empirical studies against the general notion of the applicability of over-lapping in all PDPs ( Eisenhardt and Tabrizi, 1995; Terwiesch et al., 1996 ). An empirical study conducted by Eisenhardt and Tabrizi (1995) has shown that, in a scenario of a highly uncertain market, the  X  X  X verlapping approach X  X  is of less significance even than the  X  X  X xperimental approach. X  X  Moreover, overlapping fails to provide significant benefits if it is applied to projects involving lower control over uncertainly of information ( Cordero, 1991 ). Table 1 briefly summarizes the most prominent literature in the field related to the problem of overlapping and communication. Table 1 also provides information about various critical para-meters considered in the literature in the domain of concurrent engineering.

The advantages of concurrent engineering surrounding the task of speeding and improving the product development cycle are discussed in Smith and Reinertsen (1995) . They failed, how-ever, to provide an elaborate study for the application of an underlying approach in nominally sequential activities. Krishnan (1996) introduced the term  X  X  X volution X  X  to define the continuous refinement of preliminary information. In order to illustrate this concept of evolution, they used only a single design parameter at the parametric design level. The conclusion of their findings was that higher time benefits are obtained when overlapping activ-ities are associated with faster evolution and low downstream sensitivities. In similar work, Wang and Lin (2009) defined the evolution of a stage as the ratio of information collected within a particular time period over the total time of stage execution.
In essence, the main purpose of the initial work was to propose a mathematical model that estimates the amount of overlapping in order to minimize product development lead time ( Imai et al., 1985; Takeuchi and Nonaka, 1986; Smith and Reinertsen, 1995; Krishnan et al., 1997; Carrascosa et al., 1998; Calantone and Di
Benedetto, 2000 ). Krishnan et al. (1997) were the first to intro-duce an analytical model to estimate the optimal amount of overlapping for two dependent activities. Since then, Carrascosa et al. (1998) also have utilized the Markov Chain concept to calculate product development lead time. The applicability of their models, however, makes this approach suitable only for small projects. Calantone and Di Benedetto (2000) studied the trade-off between product development lead time and product performance. They also demonstrated that optimal overlapping time and lead time can be determined without affecting product performance. Furthermore, researchers included frequent infor-mation exchange (communication policy) with overlapping (extent of the downstream stage executed simultaneously with the upstream stage) for the successful implementation of con-current engineering concepts to minimize production time. Clark and Fujimoto (1991) first emphasized the importance of integra-tion of overlapping and communication strategies. Some of the researchers further exploited and extended this concept for their studies in the broad domain of product development ( Adler, 1995; Sabbagh, 1996; Swink et al., 1996; Sobek et al., 1999;
Collaine et al., 2002; Terwiesch et al., 2002; Carrillo and Franza, 2006 ).

The studies based on the interaction of overlapping and communication can be classified broadly in two categories. First, there are those researchers who considered that information can be exchanged without sacrificing any money ( Krishnan et al., 1997; Roemer et al., 2000; Chakravarty, 2001; Lin et al., 2009 ).
These researchers assumed that communication does not cost anything and modification is transferred to the next stage once information is updated in the upstream stage. Due to such an obvious optimal communication policy, they focused on over-lapping only. Chakravarty (2001) provided a detailed study for the optimal condition and overlapping relationships by grouping such overlapping into three modes: interrupt-build overlapping, con-tinuous-build overlapping, and preempt-build overlapping.
Roemer et al. (2000) proposed an algorithm to determine the optimal amount of overlapping and studying time-cost trade-off for a multi-stage problem. Joglekar et al. (2001) also proposed a performance generation model for the purpose of managing the coupled activities after taking into consideration the constraints related to performance, resource and deadline. Lin et al. (2008) also presented a system dynamics model with the idea of handling an iterative product development process. All aforesaid studies provided detailed insights into various aspects of product development. They are not sufficient, however, to examine the product development process, which is associated with high communication cost. On the other hand, when meetings are held, teams drop all of their current work and participate in these meetings, and so a significant cost is accrued. Too many meetings during product development will result in less time for relevant work, and too few meetings will result in a final product with defects or poor quality. To address the aforesaid ambiguity, it is necessary to explore the relation between communication and overlapping.
 framework for the detailed analysis and estimation of the optimal cycle time of reviews to minimize the expected project comple-tion time. This model was a formal model for the purposes of analysis only. Helms (2002) also studied the interaction between overlapping and communication policy for a chemical company.
Loch and Terwiesch X  X  research (1998) , however, was the maiden breakthrough in the domain of studies pertaining to the under-standing of relations between overlapping and communication strategies.
 2001 ; Roemer et al., 2000 ; Browning and Eppinger, 2002; Wang and Lin, 2009 ) have targeted minimization of development cost in addition to minimization of project completion time to calculate the amount of overlapping and the communication policy. They did not, however, consider this factor explicitly. Most of these models used only two stages for demonstration purposes but Ahmadi et al. (2001) , Browning and Eppinger (2002) , Jun et al. (2005) , Wang and Hwang (2005) , and Wang and Lin (2009) extended their work to multi-stages. In most of the aforesaid works, the focus was mainly on estimating the degree of over-lapping of a group of stages for the minimization of product development time. Some researchers also studied the amount of overlapping and communication policy for product development time. Some of them assumed that communication is costless and should be exchanged as change appears. A handful went against this assumption and studied models with a high communication cost.
 aforesaid works in three major aspects. First, this paper simulta-neously estimates the optimal amount of overlapping and com-munication in order to simultaneously minimize product development lead time and cost for the entire product develop-ment process. Second, this paper adopts the fuzzy goal program-ming-based approach to add the two objectives (i.e., product development lead time and product development cost), which are incommensurate in nature. Finally, the novel approach of GA-PSO is proposed to optimize the formulated objective function. In relation to the addition of two objectives, the next section discusses the relevant background of fuzzy goal programming. 3. Background of fuzzy goal programming
Charnes and Cooper (1961) presented a goal programming (GP) model to obtain satisfactory results in a case of incommen-surable objectives simultaneously. In this model, goals are decided for each criterion by the decision maker in the initial stage, which is followed by calculating the value of decision criteria and measuring their deviations from respective, prear-ranged goals. Now, these deviations act as the decision criteria and are subjected to optimization. Thus, due to the flexibility and simplicity in modeling, as offered by GP, it has received much more consideration in the recent past.

In realistic problems, it is cumbersome to define exact goals for the decision criteria due to their imprecise nature. However, fuzzy set theory, first introduced by Zadeh (1965) , has been accepted widely in the modeling of some of the vague phenomena and relationships that are non-stochastic in nature. In such cases, fuzzy mathematics has an advantage over classical mathematics in that it provides concepts and techniques to deal with the modes of reasoning that are approximate in nature rather than exact. Hence, it is a tool to deal with the imprecise information of the decision maker (DM). This paper estimates the compromise solution by integrating two different models, namely, fuzzy and goal programming, to propose a fuzzy goal programming model.
In this approach, the imprecise objective values are deter-mined in terms of certain scalar membership function value, and thus vector optimization is transformed into a scalar type. Next, different weights also are assigned to each decision criteria by
DM, followed by adding them by way of the additive rule. Rai et al. (2002) and Mishra et al. (2006) have used this concept successfully in solving machine-loading problems. A typical for-mulation of a generalized multi-objective goal programming in fuzzy terms can be expressed as follows:
Subject to 8 &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; : wherein G is an s dimensional vector. Here, G n ( G ), y i goal constraints and system constraints, respectively. Here the goal constraints refer to the number of objectives (goals) which the DM wants to achieve by allowing certain level of variation from target value. The target value according to goal n is represented by P n and the allowable range of variation is defined by different Eqs. (2) or (3) or (4) fitting to the characteristic of goal. The characteristic of goal constraints can be fuzzy-max-imum, fuzzy-minimum, and fuzzy-equal type and their numbers are denoted by d 0 , d 1 d 0 , d 2 d 1 respectively. However, the system constraints refer to the number of constraints imposed on the objective function which must be strictly met. The value of strictly required limitation of the system constraints is repre-sented by H i . As illustrated in next Section 4, the DM wants to optimize the objective function consisting of total production time and total product development cost under a certain limit.
This objective function is subjected to a group of seven strict constraints. Therefore, the considered example has two goal constraints ( n  X  2) of minimization type ( d 0  X  0, d d 2 d 1  X  0) and a set of seven system constraints ( k  X  7).
The notation  X  g  X  represents (fuzzy-maximum) approximately greater than or equal to a certain aspiration level and implies that DM is satisfied even if it is under a certain limit. The symbol  X  represents (fuzzy-minimum) less than or equal to the aspiration level and means that the decision maker is satisfied beyond a certain limit. The symbol  X  ffi  X  indicates that the fuzzy-equal type G n should be in the neighborhood of the aspiration level (i.e., the DM is satisfied even if G n ( G )is o or 4 up to a certain limit). According to the aforementioned types, therefore, the following three functions are defined: A. For fuzzy-maximum:  X  n  X  G n  X  G  X  X  X  B. For fuzzy-minimum:
G  X  n  X  G n  X  G  X  X  X  C. For fuzzy-equal:  X  n  X  G n  X  G  X  X  X 
These membership functions (A, B, C) are strictly monotone (i.e., either increasing or decreasing and continuous with respect to G n ( G )). The membership value is denoted by  X  n  X  G ,T L n as the maximum tolerance limit to the target value. Furthermore, the formulation described in Eq. (1) is reformulated into the following function for a minimization kind of problem: mininimze subject to : 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; :
In Eq. (5), w n is the dominance factor assigned to each goal by the decision maker. The objective is to minimize the weighted sum of membership function value ( MVn ) corresponding to all goals. The estimated membership function value is less than or equal to the value calculated from the equations depending on the type of goal constraint like minimum or maximum or equal and always lies in the range of 0 or 1. For the current paper, the objective is to optimize the combined objective value of product development time and product development cost ( d 1 d 0  X  2) and is subjected to a group of seven constraints ( k  X  7). The next section presents the formulation of objection function. 4. Model formulation
Three dimensions  X  lead time, quality and cost  X  are the key criteria to access the performance of any PDP. Therefore, the basic question for industries is as follows: At what cost are the initial two criteria obtained? ( Roemer et al., 2000 ). In this paper, it is assumed that product quality is benchmarked by top manage-ment, and that to achieve a predefined quality standard, the redesign of the product development stages is conducted with an aim to minimize lead time and cost. It is assumed in the proposed model that the nominal completion time of each stage is deter-ministic and is known in the prior, wherein nominal time is the time taken to perform a stage in the absence of overlapping. It is also assumed that initial meetings create learning effects that create an accumulation of both experience and skills. Taking inspiration from relevant literature ( Chakravarty, 2001; Wang and Lin, 2009; Lin et al., 2009 ), a mathematical formulation was developed for product development lead time and cost, followed by an upstream evolution and its effect on downstream rework.
Finally, fuzzy goal programming formulation is detailed. 4.1. Product development lead time
A number of stages are involved in the new PDP. A certain amount of information is shared by some or all stages once a stage has performed its functionality and information is gener-ated. Such information dependencies can be categorized into three groups ( Wang and Lin, 2009 ), as shown in Fig. 1 . Two or more stages executed sequentially with no interaction are known as the independent stages (1(a)). Two stages are called dependent stages when the latter needs certain information from the former one to start. The latter one has to be reworked in order to accommodate any information changes in the former stage (1(b)). Interdependent stages share information with each other, and one has to be reworked as a result of the information modification mode of the other stage (1(c)).

In this problem, it is assumed that there are STG stages in the product development and that the nominal duration for each stage is N i days. Therefore, total product development lead time in the case of the sequential pattern is as follows:
N i  X  N  X  6  X 
In order to illustrate the proposed model, consider the follow-ing two subsequent stages: A (upstream) and B (downstream) with time durations of T US and T DS , respectively. In the traditional sequential pattern, in the absence of overlapping and commu-nication, T US +T DS will be the total completion time for both stages.
In overlapping patterns, however, a portion of stage B is executed in parallel to stage A on the basis of the rudimentary information available at the end of time period T I , as shown in Fig. 2 (a) Y ( Lin et al., 2010 ). Once the rudimentary information is released to the downstream stage, it is continuously updated until the upstream stage finishes. The proposed model is based on the assumption related to the principal information exchange, i.e., the nominal sequential structure of the projects. This exchange of information is only from upstream to downstream, i.e., unidirec-tional. Therefore, due to the dependency of the downstream stage on the upstream stage, a constraint is imposed on the former one.
This constraint forces the downstream stage not to finish before the upstream stage. Therefore, all possible amounts of overlap-ping (which is a continuous measure) lies in the range of ( T T US ), wherein T m is the lower bound on the start time ( T downstream stage. T m is a non-negative factor that has the value of max(0, T US  X  T DS ). The model described is extended here for handling a complete PDP involving several groups of two over-lapped stages.

T seq  X  T conc if any drawback of overlapping has not occurred. In reality, overlapping is associated with significant drawbacks despite its immediate time merits ( Ha and Porteus, 1995 ). The reason is, as discussed earlier, the dependency of the downstream stage on the rudimentary information as compared to the fina-lized information in the sequential pattern. In the two scenarios, the overlapping of stages will not provide the desired results wherein (1) the upstream information is modified significantly and/or (2) the downstream stage is highly dependent on the upstream stage ( Loch and Terwiesch, 1998 ). In order to combat the effect of the two aforementioned scenarios, teams commu-nicate before the beginning of the PDP, known as pre-communication.
 thus, the amount of rework time, but only at the cost of pre-communication time ( c ). Then, the upstream starts working and the maiden information is transferred to the downstream stage at T time. At each iteration, updated information is transferred to the downstream stage at the cost of communication time, causing a delay due to meetings. This communication time consists of two phases. The first phase includes the time for the set up and penalty times. The second phase includes the time for inspection for the upstream since the last review and time to communicate sufficiently all changes to the downstream stage. After that, the downstream stage has to be reworked iteratively to accommodate the changes that occurred in the upstream due to modification in the rudimentary information available in the beginning. This is termed as overlapping iterations ( Krishnan et al., 1997 ), which alert downstream engineers of the latest changes and so lead to reduced reworking. Therefore, in the case of concurrent engineer-ing, the time ( T ) for the complete product development project is the combination of the following several constituents as shown in Fig. 2 (b):
T  X  Pre-communication time ( c )+Initial start time ( T I stream stage time ( T DS )+Rework time ( T RET )+Communication time ( T COT )+Non-overlapped time ( T NO ) T  X  c  X 
The next section discusses the formulation of product development cost. 4.2. Product development cost In this section, the cost associated with PDP is estimated.
Several interesting implications can be deduced by considering the fact that minimization of time is not synonymous with minimization of cost ( Chakravarty, 2001 ). Product development cost ( C ) is the collection of the following several constituents, which include pre-communication cost ( C c ), actual working cost ( C
AWC ), rework cost ( C REC ), and communication cost ( C COT this formulation incorporates different types of costs associated with the complete network of the underlying problem.
 C  X  Pre-communication cost ( C c )+Actual working cost ( C
Rework cost ( C REC )+Communication cost ( C COT )+Non-overlapped cost ( C NO ) C  X  C c  X 
Any group of two overlapped stages will be subjected to the following constraints:
T r T I r T US  X  9  X  1. Eq. (9) ensures the condition that the starting time of the downstream stage lies between the range of the lower bound value for the overlapping time and duration for upstream activity, wherein:
T m  X  max  X  0 , T US T DS  X  X  10  X  2. Eq. (10) poses a constraint on the lower-bound time for the starting of the downstream stage because it is always positive or zero: 3. Eq. (11) sets the condition that the duration for all iterations of each group of the overlapped stages is equal to the amount of overlapping. This also ensures that the last burst of informa-tion transfer is settled at T US in order to incorporate all modifications that occurred at upstream stage.
 4. Eq. (12) is used to estimate the time for the next iteration to transfer the information to the downstream stage:
T F r T DU  X  13  X  5. Eq. (13) ensures that the upstream stage modifications freeze before the downstream stage is completed:
T r T Mag  X  14  X  6. Eq. (14) is used to ensure that the development time is less than the previous generation of the product or when compared to that previously decided by management:
C r C Mag  X  15  X  7. Eq. (15) is used to ensure that the development cost is less than the cost previously set by management: n o 1  X   X  l t  X  l r  X  m r  X  l 8. Eq. (16) poses a constraint on the number of maximum information bursts at the upstream stage by taking into account the total profit of overlapping and the cost due to the transfer of information and rework. The next section details the concept of evolution and sensitivity. 4.3. Evolution and sensitivity
The evolution speed of the upstream stage information and the sensitivity of the downstream stage both influence the amount of rework ( Krishnan et al., 1997; Lin et al., 2009 ). The amount of downstream stage rework is the key factor in product develop-ment lead time and cost. In this research, it is considered that the information modification at the upstream stage follows a non-homogeneous Poisson Distribution with a non-negative average rate that depends on time. This assumption is general and helps in capturing all kinds of upstream evolution patterns such as S-shaped, convex, and concave, as described in past studies ( Krishnan et al., 1997; Chakravarty, 2001 ). On the basis of the pattern followed by changing values of the average modification rate, two kinds of evolutions are defined. If the modification rate decreases with time, then it is called a fast evolution and the final form from rudimentary information is attained rapidly. In case of slow evolution, however, the opposite phenomenon is observed, i.e., the average modification rate is increased over the period of stage execution.

In the literature, it has been shown that pre-communication results in a reduction of uncertainty caused by problems relating to manufacturing and maintainability. Therefore, meetings are organized among cross-functional teams before starting PDP, and these teams can share their past experiences, proven technolo-gies, or approved databases in relation to the current project. This kind of meeting can help in mitigating routine problems that past solutions can resolve.  X  p 0 exp  X  B c  X  X  17  X  wherein p 0 represents the level of technical uncertainty at the beginning of a project in the absence of planning. B captures the organization X  X  ability to reduce uncertainty during functional interaction, and c represents the number of meetings before the development work begins. The better value of B involves a higher reduction gained in uncertainty at a particular communication intensity. Eq. (18) represents the value of p k ( T US )changing with the upstream time and communication:  X  T US  X  X  p c 1 e 2 T US t s
Lin et al. (2008) have demonstrated that, generally, the down-stream stage rework caused by modifications in the upstream stage proportionally depends on the progress of the downstream stage. At any time, t , the downstream stage progress is repre-sented by D ( t ) and modifications affect p percentage of down-stream work, changing the progress to D ( t )(1 p ). A simultaneous second modification will change the progress to D ( t )(1 p ) this way, d modifications will result in D ( t ) ( 1 p ) d downstream progress. For purposes of simplicity, this paper defines a dependency parameter Y . The value of this parameter is estimated as ( ln(1 p )), and the downstream progress after d modifications is estimated as D ( t )( e dY ).

The downstream stage continuously works from time t 0 to t and the upstream modifications are released at time t 1 , as shown in Fig. 3 . The total number of modifications raised at the t calculated according to non-homogeneous Poisson Dis-tribution progress from D 1 to D 1 e f d between time periods t 1 and t 2 are transferred at time t the downstream stage progress is reduced from
D ! no
Thus, Eq. (19) estimates the amount of downstream stage rework for one group of overlapped stages: T  X 
Upstream modifications, downstream dependency, amount of overlapping and communication policy are key parameters that have a dynamic influence on the downstream stage rework. The next section discusses the fuzzy goal programming model for-mulation for the underlying problem. 4.4. Fuzzy goal programming formulation
The problem described above is formulated as the bi-criterion objective, out of which one represents product development lead time and the other indicates cost. Here, the decision maker wants the PDP lead time and cost to be below a certain limit; hence, the
Work progress of downstream fuzzy minimum approach is the best choice. In this paper, goals are synchronized to determine the following objectives: (a) optimal amount of overlapping; (b) optimal communication policy; and (c) number of initial meetings (pre-communication). mathematical form: wherein w n dominance or priority factor is assigned to goals by the decision maker, and MV n is the membership function value of goals: product development lead time and product development cost, respectively.  X  g- X  indicates the goal set by the decision maker for both objectives. The fuzzification of goals for the underlying objectives is explained by Eq. (21). This equation captures the vague nature of the goals in the problem at hand. Fig. 4 shows the relationship between function value and membership value.
MVn  X  wherein T R n is the tolerance limit for goals and n is the index for goals. P n is the value of n th goal set by the decision maker and
G n ( G )is the estimated value of the function. Section 5 details the proposed optimization methodology. 5. Proposed optimization methodology: Gaussian Adaptive Particle Swarm Optimization optimization techniques to solve complex optimization problems effectively. In recent years, intelligent search algorithms (for example, Simulated Annealing, Genetic Algorithm, Ant Colony
Optimization, and Particle Swarm Optimization), utilizing some analogies with natural or social systems, have been applied to obtain optimal/near-optimal solutions. These algorithms basically search for an optimal solution in a random manner in a feasible search space. Continuous improvements in the past few years have reduced the response time of these meta-heuristics spectacularly, while also substantially increasing solution quality. Considering the computational complexity involved in the problem at hand, this research proposes a new meta-heuristic having its basic roots in PSO. 5.1. Background of PSO
In the last decade, Kennedy and Eberhart (1995) introduced a meta-heuristic known as  X  X  X article Swarm Optimization X  X  (PSO), which simulates the social behavior of birds as a flocking behavior. The basic constituents of the PSO-based computational paradigm are a population known as a swarm and an individual termed as a particle. In the simple version of PSO, particles change their velocity within the search space, guided by the best position ever attained by an individual particle (i.e., local search), as well as the best position found by all particles in a swarm (i.e., global search). Let us consider an n -dimensional search space with the number of particles in the swarm as m _ swarm . The position vector of the k th particle is denoted as P k  X  { P k1 , P the velocity vector is represented as V k  X  { V k1 ,V k2 , initialization stage, each particle is assigned a random position and velocity. The best position achieved by the individual particle up to the t th iteration is represented as p l  X  { p l 1 p global best found so far is enabled by p l  X  { p g 1 , p g 2 more, velocity and position of the individual particle is updated by using the following two equations:
V k  X  inertV
P k  X  P wherein V t  X  1 k denotes the velocity of k th particle at ( t+ 1)th iteration. l 1 and l 2 are acceleration coefficient and r generated in the range of [0, 1] by applying the uniform prob-ability distribution function. Eq. (22) is comprised of three components. The first component is the contribution of the particle X  X  previous velocity, which is equal to the velocity multi-plied by the inertial weight factor. The second component is the cognitive search, which pulls the particle to the region of the best position ever attained by that particle. The last part is the social search component, which speeds the particle toward the best position found so far. According to Eq. (23), the updated position is calculated. Furthermore, this updated position is used to determine the fitness of each particle according to the perfor-mance measure function. After each iteration, Eqs. (22) and (23) are employed to change the velocity and then the position of each particle. If a better individual or (and) global position is encoun-tered as compared to a previous iteration, the improved position (local or/and global) is retained in the particle memory. Faster convergence of PSO algorithm is a result of the synchronized effect of the cognitive and social component.
 The basic version of PSO has two drawbacks ( Ratnaweera and
Halgamuge, 2004 ): (1) the inability of the algorithm to adjust itself in the different stages of exploration and (2) the generation of random numbers. In order to address the aforementioned two issues, this paper proposes an improved version of PSO. The first shortcoming is avoided by using the time-varying acceleration coefficients (TVACs) in addition to time-varying inertial weight (TVIW). In order to remove the latter shortcoming of the algo-rithm, a Gaussian distribution function is applied instead of the uniform distribution function. 5.2. Time-varying acceleration coefficients (TVACs)
In the proposed algorithm, the concept of TVACs l 1 and l are incorporated, including all existing fundamentals ( Bachlaus et al., 2006 ). Owing to the advantages of TVACs, a better balance MV n between both social and cognitive components is established, which in turn leads to improved performance of the algorithm. Both of these components (i.e., social and cognitive) guide the search toward the best solution. Therefore, an emphasis on proper control of these two components is considered as a prominent strategy in exploring the best solution efficiently and effectively. Taking into consideration the above concept, the social compo-nent is increased, whereas the cognitive component is reduced by altering the acceleration coefficient l 1 and l 2 in Eq. (13) with increasing iteration. In the initial search phase, the social compo-nent is maintained as smaller, while the cognitive component has a larger value, so that the algorithm searches for the whole search space rather than the best solution of iteration. On the other hand, in the latter phase, with a larger social component and smaller cognitive component, the algorithm is capable of finding the global optimum value. This whole concept can be represented mathematically as follows: l l from 2.5 to 0.5 and from 0.5 to 2.5, as provided in Bachlaus et al. (2006) . iter represents the current iteration number, and max_iter is the maximum allowed number of iterations. The advantage of the aforementioned modification is two-fold. First, it helps the algorithm to avoid premature convergence in the early search stage, and it also improves the best solution in the latter search stage. 5.3. Gaussian probability distribution function
This section advocates the implementation of Gaussian prob-ability distribution function to generate the random numbers. Traditionally, in order to generate the random number in the velocity updating Eq. (13), a uniform probability distribution function is used. In generating the random numbers, the follow-ing two key limitations are associated with random number generators ( Caponetto et al., 2003; Krohling, 2004 ): (1) They result in sequential correlation of successive cells and so (2) They have an acute tendency to generate higher-order ran-
The first limitation results in an increased number of iterations to obtain the near-optimal or optimal solution, and the second one constraints the ability of the algorithm to explore the whole search space. These limitations have motivated researchers to employ various probability distribution functions that consis-tently perform better in generating the random numbers. Keeping this aspect in mind, the paper proposes a strategy that utilizes Gaussian probability distribution ( Khilwani et al. 2008 ). This combination provides fast convergence and ensures near-opti-mal/optimal solutions by establishing a proper balance between exploration and exploitation. After applying the Gaussian prob-ability distribution function to generate a random number in both the social and cognitive parts, the velocity updating equation is expressed as follows: V k  X  inertV wherein GPD 1 and GPD 2 are functions with Gaussian probability distribution. The value is determined in the range of [ 1, 1], which is further reset in the interval [0, 1]. Fig. 5 shows the detailed implementation procedure of the proposed algorithm in solving the underlying problem. 6. Illustrative example
In this section, a hypothetical illustrative example of mobile phones is employed to illustrate the proposed model and algo-rithm. Five main stages typically exist in a typical product development project pertaining to mobile phones ( King 2007 ).
The beginning stage of product development is the conceptuali-zation, in which innovative ideas are generated and screened.
These screened ideas are developed and tested further and are checked for technicality and preliminary Design for Manufactur-ability (DFM). The second stage is product specification and product architecture, which takes into account the voice of customers through market surveys and conducts the analysis of collected data. Additional product technical goals such as time and cost are decided, along with product specifications. Simula-tions and computer-aided design (CAD) help in improving and selecting better product architecture. The in-depth study of the product and process design is performed in the next stage, namely, the business case. In the fourth stage, Final Specifications and Design Development, prototypes are constructed and eval-uated for testing and experimental purposes and then the final no design is confirmed. In the last stage, Technical Implementation and Validate, the product and process validation is ensured with testing of usability and market acceptance. Moreover, supple-mental documents are prepared in relation to safety and occupa-tional health issues. Table 2 shows all of the stages and subsequent activity names involved in product development of the considered example of mobile phones, along with their nominal times. The authors determined intuitively that seven groups of successive stages can be overlapped. These are (1, 2), (5, 6), (8, 9), (11, 12), (14, 15), (18, 19) and (20, 21). The basic criterion for their selection is the possibly significant amount for overlapping and some relationship between them. The execution cost related to each stage also was assigned to calculate the total amount of the product development cost. 7. Implementation procedure embedded with two beneficial attributes: (1) Gaussian probabil-ity distribution and (2) Time-varying Acceleration Coefficients.
The suggested modification aims at ensuring elitism and steers the search toward optimal regions of search space. Fig. 5 shows the implementation procedure of the proposed algorithm in relation to the problem at hand.
 components of the proposed GA-PSO meta-heuristic. 7.1. The encoding schema values is employed in the proposed approach. The generic con-struct of a swarm thus formed is composed of sequentially arranged pre-communication meetings, the amount of overlap-ping for each group and the communication policy for each group.
For example, consider a swarm design composed of the aforesaid entities shown in Fig. 6 , whereby the first swarm cells (integer encoded) represent the number of pre-communication meetings needed to reduce the amount of uncertainty before project onset.
The next seven swarm cells, respectively, indicate the amount of overlapping for all seven groups of overlapped successive stages.
Thereafter, one cell is encoded to signify the number of rework iterations defining communication policy for the first group of overlapped stages. Similarly, the value in the next swarm cells decides the communication policy for the rest of the overlapped group of stages.

A simplified and effective representation of search space is the key advantage obtained through the use of the proposed encoding schema. The complete structure of the overlapped problems through the proposed encoding methodology is another point worth consideration. Factors such as allocation of pre-commu-nication and amount of overlapping each group of overlapped stages, as well as the communication policy for each group of overlapped stages are taken care by the proposed method. Fig. 7 shows the procedure to generate the potential particle. 7.2. Fitness evaluation
A fitness function is used to evaluate the effectiveness of the swarm of each population. The lower the fitness value of swarm, the better the objective function value will be. In this research, the fuzzy goal programming approach is utilized as a tool to estimate the fitness value. A procedure is proposed in this research to estimate the value of the fitness function, as shown in Fig. 8 . The proposed procedure utilizes as input the maximum number of meetings and the nominal duration of each overlapped stage that provides decisions regarding the possible amount of overlapping. It then assigns a communication policy to each group of overlapped stages, based on the maximum amount of overlapping. 7.3. Updating of equation For the updating purpose, a modified equation (27) is employed. This equation exploits both of the beneficial ch aracteristics proposed in this paper: V k  X  inertV
The next section will discuss the obtained results and their discussions. 8. Results and discussion
This section will offer details of the obtained results by applying the proposed algorithm (GA-PSO) to the considered example. Then, they will be compared with the two variants of PSO to assess related behavior and relative strengths. Comparison of the algorithms has been made on the basis of the resulting value returned by each algorithm when applied to the same case study. The goal was to provide the optimal value of the best swarm. Coding was performed in C++and in the complied program on a system specification 2.0 GHZ Pentium IV processor and 2 GB RAM. Several combinations of values for the parameters used in
GA-PSO, CPSO and PSO were tested, and results will be reported for the parameter values that were found best. A population size of 20 was utilized for all simulations in this paper. In order to measure the performance of each algorithm on a common plat-form, the number of fitness function evaluations was considered as the stopping criterion, and all three algorithms were run for an equal number of fitness function evaluations (10,000 iterations). 8.1. Computational outcomes
This section will offer the obtained computational results after implementation of the proposed algorithm has been detailed within the considered example. Table 3 offers the results yielded by GA-PSO with TVACs when both objectives are assigned equal value (0.5). The same table shows the values of the optimal swarm, which represent the value of pre-communication, the amount of overlapping of each group, and the optimal commu-nication policy for each overlapped group. Pre-communication helps in alleviating the influence of uncertainty before the beginning of the project and plays a key role in reducing the development lead time and rework.

It is evident from Table 4 that the product development lead time drops from 158 days to 133 days (16.3% reduction) at a 10.1% increment of cost from 2470 to 2723. This increased cost is due to the additional time for rework and communication caused by the overlapping. However, when both the objectives are assigned different values ( T  X  0.3 and C  X  0.7), the product devel-opment time is estimated as 139.5days (from 158) at the cost of 2610 (5.66 increment).

As mentioned earlier in Eq. (17), B plays an important role in reducing the technical uncertainty during the function interac-tion. It is obvious that more is the capability of organization to reduce the technical uncertainty, lesser will be the product development time and cost. It is also justified from Table 5 that the amount of product development time and cost is minimum (127.59, 2501.52) when the value of B is 0.3. It can also be deduced from Table 5 that the rate of improvement in objectives decreases as the value of B is increased. 8.2. Algorithmic performance
In order to show the robustness of the proposed algorithm and to assess its performance, a rigorous analysis is carried out and is confirmed by comparing the obtained results with that of two other variants of PSO. The value of the objective function approaches optimal/near-optimal value as the number of itera-tion (function evaluations) increases. See Table 6 .

The comparison of GA-PSO and two other variants is con-ducted on the basis of the final resulting value obtained. For the overlapped stage first case, the optimal value of the objective function using TPSO and CPSO is calculated as 0.368815 and 0.360293 while using GA-PSO as 0.355556. The total number of iterations in TPSO and CPSO are 8086 and 3893 while that of GA-PSO is 3337, so as to obtain a better resulting value as compared to them. Thus, GA-PSO also was found to perform better in terms of the number of function evaluations. It is evident from the obtained results that GA-PSO converges faster and takes fewer function evaluations when compared to TPSO and CPSO. Fig. 9 shows the convergence graph obtained for GA-PSO, along with TPSO and CPSO in union.
Although the quality of the final solution obtained for all approaches is approximately equivalent, there is a slight differ-ence among the optimal value returned by them. In a more precise way, the result value obtained adopting GA-PSO is better as compared to the other approaches (i.e., CPSO and TPSO) on the grounds of fitness value and number of iterations to reach it. 9. Conclusion and future research
This paper has conceived an overlapping and communication policy problem in product deve lopment. A mobile phone product development problem has been modeled mathematically with the aim of simultaneous minimization of product development lead time and cost. A fuzzy goal programming-based approach was adopted as a model of formulation that helps in capturing the vague nature of goals set by the decision makers. The problem has been solved through the use of a proposed Gaussian Adaptive PSO meta-heuristic, which amalgamate s the features of the time-varying acceleration coefficient, Gaussian distribution and Particle Swarm
Optimization. The algorithm cla ims to utilize the advantages accrued from Gaussian distributio n and adaptability to search for global optimum in large solution spaces. The overlapping strategy helped in reducing the precut development time by more than 16%, but it requires an additional sacrifice of 10.1% of the amount of the cost. Simulation results indicate that the results produced by the proposed approach are better than those obtained by PSO and CPSO alone, and the solutions also had a superior final value and good convergence characteristics.

The proposed model is generic and can be extended to handle more products of the same family. We have included, however, several assumptions that simplified the model and limited its applicability to real problems. In order to bring this model in line with realistic scenarios, incorporation of more complexities is clearly a matter of future research. Several additional issues that have potential for future research are as follows: (i) Introduction of interdependent stages. (ii) Overlapping of more than two stages. (iii) Inclusion of multiple constraints regarding time and cost. (iv) Incorporation of estimated product quality to estimate the overlapping amount and communication policy. (v) Extension of the model for multi-generation of the product. References
