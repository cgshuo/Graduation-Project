 Department of Computer Science and Artificial Intelligence, CITIC, University of Granada, Granada, Spain 1. Introduction
The approach we propose in this paper intends to solve the second-order data mining problem that often arises in practice; i.e. when the results of a data mining process have to be mined themselves due to their huge volume. Researchers in the data mining field have traditionally focused their efforts to obtain fast and scalable algorithms in order to deal with huge amounts of data. When dealing with association rules, for instance, the overwhelming number of discovered rules, usually in the order of thousands or even millions, makes them of limited us e in practice. The mere volume of these sets of rules causes the aforementioned second-order data mining problem [3].

Databases can naturally contain groups of individuals that share some characteristics [18]. For exam-ple, within a census database, we can find many different groups of individuals, e.g. according to their sex, their marital status, whether they have children, or just by combining several of such attributes. Our proposal consists in automatically identifying potentially useful groups of related association rules and ranking the resulting group association rules so that expert users can more easily sift through vast amounts of association rules.

Our paper is organized as follows. In Section 2, we present the state of the art and describe some rule explain how to rank groups and group association rules within each group. Section 5 introduces criteria to compare alternative rankings. We analyze the experimental results we have obtained in Section 6. Section 7 provides some guidelines to identify the most interesting groups according to the experiments. Finally, we end our paper with some conclusions in Section 8. 2. State of the art
Association rules have been used to analyze co-occurrence relationships among frequent itemsets in database transactions where each transaction T is a set of items such that T  X  I .Let S beasetofitems. A transaction T is said to contain S if and only if S  X  T [10]. An association rule is an implication of the form A  X  C ,where A  X  I , C  X  I ,and A  X  C =  X  .

In the following sections we will present related work to association rules and its interestingness measures as well as a summary of the interestingness measures that have been proposed in order to evaluate association rules. 2.1. Related work
One of the challenges when mining patterns and association rules is to deal with the huge amount of them that can be discovered in the mining process. Therefore, it is necessary to establish some kind of measure in order to determine which are the most interesting ones.

This problem has been addressed from several points of views. Several authors resort to statistical techniques in order to evaluate the patterns applying statistical hypothesis tests [22], using empirical Bayes models [6] or log-linear models [23]. Other proposals use clustering techniques to reduce the our goal is to identify the most interesting ones.

In the following section we analyze some of these interestingness measures proposed for association rules that we will adapt and extend to the case of the group association rules. 2.2. Interestingness measures for standard association rules
Interestingness measures have been widely used in the data mining area. Tan et al. [20] proposed objective measures to evaluate association patterns. Other measures have been proposed to evaluate as-and its confidence [1,10].
 Definition 1. The support of an itemset X in the database D is defined as the percentage of transactions that contain X , i.e., Definition 2. The rule A  X  C holds in the transaction set D with support supp ( A  X  C ) ,where supp ( A  X  C ) is the percentage of transactions in D that contain A  X  C ,i.e., Definition 3. The rule A  X  C has confidence conf ( A  X  C ) in the transaction set D , where conf ( A  X  C ) is the percentage of transactions in D containing A that also contain C , i.e.,
Confidence has some drawbacks, as we can see in the example shown in Fig. 1, where we graphically represent two rules, A  X  B and A  X  C .Forthe A  X  B rule, we have the following support values for the intervening itemsets: supp ( A )= 28%, supp ( B )= 38%, and supp ( A  X  B )= 21%. Therefore, the confidence of the A  X  B rule is 75%. For the A  X  C rule, even though the support of the consequent changes (supp ( C )= 85%), the confidence value of the A  X  C rule is still the same, 75%. In the first case, B was present in 38% of the transactions in the database and its presence increases to 75% in transactions where A is also present. In the second case, the presence of A reduces the presence of C , from 85% to 75%. However, the confidence measure does not let us distinguish between these two different situations.

In short, the confidence measure does not take into account the support of the rule consequent, hence it is not able to detect negative dependencies between items. Several measures have been proposed in support/confidence framework [9]. In the following paragraphs, we describe some of them. Definition 4. The lift of the rule A  X  C , also known as interest, is defined as [4]:
The lift measure indicates how many times more often A and B occur together than expected if they where statistically independent. Values above 1 indicate positive dependence, while those below 1 indicate negative dependence. The lift values of the A  X  B and A  X  C rules in the aforementioned corresponds to our intuition that A  X  B is more interesting than A  X  C .

Lift measures the degree of dependence between the itemsets. However, it only measures co-occurrence, but not the implication direction, since it is a symmetric measure, i.e., lift ( A  X  C )= lift ( C  X  A ) .
 Definition 5. The conviction of the rule A  X  C is defined as [5]:
The advantage of conviction with respect to the confidence measure is that it takes into account both interval mean negative dependence, values above 1 mean positive dependence, and a value of 1 means independence, as happened with the lift measure. Unlike lift, conviction is not a symmetric measure, i.e. it measures the implication direction.

In the example from Fig. 1, supp (  X  B )= 0.62 and supp ( A  X  X  B )= 0.07. Therefore, the conviction of the A  X  B rule is 2.48. For the A  X  C rule, supp (  X  C )= 0.15 and supp ( A  X  X  C )= 0.07. Therefore, conv ( A  X  C ) = 0.6, which means negative dependence.
The main drawback of the conviction measure is that, as happened with lift, it is not bounded, i.e., its range is [0,  X  ). Therefore, it is difficult to establish a convenient conviction threshold in practice.
Let us now define an ancillary measure that will be useful in our discussion below: the gain of a rule as the difference between its confidence and the support of its consequent. Formally, Definition 6. The gain of a rule A  X  C is defined as:
The gain values for the rules in Fig. 1 are gain ( A  X  B ) = 0.75  X  0.38 = 0.37 and gain ( A  X  C ) = 0.75  X  0.85 =  X  0.10. Figure 2 graphically shows these values. The lengths of the arrows represent given that the antecedent is present.
 Definition 7. The certainty factor of a rule A  X  C is defined as [19]:
The certainty factor is, therefore, the gain value normalized into the [  X  1,1] interval. The certainty factor can be interpreted as a measure of the variation of the probability that the consequent is in a transaction when we consider only those transactions where the antecedent occurs. More specifically, a positive CF measures the increase of the probability that the consequent is in a transaction, given that the antecedent is.
 In the example from Fig. 1, the CF of the A  X  B rule is 0.37/(1  X  0.38) = 0.60 while the CF for the A  X  C rule is  X  0.10/0.85 =  X  0.12. 3. Interestingness measures for group association rules
In this section, we describe how association rules can be defined to study the features that individuals within a given group have in common. We define a group as a set of items G = { G 1 ,G 2 ,...,G n } such that G  X  I .A group association rule G : A  X  C is an association rule A  X  C defined over the group G . In other words, a group association rule G : A  X  C is equivalent to the classical association rule GA  X  C .

In the following paragraphs, we explain how to adapt the measures described in Section 2 to group association rules, as well as how these new measures can be useful for evaluating the interestingness of group association rules.
 3.1. Group support Definition 8. The support of an itemset X in the group G is the percentage of transactions in G that contain X , i.e.,
Figure 3 shows the representation of a group G within an example dataset. The support of circles (  X  ) in the group G is supp G (  X  )= 6/15 = 0.4.
 Property 1. The support of an itemset X in a group G is the confidence of the rule ( G  X  X ) ,i.e., Therefore, supp G ( X )= conf ( G  X  X ) Definition 9. The support of the group association rule G : A  X  C is defined as:
In the previous example, the support of the group association rule G : A  X  X  is supp G ( A  X  X  )= 5/15 = 0.33.
 Property 2. The support of the rule A  X  C in a group G is the confidence of the rule G  X  AC ,i.e., 3.2. Group confidence Definition 10. The confidence of the group association rule G : A  X  C is defined as: The confidence of the rule G : A  X  X  in Fig. 3 is conf G ( A  X  X  )= (5/15)/(10/15) = 0.5. Property 3. The confidence of a rule A  X  C in the group G is the confidence of the rule GA  X  C in the database, i.e., Proof. By Definition 10, conf G ( A  X  C )= 3, conf ( GA  X  C )= P ( GAC ) P ( GA ) . Therefore, conf G ( A  X  C )= conf ( GA  X  C ) . 3.3. Group gain Definition 11. The gain of the group association rule G : A  X  C is defined as:
The gain represents the difference between the confidence in the presence of the consequent when we know that the antecedent appears in the group, minus the support of the consequent within the group. G : A  X  X  rule is conf G ( A  X  X  )= 0.5. Then, the gain of the rule is gain G ( A  X  X  )= 0.5  X  0.4 = 0.1. That means that, within the group G , finding a circle is 10% more likely when A holds.
Rules with high positive gain values help us describe subgroups (circles in the previous example) within the group G . On the other side, rules with high negative gain values help us find characteristics that are less frequent within the subgroup than in the overall group. For example, if the rule A  X  X  had a negative gain value, that would mean that it would be more difficult to find a circle among those elements in GA than in G .
 Property 4. The gain of the rule G : A  X  C is the difference between the confidence of the GA  X  C rule and the confidence of the G  X  C rule , i.e., Proof. By Definition 11, gain G ( A  X  C )= conf G ( A  X  C )  X  supp G ( C ) . By Properties 2 and 3, supp G ( A  X  C )= conf ( G  X  AC ) and conf G ( A  X  C )= conf ( GA  X  C ) . Therefore, gain G ( A  X  C )= conf ( GA  X  C )  X  conf ( G  X  C ) Property 5. The gain of the G : A  X  C rule is the difference between the gain of the GA  X  C rule and the gain of the G  X  C rule , i.e., Proof. By Definition 6, gain ( G  X  C )= conf ( G  X  C )  X  supp ( C ) . Then, we can solve for conf ( G  X  C ) as conf ( G  X  C )= gain ( G  X  C )+ supp ( C ) . If we replace the conf ( G  X  C ) in Property 4, we obtain gain G ( A  X  C )= conf ( GA  X  C )  X  conf ( G  X  C )= conf ( GA  X  C )  X  supp ( C )  X  gain ( G  X  C ) . Finally, by Definition 6, conf ( GA  X  C )  X  supp ( C )= gain ( GA  X  C ) . Therefore, gain G ( A  X  C )= gain ( GA  X  C )  X  gain ( G  X  C ) .
 Theorem 1. Gain pseudo-commutativity . The difference between the gain of the G : A  X  C rule in the G group and the gain of the A  X  C rule in the database equals the gain of the rule A : G  X  C in the group A minus the gain of the G  X  C rule in the database, i.e., Proof. By Definition 6, gain ( G  X  C )= conf ( G  X  C )  X  supp ( C ) .

We can isolate conf ( G  X  C )= gain ( G  X  C )+ supp ( C ) and replace it in gain G ( A  X  C )= conf ( GA  X  C )  X  conf ( G  X  C )= conf ( GA  X  C )  X  ( gain ( G  X  C )+ supp ( C )) .

If we isolate supp ( C ) from Definition 6 and replace it in the previous expression, we obtain: gain G ( A  X  C )= conf ( GA  X  C )  X  ( gain ( G  X  C )+ supp ( C )) = conf ( GA  X  C )  X  gain ( G  X  C )  X  ( conf ( A  X  C )  X  gain ( A  X  C )) = conf ( GA  X  C )  X  ( conf ( A  X  C )  X  gain ( G  X  C )+ gain ( A  X  C )) .
 By Definition 11, the first term can be expressed as conf ( GA  X  C )  X  conf ( A  X  C )= gain A ( G  X  C ) . Then, we have gain G ( A  X  C )= gain A ( G  X  C )  X  gain ( G  X  C )+ gain ( A  X  C )) .
Therefore, gain G ( A  X  C )  X  gain ( A  X  C )= gain A ( G  X  C )  X  gain ( G  X  C ) . 3.4. Group gain normalization following paragraphs, we propose several ways to normalize the group gain depending on the kind of information the user might be more interested in. 3.4.1. Group gain factor the certainty factor in the general association rule framework: Definition 12. The gain factor of the group association rule G : A  X  C is defined as: In our example, the gain factor of the rule G : A  X  X  is GF G ( A  X  X  ) = 0.1/(1  X  0.4) = 0.17.
This measure is proportional to the group gain. When it is positive, it is also inversely proportional to elements that were more common in the group G (i.e., those having a higher supp G ( C ) ). When GF is is less frequent in G , i.e. for small values of supp G ( C ) . 3.4.2. Group variation
The group variation measure always normalizes the gain using the supp G ( C ) value, in order to high-light those consequents that are less frequent in our database.
 Definition 13. The variation of a group association rule G : A  X  C is defined as: the gain is negative. The variation of the rule G : A  X  X  in Fig. 3 is  X  G ( A  X  X  ) = 0.1/(0.4) = 0.25. 3.5. Group impact
In this section we present two new interestingness measures that are also based on the group gain. In these measures, we take into account the support of the group corresponding to the antecedent of the rule. 3.5.1. Impact Definition 14. The impact of the group association rule G : A  X  C is defined as:
The impact of a group association rule represents the number of individuals that are affected by the that contain A given what we knew about G in general.

The impact is proportional to gain G ( A  X  C )and supp ( GA ) . It will be higher for those rules with a high gain and a frequent antecedent in the G group.

In our example from Fig. 3, impact G ( A  X  X  ) = (10)*0.1 = 1. That impact means that there is one circle that we did not expect to find in GA when we only knew the support of circles in G .Since supp G (  X  )= 0.4, we did expect four circles in GA but found five of them. 3.5.2. Impact ratio
The impact measure represents the number of individuals that are affected by the rule. However, in most cases, groups have different numbers of individuals and an absolute impact value might be number of individual affected by the rule and the number of individuals within the group. Definition 15. The impact ratio of the group association rule G : A  X  C is defined as:
The impact ratio of a group association rule represents the proportion of the impact of the rule within the group G with respect to the size of the group. The impact ratio is IR G ( A  X  X  ) = 1/15 = 0.07 in the example from Fig. 3.
 4. Ranking groups and group association rules
All the different groups that can be identified in the database, as well as the rules within them, can be obtained in an unsupervised manner. However, the number of rules and groups obtained in the rule mining process can be huge. As a consequence, a second-order data mining problem arises: it may be too difficult to extract useful information from so many rules and groups.

In this section, we explain how to rank the groups (and the rules within the groups) according to their potential interestingness. We will use the measures we described in previous sections to highlight those rules and groups that might be relevant to the user according to different criteria. 4.1. Ranking rules within a particular group
The use of each different interestingness measure provides a different ordering relationship among the discovered association rules. In this section, we analyze how two rules within a group will have a different relative order within that group depending on the interestingness measure we use to evaluate them.
 Figure 4 shows a group, G , within an example dataset. In this group, we have identified two rules, A  X  X  and B  X  , whose values for the different interestingness measures we described in the previous sections are summarized in Table 1. 4.1.1. Characterizing subgroups within a group
If we are interested in obtaining those rules that characterize subgroups within a group (i.e., rules sharing their consequent), we should use the gain measure because a high gain increases our confidence in the presence of the consequent when we know that the antecedent holds.

In our example from Fig. 4, the gain of both rules is 10%, i.e., the confidence on the presence of  X  increases if A also holds, while the confidence on the presence of the increases, in the same amount, when B is true.

Both are important rules within the group G but they give us different information as squares are more frequent in G than circles. Therefore, we should use other measures for distinguishing between them:  X  If we want to highlight the most frequent subgroups, the gain factor , as inversely proportional to  X  If we want to highlight anomalies, the variation measure is a better choice since, in contrast to the 4.1.2. Characterizing subgroups using frequent itemsets
If we are interested, not only in the subgroups themselves, but also in discovering itemsets that make them distinct in our database, we should use an interestingness measure that takes into account the frequency of the rule antecedent, e.g., the impact measure.

In our example, the impact of the A  X  X  rule in G is larger than the impact of the B  X  rule because the support of A is larger than the support of B.

This measure has the advantage that it can be easily interpreted: the number of individuals in G that are directly affected by the A  X  C rule, i.e., those individuals that are not expected to be in GA given the overall support of C in the group.

In our example, the impact of the A  X  X  rule is 1 because, given a 20% support for circles in G and 10 elements in the GA subgroup, we expected 2 circles in GA but found 3 of them.

It should be noted that the impact ratio measure gives us the same relative ordering among rules within the same group than the impact measure, since it takes into account the size of the group G ,whichisthe same for all the rules within the same group. 4.2. Ranking groups within the database
Apart from ordering rules within a group, we can establish an order relationship among the groups in our database to highlight those groups that host the most interesting rules.

Many different association rules can hold within a given group, but not all of them are equally impor-tant to describe the group. When we intend to rank groups rather than individual rules, we must somehow compute an aggregate value that represents the overall interestingness of the group. We should average of that group. However, as we have explained in Section 4.1, some rules are more interesting than others, hence they should not have the same importance when computing the overall group score.
Impact seems to be a good candidate for estimating the potential interestingness of the group, since it takes into account the number of individuals that are affected by each rule within the group. We can then define the weighted impact for the rules within a group using different interestingness measures. Formally, we define the weighted impact as: and analyzed in Section 4.1, for each A i  X  C i rule in the G group.

Large groups tend to have higher impact values for their rules because their impact depends on the support of their antecedent within the group and it is usually larger in large groups. Therefore, small groups are penalized in the overall group ranking if we use the impact measure to average the interest-ingness of the rules within the group. When we want to take into account the relative size of the groups, we should use the impact ratio measure instead, which gives us a more balanced ranking for groups of disparate size. Thus, we can also define a weighted impact ratio measure to rank groups within the database: 5. Comparing alternative ranking criteria
Once we have proposed different interestingness measures that can be used to rank groups and group association rules, we are interested in comparing the rankings obtained by each measure in order to analyze how similar (or different) they are.

Several measures have been proposed in the literature to compare two permutations  X  1 and  X  2 whose elements are in D . Two well-known measures are [7]:  X  Kendall X  X  tau: For each pair i, j  X  P of distinct members of D ,if i and j are in the same order in
These measures let us compare two complete rankings. However, in many cases, the top K elements in engine, for instance). Fagin [7] proposed an adaptation of the aforementioned measures to compare two top-K lists,  X  1 and  X  2 :  X  Kendall X  X  tau for top-K lists : We have to consider 4 possible scenarios taking into account that not  X  The Spearman X  X  footrule for top-K lists is computed as F l (  X  1 ,  X  2 ) = i  X  D 6. Experimental results
In order to study the performance of the proposed interestingness measures, we have performed a series of experiments using the loan multirelational database. The loan database was used in the PKDD CUP X 09. Figure 5 shows the schema of this database.

The database contains eight relations with 75,982 tuples in total. The analysis of a multirelational contain 4500 tuples. This database was adapted by Yin et al. for their experiments with CrossMine [24] and can be downloaded from: http://research.microsoft.com/en-us/people/xyin/. 6.1. Using trees to mine multirelational databases
A common approach to mine multirelational databases consists in joining all the relations in the database in order to obtain a single relation, usually called universal relation [8,15,16]. Then, classi-cal data mining techniques can be applied to this universal relation. However, join-based techniques such as the aforementioned one present a serious disadvantage: they do not preserve the proper support counts.

We have proposed two alternative representation schemes for multirelational databases. Our repre-sentation schemes are based on trees, so that we can apply existing tree mining techniques to identify frequent patterns in multirelational databases [11].

The main idea behind our two representation schemes is building a tree from each tuple in the target to each tuple in the target relation.

The key-based tree representation scheme is inspired by the concept of identity in the relational model while the object-based one is based on the concept of identity in object-oriented models. Relational databases rely on primary keys to ensure that each table row can be univocally referenced. Any unique is already unique, and no specific key is needed. In an object database, each object is automatically assigned an unique ID. This does mean that you can create objects that have identical field values but are still different objects [17].

In our experiments, we have considered the account relation as our target relation in the loan database and we have built trees by collecting information from the loan , disposition , order , and district relations.

The tree database obtained from the loan multirelational database contains 4500 trees. Trees have an average of 34 nodes using the key-based representation scheme (153,102 nodes in total) and an average of 37 nodes using the object-based one (169,842 nodes in total). 6.2. Extracting group association rules from multirelational databases
We have transformed the loan database into two sets of trees (using both the key-based and object-based tree representation schemes). This way, tree mining algorithms can be used to extract patterns from this kind of databases, as described above. We can also define two different kinds of patterns to be be mined from a multirelational datab ase using our approach, i.e., induced key-based patterns, embedded key-based patterns, induced object-based patterns, and embedded object-based patterns.
We use in [12] a tree pattern mining algorithm called POTMiner to identify these four different kinds of patterns within the loan database. Once we have identified the frequent tree patterns derived from the multirelational database, we have extracted association rules from them, using techniques that are analogous to the ones employed in a more traditional setting. Group association rules can then be derived from the discovered association rules just by clustering rules sharing parts of their antecedents.
Figure 6 shows the number of identified groups within the loan database for the four different kinds of patterns (induced key-based patterns, embedded key-based patterns, induced object-based patterns, and embedded object-based patterns) and two different minimum support thresholds (10% and 5%). As when the minimum support threshold decreases, since the more patterns are identified, the more group association rules can be extracted.

Figure 7 shows the execution time required by our algorithm to obtain all the existing groups in the multirelational database, where time is displayed in seconds on a logarithmic scale. It should be noted that execution time includes the whole process required for identifying group association rules: the time to group the association rules into sets of group association rules. The identification of key-induced object-embedded patterns is the most costly alternative because more patterns are involved. 6.3. Ranking groups
In this section, we compare the group rankings provided by different interestingness measures in order to check how many groups are highlighted as the most interesting ones and analyze potential differences among them.

In these series of experiments, we have used the groups and rules obtained from the loan multire-lational database, using embedded object-based patterns up to size 6 (i.e. maxsize = 6) and a 10% minimum support threshold. Using these parameters, we obtained 2,924 groups and 7,394,860 group association rules.

We have ranked the resulting groups using the weighted impact and the weighted impact ratio mea-sures. In order to weight those measures, we have tested five different interestingness measures: gain, gain factor, impact, impact ratio, and variation. Therefore, we have obtained 10 alternative rankings for the groups in our database. We have also included two additional rankings using the average impact and the average impact ratio measures, just to check that weighted measures give us different results than just aggregating rule impacts without taking that information into account).

Figures 8 a) and b) show the values of the weighted impact and the weighted impact ratio measures, respectively, for every group within the loan multirelational database (sorting the groups according to their weighted evaluation measure).
 As it can be seen in Fig. 8 a), the weighted impact measures highlight about 130 groups in the database. It should be noted that the weighted impact provides similar results for every different interestingness measure, i.e. the rankings provided by the different interestingness measures, used as weights in the weighted impact formula, are quite similar. The average values are lower, as expected, since less in-teresting rules contribute less to diminish the overall group score when using the weighted measure. The similarities among the particular rankings provided by different interestingness measures will be discussed later.

Figure 8 b) shows that the weighted impact ratio measures highlight about 400 of the groups in the database, more than the weighted impact measures. The weighted impact tends to highlight only large groups, since the impact of the rules depends on the absolute support of the antecedent in the group association rules and that support is typically larger in large groups. Using the weighted impact ratio, however, the group size does not influence the final group score because impact ratio is a relative mea-sure. Hence the higher number of highlighted groups when using the weighted impact ratio. This way, smaller groups are highlighted when interesting rules affect a significant portion of them.
As happened with the impact measures, the results using different interestingness measures as weights we analyze the particular rankings provided by each alternative evaluation criterion. 6.4. Comparing rankings provided by different interestingness measures
In the previous section, we obtained twelve different rankings of the 2,924 groups within the loan database. In this section, we use the Kendall X  X  and Spearman X  X  measures we described in Section 5 to compare these rankings in order to discover their similarities.

We have compared every pair of rankings using both similarity measures. Figure 9 shows the resulting similarity matrices using Kendall X  X  (top) and the Spearman X  X  (bottom) measures. Black cells indicate that the rankings are almost indistinguishable (their Kendall or Spearman value is almost 0), while white cells correspond to the most dissimilar pairs of rankings within the matrix (i.e., they have the maximum Kendall or Spearman value within all the pairs).

As it can be seen in Fig. 9, we can easily observe two clearly-defined groups of different rankings, which correspond to those obtained using the weighted impact measures (upper left quadrant) and the ones obtained using the weighted impact ratio measures (lower right quadrant). When interpreting the results, it is important to recall that Kendall X  X  measure is an order-based measure while Spearman X  X  measure is a distance-based one.

In Fig. 9, we are comparing the rankings for all the 2,924 groups within our database, hence there are some differences in the comparison between different variants of the same kind, a fact that is clearly measure. Spearman X  X  distance-based measure highlights some differences when using the gain factor as interestingness measure for individual rules within a group, as well as a surprising similarity between the average impact and the average impact ratio rankings.

However, it should be noted that apparent differences do not have the same importance if they happen at the top of the rankings or at their bottom, since end users will not usually delve into the complete list of 2,924 groups. Therefore, a more realistic scenario consists in comparing the top elements in each ranking.

We have compared the top 100 and the top 10 groups in the rankings provided by each ranking criterion in order to obtain a more realistic comparison of ranking results.

The matrices shown in Fig. 10 show the values for Kendall X  X  and Spearman X  X  measures when compar-ing the top 100 groups in each of the rankings. In this case, the matrices we have obtained using both Kendall X  X  order-based and Spearman X  X  distance-based similarity measures are remarkably similar. As happened when comparing the whole rankings, two groups are clearly visible: the ones corresponding to the weighted impact and those resulting from using the weighted impact ratio.

The different variants of weighted impact are almost undistinguishable, while some differences exist among the different rankings provided by the weighted impact ratio. Within the latter, using the impact (IR-I) and the impact ratio (IR-IR) as weights provide very similar results. Likewise, gain (IR-Gain) and variation (IR-V) are also similar. However, there are differences between gain factor (IR-GF) and the 100 most interesting groups, which typically contain many rules with positive gain values (it should be recalled that both impact and impact ratio are proportional to gain values).

Finally, we have compared the top 10 groups in the rankings as shown in Fig. 11. For our particular database, we can again identify two clusters around weighted impact and weighted impact ratio mea-sures. There are still some differences between the weighted measures and their plain averages, as well as between the variation variant of the weighted impact (I-V) and the rest of its variants (I-Gain, I-GF, factor) than they are to the impact-related measures (I-I and I-IR). 7. Identifying the most interesting groups
In the previous section we have obtained 4 different sets of rankings for the groups in our experiments: 1. The one obtained from the average impact of the rules in each group. 2. The one obtained from the average ratio of the rules in each group. 3. The one obtained using the weighted impact measure (using any interestingness measure as 4. The one obtained using the weighted impact ratio measure (using any interestingness measure as When using the average impact of the rules wi thin each group (I-A vg), large groups are favored. Almost all the groups in the top 10 have a 100% support and most of them are trivial and not really interesting. The average impact ratio (IR-Avg) is not so biased towards large groups.
Using the weighted impact measure (I-Gain, I-GF, I-I, I-IR, and I-V) provides a more balanced rank-ing. Albeit the support of the groups in their top 10 is still high (around 75%), end users can find some interesting groups, such as  X  X ccounts that have a monthly frequency of issuance of statements and an owner-type disposition X .

The weighted impact ratio measure (IR-Gain, IR-GF, IR-I, IR-IR, IR-V) provides more interesting are highlighted, such as those  X  X ccounts that have a monthly frequency of issuance of statements, and a house-type permanent order, and are located in a district with one municipality with more than 10000 inhabitants X .
In summary, weighted impact is biased towards large groups and it should be used when looking for individuals (i.e. those who are not so common in the database but exhibit consistently different peculiar behaviors). 8. Conclusions
Databases naturally contain groups of individuals that share some of their features and some aspects of their behavior. In this paper, we have proposed group association rules, which are association rules that can be discovered within groups of individuals.

We have adapted some of the standard interestingness measures for association rules to group associ-ation rules. We have also proposed new interestingness measures to evaluate group association rules and we have studied some of the formal properties of such measures.

Finally, we have proposed an approach to rank groups within a database (and also rules within each group). Alternative rankings can be provided by employing alternative, and often complementary, inter-estingness measures. Depending on their particular goals, users should choose which measure to employ groups, then he should choose a weight impact measure. On the other hand, if he is more interested in discovering small groups of individuals with common peculiar behavior, then the weighted impact ratio is the appropriate measure.

Our experiments on a real-world database corroborated our intuitions on the behavior of different order data mining problem that users must face when dealing with the huge amount of association rules that can be derived from real-world databases (more than seven million in our case study). Acknowledgements Work partially supported by the TIN2009-08296 and TIN2012-36951 research projects funded by the Spanish Ministry of Science and Innovation.
 We are grateful to the anonymous referees for their valuable comments and suggestions. References
