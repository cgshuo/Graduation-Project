 Noise is a high dimensional dynamical process which limits the extraction of quantitative information from experimental time series data. Successful removal of noise from time series data requires a model either for the noise or for the dynamics of the uncorrupted time series. For example, in wavelet based denois-ing methods for time series [ 14 , 20 ], the model for the signal assumes that the expected output of a forward/inverse wavelet transform of the uncorrupted time series is sparse in the wavelet coefficients. In other words, it is presupposed that the signal energy is concentrated on a small number of wavelet basis elements; the remaining elements with negligible coefficients are considered noise. Hard-threshold wavelet [ 25 ] and Soft-threshold wavelet [ 4 ] are two widely known noise reduction methods that subscribe to this model. Principal Component Analysis, on the other hand, assumes a model for the noise: the variance captured by the least important principal components. Therefore, denoising is accomplished by dropping the bottom principal components and projecting the data onto the remaining components.
 In many cases, the time series is produced by a low-dimensional dynam-ical system. In such cases, the contamination of noise in the time series can disable measurements of the underlying embedding dimension [ 12 ], introduce extra Lyapunov Exponents [ 2 ], obscure the fractal structure [ 9 ] and limit predic-tion accuracy [ 5 ]. Therefore, reduction of noise while maintaining the underlying dynamics generated from the time series is of paramount importance. A widely used method in time series denoising is Low-pass filtering. Here noise is assumed to constitute all high frequency components without reference to the characteristics of the underlying dynamics. Unfortunately, low pass filtering is not well suited to non-linear chaotic time series [ 23 ]. Since the power spectrum of low-dimensional chaos resembles a noisy time series, removal of the higher frequencies distorts the underlying dynamics, thereby, adding fractal dimensions [ 15 ]. In this article, we present a phase space reconstruction based approach to time series denoising. The method is founded on Taken X  X  Embedding Theo-rem [ 21 ], according to which a dynamical system can be reconstructed from a sequence of observations of the output of the system (considered, here, the time series). This respects all properties of the dynamical system that do not change under smooth coordinate transformations.
 Informally stated, the proposed technique can be described as follows: Con-sider a time series, x (1) ,x (2) ,x (3) ..... corrupted by noise. We first reconstruct the phase space by taking time delayed observations from the noisy time series (for example, x ( i ) ,x ( i +1) forms a phase space trajectory in 2-dimensions). The minimum embedding dimension (i.e., number of lags) of the underlying phase space is determined via the False Neighborhood method [ 11 ], as detailed in Sect. 2.1 . Next, we cluster the phase space non-parametrically without imposing any constraints on the number of clusters. Finally, we apply a non-linear regres-sion to approximate the temporally subsequent phase space points for each point in each cluster via a Non-parametric Bayesian approach. Henceforth, we refer to our technique by the acronym NPB-NR, standing for non-parametric Bayesian approach to noise reduction in Time Series.
 To elaborate, the second step clusters the reconstructed phase space of the time series through an Infinite Mixture of Gaussian distribution via Dirichlet Process [ 7 ]. We consider the entire phase space to be generated from a Dirichlet Process mixture (DP) of some underlying density [ 6 ]. DP allows the phase space to choose as many clusters as fits its dynamics. The clusters pick out small neighbor-hoods of the phase space where the subsequent non-linear approximation would be performed. As the latent underlying density of the phase space is unknown, modeling this with an Infinite mixture model allows NPB-NR to correctly find the phase space density. This is because of the guarantee of posterior consistency of the Dirichlet Process Mixtures under Gaussian base density [ 18 ]. Therefore, we choose the mixing density to be Gaussian. The posterior consistency acts as a fre-quentist justification of Bayesian methods X  X s more data arrives, the posterior density concentrates on the true underlying density of the data.
 each cluster formed above. We use a DP mixture of Linear Regression to non-linearly map each point in a cluster to its image (the temporally subsequent point in the phase space). In this Infinite Mixtures of Regression, we model the data in a specific cluster via a mixtures of local densities (Normal density with Linear Transformation of the covariates (  X X ) as the Mean). Although the mean function is linear for each local density, marginalizing over the local distribution creates a non-linear mean function. In addition, the variance of the responses vary among mixture components in the clusters, thereby varying among covari-ates. The non-parametric model ensures that the data determines the number of mixture components in specific clusters and the nature of the local regres-sions. Again, the basis for the infinite mixture model of linear regression is the guarantee of posterior consistency [ 22 ].
 deviation between each point in the cluster and its pre-image (previous temporal point) and post-image (next temporal point) yielded by the non-linear regression described above. To create a noise removed time series out of the phase space, readjustment of the trajectory is done by maintaining the co-ordinates of the phase space points to be consistent with time delay embedding.
 mental settings such as, noise reduction percentage and power spectrum analy-sis on several dynamical systems like Lorenz, Van-der-poll, Buckling Column, GOPY, Rayleigh and Sinusoid attractors, as compared to low pass filtering. We also show the forecasting performance of the NPB-NR method in time series datasets from various domain like the  X  X OW 30 X  index stocks, LASER dataset, Computer Generated Series, Astrophysical dataset, Currency Exchange dataset, US Industrial Production Indices dataset, Darwin Sea Level Pressure dataset and Oxygen Isotope dataset against some of its competitors like GARCH, AR, ARMA, ARIMA, PCA, Kernel PCA and Gaussian Process Regression. 2.1 Time Delay Embedding and False Neighborhood Method Time Delay Embedding has become a common approach to reconstruct the phase space from an experimental time series. The central idea is that the dynamics is considered to be governed by a solution traveling through a phase space and a smooth function maps points in the phase space to the measurement with some error. Given a time series of measurements, x (1) ,x (2) , ...., x ( N ), the phase space is represented by vectors in D-dimensional Euclidean space. rally subsequent point to y ( n ) in the phase space is y ( n + 1). The purpose of the embedding is to unfold the phase space to a multivariate space, which is repre-sentative of the original dynamics. [ 21 ] has shown that under suitable conditions, if the dynamical system has dimension d A and if the embedding dimension is chosen as D&gt; 2 d A , then all the self-crossings in the trajectory due to the pro-jection can be eliminated. The False Neighborhood method [ 11 ] accomplishes this task, where it views the dynamics as a compact object in the phase space. If the embedding dimension is too low (the system is not correctly unfolded), many points that lie very close to each other (i.e., neighbors) are far apart in the higher dimensional correctly unfolded space. Identification of these false neigh-bors allows the technique to determine that the dynamical system has not been correctly unfolded.
 For, the time series, x ( n ), in d th and ( d +1) th dimensional embedding, the Euclidean distance between an arbitrary point, y ( n ) and its closest neighbor y ( n )is, R 2 d ( n )= d  X  1 k =0 [ x ( n + kT )  X  x ( n + kT )] kT )  X  x ( n + kT )] 2 respectively. If the ratio of these two distances exceeds a threshold R tol (we took this as 15 in this paper), the points are considered to be false neighbors in the d th dimension. The method starts from d = 1 and increases it to D , until only 1  X  2% of the total points appear as false neighbors. Then, we deem the phase space to be completely unfolded in R D ,a Euclidean Space. 2.2 Dirichlet Process and Its Stick-Breaking Representation A Dirichlet Process [ 7 ], D (  X  0 ,G 0 ) is defined as a probability distribution over a sample space of probability distributions, G  X  DP (  X  0 concentration parameter and G 0 is the base distribution. According to the stick-breaking construction [ 19 ]ofDP, G , which is a sample from DP, is an atomic distribution with countably infinite atoms drawn from G 0 In the DP mixture model [ 6 ], DP is used as a non-parametric prior over parameters of an Infinite Mixture model. Here, F is a distribution parametrized by  X  z by Eq. 3 . 3.1 Step One: Clustering of Phase Space Given a time series { x (1) ,x (2) , ..x ( N ) } , let the minimum embedding dimension be D (using the False Neighborhood). Hence, the reconstructed phase space is, model of the points in the phase space is now assumed as, is the set of latent variables. The distribution, {  X  i,d the DP. { M 1 ,M 2 ,M 3 .... } denotes the Categorical Distribution parameters deter-mined by Eq. 3 . In this DP mixture, the sequence, { M 1 ,M infinite vector of mixing proportions and {  X  z ing the mixture components. This Infinite Mixtures of Gaussians picks clusters for each phase space point and lets the phase space data determine the number of clus-ters. From this perspective, we can interpret the DP mixture as a flexible mixture model in which the number of components (i.e., the number of cells in the partition) is random and grows as new data is observed. 3.2 Step Two: Non-linear Mapping of Phase Space Points Due to the discretization of the original continuous phase space, our assumption is that a point in the phase space is constructed by a nonlinear map R whose form we wish to approximate. In this section, we approximate this non-linear map of the subsequent phase space points via the proposed non-linear regression. We assume that a specific cluster has N points. We reorder these points according to their occurrence in the time series. We then pick the corresponding image of these points (which are the temporally subsequent phase space points according to the original time delay embedding). We map each phase space points in the cluster through an Infinite Mixtures of Linear Regression to their respective images. The model is formally defined as: ing set of equations. Here, X d ( n )and Y 1 ( n ) represent the d the n th phase space point and the first co-ordinate of its post image respec-{ M 1 ,M 2 ,M 3 , ... } is defined by Eq. 3 . Although these set of equations are for R 1 , the same model applies for R 2: D , representing Y 2: D covariate be associated with the model via a non-linear function, resulting from marginalizing over the other mixtures with respect to a specific mixture. Also, now the variance is different across different mixtures, thereby capturing Het-eroscedasticity. 3.3 Step Three: Restructuring of the Dynamics The idea here is to perturb the trajectory to make the modified phase space more consistent with the dynamics, which is equivalent to reducing the error by perturb-ing the phase space points from its original position and also the error between the perturbed position and the mapped position. We have to choose a new sequence of phase space points, x ( n ), such that following objective is minimized. R is the non-linear Regressors ( R 1: D ) that are used to temporally approx-imate the phase space (Described in the section above). N is the number of points in the specific cluster. This is done across all the clusters. In addition, to create the new noise removed time series, perturbations of x consistently for all subsequent points, such that we can revert back from the phase space to a time series. For example, if the time delay is 1 and the embed-ding dimension is 2, then, the phase space points are perturbed in such a way the first co-ordinate of x ( n +1)tobe t ( n + 1). These form a set of equality constraints. What results is a convex program, that is then solved to retrieve the denoised time series.
 The entire algorithm is summarized in Table 1 .
 4.1 An Illustrative Description of the NPB-NR Process First, we present an illustrative pictorial description of the complete NPB-NR process with a real world historical stock price dataset. Our model for the his-torical time series of the stock price is a low-dimensional dynamical system that was contaminated by noise and passed through a measurement function at the output. Our task was to denoise the stock price to not only recover the under-lying original phase space dynamics and create the subsequent noise removed stock price via the NPB-NR process, but also to utilize it to make better future predictions of the stock price. We picked historical daily close out stock price data of IBM from March-1990 to Sept-2015 for this task. The original noisy time series is plotted in Fig. 2 . The various stages of NPB-NR are illustrated in the subsequent figures. The underlying dimension of the phase space turned out to be 3 from the False Neighborhood Method. The Reconstructed Phase Space with noise is shown in Fig. 3 . The completely clustered phase space and one specific cluster in the phase space by Dirichlet Process Mixture of Gaussian of NPB-NR (step one) is shown in Fig. 4 . For a 3-dimensional phase space, as is the case with the IBM stock price data, consider X and Y to be two temporally succes-sive points in one cluster. Therefore, the non-linear regression model (Step Two) in NPB-NR is Y (1) = R 1 ( X (1) ,X (2) ,X (3)) ,Y (2) = R Y (3) = R 3 ( X (1) ,X (2) ,X (3)). In Fig. 5 , we plot Y (1) against X (1), X (2) and X (3) (The first regression-R (1)) to depict the non-linearity of the regression model which we have modeled through the Dirichlet Process Mixtures of linear regression (step two). The trajectory adjusted (step three) and consequently the noise removed specific cluster and the complete noise removed phase space are shown in Fig. 6 . Finally, the denoised time series is shown in Fig. 7 . The error information for prediction for IBM stock data is reported in Table 2 . Y(1) with covariate X(1) Y(1) 4.2 Prediction Accuracy NPB-NR was used for time series forecasting. The first dataset was drawn from the stock market. We choose 5 stocks (IBM, JPMorgan, MMM, Home-Depot and Walmart) from March, 2000 to Sept., 2015 with 3239 instances (time points) from  X  X OW30 X . The next four datasets came from the Santa Fe competition compiled in [ 8 ]. The first is a Laser generated dataset which is a univariate time record of a single observed quantity, measured in a physics laboratory experiment. The next is a Currency Exchange Rate Dataset which is a collection of tickwise bids for the exchange rate from Swiss Francs to US Dollars, from August 1990 to April 1991. The next dataset is a synthetic computer generated series governed by a long sequence of known high dimensional dynamics. The fourth dataset is a set of astrophysical measurements of light curve of the variable white dwarf star PG 1159035 in March, 1989. The next set of datasets are the Darwin sea level pressure dataset from 1882 to 1998, Oxygen Isotope ratio dataset of 2.3 million years and US Industrial Production Indices dataset from Federal Reserve release. All of these are taken from [ 24 ]. NPB-NR was compared with the GARCH , AR (  X  ), ARM A ( p, q )and ARIM A ( p, d, q ) models, where  X , p, d, q were taken by cross-validations ranging from 1 to 10 fold. We also compared NPB-NR to PCA and kernel PCA [ 3 ] with sigma set to 1, and Gaussian Process Based Auto-regression with  X  taken by cross-validations ranging from 1 to 5 fold. We also compared results from Hard Threshold Wavelet denoising using the  X  X den X  Matlab function. All competitor algorithms were run with a 50-50 training-testing split. We report the Mean Square Error (MSE, L2) of the forecast for all the competitor algorithms in Table 2 . Individual time series were reconstructed into a phase space with the dimension determined by the False Neighborhood method, was passed through NPB-NR to find the most consistent dynamics by reducing noise, and subsequently fed into a simple auto-regressor with lag order taken as the embedding dimension of the reconstructed time series. In most datasets, NPB-NR not only yielded better forecasts, but also a smaller standard deviation among its competitors among the 10 runs. 4.3 Noise Reduction Experiment We evaluated the NPB-NR technique for noise reduction across several well known dynamical systems, namely, Lorenz attractor (chaotic) [ 13 ], Van-der-poll attractor [ 16 ] and Rossler attractor [ 17 ] (periodic), Buckling Column attrac-tor (non strange non chaotic, fixed point), Rayleigh attractor (non strange non chaotic, limit cycle) [ 1 ] and GOPY attractor (strange non-chaotic) [ 10 ]. Although noise was added to the time series such that the SNR ranged from 15 db to 100 db, it is impossible to calculate numerically or from the Power Spectrum how much noise was actually removed from the noisy time series. Therefore, for both the noise removed and the noisy time series we calculated the fluctuation error:, This measures the distance between the observed and the predicted point in the phase space. Here, measurement of the noise reduction percentage is given by, We tabulated the noise reduction percentages of the NPB-NR, the low pass filter, and also wavelet denoising methods in Table 3 . For the wavelet method, we used the matlab  X  X den X  function in  X  X oft X  and  X  X ard X  threshold mode. The NPB-NR yielded the highest noise reduction percentage for 15 X 100 db SNR. Since the faithful reconstruction of the underlying dynamics intrinsically removes the noise, as the noise increases the noise reduction performance of NPB-NR got significantly better as opposed to the other techniques. 4.4 Power Spectrum Experiments We ran a Power Spectrum experiment for a noise corrupted Van-der-poll attrac-tor (periodic) [ 16 ] as well as a time series created by superimposing 6 Sinusoids and subsequently corrupting it with noise. The noise was additive white Gaussian noise with the SNR (Signal-to-Noise ratio) set at 15 db. Var-der-poll is a simple two dimensional attractor with b =0 . 4; x 0=1; y 0 = 1 and the superimposition of Sinusoids is a simple limit cycle attractor with negative Lyapunov Exponents and no fractal structure. We plot the phase space and the Power Spectrum of the noisy time series generated from these attractors, the noise removed solu-tion with a 6th-order Butterworth low-pass filter (cut-off freq. 30 Hz and 1000 Hz respectively) and the NPB-NR technique. The Power Spectrum and the phase space plot of the Van-der-poll and Sinusoid Attractors is shown in Fig. 1 . Note that NPB-NR successfully made the harmonics/peaks more prominent which was originally obscured by the noise. The filtering method was unable to restore the harmonics, although it removed some of the higher frequency components. We also observe that NPB-NR smoothened out the phase space dynamics better than the low pass filter.
 In this article, we have formulated a Bayesian Non-Parametric Model for noise reduction in time series. The model captures the local non-linear dynamics in the time delay embedded phase space to fit the most appropriate dynamics consistent with the data. We have derived the mean field Variational Inference for the Dirichlet Process Mixture of Linear Regression by maximizing the evidence lower bound to obtain the variational parameters. Finally, we have evaluated the NPB-NR technique on various time series generated from several dynamical systems, stock market data, LASER data, Sea Level Pressure data, etc. The technique yields much better noise reduction percentage, power spectrum analysis, accurate dimension and prediction accuracy. In the experiments, we varied the scale factor from 1 to 5 in increments of .25. This scale factor modulates the number of clusters in the phase space. Developing theoretical insights into how the number of clusters affects the adjustment of the dynamics would be an interesting topic for future research. We also plan to explore which kind of physical systems can be analyzed using Non-parametric Bayesian based noise reduction methods. Finally, considerable effort should be given to analyzing time series generated from higher dimensional systems.

