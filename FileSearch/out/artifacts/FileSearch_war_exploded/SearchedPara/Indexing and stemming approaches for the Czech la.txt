 Ljiljana Dolamic, Jacques Savoy * 1. Introduction
Slavic languages dominate in Eastern and Central Europe (e.g., Serbo-Croatian, Russian, Polish, Bulgarian or Czech), and their distinct linguistics features (e.g., the use the various grammatical cases marked by suffixes) must be taken into account in an efficient IR system ( Manning, Raghavan, &amp; Sch X tze, 2008 ). However, the IR community has only a very small number of test-collections available for this family of languages. As an exception, we could mention the Bulgarian language for which the last two CLEF evaluation campaigns have produced a test-collection (Peters et al., 2008 ). Unlike the morphology of other Slavic languages however, the grammatical cases are usually not explicitly indicated by a given suffix in the Bulgarian mor-phology (with the exception of the infrequent vocative case). Thus, experiments drawn for this language cannot be applied directly to other Slavic languages.

The CLEF 2007 campaign (Dolamic &amp; Savoy, 2008 ) produces also a shorter test-collection for the Czech language, and the main objective of this paper is to describe the main morphological difficulties when working with this language. We also proposed and evaluated a suitable stemmer for this Slavic language. In IR it is assumed that applying a stemmer will conflate several word variants into the same stem, and thus improve the pertinent matching between query and document surro-gates. For example, when a query contains the word  X  X  X orse, X  it seems reasonable to also retrieve documents containing the related word  X  X  X orses. X  Moreover, stemming procedures will also reduce the size of inverted files.

When designing a stemmer, we may create a  X  X  X ight X  suffix-stripping procedure by removing only the morphological inflections by conflating the singular and plural word forms (e.g.,  X  X  X oor X  and  X  X  X oors X ) or feminine and masculine variants (e.g.,  X  X  X ctress X  and  X  X  X ctor X ) to the same stem. More sophisticated approaches will remove derivational suffixes (e.g.,  X  X  X n-hance X  and  X  X  X nhancement X ) use to generate a new part-of-speech word from a given stem. Even though a different stem-ming procedures have been suggested for various European languages (e.g., Snowball project, CLEF, TREC and NTCIR campaigns ( Harman, 2005; Peters et al., 2008 ), no stemming algorithm with its evaluation is available for the Czech language.

The rest of this paper is organized as follows. Section 2 describes different stemming approaches while Section 3 depicts the main characteristics of our test-collection. Section 4 briefly describes the IR applied during our experiments. Section 5 evaluates the performance of various IR models, in addition to two stemming approaches for the Czech language. The main findings of this paper are presented in the conclusion. 2. Related work
In the IR domain we usually assume that stemming is an effective means of enhancing retrieval efficiency by conflating several different word variants into a common form. Most stemming approaches achieve this through applying morpholog-ical rules for the language involved (e.g., see (Lovins, 1968; Porter, 1980) for the English language). In such cases suffix re-moval is also controlled through the adjunct of quantitative restrictions (e.g.,  X -ing X  would be removed if the resulting stem had more than three letters as in  X  X  X unning X , but not in  X  X  X ing X ) or qualitative restrictions (e.g.,  X -ize X  would be removed if the resulting stem did not end with  X  X  X  as in  X  X  X eize X ). Certain ad hoc spelling correction rules are applied to improve conflation ier pronunciation. However, applying an algorithmic stemmer does not guarantee that we always obtain either the correct stem or an existing word in the corresponding language .

Compared to other languages having more complex morphologies (Sproat, 1992 ), English is considered quite simple and the use of a dictionary to correct stemming procedures could be more helpful for those other languages such as French ( Sa-voy, 1993 ). When a language has an even more complex morphology, deeper analysis could be required (e.g., for Finnish (Korenius, Laurikkala, J X rvelin, &amp; Juhola, 2004 ), where lexical stemmers are clearly more elaborate and not always freely available (e.g., Xelda system at Xerox). They are more labor intensive and their implementation is complex. Moreover their use depends on a large lexicon and a complete grammar for the language involved. These application also requires more pro-cessing time and could thus be problematic, especially when document collections are very large and dynamic (e.g., within a commercial search engine on the Web). Additionally, lexical stemmers must be capable of handling unknown words such as geographical names, products, proper names or acronyms (out-of-vocabulary problems). Lexical stemmers thus cannot be viewed as error-free approaches. Finally, it must be recognized that when inspecting language usage and real corpora, the observed morphological variations are less extreme than those that might be imagined when inspecting the grammar. Kett-unen and Airo (2006) indicate for example that in theory Finnish nouns have around 2000 different forms, yet in actual col-lections the occurrence of most of these forms is rare. As a matter of fact in Finnish, 84 X 88% of the occurrences of inflected nouns are generated by only six out of a possible 14 cases.

While stemming schemes are normally designed to work with general texts, some may also be especially designed for a specific domain (e.g., in medicine) or a given document collection, such as that developed by Xu and Croft (1998) , which used a corpus-based approach. This more closely reflects language usage (including word frequencies and other co-occurrence statistics), instead of a set of morphological rules in which the frequency of each rule (and therefore its underlying impor-tance) is not precisely known.

Few stemming procedures 1 have been suggested for European languages other than English. The proposed stemmers usu-ally pertain to the most popular languages ( Peters et al., 2008; Tomlinson, 2004 ) and some of them, like the Finnish language, seem to require a deeper morphological analysis ( Korenius et al., 2004 ) to achieve good retrieval performance.
Algorithmic stemmer ignores word meanings and tends to make errors, usually due to over-stemming (e.g.,  X  X  X rganiza-tion X  is reduced to  X  X  X rgan X ) or to under-stemming (e.g.,  X  X  X uropean X  and  X  X  X urope X  do not conflate to the same root). Most of the studies so far have been involved in evaluating IR performance for the English language, while studies on the stemmer performance for less popular languages are less frequent. For example, Tomlinson (2004) evaluated the differences between
Porter X  X  stemmer strategy (Porter, 1980 ) and lexical stemmers (based on a dictionary of the corresponding language) for var-ious European languages. For the Finnish and German languages, lexical stemmer tends to produce statistically better re-sults, while for seven other languages performance differences were insignificant.

Based on these facts, the rest of this paper will address the following questions: (1) Does stemming affect IR performance for the Czech language (and to which extent)? (2) For this language, is a light stemming approach more effective than more complex suffix-stripping algorithms? 3. Czech morphology and stemming strategies
When creating stemming procedures for the Czech language we adopted the same strategy as for the other European lan-guages for which we have created stemmers during the past years. We believe that effective stemming should focus mainly on nouns and adjectives (sustaining most of the meaning of a document), thus ignoring numerous verb forms (tending to generate more stemming errors when taken into account).
The Czech language belongs to the Slavic languages and is written, as for example the Polish language with our Latin Latin or the German languages, the Czech and usually other Slavic languages use various grammatical cases marked by suf-fixes (e.g., the noun  X  X  X ity X  in Russian could be written as  X  X  u opo l  X  (nominative),  X  X  u opo l a  X  (genitive) or  X  X  u opo l These linguistic elements indicate that Czech inflections are more complex than the English ones which are mainly limited to the final  X -s X . 2
All nouns in the Czech language belong to the three distinct genders (masculine, feminine, or neutral). Moreover, all nouns are declined both in number (singular, plural) 3 ; and using seven grammatical cases (nominative, genitive, dative, accusative, vocative, locative, and instrumental), with very few exceptions (a handful of indeclinable borrowed words). Each combination gender-case has its own set of characteristic paradigms, including hard-stem types, soft-stem types, and special types. For example, masculine noun  X  X  X uz  X   X  (husband) appears as such in the nominative case singular, but varies in other ple, we can see that the suffix denoting a case could be ambiguous in the sense that the same suffix may appear in other cases ( X  X  X uz  X  e  X  could be the accusative or genitive singular form). Moreover, the stem (e.g.,  X  X  X uz  X   X  in our case) does not change after adding the appropriate suffix (unlike other languages like Finnish ( Korenius et al., 2004 )). Although this phe-nomenon can also occur in the Czech language, it is less frequent that in other languages. Finally, it is important to know the dictionary ).
 As with many languages, the suffixes assigned to adjectives agree with the attached noun in case, gender and number. These language characteristics result in large number of suffixes being added to adjectives compared to other languages like German (having a rather limited set of suffixes (e.g.,  X -en X ,  X -es X )). Our stemmer denoted as  X  X  X ight X  contains 52 rules for remov-ing these grammatical case endings from nouns and adjectives (inflectional suffixes only). A complete description of this stem-mer is given in the Appendix. In the case of part-of-speech other than nouns and adjectives sharing the same set of suffixes (this incorrect stem. However defining the POS of each surface word is the first step of a lexical stemmer. Their use depends also on a large lexicon and a complete grammar for the language involved. These application also requires more processing time and could thus be problematic, especially when document collections are very large and dynamic (e.g., within a commercial search engine on the Web). Additionally, lexical stemmers must be capable of handling unknown words such as geographical names, products, prop-er names or acronyms (out-of-vocabulary problems). On the other hand, light algorithmic stemmers have shown to be effective for different European languages (Savoy, 2006 ).

Derivational Czech morphology is accomplished by means of prefixation and suffixation of a stem, a usual construction with the Indo-European languages. Usually, the part-of-speech of the stem changes after adding a suffix (e.g.,  X -ial X  in  X  X  X om-merce X  and  X  X  X ommercial  X ). In our work we addressed only suffixes because adding a prefix usually changes more the original added before case endings. We designed and implemented a more aggressive stemmer denoted  X  X  X ggressive X  in this paper which, besides removing inflectional suffixes, removes certain frequent derivational suffixes as for example (e.g.,  X  X  X lav X r X  (piano) ?  X  X  X lav X rista  X  (pianist)). Both suggested stemmers address other morphological characteristics of the Czech language as fleeting  X  X  X  (e.g.  X  X  X  X me k X  (lock, nominative sing.) ?  X  X  X  X mku X  (genitive, dative, vocative, and locative sing.)) or consonant English language, are usually integrated to smooth the pronunciation.

Finally, to define pertinent matches between search keywords and documents, we removed very frequently occurring terms having no important significance (e.g., the, in, but, some). For the Czech language, the suggested stopword list contains 467 forms (determinants, prepositions, conjunctions, pronouns, and some very frequent verb forms). In the process generating this stopword list we have followed the guidelines suggested by Fox (1990) . Both stemmers and the suggested stopword list for the Czech language are freely available at http://www.unine.ch/info/clef/ .
 4. Test-collections
The evaluations reported in this paper were based on the Czech collection built during the CLEF 2007 evaluation cam-paign. This corpus consists of newspaper articles extracted from the Mlad X  fronta Dnes (year 2002) and Lidov X  Noviny (year 2002) newspapers. A typical document begins with a short title (tag &lt;title&gt;), usually followed by the first paragraph under around 212.6 while the whole corpus contains 81,735 articles.

The topics available covered various subjects (e.g.,  X  X  X ATO Summit Security, X   X  X  X uman cloning, X   X  X  X IP Divorces X ) including both regional ( X  X  X ostelic Olympic Medals X ) and more international coverage ( X  X  X auses of Air Pollution X ). Topics #411 ( X  X  X est
Picture Oscar X ) or #413 ( X  X  X educing Diabetes Risk X ) owns the smallest number of pertinent articles (2) while Topic #415 ( X  X  X rug Abuse X ) has the greatest number of correct answers (47).

Based on the TREC model, each topic was structured into three logical sections comprising a brief title (examples given upper), a one-sentence description, and a narrative part specifying the relevance assessment criteria. In our experiments, we used only the title part of the topic formulation in order to reflect more closely queries sent to commercial search engines. Using only the title section, queries had a mean size of 2.98 search terms.

Finally, since the title part of the request  X  X  X osmetic procedures X  was corrupted in the original topic formulation (replaced by the narrative part of the previous topic) we changed this topic title part into  X  X  X osmeticky  X  procedury X  (the Czech trans-lation of the corresponding English version). 5. IR models
To evaluate our proposed two stemming approaches with respect to various IR models, first we used the classical tf idf model wherein the weight attached to each indexing term was the product of its term occurrence frequency ( tf ij for indexing term t j in document d i ) and the logarithm of its inverse document frequency ( idf j ). To measure similarities between docu-ments and the request, we computed the inner product after normalizing (cosine) the indexing weights (Manning et al., 2008).

To complement this vector-space model, we have implemented probabilistic models, such as the Okapi (or BM25) ap-proach ( Robertson, Walker, &amp; Beaulieu, 2000 ), and one model derived from Divergence from Randomness (DFR) paradigm (Amati &amp; van Rijsbergen, 2002 ) wherein two information measures formulated below are combined: is the probability of encountering a new occurrence of term t j in the document, given tf ij occurrences of this term had already been found.
 To model these two probabilities, we used the I ( n e )C2 model based on the following estimates: where tc j is the number of occurrences of term t j in the collection, df j indicates the number of documents in with the term t occurs, n the number of documents in the corpus, l i the length of document d i , mean dl (=212), the average document length, and c a constant (fixed empirically at 1.5).

Finally, we also used an approach based on a language model (LM) (Hiemstra, 2000 ), known as a non-parametric prob-abilistic model. Various implementations and smoothing methods might also be considered within this language model par-adigm. In this paper we adopted a model proposed by Hiemstra (2002, 2002) as described in Eq. (3) using the Jelinek-Mercer corpus ( P [ t j | C ]).
 term t j , and lc is a constant related to the size of the underlying corpus C . 6. Evaluation
In order to measure retrieval performance, we have adopted the mean average precision (MAP) computed by trec_eval (Buckley &amp; Voorhees, 2005 ) based on maximum of 1000 retrieved items. To statistically determine whether or not a given search strategy is statistically better than another, we have applied the bootstrap methodology ( Savoy, 1997 ), with the null hypothesis H 0 stating that both retrieval schemes produce similar performance. In the experiments presented in this paper statistically significant differences were detected by a two-sided test (significance level a = 5%). Such a null hypothesis would be accepted if two retrieval schemes returned statistically similar means, otherwise it would be rejected. 6.1. IR models evaluation
Given the methodology previously described, Table 2 depicts the MAP using three stemming approaches with four IR models. In the last column we have also included a language-independent indexing approach based on 4-gram ( McNamee and Mayfield (2004) . Under this indexing scheme, words are decomposed by overlapping sequences of four letters (this value of 4 was selected because it produced the best IR performance). For example, the sequence  X  X  X rime minister X  generates the the best performing model (depicted in italic) are marked with  X  X  *  X .

Finally, we have compared the retrieval effectiveness of the IR model with and without the stopword list. The perfor-mance differences were small (in mean, around 1%) and did not give any evidence of significant impact of stopword list re-moval on MAP, for this language at least. Of course, the inverted file was reduced as well as the query processing time. 6.2. Stemming evaluation
Facing a language with more complex inflectional morphology than English, we may infer that applying stemming will improve the MAP. However to which extent (if it really exists) is not, a priori, known. This section will address these ques-tions using different IR models.

If we use retrieval performance without stemming, marked  X  X  X one X  in Table 2 as a baseline, we can see that both stem-ming strategies,  X  X  X ight X  and  X  X  X ggressive X , performed better than the baseline. Applying our statistical testing, we found that all performance differences were always statistically significant when compared to an approach ignoring the stemming stage. If we average the performance over four models given, we find an increase of 42% with the  X  X  X ight X  stemmer and 46% with the more  X  X  X ggressive X  one. These relative improvements are clearly large and more important than with other lan-guages (Tomlinson, 2004 ) (+4% with the English language, +4.1% Dutch, +7% Spanish, +9% French, +15% Italian, +19% German, +29% Swedish, +40% Finnish).

When comparing different stemming strategies we can see that the  X  X  X ggressive X  stemmer performs slightly better, 2.7% in average over four models. The retrieval performance differences were in this case never statistically significant.
Denoted as  X  X 4-gram X  in Table 2 are shown retrieval performances of the given IR models when language independent 4-gram indexing strategy (without applying a stemming procedure). The performance difference between 4-gram indexing strategy and word-based indexing is rather small (e.g., in average 1% over  X  X  X ight X  and 3.5% over  X  X  X ggressive X ) and is never statistically significant.

When analyzing query-by-query the effect of applying a stemmer, and limiting our investigations of the best performing model (DFR-I(n e )C2), we found that after applying our light or more aggressive stemmer, the performance was increased for 41 queries while, for the remaining nine queries, the average precision (AP) decreases. In this case, Topic #418 ( X  X  X  X lent Ece-vit X  X  Statements X ) has the greatest improvement, starting with an AP of 0.25 without stemming to 0.6797 (+172%) with our light stemmer and 0.7526 (+201%) with the more aggressive approach. Explanation for this improvement could be found in the fact that personal names in Czech, as in other Slavic languages are changed through cases. Genitive form of the name found in this query ( X  X  X rohla X en X  B X lenta Ecavita  X ) as well as other forms found in relevant documents, after stemming con-flate to its nominative form enabling a pertinent matching. Also, Topic #441 ( X  X  X pace tourists X ) cannot retrieve any relevant articles without stemming (AP 0.0), retrieves the first relevant document in second place with both stemmers (e.g., AP 0.3568 with light stemmer). None of the terms forming the query ( X  X  X esm X rn X  turist X  X ), exists in relevant documents in the same word form (they occur as  X  X  X esm X rny  X   X ,  X  X  X esm X rnou X ,  X  X  X urista X ). Of course, applying a stemmer may sometimes hurt the AP as shown by Topic #407 ( X  X  X ustralian Prime Minister X ) having an AP of 0.9325 without stemming to 0.5616 ( 39.8%) with our light stemmer and 0.5925 ( 36.5%) with the more aggressive approach. In this case nouns  X  X  X remi X r X  (prime minister) and  X  X  X remi X ra X  (first night, premiere) conflate to the same stem resulting in retrieving large number of non-relevant articles.
Finally it is interesting to know that some topics could be classify as hard because for all indexing strategies and IR models they achieve a MAP smaller than 0.1. In our experiments, we have found seven such topics (#403, #411, #422, #425, #428, #436, #439). Those topics mostly contain either too general terms (e.g., Topic #436  X  X  X IP divorces X ) or certain spelling errors (e.g., in Topic #411  X  X  X est Picture Oscar X , Academy Award X  X  name was spelled with a K ( X  X  X skar X ) in the topic and with a C ( X  X  X scar X ) in relevant documents). 7. Conclusions
In this paper, we present the main aspects of the Czech morphology and we suggested two stemmers for this Slavic lan-guage, one removing only inflectional suffixes (denoted  X  X  X ight X ) and a second algorithm that removes also some frequent derivational suffixes (denoted  X  X  X ggressive X ). Both approaches contain some rules to correct orthographic irregularities. A stopword list containing 467 forms was also suggested. These linguistic tools are freely available on the Internet.
Using the most effective current IR models, we have evaluated our stemming approaches and found that the best per-forming IR model is derived from Divergence from Randomness (DFR) paradigm. This approach performs statistically better than a language model or the classical tf idf while the difference with the Okapi model was not statistically significant. Our various experiments clearly show that a stemming procedure improves retrieval effectiveness when applied to the Czech language (mean improvement of around +45%, larger than those found for other European languages). From a statis-tical point of view, the differences are always significant when comparing to an approach ignoring stemming.
 From comparing different stemming strategies, it seems that the more aggressive stemming approach produces better MAP than does a light stemmer, but the difference between these two stemming schemes is never statistically significant. Acknowledgment This research was supported in part by the Swiss NSF under Grant #200021 X 113273.
 Appendix A. Description of our Czech light stemmer See Fig. A1.
 References
