 The detection of objects which build dense regions with other objects within a fea-ture space is a foundation of several density-based data mining techniques, in particular density-based clustering [8], outlier detection and other density-based mining applica-tions [11,13]. We call an object o , for which exists a sufficiently large population of other objects in D that are similar to o ,a hot item . Intuitively, an item that shares its attributes with a lot of other items could be potentially interesting as its shows a typical occurrence of items in the database. App lication areas where the detection of hot items is potentially important exemplarily include scientific applications, e.g. astrophysics, biomedical, sociological and economic applications.

The applications mentioned above require special methods supporting the efficient search in modern databases that may contai n not-standard data. Modern databases have to cope with uncertain or imprecise data. Example applications are location determina-tion and proximity detection of moving objects, similarity search and pattern matching in sensor databases or personal identification and recognition systems based on video images or scanned image data. Several appr oaches that cope with uncertain objects have been proposed [6,9,14,15]. The proposed methods mainly address efficient solutions for similarity search on uncertain data including probabilistic distance range, k -nearest neighbor and ranking. To the best of our knowledge there does not exist any approach addressing retrieval of hot items in uncertain domains.

A hot item o has the property that the number of other items (objects) which are in the proximity of o ,i.e.aresimilarto o , exceed a given minimal population value. In this paper, we give a more general definition of hot items by relaxing the distance/similarity predicate between the objects.
 Definition 1 (Hot Item). Given a database D with objects and a minimum population threshold min items . Furthermore, we assume a score function d score : D X D  X  R + 0 which is defined on pairs of objects in D and a predicate  X   X  : R + 0  X  X  true , false } , where  X   X   X  X  &lt; X ,  X   X , =  X ,  X   X , &gt;  X  } and  X   X  R + 0 is a given scalar. An object o  X  X  is called hot item , iff there exist at least min items objects o  X  X \{ o } which fulfill the predicate  X   X  , formally
In the case of uncertain objects, an exact score cannot be determined, particularly if the score relates to the object attributes which are assumed to be uncertain. Con-sequently, uncertain objects lead to uncertain scores which in turn lead to uncertain predicate results. Thus, the result of the predicate  X   X  is no longer binary and instead yields a probability value. This probabilistic predicate result can be estimated. Based on this estimation we are able to compute for each object o of an uncertain database a probability value which reflects the likelihood that o is a hot item or not. A formal definition of probabilistic hot item detection is given later in Section 3. The solution for the efficient computation of hot item p robabilities can be found in Section 4. In the context of this paper, hot items can be abstracted to objects that fulfill a given predicate together with a reasonably large set of other items. If we assume the equality predicate, i.e.  X   X  ( d score ):= d score =0 , then a hot item satisfies the frequent item prop-erty. The detection of frequent items or frequent itemsets as a preprocessing step for rule mining is one of the most important problems in data mining. Chui et al. study in [7] the problem of mining frequent itemsets from uncertain data. They assume transactions whose items are associated with existentia l probabilities and intr oduce the U-Apriori algorithm, which is a modified version of the Apriori algorithm. They present a frame-work which probabilistically computes frequent items in an efficient way.

The aspect to identify objects that are similar to a given amount of other objects is the basis of several density-based algorithms for discovering clusters and outliers. There exist approaches for den sity-based clustering of uncertain data, e.g. [10] which are quite related to our approach. However the proposed model used to determine the probabilistic density does not respect the mutual exclusiveness of alternative attribute values. The missing conditional probability in their approach leads to approximative results only which disqualifies this appro ach from the accurate detection of hot items.
A lot of work has been published for managing uncertain data [4,5,14], probabilis-tic similarity queries [9] and quite recently for probabilistic top-k queries [12,15]. The detection of hot items can be efficiently supported by a similarity join query used in a preprocessing step, in particular the distance range self-join. Approaches for an effi-cient join on uncertain data are proposed in [9]. The main advantage of this approach is that sampled positions in space can efficiently be indexed using traditional spatial ac-cess methods thus allowing to reduce the computational complexity of complex query types. Our approach exploits the similarity join approach proposed in [9]. However, the cost of the probabilistic detection of hot items are originally highly CPU-bound which is demonstrated in our experimental evaluation (cf. Section 5). The advantage of an I/O cost efficient approach for the preproce ssing step only becomes noticeable when ap-plying the methods proposed in this paper such that the CPU cost less outbalance the overall query cost. In this section, we formally introduce the problem of probabilistic identification of hot items in uncertain databases. 3.1 Probabilistic Score The identification whether an object is a hot item or not requires to know the neighbor-hood of the object according to a given (simila rity) distance score function. Assuming that the object attributes the score function rel ates to are uncertain, then the score result is uncertain, too. Therefore, we require a probabilistic score function which is defined as follows: Let P  X   X  : D X D X  [0 , 1] be a probabilistic function defined on a pair of objects that returns the likelihood that a given score w.r.t. both objects fulfills a given predicate  X   X  . For example, if we use the distance d ( o i ,o j ) between two uncertain vector objects o i and o j as score function and we use the predicate  X   X  = d ( o i ,o j )  X   X  ,then P  X  ( o i ,o j ) denotes the probability that o j is within the  X  -range of o i and vice versa. 3.2 Probabilistic Hot Items Based on the definitions given above, we can compute hot items in uncertain data in a probabilistic way. However, we have to solve the problem of dependencies of the uncertain attributes. Though we assume that the attributes of uncertain objects are inde-pendent of each other, we have to respect that the values of an uncertain object attribute are mutually exclusive. For this reason, first we have to define probabilistic hot items based on a conditional probability.
 Definition 2 (Conditional Probabilistic Hot Item). Given a database D with uncer-tain objects and a minimum population threshold min items . Furthermore, we assume apredicate  X   X  : R + 0  X  X  true , false } which is defined on a probabilistic score function, where  X   X   X  X  &lt; X ,  X   X , =  X ,  X   X , &gt;  X  } and  X   X  R + 0 is a given scalar. Under the condi-tion that an uncertain object o  X  X  is equal to a certain vector x  X  R d , the pr obability that o is a hot item can be computed by |
S The above definition gives rise to the following general definition of probabilistic hot items which depends on the used uncertainty model. The probability P( o is a hot item ) of an object o being an (unconditionally) probabilistic hot item can be computed by aggregating the conditional hot item probabilities over all possible instances x of o multiplied with the probability that object o corresponds to x ,i.e. Let D be a database with uncertain objects. Each object o  X  X  is probed w.r.t. the hot item property. This computation can be split into the preprocessing step which finds candidates that match the predicate  X   X  and the query step which detects the hot items . 4.1 Preprocessing Step First, for each object o  X  ( D\{ o } ) we have to compute the probability that o fulfills a given predicate  X   X   X  X  &lt; X ,  X   X , =  X ,  X   X , &gt;  X  } w.r.t. object o , i.e. we have to compute P  X  ( o, o ) . Obviously, only those objects o account in order to com pute the probability P ( o is a hot item ) . Note that, depending on the used predicate  X   X  , usually only a small portion D  X  X  of the database fulfills the predicate  X   X  ( o, o  X  X  ) with a probability greater than zero. A quick search of those objects which have to be taken into account can be efficiently supported by means of an index structure, e.g. the R*-tree. In particular for the predicate  X   X  = X   X   X   X  ,the index supported  X  -range join [2] can be used to speed-up the search as proposed in [3]. Here, approximative representations like the minimal bounding rectangle (mbr) of an uncertain object are very appropriate to be used as index key for a filter step following the multi-step query processing paradigm. A solution for the  X  -range join on uncertain data is proposed in [9] which can be used as a preprocessing step for our proposed algorithm for the detection of hot items. 4.2 Query Step In the following, we introduce our new approach which is able to efficiently compute the probability that an object o  X  X  is a hot item. As mentioned above, our algorithm has quadratic runtime or even needs linear time if min items is assumed to be constant. The key idea of our approach is based on the following property. Given a set of j predicates S = { p 1 ,p 2 ,...,p j } for which the probability P ( p i ) that the predicate p  X  X  is  X  X rue X  is known, respectively. Now, we want to compute the probability P that at least k predicates of S are  X  X rue X .
 Lemma 1. If we assume that predicate p j is  X  X rue X , then P k, S is equal to the proba-bility that at least k  X  1 predicates of S\{ p j } are  X  X rue X . Otherwise, P k, S is equal to the probability t hat at least k predicates of S\{ p j } are  X  X rue X .
 The above lemma leads to the following recursion that allows to compute P k, S by means of the paradigm of dynamic programming: where The above dynamic programming scheme is an adaption of a technique previously used in the context of probabilistic top-k queries [15]. Here, we generalize this technique for arbitrary probabilistic predicates. We apply this method to compute the probability that an uncertain object o  X  X  is a hot item. Given an uncertain object o  X  X  , the value for min items and the set D  X  X  of objects for which the probability that the predicate P  X  ( o ,o ) ( o probability P that object o is a hot item is equal to the probability P min items, D ( o ) that for at least min items objects o  X  X  the predicates  X   X  ( o, o ) are  X  X rue X . With Lemma 1 and the dynamic programming technique described above we can compute
P In this section, we present the results of an experimental evaluation of the proposed methods w.r.t. efficiency. First we specify the used datasets and experimental setup. In the artificial ART dataset, each object is represented by a set of positions sampled from an individual five-dimensional hyper-rectangle R with a given size. The samples are uniformly distributed within the rectangles. The rectangles are arbitrarily distributed within the object space. Each of the 1500 objects of the two real-world datasets SCI1 and SCI2 consists of 10 samples, where each sample corresponds to a set of envi-ronmental sensor measurements of one single day that consist of several dimensions (attributes). The attribute set of SCI1 describes temperature, humidity and CO concen-tration, whereas SCI2 has a larger set of attributes (temperature, humidity, speed and direction of wind as well as concentrations of CO , SO 2 , NO , NO 2 and O 3 ). In this section, we compare two variants of our approach denoted by DPB and PHID . In contrast to PHID , DPB applies dynamic programming on the complete database, i.e. D = D and, thus, does not require the pre-processing step. The performance of PHID and DPB is compared to that of the brute-force solution ( BF ) by simply applying the formulas given in Section 3.2. Furthermore, we compare them to the bisection-based method ( BSB ) which is adapted to the method proposed in [1]. This method is able to significantly speed-up computation compa red to the brute-force method, but is still exponential. Note that in our algorithm, we concentrate on the evaluation of the CPU-cost only. The reason is that the PHID -algorithm is clearly CPU-bound. The only I/O bottleneck is the initial comput ation of the likelihood that o is in the -range of s o ,for each object o  X  DB and each sample s o ,where o  X  DB and o = o . This requires a distance-range-self-join of the database which can be performed by a nested-block-loop join that requires O ( | DB | 2 ) page-faults in the worst case. In contrast, the CPU time for the PHID -algorithm is cubic: Each call of the dynamic programming algorithm requires O ( | DB | 2 ) time and has to be performed once for each sample in the database.
The first experiments relat e to the scalability of the pr oposed approaches. The re-sults depicted in Figure 2 demonstrate how the runtime of the competing techniques is influenced by the database size. Figure 2(a) shows that, though the bisection-based approach has exponential runtime, it outperforms the brute-force approach by several orders of magnitude. However, the dynamic-programming-based approaches scale sig-nificantly better than their competitors which in contrast to DPB and PHID have ex-ponential runtime. Furthermore, the pre-processing step of PHID obviously pays off. The performance can be further improved by an order of magnitude when applying the dynamic-programming technique only on objects o where the probabilistic predicate P  X  ( o, o ) is not zero. The next experiment shows the scalability of PHID for differ-ent  X  -range values. Here, the average time required to compute the hot item probability for an object was measured. The results shown in Figure 2(b) demonstrate that PHID scales well, even for very large databases. Figure 3(a) demonstrates the performance w.r.t. the min items value for different database sizes. Contrary to DPB and PHID ,the BSB method is very affected by the min items value due to the expensive probability computation. The slight increase of the DPB and PHID performances can be explained by the reduced number of hot items with increasing min items value.

Finally, we evaluate the performance based on real-world data (cf. Figure 3(b)). Un-like the exponential algorithms, DPB and PHID are able to perform a full hot item scan of the database in reasonable time, even for a relatively large database size. In this paper, we propose an efficient appro ach for probabilistic queries for hot items, i.e. objects for which at least min items other objects exist which are similar to o .In particular our approach computes for each object o in an uncertain database the prob-ability that o is a hot item. We proposed methods that are able to break down the high computational complexity required to compute for an object o the probability, that o is a hot item. We theoretically and experimentally show that our approach can efficiently solve the problem (in worst-case O ( n 3 ) ) while the competing techniques have expo-nential runtime. Thereby, we achieve a speed-up of several orders of magnitude.
