 Numbers in text documents can be a good source of knowledge. In comparison to the number of reports on the mining of numeric data stored in databases, those focusing on numbers written in text documents have been few. Tables are a standard medium for expressing numeric data in documents. However, the problem associated with numbers written in tables is that some numbers are provided with no units when they are obvious from the contexts. (Imagine a table of ranking in some sports event. Typically, in such tables, the  X  X anks X  of the competitors are provided without any unit word such as  X  X ank X .) We consider the problem of recovering units omitted from numbers in tables. The estimation of such hidden units greatly contribute to the application on tables. For example, the number of cells that match the query about numbers in tables in the form of  X  X umber + unit X  will increase and the search or mining results will be greatly improved.
 The contributions of this study are two-fold. First, we propose a new task of estimating hidden units of numbers, especially focusing on tables. Second, we propose a table topic model , that can naturally model the tables and its surrounding sentences. We tested our model using regularized logistic regressions on the hidden-unit estimation task. To the best of our knowledge, this is the first work that proposes a task of estimating hidden units in tables. However, there are some works considering related problems.
 Although there have been few research efforts in analyzing numbers written in text, some researchers have attempted the task. Yoshida et al. [ 10 ]proposed to find frequent adjacent strings to number range queries. Although this research can be used to estimate units of numbers in free text, numbers in tables show different behaviors, and a different approach is needed. Narisawa et al. [ 5 ]pro-posed collecting numerical expressions to provide some  X  X ommon sense X  about numbers. Takamura and Tsujii [ 8 ] proposed to obtain numerical attributes of physical objects from the numerical expressions found in texts. Although their research is more application-oriented, our unit estimation algorithm improves the coverage of such systems by providing clues for semantics of numbers. For example, [ 3 ] provided a system that can extract knowledge about attributes of objects from a large number of Web tables. Recently, Sarawagi et al. [ 7 ]pro-posed a system that can answer numerical queries on Web tables. Their method assumes that units are explicitly shown in Web tables, and our unit estimation algorithm can be used for preprocessing for such systems. Govindaraju et al. [ 4 ] proposed to merge knowledge extracted from texts and tables using stan-dard NLP toolkits. Wang et al. [ 9 ] proposed a method to classify the sentences around a table into table-related ones or not. To the best of our knowledge, the current paper is the first work that applies topic models to analyze the table semantics, especially to find relations between tables and the sentences around them. Many previous researches have tried to find attribute positions in tables [ 11 ]. However, we can not avoid estimation errors by using such methods as pre-processing. Rather, we decided not to estimate attribute positions, and consider both positions (i.e., the first row and the first column) as features instead. We used the Japanese Wikipedia articles downloaded in 2013 as our corpus. A large portion of the number cells (i.e., the cells that contain numbers) in Wikipedia tables omit units. 2 Randomly-selected 482 documents (all of which contain one or more tables) are used in our experiments. Among them, we ran-domly selected 297 number cells that have no unit and annotated them with appropriate units by hand. We call them hidden units .
 or data , represents each cell, consisting of a list of the number in the cell and setting, the task is to estimate hidden label (unit) given each data . sections) 4 and the context words. Context words are the words in the positions that are likely to be related to the cell, such as the top cell (i.e., the cell in the first row) in the same column used for estimation of hidden units. following ones.
 Same Column and Row: the words and numbers found in the cells related to the current cell. We take all cells in the same column (same as the current cell), and the lef tmost cell (i.e., cell in the first column) in the same row (same as the current cell). 6 Headings: Subtitles in the documents are extracted using Wiki rules and the subtitle nearest to the current table is used as a context. We use (regularized) logistic regression [ 1 ] as a standard algorithm for multi-class classification. In addition to the contexts described in the previous section, we also use topic IDs related to the target cell as features for logistic regression. For topic modeling, we used a variant of Latent Dirichlet Allocation (LDA) [ 2 ]. LDA assumes for each word in documents the following generative processes: 1. Select parameter  X  d according to the Dirichlet distribution:  X  2. For each word, (a) Select topic z according to the multinomial distribution: z (b) Select word w according to the word distribution of topic z : p ( w where d is the id of the current document. Topic z is typically estimated by Gibbs sampling after  X  is integrated out.
 On the other hand, our table topic model is a variant of LDA which assigns one topic to each column of tables based on the assumption that all the cells in the same column in tables belong to the same topic. It is almost always true when we look at the row-wise tables (i.e., tables in which attributes are lined in one row). We observed that most of the tables in our data set were row-wise so the above assumption is valid to some extent for Wikipedia tables. Topics are shared between tables and sentences outside the tables, which enables us to take advantage of the sentences for better estimation of table topics.
 We regard each column of tables as a list of words belonging to the same topic, resulting in one topic for each column. Therefore, we model each column (denoted by the word list C = &lt;c 1 ,c 2 ,  X  X  X  ,c | C | (Multinomial Mixtures) assuming the following generative processes: 1. Select topic z according to the multinomial distribution: z 2. For each word, select word c i according to the word distribution of topic z : p ( c i | z ). we calculate the probabilities when we assign each topic to the column, and sample the topic according to the calculated probabilities. Note that the topic sampling for the words outside of the tables is the same as LDA. 4.1 Models for Numbers We propose a new model for numbers that is different from Naive ones (e.g., replacing them with zeros). Our idea is to use staged models a whole number by using the idea of  X  X ignificant digits X  that are popular in scientific measurements. Here, each number d is converted into a list of digits e (we call them  X  X odes X ) which consists of the position of the most significant digits followed by the most N significant digits. 9 , 10 9,5,3 &gt; because its significant-digit expression is 9 . 53 some first digits of the list corresponds to the abstraction of source number d . Because currently we set N = 2, we use the list &lt; 4,9,5  X 95300 X , ignoring the final digit.
 multinomial distribution, and the multinomial distribution is assumed to be generated from the Dirichlet distribution. 1. Each digit e i is drawn from the distribution H e 1 ...e 2. Each distribution H i is drawn from the Dirichlet distribution Dir ( H ). e ...e i  X  1 . We simply assume the Dirichlet parameter H is a uniform (i.e., the value is the same for all digits.) selves as features. For example, the number  X 95300 X  is converted into the code &lt; 4,9,5 &gt; , resulting in the feature N495. We call this expression  X  X uantization X . This scheme is equivalent to using the  X  X ignificant digit X  expressions directly. We also consider another expression which we call  X  X istory X , which include all the history before reaching to the whole expression, e.g., N4, N49, N495 for the above case for the purpose of comparison with the generative model mentioned above. We conducted the experiments on our hand-annotated corpus described in Sect. 3 . We consider only units that appeared two or more times in the cor-pus (41 unit types in total). This resulted in reducing the size of test set from 297 cells into 270 cells. Logistic regression was performed using Classias [ 6 ]. We used the L1-reguralization with the parameter C =0 . 1, which performed the best in our preliminary experiments. We performed the 5-fold cross validation by dividing each corpus into five subsets. 12 We estimated the topics for every word in the sentences and every column in the tables. We tested several settings for the number of topics, and selected 10 which performed the best in our preliminary experiments. We ran Gibbs sampling 5 times and all the accuracy values were averaged. We compared our model with the baselines that does not use topic IDs ( X  X o topic X ). We used two types of topics: one was estimated using both tables and their surrounding sentences ( X  X opic2 X ) and the other was estimated using tables only ( X  X opic1 X ). We also tested two baseline number expressions:  X  X onum X  which uses no number expressions as features, and  X  X aw X , which uses number expression as is (as mere string).
 Table 1 shows the results. We observed that using the estimated topics improved performance except for the case of the  X  X istory X  expression. It sug-gests that the estimated topics effectively modeled the words outside the tables, which contributed to improving the classification performance for cells inside the tables, as well as clustering effects which assemble the columns with the same topic ID, which increased effective features used to estimate the hidden units. We observed the best performance when we used the  X  X aw X  expressions and topic IDs. We think this is mainly because our Table Topic Model uses coded expressions of numbers, which is the expressions different from the  X  X aw X  expres-sion, thus topic IDs and  X  X aw X  numbers worked as complementary features to each other.
 The result for topic2 was slightly better than topic1, which suggests that modeling the tables and surrounding sentences simultaneously have a good effect on modeling the table topics.
 We proposed a method to estimate  X  X idden units X  of number cells in tables, which uses the new topic model for tables. Experiments showed that table topics contributed to improving accuracies. Future work includes further investigation of modeling the texts around the tables that considers linguistic features such as dependency relations.

