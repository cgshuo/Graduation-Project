 We address the task of (blog) feed distillation: to find blogs that are principally devoted to a given topic. The task may be viewed as an association finding task, between topics and bloggers. Under this view, it resembles the expert finding task, for which a range of models have been proposed. We adopt two language modeling-based approaches to expert finding, and determine their effective-ness as feed distillation strategies. The two models capture the idea that a human will often search for key blogs by spotting highly rel-evant posts (the Posting model) or by taking global aspects of the blog into account (the Blogger model). Results show the Blogger model outperforms the Posting model and delivers state-of-the art performance, out-of-the-box.
 H.3 [ Information Storage and Retrieval ]: H.3.3 Information Search and Retrieval; H.3.4 Systems and Software; H.4 [ Information Sys-tems Applications ]: H.4.m Miscellaneous Algorithms, Measurement, Performance, Experimentation Feed distillation, people-topic associations, language modeling
Information needs in the blogosphere come in many flavors. The task on which we focus is blog distillation , to identify key blogs with a recurring interest in the topic, that provide credible informa-tion about the topic. The blog distillation task is an interesting one, since it addresses a real information need, shared by professional and non-professional searchers of the blogosphere. Given this task, how, then, should we model it? From a modeling point of view, blog distillation bears a strong resemblance to tasks considered in the area of expertise retrieval [2, 13]. In expert finding, systems re-turn a ranked list of names of people that are knowledgeable about a given topic. Most approaches to this task view it as an association finding task, and rank people by the degree to which they are asso-ciated with the topic, as determined by examining the documents in which the two X  X eople and the topic X  X o-occur. Can these expert finding ideas be used to address the blog distillation task?
Below, we report on an experiment in which we apply two state-of-the-art expert finding models, both based on generative language modeling, to the feed distillation task. The first model, called Blog-ger model, explicitly models bloggers and examines the themes they are interested in. The second model, called Posting model, identifies key posts on a given topic and then determines the blog-gers from whose blogs these originate. For expert finding a counter-part of the Posting model has been found to outperform (the expert finding analogue) of the Blogger model. We find that for feed dis-tillation the situation is the other way around: the Blogger model outperforms the Posting model, suggesting that the two tasks (ex-pert finding and feed distillation) are essentially different and best addressed with different approaches.
Responding to the emerging interest in the blogosphere, TREC launched a blog track in 2006 [9]. The initial focus was on finding relevant blog posts , with a special interest in their opinionatedness, resulting in many insights in blog post retrieval (see, e.g., [7, 8, 9]). The task of finding relevant blogs was considered at the 2007 edi-tion of the track [7]. Specifically, the aim of the feed distillation task is to rank blogs (not individual posts) given a topic. TREC 2007 witnessed a broad range of approaches to this new task. Ap-proaches differed in the indexing units they considered: either in-dividual posts [3, 4, 12], or full blogs (i.e., concatenated posts) [3, 12]. The best performing TREC run uses a blog index (and expands queries using Wikipedia) [3]. Several approaches used a combina-tion of post and blog level evidence [11, 12]. Results are mixed with the combination performing worse than a blog run in [11], but better than either blog or post approaches in [12].

As to expert finding, the task has been formulated in terms of people-topic associations, for which two main language modeling based approaches have been proposed [1]. Balog et al. X  X  first model directly models the knowledge of an expert from associated docu-ments (and is analogous with our Blogger model), while their sec-ond model first locates documents on the topic and then finds the associated experts (and corresponds to our Posting model). Most systems that took part in the 2005 and 2006 editions of the Expert Finding task at TREC implemented (variations on) one of these two models; see [2, 13]. Macdonald and Ounis [6] propose a different approach for ranking people based on data fusion techniques, with-out using collection-specific heuristics. And Petkova and Croft [10] propose yet another approach, based on a combination of the two models just described, while explicitly modeling topics.
In modeling feed distillation we consider the Blogger model and the Posting model. Since blogs are much longer than queries, we obtain a more accurate estimate by invoking Bayes X  Theorem and of ranking blogs, we can drop p ( q ) . Our task, then, is to estimate p ( q | blog ) (see Sections 3.1 X 3.2) and p ( blog ) (see Section 3.3).
The Blogger model estimates the probability of a query given a blogger (or blog) by representing the blog as a multinomial proba-bility distribution over the vocabulary terms: Next, we smooth the probability of a term given a blog with the background probabilities: Finally, we estimate p ( t | blog ) as follows: We assume that the post and the blog are conditionally indepen-dent, thus p ( t | post,blog ) = p ( t | post ) , and approximate p ( t | post ) with the standard maximum likelihood estimate; for the conditional probability p ( post | blog ) , see below.
In the Posting model individual posts are queried and then the blogs to which these posts belong are considered: where the probability of a term t given the post is estimated by inferring a post model p ( t |  X  post ) for each post following:
Our Blogger and Posting models both offer the possibility of ex-pressing the prior importance of a blog (i.e., p ( blog ) ) and the im-portance of a post given a blog (i.e., p ( post | blog ) ). In our experi-ments we assume both probabilities to be uniform. In other words, all posts within a blog are equally important, as are all blogs.
We set up experiments to answer our main question: can we successfully apply out-of-the-box expert retrieval models to blog feed distillation? And if so, which of the two models, Blogger or Posting, displays the best performance on this task?
As our test collection we use the TRECBlog06 corpus [5]; we index only the HTML permalinks of the posts and ignore other collection contents like syndicated content and home pages. The TREC 2007 Blog track offers 45 feed distillation topics and assess-ments [7]. We only use the topic field of the topics.

For the smoothing parameter  X  x in Eq. 2 and 5 (with x  X  X  blog , post } ), we set  X  x equal to n ( x ) / (  X  + n ( x )) , where n ( x ) is the length of the blog (i.e., summarizing the length of all posts of the blog) or the post. We set  X  to be the average number of terms in the document:  X  = 17 , 400 for blogs and  X  = 515 for posts.
The results of our experiments are listed in Table 1. We see that the Blogger model significantly 1 outperforms the Posting model on
Significance is tested using a two-tailed paired t-test with  X  = . 01 all metrics. A few comments are in order. First, the results of the Blogger model would be ranked second in TREC 2007 (best run: MAP .3695, second best: MAP .2923). Second, while the Blogger model outperforms the Posting model for the feed distillation task, for the expert finding task, the relative ranking is the other way around [1]. What does that tell us about the difference between the two tasks? For expert finding, for a candidate expert to be ranked highly for a given topic it suffices for him or her to be one of (rel-atively) few people mentioned in the context of the topic; it is not important whether the candidate expert wrote a lot about the topic or whether he or she is also associated with other topics. In con-trast, for feed distillation, it appears we need to identify people that write mainly about the topic at hand. Hence, it makes sense that we explicitly model individual bloggers (as in the Blogger model) and take a close look at the main themes that occupy them individually.
We applied two state-of-the-art expert finding models to the feed distillation task, and arrived at two main findings. First, out-of-the-box expert finding methods can achieve competitive scores on the feed distillation task. Second, there is a qualitative difference between the expert finding and feed distillation tasks, as a result of which an effective strategy for identifying key bloggers is to explicitly model them and the main themes that occupy them.
Balog and De Rijke were supported by the Netherlands Organ-isation for Scientific Research (NWO) under project number 220-80-001. Weerkamp and De Rijke were supported by the E.U. IST programme of the 6th FP for RTD under project MultiMATCH con-tract IST-033104. De Rijke was also supported by NWO under project numbers 017.001.190, 640.001.501, 640.002.501, STE-07-012.
