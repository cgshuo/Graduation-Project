 Finding dense subgraphs is an important graph-mining task with many applications. Given that the direct optimiza-tion of edge density is not meaningful, as even a single edge achieves maximum density, research has focused on opti-mizing alternative density functions. A very popular among such functions is the average degree, whose maximization leads to the well-known densest-subgraph notion. Surpris-ingly enough, however, densest subgraphs are typically large graphs, with small edge density and large diameter.
In this paper, we define a novel density function, which gives subgraphs of much higher quality than densest sub-graphs: the graphs found by our method are compact, dense, and with smaller diameter. We show that the proposed function can be derived from a general framework, which includes other important density functions as subcases and for which we show interesting general theoretical properties. To optimize the proposed function we provide an additive approximation algorithm and a local-search heuristic. Both algorithms are very efficient and scale well to large graphs.
We evaluate our algorithms on real and synthetic datasets, and we also devise several application studies as variants of our original problem. When compared with the method that finds the subgraph of the largest average degree, our algorithms return denser subgraphs with smaller diameter. Finally, we discuss new interesting research directions that our problem leaves open.
 H.2.8 [ Database Management ]: [Database Applications-Data Mining] Algorithms, Experimentation Graph mining, Dense subgraph, Quasi-clique
Extracting dense subgraphs from large graphs is a key primitive in a variety of application domains [26]. In the Web graph, dense subgraphs may correspond to thematic groups or even spam link farms, as observed by Gibson et al. [18]. In biology, finding dense subgraphs can be used for discovering regulatory motifs in genomic DNA [16], and finding correlated genes [25]. In the financial domain, ex-tracting dense subgraphs has been applied to, among others, finding price value motifs [12]. Other applications include graph compression [9], reachability and distance query in-dexing [21], and finding stories and events in micro-blogging streams [3].

Given a graph G = ( V, E ) and a subset of vertices S  X  V , let G [ S ] = ( S, E [ S ]) be the subgraph induced by S , and let e [ S ] be the size of E [ S ]. The edge density of the set S is defined as  X  ( S ) = e [ S ] / | S | 2 . Finding a dense subgraph of G would in principle require to find a set of vertices S  X  V that maximizes  X  ( S ). However, the direct maximization of  X  is not a meaningful problem, as even a single edge achieves maximum density. Therefore, effort has been devoted to de-fine alternative density functions whose maximization allows for extracting subgraphs having large  X  and, at the same time, non-trivial size. Different choices of the density func-tion lead to different variants of the dense-subgraph prob-lem. Some variants can be solved in polynomial time, while others are NP -hard, or even inapproximable. Cliques. A clique is a subset of vertices all connected to each other. The problem of finding whether there exists a clique of a given size in a graph is NP -complete. A max-imum clique of a graph is a clique having maximum size and its size is called the graph X  X  clique number. H  X astad [20] shows that, unless P = NP , there cannot be any polyno-mial time algorithm that approximates the maximum clique within a factor better than O ( n 1  X   X  ), for any  X  &gt; 0. Feige [13] proposes a polynomial-time algorithm that finds a clique of size O (( log n log log n ) 2 w henever the graph has a clique of size O ( n log n b ) for any constant b . Based on this, an algorithm that approximates the maximum clique problem within a is a clique that is not a subset of any other clique. The Bron-Kerbosch algorithm [7] finds all maximal cliques in a graph.
 Densest Subgraph. Let G ( V, E ) be a graph, | V | = n , | E | = m . The average degree of a vertex set S  X  V is de-fined as 2 e [ S ] | S | T he densest-subgraph problem is to find a set S that maximizes the average degree. The densest subgraph can be identified in polynomial time by solving a parametric maximum-flow problem [17, 19]. Charikar [10] shows that the greedy algorithm proposed by Asashiro et al. [6] pro-duces a 1 2 -approximation of the densest subgraph in linear time.

In the classic definition of densest subgraph there is no size restriction of the output. When restrictions on the size | S | are imposed, the problem becomes NP -hard. Specifi-cally, the DkS problem of finding the densest subgraph of k vertices is known to be NP -hard [5]. For general k , Feige et al. [14] provide an approximation guarantee of O ( n  X  where  X  &lt; 1 3 . The greedy algorithm by Asahiro et al. [6] gives instead an approximation factor of O ( n k ) . Better ap-proximation factors for specific values of k are provided by algorithms based on semidefinite programming [15]. From the perspective of (in)approximability, Khot [22] shows that there cannot exist any PTAS for the DkS problem under a reasonable complexity assumption. Arora et al. [4] propose a PTAS for the special case k =  X ( n ) and m =  X ( n 2 ). Fi-nally, two variants of the DkS problem are introduced by Andersen and Chellapilla [2]. The two problems ask for the set S that maximizes the average degree subject to | S | X  k ( DamkS ) and | S |  X  k ( DalkS ), respectively. They provide constant factor approximation algorithms for DalkS and ev-idence that DamkS is hard. The latter was verified by [23]. Quasi-cliques. A set of vertices S is an  X  -quasi-clique if e [ S ]  X   X  | S | 2 , i.e., if the edge density of the induced sub-graph G [ S ] exceeds a threshold parameter  X   X  (0 , 1). Simi-larly to cliques, maximum quasi-cliques and maximal quasi-cliques [8] are quasi-cliques of maximum size and quasi-cliques not contained into any other quasi-clique, respec-tively. Abello et al. [1] propose an algorithm for finding a single maximal  X  -quasi-clique, while Uno [31] introduces an algorithm to enumerate all  X  -quasi-cliques.
Extracting the densest subgraph (i.e., finding the sub-graph that maximizes the average degree) is particularly attractive as it can be solved exactly in polynomial time or approximated within a factor of 2 in linear time. Indeed it is a popular choice in many applications. However, as we will see in detail next, maximizing the average degree tends to favor large subgraphs with not very large edge density  X  . The prototypical dense graph is the clique , but, as dis-cussed above, finding the largest clique is inapproximable. Also, the clique definition is too strict in practice, as not even a single edge can be missed from an otherwise dense subgraph. This observation leads to the definition of quasi-clique, whose underlying intuition is the following: assuming that each edge in a subgraph G [ S ] exists with probability  X  , then the expected number of edges in G [ S ] is  X  | S | 2 the condition of the  X  -quasi-clique expresses the fact that the subgraph G [ S ] has more edges than those expected by this binomial model.

Motivated by this definition, we turn the quasi-clique con-dition into an objective function. In particular, we define the density function f  X  ( S ) = e [ S ]  X   X  | S | 2 , which expresses the edge surplus of a set S over the expected number of edges under the random-graph model. We consider the problem of finding the best  X  -quasi-clique, i.e., a set of vertices S that maximizes the function f  X  ( S ). We refer to the subgraphs Table 1: Difference between densest subgraph and optimal quasi-clique on some popular graphs.  X  = e [ S ] / | S | 2 is the edge density of the extracted sub-graph, D is the diameter, and  X  = t [ S ] / | S | 3 is the triangle density. that maximize f  X  ( S ) as optimal quasi-cliques . To the best of our knowledge, the problem of extracting optimal quasi-cliques from a graph has never been studied before. We show that optimal quasi-cliques are subgraphs of high qual-ity, with edge density  X  much larger than densest subgraphs and with smaller diameter. We also show that our novel den-sity function comes indeed from a more general framework which subsumes other well-known density functions and has appreciable theoretical properties.

Our contributions are summarized as follows.  X  We introduce a general framework for finding dense sub- X  As a special instance of our framework, we introduce  X  We design two efficient algorithms for extracting opti- X  Motivated by real-world scenarios, we define interesting  X  We extensively evaluate our algorithms and problem
Table 1 compares our optimal quasi-cliques with densest subgraphs on some popular graphs. 1 The results in the table clearly show that optimal quasi-cliques have much larger edge density than densest subgraphs , smaller diameters and larger triangle densities. Moreover, densest subgraphs are usually quite large-sized: in the graphs we report in Table 1, the densest subgraphs contain always more than the 30% of the vertices in the input graph. For instance, in the Football graph, the d ensest subgraph corresponds to the whole graph, with edge density &lt; 0 . 1 and diameter 4, while the extracted optimal quasi-clique is a 12-vertex subgraph with edge den-sity 0 . 73 and diameter 2. The Jazz graph contains a perfect clique of 30 vertices: our method finds this clique achieving perfect edge density, diameter, and triangle density scores. By contrast, the densest subgraph contains 100 vertices, and has edge density 0 . 34 and triangle density 0 . 08.
Let G = ( V, E ) be a graph, with | V | = n and | E | = m . For a set of vertices S  X  V , let e [ S ] be the number of edges in the subgraph induced by S . We define the following function.
Definition 1 (Edge-surplus). Let S  X  V be a subset of the vertices of G , and let  X  &gt; 0 be a constant. Given any two strictly-increasing functions g and h , we define edge-surplus f  X  as:
The rationale behind the above definition is due to a coun-terbalancing of two contrasting terms: the first term g ( e [ S ]) favors subgraphs abundant in edges, whereas the second term  X   X h ( | S | ) penalizes large subgraphs. Our framework for finding dense subgraphs is based on the following opti-mization problem.

Problem 1 ( optimal ( g, h,  X  ) -edge-surplus ). Given a graph G = ( V, E ) , a constant  X  , and a pair of strictly-increasing functions g, h , find a subset of vertices S  X  such that f  X  ( S  X  )  X  f  X  ( S ) , for all sets S  X  V . We refer to the set S  X  as the optimal ( g, h,  X  ) -edge-surplus of the graph G .

The edge-surplus definition subsumes numerous popular existing density measures.  X  By setting g ( x ) = h ( x ) = log x ,  X  = 1, the opti- X  By setting g ( x ) = log x, h ( x ) = log x ( x  X  1) 2 ,  X  = 1, the
No general statements on the complexity characterization of the optimal ( g, h,  X  ) -edge-surplus problem can be made, since certain cases are polynomial-time solvable whereas oth-ers are NP -hard. However, the following theorem provides a family of optimal ( g, h,  X  ) -edge-surplus problems that are efficiently solvable.

Theorem 1. If g ( x ) = x and h ( x ) is a concave function, then the optimal ( g, h,  X  ) -edge-surplus problem is in P .
Proof. The optimal ( g, h,  X  ) -edge-surplus problem be-comes max  X 6 = S  X  V e [ S ]  X   X h ( | S | ) where h ( x ) is a concave function. The claim follows directly from the following suc-cession of facts.
 Fact 1 : The function defined by the map S 7 X  e [ S ] is a su-permodular function.
 Fact 2 : The function h ( | S | ) is submodular given that h is concave. Since  X  &gt; 0, the function  X   X h ( | S | ) is supermodu-lar.
 Fact 3 : Combining the above facts with the fact that the s um of two supermodular functions is supermodular, we ob-tain that f  X  ( S ) is a supermodular function.
 Fact 4 : Maximizing supermodular functions is strongly p olynomial-time solvable [28].

Finally, an important property of the edge-surplus ab-s traction is that it allows us to model scenarios in numerous practical situations where one wants to find a dense sub-graph with bounds on its size. For instance, by relaxing the monotonicity property of h , the k -densest subgraph problem can be modeled as an optimal ( g, h,  X  ) -edge-surplus problem by setting g ( x ) = x and By choosing h ( x ) appropriately, one can design algorithms that avoid outputting subgraphs of undesired size.
By setting g ( x ) = x , h ( x ) = x ( x  X  1) 2 , and restricting  X   X  (0 , 1) in Problem 1, we obtain the problem we address in this paper, which we call OQC-Problem .

Problem 2 (OQC-Problem). Given a graph G = ( V, E ) , find a subset of vertices S  X   X  V such that We refer to the set S  X  as the optimal quasi-clique of G . Hardness. Theorem 1 shows a class of problems which are solvable in polynomial time, while leaving open the hard-ness characterization of the problems that do not fall into that class. Our OQC-Problem belongs to the latter class of problems: it is not among the polynomial-time solvable optimal ( g, h,  X  ) -edge-surplus problems stated in Theorem 1, thus any result about its hardness is not immediate. How-ever, in this regard, we note the following.
 For any single edge ( u, v ), f  X  ( { u, v } ) &gt; 0; but, for any set S , where | S | is large enough and e [ S ] =  X  | S | 2 , f Therefore, the OQC-Problem assigns a positive score to sets S which have density strictly greater than  X  . Specifi-cally, let F = { S 1 , . . . , S k } be the family of sets such that f ( S i ) &gt; 0, for all S i  X  F . Notice that if the input graph G is connected, then k  X  1, as f  X  ( { u, v } ) &gt; 0, for any edge ( u, v ). This suggests that e [ S i ] = (  X  +  X  i ) | S i i = 1 , . . . , k . The objective of the OQC-Problem is equiva-lent to maximizing over all sets in F the product  X  i | S conclusion, therefore, the OQC-Problem is closely related to the problem of finding a maximum clique in a graph, thus being suspected to be NP -hard. However, a formal proof of hardness is nontrivial and it constitutes an interesting open problem for future research.
 Parameter selection. A natural question that arises whenever a parameter exists is how to choose an appropri-ate value. We provide here a simple empirical criterion to properly pick the  X  parameter in our f  X  function. Algorithm 1 G reedyOQC Input: Gr aph G ( V, E ) Output: Subset of vertices  X  S  X  V
S n  X  V for i  X  n downto 1 do end for  X 
Let us consider two disjoint sets of vertices S 1 , S 2 in the graph G . Assume that G [ S 1  X  S 2 ] is disconnected, i.e., G [ S and G [ S 2 ] form two separate connected components. Also, without any loss of generality, assume that f  X  ( S 1 )  X  f As our goal is to favor small dense subgraphs, a natural condition to satisfy is f  X  ( S 1  X  S 2 )  X  f  X  ( S 1 )  X  f we require for our objective to prefer the set S 1 (or S 2 than the larger set S 1  X  S 2 . Therefore, we obtain: which, considering that e [ S 2 ]  X  | S 2 | 2 , leads to: Let us now assume for simplicity that | S 1 | = | S 2 | = k ; then suffices choosing  X   X  1 3 t o have the condition satisfied.
Thus, we choose a value for  X  around 1 3 , which is actually the value we adopt in our experiments. Alternatively, one could choose  X  = e [ V ] / | V | 2 to obtain a normalized version of our objective. However, we do not advocate this choice since typically e [ V ] = o ( | V | 2 ). A greedy approximation algorithm. The first efficient algorithm we propose is an adaptation of the greedy algo-rithm by Asashiro et al. [6], which has been shown to provide a 2 -approximation for the densest subgraph problem [10]. The outline of our algorithm, called GreedyOQC , is shown as Algorithm 1. The algorithm iteratively removes the ver-tex with the smallest degree. The output is the subgraph produced over all iterations that maximizes the objective function f  X  . The algorithm can be implemented in O ( n + m ) time: the trick consists in keeping a list of vertices for each possible degree and updating the degree of any vertex v dur-ing the various iterations of the algorithm simply by moving v to the appropriate degree list.

The GreedyOQC algorithm provides an additive approx-imation guarantee for the OQC-Problem , as shown next. Theorem 2. Let  X  S be the set of vertices outputted by the GreedyOQC algorithm and let S  X  be the optimal vertex set. Consider also the specific iteration of the algorithm where a vertex within S  X  is removed for the first time and let S denote the vertex set currently kept in that iteration. It holds that:
Proof. Given a subset of vertices S  X  V and a vertex u  X  S , let d S ( u ) denote the degree of u in G [ S ].
We start the analysis by considering the first vertex be-longing to S  X  removed by the algorithm from the current vertex set. Let v denote such a vertex, and let also S I de-note the set of vertices still present just before the removal of v . By the optimality of S  X  , we obtain: f ( S  X  )  X  f  X  ( S  X  \{ u } ) ,  X  u  X  S  X   X  e [ S  X  ]  X   X  | S  X  d S  X  ( u )  X   X  ( | S  X  | X  1) ,  X  u  X  S  X  .

As the algorithm greedily removes vertices with the small-est degree in each iteration, it is easy to see that d V ( u )  X  d
I ( u )  X  d S  X  ( u )  X   X  ( | S that S  X   X  S I , it holds that: As the final output of the algorithm is the best over all iterations, we finally obtain:
The above result can be interpreted as follows. Assuming in Theorem 2 becomes f  X  (  X  S )  X  f  X  ( S  X  )  X   X  2 |  X  Thus, the error achieved by the GreedyOQC algorithm is guaranteed to be bounded by an additive factor proportional to the size of the optimal quasi-clique outputted. As optimal quasi-cliques are typically small graphs, this results in an approximation guarantee that is very tight in practice. A local-search heuristic. Even though the above GreedyOQC algorithm achieves provable approximation guarantee, it is not guaranteed for that algorithm to be related to any (local) optimal solution, which is a desir-able property that in many practical cases can lead to very good results. To this purpose, we present next a local-search heuristic, called LocalSearchOQC , which performs local operations and outputs a vertex set S that is guaranteed to be locally optimal, i.e., if any single vertex is added to or removed from S , then the objective function decreases. Algorithm 2 L ocalSearchOQC Input: Gr aph G = ( V, E ); maximum number of iterations Output: Subset of vertices  X  S  X  V
S  X  X  v } , where v is chosen uniformly at random b 1  X  TRUE, t  X  1. while b 1 and t  X  T MAX do end while  X 
The outline of L ocalSearchOQC is shown as Algorithm 2. The algorithm initially selects a random vertex and then it keeps adding vertices to the current set S while the ob-jective improves. When no vertices can be added, the al-gorithm tries to find a vertex in S whose removal may im-prove the objective. As soon as such a vertex is encountered, it is removed from S and the algorithm re-starts from the adding phase. The process continues until a local optimum is reached or the number of iterations exceeds T max . The time complexity of LocalSearchOQC is O ( T max m ).
The effectiveness of the LocalSearchOQC algorithm partly depends on the initial seeding set S . To this end, we devise a heuristic to choose an initial seeding set more appro-priately than setting it equal to a randomly selected vertex. t ( v  X  ) is the number of triangles of v  X  and d ( v  X  ) its degree (we approximate the number of triangles in which each vertex participates with the technique described in [24]). Given vertex v  X  , we use as a seed the set { v  X   X  N ( v  X  ) } , where N ( v  X  ) = { u : ( u, v  X  )  X  E } is the neighborhood of v
We present here two variants of our basic problem, that have many practical applications: finding top-k optimal quasi-cliques (Section 4.1) and finding an optimal quasi-clique that contains a given set of query vertices (Section 4.2).
The top-k version of our problem is as follows: given a graph G = ( V, E ) and a constant k , find top-k disjoint opti-mal quasi-cliques . This variant is particularly useful in sce-narios where finding a single dense subgraph is not sufficient, rather a set of k &gt; 1 dense components is required.
From a formal viewpoint, the problem would require to find k subgraphs for which the sum of the various objective function values computed on each subgraph is maximized. Due to its intrinsic hardness, however, here we heuristically tackle the problem in a greedy fashion: we find one dense subgraph at a time, we remove all the vertices of the sub-graph from the graph, and we continue until we find k sub-graphs or until we are left with an empty graph. Note that this iterative approach allows us to automatically fulfill a very common requirement of finding top-k s ubgraphs that are pairwise disjoint.
The constrained optimal quasi-cliques variant consists in finding an optimal quasi-clique that contains a set of pre-specified query vertices . This variant is inspired by the com-munity-search problem [30], which has many applications, such as finding thematic groups, organizing social events, tag suggestion. Next, we formalize the problem, prove that it is NP -hard, and adapt our algorithms for this variant.
Let G = ( V, E ) be a graph, and Q  X  V be a set of query vertices. We want to find a set of vertices S  X  V , so that S contains the query vertices Q and maximizes our objective function f  X  . Formally, we define the following problem.
Problem 3 (Constrained-OQC-Problem). Given a graph G = ( V, E ) and set Q  X  V , find S  X   X  V such that f It is easy to see that, when Q =  X  , the Constrained-OQC-Problem reduces to the OQC-Problem . However, contrarily to the basic OQC-Problem , the Constrained-OQC-Problem can very easily be shown to be NP -hard. The hardness is quite immediate from Theorem 1 in [31] and we omit details due to space constraints.
 Theorem 3. The Constrained-OQC-Problem is NP -hard.
 The GreedyOQC algorithm can be adapted to solve the Constrained-OQC-Problem simply by ignoring the nodes u  X  Q during the execution of the algorithm, so as to never remove vertices of Q .

Similarly, our LocalSearchOQC algorithm can solve the Constrained-OQC-Problem with a couple of simple modifications: the set S is initialized to the set of query ver-tices Q , while, during the iterative phase of the algorithm, we never allow a vertex u  X  Q to leave S .
In this section we present our empirical evaluation, first on publicly-available real-world graphs (Section 5.1), whose main characteristics are shown in Table 2, and then on syn-thetic graphs where the ground truth is known (Section 5.2). of the extracted subgraph S , D is the diameter, and  X  = t [ S ] /
Our main goal is to compare our o ptimal quasi-cliques with densest subgraphs . For extracting optimal quasi-cliques , we involve both our proposed algorithms, i.e., GreedyOQC and LocalSearchOQC , which, following the discussion in Section 3.1, we run with  X  = 1 3 ( for LocalSearchOQC , we also set T max = 50). For finding densest subgraphs , we use the Goldberg X  X  exact algorithm [19] for small graphs, while for graphs whose size does not allow the Goldberg X  X  algo-rithm to terminate in reasonable time we use the Charikar X  X  -approximation algorithm [10].

All algorithms are implemented in java , and all experi-ments are performed on a single machine with Intel Xeon cpu at 2.83GHz and 50GB ram .
Results on real graphs are shown in Table 3. We compare optimal quasi-cliques outputted by the proposed Greedy-OQC and LocalSearchOQC algorithms with densest sub-graphs extracted with the Charikar X  X  algorithm. Particu-larly, we use the Charikar X  X  method to be able to handle the largest graphs. For consistency, Table 3 reports on re-sults achieved by Charikar X  X  method also for the smallest graphs. We recall that the results in Table 1 in the Intro-duction refer instead to the exact Goldberg X  X  method. How-ever, a comparison of the two tables on their common rows shows that the Charikar X  X  algorithm, even though it is ap-proximate, produces almost identical results with the results produced by the Goldberg X  X  algorithm.

Table 3 clearly confirms the preliminary results reported in the Introduction: optimal quasi-cliques have larger edge and triangle densities, and smaller diameter than densest subgraphs . Particularly, the edge density of optimal quasi-cliques is evidently larger on all graphs. For instance, on Football and Youtube , the edge density of optimal quasi-cliques (for both the GreedyOQC and LocalSearchOQC algorithms) is about 9 times larger than the edge den-sity of densest subgraphs , while on Email the difference in-creases up to 20 times ( GreedyOQC ) and 14 times ( Local-SearchOQC ). Still, the triangle density of the optimal quasi-cliques outputted by both GreedyOQC and Local-SearchOQC is one order of magnitude larger than the tri-angle density of densest subgraphs on 11 out of 15 graphs. Figure 1: Edge density and diameter of the top-1 0 subgraphs found by our GreedyOQC and Local-SearchOQC methods, and Charikar X  X  algorithm, on the AS-skitter graph (top) and the Wikipedia 2006/11 graph (bottom).

Comparing our two algorithms to each other, we can see that LocalSearchOQC performs generally better than GreedyOQC . Indeed, the edge density achieved by Local-SearchOQC is higher than that of GreedyOQC on 10 out of 15 graphs, while the diameter of the LocalSearchOQC optimal quasi-cliques is never larger than the diameter of the GreedyOQC optimal quasi-cliques .

Concerning efficiency, all algorithms are linear in the num-ber of edges of the graph. Charikar X  X  and GreedyOQC algorithm are somewhat slower than LocalSearchOQC , but mainly due to bookkeeping. LocalSearchOQC algo-rithm X  X  running times vary from milliseconds for the small graphs (e.g., 0.004s for Dolphins , 0.002s for Celegans N. ), few seconds for the larger graphs (e.g., 7.94s for Web-Google and 3.52s for Youtube ) and less than one minute for the largest graphs (e.g., 59.27s for Wikipedia 2006/11 ). Top-k op timal quasi-cliques . Figure 1 evaluates top-k op-timal quasi-cliques and top-k densest subgraphs on the AS-Skitter and Wikipedia 2006/11 graphs using the iterative method described in Section 4.1. Similar results hold for the other graphs but are omitted due to space constraints.
For each graph we show two scatterplots. The x axis in logarithmic scale reports the size of each of the top-k dense components, while the y axes show the edge density and the diameter, respectively. In all figures, optimal quasi-cliques correspond to blue filled circles ( LocalSearchOQC ) or red diamonds ( GreedyOQC ), while densest subgraphs cor-respond to green circles. It is evident that optimal quasi-cliques are significantly better in terms of both edge density and diameter also in this top-k variant. The edge density is in the range 0 . 4  X  0 . 7 and the diameter is always 2 or 3, except for a 56-vertex clique in Wikipedia 2006/11 with di-ameter 1. On the contrary, the densest subgraphs are large graphs, with diameter ranging typically from 3 to 5, with significantly smaller edge densities: besides few exceptions, the edge density of densest subgraphs is always around 0 . 1 or even less.
Experiments on synthetic graphs deal with the following task: a (small) clique is planted in two different types of ran-dom graphs, and the goal is to check if the dense subgraph algorithms are able to recover those cliques. Two different random-graph models are used as host graphs for the cliques: ( i ) Erd  X os-R  X enyi and ( ii ) random power-law graphs. In the former model, each edge exists with probability p indepen-dently of the other edges. To generate a random power-law graph, we follow the Chung-Lu model [11]: we first generate a degree sequence ( d 1 , . . . , d n ) that follows a power law with a pre-specified slope and we connect each pair of vertices i, j with probability proportional to d i d j .

We evaluate our algorithms by measuring how  X  X lose X  are the returned subgraphs to the planted clique. In particular, we use the measures of precision P and recall R , defined as
P = # { returned vertices from hidden clique }
R = # { returned vertices from hidden clique } Next we discuss the results obtained. For the Erd  X os-R  X enyi model we also provide a theoretical justification of the out-come of the two tested algorithms.
 Erd  X os-R  X enyi graphs. We plant a clique of 30 vertices on Erd  X os-R  X enyi graphs with n = 3 000 and edge probabilities resent very dense, medium-dense, and sparse graphs. We report in Table 4 the results of running our Local-SearchOQC and GreedyOQC algorithms for extracting optimal quasi-cliques , as well as the Goldberg X  X  algorithm for extracting densest subgraphs . We observe that our two al-gorithms, LocalSearchOQC and GreedyOQC , produce identical results, thus we refer to both of them as optimal quasi-cliques algorithms. We see that the algorithms produce two kinds of results: they either find the hidden clique, or they miss it and return the whole graph. In the very dense setting ( p = 0 . 5) all algorithms miss the clique, while in the sparse setting ( p = 0 . 008) all algorithms recover it. How-ever, at the middle-density setting ( p = 0 . 1) only the optimal Table 4: Subgraphs returned by the Goldberg X  X  max-flow algorithm and by our two algorithms ( GreedyOQC , LocalSearchOQC ) on Erd  X os-R  X enyi graphs with 3 000 vertices and three values of p , and with a planted clique of 30 vertices.
 quasi-cliques a lgorithms find the clique, while the Goldberg X  X  algorithm misses it.

To better understand the results shown on Table 4, we provide a theoretical explanation of the behavior of the al-gorithms depending on their objective. Assume that h is the size of the hidden clique, p &gt; log n/n . If np  X  h  X  1 the densest subgraph criterion always returns the whole graph with high probability. In our experiments, this happens with p = 0 . 5 and p = 0 . 1. On the other hand, if np &lt; h  X  1, the densest subgraph corresponds to the hidden clique, and therefore the Goldberg X  X  algorithm cannot miss it.
Now consider our objective function , i.e., the edge-surplus function f  X  . The expected score for the hidden clique is E [ f  X  ( H )] = f  X  ( H ) = (1  X   X  ) h 2 . The expected score for the whole network is E [ f  X  ( V )] = p n 2 +(1  X  p ) h 2 We obtain the following two cases: (A) when p &gt;  X  , we have E [ f  X  ( V )]  X  f  X  ( H ). (B) when p &lt;  X  , we have f E [ f  X  ( V )]. This rough analysis explains our findings. Power-law graphs. We plant a clique of 15 vertices in ran-dom power-law graphs of again 3 000 vertices, with power-law exponent varying from 2.2 to 3.1. We select these values since most real-world networks have power-law exponent in this range [27]. For each exponent tested, we generate five random graphs, and all the figures we report are averages over these five trials.
 Again, we compare our GreedyOQC and Local-SearchOQC algorithms with the Goldberg X  X  algorithm. The LocalSearchOQC algorithm is run seeded with one of the vertices of the clique. The justification of this choice is that one can always re-run the algorithm until it finds such a vertex with high probability. 2
The precision and recall scores of the three competing al-gorithms as a function of the power-law exponent are shown in Figure 2. As the exponent increases the host graph be-comes sparser and both algorithms have no difficulties in finding the hidden clique. However, for exponent values ranging between 2.2 and 2.6 the optimal quasi-cliques are significantly better than the densest subgraphs . Indeed, in terms of precision, the Goldberg X  X  algorithm is outperformed by both our algorithms. In terms of recall, our Local-SearchOQC is better than Goldberg X  X , while our Greedy-OQC performs slightly worse. An explanation for this is that the GreedyOQC algorithm detects other high-density subgraphs, but not exactly the planted clique. As an ex-Figure 2: Precision and recall for our method and G oldberg X  X  algorithm vs. the power-law exponent of the host graph. ample, with power-law exponent 2.3, GreedyOQC finds a subgraph with 23 vertices and edge density 0.87.
 Stability with respect to  X  . We also test the sensitivity of our density measure with respect to the parameter  X  . We use again the planted-clique setting, and we test the ability of our algorithms to recover the clique as we vary the param-eter  X  . We omit detailed plots, due to space constraints, but we report that the behavior of both algorithms is extremely stable with respect to  X  . Essentially, the algorithms again either find the clique or miss it, depending on the graph-generation parameters, as we saw in the previous section, namely, the probability p of the Erd  X os-R  X enyi graphs, or the exponent of the power-law graphs. Moreover, in all cases, the performance of our algorithms, measured by precision and recall as in the last experiment, does not depend on  X  .
In this section we show experiments concerning our con-strained optimal quasi-cliques variant introduced in Section 4.2. To this end, we focus on two applications that can be commonly encountered in real-world scenarios: finding thematic groups and finding highly-correlated genes from a microarray dataset. For the sake of brevity of presentation, we show next results for only one of our algorithms, partic-ularly the LocalSearchOQC algorithm. Motivation. Suppose that a set of scientists Q wants to organize a workshop. How do they invite other scientists to participate in the workshop so that the set of all the participants, including Q , have similar interests? Setup. We use a co-authorship graph extracted from the dblp dataset. The dataset contains publications in all ma-jor computer-science journals. There is an undirected edge between two authors if they have coauthored a journal arti-cle. Taking the largest connected component gives a graph of 226K vertices and 1.4M edges.

We evaluate the results of our algorithm qualitatively, in a sanity check form rather than a strict and quantitative way, which is not even well-defined. We perform the following two queries: Q 1 = { Papadimitriou , Abiteboul } and Q 2 = { Papadimitriou , Blum } .
 Results. Papadimitriou is one of the most prolific computer scientists and has worked on a wide range of areas. With query Q 1 we invoke his interests in database theory given that Abiteboul is an expert in this field. As we can observe from Figure 3, the optimal quasi-clique outputted contains Kersten, Lesk, Maier, Molina, Naughton, Papadimitriou, Pazzani, Pirahesh, Schek, Sellis, Silberschatz, Snodgrass, Figure 3: Authors returned by our L ocal-SearchOQC algorithm when queried with Papadim-itriou and Abiteboul . The set includes well-known database scientists. The induced subgraph has 34 vertices and 457 edges. The edge density is 0.81, the diameter is 3, the triangle density is 0.66.
 Figure 4: Authors returned by our L ocal-SearchOQC algorithm when queried with Papadim-itriou and Blum . The set includes well-known theo-retical computer scientists. The induced subgraph has 13 vertices and 38 edges. The edge density is 0.49, the diameter is 3, the triangle density is 0.14. database scientists. On the other hand, with query Q 2 we invoke Papadimitriou X  X  interests in theory, given that Blum is a Turing-award theoretical computer scientist. As we can see in Figure 4, the returned optimal quasi-clique contains well-known theoretical computer scientists. Motivation. Detecting correlated genes has several appli-cations. For instance, clusters of genes with similar expres-sion levels are typically under similar transcriptional con-trol. Furthermore, genes with similar expression patterns may imply co-regulation or relationship in functional path-ways. Detecting gene correlations has played a key role in discovering unknown types of breast cancer [29]. Here, we wish to illustrate that optimal quasi-cliques provide a useful graph-theoretic framework for gene co-expression network analysis [25], without delving deeply into biological aspects of the results.
 Setup. We use the publicly-available breast-cancer dataset of van de Vijner et al. [32], which consists of measurements across 295 patients of 24 479 probes. Upon running a stan-dard probe-selection algorithm based on Singular Value De-composition (SVD), we obtain a 295  X  1000 matrix. The graph G in input to our LocalSearchOQC algorithm is derived using the well-established approach defined in [25]: each gene corresponds to a vertex in G , while an edge be-tween any pair of genes i, j is drawn if and only if the modu-lus of the Pearson X  X  correlation coefficient |  X  ( i, j ) | exceeds a given threshold  X  (  X  = 0 . 99 in our setting). We perform the following query, along the lines of the previous section:  X  X ind highly-correlated genes with the tumor protein 53 (p53) X . We select p53 as it is known to be central in tumorigenesis. Results. The output of our algorithm is a clique consisting of 14 genes shown in Figure 5. A potential explanation of our finding is the pathway depicted in Figure 6, which shows that the activation of the p53 signaling can be initiated by signals coming from the PI3K/AKT pathway. Both PI3KCA and p53, BRCA1, ARID1A, ARID1B, ZNF217, FGFR1, KRAS, N COR1, PIK3CA, APC, MAP3K13, STK11, AKT1, RB1 Figure 5: Genes returned by our L ocalSearchOQC algorithm when queried with p53 . The induced sub-graph is a clique with 14 vertices.
 Figure 6: A tumorigenesis pathway consistent with o ur findings.
 AKT1 that are detected by our method are key players of this pathway. Furthermore, signals from the JUN kinase pathway can also trigger the p53-cascade; MAP3K13 is a member of this pathway.

One of the results of p53 signaling is apoptosis, a process promoted by RB. The latter can also regulate the stability and the apoptotic function of p53. Finally, our output in-cludes BRCA1, which is known to physically associate with p53 and affect its actions [33].
In this work we introduce a novel density measure to ex-tract high-quality subgraphs. We show that the proposed density function is included into a more general framework for dense-subgraph extraction, which also subsumes other various popular density functions and provides a principled way to derive application-specific algorithms and heuristics. We provide theoretical insights both into the general frame-work and in the proposed function. We design two efficient algorithms to optimize our function: an additive approxima-tion algorithm, as well as a local-search heuristic. We test our algorithms on real graphs, showing that the subgraphs outputted by our methods have larger edge and triangle den-sities, and smaller diameter than the subgraphs extracted by the method that optimizes the popular average-degree measure. We also evaluate our methods in tackling a cou-ple of variants of our original problem, i.e., finding top-k dense subgraphs and finding subgraphs containing a set of pre-specified vertices, as well as on real-world data-mining and bioinformatics applications, such as forming thematic groups and finding highly-correlated genes from a microar-ray dataset.

Our work leaves several open problems, such as the formal hardness characterization of our OQC-Problem , the for-mal analysis of LocalSearchOQC , the design of efficient randomized algorithms, and the derivation of more densi-ties from the general framework with desirable properties for existing applications.
