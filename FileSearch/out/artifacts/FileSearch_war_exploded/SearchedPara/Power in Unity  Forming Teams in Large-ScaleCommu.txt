 The internet has enabled the collaboration of groups at a scale that was unseen before. A key problem for large col-laboration groups is to be able to allocate tasks effectively. An effective task assignment method should consider both how fit teams are for each job as well as how fair the assign-ment is to team members, in terms that no one should be overloaded or unfairly singled out. The assignment has to be done automatically or semi-automatically given that it is difficult and time-consuming to keep track of the skills and the workload of each person. Obviously the method to do this assignment must also be computationally efficient.
In this paper we present a general framework for task-assignment problems. We provide a formal treatment on how to represent teams and tasks. We propose alternative functions for measuring the fitness of a team performing a task and we discuss desirable properties of those functions. Then we focus on one class of task-assignment problems, we characterize the complexity of the problem, and we pro-vide algorithms with provable approximation guarantees, as well as lower bounds. We also present experimental results that show that our methods are useful in practice in several application scenarios.
 F.2.2 [ Analysis of Algorithms and Problem Complex-ity ]: Nonnumerical Algorithms and Problems X  Sequencing and scheduling ;K.4.3[ Computers and Society ]: Organi-zational Impacts X  Computer-supported collaborative work
The research leading to these results has received funding from the EU FP7 Project N. 255403  X  SNAPS, and from the PRIN 2008 research projects COGENT (COmputational and GamE-theoretic aspects of uncoordinated NeTworks) and the Mad Web (Models, Algorithms and Data structures for the Web and other behavioral networks) funded by the Italian Ministry of University and Research.
 Algorithms, Measurement Team formation, Task assignment, Scheduling
While massive collaboration experiments existed before the Internet, in recent years there has been an explosion in the number and the scale of such systems. We have seen the creation of large groups that use electronic communica-tions to coordinate, including large non-governmental bodies and large-scale collaborations such as GNU/Linux and the Wikipedia. On the enterprise, networks of peers with hor-izontal collaboration links are becoming increasingly com-mon. In many cases, there is no central authority micro-managing the work of the community.

People interact online in many ways: they share informa-tion, cooperate, take collective decisions [21], and more. In this paper we aim at providing algorithmic tools for helping people collaborate efficiently. Specifically, we study how to assign tasks in a large groups of peers.
 Example. A company has to deal with a continuous stream of ideas about new products or services. Evaluating a pro-posal requires combining the expertise of several people to create an evaluation team. Each proposal should be prop-erly evaluated, but we must avoid spending too much effort on each one, so evaluation teams should be small. It is also desirable to spread the reviewing effort as evenly as pos-sible, to avoid burdening someone with too many different proposals to evaluate.

This is not an easy problem, not even for a company of medium size. First, if there were no considerations of fair-ness and all the reviewers had the same cost, then those who are knowledgeable about many technical areas should have to work more than others, as they can provide on their own better coverage of the areas of each proposal. Second, if we want to avoid overloading these reviewers, we have to con-sider that in some cases we will need more than one person to replace each one of them, in order to cover many of their skills. Intuitively, there is a trade-off between individual work-load and team size.
 Contributions. In this paper we study algorithms that, given an incoming stream of tasks, allocate them to teams of people fit for the task, in a way that is fair: no-one is overloaded or unfairly singled out. Specifically:
The proposed framework has similarities with the prob-lem of scheduling jobs to machines, as well as with peer-reviewing systems, such as the ones used for allocating pa-pers to reviewers during the review phase of a conference. However, there are key differences. First, team formation entails set-cover, which differentiates our setting from the one studied in scheduling problems. Also, we do not make use of a bidding system and do not model our problem as a matching problem. We elaborate on those differences in the related-work section (Section 6).
 Roadmap : Section 2 defines a general framework. Sec-tion 3 provides a problem definition and characterizes the complexity of a class of these problems. Section 4 studies in detail approximate methods for the binary case in an online setting, which are tested experimentally in Section 5. Sec-tion 6 summarizes prior works related to ours and Section 7 presents our conclusions.
The general problem is to assign tasks J j from a set J to teams Q j , which are subsets of people P , so that teams are fit for their tasks and the assignment is fair to people. In this section we describe in detail the general framework. Tasks. We have a set of tasks (or jobs ) J = { J j ; j = 1 , 2 ,...,k } , which arrive offline or online and need to be assigned to a team of experts. In the offline setting all the tasks are available immediately, while in the online setting the j th task arrives at the j th time step and is assigned to a team of experts before the arrival of the ( j +1)thtask. Skills. Each task requires a set of particular skills to be completed. We define the notion of skill space S ,whichis the space that contains the possible ways that skills combine to form a task, so, each task is a point in the skill space: J S . We consider two settings: binary and continuous .In the binary setting we have m different skills and each job requires a subset of these skills, thus we have S = { 0 , In the continuous setting, we have again m different skills but in this case a job might need each skill up to some extent, so we define S =[0 , 1] m .Weuse J j i to denote the extent of the i th skill required by the j th task, so we have (in both settings) J j =( J j 1 , J j 2 ,..., J j m ).
 People. There is a set of people (or experts ) P = { p j ; 1 , 2 ,...,n } . People possess a set of skills and their profile is represented by a point in the skill space: p j  X  X  . Similarly with the tasks, we use p j i to denote the extent to which the j th person possesses the i th skill. Thus, in both the binary and the continuous settings we have p j =( p j 1 , p j 2 ,...,
We assume that the vector of skills that describe each expert is a priori known. In many cases one has to learn the skills of the experts from data. In this paper we consider the skill-learning phase to be an independent problem, for which either one of the methods listed in Section 6 can be applied, or new methods can be developed.
 Teams. Tocompleteataskweneedtoassignittoa team of experts. We let Q j  X  X  be the team assigned to the j th task. We assume that the skills of each team can be represented by a point in the skill space, so for each team Q j we compute its team profile q j  X  X  .Weuse q j i to denote the extent of the i th skill possessed by the j th group, so we notation q j and Q j interchangeably. Later, in Section 2.3, we describe various ways to compute the team profile. Scoring function. Given a team Q with profile q and atask J we measure the performance of the team for the task using a scoring function s ( q , J ). We assume in general that s (  X  ,  X  )  X  [0 , 1], with 0 indicating complete failure and 1 complete success, but we may consider special cases of interest. For example, writing s (  X  ,  X  )  X  X  0 , 1 } , corresponds to tasks that either fail or succeed. In the next section we consider various options for scoring, but for now it could intuitively be seen as ( i ) a measure of the match between the skills of the team and the requirements of the job, or as ( ii ) the probability of success in executing the job at a satisfactory level.
 Load. Finally, an important quantity is the load L ( p )ofa person p , which is the number of tasks in which she partic-ipates: L ( p )= { j ; p  X  Q j } .

There are two important issues to address at this point: ( i ) how is the group profile obtained from the individual pro-files; and ( ii ) how the scoring function for a task depends on the task profile and that of the team assigned to it. Be-fore we enter into specifics we note that the setting is fairly general and can capture many different situations, which in turn may require qualitatively different modeling choices.
For instance, consider creating a team for a surgery that requires at least a surgeon, an anesthetist and a nurse. In this case, the surgery can not proceed if the team does not include one person having each of these profiles. On the other hand, consider assembling a team of experts to review a proposal for a new service in a company, as in the example of our introduction. In this case, the review can still be effective, even if the reviewing team does not cover each and every one of the relevant technical areas.
We begin by describing some natural properties that we might want a task assignment system to possess, and later we discuss about them.
 Property 1 [Nondecreasing performance]. If Q j  X  Q i , that a team should perform equally or better than a subset of its members.
 Property 2 [Pareto-dominant profiles]. If q j  X  q i component-wise, then for each task J ,wehave s ( q j , J ) s ( q i , J ). In words, a team that is more competent in all skills than another team has better performance at any task. Property 3 [Job monotonicity]. If J j  X  J i component-wise, then for every team Q with profile q we have s ( q , s ( q , J i ). This property states that the same team has a higher performance on a simpler job.
 Property 4 [Nonincreasing marginal utility]. Consider two teams Q j and Q i such that Q j  X  Q i .Foraperson p  X  Q i let  X  q j = F ( Q j  X  X  p } )and  X  q i = F ( Q i  X  X  p function F gives the profile of the team as a function of its members; it is defined and discussed in Section 2.3.) Then, s (  X  q j , J )  X  s ( q j , J )  X  s (  X  q i , J )  X  s ( q i ,
For each of the four properties stated, one can find situ-ations where they would not hold. Properties 1 and 2 are nevertheless quite natural, and are required in every setting that we consider in the rest of this paper. Properties 3 and 4 are somewhat more restricting.

Property 1 (nondecreasing performance) assumes that new members do not introduce conflicts or large coordination costs  X  in spite for instance of Fred Brooks X  observation in The Mythical Man-Month [8] that  X  X dding manpower to a late software project makes it later. X 
Property 2 (Pareto-dominant profiles) ignores how skills are distributed among the members of a team, although to some extent this can be taken into consideration in the cre-ation of the team profile from the profiles of its members.
Property 3 (job monotonicity), while quite natural for many settings, does not allow for the following situation: Consider a team possessing some set of skills X trying to complete a task requiring a disjoint set of skills Y . Then it should naturally fail. However, if assigned to a more de-manding task that requires skills X  X  Y then it might have some partial success. This is related to whether all skills are required to complete a task and illustrates how application-specific details can change significantly the nature of the setting and of the problems.

Property 4 (nonincreasing marginal utility) states that the scoring function satisfies a submodularity property, if seen as a function of the team members. This may be the case whenever team members can, to some extent, replace each other: each additional member adds to the team but the marginal increase of every new person might be smaller as the size of the team increases. Marginal utility does not decrease in settings where each skill is unique to a set of people (e.g., in the surgery example described above), or in settings in which a certain minimum number of people having a skill is required for a task to succeed (e.g., when assembling sports teams). A key advantage of settings where Property 4 is satisfied is that various assignment problems can become more tractable by the application of submodular function optimization techniques.
As we mentioned previously, we assume that the per-formance of a team Q can be modeled by a team profile q  X  X  . In particular, the profile of a team consisting of | Q | people with profiles Q = { p 1 , p 2 ,..., p | Q | } q = F ( { p 1 , p 2 ,..., p | Q | } ) for a suitable function
Some possible choices for the function F include the fol-lowing: Maximum skill. Here the expertise of the team for each skill equals to the expertise of the best team member, for that skill:
F ( Q )=(max j p j i , max j p j 2 ,..., max j p j m )=(max where the maxima are taken over the | Q | team members. This might be appropriate in settings where possessing one expert for each skill is of paramount importance. Additive skills. The expertise of the team is the sum of the skills of each individual. This is appropriate in the case where individuals can complement each other in particular skills, for example, when forming a team of software devel-opers for an application having several modules.
 Multiplicative skills. Here we set One interpretation for this choice is that possessing a skill is akin to having a certain probability of success, and team members do independent attempts to apply their skills. This might be appropriate in the case of assembling a team of safety inspectors: each one has a certain chance of detecting an issue related to her particular skills, and adding more in-spectors decreases the chance of a problem going unnoticed. Binary profiles for tasks and people. Of particular interest is the special case of binary profiles, where S = { 0 , 1 } m ,so p j i  X  X  0 , 1 } and J j i  X  X  0 , 1 } . Binary profiles arise in many cases of practical interest, in which we are interested in a coarse-grained classification of people X  X  skills (e.g., possessing a license or certification to perform a cer-tain process). The binary-profile model is also interesting because in this case all the choices for skill combination pre-sented above are equivalent and they can be described in terms of the binary OR operation:
Having described how individuals combine to form a team, we now address the way the team is scored for its perfor-mance in accomplishing a task. Of course, depending on the setting, there are different natural scoring-function choices andherewedescribesomeofthem. S1: All skills required. s ( q , J )=1if q i  X  J i for all i =1 ,...,m and 0 otherwise.
 S2: Least-skill dominant. min { 1 , min i ; J i &gt; 0 { q S3: Fraction of skills possessed. s ( q , J )= |{ i ; J i S5: Macroaverage of skill. s ( q , J )= i min( q i , J i )
The first two scoring functions are more natural for cases where a specialist is required for each skill demanded by the task and, not surprisingly, they do not satisfy Property 4 (decreasing marginal utility). The second is a smoother ver-sion of the first one. The last three give partial credit for possession of a subset of the skills. In Lemma 1 we show that for any of the rules considered in Section 2.3 they sat-isfy Property 4.

In the case of a binary skill space one can consider the analogues of the aforementioned functions: BS1: All skills required. s ( q , J )=1if q i  X  J i for all i =1 ,...,m and 0 otherwise.
 BS2: Fraction of skills possessed. s ( q , J )= |{ i ; J i .

Note that scoring functions S1 and S2 reduce to the BS1 scoring function, while the S3, S4, and S5 reduce to BS2. We now state a lemma showing the submodularity properties of the scoring functions that give partial credits. The proof will appear in the extended version of this paper.
Lemma 1. Scoring functions S3, S4, S5, and BS2 satisfy the non-increasing-marginal-utility property (Property 4) if the profile of a team is obtained from those of its members according to any of the rules considered in Section 2.3.
Suppose that we want to maximize the score obtained at each task, subject to constraints on team sizes and the maxi-mum load of each person. For the team profiling methods in Section 2.3 and the scoring functions S3, S4, S5, and BS2 in Section 2.4, this problem can be formulated as the problem of maximizing a submodular function. Details of the formu-lation will be given in the extended version of the paper.
Lemma 2. The hill-climbing algorithm [20] for submodu-lar function optimization, adding one by one the person that gives to a team the largest increase in the performance func-tion, provides a 1  X  1 /e approximation for maximizing the sum of the scores, for scoring functions S3, S4, S5, and BS2.
In many scenarios, maximizing the scoring may require covering all the necessary skills for each task. This motivates the problem formulation of the next section, that we follow in the remainder of this paper.
We next focus on a broad class of balanced task assign-ment problems having additive skills in the construction of the team profile (extending the results to the multiplicative skills case is direct). We focus on scoring by requiring all skills , which can be trivially extended to require only a frac-tion of skills , as indeed we do in the experimental section.
We consider the following problem: for every task J j , find ateam Q j that has all the required skills for J j , minimizing the workload of the person with the larger number of tasks, namely, min max j L ( p j ).

Set X ji =1ifperson p j was assigned to task J i , X ji =0 otherwise. The problem can be formulated as an integer linear program as follows:
Constraint (2) ensures that all tasks are executed. Con-straint (3) limits the number of teams in which a single per-son participates. This combinatorial problem is a general-ization of well-known load balancing and covering problems. For single-skill jobs we observe an instance of load balanc-ing with restricted assignment [3,4]. This problem is usually formulated on a bipartite graph with jobs on one side and machines on the other side, and edge ( i, j ) exists if job can be processed on machine j . That is, each job can only be assigned to one of the adjacent machines in the bipartite graph. The goal is to find an assignment of jobs to machines that minimizes maximum load.

Our problem is harder than restricted assignment, as al-ready observed in [17], since forming a team requires to solve a set-cover problem: each feasible team is formed by a set of people with profiles that cover all the skills required from a job. In the following we characterize the complexity of the balanced task covering even for relevant special cases and provide offline and online optimization algorithms.
The restricted assignment problem is an NP-hard problem when the number of tasks is large, while it is polynomial-time solvable for constant number of tasks, k . On the con-trary, our balanced task covering problem remains NP-hard even when k = 2. The proof of the following theorem is omitted due to lack of space and will appear in the extended version of this paper.

Theorem 1. The balanced task covering problem with 2 tasksisNP-hard.

The next question that we ask is if some interesting special cases are poly-time solvable. The answer is positive at least for the following cases:  X  the problem with constant number of people and tasks;  X  the problem with constant number of tasks and skills.
The problem with constant number of people and tasks, n, k = O (1), admits a polynomial-time algorithm. We can enumerate in constant time all feasible and infeasible so-lutions to the problem given that there exists a constant number of teams for each task and there exists only a con-stant number of tasks. Every solution can be checked in polynomial time.

The problem with constant number of tasks and skills, k,m = O (1), also admits a polynomial-time algorithm. At most km = O (1) persons are needed to accomplish the k tasks. It is therefore sufficient to check all possible teams of at most km persons, which is a polynomial number.
A natural direction for solving the balanced task covering problem is to provide heuristics or approximation algorithms both in the offline and in the online case. In the case of the offline setting, we continue with the class of problems from the previous section. In the case of the online setting, we present a full treatment of the binary case. We also notice that our algorithms can also be adapted to continuous profiles and to tasks of nonuniform load. Details will be provided in the extended version of the paper.
We present a simple algorithm to compute a logarithmic approximation for the balanced task covering problem from Section 3.1. Observe that this result is the best possible since the balanced task covering problem contains the set cover problem, which cannot be approximated better than for a logarithmic factor [23]. In the remainder of this subsec-tion, we let N =max { mk, n } . The algorithm is inspired by the well-known randomized rounding algorithm for set cover (see, for example, [23, Chapter 14]), based on solving the LP relaxation of the ILP formulation of set cover, and then in-terpreting the LP solutions as probabilities of including a set in the cover. We are able to prove the following result; details of the algorithm and of the proof for the binary case are given in Appendix A.

Theorem 2. There is a polynomial time, randomized al-gorithm for the balanced task covering problem such that, with probability 1  X   X  : (i) every task is assigned to a team possessing all required skills and (ii) the maximum number of tasks assigned to the same person is at most O log N  X  times the optimum.
The online setting is of special practical interest, as it is more realistic to assume that tasks arrive one by one and have to be assigned immediately to a team, without waiting for more tasks to arrive. We number tasks by order of ar-rival. The algorithm has to decide on a team Q i for task inthesequencebeforetask i + 1 arrives.

For evaluating the performances of the online algorithms we resort to the notion of competitive analysis [7, 15, 22]. Competitive analysis compares an online algorithm against an offline adversary that knows the entire input sequence in advance and serves it optimally. An online algorithm is c competitive if for any input sequence it provides a solution with cost bounded by c times the optimal cost. Observe that the optimal solution may be hard to compute and that even an online algorithm with unbounded computational re-sources may not be able to provide an optimal solution given the lack of information about future tasks.

We propose several heuristics and analyze the competi-tive ratio achieved by these heuristics. All algorithms we present select for a task J i the team Q i that optimizes on a specific cost function c ( Q i ) of the current load of all persons p j  X  Q i when task J i is presented. Denote by L ( p j )the load of person j when task J i is presented, and let  X  be an appropriately chosen value (it depends on the cost of the op-timal solution and in the proof of Theorem 3 we show how to estimate it). We consider four algorithms that, whenever a task arrives, find a team Q that covers all the required skills for the current task, and minimizes: 1. Size : c ( Q )= | Q | 2. MaxLoad : c ( Q )= max j  X  Q L ( p j ) 3. SumLoad : c ( Q )= j  X  Q L ( p j ) Size : This algorithm picks the team of minimum size among those that have all of the required skills. This corresponds tothesolutionofanunweightedsetcoverproblemforwhich we use a standard greedy approximation algorithm that has approximation ratio O (log m i )ifwedenoteby m i the num-ber of skills required by task J i . Although this heuristic tries to minimize the size of the teams, it does not keep track of the work done so far, and can overload the few experts that possess most of the skills. We show indeed the following lower bound on the competitive ratio of Size :
Fact 1. Size has competitive ratio  X ( m ) ,  X ( n ) ,  X ( k
Proof. Consider a sequence of k = m/ 2 tasks. Task J i , i =1 ,...,k , requires skills { 2 i  X  1 , 2 i } .Person p i sesses skill i .Person p m +1 possesses all the skills. MinSize assigns all the jobs to person p m +1 that has load k . The op-timal assignment involves each person in at most 1 team.
This heuristic shows that optimizing only on team size mayleadtopoorresultsandthatingeneralweshouldalso consider individual workload.
 MaxLoad : This algorithm requires to solve an unweighted set cover problem on the skills of J i restricted to persons of current load at most =0 , 1 ,...,  X . We stop at the mini-mum value of for which we obtain a team with members of current load at most that covers all the skills of J i break ties by picking the team of minimum size | Q | among the ones with current load at most . This algorithm rules out the lower bound of Size since it also optimizes on load. But it might fall in the opposite problem of forming teams of very large size when teams of much smaller size and slightly higher load are possible. This is captured by the following lower bound.

Fact 2. MaxLoad is  X ( k ) ,  X ( n ) ,  X ( Proof. Consider a sequence of k =2 n tasks. Tasks J 2 i  X  1 , J 2 i are identical and they can be processed either by person p i alone or by a team formed by all persons with the exception of p i : { p j  X  X  ,j = i } . Observe that each job requires at least n  X  1 skills. Different jobs require different skills. The total number of skills will therefore be at least m = k ( n  X  1). Job J 2 i  X  1 is assigned from MaxLoad to per-son i whose load becomes i .Job J 2 i is therefore assigned to team { j  X  X  ,j = i } that has all members with load i  X  1. The final load of all persons is n = k/ 2 whereas the optimal load is 2 and it is obtained by assigning both jobs J 2 i  X  1 J 2 i to person i .

The lower bounds presented for Size and MaxLoad show that a good algorithm for balanced task covering should jointly optimize on team size and on max load. This is cap-tured by the two heuristics we present next, which achieve this tradeoff by weighting every person by his load when computing a team that covers all the skills of a job. Sum-Load and ExpLoad require to solve a weighted set cover prob-lem rather than an unweighted set cover problem as in Size and MaxLoad . The greedy algorithm for weighted set cover provides an O (log m ) approximate solution, as in the un-weighted case [23].
 SumLoad : This algorithm weights each person by his load in the set cover computation performed to cover all the skills of J . This strategy may appear reasonable. It is however pos-sible to construct instances where all the jobs are assigned to a single person that possesses all the skills rather than to a larger team formed by persons with small load. This is shown in the following lower bound.

Fact 3. SumLoad is  X ( k ) ,  X (
Proof. The first job presented must be processed by the team formed by all people. All persons have load 1. Job i i&gt; 1 can either be processed by person p 1 alone or by a team formed by the i persons in the range [( i  X  1) i/ 2+1 ,i ( The sum of the loads of these persons is larger than the load of p 1 that has all jobs assigned. The optimal solution will instead assign at most 2 jobs to each person. Observe also that the number of persons and the number of activities is quadratic in the number of jobs.

We conclude from this lower bound that a good online algorithm should be more aggressive in weighting persons with high load.
 ExpLoad : This algorithm is more aggressive in penalizing the inclusion of people who are already overloaded, by ap-plying an exponential function to their current load. We study in the following the competitive ratio achieved by this algorithm.

We observe that an  X (log k ) lower bound is unavoidable as this is a generalization of the problem of minimizing the maximum load with restricted assignment [4]. A similar lower bound is proved for any deterministic and random-ized online algorithm. The idea of the lower bound applied to ExpLoad is as follows. Consider a sequence formed by O (log k ) phases. In the first phase n tasks requiring one sin-gle skill owned by all persons are presented. ExpLoad assigns one task per person. In the second phase n/ 2 tasks requiring one single skill owned by n/ 2 persons are presented. In the third phase n/ 4 tasks requiring one single skill owned only by n/ 4 persons are presented. This can be iterated for log phases resulting in a maximum load of  X (log n ). Observe also k = n  X  1and m =log n . On the contrary the optimum can assign all tasks with a maximum load of 2.

A matching upper bound can be proved for ExpLoad .How-ever, the additional difficulty of solving a weighted set cover problem results into an additional O (log m ) overhead in the competitive factor. The proof of the following theorem is given in Appendix B.

Theorem 3. ExpLoad is O (log k log m ) competitive.
In this section we present experimental results on the per-formance of the online algorithms on real-world datasets. Our data sources are IMDB (the Internet Movie Database), Bibsonomy (a social bookmarking site), and Flickr (a photo sharing site). The mapping from them to problem instances Table 2: Mapping of data to problem instances in our setting is summarized in Table 2 and explained in the next section. Summary statistics from these datasets are included Table 3. IMDB . Our first dataset is the Internet Movie Database. We focus on two types of movie personnel, directors and actors . The movie genres play the role of skills. We assume that the set of genres of the movies that a person has partici-pated make the set of skills for that person. For example, Alfred Hitchcock has the skills { comedy , crime , film-noir , mystery , romance , thriller } ,while Laurence Olivier has the skills { biography , drama , history , romance , thriller our algorithms so that directors represent experts and actors represent tasks.

This setting simulates a scenario in which people who have directed a movie create small committees to audition actors. Bibsonomy . Our second dataset is a social bookmark and publication sharing system.The dataset contains a large num-ber of computer-science related publications, where each publication is written by a set of authors . Publications are not only peer-reviewed articles, but also tutorials, presenta-tions, blog posts, and others. The bibsonomy website is used by a large community of users who employ tags to annotate the publications. Tags are pre-processed by applying stan-dard text normalization and frequency filtering operations to remove stopwords. The set of tags associated with the papers of one author is used to represent the set of skills for that author. We partition the set of authors into two sets: one set representing the experts and another set representing the tasks. We consider the experts to be the most prolific authors in the dataset, and this explains why in Table 3 the number of skills per expert is higher than the number of skills per task.

This setting simulates a scenario where committees of sci-entists interview other scientists for a position at a Univer-sity or research institution.

As anecdotal aggregates from the Bibsonomy dataset, we mention that the top-10 tags (skills) for all papers are { mation , social , semantic , ontology , analysis , learning , knowl-edge , management , software , theory } .
 Flickr . We extract multiple datasets from the Flickr photo sharing portal by a kind of snowball sampling. We start with a concept c andusetheflickrAPItoobtainalarge number of photos P ( c )relatedwith c . This is done by: first, obtaining a large set of photos P 0 ( c )thatcontain c as tag; then, collecting all groups G ( c ) that contain a photo in By groups here we refer to flickr groups, which are pools of photographs centered around one theme. Finally, we collect all photos P ( c ) in the groups G ( c ). In this way we are able to collect many relevant photos about a concept c ,evenif is not contained directly in the set of tags of those photos. We have performed experiments for 10 concepts obtaining similar results, here we report the concepts art and nature .
Each photo of the set P ( c ) has been uploaded by a user andisassociatedwithasetof tags . We form a set of experts as the top contributing users for the photos in P ( c ), and the tags of those experts represent their skills. Photos in P (other than the photos of the experts) represent tasks.
This setting simulates a scenario where a committee of photographers judges the quality of a set of photos, for in-stance, for a photo competition.

The 10 most frequent tags (skills) in the dataset Flickr.art sculpture , stencil } ,andin Flickr.nature : { nature , water , flower , winter , macro , snow , sky , flowers , blue , green
We implement the online algorithms described in Sec-tion 4.2, which process one task at a time. This involved solving an instance of the set cover algorithm, which is done using the standard greedy algorithm [10]. The greedy algo-rithm adds experts to a team, one by one, by selecting the one who maximizes a score function.d The results of our algorithms are shown in Figure 1 and Table4. Wereportstatisticsonthesizeoftheteamsand theloadoftheexperts.WenotethatFigure1andTable4 present the results of the same experiments, the difference is that Figure 1 focuses on the center of the distributions, while the table focuses on the extreme values. In fact, for better visibility, the y -axes in Figure 1 are rescaled, so many outliers are not shown.

The first observation is that the algorithm Size makes smaller teams, and thus the average load is the smallest among all algorithms. However, we see that Size is very unfair; it uses a small number of individuals for a large number of tasks, which results in loading heavily those in-dividuals. For example, for the IMDB dataset, the director whose load is 1260 is Steven Spielberg , who is the direc-tor with the more genres than any other director; Steven Spielberg has 14 while Robert Zemeckis and Tim Burton follow with 11 and 10, respectively.

In Table 4 we try to measure overload using three mea-sures: the maximum load among all experts, the 90% quan-tile of the load (  X  . 9 ), and the average load of the top 10% of the most loaded users (  X  . 1 ). We see that even though the maximum load of Size is much higher than the maximum load of the other algorithms, the  X  . 9 is lower, suggesting that Size loads only a small fraction of the users, and the load drops quickly. However, the top users are heavily over-loaded, so  X  . 1 is high, as well.
 With respect to comparing the other three algorithms MaxLoad , SumLoad ,and ExpLoad , we see that they behave very similarly. This is a surprising fact, given that the three algorithms exhibit different behavior in theory. So in our opinion, this is a case of worst case analysis that does not happen in typical data. In fact, we have also tested the al-gorithms on a different number of synthetic data, and the Figure 1: Distributions of team size | Q | (left) and expert load L (right), as provided by our algorithms. Note that the y -axes are rescaled to emphasize the center of the distribution and not all outliers are shown. behavior of the algorithms is still similar. We omit the re-sults on the synthetic data for space limitations. Looking a bit closer at the results of the three algorithms MaxLoad , SumLoad ,and ExpLoad ,weseethat SumLoad makes teams of sightly larger size, and thus slightly average load, but it performs better according to the  X  . 1 measure.
With respect to the distribution of the size of the teams, we see that it is fairly well concentrated around its mean. The maximum team size can sometimes be high, however the 90% quantile is always less than two times the mean. We also report the measure  X  . 9 , which is the maximum team size so that all tasks are satisfied for at least 90% of their skills. We see that if we are willing to afford such a partial coverage the team size drops significantly. Creating teams. Balog et al. [6] state that the profile of experts should not only consider their individual skills, but Table 4: Statistics on team size and experts load. We report mean, maximum, and additional columns as follows:  X  . 9 denotes the 90% quantile;  X  . 9 is the maximum team size that an algorithm allocates pro-vided that each task is covered only up to 90% of the required skills; finally,  X  . 1 is the mean load of the 10% more loaded experts.
 also a description of their collaboration network. Lappas et al. [17] adopt this view by introducing a weighted social network indicating communication costs, so that close col-laborators are joined by edges of small weight. Next, they look for teams that satisfy a task (in the binary sense in our framework) and minimize the communication cost, e.g. in terms of diameter or weight of the minimum spanning tree for the team. Our framework can be extended to this case by incorporating the communication costs. Lappas et al. [17] consider the assignment of a single task, and do not consider the balance of workload when dealing with more than one task.
 Scheduling jobs. Scheduling jobs on a set of machines with the goal of minimizing the maximum load on a machine has been a well-studied problem in computer science since the seminal work of Graham [16]. We are not reviewing the vast literature here, but only pointing the reader to the works that are most closely related to our contribution.
As we described in Section 3.1, the problem that is closest to the one considered here is that of restricted assignment of jobs to machines. Here, weighted jobs have to be assigned to machines, but each job can only be processed by a subset of the available machines. The goal is to find an assignment of jobs to machines of minimum maximum load. This problem is NP-hard and it was studied in [3,4] in the online setting. Here, the authors showed a deterministic online heuristic achieving competitive ratio O (log n )( n being the number of machines) and they proved that this is asymptotically tight, even for randomized online algorithms.

Our problem is harder than restricted assignment since, as already observed in [17], forming a team entails solving a set-cover problem. This implies a logarithmic lower bound for many objective functions (e.g., SumLoad )evenintheoffline case [23].
 Peer reviewing. Refereed conferences and journals require every submission to be reviewed by several members of a program committee. Many such venues receive hundreds of submissions and it is not possible to compute by hand a matching that optimizes fitness and working load. The PC chair matches papers to reviewers based on her knowledge of submissions and PC members, with the help of scores that are computed automatically from keywords provided by PC members and authors. This is a matching problem for which several systems have recently been proposed, for instance Easychair, 1 Linklings, 2 and Softconf. 3 Easychair is currently based on a preliminary bidding process where reviewers rank papers into three classes. The problem of pro-viding efficient solutions in the bidding model has recently been addressed in [19]. In this paper, we have focused on a covering problem instead of a matching problem, and ex-cluded explicit bids.
 Determining expertise. The algorithms we have pre-sented require knowledge about the profiles of skills of the experts. For best performance in a real system, this should be done with a state-of-the-art expert-profiling method.
Early expert-finding methods could be classified basically into methods with a strong Information Retrieval (IR) com-ponent or methods with a strong Social Networks (SN) com-ponent. The IR approach can be exemplified by Craswell et al. [12] where relevant documents are concatenated to create a  X  X erson-document X  corpus, over which a standard docu-ment search system is run. Balog et al. [5] refined this to incorporate document relevance. The SN approach can be exemplified by Abrol et al. [1] where a graph of documents and people is built and connections are inferred from interac-tion histories. Other examples use HITS and/or PageRank in the context of online fora [24] or e-mail exchanges [9].
Most current approaches incorporate both IR and SN as-pects [13]. Expert finding in general has gained considerable attention in the research community since TREC started to incorporate an expert-finding task [11].
We have described and formally characterized a task as-signment problem, and proposed several efficient and effec-tive solutions to solve it. Our results, both theoretical and experimental, show that greedy methods for an online sce-nario can be effective in practice, as long as they consider both team sizes and workload of members.

Experimentally, we observe that even na  X   X ve methods, such as greedily minimizing team size, behave similarly with re-spect to the average distribution of workload. However, incorporating considerations of workload as the algorithm performs the online assignment of people to tasks, allows to reduce significantly the workload of the most-loaded experts. Future work. We plan to study other variants of the team-assignment problem, as well as to investigate key application scenarios. We also plan to address the problem of learning the skills of experts, as well as coping with issues such as dynamicity (experts joining and leaving the system) and co-ordination costs. In general, massive collaboration scenarios http://www.easychair.org/ http://www.linklings.com/ http://www.softconf.com/ present many algorithmic challenges. One of them is the task assignment problem we have described, but there are many other areas including reputation management, social-network-aware expert finding and document retrieval, and distributed decision making, among others.

Key references: [17]. [1] M. Abrol, U. Mahadevan, K. McCracken, [2] J. Aspnes, Y. Azar, A. Fiat, S. Plotkin, and [3] Y. Azar. On-line load balancing. In Theoret. Comp. [4] Y. Azar, J. Naor, and R. Rom. The competitiveness of [5] K. Balog, L. Azzopardi, and M. de Rijke. Formal [6] K. Balog and M. De Rijke. Determining expert [7] A. Borodin and R. El-Yaniv. Online computation and [8] F.P.Brooks. The Mythical Man-Month: Essays on [9] C. S. Campbell, P. P. Maglio, A. Cozzi, and B. Dom. [10] V. Chvatal. A greedy heuristic for the set-covering [11] N. Craswell, A. P. de Vries, and I. Soboroff, editors. [12] N. Craswell, D. Hawking, A. marie Vercoustre, and [13] H. Deng, I. King, and M. R. Lyu. Formal models for [14] D. Dubhashi and A. Panconesi. Concentration of [15] A. Fiat and G. J. Woeginger, editors. Online [16] R. L. Graham. Bounds on multiprocessing anomalies [17] T. Lappas, K. Liu, and E. Terzi. Finding a team of [18] S. Leonardi. On-line network routing. In A. Fiat and [19] K. Mehlhorn. Assigning papers to referees. In ICALP , [20] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis [21] C. Shirky. Here Comes Everybody: The Power of [22] D. D. Sleator and R. E. Tarjan. Amortized efficiency [23] V. V. Vazirani. Approximation algorithms . Springer, [24] J. Zhang, M. S. Ackerman, and L. Adamic. Expertise ProofofTheorem2. We give the algorithm and the proof for the binary profiles and we let the continuous [0 , 1] case for the extended version of the paper.

Recall the ILP formulation presented in Section 3.1. In the case of binary profiles, constraint (2) can be written as We solve optimally the corresponding linear programming relaxation, and let {  X  X ji } be the corresponding fractional solution, so that we have Let N =max { mk, n } . The algorithm performs R rounds (with R to be determined later). In each round, person p j is assigned to the task J i with probability  X  X ji , indepen-dently of other rounds and of other assignments within the same round. Set X ji ( r )=1if p j was assigned to J i in the r th round and 0 otherwise, and let L ( p j ( r )) be the load on person j in the r th round of assignments. At the end, X ji = 1 (i.e., person p j is assigned to task J i ) if and only if X ji ( r ) = 1 for at least one round r .Let L  X  be the optimum value. Consider the th skill required by job J i . The prob-ability that the skill is not covered (i.e., that constraint (5) is not satisfied) in the r th round is at most by using Equation (6). From that we obtain that and note that this quantity is at most  X / 2, if we set R = ln(2 N/ X  ). To bound the expected cost of the solution, note first that P (
X ji =1)=1  X  (1  X   X  X ji ) R  X  R  X  X ji . 4 This implies that for all j we have that E i X ji  X  R L  X  . Since, for every j ,the X ji  X  X  are mutually independent, a simple application of Chernoff X  X  bound [14, Equation (1.8)], allows to conclude that P L ( p j ) &gt; 2 eR L  X   X  2  X  2 eR L  X   X  4  X  eR . We therefore have that for our choice of R .
 For the sake of brevity, we define the events and note that event E 2 implies that the cost of the solution is at most O log N  X  the cost of the optimal solution. Then, from what we have shown we can conclude that Proof of Theorem 3 . The proof follows the one of Aspnes, et al. [2] for the competitive ratio of online load balancing as adapted in [18]. For the proof of the theorem it is conve-nient to use a slightly different notation from the rest of the text. Denote by Q ( i )and Q  X  ( i ) the team used for job the algorithm and by the optimal solution. Let L j ( i )= |{ i &lt;i : j  X  Q ( i ) }| and L  X  j ( i )= |{ i &lt;i : the online and the optimal load of person p j when job i is presented. Let  X  = max j =1 ,...,n L j ( k + 1) and  X  max j =1 ,...,n L  X  j ( k + 1) be the online and the optimal max-imum load on a person at the end of the sequence. Our goal is to minimize the maximum load.

Let  X  =2 n with n being the total number of persons. The algorithm for job i is as follows: 1. Let c j ( i )=  X  when job i is presented. We use  X  =2 n . 2. Find the team Q ( i ) with minimum cost j  X  Q ( i ) c j can cover the job. 3. Assign job i to team Q ( i )
Observe that in reality we cannot find a team Q ( i )ofmin-imum cost but only a team of approximately minimum cost by using an approximation algorithm for weighted set cover. Denote by c the approximation ratio of the weighted set cover algorithm used for finding a team of minimum expo-nential cost that covers all the skills of a job. The standard greedy algorithm achieves an O (log m ) approximation with m total number of skills of a job.

Assume for the moment that the algorithm knows the optimal load  X   X  . We first show that if we assign  X  = 2 c  X   X  log  X  , then the load on every person is at most  X .
Consider the time at which job i is presented. The cost of any team Q ( i )isatmost Z ( i )= n j =1 c j ( i ), the sum of the exponential costs of all the persons when job i is pre-sented. We prove in the following that Z ( i )  X  2 n , subject to
The inequality follows from the fact that the function f ( x )=(1  X  x ) R  X  1+ Rx is nonnegative in [0 , 1] and thus (1  X  x ) R  X  1  X  Rx . accepting every job i &lt;i on a team Q ( i ) with exponential cost that is at most c times the minimum. This immediately implies,  X  j  X  Q ( i ): and then L j ( i )  X   X = O ( c  X   X  log  X  ).
 We use the following potential function to prove the claim:
We have Z ( i )  X  2 X ( i )=2( X ( i )  X   X (0)) + 2 n . Z ( i ) is then bounded by 2 n if  X  does not increase when job i &lt;i is scheduled. The proof is as follows:  X ( i +1)  X   X ( i )=
The last two inequalities hold because 2 x  X  1  X  x if 0  X  x  X  1, and because Q ( i )is c -approximated minimum cost for task i .

To complete the description of the result we are left to remove the assumption that the algorithm knows the opti-mal load  X   X  . This is usually done [2] by using a doubling technique based on the observation that if the algorithm ex-ceeds load  X  then we do not have a correct estimation of  X  and we can double the current value of  X   X  . This results in a multiplicative factor of 4 in the competitive ratio of the algorithm.
