 There has been an explosion of interest in machine learning over the past decade, much of which has been fueled by the phenomenal success of binary Support Vector Machines (SVMs). Driven by numerous applications, recently, there has been increasing interest in support vector learning with linear models. At the heart of SVMs is the following regularized risk minimization problem: controls the trade-off between the empirical risk and the regularizer.
 There has been significant research devoted to developing specialized optimizers which minimize that their Bundle Method for Regularized Risk Minimization ( BMRM ) (which encompasses SVM-Perf as a special case) converges to an accurate solution in O ( nd/ ) time.
 While online learning methods are becoming increasingly popular for solving (1), a key advantage of CPM such as SVM-Perf and BMRM is their ability to directly optimize nonlinear multivariate performance measures such as F 1 -score, ordinal regression loss, and ROCArea which are widely used in some application areas. In this case R emp does not decompose into a sum of losses over In another award winning paper by Joachims [3], the regularized risk minimization problems corre-sponding to these measures are optimized by using a CPM .
 Given the widespread use of CPM in machine learning, it is important to understand their conver-gence guarantees in terms of the upper and lower bounds on the number of iterations needed to converge to an accurate solution. The tightest, O (1 / ) , upper bounds on the convergence speed of CPM is due to Teo et al. [2], who analyzed a restricted version of BMRM which only optimizes over one dual variable per iteration. However, on practical problems the observed rate of conver-upper bounds might be further tightened via a more refined analysis. In this paper we construct counter examples for both decomposable R emp like in equation (1) and non-decomposable R emp jecture 2 . We will work with BMRM as our prototypical CPM . As Teo et al. [2] point out, BMRM includes many other CPM such as SVM-Perf as special cases.
 Our results lead to the following natural question: Do the lower bounds hold because regularized words, to solve problems such as (1), does there exist a solver which requires less than O ( nd/ ) effort (better in n,d and )? We provide partial answers. To understand our contribution one needs to understand the two standard assumptions that are made when proving convergence rates: can devise an O ( nd/ under assumption A2 remains an open problem.
 k w k := (  X  w , w  X  ) 1 / 2 . We denote R := R  X  X  X  X  , and [ t ] := { 1 ,...,t } . Our paper is structured as follows. We briefly review BMRM in Section 2. Two types of lower examples that we construct. In Section 5 we describe an algorithm which provably converges to an accurate solution of (1) in O (1 / discussion and outlook in Section 6. Technical proofs and a ready reckoner of the convex analysis concepts used in the paper can be found in [7, Appendix A]. At every iteration, BMRM replaces R emp by a piecewise linear lower bound R cp k and optimizes [2] tightened until the gap falls below a predefined tolerance .
 with respect to w one can equivalently maximize the dual [2] over the k dimensional simplex: Algorithm 1: qp-bmrm : solving the inner loop of BMRM exactly via full QP.
 Require: Previous subgradients { a i } k i =1 and 1: Set A k := ( a 1 ,..., a k ) , b k := ( b 1 ,...b k ) &gt; . 2:  X  k  X  argmax 3: return w k =  X   X   X  1 A k  X  k .
 and set  X  k = argmax  X   X   X  maximizing D k (  X  ) is a quadratic programming (QP) problem, we call this algorithm qp-bmrm . Pseudo-code can be found in Algorithm 1.
 iteration, [2] proposed using a one-dimensional line search to calculate an approximate maximizer  X  code can be found in Algorithm 2. We refer the reader to [2] for details.
 Even though qp-bmrm solves a more expensive optimization problem D k (  X  ) per iteration, Teo et al. [2] could only show that both variants of BMRM converge at O (1 / ) rates: Theorem 1 ([2]) Suppose assumption A2 holds. Then for any &lt; 4 G 2 / X  , both ls-bmrm and qp-bmrm converge to an accurate solution of (1) as measured by (4) after at most the following number of steps: Generality of BMRM Thanks to the formulation in (3) which only uses R emp , BMRM is applica-(1), it yields exactly the SVM-Perf algorithm [1]. When applied to optimize the multivariate score, e.g. F 1 -score with R emp specified by (2), it immediately leads to the optimizer given by [3]. Since most rates of convergence discussed in the machine learning community are upper bounds, it is important to rigorously define the meaning of a lower bound with respect to , and to study scaled version cJ ( w ) this scales the approximation gap (4) by c . Assumptions such as A1 and A2 fix this degree of freedom by bounding the scale of the objective function.
 Given a function f  X  F and an optimization algorithm A , suppose { w k } are the iterates produced an accurate solution 3 : Upper and lower bounds are both properties for a pair of F and A . A function g ( ) is called an A to reduce the gap to less than , i.e. , On the other hand, lower bounds can be defined in two different ways depending on how the above two universal qualifiers are flipped to existential qualifiers. Table 1: Summary of the known upper bounds and our lower bounds. Note: A1  X  A2 , but not vice versa. SLB  X  WLB, but not vice versa. UB is tight, if it matches WLB.  X  Strong lower bounds (SLB) h ( ) is called a SLB of ( F ,A ) if there exists a function  X  f  X  F ,  X  Weak lower bound (WLB) h ( ) is called a WLB of ( F ,A ) if for any &gt; 0 , there exists a function f  X  F depending on , such that it takes at least h ( ) steps for A to find an accurate solution of f : Clearly, the existence of a SLB implies a WLB. However, it is usually much harder to establish SLB than WLB. Fortunately, WLBs are sufficient to refute upper bounds or to establish their tightness. The size of the function class F affects the upper and lower bounds in opposite ways. Suppose F upper (resp. lower) bounds for ( F ,A ) . w be shown to attain the lower bounds of the algorithms. The R emp for both the hinge loss in (1) and the F 1 -score in (2) will be covered, and our results are summarized in Table 1. Note that as assumption A1 implies A2 and SLB implies WLB, some entries of the table imply others. 4.1 Strong Lower Bounds for Solving Linear SVMs using ls-bmrm We first prove the  X (1 / ) lower bound for ls-bmrm on SVM problems under assumption A1 . Con-( x w instead of w as it is now a scalar): The proof relies on two lemmata. The first shows that the iterates generated by ls-bmrm on J ( w ) satisfy the following recursive relations.
 Lemma 3 For k  X  1 , the following recursive relations hold true the convergence rate of  X  2 k  X  1 , 1 and w k (see proof in [7, Appendix C]): Lemma 4 lim k  X  X  X  k X  2 k  X  1 , 1 = 1 4 . Combining with (11) , we get lim k  X  X  X  k | 2  X  w k | = 2 . rate at which J ( w k ) approaches J ( w  X  ) . See the proof of Theorem 2 in [7, Appendix D]. 4.2 Weak Lower Bounds for Solving Linear SVMs using qp-bmrm Theorem 1 gives an upper bound on the convergence rate of qp-bmrm , assuming that R emp satisfies tight) even when the R emp is specialized to SVM objectives satisfying A2 .
 (  X  1) i ( n e i +1 +
J ( w ) = check that y i  X  w  X  , x i  X  = 1 , so  X  X  ( w  X  ) = w  X   X  1  X  n P n i =1  X  i , X  1 ,..., X  n setting all  X  i = 1 2 n yields the subgradient 0 . Our key result is the following theorem. produces iterates w 1 ,..., w k ,... . Then it takes qp-bmrm at least 2 3 steps to find an accurate solution. Formally, min minimizer of J n +1 ( w ) gives exactly w  X  .
 w 1 = argmin In general, we claim that the k -th iterate w k produced by qp-bmrm is given by can again choose that J ( w k )  X  J ( w  X  ) = 1 2 k + 1 4 n as claimed. As an aside, the subgradient of the R emp in (13) does have Euclidean norm in the above run of qp-bmrm ,  X  X  emp ( w 0 ) ,..., X  X  emp ( w n ) always contains a subgradient with at the rate in Theorem 1.
 However when we assume A1 which is more restrictive than A2 , it remains an open question to determine whether the O (1 / ) rates are optimal for qp-bmrm on SVM objectives. Also left open is the SLB for qp-bmrm on SVMs. 4.3 Weak Lower Bounds for Optimizing F 1 -score using qp-bmrm F -score is defined by using the contingency table: F 1 (  X  y , y ) := 2 a 2 a + b + c . Given &gt; 0 , define n = d 1 / e +1 and construct a dataset { ( x i ,y i ) } n i =1 as follows: x i =  X  n and x n = positive training example. Then the corresponding objective function is Theorem 6 Let w 0 = 1  X  J ( w k )  X  min Proof A rigorous proof can be found in [7, Appendix E], we provide a sketch here. The crux is to show We prove (15) by induction. Assume it holds for steps 1 ,...,k . Then at step k + 1 we have For convenience, define the term in the max in (14) as Then it is not hard to see that the following assignments of  X  y (among others) maximize  X  k : a) then F 1 ( y ,  X  y ) = 0 and by (16) we have  X  k (  X  y ) = 1  X  0 + examples in x k +1 ,..., x n  X  1 (into positive). Then F 1 ( y ,  X  y ) = 2 2+ t So we can pick  X  y as (  X  i = 1 k +1 ). So (15) holds for step k + 1 . End of induction.
 The lower bounds we proved above show that CPM such as BMRM require  X (1 / ) iterations to To demonstrate this, we will show that one can devise an algorithm for problems (1) and (2) which will converge in O (1 / objective function, which renders second and higher order algorithms such as L-BFGS inapplicable. However, thanks to [7, Theorem 7 in Appendix A], the Fenchel dual of (1) is a convex smooth function with a Lipschitz continuous gradient, which are easy to optimize.
 To formalize the idea of using the Fenchel dual, we can abstract from the objectives (1) and (2) a composite form of objective functions used in machine learning with linear models: of a linear model, and g ? encodes the empirical risk measuring the discrepancy between the correct Theorem 3.3.5] under some mild constraint qualifications, the adjoint form of J ( w ) : satisfies J ( w )  X  D (  X  ) and inf w  X  Q 1 J ( w ) = sup  X   X  Q Example 1: binary SVMs with bias. Let A :=  X  Y X &gt; where Y := diag( y 1 ,...,y n ) and X := ( x 1 ,..., x n ) , f ( w ) =  X  2 k w k Example 2: multivariate scores. Denote A as a 2 n -by-d matrix where the  X  y -th row is P variate performance measure. Its adjoint form is
D (  X  ) =  X  In a series of papers [6, 9, 10], Nesterov developed optimal gradient based methods for minimizing the composite objectives with primal (17) and adjoint (18). A sequence of w k and  X  k is produced most k = O (1 / 5.1 Efficient Projections in Training SV Models with Optimal Gradient Methods However, applying Nesterov X  X  algorithm is challenging, because it requires an efficient subroutine projection or a Bregman projection.
 Example 1: binary SVMs with bias. In this case we need to compute the Euclidean projection to Q 2 defined by (19), which entails solving a Quadratic Programming problem with a diagonal Hes-all intermediate steps of the algorithm can be computed in O ( nd ) time directly yield a O ( nd/ algorithm. More detailed description of the algorithm is available in [11].
 convex function F on Q 2 , a point  X  , and a direction g , we can define the Bregman projection as: Then the application of the algorithm in [9] will endow a distribution over all possible labelings: pute the marginals in O ( n 2 ) time by using dynamic programming, and this cost is similar to the algorithm proposed by [3]. The detail of the dynamic programming is given in [11, Section 5.4]. CPM are widely employed in machine learning especially in the context of structured prediction [12]. While upper bounds on their rates of convergence were known, lower bounds were not studied on which CPM require  X (1 / ) iterations. Our examples are substantially different from the one in [13] which requires an increasing number of classes. The  X (1 / ) lower bound is a fundamental lim-itation of these algorithms and not an artifact of the problem. We show this by devising an O (1 / algorithm borrowing techniques from [9]. However, this algorithm assumes that the dataset is con-tained in a ball of bounded radius (assumption A1 Section 1). Devising a O (1 / the less restrictive assumption A2 remains an open problem.
 O ( nd/ ever, this method has been rediscovered independently by many authors (including us), with the earliest known reference to the best of our knowledge being [14] in 1990. Some recent work in optimization [15] has focused on improving the practical performance, while in machine learning [16] gave an expected linear time algorithm via randomized median finding.
 Choosing an optimizer for a given machine learning task is a trade-off between a number of poten-conversion techniques combined with stochastic subgradient descent are a good choice [17]. While the dependence on is still  X (1 / ) or worse [18], one gets bounds independent of n . However, as we pointed out earlier, these algorithms are applicable only when the empirical risk decomposes over the examples.
 On the other hand, one can employ coordinate descent in the dual as is done in the Sequential Mini-mal Optimization (SMO) algorithm of [19]. However, as [20] show, if the kernel matrix obtained by better dependence on , but is prohibitively expensive for large n . Even better dependence on can the time complexity per iteration is O (min { n 2 d,d 2 n } ) . [1] T. Joachims. Training linear SVMs in linear time. In Proc. ACM Conf. Knowledge Discovery [2] C. H. Teo, S. V. N. Vishwanthan, A. J. Smola, and Q. V. Le. Bundle methods for regularized [3] T. Joachims. A support vector method for multivariate performance measures. In Proc. Intl. [4] Y. Nesterov. Introductory Lectures On Convex Optimization: A Basic Course . Springer, 2003. [5] A. Nemirovski and D. Yudin. Problem Complexity and Method Efficiency in Optimization . [6] Y. Nesterov. A method for unconstrained convex minimization problem with the rate of con-[7] Xinhua Zhang, Ankan Saha, and S.V.N. Vishwanathan. Lower bounds on rate [8] J. M. Borwein and A. S. Lewis. Convex Analysis and Nonlinear Optimization: Theory and [9] Y. Nesterov. Excessive gap technique in nonsmooth convex minimization. SIAM Journal on [10] Y. Nesterov. Gradient methods for minimizing composite objective function. Technical Re-[11] Xinhua Zhang, Ankan Saha, and S.V.N. Vishwanathan. Regularized risk minimization by Nes-[12] I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun. Large margin methods for structured [14] P. M. Pardalos and N. Kovoor. An algorithm for singly constrained class of quadratic programs [15] Y.-H. Dai and R. Fletcher. New algorithms for singly linearly constrained quadratic programs [17] S. Shalev-Shwartz, Y. Singer, and N. Srebro. Pegasos: Primal estimated sub-gradient solver [18] A. Agarwal, P. L. Bartlett, P. Ravikumar, and M. Wainwright. Information-theoretic lower [20] N. List and H. U. Simon. SVM-optimization and steepest-descent line search. In S. Dasgupta [21] M. C. Ferris and T. S. Munson. Interior-point methods for massive support vector machines.
