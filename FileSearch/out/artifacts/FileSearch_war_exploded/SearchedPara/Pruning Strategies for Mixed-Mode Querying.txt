 Web information retrieval systems face a range of unique chal-lenges, not the least of which is the sheer scale of the data that must be handled. Also specific to web retrieval is that queries may be a mix of Boolean and ranked features, and documents may have static score components that must also be factored into the rank-ing process. In this paper we consider a range of query semantics used in web retrieval systems, and show that impact-sorted indexes provide support for dynamic pruning mechanisms and in doing so allow fast document-at-a-time resolution of typical mixed-mode queries, even on relatively large volumes of data. Our techniques also extend to more complex query semantics, including the use of phrase, proximity, and structural constraints.
 H.3.1 [Information Storage and Retrieval]: Content analysis and indexing  X  indexing methods ; H.3.2 [Information Storage and Re-trieval]: Information storage  X  file organization ; H.3.3 [Information Storage and Retrieval]: Information search and retrieval  X  search process ; H.3.4 [Information Storage and Retrieval]: Systems and software  X  performance evaluation .
 Algorithms, performance, experimentation.
 Text indexing, web querying, index compression.
Web information retrieval systems face a range of unique chal-lenges, not the least of which is the sheer scale of the data that must be handled. Also specific to web retrieval is that queries may be a mix of Boolean and ranked features, and documents may have static score components that must also be factored into the ranking process. For example, the PageRank of a page might be factored in as an additional score component, as might other factors thought to Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00. indicate overall page quality; and some query terms might be stip-ulated as being mandatory in any documents presented as answers.
In this paper we consider a range of query semantics used in web retrieval systems, and show that impact-sorted indexes provide support for dynamic pruning mechanisms and in doing so allow fast document-at-a-time resolution of typical mixed-mode queries, even on relatively large volumes of data. In particular, we consider the scenarios that are typical of web querying  X  relatively short queries, relatively short answer lists required, and a mix of Boolean and ranked query terms. Our techniques also extend to more complex query semantics, including the use of phrase, proximity, and struc-tural constraints.
Two main query types have been identified for information re-trieval systems: Boolean queries, and ranked queries. In the for-mer, documents either do or do not match an exact description of what constitutes an answer; whereas in the latter, the set of documents is scored according to a similarity estimation function, and the top r documents are presented to the user, for some pre-specified value of r . Zobel and Moffat [2006] give examples of these query types and of ranking functions, and also discuss their implementation using inverted indexes.

Within these two broad categories, there are several possible in-terpretations, and some blurring of the boundaries. In particular, this paper considers all of the following four types of query: Exhaustive Boolean (EB) . All documents that match the query are identified and presented to the user. There is no implicit order-ing on the collection, and no upper or lower limit on the number of answers that might be presented.
 Truncated Boolean (TB) . A maximum of r documents that match the query are identified and presented. It is assumed that the collec-tion has some static ordering imposed, for example as a result of a PageRank calculation that is used to permute the ordinal document numbers, and that if there are more than r matching documents in the collection, then the r with the smallest document numbers should be presented.
 Pure Ranked (PR) . Asetof r documents is identified on the basis of a similarity scoring heuristic, and presented in decreasing score order. Documents that do not match the query in a conjunctive Boolean sense (that, do not contain all of the terms) may still be ranked highly. A component of the scoring function might also be a static document-based score (such as PageRank).
 Ranked Boolean (RB) . A maximum of r documents that match specified parts of the query in a Boolean sense are identified and presented. The r documents that are presented are the highest-scoring ones of those that match the conjunctive Boolean compo-nents of the query, plus any other non-mandatory terms. Scores are again computed according to some similarity heuristic, possi-bly including a static document-based component. This group are the mixed-mode queries referred to in the title of the paper.
For example, in traditional library catalog searching in the 1960s and 1970s, the usual mode was Exhaustive Boolean  X  after each query, a message would be shown indicating (perhaps)  X  X here are 1 , 187 answers X , and the user would then refine the query by adding conjuncts so as bring the number of answers down to a more man-ageable level before printing them. On the other hand, most web search systems employ either a Truncated Boolean approach, in which a set of perhaps r =10 answers is expected (or r =20 , if the second page of results is requested, and so on), or a Ranked Boolean system, in which again a set of r documents is requested.
Many mechanisms have been developed for executing Exhaus-tive Boolean and Pure Ranked queries, see, for example, Zobel and Moffat [2006]. For the latter problem a range of accelerating tech-niques have also been devised, so that the top-r ranking can be calculated without necessarily processing every query term appear-ance in every possible document. Rather less attention, however, has been paid to the issue of Ranked Boolean queries. Yet these are an important class of query in web search services, and the volumes of data involved make efficient processing critically important.
For definiteness in what follows, we suppose a query syntax in which terms that must appear in an answer are flagged with a  X  +  X ; terms that may not appear in answers are flagged with a  X  - X ; and unannotated terms indicate words that are not mandatory in an-swers, but the appearance of which should be regarded (as well as the set of  X  +  X  terms) as being positive evidence in favor of that document as an answer. For example, the query indicates the set of documents in which howard must appear and blair must not appear, with the answers presented in decreasing order of the similarity scores calculated from the appearances of the three terms prime , minister ,and howard .

Further examples of queries appear below in Section 6.
To provide efficient query support, retrieval systems typically make use of an inverted file index that, for each distinct term that appears in the collection, stores details as to which document that term appears in, and also, in a word-level index, details as to where in each document the term appears. Queries are then resolved by processing the inverted lists for the set of terms that appear in each query, and computing a score for each of the documents that might be answers to the query. For details of inverted indexes, and query processing techniques, see Zobel and Moffat [2006].

There are two key ways in which the inverted lists can be orga-nized. In a document-sorted index, the pointers in each inverted list are stored in ascending document number order. This order allows straightforward implementation of, for example, intersection and union operations via a sequential merge process. The alternative is to use an impact-sorted index [Hawking, 1998, Anh et al., 2001]. In an impact-sorted index, the pointers are grouped into a sequence of equal-impact blocks ,wherethe impact of a pointer is a integer-quantized value that represents the  X  X mportance X  of that term in that document. Within each of these logical blocks the pointers are document-sorted, so that the usual compression techniques can be applied; the sequence of blocks itself is then stored in the inverted list in decreasing impact order, so that the most promising point-ers are available at the front of each inverted list. Note that impact blocks do not need to be the unit of access to the data, and that the physical blocks used to access the index data can be taken to be any convenient size.

While the impact-sorted organization makes list intersection and union operations more complex (as described below), it allows fast evaluation of Pure Ranked queries, and when k =8 or more quan-tized impact levels are used, retrieval effectiveness can be main-tained at high levels [Anh and Moffat, 2006a].

Queries against document-sorted indexes can be processed in two different ways: in document-at-a-time mode, or in term-at-a-time mode. In document-at-a-time processing, all index lists are processed concurrently in document number order, with each doc-ument fully evaluated before the next is considered. In term-at-a-time processing, only one index list is open for processing at any given time, and partial similarity scores are maintained for all doc-uments that are potential answers. Only at the end of the process-ing of all terms can the set of answer documents be determined. Strohman et al. [2005] and Anh and Moffat [2006a] are among a range of authors that discuss these mechanisms.

The attraction of document-at-a-time processing is that it matches the pointer ordering in a document-sorted index, and so permits straightforward implementation. Document-at-a-time processing is also natural for Truncated Boolean queries, since as soon as the necessary r answers are identified, processing can be terminated, and any trailing sections of inverted lists can remain unprocessed, and if a suitable choice is made for the physical blocksize, can also remain unread.

Use of term-at-a-time processing with a document-sorted index is more complex, in that it requires the storage of state information about each possible candidate answer, usually known as an accu-mulator . A range of techniques have been devised for limiting the amount of space that needs to be assigned to the storage of accu-mulators when evaluating Pure Ranked queries  X  see, for example, Lester et al. [2005] for one recent approach to this problem and pointers to the previous literature. The advantage of term-at-a-time processing compared to document-at-a-time operations is that only one access point (or cursor ) into the inverted index is required at any given time, and so less buffering and seeking may be required.
In an impact-sorted index, all of document-at-a-time, term-at-a-time and score-at-a-time processing modes are possible, where score-at-a-time represents a hybrid between document-at-a-time and term-at-a-time in which multiple index lists are open, but a com-plete impact block is processed at each step, again using a set of accumulator variables. Score-at-a-time is the most attractive pro-cessing mode for Pure Ranked queries [Anh and Moffat, 2006a], since only the most influential parts of each inverted list need to be processed in order to determine the most highly scoring doc-uments, and any superfluous pointers can remain unread and un-touched. Only processing the necessary front parts of each impact-sorted inverted list more than compensates for the costs associated with operating with multiple cursors, and allows fast processing of Pure Ranked queries.

Nevertheless, there are operating scenarios in which document-at-a-time processing is appropriate, including Truncated Boolean queries, Ranked Boolean queries, and the more complex query types that are described in Section 8 below. Our principal purpose in this paper is to address this dilemma, and examine how best to implement document-at-a-time processing using an impact-sorted index. Section 4, which comes next, presents our methodology for efficient document-at-a-time operations in an impact-sorted in-
B4 B2 B1 B3 A1 A2 A3 | q Figure 2: Distribution of impact values within inverted lists. The three bar graphs represent the average impact distribution over three groups of terms in the GOV2 test collection: those with f ( 10 , 725 , 138 terms); those with 1 , 000  X  f t &lt; 2 , 000 ( 22 , 390 terms); and those with 1 , 000 , 000  X  f t &lt; 2 , 000 , 000 ( 641 terms). Eight different impact levels are used, as plotted on the horizontal axis. This graph was first presented in Anh and Moffat [2006a]. dex; Section 5 then shows how the evaluation of queries can be accelerated via a refined interpretation of the max score dynamic pruning technique of Turtle and Flood [1995] (see also Strohman et al. [2005]); and then Section 6 presents experimental evidence in support of the various claims that are made about efficiency and effectiveness. Despite the seemingly obvious mismatch between impact-sorting in the index, and document-at-a-time processing at execution time, fast processing of all of the query modalities sum-marized in Section 1 is possible, and mixed-mode Ranked Boolean queries get a significant boost in throughput.
The standard mechanism for maintaining the set of candidate documents indicated by the active query cursors in a document-at-a-time evaluation is a heap  X  see, for example, Kaszkiel et al. [1999]. When there are p objects in the heap, each operation to extract the next smallest item requires O (log p ) time. For exam-ple, when a query of | q | terms is processed in document-at-a-time order against a document-sorted index, p = | q | . When the index is impact-sorted and there are as many as k blocks in each inverted list, p is as large as k | q | . Assuming that typical values are and k  X  8 , the heap operations appear to be a quite serious cost.
However, a heap is the most efficient structure for multi-way merging only if all of the component lists are of similar lengths; and in the case of an impact-sorted index this is normally not true. Figure 2, taken from Anh and Moffat [2006a], shows the distribu-tion of pointers within the impact lists for three different groups of terms in the k =8 index for the 426 GB GOV2 collection gener-ated for the 2005 TREC Terabyte Track experiments (see Voorhees and Harman [2005] for an overview, and trec.nist.gov for de-tails). The impact blocks that make up each inverted list are of widely differing lengths, resulting in part from the geometric se-quence used within each document to actually assign the impacts. In addition, queries typically involve terms with a mix of collection frequencies, further widening the set of list lengths that must be processed. These two factors combine to mean that a heap can in fact be a relatively expensive way of merging the set of blocks to get a document-ordered result. A heap also has the disadvantage of being a sequential data structure, and it is not possible, for exam-ple, to access the p th smallest item without performing p individual operations, each costing O (log p ) steps.

Instead of using a heap, we suggest maintaining the documents under the cursors in a simple array, ordered by increasing document number. This structure is shown in Figure 1 for an example two-term query involving terms A and B , and a total of seven impact blocks  X  three from term A , and four from term B . For simplicity, in this and subsequent examples, we presume that the impact con-tribution to the similarity score is determined by the impact value that is associated with the block in question, but in the actual im-plementation, an integer query-term impact weight is also factored in, and the actual score contributions associated with the set of four impact blocks for term B might well be, for example, 16 , 12 , 8 ,and 4 , rather than 4 , 3 , 2 ,and 1 .

To compute conjunctions over blocked impact-sorted indexes, the following logic is then used: [ Conjunction of terms using a sorted array ] set R  X  X } and i  X  1 for each impact block I for each conjunctive term t in q do end for sort array C based on the docnum component while all terms have a non-empty impact block do end while
The key observation is that a Boolean match has been identified whenever the | q | th cursor is equal to the first one. In this case the match can be processed. One of the cursors is then advanced to its next document number through the operation next value . It doesn X  X  matter which one, but for definiteness we suppose that it is the one. Once one of the cursors has been advanced, the others should also move least one pointer, to stay abreast of the current locus of activity. The operation seek value advances the indicated cursor until it gives rise to a document number that is not smaller than the second argument.

On the other hand, when the | q | th cursor is not equal to the first one, all of the first | q | X  1 cursors can be advanced (again using the operation seek value ) until they indicate a document number that is greater than or equal to d . Finally, irrespective of which case has occurred, the ordering in the array C of current candidates must be restored, using localized operations that are sensitive to extent of the disorder that has been introduced.

The step indicated as  X  X f document d meets other conditions in the query X  evaluates any non conjunctive aspects of the query. For example, if a Boolean query (types EB, TB, or RB) has negated terms indicated by a  X  - X , then the following logic is next applied to test a candidate document d : [ Handling negated terms ] for each impact block I for each Boolean-negated term in q do end for Similarly, in the two ranked query alternatives (types PR and RB), if a document d passes the Boolean tests, it is scored using the associated block impact scores (and the corresponding query-term impacts), and included in R if it exceeds the smallest value currently in R , which is denoted here as R min : [ Computing similarity scores ] set score  X  d. static score for i  X  1 to | q | do end for for each impact block I for each non-conjunctive term in q do end for if score &gt;R min then end if
That is, in a Ranked Boolean query, any document that matches the mandatory conjunctive parts of the query is then subjected to possible veto by any negated query terms; and then, if it passes that test, is scored and considered for inclusion in the answer set R .
Section 4 described how, when an impact-sorted index is being processed in document-at-a-time mode and Pure Ranked or Ranked Boolean queries are being executed, each of the impact blocks is simultaneously open and feeding candidates into the document-number-based merging. If the query has | q | terms, and the index is constructed with k impact levels, then as many as k | q are active, with data from each buffered into memory in fixed-size blocks.

However, if any form of ranked query is being evaluated, it may not be necessary for all of the impact blocks to remain active through-out the entire computation. For example, several techniques have been described for accelerating term-at-a-time evaluation of Pure Ranked queries (see Zobel and Moffat [2006] for details). For document-at-a-time evaluation of Pure Ranked queries, Turtle and Flood [1995] describe a technique that they call the max score heuristic .

To understand the max score technique consider the value R It starts at zero, since initially R is empty. The first r documents that are scored are thus automatically added to R ,and R min at zero while this is happening. But once | R | X  r , R min since new candidate documents d are added to R only if their score is greater than R min . That is, during the course of processing a query, the value R min is non-decreasing; and by the end of a query, it may be quite a large value.

In addition, each pointer that is processed has an impact  X  di-rectly associated with it in the inverted list. When R min ficiently high, and  X  sufficiently low, it is not possible for any combination of other term impacts to add to  X  to generate a value greater than R min , then the document d associated with that pointer can be discarded without being considered further. To perform this calculation the maximum score maxscore that can possibly be at-tained by any document is calculated in advance, based on known details of the term and query weights. Similarly, a value score [ t ] is maintained for each term t that is contributing to the ranking, that stores the maximum possible contribution that t can make to any similarity score. The function seek value is then modified so that for a given term t , any pointers that have an impact  X  such that maxscore  X  score [ t ]+  X   X  R min are skipped and not considered any further, as if they simply did not appear in the inverted list. That is, as R min increases, an increasing fraction of the pointers in each inverted list can be stepped over during the seek value operations.
The same technique can be employed with impact-sorted in-dexes, but with even better outcomes. To show how, a typical arrangement that might arise with a two-term query is shown in Figure 3, where terms A and B have three and four impact blocks respectively, with (assumed for simplicity) impact contributions of 3 , 2 ,and 1 for A , and contributions of 4 , 3 , 2 ,and 1 for B .The cursors are shown by the arrows, and at some typical point during the query, each of them has progressed part way through its list.
During processing, the pool R contains the r  X  X ighest score so far X  documents. The smallest value R min in R is the entry point at which new documents not yet scored can challenge for entry to the answer set. Suppose that, in Figure 3, the value R min reached 4 for the first time. Because all documents in the list at cur-sor B1 contribute only 1 to the final similarity score, and because the maximum contribution that can come from term A is 3 ,thereis no need to process any further documents from cursor B1 .Block the top r .
 B1 , and all of the pointers that remain in it, can be dropped from the computation, and the number of cursors decreased by one. By the same logic, should R min increase to 5 , then processing at cursor B2 can be discontinued, as can processing at cursor A1 . In the limit, if R min reaches 7 and | R | X  r , the number of desired answers, then no further processing is required at any of the cursors, since R is now a valid answer set.

Pruning is also possible when maxscore decreases, and not just when R min increases  X  if R min =4 and impact block B4 is ex-hausted, then block A1 can be pruned. This double-ended restric-tion is not possible with document-sorted indexes, since it is much less likely that any particular list will be exhausted. The following pseudo-code summarizes the logic presented in Figure 3, and is executed whenever R min changes, or when any im-pact block is exhausted. It assumes that score [ t ] is the current max-imum score contribution for term t , and that the variable maxscore contains the sum, over all of the query terms participating in the ranking (that is, excluding any that have a  X  - X  prefix), of the cur-rent values of score [ t ] . [ Whole-block pruning based on impact-sorted index ] for each impact block I for each non-negated term t in q do end for
The arrangement summarized in this pseudo-code is logically related to the Turtle and Flood max score mechanism, but derives a significant advantage because of the way it is coupled with an impact-sorted index. In the original max score proposal, index lists are processed document-at-a-time. Hence, even though the scan list function for each cursor is empowered to step past doc-ument identifiers that fall below the minimum eligibility score for that term, those pointers are still processed in the sense of being de-compressed, and compared against the eligibility threshold. They are also still read from disk. Similar drawbacks also arise with the WAND operator of Broder et al. [2005], which is another method of pruning queries in document-at-a-time processing.

In contrast, when an impact-sorted index is used, contiguous block sections are discarded. The pointers they contain are not ac-cessed in any way, and are not decoded or tested. Instead, once the eligibility threshold exceeds the impact score of any given block, the remaining pointers are simply ignored. Note also that the man-ner in which the conjunctive Boolean processing is interleaved with the document scoring process means that the cost of the Boolean filter is also reduced  X  if an impact block for a conjunctive term is discarded partway through processing of a mixed-mode query, then the Boolean part of the querying is also accelerated. Nor even is all of the impact block read from disk  X  in our implementation, the unit of physical disk access is just 8 kB. That is, compared to document-at-a-time evaluation, the revised max score implemen-tation has the potential to save considerable amounts of both input-output time, and processing time.
To test the proposed mechanisms for document-at-a-time pro-cessing in impact-sorted indexes, we make use of the GOV2 col-lection employed in the 2004 and 2005 TREC Terabyte Tracks. This collection contains around 25 million web pages, and totals 426 GB. We also followed the TREC Efficiency Track protocols when measuring performance [Clarke and Scholer, 2005]. In par-ticular, we identified (but did not fetch) the top r =20 documents for each query (for TB, PR, and RB queries); and we executed queries in strictly sequential mode with no parallelism.
Document-sorted and impact-sorted indexes were constructed for a range of values of k , the maximum impact level, based in all cases on the document-centric rank-based similarity formulation described by Anh and Moffat [2005]. In the case of the document-sorted indexes, the set of impacts  X  for the pointers in each inverted list were stored following the corresponding set of document num-bers d , in an arrangement we call a term-interleaved index, com-pared to the more usual pointer interleaved index in which each pointer is a d,  X  pair [Anh and Moffat, 2006b].

In an impact-sorted index the common  X  value is factored out of each impact block, and each inverted list is a sequence of k blocks of sorted document numbers. Values of k between 1 and 32 were used, to measure the effect that the granularity of the im-pacts has on running time. Note that the value of k does not greatly affect the time taken by the document-sorted method when han-dling Exhaustive Boolean and Truncated Boolean queries, since in these cases the term-interleaved impact parts of each inverted list are not accessed. However, when processing Pure Ranked or Ranked Boolean queries, the value of k affects processing speed of document-sorted indexes as well as of impact-sorted indexes, be-cause more data must be read and decoded.

All of the experiments directly compare document-sorted indexes and impact-sorted indexes, for document-at-a-time processing of a range of different query types, in each case producing the same list of answers. That is, query effectiveness is not an issue in these ex-periments, since the baseline document-sorted arrangement and the tested impact-sorted arrangement yield exactly the same result set to each of the queries. The results here are concerned solely with retrieval efficiency , that is, how quickly the intended computation can be carried out. As a baseline for document-at-a-time evaluation speed, the term-interleaved indexes described by Anh and Moffat [2006b] were used.

Two query sets were used in the experiments, both derived from the sequence of 50 , 000 queries used in the Terabyte Track experi-ments in 2005 [Clarke and Scholer, 2005]. The two sets are sum-marized in Table 1. To create the first set, we simply took the first 10 , 000 of the TREC queries, and regarded all of the terms as be-ing conjunctive, except when regarding them as being Pure Ranked queries. The first four queries in this Q10000 set were thus: Of the 10 , 000 queries, 1 , 229 did not have conjunctive Boolean an-swers in GOV2 .

To create the second set, the Q10000 set was processed in three ways: first, all single-term queries were removed; then the final term in each query was negated with a  X  - X  modifier; and then the second half (rounded down) of the remaining terms had the  X  +  X  modifier removed. The first four queries in this Q7764 set were: This latter set is hardly compelling from a human point of view; nevertheless, we believe that they represent a suitable test for the functionality expected of Ranked Boolean queries.
 All experiments were carried out using a 2 . 8 GHz Intel Pentium IV with 1 GB of RAM and 250 GB local SATA disk. While this is a relatively low-end machine, with a value well under $ 1 , 000 ,it is perfectly capable of managing the the necessary index manipu-lations, including construction. The relatively limited main mem-ory means that methods that rely on large amounts of buffering or caching are at a relative disadvantage.
 Conjunctive queries . Table 2 shows query throughput rates for the Q10000 query set, consisting of queries in which all terms are regarded as being mandatory (EB, TB, and RB modes) or positive evidence (PR mode). Impact-sorted indexes can be used for both document-at-a-time and score-at-a-time processing of Pure Ranked Table 2: Overall throughput results for the Q10000 query set, ex-pressed as a throughput rate in queries per second against 426 GB of data, using a 2 . 8 GHz Intel Pentium IV with 1 GB of RAM and 250 GB local SATA disk. The impact-sorted index is constructed with k =8 impact levels; the document-sorted one using the same similarity formulation and the same value of k , but stored as term-interleaved document-sorted lists (see Anh and Moffat [2006b]). Table 3: Overall throughput results for the Q10000 query set, when r =1 , 000 documents are identified for each query rather than r = 20 . Other details are as for Table 2. queries, and both options are listed in the table. The PR and RB queries make use of the max score heuristic in all cases  X  when the index is impact-sorted, using the techniques described in this paper, and when the index is document-sorted, using the conven-tional approach.

Of the four query modes tested, the document-sorted index is superior for Exhaustive Boolean (EB) queries, is of a similar speed for Truncated Boolean (TB) queries, and is slower on Pure Ranked (PR) and Ranked Boolean (RB) queries. Note also that the impact-sorted index can support PR queries at very high throughput rates if score-at-a-time processing is being carried out.

Table 3 shows the same experiment, but with r =1 , 000 doc-uments retrieved; the impact-sorted index is less efficient on the Truncated Boolean queries than when r =20 answer documents are identified, but retains its advantage on the two forms of ranked query (PR and RB).
 Mixed-mode queries . Table 4 shows what happens when nega-tion is introduced into the queries, and not all terms are manda-tory. The Q7764 query set is used; because these are now mixed-mode queries, they can only meaningfully be evaluated in Ranked Boolean (RB) mode. Note also (Table 1) that on average the queries are now slightly longer than in the Q10000 set. Comparing Tables 2 and 4, it is clear that query throughput rate is slightly lower for both index organizations; but the impact-sorted arrangement retains its throughput edge.
 The effect of k . Figure 4 shows the effect that varying k has on the throughput rate of Ranked Boolean (RB) queries, over the range 1 to 32 . High throughput rates are possible on conjunctive queries (the upper graph) when k is low, because the max score heuris-tic is able to quickly prune long impact blocks. However, when negation is introduced (in the lower graph), query processing rates Table 4: Overall throughput results for the mixed-mode Q7764 query set, in which some terms are mandatory, some terms are negated, and some terms are optional. These queries can only be meaningfully processed in RB mode. Other details are as for Ta-ble 2. Figure 4: Ranked Boolean query processing, identifying r =20 documents, varying k , the number of different impact score lev-els. The top graph shows the query set Q10000 , the lower one the query set Q7764 . Both document-sorted and impact-sorted evalua-tion modes are sensitive to the value of k when k is small, but are relatively insensitive for large values of k . are less volatile. The key point to note in these two graphs is that processing speed is relatively insensitive to increases in k beyond the standard operational point k =8 that was used in the tables of detailed throughput speeds.
The key method is due to Turtle and Flood [1995], who described the max score approach that discards pointers if there is no possi-bility of the associated document making it in to the top r answers. Subsequently, Broder et al. [2005] have described a document-at-a-time method that uses a weighted-and ( WAND ) operation as a first filter to identify candidates documents for full evaluation, and combines that mechanism with the max score approach. Simi-larly, Strohman et al. [2005] have drawn on the work of Brown [1995] and introduced a  X  X op documents X  set to the document-at-a-time processing strategy. Both of these approaches result in a quite substantial reduction in the number of documents in the collection that are fully scored. However, the use of document-sorted indexes means that all pointers in all inverted lists are read into memory and at the very least decoded. That is, while there is a saving in docu-ment scoring, not all of the benefits of the pruning are attained.
The  X  X op documents X  hybrid of Strohman et al. [2005] is espe-cially relevant to our work in this paper. Strohman et al. propose that a subset of each document-sorted inverted list be extracted to form an additional prefix list that is processed in advance of the main evaluation so as to provide an initial (and more precise) es-timate for R min . They then continue with the usual document-at-a-time processing using the max score heuristic, and are able to show that the preliminary operations result in further reductions in the number of documents that are fully scored. However, because a document-sorted index is used, pointers that are skipped are still fetched from disk and decoded. Our impact-sorted approach repre-sents a structured, and multi-level, elimination of this drawback.
Other authors have described methods for accelerating ranked queries via static pruning of the index [Soffer et al., 2001, de Moura et al., 2005, Theobald et al., 2005]. The key drawback of these methods is that the aggressive removal of thought-to-be useless pointers makes it impossible for Exhaustive Boolean queries to be processed, and such indexes are only suited when all queries will be in the Pure Ranked category.

There has been a wide range of previous investigations into the evaluation of ranked queries in term-at-a-time processing environ-ments, including work by Buckley and Lewit [1985], Harman and Candela [1990], Brown [1995], Persin et al. [1996], Anh et al. [2001], Theobald et al. [2005], Lester et al. [2005] and Anh and Moffat [2006a]. As noted above, term-at-a-time processing has two drawbacks  X  the need for state information to be retained, which may be expensive in multi-threaded environments in which mem-ory is at a premium; and a difficulty in accommodating downstream checking of more complex constraints to do with term positional information, or document structure.

Finally, we note that Salton et al. [1983] provide a detailed in-vestigation of hybrid Boolean and ranked queries, in their case by adjusting the way in which the Boolean operators combine val-ues; here we take a simpler approach in our definition of Ranked Boolean queries, and regard all non-negated terms as being positive evidence, and negated terms as exercising vetoes.
The use of impact-sorted indexes allows improved processing speed on Ranked Boolean (mixed-mode queries), because they more naturally support the max score pruning heuristic. The fact that multiple cursors are open at any given point in processing is more than compensated for by the fact that complete list sections can be discarded and neither read nor processed. Fast evaluation of web-style queries, even compared to a document-sorted index that seems more  X  X atural X , is the result.

Our work with Ranked Boolean queries is a precursor to an even more generic form of query in which term positional information, and document structural constraints, are also included. The use of document-at-a-time processing is such environments is argued by Strohman et al. [2005].
 Ranked Phrase (RP) . Asetof r documents that contain the query string (or strings) are identified and presented to the user. The pre-sentation order is determined by scoring the set of phrase-matching documents using a similarity heuristic, and ordering them by de-creasing score. Ranked Proximity (RX) . Asetof r documents that contain the query terms within the specified window size are identified and pre-sented to the user. The presentation order is determined by scoring the set of proximity-matching documents using a similarity heuris-tic, and ordering them by decreasing score.

We plan to extend our impact-sorted indexes and document-at-a-time processing to these query types, and to further explore the space of typical web queries.

Another area for further experiments lies with the evaluation methodology: we adopted the TREC approach here, which re-quires that one query be completed before the next is initiated. However, in a production system m ulti-threading would be essen-tial, and would yield considerable throughput gains. We believe that impact-sorted indexes would not suffer unduly compared to document-sorted indexes when processing mixed-mode queries in a multi-threaded environment, but plan to test that claim.
Finally, while we have noted that static document-based score components can be employed in the various ranking methods, none of the experiments reported here have done so. We plan to address the issue of static scores via further experiments, building on the software base that we have developed as our investigation has un-folded.
 Acknowledgment . This work was supported by the Australian Re-search Council, by the ARC Center for Perceptive and Intelligent Machines in Complex Environments, and by the NICTA Victoria Laboratory.

