 The popularity of crowdsourcing has recently brought about brand-new opportunities for engaging human intelligence in the process of data analysis. Most existing works on crowdsourcing have de-veloped sophisticated methods to utilize the crowd as a new kind of processor, a.k.a. Human Processor Units (HPU). In this paper, we propose a framework, called MaC, to combine the powers of both CPUs and HPUs. In order to build MaC, we need to tackle the following two challenges: (1) HIT Selection: Selecting the  X  X ight X  HITs (Human Intelligent Tasks) can help reducing the un-certainty significantly and the results can converge quickly. Thus, we propose an entropy-based model to evaluate the informative-ness of HITs. Furthermore, we find that selecting HITs has fac-torial complexity and the optimization function is non-linear, thus, we propose an efficient approximation algorithm with a bounded error. (2) Uncertainty Management: Crowdsourced answers can be inaccurate. To address this issue, we provide effective solutions in three common scenarios of crowdsourcing: (a) the answer and the confidence of each worker are available; (b) the confidence of each worker and the voting score for each HIT are available; (c) only the answer of each worker is available. To verify the effectiveness of the MaC framework, we built a hybrid Machine-Crowd system and tested it on three real-world applications -data fusion, information extraction and pattern recognition. The experimental results veri-fied the effectiveness and the applicability of our framework.
The recent success of crowdsourcing on various human-intrinsic tasks drives people to apply crowdsourcing to wider application ar-eas. Existing works treat the crowd as a new kind of processors, a.k.a. Human Processing Units (HPU). As a consequence, a query executed on an HPU is called an HPU-based task. With respect to cost-efficiency, the optimization of an HPU-based task focuses on how to decompose the task into a small number of micro-tasks, namely Human Intelligent Tasks (HITs) , that are easy for crowd-sourcing workers.

Most existing works treat the crowd as the sole information source for the queries. In other words, machines (i.e. CPUs) manage only the construction and publication of HITs, but do not informatively contribute to the answer. However, in many real-world applica-tions, such as information extraction, data fusion and pattern recog-nition, the same queries handled by HPUs can also be answered by machine-alone systems, usually associated with learning-based techniques. This indicates that the requested information can at least be partially provided by machines. In general, the latency of an HPU is much higher than that of a CPU, and an HPU may lead to high monetary cost (e.g. Amazon Mechanical Turk, Crowd-Flower). Thus, it is essential to combine the power of both methods to accomplish the tasks effectively. Motivated by this, in this paper, we propose a framework, namely MaC, to combine the power from both the crowd and the machines.

For each HIT, both machines and crowds can be seen as infor-mation sources. Whether using HPUs or CPUs, the major prob-lem associated with the results is the data uncertainty. For results obtained from machines, the inherent uncertainty is due to the in-capabilities of the current solutions in recognizing human-intuitive semantics via given data representation (e.g. images, nature lan-guage). For results obtained from the crowd, any uncertainty is due to sloppy workers, spammers, or the incapability of workers for domain-specific tasks. Since uncertainty is inherited from both the machine and the crowd, it is desirable to maintain the uncertainty in order to avoid information loss. Now we show an example of how to combine the machine and the crowd to improve the accuracy of the answer.
 Running Example: suppose we have textual data  X 51A Hayward East New York X , and the query is to extract information for three at-tributes - X  X ouse no X ,  X  X rea X  and  X  X ity X . With a machine-only tool of information extraction, we have the results as shown in Table 1. Due to a lack of capability to fully understand human semantics, four possible results are generated , each of which is associated with a probability of being the correct answer. As a result, the best answer is o 1 , but with a confidence of only 0 . 6 . On the other hand, assume we have a crowd C with accuracy 0 . 75 , then if we use the crowd alone to answer this query, say with a HIT  X  X hat are House no, Area and City of the given textual data X , the crowdsourced an-swer would have a confidence of only 0 . 75 .

In the above example, we can observe that using the machine or crowd alone, would generate query answers with a confidence of 0 . 6 and 0 . 75 , receptively. As pointed out in paper [11], even with simple tasks such as labelling, the quality of normal workers (not sloppy workers or spammers) is around 75%. For complex tasks such as information extraction, the accuracy of the crowd may be worse. In other words, 75% is already an optimistic estimation of the crowd accuracy for complex tasks.

Now we demonstrate how the collaboration between the machine and crowd is going to lead to a better result than just using either Table 1: running example -uncertain data generated by an informa-machine or crowd alone. For a given human-intrinsic query, we first apply machine-based systems to generate possible outcomes (answers) as well as probability distribution; then we selectively pose simple  X  X es-no X  questions to the crowd in order to reduce the answer uncertainty, hence improving the data quality. Continued on the running example, we ask the crowd a much easier HIT - X  X s the House No 51A ? X . Assuming the HIT is answered yes by crowd C with accuracy 0 . 75 , then we have
From the above results, we can see that, the collaboration be-tween the machine and the crowd generates a result with a confi-dence 0 . 82 , which is higher than using machine or crowd alone. In general, if we can combine the results from machines and crowds wisely, the combined results could be better than the results from a single source. In our framework, we do not have explicit con-straints for the uncertainties of the crowd, and how to manage the uncertainties are thoroughly studied in Section 4.

However, it is not trivial to propose a general framework for this collaboration, which requires the following challenges to be ad-dressed: (1) HIT Selection: Since information from humans (or the crowd) is very expensive, it is valuable to maximize the utility of the ques-tions in order to improve the overall cost-efficiency. Therefore, we would like to investigate the following question: which HITs should be published next based on current knowledge . Clearly, it is non-trivial to design algorithmic approaches to select and con-struct such HITs. (2) Uncertainty Management: The crowdsourced answers can be inaccurate. How should the accuracy of crowdsourced answers be estimated? Explicitly, for a given answer, we investigate how to compute the probability of its correctness.

In this paper, we proposed solutions to address the above two challenges and made the following contributions.
In addition, we discuss the related work in Section 6. The overall conclusion and possible future works are presented in Section 7.
In this section, we illustrate the MaC framework that collabo-rates machines with crowds, and provide formal definitions of some core concepts. The MaC framework is depicted in Figure 1. In gen-eral, MaC processes a set of analytic queries (query objects) with the following steps: (1) through some machine-only system, a set of possible outcomes and their distributions are provided for each query object, namely the  X  X robabilistic object X . (2) a number of HITs are constructed based on the machine-generated results (i.e. HIT selection problem). (3) HITs are batched as small groups and published to the crowd. (4) Based on crowdsourced answers (with uncertainty), the distributions are adjusted, and steps (2) to (4) are repeated if the budget is not exceeded. To be clear, we explain the MaC framework from top to bottom in the rest of this section.
As shown in Figure 1, the original input of the MaC framework is a set of query objects , which are human-intuitive queries to be processed on the machines or the crowd. Formally, we give the formal definition of query object, which captures a wide range of real-world tasks.

D EFINITION 2.1 (Q UERY O BJECT ). A Query Object q is an analytical task with the following two characteristics: (1) The possible outcomes of q and its probability distribution can be provided by some machine-only systems. (2) q is an easy and intuitive task for crowdsouring workers.
In the MaC framework, the query objects are first processed by a machine-only system. In the running example, the given image of poker card is a typical query object, and the recognition system is corresponding to the machine-only system in the MaC framework. For each query object, a set of possible outcomes are obtained. We call such a set of possible outcomes a probabilistic object . Since it is a fundamental concept for the later sections, we formally define this term as follows.
 Object O is a set of possible outcomes of a query object, described by a collection of attributes O = { A 1 ,...,A n } , with A value from a finite space  X ( A i ) = { a i 1 ,..,a i |  X ( A
A probabilistic object depicts the partial information derived from computer-alone systems. In the running example, for the given textual data, we have probabilistic object containing three vari-ables, i.e. House no ( A 1 ) ,Area ( A 2 ) and City ( A 3 spaces are also well defined according to Table 1. For instance,  X ( A 1 ) = { a 11 = 51 A,a 12 = 51 } and Pr ( A 1 = a 12 Pr 1 ( a 12 ) = 0 . 3 + 0 . 05 = 0 . 35 .
After probabilistic objects are obtained, we aim to further reduce the data uncertainty via publishing HITs. Then the question is: which kind of HITs should be asked?
It is well-known that crowdsourcing works best when tasks can be broken down into very simple pieces. An entire machine-generated outcome may be too large a grain for a crowd -each crowd worker may have small quibbles with a given outcome, so that asking the crowd to directly support or reject each outcome may get mostly negative answers, with each worker declaring it less than perfect. In other words, determining the correctness of an entire machine-generated outcome is too difficult for crowdsourcing workers. On the other hand, asking open-ended questions is not recommended for a crowd, because it may be difficult to integrate multiple sug-gestions of heterogeneous semantics. As a result, we propose to have the question broken down into per-attribute tasks , which is formally defined in Definition 2.3. This kind of much simpler ques-tions, in most applications, can be answered with a simple yes or no. As shown in Section 5, Yes/No questions are in fact useful in a wide range of applications.

D EFINITION 2.3 (HIT AND HIT SPACE). For a given prob-abilistic object O = { A 1 ,...,A n } , a HIT is defined as an YES/NO question, in the form of  X  X oes A i = a ij ?". So, the HIT space of O includes totally P n i =1 |  X ( A i ) | HITs. We denote HIT  X  X oes A i = a ij ? " by h ij . Hence h ij follows Bernoulli distribution with Pr ( h ij ) = Pr i ( a ij ) to have  X  X es" as ground truth, and 1  X  Pr ( h ij ) to have  X  X o".
 In the running example, Table 1 lists all the HITs in the HIT space of the probabilistic object.

For each probabilistic object, an important optimization problem is to find the best k HITs. This is known as the  X  X IT selection problem X , which will be thoroughly discussed in Section 3.
As a result of HIT selection, we have k HITs extracted from each probabilistic object. Clearly, the HITs from the same probabilistic object are generally correlated. In other words, one worker may provide correlated answers for HITS of the same probabilistic ob-ject. Since each HIT generates a unit of cost, asking correlated HITs to the same worker would be cost-inefficient .

In the running example, if the answer of HIT1 is answered ( X  X es X  or  X  X o X ) by a worker, then we can infer that what he/she would an-swer for HIT2, since HIT1 and HIT2 are exclusive. So asking both HIT1 and HIT2 to the same worker does not make any difference than only asking one of them, but would lead to two units of cost.
The above intuition indicates that, the most economical way of task publishing is to ask each user a set of independent HITs. In MaC framework, we create and publish batches of HITs with the following definition.

D EFINITION 2.4 (HIT BATCH ). A HIT batch includes multi-ple HITs, each of which is generated from an distinct probabilistic object. So the HITs within the same batch are independent. In ad-dition, when the batches are published, each worker is only allowed to answer HITs within one batch.
After the crowdsourced answers are available, we need to man-age their uncertainty, as discussed in Section 1. Since there are different paradigms of crowdsourcing, in Section 4, we develop dif-ferent methods of uncertainty management based on the accessible information. For a HIT h ij , the output of uncertainty management is the posterior probability after obtaining some answers Ans , i.e. Pr ( h ij | Ans ) .

In the following, we apply the updated value Pr ( h ij | Ans ) to ad-just the probability distribution of O . Recall that h ij question  X  X oes A i = a ij ?  X , which means a ij is the ground truth value of A i with prior probability Pr ( h ij ) . Hence, for each pos-sible outcome o of the probabilistic object O , with original proba-bility Pr ( O = o ) , if O = o entails A i = a ij , i.e. o is consistent with the answer, then we have Pr ( h ij | O = o ) = 1 . In the running example, given o 1 being the correct outcome, then the probability of  X  X ouse no = 51A" becomes 1 . As a result, we have
Pr ( O = o | Ans ) = Pr ( O = o ) Pr ( h ij | O = o ) /Pr ( h On the other hand, if O = o entails A i 6 = a ij , we similarly have Please note that, the above computation is independent of the se-quence of HITs. Therefore, the HIT answers of a probabilistic object would be collected from different batches, and utilized for probability adjustment, one after another.

As a result, the probability distributions are adjusted by the crowd-sourced answers. If the budget is not exceeded, and the qual-ity of the objects are unsatisfactory, the work-flow can be itera-tively executed. Therefore, the computation of Pr ( h conducted with at each iteration. Please note that, at each iteration, Pr ( h ij | Ans ) is computed based on all the answers received from previous iterations, rather than the current iteration only. This is because the essence of uncertainty management is statistical esti-mation, in which large sample size is preferred.
We now formally define the first problem considered in this pa-per, namely the Multiple HIT Selection Problem . The input to our problem is a probabilistic object, and we need to model the impor-tance of HITs and find the most important ones efficiently.
In this subsection, we give the definition of Multiple HIT Selec-tion (MHS) problem in the context of probabilistic objects.
From the perceptive of uncertainty, we are trying to reduce the uncertainty of the given probabilistic object O , by requesting infor-mation from the crowd via HITs. Therefore, we model the impor-tance of a HIT by its expected reduction of the uncertainty of O . In order to construct this model, we first define the uncertainty of probabilistic object with Shannon Entropy.
 bilistic object O = { A 1 ,...,A n } , let all the possible deterministic outcomes of O be  X ( O ) = { o 1 ,...,o |  X ( O ) | } , with probabilities { Pr ( o 1 ) ,...,Pr ( o |  X ( O ) | ) } respectively. Then we measure the un-certainty of O with Shannon Entropy -
The uncertainty of a probabilistic object is determined by the its marginal distribution. It reflects the information provided by the machine. In the running example, from the information extraction tool, the four possible labeling results (instances) are enumerated for the textual data (probabilistic object O ), then we have the its uncertainty computed as: H ( O ) =  X  (0 . 6 log 0 . 6 + 0 . 3 log 0 . 3 + 0 . 05 log 0 . 05 + 0 . 05 log 0 . 05) = 0 . 42 .

Since we aim to reduce the uncertainty of a given probabilistic object, we define the utility of a set of HITs based its expected uncertainty reduction.

D EFINITION 3.2 (U TILITY F UNCTION ). Given a probabilis-tic object O and a set of selected HITs S h = { h 1 ,h 2 ,...,h we define the utility of S h by the expected uncertainty reduction of O , i.e.
 where D h is all the possible outcomes of S h . Formally, we have D h = { s | s  X  2 S h s.t.  X  h  X  S h , h has ground truth yes if and only if h  X  s } .

Continued on the running example, we demonstrate the compu-tation of utility of S h = { HIT 1 ,HIT 4 } from Table 2. Based on the given data, we have Pr ( HIT 1 = yes,HIT 4 = yes ) = 0 ,H ( O | HIT 1 = yes,HIT 4 = yes ) = 0 ; Pr ( HIT 1 = yes,HIT 4 = no ) = 0 . 35 ,H ( O | HIT 1 = yes,HIT 4 = no ) = 0 . 85 ; Pr ( HIT 1 = no,HIT 4 = yes ) = 0 . 65 ,H ( O | HIT 1 = no,HIT 4 = yes ) = 0 . 12 ; Pr ( HIT 1 = no,HIT 4 = no ) = 0 ,H ( O | HIT 1 = no,HIT 4 = no ) = 0 . Since H ( O ) = 1 . 3 , we have the util-ity of S h : U ( S h ) = 0  X  (1 . 3  X  0) + 0 . 35  X  (0 . 42  X  0 . 85) + 0 . 65  X  (0 . 42  X  0 . 12) + 0  X  (1 . 3  X  0) = 0 . 0445 .

Equipped with the above utility function, we are now ready to provide the problem statement of Multiple HIT Selection.
 a probabilistic object O , there is a table  X ( O ) containing its all possible deterministic outcomes, each of which is associated with probability to be true. Given budget of HITs k, we aim to find k HITs that maximize the utility function.
One can see that the optimization problem is non-linear, due to the Shannon entropy. In addition, the optimization is essentially to find k HITs from the HIT space, so the searching space is of com-plexity O ( k !) . However, we found that the utility of a set of HITs is mathematically equivalent to their joint entropy. As a result, the utility function is a sub-modular function of the set of HITs. We formally introduce this fact with the following theorems. T HEOREM 3.1 ( EQUIVALENCY ). Given a probabilistic object O and a set of HITs S = { h 1 ,...h k } , the utility of S is equal to the joint entropy (i.e. the entropy of their joint distribution) of h , each of which is a discrete random variable following Bernoulli distribution. So we have P ROOF . From Definition 3.2, first we have
By Bayes X  theorem, Pr ( o l | s ) = Pr ( o l ) Pr ( s | o
Note that Pr ( s | o l ) represents the probability of s being the correct answers of HITs, given o l occurs, therefore, Pr ( s | o and o l reflect the same facts about the HITs (denoted o l otherwise Pr ( s | o l ) = 0 (denoted o l  X  s ). Hence, for each l , we have
C OROLLARY 3.2 (S UB -MODULARITY ). [1] The utility func-tion derived in Definition 3.2 is a monotonic sub-modular set func-tion of HITs. As stated by the above theorems, selecting a k-element subset of HITs is a maximization problem of a sub-modular function.
In general, maximizing sub-modular functions is NP-hard. Con-cerning the computation of the value of information, [1] shows that, for a general reward function R j (in our problem, R j = U ( O ) ), it is NP P P  X  hard to select the optimal subset of variables even for discrete distributions that can be represented by polytree graphical models. NP P P  X  hard problems are believed to be much harder than NPC or # PC problems.

However, maximization of sub-modular functions can be approx-imated with a performance guarantee of (1  X  1 /e ) , by iteratively selecting the best one HIT, given the ones selected so far [8].
Formally, we have the optimization function at the k th iteration: where S k  X  1 is the set of HITs selected from previous iterations. Now we consider S k  X  1 and h x as two random variables, then by the definition of conditional entropy, we have So we only need to maximize the conditional entropy at each itera-tion, i.e.
We first discuss the selection of the first HIT. This is particularly important, because one may be only interested in finding the best HIT (k=1) for each probabilistic object. In this case, the optimiza-tion is to find the HIT h i that maximize U ( { h i } ) = H ( h
H ( h i ) = Pr ( h i ) log Pr ( h i ) + (1  X  Pr ( h i )) log(1  X  Pr ( h symmetric function of Pr ( c ) , with symmetry axis Pr ( c ) = 0 . 5 . Besides, U ( { h i } ) achieves maximum Pr ( c ) = 0 . 5 , and is mono-tonic on [0 , 0 . 5] (increasing) and [0 . 5 , 1] (decreasing). Therefore, U ( { h i } ) is maximized by taking the h i with Pr ( h i to 0 . 5 .

In the running example, HIT1 (Pr(HIT1)=0.45) can be the first one to be selected, since no other possible HIT has probability closer to 0.5 than HIT1 does.

Please note that, setting k = 1 in MaC framework would lead to high utility-efficiency, but there would be only one HIT for each probabilistic object for the entire process. Hence, the overall time cost for spending the entire budget is significantly reduced.
For a probabilistic object O , we have a table containing n possi-ble outcomes  X ( O ) = { o 1 ,...,o n } with probabilities an entry of the table. For a given HIT h 0 asking  X  Does A = a ", we denote h 0  X  o i if a is the value of A in o i ; h 0 /  X  o So we have Pr ( h 0 ) = P h Pr ( HIT 1) = Pr ( o 1) + Pr ( o 4) = 0 . 45 .

One can see that, a naive way of computing the conditional en-tropy at the each iteration is to compute all the joint probabilities, hence yields to O (2 k ) complexity. However, with creating a small ( O ( n ) ) in-memory index, we can achieve overall linear complexity ( O ( kn P n i =1 |  X ( A i ) | ) ) for finding k HITs, where n is the size of  X ( O ) .

We propose an novel algorithm named  X  X able Partition". The intuition of this algorithm is the fact that, for each HIT h can be divided in to two parts, with h 0 = yes and h 0 = no . Based on this intuition, the essential goal of selecting k HITs is to partition  X ( O ) into at most 2 k parts, and the aggregated probability of each part (i.e. the sum of probabilities of entries within a part) is similar, in order to maximize the overall entropy. Now we illustrate the algorithm in detail as following steps.
 Step 1: Find the HIT h 1 with Pr ( h 1 ) closest to 0 . 5 //Section 3.2.2 Step 2: Partition the table into two parts  X  0 and  X  1 , where  X  o  X   X  ,h 1  X  o , and  X  o  X   X  1 ,h 1 /  X  o .

Step 3: Update Pr ( o i ) = Pr ( o i ) /Pr ( h 1 ) for o Pr ( o j ) = Pr ( o j ) / (1  X  Pr ( h 1 )) for o j  X   X  0 . Index Pr ( X  Pr ( h 1 ) and Pr ( X  1 ) = 1  X  Pr ( h 1 ) .
 Step 4: Find the HIT h 2 that maximize the conditional entropy:
Step 5: Partition each part  X  l further into two parts,  X  Update Pr ( o i ) = Pr ( o i ) /Pr ( h 2 ) and Pr ( o j ) = Pr ( o Pr ( h 2 )) for  X  l 0 and  X  l 1 , respectively. Index Pr ( X  and Pr ( X  l 1 ) = Pr ( X  l )(1  X  Pr ( h 2 )) Step 6: repeat Step 4 and Step 5 until find k HITs Step 7: compute the entropy of all the parts
Correctness and Complexity: The correctness of the algorithm is straightforward. After a HIT is selected, we update the probabil-ity of each outcome o i to become the current probability condition-ing on the selected HITs. Therefore, each part  X  l corresponds to a point of the marginal distribution of the selected HITs.

At each iteration, for a given HIT, computing the entropy with in each  X  l is of complexity O ( X  l ) , hence the computation of Eq 8 is O ( P l |  X  l | ) = O ( n ) . So the maximization of each iteration is of complexity O ( n P n i =1 |  X ( A i ) | ) . As a result, the overall com-plexity becomes O ( kn P n i =1 |  X ( A i ) | ) , which is essentially linear of the input. In this section, we discuss the management of the uncertainty of HIT answers from crowdsourcing workers. As illustrated in Sec-tion 2, we consider a HIT batch as the basic unit of uncertainty management. In general, we have the following problem defini-tion.
 A batch of HITs { h 1 ,...,h k } is answered by a collection of work-ers. Each HIT h i is at least answered by one worker, and each worker answers at least one HIT. Note that the HITs of a batch are independent, and we have a prior probability Pr ( h i ) of each HIT (i.e. Pr ( h i ) to yes, and 1  X  Pr ( h i ) to be no). We aim to esti-mate the posterior probability Pr ( h i | Ans ) , where Ans denotes the crowdsourced answers obtained.

Explicitly, we discuss the stated problem in three common sce-narios of HIT publication: (1) the answer and confidence of each worker is available for the given batch of HITs; (2) the confidence of each worker is available, and we only have a voting score for each HIT (e.g. yes:no = 10:8); (3) the answer of each worker is available for the given set of HITs, but their confidences are un-known. Note that, we assume workers independently answer each HIT in all the above scenarios.

Remark: There are also other possible scenarios, in which the uncertainty can be trivially evaluated. For instance, when only a voting score ( x : y ); x  X  y is available (no worker confidences), the uncertainty is simply x x + y .
In the rest of this paper, we naturally consider the confidence of a worker i as a random variable following a Bernoulli distribution with probability p i to answer a HIT correctly. Before detailing any techniques, we first discuss the possible ways to obtain the confi-dences with individual workers. In general, a confidence can be estimated based on either frequency or inference. A) frequency: when the personal historical records (i.e. the HITs previously an-swered) are available, the confidence can be estimated by the per-centage of correct ones. Typically, one may apply a set of HITs with ground truths (a.k.a. golden standard) for such estimation. B) inference: for a given HIT, the confidences can be inferred from the expertise of workers, according to the documents associated with each individual [9, 19]. Such inference is particularly appropriate for HITs with inexplicit answers, i.e. the ground truth is defined as  X  X he experts X  opinion" (e.g. schema matching, truth discovery).
The Confidence-Answer scenario is described as follows. For each HIT h 0 in the HIT batch, a set of answers a 1 ,a 2 ,...,a collected from the crowd, answered by independent workers with confidences p 1 ,p 2 ,...,p m , respectively. We aim to re-estimate the probability of h 0 being yes, based on the given answers. Since there is no correlation between the HITs, we can reduce the problem of solely one HIT. Then the solution can be repetitively applied every HIT in the batch.
 Given a HIT h 0 with Pr ( h 0 ) to be yes; a set of answers of h -{ a 1 ,...,a m } from independent workers of individual confidences { p 1 ,...,p m } . We need to compute the posterior probability of h
Computing the uncertainty is straightforward for CA scenario, since all the information of the process of crowdsourcing is ob-tained. From Bayes X  theorem, we have Due to the independence of workers, we have
As a result, the posterior probability can be efficiently computed with linear running time.
Majority voting is one of the most popular paradigms of crowd-sourcing, especially on on-line communities (e.g. social networks, forums). However, for some reasons (e.g. privacy), the voting is usually non-tangible, i.e. the individual results of workers is un-available, and what we have is only the final voting score. In other words, for a yes-no HIT, the voting score T:(m-T) indicates that T out of m workers answered  X  X es X , others answered  X  X o X . Similar to the CA scenario, we can consider each HIT in the batch indepen-dently. Therefore, we define the problem as follows.
 We are given a HIT h 0 with Pr ( h 0 ) to be yes; a set m work-ers(voters) of individual confidences { p 1 ,...,p m } ; and we know Input : A set of answers with individual confidences P m
Output : A vector of probability distribution of T , V T if m &gt; 1 then end else end
Input : A set of answers with individual confidences P m ; Output : Pr ( h 0 | e 0 ) V T  X  DC ( P m ) //indexing; P 0  X  V T [ t ] //Eq 12; P 1  X  V T [ m  X  t ] //Eq 12; that T of them answered  X  X es X , while others answered  X  X o X . We need to compute the posterior probability of h 0 ,i.e.

Comparing to the CA scenario, MV scenario preserves the pri-vacy of individual option of workers. This is particularly advanta-geous when the HIT contains sensitive information.

In the follows, we introduce a Divide-and-Conquer algorithm for the stated problem. Similar to Eq 9, we want to compute where e s is the event of voting scores being T : ( m  X  T ) . In fact, T can be considered as a discrete random variable following a Poisson Binomial distribution. Therefore, the probability mass function of T , given h 0 is where F t = { A || A | = T ;  X  i  X  A,answer of worker p i consistent with h 0 } . Eq 12 states the closed-form expression of the Pr ( T = t | h 0 ) . However, the possible number of A is facto-rial of T , so traversing the searching space is infeasible in practice unless the number of workers is small.

Based on Formula 5, Pr ( T = t | h 0 ) aims to compute the prob-ability when the T = t under the condition of h 0 given. Because each p i follows the Bernoulli distribution, T is the sum of p of which follows the Bernoulli distribution with different probabil-ity parameter. Thus, it is the core problem for obtaining the un-certainty to compute the probability mass function of T efficiently. Since the different value of T can be enumerated, the probabil-ity distribution of different values of T is represented as a vector. When the set of confidences is given, the probability distribution of T can be computed by the following divide-and-conquer-based algorithm , as shown in Algorithm 1.
 In Algorithm 1, the algorithm firstly divides the set of workers P m into two groups of the same size as long as P m includes more than one element. Then, the algorithm recursively solves the confi-dences of partitioned groups. In particular, we use the fast Fourier Transform (FFT) to speed up the recursive processing. Moreover, the recursive boundary is computed. Therefore, based on Algo-rithm 1, we obtain the probability distribution of C and can com-pute Acc of the given set of workers P m easily. Algorithm 2 shows the details of computing Acc .
 According to Algorithm 1, the computational complexity is O ( m log 2 m ) where m is the size of the set of worker P the Fast Fourier Transform acceleration. Based on the Algorithm 2, the total computational complexity is O ( m log 2 m ) for indexing the probability distribution plus O (1) to answer a given query of voting scores. Therefore, when multiple HITs are answered by the same group of workers via majority voting, Algorithm 1 only needs to be executed once.
In the Answer-Only(AO) scenario, we do not assume any prior information concerning the worker confidences. AO scenario is particularly appropriate when neither personal information nor his-torical records of the workers are available.
 A HIT batch H = { h 1 ,...h m } are answered by a set of workers U = { u 1 ,...,u m } . Each HIT is answered by one or more workers, and each user answers at least one HIT. Given the set of answers A = { a ij | a ij is the answer for HIT h i from worker u our objective is to estimate Pr ( h i | A ) without knowing the individ-ual confidences.

Since the HITs are published in batch, we can estimate the con-fidences of workers if the h i are known. On the other hand, we can also estimate Pr ( h i | A ) with the given confidences of workers. Based on this intuition, we adopt the Dawid-Skene X  X  approach [3], which utilizes an EM algorithm for the problem presented above. The details of algorithm are illustrated in the appendix.
By adopting MaC framework, we design hybrid machine-crowd systems for three real-world applications: data fusion, information extraction and pattern recognition. The experimental results veri-fied the effectiveness of the proposed methods. We focus on evalu-ating two issues. First, we examine the effectiveness of MaC frame-work in reducing the uncertainty of probabilistic objects. Second, we verify the correctness of MaC framework, by evaluating the im-provement of overall accuracy , i.e. the fraction of best outcomes that are the same as the ground truth. In particular, we compare hybrid machine-crowd systems with machine-only systems. The experimental results verified the effectiveness and applicability of our proposal. In this section, we present the details of our experi-mental studies on data fusion, information extraction and pattern recognition. The experimental study shows that MaC has wide applicability on various applications as well as different types of "crowds".
Introduction to Data Fusion: Handling conflicting web data from a series of websites has been one of the most challenging issues in modern data management systems. In many real applica-tions, the users are also willing to make a contribution to the appli-cation. Hence, such users can be considered a crowd, which brings the opportunity to resolve the conflicting information. In this exper-iment, we adopt MaC framework to build a hybrid machine-crowd fusion system.

Data sources: We identified a number of websites containing general information of computer-science conferences, including wi-kiCFP (wikicfp.com), confSearch (www.confsearch.org) and some personal web-pages manually maintained by computer scientists. We designed a crawler for each of the websites.

System overview: We implemented a system, namely ConfMGT, to integrate the information of computer-science conferences. This system is designed for researchers to conveniently manage the con-ferences with their cellphones. In general, a user can search con-ferences (s)he is interested in, and maintain personal categories of conferences. The whole system follows a classical Client-Server architecture. On the client side, a user may maintain a list of con-ferences, and synchronize the important dates with his or her calen-dar. On the server side, the crawlers constantly monitor the updates of the websites. Due to data entry errors or copying the same er-ror web-pages [5], there is usually conflicting information for the same conference. Explicitly, we focused on the truth finding on the following three pieces of information: the conference starting time, place (city), and deadline of submission. We also manually extracted the ground truths from the official websites, which are used for evaluation.

Framework Adoption: According to MaC framework, we nat-urally consider each conference as a query object (Definition 2.1). We first adopt the fusion techniques proposed in [5], which con-siders the accuracy of the websites and the copying relationship among the websites in truth finding. These fusion techniques are corresponding to the machine-only system of MaC framework. As a result, we have several possible outcomes for each conference, which is a probabilistic object (Definition 2.2) with three attributes. An example is shown in Table 3.
Crowd: We leveraged the users of ConfMGT as the crowd to improve the data quality of our system. Users may answer sim-ple YES-No HITs, which are generated by the method introduced in Section 3, and pushed to users. In detail, we have 70 confer-ences with conflicting information, and set k = 2 , 4 , 8 , 16 for HIT selection of each conference. Note that these HITs are batched ac-cording to Definition 2.4.
Performance: For evaluation purpose, we manage the uncer-tainty of the crowd under the three scenarios introduced in Sec-tion 4. As shown in Figure 2, the average uncertainty of the con-ferences (with conflicting information) is significantly reduced as HITs are answered, comparing to selecting HITs randomly. On the other hand, the overall accuracy, i.e. the fraction of best outcomes that are the same as the ground truth, outperforms the machine-only system in all the three scenarios, as shown in Figure 3. It worth noticing that the change of uncertainty is not necessarily mono-tonic. The uncertainty may increase when some surprising answers are received. For instance, a worker with high confidence answered  X  X es X  for a HIT of prior probability Pr ( h ) = 0 . 1 . Please note that, for each bar chart in Figure 3, the bar on the intersection of  X  X O_UNCERTAINTY X  and  X  X andom X  refers to the scenario that all the HITs are randomly selected, and we consider the crowd-sourced answer to be 100% accurate. When conflicting answers are received, the majority one is accepted.

An important phenomenon is that both the lowest average en-tropy and the highest accuracy are consistently found when k = 1 . This is because we always choose the very best HIT at each iter-ation. When k &gt; 1 , not every HIT is at the top of the list when they are selected, so the uncertainty is reduced more rapidly with a smaller k .
Problem Introduction: Information Extraction (IE) is the prob-lem of finding specific information from unstructured data, which is a critical issue for many applications. In general, it is still very difficult to tackle IE completely with an algorithmic approach. Ac-tually, the uncertainty of information extraction is because the ex-isting models (e.g. HMM or CRF) cannot fully capture the seman-tic of given data representation (e.g. human language). Therefore, we adopt our proposal to built a hybrid machine-crowd system of Information Extraction.

Datasets: In particular, we have a data set including 400 location addresses written in natural English (i.e. string segments). We have the following attributes of interests: house number, street name, and city name.

Framework Adoption: In information extraction problem, the input of a string segment is considered as a query object. The well-known learning-based tools (HMM or CRF) generate a set of ranked list of extracted data, each of which is associated with a probability. As a result, we consider the a learning-based IE tool as the machine-only system to obtain a set of possible extraction results, which can be seen as a probabilistic object defined in MaC framework. Naturally, each attribute of interests is an attribute of MaC framework, as illustrated in the running example of Section 1.
Crowd: In order to evaluate MaC framework with various crowd-sourcing platforms, we adopt the Amazon Mechanical Turk (AMT), which is a widely used crowdsourcing marketplace, as the crowd. Empowered with the Amazon Mechanical Turk SDK for Java, we are able to interactively publish and manage the HITs. In our im-plementation, each HIT is priced US$0.05. Each HIT is associated with a batch id, and workers are informed that, they are only al-lowed to accept HITs with the same batch id. Otherwise, their answers would not be accepted (i.e. no payment). In addition, a qualification test is required for each worker. For CA and MV scenarios, the confidence is computed as the fraction of questions answered correctly in the qualification test.

Performance: We demonstrate the change of average uncer-tainty of the extraction results. Similar to Section 5, we use the crowdsourced answers under the three scenarios. As shown in Fig-ure 4, the average entropy is reduced significantly. In addition, the accuracy is also improved in all the three scenarios, as shown in Figure 5. An important observation is that, in Figure 4, the curves with small k tend to have better performance. This is because that the smaller k leads to more knowledge for selecting each HIT. This phenomenon is intuitive, but not very obvious in the other two ex-periments. A possible reason could be that, each HIT is only an-swered by a small number of workers in AMT. Figure 6: Uncertainty Reduction of Poker Card Recognition
Problem Introduction: In the field of pattern recognition, the study on recognition of poker cards is not only interesting but also practical and valuable, especially in gaming industry. When the en-vironment is clear and stable, the accuracy of identifying ranks and suits of the poker images can be almost 100% . However, there are cases that are very difficult for a machine-only system in the real applications. For instance, the pokers may be overlapped; the light may change over time; and there may be different brands of pok-
Table 4: Probabilistic objects in MaC-based Recognition System ers (i.e. different pattens). In this experiment, we adopt the MaC framework to build a MaC-based system for poker recognition.
Framework Adoption: We consider each poker card as a query object, so the possible recognition results are probabilistic objects, as shown in Table 4. For experimental purpose, we develop a sim-ple card recognition system as follows. We set up four cameras (10 million pixels). Each cameras is connected with a different classification program. Explicitly, we apply the following classical methods-Regularized discriminant analysis (RDA), Classification and Regression Trees (CART), Support Vector Machine (SVM), and Artificial Neural Networks (ANN). The cameras are set 1.5 meters above a Baccarat gambling table. For simplicity, we set that each image includes six poker cards.

With a testing set of 500 images, RDA,CART,SVM,ANN have the individual accuracies 0.62,0.63,0.85,0.88 respectively. Note that, the cards in the testing set are randomly placed (may have overlapping), and 40%  X  X alt and pepper X  noise are added. As a re-sult, a probabilistic object can be constructed when the classifiers have conflicting results. We select 50 probabilistic objects, with initial uncertainty (entropy) 2 . 06 on average.

Crowd Simulation and Performance: In this experiment, we conduct a simulation of the crowd X  X  behavior according to three scenarios described in Section 4. Explicitly, we simulate 100 work-ers, with confidences following a uniform distribution on [0 . 5 , 1) . Figure 6 illustrates the reduction of the average of entropies; and the accuracy is improved up to almost 100% , as shown in Figure 7. A valuable observation is that, the reduction is very rapid com-paring to the other two experiments. This phenomenon indicates that, when confidences of workers follow Bernoulli distributions, the entropy would converge to zero reasonably fast. In addition, this experiment uses synthetic crowd responses, and the entropy converges to small values much faster than the previous two exper-iments. This is because there are other factors in real-world crowds that is not captured by our model.
In this section, we review the related work in two categories: crowdsourcing-based data management and active learning via crowds.
The recent booming up of crowdsourcing brings us a new op-portunity to engage human intelligence into the process of answer-ing queries (see [4] as a survey). Crowdsourcing provides a new problem-solving paradigm [2, 10], which has been blended into several research communities. In particular, crowdsourcing-based data management techniques have attracted much attention in the database and data mining communities recently. In the practical viewpoint, [6] proposed and developed a query processing system using microtask-based crowdsourcing to answer queries. More-over, in [14], a declarative query model is proposed to cooper-ate with standard relational database operators. In addition, in the viewpoint of theoretical study, many fundamental queries have been extensively studied, including filtering [13], max [7], etc. Besides, crowdsourcing-based solutions of many complex algorithms are also developed, such as categorization based on graph search [15], entity resolution [17], etc.
Although the previous studies have already proposed some fun-damental data operations based on crowdsourcing, they only focus on solving individual queries or operations. In contrast, our work aims to propose a general framework for a series of crowdsourcing-based data processing problems.
Active learning is a form of supervised machine learning, in which a learning algorithm is able to interact with the workers (or some other information source) to obtain the desired outputs at new data points. A widely used technical report is [16]. In particular, [12, 18] proposed active learning methods specially designed for crowdsourced databases. Our work is essentially different from ac-tive learning in twofold: (1) the role of workers in active learning is to improve the learning algorithm (e.g. a classifier); in MaC framework, the involvement of workers is to answer queries. (2) The uncertainty of answers in active learning is usually assumed to be given before generating any questions; in MaC framework, the uncertainty of answers has to be estimated after the answers are received, since we cannot anticipate which workers would answer our questions.
In this paper, we proposed a novel framework, namely MaC, to form a collaboration with the power of machine and the wisdom of crowds. In particular, we tracked two challenging issues involved in the MaC framework -HIT selection and uncertainty management. For HIT selection, we provided an entropy-based model to measure the importance of HITs, and an efficient (1+ ) approximation algo-rithm is deigned for the selection. For uncertainty management, we discussed the modelling and computation of workers X  uncertainty in three common scenarios. By adopting the MaC framework, we conducted extensive experiments on real-world applications. The experimental results demonstrate that the proposed framework is applicable to a wide range of applications. This work is supported in part by the Hong Kong RGC Project N_HKUST637/13, National Grand Fundamental Research 973 Pro-gram of China under Grant 2012-CB316200, National Natural Sci-ence Foundation of China (NSFC) Grant No. 61328202, Microsoft Research Asia Gift Grant and Google Faculty Award 2013.
