 In this poster, we analyze recent work in the document iden-tifiers reassignment problem. After that, we present a for-malization of a simple case of the problem as a PSP (Pattern Sequencing Problem). This may facilitate future work as it opens a new research line to solve the general problem. Categories and Subject Descriptors: H.3 [Information Storage And Retrieval] General Terms: Efficiency, Compression Keywords: Inverted Files, Compression, Document Iden-tifier Reassignment
The reassignment of document identifiers is a recent tech-nique to enhance static compression in inverted files. Some works demonstrated that it is possible to lower the num-ber of bits required to code each posting list by reassigning the document identifiers of the collection. Concretely, for a text collection of N documents and T terms, an inverted file stores a set of T posting lists following the format: where f t i stands for the frequency of the term t i (number of documents in which t i appears), and d ik is the k -th doc-ument identifier for the term i . As the notation implies, the document identifiers are ordered. A general way of com-pressing posting lists is to code differences between docu-ment identifiers, d ik +1  X  d ik , called d-gaps [6].
The document reassignment problem tries to find the bi-jective function f that maps each document identifier into a new identifier in the range [1 . . . N ] and minimizes the cost of coding the document gaps. Static codes exploit the fact that small document differences occurs often, assigning shorter codes to them. Indeed, it is clear that reordering the document identifiers in such a way that lower differences be-tween document identifiers occur in all or most posting lists, the resulting total number of bits will also be reduced.
Research in the document identifier reassignment problem is very recent. The first solutions of the problem are pre-sented in [2] and [4], in the following of this paper, the B &amp; B (Blandford and Blelloch) and the TSP approach (Travel-ing Salesman Problem) respectively. Both solutions build a weighted similarity graph G where the nodes v i , v j represent the document identifiers i, j and an edge e ( v i , v j ) represents the similarity between documents i and j .

The B &amp; B algorithm recursively splits G into small sub-graphs G l,i = ( V l,i , E l,i ) representing smaller subsets of the collection until every subgraph becomes a singleton. After that, the technique performs a reordering of the document identifiers, by depth-first traversal. The TSP-based solu-tions consider the problem a Traveling Salesman Problem which can be solved by several heuristics identified in graph theory literature. This technique tries to find the traverse that minimizes the sum of distances between consecutive documents. The minimal traversal gives the new order for the document identifiers. The work in [1] shows that an efficient implementation of the TSP approach is feasible by using a prior dimension reduction with SVD (Singular Value Decomposition).

Although presenting good results in d-gap reduction and therefore in compression ratio gains, the graph-based ap-proaches proposed so far, show scalability problems in terms of space and time. On the other hand, the work in [5] pro-poses a different approach by assigning the document iden-tifiers on the fly during the inversion of the text collection. This approach performs well, but under the assumption that the average document length is small.

Given the limitations of previous works, we present a for-malization of the problem of minimizing the average d-gap as a pattern sequencing problem (PSP [3]). This minimiza-tion problem implies obtaining a solution for the case of coding the d-gaps with unary code. Although this encod-ing has no practical consequences, the NP-Completeness of the PSP has been proved in the literature [3] and our work opens a research line to address the general problem.
Consider a binary matrix C where the columns are doc-ument vectors and the rows represent the presence/absence of each term in every document. Working with this binary matrix, the problem of minimizing the average d-gaps con-sists of finding the permutation of the matrix columns that minimizes a function cost  X  that computes the total d-gap length.

First, let us consider the posting list format in Equation (1), where for each term t i the ordered identifiers fall in the range d i 1 . . . d if t average d-gap, without including the first offset is In this situation, given a permutation  X  of the matrix C , C , the cost function  X  is the difference between the column number for the last and first one in each row, divided by the total number of ones minus one (in the row):  X  (  X  ) = if  X  k stands for the inverse term frequencies minus one, and  X  i = 1 ,  X  i : 1  X  i  X  N .

In the last form of  X  (  X  ) in 3, the first term is the expres-sion of the function cost in the Actor Costs (PSP-AC) of the shooting schedules problem [3]. The AC is a general-ization of the Average Order Spread (PSP-AOS) problem [3], and both are pattern sequencing problems. In these problems the goal is to find a permutation of predetermined production patterns. We also could consider the document identifier reassignment problem as a PSP-AOS in the partic-ular case that we measure the global average d-gap instead of the per posting list average d-gap. In [3] there is a proof that the PSP-AOS is a NP-complete problem. Therefore, the AC problem is also NP-complete and so this case of the document identifier reassignment.

Actually, coding a posting list implies taking into account the first document identifier appearing in the sequence. We can include this offset into the equation by simply adding it into the sum. Therefore, considering the first offset in each posting list, the cost function is
The solution to the problem formalized here is also a solu-tion to the reassignment of document identifiers using unary codes for d-gap encoding. However, in the real case the min-imization must take into account the coding scheme. Most static codes represent an integer x with O ( log ( x )) bits. In order to obtain good compression ratios, a better goal would be to minimize the d-gap products.This way, the log of the products and the sum of the logs would be minimal, with practical consequences in the final coded posting lists. It is important to notice that considering the problem a TSP, although producing good results, is only a strategy to address the document identifier reassignment problem. Given the weighted similarity graph G , the TSP finds the traversal  X  v 1 , . . . , v n  X  which maximizes P N  X  1 i =1 fact, the exact TSP solution may not optimize the average sum of d-gaps, as is illustrated in the following example, where the similarity between documents is measured with the inner product. Consider the following 4  X  4 matrix:
However, the traversal tr 2 =  X  d 2 , d 4 , d 1 , d 3  X  , which is not a TSP solution, has a lower d-gap sum. For the traversal tr 1 the sum of d-gaps is 12, and for tr 2 is 10.
Please notice that for this example, there exists another solution for the TSP with traversal tr 3 =  X  d 3 , d 2 , d also with a value of 12 for the sum of d-gaps. Also, the reader can verify that in these examples the TSP solutions are not optimal with respect to the sum of the d-gaps logs, since again the traversal tr 2 is better than tr 1 and tr respect to this cost function.
We have formalized a particular case of the document identifier reassignment problem, defining the real cost func-tion and identifying the problem as a PSP. This formaliza-tion shows the NP-Completeness of the problem. We have proved that TSP solutions can be not optimal, thus lead-ing to the need of experimenting with real-cost d-gap based heuristics.

