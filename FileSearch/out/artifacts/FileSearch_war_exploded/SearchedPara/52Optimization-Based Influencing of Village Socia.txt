 Insurgent movements seeking to overthrow weak governments rely on the broad or tacit support of the local population [Kalyvas 2006]. This critical support can take on many forms including active fighting, logistics, financing, intelligence, sanctuaries, or simply acquiescence to the insurgents who conduct activities in the area. Thus, the U.S. military conducting counterinsurgency (COIN) operations to defeat insurgencies believes that it ultimately succeeds by gaining the support of the population, not by killing or capturing insurgent fighters alone [Department of the Army 2006]. A key component of these counterinsurgency operations is deciding which among a broad class of nonlethal influencing activities ought to be undertaken to win the support of the local population. Examples of these activities include engaging local leaders (individuals who by virtue of their authority, power, or position have influence over the attitudes of a group of people) in constructive dialog, and addressing root causes of poor governance by providing aid and reconstruction assistance for the population. When counterinsurgents make use of the effect of local leaders and achieve popular support, they deny the insurgents the support critical to the movement X  X  survival.

In the counterinsurgency operations in both Afghanistan and Iraq, units of battalions and companies are assigned vast amounts of territory and often charged with winning the support of tens of thousands of people. These units are resource-constrained in terms of personnel, money, equipment, and time. These constraints in turn force units to be very selective in the number, type, and frequency of their nonlethal targeting activities. Furthermore, because success or failure is contingent on human behavior, it is extremely difficult to predict how a particular action will affect a group of people. A significant complexity to the environment is that the population can shift its support repeatedly throughout the conflict [Kalyvas 2006; Petersen 2001]. We are therefore presented with the nonlethal targeting problem: the problem of deciding on the people whom U.S. forces should engage through outreach, negotiations, meetings, and other interactions in order to ultimately win the support of the population in their area of operations.

The current methods of prioritizing and determining the value of targeting a specific set of local leaders are at best qualitative and are based upon the commanders X  and staffs X  intuition. Our objective is to develop a quantitative approach to address how units can determine the best nonlethal targeting assignment strategies and how the sentiments of a population might change as a result of them, given some coarse but realistically attainable data measurements.

The rest of this article is organized as follows. Section 2 describes our technical approach to the problem as well as its related work. Section 3 provides the modeling approach and formulation of both the Afghan COIN social influence model and the non-lethal targeting model. Section 4 reports our experimental results on the performance of the nonlethal targeting model against random-and doctrine-based methods of local leader selection. Finally, Section 5 discusses our results and provides conclusions. The technical approach was developed to support a variety of uses, including: (1) pro-viding decision support to commanders and their staffs when they make decisions on whom to target nonlethally in order to maximize popular support while operat-ing within the unit X  X  doctrinal and resource constraints, (2) developing effective COIN Tactics, Techniques, and Procedures (TTPs) for nonlethal engagement, and (3) training commanders in a war-game environment. We employ the following technical methods: social network analysis, agent modeling, and network optimization. Social network analysis is an interdisciplinary field that models interrelated individuals or groups of people as nodes in a network. For this application, we model the actors ( X  X gents X ) in an Afghan counterinsurgency (e.g., local leaders, Taliban, and U.S. forces) as nodes and the relationships among them as links in a social network. Tractable agent modeling provides analytic insight into the emergent behavior of a collection of agents (individuals or groups of individuals) based on a set of rules that characterize pairwise interactions. In particular, each agent in the network has a scalar-valued attitude of favorability towards U.S. forces, and the rules model probabilities of influencing each of its neighbors X  attitudes. Network optimization here refers to formulating and solving the problem of assignment of activities by U.S. forces in order to maximize the positive attitude of local leaders. Our work is related to a large opinion dynamics literature that presents explanatory models of how individual opinions may change over time. See Abelson [1964], DeGroot [1974], Friedkin and Johnsen [1999], Deffuant et al. [2000, 2002], and Hegselmann and Krause [2002]. This work is most closely related to and builds upon the work of Acemoglu et al., which characterized beliefs in a social network in the midst of influential agents [Acemoglu et al. 2010a], and  X  X tubborn X  agents (i.e., agents which do not change belief) [Acemoglu et al. 2010b]. This work is also related to Key Person Problem (KPP) literature, which uses quantitative methods to identify the k -best agents of diffusion of binary behaviors in a network. For example, see Borgatti [2006] and Kempe et al. [2003].

From previous work, we make three main contributions. First we apply existing opinion dynamics research to the context of the counterinsurgency in Afghanistan by introducing a methodology for determining approximations of interpersonal influences over Afghan social interaction networks based upon social science and anthropological research. We also provide a method to determine a quantitative value of nonlethal U.S. targeting assignments and their predicted effect over a continuous scale on the local population in the counterinsurgency. Lastly, we present an optimization-based method of nonlethal target assignment selection. The Afghan COIN social influence model is a tractable agent model that allows us to analyze the effects of repeated interactions among local leaders, Taliban insurgents, and U.S. counterinsurgents on the attitudes of the Afghan population. It is a mod-ification of a flexible and extensible Markovian model developed by Acemoglu et al. [2010a], and was enhanced to suit the context of a counterinsurgency in Afghanistan. The model represents the agents as nodes in the network graph. Values at each node represent the attitudes of the respective agent and the edges of the graph represent connections among the agents over which influence occurs. The level of influence an agent (node) exerts on the attitudes of other agents (nodes) is modeled by the degree of forcefulness of each, as described next. 3.1.1. Agent Properties and Dynamics. We model two types of generic actors found in the counterinsurgency environment in Afghanistan. The first type is the ideologically mo-tivated agent consisting of Taliban insurgents and U.S. counterinsurgents, all of whose attitudes for their causes are immutable. We use S to denote this set of  X  X tubborn X  agents, where US and TB represent the set of U.S. and Taliban agents, respectively, and S = US  X  TB . The second type of agent is the Afghan local leader who has a mu-table attitude on supporting either side of the counterinsurgency. We use A to denote this set of all others. We make a limiting assumption that the time horizon of anal-ysis is such that all agents are considered fixed in the environment; that is, no new agents appear and/or no existing agents disappear. We denote the set of all agents as V = S  X  A ,and | V | = n .

We model an agent X  X  attitude towards the counterinsurgents as a continuous random variable that takes on a scalar value at each interaction occurrence (over all the agents). Specifically, let X i ( k )and X j ( k ) represent the value of node i and j , respectively, at interaction k , where both X i ( k )and X j ( k ) are between  X  0.5 and + 0.5. A negative (or positive) value means low (or high) favorability towards the counterinsurgents, and zero means neutral. This spectrum of attitudes is depicted in Figure 1. As in Deffuant et al. [2002] note, extreme points along the scale denote a greater strength of attitude. In our model, the ideologically motivated agents, the U.S. counterinsurgents and the Taliban insurgents, possess immutable attitudes which remain at the extreme points and do not change over time.

The state of the system is the set of values (attitudes) for the nodes in the network and is denoted as X ( k )  X  R n  X  1 , which is the vector of random variables for the attitude of all agents at the k -th interaction. Changes in the state of the system are modeled using a Markov chain. Transitions occur when there is an interaction between two nodes. Interactions occur when two nodes are chosen sequentially (to model who ap-proaches whom) out of an agent selection probability distribution across nodes. The first node selected is denoted as i and the second node is denoted as j . The distribution of this meeting probability p ij could be uniform, (i.e., each agent is equally likely to be selected), or nonuniform (i.e., certain agents are more likely to instigate interactions). The values for nodes i and j can change in response to the interaction between i and j . The transition from an interaction depends upon the forcefulness (described shortly) of the agents. Conditioned on the interaction between two agents with attitudes X i ( k ) and X j ( k ), the possible event outcomes are as follows. (1) With probability  X  ij , agents i and j reach a pairwise consensus of attitudes. (2) With probability  X  ij , agent j exerts influence on agent i , where the parameter  X  ij (3) With probability  X  ij , agent i exerts influence on agent j , where the parameter  X  ji (4) With probability  X  ij , agents i and j do not agree and each retains their original
These interaction-type probabilities are parameters in the model and can depend on the degree of forcefulness of the two agents. In our model of rural Afghan social networks, forcefulness can take on one of four levels 1 : regular (lowest level of forceful-ness), forceful 0 (third highest level of forcefulness), forceful 1 (second highest level of forcefulness), and forceful 2 (highest level of forcefulness). This differentiation between local leaders is based upon the largest sphere in which they can exert influence: at household, village, and regional district levels. Those who exert influence only within their own household are regular. Those who exert influence further to within the village (a village leader) are forceful 0 . And finally, those who exert influence further still to within the region (a district/regional leader) are forceful 1 . In essence, the difference in the local leaders X  degree of forcefulness X  X s determined by their societal positions (data more easily obtained by soldiers working closely with the population) X  X s used as an estimate for the relative strength of the influence between the local leaders. As soldiers understand more of the interpersonal relationships between pairs of people, it would be possible to assign more accurate estimates of the interaction-type probabilities. We also model U.S. counterinsurgent and Taliban insurgent as forceful 2 because we as-sume their attitudes are immutable and that they possess resources able to persuade a local leader to adopt its extreme attitude.

In an exchange between two agents, the agent most likely to change in value is the less forceful of the two and the amount of change depends on the parameters  X  ij or  X  ji , which can be thought of as measures of consistency of attitude. In our model, condi-tioned on the same two agents selected, the resulting effect on each agent X  X  attitude is the same, regardless of which agent is selected first to initiate the interaction. How-ever, it can also be modified to take into account the order of the interaction. The most forceful agents (forceful 2 ) always exert an influence on less forceful agents, although the strength of the influence is parameterized. At the other extreme, regular agents are always influenced by forceful agents. For cases in between, multiple outcomes are possible. Varying the parameters and probabilities provide significant modeling flexibility.

Informed by social science research indicating the importance of traditional authori-ties within Afghan villages [Afghanistan RRC 2009; Altai Consulting 2005], we offer an example parameterization in Table I. In particular, a regular agent (head of household): (1) always reaches a pairwise consensus with another head of household, (2) always adopts the attitude of the village leader or person with more forcefulness, and (3) never influences others with more forcefulness. Admittedly, these are strong assumptions but ones that we believe must be relaxed by military analysts working within specific villages to account for localized variations [Rubin 1994; Oberson 2002] and the amount of  X  X uling by consensuses X  that some village jirgas (village councils) exhibit [Brick 2008]. The forceful 2 agents in the table refer specifically to the Taliban because we reason that the Taliban X  X  use of armed propaganda and violence is very effective at per-suading the population. Thus the probabilities  X  ij and  X  ij for interactions involving the forceful 2 agents are 1.0 (depending upon whether i or j is the Taliban agent). Because we further reason that U.S. influencing activities are primarily nonlethal, we will later adjust their  X  ij and  X  ij interaction-type probabilities appropriately to reflect that U.S. agents do not have this certainty of persuasion (described in Section 4.2).
Figure 2 illustrates a simple example network of 3 villages (each with 4 regular family heads and 1 forceful 0 village leader), 1 forceful 1 regional leader, as well as forceful 2 U.S. and Taliban agents. The color of a node represents the attitude value using the scale in Figure 1. Given that an edge represents a relationship between actors along which influence occurs, this sample network depicts the U.S. counterinsurgent attempting to influence the regional leader, while the Taliban insurgent is attempting to influence a village leader. 3.1.2. Analytic Formulation of Expected Long-Term Attitudes. While the pairwise interactions between two agents in the social influence model are simple, the resultant behavior of the system with many agents in a large network is quite complex. However, through tractable agent modeling, we devised a method to compute the expected long-term attitudes for each agent analytically. We first recall that there were four interaction types that occurred with probabilities  X  ij , X  ij , X  ij ,and  X  ij . Therefore, the expected value of agent i  X  X  attitude at the k + 1 interaction, conditioned on the state vector of all agent attitudes at the k -th interaction, is weight agent i gives to the attitude of agent j . We then arrive at a concise expression for the conditional expected attitude of agent i .

From here, we employ a mean-field approximation and assume that the preceding equation exactly captures the dynamic of attitudes for agent i when meeting agent j , that is, given that agents i and j meet (regardless of order), In essence, we assume that the system changes attitudes on average rather than ran-domly [Jackson 2008]. We further assume every agent in V has a uniform probability of initiating an interaction, such that the probability that an agent initiates an inter-action is 1 n . Therefore, with probability 1 n  X  ( p ij + p ji ), the following attitude dynamic (written in terms of the expected weights  X  ij and  X  ji . for each pair of agents i , j  X  V ) occurs.
The conditional value of agent i  X  X  attitude at the next interaction is a function of both the probabilities where agent i elects others to interact with ( p ij  X  j : p ij &gt; 0) as well as the probabilities where all other agents can select agent i to interact with ( p
We can then write the expected value of agent i  X  X  attitude at interaction k + 1 over the possible interactions it initiates or is subject to by the others X  initiation, conditioned on every agents X  attitude at the previous interaction k .

We now desire to succinctly express the expected attitude of all agents at interaction k + 1, conditioned on all the agents X  previous attitudes. This step draws on both the law of iterated expectations and the linearity of expectations. First, we assemble a vector of all attitudes for each i .
 Here each component of the matrix Q  X  R | V |  X  | V | is defined as Then we take the expected value of this vector and use the linearity of expectations For ease of notation, let  X  X ( k )  X  R n  X  1 be the vector of the expected value of X ( k ), that is,  X  X ( k ) = E [ X ( k )]. Therefore, This discrete dynamic system captures the expected change in attitudes of all agents from interaction k to k + 1. In this work, we are interested in the long-term behavior of this system.

To solve this system of equations at steady state, we consider when k  X  X  X  such that We can decompose the matrix and vector as Q = tively. The Q matrix is decomposed into the following. (1) A  X  R | A |  X  | A | : submatrix of the columns of agents  X  A , rows of agents  X  A . (2) B  X  R | A |  X  | S | : submatrix of the columns of agents  X  S , rows of agents  X  A . The  X  X (  X  ) . vector idecomposed into two parts. (1)  X  Y  X  R | A |  X  1 : vector of expected long-term attitudes of agents  X  A (mutable agents) (2)  X  Z  X  R | S |  X  1 : vector of expected long-term attitudes of agents  X  S (immutable agents) This decomposition allows us to express the system of Eq. (14) as Therefore, if A  X  1 exists, the expected long-term attitudes of the mutable agents is This result now allows to explicitly determine the effect of adjusting agent parame-ters as well as network connections on the expected long-term attitudes of the entire population.
 The analytic result given before of expected long-term attitudes is based upon a partic-ular topology and parameterization. A natural question that follows is what topology produces the attitudes most favorable to the counterinsurgents? More specifically, how should the U.S. agents form connections to other agents in the network that maximize the favorable attitudes of the population? In order to answer this question we formulate the nonlethal targeting model as a NonLinear Program (NLP). Drawing from the general methodology of the classical static Weapon-Target Assignment (WTA) problem, we seek to find with network opti-mization the assignment of a fixed number of U.S. agents to a fixed number of local leaders in a social network that maximizes the expected long-term attitudes of the pop-ulation in favor of the U.S. forces. While the complete derivation for this formulation is found in Hung [2010], we explain the key components of the optimization formulation as follows. 3.2.1. Assumptions. In formulating this problem, we make the following assumptions. (1) The local leader social network is known and static. Furthermore, we assume that (2) Each pair of agents X  interaction-type probabilities is known and fixed. (3) The number of Taliban agents and their connections to the social network are (4) We only consider expected attitudes as the number of interactions approach infinity (5) The order of interaction (whether agent i initiates an interaction with agent j ,or (6) Each agent has a uniform probability of initiating an interaction. 3.2.2. Decision Variable. Given a fixed number of U.S. agents with (possibly) different associated interaction-type probabilities, the decision one makes is which U.S. agents are assigned to which non-U.S. agents (local leaders or Taliban) in the network to connect with. The decision variable is therefore a binary matrix, where each entry is
Each U.S. agent i  X  US can form a link with an agent j  X  A = A  X  TB ,which is either: (1) the mutable local leaders, or (2) the immutable Taliban leaders. A link formed between a U.S. agent to any mutable agent (and the subsequent propagation of influence from the U.S. agent to that agent) can be representative of any activity or communication in which the targeted local leader is frequently reinforced with pro-counterinsurgent attitudes. For example when U.S. forces single out an individual for nonlethal targeting, it may conduct weekly scheduled meetings with him to discuss grievances or offer security, resources, and support, as well as initiate a reconstruction project in the targeted individual X  X  village and frequently inspect its progress during friendly visits. All these activities, assuming that they are properly resourced and exe-cuted, are designed to shape the local leader X  X  attitude in favor of the counterinsurgent.
On the other hand, a link formed between a U.S. agent and any immutable Taliban agent alters the meeting probabilities with which the Taliban agent negatively influ-ences others. Such a link in this case can be interpreted as conducting any operation in which U.S. agents disrupt the enemy X  X  freedom of movement. For example, U.S. forces might conduct vehicle searches and checkpoints along roads leading into a village, thus interfering with the Taliban efforts to interact with the population.
 3.2.3. Objective Function. We seek the U.S. assignment strategy that maximizes the weighted average of the expected long-term attitudes for all mutable agents in the network, where the unit commander can subjectively determine a weight (value) for each local leader X  X  attitude based on a variety of factors, including: (1) the tactical importance of the village where the local leaders are from, and (2) political factors that may demand that one portion of the population be aligned earlier or in lieu of others.
We denote the commander X  X  valuation for the expected long-term attitude of each agent i  X  A as v alue i , where v alue i  X  R + and i  X  A v alue i = 1. This valuation is data that is derived from the commander X  X  intent for the population.

Thus we define the objective function in the nonlethal targeting problem: the U.S. assignment strategy that maximizes the weighted average of the expected long-term attitudes for all mutable agents in the network
The particular decisions of whom the U.S. agents connect with, u . (Eq. (17)), affect the expected long-term attitude of agent i , denoted by  X  Y , i .  X  i  X  A . If all the numerical values of v alue i  X  i  X  A . are equal, then this objective function reduces to the arithmetic mean of the expected long-term attitudes for all the agents. 3.2.4. Constraints. The constraints are provided by a reformulation of Eq. (15) given before in terms of the decision variables u ij , and a limit on the number of allowable connections for the i -th U.S. agent. This limitation may be based off the leader X  X  assess-ment of his or her ability (with limited resources) to reach a certain number of local leaders. The complete formulation of constraints can be found in the Appendix.
While this optimition formulation follows from the analytic expression for the ex-pected long-term attitudes of the population (Eq. (6)), some of its properties make it difficult to solve to true optimality. Specifically, the formulation is both nonlinear as well as nonconvex, which requires heuristic methods to solve and often arrives only at local optima. Additionally, there are O ( n 2 ) variables and O ( n 2 ) constraints, where n is the total number of agents in the network, which means the problem is large. In Hung [2010], we developed a simplified formulation by using a variable substitution and homogenously fixing the number of connections that each U.S. agent could make. This reduced the number of variables and constraints to O ( n ). The goal of our experiment is to determine the usefulness of our nonlethal targeting model in finding the assignment of U.S. agents to local leaders or Taliban insurgents that produces the most favorable population attitudes. We compare our optimization-based method of nonlethal targeting with a control as well as a method based on principles found in the U.S. Army counterinsurgency doctrine. We use the abbreviation NLTP (NonLethal Targeting Problem) to denote this optimization-based method. For this experiment, we calculated performance of each method of targeting both analyti-cally (Eq. (16)) as well as in a simulation.

The control for the experiment is the random-based method of nonlethal targeting, where connections are selected randomly, chosen only from forceful 0 , forceful 1 ,and Taliban agents (not among regular or U.S. agents). This could correspond to a na  X   X ve approach or realistically represent a unit X  X  decision upon arrival into a new area with-out guidance. U.S. agents at least know to nonlethally target more influential people (as opposed to regular agents who only influence a small number of others), but do not know which ones.

The alternative method of nonlethal targeting is to select U.S. connections based on counterinsurgency doctrine found in the U.S. Army Field Manual 3 X 24 [Department of the Army 2006]. This is called the doctrine-based method of nonlethal targeting, based on the following principles. (1)  X  X dentify leaders who influence the people at the local, regional, and national levels X  (2)  X  X in over  X  X assive or neutral people X  X  (5 X 22). (3)  X  X Nonlethal targets are] community leaders and those insurgents who should be (4)  X  X tarteasy...don X  X gostraightforthemaininsu rgent stronghold ...or focus efforts Based on such statements from U.S. Army doctrine, we select targeting assignments for the network. This assignment strategy is shown and explained in detail in the Appendix. The input data for the experiment presented here is based on social science aspects of Pashtun society and publicly available aggregate data on Pashtun districts (see Hung [2010] for details). A network of 76 agents (73 local leaders and three Taliban insurgent leaders) is analyzed and shown in Figure 3. This network consists of several district-level authorities as well as seven principal villages (labeled A through G), each of which includes heads of households and village leaders. Additionally, each of the Taliban insurgents has the ability to connect to (influence) four local leaders. The complete list of agents is given in the Appendix.

Furthermore, we assign initial attitudes of the population generally by village, re-flecting the common observation that villages collectively exhibit clear friendliness, unfriendliness, or neutrality towards U.S. forces [McChrystal and Hall 2009]. Lastly, note that the specific connections between agents in this network are determined by the SNGM (Social Network General Model), a homophily-based model developed and explained in Hung [2010] for the purposes of constructing a reasonable and informed representation of the interaction network among Pashtun local leaders. In brief, the model produces a social network between local leaders that: (1) is based on homophily of qawm (solidarity group), geographic proximity, and role similarity, (2) can be modified through human-in-the-loop validation by intelligence analysts, and (3) probabilistically accounts for the presence of random connections among villagers. The resultant net-work topology is similar to that of the  X  X slands X  economic model of network formation developed by Jackson [2008].
 In this experiment, we sought the nonlethal targeting assignment strategy for three U.S. agents. In a reasonable assumption about the parameters, we designate these U.S. agents as nonhomogeneous, each having different, less-than-certain interaction-type probabilities  X  ij or  X  ij based on available resource levels. The higher the resource level, the higher the probability that the U.S. agent can influence a local leader. In particular, we parameterize the resource level of the U.S. agents according to Table II. If the j -th ( i -th) agent is U.S., then  X  ij (  X  ij ) is the adjusted probability, respectively.
We developed seven test cases for sensitivity analysis over modified parameter values and network connections. This was done to test the ability of the optimization-based nonlethal targeting model to achieve the higher population attitudes. The description of each test case is provided in Hung [2010]. Each of the selection methods produces modified network topologies (between U.S. agents and their targeting assignments). For each of the seven cases in the experiment, we obtain targeting assignments according to the random-, doctrine-, and optimization-based selection (NLTP) methods. We then simply calculate the resulting arithmetic mean (average) of the expected long-term attitudes produced by each selection method for each case (analytically). The graphical depiction of this performance is shown in Figure 4.

Compared to both the random-and doctrine-based selection methods, the optimization-based (NLTP) method produces higher mean expected long-term atti-tudes analytically in all cases. The full set of experimental results is described in Hung [2010].

The analytical evaluation includes a test of the statistical significance of the perfor-mance of the optimization-based selection method over the random or doctrine-based selection methods. We test two null hypotheses: (1) the arithmetic mean of the expected long-term attitudes produced from optimization-based selection and doctrine-based se-lection across the cases are drawn from identical continuous distributions with equal medians, and (2) the arithmetic mean of the expected long-term attitudes produced from optimization-based selection and random selection across the cases are drawn from identical continuous distributions with equal medians. We then conduct pairwise Wilcox rank sum (nonparametric) tests on the arithmetic mean of the expected atti-tudes obtained in the experiment. The tests, which result in p-values of 0.0023 and 0.0041, are significant for Hypotheses 1 and 2, respectively. We thus conclude that we could reject these null hypotheses and state that the optimization-based method achieves a statistically significant higher mean expected long-term attitude than both the doctrine-and random-based nonlethal targeting methods.

Furthermore, we can depict the analytically obtained, expected long-term attitudes of the population achieved by each selection method. These images are appealing in that they show the expected long-term attitude of each agent in the network as a color code. We present the results of one case in Figure 5. While we observe that doctrine-based selection achieves better pro-U.S. sentiments among the people, we observe an even greater favorability as a result of the optimization-based selection. In addition to comparing the performance of the methods analytically, we also exam-ine the performance of the selection methods in simulation. The Afghan COIN social influence model was instantiated in a Monte Carlo simulation. The starting values (attitudes) X i ( 0 )  X  i  X  V are generated, based on a priori information or values cho-sen for analysis purposes. Then a pair of agents is selected using the agent selection probability distribution, and the attitudes are updated according to the transition prob-abilities, all as described previously. The full process can be repeated many times with different starting pairs of nodes and realized transitions. Statistics on the node values can be calculated from results from multiple runs of the model.

For each test case, we obtain the targeting assignments based on the various se-lection methods. Simulations on the resulting network topologies produce plots of the arithmetic mean of the expected long-term attitude at each interaction, k ,for k = 1 to 10000 as illustrated in Figure 6. Specifically, we conduct 50 realizations for each selection method within each test case. Each realization produces an arithmetic mean of the expected long-term attitude (over all agents in the network) for each interaction, k . We then average over these realizations to produce the arithmetic mean (over all re-alizations) of the arithmetic mean (over all agents) of the expected long-term attitudes for each interaction, k . For simplicity, we refer to these calculations as the average mean expected long-term attitudes.

We observe that the NLTP optimization-based selection method generally achieves a higher averaged mean expected long-term attitude than the other selection methods. We also observe some interesting results within roughly the first 2000 interactions: (1) up to around the 750 th interaction, random selection in fact achieves a slightly higher averaged mean expected long-term attitude than the optimization-based method and (2) up to around the 1600 th interaction, random selection achieves a higher averaged mean expected long-term attitude than the doctrine-based method. These observations could be due to stochasticity, or possibly signify that different selection methods may be more appropriate for shorter time horizons as opposed to our optimization-based method used in this work for long-term (infinite) time horizons. We also examine the characteristics of the agents that were selected by the optimization-based method in order to detect any possible patterns or insights into the nonlethal targeting assignment problem. In the experiment, there are a total of 38 possible candidates for assignment for each U.S. agent (73 local leaders plus three Taliban agents minus 38 regular agents). There are three U.S. agents with three con-nections allotted in each case. Aggregated across all seven cases, there are only 18 different agents selected for assignment to a U.S. agent as shown in Table III.
At a high level, we observe that U.S. agents are often assigned to the friendly forceful 1 local leaders who have a generally positive (procounterinsurgent) effect on attitudes of all village-level leaders connected to them. However, it is also interesting to note that U.S. agents are also occasionally assigned to forceful 0 agents in lieu other forceful 1 agents (those with higher relative influence). We suspect that this is due to the topology and the initial conditions of agent attitudes and likely due to two apparent principles: (1) the need to overcome Taliban influence in certain unfriendly villages, (2) the careful selection of agents to distribute U.S. influence while not being redundant with other U.S. influence efforts. In this way, the optimization-based selection mathematically reasons through the merits of selecting each agent for nonlethal targeting. Additionally, with validation, these patterns of nonlethal targeting selection could be used to refine U.S. Army doctrine.
 The optimization-based nonlethal targeting assignments of U.S. forces to local leaders on large networks achieve significantly higher arithmetic mean of the expected long-term attitudes than both random-and doctrinal-based strategies. Our approach is a consistent, quantitative method of determining the value of U.S. assignments to spe-cific individuals in a counterinsurgency in Afghanistan. Previously, commanders and staffs relied on intuition, doctrinal training, and the qualitative analysis of intelligence in order to determine their high-priority target list and target valuation. Our modeling approach and optimization-based method of target selection, however, provide a sys-tematic means to quantitatively determine the potential value of a nonlethal targeting assignment strategy as well as its predicted effect on the population. This technology X  X  capabilities signify that it is an important first step to helping commanders and staffs solve the nonlethal targeting assignment problem.

We identify several focus areas for future work in this area (some of which is already ongoing). These include: (1) accounting for short-term attitude dynamics, (2) including threshold-based attitude updates by villagers considering neighbors X  opinions, and (3) a data-based validation. Additionally, later work must consider changing enemy actions when deciding U.S. agent assignments. In this article we made the significant and unrealistic assumption that Taliban agent connections remained fixed over time. In fact, we are more likely to observe Taliban agents repeatedly reevaluating their strategy and initiating a coercion and intimidation campaign targeting those local leaders who are sympathetic to the counterinsurgents. Recent work by Howard [2011] has extended these models, formulated a two-player game (between U.S. and Taliban agents), and found equilibrium strategy profiles for large networks.
 The constraints are provided by a reformulation of Eq. (15) in terms of the decision variables u ij , and a limit on the number of allowable connections for the i -th U.S. agent. This limitation may be based off the leader X  X  assessment of his or her ability (with limited resources) to reach a certain number of local leaders.

The first constraint is derived when we rewrite Eq. (15) in terms of Q .
Next, we proceed to define the terms of Q . (Eq. (11)) as additional constraints. The simplest one is carrying forward.

For all the other components of Q , we rewrite: (1) the meeting probabilities p ij and p ji and (2) the weights probabilities as the reciprocal of the number of agents that i or j are connected to, so this process is straightforward. We define
We view these a ij  X  X  as binary data for all agents i , j  X  A , meaning that we know which local leaders are connected to each other and which Taliban agents are connected to which local leaders. Additionally, we declare a priori the number of connections that the i -th U.S. agent can make and denote this as nUSconnect i , i  X  US . Then we can rewrite the meeting probability p ij as a fraction of the existence of a connection between agents i and j , over the total number of connections that agent i makes with everyone else in the network.
Next, we also rewrite the weights  X  ij in terms of the decision variable. Recall that Since  X  ij , X  ij , X  ij all data inputs for i , j  X  A , X  ij is completely deterministic for i , j  X  A . However, there are two other different cases we need to be concerned with. For i  X  A and j  X  US , we can express the following.
Multiplying  X  ij by the decision variable u ji essentially activates  X  ij whenever the j -th U.S. agent connects with the i -th agent. For cases where j  X  US we can choose to model a realistic scenario with variability in: (1) the effectiveness each U.S. agent, and (2) the stubbornness of each agent  X  A . For every U.S. agent j ,let  X  ij = 0. Then the probability of the effectiveness of every U.S. agent j is determined strictly by  X  ij .Letus assume that this probability is exogenous to the network and the pairwise connection, and is only based upon the resources, talent, and persuasiveness of the particular U.S. agent j .

Additionally, we can make the self-weight of an individual with respect to a U.S. agent to be completely endogenous to the individual, regardless of the effectiveness of the U.S. agent trying influence him. Let an agent X  X  self-weight,  X  ij , j  X  US ,beafunction of: (1) the initial attitude x i (0), and (2) the level of forcefulness. We parameterize these self-weights in accordance with the Table IV.

This particular set of parameters illustrates the belief that: (1) agents who are ini-tially unfavorable to U.S. counterinsurgents have a greater self-weight when interact-ing with U.S. agents because they are more resistant to U.S. influence, and (2) agents who are more forceful have a greater self-weight when interacting with U.S. agents be-cause they are less susceptible to U.S. influence or require more U.S. effort to influence.
We can rewrite  X  ij for i  X  A and j  X  US
Additionally, for i  X  S and j  X  V , we can express the following because all agents i  X  S are stubborn or immutable.
Thus, all associated  X  ij , X  ij = 0, and  X  ij = 1 (because immutable agents are perfectly stubborn and always retain 100% of their belief).
 We now have all the pieces to rewrite each of the other components of Q (3.6). into three expressions.
 For all the other constraints, we justify them as follows.
Constraint (31) limits the number of connections for the i -th U.S. agent. This limi-tation may be based off the leader X  X  assessment of his or her ability to reach the local leaders with limited resources. Constraints (32) and (33) permanently establish the attitudes of both sets of immutable agents (the U.S. and Taliban). Constraint (34) de-clares the decision variable as binary (0,1) between each U.S. agent and all non-U.S. agents in the network (Taliban and local leaders). And lastly, constraint (35) limits the range of expected attitudes for all mutable agents between the minimum (  X  0.5) and the maximum ( + 0.5) values. Based on U.S. Army doctrine, we selected targeting assignments for the network. The targeting assignments of the nonhomogeneous U.S. agents on the large networks and the doctrinal justification are explained in Table V. It is important to note that our selections were based on a particular interpretation of doctrine and accept that there are certainly other valid interpretations that could lead to different targeting assign-ments. Determining these other assignments and analyzing their performance, how-ever, are tasks in future research.

