 We consider the problem of Collaborative Permutation Recovery, i.e. recovering multiple permutations over objects (e.g. preference rankings over different options) from limited pairwise comparison-s. We tackle both the problem of how to recover multiple relat-ed permutations from limited observations, and the active learning problem of which pairwise comparison queries to ask so as to al-low better recovery. There has been much work on recovering s-ingle permutations from pairwise comparisons, but we show that considering several related permutations jointly we can leverage their relatedness so as to reduce the number of comparisons needed compared to reconstructing each permutation separately. To do so, we take a collaborative fi ltering / matrix completion approach and use a trace-norm or max-norm regularized matrix learning model. Our approach can also be seen as a collaborative learning version of Jamieson and Nowak X  X  recent work on constrained permutation recovery, where instead of basing the recovery on known features, we learn the best features de novo.
 H.3.3 [ Information Storage and Retrieval ]: Information Filter-ing; I.2.6 [ Arti fi cial Intelligence ]: Learning Theory, Algorithms, and Experimentation Collaborative Ranking; Active Learning; Matrix Factorization
Recovering permutations or rankings from pairwise comparisons is an extensively studied problem with wide applications in infor-mation retrieval, knowledge discovery and machine learning. The standard setup is that of recovering a single permutation objects based on information of the sort  X  X  appears before B in the permutation X . It is well known that if comparisons are indeed consistent with some underlying permutation (i.e. there are no dis-crepancies or errors) then  X ( m 2 ) random queries or  X ( m log m ) adaptively chosen queries are suf fi cient for recovering the permuta-tion (this is essentially a sorting problem). Also when dealing with noisy comparisons, or when the comparisons are not transitive and consistent with some underlying permutation, methods are avail-able for reconstructing the best consensus permutation from both random and adaptively chosen queries [ 2, 21].

But in many scenarios, we would like to recover multiple relat-ed permutations. Consider for example many people, each with their own tastes or preferences. We could try to recover a single permutation that best tries to explain the consensus among the peo-ple, treating comparisons made by different people as not-entirely-consistent noisy comparisons. This approach, seems absurd in the context of survey research, because it would fail to capture individ-ual preferences and miss out entirely on the diversity of preferences in the population.

Alternatively, we could independently learn a separate permuta-tion for each person. While this corresponds to the most common approach to imputing missing survey data, it breaks down in the context of sparse or much missing data. If we can only obtain a limited number of comparisons from each user, perhaps even less than the number of items m , this might not be enough to recov-er the permutations when each users X  ranking is considered sep-arately. By contrast, in this paper, we investigate the problem of collaborative permutation learning . That is, of jointly recovering multiple related, but not identical, permutations based on pairwise comparisons from different permutations. We will show through theoretical and empirical demonstrations that the solution of these problems could widen the application of learning with permuta-tions to the design of novel, intelligent surveys that only require respondents to rank a few items in order to approximately recover their entire preference ranking. This would allow social and in-formation science researchers to rapidly identify individually pre-ferred products, services, opinions, policies and solutions, without wasting questions on answers that are likely predictable.
This type of collaborative ranking survey has become common for organizations that seek to identify preferred solutions to prob-viduals and organizations can fi eld surveys or  X  X dea marketplaces X  of precisely the type we describe here. Individual respondents are posed with a question and an associated pair of possible responses. Respondents can either add a new response, or compare the pre-sented pair. For example, in 2011, New York City Mayor Michael Bloomberg X  X  of fi ce fi elded such a survey that posed the question  X  X hich do you think is better for creating a greener, greater New York City? X  with possible responses including  X  X pen schoolyard-s across the city as public playgrounds X ,  X  X ncrease targeted tree plantings in neighborhoods with high asthma rates X , and  X  X eep http://allourideas.org NYC X  X  drinking water clean by banning fracking in NYC X  X  water-shed X  [ 25]. Collaborative ranking has been used in other academ-ic projects to  X  X rowdsource X  common knowledge and impressions about the world. Consider the 2013 article,  X  X he Collaborative Im-age of the City X  X  24], which employed a collaborative ranking sur-vey through which thousands of respondents ranked pairs of urban street images from the United States and Europe to determine ur-ban areas of more and less perceive d safety and prosperity. In all of this research, however, comparison pairs are chosen randomly and are densely annotated by many respondents. Our research could dramatically improve the ef fi ciency of these efforts.
More formally, we consider the following setup: we have n ple and would like to learn for each person i a permutation m items. The information we obtain is through pairwise compar-isons of the form  X  X ser i prefers item a over item b  X , i.e. that comparisons might be noisy, or only partially consistent with some underlying permutation. Furthermore, we assume the permutations  X  are all related in some way, and modeling this relationship is part of our contribution here. In any case, based on such, possibly noisy and non-transitive, pairwise comparisons, our goal is to re-cover  X  1 ,..., X  n . We also consider the  X  X ctive X  or  X  X daptive X  set-up where we can actively choose which queries to make, i.e. at each step we can choose a person i and a pair of items ( a, b ) user i as to whether the person prefers a over b (i.e. ask whether  X  and suggests answers for, are: (1) how can we recover the permu-tations for every person based on these pairwise preferences, and, (2) how should we adaptively choose queries so as to make our predictions more accurate and reduce the overall number of queries required.

In order to tackle the problem of collaborative permutation learn-ing, we formulate the problem as a matrix completion problem with pairwise constraints, and use standard matrix-factorization regu-larizers, such as the trace-norm o r max-norm, to reconstruct the matrix based on limited pairwise constraints. In Section 4 we dis-cuss this matrix factorization approach, its underlying assumption about the relatedness of the permutation, and its relationship to the constrained single-permutation learning approach of [ 12]. We then leverage the existing understanding of methodology on matrix fac-torization regularizers to suggest ef fi cient optimization methods for fi tting our suggested models (Section 5) and to analyze the number of queries required for recovery X  X n Section 7 we show that under our model, O ( n + m ) random queries are suf fi cient for approximate recovery, signi fi cantly less than the O ( nm ) required for approxi-mate recovery if learning each permutation independently. In order to further reduce this query complexity we turn to active learning and suggest an adaptive query heuristic based on biasing the queries towards more ambiguous pairs (Section 6).
 Notation Let [ n ]= { 1 , 2 , ..., n } .Foramatrix X  X  R n  X  m ,let X i,j be the ( i, j ) -th element; X i,  X  be the i -th row of X , X be the matrix inner product of A and B , and denote A 0 to mean A is positive-semi-de fi nite.
There has been much work on constructing a permutation based on pairwise comparisons. If the comparisons are transitive, that is consistent with some global permutation, then outputting this glob-al permutation given enough pairwise comparisons is easy. Once the comparisons are noisy, or are not fully consistent, the task be-comes trickier and one must both decide on a criteria for measur-ing the quality of a permutation (i.e. its degree of agreement with the comparisons) and devise an algorithm for fi nding the optimal permutation under this criteria. Some criteria and algorithms sug-gested for the problem include Borda Count [7 ], Rank Centrality [17], HodgeRank [ 13], Balanced Rank Estimation [ 31], and others. There are, however, two major differences between rank aggrega-tion and the problem we pose here. For rank aggregation, it is typ-ically assumed that: 1) there is only one globally optimal ranking, while here we assume each user holds a personal ranking; and 2) there are dense observations, i.e., with all, or at least many, pairwise comparisons being observed, while in our setting the observation-s are usually sparse, with only a very small fraction of pairwise preferences revealed. In particular, there is no hope of obtaining a meaningful global permutations with less than m  X  1 comparisons, as even for perfectly consistent data, this does not enable linking re-lationships among all m items (more typically, in rank aggregation one has O ( m 2 ) comparisons).

Beyond the problem of rank aggregation given dense static data, there has also been interest in adaptive query strategies for learn-ing the optimal distribution. Again, if all comparisons are guaran-teed to be transitive and so consistent with some permutation, the problem is easy and boils down to sorting by comparisons, and can the permutation can be recovered using O ( m log m ) comparisons, e.g. using merge-sort. When the comparisons are not necessarily consistent, one might wish to obtain the most agreeing (optimal) permutation for all m 2 possible comparisons, but without actually making all these comparisons. I.e. the assumption is a user holds a system of pairwise preferences that is not necessarily consistent with a permutation, and we would like to uncover the most consis-tent permutation by making the least amount of pairwise queries. Recently, [ 1] showed that this problem too can be solved using only O ( m poly log m ) adaptively chosen queries. Furthermore, if we are willing to tolerate discrepancies in fraction of comparisons, rel-ative to the optimal permutation, we need only O ( m poly log 1 queries. This is in contrast to the O ( m/ 2 ) random queries re-quired for solving the same task. This demonstrates the power of active learning in ranking, but is still limited to learning a single independent permutation.
The problem of collaborative ranking, as we consider it here, is related to widely studied problem of collaborative fi ltering as for-malized through matrix completion , where we observe some rat-ings of items by users and would like to use these to predict the ratings of users on items they have not yet rated. Matrix factoriza-tion approaches have long been used collaborative fi ltering prob-lems [11 , 23], including using the trace-norm and max-norm [ 27] as well as other related matrix factorization regularizers. Active queries have also been investigated in this context, with heuristics suggested based on the expected value of information (EVIQ) [ 5]or the prediction margin [ 22], as well as using a Bayesian approach [14].

The main difference between standard collaborative fi ltering and the problem studied here, is that in the standard setting single-item ratings are observed, providing absolute information about a sin-gle entry in the unknown matrix. In contrast, we consider learning from pairwise comparisons, where we can only obtain relative in-formation comparing two items. Our goal is also different, in that instead of seeking accuracy of speci fi c ratings, we seek to capture a permutation for each user. Recent research [ 3, 32, 30] has also studied the problem of ranking in a collaborative fi ltering setup, but the objective of this work has been to optimize global ranking measures, such as NDCG or MAP. Moreover, their inputs are still rating scores, rather than pairwise information.
In order to reduce the query complexity of ranking from pair-wise comparisons, and allow learning permutations with less than m comparisons, we must use some external information and make assumptions on the permutation to be learned. [12] suggest asso-ciating with each item a a feature vector v a  X  R d which encodes our prior information about a . Thinking of the feature vectors as points in R d , a permutation is then speci fi ed as a direction in jected to this direction. Representing the direction in space as a vector u  X  R d , the permutation  X  u associated with u is de fi ned by  X  u ( a ) &lt; X  u ( b ) iff u, v a &lt; u, v b (we assume that general position relative to the vectors v , i.e. that for no two items a, b , u, v a = u, v b ). Alternatively, one can think of ifying a point in R d and order items according to their distances from u :  X  u ( a ) &lt; X  u ( b ) iff u  X  v a &lt; u  X  v b the norm or by the projection are equivalent if u and all vectors are normalized (i.e. on the unit sphere), and otherwise the differ-ence between them amounts to adding one additional dimension. Although [ 12] focused mostly on ordering by distance, here it will be more convenient for us to order by projection.

In either case, for a given feature map, only a subset of permuta-tions can be represented this way, allowing a signi fi cant reduction in the query complexity if we focus only on such permutations X  [12]showedhow O ( d log m ) adaptive queries are enough for learn-ing the optimal permutation (among permutations of this form).
One can think of the feature map as specifying an embedding of items into a possible  X  X reference space X , with different axes speci-fying different attributes one might prefer or not prefer, and a direc-tion u in this space specifying the preferences over these attributes, whichinturnde fi nes the preferences over items. The query com-plexity is then proportional to the dimensionality, or number of  X  X t-tributes X , d , instead of to the number of items m .

But the approach of [ 12] is still limited to a learning a single permutation at a time. Furthermore, the reduced query complexity relies on external information in the form of the feature embedding v .[12] did consider scenarios with individualized permutations, where each of many users has a different permutation over items (e.g. beer preferences in their application). But their proposed ap-proach was to fi rst obtain good features for each item using some external information source (in their case, the text of product re-views and descriptions) and then learn the permutation  X  i user i separately, using only pairwise comparisons by this user based on the fi xed feature maps. Here, we would like to avoid us-ing a pre-determined feature map based on external information, and instead learn this map de novo by considering all users jointly, and leveraging information gl eaned from one user X  X  comparisons to improve the ranking of other users.
As in the model discussed above, we associate with each item a a vector v a  X  R d and with each user a vector u i  X  R d ,such that the permutation for user i is speci fi ed by  X  i ( a ) &lt; X  u i ,v a &lt; u i ,v b . However, instead of basing the model on pre-speci fi ed feature vectors v a , we do not assume any prior knowledge on the items. Rather, following a collaborative approach, we joint-ly learn both the user vectors u i and and item vectors v the item vectors v a are learned, the permutation for any single user is not constrained, unlike [ 12]. However, having observations on multiple users constrains the possible setting of the item vectors and thus constraints the relationship between the multiple permu-tations. In other words, based on the observed comparisons from multiple users, we are learning the population space of possible per-mutations, which in turn allows us to learn individual permutations with signi fi cantly fewer observations.  X  i ( a ) &lt; X  i ( b ) iff X i,a &lt; X i,b . Requiring that requiring that it has rank at most d . We can thus consider perform-ing collaborative permutation learning as searching for a low-rank matrix X such that sgn ( X i,a &lt; X i,b ) matches our observed pair-wise comparisons, or at least matches as many as possible to our observed pairwise comparisons.

However, as was suggested by [ 9, 27], we instead consider an in fi nite-dimensional model, where the dimensionality d is unbound-Hilbert space, or simply allow them to be vectors in an arbitrari-ly high dimensional space), where we instead constrain the norms
U a,  X  2 , V b,  X  2 . Constraining the average squared-norm of these vectors corresponds to constraining the trace-norm (aka nuclear norm) of X , which is de fi ned as 2 : Similarly, constraining the norm of all vectors (i.e. constraining the maximal norm) corresponds to constraining the max-norm of de fi ned as: Both the max-norm and the trace-norm can be thought of either as convex relaxations to the rank [ 10], or as more re fi ned models, allowing an in fi nite-dimensional embedding, regularized through norm-regularization rather than a parametric constraint as in, e.g., Support Vector Machines [ 27]. Either way, in order for the norm-regularization to be meaningful, we must require not only that X i,b whenever we observe  X  i ( a ) &gt; X  i ( b ) , but that the inequality holds with a margin . And in order to allow for noisy or inconsistent observations, instead imposing a hard margin constraint, we seek to minimize an empirical hinge loss ,de fi ned below, which penalizes the extent of margin violations.

Let S :( i 1 ,a 1 ,b 1 ) , ( i 2 ,a 2 ,b 2 ) , ..., ( i |S| observed pairwise preferences, where ( i, a, b ) represents the com-parison of user i prefers item a over b . |S| is the total set of ob-served pairwise comparisons. The empirical hinge loss of then de fi ned as: And our training objectives, w ith the trace-norm and max-norm respectively are: min where  X  is a regularization tradeoff parameter.

Both the trace-norm and max-norm are semi-de fi nite-representable [9, 27] and thus both problems above can be rewritten and solved as semi-de fi nite programs (SDP). This allows us to use standard SDP 2 The trace-norm of X is also equal to the sum of the singular values of
X , but we prefer thinking in terms of the matrix-factorization characterization of the trace-norm solvers. However, in order to handle large-scale problem, special-purpose fi rst-order optimization methods are required. Fortunately, in the past few years, there has been much progress in developing such methods for both trace-norm and max-norm regularized prob-lems, and in the next Section we describe the methods we use here.
In this Section, we describe the accelerated fi rst order methods we use to solve the optimization problems ( 3)and fi t our model-s. For both the trace-norm and the max-norm we adapt recently proposed accelerated proximal methods.
For trace-norm regularized collaborative permutation learning, we use an accelerated version of Singular Value Thresholding (SVT): SVT optimization [ 6] consists of iterative updates corresponding to the optimization of a partial linearization of the objective function, where loss is linearized but the regularizer is not:
Such an update can be performed by soft-thresholding the singular-composition at each iteration [ 6]. For a smooth loss function, such updates can be accelerated by combining two sequences of iterates X k and Z k ,asin[ 18, 20]. Although our objective function is not s-mooth, empirically we found that accelerated gradient methods can usually obtain better convergence than simple gradient descent for our problem. In particular, each iteration consists of the following updates: where the SVT operator is de fi ned as: SVT  X  ( X )= U  X   X  where X = U  X  V T is the singular value decomposition of X ,and ( X   X  ) i,i =max { 0 ,  X  i,i  X   X  } ,and  X  k is the parameter recursively de fi ned as  X  k +1 = 1+
For the max-norm, we cannot take this approach, because the minimum of a quadratic function plus a max-norm regularizer is not given analytically in terms of the SVD. Instead, we take the prox-imal iterative smoothing (PRISMA) technique proposed by [ 19], where the goal is to solve a convex optimization which decompos-es into three parts: a smooth part, a simple Lipschitz part, and a non-Lipschitz part. Although the pairwise hinge loss functions in max-norm regularized CPL problems are not smooth, we can also apply PRISMA to our problem because our objective function is . This problem can be rewritten as: n ) positive semi-de fi nite matrices (zeros inside S m + n + outside).

To apply PRISMA for this problem, we learn A, B, X simulta-neously as a ( m + n )  X  ( m + n ) matrix (we denote it as each step, we fi rst perform a gradient descent step on the function  X  L hinge ( X ) , then add the proximal operator solution of the function max diag ( Z ) , and then perform a proximal operator of the func-equivalent to the proximal operator of the  X   X  on the diagonal vector of the matrix Z , which has closed-form solution [ 8], and the proximal operator of  X  S m + n eigenvalues of Z to zero. Thus the core updating steps are: where DVT is the diagonal value thresholding operator: DVT and EVT is the Eigenvalue thresholding operator obtained by set-ting all negative eigenvalues to zero.
In this section we discuss some active learning strategies for col-laborative permutation learning. Although our goal is to create a system that actively makes queries to all possible pairs, for presen-tation clarity we cons ider the setting of pool-based batch mode ac-tive learning [ 26]. Suppose at learning stage t , we already have our learned model X t , as well as a candidate pool P t = { ( i, a, b ) then need to ask users to reveal their comparison labels for a small batch of instances Q t +1  X  X  t , and add these new training data to our current training set S t . Then we re-train the model using the combined training set S t +1 = S t  X  X  t +1 to obtain improvement.
The baseline solution is uniform sampling where we randomly sample instances in P t uniformly. We can also adopt some active ranking methods for si ngle permutation learning in our setting: as inspired by [ 12], which actively query only the  X  X mbiguous X  pairs for labeling.  X  X mbiguous X  is de fi ned as the pair that can not be im-puted from known pairwise comparisons based on the consistency assumption. (Suppose we know  X  X  X  is preferred to  X  X  X ,  X  X  X  is pre-ferred to  X  X  X ; pair  X  X  X  and  X  X  X  is not an  X  X mbiguous X  pair because we can transitively impute that  X  X  X  is preferred than  X  X  X ). We can use this approach in our setting: we uniformly sample  X  X mbiguous X  pairs for all users independently.

For our proposed approaches, the margin provides important in-formation about the uncertainty of our learned model on the data. [29] proposed to actively query the instances with smallest mar-gin for Support Vector Machines (SVMs), and [ 22] adopted this strategy and showed it X  X  effectiveness for maximum-margin ma-trix factorization [ 27]. Likewise, we can use similar ideas to s-elect pairs with the smallest difference in their estimated scores: f ( i, a, b )= | X t i,a  X  X t i,b | .

Since our goal is to interactively estimate the model from data, when the model is inaccurate, the margin information could be mis-leading. As a result, we propose a stochastic sampling alternative. Given a temperature parameter T t , we randomly sample query in-stances with probability proportional to p ( i,a,b ) = e  X  Thus we favor instances with smaller margin. At the beginning, we set the temperature high, which means we select instances tending to uniform randomness, and then we decrease the temperature dur-ing the learning process. In this way, we are more con fi dent about our model and bias toward more of the instances with small mar-gin. 1 described the detailed process of our proposed  X  X PL-Margin Sampling X  algorithm. Algorithm 1 CPL-Margin Sampling  X  Algorithm of active col-laborative permutation learning from pairwise comparisons
Initialization : The initialized model X 0 at time 0 . for t =1 , 2 ,... do end for
In this section we provide some theoretical analysis of the pro-posed algorithms. Suppose the true permutations are generated by the underlying matrix X  X  , we can de fi ne the expected loss for any matrix X : L (
X )= and the empirical loss for matrix X : and the expected hinge loss for matrix X : where l hinge ( i, a, b )max(1  X  ( X i,a  X  X i,b ) , 0) and the empirical hinge loss for matrix X :
The following theorems give generalization guarantees for the proposed collaborative permutation learning models.

T HEOREM 1. Let X max [ A ] be the set of matrices that with bound-ed max-norm A . Then for any  X &gt; 0 , with probability at least 1  X  over the choice of a sample S , for every X  X  X  max [ A ] , the follow-ing holds: Proof Sketch. We treat the matrix X as a function [ n ]  X  and use existing bounds on the Rademacher complexity [ 4]ofma-trices with bounded trace-norm or max-norm [ 28, 10]. The main difference here is that the instances, and hence the loss, depend on two , rather than only one evaluation of X . Nevertheless, this only results in an increase by a factor of two in the Rademacher com-plexity of the loss class, and we can use standard arguments for obtaining uniform concentration and generalization guarantees as a function of the Rademacher complexity.

And we get the following generalization bound for trace-norm based methods:
T HEOREM 2. Let X  X  [ A ] be the set of matrices with bounded trace-norm A . Then there exists a constant K , for any  X &gt; 0 probability at least 1  X   X  over the choice of a sample S , for every X  X  X   X  [ A ] , the following holds: L ( X )  X   X  L hinge ( X )+4 K
C OROLLARY 3. Suppose X  X  is rank-r with bounded entries, let X max ( S ) be the max-norm regularized empirical loss minimiz-size Proof Sketch. By error decomposition L ( X max ( S )) = L (  X  L combining the fact of empirical loss minimizer, as well as basic mean inequalities.
 Remark. If we further assume that the true scoring matrix suffer-s 0 hinge loss, i.e., that the following realizable condition holds:  X  L hinge ( X  X  )=0 ,weget L ( X max ( S ))  X  , which means we obtain approximate recovery of all the permutations with -error.
Similarly, for the trace-norm regularized solution, we obtain the following result:
C OROLLARY 4. Suppose X  X  is rank-r with bounded entries, let X  X  ( S ) be the trace-norm regularized empirical loss minimiz-er: X  X  ( S )=argmin X a constant K , with the sample size |S|  X  32 K 2 r ( n + m with probability at least 1  X   X  , we have Remark. By comparing the sample complexity of regularized CPL with trace-norm versus max-nor m, we can see that max-norm is slightly superior by avoiding a log n factor, which is consistent with the analysis of classical collaborative fi ltering problems [ 28].
In this section, we conduct a set of experiments to demonstrate the effectiveness of our proposed approaches.
We test the performance of various algorithms for the CPL task on both real-world and synthetic data sets including actual pairwise comparison surveys, including the following:
Table 1 summarizes the statistics associated with these data set-s, and shows that our data contains pairwise comparisons ranging up to several million. We measure the performance of algorithm-s using mean Kendell-Tau distance (MKTD), a generalization of Kendell-Tau distance to our multiple permutations setting. Kendll-Tau distance is widely used in single permutation learning evalua-tion [ 12] as it measure the fraction of pairwise preferences from the true permutation  X  recovered by the learned permutation  X  s n ranking lists:  X  1 , ... X  n , given a ground truth set of test pairwise preferences S , the MKTD is de fi ned as: http://www.kamishima.net/sushi/ http://allourideas.org http://blog.allourideas.org/post/16175975017/ http://movielens.umn.edu http://grouplens.org/datasets/hetrec-2011/ We test the performance of our model on the entire data set, and evaluate performance with a learning curve.
This set of experiments is designed to demonstrate how collabo-rative information is useful for our task. We compared the proposed CPL with a set of single permutation learning methods, includ-ing the following two that represent rank aggregation approaches: Borda Count [7]and Balanced Rank Estimation [31]. Because there are no natural active learning strategies for these approach-es, we compare all algorithms to a uniform sampling of queries for fair comparison. We tune the  X  parameter in our algorithms from { 2  X  10 , 2  X  9 , ... 2 10 } for all data sets. Note that we can use rank ag-gregation methods to learn multip le rankings: each user has one, and we can follow the traditional rank aggregation setting which learns a global ranking list. We add  X  X ingle X  to denote the latter in the fi gures 8 .

Figure 1 show the learning curves associated with our algorithm-s on various data sets. When comparing with Borda Count and Balanced Rank Estimation, we found that they perform reason-ably well, and Balanced Rank Estimation usually performs slightly worse than Borda Count; When comparing the ranking aggrega-tion method which learns multiple and single rankings, we fi nd that the multiple rankings approach us ually performs better, although s-ingle permutation methods might perform better in circumstances where we do not have enough observed data; when comparing the previous method with our collaborative approach, we can see that our algorithms performs signi fi cantly better. Finally, our method can improve rank aggregation approaches more on the voting data when we have more observations (Vote200 case), which illustrates the intrinsic dif fi culty of collaborative ranking on highly sparse and noisy data sets.
Knowing that CPL methods are superior, this set of experiments compares various active learning strategies. We compare the fol-lowing methods: i) Uniform Sampling ; ii) Active Ranking :as proposed in [ 12] for single permutation learning, note in our set-ting there are no given features for items, thus we perform a re-duced SVD of our learned score matrix X = U r  X  r V T r , and use as features for the items; iii) SRRA : the Smooth Relative Regret Approximation method proposed in [ 2], which suggests uniform sampling of the pairs for which rank position differences are with-in a certain range, as suggested by [ 2]. At fi rst we narrow the range by 2 (which means we query the pairs with rank position differ-ences of at most 2), then we double this range at each query stage; iv) Simple Margin : deterministic selection of pairs with the small-est margin; v) Margin Sampling : For simplicity, we begin with the following temperature attenuation scheme as T t = 1 t is the learning stage. Since Active Ranking [ 12] needs to solve two linear programming problems in order to decide whether a pair is  X  X mbiguous X , when the query pool is large (as in data sets with millions of pairs), the time cost becomes very high. Thus, we omit comparisons with Active Ranking on some large data sets. Figure 2 graphs the learning curves for various learning strategies. We can draw the following conclusions: i) Both Simple Margin and Margin Sampling perform signi fi cantly better than Uniform Sam-pling, which demonstrate the advantages that come from exploring a range of active learning strategies. While Active Ranking did not perform much better than Random Sampling, this is likely due HodgeRank [ 13], but they failed in our setting due to the sparse-ness of the observations to 1) The active ranking approach, which is designed for the single ranking problem and so did not utilize collaborative information; 2) The  X  X mbedding X  and  X  X onsistency X  assumptions are not adequate for these real world data sets, especially when the features are not given; but most critically 3) the data are sparse and we can only test our algorithms on questions that were actually posed to and an-swered by users. Moreover, the SRRA method does not work in our setting, which may source from the reasons why Active Ranking performed poorly. ii) When comparing Simple Margin and Margin Sampling, we found that Margin Sampling performs signi fi cantly better, especially at the beginning of the learning process. This is likely because at the beginning, the model learned is not accurate as the margin information is somewhat misleading and thus we prefer more randomness. As the model becomes more accurate, we can put more trust in the margin information.
In this section we compare our proposed active collaborative per-mutation learning system(CPL+Margin Sampling) with some tradi-tional rank aggregation methods, equipped with single permutation based active learning approaches. Figure 3 summarizes our results. We can see a signi fi cant advantage of our system over tradition-al approaches. SRRA based active methods cannot do better than uniform sampling in our collaborative setting, which further vali-dates the emerging requirements of our collaborative permutation learning techniques on multiple permutation learning problems.
The following experiment uses simulation on the sample com-plexity to evaluate our proposed methods. As shown in our theoret-ical analysis, under reali zable condition, we only need O ( r pairwise observations to recover the multiple rankings list to er-ror. We aim to validate the linear growth rates in our proven sample complexity bound. For simplicity, we set # users =# items = generalize two n  X  5 matrices U, V , where every elements of the two matrices are i.i.d. generated by a uniform distribution over [0 , 1] , then we multiply these two matrices to form an n matrix, which is rank-5 , and generate all pairwise comparisons ac-cording to the rating. Then, we test the MKTD on pair with margin at least 0.2(since we require realizable conditions for our analysis). We test the samples required to approximately recover %97 of the whole pairwise preferences, test the CPL method using both unifor-m sampling and margin sampling strategies, and also compare with the single permutation learning methods. Figure 4 shows the sam-ple complexity when n grows from 100 to 300 .Intheleft fi gures, we see that the sample complexities of our methods look linear as grows, and CPL requires signi fi cantly less samples than tradition-al methods. When comparing the s ample complexities of uniform sampling and margin sampling, we found that margin sampling can usually reduce the samples needed, and it seems that sample com-plexity of margin sampling also grows linearly with n .Wealso compare the sample size needed for uniform sampling vs. margin sampling to achieve various -approximate recoveries when fi xing n = 200 ,asleft fi gure of 4 shows, the curves further validate the point that margin sampling does signi fi cantly better when we seek a very accurate solution.
In this section we compare the CPL with trace norm versus max norm. Figure 5 shows the curves learned by both trace-norm and max-norm regularized CPL algorithms. The basic observation is that trace-norm based methods and max-norm based algorithms usually perform similarly, and max-norm methods often perform-ing slightly better.
This experiment aims to study various temperature decreasing schemes for margin sampling. We consider the following gener-al temperature model: T t = 1 used in previous experiments where c =1 ,p =1 ,hereweal-so test several schemes by varying c and p : fi rst we fi x and vary p =0 . 5 , 1 , 2 , which represents sub-linear, linear, and quadratic temperature decreasing schemes, respectively. Moreover, we also adopt a  X  X erformance-driven X  strategy by setting the tem-perature according to the MKTD we achieve: T t = MKTD t (We denote this method  X  X uto X  in the fi gures). Figure 6 summarizes the results. We can see that our margin sampling strategy is ro-bust: it performs similar and quite well with different decreasing rates, when comparing different constant temperatures, we found that very low temperature tends to behave like simple margin(bad at the beginning), very high temperature tends to behave like unifor-m(bad at the end), adequate constant can performs reasonably well, although not so good as decreasing scheme. In addition, the pro-posed  X  X erformance-driven X  temperature scheme appears promis-ing. Thus, our margin sampling algorithms could be easily used in practical applications.
This paper studies the problem of collaborative permutation learn-ing from pairwise comparisons, both passively and actively. We demonstrated that collaborative information is important, and pro-pose to utilize collaborative information by matrix completion based algorithms. We then analyzed the generalization ability and sam-ple complexity needed for approximate recovery of our proposed algorithms, and empirically demonstrated that our methods perfor-m much better than traditional approaches. To reduce the number of comparisons required from users, we proposed various active learning strategies, and showed that active querying is very useful in reducing label costs. These approaches provide immediate appli-cation to a range of information retrieval and survey tasks. In par-ticular, we highlight their power for creating ef fi cient, just-in-time comparison surveys that can predict user preferences from small samples of comparisons.

We also identify several promising directions for further research, including: i) More scalable algorithms: we aim to apply our pro-posed methods on very large scale problems, where even the SVD is computationally prohibitive. Some existing large-scale trace-norm (and max-norm) optimization methods might be able to be adopted, e.g. [ 16]; ii) More theoretical analysis: currently we on-ly explore generalization ability and approximate recovery analy-sis, but interesting theoretical questions remain, including: 1) the sample complexity required for exact recovery of the permutations (which might require additional assumptions); 2) the gap between active learning label complexity and uniform sample complexity. [1] N. Ailon. An active learning algorithm for ranking from [2] N. Ailon, R. Begleiter, and E. Ezra. Active learning using [3] S. Balakrishnan and S. Chopra. Collaborative ranking. In [4] P. L. Bartlett and S. Mendelson. Rademacher and gaussian [5] C. Boutilier, R. S. Zemel, and B. M. Marlin. Active [6] J.-F. Cai, E. J. Cand X s, and Z. Shen. A singular value [7] J. C. de Borda. M X moire sur les  X lections au scrutin. Histoire [8] J. C. Duchi and Y. Singer. Ef fi cient online and batch learning [9] M. Fazel, H. Hindi, and S. P. Boyd. A rank minimization [10] R. Foygel and N. Srebro. Concentration-based guarantees for [11] T. Hofmann. Latent semantic models for collaborative [12] K. G. Jamieson and R. D. Nowak. Active ranking using [13] X. Jiang, L.-H. Lim, Y. Yao, and Y. Ye. Statistical ranking [14] R. Jin and L. Si. A bayesian approach toward active learning [15] T. Kamishima. Nantonac collaborative fi ltering: [16] J. D. Lee, B. Recht, R. Salakhutdinov, N. Srebro, and J. A. [17] S. Negahban, S. Oh, and D. Shah. Iterative ranking from [18] Y. Nesterov. A method for solving a convex programming [19] F. Orabona, A. Argyriou, and N. Srebro. Prisma: Proximal [20] T. K. Pong, P. Tseng, S. Ji, and J. Ye. Trace norm [21] A. Rajkumar and S. Agarwal. A statistical convergence [22] I. Rish and G. Tesauro. Active collaborative prediction with [23] R. Salakhutdinov and A. Mnih. Probabilistic matrix [24] P. Salesses, K. Schechtner, and C. A. Hidalgo. The [25] M. J. Salganik and K. E. C. Levy. Wiki surveys: Open and [26] B. Settles. Active Learning . Synthesis Lectures on Arti fi cial [27] N. Srebro, J. D. M. Rennie, and T. Jaakkola.
 [28] N. Srebro and A. Shraibman. Rank, trace-norm and [29] S. Tong and D. Koller. Support vector machine active [30] M. Volkovs and R. S. Zemel. Collaborative ranking with 17 [31] F. L. Wauthier, M. I. Jordan, and N. Jojic. Ef fi cient ranking [32] M. Weimer, A. Karatzoglou, Q. V. Le, and A. J. Smola. Co fi
