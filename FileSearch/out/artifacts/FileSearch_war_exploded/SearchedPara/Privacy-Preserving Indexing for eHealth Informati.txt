 The past few years have witnessed an increasing demand for the next generation health information networks (e.g., NHIN[1]), which hold the promise of supporting large-scale information sharing across a network formed by autonomous healthcare providers. One fun-damental capability of such information network is to support ef-ficient, privacy-preserving (for both users and providers) search over the distributed, access controlled healthcare documents. In this paper we focus on addressing the privacy concerns of content providers; that is, the search should not reveal the specific asso-ciation between contents and providers (a.k.a. content privacy). We propose SS-PPI, a novel privacy-preserving index abstraction, which, in conjunction of distributed access control-enforced search protocols, provides theoretically guaranteed protection of content privacy. Compared with existing proposals (e.g., flipping privacy-preserving index[2]), our solution highlights with a series of dis-tinct features: (a) it incorporates access control policies in the privacy-preserving index, which improves both search efficiency and attack resilience; (b) it employs a fast index construction protocol via a novel use of the secrete-sharing scheme in a fully distributed man-ner (without trusted third party), requiring only constant (typically two) round of communication; (c) it provides information-theoretic security against colluding adversaries during index construction as well as query answering. We conduct both formal analysis and ex-perimental evaluation of SS-PPI and show that it outperforms the state-of-the-art solutions in terms of both privacy protection and execution efficiency.
 Categories and Subject Descriptors: D.4.6 [Security and Protec-tion]: Access controls H.3.1 [Content Analysis and Indexing]: In-dexing methods H.3.3 [Information Search and Retrieval]: Search process General Terms: Security Algorithm Keywords: Privacy preserving protocol, keyword search, distributed indexing
Many healthcare providers, payers, and pharmaceutical compa-nies have increased their use of eHealth solutions to manage health-related information and to automate administrative and clinical func-tions. We are witnessing an increasing demand for the next gener-ation health information networks, which hold the promise of pro-viding large-scale information sharing over distributed, access con-trolled content across a network of healthcare providers. A repre-sentative example is the work currently under way to construct the Nationwide Health Information Network (NHIN) [1] that supports information sharing among more than 20 federal agencies, along with numerous private hospitals and doctors X  offices. A fundamen-tal capability of such information network is to provide privacy-preserving search over distributed, access controlled content.
More specifically, individual healthcare providers typically en-force strict regulations over the healthcare information for a num-ber of reasons, such as patients X  privacy requirements, conflicting economic interests, and federal administration; meanwhile, the ca-pability of efficiently identifying and retrieving relevant content across healthcare administrative boundaries is crucial for the health-care information network to improve care quality, emergency re-sponse, and diagnosis accuracy. This poses the question of how to facilitate effective search while minimally revealing which providers possess which content (i.e., content privacy).

A naive approach to achieve privacy-aware search is query broad-casting: each query is forwarded to all the participating providers; those providers with matched content may then contact the querier directly. Content privacy is best preserved in this manner, since no sensitive information is required to route the query. However, such global-scale probing is not scalable with respect to the num-ber of providers, in terms of both communication bandwidth and query latency. In the case of selective queries that most providers do not have matched content, broadcasting results in huge waste of communication and computation resources.

Alternative is to use a centralized index server (in implementa-tion which can be readily replicated) that holds an indexing struc-ture to facilitate the query routing. Query efficiency and scalability is attained for each query is only re-directed to providers which are bound to have matched contents. However, to construct the indexing structure, which is publicly accessible, typically requires providers to fully expose their content possession information. In this sense, the centralized index server must be trusted by all partic-ipating providers in its behavior. In healthcare applications, how-ever, not only the enormous trust is impractical for providers with conflicting interests, but also the centralized architecture is vulner-able to security attacks and suffers from single point of failure.
The first Privacy Preserving Index (PPI) was proposed in [2] to strike a balance between privacy preservation and search efficiency. We refer to this approach as flipping PPI. It leverages an abstraction of group-wise index, by which providers are organized into a set of disjoint privacy groups . 1 Content privacy is preserved in the sense that providers in the same group are indistinguishable. Query dis-semination is performed at the granularity of privacy group. Within a privacy group, a given query is forwarded either to all providers or to none of them, depending on whether there exists (at least) one provider with matched content. Flipping PPI is known to suf-fer from index construction inefficiency, due to the large number of rounds of PPI computation, and is vulnerable to colluding attacks.
W e use  X  X rivacy group X  and  X  X roup X  interchangeably when no confusion occurs. In sum, we argue that existing privacy preserving index and se arch protocols suffer from the following drawbacks:
In this paper, we propose the concept of role-sensitive PPI and a secure protocol for fast construction of PPI based on the primitives of secret sharing. We entitle this concrete implementation of our role-sensitive PPI as SS-PPI. Given a query in conjunction with the role of the querier, our role-sensitive PPI returns the groups of providers that potentially hold the content that matches the search term for this role. Both privacy preserving and search efficiency are attained on a finer-granularity level. Since our PPI abstraction is defined on fine granularity (role sensitive), we preserve content privacy as well as access policy privacy at the same time. This new type of privacy protects the sensitive information in provider-defined access rules, such as to which role provider p has granted access. To the best of our knowledge, this paper is the first one ad-dressing the privacy of access policy in the PPI framework. Tech-nically, our index construction protocol (SS-PPI) makes a novel use of secret sharing without requiring third party involved, which comparing to existing secret-sharing schemes sees better scalabil-ity. It is efficient in the sense that all  X  X ecret shares structed in a distributed, parallel manner with constant complexity of computation and communication. In particular, it finishes in 2 stages, each expected to take 1 time unit (for reasonable setting of group size n , like 1 k ). More importantly, our SS-PPI protocol achieves information-theoretic security against colluding attacks. For less than 2 c  X  2 adversaries in the network, any provider X  X  pri-vacy is not leaked , where c is a system parameter.
P ackets and shares are used interchangeably in the following pa-per.
T he remaining of this paper is organized as follows. Section 2 presents the overview of our system, and Section 3 elaborates privacy-aware index construction protocol. Security analysis is given in Section 4. Experimental results are shown in Section 5. Finally, Section 6 surveys related work and Section 7 concludes this paper.
In this section, we formally describe the system architecture, our role-sensitive PPI and then overview the secret-sharing based pro-tocol for index construction.
We first give an overview of our targeted multi-source informa-tion sharing infrastructure, as shown in Figure 1. The infrastructure mainly involves three entities, including a set of autonomous infor-mation providers, an index server, and a set of queriers (or users who consume the information) 3 .

Each provider holds at its depository a set of documents and has self-specified privacy requirements and regulations. The set of in-formation providers jointly provide information search for users. And each provider itself is responsible for search processing (at a finer granularity) and data retrieval. This way, each provider is able to determine the disclosure of information to the correspond-ing querier at its discretion. Specifically, provider p possesses a de-pository of private documents, D ( p ) , on which a role-based access control policy is enforced. We assume that each document d can be described by a set of content descriptors (CD), denoted by T ( d ) [6] (e.g., keywords), from a finite set of CDs T . Provider p can sum-marizes its local data and access policy by bitmap b ( p ) , where each column is associated with a role o and each row with a content de-scriptor or term t . The cell at column o and row t is a bit, with 1 meaning provider p has one or more documents matched to term t and accessible to subject role with o , and 0 otherwise. The bitmap b ( p ) is intended for being published to the index server. Also, each provider optionally maintains a local indexing structure I regarding its documents to facilitate local search and access enforcement.
A querier searches information by issuing queries and present-ing her roles. A query q is represented by a set of CDs, denoted by T ( q ) and querier X  X  roles O ( q ) . Document d satisfies query q if T ( q )  X  T ( d ) and d is accessible to certain role in O ( q ) . From the local bitmap X  X  point of view, provider p can answer query q if for every row in T ( q ) , there are at least one cell that is 1 for all columns in O ( q ) . In the framework, a query is successfully answered if all the information providers that possess documents satisfying the query receive the query. It is at the discretion of the corresponding information providers to enforce access to the rele-vant documents (retrieval), which may involve further steps such as charge negotiation. In this paper, we focus on the phase of infor-mation search.

Overall, a query q can be answered in the following steps, as shown in Figure 1. The querier sends query q consisting of T ( q ) and O ( q ) to the index server, (step (1)), which by looking up the public privacy preserving index I p returns the identity information of the corresponding providers G (step (2)). The querier then issues q to these providers (step (3)), who at their discretion contact the querier and provide access of documents d that satisfy q (step (4)).
F ollowing, we use  X  X uerier X  and  X  X ser X  interchangeably.
I n a typical PPI system, there are privacy of various information needed to be protected, including content privacy, policy privacy and query privacy, among many others. While query privacy, which involves with searcher X  X  identity being kept from disclosure, can be protected by anonymity protocols (e.g. [20, 18, 17]), content privacy and policy privacy are the ones we primarily address in this paper. Following flipping PPI [2], we define content privacy as below, Definition Given provider p and term t , content privacy is defined to be information about provider p  X  X  possession of certain docu-ment containing sensitive term t . Content privacy is leaked when one party without access to provider p can claim with certainty if provider p possesses term t .
 In addition to content privacy, we identify the access policy privacy in generic PPI systems, since our published index is fine-grained and incorporates the access policy information in it. The formal definition is introduced as follows, Definition Given provider p and role o , access policy privacy is defined to be the information about p has granted access to o on certain document that provider p holds. Policy privacy is leaked when one party without access to privoder p can claim with cer-tainty if provider p grants access to users with role o . In our architecture, a querier is expected to report her true role, but also allowed for falsely reported roles, namely the one she is not associated with. No authentication or access control are en-forced, on our public, untrusted index server. Our role-sensitive PPI is well-designed that querier reporting true role obtains a list of providers that cover full set of query answers, and that querier falsely reporting her roles receives a somewhat meaningless list of providers from which she can X  X  deduce any sensitive knowledge in terms of content privacy and policy privacy.
Motivated by the deficits of existing solutions in facing large-scale multi-source information sharing infrastructures, we propose SS-PPI, a novel indexing scheme that supports information net-work comprising thousands of content providers, and provides the-oretical guarantees on both possession privacy protection and exe-cution efficiency.

The framework of SS-PPI mainly consists of two phases, index construction and query answering. The former further processes in three major components, group formation, group aggregation and global index construction.
In this section, we present in detail the phase of privacy-preserving index construction in SS-PPI. It entails three main components; group formation, secure group aggregation, and global index con-struction.
Group formation is the process that organizes providers into dif-ferent privacy groups. In the design of a good formation strategy that strike a balance between search efficiency and privacy preserv-ing, group term selectivity is critical. Group term selectivity refers to the ratios of providers in a group that possesses the term to the group size. The less group-wise selective a term is, the harder an adversary can pinpoint a provider that possesses a specific term, thus better privacy preserving. On the other hand, less group term selectivity implies queries are forwarded to more providers with no answer, thus more bandwidth overheads. For a given group size, the goal of group formation is to make all indexed terms reach an expected values in group selectivity.

We follow in this paper the conventional approach, that is, ran-dom grouping (e.g. [2]), which randomly assigns providers to groups. Group size is a critical factor to utility and privacy preserving of published index. When group size is configured to be too big, it could easily make the group-wise index degrade to query broad-casting. Consider a group of size n and a term with global selectiv-ity q , the probability for a group to be negative (i.e., no providers in it having the term) is (1  X  q ) n . This value quickly approaches 0 as n grows, regardless of value of q . For example, when q = 0 . 5 , n = 10 , the value is 0 . 1% , and when n = 20 , the negative probability becomes 10  X  6 , implying all groups are positive ones and query broadcasting is thus required. On the other hand, when group size n is configured to be too small, privacy could easily be leaked since the possibility for providers in one group to all be positive is q n which is fairly large for small n . As shown in exper-iment part, we empirically set the value of group size and show its effectiveness.
After the privacy groups are formed, one needs to aggregate the group-wise term-possession index. The technical goal is to protect individuals X  privacy during the process in which group-wise index is formed. That is, one can not guess with confidence higher than what final aggregated index discloses. In particular, we address two technical goals,
With regards to the above goals, existing protocols show flaws in a way or two. One conventional scheme is flipping PPI X  X  iterative randomized algorithm. However, it is time-inefficient; it requires to run multiple iterations before the final group index reaches certain level of accuracy. This problem is compounded when group-wise index is frequently updated, resulting in prohibitively high cost for re-constructing the indexing structure. More importantly, its pub-lishing process is vulnerable to colluding attacks, specially in the case of an innocent provider ending up with its predecessor and successor both being malicious. Another possible technique can be used is the generic secure multi-party computation [6] which con-sumes considerable computation overheads.
I nspired by the observation above, we propose a secret-sharing based scheme for fast and secure index construction. Our novel secure group aggregation scheme is based on an extended secrete sharing protocol [19], which achieves constant communication cost in group aggregation and provides strong privacy protection. Within each group, group aggregation collects the statistics of the pos-session of providers in the group with respect to each query term and access role. We assume that the providers have already been grouped and placed into in group-wise overlay. Without loss of generality, we consider a specific group comprising a set of providers p , p 1 , . . . , p n  X  1 , each holding a private value v i called sub-secret , corresponding to a specific term and access role The output, called super-value v , is the number of providers with v = 1 , that is, where the super-value v can span from 0 to n . Our protocol com-putes the super-value accurately and securely. Each involved provider works in four stages: generates sub-packets for sub-secret, dis-tributes sub-packets, computes super-packets from received sub-packets, and aggregates the super-packets to form super-value. Next, we discuss the four stages in details.
In this stage, each provider p i splits its sub-secret v i packets u i,j , such that their modulo sum equals v i , formally, where q is the modulus with q  X  n , and each sub-packet u defined on the packet domain Z q . The packet-generating process generates a ( c, c ) -secret packets; that is, given any less than c sub-packets, the sub-secret v i is still completely undeterminable. A set of implementations are available to generate the sub-packets this paper, we select the simplest one: randomly and independently let the last one be u i,c = ( v i  X  P c  X  1 j =1 u i,j ) mod q . In Appendix, we prove this is a ( c, c ) -secret sharing in Theorem A.1.
We assume that the providers in a group are structured into a ring-like overlay, as illustrated in Fig. 2. In the overlay, each provider p has c  X  1 neighbors in the clockwise direction, p h ( i, 1) where h ( i, j ) denotes the index of the j -th neighbor of p directional secure channel is set up on each neighboring connec-tion. Provider p i also has c  X  1 neighbors in the counter-clockwise notes the index of the provider whose j -th clockwise neighbor is p , that is, h ( h  X  ( i, j ) , j ) = i . In total, each provider knows 2 c  X  2 neighbors in the group, and unaware of the rest X  X  positions. In par-ticular, the 0 -th neighbor of p i is itself, i.e., h ( i, 0) = i . A variety of instantiations of h ( , ) are possible. At this point, for simplicity,
A s will be discussed later, the aggregation process of v ent terms and roles can be combined together and related messages can be piggybacked.
For example, Shamir X  X  secret sharing[19] is a possible way to generate u i,j in the form of Equation 2. Specifically, for sub-secret v i , we randomly generate a polynomial g i ( x ) , s.t. g v . Also there are c input values x j  X  X  ( j  X  { 0 , 1 , . . . , c  X  1 } ) that are globally-agreed on. Applying x j on g i , we have y i,j = g i ( x j ) . Applying Lagrange Interpolation, v i = g P tion 2 (without modulo operation, though). we assume h 1 ( i, j ) = i + j mod n , that is, p i take the nearest-( c  X  1) providers to be its neighbors. For instance, in Fig. 2, p knows p 1 , p 2 , p 6 , p 7 and no more; p 0 knows p 6 because mutual communications are required when p 6 is to set up a secure channel with p 0 .

Provider p i proceeds to distributing the sub-packets to its neigh-first sub-packet u i, 0 is always kept locally on p i . During this stage, all communication are through the secure channels; that is, they are encrypted and authenticated. Messages from different providers are sent asynchronously and in parallel, and thus consuming O (1) time-unit. Figure 2: Overlay of secret packet distribution (with c = 3 , n = 8 )
While sending out sub-packets, providers also receive sub-packets from other providers. Specifically, p i receives from its previous neighbor p i  X  j sub-packet u i  X  j,j , where 1  X  j  X  c  X  1 . p sum them up, together with its local sub-packet u i, 0 , to get the super-packet u i , Thus, u i, 0 = ( u i  X  P c  X  1 j =1 u i,j ) mod q . Combining it with Equa-tion 2, we get, v i = ( u i  X 
Interestingly, Equation 4 defines a (2 c  X  1 , 2 c  X  1) secret shar-ing scheme, as will be proved in Theorem 4.1. It implies that even with 2 c  X  2 packets, the secret value v i is still completely unde-terminable. Note that each input sub-packet in Equation 4 corre-sponds to a distinct remote provider, e.g., u i  X  c +1 ,c  X  1 from p i  X  c +1 , u i +1 is sent to p i +1 , and so on. When the group size n is large, e.g., containing at least 2 c  X  1 or 2 c  X  2 providers (depending on how u i is aggregated, as below), our protocol is re-silient to collusion attacks of up to 2 c  X  2 or 2 c  X  3 malicious providers in the group.
In the last stage, super-packets from all providers are aggregated to form super-value u = ( u 0 + u 1 + + u n  X  1 ) mod q . In our implementation, we adopt the most time-efficient one: every provider p i sends u i to a special provider, say p 0 which is then responsible for summing up all u i  X  X . The final results u will be sent to index server as part of the privacy preserving index. The whole process is sketched in Algorithm 1. Algorithm 1 i ndex-construction(provider p i , sub-secret v 1: {Generating sub-packets} 2 : for all j  X  [0 , c  X  2] do 3: u i,j  X  random number in Z q 5: {Distributing sub-packets} 6: for all j  X  [1 , c  X  1] do 7: p i sends u i,j to provider p i + j 8: {Computing super-packets} 9: for all j  X  [1 , c  X  1] do 10: p i receives u i  X  j,j from provider p i  X  j 12: {Aggregating super-packets} 13: p i send u i to p 0 ( p 0 will then sum up all received super-Example . C onsider four providers with security parameter q = 5 , c = 3 . In the first round, every provider p i starts with splitting her sub-secret v i into c = 3 sub-packets. For instance, on p v 1 = 0 = (2 + 3 + 0) mod 5 , where the first two numbers are randomly distributed in domain Z q = { 0 , 1 , 2 , 3 , 4 } . Then, p sends out the sub-packets, e.g., 0 to p 3 , 3 to p 2 , but 2 kept locally. At the same time, p 1 receives sub-packets from other providers, e.g., 0 from p 3 and 1 from p 4 . Then p 1 sums up all these sub-packets to get the super-packet u 1 = (0 + 1 + 2) mod 5 = 3 . Other providers work in a similar manner, and they further send all super-packets to p 1 . At the end, p 1 sums up all super-packets (3 + 0 + 2 + 2) mod 5 = 2 .
Figure 3: Secret Sharing-based Index Construction Example
Our protocol outputs the correct value of v , namely, u = v , as below, u = The last step is due to that q  X  n , and v  X  { 0 , 1 , . . . , n } . Hence, in the final public index, for each provider having v i = 1 , the group will have aggregated sum v  X  1 , thus being present in the posting list. Completeness can be attained. Besides, we use posting-list intersection for multi-keyword query processing, thus query con-sistency is achieved; that is, the results of multiple-keyword query equals the intersection of all results of multiple single-keyword queries. In short, our protocol is correct.

Efficiency of our protocol can be analyzed in two aspects: the time latency and bandwidth overhead. Stage 1 of our protocol re-quires n c messages to be sent, and can finish within O(1) time-unit due to parallelism. The actual latency depends on the slowest provider in the network. In this stage, the bandwidth overhead also implies the costs of setting up secure channels. For second stage, the basic aggregation protocol can finish within O (1) time and with n messages.

Overall, the above protocol runs for one single term and one access role. To build PPI for multiple terms and access roles, it runs multiple single-term protocols, independently with each other. Specifically, the aggregation process carries a set of bitmaps or vec-tors, each vector corresponding to a role and each vector bit sum-marizing the possession information regarding to an indexed term. Sending and merging different bits or vectors can be piggybacked in the same messages and packets the same secure channel. By this way, time latency stays unchanged with growing number of indexed terms and roles.
The group-wise indices are not ready for direct use by the in-dex server to route queries, since they may, to some extent, vi-olate the content privacy of participating providers. It happens when a majority number of providers in a group hold a (set of) specific term(s), which makes it possible for the adversary to iden-tify the content possession of these providers with high confidence. Therefore, we need enforce another layer of protection before the global index is published. We achieve this by adjusting and merg-ing group-wise indices to quantitatively meet providers X  privacy needs. In the following, we will introduce a group merging process. This process is optional in our system, because it may requires a partially trusted coordinator. However, after merging, privacy pre-serving can attain certain quality as system/providers want. It is noteworthy here that security of the coordinator can be strength-ened by making it periodically offline [13].
The goal of our adjusting/merging process is to guarantee each group g has positive providers with respect to each term lower than a threshold q n ( g ) , where n ( g ) is group size and q is a predefined privacy parameter. We consider a centralized coordinator which collects the group-wise indices and merges them to address the par-ticipating providers X  privacy in a best-effort manner. For example, for term t , coordinator will find the group with the most positive providers g and the one with the least positive providers g  X  contains more positive providers than the threshold, the coordina-tor merges g with g  X  such that the percentage of positive providers percentage of positive providers regarding to term t . If the merged percentage is still too big, that is, bigger than q , the merging process continues to merge with the group currently with smallest T he whole process stops when the merged percentage drops below q . . For multiple terms, we define a metric  X  ( g ) for group g ,
W e address the global meta-information, like the number of pos-itive providers, can be leaked since it does not disclose any infor-mation on which provider is positive.
The stop condition must be met in certain iteration, for we assume the threshold q is bigger than global term selectivity. It is a rea-sonable restriction, since otherwise even query broadcasting can X  X  make all group-wise percentage of positive providers be smaller than term selectivity. where S T is the subset of terms that are privacy-sensitive, defined by providers. For multiple terms, in each iteration, we try to merge group g with lowest  X  ( g ) , and the rest similarly runs. In practice, in case that there is no trusted coordinator, one can omit this process and privacy preserving is attained in a best effort way.
The group-wise index of each group is combined into a single global index. A na X ve way is to let each group send her index to the centralized index server and to combine locally there. In this scheme, the percentage of positive providers in each group is then known by the index server, which however is sensitive informa-tion. In order to avoid this privacy breach, we adopt the privacy-preserving protocol [22] to output posting index ordered by positive percentage but without publishing the percentages. To further save the query processing costs, one can only publish Top-K groups with most positive providers, where K is a system parameter. De-pending on the value of K , this strategy makes a trade-off between query performance and result recall. For example, small K can result in more efficient query processing, but not more effective. That is, query recall may be harmed, since certain results appear in bottom of the ordered posting lists. In practice, K should be set according to users X  demands on result quality and system resource budget.
In real systems, data may be frequently updated and new providers may come and leave. A naive way to handle this update is to re-build our privacy preserving index from scratch every time an up-date occurs. For index update efficiency, we adopt an incremental, batch-oriented update approach. Whenever there are t providers that newly join or locally updates their index, we re-run the index construction protocol among the updated providers. Thus, updates can not be tied to any specific provider out of t . In addition, since we add noise and do not disclose exact value of term selectivity (as discussed in Section 4.2.4), content privacy in update is preserved.
In our system, privacy leakage consists of two parts, one P 1 is during index construction and the other P 2 after index gets pub-lished. For P 1 , in our protocol for index construction, there are four kinds of information; the  X  X uper-value X  v , the  X  X uper-packets X  u , the  X  X ub-packets X  u i,j and  X  X ub-secret X  v i . The super-value v is the final result and is made publicly known. Out of the four, only  X  X ub-secret X  v i  X  X  is the private information to protect.
For security analysis, we start with adversaries of different roles with different capabilities. Adversaries could be providers, net-work eavesdroppers, searchers and even the index server. However, to make a system function correctly, one needs to assume mini-mal level of trusts. For instance, providers and the index server in our network are assumed to be semi-honest, implying they fol-low our protocol specification, but may attempt to learn additional information by analyzing the transcript of messages received dur-ing the execution[15]. More specifically, providers will follow the secret-sharing based index construction protocol and index server will perform work for query answering, like posting list intersec-tions. A network eavesdropper could passively log the messages under her surveillance. She can have the global power to moni-tor all messages coming through the network or the local power to monitor messages sent out by a particular providers. A searcher could pose queries to the index server in the wish to obtain sensi-tive information. Overall, an adversary in our model can assume multiple roles, like she could be one of participating providers and can pose queries to index server at the same time. Or multiple ad-versaries can collude to gain more knowledge.

For privacy P 1 , providers can obtain more information than other roles, since all messages are encrypted in our network and only providers can see the content/payload of the network messages.
Recall that content privacy and policy privacy are addressed in this paper. The degree of privacy preservation is quantitatively measured by the probability with which an adversary X  X  claim on sensitive knowledge fails. The actual claim differs for different types of privacy, as defined above. The probability is equal to the percentage of false positive providers in the result list, which is used as privacy metric in our system. For instance, in the result list of 10 providers, if they all possess a sensitive term t , content pri-vacy is definitely leaked. Because for any provider p in the list, ad-versary can claim p possess term t in question and such claim is true with 100% probability. On the other hand, when there are 5 false positive providers in the list, in the case that adversary randomly pick a provider to perform attack, the probability for her claim to fail is at least half ( 50% ). In this paper, we choose the  X  X robable Innocence X  X 2, 18]) as our main quantitative privacy goal, in which the false positive rate should be higher than one half 0 . 5 .
Our general attack model involves that a security role (e.g., a provider) observing certain messages from other parties makes claim on sensitive knowledge that breaches privacy. We consider attack to breach both privacy P 1 and privacy P 2 . 1) For privacy P 1 , we consider both attacker as a single provider and attackers as col-luding providers. We assume that a single provider observing the messages from its neighbors always claim its neighbor has the term (even she can only see the sub-packets). Providers in collusion can observe multiple messages from a single innocent provider. If number of such messages is 2 c  X  1 , colluding providers can see all sub-packets of a secret value and thus be able to reconstruct the sub-secret value. If the reconstructed secret value equals 1 , providers claim the innocent provider has the term, otherwise, the innocent provider do not have the term. 2) For privacy P 2 , we assume searchers/index server search for term t and claim any provider in the result list has documents of term t .
We analyze privacy characteristic of our protocol against differ-ent roles. Our protocol achieves privacy preserving in many situ-ations, like against network eavesdroppers and single semi-honest provider. There are also certain scenarios in which privacy could be possibly leaked, as the two cases stated in our attack model. In this section, we analyze privacy preserving of P 1 against eaves-droppers, single provider and colluding providers. For privacy P 2 , we will conduct privacy evaluation by experiments.
For eavesdroppers, our protocol achieves privacy preserving mainly by encrypted communication; All communications in our protocol are authenticated and encrypted. Eavesdroppers seeing a series of cyphertext can not have any knowledge about its content and thus can X  X  make any informed claims. Secure channels[13] guarantees eavesdroppers themselves can not obtain the cryptographic keys.
In the presence of semi-honest providers, our protocol achieves information-theoretic security. 8 A single provider p i can only see at most one sub-packet/share out of totally 2 c  X  1 sub-packets of one sensitive sub-secret from other provider p i  X  . The fact that f  X  ( ) is a (2 c  X  1 , 2 c  X  1) secret sharing scheme, as proved by Theorem4.1, yields the information-theoretic security. Thus, adversary obtain-ing one piece/packet learn no information on the value of v and can not even make informed claim.
U nlike cryptographic security as in secure channel case, information-theoretic security does not rely on any assumptions of computation theory and is less computation-intensive.
T H EOREM 4.1. If f ( ) is a ( c, c ) secret sharing scheme with packets on domain Z q , f  X  ( ) is a (2 c  X  1 , 2 c  X  1) secret sharing scheme on Z q , too. Specifically, P ROOF . The first condition is directly implied by Equation 4. For the second condition, we take the worst case in consideration, that is, when there are 2 c  X  2 packets available to adversary. Let ( j  X  , y j  X  ) denote the only missing packet. We consider two cases: Case 1), j  X   X  0 . In this case, we can use Equation 3 to reconstruct the value u i, 0 , that is, u i, 0 = ( y 0  X  y  X  c +1  X  X  X  y Then for ( c, c ) secret sharing scheme f , we have all c packets deter-mined, except for u i,j  X  . By the definition of ( c, c ) secret sharing, the value v i = f ( ) is completely undetermined. Case 2), j  X   X  0 . We can determine all c  X  1 packets u i,j for j  X  X  1 , 2 , . . . , c  X  1 } , and we turn to prove that u i, 0  X  ( y 0  X  y  X  c +1  X  X  X  y  X  1 is completely undetermined given one packet ( j  X  , y j  X  We further consider two cases, if j  X  = 0 , we have u i, 0 (  X  y  X  c +1  X  X  X  y  X  1 ) mod q ; otherwise, we have u i, 0 ( y cases, the RHS of the equation is completely determined, while LHS, in the form u i, 0  X  y j  X  , is not. Applying lemma 4.2, we can see that the distribution of u i, 0 is fully unaffected by the given knowledge of u i, 0  X  y j  X  (but not y j  X  ). Thus, u i, 0 determined. Note v i = f ( u i, 0 , u i, 1 , . . . , u i,c  X  1 sharing scheme, thus the secret v i is completely undetermined.
L E MMA 4.2. Random variable a , b are natural numbers in do-main Z q . Their values are independently chosen and uniformly distributed in Z q . Then  X  x, y  X  Z q , we have prob ( a = x ) = prob ( a = x | ( a  X  b ) mod q = y ) = 1 Proof of Lemma 4.2 can be found in Appendix.
Our protocol is resistent to providers in collusion. In specific, 1) when collusion is of no more than 2 c  X  3 providers, attack-ers can X  X  gain any information on v i  X  i  X  X  1 , . . . , n } , as in the single provider case. Hence, our protocol retains the information-theoretic security. 2) When there are more than 2 c  X  3 colluding providers, privacy could be possibly leaked. In this section, we an-alyze the possibility and argue it X  X  very unlikely for such breach to occur.

Note sub-packets of a single sub-secret v i are distributed to at least 2 c  X  2 providers, which are the 2 c  X  2 consecutive neighbors of provider p i . When these nearest-(2 c  X  2) providers happen to form a collusion, then privacy regarding sub-secret v i is definitely leaked. 9 However, we argue the likehood for collusion of this kind to occur is fairly low. Besides, even in this case, only one sub-secret is disclosed, while other sub-secrets X  privacy is still guaran-teed. Note in our protocol group members are randomly ordered in
H ere, we exclude the trivial case that p i is itself in collusion, be-cause then v i can be known locally from p i . ring-like overlay and they follow this protocol specification (since they are semi-honest). The probability for a honest provider to be surrounded by 2 c  X  2 adversaries is, m is the total number of colluding providers in the network. As can be seen, the probability is very low for moderate value of c . For example, when m = n 2 , the probability is h &lt; ( 1 quickly approaches 0 for large n .
 In practice, the number of colluding adversaries is usually small. For example, as discovered in a peer-to-peer measurement study [14], most collusions are of two or three mutually colluding nodes. Thus, by setting c at relatively small value (e.g., 5 ), it suffices to make our SS-PPI secure against colluding attacks.
Our protocol discloses group-wise term selectivity in the pub-lished index, rendering privacy P 2 vulnerable. With this informa-tion, index server can make informed decision on picking up the right group and term (if any) and perform security attacks success-fully. To overcome this vulnerability in our system, we propose an enhanced version of SS-PPI which preserves privacy P 2 and still achieves efficiency in performance. In specific, we add noises to the term-wise bit before group aggregation starts. For term t and a possession bit v , the provider generate another number v  X  in { 0 , 1 , . . . , b } to do aggregation, as follows, Now the sum of v  X  does not necessarily equal the number of pos-itive providers in each group. By this means, privacy can be fur-ther preserved, at expenses of extra inaccuracy of ranking between groups in the public index. Parameter b controls the trade-off be-tween meta-data privacy and ranking accuracy. With this approach, the selectivity observed to be high could end up being small ones. In this sense, we prevent an adversary from picking up the term with high selectivity. In this section, we evaluate our SS-PPI, mainly by simulations. The evaluation is based on the comparison to previous work, flip-ping PPI[2]. Throughout the experiments, we mainly use synthetic dataset which consists of 10 5 providers, which are further mapped to 1000 groups. Groups are disjoint and are configured with an ex-pected group size, that is, 10 5 / 10 3 = 100 . We also used a peer-to-peer dataset[16], which is developed based on the TREC WT10g web test collection, a 10 gigabyte, 1 . 69 million document subset of the VLC2 collection[11]. In our default setting, we run each experiments 20 times and report the averaged results. In the first set of experiments, we evaluate the PPI X  X  correctness. For SS-PPI, the correctness is measured by the probability that the aggregated result equals number of positive providers in a group, that is, P n  X  1 0 v i ; for flipping PPI, it X  X  measured by that for logical OR of v i  X  X . In the first experiment, we vary the number of rounds and fix term selectivity being 0 . 1 , the results are shown in 4a; then, we test the protocol with terms of different selectivity and fixing the rounds to be 10 , results shown in 4b. In general, SS-PPI achieves 100% accuracy, while flipping PPI doesn X  X . For small number of rounds and selective terms, flipping PPI incurs relatively high inac-curacy and uncertainty. It becomes more accurate as the number of rounds goes up. However, this improvement comes at the expenses of more severe privacy leakage, more bandwidth consumption and longer time duration, as will be shown. (a) Varying number of rounds
This set of experiments evaluate the level of privacy preservation of our SS-PPI. We mainly follow our security analysis to conduct experiments, in which two types of privacy are considered, includ-ing index construction privacy P 1 and published privacy P 2 .
Our simulation for evaluation of privacy preserving against col-laborating adversaries is based on Equation 8. flipping PPI can be modeled with c = 1 and in our SS-PPI, c ranges from 3 to 18 . We have done two experiments; the one is with varying the number of colluding adversaries and fixed group size of 100 , the other with varying group size, and the adversaries accounting for 20% of the group. We evaluate the probability of specific positioning of ad-versaries that leaks privacy. The results are plotted in Figure 5. In general, flipping PPI incurs the highest privacy breach; its leaking probability is an order of magnitude higher than that of SS-PPI, even with small c . As c grows up, the improvement of SS-PPI X  X  privacy preserving against flipping PPI becomes significant. In Fig-ure 5b, the privacy breach generally become more severe, as there are more adversaries. When all providers in a group are malicious, the probability of privacy breach becomes 100% , for all protocols. When there are limited adversaries (which is more likely the case in real world), SS-PPI achieves much better privacy preserving com-paring to flipping PPI. As can be observed, there exist a threshold on number of adversaries under which SS-PPI X  X  leaking probabil-ity is 0 . For example, in the plot, the curve for SS-PPI-18 shows up only when adversaries are more than 35 . This is more obvious in Figure 5a. By contrast, flipping PPI is vulnerable to collaborat-ing attacks in all experiment settings. In Figure 5a, we can also see SS-PPI slightly increase privacy leaking probability until certain converging value as group size goes up, while flipping PPI stays constant. Note the probability (y axis) is plotted in log scale, dif-ferences between two protocols are significant.

In previous experiment, we consider privacy leakage of one in-nocent provider. Here, we move forward to study the multiple-provider case. Given a number of colluding adversaries, we mea-sure the number of innocent providers being attacked. Let a ( l ) denote the minimum number of colluding adversaries required to hack l providers X  private information. By analysis model in Sec-tion 4, SS-PPI has, For l and c large enough, the above equation must meet ( c  X  1)( l + 1) + l  X  n , or l  X  n +1 c  X  1 . For flipping PPI, c = 2 and we have, Comparing to flipping PPI, our SS-PPI has higher requirement on the number of colluding adversaries, thus less likely to leak privacy.
In this experiment, we evaluate property of privacy preserving of random grouping. We considered two cases, the common term case (a) Varying number of adversaries
F igure 5: Privacy preserving against collaboration of adversaries and the rare term case. For each case, we measure the true positive rates (i.e., the group-wise selectivity or how many providers in a group do possess the term) under different group sizes. The results are shown in Fig. 6. To visualize the degree of preserving privacy P 2 , we ranked groups based on true positive rates, decently. The maximal level of true positive ratios is critical to the overall de-gree of privacy preserving, thus being of interests to us. As can be seen from the results, the smaller the group size is, the more non-uniform the distribution of true positive rates is. For instance, the maximal true positive rate for group size of 10 is 0 . 6 for com-mon terms of selectivity 0 . 2 , while for group size configured to be 100 , the maximal true positive rate is around 0 . 3 . In this sense, larger group size leads to more privacy preserving. Comparing rare terms and common terms, grouping with common terms could end up with every group having non-zero true positive rate, implying query broadcast, which is not the case for those rare terms.
We evaluate the performance of SS-PPI by simulation. Specifi-cally, we use two distributions on round-trip times (RTTs) to emu-late the message delays, that is, gaussian distribution with deviation being 1 and mean being 3 , and the distribution modeled from real network traces [12]. In the latter case, about 35% of the messages have RTT &lt; 50 ms , 60% with RTT &lt; 100 ms , 25% with RTT &gt; 200 ms , and the rest are in seconds. For fair comparison, we set r = c (by which the bandwidth costs of SS-PPI are equal to those of flipping PPI). The simulation results are shown in Fig. 7, from which we can see that SS-PPI achieves much better perfor-mance in terms of scalability (especially in the large groups). We explain the results based on time-complexity analysis. For SS-PPI, the bandwidth costs are n c and latency is max ( hop for  X  i  X  [0 , n  X  1] , j  X  [ i + 1 , i + c  X  1] . For flipping PPI, the la-tency is r P n  X  1 i =0 hop i,i +1 and bandwidth costs are n r (in terms of number of messages transmitted). When c = r , latency of flipping PPI is O( n r ) while that of SS-PPI is O (1) .
The query processing costs are measured by the number of providers (a) On network with RTT of gaus-s ian distribution returned from the index server for a single query. In this experi-ment, we focus on single-term queries, in which term is randomly picked from index dictionary. We vary the group size from 2 to 1000 and plot the results in Figure 8. Overall, the query costs grow up as the group size increases. For group size bigger than 50 , the percentage of providers that need to check by queriers quickly ap-proaches to 100% , implying our index deteriorates to query broad-casting in this setting, which conforms to our previous experimental and analysis result.

We further study the relationship between search recall and search costs. Experiments are conducted in the both cases of common terms and rare terms. Common term is with selectivity 0 . 1 while rare term with selectivity 0 . 004 , as they can be picked from the peer-to-peer text dataset[16]. Different value of group sizes are picked for experiments. With results illustrated in Fig. 9, we can see that search costs approximately grow in linear to search recall. For 100% recall, search for common terms always require query broadcasting, while search for rare terms only need multicast to the partial set of providers. In rare term case, the search costs are sen-sitive to the group size; a big group size generally results in more search costs.

The set of experiments give us implication to properly set the value of group sizes. Finding an appropriate value for group size is tricky, because as aforementioned, too big a group size could lead to query broadcast which hurts scalability and performance, while too small a group size deteriorates the level of privacy preserving. From the experiment results, rules of thumb are to set group size to 50 , by which only terms with selectivity bigger than 0 . 01 will ends up with query broadcast (from Fig. 8) and maximal true positive rate for common terms (e.g., with selectivity 0 . 2 ) is less than 0 . 4 (note in this case, the false positive rate is smaller than 0 . 5 , thus meeting the privacy requirement of  X  X robable Innocence X  X 2, 18]).
This section briefly surveys relevant work. We review different architectures of privacy-preserving indices proposed in literature, compare two important primitives to construct such architectures, namely secure multi-party computation (SMC) and secret sharing, and finally discuss other privacy issues in information sharing in-frastructures.
The work [2] paved the way for public privacy preserving index from multiple content providers. It randomly organizes providers into disjoint privacy groups; it employs an iterative, randomized algorithm to form group-wise indexing structure, which is further used to direct queries. Comparing to our protocol, this solution suffers three major drawbacks. First, the random grouping strategy makes privacy groups tend to have all terms, and query processing ends up broadcasting. Second, the probabilistic index construction scheme take arbitrary rounds before convergency, leading to unac-ceptable running time. Third, index construction leaks considerable privacy and is vulnerable to colluding attacks.

Zerber [23] is based on multiple servers with certain amounts of trusts. Zerber distributes inverted index over n servers by using a k -out-of-n secret sharing scheme. During query time, a searcher has to be authenticated and authorized by at least k servers. Then after issuing masked queries individually, searcher obtains shares of matched posting entries from each server, and proceeds to com-posite the secrets, including indexed terms, document id and rel-evances. The scheme performs client-side intersection of positing lists, which seriously slow down query performance for large scale dataset (in terms of large number of documents), multiple-keyword queries and searcher with broader accesses. Overall, the amount of trusts assumed on index servers may become unacceptable, since it relies on servers to do authentication and authorization. In partic-ular, access policy privacy is seriously leaked in the sense that any single malicious server cloud disclose such privacy.

Union query dissemination trees (or UQDT) [6] is a distributed privacy preserving index; the indexes are organized as multiple trees, which share the same set of leaf nodes, each correspond-ing to a disjoint privacy group of publishers/providers. In essence, each QDT can be viewed as a hierarchy of group-wise index at different granularity, and privacy preserving (defined in publisher k-anonymity) is attained in a similar group-wise way. To form the finest group at leaf level, a generic secure multi-party computa-tion [9] is adopted, which however is inefficient and unscalable to thousands of providers. Different QDT X  X  are responsible for differ-ent (disjoint) subset of index terms; The multiple-QDT architecture is intended for better load balance and higher throughput, as com-pared to single UQDT with global set of indexed terms. Specifi-cally, the same physical nodes are intelligently positioned at differ-ent levels of different QDT, so overall load is balanced.
Secure multiparty computation (or SMC) [10] refers to the prob-lem in which multiple parties, each holding a private input, collec-tively perform a computation without disclosing information more than the output reveals. Many operations in privacy-aware appli-cations [7] can be deemed as secure multiparty computation, in-cluding the group-wise index aggregation in our problem. Secret sharing is one primitive for SMC problems. In particular, a generic secret sharing scheme splits a secret into multiple shares, only more than a certain mount of which can reconstruct the secret. Many se-cret sharing schemes [19] are additive homomorphic [3]. Our pro-tocol takes advantages of this nice property and applies in privacy preserving index construction. Comparing to other primitives for secure multiparty computation, secret sharing is advantageous; it attains information-theoretic security, robust against colluding at-tacks. More importantly, secret sharing has been shown to signif-icantly outperform those generic SMC protocols in execution effi-ciency [5, 4]. Secret sharing has been applied in various contexts, for example, database query processing [8], information aggrega-tion [5] and keyword searches[23]. The above approaches put the computation of secret shares onto multiple third parties while index construction in our SS-PPI involves no third party, which sees bet-ter scalability. 10 Other work [21] uses similar secret-sharing pro-tocol to preserve privacy in data mining. However, their way to distribute shares incurs load imbalance and hurts performance.
In this paper, we propose SS-PPI, an efficient and strong pri-vacy preserving index over multiple content sources. Specifically, SS-PPI adopts a new architecture of PPI, namely role-sensitive PPI, that takes into account role access information and achieves better search performance. We also identify a new type of poten-tial privacy leakage in this architecture, that is, access policy pri-vacy. Further, we propose a secret sharing based approach for ef-ficient and secure construction of public index, from multiple con-tent providers. Comparing to previous work, SS-PPI makes a bet-ter balance between privacy preserving and search performance. Our protocol is secure against colluding adversaries and achieves information-theoretic privacy preserving. We also conduct exten-sive analysis and experiments that show advantages of SS-PPI in terms of query performance and security properties.
 The authors would like to thank the anonymous reviewers. This work is partially supported by grants from NSF CISE NetSE, NSF CyberTrust, an IBM SUR grant, an IBM faculty award, and a grant from Intel Research Council.
I t implies the more providers participate in the network, the more secure we will end up with, because adversaries now need to com-promise all providers to obtain all secrets.
