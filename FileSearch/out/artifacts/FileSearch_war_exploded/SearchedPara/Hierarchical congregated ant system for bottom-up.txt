 1. Introduction
With the complexity and the reduction in the size of VLSI chip design increasing rapidly, floorplanning has gained significant importance in the VLSI physical design. There are many realistic objectives in the physical design of a chip. However, in this paper, only area minimization is considered as the main objective.
Among the mathematical tools that have been used, the stochas-tic algorithms are the most preferable due to their fast converging and promising properties in high quality outcomes. However, a suitable framework is the main key for a successful stochastic algorithm. The difficulty level of floorplanning increases as the number of transistors increases and different frameworks are employed to tackle these problems b ased on their levels of difficulty.
In IMF ( Chen et al., 2007 ), three major frameworks have been 2001 ; Hong et al., 2000 ; Hong et al., 2004 ; Kang and Dai, 1997 ; Lin and Chang, 2001 ; Lin and Chang, 2004 ; Lin et al., 2003 ;
Liu et al., 2008 ; Ma et al., 2001 ; Murata et al., 1995 ; Murata et al., 1982b ; Pang et al., 2000 ; Tang and Wong, 2001 ; Young et al., 2003 ;
Zhuang et al., 2002 ; Zhou and Wang, 2004 ), (b) the hierarchical ( Adya and Markov, 2003 ; Lai and Wong, 2001 ; Pan and Liu, 1995 ; Pan et al., 1996 ; Stockmeyer, 1983 ; Wang and Wong, 1992 ; Wong and Liu,
Cong and Wu, 2002 ). These three sets of approaches have been discussed in detail by Shen and Chu (2003) and Chan et al. (2005) . Fig. 1 shows the relationship among the frameworks.

There are several hierarchical and multilevel framework algo-rithms which are initiated in bottom-up fashion. Mixed-Mode
Placement (MMP) is a bottom-up clustering by adopting the quadratic and min-cut technique ( Yu et al., 2000 ). However there is no empirical comparison with other techniques or its scalability ( Roy et al., 2006 ). HPM ( Wang and Selvaraj, 2002 ) is a multilevel framework which works on bottom-up procedure by clustering local modules followed with refinements. However, there are no experimental results available and empirical comparisons made with other techniques. MB * -tree ( Lee et al., 2003 ) is a two-stage multilevel technique based on bottom-up coarsening followed by top-down uncoarsening. Since MB * -tree is initiated with bottom-up manner by clustering local modules based on local area and connectivity, there is no global view at the initial stage. It is noted that bottom-up clustering, by only referring to local information, will lead to local optima and may cause further refinement cumbersome in the uncoarsening stage ( Chen et al., 2007 ).
Metaheuristics approach is employed by floorplanners to solve the general orientation optimization as it is proven to be NP-hard for general layouts (nonhierarchical floorplan) ( Stockmeyer, 1983 ).
Althoughthereareanumberofmetah euristics algorithms existing, e.g. Simulated Annealing (SA) ( Cheng et al., 2005 ; Kirkpatrick et al., 1983 ; Wong and Liu, 1986 ), Genetic Algorithms (GA) ( Rebaudengo and Reorda, 1996 ), Evolutionary Algorithms ( Liu et al., 2008 , Wang et al., 2007 ) and so on, SA is preferable in flat framework floor-planners because of its simplicity. However, because SA is a local search based heuristic approach, SA based floorplanners tend to be trapped in local optima. Swarm intelligence is a relatively new metaheuristics approach in problem solving, which is inspired by the sociable natural behaviors of insects or animals. Peculiarly, ant has inspired a plenty of methods and techniques after the first ant-based searching algorithm namely Ant System (AS), which was introduced by Colorni et al. (1991) . AS was further improved by
Dorrigo et al. (1996) and was called as Ant Colony System (ACS) algorithm. Ant-based metaheuristics algorithms have been success-fully applied in many fields such as Traveling Salesman Problem (TSP) ( Dorigo and Gambardella, 1997 ), Quadratic Assignment Pro-blem (QAP) ( Maniezzo and Colorni, 1999 ), Redundancy Allocation Problem (RAP) ( Liang and Smith, 2004 )etc.

In the electronic design automation (EDA) floorplanning pro-blems, there are some studies on the application of ant-based metaheuristics algorithms. Alupoaei and Katkoori (2004) applied the Ant Colony System (ACS) in removing the overlaps in macrocells.
The macrocells were placed using quadratic programming and force-directed algorithm, where overlap was difficult to avoid completely.
The initial solution of placement will influence the removal of overlaps directly and might be trapped into local minima ( Hsieh et al., 2006 ). Chiang (2009) presented an ACO algorithm that was used for floorplanning with the clustering constraints. However, the experimental results were not comparable with the best results at the publication time of that paper. Luo and Sun (2007) used
ACO-based algorithm in the thermal aware floorplanning to reduce the temperature differences and t he total area. Hence, the cost function with weighted thermal differential and total area was introduced. Xu et al. (2006) applied ACO algorithm in the vertical and horizontal constraint graph of sequence pair representation to speed up the sequence pair with SA. The experimental results were comparable to FAST-SP ( Tang and Wong, 2001 )intermsoftime.Ant-based metaheuristics algorithms are promising paradigm for effec-tive optimization in floorplanning automation. The reason for fewer ant-based algorithms applied to floorplanning is the memory inten-sive property of ant-based algorit hms. Hence, new ant-based algo-rithm has been developed in this paper by adapting variable-order bottom-up strategy to reduce the m emory constraints imposed by the ant-based algorithms.

This paper is organized as follows. Section 2 discusses the VLSI floorplanning hierarchical approaches and the main properties of the proposed bottom-up floorplanning algorithm. Section 3 deals with the characteristics of AS algorithm. Section 4 highlights the proposed H-CAS algorithm and how H-CAS adapts the properties of bottom-up floorplanning. Section 5 discusses the experimental results and comparisons. Finally, the conclusion is presented in Section 6 . 2. Hierarchical floorplanning
Basically hierarchical framework is based on two techniques: one is top-down approach and the other is bottom-up approach. In top-down hierarchical construction, the floorplanner decomposes the particular placement into p number of smaller subregions or less, by subdividing the placement regions and allocating the modules to subregions without overruling the constraints such that good solutions of subregions can be combined into good solutions of original problem. While for bottom-up construction, floorplanner begins with all the primitive modules (modules without being clustered) and at each step, they are clustered into at most p modules or primitive modules into a group (for some constant p ) according to certain criteria/objectives. This process is done recursively until all the modules are clustered into a single module.

Compared to the top-down approach, the bottom-up approach in floorplanning requires a simpler model and a hierarchical construction. In addition, bottom-up approach can generate phy-sical hierarchy for arbitrary-sized modules ( Dai and Kuh, 1987 )and this approach is more flexible. Flexibility restrictions and computa-tional difficulties are the main drawbacks in top-down approach because of the whitespace assigned to the particular partitions ( Caldwell et al., 2000 ; Caldwell et al., 2003 ). Unpredicted white-space and overlap have always been created due to unknown desirable relative sizes ( Dai and Kuh, 1987 ) and reduction of the partitioning tolerance with the hierarchy levels. The limitation of permutation of the blocks might lead to uneven area utilization. Furthermore, top-down approach might be trapped into local optima due to cut size limitations.

However, commercially the typical hierarchical framework placers are using the top-down divide-and-conquer scheme approach as the initial global placement. The main advantage of the top-down approach over the bottom-up approach is the introduction of global information about the circuit such as the fixed outline and whitespace at the highest level, transferred from top to down. Therefore, the whitespace and the outline of a circuit are controllable and the outcome of the floorplan is predictable. The top-down hierarchical framework placers are normally deal-ing well with soft module problem ( Chen and Yoshimura, 2008 ). All these above characteristics of the top-down approach in floorplanning are lacking in the bottom-up approach. Besides the uncontrollable and the unexpected whitespace properties in bottom-up approach, the whitespace of bottom-up based floor-plan is proportional to the complexity and depth of the hierarchy and therefore the whitespace increases as the number of hier-archy levels rises. The bad coarsening results created at lower levels will be propagated to higher levels and these particular errors cannot be compensated at higher levels ( Cong and Wu, 2002 ). Due to lack of global information, bottom-up floorplan mostly concentrates on local optima by just referring to the local information. There is a high possibility that bottom-up hierarch-ical floorplanning be trapped into local optima due to lack of global information. In this paper, H-CAS is proposed to introduce global whitespace information (main objective of this floorplan-ner) at every level in the hierarchy in bottom up approach. 2.1. Proposed bottom-up hierarchical framework
A hierarchical floorplan with order of p (maximally p child nodes for each node) can be described by a p-nary tree ( Dai and Kuh, 1987 ) corresponding to the partitioning/clustering process.
The bottom-up hierarchical floorplan can be represented by the bottom-up cluster tree as shown in Fig. 2 . The order of the hierarchical framework is fixed to be a maximum of five so that the pattern enumeration would be easier and less complex in the searching algorithm. The reason is that cost for partitioning/ clustering process increases rapidly with the number of p ( Dai and Kuh, 1987 ). Due to the NP-hard property, the number of possible placement increases rapidly with the number of hierarchical order p which will lead to higher computational complexity and increased runtime. Although the hierarchical order p can be smaller than five, minimum order of five is required to represent all the possible placements. 2.2. Bottom-up whitespace fundamental computation
In this paper, a new bottom-up whitespace fundamental computation is proposed and adapted into H-CAS, making the ant to have more information as reference.

Property 1. In every level in bottom-up hierarchy, the relative whitespace of arbitrary cluster (parent node) is the convex combination of its own lower level clusters/primitive modules (child nodes) and a constant of unity.

Proof. Caldwell et al. (2003) proved that a top-down partitioning whitespace is a convex combination of relative whitespaces of child blocks. Although both the top-down and the bottom-up approaches are hierarchical based constructions, their whitespace fundamental computations are different.

At each level, all modules (lower level clusters/primitive modules) have respective dimension information about width w and height h . By using w and h, the modules area M can be calculated and the clusters have the cluster area C (typically M r C if no overlap occurs among modules in the cluster), absolute whitespace A  X  max { 0 , C-M }, and relative whitespace a  X  A / C .
Let the cluster area C of the parent cluster, cluster area C the child clusters, and additional whitespace A 0 after clustering, such that ( P C n )  X  A 0  X  C, where 2 r n r 5, C n r C and A 0 shown in Fig. 3 . Besides, we know that the module area is ( P
M n )  X  M , where 2 r n r 5 and 0 r M n r C . While for each child module, the absolute whitespace A n  X  C n  X  X  n and relative white-space a n  X  A n / C n .

The relative whitespace a can be obtained by a  X  A = C  X f  X  X
Hence, a  X  A C  X 
Since ( P C n )  X  A 0  X  C, we know P ( C n /C )  X  A 0 / C  X  1 where C and a 0 , which is defined as the coefficient of A 0 /C is always unity.
Hence, although the combination equation is different from the top-down whitespace partitioning, it is observed from the above and (1) that relative whitespace of cluster is a convex combina-tion of the relative whitespace of child clusters and a 0 in that particular cluster. This implies that the relative whitespace of cluster will never be smaller than any of its child modules X  relative whitespaces. In agglomerative clustering, a 0 is proven as a constant which is unity and cannot be changed. But, it is adequate to predict the minimum relative whitespace of a cluster at higher level of bottom-up hierarchical approach by only considering the lower level clusters (modules).

Property 2. A badly constructed cluster at lower level might create worst cluster at the higher level and this ripple effect might be transferred to the next higher levels and eventually degrades the whole floorplan. The effect is greater when the area of the badly constructed child clusters is large enough as compared to the total area of the parent cluster.

Proof. In Property 1 , the relative whitespace of the next level of a bottom-up hierarchical approach can be obtained by convex combinations of the lower level clusters and a constant of unity.
At each level, the relative whitespace of the cluster at one level above is obtained by (1). Hence, the set of all convex combina-tions of relative whitespace vectors (relative whitespaces of the corresponding child clusters) in that particular cluster and a unity constant, will constitute the convex hull of that particular cluster X  X  relative whitespace. Let the convex hull of the relative whitespace of arbitrary cluster at level v be S v { j 1 S  X  j p S v 1 , n  X  ( j )1: j n , j Z 0 for all p and P j n  X 
S v 1 , n is the convex hull of its n -th child cluster X  X  relative white-space at level ( v 1 ) and n E [2,5]. Hierarchical clustering process is a recursive process and hence, the convex hull S v 1,n, relative whitespace convex hull, which is actually constituted by its own child clusters X  relative whitespaces.
 From the properties of convex combination, it is assured that
S
Z min ( { S v 1 , n } ), where n E [2, 5]. Therefore, due to the power of hierarchical propagation, the relative whitespace at lower levels will be propagated to higher leve ls and hardly be compensated. In conclusion, relative whitespace at lower level will affect the higher level whitespace by propagating i n an agglomerative way, and this effect is greater when the child cluster area is large enough as compared to parent cluster area. 3. Ant-based metaheuristics
An ant colony is a successful swarm of ants working coopera-tively to find food and defend their own community and breeding.
Impressively, ant is one of the social insects that can find a source of food in the shortest path and more and more ants will go in the same path to the same food source from time to time. This efficient and converging result is due to the collective work of all the worker ants. In nature, ants search for the food source randomly at the initial stage and deposit some chemicals called pheromones on their trail between the nest and the food source.
Therefore the pheromone level on the trail gives information to the other ants about the particular food source and based on the pheromone trail, the other ants will choose the path. The path with the higher pheromone level is preferred. As more ants travel on the particular path, more pheromones will be deposited. However, all the pheromones will start evaporating over time.
Therefore, after certain time, the old pheromone trail will vanish if it is not reinforced by the other ants. At the end, all the ants will take the same path to the food source. 3.1. Ant colony optimization
Inspired by the ant colony foraging behavior, Ant-System (AS) was introduced by Colorni et al. (1991) . Following their work, many ant-based metaheuristic algorithms have been developed to aim specific problems literally by applying ant X  X  behavior. Several researches have been done on the development of ant-based metaheuristics such as Ant Colony System (ACS) applied in Traveling Salesman Problem (TSP) ( Dorrigo et al., 1996 )andsym-metric and asymmetric TSPs ( Gambardella and Dorigo, 1996 ), etc. All the virtual ants in ant-based metaheuristics have the same foraging behavior as the real ants. In genera l, the ant-based metaheuristics algorithm consists of three parts, which are initialization, construc-tion, and feedback. The initialization part is mainly proposing the initialization of the parameters s uch as the number of colonies and number of ants. Then the construction phase deals with the guidance to the artificial ants th at construct the path based on the probability. Finally, the feedback part just aims at the extraction and reinforce-ment of the ants traveling experi ences which were obtained in the previous searching path. This update will aid the optimal solution searching, of the subsequent ants. Ant-based algorithm has been proven to be a promising metaheuris tics approach as it is applied in many fields and found to give beneficial results. 3.2. Ant system
Retaining the main properties of AS, the other ant-based algorithms were developed by introducing some meaningful modifications and improvements in order to suit the problems on hand. The main characteristic of AS is that, ant selects the espousing city/destination to be visited through a random mechanism during the formation of the solutions. When ant m is at the current city i , and with the instant partial solutions s prob m  X  i , j  X  X  and N ( s p ) is the set of executable components, which mean that the edges c( i,j )havenotbeenvisitedbytheant m . The parameters a and b are used to control the impingement of the pheromone t ( i,j ) (global information) and heuristic information Z ( i,j )(localinforma-tion) on the ant destination selection, which are recommended to be  X  1and b E [3, 5]. The heuristic data Z ( i,j )isdefinedas  X  i , j  X  X  where d ( i,j ) is the distance between cities i and j .
After each of the iterations, the pheromone values of the trails traversed by all the ants m are updated by  X  i , j  X  X  X  1 r  X  t  X  i , j  X  X  where p is the evaporation rate, Z is the total number of ants involved, and D t m ( i,j ) is the quality of pheromone laid on the edges c ( i,j ) taken by ant m which is defined as m  X  i , j  X  X  where Q is a constant set by user, and Cost m is the length of the tour performed by the ant m .

Although AS has achieved a greater success in solving the TSP problems, the performance of A S in TSP decreases dramatically compared to other metaheuristic algorithms when the scale of the
TSP problems rises. Hence, most of the following ant-based meta-heuristic algorithms are basically trying to improve the scalability of AS, for instance, ACS ( Dorigo and Gambardella, 1997 ) and MAX-MIN
Ant System (MMAS) ( Stuzzle and Hoos, 2000 ). 4. Hierarchical congregated ant system
Ant-based metaheuristics approach is an aggressive search technique, inspired by the foraging behavior of ant colony. Based on the report by Stovba (2005) , the principal reasons of the inefficiency of AS algorithm in scalability are (a) The best solutions might be lost due to the probabilistic rule used in the route selection. (b) The convergence closed to the optimum is weak due to the contributions of best and worst solutions as the pheromone levels are approximately the same, which means that pher-omone values have insignificant influence on the ant route selection. (c) The ant colony memory storage of the solution keeps chan-ging which are clearly unpromising in getting good results.
This is because the considerable extension of search space is created and this issue is magnified when the size of the problem is increasing.

In order to tackle these critical constraints, the rest of ant-based algorithm is developed by keeping the backbone of AS algorithm with modifications in the pheromone update mechan-isms and route selection rules.

In this paper, we introduce a new ant-based metaheuristics, called as Hierarchical Congregated Ant System (H-CAS) for placement problems.H-CASbehavesasmemoryfortheglobalviewofthe whole hierarchical structure and i t provides some degree of random-ness on the selection of the modules yet offering convergence to the best possible solution. The basic concept of H-CAS is that the ants search for the partnership throu gh stochastic mechanism and then will communicate, update the pheromone trails and congregate once they reach the next milestones (cities) in their path to the food source. Penalty is given if an ant has chosen the bad partners. After joining each other, and forming a new yet larger group, the ants in the congregation will exchange their experiences and build up a new pheromone trail that belongs to the particular new ant congregation.
They will undergo the equal quantum of pheromone updates in future. This is the major property of H-CAS which is different from the other ant-based metaheurist ics approaches, w here they do not share experiences and involve in intercommunication. Basically, in
H-CAS, ants help the variable-order bottom-up hierarchical frame-workinthesortingstageasthispartisthemainkeytothewholeof bottom-up structure formed. The fundamental rudiments of ant-based metaheuristics approach are adapted in H-CAS.

In this bottom-up hierarchical construction, a variable-order bottom-up hierarchical ( p  X  5, as discussed in Section 2.1 ) floor-planning is proposed to handle hard module problems whereas the order is reduced to two for soft module problems due to the flexibility of soft modules.

The properties of the above floorplanning approaches are adapted into the H-CAS. Basically, the proposed bottom-up hierarchical floorplanning algorithm consists of three major steps: (a) ant-partnership seeking stage (sorting stage), (b) ant congregation stage (modules merging), and (c) LB-compaction (final floorplan refinement), as shown in Fig. 4 . 4.1. Ant-partnership seeking stage (sorting stage)
In order to handle different types of floorplanning problems, different sorting approaches are utilized. In soft module problems, the differences between the areas of modules are considered.
However, for hard module problems, the area (a two-dimensional function) is reduced to a one-dimensional function, which is the difference in dimensions between two modules. 4.1.1. Concept of sorting stage
Let node v to be an arbitrary node in the cluster tree T ,andthe set of child nodes which is rooted at v is denoted by y ( v ). At the initial stage, for node v of the cluster tree T , the algorithm will choose a module from y ( v ) randomly. Then a pair vector, namely -vector , which indicates the differences of dimensions (for hard module floorplanning) or differences in area (for soft module floor-planning) between the first module and unselected modules in y ( v ), is generated. If the widths and heights of the modules are denoted by w i and h i respectively, then the g vectors are defined as  X  o 1 , 2 , ... , s 4  X  6  X  where s is defined as s r 9 y  X  v  X  9 2 ! the number of vertices.

The g vectors are subjected to the following constraints: i Let j o k and { j , k } A y ( v ) (a) For hard modules floorplanning, the u -th member of the (b) For soft modules floorplanning, the u -th member of the ii n r n  X  1 , for 1 r u r s 1.

From the -vector , the second module is chosen by referring to the min { } which denotes the first element 1 in the -vector .
These two modules which correspond to 1 would lead to the first and second modules in the sorting list y 0 ( v ). Then be eliminated from the -vector . Subsequently, components in from the newly constructed -vector, which contains the last module in the y 0 ( v ) list, would be extracted to form a new -vector , and condition (ii) stated above once again applied to the -vector . The successive modules in y 0 ( v ) will be based on the min { }, and min { } as well as that involve previous compo-nents in the y 0 ( v ), will be eliminated from the . These extract-and-sort and select-and-eliminate processes are repeated until the number of modules sorted into the y 0 ( v ) -list is five (for hard module problems) and two (for soft module problems), as discussed in Section 4 . 4.1.2. Dimension reduction of hard module problems
Property 3. For placement optimization problem, which focuses on area minimization (two-dimensional optimization), it is suffi-cient to calculate the cost function in sorting algorithms purely based on one-dimensional units.

Proof. Let two child clusters have the dimensions of x 1 , y y respectively, and a partition consists of a pair of child partitions having the widths of x 1 and x 2 (same width as the child clusters) respectively. The areas of these two child partitions are denoted as C 1 and C 2 , such that cluster area C  X  C 1  X  C 2 , C
Then, the two child clusters are placed into the child partitions having the same width. This is a common representation for all the permutations involving two child clusters only, as width and height are the mutual dimensions for a cluster when they are rotated or permuted rightwards or upwards.

Since all the clusters are considered as a single module after merging, the whitespace inside the cluster will be propagated to the second level and will not be considered during sorting or merging stage. Therefore, the absolute whitespace A created by both clusters in this partition is equal to A 1  X  A 2 and the relative whitespace a is equal to A / C of that particular partition. For each child partition, the relative whitespace a g is equal to A 1 r g r 2, as shown in Fig. 5 .

In order to express the relative whitespace of the cluster q in terms of child partitions X  relative whitespaces q 1 and q define a  X  A / C  X  A 1 / C  X  A 2 / C  X  ( A 1 / C 1 )( C 1
Thus, a  X  a 1 C 1 C  X  a 2 C 2 C  X  7  X 
Since C  X  C 1  X  C 2 and thus, C 1 / C  X  C 2 / C  X  1 where ( C also ( C 2 / C ) Z 0. Hence, for a partition which comprises of two child partitions, it is proven that the relative whitespace of the partition is a convex combination of the relative whitespaces created by both child partitions. Based on the convex combination property, a has to lie between a 1 and a 2 . Let a 1 r a 2 a r a r a 2 . Because the partition X  X  height is the same as the maximum height of the two child clusters, a 1 is equal to zero. Consequently, the inequality equation will now be reduced to 0 r a r a 2 and a 2 can be calculated using a 2  X  {( y 1 y ( y 1 2 )  X  ( y 1 y 2 )/ y 1  X  1 ( y 2 / y 1 ).

The inequality equation is 0 r a r 1 -( y 2 / y 1 ) and therefore the area optimization sorting algorithm can further be reduced to obtain the sorting cost function as in (8). That is sorting f unction  X  1 y 2 y with the constraint that y 2 r y 1 .

This is a linear equation which can be solved easily. Obviously the optimal solution can be obtained directly when the ratio of the vertical dimension of first module to the vertical dimension of second module is maximized (closer to unity). The module selection in the sorting algorithm should be area-based. However, area-based selection, which is purely based on comparisons of two successive modules,wouldbemorecomplexduetoinvolvementofadditional variables. With this reduction in sor ting function (8), the complexity of area optimization can also be reduced significantly by just performing one dimensional ratio optimization.
 Property 4. For area minimization problem, sorting cost function, which is based on local whitespace, might be trapped into local optima.
 Proof. By referring to the definitions and notations given in Property 3 and letting a 1  X  0 , then, a  X  A = C  X f X  y 1 y 2  X  x 2 g = f y 1  X  x 1  X  x 2  X g X f X  y Hence, a  X  1 y 2 y
So the first part of right hand side is the normalized-vertical-dimension-difference-ratio, while the second part is the normal-ized-horizontal-dimension-ratio. In order to prove that (9) is a non-convex function, we assume that: (a) the normalized-hor-izontal-dimension-ratio is a constant K 1 and (b) normalized-vertical-dimension-difference-ratio is a constant K 2 , where, cases (a) and (b) are as described below and o  X  y 2 / y 1 . We know that 0 o o r 1, o 1 and o 2 are arbitrary points in the interval (0, 1), where o 1 o o 2 , then, f 1 (1 l ) o 2 ]  X  [1 l o 1 ( 1 l ) o 2 ] K 1 and l f 1 ( o 1 )  X  (1 l ) f 1 ( o 2 )  X  [ 1 l o 1 (1 l ) o 2
Therefore, f 1  X  l  X  o 1  X  X  X  1 l  X  o 2  X  l f 1  X  o 1  X  X  X  1 l  X  f 1  X  (0 o l o 1) and O  X  x 2 / x 1 . We know that 0 o O o N , O are arbitrary points in the interval (0, N ), where O 1 o O f 2 [ l ( O 1 )  X  (1 l ) O 2 ]  X  1 1/[1  X  l ( O 1 )  X  (1 l ) O l f 2 ( O 1 )  X  (1 l ) f 2 ( O 2 )  X  1 l /(1  X  O 1 )  X  (1 l )/(1  X  O
By computing the difference, it is found that f 2 [ l ( O 1 )  X  (1 l )( O 2 )] l f 2 ( O 1 )  X  (1 l ) f [ l (1 l )( O 1 O 2 ) 2 ]/ { [(1  X  O 1 )(1  X  O 2 )][1  X  lO
Since [ l (1 l )( O 1 O 2 ) 2 ]/ { [(1  X  O 1 )(1  X  O 2 )][1  X  lO a is always positi v e, and hence, f  X  l  X  O 1  X  X  X  1 l  X  O 2 4 l f 2  X  O 1  X  X  X  1 l  X  f 2  X  O 2
From (10) and (11), we conclude that area-based cost metric (9) is a non-convex function and the optimization will have a higher probability of trapping into local optima.

Property 5. Cost metric (8) is a convex function. This one dimensional optimization cost metric will never be trapped into local optima.

Proof. From (10), let K 2  X  1, then the cost metric will be reduced to f in (10), the sorting cost metric is a convex function, in which local optima is actually the global optima. 4.1.3. Ant-partnership seeking algorithm for hard module Problems
In H-CAS algorithm, all the ants will start from the same city i (set of child nodes), select respective partners to form a group and then travel to city j (parent node) based on (2) and (3). However, in this paper, the parameter a in (2) is changed to a variable and (3) is modified for the problem on hand. In (2), the parameter b is fixed to be three while the parameter a is set to  X  ( where n indicates the n -th module that is being selected into the partnership.

Eq. (12) ensures that by setting a  X  0 when selecting the first module, will prevent the repeated selection of the same module that leads to suboptimal solutions. This is due to the high pheromone level deposition on certain modules after several repeated modules have been selected. This will increase the probability of an ant to visit more unexplored vertices. Hence, the first module is selected randomly to obtain more partner-ships, which might lead to better global optimal solutions.
Dorigo (1992) and Dorrigo et al. (1996) have suggested that for selected value a 4 1 will lead to rapid growth of saturated situation where all ants will follow the same path and construct the same tour, where suboptimal solution is generated. Besides, the value of b ranging from two to five is suggested based on the experimental studies done in AS ( Colorni et al. 1991 ), Elitist Ant
System (EAS) ( Dorigo, 1992 ), ACS ( Dorigo and Gambardella, 1997 ) and MAX-MIN Ant System (MMAS) ( Stuzzle and Hoos, 2000 ). Hence, a is set as stated in (12) and b is set to 3 for all the ant-based metaheuristics. The edge-weights between the cities i and j for unselected partners, d ( i , j ) in (3) is defined as the one dimensional difference between the module that is just selected and the remaining unselected modules as discussed in Section 4.1.2 . The selection of partners is based on Section 4.1.1 and the termination criterion is the number of modules selected reaching five. 4.1.4. Ant-partnership seeking algorithm for soft module problems
In soft module problems, H-CAS will start choosing the module with smallest area as the first candidate for the partnership. Its partner is chosen using a Roulette-Wheel based selection techni-que, which employs (2) and (3), where the edge-weights between the differences in area between the first module and the remain-ing unselected modules. As discussed in Section 4.1 , ant will only form a partnership of two and the a nt-partnership seeking process will be terminated. 4.2. Ant congregation (merging stage) 4.2.1. Cost function for hard module problems
Area and aspect ratio have different dimensions, where area will have larger orders of magnitude for values of width and height greater than unity and smaller for values of width and height lesser than unity as compared to aspect ratio. In order to solve the disparity, these two independent variables are normal-ized. Let the relative whitespace and the aspect ratio of the cluster are denoted by a and R respectively. Then
Costmetric  X  X  W  X  X  a  X  X  X  1 W  X  X  R 2 1  X  ,  X  13  X  where aspect ratio R  X  max{w / h , h / w} , w  X  width, h  X  height, and W  X  weight of the normalized area, for 0 r W r 1
Eq. (13) shows that the cost metric is a convex combination of the relative whitespace and the aspect ratio converging to unity.
This means that the cost metric is highly dependent on both relative whitespace a , and aspect ratio R . This relationship causes the priority issue between the relative whitespaces and the aspect ratios in which the aspect ratios converge to unity. Jagannathan et al. (2002) have studied the relationship between the linear combination and Pareto curve where they have shown that any points on the lower convex hull (LCH) will only be found by suitable choice of coefficients. However this is not practical because of the difficulty in automating the coefficients of a placer cost metric which is a non-dominant solution with respect to the relative whitespace and also the aspect ratio converging to unity.
Thus, the dominance is given to the relative whitespace rather than the aspect ratio converging to unity, as area minimization is our main objective. 4.2.2. Merging algorithm for hard module problems
In the merging stage, four groups of modules are first established each of the respective groups denoted by F n-1  X  { b 1 , 2 r n r 5. For these four groups, the best permutation (with the minimum whitespace) in each group is chosen. Based on (13), the group with the lowest cost is chosen. After the merging process, the cluster will be treated as a new single module. This is followed by another phase of sorting-merging stage. This process is done recursively until all the modules are clustered to be a single module, as shown in Fig. 6 . 4.2.3. Merging algorithm for soft module problems
As discussed in Section 4 , the order p is limited to two for the soft module problems. Hence, in the merging stage of the soft module problems, both the modules selected during the sorting stage will be aggregated without the aid of the cost function.
This is because the soft modules are flexible in their dimensions and able to adjust themselves to match each other at the final stage of the floorplanning and create minimum or zero whitespace. 4.2.4. Ant-congregation algorithm for hard module problems
As the best merging group is selected after each merging stage in the bottom-up hierarchical placement, H-CAS ants will update the pheromone trails by applying the pheromone deposition formula (5). Cost m is the cost of the best merging group obtained by the ant m and this is the relative whitespace which is calculated by the absolute whitespace divided by the total area of the cluster. However, the pheromone trail update rule in (4) is modified and the new pheromone trail t 0 ( i , j ) is given by t  X   X  i , j  X  X  8 &lt; :  X  14  X  where r is an evaporation coefficient such that 0 o r o 1inorderto avoid unconstrained accretion of the pheromone and X desired constant which corresponds to the d esired relative whitespace of the placement. The value of r is 0.02 whereas X desired is 1% of relative whitespace. The value of X desired is selected by experimenting with several cases for the same benchm ark. The pheromone evaporation rate r is set to a low value as this will increase the number of tours explored at the initial search. Besides, the pheromone trails of all the ants will be updated several time sintheprocessofasingletree construction. The number of upda tesishighlydependentonthe depth of the tree constructed. Thus, a higher evaporation rate will cause the ant to be trapped into a local optima which is the suboptimal solution found by H-CAS in the earlier stages. The update method (14) is based on the concepts developed in Properties 1 and 2 with the purpose of minimizing the possibility of bad solutions by penalizing them as per the (14) and making them converge to the possible best solution in a short time.

The pheromone update is carried out on all the successful edges found by the ants and/or the consorted-ants. If there are one or more ant consortiums, the ants from the same consortium will start to communicate among themselves and identify each other. This step is crucial when pheromone is updated. All the pheromone trails of ants that are involved in this merging stage will be updated with the same amount of pheromone deposition by applying (14). However, the trails among the ants from the same ant consortium will not be updated. For example, there are t hree ants and/or consorted-ants merged at this stage, namely, set A ,set B ,andset C .Then,by applying (14), the three pheromone updates are applied as below (a) Set of i + set A , and set of j + set B  X  set C (b) Set of i + set B , and set of j + set A  X  set C (c) Set of i + set C , and set of j + set A  X  set B
After all the ants and/or the consorted-ants have updated their pheromones, they will be congregated and become a new con-gregation. All the ants and/or the consorted-ants in this newly formed congregation will share their experiences and contribute to the new pheromone trails that are defined as  X  i , j  X  X  where G is the number of ants and/or ant consortiums involved in the newly formed congregation (equivalent to the order of that subtree) and t m ( i , j ) is the respective pheromone trails of ant m . Eq. (15) is used to calculate the partnership preference between this newly formed ant congregation and other ants and/or ant consortiums. If majority of the ants in this newly formed con-gregation have bad experiences (had resulted in a large white-space in the previous tour) with certain ants/consorted-ants, then the possibility of this newly formed ant congregation to con-gregate with the other ants and/or ant consortiums will be reduced, and vice versa. After the new pheromone construction, this newly formed ant congregation will share the same pher-omone deposition updates for every subsequent search. 4.2.5. Ant-congregation algorithm for soft module problems
When solving soft module problems, the hierarchical tree struc-ture is constructed before the H-CAS can update the pheromones. This is because the ant does not have the precise information about the instant cluster details as the dimensions of the paired modules are always commuting to match each other. The pheromone is updated based on the final floorplan results after the current hierarchy is built up and the sa me pheromone update mechanisms are applied as for the hard module problems. 4.3. Example of H-CAS in the hard module problem
Let us consider a 10-hard modules floorplanning problem and each of the module is represented by an ant ant m , where 1 r m r 10. The pheromone matrix t having a size of (10 10) is given as under  X  it is known that t matrix is always symmetrical, i.e., where1 r q , r r 10 :
Initially all the ants are allocated to a community (consists of unselected ants and/or ant consortiums) and one of the ants will be selected to travel from city i to city j . Assume that this ant is ant . Ant 7 will select its own partner (assume that the partner ant is ant 3 ) to travel together based on (2), (3) and (12), as discussed in Section 4.1.3 . Then the newly selected member, ant 3 in the city i , will stand a chance to choose its preferable partner and exclude the ant that has been chosen previously. The partner-selection process will cease once the member in city i is five, or will be skipped and proceeded to the congregation stage if the number of all the members in the community is less than or equal to five. Let us assume that the sequence of ants selected is: ant 7 -ant ant -ant 10 -ant 1 . These five ants will try to form four groups which consist of first two, first three, first four and first five members respectively. The group vector F is defined as F  X  0 B B B
B @
For each of the member in F vector, all the possible orienta-tions are tried and the member with lowest cost in (13) will be selected to form a congregation to travel from city i to city j. Let us assume F 2 gives the lowest cost and the congregation formed is called as consortium (2,3,7,10) . The ants in the congregation will update the pheromone with respect to all the members in the congregation based on (5) and (14) while the new pheromone intensity that belongs to this particular congregation with respect to other ants is obtained by applying (15). The congregation of these four ants leads to a reduction in subsequent search space.
The original (10 10) matrix t is now reduced to a (7 7) matrix and is shown below t
This consortium (2 , 3 , 7 , 10) will be treated as a single group to travel to participate in the formation of further congregation. The ant congregation, consortium (2 , 3 , 7 , 10) and the unselected ant, ant will now return to the community and the partner-selection process continues. Let us assume that based on (2), (3) and (12), the sequence of the ants and/or ant consortiums selected from the community is: ant 1 -ant 8 -consortium (2,3 , 7 , 10) -the group vector F formed is F  X  0 B B B
B @
Let F 3 gives the lowest cost and the congregation formed is again to become  X  0
B @
The number of modules remaining after this congregation stage is three. Since it is less than five, the partner-selection process will be skipped and all the ants and consortiums in the community, namely ant 4 , ant 6 and consortium {1,(2,3,7,10),5,8,9} congregate, resulting in only one single congregation and the floorplanning process ends. This whole process is shown in Fig. 7 .
Fig. 8 shows the corresponding tree structure of this example. 4.4. Floorplan refinement (LB-compaction stage)
This stage is only applied in the hard module problems as the soft modules can refine themselves. In the final stage, the
LB-compaction is performed in order to generate a more compact floorplan layout. This technique is used by Chang et al. (2000) , Guo et al. (1999) , and Lai and Wong (2001) . According to Lai and
Wong (2001) , a compact placement of a set of modules is defined as  X  X one of the module in the placement permutation can move vertically upward or horizontally leftward without overlapping and dislocating other modules X . This concept is used in the O-tree ( Guo et al., 1999 ) and B-tree ( Chang et al., 2000 ) and is named as
LB-compaction.
Community 
L-compaction is a step where all the modules are sliced leftwards without yielding any overlap while B-compaction are sliced downwards without yielding any overlap. LB-compaction is just a simple recursive L-compaction followed by B-compac-tion or vice versa. This simple compaction is proven to be highly efficient to reduce the area of floorplans ( Lai and Wong, 2001 ). In the review paper by Chan et al. (2005) ,theexperi-mental results show that the seve ral repetitions of compaction algorithm do not lead to substantially improved results in the purely area-based optimization problems. Based on the experi-mental observations, Chan et al. (2005) suggested that the floorplan compaction algorithm should be executed as a post-process task. Therefore, in our work, the hard module final floorplan is compacted with the simple single-order LB-com-paction since the complexity of the algorithm is directly proportional to the order of compaction. 5. Experimental results
H-CAS was compiled using gcc on a Windows-XP PC platform with Intel Pentium IV 1.8 GHz CPU and 512 MB memory by using the same parameters in all test cases, where the values are specified in Sections 4.1.3, 4.1.4, 4.2.4, and 4.2.5 . The comparisons are made on the following floorplanning/placement algorithms: O-Tree ( Guo et al., 1999 ; Guo et al., 2001 ), Enhanced O-Tree ( Pang et al., 2000 ), and Chang, 2004 ), CBL ( Hong et al., 2000 ), FAST-SP ( Tang and Wong, 2001 ), Enhanced Q-Sequence ( Zhuang et al., 2002 ), TBS ( Young et al., (2001) ,MAEA-MBS( Wang et al., 2007 ), ACG ( Zhou and Wang, 2004 ), Chen et al. (2007) ,BloBB( Chan and Markov, 2004 ), Parquet ( Adya and Markov, 2003 ; Chan and Markov, 2004 ), Elitist Non-Dominated Sorting based Genetic Algorithm Floorplanner (ENDSGA) ( Fernando ESA ( Chen and Chen, 2010 ), and HSA ( Chen et al., 2011 ). All of these algorithms were implemented in C/C  X  X  language except FAE and ENDSGA which used Hypertext Processor (PHP) and Matlab 6.5 respectively. Although all the floorplanning algorithms were simulated in different PCs, the recent works (from 2007 onwards) which were implemented in C/C  X  X  ,wererunonthePCswithCPU speed ranging from 2.0 GHz X 3.0 GHz, and with 1 GB memory (except for HSA with 512 GB memory). H-CAS is compared to the recent floorplanning algorithms, namely MBS-OEA, MAEA-MBS, Chen et al., ESA and HSA, by simulating H-CAS on a slower PC to indicate the improved performance of H-CAS in terms of runtimes.

The MCNC and GSRC ( Rabaey, 2005 ) benchmarks are used as the standards for comparison and are shown in Table 1 and the number of modules is varied from 9 to 600 which are adequate to show the scalability and the flexibility of H-CAS in handling placement problems. The maximum dimension ratio of a soft module is found by calculating the ratio of the maximum dimension to the minimum dimension of the particular module and the minimum dimension ratio is the reciprocal of the maximum dimension ratio. The maximum and the minimum dimension ratios of the soft modules and the summations of the total area of all the blocks of the respective benchmark problems are also given in Table 1 . Chan et al. (2005) emphasize the importance of the number of independent runs to obtain near optimal solutions as most papers in floorplanning/placement indicate their best results but fail to report the average values and the standard deviations for their independent runs. In line with the suggestion, H-CAS is executed 25 times independently for each benchmark problem to compute the averages and the standard deviations. This information is crucial where the preci-sion, variability and convergence of the placer/floorplanner algo-rithm can be ascertained. The measure to evaluate the quality of
H-CAS solutions is to determine the difference between the minimum area of the rectangle which covers all the modules and the summation of all the modules X  areas. This difference is the whitespace. To provide a relative comparison, normalization of results is used to calibrate and compare H-CAS results with other benchmark algorithms in terms of area and runtime. The normal-ization is a ratio of  X  X he results obtained X  to  X  X he best simulation result X , for any benchmark test case. 5.1. Floorplanning problems with hard modules
In this work, the best-so-far and the average floorplan layout areas, the relative whitespaces (in percentages), the standard deviations, and the runtimes for the permutations of the hard module problems run with H-CAS, are shown in Table 2 .Allthe 21 near optimal solutions are packed minimally to within 5.52% of relative whitespaces. For all the problems with less than 100 blocks, the relative whitespaces obtained by using H-CAS is less than 3%. The average relative whitespaces for all the benchmark runs are below 6.57%. The average relative whitespaces of all the 21 problems are within the range of 0.77% X 6.57%. The low standard deviations of the results in all the cases show that the best-so-far area obtained for several runs by H-CAS are consis-tent. The near optimal and the average results, as well as the standard deviations of H-CAS in these 21 problems show that
H-CAS is a robust placer which not only be able to search for near optimal solutions but also provide stable and consistent performance.
 Table 3 compares the MCNC benchmark results of H-CAS with O-Tree, Enhanced O-Tree, B * -Tree, TCG, TCG-S, FAST-SP, Enhanced Q-Sequence, ( Chen et al., 2007 ), TBS, CS, ACG, CBL, MBS-OEA, MAEA-MBS, FAE, DPSO, ENDSGA, ESA and HSA. Table 4 shows the normalized whitespaces of H-CAS along with the other existing floorplanning algorithms and the best results among the algo-rithms for individual test cases are shown in bold case. By referring to the sample cases from Table 3 , it is seen that H-CAS Percentages (%) shows improved results in terms of area in 62 cases and equal results in 20 cases, out of in total 86 cases as compared to the other algorithms. These marked improvements by H-CAS are very obvious as can be seen from the normalized results given in Table 4 .
This clearly proves that H-CAS performs well over 72.1% and equal in 23.3% of other floorplanning alg orithms in terms of whitespace, using MCNC benchmark cases. The comparisons of all the floor-planning algorithms with others by using MCNC benchmark are carried out and detailed distinctions amongst various floorplanning algorithms are brought out in Fig. 9 . The results of applying the algorithms are classified as successful if they give better results, comparable if the results are equ al and unsuccessful if the results are inferior as compared to other floorplanning algorithms. It is evident that H-CAS shows the hi ghest percentage of successful results and the lowest percentage of unsuccessful results of all the floorplanning algorithms. By refer ring to the best results for differ-ent benchmark test cases in Table 4 ,H-CAShasanedgeoverall other algorithms in case of ami 49 benchmark. From the results of
TBS, MBS-OEA, ESA and HSA, it is found that each one of the above algorithms shows better results in only one of the benchmark test cases. Whereas, H-CAS shows better results in four of the remaining benchmark test cases as compared to TBS, ESA and HSA. As compared to MBS-OEA, H-CAS resul ts are the same in three bench-mark test cases (up to 11 blocks) and inferior in ami 33 benchmark, but H-CAS has the better result in the largest scale benchmark test case in MCNC benchmark. Moreover, the limited number of blocks (up to 50 blocks only) considered in all MCNC benchmark test cases, cannot wholly deal with the modern VLSI floorplanning problems where more than hundreds of blocks are handled normally. Thus, the empirical performance of H-CAS is further established by using larger scaled benchmark problems, namely GSRC benchmark. This will indicate the advantage of H-CAS over all the floorplanning algorithms. Fig. 10 shows the best result of ami 49 hard benchmark placement layout using H-CAS.
 Table 5 compares the GSRC benchmark results of H-CAS with
Chen et al. (2007) , MBS-OEA, MAEA-MBS, FAE, DPSO and ENDSGA while Table 6 shows the normalized whitespaces of these floor-planning algorithms and H-CAS. In general, H-CAS has given much improved results as compared to other floorplanning algorithms in terms of area minimization especially for problems with more than 30 blocks. In this paper, our main objective is to focus on area minimization using H-CAS and now once again through the
GSRC benchmark comparisons in Table 6 , it is proven that H-CAS has performed better than the other floorplanning algorithms available in terms of area. From Table 6 , it is evident that H-CAS results are better than 87% of the results obtained by the other floorplanning algorithms. Fig. 11 shows the best layout result of n 300 hard benchmark placement by H-CAS.
 It is to be noted that there are two existing floorplanners, BloBB and Parquet, which are based on hierarchical frameworks.
An experiment was carried out by simulating the proposed bottom-up hierarchical floorplanning algorithm to determine whitespaces by applying random-based and Simulated Annealing (SA) searches, and the results are shown in Table 7 . The normal-ized whitespaces are also shown in the same table. The compar-isons made among these four hierarchical based floorplanners show that the bottom-up floorplanning technique with SA or even without any heuristics tool (random search) can perform better in terms of area minimizations than that of the BloBB and Parquet.
As shown in Fig. 12 , in spite of SA approach giving better results as compared to the random search, its optimization results are only marginally better than the random search if the number of blocks is increasing. In other words, the results obtained by using random-based and SA approaches will be nearly in equal when the scale of the floorplanning is large. SA relies greatly on the initial solution generated and the size of the problem, and gets trapped into local optima when the number of blocks increases. By applying H-CAS, improved performances as compared to SA and random search were obtained. Moreover, H-CAS shows better Relative whitespace (%) Percentages (%) results in terms of area than the other floorplanning algorithms as depicted in Fig. 14 and discussed in detail.

Fig. 13 shows the percentages of successful, comparable and unsuccessful cases of H-CAS hard module floorplanning results for all the MCNC and GSRC benchmarks. H-CAS results are considered to be successful if they are better; comparable if they are the same or unsuccessful if they are inferior as compared to other algorithms. From Fig. 13 , it is observed that for problems with a maximum of 33 blocks, the near optimal results of H-CAS are comparable with the results of other floorplanning algorithms.
But, for problems with more than 33 blocks, H-CAS has given significantly improved results over the other algorithms. Fig. 14 shows the results of the proposed bottom-up floorplanner (random-based) and H-CAS in hard modu le floorplanning problems as compared to other existing algorithms by using the MCNC and
GSRC benchmarks. Based on the graph trendlines in Fig. 14 the results for problems with larger than 200 blocks can be predicted in advance as the relative whitespaces fairly remain constant through-out. In Fig. 14 , it is shown that the random search and SA approaches do not lead the proposed bottom-up floorplanner for improved solution as compared to the other state-of-the-art algorithms. This is because the random-based floorplanner approach relies on its randomness while the semi-exhaustive nature of SA ( Ranjan et al., 2001 ) requires substantial comput ational resources and hence unable to handle large scale VLSI floorplanning problems (dealing with 100 blocks and more) ( Yan and Chu, 2010 ; Hameen and
Gnanamurthy, 2009 ; Cong et al., 2006 ). H-CAS is developed to steer the optimization performance to a higher level. This can be readily observed that the whitespace resu lts of H-CAS are fast saturating and approaching a constant value, whereas, all other floorplanning algorithms tend to saturate to a higher value of relative whitespace than that of H-CAS. It is to be noted from Fig. 14 that although the recent algorithm HSA ( Chen et al., 2011 ) has marginally inferior trendline as compared to H-CAS, HSA has performed very poorly in terms of runtimes ranging from 6.5 to 5088 times slower than the
H-CAS, which is evident from Table 3 . Figs. 13 and 14 have shown improved H-CAS hard module benchmark results over other floor-planning algorithms in terms of scalability, stability and conver-gence. H-CAS has faster converging rate of relative whitespace as compared to other floorplanning algorithms as shown in Fig. 14 .
This shows that H-CAS X  X  relative whitespace results are less depen-dent on the problem size. This property will aid H-CAS in handling problems with larger number of blocks to fall in line with the recent trend in accommodating a larger number of transistors for VLSI placements.

As discussed in Section 5 , the runtime results are compared with recent floorplanning algorithms, namely MBS-OEA, MAEA-
MBS, Chen et al. (2007) , ESA and HSA. Fig. 15 shows the runtimes of MCNC and GSRC benchmarks simulated by the recent floor-planning algorithms as compared to H-CAS. Based on the graph trendlines, the runtimes of all the floorplanning algorithms are becoming longer than H-CAS when the size of the benchmark problems is increasing. 5.2. Floorplanning problems with soft module
For all the soft module problems, the minimum and the max-imum dimension ratio constraints of all the modules in the bench-marks are considered in the simulations by H-CAS. The best-so-far floorplan areas, the average floorplan areas, the relative whitespaces (in percentage), the standard deviations and the runtimes for the best-so-far permutations for soft module floorplan problems, which are carried out using H-CAS, are shown in Table 8 . Out of 21 best-so-far solutions, H-CAS shows zero w hitespace in 19 benchmark cases, which means around 90.5% of the soft module problems simulated with H-CAS have zero whitespaces. When the number of blocks 0 5 10 15 20 25 Relative whitespace (%) increases, the whitespaces remain at zero and this is adequate to justify that H-CAS is capable of handling soft module problems with larger number of blocks efficiently. Besides, 18 out of 21 (87.5%) soft module problems give zero standard deviations of the areas. It is shown that H-CAS is not only capable of handling large scale problems, and also provides consistent performance.

Table 9 compares the MCNC benchmarks with Young et al. (2001) ,CBLandMBS-OEA,while Table 10 is the normalized values from Table 9 .From Tables 9 and 10 , the results of H-CAS are found to be better in terms of area as compared to all the other algorithms and also H-CAS has shown much improvement in the results obtained when the number of modules has increased. In terms of runtimes, H-CAS results are compared with MBS-OEA, which is the only recent benchmark algorithm g iving soft module area optimiza-tion. From Table 10 , it is obvious that the runtimes of H-CAS are much shorter as compared to MBS-OEA. Though H-CAS was simulated on a slower PC, the runtimes of H-CAS are much faster ranging from 118 to 1127 times as compared to MBS-OEA. Fig. 16 shows the best layout of ami 49 soft benchmark placement layout using H-CAS.
 Table 11 compares H-CAS results with MBS-OEA using the
GSRC benchmarks. Normalized areas and runtimes are calculated to make the comparisons of the results of H-CAS and MBS-OEA obvious. H-CAS is consistent in giving improved area and run-times compared to MBS-OEA. The runtime results of H-CAS show improvement over MBS-OEA while the area minimizations are zero whitespace for all the cases. From Table 11 , H-CAS has shown much improved runtime of at least 7.23 times faster than MBS-
OEA in all the benchmark cases. Fig. 17 shows the best result of n 300 soft benchmark placement layout using H-CAS.

Fig. 18 shows that H-CAS optimal or near optimal results in soft module floorplanning problems as compared with other existing algorithms by using the MCNC and GSRC benchmarks results. Based on the trendlines of the graph, it is observed that there are two algorithms, namely Soft Modules with Lagragian
Relaxation and MBS-OEA, tending to reach higher values of relative whitespaces as the problem size increases. Referring to the rest of the algorithms, though the CBL algorithm is converging to lower values of relative whitespaces, still having a higher value of relative whitespace as compared to H-CAS. Among these four results, H-CAS trendline shows that the relative whitespaces obtained with H-CAS simulations remain at a very low value closer to zero when the number of modules increases, while the other algorithms give rise to higher relative whitespace values at convergence.
 6. Conclusion
A variable-order bottom-up hierarchical placer, namely Hier-archical Congregated Ant System (H-CAS) has been proposed which is capable of generating compact placements in a chip layout, both for soft and hard modules floorplanning. H-CAS adapts the basic concept of ant-based metaheuristics and has provided global solu-tions for variable-order bottom-up hierarchical placements. The unique properties of H-CAS are it s intercommunication, modified pheromone updates, congregations , and the experience sharing that leads to the formation of pheromone trails that belong to the new ant congregation. The reduction of 2D cost metric to 1D cost metric for hard modules floorplanning is proven mathematically and the solutions can be devoid of being trapped into local optima. Experi-mental results have shown that H-CAS performs much better than the other state-of-the-art algorithms in terms of area minimization, especially as the circuit size an d the complexity increase. The low standard deviations in the total placement areas clearly bring out the superiority of the precision and the stability of H-CAS. The runtime comparisons with the mos t recent floorplanning algorithms indicate the capability of H-CAS in achieving shorter runtimes.
Overall, the proposed H-CAS is fo und to be an efficient placer, in respect of scalability, convergence, precision, stability, and reliabil-ity. As evident from the graph, H-CAS excels all other algorithms for larger sized problems in area minimization. Further research on the application of H-CAS to other types of NP-hard problems is ongoing. Acknowledgement The authors would like to acknowledge ICT Research Cluster,
University of Malaya, Kuala Lumpur, Malaysia for the research fund support.
 References Relative Whitespace (%) 
