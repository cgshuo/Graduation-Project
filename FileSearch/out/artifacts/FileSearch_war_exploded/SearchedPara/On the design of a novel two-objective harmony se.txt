 1. Introduction
The increasing attention attracted by the so-called wireless sensor networks (WSNs) during the last decade stems from their capacity to efficiently sense physical phenomena, without the need of any wired link and at a reduced per-node computational complexity Akyildiz et al. (2002) . In addition to the classical monitoring applications for which WSNs were initially targeted, their proliferation and the value of their sensed information has ignited the interest in context-aware services and applications, in which the knowledge of nodes X  location becomes essential so as to provide valuable spatio-temporal information on the physical world and its dynamics. Hence, in such applications it is essential to associate the captured data with the location of the node at hand in order to make such sensed data meaningful ( Hu and
Evans, 2004 ). Indeed, the importance of localization is exempli-fied by a large number of applications such as vehicle and animal tracking, habitat monitoring, precision agriculture, location-based routing ( Ko and Vaidya, 2000 ), industrial sensing, infrastructure security and control of machinery, all of which inherently rely on location information of the constituent nodes of the WSNs.
From a theoretical point of view, effective location awareness in WSNs might be based on installing a global positioning system (GPS) on each compounding node of the network. However, the size constraints, the limited energy budget and the reduced cost imposed on such nodes make this solution unfeasible in practice. Another drawback of GPS-based schemes lies on the fact that they are not suitable for indoor and underground deployments, because of the lack of satellite coverage in these areas. Conse-quently, effective , yet also efficient node localization in WSNs is still considered to be a challenging paradigm in the scientific community, which has unchained an upsurge of alternative approaches to this problem.

In the majority of such alternative schemes, it is assumed that only a fraction of the nodes of the network, referred to as anchor nodes, know their coordinates either by resorting to the aforemen-tioned locally installed GPS devices, or by being placed at pre-defined geographical locations. The remaining nodes (denoted as non-anchor nodes) are able to infer their positions based on (1) the information on the location of the anchor nodes, (2) connectivity-based information, and (3) noisy pairwise distance estimations obtained through distance-ranging techniques, e.g. received signal strength (RSS) ( Alippi and Vanini, 2006 ), time difference of arrival (TDoA) ( Savvides et al., 2001 ) or angle of arrival (AoA) ( Niculescu and Nath, 2003 ). In this work we will focus on RSS based techniques, for which the maximum likelihood (ML) estimation is the most natural approach to tackle the localization problem.
However, the ML formulation of the problem, i.e. locating the nodes from a set of pairwise measured distances, results in a multivariable non-convex optimization problem ( Aspnes et al., 2004 ) for which different methods have been proposed in the literature, namely multidimensional scaling (MDS) ( Ji and Zha, 2004 ; Costa et al., 2006 ), semi-definite programming (SDP) ( Biswas et al., 2006 ) and stochastic optimization ( Kannan et al., 2005 , 2006 ). MDS, which is widely applied in data analysis, hinges on obtaining the relative coordinates of each node based on a starting distance matrix. On the other hand, SDP relaxes the original ML problem formulation in order to obtain an approximate solution at a reduced computational effort ( Biswas et al., 2006 ; Tseng, 2007 ).
Since the relaxation may increase the estimation error ( Wang et al., 2008 ), additional refinements, such as gradient descent search procedures ( Liang et al., 2004 ), are often employed to refine the initial solutions obtained by SDP ( Biswas and Ye, 2004 ). Finally, the third class of techniques considers heuristic optimization algo-rithms to efficiently solve the localization problem, such as simulated annealing (SA) ( Kannan et al., 2006 ) or genetic algo-rithms ( Vecchio et al., 2012 ). In this paper we concentrate on this last set by deriving a connectivity-and distance-based heuristic localization technique.

The localization problem is generally further complicated by the non-uniqueness of the nodes X  location in the network. Indeed, when tackled from a graph-theoretic perspective, the problem of finding a unique graph realization compatible with the inter-node distance measurements (i.e. the so-called network localizability problem) has gained momentum in the last years ( Jackson and
Jordan, 2005 ; Yang and Liu, 2011 ). Dense connectivity is obviously a principal requirement for a network to be localizable, even though a necessary and sufficient condition for the network localizability still represents an open research issue. The lack of localizability may lead to the so-called flip ambiguity phenom-enon, which generally occurs due to the almost collinear place-ment of the neighbors of a particular sensor node. In this case, although the node location is flipped with respect to the virtual line connecting its neighboring nodes, the estimated topology is still compatible with the inter-node distance measurements. This effect can propagate catastrophically to subsequent iterations affecting, in turn, the location estimates of other nodes of the network. Therefore, it is of utmost importance to identify possibly flipped nodes, and to perform some specific processing during the localization task in order to avoid, or at least alleviate, its effect on subsequent location estimates. The flip ambiguity phenomenon is exemplified in Fig. 1 where, since sensor nodes A, B, G and H are nearly collinear, node F can be reflected to position F 0 , while satisfying both distance and connectivity constraints. The effects of the flip in the estimated position of F can lead nodes C, D and E to be estimated at location C 0 , D 0 and E 0 , at their turn.
So far a number of heuristic locali zation approaches have speci-fically incorporated strategies for efficiently dealing with flip ambi-guities in sparse networks. For instance, the authors in Kannan et al. (2005) proposed a two-phased simulated annealing (SA) approach tackling the localization problem in presence of the flip ambiguity phenomenon. During the first phase, SA is used to obtain an accurate estimate of the node locations by minimizing the squared error between the estimated and the measured inter-node distances while, in the second phase, an additional error term is added to the cost function when the estimated node location violates the connectivity constraints imposed by the network topology. Likewise, the same authors in Kannan et al. (2010) propose a robust criterion to detect flip ambiguities and enhance the reliability of the estimations by rejecting flipped nodes from being included in the localization process. More recently, a two-object ive evolutionary algorithm based on the Pareto archived evolution strategy (PAES) is presented in
Vecchio et al. (2012) . There, the first objective function to be minimized, denoted as CF, is given by the squared error between the estimated and the measured inter-node distances. The second objective function, referred to as CV, is defined as the sum of neighborhood violations in the candidate topology. The obtained results show that the multi-objective treatment of the problem outperforms SA in terms of normalized location error (NLE) for a wide set of network topologies.

Thispaperadvancesoverthestateoftheartbyproposinganovel two-objective heuristic localization algorithm based on the combina-tion of the Harmony Search algorithm with a novel local search procedure that alleviates the effects of the flip ambiguity phenom-enon. Similar to the PAES-based counterpart, each candidate solution is evaluated in terms of both localization accuracy (CF) and con-nectivity constraint violation (CV). Our proposal, hereafter referred to as non-dominated sorting harmon y search (NSHS), resorts to the same ranking and crowding estimation operators used by the non-dominated genetic algorithm-II (NSGA-II, Deb et al., 2002 )inorderto achieve a wide and uniformly covered Pareto-optimal front approx-imation. The obtained simulation results show that our approach outperforms the multi-objective PAES-based approach proposed in
Vecchio et al. (in press) for a number of different network topologies and performance metrics.

The rest of the paper is structured as follows: in Section 2 the node localization problem is mathematically formulated, whereas
Section 3 delves into the proposed NSHS multi-objective algo-rithm. Section 4 presents the simulation framework and discusses the obtained experimental results in terms of normalized locali-zation error (NLE) and different unary multi-objective quality indicators, i.e. the hypervolume, the unary-E and the R 2
Finally, concluding remarks are discussed in Section 5 . 2. Problem statement
The node localization problem can be mathematically defined by considering a WSN composed by a set of n nodes uniformly deployed in T R 2 , out of which the first m o n nodes represent the set of anchor nodes, whose coordinates p i  X  X  x
T  X  i A f 1 , ... , m g X  are fixed and assumed to be known a priori for the localization algorithm. The problem consists of estimating the anchor nodes, assuming that any two sensor nodes in the connectivity range of each other, say i and j , can estimate their inter-node distance d ij by resorting to any of the measure-ment techniques listed in Section 1 . In the following, d modeled as d  X  where r ij 9 J p i p j J represents the actual (real) distance between node i and j ( J J denotes the Euclidean norm), and e ij stands for the measurement error.

We assume that each node knows which nodes it can com-municate with. Let us define the n n binary connectivity matrix
C , such that c ij  X  1 if sensor nodes i and j are within the connectivity range of each other, i.e. if r ij r R , where R represents the radius of the circular coverage area of every node of the network. Hence, we can define the set of neighbors of node i as
N 9 f j A f 1 , ... , n g , j a i : r ij r R g X  2  X  and its complementary set N i , composed by those nodes placed outside the coverage area of node i . Observe that the positions of anchor nodes and the connectivity range determine the regions in which each non-anchor node can (or cannot) be located. This information can be exploited in the initialization phase and during the localization process to further refine the position estimates of the non-anchor nodes.

The goal of the localization algorithm is to estimate the positions of all non-anchor nodes as accurately as possible given
R , C and f p i g m i  X  1 . To this purpose, two different, though related, objective functions to be minimized can be defined: CF (cost function) and CV (constraint violation). In detail, the first objec-tive function CF is defined as
CF 9 X n where d ij represent the measured inter-node distances given in expression (1), while ^ d ij represent the estimated distances between nodes i and j and computed as ^ d 9
Therefore, CF represents the squared error between the estimated and the measured inter-node distances of those nodes that are in the connectivity range of each others. The second objective function, CV, takes into account the number of connectivity neighborhood constraints violated by the candidate topology. In words, a node j fulfilling j A N i for a given i causes a violation of the connectivity constraints given by C if its estimated position lied outside the transmission range of node i or, equivalently, if ^ d o R provided that j A N i . Thus, CV can be formally defined as
CV 9 X n
Thus, both CF and CF leads to the multi-objective formulation of the localization problem min
Finally, in order to a posteriori evaluate the accuracy of an estimated topology we use the normalized localization error (NLE) defined as NLE 9 100 R where NLE  X  0% corresponds to the case of a perfect estimation. 3. The proposed NSHS algorithm
The bi-objective minimization problem posed in expression (6) will be tackled by means of a multi-objective formulation of the so-called harmony search (HS) algorithm ( Geem et al., 2001 ). HS is a relatively new population-based metaheuristics that imitates the music improvisation process when seeking the most harmo-nious melody. Since its first publication in 2001, it has been widely applied for solving several optimization problems in different application fields such as vehicle routing ( Geem et al., 2005 ), multicast routing ( Forsati et al., 2008 ), multiuser detection ( Zhang and Hanzo, 2009 ; Gil-Lopez et al., 2009 ), engineering design ( Liao, 2010 ), radio resource allocation ( Del Ser et al., 2012 , 2011 ) and the access node location problem ( Landa-Torres et al., 2011 ). A thorough review of the HS algorithm, its comparison with other metaheuristic approaches and a number of related applications can be found in Geem (2009) . However, to the best of our knowledge, no previous work has been reported in the scientific community dealing with the application of multi-objective HS to the node localization problem.

Given its population-based nature, HS relies on a set of candidate solutions f H  X  k  X g K k  X  1 (harmony memory), which are iteratively refined by means of intelligent combination and mutation operators applied note-wise. Adopting the classical notation of the related literature, in the following we will refer to a possible candidate set H  X  k  X  as harmony or melody , whereas a note denotes any of its compounding entries h l ( k ), with k melody represents the positions of all the nodes of the network, thus the harmony memory can be redefined as H  X  k  X  9 f ^ p numbers representing the ( x , y ) coordinates of the anchor nodes (which are assumed to be known a priori), whereas the remaining n m pairs ( i  X  m  X  1, y , n ) correspond to the estimated coordi-nates of the non-anchor nodes of the network. Thus, the impro-visation process of the proposed HS algorithm will be only applied to the estimated positions of the non-anchor nodes (i.e. the second part of the melody or, equivalently, f ^ p i  X  k  X g can be located in the areas defined by the topological constraints described in the previous section.

Briefly, the improvisation procedure is controlled by three different stochastic operators, each driven by its corresponding probabilistic parameter: the harmony memory considering rate (HMCR), the pitch adjusting rate (PAR) and the random selection rate (RSR) 1 . After the improvisation procedure, the value of the two objective functions (CF and CV) are separately computed for each improvised harmony and the best K harmonies (with respect to the fitness values and the spread, the latter measured in terms of crowding distance as in Deb et al., 2002 ) are kept in the harmony memory for the next iteration. This procedure is repeated until a fixed number of iterations I HS is completed.
The flow diagram of the proposed NSHS algorithm is depicted in Fig. 2 , and consists of five steps: A. The initialization process is executed only at the first iteration.
At this step, the initial K harmonies are arranged by fixing 8 k  X  1 , ... , K the first m notes to the actual positions of the anchor-nodes (i.e. f h i  X  k  X g m i  X  1  X f ^ p i g m i  X  1 f x , y i g m i  X  1 ) and by generating the remaining n m notes at random, within the topological constraints imposed on the corresponding n m non-anchor nodes.

B. During the improvisation procedure, the stochastic operators are sequentially applied to each note of the harmonies so as to produce the new set of K improvised harmonies (i.e. candidate positions). In detail, 1. HMCR A  X  0 ; 1 sets the probability that the new value for a 2. PAR A  X  0 ; 1 refers to the probability that the new value for a 3. The random selection rate, RSR A  X  0 ; 1 , acts in a similar C. Additionally, a local search procedure is performed every I iterations. The details of this refinement procedure will be given in Section 3.1 .

D. At each iteration the generated harmonies are evaluated in terms of CF and CV (expression (3) and expression (5), respectively). Then, as explained in Kalyanmoy et al. (2000) , each current and improvised harmony is associated with a rank equal to its non-dominance level (1 for the best level, 2 for the next-best, and so on). Then, within each front, a specific crowding measure representing the sum of distances to the closest harmony along each objective is used to define an ordering among the harmonies: in order to cover the overall objective space, harmonies with large crowding distance are preferred to harmonies with small crowding distance. Thus, the harmony memory is filled by selecting the best K harmo-nies (considering first the ordering among the fronts and then among the harmonies).

E. If the iteration counter nIter o I HS , the algorithm iterates by setting nIter  X  nIter  X  1 and returning to step B. Otherwise, the algorithm stops and the set of harmonies belonging to the first non-dominance level represents the Pareto front approximation. 3.1. Local search procedure
The proposed local search procedure is triggered every I LS iterations, at the end of the improvisation procedure. When invoked, it is executed on each non-anchor node i (1) lying outside the coverage area of any anchor node; and (2) whose any of its neighbors in the estimated topology violates the connectivity constraints imposed by the i -th row of C . Fig. 3 depicts an example of the application of the local search proce-dure to the estimated node 1 0 in a simplistic scenario. In this setup, anchor nodes A, B and C are represented by crosses ( ), whereas real and estimated positions of non-anchor nodes are denoted with circles  X  J  X  and squares ( &amp; ), respectively. Real and estimated positions of node 1 (to which the local search proce-dure is applied) are highlighted by filling the marks in black ( and  X  , respectively). In this setup, the real connectivity matrix C and the estimated connectivity matrix C 0 are given in Fig. 4 . Note that C is provided as an input parameter to the algorithm, whereas C 0 can be inferred for every candidate topology.
The fact that non-anchor node 1 0 lies outside the coverage range of any anchor node and has some false neighbors implies a violation in the connectivity constraints imposed by C (i.e. 7 0 and refined. The next step is to identify the group of nodes to be moved together with node 1 0 , so as to avoid generating new connectivity violations. Specifically, this group will be composed by selecting those non-anchor nodes that are not inside the coverage range of any anchor node, but are real neighbors of node 1. Thus, in this specific case, the group will be composed by to any actual neighbors of node 1 (nodes A, B and C) define the region in which node 1 0 can be located. This region comprises the intersection of the annuli with inner and outer radii R and 2 R respectively, centered in the selected anchor nodes, under the condition that the number of false neighbors decreases. Finally, coverage region of node 1 0 (see Fig. 3 ). 4. Numerical results
In order to assess the performance of the proposed multi-objective NSHS algorithm in tackling the node localization pro-blem in WSNs, a comparison study between the NSHS and the PAES-based approaches has been performed based on extensive
Monte Carlo simulations. In these simulations the localization technique proposed in Vecchio et al. (in press) will be used as a reference for the comparison, as it was shown to be more effective with respect to the Simulated Annealing-based counterpart in
Kannan et al. (2006) . 4.1. The PAES-based approach to the node localization problem
The PAES algorithm was introduced in Knowles and Corne (2000) and probably represents the simplest possible non-trivial algorithm capable of generating diverse solutions in the
Pareto optimal set. Further, PAES is characterized by a lower computational complexity than traditional niching methods ( Knowles and Corne, 2000 ; Coello et al., 2006 ). Briefly, it consists of three steps: (1) generation of a candidate solution c ; (2) muta-tion of c so as to produce a new candidate solution m ; and (3) replacement of c with m if m dominates c , or inclusion of m in the archive of non-dominated solutions if it is not dominated by any solution already included in the archive. The archive of non-dominated solutions is divided into a number of equally sized regions for which a crowding degree value is determined by counting the solutions associated to each region. This approach prioritizes solutions associated with scarcely crowded regions, so as to increase the diversity in the Pareto front. The algorithm stops after a maximum number of iterations, and the final archive of non-dominated solutions represents the Pareto front approx-imation. For more details on PAES the reader should refer to Knowles and Corne (2000) and Coello et al. (2006) .

Regarding the specific PAES-based approach to the node localization problem presented in Vecchio et al. (in press) , two ad-hoc mutation operators, namely the node mutation and the neighborhood mutation operators, are used. The first mutation operator performs a uniform-like mutation with probability P which the mutated position of a randomly selected non-anchor node is generated within its topological constraints. If not applied, then the second mutation operator is executed. It also mutates the position of a given non-anchor node considering its topolo-gical constraints, but it further applies the same translation to the neighbors of the node with a certain probability P N . In addition to the topological constraints imposed by the connectivity matrix C , the PAES-based approach in Vecchio et al. (in press) defines a new type of node which is second-level neighbor to at least one anchor node. Thus, its position is forced to lie within the intersection of the annuli with inner and outer radii R and 2 R , respectively, and centered in the anchor nodes which it is second-level neighbor to. 4.2. Simulation setup
The simulation framework consists of 12 different network topologies built by uniformly placing n  X  200 nodes in
T 9  X  0 ; 1  X  0 ; 1 . Out of these nodes, 10% are assumed to be the anchor nodes (i.e. m  X  20), while the remaining n m  X  180 nodes represent the non-anchor nodes to be localized. Moreover, three to model different degrees of network sparsity. We assume that the inter-node distances are estimated from RSS measurements, which are generally affected by log-normal shadowing ( Liu et al., 1998 ). Therefore, the errors e ij follow a zero-mean distribution with variance s 2 . Note that the variance of e ij in expression (1) is the scenarios.

Table 1 summarizes the values of the parameters used in the execution of both algorithms. 2 It should be pointed out that a fair comparison in terms of computational complexity has been targeted by imposing an equal number of fitness evaluations between the compared algorithms. In this context, the number of fitness evaluations for both algorithms equals 10 5 in all the simulated cases (i.e. K I HS for NSHS and I P for the PAES-based approach).

Finally, the simulation results have been obtained by perform-ing 30 Monte Carlo experiments for each algorithm and network scenario. 4.3. Simulation results
As a preliminary step, in order to quantitatively compare the approximated fronts obtained by the two multi-objective sto-chastic solvers on each simulated scenario, we have computed three unary Pareto-compliant quality indicators. In particular, to compare the NSHS and the PAES approaches we have used the hypervolume indicator ( Zitzler and Thiele, 2009 ), the unary-E indicator ( Zitzler et al., 2003 ) and the R 2 indicator ( Hansen and
Jaskiewicz, 1998 ), computed in the performance assessment package provided in the PISA toolkit ( Bleuler et al., 2003 ), and whose features and properties have been discussed in detail in
Zitzler et al. (2003) . Here, the lower the value of the indicator is, the higher the quality of the corresponding algorithm is.
Fig. 5 shows the box plots of the distributions of three indicators obtained by the two multi-objective solvers, in all the considered scenarios, with the following notation: P and NH stand for PAES and NSHS, respectively; 1, y ,12 denote the network topologies; whiskers are used to represent the lowest and largest values of the distribution; the boxes delimit the lower and the upper quartiles; the medians are depicted with a solid line and the outliers are eventually marked with asterisks. By analyzing the box plots we can observe that the proposed NSHS approach produce significantly better multi-objective performance indica-tors with respect to the PAES counterpart. For verifying whether the distributions of the different indicators are statistically different, we have performed a two-sided rank sum test (Wil-coxon test). The different colors of the box plots have been used to represent the results of the non-parametric test applied to each distribution of the indicators, for each scenario. Briefly, the test compares the medians of two samples, and returns the p -value for the null hypothesis that the samples are drawn from the same population. If the p -value is lower than 0.05, we deduce that the null hypothesis does not hold, that is, the sample medians are significantly different from each other. A white box plot denotes the best distribution of the indicator values obtained for a specific topology. A black box plot identifies a distribution of the indicator values whose median is larger than the median of the correspond-ing white box plot with a statistical significance. A gray box plot denotes a distribution of the indicator values whose median is larger than the median of the corresponding white box plot, but the difference between the medians is not statistically significant.
We observe that NSHS was always able to produce, for all the considered scenarios, better distributions of the three indicators, with statistical significance. Furthermore, the coverage rate (C-metric) has been calculated based on the approximated dominant front for all scenarios obtaining a value of C(NSHS,PAES)  X  1, hence supporting the claim that NSHS dominates PAES with respect to Pareto dominance.

Moreover, in order to evaluate and compare the localization accuracy of the two approaches, we use the normalized localiza-tion error (NLE) formally posed in expression (7). Table 2 lists, for every scenario, algorithm and averaged over 30 Monte Carlo experiments, the mean, minimum and standard deviation of the
NLE values associated to the topologies belonging to the approxi-mated Pareto front produced after I P (correspondingly, I iterations. Note that in light of the obtained results, NSHS in general outperforms the previously published PAES approach in terms of minimum, mean and standard deviation of the NLE values associated to the topologies embodying their estimated fronts.

To shed more light on the obtained NLE results, the distribu-tion of the best NLE values is computed by selecting, within the corresponding 30 Monte Carlo experiments, the minimum NLE values associated to each approximated non-dominated front for each algorithm and scenario. Fig. 6 shows the results, again in box plot fashion. The results elucidate a quite stable behavior of both algorithms, as shown by the equally balanced lower and upper quartiles, whiskers close to the quartiles boundaries and a relatively low number of outliers. However, it can be observed that the outliers of PAES are in general more distant from the medians, being lower for NHSH. Again, for verifying whether the distributions are statistically different, we have performed a two-sided rank sum test (Wilcoxon test) with a confidence interval of 95%, and exploited the same color notation as before for the boxes, to highlight the best median (white box) and whether the worse median is statistically significant (black box) or not (gray box). We observe that only for topology 4 PAES outperforms NSHS with statistical significance. For all the remaining topologies NSHS outperforms PAES: in particular NSHS gave better results with statistical significance in all the remaining scenarios, except for scenarios 1 and 2 where the null hypothesis of equal medians could not be rejected.

Finally, in order to evaluate the benefits introduced by the local search procedure, Fig. 7 depicts the behavior of the CF and CV fitness functions, averaged over the harmony memory at each iteration, for two different runs of NSHS executed on scenario 1, with and without the application of the local search procedure, respectively. It can be observed that the introduction of the local search procedure positively affects the convergence of both the metrics. We have verified that this positive effect does not depend on the specific topology, and is directly reflected also in the NLE metric: for scenario 1, the statistical (mean/min/std) NLE perfor-mance degrades from 29.11/15.62/8.82 to 88.70/56.19/19.09 when the local search procedure is removed from the NSHS algorithm.
 5. Concluding remarks
In this paper we have presented a novel multi-objective heuristic localization technique for wireless sensor networks based on the harmony search algorithm. The proposed approach is further aided by a local search procedure that aims at alleviat-ing the so-called flip ambiguity phenomenon. The proposed algorithm exploits the information on the node connectivity by imposing geometrical constraints so as to bound the areas where nodes can be placed. Through extensive computer simulations, it is shown that our approach embodies a cost-effective localization scheme that outperforms, in terms of multi-objective quality and localization accuracy, a state-of-the-art localization approach based on the PAES algorithm, for the majority of the simulated scenarios.
 Acknowledgments
This work has been supported in part by the Spanish Ministry of Science and Innovation through the CONSOLIDER-INGENIO 2010 (CSD200800010) funding program and the projects ECO2010-22065-C03-02 and TEC2011-28250-C02-02 (ACORDY). References
