 1. Introduction originating from heart disease occur at a high rate. Early diagnosis of heart disease is one of the most important areas of medical investigation.
 parameters such as blood volume and pressure within the heart.
Heart sounds are normally the result of valve closure and blood flow within the heart and arteries ( Ahlstr  X  om, 2006 ). In other words, these sounds are produced by the motion of myocardial walls, the opening and closing of valves and blood flow into and out of the chambers. Heart sounds are the combination of two repeating, dominant sounds, known as the first heart sound ( S1 ) and the second heart sound ( S2 ). S1 occurs during closure of the mitral and tricuspid valves. S2 occurs during closure of the aortic and the pulmonary valves ( G  X  uler et al., 1996 ).
 segments: mitral, tricuspid, pulmonary and aortic. These seg-ments are related to blood flow, not anatomical structures.
Sounds are monitored within each of these segments and they are evaluated together to identify abnormal segments and deter-mine the source of the problem ( Say, 2002 ).
 ventricle. Reduction of the mitral valve opening causes mitral stenosis (MS). This abnormality may be congenital or may develop later in life. The pulmonary valve is located between the right atrium and the pulmonary artery. Pulmonary stenosis (PS) is a disease that occurs due to increased blood flow to the lungs through the pulmonary valve. It is one of the most common diseases that occur in adults and, if left untreated, it may cause serious problems ( Crawford, 2002 ).
 In this study, a system has been developed for diagnosing
MS and PS diseases. Because structural heart abnormalities are usually reflected in heart sounds, sounds from the mitral and pulmonary segments have been used for the detection of these abnormalities.

One of the most common methods of auscultating to heart sounds is with a stethoscope ( Sinha, 2003 ). An important problem with this method is that it requires a doctor with experience and ability. Furthermore, problems such as inappropriate environ-mental conditions and patient incompatibility can cause deficien-cies in diagnosis ( O X  Rourke, 2000 ). All of these reasons have led researchers to design support systems to help doctors evaluate heart sounds. Such systems enable better interpretations of heart sounds and can result in more accurate diagnoses. Examination of heart sounds via a computer is also easier and cheaper than examination with only a stethoscope.

Using heart sounds for the detection of heart disease is a pre-valent research topic in the literature. Normal heart sounds, MS and mitral regurgitation diseases have been classified by performing frequency estimation from heart sound signals ( Sharif et al., 2000 ).
El-Sagaier et al. have improved an algorithm for the detection of the first and second heart sounds ( S1 and S2 , respectively). They have used DFT to analyze heart sound signals in a study in which the pediatric department X  X  patients are benefitted ( El-Segaier et al., 2005 ). Folland et al. have applied fast Fourier transform and Levinson X  X urbin algorithms to heart sounds in order to analyze abnormalities. They have classified t he resulting features using multi layer perceptron (MLP) and radial basis function (RBF) classifiers ( Folland et al., 2002 ). Reed et al. have employed wavelet transform (WT) and artificial neural network (ANN) algorithms to analyze and classify heart sounds ( Reed et al., 2004 ; Sinha et al., 2007 ). Pavlopoulos et al. have developed a decision tree-based method for the detection of aortic stenosis and mitral regurgitation disease using heart sounds ( Pavlopoulos et al., 2004 ). Voss et al. have classified features obtained from normal and aortic valve stenosis heart sound signals with the help of WT and Fourier transform using the linear discriminate functi on analysis method ( Voss et al., 2005 ).
PCA is commonly used as a dimension reduction method in biomedical applications. It can be used in medical diagnosis and treatment studies ( Sinha et al., 2007 , Macpherson et al., 1984 ). Li and Chutatape (2004) have used PCA for basic feature extrac-tion from images in color retinal photography (a tool for detecting various eye diseases). Landis et al. (2001) have used PCA to characterize specific properties of the peripheral vasculature in a dynamic optical tomography method.

DFT, WT and Fourier transform are frequently used methods in the literature. DFT has been chosen for this study because it is easy to implement. Thus, an important advantage of the biome-dical system described in his study is that it was designed to be easily applicable and highly accurate.

Two data sets have been employed in this study. The first data set required pre-processing for feature extraction and dimension reduction. It contained three classes: healthy, PS and MS subjects. First, heart sound signals were obtained with a stethoscope. Then, features were extracted from the heart sound data. In this stage, DFT was used to obtain the frequency spectrum of the heart sound signals. In other words, the heart sound signals were converted from the time domain to the frequency domain. Because there were many extracted features, feature reduction was preferred for easy and effective classification. PCA, the most frequently used reduction method in the literature, was chosen for this study. In the final stage, the reduced features were subjected to classification by a DHMM. The experimental results showed that the proposed method efficiently classifies heart sounds. The second data set was the SPECTF heart diagnosis set from UCI Machine Learning Repository. These data did not require pre-processing for feature extraction, but they did require processing for dimension reduction.
The difference between this study and other studies that address the same topic is that a strong classifier system has been created by combining PCA and DHMM methods, which has very important implications for dimension reduction and sound clas-sification. Furthermore, this method yields more efficient results than any of the other methods tested in this study.
 The details of this study have been organized into 4 sections. In Section 2 , the procedure for acquisition of heart sound signals and the theoretical background of techniques implemented in this study have been explained. In Section 3 , the classification of heart sounds used for diagnosis has been explained. Finally, conclusions and suggestions have been described in Section 4 . 2. Methods
In this section, measurement of heart sound signals with a stethoscope, feature extraction from heart sounds by using DFT, feature reduction and classification stages have been explained. 2.1. Subjects
In this study, two datasets have been used. The first data set consists of the heart sounds obtained by G  X  uraksin from Afyon Kocatepe University Cardiology Clinic in the course of his master X  X  valve disease has been developed based on heart sounds from 120 subjects, 40 healthy subjects, 40 MS and 40 PS. The group contains 55 males and 65 females with an age range of 4 X 65 years old. The training set contains 60 samples (20 from each class: healthy, MS and PS), and the test set contains the remaining samples.
The second dataset is the SPECTF heart diagnosis set. This set has 44 continuous attributes. Samples are classified in two categories: normal and abnormal. The training set contains 80 samples (40 from each category) and the test set contains 187 samples. 2.2. Measurement of heart sound signals
In the first data set, heart sounds have been collected by lightly touching a Littman 4100 model electronic stethoscope to the chest wall. The Littman 4100 model electronic stethoscope can record up to 6 sets of sounds within its memory. Heart sounds taken from 6 patients in a row can be registered in the stetho-scope X  X  memory. The collected heart sounds have been sampled at 8 kHz. Ambient sounds have been reduced by 75% ( 12 dB) on average via the stethoscope X  X  noise reduction technology without eliminating critical body sounds. The sounds have been recorded in  X  X  e4k  X  X  format ( G  X  uraks X n, 2009 ) and then converted to  X  X  X av X  X  format using a program supplied by Littman. Afterwards, the heart sounds have been translated into digital form by a custom
C# application. 2.3. Feature extraction via DFT
When the signals used in biomedical applications are analyzed and investigated, in practice, most signals are collected as time domain signals and the measured quantity is a function of time.
Because a time domain signal is not preferred, the signal must be transferred to a different domain by employing a mathematical transform. In this new domain, information about the signal has been obtained from its representative components. The frequency spectrum of a signal is obtained via Fourier transform. Thus, undetectable information in the time domain has been trans-ferred to the frequency domain ( Say, 2002 ).

Unlike some series that are defined as theoretical, Fourier trans-form of a real series cannot be calculated. Thus, it is inappropriate to apply Fourier transform to digital signals. The main reason for this impropriety is that frequencies need to be represented as analog signals, which requires an infinite number of samples ( G  X  uraks X n, 2009 ). Furthermore, Fourier transform investigates which frequency components exist in a signal, rather than containing any information about the moment in time when these components arise. Thus, sounds which have the same frequency but are generated in different regions of the time domain will correspond to the same region within the frequency spectr um.Asaresult,thiswillcausethe classifier to produce incorrect results ( G  X  uraks X n, 2009 ).
Because of these difficulties and the importance of Fourier transforms in signal processing, a more applicable transform needs to be defined. This yields more practical solution called
DFT, which is defined for N frequency points properly positioned around a unit circle and for N samples of an x ( n ) series. DFT calculations are used in many engineering applications.
A feature of this transformation, which can be inverted for a time series, is very robust. It is identical to the mathematical features of a Fourier integral transform. DFT defines the spectrum of a time serial ( Cochran et al., 1967 ). The most important feature of DFT is that the multiplication of two DFTs in the time domain is equal to the convolution sum of the series. Moreover, the fundamentals of many spectral analysis methods are based on DFT.
 A r  X  the k th sample of a time serial that consists of N samples. X complex numbers, but A r coefficients are always complex numbers. sound signals have been obtained using DFT. Thus, the features that represent heart sounds have been obtained by transforming heart sound signals from the time domain to the frequency domain. After performing DFT, the 0 X 300 Hz frequency spectrum 2009 ). An example of a heart sound waveform from a healthy subject and a spectral graph after applying DFT are presented in
Fig. 1 (a) and (b), respectively. 2.4. Dimension reduction via PCA chosen for features extraction. Dimension reduction has been implemented to investigate its effects on classification. PCA, which is a linear technique, converts a data set from its m-dimensional original form into a new, smaller p -dimensional form. Thus, the training period of a DHMM will be shorter because it has fewer observation numbers than the original set. In addition to reducing input variables in the dataset, the use of PCA will also increase the classification performance of a DHMM.

The number of principal components obtained via PCA is the same as the number of variables. One of the main advantages of PCA is representing m variables in the form of p numbered variables, where p o m . In this case, the most appropriate p principal component should be selected from all of the principal components to represent the data. There are some criteria to determine the optimal number of principal components.  X  X  X roken stic k model, Velicer X  X  partial correla-tion procedure, cross-validation, Ba rtlett X  X  test for equality of Eigen values, Kaiser X  X  criterion, Cattell  X  X  scree test and cumulative percen-tage of variance X  X  are some examples of these criteria ( Ferr, 1995 ). In this study, different numbers of p principal components have been selected to observe their effects on classification.

PCA analysis indicated that 300 principal components have been obtained for 300 features. The cumulative percentage of variance values corresponding to select p values from the 300 principal components have been given in Table 1 . 2.5. Classification using a DHMM
A hidden Markov model (HMM) is a stochastic finite state machine (FSM) and a double-layered finite state stochastic process with a hidden Markovian process to control selection of states of an observable process. In general, a HMM has N states and transitions between these states are available. The system is in each of these states at different times. Each state transition has an associated pro-bability and each state has an associ ated observation output (symbol).
A HMM is characterized by the following items ( Rabiner, 1989 ): 1. N represents the number of states that belong to the model.
The set of individual states is denoted as S  X  { S 1 , S 2 state at time t as q t . 2. T represents the number of observations. A typical observation sequence is denoted as
O  X  O 1 , O 2 , ... , O T  X  2  X  3. A  X  { a ij } is the state transition probability distribution of size
N N , which defines the probability of transition from state i at time t , to state j at time t  X  1. a ij  X  P  X  q t  X  1  X  S j 9 q t  X  S i  X  , 1 r i , j r N  X  3  X  distribution of observation symbols for each state. Here, b the observation symbol probability in state j and M is the number of the observation symbols. any given state, where p i  X  P  X  q 1  X  S j  X  , 1 r I r N  X  4  X 
Complete specification of a HMM requires model parameters and three probability measures: A , B , p . The HMM parameters use the following set: L  X  A , B , p  X  5  X  Given the form of the HMM, there are three main problems that must be solved: Problem I. Given the observation sequence O  X  O 1 , O 2 , a HMM model l , how do we efficiently calculate P ( O 9 l ), the probability of the observation sequence? This problem is called Evaluating. Evaluating problem was solved using forward X  backward algorithms ( Rabiner, 1989 ).

The forward variable a t ( i ) has been defined as in Eq. 11 and for all the equations below: 1 r i r N ,1 r m r M .  X  i  X  X  P  X  O 1 O 2 ... O t , q t  X  S i 9 l  X  X  6  X  It can be solved as follows:
Initialization:  X  i  X  X  p i b i  X  O 1  X  , t  X  1  X  7  X 
Induction: Termination: P  X  O 9 l  X  X  In a similar manner, the backward variable b t ( i ) has been defined as equality 15. b  X  i  X  X  P  X  O t  X  1 O t  X  2 ... O T 9 q t  X  S i , l  X  X  10  X  We can solve for b t ( i ) inductively, as follows:
Initialization: b  X  i  X  X  1 , t  X  T  X  11  X 
Induction: b  X  i  X  X  Termination: P  X  O 9 l  X  X  Problem II. Given the observation sequence O  X  O 1 , O 2 , and a HMM model l , how can we find the optimal correspond-ing sequence of states O  X  O 1 , O 2 ,.., O T ? This problem is called Decoding . Decoding problem was solved using a forward algorithm.

Problem III. Given the observation sequence O  X  O 1 , O 2 can we find a HMM model parameter l which maximizes the probability of observation sequence P ( O 9 l )? This problem is called
Training . Training problem was solved using a Baum X  X elch algorithm ( Rabiner, 1989 ).

To implement the solution, define the variable g t ( i ) which is the probability of being in state S i at time t given the observation sequence O , and define x t ( i , j ) the probability of being in state S time t and S j at time t  X  1, given the model and observation sequence.  X  i  X  X  P  X  q t  X  S i 9 O , l  X   X  a t  X  i  X  b t  X  i  X  = P  X  O 9 l  X  X  14  X  x  X  i , j  X  X  P  X  q t  X  S i , q t  X  1  X  S j 9 O , l  X   X  a t  X  i  X  a ij b j  X  O t  X  1  X  b t  X  1  X  j  X  = P  X  O 9 l  X  X  15  X  We can write: x t  X  i , j  X  X  expected number of transition from S i to S j t  X  i  X  X  expected number of transition from S i  X  17  X  Using the above formulas, we can provide a method for Baum X 
Welch re-estimation of parameters of a HMM. The Baum X  X elch re-estimation formulas have been defined in the following equal-ities [23 X 25].  X  g 1  X  i  X  X  18  X  a  X  b  X  k  X  X  3. Experimental results The first method applied for classification of heart sounds is
DHMM. In this application, both data sets have been subjected to classification processes without performing dimension reduction. The parameters used in the DHMM have been given in Table 2 .
The VQ process and number of states of a DHMM classifier are the most important factors that affect its classification perfor-mance. Therefore, the VQ dimension and number of states have been varied in these experiments to obtain the best classification performance. In this study, a Fuzzy C Means algorithm has been used for the VQ process.

The results obtained at the end of this stage have been used in the three classes listed in Tables 3 and 4 . In these tables, the results have been computed by selecting one of the decision classes (PS for Table 3 and MS for Table 4 ) and grouping the other two classes in the confusion matrix. The SPECTF data set results are shown in Table 5 .
 specificity and the accuracy. These are statistical measures for evaluating the performance of a classification test. Sensitivity is division of the number of true positive decisions by the actual number of positive cases. Specificity is division of the number of false positive decisions by the actual number of negative cases.
The accuracy is used and corresponds to the mean of the confusion matrix.
 increase the classification accuracy and reduce the processing time of the DHMM. PCA has been applied to m -dimensional data and the selection of p parameters determines how much this dimension is decreased. By running the system with different p values, the effects of p parameters on classification accuracy have been investigated. For this purpose, 10 values between 3 and 40, each of which is the mentioned p value, have been examined on the first data set. The classification accuracy is obtained using the DHMM. The results for selected p values have been presented in Table 6 .

As seen in Table 6 , the most successful classification results have been obtained when 20 X 30 principal components are chosen. The best classification results occurred when the cumu-lative range of principle components was 0.93 X 0.98. Similarly, the best classification results occurred for SPECTF data set using PCA-DHMM when p value of PCA has been obtained as 4 ( Table 9 ).
The proposed method has been compared to a DHMM without reducing features; ANN-based method and a k Nearest Neighbor (kNN) classifier. The comparison results for the first data set (PS and
MS, separately) and SPECTF data set have been presented in Tables 7, 8and9 , respectively. In these tables, the results obtained from the
ANN-based method are taken from a study performed by G  X  uraks X n (2009) . In his study, the tree-layered feed-forward ANN architecture consists of 300 inputs, 80 hidden layer and 3 output layer neurons.
Sigmoid has been selected as an activation function. The best values of these parameters have been selected via trial and error. Training of the weights has been implemented via back propagation. As it can be seen in Tables 7 X 9 , the proposed method has yielded better results than the other three methods. In Tables 7 and 8 (the first data set), k value of the kNN has been set to 1 because this value has given the best classification results. Similarly in Table 9 (SPECTF data set), the best k value has been set to 4.

For the ANN indicated in Table 9 , the number of hidden layers, the learning rate, and the types of activation functions have been modified to obtain the best classification performance. The three-layered feed-forward ANN architecture consists of 44 inputs, 12 hidden layer and 2 output layer neurons. The learning rate has been assigned as 0.001. In addition, activation function type, mean squared error and maximum training iterations have been set to log-sigmoid, 10 5 and 1000, respectively.

Tables 10 and 11 show the calculated accuracies of the classi-fication methods used in Tables 6 and 7 . Sensitivities, specificities and accuracy for MS and PS have been given in Table 8 . Using PCA to reduce the dimensionality has increased the accuracy of the
DHMM. Moreover, the success rate of the DHMM classifier had surpassed the ANN-based method and kNN classifier. 4. Discussion and conclusion DHMMs are a commonly used method for sound classification.
In this study, a DHMM-based system has been proposed for classification of heart sound signals. In the first stage, a feature extraction process was performed on heart sounds using DFT. The data set was then ready for reduction by PCA and classification by a DHMM. The principal component range with the best classifica-tion accuracy has been investigated. The proposed method yielded more successful results than a previously published study based on sensitivity and specificity. In addition, the proposed
PCA-DHMM approach has been implemented on another public data set (the SPECTF heart diagnosis set). The proposed approach yielded more successful results with this data set than ANN and kNN methods.

In future studies, the classification accuracy can be improved by applying different feature extraction methods to the signal. The study performed herein demonstrates that a system with a high accuracy rate can be used as a tool to help doctors. Another advantage of this type of decision-support system is that it provides knowledge transfer from experienced doctors to those with less experience during diagnosis.
 References
