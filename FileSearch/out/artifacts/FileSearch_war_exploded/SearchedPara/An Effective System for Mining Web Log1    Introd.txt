 The World Wide Web has become one of the most important media to store, share and distribute information. At present, G oogle is indexing more th an 8 billion Web pages [1]. The rapid expansion of the Web has provided a great opportunity to study user and system behavior by exploring Web access logs . Web mining that discovers and extracts interesting knowledge/patterns from Web could be classified into three types based on different data that mining is executed: Web Structure Mining that focuses on hyperlink structure, Web Contents Mining that focu ses on page contents as well as Web Usage Mining that focuses on Web logs. In this paper, we are concerned about Web Usage Mining (WUM), which also named Web log mining.

The process of WUM includes three phases: data preprocessing, pattern discovery, and pattern analysis [14]. During prepro cessing phase, raw Web logs need to be cleaned, analyzed and converted before further patte rn mining. The data recorded in server logs, such as the user IP address, browser, viewin g time, etc, are available to identify users and sessions. However, because some page views may be cached by the user browser or by a proxy server, we should know that the data collected by server logs are not entirely reliable. This problem can be partly solved by using some other kinds of usage information such as cookies. After each user has been identified, the entry for each user must be divided into sessions. A timeout is often used to break the entry into sessions. The following are some preprocessing tasks [14]: (a) Data Cleaning: The server log is examined to remove irrelevant items. (b) User Identification: To identify different users by overcoming the difficulty produced by the presence of proxy servers and cache. (c) Session Identification: The page accesse s must be divided into individual sessions according to different Web users.

The second phase of WUM is pattern mining and researches in data mining, machine learning as well as statistics are mainly focused on this phase. As for pattern mining, it could be: (a) statistical analysis, used to obtain useful statistical information such as the most frequently accessed pages; (b) a ssociation rule mining [12], used to find references to a set of pages that are accessed together with a support value exceeding some specified threshold; (c) sequential pattern mining [13], used to discover frequent sequential patterns which are lists of Web pages ordered by viewing time for predicting visit patterns; (d) clustering, used to group together users with similar characteristics; (e) classification, used to group together users into predefined classes based on their characteristics. In this paper, we focus on sequential pattern mining for finding interest-ing patterns based on Web logs.

Sequential pattern mining, which extract s frequent subsequences from a sequence database, has attracted a great deal of interest during the recent surge in data mining research because it is the basis of many app lications, such as Web user analysis, stock trend prediction, and DNA sequence analysis. Much work has been carried out on min-ing frequent patterns, as for example, in [13] [16] [10] [7] [4]. However, all of these works suffer from the problems of having a la rge search space and the ineffectiveness in handling long patterns. In our previous work [18], we proposed a novel algorithm to reduce searching space greatly. Instead of s earching the entire projected database for each item, as PrefixSpan [7] does, we only search a small portion of the database by recording the last position of item in each sequence (LAPIN: LAst Position INduction). While support counting usually is the most costly step in sequential pattern mining, the proposed LAPIN could improve the performance significantly by avoiding cost scan-ning and comparisons. In order to meet special features of Web data and Web log, we propose LAPIN WEB by extending our previous work.

In pattern analysis phase, which mainly filter out uninteresting rules obtained, we implement a visualization tool to help interpret mined patterns and predict users X  future request.

Our contribution in this paper could be summarized as: 1) propose an effective Web log mining system that deals with log preprocessing, sequential pattern mining, and re-sult visualizing; 2) propose an efficient sequential pattern mining algorithm by extend-ing previous LAPIN techniques; 3) implement a visualization tool to interpret mining results and predict users X  future behavior. Experimental results on real datasets demon-strate the effectiveness of the whole system as well as the high performance of the proposed mining algorithm, which outperforms existing algorithm by up to an order of magnitude.
 The remainder of this paper is organized as follows. We present the related work in Section 2. In Section 3, we introduce our Web log mining system, including preprocess-ing, pattern discovery and pattern analysis parts. Experimental results and performance analysis are reported in Section 4. We conclude the paper and provide suggestions for future work in Section 5. Commonly, a mining system includes three parts, as mentioned in Section 1, data pre-processing, pattern discovery and pattern analysis. In this section, we first introduce some related work in data preprocessing and then we focus on pattern mining and pat-tern analysis.
 Data preprocessing: Because of the proxy servers and Web browser cache existing, to get an accurate picture of the web-site access is difficult. Web browsers store pages that have been visited and if the same page i s requested, the Web browser will directly displays the page rather than sending another request to the Web server, which makes the user access stream incomplete. By using th e same proxy server, different users leave the same IP address in the server log, which makes the user identification rather diffi-cult. [14] presented the solution to these problems by using Cookies or Remote Agents. Moreover, in the same paper, the authors hav e presented several data preparation tech-niques to identify Web users, i.e., the path completion and the use of site topology. To identify the user sessions, a fixed time period, say thirty minutes [14] [3], is used to be the threshold between two sessions.
 Sequential pattern mining: Srikant and Agrawal proposed the GSP algorithm [16], which iteratively generates candidate k-se quences from frequent (k-1)-sequences based on the anti-monotone property that all the s ubsequences of a frequent sequence must be frequent. Zaki proposed SPADE [10] to elucidate frequent sequences using efficient lattice search techniques and simple join operations. SPADE divides the candidate se-quences into groups by items, and transforms the original sequence database into a ver-tical ID-List database format. SPADE counts the support of a candidate k-sequence gen-erated by merging the ID-Lists of any two frequent (k-1)-sequences with the same (k-2)-prefix in each iteration. Ayres et al. [4] p roposed the SPAM algorithm, which uses SPADE X  X  lattice concept, but represents each ID-List as a vertical bitmap. SPADE and SPAM can be grouped as candidate-generation-and-test method. On the other hand, Pei et al. proposed a pattern growth algorithm, PrefixSpan [7], which adopts a projection strat-egy to project sequences into different groups called projected databases . The PrefixS-pan algorithm recursively generates a proj ected database for each frequent k-sequence to find the frequent (k+1)-sequences. A comprehensive performance study showed that PrefixSpan, in most cases, outperforms former apriori-based algorithms [8]. However, PrefixSpan still needs to scan large projected database and it does not work well for dense datasets, i.e. DNA sequences, which is an very important application. These observations motivate our work in [18], which proposed an efficient sequential pattern mining algo-rithm LAPIN by the idea of using the last position of each item to judge whether a k-length pattern could grow to a (k+1)-length pattern. LAPIN could improve the performance sig-nificantly by largely reduce the search space required. In this paper, we propose another pattern mining algorithm by combining the merits of both LAPIN and PrefixSpan to meet the special requirement of Web logs, which is very sparse.
 Visualization tools: Pitkow et. al. proposed WebViz [9] as a tool for Web log anal-ysis, which provides graphical view of we b-site local documents and access patterns. By incorporating the Web-Path paradigm, Web masters can see the documents in their web-site as well as the hyperlinks travelle d by visitors. Spiliopoulou et. al. presented Web Utilization Miner (WUM) [11] as a mining system for the discovery of interesting navigation patterns. One of the most important features of WUM is that using WUM mining language MINT, human expert can dynamically specify the interestingness cri-teria for navigation patterns. To discover the navigation patterns satisfying the expert criteria, WUM exploits Aggregation Servi ce that extracts information on Web access log and retains aggregated statistical information. Hong et. al. proposed WebQuilt [5] as a Web logging and visualization system that helps Web design teams run usability tests and analyze the collected data. To overcome many of the problems with server-side and client-side logging, WebQuilt uses a proxy to log the activity. It aggregates logged usage traces and visualize in a zooming int erface that shows the Web pages viewed. Also it shows the most common paths taken through the web-site for a given task, as well as the optimal path for that task. We designed a Web log mining system for sequential pattern mining and its visualiza-tion, as shown in Fig. 1. The input and output of the system is Web log files as well as visualized patterns or text reports. As mentioned in Section 1, the whole system includes:  X  Data Preprocessing. This is the phase where data are cleaned from noise by over- X  Pattern Mining. While various mining algorithms could be incorporated into the  X  Pattern Analysis. In this phase, the mined patterns which in great numbers need
We will discuss each part in more detail in following subsections. 3.1 Data Preprocessing The raw Web log data is usually diverse and incomplete and difficult to be used directly for further pattern mining. In order to process it, we need to: 1) Data Cleaning. In our system, we use server logs in Common Log Format. We examine Web logs and remove irrelevant or redundant items like image, sound, video files which could be downloaded without an explicit user request. Other removal items include HTTP errors, records created by craw lers, etc., which can not truly reflect users X  behavior. 2) User Identification. To identify the users, one simple method is requiring the users to identify themselves, by logging in before using the web-site or system. Another ap-proach is to use cookies for identifying the visitors of a web-site by storing an unique ID. However, these two methods are not ge neral enough because they depend on the application domain and the quality of the source data, thus in our system we only set them as an option. More detail should be imp lemented according to different applica-tion domains.

We have implemented a more general method to identify user based on [14]. We have three criteria: 3) Session Identification. To identify the user sessions is also very important because it will largely affects the quality of pattern discovery result. A user session can be defined as a set of pages visited by the same user within the duration of one particular visit to a web-site.

According to [2] [6], a set of pages visited by a specific user is considered as a single user session if the pages are requested at a tim e interval not larger than a specified time period. In our system, we set this period to 30 minutes. 3.2 Sequential Pattern Mining Problem Definition. A W eb access sequence , s , is denoted as i 1 ,i 2 ,...,i k ,where i is a page item for 1  X  j  X  k. The number of page items in a Web access sequence is called the length of the sequence. A Web access sequence with length l is called an l -sequence . A sequence, s a = a 1 ,a 2 ,...,a n , is contained in another sequence, s b = b 1 ,b 2 ,...,b m , if there exists integers 1  X  i 1 &lt;i 2 &lt; ... &lt; i n  X  m ,such that a 1 = b i 1 , a 2 = b i 2 , ... , a n = b i n . We denote s a a subsequence of s b ,and s b a supersequence of s a . Given a Web access sequence s = i 1 ,i 2 ,...,i l ,andan page item  X  , s  X  denotes that s concatenates with  X  ,as Sequence Extension ( SE ), s  X  = i 1 ,i 2 ,...,i l , X  .If s = p s ,then p is a pref ix of s and s is a suffix of s .
A W eb access sequence database , S , is a set of tuples uid, s ,where uid is a user id and s is a Web access sequence. A tuple uid, s is said to contain a sequence  X  , if  X  is a subsequence of s . The support of a sequence,  X  , in a sequence database, S ,is the number of tuples in the database containing  X  , denoted as support (  X  ) .Givenauser specified positive integer,  X  , a sequence,  X  , is called a frequent Web access sequential pattern if support (  X  )  X   X  . For sequential pattern mining in the pattern discovery phase, the objective is to find the complete set of We b access sequential patterns of database S in an efficient manner. Let our running database be the sequence database S shown in Table 1 with min support = 2. We will use this sample database throughout the paper.
Here, we propose an efficient sequential pattern mining algorithm to mine Web logs by extending our previous work LAPIN [18]. Let us first briefly introduce the idea of LAPIN: LAPIN Algorithm. For any time series database, the last position of an item is the key used to judge whether or not the item can be appended to a given prefix (k-length) sequence (assumed to be s ). For example, in a sequence, if the last position of item  X  is smaller than, or equal to, the position of the last item in s , then item  X  cannot be appended to s as a (k+1)-length sequence extension in the same sequence.
 Example 1. When scanning the database in Table 1 for the first time, we obtain Table 2, which is a list of the last positions of the 1-length frequent sequences in ascending order. Suppose that we have a prefix frequent sequence a , and its positions in Table 1 are 10:1, 20:6, 30:5, where uid:pid represents the sequence ID and the position ID. Then, we check Table 2 to obtain the first indices whose positions are larger than a  X  X , resulting in 10:1, 20:3, 30:2, i.e., (10:b last = 3, 20:b last = 7, and 30:d last =6).We start from these indices to the end of each sequence, and increment the support of each passed item, resulting in a :2 , b :2 , c :2 , and d :2 , from which, we can determine that aa , ab , ac and ad are the frequent patterns.

From the above example, we can show that the main difference between LAPIN and most existing algorithms is th e searching space. PrefixSpa n scans the entire projected database to find the frequent pattern. SPADE temporally joins the entire ID-List of the candidates to obtain the frequent pattern of next layer. LAPIN can obtain the same result by scanning only part of the search space of PrefixSpan and SPADE, which indeed, are the last positions of the items. The full justification and more detail about LAPIN can be found in [18].

However, we can not get the best performance by directly applying LAPIN to Web log ming because of the different properties between datasets. Comparing with general transaction data sequences that are co mmonly used, Web logs have following charac-teristics: Based on above points, we extended LAPIN to LAPIN WEB with: LAPIN WEB: Design and Implementation. We used a lexicographic tree [4] as the search path of our algorithm. Furthermore, we adopted a lexicographic order, which was defined in the same way as in [17]. This used the Depth First Search (DFS) strategy. For Web log, because it is impossible that a user clicks two pages at the same time, Itemset Extension ( IE ) case in common sequential pattern mining does not exist in Web log mining. Hence, we only deal with Sequence Extension ( SE ) case. The pseudo code of LAPIN WEB is shown in Fig. 2. In Step 1, by scanning the DB once, we can obtain all the 1-length frequent patterns. Then we sort and construct the SE item-last-position list in ascending order based on each 1-length frequent pattern X  last position, as shown in Table 2.
 Definition 1 (Prefix border position set). Given two sequences, A= A 1 A 2 ...A m and B= B 1 B 2 ...B n , suppose that there exists C= C 1 C 2 ...C l for l  X  m and l  X  n , and that C is a common prefix for A and B. We record both positions of the last item C l in A and B, respectively, e.g., C l = A i and C l = B j . The position set, (i, j), is called the prefix border position set of the common prefix C, denoted as S c .Furthermore,we denote S c,i as the prefix border position of the sequence, i. For example, if A= abc and B= acde , then we can deduce that one common prefix of these two sequences is ac , whose prefix border position set is (3,2), which is the last item C X  X  positions in A and B.
In function Gen P attern , to find the prefix border position set of k-length  X  (Step 3), we first obtain the sequence pointer and offset of the last item of  X  , and then perform a sequential search in the corresponding se quence for the (k-1)-length prefix border position. This method is similar to pseudo-projection in PrefixSpan, which is efficient for sparse datasets.
 Definition 2 (Local candidate item list). Given two sequences, A= A 1 A 2 ...A m and B= B 1 B 2 ...B n , suppose that there exists C= C 1 C 2 ...C l for l  X  m and l  X  n , and that C is a common prefix for A and B. Let D =( D 1 D 2 ...D k ) be a list of items, such as those appended to C, and C = C D j (1  X  j  X  k ) is the common sequence for A and B. The list D is called the local candidate item list of the prefix C X . For example, if A= abce and B= abcde , we can deduce that one common prefix of these two sequences is ab , and abc , abe are the common sequences for A and B. There-fore, the item list (c,e) is called the local candidate item list of the prefixes abc and abe .

Step 4, shown in Fig. 2, is used to find the frequent SE (k+1)-length pattern based on the frequent k-length pattern and the 1-length candidate items. Commonly, support counting is the most time consuming part in the entire mining process. In [18], we have found that LCI -oriented and Suffix -oriented have their own advantages for differ-ent types of datasets. Based on this discovery, in this paper, during the mining process, we dynamically compare the suffix sequence length with the local candidate item list size and select the appropriate search space to build a single general framework. In other words, we combine the two approaches, LAPIN LCI and LAPIN Suffix, together to improve efficiency at the price of low memory consuming. The pseudo code of the frequent pattern finding process is shown in Fig. 3.

From a system administrator X  X  view, the logs of special users (i.e. domain experts) are more important than other logs and thus, should be always considered more prior, as shown in Fig. 3 (Step 1). The appended candidate items are also judged based on this criteria (Step 7 and Step 14). 3.3 Pattern Visualization We could see from pattern mining process that given a support, usually there are great number of patterns produced and effective method to filter out and visualize mined pattern is necessary. In addition, web-site developers, designers, and maintainers also need to understand their efficiency as what kind of visitors are trying to do and how they are doing it. Towards this end, we developed a navigational behavior visualization tool based on Graphviz 1 .

At present, our prototype system has only implemented the basic sequential pattern discovery as the main mining task, which requi res relevant simple user-computer inter-face and visualization. As more functions are added and experiment done, we will make the tool more convenient to the users. In this section, we will describe our experiments and evaluations conducted on the real-world datasets. We performed the experiments using a 1.6 GHz Intel Pentium(R)M PC machine with a 1 G memory, running Microsoft Windows XP. The core of LAPIN WEB algorithm is written in C++ software. When comparing the efficiency between LAPIN WEB and PrefixSpan, we turned off the output of the programs to make the comparison equitable. 4.1 Real Data We consider that results from real data will be more convincing in demonstrating the ef-ficiency of our Web log mining system. There are two datasets used in our experiments, DMResearch and MSNBC. DMResearch was co llected from the web-site of China Data Mining Research Institute 2 , from Oct. 17, 2004 to Dec. 12, 2004. The log is large, about 56.9M, which includes 342,592 entries and 8,846 distinct pages. After applying data preprocessing described in Section 2.1, we identified 12,193 unique users and average length of the sessions for each user is 28. Th e second dataset, MSNBC, was obtained from the UCI KDD Archive 3 . This dataset comes from Web server logs for msnbc.com and news-related portions of msn.com on Sep. 28, 1999. There are 989,818 users and only 17 distinct items, because these items ar e recorded at the level of URL category, not at page level, which greatly reduces the dimensionality. The 17 categories are  X  X ront-page X ,  X  X ews X ,  X  X ech X ,  X  X ocal  X ,  X  X pinion X ,  X  X n-air X ,  X  X isc X ,  X  X eather X ,  X  X ealth X ,  X  X iv-ing X ,  X  X usiness X ,  X  X ports X ,  X  X ummary X ,  X  X bs X ,  X  X ravel X ,  X  X sn-news X , and  X  X sn-sports X . Each category is associated with a category number using an integer starting from  X 1 X . The statistics of these datasets is given in Table 3.
 4.2 Comparing PrefixSpan with LAPIN WEB Fig. 4 shows the running time and the searched space comparison between PrefixS-pan and LAPIN WEB. Fig. 4 (a) shows the performance comparison between Pre-fixSpan and LAPIN WEB for DMResearch data set. From Fig. 4 (a), we can see that LAPIN WEB is much more efficient than PrefixSpan. For example, at support 1.3%, LAPIN WEB (runtime = 47 seconds) is more than an order of magnitude faster than PrefixSpan (runtime = 501 seconds). This is because the searched space of Prefixspan (space = 5,707M) was much larger than that in LAPIN WEB (space = 214M), as shown in Fig. 4 (c).
Fig. 4 (b) shows the performance comparison between PrefixSpan and LAPIN WEB for MSNBC data set. From Fig. 4 (b), we can see that LAPIN WEB is much more efficient than PrefixSpan. For example, at support 0.011%, LAPIN WEB (runtime = 3,215 seconds) is about five times faster than PrefixSpan (runtime = 15,322 seconds). This is because the searched space of Prefixspan (space = 701,781M) was much larger than that in LAPIN WEB (space = 49,883M), as shown in Fig. 4 (d).

We have not compared PrefixSpan and LAPIN WEB on user X  X  preference, because the former one has no such function. 4.3 Visualization Result To help web-site developers, and Web administrators analyze the efficiency of their web-site by understanding what and how visitors are doing on a web-site, we developed a navigational behavior visualization tool. Fig. 5 and Fig. 6 show the visualization result of traversal pathes for the two real datasets, respectively. Here, we set minimum support to 9% for DMResearch and 4% for MSNBC. The thickness of edge represents the support value of the corresponding traversal path. The number value, which is right of the traversal path, is the support value of the corresponding path. The  X  X tart X  and  X  X nd X  are not actual pages belong to the site, they a re actually another sites placed somewhere on the internet, and indicate the entry and exit door to and from the site.
From the figures, We can easily know that the most traversed edges, the thick ones, are connecting pages  X  X tart X   X   X  \ loginout.jsp X   X   X  X nd X  in Fig. 5, and  X  X tart X   X   X  X ront-page X   X   X  X nd X  in Fig. 6. Similar interesting traversal path can also be understood, and used by web-site designers to make improvement on link structure as well as document content to maximize efficiency of visitor path. In this paper, we have proposed an effective framework for Web log mining system to benefit web-site designer to understand user behaviors by mining Web log data. In particular, we propose an efficient sequential pattern mining algorithm LAPIN WEB by extending previous work LAPIN with special consideration of Web log data. The proposed algorithm could improve the mining performance significantly by scanning only a small portion of projected database an d extract more reasonable web usage pat-terns. Experimental results and evaluations performed on real data demonstrate that LAPIN WEB is very effective and outperforms existing algorithms by up to an or-der of magnitude. The visualization tool could be further used to make final patterns easy to interpret and thus improve the presentation and organization of web-site. Our framework of Web log mining system is designed in such a way that it could be easily extended by incorporating other new methods or algorithms to make it more functional and adaptive. We are now considering other pattern mining algorithms as we mentioned earlier such as clustering and association rule. Moreover, we are planning to build more sophisticated visualization tools to interpret the final results.
