  X  which is used to fi nd a similar case with a query, and  X  1. Introduction
The signi fi cant progresses in electronic devices and the avail-ability of the storage capacity make it possible to store huge amounts of images. Therefore, users need professional search engines to help them in managing and/or communicating with large databases. Content based image retrieval (CBIR) is the process of retrieving desired images from the image databases ( Antani et al., 2002 ; Liu et al., 2007 ; Smeulders et al., 2000 ). Ef fi cient image browsing and retrieval tools are required by users from various domains. They are employed in diverse areas such as entertainment, art, fashion design, advertising, history, medicine and industry. In CBIR systems, visual (low level) features are used to represent images for searching and indexing ( Rashedi et al., 2013a ). However, visual features are not suf fi cient to represent the semantic concepts of the images ( Liu et al., 2007 ). There is a gap between the interpretation of an image and its visual low level contents that is called semantic gap ( Smeulders et al., 2000 ).
Many attempts in CBIR have been devoted to bridge the semantic gap by employing relevance feedback ( Jing and Allinson, 2013 ). Relevance feedback (RF) is a supervised learning technique which uses positive and negative examples provided by the users to improve retrieval results. In an image retrieval session, a user is interested in fi nding a speci fi c semantic content. The initial retrieval results are produced by the CBIR system. After that, until the end of the session, the user subsequently marks the images as relevant and irrelevant across relevance feedback rounds. During these rounds, RF increases the retrieval performance by learning what is relevant or irrelevant to the user's desire.

Two famous learning techniques of RF are Short term learning (STL) ( Rocchio, 1971 ) and long term learning (LTL) ( He et al., 2003; Nezamabadi-pour and Kabir, 2009; Rashedi, 2013 ). By STL, the
CBIR system learns the images that are relevant to the user's query over the course of the current query session, whereas through LTL the CBIR system learns the connections between images over the course of multiple query sessions ( Qi et al., 2011 ). Thus, STL is an intra-query and LTL is an inter-query learning technique. It is often useful to employ both of them in CBIR systems.

Case based reasoning (CBR) is one of problem solving techni-ques that is attracting increasing attention. CBR is the process of solving new problems by fi nding relevant past problems and adapting them to fi t the new situations (Aamodt and Plaza, 1994;
Liu et al., 2008 ). Previously experienced problems are stored in the case knowledge base (CKB). A general CBR cycle is described by the following four processes: (a) Retrieve the most similar case(s), (b) Reuse the information and knowledge in that case(s) to solve the problem, (c) Revise the proposed solution, and (d) Retain the parts of this experience likely to be useful for future problem solving. Case based reasoning is a methodology for both learning and reasoning. By learning, CBR adapts CKB to fi t the new situations. Revise and Retain processes are two parts of learning stage. By reasoning, CBR solves problems by retrieving the most relevant past problems from an existing case knowledge base (CKB). Retrieve and Reuse processes are two parts of reasoning stage. Some examples of CBR applications are knowledge discov-ery frameworks for textual Case-based reasoning ( Patterson et al., 2008 ), document retrieval system development ( Watson and
Watson, 1997 ), medical diagnosis ( Hsu and Ho, 2004 ), image processing ( Perner et al., 2006 ), bone age estimation ( Fischer et al., 2012 ), and so on.
 long term learning of relevance feedback. Using CBR, the result of a query session could be improved using the solution of the system for similar queries that were searched before. Regarding this idea, in this paper, we introduce a method of using CBR in long term learning. We called this method Case-based LTL or CB-LTL. At a general approach of this method is produced. Next, an example of the CB-LTL method is introduced and examined in the CBIR systems with similarity re fi nement based STL. The results are compared with one of recent LTL methods that is virtual feature based LTL method ( Yin et al., 2008 ).
 related works are reviewed. In this section, fi rst we categorize the existing methods and then discuss about the challenges. In Section 3 , the general approach of CB-LTL method is proposed. In this section, the framework of the method is produced by de fi basic components and two main stages of the method. In Section 4 , the method is implemented in a CBIR system with similarity re fi nement based STL. Results are studied in Section 5 and the paper is concluded in Section 6 . 2. Background and motivation and LTL are reviewed. Then, challenges and the motivation of the work are explained. 2.1. Background during STL, the CBIR system learns relevant images to the current query over the course of a single query, and during LTL, it learns the relations between images over the course of multiple queries ( Qi et al., 2011 ).
 classi fi cation based methods ( Han et al., 2005 ), similarity re ment based methods ( Cheng et al., 2008; Shamsi et al., in press ), query re fi nement methods ( Porkaew et al., 1999; Rocchio, 1971 ), and multi-query methods ( Salvador and Chan, 2003; Kim et al., 2005 ). In the classi fi cation based methods, a classi fi to separate relevant and irrelevant images ( Han et al., 2005 ), and in the similarity re fi nement based methods, the similarity function is improved often by feature reweighting ( Cheng et al., 2008;
Shamsi et al., in press ). In query re fi nement methods, the query vector is improved in such a way to approach the relevant images and keep away from the irrelevant images ( Porkaew et al., 1999;
Rocchio, 1971 ), and in multi-query methods, several further query vectors are introduced often by clustering ( Salvador and Chan, 2003; Kim et al., 2005 ). In some works, a combination of these techniques is used to enhance the retrieval precision ( Su et al., 2011 ).

As mentioned before, through an LTL technique, the CBIR system learns the feedback information provided by the users' interactions during multiple sessions. Creating LTL methods is still one of the active challenges in the CBIR fi eld. Till now, several techniques for LTL are introduced that some of them are reviewed in the sequel.

Han et al. (2005) proposed a memory learning method to learn the semantic relations between images. It uses a feedback knowl-edge memory model to gather the users' feedback information during the process of image search and feedback. In the iFind CBIR system ( Lu et al., 2003 ), semantic contents of images are extracted and saved during sessions by forming a semantic network on top of the keywords association with images. He et al. (2003) con-structed a semantic space from user interactions in a matrix whose rows correspond to images and columns correspond to attributes. Then, a singular value decomposition (SVD) technique is used to reduce the dimension of semantic space. Dong and
Bhanu (2005) used a semi-supervised expectation-maximization (SS-EM) algorithm for concept learning. The LTL method proposed by Barrett (2007) is based on concept clustering. This method creates semantic clusters and stores each image's relationship to each cluster.

In the LTL method of Nezamabadi-pour and Kabir (2009) ,a semantic network which shows the relations between images and concepts is built. A fuzzy k -nearest neighbor classi fi er assigns initial semantic labels to database images. These labels are gradually modi fi ed by relevance feedbacks from users.
Boutemedjet and Ziou (2010) proposed a fl exible mixture model that clusters both images and users into separate groups. A long-term relevance feedback is used to maintain accurate modeling of growing image collections and changing user long-term needs over time. Ma et al. (2010) built a uni fi ed graph to combine the visual feature-based image similarity graph with the image-tag graph and a random walk model is proposed to balance the in fl uences between the image contents and tags.

Bhanu and Dong (2002) proposed a semi-supervised fuzzy clustering method to learn the class distribution in the sense of high level concepts from retrieval experiences. Using fuzzy rules, they incorporate the meta-knowledge into a probabilistic rele-vance feedback approach to improve the retrieval performance.
Lakdashti et al. (2008) used a clustering based training algorithm for creating the fuzzy rules to reduce the semantic gap in the CBIR systems. ElAlami (2011) proposed the retrieval process based on a rule based system and a clustering method. In this method, the fuzzy rules are extracted from the obtained clusters and re removing the redundant and speci fi c rules from the rule base.
Yin et al. (2008) represented the feedback history with all the users as a virtual feature of the images. The virtual feature of an image illustrates the degree of its dependency to different con-cepts. Zhuang et al. (2000) de fi ned a semantic template (ST) for each keyword. When a user enters a keyword query, relevant images are returned to the user with the help of ST association.
The ST consists of the centroids of feature vectors and the weights achieved by relevance feedback. The method is supported by
WordNet ( Aslandogan et al., 1997 ). Using WordNet, the relations between keywords is employed to achieve better results. 2.2. Motivation
Referring the above review, we divide LTL methods into three categories. The fi rst kind of methods construct the relevancy networks between images ( Han et al., 2005 ) or between images and concepts which are extracted from the feedback of the users ( Lu et al., 2003; He et al., 2003; Dong and Bhanu, 2005; Barrett, 2007; Nezamabadi-pour and Kabir, 2009; Ma et al., 2010 ). In these methods, to achieve acceptable results, enough large number of user interactions should be collected. Thus, they are not proper for very large or dynamic databases.

The second kind of methods use low level representatives to save discovered concepts. These representatives often are the centers of semantic groups or fuzzy rules de fi ned in feature space ( Bhanu and Dong, 2002; Lakdashti et al., 2008; ElAlami, 2011 ). In these methods, a smaller number of visits is required to record suf fi cient concepts. They are better suggestions for dynamic databases. However, visual representatives are not suf fi effective saving of discovered concepts.

The third kind of methods are based on de fi ning high level representatives for each concept. These methods save concepts using both low level and high level features. They will be more ef fi cient than the second methods, but this is dif fi cult to de high level features for semantic concepts. A method in this group is based on de fi ning semantic templates (ST) which represent keywords using low level and high level features ( Zhuang et al., 2000; Rashedi and Nezamabadi-pour, 2012 ). Yin et al. (2008) extracted high level features of images and saved as virtual features. A brief summary of the three mentioned LTL methods is presented in Table 1 .

In each of the mentioned strategies, several techniques are employed to save the information of user interactions and to use this information in the next sessions. There are techniques that save the relations between images or between images and con-cepts. In contrast, some other techniques save the discovered concepts with the use of low level features, and others save them with the use of low level features as well as high level features. High level features could be extracted via relevance feedback.
There are some problems within most of the long-term learn-ing methods ( Patil and Kokare, 2011 ). The fi rst is that they are unsuitable for applications where images are frequently added or removed. The second problem is the sparsity of the memorized feedback information. These drawbacks are more remarkable in the long-term learning approaches that only memorize the rela-tions between images or between images and semantics. Thus, in producing new LTL methods, it could be more bene fi cial to use the other types of information rather than just using the relevancy networks. 2.3. Our work
To design an LTL method, there are four main questions to be considered:
How the semantic concepts could be extracted from retrieval sessions? How the knowledge could be recorded and updated?
How the recorded knowledge could be employed to boost retrieval results?
How the similarity function between images and recorded concepts could be de fi ned?
Every LTL method should have a solution for each of these questions. In our opinion, the methodology of CBR innately has the answers to all of these questions. In this paper, we propose a Case-based LTL (CB-LTL) method that has a lot of potential to be applied in various CBIR systems.

The method has two stages of learning and reasoning. In the learning stage, information extracted from retrieval sessions is recorded as cases and in the reasoning stage, information of cases is used to improve the retrieval results. CB-LTL uses low level and high level features to record cases. Although, this is dif extract high level features for semantic concepts, but it is possible to use meta-information achieved from user interactions as high level features. After producing the general approach, an example of the CB-LTL method is implemented in the similarity re fi based CBIR systems. In the implemented method, meta-knowledge is achieved by STL. 3. Case-based long term learning: the general framework
Case based reasoning (CBR) utilizes the speci fi c knowledge of previously experienced problems (cases) to solve a new problem by fi nding a similar past case, and reusing it in the new problem situation (Aamodt and Plaza, 1994). Referring to this de fi
CBR properly fi t the LTL in such a way that every retrieval session could be solved using the retrieval results of the previously seen sessions similar to this session. Here, the general approach of the
Case-based LTL which employs the methodology of CBR is intro-duced. In the CB-LTL, long term knowledge base is the case knowledge base or CKB. The block diagram of a CBIR system with the proposed CB-LTL method is presented in Fig. 1 .

As this fi gure suggests, the main part of a CBIR system is the retrieval block that processes the user's query, executes the search process, and delivers retrieval results to the user. The knowledge base of this system is the case knowledge base that is a collection of cases created and updated during long term learning. The retrieval block has a bi-directional link with CKB to execute learning and reasoning processes. In the learning process, the retrieval results are employed to update CKB, and in the reasoning process, the knowledge of CKB is used to enhance the retrieval results. During learning and reasoning processes, the desire of the user is represented by the key of query and a similar case to the query is found by the trigger function.
 (SF). SF is a structure for saving low level and high level features.
Each case in the database includes the problem and the solution that are the desire of the user and the retrieval solution of the system, respectively. Therefore, every case describes an appear-ance of a semantic concept. As an example, consider a case constructed by a group of images with the look of jungle that has the semantic concept of  X  nature  X  .
 follows: a) As a case based method, it involves two stages of learning and b) Each case in the database includes the desire of the user and c) The desire of the user is represented by the  X  key of query  X  e) Cases are recorded in the format de fi ned as  X  semantic frame function  X  , and  X  semantic frame  X  and two stages of  X  learning  X  reasoning  X  . The whole procedure of the CB-LTL is shown in Fig. 2 .
Cases are recorded as SFs in the CKB. In each retrieval session, key of query is extracted and the trigger function is used to case in the CKB. During retrieval process, the CKB is used to enhance the retrieval results that is the reasoning stage. At the end of the retrieval session, the retrieval results are employed to update CKB that is the learning stage.
 de fi ning the main components and secondly explaining learning and reasoning processes. 3.1. Key of query
It could be a keyword, or a feature vector. The key of query is extracted from the query of the user and activates the trigger function. 3.2. Trigger function
Encountering every new session, the key of query is used to fi nd a similar case. Trigger function is a function that is activated when the similarity between a case and the key of query overpass a certain threshold. Using this function, it is possible for every new session to trigger a similar case in the CKB. 3.3. Semantic frame
Semantic frame (SF) is the structure of saving and representing cases in the long term knowledge base that is CKB. The semantic frame has three main parts. Part (A): to save low level features, part (B): to save high level features, and part (C): to save the frequency of visitation ( Fig. 3 ).

Part (A) is called  X  Low Feature Space Description  X  (LFD). The LFD part contains low level features. These features could be for example MPEG-7 descriptors including visual, audio, and multi-media descriptors ( Chang et al., 2001; Sikora, 2001 ). The second part of semantic frame is called  X  Semantic Space
Description  X  (SSD). The SSD part includes every meta-data about the concept that is not low level features. This data is mentioned as high level features. Various innovative techniques could be suggested for extracting high level features to describe discovered concepts. High level features could be extracted from relevance feedback by short term learning. For example, the similarity function or the classi fi er of STL is recommended.

The last part of semantic frame is  X  Frequency of Visitation that shows the number of times this SF is triggered during learning process. Referring Fv , we can identify useful or useless cases. 3.4. Learning process The CKB is created and updated during the learning process. The way is that if a query triggers a case in the CKB, the SF's
Reasoning content of that case is updated; otherwise, the query is added to the CKB as a new case ( Fig. 4 ). Learning process is done at the end of the session.

If the key of query triggers an available SF: the LFD and the SSD of the SF are updated considering the frequency of visitation, and the SF's frequency of visitation is increased by one. If there is not any similar case in the database, this session is considered to be a new case. In this situation, the LFD, and the SSD of the current session are added to the knowledge base with Fv  X  1. 3.5. Reasoning process
If a query triggers a case in the CKB, its SF's contents are used to improve retrieval results. Reasoning process could be done at every round of relevance feedback in a session. If no case is triggered, the retrieval session is completed just by using STL (without any improvement using LTL). The pseudocode of the reasoning process is given in Fig. 5 .
 To use the information content of a case, the content of part LFD is used to improve the low level features of the query. Furthermore, the content of part SSD, according to what it is, is used for improving retrieval results. For example, if SSD has some information about the STL (similarity function or classi fi instance), it could be used for improving or initializing the STL process.

Now, after de fi ning CB-LTL method, a version of this method is implemented and examined in the next sections. 4. Implementation of CB-LTL in CBIR systems with similarity re fi nement based STL In this section, we describe a particular implementation of CB-LTL in a CBIR system with the similarity re fi nement based STL method. The proposed CBIR system is shown in Fig. 6 . As this fi gure suggests, in each query session, query image is processed and similar images are found by a similarity function. The STL method is a similarity re fi nement based method that improves the weights of the similarity function during relevance feedback rounds. In each retrieval session, the user interacts with system and system learns his/her desired concept by STL. In LTL, during the learning stage, the CKB is updated using the information of the retrieval sessions and during the reasoning stage, retrieval results are improved using the information of the CKB.

In the similarity function block of Fig. 6 , the dissimilarity value between two feature vectors of F and Q is calculated using the function of d  X  Q ; F j W  X  where W presents the weights of the dissimilarity function. W is updated by STL method during RF rounds.

The proposed LTL method is a kind of case-based LTL method in which (a) LFD contents of semantic frames are achieved by relevant images, (b) SSD contents of semantic frames are derived from STL, (c) the trigger function triggers the similar case to the query, (d) the learning stage is processed at the end of the session, and (e) the reasoning stage is processed at every round of relevance feedback.
 Every retrieval session is determined by using some LFD and
SSD descriptors explained in the next subsection. Afterward, the details of the semantic frame and the trigger function, and the processes of learning and reasoning are explained. 4.1. Retrieval session descriptors
The i th session is determined by { Q i , W i , Q  X  i , Q the key of query, W i is the weight vector, and Q  X  i and Q the set of relevant and irrelevant marked images respectively and r is the semantic radius.

At the beginning of the i th session, the key of query ( Q de fi ned by the low level feature vector of the query image. It is updated during RF rounds by averaging positive images as given in
Eq. (1) (Nezamabadi-pour et al., 2009; Rashedi et al., 2012 ). states the number of the relevant images or the size of the set Q
Q  X  1 j Q  X  i j
The semantic radius ( r )isde fi ned as the maximum distance among the distances between the query and every relevant marked image (Eq. (2) ). This is the radius around the query that relevant images are getting inside. r  X  max 4.2. Semantic frame format of semantic frames. Semantic frames are created and updated in the learning stage. Each j th SF contains the low-level representative, the weight vector of the similarity function, the semantic radius, and the frequency of visitation that are shown by shown in Fig. 7 .
 indices are adopted. Semantic categories are constructed using RF information during multiple sessions ( Rashedi et al., 2013b ).
The fi rst session is the fi rst category. After that, each new session will be assigned to an existed category or construct a new category. The process is described in the following section. by L that is the index of the associated category. The relationship between images and the L th category are kept in a vector shown by H L . It is possible for some cases to have the same semantic index. These cases present various shapes of a semantic category. For these cases, L and H L are the same.
 part. A semantic category of  X  L  X  corresponds to a vector of H shows the relevancy ratio of dataset images to the L th category. 4.2.1. Constructing semantic categories
H j  X  :  X  is the relevancy between j th semantic category and database images. H j  X  :  X  is updated during the learning process. Here, we explain the procedure of fi nding the semantic category of every session among available categories, or considering a session as a new semantic category. Encountering every new session, we try to fi nd the corresponding semantic category among discovered categories. If there is any associated semantic with a query, the corresponding category index will be detected. If not, the query will be considered as a new semantic category ( Rashedi et al., 2013b ). L i is the index of a semantic category which i th query is associated with. Let s be the total number of semantic categories discovered till now. The degree of relevancy of image  X  i  X  values of a k and b k are calculated using Eqs. (3) and ( 4 ) for all category indices. a k is the proportion of the images in Q are relevant to the category k and b k is the proportion of the images in Q i which are relevant to the category k . According to this de fi nition, we fi nd out that with how much proportion the positive or negative images of a query are related to a category. a  X  1 n  X  b  X  1 n  X  where n is the number of retrieved images in each RF round, U  X  x  X  is the unit step function, in which U  X  x  X  X  1 for x 4 0 and U  X  x  X  X  0 for x r 0. After calculation of a k and b k , the associated semantic category is determined statistically using Eqs. (5) and (6) .
We de fi ne a set  X  A  X  as Eq. (5) . The set is used in Eq. (6) to determine the index of the semantic category associated with the current query. The parameter of th is used as a threshold for fi nding associated categories. In this equation, if A a  X  ( A is not empty), then L i is assigned to a category with a maximum value of a . With this de fi nition, the session is assigned to a category which the relevant marked images of the session have most relevancy to it and irrelevant marked images of the session have less relevancy similar category. In this situation, current query is added to the semantic category list as a new one, through inserting one extra vector of H with index s  X  1. Accordingly, the total number of semantic categories discovered till now and also L i become s  X  1.
A  X f k : a k Z th ; b k r th  X g X  5  X  if A a  X  then L i  X  arg max if A  X   X  then L i  X  s  X  1 ; s -s  X  1
The members of set A are checked for possible merging. If all or some of them are similar, they will be merged. Two categories i ; k
A A are merged into one if there are less than a prede fi number of irrelevant images in one of them that are relevant to the other one (Eq. (7) ). The couple of { i ; j } is merged into one category by removing H j and setting H i  X  H i  X  H j . The parameter of th m is used as a threshold for merging purposes.  X   X 
U  X  H i  X  : U  X  H j  X   X   X   X  U  X  H i  X  : U  X  H j  X   X  r th m 4.3. Trigger function
Trigger function is de fi ned using a dissimilarity function between images and cases. The dissimilarity between the i th query session and the j th case is de fi ned as Eq. (8) that is the distance between Q i and S j with the weights of W j . If the dissimilarity value is less than the semantic radius of the j th case ( r ) and the indices of the semantic category of the query and the case are the same, then the j th case is triggered as a similar case to
Similarity function 
Visual features the i th query (Eq. (9) ): D  X  d  X  Q i ; S j j W j  X  X  8  X  4.4. Learning process
In the learning process, case knowledge base is updated. Only successful sessions are used to update CKB. Successful sessions are the sessions that have a fi nal precision more than a prede threshold  X  th p  X  . We ignore sessions with low precision as useless sessions. Precision is de fi ned as the ratio of the relevant marked images to the total number of retrieved images (Yin et al., 2008). Low precision shows that the solution of the system is not satisfactory and there is no need to record this solution.
By using the trigger function at the end of the i th successful session, the CKB is searched to fi nd similar cases to this query session. If a similar case exists, the SF of the similar case is updated. Otherwise, this session is added to the CKB as a new case.
The j th case is determined by { S j , W j , r j , L j , Fv case (e.g., j th case) using the information of the i th session, S r , and L j are considered equal to Q i , W i , r i , and L Fv j is set to 1. On the other hand, to update the j th case using the information of the i th session, the information of the semantic frame is updated by Eqs. (10)  X  (12) and the frequency of visitation is increased by one. With this de fi nition, the descriptors of the similar retrieval sessions that are visited one by one are averaged to create a case. r  X  new  X  X  r j  X  old  X  Fv j  X  r i Fv S  X  new  X  X  S j  X  old  X  Fv j  X  Q i Fv W  X  new  X  X  W j  X  old  X  Fv j  X  W i Fv
Furthermore, in the learning process, the relevancy vector of the L j th semantic ( H L j  X  :  X  ) is updated using Eqs. (13) and (14) ( Nezamabadi-pour and Kabir, 2009 ). The initial value of H zero.
 H  X  q  X   X  X  H L j  X  q  X   X  X  0 : 01 : for all q  X  A Q  X  j  X  13  X  H  X  q  X  X  H L j  X  q  X  0 : 01 : for all q A Q j  X  14  X  4.5. Reasoning process
In the reasoning stage, the information of CKB is used to improve the accuracy of the session. At the beginning of the session, the query vector is compared with all of the existing cases by the trigger function. If any similar case is triggered, the weights of the similarity function are initialized by the weights of the closest case to the query vector. Otherwise, it is initialized to W W 0 is a prede fi ned initial weight vector. After initialization, the weights are re fi ned by STL during RF rounds.

In the reasoning process, in every round of relevance feedback, the set of retrieved images ( R ) with size n is partitioned into two sets. The fi rst set is R 1 with size  X  n 1  X  and the second set is R size  X  n 2  X  where n 1  X  n 2  X  n . In the fi rst set, n 1 with the Q (key of query) are retrieved using the weighted similarity function of STL. In the second set, n 2 images with the highest positive values of H L are retrieved, where L is the semantic category index of the current session. Retrieved images in the second set are images with maximum relevancy with the semantic category of the current session. The images in the set R 1 removed from the set R 2 to prevent duplication. With this procedure, we use the retrieval results of the similar case to boost the performance of the current retrieval session.

The values of n 1 and n 2 directly depend on the p 1 and p p are de fi ned according to Eq. (15) . In this equation, the values of p and p 2 are calculated using the number of relevant images in R p  X  p 2 . Using this de fi nition, the method that is more successful in the previous round retrieves more images in the next round. p  X  j Q j Q  X  1 j X j Q  X  2 j 5. Experimental results
We implemented our system on a set of Corel dataset containing 10k images of 82 semantic groups. All images are colored and in JPEG format. Corel dataset has been widely used by the image processing and CBIR research communities ( Han et al., 2005; Barrett, 2007; Qi et
China, Space, Speed, Religion, Castle, etc. The details of the imple-mented system and the results are as follows.

Furthermore, the comparative results are also reported in 10k images of Pascal VOC 2012 dataset ( Everingham et al., 2012 ).
It contains real-world images from Flickr, with 20 different classes of objects such as Person, Bicycle, Train, Cat, Dog, etc. 5.1. Similarity function and STL method
STL is a similarity re fi nement method. At each query session, the system is re fi ned by short-term RF technique for 4 rounds.
In each RF round, top 25 images are returned ( n  X  25). In this article, the dissimilarity function between two feature vectors of F and Q considering the weight vector of W is de fi ned as follows ( Rashedi et al., 2012 ): d  X  Q ; where F and Q are the feature vectors of two images; d is the dissimilarity measure between two images; f k ; j is the j th compo-from the image F ); l k represent the length of vector of k th type of feature. w k ; 0 is the weight of the k th type of feature, and w 1 r j r l k is the weight of the j th component of the k th type of feature. K is the total number of feature types. Type of feature would be any visual descriptors of MPEG7. The initial weight of W has equal weights for each feature element of a feature type and for each type of features.

The weights of the dissimilarity function are optimized using a
The error function is de fi ned as Eq. (17) and is then minimized using a gradient descent method ( Rashedi et al., 2012 ). In this equation, F  X  e presents the farthest relevance retrieved image to the query and F f presents the closest irrelevant retrieved image to the query. By minimizing this error function, the weights of the dissimilarity function are optimized to increase the distance between the query and most similar irrelevant marked image and to decrease the distance between the query and less similar relevant marked image.
 J  X  d  X  Q 5.2. Visual features
Sikora, 2001 ) are used for image indexing ( K  X  3). The color features are taken from 256 bins (16 4 4) HSV-based scaled color descriptor (SCD). Edge features are taken from the Edge
Histogram Descriptor (EHD) that is the local edge distribution in the image. After subdivision of an image into 4 4 sub-images, four directional edges called vertical, horizontal, 45 1 ,135 as a non-directional edge are computed in each sub-image. By histogram computation, a total of 16 5  X  80 bins are gained.
Texture features are calculated by Homogeneous Texture Descrip-tor (HTD) with 62 components including means and variances of fi ltered images by 30 Gabor fi lters with six different orientations and fi ve different scales. By 256 features of color ( l 1 features of edge ( l 2  X  80), and 62 features of texture ( l total number of features becomes 398. 5.3. Evaluation criteria (PR) that is de fi ned as the division of the number of relevant marked images to the total number of retrieved images. In a number of query images, averaged precision graph versus number of relevance feedback rounds is the common way of comparison of various RF methods in CBIR systems ( Han et al., 2005; Barrett, 2007; Qi et al., 2011; Yin et al., 2008 ). In this paper, the averaged precision rate at round i is shown by PRi . PR 0 is the averaged precision at the start of the session before getting any relevance feedback (so called round zero). The sequence of query images used in all the experiments is generated at random. 5.4. Comparative results on Corel dataset dataset, with 82 different classes of objects. To evaluate the proposed method, three sets of experiments are conducted. At the fi rst set, the effect of the proposed LTL method in improving the retrieval results of the CBIR systems is investigated. In these experiments, we compare the proposed CB approach with an existing long-term learning method of virtual feature based LTL or
VFB-LTL ( Yin et al., 2008 ) that use both low level and high level features to represent images. VFB-LTL method utilizes relevance feedback to construct the virtual features for each image. This method improves precision results by considering virtual features in the similarity function. Virtual features are high level features extracted by relevance feedback during retrieval sessions. We select VFB for comparison because both CB and VFB use low level and high level features to represent semantic meanings (the third kind of methods in Section 2.3 ).

At the second set of experiments, the robustness against noise is evaluated by injecting 5% and 10% noise into retrieval logs.
At the third set of experiments, we track the progress of the pro-posed method while visiting half of the dataset images. In these experiments, to report averaged precision, the averaged precision of several sets of 500 sessions are considered. In all of these experiments, to implement the CB-LTL method, the value of th in
Eq. (5) is set to 0.04 and th m  X  2 in Eq. (7) and the value of th set to 0.16. These values are determined empirically. 5.4.1. Performance evaluation At fi rst, we observed the retrieval performance of our system.
Experiments are conducted on both our method and VFB-LTL method. To test the effect of the memorized knowledge, 1500 query sessions are collected in the user log. After that, the average of the results of 100 query sessions are considered with the information of long term learning using 500, 1000 and 1500 user logs. Results are shown in Fig. 8 . These experiments demonstrate that both LTL methods enhance the CBIR system and improve the results of the CBIR system in comparison with the results of the
CBIR system without using LTL method. Furthermore, the results are improved by increasing the number of user logs.

The comparison between VFB-LTL and CB-LTL methods shows that CB-LTL method achieves better retrieval precision than VFB method, except for round zero. VFB-LTL method, by considering virtual features of all images in the similarity function, gets better results in the round zero. However, in the CB-LTL method, due to the smart initialization of weights, the improvement of precision during rounds is better. In other words, by using CKB, the STL becomes more effective. In addition, by using the relevancy vector of each semantic category, more semantically similar images that are not similar in visual features, are delivered to the user.
An example of retrieved images for a query image with semantic meaning of space in the CBIR system without LTL method and with the LTL methods of CB and VFB are presented in Fig. 9 .In this example, CB-LTL method produces the higher precision. 5.4.2. Robustness against noise
We further evaluated the proposed system in the situation of erroneous feedback ( Qi et al., 2011; Yin et al., 2008 ). Erroneous feedback results from the inherent subjectivity of judging rele-vance, user laziness, or maliciousness ( Qi et al., 2011 ). In a CBIR, there are two types of noises: false negative noise and false positive noise ( Yin et al., 2008 ). In a false negative noise, a truly relevant retrieved image is marked as irrelevant. On the other hand, in a false positive noise, a truly irrelevant retrieved image is mistakenly marked as relevant. In this paper, both types of noise are simultaneously injected in equal proportions. The vein is that in each session, a percent of the retrieved images are randomly chosen and marked as noisy feedbacks.

In order to evaluate the proposed algorithms for noisy logs, 5% and 10% noise are injected into the 1500 log sessions. The methods are compared in terms of the retrieval precision when correct and erroneous feedback is involved. Fig. 10 compares the average retrieval precision of the CB-LTL and VFB-LTL at the level of 5% and 10% random erroneous feedback. As it shows, the mislabeling makes the two LTL methods decrease their retrieval precision in all rounds comparing with their retrieval precision achieved using correctly labeled information. However, in Fig. 10 , it is seen that
CB-LTL method is more robust against noise than the VFB-LTL method. The averaged precision reduction of fi nal round (PR4) at the level of 5% and 10% erroneous feedback, respectively, are about 0.07 and 0.13 for CB-LTL method and are about 0.08 and 0.10 for
VFB-LTL method. Furthermore, the averaged precision reduction of round zero ( PR 0) at the level of 5% and 10% erroneous feedback, respectively, are about 0.06 and 0.07 for CB-LTL method and are about 0.14 and 0.24 for VFB-LTL method. In fact, the CB-LTL method uses the information of the cases stored in semantic frames. These values are averaged not only between relevant images in a session, but also over various sessions. Thus, its robustness against noise is better than VFB-LTL. In general, noisy logs degrade learning methods easily.Accordingly,itisanimportanttaskto fi lter the noise from the logs. It is expected for future studies to produce advanced techniques for removing noise from the logs. 5.4.3. Tracking the progress of CB-LTL method
In this experiment, the system starts with an empty CKB. CKB is gradually completed while visiting half of the dataset images (5k images). In these sessions, images are retrieved using long term reasoning, and case knowledge database (CKB) is updated after each session. To construct the progress graph, the whole sessions (in the order of visiting) are divided into several sets of 500 sessions and the averaged precision of each set is calculated for fi nal round. Considering this graph, we can track the progress of the CBIR system by completing LTL knowledge base.

The progress graph of a CBIR system without LTL (just with STL) and a CBIR system with the  X  CB-LTL method  X  is given in Fig. 11 .
In Fig. 11 , the vertical axis presents the averaged precision taken over 500 retrieval sessions and the horizontal axis is the order of the set (i.e. 1st set or the fi rst 500 sessions, 2nd set or second 500 sessions, ... , and so on). In this graph, the progress is tracked from the start until visiting half of the dataset images. In the CB-LTL method, by completing long term knowledge base, it is expected that each set achieves better precision results than its previous set. In Fig. 11 , it can be seen that system do not progress without using
LTL but with using CB-LTL, the system progress by visiting more queries. The progress graph shows that the results are improved gradually by completing the CKB while visiting half of the dataset images. 5.4.4. Parameter tuning
In the proposed method, there are three parameters of th p and th which are determined empirically. With th p , successful sessions are determined. We ignore sessions with the value of precision less than 0.16 as useless sessions. In these sessions, the number of relevant images is less than 4 images of 25 retrieved images. We empirically found that sessions with the value of precision less than 0.16, do not drastically improve the retrieval results of the future sessions. By saving useless sessions, we just waste memory.

The parameter of th m is used for merging purpose. If the value of th m is high, similar categories will not merge and if it is low, wrong categories are merged. Referring to Eq. (7) , with th the categories that activated at the same time and have the different relationship (relevant or irrelevant) with less than two images, are merged.

Parameter of th , is the threshold that shows the relevancy of positive or negative images to a category. In a session, if the proportion of positive images which are relevant to category k is more than th , and the proportion of the negative images which are relevant to category k is less than th , we statistically determine that this session is associated with category k . We try all possible values of th in the range of 0  X  1. The graphs of the averaged precisions for th  X  0.04, 0.08, and 0.16 are compared in the case of 1500 user logs in Fig. 12 . It can be seen that the best setting for th is 0.04. 5.5. Comparative results on VOC dataset
In this section, the results are compared in 10k real-world images of Pascal VOC 2012 dataset, with 20 different classes of objects. To this, 1500 query sessions are collected in the user log. Then, the average of the results over 100 query sessions is presented. The graph of the average precision per round for 100 random query images is shown in Fig. 13 . From this fi gure, it can be seen that the each of the LTL methods improves the retrieval accuracy in comparison with the same CBIR system without using the LTL method. The comparison between VFB-LTL and CB-LTL methods shows that CB-LTL method achieves better retrieval precision than VFB method, except for round zero. 6. Conclusion and future work
In this paper, the methodology of case based reasoning is employed to propose a relevance feedback technique in the CBIR systems. We name this method case-based long term learning or
CB-LTL. In the proposed CB-LTL method, well doing retrieval sessions are recorded as cases which are kept in the case knowl-edge base or CKB. To record cases, the semantic frame is intro-duced. Semantic frame is the structure of recording discovered semantics with both low level and high level features. Two main processes of CB-LTL are learning and reasoning processes. During the learning process, the CKB is updated and during reasoning process, the contents of the CKB are employed to boost retrieval results. To fi nd a case similar to a retrieval session, the trigger function is used.

After de fi ning the general idea of the CB-LTL, a version of this method is designed and examined in a CBIR system with the similarity re fi nement based STL. In the proposed method, infor-mation obtained in short term learning (i.e., learned weights and key of query) is used to construct cases. Comparative results with virtual feature based LTL method con fi rm the ef fi ciency of the proposed method.
 This is possible for the CB-LTL method to be adopted in variety
CBIR systems or even in video retrieval systems. In this paper, this method is implemented in a similarity re fi nement based CBIR systems. In future works, it is suggested to design further kinds of
CB-LTL method to employ in other types of CBIR systems. To this purpose, the information of semantic frames and the processes of learning and reasoning should be adapted to the target CBIR system.

Another open research area in this method is providing some innovative data for extracting from sessions during relevance feedback. One of the most effective parts in CB-LTL method is meta-knowledge extraction. Recording cases with meaningful data makes them more bene fi cial for improving future retrieval ses-sions. Therefore, suggesting useful data could signi improve the ef fi ciency of the method.
 Acknowledgement
This work is supported in part by Iran Research Institute for ICT under Contract no. t-500-19245.
 References
