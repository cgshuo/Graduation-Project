
How can we quickly find the number of triangles in a large graph, without actually counting them? Trian-gles are important for real world social networks, ly-ing at the heart of the clustering coefficient and of the transitivity ratio. However, straight-forward and even approximate counting algorithms can be slow, trying to execute or approximate the equivalent of a 3-way database join.
 In this paper, we provide two algorithms, the Eigen-Triangle for counting the total number of triangles in a graph, and the EigenTriangleLocal algorithm that gives the count of triangles that contain a desired node. Additional contributions include the following: (a) We show that both algorithms achieve excellent ac-curacy, with up to  X  1000x faster execution time, on several, real graphs and (b) we discover two new power laws ( Degree-Triangle and TriangleParticipa-tion laws) with surprising properties.
Finding patterns in large scale graphs, with millions and billions of edges is attracting increasing interest, with numerous applications in computer network se-curity (intrusion detection, spamming), in web appli-cations (community detection, blog analysis) in social networks (facebook, linkedin, for link prediction), and many more. One of the operations of interest in such a setting is the estimation of the clustering coefficient and the transitivity ratio, which effectively translates to the number of triangles in the graph, or the number of triangles that a node participates in.

It is known that in social networks there is a higher-than-random number of triangles ([27]). The reason is that friends of friends are typically friends themselves. the number of nodes in the network. For large or huge networks this is prohibitive. Therefore, in practice it is preferred to list the triangles ([20]). Other approaches, instead of counting exactly the triangles, adopt the streaming model ([3],[5]) or even more recently a semi-streaming model([4]).
 The main contribution of this paper is the Eigen-Triangle algorithm, based on Theorem 3.1 saying that the number of triangles is exactly one sixth of the sum of cubes of eigenvalues and the properties of  X  X eal-world X  network spectra. This is a completely novel view point, which opens the door to the vast machin-ery of eigenvalue algorithms and fine-tunings. Eigen-values can be easily computed for sparse graphs, and can be applied on a map/reduce ( X  X adoop X ) architec-ture, which is extremely promising for Peta-byte scale graphs.

The additional contributions are the following 1. Fast total triangle count An algorithm for the 2. Fast local triangle count A theorem and an al-3. Extensive experimentation We used almost 4. Laws : New power laws in real networks with sur-
The rest of the paper is organized as follows: Sec-tion 2, surveys earlier triangle-counting methods. In Section 3 we present the EigenTriangle and Eigen-TriangleLocal theorems and algorithms, for global and local triangle counting, respectively. Section 4 gives the experimental results on several real data sets. Section 5 lists some surprising laws that govern the count of triangles in real graphs. In Section 6 we present some theoretical ramifications of the previous sections and we conclude in Section 7. [20], a further improvement of the forward algorithm is proposed, called the compact -forward algorithm. Streaming algorithms The memory restrictions when dealing with huge graphs lead us to the streaming approach. In the streaming model, the goal is to find a randomized algorithm that outputs an -approximation of the number of triangles with probability at least 1- X  with one pass access to the graph data stream. The main advantage of this approach in comparison to the non-streaming scenario is that it requires a single pass over the data. Representative work on the streaming case are [3] and [5]. In [3], rigorous theory supports the algorithms making them attractive for practical appli-cations. Still, there are open issues according to the authors such as justifying when their adjacency stream model is superior to the naive sampling method.In [5], accuracy in certain cases can be an issue. Recently, the semi-streaming model was introduced by [4] to solve the local counting problem. This model relaxes the strict restriction of the single pass over the data, and instead it uses an amount of main memory ( O ( n )) and performs O ( log ( n )) sequential scans over the edge file. The authors do not make a comparison to existing ap-proaches and report overflow problems in the imple-mentation as the number of passes increases.
The goal of this work is to propose a new method for counting triangles approximately in large, real-world networks while being accurate, fast, and easily parallelizable. The last goal is also of great impor-tance, since it will provide a way to mine huge graphs using parallel architectures such as the map/reduce ( X  X adoop X ) [10]. Furthermore,if all these goals are met at once, the  X  X rade-off X  described in section 2 will be destroyed. The method we propose achieves all the above characteristics when the graph has some special properties. Real-world networks appear to have them very frequently.

Table 1 gives a list of symbols and their definitions.
Using simple linear algebra arguments, we prove two theorems on the top of which our methods are built. Theorem 3.1 (EigenTriangle) The total number of triangles in a graph is proportional to the sum of cubes of eigenvalues, namely: Algorithm 1 The EigenTriangle algorithm Require: Adjacency matrix A ( n x n ) Require: Tolerance tol Output:  X  0 ( G ) global triangle estimation  X  1  X  LanczosMethod ( A, 1) ~
 X   X  [  X  1 ] i  X  2 { initialize i , ~  X  } repeat until 0  X  return  X  0 ( G ) adjacency matrix where u i,j is the i -th entry of the j -th eigenvector. Proof Easy extension of 3.1. It follows from the facts that since A nxn is symmetric, A = U n  X U 0 n , where  X  is a diagonal matrix with diag (  X  ) = ~  X  n (all eigen-values are real and U n is an orthogonal matrix and therefore A 3 = U n  X  3 U 0 n according to [25]) and that each triangle is counted twice. Q.E.D
We can see the pseudocode of the EigenTriangle and EigenTriangleLocal algorithms. Both take only a tolerance parameter: tol . The intuition behind the tolerance parameter is to stop looping when the smallest eigenvalue contributes very little to the total number of triangles.

Both algorithms use the subroutine LanczosMethod as a black box 1 . The Lanczos method is a well stud-ied projection method for solving the symmetric eigen-value problem using Krylov subspaces. Our choice is due to the following reasons: a) It is based only on matrix-vector products, which are easy to parallelize. b)  X ..with minimal memory requirements very large problems can be handled on not very large computers, and huge problems can be handled on large comput-ers X  (quote from [9]). c) High quality software is avail-able (ARPACK,Parallel ARPACK etc.). More details about the Lanczos method can be found in [17], [19]. 3.3.1 Justifying the convergence speed of the Lanczos algorithm can run in general into convergence problems. However, in the experiments we conducted, we never faced this problem. This interesting phe-nomenon happens because real-world networks have usually have a big spectral gap, which makes Lanc-zos robust. In more detail, we use the Kaniel-Paige convergence theory and the special properties of real-world networks. In particular, in [12] it is claimed that real-world networks have a big gap  X  1 -|  X  2 | 2 . This claim was experimentally verified and is in accordance with [13],[24],[6]. Also, according to Kaniel-Paige con-vergence theory ([17]) if  X  1  X  ...  X   X  k are the eigen-values of the tridiagonal T k (a small matrix internally constructed by Lanczos) obtained after k steps of the Lanczos iteration, then the following inequality holds: polynomial of degree k  X  1. Therefore, in our case  X  1 is larger than zero and since Chebyshev polynomials grow very fast outside [-1,1] ([23]), Lanczos converges very fast.
We do experiments to answer the following ques-tions: for at least 95% accuracy what are the speedups we can achieve for the triangle counting problem?
First we give the experimental setup, and then the results.
Each graph was preprocessed by removing any self-edges, the direction of the edges and the weights when-ever needed. The number of nodes and edges of the networks used after the preprocessing are summarized in table 2. 3 As a competitor we chose the Node Itera-tor (see section 2) since it is much superior to the naive O ( n 3 ), easy to implement and has asymptotically the same time and space complexity with the Edge itera-tor . We ran the experiments in a machine with a quad-(#edges).
 Finishing this section, we provide the following  X  X ule of thumb X : Follow the default tol =0.05 which gave the results reported here. Our experiments showed little sensitivity on the choice of tol . Alternatively an even easier rule of thumb is to pick the top 30 eigenvalues (since we got all our results with less than 25 eigenval-ues, see figure 3).
To measure of the performance of the EigenTri-angleLocal algorithm, we use Pearson X  X  correlation coefficient  X  and the relative reconstruction error (as in [4]).
 In figure 4 we see how well ~  X  0 ( G ) approximates ~  X ( G ) with the top 10 eigenvalues and eigenvectors. The RRE we obtain is 7  X  10  X  4 and  X  almost 1.

Figure 5 explains why our proposed methods work well in practice. It plots the rank of the approxima-tion vs.  X  . We observe that after the second rank approximation, for all three networks the approxima-tion is excellent:  X  is greater than 99.9% whereas the RRE has always order of magnitude between 10  X  7 and 10  X  4 . Similar results hold for the rest of the datasets we experimented with.

Social Networks
Co-authorship networks
Information networks
Web graphs 2,983,494 35,048,116 Wikipedia 2006-Sep-25 3,148,440 37,043,458 Wikipedia 2006-Nov-04
Internet networks
Table 2. Summary of real-world networks used. the count of nodes participating in that many triangles. Both scales are logarithmic. We show the results only for three of the datasets for brevity (Epinions, Anony-mous social network and HEP-TH) , because the rest have similar behavior. The over-arching observation is that the number of participating triangles follows ei-ther a power law, or a lognormal-like distribution, with a power-law tail. The important point is that gener-ating these plots can be from 30x to 1000x faster with our proposed algorithms with high accuracy. 5.2 Degree-Triangle law
Is there a correlation between the i -th largest degree d , and the number of triangles? This is the focus of our exploration. The results are surprising, and shown in Figure 7. The Figure plots the degree d i vs. the mean number of triangles over all nodes with degree d i for the specified networks (the rest of the networks we used had similar behavior and are omitted for brevity). The Figure also has insets, showing the degree distribution (PDF), in log-log scales. We performed least square fitting.

We have the following observations from there.  X  Degree-Triangle power law:  X  d i avg (see table 1 of the degree distribution in the insets (least squares fitting). the Kronecker matrix multiplication). Let G B denote the corresponding graph.
 Let ~  X  = (  X  1 ,.., X  n ) be the eigenvalues of matrix A . Then we have: Theorem 6.1 (KroneckerTRC) The number of tri-angles  X ( G B ) of G B can be computed from the n eigen-values of A : Proof We use induction on the depth of the recursion k . For k = 0, KroneckerTRC trivially holds (see thrm. 3.1). So the base case is true. Let Kroneck-erTRC hold for some r  X  1. For notation simplicity, Timing results, and stochastic Kronecker graphs Experimenting on a small deterministic Kro-necker graph with 6,561 nodes and 839,808 edges com-ing from the 3-clique initiator with depth of recursion equal to 3, we get 10 6 faster performance. As the size of the Kronecker graph increases, we obtain arbitrarily huge speedups.

What is interesting is that the KroneckerTRC theorem also leads to fast estimation of triangles, even for stochastic Kronecker graphs (see [22] for the defini-tions). Stochastic Kronecker graphs have been shown to mimick real graphs very well. Intuitively, a stochas-tic Kronecker graph is like a deterministic one, with a few random edge deletions and additions. Our ex-periments with a stochastic Kronecker graphs show that these random edge manipulations have little ef-fect on the accuracy. Specifically, our experiments with n =6,561 and m =2,202,808 4 , show that we obtain 1 . 5  X  10 6 x faster execution, while maintaining 99.34% accuracy. Similar results hold for other experiments we conducted as well. Proving bounds for the accuracy for stochastic Kronecker graphs is an interesting research direction.
It is interesting to notice that our algorithm is guaranteed to give high accuracy and speedup perfor-mance for random Erd  X os-R  X enyi graphs. This is due to the so-called Wigner X  X  semi-circle law for all but the first eigenvalue [15]. For example, for a graph with n = 20 , 000 and p = 0 . 6, using EigenTriangleLo-cal with 0.05 tolerance parameter, we get 1600 faster performance compared to the Node Iterator with rela-tive error 5  X  10  X  5 and Pearson X  X  correlation coefficient almost equal to 1 5 . The main contribution of this work is the Eigen-Triangle algorithm. It uses a link between the num-ber of triangles and the eigenvalues (Theorem 3.1) of the adjacency matrix and the observation that just the top eigenvalues contribute significantly to the to-tal number of the triangles. This is a major observa-tion opening the door to the vast machinery of readily available, highly fine-tuned eigenvalue algorithms and implementations. These algorithms are not only fast, [4] L. Becchetti, P. Boldi, C. Castillo, and A. Gionis. [5] L. S. Buriol, G. Frahling, S. Leonardi, [6] F. Chung, L. Lu, and V. Vu. Eigenvalues of ran-[7] F. R. K. Chung. Spectral Graph Theory . American [8] D. Coppersmith and S. Winograd. Matrix mul-[9] J. K. Cullum and R. A. Willoughby. Lanczos Al-[10] J. Dean and S. Ghemawat. Mapreduce: Simplified [11] J.-P. Eckmann and E. Moses. Curvature of co-[12] E. Estrada. Spectral scaling and good expansion [13] M. Faloutsos, P. Faloutsos, and C. Faloutsos. On [14] I. J. Farkas, I. Derenyi, A.-L. Barabasi, and [15] Z. F  X uredi and J. Koml  X os. The eigenvalues [16] R. G. Godsil C.D. Algebraic Graph Theory .
