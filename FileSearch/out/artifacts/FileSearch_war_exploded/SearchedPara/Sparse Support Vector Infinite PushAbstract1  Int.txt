 Alain Rakotomamonjy alain.rakoto@insa-rouen.fr Learning to rank is a supervised learning problem which objective is to estimate a scoring function from training examples. That function is expected to define a partial order on the examples by scoring relevant in-stances higher than the non-relevant ones. Examples of applications in which ranking is central are infor-mation retrieval ( Chapelle &amp; Keerthi , 2010 ), drug dis-covery ( Agarwal et al. , 2010 ).
 Many machine learning algorithms have been proposed for learning ranking functions. Some of them aim at optimizing a pairwise ranking criterion using ex-ponential loss, like the RankBoost of Freund et al. ( 2003 ) or using Hinge loss ( Joachims , 2002 ). Meth-ods based on decision trees have also been investigated ( Cl  X emencon &amp; Vayatis , 2009 ). While these methods have shown their interests, they may not be optimally targeted at a specific goal which is getting an accurate ranking at the top of the list. Indeed, for instance, in information retrieval, one usually wants to have the most relevant documents as possible at the top of the list, while getting an accurate pairwise ordering in other part of the list is not of great importance. For this reason, several recently proposed algorithms focus on correctly ranking the best instances ( Rudin , 2009 ; Agarwal , 2011 ).
 For most of the works we described above, the scoring function is a linear function of the form f ( x ) = w  X  x , where w is the weight vector that has to be learned. The resulting weight vector w is usually a non-sparse vector, which means that all features will be con-sidered in the scoring function even though they are non-informative. Hence, similarly to other supervised learning paradigms, ranking methods may also bene-fit from feature selection as keeping only few features in the scoring function may improve performances as well as reducing prediction time. To the best of our knowledge, very few works have addressed the prob-lem of feature selection in ranking ( Geng et al. , 2007 ) and in ranking on top of the list problems. Naturally, algorithms like the SVM-RFE or methods based on sparsity-inducing norms like the  X  1 norm can be easily extended to ranking algorithms. But developing algo-rithms for embedded feature selection becomes more challenging when loss functions related to ranking on top have to be considered. This is the challenge we want to address in this paper and as far as we know, this is the first paper proposing embedded feature se-lection using sparsity inducing norms for ranking on top of the list.
 We focus on the recent p -norm push loss function in-troduced by Rudin ( 2009 ) and more specifically, on the case where p =  X  , denoted as an infinite push framework by Agarwal ( 2011 ). In this latter work, Agarwal ( 2011 ) has also proposed a support vector like algorithm, named as support vector Infinite Push, which has been proved to perform better than com-petitors when the goal is to maximize the number of relevant instances on top of the list. Here, we provide a novel algorithm for solving the regularized empirical risk minimization related to the support vector Infi-nite Push loss function that can also handle sparsity inducing regularizers. While typical methods dealing with sparsity suppose that the loss function is smooth ( Bach et al. , 2011 ), our optimization problem is chal-lenging since both the loss function and the regularizer can be non-differentiable. We propose to overcome this issue by proposing an alternating direction method of multipliers (ADMM), which is wrapped around the computation of the infinite push loss function proxi-mal operator in addition to the one of the regularizer. Globally, the paper provides contributions to the state of the art in several points: (a) it proposes a numer-ical scheme for computing the proximal operator of the support vector infinite push loss function, (b) it shows that the optimization framework we consider offers some theoretical guarantees on the uniqueness of the problem minimizer, property that is not always insured by Agarwal X  X  algorithm, (c) it is the first paper showing that p -norm push ranking algorithms can also embed feature selection through the use of sparsity in-ducing norms. It demonstrates that ranking on top applications can also benefit from feature selection ei-ther by improved performances or reduced prediction time.
 The paper is organized as follows. Section 2 introduces the global framework for ranking on top of the list as well as the optimization related to sparse support vector infinite push. In Section 3 , the ADMM-based algorithm proposed for solving the problem and the numerical scheme for computing the proximal operator of the infinite push loss are presented. Experimental results are described in Section 4 while conclusion is in Section 5 . In this section, we introduce the Infinite Push loss function and the support vector Infinite Push opti-mization problem we are interested in. Existence and uniqueness of solutions to the problem are also dis-cussed. 2.1. Infinite Push loss function We limited ourselves to the case of bipartite ranking problem which goal is to learn a function that, given negative examples, gives higher scores to positive ex-amples than to negatives ones. Learning such a func-tion can be cast into an empirical regularized risk min-imization framework, where the loss function related to the risk is designed so as to favor higher scores for positive examples. Typically, in such a context, the loss function focuses on the average pairwise scoring losses and it can be written as : where I  X  is the indicator function, S is a set of exam-ples with known labels and f (  X  ) is the scoring function that we want to evaluate. Several extensions of this loss function have been recently considered in order to provide more importance to errors made on top of the lists, for instance by weighting the pairwise loss ( Usunier et al. , 2009 ) or by replacing the mean with some more appropriate functions. For this purpose, Rudin ( 2009 ) has introduced the Infinite Push loss function which gets smaller as the negative example with high-est score is assigned a small score. This loss function is the one on which we have focused our interest. 2.2. Support Vector Infinite Push We can now define the empirical risk minimization (ERM) framework used for learning the scoring func-tion f (  X  ) that we have chosen to be linear so that f ( x ) = w  X  x . the loss function given in Equation ( 1 ) is non-convex and different convexifications proposed in the literature have led to different ERM frameworks and algorithms. We can mention for instance the re-laxation by means of exponential loss that yield to boosting-like algorithm ( Rudin , 2009 ). If Hinge loss is used as a convex relaxation then we get the following Support Vector like optimization problem : min where  X ( w ) is some regularization term and the func-tion ( u ) + = u if u &gt; 0 and 0 otherwise. For  X ( w ) =  X  2 k w k 2 , Agarwal has proposed an algo-rithm for solving the dual of this problem, which is : min which has smooth quadratic objective function under some mixed-norm constraints over the dual variables  X  i,j . The algorithm is based on a nice and clever gra-dient projection algorithm ( Agarwal , 2011 ). In this paper, we focus our effort on this support vec-tor infinite push problem and propose a novel opti-mization algorithm for solving it when  X ( w ) is some non-differentiable sparsity-inducing regularizer so as to perform feature selection in a top-ranking learning problem. For this purpose, we investigate an algorithm that directly solves the primal problem in Equation ( 2 ).
 However, before delving into the details of the algo-rithm, we discuss, in what follows the existence and uniqueness of the solution of the primal problem ( 2 ) based on some classical results on convex analysis: Proposition 1. (a) For any convex regularization term  X ( w ) that is lower semi-continuous and and coer-cive, problem ( 2 ) admits at least one solution. (b) For any strictly convex, lower semi continuous and coer-cive regularization term, problem ( 2 ) admits an unique solution.
 We omit the proof of these two propositions since they are rather direct consequences of some well known re-sults on the minimization of composite non-smooth functions ( Combettes &amp; Pesquet , 2007 ). Instead, we prefer to bring to light some properties of the pri-mal problem compared to the dual one that are con-sequences of these propositions : An interesting point is that for  X ( w ) =  X  2 k w k 2 , point 2 of the proposition guarantees uniqueness of solution since  X  satisfies all required properties. Conversely, when considering the dual problem ( 3 ) as in Agarwal ( 2011 ), this property may be lost. Indeed, it can be easily shown that when the dimensionality of the prob-lem d is smaller than m  X  n , the Hessian of the dual ob-jective function is only positive semi-definite. We re-mark that even for small-scale high-dimensional learn-ing problem, the condition d &lt; m  X  n can be rapidly reached making optimization in the primal theoreti-cally more sound.
 Uniqueness of the solution for  X  1 norms or mixed-norms are more involved and we have left these anal-yses for future works. In this section, we show how we leverage the issues raised by the non-smooth objective function in prob-lem ( 2 ) and we describe in details the ADMM algo-rithm we propose for solving the sparse support vector infinite push problem. 3.1. Deriving ADMM formulation Before delving into the derivations, we want to men-tion that Douglas-Rachford splitting algorithm is tai-lored for minimizing the sum of two non-smooth ob-jective functions. However, the presence of the design matrix will add some linear constraint on the prob-lem, making it easier to address through an ADMM framework. For this purpose, we rewrite the optimiza-tion problem ( 2 ) as the following linearly-constrained problem : where  X ( w ) can be any sparsity inducing norm like the  X  1 norm, any mixed-norm ( Bach et al. , 2011 ) or the classical  X  2 regularization term. Then, by prop-erly defining the matrix X (which rows are of the form ( x + i  X  x  X  j ) T ), the vector a and the function g ( a ) = max j 1 m P i max( a i,j , 0) we yield the follow-ing reformulation : The augmented Lagrangian related to this problem is
L ( w , a ,  X ,  X  ) =  X ( w ) + g ( a ) +  X   X  ( Xw + a  X  1 ) where  X  is a vector of Lagrangian multipliers related to the equality constraint and  X  is a parameter weighting the quadratic penalty. After rearranging the terms, one can show that the augmented Lagrangian is
L ( w , a ,  X  ) =  X ( w ) + g ( a ) +  X  2 k Xw + a  X  1 +  X  k where  X  =  X   X  . The alternating direction method of multipliers that solves our original problem ( 4 ) looks for a saddle point of the augmented Lagrangian by solving alternatively at iteration k the following prob-lems : All the challenges of the algorithm now resides essen-tially in the resolution of these problems.
 3.2. Solving problem ( 6 ) The optimization problem related to w can be restated as with s being 1  X  a k  X   X  k . Depending on the form of  X ( w ), this problem becomes a ridge regression prob-lem for  X ( w ) =  X  2 k w k 2 , a Lasso when  X ( w ) =  X  k w k or another (probably known) problem if a different reg-ularization term is considered.
 For sparsity-inducing regularizers ( e.g  X  1 norm), the problem has to be solved numerically and thus, each iteration of the ADMM approach involves the resolu-tion of a Lasso. Depending on the Lasso algorithm used, one can highly benefit from warm-starting the solution since between two consecutive ADMM itera-tion, the second member s is not expected to vary a lot.
 For the  X  2 norm regularizer, the solution has a closed-form solution In some situations, when the dimensionality of the problem is large, it may be more efficient to numer-ically solve this linear system by means of a conjugate gradient descent approach. 3.3. Solving problem ( 7 ) Now supposing that w and the Lagrangian multipliers  X  are fixed in the Lagrangian, the optimization prob-lem related to ( 7 ) boils down to be : with s being 1  X   X  k  X  Xw k +1 . We note that by def-inition, a k +1 is the result of 1  X  g (  X  ) proximal operator applied to the vector s ( Combettes &amp; Pesquet , 2010 ). Now, let us look into more details at this problem. The most challenging part of it comes from the two nested max functions defining g (  X  ). In order to overcome part of the issues, we propose to use the doubling trick and rewrites the minimization problem as : with a = a +  X  a  X  . Now, since the regularization term and the constraints are decoupled in a + and a  X  , we suggest to solve problem ( 10 ) by means a of block-coordinate descent (BCD) algorithm that starts from some positive random vectors and alternatively opti-mize over a + then a  X  keeping the other vector fixed. Before providing algorithmic details, we state here a proposition based on the work of Tseng ( 2001 ) that guarantees the soundness of the BCD algorithm. Proposition 2. Let us define f 0 ( a + , a  X  ) = 1 2 k a + a  X   X  s k 2 f ( a  X  ) = I method by alternatively optimizing over a + and a  X  converges towards the minimum of Problem 10 . Proof. It is easy to see that the objective function f ( a + , a  X  ) of Problem 10 is f ( a + , a  X  ) = f 0 ( a f its domain and coercive, f (  X  ,  X  ) is convex with respect to any of its parameter with the other fixed and the Owing to all these properties, applying Theorem 5.1 of Tseng ( 2001 ) concludes the proof.
 Now, we are interested in solving each coordinate de-scent of Equation ( 10 ). When considering minimizing over a  X  with a + fixed, the problem is rather simple since it boils down to be a projection of  X  s + a + on the positive quadrant. Hence, we have the following closed-form solution for each component of a  X  : We can now focus on the other alternate problem with b = a  X  + s and G i being the indices of elements of a coupling the negative example x j with positive examples. Interestingly, owing to the positiveness of a + and by replacing the constraint in the objective value this problem is equivalent to min We can note here that the solution of this problem occurs at with I  X  X  0 being the indicator on the positive quad-rant and  X   X  ( u ) = max j 1 m X  P i  X  G a mixed  X   X   X   X  1 norm on u . The proximal opera-tor prox I puted numerically. For this purpose, we have applied a Douglas-Rachford algorithm which can handle the minimization of the sum of two non-smooth convex functions f 1 and f 2 . The following proposition makes this explicit : Proposition 3. ( Combettes &amp; Pesquet , 2010 ) Let f 1 and f 2 be two convex lower semi-continuous functions of R d such that the intersection of their domain rela-tive interiors is not empty and such that f 1 (  X  ) + f 2 is coercive. Set v 0  X  R d and build u n for n  X  0 as with  X  &gt; 0 and  X   X  ]0 , 2[ , then every sequence { u n generated by this algorithm converges towards a mini-mizer of f 1 + f 2 .
 Hence, a direct application of this algorithm to our problem given in Equation ( 11 ) with f 2 ( v ) = 1 2 k v  X  b k 2 + I v  X  0 and f 1 ( v ) = max j to the minimizer of Equation ( 11 ). Now the remaining question is : what are the proximal operators of  X f 1 and  X f 2 ? For  X f 2 , we have to solve the problem which solution can be easily proven to be with P C being the projection on the positive quadrant. Now, regarding  X f 1 , we look for which is the proximal operator of a  X   X   X   X  1 mixed norm. For solving this problem, we use classical result from convex analysis and proximal operator ( Combettes &amp; Wajs , 2005 ; Sra , 2011 ), which states that the proximal operator of a norm k X k is radius ball of the dual norm k X k  X  . Then, since the dual norm of  X   X   X   X  1 norm is the  X  1  X   X   X  norm, we have This problem is easily tractable since projection of vec-tor on a  X  1  X   X  ball has been recently studied and several efficient algorithms proposed ( Quattoni et al. , 2009 ; Sra , 2011 ).
 Algorithm 1 ADMM approach for primal infinite push. 1: Input : X : matrix of pairwise difference of exam-2: set  X  &gt; 0, k = 0 4: repeat 5: s = 1  X  a k  X   X  k 8: set a + = 0 and a  X  = 0 9: repeat 10: a  X  = max(  X  s + a + , 0) 11: set b = a  X  + s and v 0 = 0 12: repeat 13: u n = 1 1+  X  max( v n +  X  b , 0) 15: until convergence is met 16: a + = u n 17: until convergence is met 20: k  X  k + 1 21: until condition 3.4. Convergence analysis Convergence of Algorithm 1 , for solving the primal in-finite push problem builds upon classical convergence results of ADMM or Douglas-Rachford splitting algo-rithm ( Eckstein &amp; Bertsekas , 1992 ). Indeed, a direct application of Theorem 8 in that paper tells us that our algorithm converges for any  X  &gt; 0, as long as the matrix X has full column rank (condition that is satisfied by most non-degenerate problems for which d &lt; m  X  n ) and that the computation errors of prob-lem ( 6 ) and problem ( 7 ) are summable. Practically, this latter condition means that the convergence cri-terion on these two problems should become tighter and tighter as the iterations go. However, in our im-plementation, these stopping criteria have been kept fixed but still no empirical problem of convergence has been noticed. 3.5. Computational complexity The two most computationally demanding part of our algorithm for sparse infinite push is the Lasso prob-lem that has to be solved at each iteration and the projection on the  X  1  X   X   X  ball. For the Lasso, there exists efficient algorithms that scale linearly with the number of training examples. We can, for instance, mention the SpaRSa algorithm of Figueiredo et al. ( Figueiredo et al. , 2007 ). Similarly, the projection on the  X  1  X   X   X  ball of Quattoni et al. ( 2009 ) has a com-plexity of O ( n log n ) in the size of the vector to project. Hence, in our case, since the number of examples in the Lasso and the size of the vector to project are both m  X  n , we end up with an algorithm which complexity is O ( m  X  n log m  X  n ).
 As a comparison, a plain implementation of RankSVM would also lead to a complexity that is linear with respects to the number of pairwise exam-ples ( Chapelle &amp; Keerthi , 2010 ). However, since RankSVM is easier to deal with as the loss function can be made differentiable we expect RankSVM to have a better constant. Our objective here is to provide empirical evidences that our method can be beneficial in problems with noisy or redundant features compared to an infinite push approach that considers all the features. We also show that when compared to other feature selection methods like recursive feature elimination (RFE) in an infinite push context, our embedded approach based on sparsity-inducing norm provides better accuracy on top of the list.
 Note that we have not compared our methods to other ranking algorithms, except SVMRank ( Chapelle &amp; Keerthi , 2010 ), since Agarwal ( 2011 ) has already shown the superiority of the infinite push model on other methods for ranking positive instances on top of the list and because these methods such as SVMMAP does not have their sparse counterpart in the literature. 4.1. Toy problem On this problem, we compare the efficiency of using an  X  1 sparsity-inducing norm to recursive-feature elim-ination for reducing the influence of noisy variables in an infinite push framework. Our RFE implemen-tation follows exactly the same procedure as the one used for SVM RFE ( Guyon et al. , 2002 ), but replac-ing the SVM with the infinite push algorithm as pro-posed by Agarwal ( 2011 ). This infinite push RFE bears strong resemblance with the backward elimina-tion of Geng et al. ( 2007 ). For a baseline comparison, we have also included an  X  1 SVM Rank.
 The toy problem is a binary classification problem in R variables, only r of them define a subspace of R d in which classes can be discriminated. For these r rele-vant variables, the two classes follow a Gaussian pdf with mean respectively  X  and  X   X  and covariance ma-trices randomly drawn from a Wishart distribution.  X  has been randomly drawn from { X  1 , +1 } r . The other d  X  r non-relevant variables follow an i.i.d Gaussian probability distribution with zero mean and unit vari-ance for both classes. We have respectively sampled n and n t number of examples for training and test-ing. For some experiments, n is varying, but we have always set n t = 1000. Before learning, the training set has been normalized to zero mean and unit vari-ance and the test sets have been rescaled accordingly. Hyperparameters of all methods have been chosen as those maximizing performance on a validation set ob-tained by random 70%  X  30% split of the training set examples.
 Averaged results over 20 trials are depicted on Fig-ure 1 which plots the rate of positive on top of the list defined as #pos. on top m , with respects to varying number of training examples for fixed number of fea-tures. We note that our  X  1 support vector infinite push significantly outperforms other competitors, in most cases with a p-value of a Wilcoxon signed rank test lower than 0 . 05 (the numbers besides the markers). We can also remark that unlike the infinite push ap-proach, SVM Rank does not necessarily improve its performances on the top as the number of examples increases. This is unsurprising as SVM Rank aims at optimizing average ranking.
 Figure 2 depicts the precision and the F-measure of the different algorithms for retrieving the true variables. We remark that the RFE infinite push performs very good with respects to the F-measure. However, the use of the  X  1 norm yields to a better precision : more relevant variables are selected at the expense of select-ing some irrelevant ones. This is a well known issue of the  X  1 norm that can be overcome using an adaptive approach ( Zou , 2006 ).
 An empirical illustration of the computational com-plexity of our algorithm as well as the one of a sparse SVM Rank is reported in Figure 3 . We can highlight that both algorithms have an empirical exponent com-plexity of about 1 with respects to the number of pair-wise training examples. 4.2. Real-world problems We also also carried out experiments on some real-world datasets. These datasets are essentially related to DNA microarray analysis (colon,yeast), or comes from the UCI dataset repository (ionosphere, sonar, spectf, wpbc), as well as P300 based BCI speller. The same pre-processing as for the toy dataset has been applied to these real ones.
 We have compared a plain infinite push method that does not perform embedded variable selection and a  X  1 SVM Rank to our sparse  X  1 infinite push. Comparison criteria are the rate of positive examples ranked on top and the number of variables used by the scoring func-tions. Averaged results over 10 iterations have been reported in Table 1 . Results clearly shows that our  X  1 infinite push model is the model that achieves the best compromise between accuracy on top of the list and variable selection. Indeed, for all datasets, per-formances on top are statistically equivalent whereas
Data Algo top # var colon  X  1 IP 0 . 41  X  0 . 3 68 . 20  X  25 . 4 d = 2000  X  2 IP 0 . 36  X  0 . 2 -(43-19)  X  1 Rank 0 . 40  X  0 . 3 572 . 40  X  320 . 1 yeast  X  1 IP 0 . 85  X  0 . 2 25 . 90  X  5 . 3 d = 79  X  2 IP 0 . 53  X  0 . 4 -(124-208)  X  1 Rank 0 . 86  X  0 . 2 64 . 20  X  2 . 8 sonar  X  1 IP 0 . 44  X  0 . 2 23 . 70  X  6 . 5 d = 60  X  2 IP 0 . 48  X  0 . 3 (187-208)  X  1 Rank 0 . 39  X  0 . 2 59 . 80  X  0 . 4 wpbc  X  1 IP 0 . 18  X  0 . 3 26 . 00  X  12 . 8 d = 33  X  2 IP 0 . 34  X  0 . 3 -(174-194)  X  1 Rank 0 . 34  X  0 . 1 32 . 70  X  0 . 7 iono  X  1 IP 0 . 64  X  0 . 2 15 . 00  X  5 . 1 d = 33  X  2 IP 0 . 66  X  0 . 1 -(245-351)  X  1 Rank 0 . 69  X  0 . 1 33 . 00  X  0 . 0 spectf  X  1 IP 0 . 14  X  0 . 1 40 . 70  X  4 . 4 d = 44  X  2 IP 0 . 10  X  0 . 1 -(215-269)  X  1 Rank 0 . 19  X  0 . 2 43 . 90  X  0 . 3
BCI  X  1 IP 0 . 06  X  0 . 04 71 . 1  X  16 d = 310  X  2 IP 0 . 06  X  0 . 04 -(288-2592)  X  1 Rank 0 . 07  X  0 . 06 272 . 0  X  7 . 9 sparse infinite push uses significantly fewer variables in most of the cases. A reduction of a factor 20 or 8 can respectively be achieved with respects to the original number of variables or the number of variables selected by SVM Rank. We have shown in this paper that embedded fea-ture selection based on sparsity-inducing norms can be extended to loss functions that are themselves non-differentiable and intrinsically complex. For sparse SVM infinite push, we have proposed an algorithm based on alternate direction method of multipliers that alternatively solves a Lasso (or related) problem and applies the proximal operator of the infinite push loss. For computing this proximal operator, we have devised a novel algorithm based on the projection on  X  1  X   X   X  ball. Our experimental results show that our sparse SVM infinite push compares favorably to other ap-proaches in terms of number of variables used in the model as well as in term of accuracy of ranking on top of the list. Future works will focus on algorithms that scale linearly or sublinearly with m  X  n and on theoretical analysis of the methods.
 This work is partially supported by the PASCAL2 Net-work of Excellence, ICT-216886, ANR Project ASAP ANR-09-EMER-001.
 Agarwal, S. The infinite push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list. In Proceedings of the SIAM International Conference on Data Mining (SDM) , 2011.
 Agarwal, S., Dugar, D., and Sengupta, S. Ranking chemical structures for drug discovery: A new ma-chine learning approach. Journal of Chemical Infor-mation and Modeling , 50(5):716 X 731, 2010.
 Bach, F., Jenatton, R., Mairal, J., and Obozinski, G. Convex optimization with sparsity-inducing norms.
In Optimization for Machine Learning . MIT Press, 2011.
 Chapelle, O. and Keerthi, S.S. Efficient algorithms for ranking with svms. Information Retrieval Journal , 13(3):201 X 215, 2010.
 Cl  X emencon, S. and Vayatis, N. Tree-based ranking methods. IEEE Transactions on Information The-ory , 55(9):4316 X 4336, 2009.
 Combettes, P. and Pesquet, J.-C. A douglas-rachford splitting approach to nonsmooth convex variational signal recovery. IEEE Journal Selected Topics Signal Processing , 1:564 X 574, 2007.
 Combettes, P. and Wajs, V. Signal recovery by prox-imal forward-backward splitting. Multiscale Model-ing and Simulation , 4:1168 X 1200, 2005.
 Combettes, P. L. and Pesquet, J.-C. Proximal split-ting methods in signal processing. In Bauschke, H. H., Burachik, R., Combettes, P. L., Elser, V., Luke, D. R., and Wolkowicz, H. (eds.), Fixed-Point
Algorithms for Inverse Problems in Science and En-gineering . Springer-Verlag, 2010.
 Eckstein, J. and Bertsekas, D. On the douglas-rachford splitting method and the proximal point algorithm for maximal monotone operators. Mathematical Programming , 5:293 X 318, 1992.
 Figueiredo, M., Nowak, R., and Wright, S. Gradi-ent projection for sparse reconstruction: application to compressed sensing and other inverse problems.
IEEE Journal of Selected Topics in Signal Process-ing: Special Issue on Convex Optimization Methods for Signal Processing , 1(4):586 X 598, 2007.
 Freund, Y., Iyer, R., Schapire, R., and Singer, Y. An efficient boosting algorithm for combining prefer-ences. Journal of Machine Learning Research , 4: 933 X 969, 2003.
 Geng, X., Liu, T.-Y., Qin, T., and Lin, H. Feature se-lection for ranking. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval , 2007. Guyon, I., Weston, J., Barnhill, S., and Vapnik, V.
Gene selection for cancer classification using support vector machines. Machine Learning , 46(1-3):389 X  422, 2002.
 Joachims, T. Optimizing search engines using click-through data. In Proceedings of the ACM Con-ference on Knowledge Discovery and Data Mining , 2002.
 Quattoni, A., Carreras, X., Collins, M., and Darrell, T. An efficient projection for  X  1 ,  X  regularization. In Proceedings of the 26th International Conference on Machine Learning , 2009.
 Rudin, C. The p-norm push: A simple convex rank-ing algorithm that concentrates at the top of the list. Journal of Machine Learning Research , 10: 2233 X 2271, 2009.
 Sra, S. Fast projections onto l1,q-norm balls for grouped feature selection. In Proceedings of the Eu-ropean Conference on Machine Learning , 2011. Tseng, P. Convergence of block coordinate descent method for nondifferentiable minimization. Journal of Optimization Theory and Application , 109:475 X  494, 2001.
 Usunier, N., Buffoni, D., and Gallinari, P. Ranking with ordered weigthed pairwise classification. In Proceeding of the 26 th International Conference on Machine Learning , 2009.
 Zou, H. The adaptive lasso and its oracle properties.
Journal of the American Statistical Association , 101
