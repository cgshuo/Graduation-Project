 Recommender systems help users find items of interest by tailoring their recommendations to users X  personal prefer-ences. The utility of an item for a user, however, may vary greatly depending on that user X  X  specific situation or the context in which the item is used. Without consider-ing these changes in preferences, the recommendations may match the general preferences of a user, but they may have small value for the user in his/her current situation. In this paper, we introduce a hierarchical hidden Markov model for capturing changes in user X  X  preferences. Using a user X  X  feed-back sequence on items, we model the user as a hierarchi-cal hidden Markov process and the current context of the user as a hidden variable in this model. For a given user, our model is used to infer the maximum likelihood sequence of transitions between contextual states and to predict the probability distribution for the context of the next action. The predicted context is then used to generate recommen-dations. Our evaluation results using Last.fm music playlist data, indicate that this approach achieves significantly bet-ter performance in terms of accuracy and diversity compared to baseline methods.
Traditional recommender systems recommend items based on users X  history of preferences and interactions. In general, however, users X  preferences can change because of the nat-ural evolution of their tastes, changes in their current con-text, or the emergence of new items. As a result of these preference changes, a static set of recommendations gener-ated based on the full set of past preferences does not always provide the most utility for a user. In particular, in domains where there may be frequent changes in user X  X  context dur-c  X  ing the course of interaction with the system, failure to con-sider these changes may result in considerable performance degradation. For example, the user of a music recommender may have different interests in music depending on her/his current activity (such as exercising, relaxing, driving, etc.).
To address this issue context-aware recommender systems (CARSs) have been introduced [1]. Compared to the tradi-tional systems that mainly utilize users X  preference history, CARSs provide more relevant results by generating recom-mendations that match the current interests of each user. In some applications, the current context of the user might be explicitly given to the system as a set of factors affecting the recommendations. On the other hand, if the contextual factors explaining the preference changes are not directly observed, it might still be possible to infer them as a set of latent variables and use them to generate recommendations during the course of a user X  X  interactions with the system.
In this paper, we focus on a setting where users X  feedback on items is revealed sequentially. Based on the feedback data in the current session and also the user X  X  history of preferences, the recommender predicts the next item that would be interesting for the user. For example, based on the sequence of songs that a user has listened to in her current playing session, the recommender suggests other songs that might be of interest.

We propose a context-aware recommendation algorithm based on hierarchical hidden Markov modeling (HHMM) [4]. Our model captures common patterns of contextual changes in users X  preferences, represented as hidden variables in the model, and use them to produce personalized recommenda-tions matching the current interests of the user. Also, the proposed approach increases diversity of recommendations while maintaining an acceptable level of accuracy. The abil-ity to capture user preferences at a more aggregate level of latent variables representing contexts, enables our approach to produce more diverse recommendation lists.

We evaluated our approach using an off-line cross valida-tion strategy. In our experiments we used Last.fm dataset containing time-stamped sequences of users X  listening activ-ities. Our evaluation results indicate that our proposed ap-proach achieves significantly better performance in terms of accuracy and diversity of the recommendations compare to other baseline methods.
Many of the existing conventional recommendation meth-ods, such as matrix factorization or neighborhood-based meth-ods, don X  X  take into account the users X  change of interests. Time-aware recommendation approaches such as [6] consider the drift in users X  preferences over time and model the tem-poral dynamics within the data. However, these methods assume that time is the only factor that can impact users X  interests while ignoring other possible contextual factors.
Recommendation based on pattern-mining [7][5], can be one possible approach for context-adaptation in sequential recommenders. This technique relies on discovering frequent patterns of items based on sequence of items in the training data and using these patterns to generate recommendations.
Recommendation based on a Markov chain model [8] is another method that can utilize such sequential data by predicting users X  next actions based on their previous pref-erences. For an m th order model, the recommendations are generated based on only the last m recent observations from each user. So, if m is a small value, then the recommender is not generating personalized recommendations as the algo-rithm is ignoring a large part of the information in a user X  X  profile. On the other hand, setting m to a large value in-creases the number of model parameters exponentially which makes it impractical to learn the model in many situations.
Another alternative is the hidden Markov modeling (HMM) approach [11], where the states are latent variables and the items liked by the user in that state are observed variables. Each state has a probability distribution over the set of items. The learning process includes estimating the tran-sition probabilities between the states as well as the proba-bility distribution of observing items at each hidden state. The distribution of current state changes as result of changes in a user X  X  behavior. Therefore, these latent states can be used as a representation of the current context of the user.
Many of the recommendation algorithms are biased to-ward recommending a few popular items. These algorithms often can achieve good precision and recall levels in com-parison to more complex methods. In fact, according to the analysis in [3], the recommendation accuracy captured based on precision and recall can be increased when an additional popularity bias is introduced. However, it has been shown that these popular items are not extremely exciting for the users and do not help with increasing the sales revenue as much as more niche and new items. Similar studies (e.g., [2]) have shown that recommendation in the long tail has special value in increasing the sales revenue and producing more useful and diverse recommendations.
In this paper, we focus on a setting where users X  prefer-ences are revealed as a time-stamped sequence of positive feedback on items, such as playing songs or clicking on Web pages. The goal of the recommender is to predict the fu-ture interests of the user. We introduce a context-aware recommender that models the changing contextual states of the user based on the feedback sequence collected from that user. The recommender system monitors variations in users X  preferences and dynamically adapts to these changes.
Our approach is based on training an HHMM for model-ing context as a latent variable affecting the users X  feedback behaviors. Hierarchical hidden Markov model is a type of structured hierarchical stochastic process. HHMM extends the original hidden Markov model by training two levels of hidden variables. The hidden variables at the first level are used as observations for training the second level.
In our system, we used users X  sequences of positive feed-back on items as the set of observations to train the first level of hidden states. The first level of hidden variables, repre-sent our model of the latent contextual states affecting users X  preferences over time. The second level of hidden variables, captures the common patterns of transition between differ-ent contextual states and correspond to our latent model of users X  interests. Figure 1 presents the overall process of HHMM in our system. Table 1 describes the notation used in the presented graphical model. Algorithm 1 presents the general process of training the HHMM in our system and using it for producing context-aware recommendations [4]. The model parameters that need to be inferred are shown as  X  ( A,B,C,D, X  ) and are described in table 1. At the beginning, each of these pa-rameters is randomly initialized. Let O = &lt; o 1 ,o 2 ,  X  X  X  ,o represent a feedback sequence with size l where o i indicates the i th item in the sequence that received positive feedback from the user. Given each user feedback sequence, param-eters A and B are first updated. In other words, for each input sequence, the state distribution, the first-level state
Algorithm 1: HHMM for context-aware recommendation 1-Initialize  X  = ( A,B,C,D, X  ) to small random values. 2-For each user: 3-For each user X  X  feedback sequence: 4-Re-estimate  X  ( A,B, X  ). 5-Find the most likely first-level state sequence. 6-Re-estimate  X  ( C,D, X  ) based on first-level state 7-Find the most likely second-level state sequence 8-Predict next context using  X  ( C,D, X  ). 9-Predict next observation using  X  ( A,B,C,D, X  ). transition probabilities, and the observation probability ma-trix (between the first-level latent variables and the items) are updated. These parameters are updated as follows: for i=0..N-1 do for i=0..N-1 do for j=0..N-1 do
Where  X  l ( i,j ) = P ( x l = s i ,x l +1 = s j | O, X  ) is the tran-sition probability from state s i to state s j at time l + 1, state sequence with maximum likelihood is discovered. This corresponds to the most likely transition sequence between contextual states that explains the user feedback sequence. We applied Viterbi algorithm to solve this problem [10].
The first-level state sequence discovered in the previous step is then used to update matrices C and D . The proce-dure we used in this step is similar to the method used for updating the matrices A and B . The only difference is in the type of input: the parameters C and D are updated based on the discovered first-level state sequences while A and B are re-estimated based on the observed item sequences.
In the next step, the second-level state sequence with max-imum likelihood is determined. This sequence is the most likely transition sequence between the second-level hidden variables that explains the contextual changes. Based on the trained context transition probabilities (parameters C and D ), our model predicts the context of the next action of the user. By using the predicted context and having the obser-vation probability matrix B , our model then generates the recommendations that match the predicted context. These recommendations are chosen as the set of items that have the highest probability given the predicted context.
After training the model, we used the multiplication of C and D to predict the next context for a given user. In the next step, by multiplication A and B , we compute the prob-ability of each item for the recommendation based on the contexts. Finally, by using these probabilities and having predicted context, we predict the top-N recommendations with the highest probability that correspond to predicted context.
This section describes our experiments for evaluating our sequential recommendation approach against a number of other popular baseline methods. We did our experiments based on users X  music listening activities collected from Last.fm Website between 2009/01/01 to 2009/05/31. This dataset contained the time-stamped sequence of artists that each user had listened to during the specified time period. We used the first four months of the data for training the mod-els and the last month (2009/05) for evaluation of the rec-ommendations. The training set contained 837 users, with at least one artist in the test and train partitions, and the number of unique artists was 51759. The test data contained 462 users. Given a user, each of the competing algorithms produced a set of N recommendations which were then eval-uated based on the test data.
All the recommendation methods were compared based on the precision and recall metrics. These two measures are among the common metrics used for off-line evaluation of recommendation algorithms where binary type of feed-back is available. Given a set of recommendations, let TP represent the number of correct recommendations, and FP indicate the number of incorrect recommendations. A rec-ommendation is assumed to be correct only if it appears in the test data. The precision and recall are computed as:
Where FN indicates the number of relevant items that are not included in the recommendation list. Another metric used in our experiments was F-measure that is defined as:
Popularity Bias was used in our evaluations to compare the diversity of different recommendation methods. We fol-lowed the same approach as in [3] to compute this metric. The items were first sorted based on their overall frequencies in all users X  profiles and were then grouped into I = 10 bins such that the items in the same bin were similar in popular-ity. For each baseline method, the top N = 10 recommen-dations generated for each test case were then analyzed to compute the normalized distribution of each category. This section focuses on comparing the performance of HHMM against other baseline approaches. We used AIC criterion ( AIC= ML  X   X  P  X  ) to determine the optimal num-ber of latent states for HMM and HHMM. Where ML  X  is the maximum likelihood of the model, and P  X  is the num-ber of parameters in the model. Based on this criterion, the number of latent states in the first level was set to 20 and the number of states in the second level was set to 10. The baseline methods used in our evaluations are as followed:
HMM: Recommendation algorithm based on the stan-dard HMM model [11]. Similar to HHMM, we used 20 hid-den states for training the HMM model.

Sequential Pattern Mining: Recommendation based on contiguous sequential patterns [7][5] was used as one of the baselines in our evaluations. In our evaluations, the support value of sequential patterns was tuned and set to 0.01.

Item-based Markov Modeling: As another baseline sequential recommender, a k th -order Markov model was built where states corresponded to all item subsequences of length k observed in the training data, and actions corresponded to different items. For each user, the last k items were used to produce recommendations. The transition probability for state s i and action a j was computed based on the training sequence database and as the normalized frequency of times a occurred after s j . The order of the model was to k = 3.
User-Based k NN: This method was used as one of the baseline approaches. The cosine metric was used to compute the similarity of users and the size of neighborhood for each user was set to 100. Figure 2: Comparison of popularity bias of different recommendation methods
BPRMF: Matrix Factorization using Bayesian Personal-ized Ranking (BPRMF) [9] was used as another baseline in our evaluations. This model was trained for 30 factors.
Most Popular: This baseline ranks the items based on popularity.

Random: This recommender, randomly selects N items as the recommendation list for each given user.
Table 2 presents the recall and precision at ranks 5, and 10 for each of the competing algorithms. According to this table, HMM has slightly better precision in comparison to HHMM and also has a significantly higher precision compare to the rest of the baseline methods. However, HHMM has the highest recall and achieves the best overall F-score.
Figure 2 compares the popularity bias of HHMM and other methods. As expected, the random recommender has the lowest popularity bias as the recommendations are al-most uniformly distributed over the 10 bins. On the other hand, user-based k NN, most-popular recommender, and rec-ommendation based on sequential pattern mining have the highest popularity bias. All the recommendations gener-ated by these three algorithms belong to a single bin (most popular items) while the items in the remaining bins are not selected for recommendation. Although BPRMF and Item-based Markov model have better diversity than user-based k NN, both HMM and HHMM achieve better perfor-mance with respect to lower popularity bias while HHMM has slightly better diversity compare to HMM. This paper proposes a recommendation method based on Hierarchical Hidden Markov Models for adapting to users X  varying interests as a result of contextual changes. We model context as a latent variable affecting the likelihood that a user likes a given item. Our model captures the probabil-ity of transition between different contextual states and uses these probabilities to predict the context of the next inter-action of the user with the system. The predicted context is then used to generate the recommendations that are most relevant to the current interests of the user as well as his/her history of preferences. Our evaluation results indicate that using the predicted context can improve the diversity of the recommendations. [1] G. Adomavicius, B. Mobasher, F. Ricci, and [2] O. Celma. Music Recommendation and Discovery -[3] F. G. D. Jannach, L. Lerche and G. Bonnin. What [4] S. FINE, Y. SINGER, and N. TISHBY. The [5] N. Hariri, B. Mobasher, and R. Burke. Context-aware [6] Y. Koren. Collaborative filtering with temporal [7] B. Mobasher, H. Dai, T. Luo, and M. Nakagawa. [8] J. Pitkow and P. Pirolli. Mining longest repeating [9] S. Rendle, C. Freudenthaler, Z. Gantner, and [10] M. S. Ryan and G. R. Nudd. The viterbi algorithm. [11] N. Sahoo, P. V. Singh, and T. Mukhopadhyay. A
