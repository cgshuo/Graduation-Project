 1. Introduction
Document clustering is a central problem in information retrieval, which can be defined as grouping doc-uments into clusters according to their topics or main contents in an unsupervised manner. It has been used as a way for improving retrieval performance and navigating large document collection ( Cutting, Karger, Peder-son, &amp; Tukey, 1992; Zamir &amp; Etzioni, 1998 ).

A large variety of algorithms have been suggested for document clustering, which can be categorized as
One common characteristic of most of these methods is that the number of clusters is required to be pro-vided by users. But in practice, this knowledge is usually unknown in advance. Hierarchical clustering tech-niques do not require a stated number of clusters as input. However, it is desirable to automatically identify the value of cluster number for uncovering the intrinsic structure in document set.
The other observation is that for most of document clustering algorithms, feature words are selected by simple ranking scheme, without considering their effect on clustering procedure. To effectively identify docu-back from clustering procedure.

For achieving feature selection and model order identification capabilities, we propose a cluster validation based model selection algorithm. Firstly salient words are selected from all the words occurred in a document number. We choose the feature subset and cluster number which maximize the cluster validity criterion as our estimate cluster structure since it has been shown to be the state of the art method for document clustering.
This paper is organized as follows. Section 2 provides a brief review of related efforts on document cluster-
In Section 4 , we provide the experimental results of our algorithm and discuss some findings from these results. Section 5 concludes our work and suggests some possible improvements. 2. Related work
Vaithyanathan and Dom (1999) proposed a Bayesian approach that used stochastic complexity to deter-mine the important feature subset and the intrinsic value of cluster number. Their feature selection algorithm grouped feature words into clusters and then selected the important feature subset by removing clusters con-taining noise words. But this procedure made the performance of feature selection algorithm dependant on selection algorithm would fail to remove them.

The other method presented by Liu, Gong, Xu, and Zhu (2002) is to employ Gaussian mixture modeling (GMM) with EM algorithm to conduct an initial clustering. Then document clusters were refined by voting on number of clusters, they introduced randomness in the clustering initialization, then determined the intrinsic value of cluster number by which running the document clustering process on the full data set for a fixed num-ber of times yielded the most similar results.

Compared with the Bayesian statistical estimation approach ( Vaithyanathan &amp; Dom, 1999 ), we adopt a different model selection measure, cluster validation. In addition, the feature selection is conducted on fea-tures, rather than feature clusters. In contrast with the other approach based on GMM and cluster refinement of the noise words on the clustering procedure. Furthermore, the clustering analysis algorithm (sIB) which we adopt makes no assumption about the structure of data distribution. 3. Proposed algorithm
Given a collection of documents, for revealing the underlying structure of documents, we need to discover the Cluster validation is a commonly used method for the problem of model order identification ( Lange,
For the problem of document clustering, we extend the cluster validation strategy further to address both fea-with the intrinsic value and the selected feature subset is important and complete, then the cluster structure mated cluster structure more likely be the artifact of the data generated by resampling.
From the point of the view of feature selection, this combination can be seen as a wrapper strategy: the 2000; Law, Figueiredo, &amp; Jain, 2002; Modha &amp; Spangler, 2003; Vaithyanathan &amp; Dom, 1999 ). Table 1 presents our model selection algorithm. The objective function M ture subset and the cluster number. Clustering solution which is stable against resampling will give rise to a local optimum of M F number. We use the sIB algorithm to perform clustering analysis here (described in Section 3.3 ). 3.1. Preprocessing for feature selection
Before feature selection, we try to remove some noise words using a saliency based criterion. This may help to improve the efficiency of the feature selection. Let W ={ w a document set D , where D ={ d 1 , d 2 , ... , d M }. The frequency of the word w n ,1 6 i 6 N ,1 6 j 6 M . The frequency of the word w i in a large reference corpus R is represented by n this paper, we use New York Times News data (July 1994 X  X ecember 1996) as the reference corpus. The length (the number of occurrences of words) of the document d j and the corpus R are denoted by L tively. Then we measure the salience of the word w i in the document d Higher values of s ( w ) correspond to more salient words w .

After measuring the salience of all the words in the entire document set, we use the following conditions to identify a salient word set, denoted as W S : retrieval task.

Then each document d j is represented by a vector v j , which is defined as where n i , j is the frequency of the word w i occurred in the document d 3.2. Feature subset selection
When selecting salient words from the initial vocabulary set W , the ability of the words to discriminate the documents with different topics is not considered. It is necessary to refine this salient word set W unsupervisedly removing noise words which do not help or even deteriorate the discrimination of documents with different topics. This problem can be generalized as selecting an important feature subset from W unsupervised manner.

Since for each document there should exist some words which can represent its topic, it is reasonable to rate of the feature set F with respect to the document set D , i.e., the ratio of the number of documents with occurrence of at least one feature against the total number of documents, then it is assumed that coverage( D , F )=1.

Our feature subset selection procedure is formulated as subject to coverage( D , F )=1. b k are the feature subset and the value of cluster number to be evaluated. D represents the document set, and q is the sampling frequency for the estimation of cluster validation criterion. q is set as 20 in this work.
Cluster validation process works as follows: (1) randomly sample a subset from the full dataset; (2) group the documents in the sampled subset and the full dataset into k clusters respectively; (3) measure the propor-
In other words, the clustering solution with the intrinsic cluster number as the parameter is robust against resampling, which gives rise to a local maximum of the function  X  X  X riterion X  X .

In this paper we consider the sequential backward floating search ( Pudil, Novovicova, &amp; Kittler, 1994 )to tion  X  X  X riterion X  X  is reached. Mutual information between feature candidates and all the documents is used as the criterion for sorting feature candidates. In this paper, l =2, m = 1, where l is the number of take-away steps in step (1), and m is the number of plus steps in step (2).

This constrained optimization process results in an important feature subset which maximizes the criterion and meets the given constraint at the same time. For each possible value of cluster number, we can get a corresponding feature subset. In all the pairs of feature subset and cluster number, we choose the pair that maximizes the objective function  X  X  X riterion X  X  as our answer.
 The function M ( C l , C )in Table 2 is given by Levine and Domany (2001) : where D l is a subset with size a j D j sampled from the full data set D , C and C ces based on the clustering solutions computed on D and D matrix C is defined as: C i , j =1if d i and d j belong to the same cluster, otherwise C the same way. a is set as 0.90 in this paper.

M ( C l , C ) measures the proportion of document pairs in each cluster computed on D that are also assigned identical with the intrinsic value, and the selected feature subset contains no noise words, then clustering maximum of M ( C l , C ).
 objective function different from the figure of merit (Eq. (6) ) proposed in Levine and Domany (2001) . The reason to normalize M  X  C l F ; k ; C F ; k  X  is that M  X  C fore for avoiding the bias that smaller value of k is to be selected as the cluster number, we use the cluster validity of a random predictor to normalize M  X  C l F ; k In later experiments, we provide the results of cluster number estimation procedure using M
M 3.3. Clustering procedure to be the state of the art method for document clustering task ( Slonim et al., 2002 ).
 as much information as possible about F . T is the document clustering solution. This optimization problem can partition T , iteratively drawing a d 2 D out of its cluster t ( d ), t 2 T , and merging it into t argmin t 2 T d ( d , t ). d ( d , t ) is the change of I ( T , F ) due to merging d into the cluster t JS( p , q ) is the Jensen X  X hannon divergence ( Lin, 1991 ), which is defined as 4. Experiments and results 4.1. Test data we constructed several subsets from 20 Newsgroup corpus ( NG 20) for the evaluation of our algorithm. The
NG 20 data contains about 20,000 articles evenly distributed among 20 Usenet discussion groups, which is a widely used benchmark corpus for supervised text categorization task. For our test, we constructed nine data-sets by randomly selecting 500 documents evenly distributed among categories in each dataset. The details of lines, lowering the upper case characters, ignoring all the words that contained digits or non alpha-numeric characters, removing words from a stop-word list containing 599 words, and filtering out low frequency words which appeared only once in the entire corpus. We did not use stemming procedure. 4.2. Evaluation method
When assessing the agreement between the clustering result and the known ground truth, we will encounter the difficulty that there is no label value for each cluster.

To solve this problem, the authors in Dhillon et al. (2003), El-Yaniv and Souroujon (2002), Slonim et al. (2002), Slonim and Tishby (2000) proposed to assign documents in each cluster t , t 2 T , with the most dominant class label in that cluster, and then conducted evaluation on these labelled documents. In this work, we followed their method to assign labels to document clusters.

Given this uni-labelled data, we define a ( c , T ) as the number of documents correctly assigned to class c , incorrectly not assigned to class c . Following ( Dhillon et al., 2003; El-Yaniv &amp; Souroujon, 2002; Slonim measure, which are given by data. 4.3. Experiments and results
For comparison, we tested both sIB and FSCV on nine datasets from NG 20 corpus, created by ourselves the number of initializations for each run, is used for assessing the convergence of iteration procedure, and max L is the maximum of the number of loops in sIB clustering process. = 0 means that the clustering process will stop if the local maxima of the objective function in sIB is reached.
 sIB : For the sIB algorithm, top 2000 words were selected for each dataset according to words X  contribution to the mutual information about the documents. Then the sIB algorithm co-occurrence matrix. The number of clusters was taken to be identical with the number of real categories (ground truth classes).

FSCV : We employed the algorithm presented in Section 3 to determine both the feature subset and the clus-computed on full data set D in feature space b F ^ k using the sIB algorithm with the cluster number
In Table 4 we present the results of micro-averaged precision for above two procedures (sIB and FSCV) over nine datasets. Moreover, it also summarizes micro-averaged precision results of double clustering algo-rithm (DC), iterative double clustering algorithm (IDC) and co-clustering algorithm (CoC) taken from ( Dhil-to be provided in other clustering algorithms (e.g., DC, IDC, CoC, and sIB).

The size of selected feature subsets with M F , k as the evaluation function for datasets Binary and Multi10 1,2,3 are 2252, 2313, 2454, 1591, 1665, 1633, 1513, 1361, and 1488, respectively. Table 5 provides the results of model order identification procedure with different objective functions, M
Results in Table 4 show that FSCV outperforms DC, IDC, CoC, and sIB if we use average precision to assess their performance. Specifically, FSCV achieved 82.6% average precision, while sIB, CoC, IDC, and DC achieved 81.4%, 79.7%, 74.2%, and 54.2% average precision, respectively. Specifically, when FSCV found the ground truth cluster number, FSCV performs better than other document clustering algorithms in most of cases. Taking into account no requirement of the predefinition of cluster number in FSCV, we can see that these results are encouraging.

In Table 5 , it is shown that the number of real categories can be correctly identified using normalized mea-sure M F , k over five datasets (Binary 2 , Multi5 1 , Multi5 ary real categories, which chose 2 as the cluster number over all datasets. Comparing the results of M
M
F ; k in Table 5 , we can see that M F , k clearly outperforms M
Fig. 1 presents the detailed result in terms of the scores of two evaluation criteria as functions of cluster numbers. The scores of M unnorm F ; k decreased while increasing the cluster number k although there was small ity score for avoiding the bias that smaller value of k is to be selected as the cluster number. 5. Conclusions and future work
This paper attacked the problem of feature selection and model order identification for document cluster-ing. The important feature subset and the intrinsic cluster number were determined by optimizing a model selection criterion that evaluated the validity of clustering solutions computed on data subsets generated by resampling. We demonstrated that our algorithm can automatically estimate the cluster number, and the data. The overall performance of our algorithm in terms of micro-averaged precision was better than previous document clustering algorithms.

Efficient search strategy is very important for feature selection here, considering the high dimensional search space (about 1300 X 2600 words) in feature selection procedure. Future work includes the investigation of other search methods, e.g., evolutionary algorithms, to find local optima more efficiently. attempt to categorize the documents. Our algorithm can help to estimate the number of real categories using cluster validation method. After document clustering, it becomes easier to navigate the contents of document collection.
 References
