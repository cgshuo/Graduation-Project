 In recent years, there have been increasing efforts in applying association rule mining to build classification models [1] [2] [3] [4] [5], which have resulted in the area of Associative Classification (AC) modeling. Several studies [1] [2] [3] have provided empirical evidence that AC classifiers can outperform tree-based [6] and rule-induction based models [7] [8]. The good performance of the AC models can be attributed to the fact that by using a bottom-up approach to rule discovery (either via frequent items et mining or instance-based rule mining) they can discover better rules than the traditional heuristic-driven top-down approaches.

Regression is a data mining task that is applicable to a wide-range of ap-plication domains. However, despite th e success of association rule mining for classification, it has not been extensiv ely applied to develop models for regres-sion. We are only aware of the Regression Based on Association (RBA) method developed by Ozgur et al. [9] that uses association rule mining to derive a set of regression rules. Since regression models need to predict a continuous value, whereas the classification models need to predict a categorical value, the methods developed for AC modeling are in general not applicable for solving regression problems.

Motivated by the success of AC modeling, we study the problem of applying the association rule mining to build an Associative Regression (AR) model. We believe this is an important problem for the following two reasons: First, an AR model is built upon a set of regression rules, which in many cases, can be easily interpreted by domain experts and thus provide valuable insights. Second, the good performance of the well studied AC classifiers leads us to believe that the AR model may potentially perform better than the tree-based [10] [11] and rule-induction based [12] regression models.

We present an associative regression model utilizing expectation maximiza-tion [13], called AREM. An AR model consists of three major components: (i) the method used to identify the sets of itemsets that form the left hand sides of the rules, (ii) the method used to estimate the right hand sides of the rules, and (iii) the method used to compute a prediction. Drawing upon approaches used for developing AC models, AREM uses an instance-based approach to se-lect a subset of frequent itemsets that are used to form the left hand side of the rules. However, unlike existing AC and AR models, it develops and utilizes a probabilistic model coupled with an EM-based optimization approach to de-termine the right hand side of the rules and also assign a weight to each rule that is used during prediction. The advantage of this probabilistic model is that it allows AREM to capture the interactions of the various rules and to learn the parameters that lead to m ore accurate predictions. Our experimental evalu-ation shows that AREM outperforms several state of the art regression models including RBA [9], Boosted Regression Trees [10], SVR [14], CART [11] and Cubist [12] on many data sets, with the Mean Square Error (MSE) being used as the performance metric.

The remainder of this paper is organized as follows. Section 2 introduces some notations and definitions. Section 3 pres ents the related work in this area. AREM is formally presented in Section 4. In Section 5, we explain the experimental design and results for model evaluation. And finally Section 6 concludes. The methods developed in this work apply to datasets whose instances are de-scribed by a set of features that are pr esent. Such datasets occur naturally in market basket transactions (features represent the set of products purchased) or bag-of-word modeling of documents (features correspond to the set of words in the document). We will refer to these features as items. Note that other types of datasets can be converted to the above form at via discretization techniques [15].
Let the data set D = { (  X  i ,y i ) | i =1 , 2 ,...,N } be a set of N instances. The instance (with index) i is a tuple (  X  i ,y i ), where  X  i is a set of items (or, an itemset), and y i is the real-valued target variable. Given an itemset x ,andan The support of itemset x , is defined as the number of instances in D that contain x . The itemset x is frequent if its support is not less than s 0 ,where s 0 is the user specified parameter. For itemset x , we define its mean (  X  x ) and standard deviation (  X  x ) as computed from the set of targ et variables from instances in D that contain x .

A regression rule is of the form r x : x  X   X  x . The rule X  X  left hand side (LHS) x is an itemset.The rule X  X  right hand side (RHS)  X  x is the target value predicted by this rule. Each rule is also associated with a positive value w x which is used as the weight when combining multiple rules together for making predictions. The rule r x is frequent if its itemset x is frequent. To our best knowledge, the RBA [9] model is the only previous work on associa-tive regression. It starts with mining the set of frequent itemsets which form the set of rules X  LHS. For each frequent itemset x , RBA computes the rule X  X  RHS as the mean of x . It also computes the standard deviation  X  x of x . These rules are then ranked by variance (i.e.,  X  2 x ) from small to large. The database sequential coverage is applied to prune rules which are ranked low. For making predictions, three weighting schemes for w x are developed: (1) equal , where rules are equally weighted, (2) supp , where the rule r x is weighted by the support of x ,and(3) inv-var , where the rule X  X  weight is inverse proportional to the variance  X  2 x .
Associative Classification (AC) [16] is an area that applies similar techniques, but the focus is on the Classification task. Among the many methods developed for AC modeling [1] [2] [3] [5], Harmony [4] is the model that employs a similar rule pruning strategy to AREM: it mines the highest confidence rules for each instance and combines them to the final rule set.

AR and AC models are descriptive in that they can be easily interpreted by end users. Tree based and rule induction based models are another two groups of descriptive models. The classification and regression tree (CART) [11] partitions the input space into smaller, rectangular regions, and assigns the average of the target variables as the predicted value to each region. Cubist [12] is a rule based algorithm and fits a linear regression model to each of the regions. Boosting [10] is a technique to build ensemble models by training each new model to emphasize the training instances that previous models misclassified. Boosted regression trees have shown to be arguably the best algorithms for web-ranking [17]. The AREM model training consists of two m ajor components. First, it discovers a set of frequent regression rules r x : x  X   X  x ,where  X  x is the mean value of x in D .Wedenotethissetofrulesby R . Second, for each r x  X  X  ,AREMupdates its RHS to a new value  X  x by learning a probabilistic model. The EM algorithm is applied for model learning where  X  x is learned together with the rule X  X  weight w
For the rule discovery component (i.e., the first component above), AREM follows a two-step approach to find the rule set R . First, it uses the FP Growth algorithm [18] to find all frequent itemsets x in D . For each frequent itemset x , AREM generates the rule r x : x  X   X  x ,where  X  x is the mean value of x in D . Let F be this set of frequent rules. Second, for each training instance i ,let F i be the set of rules r x from F such that x  X   X  i . AREM selects K rules from F i to form the set R i . Finally, R is the union of these rules R i over all training instances i in D .Since R will in general contain fewer rules than F ,thisstep applies instance based approach to prune the initial set of frequent rules.
Using the set of updated rules R with the associated weights, AREM predicts R x  X   X  ), then it eliminates from R values among them. This set of rules, denoted by R k  X  ,isthenusedtopredictthe target variable using the formula which is nothing more than the average of the RHS of the k rules weighted by their corresponding w x i values. In the case when the test itemset  X  is not covered by rules in R , i.e., |R  X  | = 0, we simply predict  X  y as the global mean of target variables in database D .

AREM model requires the specification of four parameters: (i) the minimum support s 0 , (ii) the number of rules K that are selected for each training instance, (iii) the number of EM steps M for rule parameter learning, and (iv) the number of rules k from R that are used for predicting the target variable. Even though the optimal values of these paramet ers need to be determined using a cross-validation framework, our experience has been that the performance of AREM remains consistently good for a wide range of these values.

In the rest of this section we describe the probabilistic model that we devel-oped for estimating from D the  X  x and w x parameters of the rules in R and the method used to select for each training instance i the K rules from F i . 4.1 The Probabilistic Model Let X be the set of itemsets of rules in R (i.e., X = { x | r x  X  X } ). Consider an arbitrary training instance (  X ,y ). The goal of the probabilistic model is to this quantity to the set of itemsets in X . To this end, we treat itemset x as a random variable that takes values in X and write P [ y |  X  ]as where P [ y |  X ,x ] is the probability of generating the target variable y given  X  and x , which is generated from  X  with probability P [ x |  X  ]. Our goal then becomes to specify P [ y |  X ,x ]and P [ x |  X  ] and relate them to  X  x and w x . In order to specify P [ y |  X ,x ], we first assume the conditional independence P [ y |  X ,x ]= P [ y | x ]. That is, we assume that once the itemset x is known, the probability of y is not dependent on  X  , which simplifies our model so that the a Normal distribution whose mean is the RHS of the rule x  X   X  x and standard deviation  X  x .Thatis, Next, we specify P [ x |  X  ] by considering how AREM makes predictions. In order to simplify this discussion we ignore the fact that AREM picks the top k rules (i.e., it uses the set of rules in R k  X  ) and assume that it predicts the target value by using all the rules in R  X  . Specifically, Equation 1 now becomes where I x  X   X  is the indicator function which takes value 1 (0) when x  X   X  is true (false).

From the probabilistic modeling point of view, we predict the target variable as the expected value of y given  X  ,thatis, From Equation 2, we get E [ y |  X ,x ]=  X  x . To specify P [ x |  X  ], we compare Equation 3 with 4, and get first step, a regression rule X  X  LHS x  X  X  is generated based on  X  with probability P [ x |  X  ] given by Equation 5. In the second step, the target variable y is generated by x with probability P [ y | x ] given by Equation 2. 4.2 EM Algorithm: Learning  X  x ,  X  x and w x Denote by  X  = {  X  x , X  x ,w x | x  X  X } the complete set of model parameters. The maximum likelihood estimation of  X  given the training data set is to maximize wherewehaveintroduced x i to denote the itemset generated by our probabilistic model for instance i . The difficulty of this optimization problem comes from the summation inside the logarithmic function. This is due to the existence of the hidden variables x i , which are not directly observable from the training data set. EM algorithm is the standard approach to solve this problem.

EM algorithm is an iterative optimization technique. In the following, we add a subscript t to all model parameters to denote the parameters used by EM algorithm at iteration t . For each iteration t , EM algorithm finds the updated set of parameters  X  t +1 given the current parameter estimations  X  t .Thisisac-complished by maximizing the function This optimization problem is much easier than the original one for Equation 6, due to the fact that the logarithmic function is now inside the summation. The EM algorithm at iteration t is splitted into an E-step which computes  X  i,x i ,t = each iteration, the log-likelihood function L is guaranteed to be increased, that is, L (  X  t +1 )  X L (  X  t ).

At iteration t = 0, we initialize the weight w x, 0 to one and  X  x, 0 ,  X  x, 0 to the mean and standard deviation of x in D . For the E-step, we first apply Bayes X  Theorem so that  X  According to Equations 5 and 2, we have Combining these two Equations, we get Q = Q w Next, we optimize Q 1 which is given by By changing the order of summation, we can write Q 1 = x Q x ,where One can see that different itemsets are decoupled from each other, so we only need to solve Q x for  X  x  X  X  .Observethat Q x is nothing but the weighted version the weights are given by  X  i,x,t for instance i . The solution is straightforward: and, In Equations 9 and 10, the parameters  X  x and  X  x are the weighted mean and standard deviation where the weight of instance i at iteration t is given by  X  i,x,t . This weighting mechanism can help to remove the outlier instance whose  X  i,x,t is small.
 Now, we optimize Q 2 which is given by By plugging Equation 5 into Q 2 , and taking the derivative, we get One can see that different weights w x,t +1 are coupled in the above equation. So the exact analytical solution becomes impossible. To ensure the simplicity and computational efficiency of our approach, we make an approximation here by replacing t +1by t in the second term of RHS. Then by setting the derivative to zero, we get From Equations 9, 10 and 11, we see that  X  i,x plays the key role of relating parameters  X  x and  X  x to weights w x , so that they can interact with each other and be optimized consistently.

Finally, we note that AREM introduces a parameter M which controls the number of EM-steps. After the EM algorithm is completed, the rule X  X  RHS and weight are finalized to be  X  x,M and w x,M . 4.3 Instance Based Rule Mining The instance based rule mining is applied in the rule discovery component of AREM discussed at the beginning of Section 4, which selects K rules from F i to form R i for each training instance i . For this, AREM first ranks rules in F i by some  X  X uality X  metric, and then select the top K rules. The  X  X uality X  metric captures the quality of a rule from an in stance X  X  perspective. From our proba-better if it has a higher probability of being generated by the instance. We use Thus, AREM uses N ( y i |  X  x, 0 , X  2 x, 0 ) for rule ranking for each instance. 4.4 Comparing AREM with RBA We summarize the main differences betw een AREM and RBA as follows. First, in determining a small set of itemsets to form the final rules X  LHS, AREM applies an instance based approach, while RBA applies the database sequential coverage technique. Second, in determining the final rules X  RHS, AREM learns them in the EM framework, while RBA simply uses the mean of the rules X  itemsets. It turns out that, in AREM, the rule X  X  RHS is the weighted mean, which is likely to be a better estimation than the unweighted mean used by RBA. Third, in determining the rule weights used for predictions, AREM learns them together with rules X  RHS, while RBA pre-specifies methods for computing them. These pre-specified methods may be reasonable but they are not optimized. Finally, in determining top k rules used for making predicti ons, AREM selects rules with the highest weights, while RBA selects rules with the smallest variance. Our choice is consistent with our probabilistic model in that rules with higher chance of being generated (see Equation 5) are more important and should be selected. 5.1 Data Sets We evaluate the performance of AREM on 10 data sets summarized in Table 1. The first six data sets are randomly sampled from user reviews downloaded from three websites:  X  X estBuy X  [19],  X  X itySearch X  [20], and  X  X elp X  [21]. Each instance corresponds to the review of a product where the target variable to predict is the user X  X  rating which ranges from one to five. The review text is parsed and a set of features, or items, is extracted. We constructed two types of features:  X  X ep X  and  X  X f X . For  X  X ep X , the Stanford dependencies [22] between words in each sentence are extracted. Each dependency is a triplet containing the name of the relation, the governor and the dependent. For  X  X f X , words in the review text are extracted. We remove the infrequent items whose relative supports (that is, the support divided by |D| ) are less than 0 . 5%. The  X  X irline X  data set is downloaded from DataExpo09 competition [23]. The last three data sets are downloaded from CMU StatLib [24]. 5.2 Models For model comparison X  X  purpose, we focus on descriptive models and select sev-eral state of the art tree-based and rule-based regression models. The support vector regression (SVR) [14] is an exception. It is included because it is one of the best known and standard models for regression.
 SVR We use  X  X ibsvm X  [25] for SVR , and use only the linear kernel. Model parameters tuned are: C and ,where is the size of -insensitive tube, and C controls the model complexity.
 CART k This group of models contain the Classification And Regression Tree (CART) [11] and the Boosted Regression Tree [10] where CART of fixed size is acting as the weak learners. So, CART k stands for CART being boosted k times [26]. We tuned three parameters for CART k : depth , leaf and lrate ,where depth is the maximum depth of the tree, leaf is the minimum number of leaf samples of the tree, and lrate is the learning rate of the gradient boosting method. CUBIST k Cubist [12] is a rule based algorithm which has the option of build-ing committee models. The number of members in the committee is captured in k . We tuned two binary parameters for CUBIST k : UB (unbiased), and CP (composite). Parameter UB instructs CUBIST to make each rule approximately unbiased. Parameter CP instructs CUBIST to construct the composite model. RBA k We implemented the RBA model following [9]. Here k is the number of top ranked rules used for prediction. We tuned two parameters for RBA k : s 0 and weight ,where s 0 is the minimum support threshold, and weight is the weighting scheme used for prediction, which can take three values supp , inv-var and equal . AREM k Here, k is the number of top ranked rules used for prediction. We tuned three parameters for AREM k : s 0 , K and M ,where s 0 is the minimum sup-port threshold, K is the number of high quality rules for each training instance during pruning, and M is the number of EM steps during model training.
The parameter k in the above models (except SVR ) can be uniformly inter-preted as the number of rules used for mak ing predictions. For our experimental study, we choose k to be 1, 5, 10, 15 and 20 for all four models. The rationale of choosing these values comes from the following: if k is too large, these models X  strength of being interpretable essentially disappears; on the other hand, if k is too small, the performance may not be satisfactory. We choose the maximum k value to be 20 as a compromise from thes e two extreme case considerations. 5.3 Evaluation We used the Mean Squared Error (MSE) between the actual and predicted target variable X  X  values as the performan ce metric. For each (model, data) pair, we first identified a set of parameter configurations that was likely to achieve the best performance. The model was the n trained on the training set and MSE was calculated on the validation set for each of the parameter configurations. Then we selected the parameter configur ation that gives the best MSE on the validation set, and computed the corresponding MSE on the testing set. This process is repeated for the number of trial s shown in Table 1. Finally, we reported the average MSE on all testing trials.

For a given data set, in order to compare model m 1 to model m 2 ,wetakeinto account the distribution of the MSE values computed on multiple testing trials the number of observations of the set of MSE values for model m 1 ( m 2 ), respec-of two population means. Under the null hypothesis that two population means are the same,  X  m 1  X  m 2 / X  m 1  X  m 2 can be assumed to have the Normal distribution N (0 , 1). So the more deviated from zero this quantity is, the more likely that two models are performing differently. 5.4 Experimental Results The average MSE for the discussed set of models on the various data sets are shown in the Table 2, where the best results have been highlighted. Table 3 shows the quantity  X  m 1  X  m 2 / X  m 1  X  m 2 for comparing AREM k to the rest of the models. Note that CART 1 is the standard CART model, in contrast to CART k which stands for the boosted regression tree. For easy comparison, we derive the win-tie-loss from Table 3 and present them in Table 4.

Tables 3 and 4 show that AREM is performing better than all competing methods on most of the data sets. For almost all cases, AREM is either better or at least as good as the competing method (with the only exception on  X  X ollen X  when compared to SVR ). It is also interesting to observe that AREM performs almost uniformly well on the review data sets, but not as uniform on the rest of the data sets. Given that the review data sets have much larger number of items (see Table 1), we think this is an indication that AREM is more suitable for high-dimensional and sparse data sets. Finally, from Table 2, we can see how different k values affect the AREM X  X  performance. When k = 1, the performance is not satisfactory. This is not surprising because our probabilistic model is optimized for large number of rules. However, as k becomes sufficiently large (15 or 20), the performance improves consid erably and remains quite stable. We have proposed a novel regression model based on association rules called AREM. AREM applies the instance based rule mining approach to discover a set of high quality rules. Then the rules X  RHS and importance weights are learned consistently within the EM framework. Experiments based on 10 in house and public datasets show our model can perform better than RBA [9], Boosted Regression Trees [10], SVR [14], CART [11] and Cubist [12].
 Acknowledgment. This work was supported in part by NSF (IOS-0820730, IIS-0905220, OCI-1048018, CNS-1162405, and IIS-1247632) and the Digital Tech-nology Center at the University of Minne sota. Access to research and computing facilities was provided by the Digital Technology Center and the Minnesota Su-percomputing Institute.
