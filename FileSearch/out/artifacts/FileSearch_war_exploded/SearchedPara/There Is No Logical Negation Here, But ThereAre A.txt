 Center for Mind/Brain Sciences, University of Trento Center for Mind/Brain Sciences, University of Trento Center for Mind/Brain Sciences, University of Trento Center for Mind/Brain Sciences, University of Trento
Logical negation is a challenge for distributional semantics, because predicates and their nega-tions tend to occur in very similar contexts, and consequently their distributional vectors are very similar. Indeed, it is not even clear what properties a  X  X egated X  distributional vector should possess. However, when linguistic negation is considered in its actual discourse usage, it often performs a role that is quite different from straightforward logical negation. If someone states, in the middle of a conversation, that  X  X his is not a dog , X  the negation strongly suggests a
In particular, other canids and middle-sized mammals are plausible alternatives, birds are less likely, skyscrapers and other large buildings virtually impossible. Conversational negation acts capturing. In this article, we introduce a large data set of alternative plausibility ratings for perspective, far from being a nuisance, is an ideal application domain for distributional semantic methods. 1. Introduction
Distributional semantics (DS) derives vector-based representations of the meaning of words and other linguistic expressions by generalizing over the contexts in which such expressions occur in large text corpora (Turney and Pantel 2010; Erk 2012). By exploiting the rich commonsense knowledge encoded in corpora and a continuous notion of relatedness that is well-suited to capture the fuzzy nature of content-word semantics,
DS representations can successfully model lexical aspects of meaning such as synonymy (Landauer and Dumais 1997), word analogy (Mikolov, Yih, and Zweig 2013), selectional preferences (Erk, Pad  X  o, and Pad  X  o 2010), and, to a certain extent, hypernymy (Roller,
Erk, and Boleda 2014). There is, however, virtually no evidence that DS can capture the semantic properties of grammatical terms such as conjunctions, determiners, or adverbial particles. The very notion of continuous similarity that is so powerful in modeling lexical phenomena is problematic when it comes to capturing the discrete logical operations that are typically associated with the meaning of grammatical terms. a very elegant treatment in logic-based approaches: if dog denotes the (appropriately indexed) set of all dogs, then no dog denotes the complement of the set. However, there is no straightforward  X  X egation X  operation that, when applied to the DS vector of dog , would derive a no dog vector capturing the same complement intuition in vector space.
Moreover, negated elements tend to occur in the same contexts of their affirmative counterparts (cf.: A dog was barking , No dog was barking ). Consequently, corpus-induced vectors of predicates and their negations are very similar. This  X  X ontextual invariance X  of negation is indeed a well-known problem also in lexical semantics, where it has been observed that vectors of words and their (lexicalized) opposites tend to be extremely similar (Mohammad et al. 2013).
 are trying to capture a purely logical kind of negation that is neither well-suited to DS nor particularly useful for modeling real-life language usage. If we isolate dogs and non-dogs in the lab, the logical approach is very appealing: non-dogs include anything that is not a dog. However, consider which of the following two sentences is more likely to be uttered in a natural conversational context: (1) a. This is not a dog. . . it is a wolf. If the negation of a predicate is just the complement of the corresponding set, then
Examples (1a) and (1b) should be equally plausible. However, Example (1a) is clearly more natural than (1b).
 semantics, pragmatics and psycholinguistics has stressed that, in actual conversational contexts, negation is not just excluding possible denotata of the predicates it takes scope over, but also suggesting the truth of an alternative assertion. Alternativehood (the possibility of an expression to constitute an alternative to a negated item) seems very well-suited to be modeled in DS. It is obviously similarity-based. It is, more specifically, tied to a contextual notion of similarity: We expect plausible alternatives to be objects 638 alternativehood, just like many lexical properties successfully modeled in DS, is an inherently graded property. Consider: (2) a. This is not a dog. . . it is a tarantula.
Sentence (2a) is more surprising than (1a), but arguably less so than (1b). In turn, the contingencies in which the latter might be uttered, although undoubtedly bizarre, are still easier to conceive than those that would justify uttering Example (2b).
 community to the pragmatic, alternative-licensing view of negation, that we will call conversational negation .
 alternativehood under conversational negation. Thanks to its ability to automatically identify potential alternatives in a large vocabulary of linguistic expressions, DS allows us to make predictions about which elements fall into the (fuzzy) alternative set of a negated expression. This is a new contribution to studies on the semantics of alterna-tives (in negation or other domains), where authors rely instead on their intuition to pick a small number of candidate alternatives.
 predicate/alternative statements, and to predict these ratings with DS. We collect al-ternativehood judgments in two (minimal) sentential contexts, and study how both sentential context and the negated-item/alternative relation affect the judgments. The most striking result of the computational simulations is how good simple distributional similarity is at predicting the plausibility of an alternative. This measure comes so close to an estimated upper bound that we can only improve over it by a small margin when we use compositional methods and supervision to take sentential context and the specifics of negation into account.
 conversational negation could look like. We argue that negation should not be modeled as part of the static distributional representation of a single statement, but as a function that, given the negated predicate, produces a probability distribution over the predi-cates that are most likely to follow. This approach suggests, more generally, adopting a dynamic view of DS, not unlike the one that has been prominent for decades in other areas of semantics.
 (logical) negation in DS. Section 3 surveys the literature on alternative-licensing con-versational negation. Our data set containing subject plausibility ratings for negated-item/alternative pairs is introduced and analyzed in Section 4. In Section 5, we use
DS to model the ratings in the data set. We conclude in Section 6 by looking at the theo-retical implications of our work, as well as suggesting directions for further study. 2. Negation in Distributional Semantics
Because distributional semantics has traditionally focused on lexical aspects of mean-ing, negation has mostly been tackled, implicitly, as part of the study of opposites ( hot and cold ), or, more generally,  X  X ontrasting X  words ( warm and cold ). A survey of the relevant DS literature is provided by Mohammad et al. (2013). The consensus view is that contrasting words tend to occur in similar contexts (Mohammad et al. even propose a  X  X istributional hypothesis of highly contrasting pairs X  stating that highly contrasting pairs occur in similar contexts more often than non-contrasting word pairs).
Thus, it is impossible to distinguish them from non-contrasting related words (e.g., synonyms) using standard distributional similarity measures, and ad hoc strategies must be devised.
 sumption of that work is that negated word meanings should be orthogonal, which is to say that they should not share any common feature. Specifically, Widdows proposes a binary negation operator, NOT ( A , B ), which projects the vector representing A onto the orthogonal space of the B vector. In logical terms, this can be seen as conjunction with a negated predicate ( A  X  X  B ). The orthogonality assumption makes perfect sense for the information retrieval applications envisioned by Widdows ( web NOT internet ), but it is too strict to characterize the linguistic predicates of the relevant form in general ( Italian but not Roman refers to somebody who shares many properties with Romans, such as that of speaking Italian).
 risen thanks to the development of compositional DS models (Mitchell and Lapata 2010;
Baroni 2013). A shared assumption within this framework is that the operation per-formed by negation on vectors should be defined a priori, attempting to mimic the logical properties of negation, rather than being induced from distributional data. Clark,
Coecke, and Sadrzadeh (2008) explore the idea that sentences live in a space spanned by a single  X  X ruth-denoting X  basis ( ~ 1), with the origin ( sentence like John likes Mary is represented by ~ 1 if the sentence is true, this framework, further elaborated by Coecke, Sadrzadeh, and Clark (2010), negation is elegantly modeled as a swap matrix. Related approaches have been presented by Preller and Sadrzadeh (2011) and Grefenstette (2013). All this work, however, is purely theo-retical, and it is not clear how the proposed models would be implemented in practice.
Moreover, treating negation as a swapping operator only makes sense in the abstract scenario of a vector space representing truth values. If vectors of sentences and other ex-pressions are instead distributional in nature (e.g., representing distributions over possi-ble contexts), it is far from clear that swapped vectors would capture linguistic negation. not affect all dimensions in a vector, because a word, when negated, does not change its domain: The vector representation of not blue should still be close to that of other colors (Hovy [2010] also defends a similar view). Hermann and colleagues propose that vectors should include distinct  X  X omain X  and  X  X alue X  features, and negation would modify (change sign and possibly rescale) only the latter. In this way, not blue would still be in the color domain, but its chromatic values would differ from those of blue .
Extrapolating to nouns, under this proposal we might expect not dog to still belong to the canid domain, but with different values from those that specifically characterize dogs. This would capture the intuition we spelled out in the introduction that a wolf is a better non-dog than a screwdriver. However, the proposal of Hermann and colleagues is, again, purely theoretical, and we do not see how domain and value features with the desired properties could be induced from corpora on a large scale.

Erk, and Mooney (2013) have proposed a division of labor between DS, handling lexical relations between content words, and first-order logic, accounting for the semantics of grammatical terms. In this framework, the issue of the distributional meaning of negation does not arise. 640 benchmarks to evaluate empirical models of negation in DS. 3. Conversational Negation and Alternative Sets
As already pointed out by Horn (1972), all human languages have negation and no other animal communication system includes negative utterances. This alone makes linguistic negation intriguing and justifies the huge amount of literature dedicated to it.
Furthermore, linguistic negation seems to play different roles and therefore constitutes a challenge for any formal theory. On the one hand, negation works as a truth-functional operator, and as such it has attracted philosophers and formal semanticists, for example, for its scope ambiguity behavior. However, linguistic negation also works as a conver-sational illocutionary marker, causing non-literal interpretations of propositions, and as such it has attracted the attention of linguists, psychologists, and epistemologists.
Conversational negation is something different from a logical truth-functional operator that flips the values of its argument. In particular, in actual linguistic usage, the negation of a predicate often suggests that one of a set of alternatives might be holding. versational maxims (Grice 1975) and Horn X  X  principle of alternate implicatures (Horn 1972), and, on the other, to the  X  X lternative semantics X  theory of focus (Rooth 1985). the strictly logical meaning. A commonly assumed mechanism for generating implica-tures to a statement is to take alternatives of the statement as false. For instance, Some dogs bark implicates that the alternative All dogs bark is false, even though it is compatible with the literal interpretation of the sentence ( X  X here are some dogs barking X ). This derives pragmatic strengthening of a class of scalar elements ( some &gt; some but not all , can &gt; can but does not have to , etc.).
 signed, in addition to their usual semantic values, an alternative set. For a sentence
John likes JANE with focus on the individual liked by the subject, the alternative set is lytical option is the so-called  X  X tructured meaning approach to focus, X  which considers alternatives only to parts of the sentence, for example, the noun Jane , but not to whole propositions (Krifka 1992). The two theories formalize the meaning of focus-sensitive operators differently, but, importantly for us, both assume the notion of semantic alter-natives to be crucial for focus interpretation.
 of focus particles such as even or only . But students of focus noticed that negation is also sensitive to them: Not A implies the truth of an alternative to A , for example, John doesn X  X  like JANE suggests that John likes someone else. This is not a boy suggests an alternative assertion ( This is a girl ; This is a man ); see Kratzer (1989, p. 646) for an explicit intensional analysis of negation in terms of focus alternatives. Negation, seen as a focus operator, is similar but logically opposite to only : whereas John only likes JANE means that John likes Jane but does not like anyone else, John doesn X  X  like JANE means that John does not like Jane but likes someone else. Non-trivial interaction with focus alternatives is very typical for usage of negation in natural language, so negation is rarely used in a purely logical sense.
 resulting from replacing the negated element with arbitrary values of the right semantic type. However, it is clear that not all alternatives are created equal. The most plausible ones are relevant across many varied contexts, whereas others require a heavy con-textual pressure to become acceptable. For example, boy and submarine are of the same semantic type (that of unary predicates), but it requires a very unusual context for This is not a boy to suggest This is a submarine . 1 In most contexts a limited set of predicates ( girl , man , etc.), all related to boy , constitute viable alternatives, and submarine is not one of them. So, although it is true that context affects the set of relevant alternatives, the most prominent ones are largely predictable from the propositional content of the utterance. reasoning tasks such as the construction of settings that verify or falsify a given rule (Evans 1972) or selection of information critical for determining the truth of a rule (Wason 1966). The alternative possibilities primed by negation have been said to be  X  X he most likely or relevant members of the complement set X  (Oaksford 2002, page 140). In particular, Oaksford and Stenning (1992) identify several mechanisms used for constraining contrast classes (viz. alternative sets): focus/intonation, high-level rela-tions, and world knowledge. They take the sentence Johnny didn X  X  travel to Manchester by train as an example. Different contrast classes will be built based on where the focus is put (Johnny vs. Manchester vs. train.). The high-level traveling schema relation imposes constraints for each slot (travelers, destinations, or mode of transportation).
Other constraints are imposed by world knowledge. For example, if you are traveling from London, the vehicle of choice is unlikely to be a ship. In short, Oaksford and
Stenning conclude that (emphasis ours)  X  X he contrast-class members should be as similar as possible, in the relevant respects, to the negated constituent X  (page 849). of negation automatically evokes a set of alternatives ( X  X earch for alternatives X  view) (Oaksford and Stenning 1992; Oaksford 2002) or whether the direct effect of negation is just one of information denial ( X  X uasi-literal X  view) (Evans, Clibbens, and Rood 1996).
Even under this second view, alternatives can still be evoked and explored at a later interpretation stage. Indeed, based on behavioral evidence, Prado and Novek (2006, page 327) propose to reconcile the two views by concluding that  X  X n initial reading of a negation will be narrow [viz. literal] and in some scenarios this might be enough. [..] A search for alternatives arises, but as part of a secondary effort to interpret the negation in the proposition. X  More recently, Ferguson, Sanford, and Leuthold (2008) presented eye-movement and ERP evidence in favor of the search for alternative view. Neither side of this debate denies that alternatives play an important role in the interpretation of negated statements, and we do not take a stand on it.
 sibility of a negated identity. Wason (1965, 1971) has claimed that the interpretation of negative statements of this kind is easier when the sentence negates a presupposition, something that is believed to be true. In this view, the sentence The whale is not a fish is easier to interpret than The whale is not a motorcycle . While negation underlines the difference between two terms, at the same time it presupposes that they are similar:
It is pragmatically reasonable to negate that two terms are the same thing when they can be confused. An alternative approach to this view is proposed by Clark (1974), who claims that comprehending negation relies on detecting differences between the proposition negated and the actual state of affairs. This predicts that, when two things are dissimilar, it should be easier to perceive one of them as a negation of the other: The 642 whale is not a motorcycle should then be easier to interpret than The whale is not a fish .
Cherubini and Mazzocco (2003), among others, have tested these theories, finding that similarity facilitates comprehension of negation across various experimental settings.
These results establish a connection between alternativehood in psychological studies and the similarity relation captured by DS that we are going to investigate in the remainder of the article.
 useful to account for linguistic and psychological data. Moreover, alternatives appear to be linked to negated expressions by a relation of similarity. However, all studies we are aware of base their claims on a small number of hand-picked examples of felicitous or implausible alternatives. As a consequence, no model has been proposed that, given a negated element and an arbitrary predicate, makes explicit predictions about how plausible it is for the predicate to fall into the alternative set of the negated element.
In the remainder of this article, we introduce a large data set of alternative plausibility ratings, and propose DS as a model to predict the plausibility of potential alternatives. 4. A Data Set of Alternative Plausibility Ratings
This section documents the creation and structure of our data set of plausibility ratings for alternatives to a negated predicate. We describe in turn the sentential frames we used, the sources of negated-predicate/alternative word pairs, the rating collection procedure, and its outcome. 4.1 Selecting Sentential Contexts
Semantic (or pragmatic) alternatives are defined for all types of interpreted constituents, from words to phrases to full sentences. Because our study is the first of its kind, it is best to start simple. We decided to focus on alternatives to common nouns, but, because a noun in isolation does not constitute a very natural utterance, we placed each noun in a minimal sentential context. The two simple options we adopt include using the noun predicatively in a classification statement ( This is (not) N ) ( IT context) and having the noun existentially quantified ( There is (no) N here ) ( THERE context) (of course, we do not claim such contexts to exhaust the spectrum of natural language negation usages).
In both cases, context does not add much information, and the main burden lies on the noun itself.
 ferent pragmatic effects. The IT context has a  X  X orrection X  reading whereas the THERE context has the flavor of an  X  X t least X  reading with the alternative compensating for the lack of the negated term. Moreover, This is not N suggests that the alternative should be a noun denoting something that could substitute or be taken for N . There is no N , on the other hand, suggests situations similar to ones in which there is N . Sets of salient alternatives in the two contexts need not be identical. For example, There is no piano here. . . might be plausibly continued with . . . but there is music , since pianos and music appear in similar situations. On the other hand, This is not a piano, it is music sounds odd, because pianos and music are very different things.

If we find that ratings are essentially comparable across contexts, then we have some evidence that we are getting stable and general alternativehood ratings. Should, instead, systematic differences emerge, we could gain preliminary empirical insights on how sentential, as opposed to purely lexical, factors affect alternatives. We will briefly come back to this point in the analysis of subject ratings.
 more explicit understanding of linguistic pragmatics than one can expect from a naive speaker, even with some training. Instead, we ask subjects to rate the explicit conjunc-tion of the negated predicate and the alternative, as a close proxy for alternativehood. So for instance, instead of asking  X  X oes This is not a dog plausibly evoke the alternative
This is a cat ?, X  we ask the more intuitive question:  X  X ow plausible is the sentence This is not a dog, it is a cat ? X  The corresponding THERE context is There is no dog here, but there is a cat , with but added as it makes the sentence more natural. 4.2 Selecting Potential Alternatives
As just discussed, our stimuli contain exactly two content words X  X  noun either in a predicative or in an existential negated position, and its potential alternative in a com-parable position. To construct the noun pairs, we took as negated elements 50 randomly selected items from BLESS (Baroni and Lenci 2011), and paired them with potential alternatives from several sources. We picked alternatives from different sources in order to take a variety of relations that might affect alternativehood into account. However, we make no claim about the exhaustiveness of the phenomena we are considering, and we do not present theoretical conjectures about how lexical relations affect the likeli-hood of being a plausible alternative.
 hyponyms, and hypernyms. For the 50 negated items, there are almost 4K WordNet cohyponyms, many of them based on very rare senses ( library vs. battery ). We picked the first 10 cohyponym synsets of each noun (as more common senses are typically listed earlier) and filtered out the ones expressed by phrases, ending up with a total of 534 negated-item/hyponym pairs (e.g., deer / pollard , falcon / buteonine , chair / academicianship , bag / bread-bin ). We also covered hyponyms (WordNet subcategories), with a total of 314 distinct pairs (e.g., truck / lorry ), and hypernyms, including 32 category names from the norms of Van Overschelde, Rawson, and Dunlosky (2004) and all WordNet super-categories, for a total of 216 distinct pairs (e.g., garlic / seasoner ).
 alternatives, it would be wrong to miss non-taxonomic relations, which we extracted from various other sources. We included nine nearest neighbors per item from the best  X  X ount X  distributional semantic model of Baroni, Dinu, and Kruszewski (2014), functionally similar items (nouns that share the UsedFor relations) from ConceptNet (408), and visually similar nouns from Silberer and Lapata (2012). From the latter, we included all pairs with more than minimal visual similarity ( &gt; 1), a total of 525 pairs (e.g., bus / cabin , dress / trousers ). Further pairs were extracted from the University of
South Florida Word Association Norms (Nelson, McEvoy, and Schreiber 1998). We only picked nouns, for a total of 492 free associates (e.g., giraffe / trees ). To construct unrelated pairs, we randomly matched our nouns with ten frequent nouns each (e.g., poplar / fuel , data to support the intuition that a concept cannot be an alternative to itself ( *This is not a dog, it is a dog! ), we paired each word with itself in a set of  X  X dentity X  pairs. 644 100 times in our source corpus (see Section 5.1.1). We also removed some obviously mistagged items ( th , these , others incorrectly tagged as nouns), and potentially offensive materials. No other filtering was performed on the data. We were left with 2,649 pairs (50 identity pairs and 2,599 pairs for the other relations). is a Y sentences. We manually corrected determiners where needed ( a broccoli &gt; broccoli ), number agreement in sentences with plural terms ( There is jeans &gt; There are jeans ), and we adjusted capitalization ( pbs &gt; PBS ). 4.3 Collecting Human Ratings
We used the Crowdflower service 5 to collect plausibility ratings on a 1 X 5 Likert scale for the 2,649 negated-item/alternative pairs embedded in both THERE and IT contexts, collecting at least 10 judgments per pair. Following the standard practice in crowd-sourcing experiments, we added 42 manually crafted sentences that were obviously (un)acceptable (40 in the THERE setting since two pairs were more ambiguous in this context). Participants who did not rate these pairs within the expected ranges were excluded from the survey.
 told to think whether in an ordinary real-life situation (not  X  X airy-tale X  circumstances) the sentence could be reasonably uttered. Furthermore, they were told that, in case of ambiguity, they had to choose, if available, the (sufficiently common) sense of a word that would make the sentence more plausible. Finally, participants were instructed to mentally add, remove, or change the article in each example if that made it more natural (e.g., This is not a planet, it is a sun could be changed to the more natural This is not a planet, it is the sun ; There is no subway here, but there is a bus , could be changed to the more natural There is no subway here, but there is the bus ). No further definition of the phenomena involved in the sentences were given. Subjects were instead provided with examples (fully reported in Tables 1 and 2).
 we decided to exclude from further analysis those pairs that were not rated consistently by the subjects. In particular, we discarded all pairs whose inter-subject variance was not significantly below chance at  X  = 0 . 1, based on simulated chance variance distributions.
We discarded all identity pairs because the overwhelming majority was characterized by very high variance. Evidently, the subjects found statements such as This is not a cat, it is a cat too nonsensical to even parse them coherently. After filtering, we were left with 1,231 IT pairs and 1,203 THERE pairs. 6 4.4 Distribution of Alternative Plausibility Ratings
Table 3 reports summary statistics for the reliably rated items. As the table shows, excluding high-variance pairs still leaves us with relatively many examples of the non-identity relations in both sentential settings.
 both IT and THERE contexts. It is also not too surprising that, for all other relations except hyponyms, the THERE ratings are higher than the IT ratings. As we observed earlier, the IT context suggests that the alternative should be something highly similar to the negated item, whereas in the THERE context, it is the situations in which the negated item might occur that must be shared with the alternative. Figure 1 reports the pairs where the positive difference between the THERE and IT mean rating is largest (the opposite happens very rarely). The case of castle and prince is exemplary: a castle 646 is a very different entity from a prince (hence, the oddness of *This is not a castle, it is a prince ), but the presence of a prince suggests that we should be at least surprised by the absence of a castle, and so There is no castle here, but there is a prince sounds like a reason-able observation. In this perspective, it makes perfect sense that the alternatives with the largest relation-wise positive THERE X  X T difference are free associates and visually related items (items that might look similar, but can be ontologically quite different). ings in both contexts, and they are indeed the only relation showing a slight preference for the IT context. We expected hyponyms to be treated as implausible alternatives, because they should lead to contradictory sentences ( *This is not a vegetable, it X  X  a potato ).
By inspecting the highly rated hyponyms, we conclude that the unexpected pattern is almost entirely due to the following artifact: All our target negated items are base-level concepts from the BLESS resource, and not general category names. Consequently, the hierarchical distinction with their WordNet hyponyms is not very sharp, and indeed in most of the cases in which a negated-noun/hyponym pair receives a high rating, the two terms can be as easily interpreted as cohyponyms: coat/jacket , truck/van , shirt/t-shirt , bag/rucksack , cat/panther , and so on. Indeed, these are better cohyponym pairs than many of those we harvested through WordNet cohyponym links, that were often too distantly related ( bottle/bath under the vessel category) or based on unusual senses of words ( goat/mug under the victim category). As a result, cohyponyms received, on average, lower ratings compared with hyponyms (again, the THERE context, being more tolerant towards distant relations, affords higher cohyponym ratings). 648 neighbors in a distributional semantic space) receive, on average, high ratings, com-parable to those of hyponyms. By looking at top-rated distributional alternatives, we find that many of them are close cohyponyms (e.g., lizard/iguana , poplar/elm , trumpet/saxophone ). So, we conclude that, as expected, close cohyponyms are very good alternatives (both in the IT and THERE contexts), and that following the WordNet hyponym link or harvesting near distributional neighbors are better ways to get at the close hyponyms than relying on the WordNet cohyponym relation.
 more a preference for them in the THERE context. This is at least in part because of the presence of but in the latter frame, which encourages a  X  X ontrastive X  reading (cf. There is no trumpet here, but there is an instrument vs. ?This is not a trumpet, it is an instrument ). and distinct relations on the ratings. This analysis should, however, not obscure two important points illustrated by the scatterplots in Figure 2. First, correlations between
IT and THERE ratings are uniformly extremely high, except for the unrelated pairs, where the (relatively) low correlation is simply an artifact of the lack of spread among pair ratings (as nearly all pairs get very low scores). It seems safe to conclude, then, that the subtle pragmatic and semantic implications carried by the two contexts affected subjects X  ratings only very marginally, and we are getting robust alternativehood intu-itions across contexts. Consequently, we also expect that the same similarity measure might be able to approximate the ratings in either context reasonably well. Second, for all relations (except the one linking unrelated pairs), there is a good number of both plausible and implausible alternatives. 7 This shows that relation type does not suffice to account for the plausibility of an alternative, and we need a more granular similarity measure. We thus turn, in the next section, to various candidates that distributional semantics provides for such a measure. 5. Predicting Alternative Plausibility with Distributional Semantics
Predicting human ratings about the plausibility of alternatives under conversational negation with a DS model is straightforward. Following standard practice (Turney and Pantel 2010), we take the cosine of the angle between the distributional vectors of a negated noun and the potential alternative to be an estimate of their degree of semantic similarity. Because alternativehood obviously correlates with similarity, this simple method should provide good estimates of perceived alternative plausibility. because we saw that ratings are affected by sentential context, we exploit compositional
DS methods to derive vector representations of negated items and their potential alter-natives when embedded in the IT and THERE contexts. Second, because we know that generic similarity cannot be the whole story (for example, hyponyms are expected to be quite similar to their hypernyms, but our survey results suggest that hypernyms are not particularly felicitous alternatives), we feed rated pairs as training examples to a supervised algorithm (specifically, support vector regression). We hope, in this way, to tune generic DS similarity to the specific characteristics of alternativehood. in our data set into 563/550 IT/THERE training items, 186/187 development items, and 482/466 test items (the split is carried out so as to maximize IT/THERE overlap across the subsets). 5.1 Model Implementation 5.1.1 Distributional Semantic Space Construction. We extracted co-occurrence informa-tion from a corpus of about 2.8 billion words obtained by concatenating ukWaC,
Wikipedia, 9 and the British National Corpus. 10 Our vocabulary X  X he words we produce semantic vectors for X  X s composed of the 20K most frequent nouns in the corpus (in inflected form), plus those needed to have full coverage of the rated data set. We counted sentence-internal co-occurrences of these nouns with the top 20K most frequent in-flected words, thus obtaining 20K-dimensional vectors. Following standard practice, we transformed raw counts into non-negative Pointwise Mutual Information scores (Evert 2005) and compressed the resulting vectors down to 300 dimensions using Singular
Value Decomposition (Golub and Van Loan 1996). All the described parameters were 650 picked without tuning, based on our previous experience and insights from earlier lit-erature (e.g, Bullinaria and Levy 2012). We exploited the development set to decide if we should rescale the Singular Value Decomposition vectors by the corresponding singular values (as suggested by mathematical considerations) or not (as recently recommended, based on empirical evidence, by Levy, Goldberg, and Dagan [2015]). We found that the latter option is better for our purposes.
 described to the neural-language-model vectors shown to be at the state of the art in many semantic tasks by Baroni, Dinu, and Kruszewski (2014). Perhaps surprisingly, we found that, for our purposes, the count vectors are better. 5.1.2 Modeling Sentential Contexts with Composition Functions. In order to produce seman-tic representations for our target nouns in the relevant sentential contexts, we harness the compositional extension of DS. In particular, we adopt the functional model in-dependently proposed by Coecke, Sadrzadeh, and Clark (2010) and Baroni, Bernardi, and Zamparelli (2014). In this model, certain linguistic expressions (e.g., verbs) are represented by linear functions (matrices or higher-order tensors) taking distributional vectors representing their arguments (e.g., nouns) as input, performing composition by matrix-by-vector multiplication (or the equivalent operation for tensors of larger arity), and returning output vectors representing the relevant composed expressions (e.g., sentences). We assume that the affirmed and negated IT and THERE contexts vector representations of the nouns of interest (e.g., hawk ) as input and return vectors representing the corresponding phrases (e.g., this/it is a hawk ) in output. We then use cosines between negated and alternative phrases to predict alternativehood plausibility. poor development set performance. These were: ignoring negation (e.g., using the same composition function for this/it is a hawk and this/it is not a hawk ), and modeling negation as a separate composition step (e.g., deriving this is not a hawk from the application of two composition functions: not ( this is ( hawk ))). We did not attempt to model here and, more importantly, but in the THERE context ( there is no X here, but there is a Y ). of Guevara (2010), Baroni and Zamparelli (2010), and Dinu, Pham, and Baroni (2013), as implemented in the DISSECT toolkit. 11 Specifically, we extracted from our corpus distributional vectors for sufficiently frequent phrases matching the target template (e.g., this/it is cat ), and estimated the corresponding function by optimizing (in the least-squares sense) the mapping from the vectors of the nouns in these phrases ( cat ) onto the corpus-extracted phrase vectors. Theoretical and empirical justifications for this method can be found in Baroni, Bernardi, and Zamparelli (2014), or any of the articles mentioned here. We relied on a MaltParser 12 dependency parse of our corpus to identify the target phrases, and treated other words occurring in the same sentences as contexts (e.g., from sly as contexts). The phrase vectors were assembled and transformed using the same parameters we used for nouns (see Section 5.1.1). We built vectors for any phrase that (i) matched one of the templates of interest; (ii) contained a noun from the semantic space vocabulary; (iii) and occurred with at least 100 distinct collocates in the corpus.
These constraints left us with 8,437 training examples for this/it is X , 3,071 for this/it is not X , 7,350 for there is X , and 3,220 for there is no X .
 randomly selected 500 pairs of words such that they would have a corresponding there is X vector. Then, we calculated their respective cosine similarity, obtaining a mean score of 0.02, indicating that words are quite dissimilar on average. Next, we replaced one of the words in each of the pairs with its corresponding phrase vector and computed the cosine score again. Interestingly, the average cosine score between phrase and word vectors is 0.06, which is significantly higher, confirming that phrase representations obtained with the method outlined here live in the same sub-space as words do. Moreover, we expect that, even if X and Y are unrelated concepts, it is likely that the utterances there is X and there is Y should be somewhat similar in meaning, since they are expressing related  X  X xistential X  claims. Indeed, if we compare phrase vectors corresponding to the same pairs of words we used earlier, we find that the cosine score increases from 0.02 to 0.54. We can conclude, then, that word and phrase vectors co-exist in the same space and, at the same time, that they have, sensibly, different distributions: phrase vectors, because of their shared semantics, tend to be more similar to each other than word vectors are. 5.1.3 Supervised Regression. The distributional vectors of negated items and their alterna-tives (either noun or composed phrase vectors) were also fed to a supervised regression algorithm, in order to tune similarity to the specific factors that determine felicitous alternativehood. We explored all the neural-network techniques of Kruszewski and
Baroni (2015) across a wide range of hyperparameters, but found, on the development set, that it was best to use support vector regression (Drucker et al. 1996) with an RBF kernel. We also exploited the development set to tune the hyperparameters of this model through a broad grid search, conducted separately for noun vs. phrase inputs and IT vs. THERE ratings.
 didate alternative in order to feed them together to the supervised regression algorithm.
Following recent work that addressed the same problem in the context of supervised entailment detection with distributional vectors (Roller, Erk, and Boleda 2014; Weeds et al. 2014), we explored the options of concatenating and subtracting the input vectors.
We picked the second strategy as it consistently produced better development set results across all settings. Note that subtraction, unlike concatenation, explicitly encodes the knowledge that we are comparing two feature vectors living in the same space, and what matters should be how the two vectors differ on a feature-by-feature basis. already captured by direct distributional similarity, we explored the possibility to train supervised regression on the residuals of cosine-based rating predictions. Concretely, we first trained a simple single-variable linear regression model using the cosine scores to predict the human ratings. Then, we trained a support vector regression model to predict the difference between human ratings and the output of the cosine-to-ratings model from distributional representations. The final rating prediction for a target pair was obtained by first feeding the corresponding cosine score to the cosine-to-ratings linear function and further incrementing or decrementing the resulting value by the residual produced by the support vector regression model we just described for the pair.
Compared with learning the regression parameters by directly predicting the original ratings, this strategy produced better development set results across the board, and we thus adopted it on the test set. 652 5.2 Results
Table 4 reports Pearson correlations with mean human plausibility ratings on the test set pairs. The unsupervised results are obtained by directly correlating vector cosines, the supervised ones by correlating scores obtained by feeding the relevant distributional vectors to the trained regression algorithm, as detailed in Section 5.1.3. In the nouns setting, the vectors represent the negated and alternative nouns, whereas in the composed phrases setting, the vectors are compositionally derived by applying the relevant phrase functions to the nouns. To put the results into perspective, the table also contains an upper bound ( experts row) that we estimated by rating the test set pairs ourselves, and correlating our averaged ratings with the ones elicited from subjects.
 similarity is very good at predicting alternativehood judgments. Both the IT and THERE correlations obtained in this way are just a few points below the upper bound. Although the underlying benchmarks are not directly comparable, the correlations are as high or higher than those of state-of-the-art systems on widely used semantic similarity data sets (see, e.g., Baroni, Dinu, and Kruszewski 2014), suggesting alternativehood judgments as the ideal task for DS. 13 has a strong negative effect. However, by combining composition and supervision, we obtain an increase in correlation of about 1% for both IT and THERE. Because we are very close to the upper bound, we cannot hope for much more than tiny improvements of this sort. Still, the correlations between unsupervised noun-based cosines and super-vised phrase-based scores are extremely high (99% for IT and 98% for THERE), making it pointless to search for interesting differences between the approaches. We thus focus the rest of the analysis on the simple unsupervised word-based model.
 and THERE ratings itemized by relation, illustrating how the results are consistently 654 high. As the scatterplots show, the low unrelated and distributional correlations are an artifact of the lack of spread of the corresponding values (not surprisingly, cosines of distributional neighbors are uniformly high). Besides these trivial effects, the data suggest that a single similarity measure is a good predictor of alternativehood, with no strong impact of relation or context type.
 looking at the largest discrepancies between noun cosines and IT/THERE ratings is the following: Many pairs with a large positive difference in favor of cosines are only  X  X opi-cally related, X  and thus do not make for good alternatives. Examples include: television/ airing (IT), shirt/flannel , lizard/tongue (THERE), television/ABC , television/rediffusion , cranberry/soda , and dagger/diamond (both). This discrepancy might easily be addressed by building DS models based on narrower contexts, which are known to produce similarity estimates that are more ontologically tight, and less broadly topic-based (Sahlgren 2006). Other discrepancies are due to idiosyncratic properties of specific words. For example, among the pairs with the largest positive difference between (scaled) IT ratings and cosines, we find cat/cougar , cat/panther , and other cat/big-cat pairs, where the corpus-based distributional model is strongly influenced by the pet function of domestic cats, and thus underestimates their similarity to large felines. Similarly, subjects assigned a high THERE rating to bottle/cup , whereas the distributional representation of cup might be too dominated by its  X  X rize X  sense, making it less similar to bottle . In a realistic scenario, the relevant statements would be produced in context ( There is no bottle here, but there is a cup would presumably be uttered as part of a discussion of liquid containers, rather than sports events). Word ambiguity effects could then be addressed by adapting the DS representations of the target terms to the broader context (e.g., emphasizing the container components of cup ) by means of standard word-meaning-in-context methods (Erk and Pad  X  o 2008). 6. Discussion and Future Work
This special issue addresses the integration of formal and distributional models. This is a challenging task, because the two strands of research rely on different research cultures, methodologies, and simplifying assumptions inevitable in any scientific work. Some studies on finding a unifying perspective have been carried out on both empirical and theoretical fronts (Garrette, Erk, and Mooney 2013; Grefenstette 2013;
Lewis and Steedman 2013; McNally and Boleda, to appear). We started our work on this article with the firm conviction that distributional models can do more, inspiring and helping to tackle new tasks that are both theoretically interesting and empirically challenging. The pragmatic contribution of negation is just such a task. Our success at modeling alternatives under conversational negation shows that distributional models are immediately applicable to theoretically interesting problems beyond arguably trivial ones, such as identifying near-synonyms.
 tor of alternativehood, suggesting that distributional similarity captures a notion of substitutability in context that is very much in line with the idea of an alternative.
Alternatives, in turn, play an important role in many more linguistic phenomena than just conversational negation, and DS, as already conjectured by Baroni, Bernardi, and
Zamparelli (2014), might just be the right tool for a large-scale, explicit approach to pre-dicting the set of possible alternatives that are salient at a given point in a conversation.
In a broader theoretical perspective, this also resonates with the view from cognitive science of the brain as an  X  X nalogy machine, X  constantly generating rough predictions about the next state of the world (or of a conversation), based on similarity matching between current information and representations in memory (Bar 2007; Hofstadter and Sander 2013).
 in order to make it more challenging to the plain DS similarity approach. Crucially, the current set lacks a sufficient number of synonyms, which will have very high DS similarity but should not make for plausible alternatives ( ?This is not an automobile, it but there is an animal is plausible, but ?There is no animal here, but there is a cat sounds odd). Inverted pairs will obviously be a challenge to the symmetric cosine measure. We expect that, once we enrich the data set with such cases, plain DS similarity will no longer suffice, and we will have to rely on supervised approaches that currently seem almost superfluous.
 for our current skeletal sentential contexts. Compositional, or, more generally, word-meaning-in-context approaches (Erk 2010) will have a better chance to prove their worth if we extend the empirical base to include more informative contexts, and let longer constituents be under the scope of negation and/or in the alternative set (cf., There is no bachelor here, but there is a. . . married man, ??unmarried man ).
 conversational negations in more natural set-ups than the highly controlled experiment we designed.
 integrating what we observed empirically into a formal model. We think that, just like in standard approaches to semantics and discourse (Kamp and Reyle 1993; Ginzburg 2012), and as also recently advocated by McNally and Boleda (to appear), meaning in
DS must be modeled in dynamic terms, that is, by considering how each utterance affects shared informational content as a coherent discourse unfolds. In particular, we assume that part of the meaning of a linguistic expression is given by a probability distribution over possible linguistic expressions that might follow. Negation, like other dynamic operators, changes this distribution by updating probabilities, according to a similarity function between the distributional representation of the negated expression and the vectors of possible continuations. Appealingly, distributional vectors, especially when contextualized with appropriate techniques, can account at once for generic conceptual aspects of meaning (if we are talking about dogs, other animals are a priori more relevant alternatives) as well as pragmatic and episodic factors (if the topic at hand is therapies for depression, pills might be perfectly coherent alternatives to dogs). Ideally, specific properties of negation and other operators should be induced from corpus data.
In particular, the logical ( X  X omplement X ) constraint on negation might be captured by a non-linear scoring function that assigns very low probabilities to vectors that are too similar to the one of the negated element.
 to utterance meaning. Inquisitive semantics, which ultimately stems from the analysis of questions by Groenendijk and Stokhof (1984), is devised as a logical system able to char-acterize (some) conversation moves, and it recently received a complete axiomatization (Ciardelli and Roelofsen 2011). In particular, inquisitive semantics interprets a question as a partition of the set of possible worlds { w 1 , w 2 ... } according to potential answers to the question, cf. Example (3a), where the relevant answer fragments are given in 656 one, e.g., Example (3c), just eliminates some of the possibilities. However, one could imagine an arguably more realistic system where negation does not just exclude one of the possibilities in question (as it does standardly in inquisitive semantics) but assigns different weights or probabilities to the remaining ones, as illustrated schematically in
Example (3d), where darker shades of gray correspond to greater weight (probability) of the alternative proposition. As our article suggests, distributional models provide very strong cues for such weights. (3) a. Question under discussion: What is this?
From the point of view of linguistic analysis, a very important issue that remains to be settled is whether linguistic negation always evokes alternatives, and whether the latter are always determined by similarity. We conjecture this to be the case but also that, when negation takes wider scope, the range of alternatives becomes much broader and so does the notion of similarity that we must adopt. Consider: (4) a. I do not want to watch a movie this afternoon. . .
Example (4b) is a more coherent continuation for (4a) than (4c), and a very broad notion of similarity seems to be at work here as well (roughly, plausible alternatives to Example (4a) must involve activities that can be carried out in the span of an afternoon).
It remains to be seen whether compositional distributional semantics is up to the task of modeling alternatives at this level of abstractness. suggested to us by Mark Steedman, would be to collect evidence about factoids from implicit contexts. Consider, for example, an information extraction system that is harvesting corpus data supporting the factoid Pablo Picasso owns poodle . Obviously, sentences directly stating this fact are the most informative. However, our results suggest that even Pablo Picasso did not own a chihuahua should bring (probabilistic) support to the given factoid, to the extent that poodle is a plausible alternative for chihuahua .
 and much empirical and theoretical work remains to be done. However, we hope to have demonstrated that accounting for negation, far from being one of the weak points of this formalism, is one of the most exciting directions in the development of a fully linguistically motivated theory of distributional semantics.
 results, but will benefit from the data set of alternatives that we collected for this article. 14 For instance, an immediate use of the data set would be in constructing natural examples involving alternatives for theoretical or experimental research in semantics, pragmatics, and reasoning.
 Acknowledgments References 658
