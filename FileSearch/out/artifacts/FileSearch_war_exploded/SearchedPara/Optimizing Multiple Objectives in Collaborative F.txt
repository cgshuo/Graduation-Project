 This paper is about the utility of making personalized rec-ommendations. While it is important to accurately predict the target user X  X  preference, in practice the accuracy shou ld not be the only concern; a useful recommender system needs to consider the user X  X  utility or satisfaction of fulfilling a cer-tain information seeking task. For example, recommending popular items (products) is unlikely to result in more gain than discovering insignificant ( X  X ong tail X ) yet liked item s be-cause the popular ones might be already known to the user. Equally, recommending items that are out of stock would be frustrating for both the user and system if the system is employed to discover items to purchase. Thus, it is im-portant to have a flexible recommendation framework that takes into account additional recommendation goals mean-while minimizing the performance loss in order to provide greater adjustability and a better user experience.
To achieve this, in this paper, we propose a general recom-mendation optimization framework that not only considers the predicted preference scores (e.g. ratings) but also dea ls with additional operational or resource related recommen-dation goals. Using this framework we demonstrate through realistic examples how to expand existing rating prediction algorithms by biasing the recommendation depending on other external factors such as the availability, profitabili ty or usefulness of an item. Our experiments on real data sets demonstrate that this framework is indeed able to cope with multiple objectives with minor performance loss.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Information Filtering General Terms: Algorithm, Performance, Experimenta-tion
Collaborative filtering aims at identifying interesting ite ms (e.g. movies, books, websites) for a given user based on their previously expressed preferences. Previous studies have de-voted a lot of effort to improving the accuracy of the rec-ommendation. Most of the time these algorithms are for-mulated as a rating prediction problem. These techniques include the popular user-based approach [8], the Probabili s-tic Latent Semantic Analysis model[13], and matrix factor-ization methods [16]. Alternatively, some researchers reg ard recommendation as a ranking problem and try to improve the rank accuracy [15, 23, 18].

However, to build a practical recommender system, pro-viding items that fit to the target user X  X  taste (recommen-dation accuracy) is not the only concern. Users X  satisfactio n also relies on the utility of obtaining recommendations to a c-complish a certain information seeking task. Additionally, in a practical operational environment there might be other factors that can affect the effectiveness of the whole system. For example, many recommendation algorithms use, either explicitly or implicitly, the Root Mean Square Error mea-sure as the objective function [16] -a typical case is the Net-flix competition. To reduce the error, the algorithm has to focus on the popular items (in the training phase). As a re-sult the algorithm is more likely to recommend mainstream items which might be already known to the user. However, recommending these items is likely to be less useful than suggesting X  X ong tail X , more disputable yet preferable, it ems. Such usefulness also depends on how  X  X lternative X  a user X  X  preference might be. Thus, the offset of a user X  X  taste from the mainstream has to be defined. It is certain that Root Mean Square Error alone cannot address this problem.
From the system X  X  perspective, the organization that is operating the recommender system expects that the sys-tem could help their users discover their products or ser-vices effectively. By the same token, other factors such as users X  feedback, available resources, bandwidth and profit can also influence the productivity and performance of a rec-ommender system. For example, recommending items that are not immediately available would be frustrating for both the user and the system. Arguably these factors can be as important as the recommendation itself, so they should be taken into account and embedded into the system.

We, thus, argue that a recommender system can only be successful in a competitive environment if it is able to opti-mize multiple goals without the necessity of redesigning th e whole algorithm. This motivated us to conduct a formal study on how to formulate the recommendation construc-tion problem when multiple objectives are considered. To achieve this, we formulate our problem using constrained linear optimization techniques [1]. Our idea can be simpli-fied as follows: we assign each of the items a utility score which is related to the rating of the item; the higher the predicted rating is, the more the utility score increases. B ut most importantly, the utility also depends on the predefined operational objectives. The rationale of using constraine d optimization is that it can naturally specify accuracy as the main objective and other operational objectives as con-straints, then optimize them in a unified framework. These objectives are generally conflicting so that we expect some performance loss, which are to be minimized. Two realis-tic situations are to be given to show how easily multiple factors can be added to this framework depending on the exact specification of the system. The first scenario is con-cerned with improving the quality of the recommendation by reducing the likelihood that popular items would be recom-mended to users with less popular taste, the second scenario concentrates on introducing constraints that can deal with other operational and business related factors.

The remainder of the paper is organized as follows. We first describe related work and establish our optimization scheme. The resulting recommendation models are then de-rived and discussed. After that, we provide an empirical evaluation of the effectiveness of the recommendation in two practical scenarios, and finally conclude our work.
Collaborative filtering was first coined in 1992 [7]. Its aim was to develop an automatic filtering system for electronic mail, called Tapestry . The idea of collaborative filtering was derived, originally, from heuristics, assuming that users who have similar preferences in the past are likely to have simil ar preferences in the future, and the more similar they are, the more likely they would agree with each other in the future. The preference prediction is therefore calculated by the weighted-averaging of the ratings from similar users.
Most of the studies in collaborative filtering focus on pre-dicting users X  preference ratings. The task is to make that prediction as accurate as possible. Memory-based approache s are the most widely adopted ones. In these approaches, all user ratings are indexed and stored into memory, forming a heuristic implementation of the  X  X ord of Mouth X  phe-nomenon. In the rating prediction phase, similar users or (and) items are sorted based on the memorized ratings. Re-lying on the ratings of these similar users or (and) items, a prediction of an item rating for a test user can be gen-erated. Examples of memory-based collaborative filtering include user-based methods [8], item-based methods [5] and combined methods [22]. To address the data sparsity prob-lem, model-based approaches are proposed. In the model-based approaches, training examples are used to generate an abstraction (model parameters) that is able to predict the ratings for items that a test user has not rated before. In this regard, many probabilistic models have been proposed. Examples include the aspect model [13] and the latent factor model [2]. These methods require some assumptions about the underlying data structures and the resulting  X  X ompact X  models to solve the data sparsity problem to a certain ex-tent. However, the need to tune an often significant number of parameters has prevented these methods from practical usage. Alternatively, rating prediction can be considered as a matrix factorization problem and it has emerged as the clear favourite in the Netflix competition [16]. In general, the approach aims to characterize both items and users by vectors of factors inferred from item-rating patterns. The approximation is usually found such that it minimizes the sum of the squared distances between the known entries and their predictions. One possibility of doing so is by using a Singular Value Decomposition (SVD) [25]. The main rea-son of its success may be due to the fact that the objective function of the approach is equivalent to the performance measure (Root Mean Square Error) that has been targeted in the competition. The drawbacks of using the RMSE per-formance measure is studied in [9].

Part of this paper is concerned with the long-tail problem that has been attracting significant attention in academic spheres. Therefore, many algorithms have been developed to help discovering items from the long tail. In [19] the item set was divided into head and tail and only the items in the tail were used for a method called Clustered Tail. This method used a number of derived variables (both user and item related) and built a model on each cluster in the tail. Another method introduced in [10] applied the innovation diffusion theory, the recommendation for the target user is based on a list of items that an identified reference users have accessed previously.

On the other hand, researchers also argued that formu-lating collaborative filtering as a rating prediction probl em is only limited. In many practical scenarios, such as the Amazon X  X  book recommender system [17], a better view of the task is of generating a top-N list of items that the user is most likely to like. In this regard, an item-based top-N recommender system was proposed in [15]. Inspired by text retrieval ranking, a probabilistic preference ranking al -gorithm is proposed [23]. Based on a random walk model, the learning to rank paradigm has been explored for the item ranking problem [18].

In this paper, while considering recommendation as a rank-ing problem, we are less worried about the recommendation accuracy. Instead, an operational/resource related recom -mendation framework is proposed in order to incorporate multiple objectives. Similar to [21, 24, 4], we apply con-strained optimization techniques. However, the purpose of the specific algorithm is quite different. In [21, 24], diver-sification is modelled by applying portfolio theory in stock markets. In [4], robust query expansion is introduced by exploring the risk and reward trade-off. In this paper, we start with a simple linear relevance objective, and devote our efforts to designing constraints to specify additional o b-jectives.
In this section, we first introduce a general framework and then move towards its specific applications. Let us begin tion for each item that can potentially be recommended to the user. The predicted ratings of the items can be conve-niently denoted as a row vector  X r = {  X  r 1 , ...,  X  r n is the number of the candidate items for user u . Normally n u equals the number of all unseen items for user u .
Conventional systems would already do recommendation by ranking items based on their predicted ratings. Here, however, to distinguish between rating prediction and rec-ommendation utilities, we now, for each of the items, assign a positive weight to describe its importance or utility on th e recommendation list. Mathematically, we have a row vector w = { w 1 , ..., w n u } . The weight is normalized so that: 1) The summation of its elements equals 1, i.e. 1 T w = 1, where 1 is a n u -dimensional vector whose elements are all 1, and 2) the weights are positive, i.e. w  X  0, where  X  represents the inequality for all elements in the vector.

Higher weights represent higher importance on the rank-ing list. Clearly, an item that has a higher predicted rat-ing would have a higher chance to be recommended, thus a higher weight. The question is how to find the weights by not only considering the predicted ratings but also the con-straints enforced to the items. To achieve this, we consider the following optimization problem: By casting the problem as a simple linear optimization prob-we use u and v and for items i and j . If the variable is time dependent we also have t reserved for time. For example p i,u,t would represent the probability that item i is selected by user u at time t . Furthermore, letter l is reserved for the relevant item of the target user (relevance is defined in the appropriate sections). We interpret time in a simplified way in this paper, it is defined by a number of events occurring one after another. So that decisions (to choose or not choose an item) made by the users trigger time. Following this, a bigger time frame (i.e. a day) can be understood as a collection of certain number of decisions. lem [1], we naturally extend the system towards multiple goals; each goal will be considered as a constraint and de-fined in the following sections.
We continue our development by introducing two basic scenarios that are designed to illustrate the importance of optimizing multiple objectives. We aimed to create scenari os that might be useful in practice and can be generalized to be able to apply them to a wide range of problems.
One of the shortcomings of current recommendation sys-tems is that they promote already popular items [6]. We ar-gue that this can partly be explained by the fact that most of the users prefer popular items, but it is also the result of that it is more likely to get the recommendation right if popular items receive a high prediction from the algorithm. Thus, higher rated items might get recommended higher on the ranking list over all users. To show this we obtained the first one hundred popular items and computed the proba-bility of those items occurring at each ranking position. We measured popularity by the average rating (Figure 1 (a)) given that items received a sufficient number of votes and also by the variance (Figure 1 (b)) such as that lower vari-ance implies popularity. The latter assumption is based on the observation that users X  opinion tend to be similar on pop -ular items, hence the low variance. Figure 1 (a) and (b) show that some of the widely used algorithms (user-based, item-based and SVD) tend to follow this pattern and recommend items higher if they are popular compared to a random sam-ple. For example the probability that an item is ranked at the first position on the ranking list given that it is popular is 12% (mean) and 8.2% (variance) using the SVD algorithm (Figure 1 (a) and (b)), whereas it is only 1.5% (mean) and 0.9% (variance) from a random sample. Furthermore, these popular items (Figure 1 (a)) were recommended 2730 times at position one which means that 45% of all users have one of these items recommended at the highest position (this statistics was obtained from the Movielens 1m data set). To avoid this, it is important to determine the extent to which users are likely to be interested in popular items, so the rec -ommender system could provide recommendations accord-ingly. Ideally, the algorithm would keep providing popular item for users who are interested in these items and it would provide alternative choices for users who are more likely to be interested in exploring less popular items. Thus, we aim to illustrate how we can propagate items that can be found in the long tail and match those items to users accordingly.
One simple approach that would help to decide whether the user is interested in popular items is to compute a value that would differentiate between items that are popular (bas ed on the observation depicted on Figure 1 (a) and (b)) and items that are less popular, yet still interesting for the us er. Figure 2: The relationship between m i (as defined in Equa-tion 2), mean (  X  ) and variance (  X  ).
 This can be expressed mathematically as follows: where the score of an item is the reciprocal of the mean (  X  and the variance (  X  i ). One is added to the variance in order to avoid division by zero. We also decided to square the vari-ance to emphasize higher values to reflect the disagreement among users which was intended to be the most important part in this formula. In this way we can identify items with fairly high mean and fairly high variance, because there is n o consensus on those items, they might be interesting for the user. Therefore, m i is lower if we have disputed items with fairly high popularity and it is higher for items where users agreed on whether it is good or bad. This relationship is illustrated in Figure 2 where we plotted the the outcome of m i with respect to mean and variance. It shows that we get the lowest m i values when we have high variance combined with high mean, which are the disputed items that can be found in the long tail.

In order to measure the extent to which users are inter-ested in disputed items, we used the same approach de-scribed above for all items that the user rated relevant where n l is the number of relevant items rated by the user.
An extra constraint is added to our original equation which would ensure that users who have mainstream taste get pop-ular items recommended (which would happen by default) and users who are interested in items in the long tail would get their taste satisfied, too. The Long Tail Constraint (LTC) that is defined in Equation 2 and 3 can be added as a inequality constraint to our optimization problem as where m = { m 1 , ..., m n u } is a row vector that contains the corresponding m i values (Equation 2) for all items returned by the recommender engine for the given user and  X  is a pa-rameter set to control the extent of users X  alternative taste .
This constraint is aimed to illustrate how we can embed other external factors into the system that are not directly related to recommendation. At the abstract level this can include all the operational factors such as profit margin of items, the currently available bandwidth to supply digital content etc. The scenario that we present below is the availability of items in stock during recommendation. This might be useful for companies who supply hard-copies of items, which cannot be produced instantly. For example DVD rental companies like Lovefilm (UK) or Netflix (US) could only recommend items that are in stock, which would reduce the probability that users choose movies that cannot be provided. Another application of this approach might be that digital television service providers (e.g. BT Vision) could recommend items that are already stored locally or on a server close to the target machine which would reduce network traffic at peak times.

We embed this into a probabilistic framework that would provide a more flexible interpretation of the problem than simple stock level values. It would be modelled as a stochas-tic process where the outcome depends on whether the user chooses to consume products or use services. For each user we have a row vector p = { p 1 ,u,t , ..., p n u ,u,t } , that is ranked from 1 to n u based on the initial predictions provided by the recommender engine where p i,u,t represents the accumulated probability that user u chooses item i . Every time an item is shown to the user the probability that the user will choose the item increases:
Here k i,u represents the ranking position for item i on the ranking list of user u . This probability value depends on the position it occupied when it was presented (i.e. the higher its rank was, the most probable that it was chosen). It also depends the accumulated probability values ( p i,v,t is the probability that the item was chosen when the item was presented to other users ( v ) in the the past ( t  X  1). This is essentially a Markov chain where the property of the current state depends on the previous state. p
An event e i,u,t occurs when the cumulative probability p for an item reaches one. In this case that means that the user chooses to consume item i . We also introduce a threshold c that would ensure that items whose p i value is below the threshold would not be affected by the constraint. Therefore, let us also define s = { s 1 ,u,t , ..., s n u vector where s i,u,t represents the cut-off probability value that will be passed to the algorithm.
In other words, c is set to control the threshold from which the system starts re-ranking items, which depends on our choice of what we consider as a cut-off point in the model. For example if we want to make sure that s i,u,t does not reach one (which will be useful for the simulation discussed later) we need to set a threshold that would give enough space to the model to re-rank items as they approach one. The reason for introducing this threshold is to make sure that items which have low s i,u,t values are not penalized, since our model finds the optimal ranking order based on the s i,u,t value of each item, and the relative distance be-tween the s i,u,t values of the items. We express this as an inequality constraint where we have a row vector w = { w 1 , ..., w n u } that repre-sents the weights that determine the extent to which items will be re-ranked and s = { s 1 ,u,t , ..., s n u ,u,t } is a row vec-tor that contains the corresponding s i,u,t values (Equation 7) of all items returned by the recommender engine for the given user. Also, symbol  X  represents the inequality for all elements in the vector and symbol  X  is the operator for element-wise vector multiplication (i.e. x  X  y = { x 1 y , ..., x n  X  y n } ). Now using vector s we define s u for each user as follows:
The Resource Constraint defined in Equation 8 is used to extend the optimization problem. This inequality constraint would ensure that the system will recommend items that are more likely in stock:
One of the drawbacks of Equation 9 is if higher ranked item are out of stock, the algorithm starts to rank lower rated items higher, which might hurt the performance of the system. So the if we have an item which is predicted five (out of five) and an item that is predicted one, we might prefer not to place the second item higher than the first one even if the first one is out of stock. Therefore we introduce another parameter  X  that could be set to control the extent the algorithm would re-rank lower rated items. We modify Equation 9 as follows: where n u is the number of items returned by the recom-mender for the given user and n l is a number of items that are predicted relevant for same user.

Varying  X  from zero to one would help to fine tune the system, giving priority to performance (  X  = 1) where only items that are predicted relevant re-ranked or prioritizin g stock availability depending on particular needs. In other words, decreasing  X  simply increases the number of potential items which are taken into consideration during the process of re-ranking.
We empirically investigated the performance of extend-ing the system with the constraints discussed above. The experiments were conducted with the Movielens data set. This publicly available data set consist of 1 million rating s for 3900 movies by 6040 users. We divided the data set into test (40%) and training (60%) sets making sure that ratings from any given user are in both of the sets. Every user in the data set rated at least 20 movies and movies from each user are distributed randomly when the data set was divided. This is an important criterion since the performance mea-sures that are discussed below consider users as a point of evaluation. The results were cross-validated using a five-f old cross-validation method and the outcomes were averaged.
For each scenario we aimed to illustrate the performance of the particular constraint following the approach intro-duced in [11], so that first we considered the performance based on the expectation of what aspect(s) of the system would be improved. Most of the time it is trivial and easy to measure (e.g. increasing the gross profit), but sometimes it is not that straightforward (e.g. providing a wider variet y of items for the user). In addition to that, we assumed that the aspects in question cannot be measured using a general evaluation metric and they are likely hurt the performance of the system. Therefore, we also used other generic evalu-ation metrics which were set to measure the performance of the system as a whole.

We considered the outcome of the recommendation as a top-N list, because in most cases this is the way the sys-tem presents recommended items to the user. Therefore, the best way to measure such performance is to use vari-ous IR metrics. One of the evaluation metrics we used was Normalized Discounted Cumulative Gain (NDCG) [20] that measures the gain based on the position of the items on the recommended list. This measure was introduced in [12]. It penalizes the system if it returns highly relevant documents lower in the ranking list but penalizes less if the lower end of the ranking list was retrieved incorrectly. NDCG is nor-malized by the perfect permutation of all the documents in the set. The other measure we used was Precision, which is simply the fraction of retrieved documents that are relevan t to the given user. We have worked with binary relevance, that is we considered an item relevant if it was rated four or five (on a rating scale of one to five) and non-relevant other-wise. In a similar fashion, an item was considered predicted relevant if its rating was predicted over 3.5 and non-releva nt otherwise.
As explained above the aim of this approach is to pro-mote less popular items to users who might be interested in these items without sacrificing accuracy. Since this in-terest is highly subjective and hard to measure, there is no straightforward way to show that our approach works cor-rectly. As the aim was to promote items that are in the long tail, one approach to measure performance is to moni-tor the probability whether popular items get recommended higher than randomly selected items. This approach can only provide a satisfactory proof if we accept that our test set contains users who are indeed interested in alternative choices, because satisfying those users would result a de-crease in the probability that popular items ranked higher if the model works correctly, however, the extent of this re-duction might depend on the number of users whose taste is not popular. In the following experiments we set to explore the effects of this constraint on the quality of the recommen-dation combining the result with diversification to produce more personalized outcomes.

The initial reason why we needed diversification was that we aimed to promote items which are disputable with fairly high mean and variance (see Equation 2). This would in-Figure 3: The distribution of popular items (high mean) against ranking position.
 Table 1: Performance of the Long Tail Constraint (LTC) and Diversification (Div.).
 evitably result in higher risk of making the recommendation wrong. Therefore, adding diversification to the equation, which would promote disputable items that are differ from each other (with higher covariance), might reduce perfor-mance loss. This was studied in portfolio theory of document ranking [24] and query expansion [3], where it was argued that diversification might reduce the risk of expanding such a system without loosing on performance by ranking results based on risk and reward. Thus, we extended Equation 4 as follows where  X  is the n u  X  n u covariance matrix for the candidate items and  X  is the parameter that can control the extent of diversification. It is important to note that this additio n made our objective function non-linear, so the function was casted as a convex optimization problem for this part of the experiment.

The other problem was how to obtain the covariance ma-trix  X . First we approached the calculation using a simple unbiased estimator, taking users previously expressed pref-erences as the observed values. However, for our applica-tions this estimate was not acceptable because the estimate d covariance matrix was not guaranteed to be positive semi-definite. Therefore, we obtained two rectangular matrices from the original user -by-item matrix using Singular Value Decomposition factorization ( O = U DV T ). The obtained matrix V was used to estimate the covariance matrix for Equation 12.

We also ran some initial experiment to explore whether di-versification would be enough to produce alternative choice s for the user [26]. One of the important initial findings was that diversification alone does not reduce the probability that popular items are ranked higher, simply because pop-ular items can be diversified among themselves. It is the constraint that we introduced in Equation 4 that promotes items from the long tail and diversification distributes it o ver the top positions. However, using the constraint without di -versification new items that come from the long tail would more likely to be promoted very high on the ranking list, but with the combination of diversification the curve gets smoother. This can be observed in Figure 3 where we plot-imdb.com).
 Table 2: Top 10 recommendation list using the Long Tail Constraint (LTC) and Diversification (Div.) against the baseline. The performance improved by 78% for NDCG@10 and 50% for Precision@10.
 ted the probability of the ranking position of the first one hundred most popular items (in the same way as in Figure 1 (a)) concentrating on the first ten positions (  X  is set to one in this experiment). As Figure 3 shows that the Long Tail Constraint successfully reduced the probability that item s get recommended in ranking position one and two, but it in-creased the probability for ranking position three and four. This happens because the algorithm places long tail items at the top and the items that were there before are ranked lower accordingly. This is where diversification can help to distribute those items evenly. As a result of that only 32% of the users had a popular item in the first position of their recommended list (compared to 45% of the baseline algo-rithm). In terms of performance Table 1 shows that we only have a minor performance loss between the baseline and our combined version, which is 1.05% for NDCG@10, 0.3% for Precision@10 and 1.7% for Mean Reciprocal Rank.

Also, it is important to highlight that the Long Tail Con-straint is very likely to produce a completely different top-10 list which contains new items that would not have been there otherwise. Table 2 consists of a randomly selected user X  X  top-10 recommendation lists comparing the baseline algo-rithm with the Long Tail Constraint (keep it in mind that this data set was collected in 2000). There are two main things to note here. First, using the Long Tail Constraint we are able to provide a different range of movies that might be not that popular. In addition, a wider range of genre is present on the list. Figure 4 (a) and (b) show the rating dis-tribution for the two items that are ranked number one by the baseline algorithm and the Long Tail Constraint. They show that Dirty Dancing has a much higher variance that Aladdin, yet still a fairy high mean, this suggest that there is less agreement among users on whether Dirty Dancing is a good movie which would suggest that Dirty Dancing might be a good candidate as an alternative choice for adequate users.

In this case the variance of Dirty Dancing can be ac-counted for the fact that this movie is aimed at a female audience and high variance arises from a gender related fac-tor, that divides the audience, but high variance can also arise due to other factors such as political orientation, co n-troversy etc. Despite the differences they all share one thin g in common, that is higher variance is the result of that users are divided which would occur with items that are worthy of such a division. Therefore we consider this as one of the distinguishing features of items that can be found in the lon g tail.

In the case described above ranking Dirty Dancing high was a good decision, the item turned to be a good alterna-tive choice for this user, since we know that the user marked it relevant. Despite that the baseline algorithm ranked it t o the 22nd position. However, the question arises if we can always decide with high confidence whether high variance implies that an item is relevant to the user given that the user is interested in such items. For example, a politically controversial movie that has high variance can only be rec-ommended to users who are interested political controversy . The reason why the algorithm is able to decide is that we apply the combination of two main forces, the main algo-rithm that predicts whether the user X  X  taste is close to the target item (in our example, romantic movies) and the Long Tail Constraint picks out movies from potentially relevant items that can offer a good alternative to the extent that is determined by the user X  X  interest in such items.
In order to stimulate the scenario that concerns with the availability of recommended items (as described in Section 3.1.2), we designed a simulation that reflects a real-world e n-vironment. In fact, we only aimed to create a semi-realistic simulation, since we aimed to model the effects of our con-straint on the performance of a recommender system sepa-rating it from other factors. So we made a basic assumption that users base their decisions to borrow/buy items purely on recommendations. This set-up would model the relation-ship between the constraint we introduced and the quality of the recommendation but ignore part of the users X  decision making process that is independent from recommendation.
We set up the simulation as follows. We stimulated time by using time ticks, each time tick represented a day. We modelled a day as a cluster that groups together a decision of certain number of users to choose (or not choose) and item. So at each time tick we presented a list of items to a number of randomly selected users from our user base. The number of users we selected varied over the simulation with an average of one hundred. We assigned a probability of choosing an item from the first ten items that are presented to the user assuming that this probability depends on the rank of the item on the list as described in Equation 5 and 6. The probability for each ranking position was calculated using Equation 5 where the function is normalized for the top ten items on the ranking list, modeling users X  interested as a cumulative function as described in [14]. Since we had approximately one hundred users who used the system each Figure 6: The waiting list size with respect to the parameter c as defined in Equation 7. day with the overall probability of taking one item per user, this meant that maximum one hundred items could be bor-rowed a day. The simulation ran for 50 days and we moni-tored how the current stock could deal with the demand.
We operated this in an imaginary warehouse that can store 5000 items. We kept the number of items low in the warehouse to model a situation that would be not feasi-ble without introducing restrictions on the recommendatio n (e.g. many items would run out of stock after a couple of days). In order to make our system more effective we stored more copies of items that were popular (i.e. higher rated), but at least one copy of each item. As items got recom-mended more, the probability that they would be taken out increased. After an item was taken, the recommender took into account that we had less items in stock, and modi-fied the recommendation accordingly, promoting items that were available. To make the simulation more realistic, we assumed that if an item was out of stock and there was de-mand for that item, the user put the item on her waiting list (which is the way how DVD rental companies operate) and after it returned from another user the item would be supplied to users who had already requested it.

Updating the stock availability of items in real-time might be problematic to implement in practice, since it is not prac -tical to do real-time computing and distribute the data over the network in larger system, instead most of the data is precomputed and distributed over the system periodically. We took this into account, so during the simulation our al-gorithm updated the probability (as described in Equation 6) of all the items only once a day, at the end of each day.
We found that the best way of monitoring the effectiveness of our algorithm was to keep track of the number of items that were on users X  waiting lists, since that would give a good indication of how long users had to wait for an item. Therefore if we had less items on the waiting list, that meant we had less items that ran out of stock, so users were more satisfied with the service in general.
 We plotted the waiting list size over 20 days (Figure 6) NDCG@3(mean) 12.3% 4.32% 1.03% 0.43% 0.13% NDCG@3(max) 14.7% 5.12% 1.34% 0.56% 0.50% P@10(mean) 6.42% 3.37% 0.86% 0.06% 0.03%
P@10(max) 8.42% 3.91% 1.11% 0.24% 0.18% (the trend after 20 days remained the same) and the corre-sponding performance metrics NDCG@3 and Precision@10 for 50 days (Figure 5 (a) and(b)). We omitted the result of c = 1 . 6 on Figure 5, because the performance difference between c = 1 . 4 and c = 1 . 6 was so small that it could not be visualized on the graph. The performance was measured across all users who used the system up until the present point (e.g. the latest recommender list provided for each user was taken into account for the score). This ensured that the tendency rather than the daily fluctuation of the system was measured. We tested whether the results were statis-tically significant using a five-fold cross validation metho d. As Figure 6 shows if we just run the simulation without re-ranking the results (baseline) we would end up with a big waiting list very soon, since the demand for particular item s is constant. However, if our constraint (Equation 10) is used then we were able to keep the waiting list at bay. Note that we did not include c = 0 . 4 and c = 0 . 8 on Figure 6 be-cause they resulted in a waiting list size identical to c = 0. In terms of performance if we always re-ranked the results ( c = 0) we had a significant performance loss (see Table 3) which represents the lower bound of the loss. If we set the threshold higher the performance improved significantl y (Figure 5 (a) and (b) and Table 3) resulting in a very small performance loss for c = 1 . 2 and c = 1 . 6. As mentioned above the simulation was cross validated and all the im-provements from the lowest c value (including the baseline) were found statistically significant.

As Figure 6 shows if we do not control the stock level, the waiting list gets out of control soon. However, we ac-knowledge that this is an artificial situation as in practice there might be various methods that could help to keep the waiting list in control, for example the stock level can be increased as the demand grows, but the advantage of our method is that we can find the optimal cost/performance ra-tio that would help to run a system more efficiently. Besides, the system can respond immediately to demand whereas in-creasing the stock level might take more time. It is also important to note that this approach could bias the recom-mender to an extent when recommendation is based only on stock levels, therefore regularization is needed. One way to regularize the system is to enable the algorithm to increase stock level if the demand for a particular items is high. This approach with the combination of the constraint could offer a optimal solution in an ever changing environment.
We also investigated the effect of  X  (Equation 11) on the waiting list size, but with the current setting where we have Figure 7: The waiting list size with respect to the parameter  X  . more copies of popular items and the stock level is updated daily, we did not expect that enabling to re-rank all the recommended items would reduce the waiting list size, since it enables to recommend items which we have less copies of, therefore it is more likely that those items would run out of stock earlier. Thus, we slightly modified the experimental setting, so that we only allowed to have one copy of each item (operating with 3900 items). Figure 7 depicts the effect of  X  on the waiting list size. Setting  X  to zero (all the items recommended for the user are re-ranked) reduced the waiting list size with an average of 10.45% over 50 days. In terms of performance loss we witnessed a fairly big drop that is an average 2.10% for NDCG@3 with the maximum value of 2.99% and an average 5.58% drop for Precision@10 with the maximum value of 7.01%. It is important to emphazise that this drop was expected since we enabled to use items that were not predicted relevant, which increased the risk o f ranking potentially non-relevant items higher.

The real importance of  X  also depends on whether the system is able to provide enough relevant items for recom-mendation. For example  X  would not make any difference if all the items that are presented to the user are predicted relevant, which is is very likely in practice, because the nu m-ber of items that form the possible basis of the prediction is the whole set (i.e. all the items in the system), whereas in our case it is just the number of items that can be found in a test set for any given user. Therefore, setting  X  to less than 1 could only be used useful in practice when the system is designed to present a longer list to the user, where it is likely that the list would contain items that are predicted non-relevant, too.

It might be questionable why one would like to enable ranking items higher when they are predicted non-relevant increasing the risk that users receive non-relevant items, but there are some scenarios when this would be the only way to go. For example if the user wants an item instantly (e.g. using a video on demand service) and for some reason the demand for some of the items is very high, it is crucial to enable re-ranking lower rated items, otherwise the system would not be able to recommend any items and the user would scroll down the list and choose from lower rated items anyway. In other cases  X  could be set dynamically depend-ing on how high the demand is at a given moment.

Despite that we focused on a very specific scenario in this section, it is important to emphasize that this approach can be applied to any other resource related optimization prob-lems. For example if a company wants to penalize items that have lower profit margins, s i,u,t (Equation 7) can rep-resent the buying price/selling price ratio of a product for a given user and we can set the threshold to penalize items that exceed this ratio.
This work was set to define a new way of understanding and optimizing multiple goals in recommender systems. It offers practical solutions for expanding a recommender sys-tem in a way that can be generalized and reused in many different scenarios; it also offers practical solutions to so me specific problems such as identifying users who have less popular taste and matching appropriate items to these users accordingly. Furthermore, this paper investigated how de-mand affects the availability of items and offers a solution that can help to fine tune the trade-off between cost and performance.

We also identified some areas that are worth investigat-ing further. This includes understanding how parameter  X  (Equation 4) affects the quality of recommendation. This would provide a more precise interpretation of the relation-ship between the offset of users X  taste from the mainstream and items in the long tail. Also, it is of interest to identify and generalize more features that can be used to describe items in the long tail, for example items that can be poten-tially interesting for a small group of people or items that are new to the system. To gain more understanding of the framework, a real-life evaluation is needed to test the per-formance in a constantly changing environment.
