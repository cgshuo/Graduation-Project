 mation, a number of techniques such as randomization and homomorphic encryption have been suggested in order to perform data mining with the private information preserved. In this paper, we propose a new privacy preserving data mining method with m parties from a general problem in data mining: Latent Dirichlet Allocation model (LDA, Blei et al. [1]). LDA is a generative probabilistic model for collections of discrete data such as text corpora, which can be seen as a special mixture model, in which each document is generated by choosing a distribution over topic and then choosing each word in the document from a distribution according to the topic se-lected. We can employ a Markov chain Monte Carlo algorithm (Griffiths et al. [2]) for inference in this model. 
This paper is organized as follows. We introduce the terminology of privacy-formulate the main problem. And in section 4, we describe our main protocol: RSS protocol, and evaluate the security and efficiency of this protocol. Section 5 illustrates how to assemble our protocol to solve the problem of privacy-preserving LDA described in section 2. In section 6, we present experimental evaluations of these techniques. Finally, we conclude with a summary in section 7. Large numbers of conclusions in privacy-preserving data mining have been obtained particular, one is a semi-honest party means that the party follows the protocol prop-sults and tries to deduce additional information from them other than the protocol result. In this paper, we also consider a problem called collusion that a subset of the attempt to deduce additional information of non-coalition parties, although every party also follows the protocol properly, as same as in semi-honest assumption. 
A protocol is called t-private if no coalition containing at most t parties can get any additional information from its execution. 
We will utilize some standard cryptographic tools and secure protocols to preserve privacy in our protocols. For convenience, we name the two parties "Alice" and "Bob" in the case of 2-party system. Homomorphic encryption. Public key encryption is a fundamental and widely used technology. The asymmetric key algorithm generates a pair of encryption keys  X  a from the private key used to decrypt it. The private key is kept secret, while the public key may be widely distributed. Given a key pair ( sk , pk ) and a message msg , particular, we call such an encryption system a homomorphic encryption, if there is an operation *, satisfying the following condition for any msg 1 and msg 2 : Secure linear function evaluation (SLFE). Alice has b , while Bob has c and d . After learns the value of d -bc , and Bob learns nothing . Here E pk and D sk denote the encrypt function and the decrypt function of a homomor-phic encryption system respectively. From the homomorphism, we can get E c = E pk (-b ) c = E pk (-b )* E pk (-b )*...* E pk (-b ) = E pk (-bc ), hence D = d -bc . 2.1 Latent Dirichlet Allocation Typically, LDA model is a generative probabilistic model proposed to research text documents, then we can also see a corpus as a sequence of N words, denoted by treated as a probability distribution over words in the vocabulary. Thus we can view a can write the probability of the i th word in a document as 2.1.1 Gibbs Sampling for LDA To infer z i for each word w i using Gibbs sampling, we need only compute the poste-Griffiths et al. [2]: z of words w except w i ; ) ( topic j except the current assignment of z i ; ) ( signed to topic j except the current assignment of z i ; and  X  ber of words in the current document d i except the current assignment of z i . 
To draw a sampling for a latent variable of a word w i , we only need to compute T z is equal to j under the condition of z -i and w . 2.1.2 Distributed LDA spectively. They attempt to run Gibbs sampling to infer all z i with respect to the whole corpus spreading around them without rev ealing anything. In this case, because any thus compute the second item of (2) locally. Then the only remaining problem is only related to i and j , we can express it as a function of i and j : cluding the current assignment of z i , and  X  When the data size is quite large, we propose the following approximation: protected. From (4) and (5), This means that the value of z i is a little harder to be changed when sampling. Hence, it will somewhat cause a slow convergence. However, this kind of approximation always does keep the convergence in Gibbs sampling because of the following rea-sons: 1) It is so near to the real value if data size if big enough; 2) The second term of holds because all the values of probabilities are proportional to the real values except what corresponds to current topic. This will be verified by experiments in section 6. 
In the rest of the paper, the index attached to the left-top of a variable denotes the that word w has been assigned to topic j in all documents in party k . So we can get: 
The variables with nothing being attached to the left-top denote the variables corre-sponding to the whole m parties, as shown in (8). q' w for w from 1 to W . In other words, we need not compute anything for all words in the entire corpus. Therefore, our whole strategy of sampling is a 2-step iteration: one LDA, we concentrate our attention on the computation of q' 1 ,..., q' W , expressed as: The problem of privacy-preserving LDA encountered the problem that how to se-with nothing of each party being revealed. We formulate our problem as below. be evaluated by any party other than i . We propose a symmetric protocol solving the RSS problem. Stage 1. Each party generates 2 m +1 random numbers in this stage. 
Therefore, each party generated 2 m +1 numbers satisfying the following condition: where pute the values of i b i and i c i , even though they are two variables actually. 
Stage 2. In this stage, each party collaborate to compute the value of d x m we can get that f is just what we want: Stage 3. In terms of i y , we achieve the operators in stage 1 to regenerate another series of b s, and c s, with the values of 1 d , 2 d ,..., m d not being changed, such that where d = 1 d + 2 d +...+ m d . Hence we can compute the following value by protocol 2-2: 
Therefore, the value of f/f' is just the ratio r in (10), which we want to evaluate: 
The value d = 1 d + 2 d +...+ m d is known to nobody unless all the m parties publish their own i d . Thus all parties can deduce nothing. In addition, we achieve stage 1 for only two times, and achieve stage 2 repeatedly. Security. Following theorem ensures the security of the RSS protocol. Theorem. The RSS protocol is ( m -1)-private. communication, random number generation, encryption and decryption, respectively. 
Because of the symmetry of RSS protocol, all parties can execute the protocol in summarize the running time of RSS protocol in Table 1. In summary, The running time with respect to each operation is O ( m ). 
To compute R ratios, RSS protocol needs just two times stage 1, 2 R times stage 2 and R time stage 3. Thus we summarize the result in Table 2. in our protocols. So we can say that t e and t d are O ( m ) in RSS protocol. protocol to compute one ratio in terms of w by setting the variables as follows: 
Hence we can securely compute one ratio as 
Sampling can be drawn, after all the WT values in Q are computed. In our 2-step iteration of distributed LDA, sampling step is as same as original LDA. As we have mentioned, the approximation in our method makes convergence slower than original LDA. To evaluate it, we compare the results of these two methods in the same machine. The experiment data is a corpus with 300 documents. All documents contain about 200,000 words. The number of words in vocabulary is W =20, where the words occurring in almost every document are omitted. The number of topics is T =5. Here we just evaluate and compare generated assignments of both methods. As shown in Figure 1, more than 167,000 data are changed in first round of both methods. Original LDA converges after about 10 th round, while approximate LDA converges after about 18 th round. The final results of sampling of both methods are also the same as each other in terms of generated assignments corresponding to each of them. 
In multi-computer environment, sampling step is achieved by m parties in parallel, and without updating parameters, so the 1-round cost of sampling step in distributed LDA is less than 1/ m of original LDA. 
Now we discuss the computing step. Since original LDA does not contain this step, the efficiency of this step is with strong relation to the whole efficiency of distributed LDA. By the limitation of number of computers, we just simulate such a system in a single computer by running all the necessary steps in sequence, recording the running one round of secure computation in computin g step. To compare the cost in different cases, we simulate the cases that m is 5, 10 and 30, and T is 5, 10 and 50, where the data are different from experiment of text analysis above. The result is shown in Table 3. Here, we just fixed W =10 in each case. We notice from Table 3 that the cost of RSS protocol is proportional to m , because the total cost is O ( m ) when T is fixed. In addi-tion, the increment of the cost of RSS protocol is not so fast when T increases, since t e and t d is independent on T . In this paper, we have introduced a protocol of computation of ratio of secure summa-tions. Our RSS protocol has higher security in the case of coalition. Furthermore, we also discussed the performance of the RSS protocols in this paper. 
We have also introduced the Privacy-Preserving distributed LDA model which can numbers of secure computation problems in privacy-preserving data mining, which require computing ratios of secure summations. 
