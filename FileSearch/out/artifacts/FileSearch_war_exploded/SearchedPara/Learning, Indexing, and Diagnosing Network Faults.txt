 Modern communication networks generate massive volume of operational event data, e.g., alarm, alert, and metrics, which can be used by a network management system (NMS) to diagnose potential faults. In this work, we introduce a new class of indexable fault signatures that encode tempo-ral evolution of events generated by a network fault as well as topological relationships among the nodes where these events occur. We present an efficient learning algorithm to extract such fault signatures from noisy historical event data, and with the help of novel space-time indexing struc-tures, we show how to perform efficient, online signature matching. We provide results from extensive experimental studies to explore the efficacy of our approach and point out potential applications of such signatures for many dif-ferent types of networks including social and information networks.
 C.2.3 [ Computer-communication Networks ]: Network Operations X  Network monitoring ; H.2.8 [ Database Man-agement ]: Database Applications X  Data mining Algorithms, Experimentation Network topology, fault signature, online diagnosis
The motif of networks is ubiquitous in our lives [4]. In its simplest form, a network can be modeled as a graph where the vertices of the graph represent network entities and the edges represent pairwise interactions between network enti-ties. It turns out that the simple, local, pairwise interactions between network entities can give rise to complex, interest-ing global phenomena [4]. Models of such global phenomena as a function of local interactions is one of the key issues being investigated in the area of networks. In this work, we propose a new class of models suitable for learning, in-dexing, and diagnosing a wide range of network phenomena while focusing on faults in the communication networks to exemplify our techniques.

Large communication networks have hundreds of thou-sands of network entities, and they are typically managed by a centralized network management system (NMS) that collects (local) monitoring data from network entities to di-agnose network faults. When a fault occurs at a network entity, it tends to influence the  X  X eighboring X  entities. Con-sequently, faults often results in a large burst of messages be-ing sent to the NMS from the affected entities. Each message contains a timestamp, an identifier of the affected device, and a type that signifies an event at the affected device The goal of NMS is to correlate the events occurring in the whole network, and identify the root-cause fault event(s), suppress dependent events, and discard routine operational events.

A key challenge faced by today X  X  NMS is that of scala-bility. All widely deployed NMSes maintain a cache of  X  X n-resolved X  events, and as each new event arrives, they use a rule-based mechanism to correlate the incoming event with all cached events to suppress dependent events and retain only the (unfixed) root-cause events in the cache. The re-sulting computation complexity is quadratic in network size since the number of unresolved events in the cache as well as event arrival rate is typically proportional to the network size.

Events triggered by a fault are typically generated by a small, constant-size subset 2 of nodes that are topologi-cally related to the faulty node. Thus, each event arriv-ing at the NMS only needs to be correlated with a small, constant-size subset of events in the cache, yielding a lin-ear complexity of event correlation. Intuitively, achieving the linear complexity would require data structures that en-code and exploit network topology. In this paper, we pro-pose a framework Meta (M onitoring network E vents with T opology A ssistance) that, to the best of our knowledge, is the first proposal to utilize topologically-aware event pat-terns to perform scalable network fault diagnosis.
Henceforth, we will use the words  X  X essage X  and  X  X vent X  interchangeably, while ignoring the semantic distinction that events occur at network entities resulting in messages that are received by the NMS for diagnosis.
The size of this subset depends on the degree distribution, etc., of the network and is independent of the size of the network. The remainder of the paper will be organized as follows. Section 2 formalizes the problem of network fault diagnosis; Section 3 and Section 4 describe in detail the offline learning and the online matching components of Meta , respectively (see Figure 1). An empirical analysis of our approach is presented in Section 5. Section 6 discusses related work. The paper is concluded in Section 7.
This section introduces fundamental concepts and nota-tions used in the paper, and formalizes the problem of online network fault detection and localization.
 Definition 1 ( Network) . A network is modeled as a graph G = ( V , E ) with V representing the set of nodes, each corresponding to a network entity 3 , and E representing the set of edges over V , each corresponding to a network link. Definition 2 ( NMS/Agent/Sink) . A network manage-ment system ( NMS ) consists of a set of monitoring agents and a sink . The agents are deployed on various network en-tities to collect monitoring data, and send them to the sink which is responsible for diagnosing potential faults. Definition 3 ( Network Event) . Each event x is a tuple of the form x = h e, v, t i , where e represents the event type, v the network node generating the event, and t the timestamp of the event.

In the rest of this paper, we use e x , v x , and t x to denote the type, entity, and timestamp of an event x , respectively. Definition 4 ( Event Stream) . We model the event stream as a sequence of events, ( x 1 , . . . , x n ) , where x n recent event. Real-time fault diagnosis focuses on events oc-curring within a time window of length  X  , i.e., an event subsequence ( x i , x i +1 , . . . , x n ) , with t x n  X  t t
Now we are ready to formally define the problem of real-time network fault detection and diagnosis: Problem Definition. For each time-window, by analyzing the events occurring within the window and exploiting net-work topological information, detect potential faults (if any) and identify the fault types and failed entities.
In this section, we describe in detail our method of dis-tilling the essential features of network faults manifested in
Without ambiguity, in the following we use  X  X ntity X  and  X  X ode X  interchangeably. network events and composing them into compact, index-able fault signatures. The signatures are designed to cap-ture two critical aspects of network phenomena, namely, the temporal evolution of fault-triggered events, and the topo-logical relationship of nodes associated with fault-triggered events. Furthermore, signatures are universal for a class of networks; that is, signatures learnt using data from one network instance can be used to diagnose faults in other network instances in the same class.

The feature learning process can be roughly divided into three phases. First, from the noisy historical data, we iden-tify event subsets that correspond to network faults (with high probability) to train our feature extractor. Second, we extract temporal patterns embedded in the training data by extending the classical expectation maximization (EM) framework. Third, we combine the discovered temporal pat-terns with the topological information available to form com-pact fault signatures that are amenable to efficient indexing and matching. The details of the three phases are presented in Section 3.1, 3.2, and 3.3, respectively.
For the purposes of training fault signatures, it is nec-essary to separate events caused by faults and those trig-gered by regular network operations. In Meta , this step is achieved by applying three filters, interval filter, support fil-ter, and periodicity filter to events generated by each node . Interval Filter Typically, the operational events caused by network faults occur in  X  X ursts X . The interval filter segments the event se-quence generated by each node into a series of X  X vent bursts X . Definition 5 ( Event Burst) . An event burst is an or-dered sequence of events wherein two successive events are separated by no more than  X  time units.

As will be discussed in Section 5, an appropriate value for the parameter  X  (typically a few milliseconds for communica-tion networks) can be obtained by analyzing the distribution of inter-arrival time of events in a historical dataset. Since events in a burst occur within a very small time window, we arbitrarily define the timestamp of an event burst as the timestamp of its first event.
 Support Filter Given a set of event bursts B generated by a node, support filter treats each burst s  X  B as a set and ignores the tem-poral ordering of events. Without ambiguity, we use s to denote both the event burst and its corresponding event set. We have the following definition.
 Definition 6 ( Support) . Given a set of event bursts B , the support of an event set s , sup ( s ) , is the number of bursts in B with event sets identical to s .

To make implementation resilient against noise, we con-sider two event sets s i and s j identical if their Jaccard sim-
Support filter separates fault-triggered and regular event bursts at a node by exploiting differences in their support. Specifically, it selects the subset of bursts in B with support within a range [  X  ,  X  ], since event sets with extremely low support are usually the noise component while over-frequent event sets typically correspond to regular network operations occurring at the node.
 Periodicity Filter The goal of the periodicity filter is to further reject event sets that occur periodically 4 since periodic event sets typically correspond to regular network operations, e.g., heartbeat messages.
 Definition 7 ( Periodicity) . Let t s 0 , . . . , t s k be the times-tamps when the event set s occurs, and d s i = t s i  X  t s the interval between the ( i  X  1) -th and i -th occurrences. The periodicity of s , prd ( s ) , is defined as the relative standard deviation of intervals: where d s = P k i =1 d s i /k denotes the average interval. We reject an event set s if prd ( s ) &lt;  X  .
Taking the event bursts B at a node (after the filtering of the first phase as input), this phase utilizes Markov chains to model B and produces a set of chains MC as the summariza-tion of event bursts at a node. Markovian properties have been verified to be common in network operational events, e.g., [16, 19]. However, note that while we use Markov chains to model event bursts, we do not claim its optimality. It is worth emphasizing that our framework is flexible enough to support many other models (see Section 7) that can be used to summarize events at a node.

We adopt a mixture model that contains multiple Markov chains MC = { c k } K k =1 . We assume that each event burst is independently generated by one specific chain. Each chain c  X  MC describes one type of sequential behaviors; thus, the mixture model is able to capture diverse behaviors em-bedded in event bursts.

Now we proceed to describing the structure of the mixture model. Without ambiguity, let B represent the collection of event bursts after initial filtering, and let  X  = { e i represent the event types that appear in B . All chains in MC share the same structure: in a chain c k , for each event e  X   X , there is a corresponding state o k,i ; each state o k,i is associated with an initial probability  X  I k,i , indicating the probability that a burst starts with e i ; each state o k,i transit to all other states o k,j (including to the state o itself) with certain transition probability  X  T k,i,j ; there is a
A failed entity may also periodically generate failure events (e.g., syslog messages, ping fails, etc.); however, the NMS eliminates such duplicate failure events from the event stream using a standard process known as de-duplication before passing them to the diagnosis engine. special ending state o k, 0 for which all transition probabilities are zero. In the mixture model, each chain c k is associated with a prior probability  X  k , which satisfies P K k =1  X  the parameter space of this mixture model is represented as  X  = (  X , {  X  I k ,  X  T k } K k =1 ). Given an event burst s = ( e the likelihood that chain c k generates s is given by: Meanwhile, the posterior probability that c k generated s can be calculated as: The optimal setting of the parameters  X  and the number of chains K remain to be determined. In the following, we first discuss how to determine  X  that maximizes the posterior probability of the given set of event bursts. Let where prob (  X  ) is a prior distribution over  X  and like ( B|  X  ) represents the likelihood of observing the whole set of event bursts B under this model: Q s  X  X   X  P K k =1  X  k like ( s | c Unfortunately, no closed-form solutions exist for such max-ima. Here, as sketched in Algorithm 1, an expectation maxi-mization (EM) [7] algorithm can be used to iteratively search for the maxima (in the pseudo code below, Q denotes the ob-jective function over the posterior distribution using current parameter estimation  X  old ).

Now, we discuss how to set K . Essentially, by controlling the number of chains, K determines the complexity of the mixture model. Here, we apply the Akaike X  X  information criterion [3, 16] to select K . Specifically, the information criterion of the mixture model is given by: aic (  X  ) = 2 |  X  | -2 log[ like ( B|  X  )], where |  X  | is the number of parameters to be estimated. The setting of K leading to a minimum aic (  X  ) is considered as optimal.
A novel feature that significantly distinguishes Meta from existing solutions lies in its incorporation of network topol-ogy information in learning and matching faults. In this paper, we consider the following set of relationships, { self-ing, neighboring, containing/contained, down/up-streaming, tunneling } , with brief descriptions listed in Table 1. Note that the relationships down/up-streaming are referred from the perspective of the sink, i.e., u is at v  X  X  down-stream side if the route from the sink to u contains v . In the following, we use R = { SE, N E, CN/CD, DS/U S, T N } to denote this set of topological relationships. Each relationship r  X  X  is asso-ciated with an inverse counterpart  X  r , e.g.,  X  X own-streaming X  to  X  X p-streaming X ,  X  X ontained X  to  X  X ontaining X , etc. Given a node v , we refer to the set of network nodes with a specific relationship r to v as a topo-set , denoted by N r ( v ).
Intuitively, we construct our fault signature based on the following two fundamental observations. (1) Typically, when a fault occurs at a root-cause node u , symptom events may be triggered in affected nodes that are topologically related to u . (2) The triggered event burst at an affected node v differs depending on the topological relationship between u and v . For example, in an Internet Protocol (IP) network if v is a direct neighbor of u ( neighboring ), the failure of u may lead to the event burst of ( X  OSPF Interface Down  X ,  X  OSPF Neighbor Down  X ) at v ; while if u is on a tunnel with v as one end ( tunneling ), the failure of u may cause the event burst of ( X  Failed Connection Attempt  X ,  X  Open Tunnel Failure  X ) at v . Therefore, Definition 8 ( Fault Signature) . For a specific type of fault f , we define its signature sig ( f ) as a series of tuples is the probability of observing an event burst with temporal pattern c at an affected node that has the topological rela-tionship r with the root-cause node where the fault f occurs.
To learn fault signatures from historical data, we make the following assumptions: each event burst s  X  X  (observed at a node v ) has been classified into a Markov chain c v , and represented as a pair ( v, c v ); the number of fault types |F| is known and all faults are reflected in the historical data; the time-window size  X  is set as the maximum delay between observing the first and the last event bursts triggered by a single fault.

Algorithm 2 sketches our solution. (i) The event bursts B are first divided into subsets, each within a time-window less than  X  , i.e., the event bursts in the same subset are possibly triggered by a single fault. (ii) In every subset, for each involved node v , one identifies the topological relationship r that leads to the minimum non-empty intersection of all the topo-sets, i.e., the set of candidate causes. Note that the principle of minimum explanation is applied here. (iii) All the tuples h v, r  X  v , c v i in a subset B i are then used to compute a potential signature S i (a |R| X |MC| matrix). (iv) A K -means (with K = |F| ) clustering algorithm is applied to the set { S i } ; the centers of the clusters are regarded as the signatures for the |F| faults.
The online matching component of Meta attempts to de-tect and localize faults as follows: (1) the incoming events are aggregated into event bursts, and for each burst s occur-ring at an affect node v , the probability prob ( c | s ) is calcu-lated for all c  X  X C ; (2) topologically-aware fault signatures are used to compute the probability prob ( f |  X  r, v  X  s ) that the faulty node incurred the fault f and has a topological relationship r to the affected node v . If this probability is greater than a certain threshold, then h f, v,  X  r i is termed an evidence that points to the set of all nodes with relationship r to v as the set containing the faulty node; (3) all collected evidences within a short time window are used to narrow down the set of nodes that include the faulty node.
We need four main data structures to accomplish the on-line matching: a buffer for aggregating incoming events into event bursts and to compute probability of a temporal model generating an event burst; an index of fault signatures to compute evidences; and an index of network topological de-pendency and a signature matching tree to enable efficient fault localization. Due to the space constraint, we will only describe the latter three data structures.
To support efficient model-to-fault lookup, we devise an inverted fault signature structure I s which maintains the association between models and possible faults. Recall that the signature of a fault f is a series of tuples of the form {h c, r, prob ( c | f, r ) i} c  X  X C , where c and r represent a chain and a topological relationship, respectively, and prob ( c | f, r ) is the probability of observing c at a node with topological relationship r to the faulty node. Corresponding to each sig-nature, we create an entry in I s : {h f,  X  r, prob ( f |  X  r, c ) i} where  X  r is the inverse relationship of r , and prob ( f |  X  r, c ) is the posterior probability that f occurs at a node with topo-logical relationship  X  r to a given node observing c . Its com-putation is given by: where the prior probability of the occurrence of f , prob ( f ), can be derived from the overall statistics of network faults.
Now, the posterior probability that a fault f occurs at certain node with relationship r to a node v which observes an event burst s can be calculated as follows: For each f and v (with event burst s ), we select the set of topological relationships R v that satisfies prob ( f |  X  r, v  X  s )  X   X  (  X  r  X  X  v ). We term such a triple h f, v, R v i as an evidence .
While the incorporation of network topological informa-tion significantly boosts the precision of fault diagnosis, such improvement incurs extra computation cost in terms of 1) storing the topological information, and 2) correlating event bursts according to their underlying topological relation-ships. Here, we introduce novel space-efficient indexing stru c-tures for topological correlation.
As will be shown Section 4.3, a key operation heavily in-volved in the fault localization is computing the intersection of two topo-sets, e.g., joining the down-streaming neighbors of one node and the direct neighbors of another; therefore, for each indexing structure, we are particularly interested in analyzing its storage demand and the cost of retrieving (constructing) a topo-set from it. Here, we assume network configurations to be static, and consider incremental main-tenance of indices for evolving networks as one direction for our further research. Due to space limitations, we focus our discussion on building indices for up/down-streaming and tunneling relationships.
 Up-Streaming/Down-Streaming A na  X   X ve solution that stores the up/down-streaming nei-ghbors for each network entity, results in O (1) retrieval cost and totally O ( |V| 2 ) storage cost. We construct our indexing structure based on the following two observations: (1) the shortest path routes from the sink to all the nodes form a spanning tree rooted at the sink, i.e., a tree cover of G [1]; (2) the diameter  X  of a typical management domain (as observed in four large enterprise networks) is about 3-7 hops. Therefore, in this setting, the set of up-streaming neighbors (utmost  X  ) of a node can be directly cached. We then traverse the routing tree in a level-order (breadth-first) assigning each node a traversal-order number. The down-streaming neighbors of a given node u can be summarized as  X  intervals, { [ l i , r i ] }  X  i =1 , where l i ( r i number of its left-most (right-most) descendent on the i th level below u (see example in Figure 2).

Clearly, this indexing structure requires O ( |  X  V| ) space; maintaining a mapping (sorted on traversal-order number) that projects traversal-order numbers to node-identifiers, th is scheme achieves retrieval cost of O (  X  ), since the neighbors on the same level can be retrieved in one consecutive chunk. Tunneling For tunneling relationship, we are interested in retrieving the set of nodes on tunnels with a given node u as one end, or, reformulated as: given two nodes u and v , what set of nodes are on the tunnel (if any) connecting u and v ?
Without loss of generality, we assume that all the tunnels follow approximately shortest paths (e.g., OSPF and IGP routing [10]); hence, the problem is cast as indexing a set of shortest paths. Our solution is constructed atop the notion of hop cover of a collection of paths [5].
 Definition 9 ( Hop/Hop Cover) . Let G = ( V , E ) be a graph and P be the set of shortest paths we intend to in-dex. A hop is a tuple ( p, u ) , where p is a shortest path with u as one end. A collection of hops H is said to be a hop cover of P if for any P  X  P , there is a subset of H such that P is a concatenation of these hops.

We construct the collection of hops as follows: starting from an arbitrary path P 1  X  P , we incrementally add in paths P 2 , P 3 , . . . from P ; the intersected segments between P i and previous ones P 1 , . . . , P i  X  1 break paths into disjoint hops, or divide existing hops into smaller ones; we collect the set of hops after inserting all paths of P as H . A moment of reflection shows that (1) two paths can have at most one intersected segment and (2) the set of hops are invariant of the insertion order of paths.

Within this setting, the space-time tradeoff is achieved by caching a subset of H and leaving uncached hops to online computation; therefore, we are interested in selecting the optimal subset H  X   X  H that leads to the minimum over-all cost as follows. For a hop h , let len ( h ) be its length and sup ( h ) be the number of paths in P that contain h as a com-ponent. For simplicity, we model storage cost cost space ( h ) =  X  len ( h ) and computation cost cost time ( h ) =  X  len ( h ). Assuming that all the paths are queries with equivalent fre-quency, the overall cost of caching a subset H  X  of H can be modeled as: cost ( H  X  ) = P h  X  X   X  cost space ( h ) + P sup ( h ) cost time ( h ); and the optimal subset H  X  leads to the minimum overall cost: H  X  = arg min H  X  cost ( H  X  ). Clearly, in this model, a hop h should be cached if and only if its storage cost exceeds its computation cost with respect to all the paths, formally: cost space ( h ) &gt; sup ( h ) cost
With the help of the network topology index, in each ev-idence h f, v, R v i , ( v, R v ) can be replaced with the corre-sponding topo-sets S r  X  X  vant if (1) f = f  X  , (2) N R u ( u )  X  X  R v ( v ) 6 =  X  , and (3) they are within a time-window of size  X  . This concept can be generalized to multiple evidences.

While it is straightforward to check conditions (1) and (3), computing the intersection of N R u ( u ) and N R v ( v ) is expen-sive: even if both sets are stored in a hash-table, the com-the na  X   X ve pair-wise comparison paradigm, each incoming ev-idence is compared with all existing ones to detect relevance, and thus scales poorly with the network event rate.
We devise a novel structure, signature matching tree T s , which enables efficient correlation of relevant evidences. Our design follows the one-pass clustering philosophy, [11, 25], which endows T s with high throughput and scalability.
T s is a hierarchical structure, with the highest level con-taining |F| buckets, each corresponding to one fault f  X  X  . Within each bucket is a height-balanced tree T f s , into which evidences of the form h f, N R v ( v ) i are inserted. Each leaf of s corresponds to a cluster of relevant evidences; each non-leaf represents the union of all the clusters in its subtree.
For each leaf (cluster) C containing a set of evidences, we maintain the intersection of their topo-sets, called its ag-gregation,  X  ( C ) = T h f, N (super cluster) SC , we maintain the union of the aggrega-tions of the clusters in its subtree,  X  ( SC ) = S C  X  SC
The signature matching tree supports two basic opera-tions, insertion and deletion. In an insertion operation, a newly coming evidence h f, N R v ( v ) i recursively descends down T f s by testing N R v ( v )  X   X  ( SC ) for each non-leaf SC encountered, until being clustered into an appropriate leaf that can absorb it; if no such leaf exists, a new one is cre-ated which solely contains this evidence; it then updates the aggregations of the nodes on the path from the leaf to the root of T f s . Those evidences with timestamps out of the cur-rent time-window are considered as expired. In a deletion operation, expired evidences are removed from the tree, and the aggregations of the nodes on the paths from the affected leaves to the root are updated in a bottom-up manner.
Two expensive operations involved in the signature match-ing tree are (1) testing the intersection of the topo-sets of an evidence and the aggregation of a (non-)leaf, and (2) up-dating the aggregations of the affected (non-)leaves when deleting expired evidences. Here, we introduce two-folded optimizations to ameliorate these two operations.
 Filtering-and-Refining Instead of performing direct comparison of two sets, we fol-low a filtering-then-refining paradigm: in the filtering phase, we perform fast check to determine if the intersection is non-empty, which may contain false positive results, but no false negative ones; in the refining phase, we make the real comparison. To this end, for each evidence h f, N R v ( v ) i , we maintain its bloom filter encoding, bf [ N R v ( v )]; for each leaf C , we maintain the bloom filter encoding of its aggrega-tion, bf [  X  ( C )]; while for each non-leaf SC , a counting fil-ter [8] encoding (to support efficient update) of its aggrega-tion, cf [  X  ( SC )], is maintained. Therefore, the intersection of N
R v ( v ) and  X  ( SC ) (or  X  ( C )) can be easily pre-tested using Slotted-Aggregations To ameliorate the impact of frequent deletions of expired ev-idences over updating the aggregations of (non-)leaves, we introduce the slotted-aggregates mechanism [2]. Assuming that the sliding window size is  X  , a slot cache maintains the aggregations in m slots, the i th slot corresponding to the ev-idences with timestamp falling in the i th sub-window of size  X /m time units. Now, the deletion of expired evidence af-fects at most one slot, and the aggregations in all remaining slots can be reused.
This section presents an empirical evaluation of Meta by using it in the context of communication networks. The experiments are specifically designed to center around the following metrics: (1) the efficacy of the signature model in capturing real network-faults, (2) the effectiveness of online matching in detecting and localizing network faults, and (3) its space and time complexity. We start with describing the datasets and the setup of the experiments.

We used two datasets collected from real-life communica-tion networks to evaluate the learning and matching com-ponents of Meta . The first dataset is an archive of SNMP (Simple Network Management Protocol) trap messages col-lected from a large enterprise network (7 ASes, 32 IGP net-works, 871 subnets, 1,268 VPN tunnels, 2,068 main nodes, 18,747 interfaces and 192,000 entities) over several days in 2007; this dataset is used to extract fault signatures. Event attributes of interest to us are listed in Table 2. The second dataset is a European backbone network consisting of 2,383 network nodes (spans 7 countries, 11 ASes and over 100,000 entities). We generate a synthetic event stream for this net-work (with tuneable failure rate) to quantify the efficacy and scalability of the online matching component.
 A majority of the algorithms are implemented using Java. All the experiments are conducted on a Linux workstation running 1.6GHz Pentium IV and 1G memory.
In this set of experiments, we studied the effectiveness of our methodology in all three phases of the learning com-ponent of Meta : preparation of training data, modeling of event bursts, and incorporation of topological information. Preparing Training Data The first set of experiments studied the distribution of times-tamp intervals, frequency, and periodicity of event sets to demonstrate the effectiveness of interval filter, support fil-ter, and periodicity filter, respectively.

The left plot in Figure 3 illustrates the impact of inter-val size  X  on the average length of event bursts. It is clear that the average length increases significantly as the interval grows, e.g., 50 events for  X  = 8ms; meanwhile, a wider inter-val also enlarges the length deviation of the event bursts. We are interested in an optimal setting of  X  that filters spurious event bursts. In our implementation, we used the following heuristic: in the cumulative distribution function (CDF) of intervals, find the interval value with the largest derivate, i.e., the one resulting in the most significant change of the number of event bursts. For example, in the CDF plotted in Figure 3, we selected  X  = 1ms as the optimal setting.
The normalized histogram of event sets with respect to support (in log scale) is depicted in the center plot of Fig-ure 3, which approximately follows a power law distribution. It is observe that more than 60% event sets have fairly low support, e.g., below 5, which, as we confirmed by examining the definition of traps, are mainly caused by infrequent net-work operations, e.g., the event set { 3 } represents  X  X he cisco NetReg server has started on the host from which this no-tification is sent X , or certain non-recurrent faults, which are of modest interest for our purposes of leveraging existing di-agnosis efforts. Meanwhile, the event sets with significantly higher support than others are typically due to regular net-work operations, e.g., the event set { 102, 104 } which ap-pears with support 348 indicates  X  X ata from the remote side is available for the TDM channel X .
The distribution of the periodicity of event sets is illus-trated in the right plot of Figure 3. Observe that most of the event sets demonstrate low deviation of occurrence inter-vals, i.e., they are resulted from normal network operations. We randomly selected two event sets { 28, 102, 104, 130 } and { 79, 124 } with periodicity 0.43, and 1.09 (lower peri-odicity  X  more regular), respectively, and examined their implications. Figure 4 compares their occurrences. From the descriptions of the traps as shown in Table 3, it is con-firmed that the event set { 79, 124 } indicates potential net-work faults, while the event set { 28, 102, 104, 130 } is caused by regular network operations, e.g., link mode sniffing. Modeling of Event Bursts We verified the Markovian assumption on event bursts using the event burst length histogram metric. More specifically, by running Monte Carlo simulation, we derived the histogram of event burst length from the learned Markov model, and compared it against that extracted from the real data.
The upper plot of Figure 5 illustrates the comparison of these two histograms (normalization is applied). It is clear that the distribution of the model-generated data fits that of the underlying data fairly tightly. Furthermore, we analyzed the distribution of individual events for real data and model generated data, respectively. As shown in the lower plot of Figure 5, these two distributions demonstrate strong consis-tency, which empirically proves that our learning model can capture the essential features of the real data.
 Incorporation of Topological Dependency Now, we proceed to verifying the imperative need of incor-porating topologically correlated nodes in detecting and lo-calizing network faults. Figure 6 illustrates the fractions of fault-triggered events reported at network nodes in different categories: the fault node itself (SE), and nodes with spe-Figure 5: Histograms of lengths of event bursts and indi-vidual events in real event data and model generated data. Figure 6: Fractions of fault-triggered events reported at fault nodes (SE) and nodes with specific relationships to fault ones (NE, DS, US, TN) in four real enterprise net-works. The network sizes are listed as follows. Enterprise 1: 2514 nodes, Enterprise 2: 3200 nodes, Enterprise 3: 141 nodes, Enterprise 4: 12,444 nodes. cific relationships (neighboring -NE, down-streaming -DS, up-streaming -US, and tunneling -TN) to the fault one us-ing event data collected from real enterprise networks. Note that Enterprise 3 is a small-scale network where no VPN tunnels are deployed. Observe that the fault node itself re-ports only 18-29% of overall events, while those topologically correlated nodes take up to an overwhelming 71-82%.
In evaluating the online matching component of Meta , we first generate synthetic event data for a European back-bone network using the features of the real-life event data extracted in the previous phase, including 1) the temporal models for generating event bursts as symptoms of network faults, 2) the topological correlations for selecting the net-work entities where the symptoms will be observed, 3) the frequencies of individual events (type), and 4) the frequen-cies and periodicities of event sets. By controlling failure rates, we simulate network environments under both well-regulated and unstable conditions. The setting of major parameters is listed in Table 4.
 Table 4: Setting of parameters for synthesizing network event data.
 Accuracy of Fault Diagnosis This set of experiments evaluated the effectiveness of the Meta framework in detecting potential network faults by analyzing streaming network event data. We aim at achiev-ing fault detection and localization in a unified framework; therefore, we consider that a fault is successfully diagnosed only if the fault type is correctly determined and the fault node is localized with sufficient accuracy (in our implemen-tation, we require that for every detected fault, the system suggest no more than D potential fault nodes (candidate size)). We refer to a successfully diagnosed fault as a hit . Viewing fault diagnosis as an information retrieval task, we measure the exactness and completeness of fault diagnosis using precision and recall . Formally, precision =
Moreover, we measured the impact of topological informa-tion on fault diagnosis. We construct a baseline approach that is agnostic to topology information as follows: it has ac-cess to complete knowledge associating network faults with the observed symptoms, but has no possession of topolog-ical information. Given a symptom, the baseline approach attempts to identify the minimum set of faults that may trigger these symptoms; we regard it as a hit if the fault type suggested by the baseline approach is correct.
We measured the performance of Meta and the baseline approach under varying configuration of fault occurrence rate and topological correlations. The fault occurrence rate indicates the frequency of network faults (resulting in ab-normal event bursts) relative to regular network operations (leading to normal event bursts); the configuration of topo-logical correlation refers to the fractions of fault-triggered events observed at nodes with various topological relation-ships to the faulty node, e.g., SE, NE, DS, US, etc. Here, we adopt four different configurations as observed in real enterprise networks (shown in Figure 6).

Figure 7 compares the accuracy of fault diagnosis by Meta and the baseline approach. We make the following observa-tions: (1) Meta achieves steady precision and recall scores under all the four configurations; the accuracy of the baseline approach is strongly correlated with the fraction of SE (fault node itself) events  X  even under configuration 3 (29% SE events), its recall (0.6) is substantially lower that of Meta (0.85). (2) The recall of Meta increases significantly as we increase D , for example, under configuration 2, the recall score of Meta grows from 0.65 to 0.84 as the candidate size D varies from 3 to 7. (3) The precision of Meta also in-creases as the candidate size D grows, which at the first glance may seem to contradict the inverse relationship be-tween precision and recall typically observed in information retrieval systems; however, this can be explained by the fact Figure 8: Average processing time (ns) per event with re-spect to fault occurrence rate, where opt 1 and opt 2 refer to the filtering-then-refining and the slotted aggregation strate-gies, respectively. that a larger D essentially provides more leeway in identify-ing the fault node.
 Efficiency of Execution This set of experiments are designed to measure the scalabil-ity of the fault diagnosis in Meta . Specifically, we evaluate the average processing time of each incoming event, under varying condition of fault occurrence rate, with and without the multi-folded optimizations introduced in Section 4.3.2. Here, the fault occurrence rate refers to the fraction of event bursts caused by network faults.

Figure 8 shows the average processing time per event by three variants of Meta (the basic version, the one with the filtering-then-refining strategy, and the one with both opti-mization strategies) as the fault occurrence rate varies. We can obtain the following observations. (i) The processing cost of the basic Meta grows approximately linearly with the fault rate. (ii) The multi-folded optimizations signifi-cantly boost system performance, and the processing cost of both optimized variants of Meta manifest sub-linear growth rate with respect to the fault rate. (iii) The cost saving achieved by the optimization strategies demonstrates an in-creasing trend as the fault occurrence rate grows, which can be explained by the fact that a higher fault rate results in a greater number of evidences being fed to the diagnosis engine, thus resulting in superior performance gains.
For anomaly detection, a plethora of work has been done that uses analysis of low-level metric data, e.g., traffic or routing data, for anomaly detection. For example, in [9], BGP update messages are clustered along three dimensions, time, prefix, and views to detect network disruptions; in [14, 12], multivariate analysis is applied to model normal network traffic and detect deviations; in [24], a wavelet-based cluster-ing algorithm is used to detect abnormal routing behavior. Nevertheless, targeting static analysis of low level metric data, these techniques are not suitable for real-time analysis of high-level event stream. Meanwhile, anomaly detection using historical data has also been an important topic for computing systems in general [6, 23], whose application to networked systems, however, is not clear.

Another line of research is specifically dedicated to fault localization from a set of observations or symptoms (de-tailed survey in [20]). The existing solutions can be cat-egorized roughly as expert-system techniques and graph-theoretic techniques. The first category of approaches at-tempt to imitate the knowledge of domain experts, with ex-amples including rule-based systems, e.g., [21], cased-based systems, e.g., [15], and model-based systems, e.g., [17]. The graph-theoretic techniques rely on a graphical model of the system, which describes the propagation for each specific fault, with examples including dependency graph [13], code-book technique [22], and belief-network [18]. These tech-niques suffer from two main drawbacks: first, they require accurate dependency information amongst network entities, which is usually not available for large scale enterprise net-works; second, fault inference typically involves complicated computation and scales poorly with network size and com-plexity. In contrast, our approach only requires elemen-tary topological information and fault signatures to support matching over high-volume event data.
To the best of our knowledge, this work presents the first  X  X etwork-aware X  X ignatures or patterns that incorporate topo-logical relationships of nodes participating in a network phe-nomenon in conjunction with temporal evolution of events. Extensive experiments using data from communication net-works demonstrate multiple benefits of  X  X etwork-aware X  sig-natures including a linear computational complexity algo-rithm for real-time detection.

This work also opens up several directions for further re-search: 1) incorporation of domain knowledge in training fault signatures; 2) exploration of alternative models of tem-poral evolution, e.g., hidden Markov chains, frequent item-sets; 3) search for data structures that can be incrementally adapted as network evolves; and 4) incorporation of a richer set of topological relationships derived from multi-layer net-works, e.g., mining information diffusion or providing risk-aware access-control in socio-information networks. The authors would like to thank Matthew Duggan (Prin-ciple Software Engineer, IBM Software Group) for over-all guidance and domain expertise, Venkateshwara Madduri and Dipyaman Banerjee (IBM Research) for the network fault simulator, Dr. Charu Aggarwal (IBM Research) for in depth technical discussions, Dr. Kristian Stewart (Manager, IBM Software Group) for the event datasets, Dr. William Berriss (Tivoli Software Engineer, IBM Software Group) for the topology datasets, Daniel Martin (Tivoli Solutions Ar-chitect, IBM Software Group) for introducing the commu-nication networks problem, and Dr. Dinesh Verma (Senior Manager, IBM Research) and Dr. Matthew Ellis (Vice Pres-ident, IBM Sales and Distribution) for supporting this re-search effort. The first and last authors are partially spon-sored by grants from NSF CyberTrust, IBM Faculty Award, and IBM SUR program.
