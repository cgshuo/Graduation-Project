 Like many purely data-driven machine learning methods, Support Vector Machine (SVM) classifiers are learned exclu-sively from the evidence presented in the training dataset; thus a larger training dataset is required for better perfor-mance. In some applications, there might be human knowl-edge available that, in principle, could compensate for the lack of data. In this paper, we propose a simple general-ization of SVM: Weighted Margin SVM (WMSVMs) that permits the incorporation of prior knowledge. We show that Sequential Minimal Optimization can be used in train-ing WMSVM. We discuss the issues of incorporating prior knowledge using this rather general formulation. The exper-imental results show that the proposed methods of incorpo-rating prior knowledge is effective.
 I.2.6 [ Artificial Intelligence ]: Learning; I.5.4 [ Pattern Recognition ]: Design Methodology X  classifier design and evaluation Algorithms,Performance Text Categorization, Support Vector Machines, Incorporat-ing Prior Knowledge
Support Vector Machines (SVM) have been successfully applied in many real-world applications. However, little  X  (Produces the permission block, copyright information and page numbering). For use with ACM PROC ARTICLE-SP.CLS V2.6SP. Supported by ACM.
 work [4, 14] has been done to incorporate prior knowledge into SVMs. Sch  X  olkopf [14] showed that the prior knowledge can be incorporated with the appropriate kernel function, and Fung [4] showed prior knowledge in the form of mul-tiple polyhedral sets can be used with a reformulation of SVM. In this paper, we describe a generalization of SVM that allows for incorporating prior knowledge of any form, as long as it can be used to estimate the conditional in-class probabilities. The proposed Weighted Margin Support Vector Machine (WMSVM) can generalize on imperfectly labeled training dataset because each pattern in the dataset associates not only with a category label but also a con-fidence value that varies from 0.0 to 1.0. The confidence value measures the strength of the corresponding label. This paper provides the geometrical motivations for generalized WMSVM formulation, its primary and dual problem, and a modification of Sequential Minimum Optimization (SMO) training algorithm for WMSVM. We can then incorporate the prior human knowledge through generating the  X  X seudo training dataset X  from an unlabeled dataset, using the es-timation of conditional probability P ( y | x ) over the possible label values { -1,+1 } as the confidence value.

In this paper we use text classification as a running exam-ple not only because empirical studies [7, 18] suggest SVM is well suited for the application and often produces better results, but also because the keyword based prior knowledge is easy to obtain [13] in the text domain. For example, it is intuitive that words like  X  X BA X  are indicative of sports category. Therefore it is of interest to see whether the abil-ity of incorporating fuzzy prior knowledge can offer further improvement over this already highly effective method.
The rest of this paper is structured as follows. We intro-duce related work in section 2. Section 3 discusses the gen-eralized WMSVM, its geometrical motivation, formulation, primary and dual optimization problem. Section 4 briefly describes how to use the modified SMO for WMSVM train-ing. The general issues faced when combining the true train-ing dataset and pseudo training dataset are analyzed in the section 5. In Section 6, we present experimental results on a popular text categorization dataset. We conclude in Section 7 with some discussion of potential use of WMSVMs.
Most machine learning methods are statistical based. They are usually considered as data-driven methods, since pre-diction models are generalized from some labeled training datasets. Different learning methods usually use different hypothesis space, and thus can result in different perfor-mance on the same application. The common theme how-ever is that an adequate number of labeled training exam-ples is required to guarantee the performance of generalized model, and the more labeled training data the better the performance.

However, labeling the data is usually time consuming and expensive and therefore having enough labeled training data is rare in many real-world applications. The lack of labeled data has been addressed in many recent studies [15, 1, 8, 3, 13]. To reduce the need for the labeled data, these studies are usually conducted on a learning problem that is slightly different from the standard settings. For example, while the training set is chosen to be a random sampling of instances, in active learning [15], the learner can actively choose the training data. By always picking the most informative data points to be labeled, it is hoped that the learner X  X  need for large quantities of labeled data can be reduced. This pa-per is, however, developed based on the following two ap-proaches: learning with prior knowledge and transductive learning.

In some applications, while labeled data can be limited, there may be human knowledge that might compensate for the lack of labeled data. Schapiro et al. showed in [13] that logistic regression can be modified to allow the incor-poration of prior human knowledge. Note that although the training method is a boosting style algorithm, the modi-fied logistic regression can also be trained by other methods such as Gauss-Seidel [5]. In their approach, rough prior hu-man knowledge is represented as a prediction rule  X  that maps each instance x to an estimated conditional probabil-ity distribution  X  ( y | x ) over the possible label values Given this prior model and training data, they seek a lo-gistic model  X  ( x ) that fits not only the labeled data but also the prior model. They measure the fit to the data by log conditional likelihood, the fit to the prior model by the relative entropy(Kullback-Leibler divergence). Let  X  + =  X  ( y =+1 | x ), the objective function for the modified logistic regression is given: X where RE (  X  ) is the binary relative entropy, and  X  is used to control the relative importance of two terms in the objec-tive function. While using the relative entropy to measure the fit to the prior model is a natural solution for the logis-tic model, it is not applicable to SVM since the prediction model generalized by SVM is discriminant in nature.
Transductive learning was first introduced in [16]. In [1, 8], transductive support vector machine was proposed and its application in text categorization was demonstrated. The difference between the standard SVM and transductive SVM is whether the unlabeled test set is used in the training stage. In particular, the position information of unlabeled test set is used by transductive SVM to decide the decision hyperplane. Transductive SVM is depicted in figure 1. Pos-itive/negative examples are marked as +/-, test examples as circles. The dashed line is the solution of the standard SVM. The solid line shows the transductive classification. The problem of transductive SVM is that its training is much more difficult. For example, integer programming was used in [1], and an iterative method with one SVM training on each step was used in [8]. Although the exact time complex-ity analysis for these training algorithms are not available, the general impression is that they are significantly slower than the standard SVM training.
We now describe some notations and definitions from which we developed weighted margin support vector machines. Given a set of vectors ( x 1 ,...,x n ), along with their corresponding labels ( y 1 ,...,y n )where y i  X  X  +1 ,  X  1 } , the SVM classifier defines a hyperplane ( w,b ) in kernel mapped feature space that separates the training data by a maximal margin.
Definition 1. We define the functional margin of a sam-ple ( x i ,y i ) with respect to a hyperplane ( w,b ) to be y x i + b ) . We define the geometric margin of a sample ( x i with respect to a hyperplane ( w,b ) to be y i ( w  X  x i + b ) / w where w 2 is the L 2 norm of w . Furthermore, we define the geometric margin of a set of ( x i ,y i ) with respect to a hy-perplane ( w,b ) to be the quantity of min 0  X  i&lt;n ( y b ) / w 2 ) .

The maximum margin hyperplane for a training set S is the hyperplane with respect to which the training set has maximal margin over all hyperplanes defined in the fea-ture space. Typically the maximum margin hyperplane is pursued by fixing the functional margin of the training set to be 1 and minimizing the norm of the weight vector w . Those samples with minimum geometric margin with re-spect to maximum margin hyperplane are called support vectors because the maximum margin hyperplane is sup-ported by these vectors: deleting support vectors will result in different maximum margin hyperplane.
We consider the problem settings where, besides the vec-tors ( x 1 ,...,x n ) and their corresponding labels ( y 1 we also have confidence values ( v 1 ,...,v n ). Each v i v  X  (0 , 1], indicates the confidence level of y i  X  X  labeling. In-tuitively, the larger the confidence we have on a label, the larger the margin we want to have on that sample. But in the standard SVM, there is no provision for this confidence valuetobeuseful. ThedifferencebetweentheWMSVMand SVM is illustrated in figure 2. There, positive examples are depicted as circles and negative examples squares. The size of the squares/circles represents their associated confidence value. The dashed line in the middle is the hyperplane de-rived based on the standard SVM training, and the solid line is the solution to the transductive SVM learning.
Definition 2. We define the effective weighted functional margin of weighted sample ( x i ,y i ,v i ) withrespecttoahy-perplane ( w,b ) and a margin normalization function f to be f ( v i ) y i ( w  X  x i + b ) ,where f is a monotonically decreasing function.
The simplest model of support vector machine is the max-imal hard margin classifier. It only works on a data set that is linearly separable in feature space thus, it can not be used in many real-world situations. But it is the easiest algorithm to understand, and it forms the foundation for more com-plex Support Vector Machines. In this subsection, we will generalize this basic form of Support Vector Machines so that it can be used on fuzzy truthing data.

When each label is associates with a confidence value, in-tuitively one wants support vectors that are labeled with higher confidence to assert more force on the decision plane, or equivalently one wants those support vectors to have big-ger geometric margin to the decision plane. So, to train a maximal weighted hard margin classifier, we fix the effective weighted functional margin instead of fixing the functional margin of support vectors. Then we try to minimize the norm of weight vector. We thus have the following proposi-tion.

Proposition 1. Given a linearly separable (in feature space if kernel function is used) training sample set the hyperplane ( w,b ) that solves the following optimization problem realizes the maximal weighted hard margin hyperplane, where f is a monotonically decreasing function such that f (  X  ) (0 , 1] .

The corresponding dual optimization problem can be found by differentiating the primal Lagrangian with respect to w and b , imposing stationarity:
Proposition 2. Given a linearly separable (in feature space if kernel function is used) training sample set and suppose the parameters  X   X  solve the following optimiza-tion problem maximize W (  X  )= subject to then the weight vector w  X  = maximal weighted hard margin hyperplane.
 The value of b does not appear in the dual problem so b  X  must be found in the primal constraints: Where The Karush-Kuhn-Tucker condition states that optimal so-lutions  X   X  ,( w  X  ,b  X  )mustsatisfy This condition implies that only inputs x i for which the functional margin is f  X  1 ( v i ) have their corresponding  X  non-zero. These are the support vectors in the WMSVM. All other training samples will have their  X   X  i equal to zero. In the final expression of weight vector w  X  , only these support vectors will be needed. Thus we have decision plane h ( x ): h ( x,a  X  ,b  X  )= w  X   X  x + b  X  =
The hard maximal margin classifier is an important con-cept, but it has two problems. First, hard margin classifier can be very brittle, since any labeling mistake on support vectors will result in significant change in decision hyper-plane. Second, training data is not always linearly separa-ble, and when it is not, we are forced to use a more powerful kernel, which might result in over-fitting. To be able to tol-erate noise and outliers, we need to take into consideration the positions of more training samples than just those clos-est to the boundary. This is done generally by introducing slack variables and soft margin classifier.

Definition 3. Given a value  X &gt; 0 , we define the mar-gin slack variable of a sample ( x i ,y i ) with respect to the hyperplane ( w,b ) and target margin  X  to be
This quantity measures how much a point fails to have a margin of  X  from the hyperplane ( w,b ). If  X  i &gt; 0, then x i is misclassified by ( w,b ). As a more robust measure of margin distribution, which the training set fails to have margin  X  ,andittakes into account any misclassification of the training data. The soft margin classifier is typically the solution that minimizes the regularized norm of w  X  w + C the soft margin classifier to weighted soft margin classifier, we first define a weighted version of slack variable.
Definition 4. Given a value  X &gt; 0 ,wedefinetheeffec-tive weighted margin slack variable of a sample ( x i ,y i with respect to the hyperplane ( w,b ) and margin normaliza-tion function f , slack normalization function g and target margin  X  as i = g ( v i )max(0 , X  where f is a monotonically decreasing function such that f (  X  )  X  (0 , 1] , g is a monotonically increasing function.
The primal optimization problem of maximal weighted soft margin classifier can thus be formulated as: Proposition 3. Given a training sample set the hyperplane ( w,b ) that solves the following optimization problem minimize : w  X  w + C subject to : y i ( w  X  x i + b ) f ( v i )  X  1  X   X  i ,i =1 , realizes the maximal weighted soft margin hyperplane, where f is a monotonically decreasing function such that f (  X  ) (0 , 1] , g is a monotonically increasing function such that g (  X  )  X  (0 , 1] .
 Here the effective weighted margin slack variable is used to regulate w  X  w . This implies that the final decision plane will be more tolerant on these margin violating samples with low confidence than others. This is exactly what we want: samples with high confidence label to contribute more to final decision plane.

The corresponding dual optimization problem can be found by differentiating the corresponding Lagrangian with respect to w , b ,  X  i , imposing stationarity: Proposition 4. Given a training sample set and suppose the parameters  X   X  solve the following optimiza-tion problem maximize W (  X  )= subject to then the weight vector w  X  = maximal weighted soft margin hyperplane, where f is a mono-tonically decreasing function such that f (  X  )  X  (0 , 1] , g is a monotonically increasing function such that g (  X  )  X  (0 , 1] . Notice the dual objective function is curiously identical to that of the weighted hard margin case. The only difference is the constraint g ( v i ) C  X   X  i  X  0, where the first part of the constraint comes from the conjunction of Cg ( v i )  X   X  i and r i  X  0.

The KKT conditions in this case are therefore This implies that samples with non-zero slack can only oc-cur when  X  i = g ( v i ) C , they are bounded support vectors. Samples for which g ( v i ) C&gt; X  i &gt; 0 (unbounded support vectors) have an effective weighted margin of 1 / w from the hyperplane ( w  X  ,b  X  ). The threshold b  X  can be calculated in the same way as before. The h ( x ) will also have the same expression as before.
In [9], SVM with different misclassification costs is intro-duced to battle the imbalanced dataset where the number of negative examples is overwhelming. In particular, the primal optimization problem is given: Let m  X  1 , m +1 denote the number of negative and positive examples, and assume m  X  1  X  m +1 , one typically wants to have C +1  X  C  X  1 . This amounts to penalize more on an error made on positive example in training process.
Both WMSVM and SVM with different misclassification costforeachexamplecanresultinthesameboxconstraint for each  X  when we have C SV M i = C WMSVM i g ( v i ). However, there is some intrinsic difference between them. To see this, let C i = 0 for both formulations. As shown in Fig. 2, these two different formulations can result in different decision hy-perplanes. The difference between these two formulations is also readily revealed in their respective dual objective func-tions. For example, attempt to replace  X  i f ( v i )with  X  dual objective function for WMSVM results in which is different from that of standard SVM: .
The Sequential Minimal Optimization (SMO) algorithm is first proposed by Platt [12], and later enhanced by Keerthi [10]. It is essentially a decomposition method with work-ing set of two examples. The optimization problem can be solved analytically; thus SMO is one of the easiest optimiza-tion algorithms to implement. There are two basic compo-nents of SMO: analytical solution for two points and work-ing set selection heuristics. Since the selection heuristics in Keerthi X  X  improved SMO implementation can be easily mod-ified to work with WMSVM, only the analytical solution is briefly described here.

Assume that x 1 and x 2 are selected for current optimiza-tion step. To observe the linear constraint, the values of their multipliers (  X  1 , X  2 ) must lie on a line: y where a box constraint applies: g ( v 1 ) C  X   X  1  X  0 ,g ( v  X  2  X  0. A more restrictive constraint on the feasible value for  X  new 2 , U  X   X  new 2  X  V , can be derived by the box con-straint and linear equality constraint, where
U =max(0 ,  X  old 2 g ( v 2 )
V =min( g ( v 2 ) C, g if y 1 = y 2 ,and if y 1 = y 2 .

Let h ( x ) denote the decision hyperplane w  X  x + b repre-sented as difference between the function output and target classifica-tion on the training samples: then it is easy to prove the following theorem.

Theorem 1. The maximum of the objective function for the soft margin optimization problem, when only  X  1 , X  2 are allowed to change, is achieved by first computing the quantity  X  and then clipping it to enforce the constraint U  X   X  new,unc V : The value of  X  new 1 is obtained from  X  new 2 as follows:
The proposed Weighted Margin Support Vector Machine is a general formulation. It is useful for incorporating any confidence value attached to each instance in the training dataset. However, along with added generality, there are some issues which need to be addressed to make it practi-cal. For example, it is not clear from the formulation how to choose margin normalization function f and slack nor-malization function g . One also needs to determine the confidence value v i foreachexample. Inthissection,we will address these issues for the application of incorporating prior knowledge into SVM using WMSVM.

We propose a two-step approach. First, rough human prior knowledge is used to derive a rule  X  , which assigns each unlabeled pattern x a confidence value that indicates the likelihood of pattern x belonging to category of inter-est. A  X  X seudo training dataset X  is generated by applying these rules on a set of unlabeled documents. Second, the true training dataset and the pseudo training dataset are concatenated to form a training dataset, and a WMSVM classifier can then be trained from it.
In [4], Fung et al introduce a SVM formulation that can incorporate prior knowledge in the form of multiple poly-hedral sets. However, in practice, it is rare to have prior knowledge available in such closed function form. In gen-eral, human prior knowledge is fuzzy in nature, the rules resulting from it thus have two problems. First, the cover-age of these rules are usually limited since they may not be able to provide prediction for all the patterns. Second, these rules are usually not accurate and precise.

We will have to defer the discussion on how to derive prediction rules to the next section as it is largely an ap-plication dependent issue. Given such prediction rules, we generate a  X  X seudo training dataset X  by applying these rules on a set of unlabeled dataset, in our case, the test set. This amounts to using the combined evidence from the human knowledge and labeled training data at both training and testing stage. Similar to transductive SVM, the idea of using unlabeled test set is a direct application of Vapnik X  X  princi-ple of never solving a problem which is more general than the one we actually need to solve [17]. However, the pro-posed approach differs from the transductive learning in two aspects. First, in determining the decision hyperplane, the proposed approach relies on both the prior knowledge and the distribution of these testing examples, while transduc-tive SVM relies only on the distribution. Second, contrast to one iteration of SVM training needed by the proposed approach, multiple iterations of SVM training are needed and the number of iterations is dependent on the size of test set. For a large test-set, transductive SVM is significantly slower.

The proposed way of incorporating such fuzzy prior knowl-edge is mainly influenced by the approach introduced in [13]. However, there are some noticeable differences between these two approaches. First, while the proposed approach can work on rules with limited coverage, the approach in [13] needs to work on rules with complete coverage. In another words, the rules needed there have to make a prediction on every instance. This requirement can be too restrictive sometimes and reenforcement of such a requirement can in-troduce unnecessary noise. Second, the proposed approach has an integrated training and testing phase, thus classifica-tion is based on the evidence from both the training data and prior knowledge. However, the prediction power of human knowledge on testing data is thus lost in their approach.
Given the true training dataset and pseudo training dataset, we now have two possibly conflicting goals in minimizing the empirical risk when constructing a predictor: (1) fit the true training dataset, and (2) fit the pseudo training dataset and thus fit the prior knowledge. Clearly, the relative impor-tance of the fitness of the learned hyperplane to these two training datasets needs to be controlled so that they can be appropriately combined.

For SVM, it is easier to measure the unfitness of the model to these training datasets. In particular, one can use the sum of the weighted slack over the dataset to measure the unfit-ness of the learned SVM model to these two training sets. Let the first m training examples be the labeled examples, and the rest be the pseudo examples, the objective function of primal problem is given: Here the functionality of the parameter C is the same as the standard SVM to control the balance between the model complexity and training error. The parameter  X  is used to control the relative importance of the evidence from these two different datasets. Intuitively, one wants to have a rela-tive bigger  X  when the number of the true labeled examples is small. When the number of true training examples in-creases, one typically wants to reduce the influence of the  X  X seudo training dataset X  since the evidence embedded in the true training dataset is of better quality. Because we do nothaveaccesstotheexactvalueof  X  i before training, in practice, we approximate the unfitness to these two datasets by mC and
The solution of WMSVM on the concatenated dataset de-pends on a number of issues. The most important factor is v , the confidence value of each test example. The influence of margin/slack normalization function f / g is highly depen-dent on v i . Since the value of v i is just a rough estimation in this particular application, and there is no theoretical jus-tification for the more complex function form, we choose to use the simplest function form for both f and g .Precisely, we use f ( x )=1 /x and g ( x )= x in this paper. Experiments show this particular choice of function form is appropriate.
To test the effectiveness of the proposed way of incor-porating prior knowledge, we compare the performance of WMSVM with prior knowledge against SVM without such knowledge, particularly when the true labeled dataset is small. We use text categorization as a running example as prior knowledge is readily available in this important ap-plication.

We conduct all our experiments on two standard text cate-gorization datasets: Reuters-21578 and OHSUMED. Reuters-21578 was compiled by David Lewis from Reuters newswire. The ModApte split we used has 90 categories. After remov-ing all numbers, stop words and low frequency terms, there are about 10,000 unique stemmed terms left. OHSUMED is a subset of Medline records collected by William Hersh [6]. Out of 50,216 documents that have abstract in year 1991, the first 2/3 is used in training and the rest is used in testing. This corresponds to the same split used in [11]. After removing all numbers, stop words and low frequency terms, there are about 26,000 unique stemmed terms left. Since we are studying the performance of the linear classifier under different data representation, we split the classifica-tion problem into multiple binary classification problems in a one-versus-rest fashion. The 10 most frequent categories are used for both datasets. No feature selection is done, and a modification of libSVM [2] based on description described in section 4 is used to train WMSVM.
The proposed approach permits prior knowledge of any kind, as long as it provides estimates, however rough, of the confidence values of some test examples belonging to the class of interest.
 For each category, one of the authors, with access to the Table 1: Keywords used for 10 most frequent cate-gories in Reuters training data (not the testing data that will later form the  X  X seudo training dataset X ), comes up with a short list of indicative keywords. Ideally, one could come up with such a short list with only an appropriate description of the cat-egory, but such description is not available for the datasets we use. These keywords are produced through a rather sub-jective process based on only the general understanding of what the categories are about. The idea of using keywords to capture the information needs is considered to be prac-tical in many scenarios. For example, the name for each category can be used as keyword for OHSUMED with little exception(ignoring the common words such as  X  X isease X ). Keywords used for both dataset are listed in table 1, 2.
We next use these keywords to build a very simple model to predict the confidence value of an instance. To see how the proposed approach performs in practice, we used a model that is, while far from perfect, a natural solution given the very limited information we processed. Given a document x , the confidence value of x belonging to the class of in-of keywords appearing in documents x ,and | c | w the total number of keywords that describe category c .Tomakesure that SVM training is numerically stable, a document will be ignored if it does not contain at least one of keywords that characterize the category of interest. This suggests the prior model we use has an incomplete coverage, it is thus significantly different from the prior model used in [13]. We think such a partial coverage prior model is a closer match to the fact that the keywords have only limited coverage, par-ticularly when the category is broad (thus there are many indicative keywords). Inducing a full coverage prior model like [13] from the keywords with limited coverage, in princi-ple, will introduce noise.

Nine true datasets are created by taking the first m i ex-amples, where m i =16  X  2 i ,i  X  [0 , 8]. We then train stan-dard SVM classifiers on these true datasets, WMSVM clas-sifiers on the concatenations of these true datasets and the pseudo datasets. The pseudo datasets are always generated by applying the prior model on the testing sets. The test examples are then used to measure their performance. No experiments were conducted to determine whether better performance could be achieved with wiser choice of C (for SVM), we set it to 1.0 for all experiments.

We set the parameter  X  using the heuristic formula 400 /m , where m is the number of true labeled training examples Table 2: Keywords used for 10 most frequent cate-gories in Ohsumed myocardial-infarction myocardial, infarction heart failure, congestive congestive, failure heart defects, congential fontan, congential coronary arteriosclerosis arteriosclerosis, arteriosclerotic Figure 3: Comparison of macro-average Break-Even-Point using prior knowledge and data sepa-ratel yor together on the Reuters 25718, 10 most fre-quent categories, measured as a log function of the number of training examples divided b y16, macro-average F1 over BEP. used. Making  X  an inverse function of m isbasedontwo common understanding: first, SVM performs very well when there are enough labeled data; second, SVM is sensitive to label noise [19]. This inverse function form makes sure that when there is more data, the noise introduced by noisy prior model is small. The value 400 is picked to give enough weight to prior model when there are only 32 examples on Reuters dataset. We did not study the influence of the dif-ferent function forms, but the performance of the WMSVM with prior knowledge seems to be robust in term of the co-efficient value in the heuristic formula 400 /m as shown in table 3.

Figures 3,4 report these experiments. They compare the performance among the prior model, standard SVM clas-Table 3: Macro-average F1 over different  X  values on top 10 most frequent categories from Reuters dataset, WMSVM on 32 true labeled training ex-amples along with pseudo training dataset. Figure 4: Comparison of macro-average Break-Even-Point using prior knowledge and data sepa-ratel yor together on the OHSUMED, 10 most fre-quent categories, measured as a log function of the number of training examples divided b y16, micro-average F1 over BEP. sifiers, and these WMSVM classifiers when the size of the true dataset is increasing. For OHSUMED, we report per-formance in micro-average F1 over Break Even Point (BEP), a commonly used measure in text categorization community [18]. For Reuters dataset, to stay comparable with that of [8], we report performance in macro-average F1 over BEP instead. It is clear that combining prior knowledge with training examples can dramatically improve the classifica-tion performance, particularly when the training dataset is small. The performance of WMSVM with the prior knowl-edge on Reuters is comparable to that of transductive SVM [8], but the training time is much less as only one iteration of SVM training is needed. Usually the performance of SVM increases when one adds more labeled examples. But if the newly added examples are all negative, it is possible that the performance of SVM actually decreases, as shown in Figure 4. Note that the influence of prior knowledge on the final performance is decreasing when the number of true labeled examples is increasing. This is due to the particular function form of parameter  X  (400 /m ). But one can also understand this phenomenon by noting that the more labeled examples, drawn from an independently and identically distribution, the less the additional information one might have in prior knowledge.
For statistical learning methods like SVM, using human prior knowledge can in principle reduce the need for larger training dataset. Since weak predictors that estimate the conditional in-class probabilities can be derived from most human knowledge, the ability to incorporate prior knowl-edge through weak predictors thus has great practical impli-cations. In this paper, we proposed a generalization of the standard SVM: Weighted Margin SVM, which can handle the imperfectly labeled dataset. SMO algorithm is extended to handle its training problem. We then introduced a two-step approach to incorporate fuzzy prior knowledge using the WMSVM. The empirical study of our approach is con-ducted through text classification experiments on standard datasets. Preliminary results demonstrates its effectiveness in reducing the number of the labeled training examples needed. Furthermore, WMSVM is a fairly generic machine learning method and incorporating fuzzy prior knowledge is just one of its many possible applications. For example, WMSVM can be readily used in distributed learning with heterogeneous truthing. Further research directions include studies on the robustness of incorporating prior knowledge with respect to different quality of rough predication rules. More generally, how to combine the evidence from different sources and in different forms for effective modeling of data is an interesting future research direction. We want thank Dr. Zhixin Shi for his valuable comments. We also want to thank the anonymous reviewers for their feedback. [1] K. Bennett and A. Demiriz. Semi-supervised support [2] C. Chang and C. Lin. LIBSVM: a library for support [3] G. Fung and O. Mangasarian. Semi-supervised [4] G. Fung, O. L. Mangasarian, and J. Shavlik.
 [5] G. H. Golub and C. F. V. Loan. Matrix Computation . [6]W.R.Hersh,C.Buckley,T.J.Leone,andD.H.
 [7] T. Joachims. Text categorization with support vector [8] T. Joachims. Transductive inference for text [9] T. Joachims. Learning To Classify Text Using Support [10] S. Keerthi, S. Shevade, C. Bhattacharyya, and [11] W. Lam and C. Ho. Using a generalized instance set [12] J. Platt. Fast training of support vector machines [13] R. Schapire, M. Rochery, M. Rahim, and N. Gupta. [14] B. Sch  X  olkopf, P. Simard, A. Smola, and V. Vapnik. [15] S. Tong and D. Koller. Support vector machine active [16] V. N. Vapnik. Statistical learning theory . John Wiley [17] V. N. Vapnik. The nature of statistical learning theory, [18] Y. Yang and X. Liu. A re-examination of text [19] J. Zhang and Y. Yang. Robustness of regularized
