 ORIGINAL PAPER Manoj Kumar Sharma 1  X  Vijay Pal Dhaka 1 Abstract This article proposes offline language-free writer identification based on speeded-up robust features (SURFs), which goes through training, enrollment, and identification stages. In all stages, an isotropic box filter is first used to seg-ment the handwritten text image into word regions (WRs). Then, the SURF descriptors (SUDs) of WR and the corre-sponding scales and orientations (SOs) are extracted. In the training stage, an SUD codebank is constructed by cluster-ing the SUDs of training samples. In the enrollment stage, the SUDs of the input handwriting adopted to form an SUD signature (SUDS) by looking up the SUD codebank and the SOs are utilized to generate a scale and orientation histogram ( H the input handwriting are extracted and matched with the enrolled ones for identification. Experimental results on eight public datasets demonstrate that the proposed method outper-forms the state-of-the-art algorithms.
 Keywords SUDS  X  Codebank  X  SO  X  WRs Autoofflinelanguage-freewriteridentificationisveryimpor-tant for digitalization of handwritten documents, automation of postal codes identification, bank check X  X  signature identi-fication, and forensic(s) analysis, etc. The offline language-free writer identification is also to digitize the handwritten text by feature matching with their corresponding sample images. Wide research work have been conducted in this field [ 1  X  7 ]. And wide number of national, international hand-writing identification contests [ 8  X  15 ] have been organized successfully. Ghosh et al. [ 16 ] presented a comprehensive review of earlier research literatures with respect to writer identification. Therefore, the existing offline language-free writeridentificationapproachescanbeclassifiedintotexture-and structure-based approach.

Texture-related approaches take offline handwritten texts as a texture image and extract the textural features for writer identification. Tan et al. [ 2 ] and Oliveira et al. [ 3 ]useda gray-level co-occurrence matrix (GLCM) to extract the fea-tures from the handwritten images. Safwan et al. [ 4 ] designed script-independent line-based word-spotting framework based on HMM. Moghaddam et al. [ 42 ] extract features from handwriting data using Gabor and XGabor filter and rep-resent the extracted features with a feature relation graph (FRG). Salvador et al. [ 6 ] identify unconstrained offline handwritten texts based on hidden Markov model (HMM), and the structural part of the optical models has been modeled with Markov chains. Ryu et al. [ 7 ] developed a connected-component (CC)-based language-independent text-line extraction algorithm. Bertolini et al. [ 8 ] considered local binary patterns (LBPs) and local phase quantization (LPQ) as texture descriptors of handwritings for writer veri-fication and identification.

The structural features of offline handwritten texts are much more prominent and committed for handwriting writer identification in comparison with the textural feature-based identification. Therefore, recently huge numbers of the researches are focused on the structure-based approaches for handwriting identification [ 17  X  26 ]. Schomaker et al. [ 9 ] proposed edge-based directional features of handwriting, i.e., edge direction distribution, edge hinge distribution, and directional co-occurrence. Laure et al. [ 10 ] proposed HMM-based handwriting recognizer which considers dynamic and contextual information for modeling of writing units. For modeling the contextual units, a state-tying process based on decision tree clustering is introduced. Decision trees are built according to a set of expert-based questions on how characters are written. Van der Zant et al. [ 11 ] proposed a biologically inspired whole-word identification method that is used to incrementally elicit word labels in a live Web-based annotation system, named Monk. Graves et al. [ 12 ] proposed an alternative approach based on a novel type of recurrent neural network, for sequence labeling tasks, where the data are hard to segment and contain long-range bidi-rectional inter-dependencies. Jiang et al. [ 16 ] transformed classifier outputs to confidence values under the soft-max framework. Fink and Plotz [ 27 ] also proposed a system based on contexts, these contexts being defined as broad categories. A data-driven clustering of the 1500 Gaussian densities of the mixture is performed at each state position and for each cat-egory. Safabakhsh et al. [ 28 ] employed the coordinates of the points on the normalized and re-sampled contours of the connected components to form feature vector for codebank generation and writer identification. Doermann et al. [ 29 ] used straight line segments to fit the connected-component contour of handwriting and extracted the features accord-ing to the relationship of these segments. Siddiqi et al. [ 30 ] extracted a set of run length features on a binary image of handwriting instead of using points on contours.

The existing structural approaches are contours driven, so they are easily affected by the slants and aspect ratio of the characters in handwritten texts. Moreover, they extract features from the handwritten text and fail to extract the structural features between same words. However, in the document writing the words are always taken as a whole and their structures remain stable, that X  X  why they have dis-criminability for different writing styles. To deal with these discriminabilities, we propose a speeded-up robust feature (SURF)-based keypoint extraction at word level from hand-written texts, which contain the structural feature information of words.

The rest of the work is organized as follows: Sect. 2 gives a descriptionoftheproposedmethodindetail.Section 3 reports the experimental results and analyses. Finally, in Sect. 4 the conclusions are presented. 2.1 The framework of the proposed method The proposed method consists of three stages: training, reg-istration, and identification, as shown in Fig. 1 .
AsshowninFig. 1 , there are five main sections in the framework, i.e., line segmentation, word segmentation, code-bank generation, feature extraction, and feature matching and fusion. In the above three stages, the handwritten text image is firstly segmented into word regions (WRs). Then, the SURF is used to extract their SURF descriptors (SUDs) and to detect the keypoints, orientations (SOs) from the LRs andWRs.TheSURFdescriptorsandorientationswillbeused in different stages. In the training stage, SURF descriptors are used to generate a codebank for the use of enrollment and identification. In the registration stage, two features, called SURF descriptor signature (SUDS) and SURF orientations histogram (SOH), are extracted from SURF descriptors and SURF orientations of WRs of the registering handwritten text and saved for identification. In the identification stage, the SURF descriptor signature and SURF orientation his-togram are extracted from the input handwritten text images and respectively harmonized with the registered ones to get two harmonized distances, which are then fused to form the final harmonized distance for decision. 2.2 Word segmentation To extract the word(s) structural features of handwritten text image, the handwritten text image should segment into word regions (WRs). In earlier literatures, handwritten text images are manually segmented [ 31 ], which is very tedious and time-consuming. Many automatic word segmentation tech-niques have been devised in recent years [ 16 , 17 , 32 , 33 ] and are mostly based on line segmentation. Gatos et al. [ 32 ] segmented text lines using Hough transform and segment words according to the distances between the adjacent con-nected components. Stafylakis et al. [ 33 ] used a sequence of consecutive non-overlapped vertical zones for text-line seg-mentationandthenlocatedwordsbyadoptinganSVM-based metric. But in skew handwritten text images, line-based seg-mentation may fail, because the text lines are not horizontal. To overcome the problems of line segmentation, we have used an isotropic box filter to segment words from handwrit-ten text images.
 Algorithm 1: Word _ Segmentation Step 1: Input an offline handwritten text image I ,asshown Step 2: Convert text image I to gray scale image and then Step 3: Compute average height h a of all connected compo-Step 4: Filter binary image I b with an isotropic box filter and Step 4: Get filtered binary image I fb by binarizing filtered Step 5: Semi-word regions (SWRs) (see Fig. 2 e) formation Step 6: Get the word regions (WRs) according to the dis-Step 7: Splitting the overlapping connected components
With the completion of word segmentation process, a handwritten text image is divided into many word regions. These segmented word regions will be used for feature extraction. 2.3 SURF Speeded-up robust features (SURFs), presented by Her-bert [ 34 ] for a novel scale and rotation-invariant detection, description, and feature extraction from an offline scripts has been successfully applied in broad range of computer vision application. The SURF algorithm generates keypoints and descriptors efficiently by employing efficient scale-space construction. The SURF algorithm has five stages of computation: (1) employs integral images, (2) scale-space construction, (3) keypoints generation, (4) keypoints descriptor, (5) reproducible orientation. In the first stage, the integral images allow the speed-up computation of approx-imate Laplacian of Gaussian images using box filter. Due to integral image representation, computation overheads of applying the box filter is independent from the size of the fil-ter. In the second stage, the Hessian matrix is used to detect the keypoints and computes the locations, reproducible ori-entations, and scale space of these keypoints, by keeping constant image size and variable filter size. The first stage results are invariant to location and scale, and in the final stage, detected keypoints are first assigned a reproducible orientation. A Haar-wavelet responses for orientation in x and y are calculated for a number of pixels within range of 6  X  , where  X  denotes keypoints scale. Then, SURF descriptor for detected keypoints is generated by imposing a window around the keypoint and oriented as per obtained orientation. This window imposed around the keypoint further divides into 4  X  4 subwindows and calculates Haar wavelets of size 2  X  in each subwindow. In the construction of 64D descriptor vectors, each subwindow contributes 4 values and then nor-malized to the unit length. The SURF resulting descriptor is invariant to scale and rotation and partially invariant to other transformations.

In this research work, we prefer SURF algorithm because it is an approximation algorithm of SIFT and produces bet-ter results with less brighter images. The SURF algorithm is used in this work to detect the keypoints of handwritten scripts, their SURF descriptors (SUDs), and the correspond-ing space scales and reproducible orientations (SROs). The SURF descriptors are not only faster but also scale invariant and in-plane rotation-invariant and can reflect the skeleton of the image regions centered at the keypoints and the SROs can store the space-scale and reproducible orientation-related information of these skeletons. Both SUD and SRO play a vital role in handwriting identification and will be used in feature extraction in Sect. 2 . 2.4 Codebank generation After segmenting words, number of word regions (WRs) are obtained from a given handwritten offline image document. The SURF algorithm is used to find keypoints (as shown in Fig. 3 ) for every word region and extract their scales, descrip-tors, and orientations. To solve the storage and complexity issues, we consider the limited number of features and clus-ter the SUDs of the keypoints into N categories and center of each category called code, which form a SUD codebank with size N. On behalf of the codebank, a histogram will be computed with fixed dimension as feature vector for script identification in the following subsection.

For codebank generation, we used the hierarchical EM clustering algorithm, which has been successfully used for clustering dynamic textures [ 35 ], and size N of SUD code-bank is empirically selected as 450. 2.5 Feature extraction For feature extraction and matching, we are considering the occurrence frequency of SUD and OS in the handwritten text images in place of position of keypoints. Therefore, each text image may have different keypoint layout and the text in the recognizing handwritten document may be different with text registered handwritten document in an offline language-free text identification mechanism. 1. SURFdescriptorsignature(SUDS)extraction:Let SU D 2. Histogram extraction: For histogram extraction, the
Figure 4 shows the average absolute differences between ten positive and negative pairs for each component of SUDS and SOH. The figure predicts that the difference between inter-handwriting is much larger than the difference between intra-handwriting for both SUDS and SOH, which means that both SUDS and H SO have much discriminability to different handwritings. Figure 4 b shows that the components differ-ences with large index in H SO is decreased with respect to index increase. The large indexes correspond to large scales according to the H SO . The handwritten text image becomes blurred with the increase in scales, and more detailed struc-tures are missed. Therefore, the SURF keypoint detection become much less at large scales and becomes much large at small scales, which devise the decrement of the values of components with large scales with the increase in scale index. 2.6 Feature matching and fusion Let I 1 and I 2 are two handwritten text images, u = ( u and x = ( x 1 , x 2 ,..., x M ) and y = ( y 1 , y 2 ,..., their H SO .

In this work, because of its simplicity and high efficiency, therectilineardistancewhichissuccessfullyusedinminimax location problem on the plane [ 37 ] is adopted to measure the dissimilarity between two SUDSs u and v : D
As we discussed, the differences of the components with large indexes in H SO are much smaller. Therefore, with rec-tilinear distance the contribution large index components is very less to measure the dissimilarities between H SO than the ones with small indexes. In this paper, the weighted Euclid-ean distance, which successfully applied in clustering [ 38 ] and improved the importance of the small value components by initializing them more weight, is used to measure the dis-similarity between H SO x and y : D After normalization, both D 1 and D 2 fused and formed a new distance to measure the dissimilarity between I 1 and I 2 D ( I where 0  X  w  X  1 is a weight which is database dependent and can be determined by cross-validation on the training dataset. 3.1 Datasets We used eight datasets: Five of them are English datasets, i.e., MNIST CD-1 [ 39 ], MNIST CD-2 [ 39 ], IAM [ 40 ], Firemaker [ 41 ], and Unipen [ 42 ], one Chinese dataset HIT-MW [ 43 ], and two hybrid-language datasets, i.e., ICDAR 2011 [ 44  X  46 ] and ICFHR 2012 [ 47 , 48 ].

A brief overview of datasets used in experiments is given in Table 1 .

The MNIST CD-1 dataset and MNIST CD-2 dataset [ 39 ] contain 700 and 500 English offline handwriting text images from 300 and 250 different writers, respectively. There are 168 writers owning 4 or more handwritten samples, but we consider only two samples for those writers who contribute more than one document. The MNIST CD-1 dataset is used for training, and MNIST CD-2 dataset is used for testing, respectively. After fusion of both datasets, modified MNIST dataset is renamed as MNIST X  dataset.

The IAM dataset [ 40 ] contains 1839 English offline hand-writing text images from 850 different writers. There are 148 writers owning 4 or more handwritten samples, but we con-sider only two samples for those writers who contribute more than one document. The modified IAM dataset is renamed as IAM X  dataset. The Firemaker dataset [ 41 ] contains 900 handwriting sample pages from 350 different writers and three pages per writer. Pages 1 and 2 have a text of four paragraphs in normal handwriting, Page 3 has the content of cartoons written in their own words, and Page 1 and Page 3 are used for handwritten text identification.

The Unipen dataset contains handwritten from 250 dif-ferent writers and two samples per writer [ 42 ]. We modify the database and select 600 samples from 130 writers for the experiments. The HIT-MW dataset [ 43 ] consists of 1000 handwritten Chinese samples, from 250 different writers. Most of the writers have two pages of handwritten sample text. We modify the HIT-MW dataset as done in [ 49 ], and only one page from each writer is used.

The ICDAR2011 dataset [ 44 ] consists of 80 writers for training dataset and 240 writers for testing dataset. Each writer copied ten pages; each page contains text in three languages (English, German, and French), and each lan-guage has four pages. A new modified dataset, called MICDAR2011 dataset, is built by considering only the first four text lines from each sample page. The ICFHR2012 dataset [ 47 ] consists of 70 writers for training dataset and 80 writers for testing dataset. Each writer copied ten pages; each page contains text in two languages (German and Eng-lish), and each page contains text lines in range of four to eight. 3.2 Criterions In the experiments, we considered criterions, i.e.,  X  X eave-one-out, X  soft Top-N, and hard Top-N criterions for each dataset. In  X  X eave-one-out X  strategy, the distances to all other samples of datasets are computed for each handwritten sample [ 42 ]. In soft TOP-N criterion, only the correct hits are considered as at least one sample document of the same writer is considered in the N similar sample documents [ 42 , 44 ]. In hard TOP-N, only the correct hits are considered for all N similar sample documents written by the same writer [ 44 ], and when at least N reference sample documents exist for a writer, then the hard TOP-N criterions is used. 3.3 Experiments with different level features For offline handwritten text document image, the feature extraction is proposed at multiple levels, i.e., page level, para-graph level, word level, and alphabet level. Some examples of different levels are shown in Fig. 5 .

We adopt MNIST, Unipen, and IAM X  datasets for training and testing, respectively, to investigate the discriminabil-ity between SUDS and H SO at different levels, and for experiments, we employed soft TOP-N and  X  X eave-one-out X  strategy.
 The different level experimental results are presented in Table 2 . SUDS and H SO produce better experimental perfor-mance at the word level; it means that these features are more powerful at word level to represent the handwritten text than at other levels. The possible causes are as follows.
When we write a text document, each word is always taken as a whole and detectable by either leading or trail-ing space, that X  X  why word-level feature extraction is sta-ble. At page-level feature extraction, multiple features like paragraph-level features, word-level features, and the fea-tures at line level are to be extracted which are not stable and hence not suitable for offline handwritten identification.
At the paragraph-level feature extraction, multiple fea-tures like word-level features and the features at line level are to be extracted which are not stable and hence not suit-able for offline handwritten identification. Alphabet-level feature which are subset of word-level features misses var-ious features between alphabets in the same words. These missing features have strong discriminability for different offline handwritten text.
Therefore, word-level features are extracted for offline handwritten text recognition in the experiments. For word-level feature extraction with IAM and HIT-MW datasets, the word regions are being used with the datasets, and for rest of the datasets, the word regions are segmented for word-level feature extraction through proposed word segmentation algo-rithm. 3.4 Experimental performances on public datasets 3.4.1 Experiments on English datasets In the earlier research work as done in [ 28 , 39 , 42 ], MNIST CD-1 dataset and Unipen dataset are used for training, and Firemaker, MNIST CD-2, and IAM X  datasets are used for testing and evaluation, and analysis of the proposed method-ology is done through the  X  X eave-one-out X  and the soft TOP-N.

Table 3 lists the handwritten text recognition results of dif-ferent approaches using IAM X  dataset. Table 3 predicts that the presented results in [ 50 ] are better than the results pre-sented in [ 42 ] for the same Contour-hinge feature. In [ 50 ], most of the writers have referred 2 X 58 samples during recog-nition, while each writer has referred only one sample in [ 42 ]. We work with the same strategy as [ 42 ] for the proposed method, even though the proposed method outperforms all of the state-of-the-art approaches, including the one proposed in [ 50 ] with SUDS and H SO . During experiments, all 850 images of IAM X  dataset are used in testing of the proposed methodology, while some earlier approaches [ 28 , 42 , 51 ] only use 650 samples.

Table 4 lists the handwritten text recognition results of dif-ferent approaches using NMIST CD-2 dataset and predicts that the proposed method outperforms all of the state-of-the-art approaches. The results presented in Tables 3 and 4 show that the Top-1 performances of different approaches in IAM X  dataset are better than those in NMIST CD-2 dataset. The possible reason is that since the average amount of hand-written text images of IAM X  dataset is more than those in NMIST CD-2 dataset, the extracted features from handwrit-ten text images of IAM X  dataset are more stable than those extracted from NMIST CD-2 dataset. The results presented in Tables 3 and 4 also predict the fusion of SUDs or H SO outperform some state-of-the-art approaches, which means that SUDS and H SO characterize the different aspects of the handwritten text and can complement each other.

Table 5 lists the handwritten text recognition results of different approaches using Firemaker dataset. The results are presented in Table 5 . They predict that the proposed method outperforms all of the state-of-the-art approaches. According to the results presented in Tables 3 , 4 , and 5 , it is concluded that the Top-1 performances of different approaches in IAM X  dataset are better than those in Firemaker dataset. The pos-sible reason is that since the average amount of handwritten text images of IAM X  dataset is more than those in Firemaker dataset, the extracted features from handwritten text images of IAM X  dataset are more stable than those extracted from Firemaker dataset. The results presented in Tables 3 , 4 , and 5 also predict the fusion of SUDs or H SO can outperform some state-of-the-art approaches, which means that SUDS and H SO characterize the different aspects of the handwrit-ten text and can complement each other. 3.4.2 Experiments on Chinese datasets In Chinese datasets, U-HIT-MW dataset is used for training and L-HIT-MW dataset is used for testing purposes. As pre-sented in [ 49 ], one handwritten text image in L-HIT-MW is used for the query and the other one is used for reference. Query handwritten text images are compared with corre-sponding reference images. Table 6 lists the handwritten text recognition results of different approaches on the dataset, and the presented results predict that the fusion of both SUDS and H
SO outperforms the state-of-the-art approaches. 3.4.3 Experiments on hybrid datasets For hybrid dataset, ICDAR2011 dataset is used for training and ICFHR2012 dataset is used for testing purposes. The training dataset is directly adopted to create codebank and determine parameters for each dataset. For the evaluation of the proposed methodology,  X  X eave-one-out, X  soft TOP-N, and hard TOP-N are used. As there are ten text documents for a given handwritten text with ICDAR2011and ICFHR2012 dataset, it is possible to do hard evaluation with Top-8 crite-rions: one page for query and other eight as the references. The soft and hard Top-N performances on ICDAR2011 and ICFHR2012 datasets are given in Tables 7 and 10 , respectively, and the results predict that all the approaches outperform all of the state-of-the-art approaches with soft Top-N criterions instead of those with hard Top-N criterions. The performance degradation of the proposed methodology is less when we switched the criterion from the soft Top-N to the hard Top-N, and it means the proposed methodology is much stable than other approaches.
 The performances of different language subdatasets of ICDAR2011 and MICDAR2011 are presented in Tables 8 and 9 . The results presented in these tables predict that proposed methodology outperforms in all the tests, except one the soft Top-5 on Greek cropped subdataset. All the approaches outperform the ICDAR2011 dataset and its subdatasets instead of those in MICDAR2011, and this per-formance is due to the less number of handwritten lines in MICDAR2011. As the results shown in these tables, the proposed methodology is more robust to the amount of handwritten text documents than other earlier presented approaches.

To further investigate the robustness of the proposed methodology, the testing is again done on the ICDAR2011 different languages subdatasets. Two images for each writer from the testing dataset are used for reference sample, and the rest one is used as a query. With the fixed reference sam-ples, a different number of segmented words of the querying image are randomly selected and the Top-1 performance of the proposed methodology is evaluated for 140 times. Fig-ure 6 shows the average performances of Top-1 with different number of handwritten words, and it reflects from the graph that the raising of performance of different datasets is directly proportional to the increase in the handwritten word; when the handwritten word increase to 16, 23, and 64, the Top-1 performance for German, English, and French increase accordingly, and for Greek, the Top-1 performance converges to 97.45% when the handwritten word increases to 26. As the results shown in Fig. 6 , the performance of Top-1 for German, English, and French has exceeded 99.4% when the images contain only 6, 8, and 10 handwritten words, and for Greek, it has exceeded 95.4% when the handwritten text image contains only 16 words, which means that the pro-posed methodology can better perform on the less amount of handwritten text images.

The soft Top-N performances of ICFHR2012 entire dataset and subdatasets are shown in Table 10 , which predict that the proposed methodology outperforms the state-of-the-art approaches.
 The soft Top-N performances of ICFHR2012 English and Greek subdatasets are shown in Table 11 , which predict that the proposed methodology outperforms the state-of-the-art approaches.

Therefore, it is observed that the proposed methodol-ogy performs well with English, Chinese, French, German, Greek, and hybrid languages, and it also came to notice from Tables 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , and 11 that the performance of the proposed methodology slightly varies with dataset of dif-ferent languages, and it is because of distinct word structures in different languages. 3.5 Analysis In this section, we re-analyze the performances of Top-1 cri-terion for the proposed methodology.

A handwritten text sample correctly recognized by the proposed methodology and incorrectly recognized by the state-of-the-art approaches as done in Contour-hinge [ 42 ], Grapheme emission [ 42 ], and GMF [ 49 ] is shown in Fig. 7 . From the results, it is observed that the gap between most of the alphabets is very similar, but their height and width are different. The heights of the characters in the top one are more than those in the bottom, while the widths are similar, with the different aspect ratios between sample char-acters. Second, the bottom sample is more slant than the top one.

There is no slant normalization with the contour-based approaches (Contour-hinge, Grapheme emission, and GMF), that X  X  why they are more sensitive to the slant of the handwrit-ten texts. The size variance problem with the handwritten text mayovercomewiththesizenormalizationfeatureofcontour-based approach. That X  X  why sampled text shown in Fig. 7 is incorrectly recognized by the state-of-the-art approaches. The proposed methodology is based on SURF keypoints and hence insensitive to the aspect ratio and slant of handwrit-ten text, that X  X  why the proposed methodology can correctly recognize these handwritten text images.

Figure 8 shows handwritten text written by different writers and correctly recognized by the proposed methodol-ogy and incomprehensible recognized by the state-of-the-art approaches, i.e., Contour-hinge [ 42 ], Grapheme emission [ 42 ], and GMF [ 49 ]. As shown in Fig. 8 , the two hand-writings are very similar in their slant, orientation, and the shape, and hence, these state-of-the-art approaches based on the contour or alphabets fragments incomprehensible iden-tified them from the same writer. However, the alphabets in the bottom sample are more compact than the top one, which indicate that the text is written by different writers. The com-pactinginformationofawordalsocontainswiththeextracted features.

Figure 9 shows false rejection and acceptance of the text samples written by the same writer in different styles. The text shown in the above figure cannot be judged by the experts that they are from the same writer. The accurate recognition of the distorted handwritten written by the same writer is not possible with the proposed method.

Figure 10 shows the wrong identification done by the pro-posed methodology. In the extracted features, the occurrence frequency of the local structure features is reflected and the amount of handwritten text is too less, that X  X  why the pro-posed methodology cannot extract stable features and fails to identify correct writer. In this research article, we have proposed a automatic offline language-free writer identification based on SURF, in which two SURF features, i.e., SUDS and H SO , are extracted from offline handwritten text samples. The experiments on eight public datasets demonstrate that the proposed method-ology outrun the state-of-the-art approaches. This method is based on SURF keypoints, which is insensitive to the aspect ratio and slant of the characters. SUDS and H SO are very stable and can reflect the structures around the SURF keypoints. The word-level features of handwritten text are much more suitable to recognize the text. The proposed methodology is language free and can perform well with dif-ferent and hybrid languages with their complex structures. The proposed methodology outperforms the state-of-the-art approaches.Withthelessamountofhandwrittentext,theper-formanceoftheproposedmethodologyislittlebitless,unless otherwise the proposed methodology devises very promising results. In further research, we will improve the performance of the proposed methodology with the small amount of hand-written text samples.

