 The increasing availability of large volumes of human-curated content is shifting web search towards a paradigm that intro-duces seamlessly more semantic information to search engine result pages. This trend has resulted in the design of a new element known as the knowledge module (KM), where certain facts about named entities, obtained from various knowledge bases, are shown to users. So far, little has been done to uncover the role that this module plays on user experience in web search and whether it is perceived by users as a useful aid for their search tasks. Our work is an early attempt to bridge this gap. To this end, we conducted a crowdsourcing study aimed at understanding the effect of the KM on users X  search experience and its overall utility. In particular, our study is the first to provide insights about the noticeabil-ity and usefulness of the KM in web search, together with comprehensive analyses of usability and workload.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval; H.1.2 [ User/Machine Systems ]: Hu-man factors web search engine; knowledge module; user experience
In recent years, the knowledge module (KM) has become a standard component on search engine result pages (SERPs) of all major web search engines (Fig. 1). This module pro-vides users with information about the named entities they are searching for as part of their search tasks. The con-tent presented in the KM is typically obtained in a semi-structured format from curated entity databases, such as Freebase or Wikipedia, and often includes both quantitative and qualitative information about the queried entity. This raw information can be further enriched by the search engine; Figure 1: The KM (in red border) displayed on the e.g., by showing a ranking of related entities, accompanied with explanations of their relationship. Moreover, the KM is often complemented with additional content, such as mul-timedia or social media content associated with the entity, typically obtained from third-party data sources.

In this context, most research has focused on general back-end system tasks, the most important being knowledge base construction [1, 4, 6, 7, 11], or more specific backend tasks, such as related entity recommendation [2, 3]. With the excep-tion of a recent query log analysis on exploratory search [10], so far little has been done to understand the way web search users interact with the frontend system, i.e., the knowledge component presented as part of the SERP. Our work makes an early attempt to understand the impact of the KM on users X  overall search experience in entity-centric search tasks. In particular, we try to answer questions of the following kind: Do users notice the presence of the KM on SERPs? If they notice it, do they find it useful? Does the KM really ease web search? Is it cognitively or physically demanding?
Our contribution can be summarized as follows. To un-derstand the user experience with the KM, we conducted a crowdsourcing study. The study involved questionnaires and self-reported feedback from 533 users about noticeability, usefulness, usability, and workload toward the KM shown on the Yahoo web search engine. We observed that the majority of the participants (about three-fourths) who per-formed the search tasks noticed the presence of the KM on the SERP, and they felt that, overall, it provided a useful aid to accomplish their search tasks better and faster.
To understand the impact of the KM in web search, we conducted a crowdsourcing study and collected feedback from users who performed short, entity-centric search tasks using the Yahoo web search engine. With this study, we aimed to determine: (i) what percentage of users notice the KM on the SERP, (ii) to what extent they perceive it as a useful aid to their search tasks, and whether the presence of the KM can affect (iii) the perceived usability and (iv) experienced workload due to web search engine usage.

Crowdsourcing offers several advantages not available in other experimental settings [9], such as access to a large and diverse pool of participants with stable availability, as well as collection and analysis of real usage data at a large scale. Another advantage of crowdsourcing is the low cost of the tasks, which makes it a preferable solution over the more expensive laboratory-based experiments. On the downside, a limited range of parameters can be explored in a controlled manner and experimenters have to account for potential threats to ecological validity, distractions in the physical environment of the user, and privacy issues, to name a few. In our study, we used the Amazon Mechanical Turk service. All of the aforementioned limitations were taken into consid-eration and preventive measures were put into practice to discount low-quality responses. Also, strict selection criteria were applied to exclude unsuitable participants (e.g., HIT approval rate  X  98%, number of HITs approved  X  1,000).
The experiment had a repeated measures design with one independent variable: KM (with two levels:  X  X isible X  or  X  X idden X ). The KM visibility was controlled with client-side scripting, removing the KM from the SERP in the  X  X idden X  condition. The dependent variables (Section 2.3) were: (i) KM noticeability, (ii) KM usefulness (ease of use and speed of use), (iii) perceived usability of the search engine (Tables 1 and 2), and (iv) overall workload (Table 3). The experiment consisted of two short search tasks that were completed using the Yahoo search engine, one task displaying the KM on the SERP and one without it. To control for order effects, we counterbalanced task assignments using Latin square design.

Participants accessed the search engine through a custom proxy which did not alter the original look and feel of the SERPs. This allowed us to instrument the browsed pages on the fly and capture user interactions with the SERP without interfering with the actual web search engine interface in production. The proxy had a common entry page for all participants. For each search task, participants were pre-sented with a question and were suggested a search query to begin with. Finally, the suggested queries were all picked from a pool of queries that triggered the KM on the SERP, independent of the KM visibility (Section 2.2).
Our query set consisted of 32 unique query patterns that were selected after a large-scale query log analysis All queries would trigger the KM on the Yahoo SERP, so we could ensure that in all tasks the KM would be displayed on the SERP, thus allowing us to choose between leaving it visible or hiding it, depending on the experimental condition.
The selected query patterns belonged to four different themes (famous people, movies, athletes, sport teams) and required either single or multiple answers. An example of a single-answer query pattern is  X  X ho is the head coach of the team X? X  while an example of a multi-answer query is  X  X ho are X X  X  children? X . To diversify our search query pool, we produced three questions per query pattern while we introduced some additional multi-answer questions to increase the difficulty of the search tasks. In total, our query set included 144 different queries. 1 In the study, the query set was repeated as many times as needed to accommodate all participants. Each query was answered under each condition by at least two participants and at most six participants.
We used three different post-task questionnaires to elicit participants X  subjective experience about the search engine and search tasks. More specifically, participants were asked to complete the Computer System Usability Questionnaire (CSUQ), the Perceived Usefulness and Ease of Use question-naire (PUEU), and the NASA Task Load Index (NASA-TLX), together with custom statements described later.
The CSUQ [8] is a multi-dimensional user satisfaction ques-tionnaire designed for use in scenario-based usability evalua-tions. Out of the four scales it contains, we considered only the scores from the system usefulness (SYSUSE) subscale (Ta-ble 1). The PUEU questionnaire [5] is a psychometric scale with significant empirical relationships with self-reported measures of usage behavior. It focuses on two theoretical constructs, perceived usefulness and ease of use, which are fundamental determinants of system usage. In our study, we considered only the perceived usefulness scale, which consists of the six statements shown in Table 2. The NASA-TLX is a multi-item assessment tool that allows participants to perform subjective workload assessments of human-computer interaction systems. NASA-TLX employs a rating procedure based on the six questions shown in Table 3. Combined to-gether, CSUQ, PUEU, and NASA-TLX gauged key aspects of participants X  experience with the search tasks and the search engine. The questions were all forced-choice type and appeared at random to mitigate order effects. A 7-point Likert scale was used in all questionnaires, with high scores representing a stronger agreement with the given statement.
In addition to the above psychometric scales, we also collected demographic information as well as information about participants X  agreement to the following statements: (i)  X  X his search engine helped me accomplish my task in a reasonable amount of time X , (ii)  X  X  feel satisfied with the retrieved results X . Finally, we inquired about the KM through a mini-questionnaire, which only appeared on the SERPs that displayed the KM. The mini-questionnaire was initially hidden, in order not to interfere with regular browsing, and was shown to the user just before unloading the SERP on closing the browser tab. The mini-questionnaire contained three questions: (i)  X  X id you notice the KM? (yes/no) X , (ii)  X  X o what extent did you find the KM useful in answering the question? (1: not useful at all, . . . , 5: completely useful) X , (iii)  X  X o what extent did the KM help you answer the question faster? (1: not faster at all, . . . , 5: extremely faster) X . We recruited 612 participants through Amazon Mechanical Turk. From this original sample, we approved assignments http://personales.upv.es/luileito/kme/queries.tsv for 533 participants (female = 226, male = 307), aged from 18 to 66. Participants were of mixed nationality (e.g., Belgian, Finnish, British, American) and had varying educational backgrounds: 29.98% had a high school diploma, 18.98% had a college diploma, 41.56% had a BSc degree, 7.97% had an MSc, and 1.52% had a PhD. All participants were proficient in English, 98.31% being native speakers. When asked about their search engine at home or work, participants reported using primarily Google, followed by Yahoo and Bing.
At the beginning, participants were informed about the terms and conditions of the study, followed by a short de-scription of the SERP. The study had to be done in a single session. The participants could opt out at any moment, in which case they would not be compensated. Participants were asked to  X  X valuate two different backend systems of Yahoo Search, by performing two search tasks X . Therefore, participants were not informed of the actual intent of the study ( X  X nderstand the impact of KM in web search X ), in or-der to avoid a potential bias. For each task, participants had to answer a question by searching for relevant information on the proxified search engine. They were also presented with a suggested query to begin their search, although participants were free to submit additional queries (e.g., if the suggested query did not lead to the answer) and examine as many results as necessary to complete the search task.

We used informational, entity-centric queries to introduce a common starting point across all participants who tested each particular combination of query and backend system. Upon finishing each task, participants were instructed to submit their answer and complete the post-task questionnaire. The study concluded with a demographics questionnaire. The payment for participation was $1.20 and each participant could take the study only once.
In the following, we discuss our findings based on the 1,066 search tasks performed by 533 participants. The results are presented in three sections. The first section discusses the noticeability and the usefulness of the KM. The second section shows the effect of the KM on the web search engine X  X  perceived usability. The third section presents findings of the workload analysis. To quantify the statistical significance of our results, we used the Wilcoxon signed-rank test at an  X  level of 0.05. The first research questions we answered are whether the KM is being noticed by web search users, and to what ex-tent it is considered a useful aid to their search activities. According to the responses from the mini-questionnaire (Sec-tion 2.3), out of the 533 participants who were involved in our study, the majority (78.86%) reported noticing the KM on the SERP. Considering that the KM is a relatively new element introduced in SERPs, the high percentage of par-ticipants who engaged with it is a first positive indication of its noticeability, even if this was demonstrated for only one of the available commercial search engines. The KM was also found to be very useful in answering the search task questions ( M = 4 . 03 ,SD = 1 . 48). Moreover, the KM helped the participants who noticed it to answer the search task questions fairly faster ( M = 3 . 84 ,SD = 1 . 60). These findings suggest that the KM is both noticeable and useful to web search users.

Furthermore, we performed a correlation analysis and com-puted the point-biserial correlation coefficient ( r pb ) for the above variables. In the case of r pb , the sign of the correlation depends on the way the coding of the variables was made, therefore we ignore all information about direction. Our find-ings indicated that noticeability is significantly correlated with both ease of use ( r pb = 0 . 60 ,p &lt; . 0001) and speed of use ( r pb = 0 . 54 ,p &lt; . 0001). In short, users who noticed the KM felt that they could accomplish their tasks better and faster.
Next, we examined the impact of the KM on perceived system usability. To this end, we looked at the participants X  responses to our two custom statements as well as the 8-item CSUQ-SYSUSE and 6-item PUEU scales shown in Table 4. We averaged the responses to obtain the final scores and then contrasted and compared what the participants reported in the experimental conditions (visible or hidden KM).
The Wilcoxon signed-rank test showed that participants found the search engine to be significantly more helpful in accomplishing their search tasks in a reasonable amount of time ( z = 8 . 13 ,p &lt; . 001 ,r = 0 . 35) when the KM was visible ( Mdn = 7) compared to when it was hidden ( Mdn = 6). Moreover, participants felt significantly more satisfied with the retrieved results ( z = 7 . 36 ,p &lt; . 001 ,r = 0 . 32) when having seen the KM ( Mdn = 7) rather than not ( Mdn = 6). Participants also perceived the search engine to be signifi-cantly more usable ( z = 9 . 06 ,p &lt; . 001 ,r = 0 . 39) when the SERP displayed the KM ( Mdn = 6 . 66) than when it did not ( Mdn = 6). Indeed, the CSUQ-SYSUSE scores were higher for the  X  X isible X  condition, as observed in Table 4. More-over, the reported PUEU scores were significantly higher ( z = 8 . 58 ,p &lt; . 001 ,r = 0 . 37) for the  X  X isible X  condition ( Mdn = 5 . 5) than the  X  X idden X  condition ( Mdn = 5).
Finally, we looked at the perceived workload experienced by our participants as they performed the search tasks. Ta-ble 5 shows the NASA-TLX scores reported for each factor (lower is better). The individual factor scores were summed up to obtain the overall workload scores. Participants who interacted with the SERP that did not display the KM ( Mdn = 14) experienced a significantly higher workload ( z = 4 . 40 ,p &lt; . 001 ,r = 0 . 19) than the participants who were shown the KM ( Mdn = 13). Table 5 also presents the relative contribution of each factor to the overall workload score for both experimental conditions. More specifically, the partici-pants in the  X  X idden X  condition ( Mdn = 1) reported a signif-icantly higher mental demand ( z = 4 . 81 ,p &lt; . 001 ,r = 0 . 20) than those in the  X  X isible X  condition ( Mdn = 1). Participants in the  X  X idden X  condition also reported lower physical and temporal demand scores than those in the  X  X isible X  condition, although these differences were not statistically significant.
When examining how successful they were in accomplish-ing the search tasks, participants in the  X  X isible X  condi-tion ( Mdn = 7) reported significantly higher performance ( z = 3 . 39 ,p &lt; . 001 ,r = 0 . 14) than those in the  X  X idden X  con-dition ( Mdn = 7). Furthermore, the search task demanded significantly more effort ( z = 5 . 25 ,p &lt; . 001 ,r = 0 . 22) in the  X  X idden X  condition ( Mdn = 2) compared to the  X  X isible X  condition ( Mdn = 1). Lastly, participants in the  X  X idden X  condition ( Mdn = 1) reported significantly higher levels of frustration ( z = 5 . 56 ,p &lt; . 001 ,r = 0 . 10) than those in the  X  X isible X  condition ( Mdn = 1).
This work entails an early attempt to understand the im-pact of the KM on users X  search experience and provides empirical evidence of its overall utility. To this end, we con-ducted a crowdsourcing study which revealed the potential benefits of the KM, when dealing with entity-centric search tasks. In particular, we showed that the KM was noticed by most participants and was perceived to be a valuable help in web search. Moreover, the KM was perceived to ease the search process for the users. Our ongoing work is on correlating mouse cursor tracking data and user engagement with the KM. We believe that this is a research avenue worth pursuing given the lack of explicit user feedback about en-gagement (e.g., clicks or dwell time) in the context of the KM. Finally, we anticipate that further research on the topic may have an impact on future web search interfaces.
