 Multimodal Analysis Lab, Interac tive Digital Media In stitute, National University of Singapore, Singapore 1. Introduction Modern media increasingly employ a wide range of strategies to communicatemeaning to the audience. After being shown a news clip, a po litician X  X  s peech, a music video, a magazine cover or a fashion show one will have a fairly clear idea not only about its contents or narrative, but also about how the message has been delivered; for example, the mood, whether formal, romantic, aggressive, energetic or inspiring and the audience it targets, whether youth, elderly, housewives, middle class or business people. Though it is generally understood that this complex messa ge is conveyed through collaborative use of multiple resources combined by the media creator  X  an artist, an author, an editorial board  X  people, often the creators themselves, usually fi nd it dif fi cult to identify and crystallize how exactly the meaning is constructed. Being asked, one will generally describe the sensation or the effect produced by the media, but not how the tools  X  color, language, background music, camera work, gestures, and so forth  X  have been used to produce this interpretation. The fi eld of science studying how meaning is produced and communicated through the use of a variety of available meaning-making resources is Semiotics. In what follows, we give a brief introduction into the fi eld of Semiotics , Social Semiotics and Multimodal Analysis .

Semiotics is the theory and study of signs and symbols, their use and interpretation as elements of systems of communication. One can generally say that semiotics studies the role of signs in the meaning making process [1]. Social Semiotics is a branch of semiotics studying meaning making as a social practice, that is meaning making in speci fi c social and cultural circumstances [2]. Multimodal Analysis adopts a social semiotic approach based on the assumption that humans in their meaning making practice, rarely communicate using one single mode of communication, for example, not only by language, but  X  X t is done simultaneously through a number of modes  X  multi-modally , by combinations of the visual, sound, language, etc. X  [3]. Multimodal analysis is a me thod which involves br eaking down the meaning-making resources into their most basic components in order to describe the range of choices available  X  the potential , which choices are used in a particular context  X  the actual , and how the combination of different resources works together to create multimodal meaning  X  the analysis .

In order to illustrate the concepts of potential and actual, consider a study of how camera movement contributes to the meaning of the movie. In multimodal analysis, the researcher investigates a palette of choices for camera movement. For example, one may determine that there is a fi nite set of camera movement types: static, panning, tilting, tracking or zooming. This provides a description of camera movement potential, referred to also as a system of choices . Using this description one can analyze a movie and offer a comprehensive description which camera movement choices and where they are activated  X  the actual. This approach facilitates the systematic and consistent description of phenomena under study. In addition, it pr omotes comparison of current choices to the available alternatives and the resultant alternative meanings.

Multimodal analysis starts with selecting a range of modalities to be investigated and creating an anno-tation  X  a detailed localization and description of which choices in the selected modalities are actualized in the media under study. Typical annotation techniques are con fi ned to creating a table on a sheet of paper, or its digital analogue using standard document editing software, e.g. the Microsoft Of fi ce suite, where the rows of the table represent the modalitie s and the columns localize annotations in the source media. The cells on the intersection of the modality (row) and localization (column) are used to type-in the actual activated choice. Figure 1 illustrates a t ypical table-based multimodal annotation created in Microsoft Word , for the analysis of a business advertisementmovie clip [4]. Annotated modalities include music, song, speech, verbal description, narrative representation, conceptual representation, mood and others.

For obvious reasons, a table-based methodology is extremely time consuming. Moreover, this method-ology does not allow precise localization of annotation elements and is very inef fi cient when further processing of the data is required, like calculating statistics or drawing diagrams. There is a variety of software solutions which can be used to ma ke the multimodal annotation process more ef fi cient, for example Elan [5], Anvil [6], Praat [7] or others. One can fi nd a comprehensive comparison of available multimodal annotation tools in [8]. State-of-the art m ultimodal annotation software [9] is being devel-oped by the authors of the current work within the framework of the  X  X vents in the world X  project [19]. All these tools implement similar methodology which we refer to as tier-based annotation. The software implements an interactive GUI allowing the user to create tiers analogous to rows in a table-based ap-proach. When tiers are created, the user is able to create  X  X nnotation units X   X  segments localizing the annotation in the source media using start and end time stamps or, equally, start time stamp and duration. The content of the annotation unit is usually typed-in manually or selected from a prede fi ned palette of tags. Figure 2 illustrates a sample GUI of Elan [5], a linguistic annotation software. The principal elements of GUI are typical for the whole class of tier-based annotation software:
The ef fi ciency in creating annotations makes it possible to annotate long media fi les or large corpora of media. Here arises another problem  X  how to analyze and interpret the data, since it is not straightforward to identify patterns and outliers by looking at the tier-based annotation, especially in case where there are several thousand of annotation units spread over num erous moda lities. Standard tools used for analysis include query-based search, calculating statistics o n the data (frequencies, cond itional probabilities) and creating standard visualizations (piecharts, histograms). These techniques are either implemented by the annotation tool itself or achieved by exporting the annotations into external data processing software, usually spreadsheet or database applications like Microsoft Excel or Microsoft Access .

In the current work we propose to analyze multimodal annotations as state-transition diagrams .The annotation is seen as a record of change in fi nite state automaton, which is represented as a directed graph, where nodes of the graph represent unique  X  X tates X  and edges represent the paths of change of one state to another. The constructed diagram, which is rendered using a graph layout algorithm or manually, provides an alternative and fairly holistic view on patterns and outliers in the annotation. On the one hand, repetitive sequencesof events in the annotation are visible in the diagram as multiple edges between the same nodes: that is, the higher the  X  X ensity X  of t he edges  X  the more repetitive the pattern is. On the other hand, long unique paths in the diagram reveal outlying sequences in the annotation and, therefore, in the multimodal phenomen a under study. The identi fi ed outliers also help discovering mistakes and imperfections in user input. Minor mismatches in manually created time stamps are hard to identify by looking at tiers, but their effect on statistics can be signi fi cant. We consider an algorithm constructing a fi nite state automaton from an annotation and discuss h ow the resulting diagram can be visualized using openly available software tools. Also, we consider a state-transition diagram in synchronization with the original media, implement a software system for this synchronization and illustrate the advantages of synchronous view in a case study that explores multimodal pattern s in business news videos from a social semiotic perspective.

State-transition diagrams are widely used for m odeling and visualization of dynamical systems and their formal speci fi cations have been developed and included into well-known speci fi cation languages Speci fi cation and Description Language (SDL) and Uni fi ed Modeling Language (UML). Due to a mutual connection of state-transition diagrams and directed graphs, one can use a fairly rich palette of tools developed for graph visualization [10]. Moreover, visualization approaches developed speci fi cally for state-transition systems can be found in the literature. For example, a technique based on attribute clustering is proposed in [11]; a procedurally oriented approach focused on structure symmetry,producing tree-like visualizations is considered in [12]; an approach based on state-space simpli fi cation can be found in [13]; transition diagram based analysis has been implemented also by Anvil annotation tool [6].
This paper is organized as follows. Chapter 2 introduces fi nite state automatons in the context of multimodal annotation a nd proposes the algorithm for c onstructing an automaton and fi ltering technique for removal of user X  X  input imperfec tions. Chapter 3 proposes automat ons as state-transition diagrams, discusses how freely available tools can be used for visualization and the drawbacks of this approach. Finally, the chapter proposes an interactive visuali zation software synchronizing the state-transition diagram with the source media. A case study on how the proposed visualization techniques can aid the media researcher in the exploration of socio-cultural patterns in multimodal news videos is presented in Chapter 5. Chapter 6 presents the conclusions of the paper.
 2. State-transition diagrams
The parallel between tier-based time-stamped annotation and fi nite state automatons require elabora-tion. Figure 3 presents an example of manually made annotations of cinematography in a business news movie clip, where three systems are used to describe horizontal perspective , vertical angle and size of frame modalities with time dimension projected horizontally. Horizontal perspective may have a value of  X  X rontal/involved X  or  X  X blique/detached X ; vertical angle may be  X  X ow angle X ,  X  X edium, eye-level X  or  X  X igh angle X ; size of frame may be  X  X xtreme close-up X ,  X  X lose-up X ,  X  X edium close-up X ,  X  X edium shot X ,  X  X edium long shot X ,  X  X ong shot X  or  X  X xtreme long shot X  (see Table 1). One can conclude that there can possibly be 2  X  3  X  8 = 48 different  X  X inds X  of cinematography in the selected annotation methodology.
Tier-based representation clearly reveals that there are different dynamics in camera movement over time. However, with an increase in the number of tiers/values it becomes more and more dif fi cult to understand what is actually going on. Continuing to build the fi nite state automaton analogy, we see, that the set of active states for this annotation consists of only four states: A (oblique/detached, Medium eye-level, Medium close-up) B (oblique/detached, Low angle, Medium long shot) C (frontal/involved, Medium eye-level, Medium close-up) D (oblique/detached, Low angle, Long shot) And there are 11 transitions (time of transition is not recorded for simplicity): A  X  B, B  X  A, A  X  C, C  X  A, A  X  C, C  X  A, A  X  C, C  X  A, A  X  D, D  X  A, A  X  C. Now, the annotation can be visualized as directed graph which is also referred as state-transition diagram , see Fig. 4. The number on transition in the fi gure represents its number in sequence. In what follows we discuss the formal de fi nitions of annotation and state-transition diagram. 2.1. Formal de fi nitions
Let system S = { X  ,c 1 ,c 2 ,... } be a fi nite set of choices including empty choice. Let annotation unit beatriplet u =( t 1 ,t 2 ,c  X  S ) ,de fi ned by two time stamps and a system choice. We require t 1 ,t 2  X  be the real numbers and t 1 0 ,t 2 &gt; 0 ,t 1 &lt;t 2 for time stamps to make sense. We de fi ne annotation A =  X  S, U ,where  X  S = S 1 ,...,S N is a set of systems and U = u 1 ,...,u K is a set of annotation units. The set of systems corresponds to the annotation tiers on the assumption that one tier is used for one system. Moreover, we impose the restriction that annotation units within one tier, i.e. using the same system, cannot intersect. Formally, for any u 1 =( t 1 ,t 2 ,c 1  X  S )  X  U and u 2 =( t 3 ,t 4 ,c 2  X  S )  X  U ,it is true that [ t 1 ,t 2 ]  X  [ t 3 ,t 4 ]=  X  .
 Timed automaton model is de fi ned in [14] as  X =( X, E, f,  X  ,x 0 ) ,where to be applied for representing the tier-based annotation, this model can be further simpli fi ed. Since annotation only captures the phenomena, and does not provide any information of internal system X  X  logic, we do not need a concept of event in our de fi nition, as well as we do not need the concept of active event function. Every transition in the annotation automaton model is solely de fi ned by the timing information, which makes it possible to de fi ne annotation automaton model as  X =( X, f ) ,where
Let us construct an automaton  X =( X, f ) given the annotation A =  X  S, U . Firstly, assuming that annotation time starts from 0, we de fi ne time interval [0 ,t M ] ,t M =max from 0 to maximal time stamp of all annotation nodes. Then, we de fi ne a set of annotation units active at time t denoted u ( t ) ,t  X  [0 ,t M ] ,as u ( t )= { u =( t 1 ,t 2 ,c )  X  U : t 1 t t 2 }  X  X setof annotation units, whose time stamp interval intersects with t . Finally, we de fi ne state active at time t as x ( t )= { X  c :( t 1 ,t 2 ,c )  X  u ( t ) }  X  a set of choices of active annotation units.

This enables us to de fi ne a state space X and transition function f of automaton  X =( X, f ) .Letus de fi ne state space f :  X  X denoted as f ( t ) ,t  X  [0 ,t M ] as The function f is de fi ned at moments of time when a set of active annotation units changes and gives us the value of the new active state at this moment. Note that it is important to de fi ne f at moments when there is a change in active annotation units, not a change in active state, because it makes it possible to represent the situation when state x changes to itself, i.e. self-transition of the state. 2.2. The algorithm
The de fi nition of a system gives rise to a view of it as a set of tags along with the empty tag. Therefore we implement a system as a set of strings with the empty string representing an empty choice. This leads a state to be implemented as an array of strings of size N , where every string i corresponds to a choice from one of systems  X  S = S 1 ,...,S N . Though one can use a straightforward approach to fi nd all the changes in annotation by scanning all values of t from 0 to t M with a desired resolution, this approach would be very inef fi cient and involve the duration of the analysis t M into complexity of the algorithm. The approach we propose uses the fact that every annotation unit u =( t 1 ,t 2 ,c  X  S ) de fi nes a change in state on its time stamp boundaries t 1 and t 2 . At time t 1 some previous choice changes to choice c ,and at time t 2 choice c changes to something else. To determine the unknowns we need to carefully process all units time stamps sorted from 0 to t M . The complexity of this approach depends on the number of annotation units K .

Let us outline steps of the algorithm in more details. Let x be an array of N strings representing state where the i -th element represents a choice from the i -th system S i .De fi ne transition command as a triplet ( i , t , choiceFrom , choiceTo ) which meaning is  X  X t time t ,insystem i , choice choiceFrom changes to choiceTo .To execute a tr ansition comm and on state x means setting x [ i ]  X  choiceTo .Let a be an array of transition commands, X be array of states and f beamap f ( t )  X  x  X  X .
 Step 4.1: Foreach command in a do
Step 4.2: Execute all commands with the same timestamp on x . Step 4.3: If x/  X  X ,add x into X Step 4.4: Add transition f ( t )= x into f ,where t is a command X  X  timestamp.

The complexity of Step 2 is O ( K ) , the complexity of Step 3 is K  X  log K and the complexity of Step 4 is O ( K ) . The overall complexity is therefore linear on the number of annotation units.

We also consider a case when available annotation is assumed to be dynamically modi fi ed by the user. In that case, modi fi cation of the already constructed state-transition diagram would involve two principal steps: localization of the modi fi ed annotation in a diagram and execution of modi fi ed transition commands. The fi rst step can be implemented as a search in a sorted array, the complexity of this operation is log K ; the second step is of constant time complexity. The resulting complexity of dynamical modi fi cation of state-transition diagram is, therefore, logarithmic. 2.3. Noise fi ltering
One must keep in mind that annotation A is created manually by de fi ning timestamps t 1 and t 2 as well as system choice c of every annotation unit u =( t 1 ,t 2 ,c ) . Consider a situation when user decides transition diagram represents the change from c 1 into c 2 . However, even provided with a very ef fi cient GUI, due to the manual nature of the input, it is very common that | t 2  X  t 3 | =  X &gt; 0 meaning that there is a small gap between t 2 and t 3 . This will affect the resulting sta te-transition diagram by producing an extra empty state c 1  X  X  X  X  c 2 , which is interpreted as noise. In real annotation scenarios, when many units for many systems are created, this effect may seriously affect the resulting state-transition diagram with noisy states and impair its interpretative quality so one must consider a strategy to deal with imperfections in the user X  X  input.

We base our fi ltering approach on the assumption that there exists a minimal acceptable duration t min for the state to be active and perceivable by the human analyst. Therefore, we consider that any state with a duration of less than t min is a noisy state and needs to be fi ltered out. Let { t 1 ,t 2 ,...,t M } be a set of moments in time, where the transition function f is de fi ned, f ( t i )= x i  X  X .The fi ltering is performed by setting f ( t i )=  X  if t i  X  t i  X  1 &lt;t min . In terms of states and transitions it means that if in a sequence of states x i  X  1  X  x i  X  x i +1 , state x i takeslessthan t min , it will be fi ltered out and the sequence will become x i  X  1  X  x i +1 . The effect of the proposed fi ltering approach is illustrated in Table 2 demonstrating its performance in removing user input mistakes and simpli fi cation of the resulting state-transition diagram. 3. Visualization
Finite state automaton can be seen as a directed graph [14] and any common graph visualization approach can be applied [10]. In the fi rst part of this section we describ e how annotation s tate-transition diagrams can be visualized using freely available tools Graphviz [15,16] and Cytoscape [17,18]. In the second part, we brie fl y discuss the disadvantagesof existing tools and propose an interactive visualization software developed within the framework of the  X  X vents in the world X  project [19]. 3.1. Using the existing tools
Graphviz is an open source  X  X ackage of practical tools and libraries for manipulating graphs and their drawings X  [16], which uses DOT language to de fi ne graphs. DOT follows intuitive human-readable syntax (see Fig. 7) making it easy to start using the Graphviz suite and produce simple as well as customized graph visualizations. In order to visualize an annotation, one can directly apply the algorithm proposed in the previous chapter and out put the resulting state-t ransition diagram in DOT format. After that, the DOT fi le can be edited to customize the attributes of the graph, for example, graph layout algorithm, colors and shapes of nodes, thickness of lines, and many more. Then, the customized DOT fi le is rendered into one of the popular image formats, e.g. PNG, PDF, JPG or other. The illustration in F ig. 4 is an example of a state-transition diagram produced by Graphviz rendered using the spring-force layout [20]. Graphviz -based visualizations of state-transitions diagrams have been used in our research [9,21,26].

Cytoscape [17] is  X  X n open source software platform for visualizing complex-networks and integrating these with any type of attribute data X . The platform was originally developed to deal with bioinformatics network data, but the level of generality and open architecture allows its application in many network related areas, like social network analysis, semantic web, genome research and others. In contrast to Graphviz , which provides graph layout and rendering functions producing a rather static visualization, Cytoscape provides a rich functionalGUIallowing fl exible interaction and processing of the network. The user can browse it, modify by adding or removing edges and nodes, arbitrarily de fi ne and edit node and edge attributes, manually rearrange the layout as well as apply various layout algorithms. The system provides GUI-driven search and fi ltering functionalities for interactive construction of search queries and fi ltering criteria. One of the most useful features of Cytoscape is VizMapper TM  X  an interactive interface for mapping node and edge attributes into the visual style of their graphical representation. Both continuous or discrete attributes can be mapped into, for example, node size, thickness of lines, colors, shapes and many more, making Cytoscape a very powerful instrument for network analysis.
Analogously to a Graphviz -based approach, in order to visualiz e the annotation state-transition dia-gram, one needs to convert the resulting d iagram into one of the formats supported by Cytoscape and import it (e.g. GML format [22]). In our research, we used Cytoscape -based visualizations to study pat-terns in a teacher X  X  use of classroom space [23], see Fig. 5 for an example diagram visualizing diagram attributes using node size, color, shape and edge thickness and color. 3.2. Proposed interactive visualization tool
Though existing software provides powerful tools for the visualization and analysis of networks, and we have shown how these tools can be generally applie d to annotation sta te-transition diagrams, there is still a common drawback. The dynamic, time-base d connection between annotation and the source media is lost in conversion. Though one can record th e time stamp of every transition as an attribute of the edge, it still remains dif fi cult to see how states and transitions are activated in synchronization with the original media. The network representation is powerful for revealing patterns and outliers in the annotation, but locating a state or transition in the source media, or seeing ho w a particular sequence of transitions unfolds in real time requires a signi fi cant effort from the analyst.
In order to facilitate the analyst X  X  need to synchronize state-transition diagrams with the original media, we developed a software application, which provides the following functionalities:  X  implements the proposed algorithm convertin g annotation into a state-transition diagram  X  allows applying several graph layout algorithms as well as modifying the layout manually  X  implements browsing of state-transition diagrams  X  synchronizes the state-transition diagram with th e original media, enabl es synchronous playback
The GUI of the proposed visualization application is presented in Fig. 6. The fi gure illustrates the state-transition diagram created for the same analysis as the one from Fig. 4. Area (1) is a network view; the user can interact with a current layout by rearranging the nodes manually or by applying one of available layout algorithms from Layout tab (5). In the current version of the tool we allow applying circular , KamadaKawai spring force and G  X  ursoyAtun layouts algorithms implemented by open-source Boost Graph Library [24]. Area (2) is a standard media player interface, which is synchronized with a network view (1), where currently active state is emphasized using a playhead item (8); the corresponding playback position is visualized in a player X  X  slider control; the next and previous transitions in the diagram are highlighted (7) allowing the user to see where the state in the system is  X  X oming from X  and  X  X oing to X . The contents of currently active state are visible in the  X  X tate view X  area (6). Playhead (8), current path (7) and state view (6) are updated in synchronization with the video (2) showing how the con fi guration of the state-transition diagram unfolds dynamically. Besides playback, the user is able to navigate through the media using a diagram (1) by jumping to the next or previous state using Next and Prev push buttons (3) or by double clicking on any of the diagrams transiti ons. In the former case, the media is rewound to the time stamp associated with the clicked transition. The user is also able to play current state only using Play State button (4), which causes the player to stop at the next transition. The software is implemented using QT GUI framework [25] and, therefore, available for Windows, Mac OS X and Linux platforms.
The proposed interactive interface restores time-based connection between state-transition diagram and the original media, which is lost when other tools are used. The analyst can see how the analysis unfolds in the diagram as the movie plays, use the diagram to locate points of interest in the source media and interactively trace common and outlying patterns in the analysis. It is also worth mentioning that similarly organized interface can be utilized in any application where categorical descriptions are used to model dynamically unfolding phenomena. 4. Case study The following case study is part of a larger project conducted within the Events in the World project. This project is concerned with describing how business news events are mediated on television and the Internet by using prototype software and interactive software tools for the analysis of multimodal business news videos [26]. The data in this paper comes from a sample of 200 analyzed videos clips from a corpus of more than 800 videos released on the internet by popular business news networks such as Bloomberg, CNBC, FOXBusiness and Reuters. Combining social semiotic theory, conversation and discourse analysis, as well as other interdisciplinary approaches and methodologies, the study investigates the mu ltiple patterns, strategies, and resources that are drawn upon, often simultaneously, for representing social actors and events through the dynamic interplay of live or recorded video footage, displays of on-screen text, graphics, logos, still images, s tudio props, etc., and dia logic representations, and how these multimodal systems interact.

The case study in this paper explores how static and interactive graphic visualization tools can facilitate the inquiry into who or what is represented in which mode or medium, by affording the researcher with alternative perspectives on the analysis performed in a tier-based digital interface [9,21]. Two types of state-transition diagrams are used: static and dynamic. Static diagrams (Figs 7(a) and 8(a)) are produced using Graphviz software package. Dynamic diagrams are created and investigated using the proposed software tool, corresponding screenshots are presented in Figs 7(b), (7c), 8(b) and (8c). In this particular case, state diagrams were used to explore how much time is allocated to varying degrees to representations of social actors in different modes and media (e.g., visual, verbal, visio-textual) in two video clips of a related event by Bloomberg (set of Fig. 7) and CNBC (set of Fig. 8). From a social semiotic perspective, the amount of time can be indicative of the relative degree of the power and authority that is being bestowed upon corresponding social actors by the news organization.

State-transition diagrams rendered in Graphviz (Figs 7(a) and 8(a)) allow choices in the representation of social actors to be visualized in the form of differently shaped nodes in various shades of colors on the basis of a pre-de fi ned color-coding scheme determined by the analyst. Numerical values, in our case the amount of time that is accorded to multimodal repre sentations of so cial actors, can also be directly visualized by including it into the state X  X  caption.

While static visualizations are a powerful resource for revealing overall patterns in representations, dynamic visualizations (Figs 7(b), (7c), 8(b) and (8c)) afford the analyst with the opportunity to further correlate a particular state or transition in the sate diagram with the actual sequence of events as they unfold in real time in the news video. Visualized in the form of dynamic state diagrams, the data further reveals that the amount of time that is allocated to varying degrees to multimodal representations of social actors in dynamic video footage is closely bound up with the respective discourse type or genre that is the preferred medium of communication for a particular news agency. Used in combination, the two visualization techniques can assist the researcher in identifying patterns in representational states (including non-activated choices), which would otherwise be dif fi cult, if not impossible, to detect using conventional analytical methods.

Our study yields that in news interviews with certi fi ed experts released by Bloomberg  X  which is its preferred type of communication for video clips released on the internet (49 out of a sample of 76 news videos)  X  instances of self-naming by anchors/presenters, or identi fi cation by way of on-screen nomination, are the exception rather than the norm (Fig. 7(b), label (1)), as certain states are not re fl ected in the state-transition diagram (Figs 7(a), diagrams b) and c)). On the other hand, interviewees, who are called upon to comment on an event in the capacity of certi fi ed experts, are always identi fi ed verbally by the anchor or presenter (Figs 7(a) and (7b), label (2)) at the beginning of the video sequence, as well as visio-textually through multiple, peri odic displays of on-screentext in th e lower thirds (Figs 7(a) and (7b), label (3)). The primary visual focus in this video is centered fi rmly on the unfolding dialogue between anchor/presenter and interviewee, represented by the dense sequence of circular and box-shaped nodes labeled (1) and (3) in the static diagram (Fig. 7(a), diagram a)), with certi fi ed experts being accorded the majority (60.12%) of total on-screen time. In contrast, the social actor or newsmaker, who is featured as the central topic of the event, is marginalized visually in the video text, as indicated by the outlying states labeled (4) in the state diagrams (Figs 7(a) and (7c)) and accorded only a small amount of dedicated onscreen time in the form of embedded actuality footage (0.72%). The event itself is represented largely visio-textually in the form of periodic displays of on-screen text in the lower thirds (Figs 7(a) and (7c), label (5)).

In contrast to Bloomberg, where the anchor/presenter remains largely anonymous in the video text, in a video clip of the same event released by CNBC  X  which favors multi-part y panels, round-table discussions and other hybrid discourse formats  X  the authority of the main presenter, or rather af fi liate expert who is called upon to speak in the capacity of the network X  X  senior economics reporter, is rati fi ed fi rmly in the form of a visio-textual display (Fig. 8(a), diagram b), label (6); Figure 8(b), label (6)). Not only is he the only social actor identi fi ed explicitly through on-screen characters, the af fi liate expert is also the only discourse participant who is granted exclusive on-screen space (Fig. 8(a), diagram a), label (6); Figure 8(b), label (6)). As shown further in the dynamic state diagram, in this particular video, the af fi liate expert also forms the core of a sequence of synchronous visual-verbal clusters (Fig. 8(b), labels (7) and (9)) through which the event is event is mediated cross-modally (26.61% in terms of total video time).

Conversely, expert interviewees (Fig. 8(c), label (8))  X  although introduced by means of dialogic naming (visualized in the form of an egg-shaped node in Fig. 8(a), diagram c), label (8))  X  are not identi fi ed by way of on-screen text. Nor are they accorded exclusive on-screen time, as indicated by the box-shaped nodes in Fig. 8(a), diagram a), label (8). Instead, they have to negotiate and compete for visual, temporal, as well as dialogic space with anchors/presenters, af fi liate experts and other panelists (not shown in the screenshots of interactive state data), which collectively occupy about one third of the total on-screen time, as well as several other competing discourses composed of  X  X ive X  actualities of dynamic video footage and digital displays that unfold simultaneously on-screen (Fig. 8(c), labels (9) and (10)).

Our study revealed that business news networks vary considerably in the way they represent social actors and events, not only in terms of the preferred mode and medium used for presentation, but also in terms of the amount of time that is allocated to individual representations. The above case study has demonstrated that by comparing static and dynamic visualizations of state data, the researcher is in a better position to make empiri cally informed judgments about the d ifferences (and similarities) in the representation of social actors and events by different news networks, which would otherwise be accessible and pr esentable only through intuition and qua litative inte rpretation. 5. Conclusion
In this paper we discussed different aspects of using state-transition diagrams for visualization of multimodal annotation data. We presen ted a short introduction into the fi eld of Social Semiotics and Multimodal Analysis, proposed the algorithm constructing fi nite-state automaton given the multimodal annotation and proposed a fi ltering technique removing imperfec tions of user X  X  input from the resulting state-transition diagram. We discu ssed how annotation state-transition diagrams can be visualized using freely available software tools, presented bene fi ts and problems of such approach. Further, we motivated the necessity for and proposed an interactive visuali zation tool able to synchronize the state-transition diagram with the original media fi le. The proposed software tool give s the analyst the ability to see the analysis dynamically unfolding, browse and locate points of interest in the analysis in connection with the media being analyzed. Finally, we presented a case study analyzing presentations of business news events by Bloomberg and CNBC networks to demonstrate how the proposed techniques are applied in real world social semiotic analysis.
 References
