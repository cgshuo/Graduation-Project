 MAREK LIPCZAK and EVANGELOS MILIOS , Dalhousie University Collaborative tagging is a recently popularized information management approach. Free-form tags allow large communities of us ers to collaborative ly create accessible repositories of Web resources (e.g., references to scientific literature in CiteULike , bookmarks in Delicious or programming questions in Stack Overflow ). Each resource is entered into the system in the form of a post ,whichcombinesthe resource ,the user who is posting it and a set of tags . The tags position the resource in a folksonomy ,a self-emerging structure that organizes all posts gathered in the system. In this article we use a classification scheme proposed by Wal [2005], which divides folksonomies into broad folksonomies and narrow folksonomies . In broad folksonomies the same resource (e.g., a bookmark or reference to a scientific publication) can be added to the system by many users. These users are not the authors of the resource, but each of them can use a personal set of tags to describe it. In n arrow folksonomies a resource (e.g., blog or forum entry) can be added to the system only once by its author. The author is also the only person who tags the resource. As we will show, the two folksonomy types have different characteristics but can be addressed with the same tag recommendation approach. One of the main advantages of tagging is the lack of a predefined classification system, which reduces the constrains imposed on users. On the other hand, because users are not supported by the classification system, they have to come up with a set of descrip-tive tags on their own. This is a cumbersome and labor-intensive task. The objective of a tag recommender is to ease this process and propose potentially useful tags. Apart from its practical importance, tag recommend ation is an interesting research problem. The complex structure and the large amount of information gathered in folksonomies create lots of potential solutions, which is reflected by the variety of proposed tag rec-ommendation systems. An opportunity to compare these approaches was introduced by the ECML/PKDD Discovery Challenge 2009 [Eisterlehner et al. 2009]. The tag recommendation systems were compared in three tasks including online evaluation, in which the tags were judged by real users. Our own system [Lipczak et al. 2009] submitted to the challenge achieved two first places (content-based and online recom-mendation) and one third place (graph-based recommendation). The key to its success was simplicity and utilization of the combined advantages of various tag sources: re-source title, tag profiles of resources and users (tags that were previously used for the resource or by the user), as well as associations between title words and tags. Encouraged by the outcome of the challenge, we looked at our system from a broader, more practical perspective. We defined and utilized three features of a practical tag recommendation system.  X  Generality. Each collaborative tagging system has its own specific characteristics (e.g., personal or social character of posts). These differences are likely to have impact on tagging decisions made by users, hence they should be taken into con-sideration while designing a tag recommendation system. Manual tuning of system parameters has obvious limitations; therefore, the recommendation system should be able to automatically adapt to these characteristics. A learning algorithm in-corporated into our system performs automatic parameter tuning to optimize the results based on tags entered into the system by users.  X  Adaptability. Tag recommendation is a dynamic p rocess. Each recommendation is instantly followed by the real tags entered by the user. This feedback loop constantly brings new valuable information to the system. Our system uses the content of each entered post to update the resource and user profiles as well as the associations between title words and tags. The main advantage of such online content adaptation is the improved quality of tags extracted fr om a user profile, which adapts to current interests of a user.  X  Efficiency. The tag recommendation system should be able to handle the large size of repositories created collaboratively by users, the open-ended vocabulary of tags, and still remain efficient enough to produce results in real time. At the same time, tag recommendation is just an extension to the collaborative tagging system, so it should be able to operate with limited computing resources. Our system meets all these constraints thanks to its architecture, which is based on a text indexing engine with an additional cache layer.

In comparison to the system used in the Discovery Challenge, the new version is not constrained to a single dataset, but is able to automatically tune its parameters utilizing the user feedback. The feedback also allows the system to significantly im-prove the quality of recommended tags, thanks to the fact that newly added tags are instantly updating the models used in the recommendation process. However, the key new feature is the new system architecture, which greatly improved the efficiency and scalability of the system. Overcoming the limitations of the previous version of the sys-tem allowed us to run an extensive evaluation on six real-life datasets with sizes rang-ing from over two hundred thousand to nearly nine million posts. Unlike the common approach, we did not constrain the datasets by removing infrequent tags, resources, or users. In our opinion, these elements should not be treated as noise as they are a large and valid part of folksonomies. To create the most realistic conditions of off-line eval-uation, we reproduced the process of folksonomy generation based on the time-stamps of the posts. The results demonstrated the ability of the system to combine tags from different sources to achieve the best quality of recommended tags. Additional experi-ments showed that, although the system operates on an open-vocabulary of tags, it is able to remain accurate for the most frequent tags. In addition, the experiments re-vealed valuable insights about the future directions of system development: extraction of textual content-based tags and personalized parameter learning. Tag recommendation systems can be divided into three categories: graph-based, content-based, and hybrid systems. Graph-based techniques utilize cooccurrence re-lations among users, resources, and tags represented in a folksonomy graph .Inmost cases graph-based recommendation is addre ssed with collaborative filtering methods. Content-based techniques are based solely on the textual metadata related to the re-source. Hybrid systems usually combine these two types of input. J  X  aschke et al. [2007] proposed a graph-based tag recommendation system based on FolkRank, an adaptation of PageRank to the folksonomy graph. Given a resource-user pair the system increases their weights in the folksonomy graph and runs FolkRank to spread the weights in the graph. Tags with the highest weights are returned as recommendations. The process has to be run for each incoming post, which makes the system inefficient. Symeonidis et al. [2008] used a generalization of Singular Value Decomposition to model the relations among users, resources, and tags. Each of these triplets is assigned a probability value. Given a user and resource, the system simply returns the most probable tags related to them. Hence, the recommendation process in an already trained system is very efficient. This idea was extended by Rendle et al. [2009] and Rendle and Schmidt-Thieme [2010]. As both methods rely on tensor fac-torization, the efficiency and scalability of the training process is questionable. Apart from the efficiency problem, the main limitation of graph-based methods is the need for a densely connected graph. The commonly accepted approach to address this prob-lem is graph pruning up to the point where all nodes (resources, users, and tags) occur in at least p posts (p-cores) [J  X  aschke et al. 2007]. The pruning process results in a greatly limited dataset due to the sparsity of folksonomy graphs. These methods are also not applicable to narrow folksonomies, in which each resource is posted only once. These limitations question the practical usability of the graph-based systems. One of the first content-based recommenders was presented by Lee and Chun [2007]. The system recommends tags retrieved from the content of a blog, using an artificial neural network. The network is trained based on statistical information about word frequencies and lexical information about word semantics extracted from Song et al. [2008] viewed the tag recommendation task as a multilabel classification problem. A Gaussian process framework is used to creat e a classifier that trains on the content of Web resources (title and short description). Each class corresponds to a topic that is represented as a profile of tags. The tags from different profiles are later combined to create the final recommendation. Although the content-based methods are not limited by the uniqueness of resources, their practicality is still in question, as they rely on computationally intensive machine learning tools. In addition, these methods are only able to reuse the tags that are already present in the system frequently enough so the classification models can be built for them. Hybrid tag recommendation systems try to combine the advantages of resource con-tent and folksonomy graphs. As they usually start the recommendation process with the resource content, they are often classified as content-based methods. Graph-and content-based systems usually adapt the tag recommendation problem to a well known machine learning approach. In comparison, hybrid systems try to utilize specific strengths of information sources in folksonomies. Such an approach allows them to be more efficient and process a wider variety o f posts, hence makes them more practical. Our system follows this tag recommendation approach. Among many proposed hybrid systems we mention three that are most related to our work. Tatu et al. [2008] pro-posed a system based on tags extracted from resource and user profiles. The set of tags is extended using NLP techniques and later merged with content-based tags. A system by Ju and Hwang [2009] scans the content of previously tagged documents to evaluate the likelihood of a content word being used as a tag. The likelihood is later used as a score for words that occur in the content of currently posted resources. The content-based tags are linearly combined with tags from resource and user profiles. Musto et al. [2009] based their system on a search engine. The system retrieves resources with content related to the posted resource title and builds the recommendation based on prominent tags from their profiles. Specific attention is given to resources posted previously by the author of the current post. Our system combines the advantages of these methods (utilization of various sources of tags and scalability of a search engine) and extends them by unique features such as exploitation of cooccurrence relations between content terms and tags and utilization of temporal patterns for user profiles.
An interesting perspective on hybridization in tag recommendation was presented by Gemmell et al. [2010]. Unlike other approaches, their system is based solely on the information extracted from the folksonomy graph and does not use the resource content. The system is based on six simple recommendation models, which include the most frequent tags from resource and user profiles as well as four collaborative filtering methods with different ways of calculating the similarity between users and resources. The authors tested the performan ce of the hybrid, as well as its components, showing interesting differences in tagging behavior between various datasets. Combi-nations of simple recommenders that exploit specific data dimensions is able to match or outperform state-of-the-art graph-based approaches [Rendle and Schmidt-Thieme 2010]. It is important to mention that the authors extracted p-cores from each of the datasets to focus on the dense core of the folksonomy graph. P-cores can be extracted only for broad folksonomies, and even then, they contain only a small fraction of all posts entered into the system. Therefore, p-cores completely change the character of the tag recommendation problem. The obje ctive of our work was to design a tag rec-ommender capable of producing a recommendation for all posts entered into a system. In our opinion, this is a more realistic problem. Our system is built of five basic recommend ers (Figure 1): (a) a title recommender, which extracts tags from a resource title, (b) two profile-based recommenders, which are based on tags from resource and user profiles, (c) two graph-based recommenders, which take tags extracted from the title as input and run a spreading activation algo-rithm [Cohen and Kjeldsen 1987] using title-to-tag or tag-to-tag cooccurrence graphs. The main idea behind the design of the recommender is to utilize the specific advan-tages of each source of tags and combine the results produced by each of them. Each recommender produces a tag recommendation set, which is a set of proposed tags with assigned scores, s  X  [0 , 1]. The tag recommendation sets are combined by mergers which take two tag recommendation sets as input, linearly rescore the tags given the merge coefficient p merge  X  [0 , 1], representing the relative importance of both sources of tags, and merge the sets adding the scores of the tags that can be found in both input sets. The values of the merging coefficients are learned based on real tags from user feedback. The learning approach is discussed in Section 6.2. Title recommender. The processing starts with tags extracted from the resource title. The title is a dense description of the resource, which is likely to influence the tagging decisions of users [Lipczak and Milios 2010a]. The score attached to each title word represents its use in previous posts, calculated as the number of posts for which the word was both a title word and a tag, divided by the number of posts for which it was a title word. Words with low score are removed to increase precision. This step serves as a dataset and language independent stop-word filter. As the title is the only element of resource content that can be found in all collaborative tagging systems and is the most precise source of tags among content elements, it is used as the only source for content-based tags.

Title-to-tag recommender. To maintain the consistency of their profiles, users often choose to modify the tag that describes the concept represented by the title word [Lipczak and Milios 2010a]. For example, term, network, can be modified to networks, or more specifically social-network. To gain access to other forms of the term and related terms, the system runs a spreading ac tivation algorithm on a directed cooccur-rence graph of terms that were used as title words or tags. The weight w ij of the edge between two terms is equal to the number of posts in which they occurred together X  the term i as a title word and the term j as a tag, divided by the total number of occurrences of the term i as a title word. Spreading activation is a technique used broadly in various areas from Artificial Intelligence to Information Retrieval. Given a directed weighted graph, it can be used to search for related elements in the graph (e.g., concepts in a semantic network [Cohen and Kjeldsen 1987]). Starting with a set of input nodes with assigned output values O i , the algorithm activates nodes con-nected to them assigning them an input value I j , which is calculated based on an input function. In a general case, the input is then processed to form output values that are used in the next pulse of the algorithm. However, to avoid overgeneralization, our sys-tem accepts the output of the first pulse as the result of the process. The output value O i is the score attached to a word by the title recommender. The input of an activated tag I j is used as the score of the title-to-tag recommender. The input function uses the formula for the union of probabilities of independent events (Eq. 1) to ensure that the produced scores are in the [0 , 1] range.
 Tag-to-tag recommender. An analogous approach can be applied to a tag-to-tag graph. The graph captures the relations between tags that frequently co-occur in the same posts. Unlike the title-to-tag graph, this graph is not likely to represent connections between terms that convey similar meaning because most users try to avoid redun-dancy while tagging. The objective of this graph is to capture hypernymic relations between tags. The system runs spreading activation on the tag-to-tag graph using the set of tags extracted from the title. The tags extracted from both graphs are merged producing a set of content related tags.

Resource profile recommender. Tags related to the resource content are extended by the tags extracted from the resource profile (all tags previously used for the resource). The score of a tag extracted from the profile is its frequency (the number of posts in which the tag was used for the resource), divided by the total number of posts of the given resource. The collaborative effort of user s makes the resource profile a very precise source of tags. Unfortunately, this source is rarely usable, as many of the resources added to broad folksonomies are unique [Lipczak et al. 2009]. This is also the case for all resources in narrow folksonomies. This is why, in our system, resource profile tags are only a supplement to the content related tags. Together they create resource related tags.

User profile recommender. User profile is a very rich, but noisy source of potential tag recommendations. It is likely to contain tags representing different users X  interests and activities, which change dynamically. Tags frequently used in the past are not necessarily a good current re commendation. To adjust to this fact, the user profile recommender uses an additional recency-based scoring scheme, to complement the frequency-based scheme, as in the resource profile recommender. Both schemes pro-duce two identical sets of tags with different scores. The sets are later merged, so the final score is a linear combination of the scores proposed by both schemes. The out-come of this recommender is a set of user related tags . Finally, resource related tags and user related tags are merged to produce the final recommendation .

As the system is a hybrid tag recommender that utilizes several tag sources, there is a large space of possible combinations of basic system components. The proposed system structure is based on two objectives. First, we wanted a system with a structure that can be easily explained to the users. Second, to reduce the complex-ity of parameter learning, we limited the number of merger inputs to two. The large amount of processed data, as well as the need for short response time, make the system architecture a crucial aspect of the design process. The main challenge in the implementation of the presented tag recommendation system is the representation of the cooccurrence graphs and the tag profiles (for resources and users). In both cases it is clear that, given the amount of data and open-ended vocabulary, they cannot be stored in operational memory. The system architecture must consider various aspects of post processing:
Recommendation. To perform a recommendation task the system needs to extract two tag profiles (for the resource and the user) and a series of references to the cooccurrence graphs. The number of these references is limited by the size of the content based recommendation set. To simplify the prob lem, the cooccurrence graph lookup can be reduced to the tag profile lookup task. A tag profile for a term represents all tags that cooccurred with it in any of the posts, while the frequency of cooccurrences can be used to calculate the weight of the connection. To extract a tag profile for a post element (user, resource, tag, or content word) the system uses a text indexing engine (Apache Lucene 1 ), which stores all previously processed posts. By accessing the Lucene index directly, the system is able to quickly retrieve a list of posts that contain a given element. As the extraction of posts is a much more time consuming task, we decided to limit the number of posts on which the profile is built, to the 1000 most recent posts that contain the element.

To reduce the number of references to the index, the system contains a layer of caches (Figure 2). Each element type has a separate tag profile cache. If the system hits the profile in the cache, it does not have to refer to the index. In case of a miss, the profile is built based on the information extracted from the index. If the element was used in over 20 posts, its profile is added to the cache replacing the profile with the low-est value of the replacement function. We experimented with two basic replacement policies: Least Frequently Used and Least Recently Used and found their performance inconsistent. In the system, we decided to use a combination of recency and frequency factors (Eq. 2), which in most cases is able to match or outperform the better of the basic policies. To examine the performance of the cache layer we measured the cache hit ratio for different cache sizes applied to broad folksonomy datasets (see Section 5 for dataset details). Although the cache performance differs depending on the element type and dataset characteristics, the cache of 5000 element profiles is enough to obtain over 80% cache hit ratio. Indexing. Whenever a new post is added to the system, it is stored in the text index. Each of the post elements is indexed separately. In addition, the tags entered by the user are used to update each of the relevant profiles in the cache layer (Figure 2). This approach solves the cache synchronization problem without the need for additional in-formation extraction from the index. To better control the memory usage, the system has a hard constraint on the maximal size of a profile. Tags, that are relatively rare in the profile or have not been entered into it recently, are not likely to become promi-nent enough in the recommendation process to reach the top of the list that is finally presented to the user, so they can be omitted. To retain potentially useful tags, the profile itself is also implemented as a cache, using the same cache replacement policy (Eq. 2). All the constraints put a hard limit on the memory allocated to the storage of the profiles in the cache layer; however, they can potentially decrease the quality of recommended tags as they limit the number of posts and tags used in the recom-mendation process. To investigate whether this is the case we removed the constraints from the system and ran it for the BibSonomy dataset (see Section 5 for dataset de-tails). The difference in the quality of the results produced by the constrained and unconstrained version is negligible. Therefore, the constraints on posts and tags do not play a negative role in the recommendation process.

Parameter tuning. The tags entered by the user are also passed to the feedback pro-cessing module , which is responsible for tuning the mergers. The module stores the input sets used by all mergers while processing the post. Given the user tags, it is able to reproduce the merging process for differe nt values of merge coefficient and learn the optimal value online. The system has no parameters that would have to be defined by the administrator to tune its performance towards a specific underlying collaborative tagging system. In addition, as both indexing and parameter tuning is done every time a post is added to the system, there is no need for additional reindexing or retraining steps, which greatly simplifies system maintenance.
 To examine the practical usability of the system, we ran efficiency tests using the Delicious dataset, containing around 9 million posts. To avoid the bias caused by fac-tors like disk caching, the experiments were run on a personal computer rather than a high-performance computing server. The experiments confirmed that, even given limited resources, the system is able to maintain high throughput (around 200 posts per minute) and low response time (majority of tag recommendations were produced in less than 100 miliseconds). More detailed efficiency evaluation is presented in Lipczak and Milios [2010b]. In this article, we decided to focus on the evaluation of the results of recommendation process.
 To evaluate the presented tag recommendation system we used datasets from six col-laborative tagging systems, including three broad, and three narrow, folksonomies. The basic statistical information about the number of posts, tags, resources, and users in all datasets, after the preprocessing stage, is presented in Table I.
BibSonomy dataset. BibSonomy 2 is a repository of Web page bookmarks and refer-ences to scientific publications. BibSonomy administrators make their dataset avail-able every half year. The dataset used in our experiments contains all public posts entered into the system before July 2010 as well as the metadata information of the posted resources.
 CiteULike dataset. CiteULike 3 is a repository of references to scientific publications. The full CiteULike dataset, available for research purposes, is updated daily. The dataset we used contains posts entered into the system before July 2010. Unfortu-nately, the CiteULike dataset does not contain resource information, including the resource title. To obtain this information we queried the system retrieving BibTeX metadata information for resources tagged with one out of 3000 midfrequency tags. From this metadata we extracted titles that matched 65% of the posts of the origi-nal dataset. Only these posts were used in the experiments. During this process no information about real user IDs was accessible.

Delicious dataset. Delicious 4 is a popular social bookmarking site. Despite the fact that Delicious does not make its dataset publicly available for research purposes, its size and popularity makes it a frequent object of crawling. To evaluate our system, we used a combination of two Delicious snapshots, which contain full post profiles of over 13 , 000 users [Bender et al. 2008] and 900 , 000 users [Wetzker et al. 2008]. As the for-mer does not contain post time-stamps and the latter does not contain resource titles, both snapshots had to be merged. The detaile d description of the merging process can be found in Lipczak and Milios [2010a]. In the experiments, we used around nine mil-lion posts for which all needed information was known. The posts were entered into Delicious between September 2003 and April 2007.  X  Stack Overflow dataset. Stack Overflow 5 is a questions and answer forum for pro-grammers. Stack Overflow makes all information gathered in the system publicly available monthly. The dataset we used contains posts entered into the system be-fore August 2010. We used only the question posts, which were tagged by their authors. Each post contains a short description of a programming problem and its title.  X  BlogSpot dataset contains blog posts from the blogspot.com domain (owned by Blog-ger service) crawled by Spinn3r 6 between August 1st and October 1st, 2008. The dataset was released for the ICWSM 2009 Data Challenge. 7  X  WordPress dataset. Analogously to the BlogSpot dataset, the WordPress dataset contains blog posts from the wordpress.com domain extracted from the ICWSM 2009
Data Challenge dataset. All tags used in the experiments were lowercased. We cleaned the datasets looking for two types of posts that can bias the evaluation of a tag recommendation system:  X  Imports. Collaborative tagging systems allow u sers to import their resources from external repositories (e.g., browser bookmarks) or other collaborative tagging sys-tems. In most cases, the posts are given the same automatically created set of tags. It is especially important to remove such posts because they can strongly bias the results of tag recommendation evaluation. We eliminated posts containing tags that likely marked the imported posts (e.g.,  X  X irefoxbookmarks X ). In addition, we removed large groups of resources with the same tags posted by a single user in a short time period and posts of the same user with different tags, if the time differ-ence between two posts was lower than two seconds. This technique is not effective for Delicious data because, while importing posts from browser X  X  bookmarks folder,
Delicious copies the original time-stamp of the bookmark and uses subfolders names as tags, making these posts hard to distinguish from real posts. This import removal step resulted in significant changes of the da taset characteristics (e.g., reduction of the number of BibSonomy posts by 60%).  X  Spam. Tagging systems are frequent targets of spamming as they are well posi-tioned in search engines and allow quick addition of content. Similarly to imported posts, large number of spam posts of a similar pattern could potentially bias the performance of the tag recommendation s ystem. We manually browsed all datasets looking for spamming activity, but we did not find any large group of suspicious posts. For the Delicious dataset it is likely due to the fact that one of the source datasets was crawled based on fan links between users, who were not likely to link to spammers. All the companies and services that released the other datasets use some measures of spam prevention. In preparation for the evaluation, we sorted the posts chronologically and separated roughly the latest 20% of posts to test the system; the 20% of the posts that pre-ceded them were used to tune the system parameters. The division was made just to clarify the presentation of the process. In the system in operation, indexing, parameter tuning, and recommendation are done simultaneously in a single run.

While evaluating the system, we assumed t hat all, and only, correct tags were pro-vided by the user. We decided to adopt this approach because of its simplicity and popularity, although it has certain limitations [Gemmell et al. 2009]. Following this assumption, we compared a ranked list of recommended tags with the set of real tags provided by a user. The task is analogous to standard Information Retrieval tasks, hence the basic IR measures are used to evaluate tag recommenders (e.g., precision, recall, f1 score [Eisterlehner et al. 2009], mean average precision [Krestel et al. 2009]). In our opinion, a tag recommendation system should provide the user the maximal possible number of correct tags, given a hard constraint on the number of tags recom-mended (usually five). If the limit of tags presented to the user is five, a system that gives the user five tags, the last three of which are correct, is better than a system that proposes only two tags, even if both of them are correct. This is why we decided to adopt recall @5 as the main quality criterion. We also use this measure to tune the parameters of the tag recommendation system. One of the crucial aspects of the proposed tag recommendation system is merging of tag recommendation sets that come from different components of the system. There are four processing stages, at which two input tag sets are merged (Figure 1). Each merger has its individual merge coefficient ( p merge ), which allows for adjustment of the relative importance of the input sets. Tag s from the two sets are linearly rescored by p choice of the merge coefficient influences the quality of the result set, we discretized the range of p merge into 101 values ( p merge = 1 represents tags from the first input set only and p merge = 0 represents tags from the second input set only). We used the 80% of the posts with the earliest time-stamps to build the folksonomy and then we iter-atively, in timestamp order, added the remaining 20% of test posts to the repository calculating the average quality score ( recall @5) for each value of p merge .Asaresultwe obtain the merge quality curve , which is the quality score (recall@5) as a function of the merge coefficient, for each merger (Figure 3). The comparison of the curves shows that each merger has its specific characteristic, which also depends on the dataset. In many cases (e.g., the merger producing user related tags for the Delicious dataset), the optimal value of p merge is closer to the input set with the lower quality, which is coun-terintuitive. In general, the optimal value of p merge tends to be close, but not equal, to one of the extremes. These facts show that the value of the merge coefficient should not be related to the differences in the accuracy of input sets, which seems to be the most intuitive approach. The observations of intermediate results of the experiment suggest another solution to this problem. It seems that the shape of the curve is con-stant for a given merger-dataset pair. As a result, two different subsets of posts taken from the same dataset should lead to the same optimal value of the merge coefficient. In addition, the shape of the curve is smooth, in the sense that a small change in p merge is not able to make a dramatic change in the tag ranking, hence it cannot affect the score. Therefore, it is possible to choose a nearly optimal value of p merge from a discrete number of choices. Given these two observations, parameter tuning becomes a simple optimization task that can be solved by recording the average quality of the merger given a limited set of p merge values and using the value that has the highest quality. We used this learning approach to tune the merge coefficient to a value that overall produces results with the highest average quality. The parameter learning was done on the 20% of the posts that precede the test posts. The learning method is able to discover nearly optimal values of p merge in almost all cases. On the plots, the learned value of each merge coefficient and recall @5 obtained for this value are represented with a cross (Figure 3). The only case in whi ch the learning approach failed to predict the correct value of p merge is the merger producing user related tags for the WordPress dataset. Most likely it is caused by the presence of a large group of users with different tagging patterns in the test set. To mitigate such problems we experimented with on-line adaptation of the merge coefficient based on a sliding window over the most recent posts. However, we found this approach less computionally efficient and slightly less effective for most of the merger-dataset pairs. To observe the impact of online content adaptation on the results and provide a base-line for the system we ran a series of experiments in which this feature was turned off. The parameters of the system were retrained to tune it to the new conditions. Adap-tation improves the results of the recommendations for all tested datasets (Table II). The statistical significance of the difference was confirmed by a Wilcoxon signed-rank test ( P &lt; 0 . 001). For the three broad folksonomies, online content adaptation has a clear impact on the relative importance of different tag sources. We present the plots of recall and precision for each stage of the r ecommendation process, without and with adaptation, to show how they contributed to the final result (Figure 4). For all datasets the largest improvement is noticed for the user related tags. Adaptation allows the system to extend the repository of user related tags by the tags that describe users X  recent interests. The system is also able to gather information about new users from the moment they start to use the system. It is especially important for the BibSonomy and CiteULike datasets, for which we observed a large number of users who started to use the system in the test period. For these two datasets, user related tags become the richest and most accurate source of tags. This is not the case for the Delicious dataset, where the improvement of user related tags is comparable to resource related tags. It seems that the availability of a large number of newly added posts allows resource profiles to overcome the problem of cold start [Krestel et al. 2009] X  X he noisiness of profiles of infrequently posted resources. Finally, the adaptation seems to have little or no impact on the content related tags ext racted from the co-occurrence graphs. The associations among tags are well established at the time of the evaluation and they are not changed by the adapted content. In this case, the adaptation is likely to be useful in the early stage of folksonomy formulation only.

Online content adaptation has less of an impact on the narrow folksonomies. The relative importance of processing stages remains the same independently of the use of online content adaptation. For the Stack Overflow dataset this is caused by the fact that the recommendations are mostly based on the content related tags. The most likely reason of this outcome for blog datasets is the short time span of posts. Comparison of the precision/recall plots for the final recommendation and intermedi-ate processing stages reveals that the impo rtance of tag sources for recommendation strongly depends on the characteristics of the collaborative tagging systems (Table III and Figure 4). Among the broad folksonomies, the results for two similar systems Bib-Sonomy and CiteULike are much alike, while at the same time being different from the Delicious results. The first two systems are used to gather resources related to research interests of the users. Well defined interests of the users result in higher precision and recall of recommendation based on user profiles. In comparison, De-licious gathers bookmarks that represent general interests of users, hence the user based recommendation is noisier. On the other hand, the size of Delicious results in a higher percentage of nonunique resources and allows the recommendation system to take advantage of the resource profiles. Low performance of the resource profiles for BibSonomy and CiteULike reveals an important characteristic of these datasets X  uniqueness of posted resources. The percentage of posts that contain a resource that can be found in only 5 or less posts of the overall dataset is 95% and 80% respectively. This implies that unless the repository contains millions of posts, as in case of the Delicious dataset, resource profile is not a prac tical source of tag recommendations. Among the narrow folksonomies we can observe a clear distinction between Stack Overflow and two blog datasets ( BlogSpot and WordPress ). The authors of program-ming questions posted in Stack Overflow try to design informative titles so they are easier to find by others, which makes the title a rich source of potential tags. Con-versely, the authors of blogs tend to make their titles attractive to catch the attention of the readers. Hence, the overlap between attractive title words and informative tags is low. In addition, the authors of blogs use the tags as a personal classification scheme for their posts which results in higher precision and recall of user based tags. Despite the differences among datasets, our system is able to utilize the most accurate tag sources and combine them in the final recommendation. In all cases recall @5 of the final recommendation is higher than the best basic recommender used as a baseline (Table III). The difference is statistically significant ( P &lt; 0 . 001, Wilcoxon test). The examination of the results of the different processing stages revealed the impor-tance of the two final tag recommendation sets (resource related tags and user related tags). To gain deeper insight into the system X  X  performance we turned off some of its components. We focused on the generation of two tag recommendation sets: content related tags and user related tags (Table IV). The content related tags are a combina-tion of results of the spreading activatio n algorithm on two term cooccurrence graphs: title-to-tag graph and tag-to-tag graph. Discarding the results of one of the graphs has a slight negative impact on the final recommendation results. Although the tags extracted from the two graphs are not identical, there is some overlap between them. Therefore, if needed, one of them can be removed to increase the efficiency of the sys-tem. Discarding the results from both graphs causes a significant drop in system performance. The value of recall @5 for the final recommendation set drops as much as 11% for the Stack Overflow dataset. All other datasets are mostly dependent on the user related tags. The scores in the user related tags set are a combination of two scoring schemes, based on frequency or recency of tag use. Discarding one of the schemes reveals interesting differences between datasets. The recency factor has great importance for broad folksonomies. Possibly, the overall frequency of tag use does not reflect the current interests of the user. The opposite behavior can be observed for blog datasets. Here, the users have a constant set of categories that represent their intrests and they switch between them, often decreasing the importance of the re-cency scheme, up to the point where, for the WordPress dataset, removing the recency scheme increases the quality of recommended tags. This unexpected outcome is the result of a poorly trained parameter, as discussed in Section 6.2. In this section we present the results of a set of additional experiments on the pre-sented tag recommendation system. The contribution of the experiments is twofold. First, they allowed us to gain more insight into the performance of the system and the characteristics of the processed datasets. Second, they determined the future directions of system development. In particular, we were interested in whether the system can be improved using the ideas and methods proposed in other streams of tag recommendation research. Both graph-based recommendation and content-based techniques recommend tags from a fixed vocabulary. In addition, a tag should be used frequently enough to provide information about its usage. On the contrary, our system utilizes title words and newly added user tags, which give it constant access to unique tags. The use of an open-ended vocabulary of tags creates a risk of underestimation of frequent tags. In that case, a possible extension of the system would be to utilize these recommendation methods designed for frequently used tags as an additional postpro-cessing step. To determine if such an extension is potentially useful, we reevaluated the outcome of our system, considering the most frequently used tags only. Another interesting aspect is the utilization of textual content of the resource (other than the title). This issue seems to be especially important for blogs, where the quality of tags extracted from the title is particularly low. To investigate this issue, we repeated the experiments for both blog datasets, replacing the title with a set of keywords extracted from the content using two simple techniques. Finally, we looked into the concept of recommendation personalization. We tried to capture the individual tagging patterns of users by personalized learning of merging coefficients. Unlike graph-based and content-based recommendation techniques, our system does not explicitly focus on frequently used tags, which creates a potential area of improve-ment. If the system failed to recommend frequent tags with high accuracy, its results could be combined with the results of a system that focuses explicitly on these tags. To test whether such an extension is needed, we reevaluated the results of the sys-tem considering the top N  X  [1 , 10000] tags, sorted by the frequency of occurrence in all posts. Posts that contained no tags from the set of the most frequent tags were removed from the evaluation process. It is important to notice that we did not prune the list of recommended tags by removing the low-frequency tags. Although, it would certainly improve the accuracy of the syste m, it would defeat one of the purposes of the experiment, which was to determine if the system needs an additional module to increase the rank of frequently used tags among all recommended tags.

The results of the experiment show that the system achieves much higher recall@5 score considering the most frequent tags only (Figure 5), compared to the results of the system evaluated for all tags (Table III). In most cases the largest improvement is noticed for the top few tags. The accura cy of recommendation decreases with the increasing size of the most frequent tags set, which is an expected behavior, given that less frequent tags would become harder to recommend. The same pattern can be observed for user related tags, which shows that the recency ranking scheme is not impairing the quality of recommendation for high frequency tags. The results for title-based tags show that the title is not a good source of the most frequently used tags, which seem to be too general to be used as title words. However, this limitation is overcome by the use of the spreading activation algorithm, which confirmed its ability to generalize the content-based tags. In fact, for the most frequent tags, the content-related tags have the highest accuracy (excluding the blog datasets).

When focusing on the differences among datasets, we observe a very low system performance for the most frequent tag in the CiteULike dataset ( review ). Review is an example of task organizing tags [Golder and Huberman 2006], which are generally hard to recommend. There is no concrete context in which the tag occurs, therefore it is not well captured in the term cooccurre nce graphs. Our observations show that such tags are in a great minority among all tags, which are generally used to describe a resource. Therefore, we did not design the system to focus on this type of tag. When the context of a tag is well-defined, the cooccu rrence graphs are able to recommend tags with very high accuracy. T he example of such behavior can be observed in the Stack Overflow dataset, where the most frequently used tags are the names of programming languages (Table V). In this case, the spreading activation algorithm, ran on term coccurrence graphs, which su ccessfully replaces a classification algorithm assigning a post to a related category (programming language). A similar situation is observed for the WordPress dataset, where the top tags represent the general categories of posts. On the contrary, the BlogSpot dataset is strongly skewed towards a single topic X  presidential election in the U.S. (the data was collected in fall 2008). The top four tags are related to each other. The most frequent tag, politics , is much more general than the other three tags (names of candidates). In addition, the names of candidates are often used together, which creates strong cooccurrence scores between them. As a result, they are recommended together, downgrading the more general tag, politics , in the recommendation ranking, lowering the accuracy of the system for this tag. The BlogSpot dataset seems to be the only case where a technique tailored for frequent tags could be beneficial. The comparison of the system performance on various datasets revealed the high vari-ability of the accuracy of tags extracted from the resource title. For some types of resources (blog posts) the title is a poor source of content-based tags. In such cases, the keywords extracted from the textual content of the resource (post text) could pos-sibly be a better choice. To examine this possibility, we replaced the resource titles from both datasets by a set of words extracted from the resource content. For clarity and consistency with related work we refer to the blog post text as a document .For a fair comparison to the title words, we limited the number of words extracted from the content to five. Two ranking scores were used. Term frequency-inverted document frequency score (Tf-Idf, Eq. 3) promotes words with a high number of occurrences n w in the document and low relative number of documents d w in the dataset D where it occurred. To capture the additional inform ation about tag usage we modified the Tf-Idf score, replacing the Idf part by the logarithm of the total number of occurrences of a word as tag-tag frequency t w (Eq. 4). Tf-Idf score looks for specific terms that are unique for the document, whereas Tf-tf promotes general terms that are likely to be used as tags.
Surprisingly, despite the difference in t he underlying assumption, both scores pro-duced tags of similar quality (Table VI). Tf-Idf accuracy was slightly below, and Tf-tf slightly above, the accuracy of title words. A lthough the accuracy of content-related tags based on Tf-tf tags is higher, it does not result in the improvement of the final rec-ommendation. It suggests that the low quality of title-based tags is in fact not caused by the title itself, but by the character of tags used for blog posts. Blog datasets tend to have a very rich tag vocabulary. For example the BlogSpot dataset, despite being smaller, contains over ten times more distinct tags than the Stack Overflow dataset (Table I). Over 60% of these tags were used only once. Most of them are tags com-posed of two or more terms, many of these a re names. These characteristics suggest that utilization of resource content as a source of tags is possible, but would require an information extraction approach based on natural language processing techniques (e.g., named entity recognition). As shown in Section 6.2, the system is able to discover the optimal value of a merge coefficient on the merge quality curve. The system uses a set of constant merge coef-ficients for all tested posts, which on the average produces the best result. We refer to this approach as global tuning . Global tuning has a clear limitation. Each of the processed posts has a specific range of merge coefficient values, for which the best com-bination of two input sets could be produced. If the system was able to discriminate between posts that produce best results for different settings of merge coefficients, parameter tuning could be adapted to these specific classes of posts. Given the real tags, we were able to calculate the upper limit in performance of such a modification. We reran the experiments for each dataset assuming the perfect prediction of merge coefficients for each specific post. The quality of the results ( X  X erfect prediction X  in Table VII) shows a wide range of potential improvements for localized parameter tun-ing methods. The most intuitive extension of parameter learning is utilization of the personal character of tagging. As users tend to reuse the same set of tags they could also have specific tagging patterns that would favor one of the input sets of a given merger (e.g., resource-related tags over user-related tags in the system X  X  final merger). This intuition is supported by a recent study by K  X  orner et al. [2010]. The study shows that there are two types of taggers X  X ategorizers and describers X  X ho prefer different recommendation techniques.

We modified the system to train the merge coefficients separately for each user (given that the number of processed user X  X  posts exceeded the threshold of 10). In this case, the feedback processor tuned the pa rameters for both train and test posts, to make personalization possible for new users. As discussed in Section 4, the system is designed for online learning so the only extension needed is the storage of personal parameters. Personalized pa rameter training was able to improve the quality of rec-ommended tags. However, the improvement was lower than expected. We found two potential explanations of this outcome. First, the tagging pattern of a user is to some extent, already embedded in the recommendation process. For example, a user who often reuses personal tags increases the scores of user profile recommender results, giving it an advantage over resource-related tags when these two sets are merged. Second, user tagging patterns are likely to depend on other factors (e.g., type of re-source), hence more complex methods are needed to extract and represent users X  tag-ging patterns. We find evidence for the second hypothesis observing the merge quality curves for specific users. In most cases, they have the same characteristics as the global curve. In addition, the comparison of the number of correct tags found among resource-related and user-related tags revealed that, even when a user prefers one of the tag sources, the other also contains a significant amount of correct tags. The experiments on six real-life datasets revealed important differences among vari-ous tagging systems. Tags can be mostly driven by the resource content (as in Stack Overflow ), have strong social or personal inclination ( Delicious and BibSonomy respec-tively), or be mostly used as a personal categorization scheme (blog posts). We proposed a hybrid tag recommendation system able to utilize various sources of tags that provide the most accurate recommendations for a given dataset, together with a scalable and efficient system architecture that makes possible the processing of large collaborative tagging systems, counted in millions of posts, in real time. The evaluation of specific system components confirmed their importan ce in the tag recommend ation process. It also demonstrated the significance of online adaptation that utilizes tags from newly added posts. These tags are crucial in maintaining up-to-date information about user interests. Finally, detailed experimentation with the proposed system determined two areas of potential performance improvement : extraction of tags from resource content and personalized parameter learning. Although both extensions have the potential to increase the quality of recommended tags, they would require complex natural lan-guage processing and machine learning techniques. The first problem requires the use of named entity recognition techniques to extract multiword phrases that are chosen as tags. The second problem requires a better understanding of user tagging behavior. The user tagging decisions are poorly captur ed by personalized parameters, which sug-gests that they depend not only on the character of the user but also on other factors, like the type of resource or context.

