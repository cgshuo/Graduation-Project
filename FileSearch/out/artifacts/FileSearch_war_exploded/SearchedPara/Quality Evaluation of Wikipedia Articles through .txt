 ticles have been written collaboratively by volunteers around the world, and almost all of its articles can be edited by anyone with access to the site. Wikipedia is currently stantly listed in the top ten most visited websites worldwide. 
Every editable page on Wikipedia has an associated edit history, which is accessed by clicking the "history" tab at the top of the page. The page history contains a list of the page's previous revisions, including the date and time of each edit, the username or IP address of the user who made it, and their edit summary. 
Wikipedia grows in the span of a few years to become one of the most widely used its ability to harness the contributions of millions of individuals, ranging from casual voluntarily by everyday web users, wher eas with traditional encyclopedias, the Encyclopedia Britannica. difficult for visitors to form an idea of the reliability of the content. Wikipedia articles are constantly changing, and the contributors range from domain experts, to vandals, to dedicated editors, to superficial contributors not fully aware of the quality standards the how the article content has evolved into its most current form, nor does it offer a meas-ure of how much the content can be relied upon. These considerations generated inter-est in algorithmic systems for estimating the quality of Wikipedia articles. 
The open access has been known to cause quality problems. The possibility of ma-nipulation and vandalism cannot be ruled out. For example, inaccurate information is occasionally published by opportunistic or inexperienced contributors. Additionally, when articles are not being focused on by the Wikipedia community and hence there cient. As a consequence, the quality and accuracy of any given Wikipedia article cannot be guaranteed. To overcome this weakness Wikipedia has developed several user-driven approaches for evaluating the articles. High quality articles can be marked as  X  X ood Articles X  or  X  X eatured Articles X  whereas poor quality articles can be marked as  X  X rticles for Deletion X . However, these user-driven evaluations can only Wikipedia is evaluated by them. For example in June 2010 only about 0.5% of articles were evaluated in the Wikipedia. Another difficulty of the user-driven evalua-Wikipedia. In this paper we provide a new approach using network structural indica-based on the structure of editors of a certain article through its edit history. 
The rest of this paper is organized as follows. In Section 2, we survey previous re-search about Wikipedia, especially on the trustworthiness and quality measurement of the indicator can affect the quality of articles. In Section 4, we use the proposed indi-existing ones. Section 5 concludes this paper. surprising that numerous researches about Wikipedia have appeared in the last few 18]. Relating to quality assessment there are two divisions of research. The first group investigates the trustworthiness of the text of a Wikipedia article whereas the second one is involved in the assessment of the quality of the article. 2.1 Computing the Trustworthiness of Text The methods in this category offer a means for predicting the accuracy of certain facts colors. Adler and de Alfaro calculate the reputation of the authors of the Wikipedia by using the survival time of their edits as the first step. Then they analyze exactly which text of an article was inserted by precisely which author. Finally, based on the reputa-by using color-coding. 2.2 Assessing the Quality of Articles A first work in this category was published by Lih [12], who discovered a correlation of the quality of an article with the number of editors as well as the number of article number of revisions and the reputation of the authors, which is measured by the total number of their previous edits. Zeng et al. propose to compute the quality of a particu-lar article version with a Bayesian network from the reputation of its author, the num-ber of words the author has changed and the quality score of the previous version[15]. Non-Featured Articles in the English Wikipedia, Stvilia et al. constructed seven com-plex metrics and used a combination of them for quality measurement[18]. Dondio et al. derived ten metrics from research related to collaboration in order to predict quali-number of words, characters, sentences, internal and external links, etc. He evaluates the metrics by using them for classifications between Featured and Non-Featured Articles. Zeng et al., Stvilia et al. and Dondio et al. used a similar evaluation method which enables the evaluation results to be compared. Blumenstock demonstrates, with metric for distinguishing between Featured and Non-Featured Articles. 2.3 Evaluating Method Using Lifecycle W X hner et al. proposed a novel method to calculate quality of Wikipedia articles using lifecycle calculations[20]. Wikipedia includes a great number of articles i=1..n that were edited by the Wikipedia authors during the life span. With every contribu-months, since a shorter period causes overly high volatility of the metrics, whereas a longer period does not enable us to track the metrics precisely. The period in which a call the period in which the article becomes a candidate for the respective Wikipedia evaluation c ( i ). 
For the calculation of the persistent and the transient contributions we have to pa-rameterize the differences between two article versions. Therefore, we define the editing distance dis( i,j,k ) as that which shows the difference between the versions v i,j and v i,k . It refers to the number of words which were deleted from the former version and the number of words which were inserted into the newer version. persistent contribution and the transient contribution. They presented a Wikipedia model for analysis, and based on this model they described the meanings and mea-surements of the persistent and transient contributions. 
To compute the persistent contribution they measured the editing distance between the last article version in a given period and the last one in the previous period. The index of the last version of an article i in a period p was defined as Accordingly the persistent contribution is defined as They define the transient contribution as They used these metrics to assess the quality of Wikipedia articles. The experimental result showed a good accuracy. In our experiment we use the metrics proposed by W X hner as the features in the machine learning technology. We will have a compari-son between the existing methods and our proposed method. We give models and algorithms to describe and analyze the collaboration among authors of Wikipedia from a network analytical perspective. The edit network en-previous network models that code author communities in Wikipedia. Several charac-teristics summarizing certain aspects of the organization process and allowing the Moreover, we propose two indicators characterizing the network structure. We show that the structural network indicators are corr elated with the quality of the associated Wikipedia articles. 3.1 Network Model and encodes how authors contributed to p and how authors interacted with each other has been deleted, or remained unchanged when going from one version of the page to the next. The edit network associated with a Wikipedia page p is modeled as a graph G= ( V, E, A ) , whose components are defined as follows [12]. 1. The nodes V of the graph (V, E) correspond to the authors that have done at least 2. The directed edges E  X  X  X V of the graph (V, E) encode the edit interaction 3. A is a set of weighted attributes on nodes and edges. 3.2 Attributes on Nodes and Edges The weighted attributes on nodes and edges encode how much text users add, delete, or restore. Furthermore, in case of deletion we keep track of who has previously writ-number of words. 
We will also keep track of the timepoint when edit actions occur by indexing attributes with the revision number. In the following we assume that the history of a stamps 1,...,N . 
For each timepoint i  X   X  1,...,N  X  and each pair of authors (  X , X  )  X  X  X V , z delete  X  (  X , X  ) denotes the number of words deleted by u in revision r i and writ-z undelete i z restore  X  (  X , X  ) denotes the number of words restored by u in revision r  X  , written 
For each timepoint i  X   X  1,...,N  X  and each author  X  X  X  , z add  X  (  X  ) denotes the number of words that are added by u at time i ; z authorship i Summing values over all timepoints yields three weight functions for edges E , that are given by The sum over the two negative relations, denoted by The revise (  X , X  ) encodes how much u undoes v X  X  edits. It is interpreted as a measure of how strongly u agrees with v . 3.3 Network Structural Indicators In contrast to the negative disagreement edges that are given by the attribute revise( u , If the two opposing groups (V 1 , V 2 ) really represent contradicting opinions, we expect that positive edges are mostly between members of the same group. The following indicator estimates to what extent this property holds. 
Let be the aggregated weight of positive edges within the groups and the following new indicator called restoreratio : contradicting opinions. It equals 0 if the restore-edges are independent from the group membership, indicating that the two groups do not have contradicting opinions. It between the two groups. their own group. This suggests that for controversial articles the two computed groups indeed represent contradicting opinions, wh ile the opposition is less clear for featured articles. 
We hypothesize that the network structural indicator restoreratio has correlation with the quality of Wikipedia articles, because of the following observations: z The restoreratio indicator is higher for controversial articles. z The contents of a controversial article can be hampered by an  X  X dit fight X  be-z The two opposing groups will not support the controversy article, unless they and the quality of articles. 4.1 Support Vector Machine We will use the machine learning technology which is called support vector ma-methods used for classification and regression. Given a set of training examples, each marked as belonging to one of the other cat egories, an SVM training algorithm builds mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and pre-dicted to belong to a category based on which side of the gap they fall on. In this paper we use the SVM tool named winSVM, which is developed by Marc Block based on libsvm. 4.2 Sample Articles Using Original Wikipedia Evaluation To increase the trustworthiness of the quality, Wikipedia introduced the voting-based quality evaluations  X  X rticles for Deletion  X ,  X  Good Articles  X  and  X  Featured Articles  X . For the rest of the paper, we refer to them as Wikipedia evaluations. As we investigate the English Wikipedia. First, for all of the Wikipedia evaluations, any user can nomi-nominated, the article is flagged with a special tag. According to the type of evalua-tion, there are particular crite ria that are used for the decision. Featured Articles have quality are tolerated, such as a lack of illustrations or small weaknesses in the writing tagged for deletion. Criteria are, for example, an unsuitable representation or a lack of relevance for an encyclopedia. However, even Articles for Deletion actually maintain deletion, such as those victimized by vandalism or other nonsense, are deleted quickly by using the speedy deletion procedure. 
After the nomination of an article, the community decides via a vote as to whether or not the article complies with certain criteria. The voting period and the voting rule depend on the kind of evaluation. For example, in order to become a Featured Article, necessary. After a successful election, the Featured and Good Articles are marked by special tags and are displayed in the respective sections of the Wikipedia portal, whe-reas Articles for Deletion are deleted by an administrator. 
In the experiment we will randomly choose samples of featured articles and non-represent lower quality ones. 4.3 Features of SVM posed by previous research to be the features. Our proposed methods are combined our methods. 
The metrics that will be used as SVM features are shown below z A  X  : average number of editors per month; z M  X  : maximum number of editors per month; z E : overall number of editors; z Q  X  : Quotient of the sum of the transient contributions and the sum of the persis-z RE : restoreratio (proposed feature in Section 3). 4.4 Experimental Results We randomly choose 16 featured articles and 16 non-featured articles to form the sample of training data. We randomly choose another 16 featured articles and 16 non-featured articles for prediction. We will do three experiments using SVM for compar-ison and analysis. 
First we use three features, A  X  , M  X  , E . The result is shown in Table 1. higher quality articles are predicted to be lower quality articles while 4 lower quality articles are predicted to be higher quality articles. The total precision is 0.719. It is not Table 2.
 quality articles are predicted to be higher quality articles. The total precision is 0.780, which is proposed by W X hner[20]. The result shows it has a high correlation with of quality of Wikipedia articles. Then we use four features, A  X  , M  X  , E , RE. The result is shown in Table 3. lower quality articles while 3 lower quality articles are predicted to be higher quality articles. The total precision is 0.844, which is higher than the result of first and second experiment. 
We exchange the training data for another sample of randomly picked featured and the same prediction data. The precision and recall curves of the four experiments are experiment of features A  X  , of features A  X  , M  X  , E , an d features A  X  , M  X  , E , and R E
As shown in Figure 1, t h dicator RE is higher than t h riment 2. The recall curves higher than the others. O mance in quality evaluatio n In this paper we investig a Wikipedia is an appropriat e compared to traditional w e history a vast array of inf o includes implicit evidence quality assessment. 
In this paper we proposed a model of network structure and explained the algo-rithm to calculate the network structural indicator. Then we use the network structural indicator combining with several existing metrics for evaluating the quality of ar-ticles. The experimental results show that our proposed method has better perfor-mance than existing ones. the number of edits that a contribution survives could be used as an alternative meas-studies that compare Wikipedia with other traditional encyclopedias, could be used. It quality standard may not be elected. Furthermore by using articles assessed by Wiki-pedia evaluations, the metrics for the time period in which an article is determined to be high quality, cannot be measured in that exact same period of time. The metrics are pedia pages. By using expert rated articles instead, this period of time can be analyzed too, which may provide more efficient metrics. 
