 Uncertainty and Information: Foundations of Generalized Information Theory, George J. Klir, Wiley, New York, 2005, 499 pages + xv, ISBN: 0471748676, Cost: $94.95
This book, written by a pioneer and leading researcher in generalized information theory, is a comprehen-sive overview of the field that is suitable as a textbook for a specialized advanced course and is a valuable ref-erence for those already working in the area. There are extensive notes and exercises at the end of each chapter. The bibliography contains approximately 600 citations, dated from 1891 to 2005.

The  X  X  X eneralization X  X  involved in generalized information theory is the addition to standard (point-valued) probability-and possibility-based theories and methodologies of uncertainty generalizations that for the most part emerged during the 1980s and 1990s, although some date back to the 1930s or earlier. Examples include interval-valued probability functions, convex sets of point-valued probability functions, Dempster X  X hafer be-lief functions, graded possibilities, etc. Each of these uncertainty representations has an associated functional (or candidate set of appropriate functionals) suitable for measuring the amount of uncertainty embodied in the representation. Typically, a set of axioms each of which captures some intuitively desirable property of an uncertainty measure (additivity, branching, etc.) is given and functional equation solution techniques are employed to prove the existence of a unique measure satisfying all of the axioms. Several such proofs are provided in the text, as are proofs of many other types of results.

Klir recognizes four distinct areas that need to be addressed for any particular uncertainty theory, T , under development:  X  Level 1  X  Relevant uncertainty functions, u , of the theory T have been characterized by appropriate axioms (examples of these functions are probability measures).  X  Level 2  X  A calculus has been developed for dealing with functions u (an example is the calculus of prob-ability theory).  X  Level 3  X  A justified functional U in theory T has been found, which for each function u in the theory mea-sures the amount of uncertainty associated with u (an example of functional U is the well-known Shannon entropy in probability theory).  X  Level 4  X  A methodology has been developed for dealing with the various problems in which theory T is involved (an example is the Bayesian methodology, combined with the maximum and minimum entropy principles, in probability theory) (p. 8).

There are some statements here and there that one could take issue with, for example, that  X  X  X tatistical meth-ods X  X  were  X  X  X eveloped originally for studying motions of gas molecules in a closed space X  X . The maximum entropy principle is discussed at length, but there is no acknowledgement that its use is controversial. Approxi-mately 25 references are given to the literature on maximizing entropy, but none of them are to authors critical of the technique. Another quibble is the failure to mention Tsallis entropy (although Renyi entropy and other generalizations of Shannon entropy are covered).

The book is likely to be of special interest to researchers in the areas of data mining and decision support systems. Conditional forms of the uncertainty measures discussed have potential as the basis for new measures of association and of (approximate) data dependencies. Decision criteria for the newer uncertainty represen-tations analogous to expected utility maximization for probability remain to be worked out.
