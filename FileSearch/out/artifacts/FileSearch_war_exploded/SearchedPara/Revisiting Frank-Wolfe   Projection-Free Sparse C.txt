 Martin Jaggi jaggi@cmap.polytechnique.fr CMAP,  X  Ecole Polytechnique, Palaiseau, France Our work here addresses general constrained convex optimization problems of the form We assume that the objective function f is convex and continuously differentiable, and that the domain D is a optimization problems, one of the simplest and earliest known iterative optimizers is given by the Frank-Wolfe method (1956), described in Algorithm 1, also known as the conditional gradient method . Algorithm 1 Frank-Wolfe (1956)
Let x (0)  X  X  for k = 0 ...K do end for A step of this algorithm is illustrated in the inset fig-ure: At a current position x , the algorithm considers the linearization of the objective function, and moves solution to (1) (Frank &amp; Wolfe, 1956; Dunn &amp; Harsh-barger, 1978). In recent years, Frank-Wolfe-type methods have re-gained interest in several areas, fu-eled by the good scalability, and the crucial property that Algorithm 1 maintains its iterates as a convex combination of only few  X  X toms X  s , enabling e.g. sparse and low-rank solutions (since at most one new extreme point of the domain D is added in each step) see e.g. (Clarkson, 2010; Jaggi, 2011) for an overview. Contributions. The contributions of this paper are two-fold: On the theoretical side, we give a conver-gence analysis for the general Frank-Wolfe algorithm guaranteeing small duality gap, and provide efficient certificates for the approximation quality (which are useful even for other optimizers). This result is ob-tained by extending the duality concept as well as the analysis of (Clarkson, 2010) to general Fenchel duality, and approximate linear subproblems. Furthermore, the presented analysis unifies several existing conver-gence results for different sparse greedy algorithm vari-ants into one simplified proof. In contrast to existing convex optimization methods, our convergence anal-ysis (as well as the algorithm itself) are fully invari-ant under any affine transformation/pre-conditioning of the input optimization problem (1).
 On the practical side, we illustrate the broader ap-plicability of Frank-Wolfe-type methods, when com-pared to their main competitors being projected gra-dient descent and proximal methods. Per iteration, Frank-Wolfe uses significantly less expensive linear subproblems compared to quadratic problems in the later, which can make the difference between simple and intractable for e.g. the dual of structural SVMs (Lacoste-Julien et al., 2013), or an order of magnitude iteration cost for the trace norm (leading eigenvector vs. SVD) (Jaggi &amp; Sulovsk  X y, 2010).
 We point out that all convex optimization problems over convex hulls of atomic sets (Chandrasekaran et al., 2012), which appear as the natural convex re-laxations of combinatorial (NP-hard)  X  X parsity X  prob-lems, are directly suitable for Frank-Wolfe-type meth-ods (using one atom per iteration), even when the do-main can only be approximated. For optimization over vectors, prominent examples include optimizing over arbitrary norm-constrained domains (such as ` 1 ), as well as norms that induce structured sparsity of the approximate solutions, such as submodular polyhedra. For matrix optimization problems, our presented ap-proach results in simplified algorithms for optimizing over bounded matrix trace norm, arbitrary Schatten norms, or also permutation matrices and rotation ma-trices. Another particularly interesting application is convex optimization over bounded matrix max-norm, where no convergence guarantees were known previ-ously. Finally, we present a new general framework for convex optimization over matrix factorizations , where every Frank-Wolfe iteration will consist of a low-rank update, and discuss applications for a broad range of such domains.
 History and Related Work. The original Frank-Wolfe algorithm (1956) was introduced and analyzed for polyhedral domains D in R n (given as an inter-section of linear constraints, so that the subproblem becomes an LP). The original paper did not yet use the  X  X ixed X  step-size as in Algorithm 1, but instead re-lied on line-search on a quadratic upper bound on f . (Levitin &amp; Polyak, 1966) coined the term conditional gradient method for the same algorithm, which (De-myanov &amp; Rubinov, 1970) then generalized to arbi-trary Banach spaces as in the setting here. Later (Dunn &amp; Harshbarger, 1978) could show primal con-vergence with 1 imizers of the subproblems are used, and (Patriks-son, 1993) investigated several alternative variations of (non-)linear subproblems. Another variant using non-linear subproblems was proposed in (Zhang, 2003), in each iteration performing a line-search on f towards all  X  X ertices X  of the domain.
 In the machine learning literature, algorithm variants for penalized (instead of constrained) problems were investigated by (Harchaoui et al., 2012; Zhang et al., 2012). For online optimization of non-smooth func-tions in the low-regret setting, a variant has recently been proposed by (Hazan &amp; Kale, 2012), using ran-domized smoothing. (Tewari et al., 2011) and (Dudik et al., 2012, Appendix D) have recently studied Frank-Wolfe methods for atomic domains using similar ideas as in (Jaggi, 2011), but obtaining weaker convergence results. (Temlyakov, 2012) gives a recent comprehen-sive analysis of such greedy methods from the convex analysis perspective. To the best of our knowledge, none of the existing approaches could provide duality gap convergence guarantees, or affine invariance (ex-cept (Clarkson, 2010) for the simplex case). A block-coordinate generalisation of Frank-Wolfe has recently been proposed in (Lacoste-Julien et al., 2013). For any constrained convex optimization problem of the form (1), and a feasible point x  X  X  , we define the following simple surrogate duality gap Convexity of f implies that the linearization f ( x ) + s  X  x ,  X  f ( x ) always lies below the graph of the func-tion f , as again illustrated in Figure 1. This immedi-ately gives the crucial property of the duality gap (2), as being a certificate for the current approximation quality, i.e. g ( x )  X  f ( x )  X  f ( x  X  ).
 While the value of an optimal solution f ( x  X  ) is un-known in most problems of interest, the quantity g ( x ) for any candidate x is often easy to compute. For ex-ample, the duality gap is  X  X utomatically X  computed as a by-product of every iteration of the Frank-Wolfe Al-gorithm 1: Whenever s is a minimizer of the linearized problem at an arbitrary point x , then this s is a certifi-cate for the current duality gap g ( x ) = x  X  s ,  X  f ( x ) . Such certificates for the approximation quality are use-ful not only for the algorithms considered here, but in fact for any optimizer of a constrained problem of the form (1), e.g. as a stopping criterion, or to verify the numerical stability of an optimizer. This duality con-cept also extends to the more general case if f is convex but non-smooth. In this case, the gap is certified by a subgradient of f , see e.g. (Jaggi, 2011, Section 2.2). Our defined duality gap (2) can also be interpreted as a special (and simplified) case of Fenchel duality. Using the Fenchel-Young (in)equality, the gap (2) can Algorithm 2 Frank-Wolfe with Approximate Linear Subproblems, for Quality  X   X  0
Let x (0)  X  X  for k = 0 ...K do end for Algorithm 3 Line-Search for the Step-Size  X  a X )  X  := arg min Algorithm 4 Fully-Corrective Variant, Re-Opt-imizing over all Previous Directions (with s (0) := x (0) be shown to be equal to the difference of f ( x ) to the Fenchel conjugate function of f , if the corresponding dual variable is chosen to be the current (sub)gradient, see (Lacoste-Julien et al., 2013, Appendix D). Besides classical Frank-Wolfe (Algorithm 1), the fol-lowing three algorithm variants are relevant. Later we will prove primal-dual convergence for all four algo-rithm variants together.
 Approximating the Linear Subproblems. De-pending on the domain D , solving the linear subprob-lem min s  X  X  s ,  X  f ( x ( k ) ) exactly can be too expen-sive. Algorithm 2 uses any approximate minimizer s instead, of an additive approximation quality at least  X  trary fixed accuracy parameter.
 Line-Search for the Step-Size. Instead of using the pre-defined step-sizes  X  = 2 the best point on the line segment between the current  X  X ully Corrective X  Variant. Algorithm 4 de-picts the harder-working variant of the Frank-Wolfe method, which after the addition of a new atom (or search direction) s re-optimizes the objective f over all previously used atoms. Here in step k , the current linear minimizer.
 Comparing to the original Frank-Wolfe method, the idea is that the variant here will hopefully make more progress per iteration, and therefore result in iterates x being combinations of even fewer atoms (i.e. better sparsity). This however comes at a price, namely that the internal problem in each iteration can now become as hard to solve as the original optimization problem, implying that no global run-time guarantees can be given for Algorithm 4 in general.
 In computational geometry, the fully corrective method has been used to prove existence results for coresets, e.g. for the smallest enclosing ball problem. Here it is known that compared to the cheaper Al-gorithm 1, it gives coresets of roughly half the size (Clarkson, 2010). Algorithm 4 is very close to orthog-onal matching pursuit (Tropp &amp; Gilbert, 2007), which is among the most popular algorithms in signal pro-cessing (the difference being that the later applies to an unconstrained domain, more similar to the Frank-Wolfe variant of (Zhang et al., 2012; Harchaoui et al., 2012)). Algorithm 4 for the case of quadratic objec-tives has also been known as the minimum-norm-point algorithm (Bach, 2011). Recently, Yuan &amp; Yan (2012) suggested the use of Newton-type heuristics to solve the subproblems in Algorithm 4.
 Away-Steps. Another important variant is the use of away-steps , as explained in (Gu  X eLat &amp; Marcotte, 1986), which we can unfortunately not discuss in de-tail here due to the lack of space. The idea is that in each iteration, we not only add a new atom s , but po-tentially also remove an old atom (provided it is bad with respect to our objective). This requires that the iterate x is represented as a convex combination of the current atoms. Similarily as for the fully corrective Al-gorithm 4 above, this variant can improve the sparsity of the iterates (Clarkson, 2010). Using away-steps, a faster linear convergence can be obtained for some spe-cial problem class (Gu  X eLat &amp; Marcotte, 1986). The Curvature. The convergence analysis of Frank-Wolfe type algorithms crucially relies on a mea-sure of  X  X on-linearity X  of our objective function f over the domain D . The curvature constant C f of a convex and differentiable function f : R n  X  R , with respect to a compact domain D is defined as
C f := sup For linear functions f for example, it holds that C f = 0. A motivation to consider this quantity follows if we imagine moving from a current point x towards a next  X  X terate X  y := x +  X  ( s  X  x ), for any relative  X  X tep-size X   X   X  [0 , 1]. Bounded C f then means that the deviation of f at y from the linearization of f given by  X  f ( x ) at x is bounded, where the acceptable deviation is weighted by the inverse of the squared step-size  X  . The defining term f ( y )  X  f ( x )  X  X  y  X  x ,  X  f ( x )  X  is also widely known as the Bregman divergence defined by f . For f ( x ) := 1 the squared Euclidean diameter of the domain D . The assumption of bounded curvature C f closely corre-sponds to a Lipschitz assumption on the gradient of f (sometimes called C f -strong smoothness ). More pre-cisely, if  X  f is L -Lipschitz continuous on D w.r.t. some arbitrary chosen norm k . k , then C f  X  diam k . k ( D ) 2 L , where diam k . k ( . ) denotes the k . k -diameter, cf. Ap-pendix D. Note that the curvature constant C f itself does not depend on the choice of a norm.
 Convergence in Primal Error. The following the-orem shows that after O 1 ants 1, 2, 3, and 4 is an  X  -approximate solution to being an optimal solution.
 Compared to the existing literature (Dunn &amp; Harsh-barger, 1978; Jones, 1992; Patriksson, 1993; Zhang, 2003; Clarkson, 2010), our following proof more clearly highlights the dependence on the approximation qual-ity  X  of the linear subproblems, holds for all algorithm variants, and will prepare us for the main result of con-vergence in the duality gap in the next Section. Later we will also show that the resulting convergence rate is indeed best possible for any algorithm that adds only one new atom per iteration.
 Theorem 1 (Primal Convergence) . For each k  X  1 , the iterates x ( k ) of Algorithms 1, 2, 3, and 4 satisfy where x  X   X  D is an optimal solution to problem (1), and  X   X  0 is the accuracy to which the internal linear subproblems are solved (i.e.  X  = 0 for Algorithm 1). The proof of the above convergence theorem relies on expressing the improvement per step in terms of the current duality gap, and then follows along the same idea as in (Clarkson, 2010, Theorem 2.3). A proof is given in Appendix A for completeness.
 Inexact Gradient Information. Instead of ap-proximately solving the linear subproblem given by the exact gradient, the same convergence guarantees can be obtained if an inexact gradient is used: For the convergence to hold, we need that the algorithm picks a point s that satisfies  X  s ,d x  X  X  X  min Consider the case when D is a norm-ball for a norm k . k , and we only have an estimate  X  d x of the gradient with small  X  0  X   X  d x  X  d x max arg min Obtaining a Guaranteed Small Duality Gap. From the above convergence Theorem 1, we have ob-tained small primal error. However, since the optimum value f ( x  X  ) as well as the curvature constant C f are of-ten unknown in practical applications, certificates for the current approximation quality are greatly desired. The duality gap g ( x ) that we defined in Section 2 is such an easy computable quality measure, and always upper bounds the primal error f ( x )  X  f ( x  X  ). Here we state our main result that all variants of the Frank-Wolfe algorithm indeed obtain guaranteed small duality gap g ( x ( k ) )  X   X  after O 1 bitrary bounded domain D  X  X  , and even if the linear subproblems are only solved approximately. This gen-eralizes the result of (Clarkson, 2010), which already proved the convergence of Algorithms 1 and 3 on the unit simplex domain (using exact subproblems). Theorem 2 (Primal-Dual Convergence) . If Algo-rithm 1, 2, 3 or 4 is run for K  X  2 iterations, then the algorithm has an iterate x (  X  k ) , 1  X   X  k  X  K , with duality gap bounded by where  X  = 27 8 = 3 . 375 , and  X   X  0 is the accuracy to which the linear subproblems are solved.
 The proof is provided in Appendix B. The idea is to show that the duality gap cannot stay large over many iterations, since the step improvements would then lead to convergence below the optimal value. Invariance under Affine Transformations. In-terestingly, the Frank-Wolfe algorithm as well as our presented convergence analysis is fully invariant un-der affine transformations and re-parameterizations of the domain: If we chose any re-parameterization of the domain D , by a surjective linear or affine map M :  X  D  X  D , then the  X  X ld X  and  X  X ew X  optimiza-tion problem variants min x  X  X  f ( x ) and min  X  x  X   X  D  X  for  X  f (  X  x ) := f ( M  X  x ) look completely the same to the Frank-Wolfe algorithm: More precisely, every iteration will remain exactly the same, and also the convergence with C f /k is unchanged, since the curvature constant C f by its definition (3) is also invariant under such transformations (using that  X   X  f = M T  X  f ). A natural variant of such a re-parameterization is the use of bary-centric coordinates , if D is a convex hull of finitely many vectors (then M contains these vectors as columns, and  X  D is the unit simplex). This particu-larly highlights the importance of the case of simplex domains, as studied by the seminal paper of (Clark-son, 2010). However, convex hulls of infinitely many vectors can not be represented this way.
 The observed invariance under any  X  X istortion X  of the domain is surprising in the light of the popularity of pre-conditioners and second-order methods, and the fact that the convergence of the majority of existing convex optimizers crucially depends on the distortion of the domain. Here in contrast, for Frank-Wolfe-type methods, no distortion has any effect.
 Optimality in Terms of Sparsity of the Ob-tained Solutions. We will now show that the num-ber of used atoms (i.e. the sparsity of x ) of O 1 used by the Frank-Wolfe algorithm is indeed worst-case optimal (for a primal and/or dual approximation error  X  ), by providing a lower bound of  X  1 gether with the upper bound, this therefore character-izes the trade-off between sparsity and approximation quality for the family of optimization problems of the form (1). For the lower bound, the domain is chosen as the unit simplex, D :=  X  n  X  R n . The same matching sparsity upper and lower bounds will also hold for op-timizing over the ` 1 -ball instead, and also for the rank in trace-norm constrained optimization (Jaggi, 2011). Consider the function f ( x ) := k x k 2 2 = x T x . Its curva-ture over the simplex is C f = 2 diam( X  n ) 2 = 4, which follows directly from the definition (3).
 Lemma 3 (see Appendix C) . For f ( x ) := k x k 2 2 , and 1  X  k  X  n , it holds that min x  X   X  In other words, for any vector x of sparsity card( x ) = k , the primal error f ( x )  X  f ( x  X  ) is always lower bounded by 1 (Canon &amp; Cullum, 1968) have proved a slightly more complicated asymptotic lower bound of  X  1 the primal error of the Frank-Wolfe algorithm when run on quadratic objectives, for all  X  &gt; 0. Our lower bound here also extends to prove that the obtained duality gap g ( x ) is best possible: Lemma 4. For f ( x ) := k x k 2 2 , and any k  X  N , k &lt; n , it holds that g ( x )  X  2 k  X  x  X   X  n s.t. card( x )  X  k . For any compact and convex subset D of a vector space X , the function  X  D : X  X  R +  X  X  +  X  X  defined as is called the gauge function (Rockafellar, 1997) of the convex set D . The support function of D is given by If the original gauge function  X  D ( . ) = k . k is a norm, then  X   X  D ( . ) = k . k  X  is precisely its dual norm. Atomic Norms. In the special case when the set D := conv( A ) is a convex hull of another set A , then  X  D ( . ) becomes the so called atomic norm (Chan-drasekaran et al., 2012) defined by A . Despite its name, the atomic norm is not always a norm. In gen-eral, the function  X  D ( . ) is known to be a semi-norm if and only if D is centrally symmetric, and it becomes a norm if 0  X  int ( D ) (Rockafellar, 1997).
 The support function of an atomic domain is obtained by taking the largest inner product with an atomic ier to compute than a maximum over the full domain conv( A ). This follows directly from the definition of the convex hull, implying that any linear function at-tains its maximum over a convex hull at a vertex, or formally  X   X  A ( . ) =  X   X  conv( A ) ( . ). This key property en-ables the efficient application of the Frank-Wolfe algo-rithm for atomic domains in the following.
 Frank-Wolfe Algorithms for Optimizing over Atomic Domains. In Table 1, we summarize a va-riety of atomic domains D , over which convex opti-mization problems of the form (1) can be solved effi-ciently by the presented Frank-Wolfe methods, using atoms, this means that the Frank-Wolfe iterates x will often inherit some of this structure, such as sparsity or low rank. In the next subsections we explain these domains more precisely and comment on the compu-tational complexity of the respective linear subprob-lems. Note that the use of unit ball (or gauge) domains comes with no loss of generality, since the argument of f can be re-scaled by an arbitrary constant. 4.1. Optimizing over Vectors Sparse Vectors / ` 1 -Ball / Simplex. The convex hull of the signed unit basis vectors A = { X  e i | i  X  [ n ] } in R n is the unit ball of the ` 1 -norm. On the other hand, the unit simplex is the convex hull of the unit basis vectors. The use of Frank-Wolfe-type greedy al-gorithms for finding sparse vectors which optimize a convex function over such domains is well-studied in the literature, see e.g. (Clarkson, 2010) and the refer-ences therein. This motivated by the many prominent applications such as for example Lasso regression (Tib-shirani, 1996), sparse recovery (Mallat &amp; Zhang, 1993), and many learning tasks, where e.g. boosting (Ad-aboost), support vector machines (G  X artner &amp; Jaggi, 2009; Clarkson, 2010; Ouyang &amp; Gray, 2010), and den-sity estimation (Li &amp; Barron, 2000; Bach et al., 2012) turn out to be such problem instances. Clearly, every iteration will add at most one new non-zero coordinate to x , and the linear subproblems consist of finding the largest entry of the gradient.
 The resulting trade-off between the sparsity and the approximation quality is interesting. Our above spar-sity lower bounds from Lemmata 3 and 4 together with the upper bounds of O 1 sis show that the sparsity of the Frank-Wolfe iterates is indeed best possible in terms of both primal and dual approximation quality. For optimizing over the sim-plex, this trade-off was also described by (G  X artner &amp; Jaggi, 2009; Clarkson, 2010), and by (Shalev-Shwartz et al., 2010) for the ` 1 -ball (considering primal error). The ` p -Ball. An exact Frank-Wolfe iteration only costs linear time when optimizing over any ` p -ball do-main D , for p  X  [1 ,  X  ]. This follows by the dual-ity of the ` p and ` q -norms, as in H  X older X  X  inequality  X  s , y  X   X  k s k p  X k y k q (for p,q  X  [1 ,  X  ], 1 lowing q =  X  for p = 1 and vice versa). An optimal solution s to the linear problem max  X  s , k  X  s k simply be obtained from y by choosing | s i | X  X  y i | q  X  1 keeping the same signs. This also holds for the case p =  X  , q = 1, where the domain D becomes the cube. Structured Atomic Norms. In recent years, structured norms have gained strong interest in sev-eral areas of machine learning, computer vision, and signal processing, due to their ability to induce more general and structured notions of sparsity, see e.g. (Je-natton et al., 2011) for an overview.
 Here we will focus on one large class of structured norms, proposed by (Obozinski et al., 2011), which due to the atomic structure is particularly suitable to be used with the Frank-Wolfe algorithm. Let G be a finite collection of groups of indices g  X  [ n ] (which are allowed to overlap), and S g  X  X  g = [ n ]. For each group g , we choose an arbitrary norm k . k g , which acts only on the coordinates belonging to g , i.e. on R For any v  X  R n and g  X  [ n ], we write v [ g ]  X  R n for the vector coinciding with v in the coordinates in g , and being zero elsewhere, i.e. supp( v [ g ] )  X  g . The same vector when restricted to these coordinates is written the latent group norm (Obozinski et al., 2011) is given by k x k It is known (Obozinski et al., 2011) that this norm is an atomic norm (and a norm), with the atoms A = { D g | g  X  X } being the unit disks defined by the we discussed above when introducing atomic norms, this implies that the dual norm is now given by k y k  X  G such atomic set of disks with the non-negative cone, and therefore obtain a corresponding  X  X on-negative X  atomic norm. In the special case that G forms a par-tition of [ n ], and all group norms k . k g are chosen as the Euclidian norm, then k . k G becomes the standard group-lasso penalty (Yuan &amp; Lin, 2006). 4.2. Optimizing over Matrices Schatten Matrix Norms. If k . k is a vector norm on R r , r := min { m,n } , then the corresponding Schat-ten matrix norm of a matrix M  X  R m  X  n is defined as k (  X  1 ( M ) ,..., X  r ( M )) k , where  X  1 ( M ) ,..., X  the singular values of M . The dual of the Schatten ` -norm is the Schatten ` q -norm. The two most promi-nent examples are the trace norm k . k tr (also called the nuclear-or Schatten ` 1 -norm, being the sum of the sin-gular values), and the operator norm k . k op (Schatten `  X  -norm, being the largest singular value).
 To apply the Frank-Wolfe algorithm to minimize a convex function over a norm ball of a Schatten-` norm, we need to be able to solve the linear subprob-lems of the form sup S  X  X   X  S,M  X  . Here, the following fact comes to help: Since Schatten norms are invari-ant under orthogonal transformations (by invariance of the spectrum of the matrix), we can find such mini-mizers by employing the singular value decomposition (SVD): If the SVD of the given matrix M  X  R m  X  n is U diag(  X  ) V T = M (where  X  = (  X  1 ,..., X  r )  X  R r S := U diag( s ) V T is an optimizer of sup S  X  X   X  S,M  X  , if s is any vector attaining s T  X  = k  X  k q with k s k p  X  1. While finding such a conjugate vector s only costs linear time O ( r ), the main computational cost of a Frank-Wolfe step on a Schatten norm domain remains the computation of the SVD (of the current gradient matrix M ), which is in O (min { mn 2 ,m 2 n } ). In the important case of optimizing over bounded trace-norm (Schatten ` 1 -norm), the subproblems can be solved much more efficiently, by a single approx-imate eigenvector computation instead of a complete SVD. We discuss this case in more detail in Section 4.3. Orthonormal Matrices, and the Operator Norm Ball. The convex hull of all orthonormal matrices U  X  R m  X  n , U T U = I , is the norm ball of the standard Schatten-`  X  -norm. Here it becomes particularly easy to obtain a linear optimizer over D (the operator norm ball) using the SVD approach we have explained above for general Schatten norms. If U  X  V T = M is the SVD of M , then S := UV T is a solution to the linear always the identity matrix).
 Permutation Matrices. The convex hull of all n  X  n permutation matrices is known as the Birkhoff poly-tope, and coincides with the set of all doubly stochas-tic matrices (Lov  X asz &amp; Plummer, 2009). Despite the number of atoms being exponential ( n !), a linear func-tion can be optimized efficiently over this polytope, by using the primal-dual Hungarian algorithm in time O ( n 3 ) (Lov  X asz &amp; Plummer, 2009). Therefore, the ex-act Frank-Wolfe algorithm can be applied efficiently for such domains, see also (Tewari et al., 2011). Rotation Matrices. We consider optimizing over the convex hull of all rotation matrices, i.e. the or-thogonal n  X  n matrices of determinant one. Linear optimization over this set D is known as the orthogo-nal Procrustes problem , and can be solved by one SVD. We can therefore optimize arbitrary convex functions f by the Frank-Wolfe algorithm, using combinations of only few rotations matrices. An online-version of such optimization tasks was studied in (Hazan et al., 2010). 4.3. Factorized Matrix Norms In this section, we propose a new general framework for optimization over factorizations of a matrix M  X  R R  X  R n  X  r for some r  X  N . To do so, we consider atomic domains which consist of the (matrix) outer products of two atomic sets , i.e.
 compact subsets (not necessarily finite) of R m  X  r and R By definition of this atomic set, any iteration of the Frank-Wolfe algorithm when optimizing over D = conv( A ) will result in an update of the form s = LR T , that is a low-rank update (of rank  X  r ). In other words, such domains allow us to maintain all Frank-Wolfe iterates x as a low-rank matrix factorization (of rank at most  X  rk in step k ).
 Our definition can also be seen as a generalization of the fact that any pair of norms on vectors u  X  R m and of the quadratic form u T M v , see e.g. (Bach et al., 2008; Zhang et al., 2012) and (Boyd &amp; Vandenberghe, 2004, Example 3.11). We recover this case when r = 1. (The work of Zhang et al. (2012) appeared after our paper was put online).
 Trace Norm. The trace norm (Schatten ` 1 -norm) gives the most natural example of such a factorized matrix norm. The unit ball of the trace norm is known to be the convex hull of the rank-1 matri-the cubic complexity of solving the linear subprob-lem for general Schatten norms (using SVD, as ex-plained in Section 4.2), the Frank-Wolfe steps become much more efficient. This is because the subprob-lem amounts to approximating the top eigenvalue (or singular value), which when using the standard Lanc-zos X  algorithm takes  X  O ( N f / (suppressing constants and logarithmic factors), see e.g. Appendix E, when N f is the number of non-zeros of  X  f . Altogether, the Frank-Wolfe algorithm therefore provides  X  -accurate low-rank solutions (rank near-linear in the number of non-zeros N f , see (Jaggi &amp; Sulovsk  X y, 2010). This contrasts the accelerated ver-sions of the  X  X ingular value thresholding X  algorithm of (Cai et al., 2010), which perform O (1 / SVD computations, in each iteration taking time cubic in the matrix dimension.
 For trace-norm optimization, the presentation here avoids the detour over a semidefinite programming for-mulation present in (Jaggi &amp; Sulovsk  X y, 2010) when applying the method of (Hazan, 2008). The same algorithm applies to optimizing under constrained weighted trace norm, by reduction to the trace-norm as e.g. described in (Giesen et al., 2012). For op-timizing over semidefinite matrices S n  X  n of bounded trace, the above discussion is analogous, with A := uu T u  X  R n , k u k 2 = 1 .
 General Factorized Matrix Norm Domains. Even in the case when optimizing over the individ-ual atomic domains (given by A left and A right ) is easy, optimizing a linear function over such a product do-main A can rapidly turn into an intractable combina-torial problem. For example, maximizing uv T ,M over vectors k u k  X   X  1 and k v k  X   X  1 for a given ma-trix M amounts to computing the cut-norm k M k  X  X  X  1 , which is NP-hard (Alon &amp; Naor, 2006). Maximiz-ing the same quadratic form over non-negative vectors k u k 2  X  1, u  X  0 and k v k 2  X  1, v  X  0 was also shown to be NP-hard by (Murty &amp; Kabadi, 1987).
 Matrix Max-Norm, and Semidefinite Optimiza-tion with Bounded Diagonal. Another efficiently tractable case of a factorized matrix domain is given by the matrix max-norm, which is known to be an approximation of the cut-norm (Srebro &amp; Shraibman, 2005). Optimizing a linear function over the PSD ma-trices with all diagonal elements upper bounded by one is a well-studied problem, e.g. appearing as the stan-dard SDP relaxation of the Max-Cut problem (Goe-mans &amp; Williamson, 1995). The algorithm of (Arora et al., 2005) delivers an additive  X  0 -approximation to the linearized problem over such matrices in time  X  the value of the linear problem, and N M is the number of non-zeros in M (Jaggi, 2011, Section 3.5).
 Using the alternative characterization of the max-norm of a rectangular matrix M  X  R m  X  n in terms of a semidefinite program of the above form (Srebro &amp; Shraibman, 2005; Jaggi, 2011), we can directly plug in the algorithm of (Arora et al., 2005) into the Frank-Wolfe method, in order to optimize any convex func-tion over a max-norm constrained domain. This, to our knowledge, gives the first algorithm with a con-vergence guarantee for such problems. (Lee et al., 2010) have studied a proximal optimizer on a non-convex formulation of the max-norm, and very re-cently, (Orabona et al., 2012) have introduced a first-order smoothing technique for max-norm problems. 4.4. Optimizing over Submodular Polyhedra For a finite ground set S , a real valued function defined on all subsets of S , is called submodular , if g ( A  X  B ) + g ( A  X  B )  X  g ( A ) + g ( B ) holds  X  A,B  X  S . For any given submodular function g with g (  X  ) = 0, the corresponding submodular polyhedron (or polymatroid) is defined as the convex set P g := x  X  R n P i  X  A x i  X  g ( A )  X  A  X  S , where n = | S | . Our presented Frank-Wolfe algorithm variants directly apply to minimization of a convex function f over such a domain. This follows since linear optimiza-tion over such a submodular polyhedron domain is efficient, by an O ( n log n ) time greedy algorithm (Ed-monds, 1970; Lov  X asz, 1983; Bach, 2011). (Note that for compactness, the domain is usually restricted to the non-negative orthant D := P g  X  R n  X  0 ). Submodu-lar optimization is currently gaining increased interest as a more general way to relate combinatorial prob-lems to convexity, such as for example for structured sparsity, see e.g. (Bach, 2011).
 Acknowledgements. The author would like to thank Alexandre d X  X spremont, Francis Bach, Guil-laume Bouchard, Bernd G  X artner, Zaid Harchaoui, Ste-fanie Jegelka, Rodolphe Jenatton, Andreas Krause, Si-mon Lacoste-Julien and Guillaume Obozinski for help-ful discussions and remarks, and Robert Carnecky for the 3d-visualization. MJ acknowledges support by the ERC Project SIPA, by a Google research award, and by the Swiss National Science Foundation (SNSF). Most of this work was done while at ETH Zurich. The proof of the convergence rate of the primal error crucially depends on the following Lemma 5 on the im-provement in each iteration, expressing this improve-ment in terms of the current duality gap. Using the lemma, the convergence proof then follows along the same idea as in (Clarkson, 2010, Theorem 2.3). Note that a weaker variant of Lemma 5 for the exact case  X  = 0 was already proven by (Frank &amp; Wolfe, 1956) (without allowing for approximate linear minimizers). with arbitrary step-size  X   X  [0 , 1] , it holds that if s is an approximate linear minimizer, i.e. s ,  X  f ( x ( k ) )  X  min Proof. We write x := x ( k ) , y := x ( k +1) = x +  X  ( s  X  x ), and d x :=  X  f ( x ) to simplify the notation. From the definition of the curvature constant C f of our convex function f , we have Now we use that the choice of s is a good  X  X escent direction X  on the linear approximation to f at x . For-mally, we are given a point s that satisfies  X  s ,d x  X   X  min Here we have plugged in the definition (2) of the duality gap g ( x ). Altogether, we therefore obtain f ( y )  X  f ( x )  X   X g ( x ) +  X  2 lemma.
 Theorem X  1 (Primal Convergence) . For each k  X  1 , the iterates x ( k ) of Algorithms 1, 2, 3, and 4 satisfy where x  X   X  D is an optimal solution to problem (1), and  X   X  0 is the accuracy to which the internal linear subproblems are solved (in the exact Algorithm 1, we have  X  = 0 ).
 Proof. From Lemma 5 we know that for every step line-search variant as in Algorithm 3 and for the  X  X ully corrective X  Algorithm 4, the same bound (using the same fixed  X  := 2 simply by inclusion of the fixed step-size case in the re-the bound holds for  X  = 0.
 Writing h ( x ) := f ( x )  X  f ( x  X  ) for the (unknown) pri-mal error at any point x , this implies that where we have used weak duality h ( x )  X  g ( x ) as dis-cussed after the definition of the duality gap (2). We will now use induction over k to prove our claimed bound, i.e. The base-case k = 0 follows from (4) applied for the first step of the algorithm, using  X  =  X  (0) = 2 Now considering k  X  1, the bound (4) reads as where in the last inequality we have used the induc-gives which is our claimed bound for k  X  1.
 Theorem X  2 (Primal-Dual Convergence) . If Algo-rithm 1, 2, 3 or 4 is run for K  X  2 iterations, then the algorithm has an iterate x (  X  k ) , 1  X   X  k  X  K , with duality gap bounded by where  X  = 27 8 = 3 . 375 , and  X   X  0 is the accuracy to which the linear subproblems are solved.
 Proof. We will actually prove that the iterate of small duality gap will appear in the last third of the K itera-tions. To simplify notation, we will denote the primal and dual errors for any iteration k  X  0 in the algorithm By our previous primal convergence Theorem 1, we E[ f ( x ( k ) )]  X  f ( x  X  )  X  C use the notation C := 2 C f (1 +  X  ).
 In the last third of the k iterations, we will now sup-derive a contradiction to this assumption. We write D := K + 2 to simplify the notation. Formally, we assume that Here the parameter 0 &lt;  X  &lt; 1 is arbitrary fixed, but we will see later that a good choice for this parameter is given by  X  := 2 Now employing the crucial improvement bound from Lemma 5 for the choice of  X  := 2 by using the pre-defined step-size, or using line-search, or by re-optimizing over the previous directions, since we have Plugging in our assumption that the duality gap is still  X  X arge X , we obtain Now we use that in our last third of the steps, our  X  := 2 precisely, if we define k min := d  X D e  X  2 (note that k min  X  0 if K  X  1  X   X   X  2), and consider the steps in k min  X  k  X  K , then  X D  X  k + 2  X  D , so that our bound now reads as We will now sum up this inequality over the last third of the steps from k = k min up to k = K . These are at least K  X  k min +1 = K  X  ( d  X D e X  2)+1  X  (1  X   X  ) D =: n many steps, resulting in here in the last inequality we have just used the primal This completes the proof, since we arrive at the con-tradiction that the primal error becomes negative, i.e.  X  := 2 make the following term become zero: 1  X  n 3 2  X  X   X  1 / X  1  X  (1  X   X  )(2  X  X   X  1 / X  ) = 1  X  1 Therefore, our assumption on the gap is refuted, and we have proven the claimed bound.
 It is possible to obtain small duality gap within a slightly smaller number of iterations, corresponding to  X   X  2, if a constant step-size is used in the second half of the iterations, as formalized in the following theo-rem. The proof follows the idea of (Clarkson, 2010, Section 7).
 Theorem 6 (Primal-Dual Convergence, Two-Regimes Variant) . Suppose Algorithm 1, 2, 3 or 4 is run for K  X  1 iterations, and then continued for an-other K + 1 iterations, now with the fixed step-size Then the algorithm has an iterate x (  X  k ) , K  X   X  k  X  2 K + 1 , with duality gap bounded by where  X   X  0 is the accuracy to which the internal linear subproblems are solved.
 Proof. Following the idea of (Clarkson, 2010, Section 7): By our previous Theorem 1 we already know that C (1 +  X  ).
 In the subsequent K + 1 iterations, we will now sup-will try to derive a contradiction to this assumption. improvement bound given by Lemma 5, we get that the algorithm, this reads as Summing up over the additional steps, we obtain which together with our known primal approxima-f ( x (2 K +2) )  X  f ( x  X  ) &lt; 0, a contradiction. There-fore there must exist  X  k , K  X   X  k  X  2 K + 1, with Lemma X  3. For f ( x ) := k x k 2 2 , and 1  X  k  X  n , it Proof. We prove the inequality min duction on k . The base-case k = 1 follows since f ( x ) = k x k 2 = k x k 1 = 1 for any unit length vector x  X   X  n having just a single non-zero entry. For k &gt; 1, we use that for every x  X   X  n of sparsity card( x )  X  k , we can pick a coordinate i with x i 6 = 0, and write x = (1  X   X  ) v +  X  e i as the sum of two orthogonal vec-tors: v and a unit basis vector e i , where v  X   X  n of sparsity  X  k  X  1, v i = 0, and  X  = x i . Therefore f ( x ) = k x k 2 2 = ((1  X   X  ) v +  X  e i ) T ((1  X   X  ) v +  X  e In the first inequality we have applied the induction hypothesis for v  X   X  n of sparsity  X  k  X  1.
 Equality: The value f ( x ) = 1 of the coordinates of x to 1 The lower bound here also extends to prove that the obtained duality gap g ( x ) is best possible: Lemma X  4. For f ( x ) := k x k 2 2 , and any k  X  N , k &lt; n , it holds that g ( x )  X  2 k  X  x  X   X  n s.t. card( x )  X  k . Proof. g ( x ) = x T  X  f ( x )  X  min i (  X  f ( x )) i = 2( x T x  X  min i x i ). We now use min i x i = 0 because card( x ) &lt; n , and that by Lemma 3 we have x T x = f ( x )  X  1 For any choice of norm k . k , the curvature constant C f can be upper bounded as follows: Lemma 7. Let f be a convex and differentiable func-tion with its gradient  X  f is Lipschitz-continuous w.r.t. some norm k . k over the domain D with Lipschitz-constant L &gt; 0 . Then Proof. By (Nesterov, 2004, Lemma 1.2.3), we have that for any x , y  X  X  , We want to use this upper bound in the definition (3) of the curvature constant. Observing that for any x , s  X  D , we have that also y := x +  X  ( s  X  x )  X  D and 1 bound the curvature as which is the claimed bound.
 For optimization over bounded trace-norm (see Sec-tion 4.3), we have seen that the linear subproblem to be solved in every iteration of the Frank-Wolfe algo-rithm amounts to finding an approximate top eigen-value (or singular vector pair). The running time of the standard Lanczos X  algorithm for this subproblem is bounded as follows: Proposition 8 (Kuczy  X nski &amp; Wo  X zniakowski (1992)) . For any matrix M  X  R m  X  n , and  X  0 &gt; 0 , Lanczos X  algorithm returns a pair of unit vectors ( u , v ) s.t. u T M v  X   X  1 ( M )  X   X  0 , with high probability, using at Here N M is the number of non-zero entries of the input matrix M , and L is an upper bound on  X  1 ( M ). Note that for the Frank-Wolfe Algorithms 2, 3, and 4, the subproblem accuracy needs to be chosen not larger Compared to SVD taking at least cubic time in n + m , such an approximate computation of only one approx-imate eigenvector (or singular vector pair) is much more efficient, see also (Jaggi &amp; Sulovsk  X y, 2010). Randomized Subproblems. Note that in general, if the linear subproblem in each step is solved approxi-mately only in expectation , then the step-improvement bound from Lemma 5 still holds in expectation (condi-tioned on the previous iterate). Therefore, the primal as well as primal-dual convergence bounds (from the main Theorems 1 and 2) do still hold in expectation
 Martin Jaggi jaggi@cmap.polytechnique.fr CMAP,  X  Ecole Polytechnique, Palaiseau, France Our work here addresses general constrained convex optimization problems of the form We assume that the objective function f is convex and continuously differentiable, and that the domain D is a optimization problems, one of the simplest and earliest known iterative optimizers is given by the Frank-Wolfe method (1956), described in Algorithm 1, also known as the conditional gradient method . Algorithm 1 Frank-Wolfe (1956)
Let x (0)  X  X  for k = 0 ...K do end for A step of this algorithm is illustrated in the inset fig-ure: At a current position x , the algorithm considers the linearization of the objective function, and moves solution to (1) (Frank &amp; Wolfe, 1956; Dunn &amp; Harsh-barger, 1978). In recent years, Frank-Wolfe-type methods have re-gained interest in several areas, fu-eled by the good scalability, and the crucial property that Algorithm 1 maintains its iterates as a convex combination of only few  X  X toms X  s , enabling e.g. sparse and low-rank solutions (since at most one new extreme point of the domain D is added in each step) see e.g. (Clarkson, 2010; Jaggi, 2011) for an overview. Contributions. The contributions of this paper are two-fold: On the theoretical side, we give a conver-gence analysis for the general Frank-Wolfe algorithm guaranteeing small duality gap, and provide efficient certificates for the approximation quality (which are useful even for other optimizers). This result is ob-tained by extending the duality concept as well as the analysis of (Clarkson, 2010) to general Fenchel duality, and approximate linear subproblems. Furthermore, the presented analysis unifies several existing conver-gence results for different sparse greedy algorithm vari-ants into one simplified proof. In contrast to existing convex optimization methods, our convergence anal-ysis (as well as the algorithm itself) are fully invari-ant under any affine transformation/pre-conditioning of the input optimization problem (1).
 On the practical side, we illustrate the broader ap-plicability of Frank-Wolfe-type methods, when com-pared to their main competitors being projected gra-dient descent and proximal methods. Per iteration, Frank-Wolfe uses significantly less expensive linear subproblems compared to quadratic problems in the later, which can make the difference between simple and intractable for e.g. the dual of structural SVMs (Lacoste-Julien et al., 2013), or an order of magnitude iteration cost for the trace norm (leading eigenvector vs. SVD) (Jaggi &amp; Sulovsk  X y, 2010).
 We point out that all convex optimization problems over convex hulls of atomic sets (Chandrasekaran et al., 2012), which appear as the natural convex re-laxations of combinatorial (NP-hard)  X  X parsity X  prob-lems, are directly suitable for Frank-Wolfe-type meth-ods (using one atom per iteration), even when the do-main can only be approximated. For optimization over vectors, prominent examples include optimizing over arbitrary norm-constrained domains (such as ` 1 ), as well as norms that induce structured sparsity of the approximate solutions, such as submodular polyhedra. For matrix optimization problems, our presented ap-proach results in simplified algorithms for optimizing over bounded matrix trace norm, arbitrary Schatten norms, or also permutation matrices and rotation ma-trices. Another particularly interesting application is convex optimization over bounded matrix max-norm, where no convergence guarantees were known previ-ously. Finally, we present a new general framework for convex optimization over matrix factorizations , where every Frank-Wolfe iteration will consist of a low-rank update, and discuss applications for a broad range of such domains.
 History and Related Work. The original Frank-Wolfe algorithm (1956) was introduced and analyzed for polyhedral domains D in R n (given as an inter-section of linear constraints, so that the subproblem becomes an LP). The original paper did not yet use the  X  X ixed X  step-size as in Algorithm 1, but instead re-lied on line-search on a quadratic upper bound on f . (Levitin &amp; Polyak, 1966) coined the term conditional gradient method for the same algorithm, which (De-myanov &amp; Rubinov, 1970) then generalized to arbi-trary Banach spaces as in the setting here. Later (Dunn &amp; Harshbarger, 1978) could show primal con-vergence with 1 imizers of the subproblems are used, and (Patriks-son, 1993) investigated several alternative variations of (non-)linear subproblems. Another variant using non-linear subproblems was proposed in (Zhang, 2003), in each iteration performing a line-search on f towards all  X  X ertices X  of the domain.
 In the machine learning literature, algorithm variants for penalized (instead of constrained) problems were investigated by (Harchaoui et al., 2012; Zhang et al., 2012). For online optimization of non-smooth func-tions in the low-regret setting, a variant has recently been proposed by (Hazan &amp; Kale, 2012), using ran-domized smoothing. (Tewari et al., 2011) and (Dudik et al., 2012, Appendix D) have recently studied Frank-Wolfe methods for atomic domains using similar ideas as in (Jaggi, 2011), but obtaining weaker convergence results. (Temlyakov, 2012) gives a recent comprehen-sive analysis of such greedy methods from the convex analysis perspective. To the best of our knowledge, none of the existing approaches could provide duality gap convergence guarantees, or affine invariance (ex-cept (Clarkson, 2010) for the simplex case). A block-coordinate generalisation of Frank-Wolfe has recently been proposed in (Lacoste-Julien et al., 2013). For any constrained convex optimization problem of the form (1), and a feasible point x  X  X  , we define the following simple surrogate duality gap Convexity of f implies that the linearization f ( x ) + s  X  x ,  X  f ( x ) always lies below the graph of the func-tion f , as again illustrated in Figure 1. This immedi-ately gives the crucial property of the duality gap (2), as being a certificate for the current approximation quality, i.e. g ( x )  X  f ( x )  X  f ( x  X  ).
 While the value of an optimal solution f ( x  X  ) is un-known in most problems of interest, the quantity g ( x ) for any candidate x is often easy to compute. For ex-ample, the duality gap is  X  X utomatically X  computed as a by-product of every iteration of the Frank-Wolfe Al-gorithm 1: Whenever s is a minimizer of the linearized problem at an arbitrary point x , then this s is a certifi-cate for the current duality gap g ( x ) = x  X  s ,  X  f ( x ) . Such certificates for the approximation quality are use-ful not only for the algorithms considered here, but in fact for any optimizer of a constrained problem of the form (1), e.g. as a stopping criterion, or to verify the numerical stability of an optimizer. This duality con-cept also extends to the more general case if f is convex but non-smooth. In this case, the gap is certified by a subgradient of f , see e.g. (Jaggi, 2011, Section 2.2). Our defined duality gap (2) can also be interpreted as a special (and simplified) case of Fenchel duality. Using the Fenchel-Young (in)equality, the gap (2) can Algorithm 2 Frank-Wolfe with Approximate Linear Subproblems, for Quality  X   X  0
Let x (0)  X  X  for k = 0 ...K do end for Algorithm 3 Line-Search for the Step-Size  X  a X )  X  := arg min Algorithm 4 Fully-Corrective Variant, Re-Opt-imizing over all Previous Directions (with s (0) := x (0) be shown to be equal to the difference of f ( x ) to the Fenchel conjugate function of f , if the corresponding dual variable is chosen to be the current (sub)gradient, see (Lacoste-Julien et al., 2013, Appendix D). Besides classical Frank-Wolfe (Algorithm 1), the fol-lowing three algorithm variants are relevant. Later we will prove primal-dual convergence for all four algo-rithm variants together.
 Approximating the Linear Subproblems. De-pending on the domain D , solving the linear subprob-lem min s  X  X  s ,  X  f ( x ( k ) ) exactly can be too expen-sive. Algorithm 2 uses any approximate minimizer s instead, of an additive approximation quality at least  X  trary fixed accuracy parameter.
 Line-Search for the Step-Size. Instead of using the pre-defined step-sizes  X  = 2 the best point on the line segment between the current  X  X ully Corrective X  Variant. Algorithm 4 de-picts the harder-working variant of the Frank-Wolfe method, which after the addition of a new atom (or search direction) s re-optimizes the objective f over all previously used atoms. Here in step k , the current linear minimizer.
 Comparing to the original Frank-Wolfe method, the idea is that the variant here will hopefully make more progress per iteration, and therefore result in iterates x being combinations of even fewer atoms (i.e. better sparsity). This however comes at a price, namely that the internal problem in each iteration can now become as hard to solve as the original optimization problem, implying that no global run-time guarantees can be given for Algorithm 4 in general.
 In computational geometry, the fully corrective method has been used to prove existence results for coresets, e.g. for the smallest enclosing ball problem. Here it is known that compared to the cheaper Al-gorithm 1, it gives coresets of roughly half the size (Clarkson, 2010). Algorithm 4 is very close to orthog-onal matching pursuit (Tropp &amp; Gilbert, 2007), which is among the most popular algorithms in signal pro-cessing (the difference being that the later applies to an unconstrained domain, more similar to the Frank-Wolfe variant of (Zhang et al., 2012; Harchaoui et al., 2012)). Algorithm 4 for the case of quadratic objec-tives has also been known as the minimum-norm-point algorithm (Bach, 2011). Recently, Yuan &amp; Yan (2012) suggested the use of Newton-type heuristics to solve the subproblems in Algorithm 4.
 Away-Steps. Another important variant is the use of away-steps , as explained in (Gu  X eLat &amp; Marcotte, 1986), which we can unfortunately not discuss in de-tail here due to the lack of space. The idea is that in each iteration, we not only add a new atom s , but po-tentially also remove an old atom (provided it is bad with respect to our objective). This requires that the iterate x is represented as a convex combination of the current atoms. Similarily as for the fully corrective Al-gorithm 4 above, this variant can improve the sparsity of the iterates (Clarkson, 2010). Using away-steps, a faster linear convergence can be obtained for some spe-cial problem class (Gu  X eLat &amp; Marcotte, 1986). The Curvature. The convergence analysis of Frank-Wolfe type algorithms crucially relies on a mea-sure of  X  X on-linearity X  of our objective function f over the domain D . The curvature constant C f of a convex and differentiable function f : R n  X  R , with respect to a compact domain D is defined as
C f := sup For linear functions f for example, it holds that C f = 0. A motivation to consider this quantity follows if we imagine moving from a current point x towards a next  X  X terate X  y := x +  X  ( s  X  x ), for any relative  X  X tep-size X   X   X  [0 , 1]. Bounded C f then means that the deviation of f at y from the linearization of f given by  X  f ( x ) at x is bounded, where the acceptable deviation is weighted by the inverse of the squared step-size  X  . The defining term f ( y )  X  f ( x )  X  X  y  X  x ,  X  f ( x )  X  is also widely known as the Bregman divergence defined by f . For f ( x ) := 1 the squared Euclidean diameter of the domain D . The assumption of bounded curvature C f closely corre-sponds to a Lipschitz assumption on the gradient of f (sometimes called C f -strong smoothness ). More pre-cisely, if  X  f is L -Lipschitz continuous on D w.r.t. some arbitrary chosen norm k . k , then C f  X  diam k . k ( D ) 2 L , where diam k . k ( . ) denotes the k . k -diameter, cf. Ap-pendix D. Note that the curvature constant C f itself does not depend on the choice of a norm.
 Convergence in Primal Error. The following the-orem shows that after O 1 ants 1, 2, 3, and 4 is an  X  -approximate solution to being an optimal solution.
 Compared to the existing literature (Dunn &amp; Harsh-barger, 1978; Jones, 1992; Patriksson, 1993; Zhang, 2003; Clarkson, 2010), our following proof more clearly highlights the dependence on the approximation qual-ity  X  of the linear subproblems, holds for all algorithm variants, and will prepare us for the main result of con-vergence in the duality gap in the next Section. Later we will also show that the resulting convergence rate is indeed best possible for any algorithm that adds only one new atom per iteration.
 Theorem 1 (Primal Convergence) . For each k  X  1 , the iterates x ( k ) of Algorithms 1, 2, 3, and 4 satisfy where x  X   X  D is an optimal solution to problem (1), and  X   X  0 is the accuracy to which the internal linear subproblems are solved (i.e.  X  = 0 for Algorithm 1). The proof of the above convergence theorem relies on expressing the improvement per step in terms of the current duality gap, and then follows along the same idea as in (Clarkson, 2010, Theorem 2.3). A proof is given in Appendix A for completeness.
 Inexact Gradient Information. Instead of ap-proximately solving the linear subproblem given by the exact gradient, the same convergence guarantees can be obtained if an inexact gradient is used: For the convergence to hold, we need that the algorithm picks a point s that satisfies  X  s ,d x  X  X  X  min Consider the case when D is a norm-ball for a norm k . k , and we only have an estimate  X  d x of the gradient with small  X  0  X   X  d x  X  d x max arg min Obtaining a Guaranteed Small Duality Gap. From the above convergence Theorem 1, we have ob-tained small primal error. However, since the optimum value f ( x  X  ) as well as the curvature constant C f are of-ten unknown in practical applications, certificates for the current approximation quality are greatly desired. The duality gap g ( x ) that we defined in Section 2 is such an easy computable quality measure, and always upper bounds the primal error f ( x )  X  f ( x  X  ). Here we state our main result that all variants of the Frank-Wolfe algorithm indeed obtain guaranteed small duality gap g ( x ( k ) )  X   X  after O 1 bitrary bounded domain D  X  X  , and even if the linear subproblems are only solved approximately. This gen-eralizes the result of (Clarkson, 2010), which already proved the convergence of Algorithms 1 and 3 on the unit simplex domain (using exact subproblems). Theorem 2 (Primal-Dual Convergence) . If Algo-rithm 1, 2, 3 or 4 is run for K  X  2 iterations, then the algorithm has an iterate x (  X  k ) , 1  X   X  k  X  K , with duality gap bounded by where  X  = 27 8 = 3 . 375 , and  X   X  0 is the accuracy to which the linear subproblems are solved.
 The proof is provided in Appendix B. The idea is to show that the duality gap cannot stay large over many iterations, since the step improvements would then lead to convergence below the optimal value. Invariance under Affine Transformations. In-terestingly, the Frank-Wolfe algorithm as well as our presented convergence analysis is fully invariant un-der affine transformations and re-parameterizations of the domain: If we chose any re-parameterization of the domain D , by a surjective linear or affine map M :  X  D  X  D , then the  X  X ld X  and  X  X ew X  optimiza-tion problem variants min x  X  X  f ( x ) and min  X  x  X   X  D  X  for  X  f (  X  x ) := f ( M  X  x ) look completely the same to the Frank-Wolfe algorithm: More precisely, every iteration will remain exactly the same, and also the convergence with C f /k is unchanged, since the curvature constant C f by its definition (3) is also invariant under such transformations (using that  X   X  f = M T  X  f ). A natural variant of such a re-parameterization is the use of bary-centric coordinates , if D is a convex hull of finitely many vectors (then M contains these vectors as columns, and  X  D is the unit simplex). This particu-larly highlights the importance of the case of simplex domains, as studied by the seminal paper of (Clark-son, 2010). However, convex hulls of infinitely many vectors can not be represented this way.
 The observed invariance under any  X  X istortion X  of the domain is surprising in the light of the popularity of pre-conditioners and second-order methods, and the fact that the convergence of the majority of existing convex optimizers crucially depends on the distortion of the domain. Here in contrast, for Frank-Wolfe-type methods, no distortion has any effect.
 Optimality in Terms of Sparsity of the Ob-tained Solutions. We will now show that the num-ber of used atoms (i.e. the sparsity of x ) of O 1 used by the Frank-Wolfe algorithm is indeed worst-case optimal (for a primal and/or dual approximation error  X  ), by providing a lower bound of  X  1 gether with the upper bound, this therefore character-izes the trade-off between sparsity and approximation quality for the family of optimization problems of the form (1). For the lower bound, the domain is chosen as the unit simplex, D :=  X  n  X  R n . The same matching sparsity upper and lower bounds will also hold for op-timizing over the ` 1 -ball instead, and also for the rank in trace-norm constrained optimization (Jaggi, 2011). Consider the function f ( x ) := k x k 2 2 = x T x . Its curva-ture over the simplex is C f = 2 diam( X  n ) 2 = 4, which follows directly from the definition (3).
 Lemma 3 (see Appendix C) . For f ( x ) := k x k 2 2 , and 1  X  k  X  n , it holds that min x  X   X  In other words, for any vector x of sparsity card( x ) = k , the primal error f ( x )  X  f ( x  X  ) is always lower bounded by 1 (Canon &amp; Cullum, 1968) have proved a slightly more complicated asymptotic lower bound of  X  1 the primal error of the Frank-Wolfe algorithm when run on quadratic objectives, for all  X  &gt; 0. Our lower bound here also extends to prove that the obtained duality gap g ( x ) is best possible: Lemma 4. For f ( x ) := k x k 2 2 , and any k  X  N , k &lt; n , it holds that g ( x )  X  2 k  X  x  X   X  n s.t. card( x )  X  k . For any compact and convex subset D of a vector space X , the function  X  D : X  X  R +  X  X  +  X  X  defined as is called the gauge function (Rockafellar, 1997) of the convex set D . The support function of D is given by If the original gauge function  X  D ( . ) = k . k is a norm, then  X   X  D ( . ) = k . k  X  is precisely its dual norm. Atomic Norms. In the special case when the set D := conv( A ) is a convex hull of another set A , then  X  D ( . ) becomes the so called atomic norm (Chan-drasekaran et al., 2012) defined by A . Despite its name, the atomic norm is not always a norm. In gen-eral, the function  X  D ( . ) is known to be a semi-norm if and only if D is centrally symmetric, and it becomes a norm if 0  X  int ( D ) (Rockafellar, 1997).
 The support function of an atomic domain is obtained by taking the largest inner product with an atomic ier to compute than a maximum over the full domain conv( A ). This follows directly from the definition of the convex hull, implying that any linear function at-tains its maximum over a convex hull at a vertex, or formally  X   X  A ( . ) =  X   X  conv( A ) ( . ). This key property en-ables the efficient application of the Frank-Wolfe algo-rithm for atomic domains in the following.
 Frank-Wolfe Algorithms for Optimizing over Atomic Domains. In Table 1, we summarize a va-riety of atomic domains D , over which convex opti-mization problems of the form (1) can be solved effi-ciently by the presented Frank-Wolfe methods, using atoms, this means that the Frank-Wolfe iterates x will often inherit some of this structure, such as sparsity or low rank. In the next subsections we explain these domains more precisely and comment on the compu-tational complexity of the respective linear subprob-lems. Note that the use of unit ball (or gauge) domains comes with no loss of generality, since the argument of f can be re-scaled by an arbitrary constant. 4.1. Optimizing over Vectors Sparse Vectors / ` 1 -Ball / Simplex. The convex hull of the signed unit basis vectors A = { X  e i | i  X  [ n ] } in R n is the unit ball of the ` 1 -norm. On the other hand, the unit simplex is the convex hull of the unit basis vectors. The use of Frank-Wolfe-type greedy al-gorithms for finding sparse vectors which optimize a convex function over such domains is well-studied in the literature, see e.g. (Clarkson, 2010) and the refer-ences therein. This motivated by the many prominent applications such as for example Lasso regression (Tib-shirani, 1996), sparse recovery (Mallat &amp; Zhang, 1993), and many learning tasks, where e.g. boosting (Ad-aboost), support vector machines (G  X artner &amp; Jaggi, 2009; Clarkson, 2010; Ouyang &amp; Gray, 2010), and den-sity estimation (Li &amp; Barron, 2000; Bach et al., 2012) turn out to be such problem instances. Clearly, every iteration will add at most one new non-zero coordinate to x , and the linear subproblems consist of finding the largest entry of the gradient.
 The resulting trade-off between the sparsity and the approximation quality is interesting. Our above spar-sity lower bounds from Lemmata 3 and 4 together with the upper bounds of O 1 sis show that the sparsity of the Frank-Wolfe iterates is indeed best possible in terms of both primal and dual approximation quality. For optimizing over the sim-plex, this trade-off was also described by (G  X artner &amp; Jaggi, 2009; Clarkson, 2010), and by (Shalev-Shwartz et al., 2010) for the ` 1 -ball (considering primal error). The ` p -Ball. An exact Frank-Wolfe iteration only costs linear time when optimizing over any ` p -ball do-main D , for p  X  [1 ,  X  ]. This follows by the dual-ity of the ` p and ` q -norms, as in H  X older X  X  inequality  X  s , y  X   X  k s k p  X k y k q (for p,q  X  [1 ,  X  ], 1 lowing q =  X  for p = 1 and vice versa). An optimal solution s to the linear problem max  X  s , k  X  s k simply be obtained from y by choosing | s i | X  X  y i | q  X  1 keeping the same signs. This also holds for the case p =  X  , q = 1, where the domain D becomes the cube. Structured Atomic Norms. In recent years, structured norms have gained strong interest in sev-eral areas of machine learning, computer vision, and signal processing, due to their ability to induce more general and structured notions of sparsity, see e.g. (Je-natton et al., 2011) for an overview.
 Here we will focus on one large class of structured norms, proposed by (Obozinski et al., 2011), which due to the atomic structure is particularly suitable to be used with the Frank-Wolfe algorithm. Let G be a finite collection of groups of indices g  X  [ n ] (which are allowed to overlap), and S g  X  X  g = [ n ]. For each group g , we choose an arbitrary norm k . k g , which acts only on the coordinates belonging to g , i.e. on R For any v  X  R n and g  X  [ n ], we write v [ g ]  X  R n for the vector coinciding with v in the coordinates in g , and being zero elsewhere, i.e. supp( v [ g ] )  X  g . The same vector when restricted to these coordinates is written as v ( g )  X  R | g | . In this setting, a slight generalization of the latent group norm (Obozinski et al., 2011) is given by k x k It is known (Obozinski et al., 2011) that this norm is an atomic norm (and a norm), with the atoms A = { D g | g  X  X } being the unit disks defined by the we discussed above when introducing atomic norms, this implies that the dual norm is now given by k y k  X  G such atomic set of disks with the non-negative cone, and therefore obtain a corresponding  X  X on-negative X  atomic norm. In the special case that G forms a par-tition of [ n ], and all group norms k . k g are chosen as the Euclidian norm, then k . k G becomes the standard group-lasso penalty (Yuan &amp; Lin, 2006). 4.2. Optimizing over Matrices Schatten Matrix Norms. If k . k is a vector norm on R r , r := min { m,n } , then the corresponding Schat-ten matrix norm of a matrix M  X  R m  X  n is defined as k (  X  1 ( M ) ,..., X  r ( M )) k , where  X  1 ( M ) ,..., X  the singular values of M . The dual of the Schatten ` -norm is the Schatten ` q -norm. The two most promi-nent examples are the trace norm k . k tr (also called the nuclear-or Schatten ` 1 -norm, being the sum of the sin-gular values), and the operator norm k . k op (Schatten `  X  -norm, being the largest singular value).
 To apply the Frank-Wolfe algorithm to minimize a convex function over a norm ball of a Schatten-` norm, we need to be able to solve the linear subprob-lems of the form sup S  X  X   X  S,M  X  . Here, the following fact comes to help: Since Schatten norms are invari-ant under orthogonal transformations (by invariance of the spectrum of the matrix), we can find such mini-mizers by employing the singular value decomposition (SVD): If the SVD of the given matrix M  X  R m  X  n is U diag(  X  ) V T = M (where  X  = (  X  1 ,..., X  r )  X  R r S := U diag( s ) V T is an optimizer of sup S  X  X   X  S,M  X  , if s is any vector attaining s T  X  = k  X  k q with k s k p  X  1. While finding such a conjugate vector s only costs linear time O ( r ), the main computational cost of a Frank-Wolfe step on a Schatten norm domain remains the computation of the SVD (of the current gradient matrix M ), which is in O (min { mn 2 ,m 2 n } ). In the important case of optimizing over bounded trace-norm (Schatten ` 1 -norm), the subproblems can be solved much more efficiently, by a single approx-imate eigenvector computation instead of a complete SVD. We discuss this case in more detail in Section 4.3. Orthonormal Matrices, and the Operator Norm Ball. The convex hull of all orthonormal matrices U  X  R m  X  n , U T U = I , is the norm ball of the standard Schatten-`  X  -norm. Here it becomes particularly easy to obtain a linear optimizer over D (the operator norm ball) using the SVD approach we have explained above for general Schatten norms. If U  X  V T = M is the SVD of M , then S := UV T is a solution to the linear always the identity matrix).
 Permutation Matrices. The convex hull of all n  X  n permutation matrices is known as the Birkhoff poly-tope, and coincides with the set of all doubly stochas-tic matrices (Lov  X asz &amp; Plummer, 2009). Despite the number of atoms being exponential ( n !), a linear func-tion can be optimized efficiently over this polytope, by using the primal-dual Hungarian algorithm in time O ( n 3 ) (Lov  X asz &amp; Plummer, 2009). Therefore, the ex-act Frank-Wolfe algorithm can be applied efficiently for such domains, see also (Tewari et al., 2011). Rotation Matrices. We consider optimizing over the convex hull of all rotation matrices, i.e. the or-thogonal n  X  n matrices of determinant one. Linear optimization over this set D is known as the orthogo-nal Procrustes problem , and can be solved by one SVD. We can therefore optimize arbitrary convex functions f by the Frank-Wolfe algorithm, using combinations of only few rotations matrices. An online-version of such optimization tasks was studied in (Hazan et al., 2010). 4.3. Factorized Matrix Norms In this section, we propose a new general framework for optimization over factorizations of a matrix M  X  R R  X  R n  X  r for some r  X  N . To do so, we consider atomic domains which consist of the (matrix) outer products of two atomic sets , i.e.
 compact subsets (not necessarily finite) of R m  X  r and R By definition of this atomic set, any iteration of the Frank-Wolfe algorithm when optimizing over D = conv( A ) will result in an update of the form s = LR T , that is a low-rank update (of rank  X  r ). In other words, such domains allow us to maintain all Frank-Wolfe iterates x as a low-rank matrix factorization (of rank at most  X  rk in step k ).
 Our definition can also be seen as a generalization of the fact that any pair of norms on vectors u  X  R m and of the quadratic form u T M v , see e.g. (Bach et al., 2008; Zhang et al., 2012) and (Boyd &amp; Vandenberghe, 2004, Example 3.11). We recover this case when r = 1. (The work of Zhang et al. (2012) appeared after our paper was put online).
 Trace Norm. The trace norm (Schatten ` 1 -norm) gives the most natural example of such a factorized matrix norm. The unit ball of the trace norm is known to be the convex hull of the rank-1 matri-the cubic complexity of solving the linear subprob-lem for general Schatten norms (using SVD, as ex-plained in Section 4.2), the Frank-Wolfe steps become much more efficient. This is because the subprob-lem amounts to approximating the top eigenvalue (or singular value), which when using the standard Lanc-zos X  algorithm takes  X  O ( N f / (suppressing constants and logarithmic factors), see e.g. Appendix E, when N f is the number of non-zeros of  X  f . Altogether, the Frank-Wolfe algorithm therefore provides  X  -accurate low-rank solutions (rank near-linear in the number of non-zeros N f , see (Jaggi &amp; Sulovsk  X y, 2010). This contrasts the accelerated ver-sions of the  X  X ingular value thresholding X  algorithm of (Cai et al., 2010), which perform O (1 / SVD computations, in each iteration taking time cubic in the matrix dimension.
 For trace-norm optimization, the presentation here avoids the detour over a semidefinite programming for-mulation present in (Jaggi &amp; Sulovsk  X y, 2010) when applying the method of (Hazan, 2008). The same algorithm applies to optimizing under constrained weighted trace norm, by reduction to the trace-norm as e.g. described in (Giesen et al., 2012). For op-timizing over semidefinite matrices S n  X  n of bounded trace, the above discussion is analogous, with A := uu T u  X  R n , k u k 2 = 1 .
 General Factorized Matrix Norm Domains. Even in the case when optimizing over the individ-ual atomic domains (given by A left and A right ) is easy, optimizing a linear function over such a product do-main A can rapidly turn into an intractable combina-torial problem. For example, maximizing uv T ,M over vectors k u k  X   X  1 and k v k  X   X  1 for a given ma-trix M amounts to computing the cut-norm k M k  X  X  X  1 , which is NP-hard (Alon &amp; Naor, 2006). Maximiz-ing the same quadratic form over non-negative vectors k u k 2  X  1, u  X  0 and k v k 2  X  1, v  X  0 was also shown to be NP-hard by (Murty &amp; Kabadi, 1987).
 Matrix Max-Norm, and Semidefinite Optimiza-tion with Bounded Diagonal. Another efficiently tractable case of a factorized matrix domain is given by the matrix max-norm, which is known to be an approximation of the cut-norm (Srebro &amp; Shraibman, 2005). Optimizing a linear function over the PSD ma-trices with all diagonal elements upper bounded by one is a well-studied problem, e.g. appearing as the stan-dard SDP relaxation of the Max-Cut problem (Goe-mans &amp; Williamson, 1995). The algorithm of (Arora et al., 2005) delivers an additive  X  0 -approximation to the linearized problem over such matrices in time  X  the value of the linear problem, and N M is the number of non-zeros in M (Jaggi, 2011, Section 3.5).
 Using the alternative characterization of the max-norm of a rectangular matrix M  X  R m  X  n in terms of a semidefinite program of the above form (Srebro &amp; Shraibman, 2005; Jaggi, 2011), we can directly plug in the algorithm of (Arora et al., 2005) into the Frank-Wolfe method, in order to optimize any convex func-tion over a max-norm constrained domain. This, to our knowledge, gives the first algorithm with a con-vergence guarantee for such problems. (Lee et al., 2010) have studied a proximal optimizer on a non-convex formulation of the max-norm, and very re-cently, (Orabona et al., 2012) have introduced a first-order smoothing technique for max-norm problems. 4.4. Optimizing over Submodular Polyhedra For a finite ground set S , a real valued function defined on all subsets of S , is called submodular , if g ( A  X  B ) + g ( A  X  B )  X  g ( A ) + g ( B ) holds  X  A,B  X  S . For any given submodular function g with g (  X  ) = 0, the corresponding submodular polyhedron (or polymatroid) is defined as the convex set P g := x  X  R n P i  X  A x i  X  g ( A )  X  A  X  S , where n = | S | . Our presented Frank-Wolfe algorithm variants directly apply to minimization of a convex function f over such a domain. This follows since linear optimiza-tion over such a submodular polyhedron domain is efficient, by an O ( n log n ) time greedy algorithm (Ed-monds, 1970; Lov  X asz, 1983; Bach, 2011). (Note that for compactness, the domain is usually restricted to the non-negative orthant D := P g  X  R n  X  0 ). Submodu-lar optimization is currently gaining increased interest as a more general way to relate combinatorial prob-lems to convexity, such as for example for structured sparsity, see e.g. (Bach, 2011).
 Acknowledgements. The author would like to thank Alexandre d X  X spremont, Francis Bach, Guil-laume Bouchard, Bernd G  X artner, Zaid Harchaoui, Ste-fanie Jegelka, Rodolphe Jenatton, Andreas Krause, Si-mon Lacoste-Julien and Guillaume Obozinski for help-ful discussions and remarks, and Robert Carnecky for the 3d-visualization. MJ acknowledges support by the ERC Project SIPA, by a Google research award, and by the Swiss National Science Foundation (SNSF). Most of this work was done while at ETH Zurich.
