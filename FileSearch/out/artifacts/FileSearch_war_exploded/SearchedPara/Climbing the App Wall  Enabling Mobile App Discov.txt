 The explosive growth of the mobile application (app) mar-ket has made it difficult for users to find the most interesting and relevant apps from the hundreds of thousands that ex-ist today. Context is key in the mobile space and so too are proactive services that ease user input and facilitate effec-tive interaction. We believe that to enable truly novel mo-bile app recommendation and discovery, we need to support real context-aware recommendation that utilizes the diverse range of implicit mobile data available in a fast and scalable manner. In this paper we introduce the Djinn model, a novel context-aware collaborative filtering algorithm for implicit feedback data that is based on tensor factorization. We eval-uate our approach using a dataset from an Android mobile app recommendation service called appazaar 1 . Our results show that our approach compares favorably with state-of-the-art collaborative filtering methods.
 H3.3 [ Information Search and Retrieval ]: Information filtering X  Collaborative Filtering ; G3 [ Probability and Statis-tics ]: Correlation and regression analysis; G1.6 [ Optimization ]: Gradient methods Collaborative Filtering, Tensor Factorization, Context, Im-plicit Feedback, Mobile apps, Mobile Recommendation See: http://appazaar.net last accessed Nov 2011
According to AppsFire , there are currently 1 million mo-bile apps available between Apple X  X  AppStore and the An-droid Market 2 . However, this explosive growth has lead to a new challenge facing mobile users. That is, finding the most interesting and relevant apps from the hundreds of thousands that exist. A number of industry solutions have emerged that provide app recommendation and aggregation services which attempt to filter, rank and recommend the best apps to end users. Most of these services enable sharing and discovery of mobile apps through (1) ratings, which suf-fer from tedious explicit input from users, and (2) simplistic recommendations based on: users profiles, the apps installed by the end-user, and in some cases the duration/usage of those apps. However, few of these services use any form of mobile context information (e.g. location, time, etc.) to facilitate the recommendations and most of these services base their recommendations on explicit input (i.e. ratings) or weak implicit data (i.e. an example of weak indicator of whether the user is interested in an app is that the user downloaded the app).

Recent research has shown that key mobile contexts like location, time, activity and social interactions have a sig-nificant impact on the information needs and behaviours of mobile users [4]. The same is true for mobile app usage [1].
In this paper we introduce the Djinn model: a novel context-aware collaborative filtering method for implicit data that is based on tensor factorization. We deal with the dual challenge of building a preference model in the absence of ex-plicit feedback information from the user and incorporating real contextual information into a single recommendation model. Note that our method can be used in any context-aware recommendation setting with implicit feedback data.
Context-Aware Recommender Systems (CARS) are based on the fact that contextual factors (such as e.g. time, lo-cation, activity, weather, emotional state, social surround-ing) have a heavy influence on the recommendation needs of users. In [8] a context-aware collaborative filtering model for explicit data (i.e. ratings) that is based on tensor factor-
See: http://tcrn.ch/k9k3Ro last accessed Nov 2011 ization was introduced . However, as mentioned previously CF models for explicit data are not adequate for the case of implicit data. Moreover we show analytically how our new model scales favorably when compared to [8].

In implicit feedback the numerical values of the interaction between items and users (counts/number of clicks etc.) can only be considered as an indirect indication or a confidence measure of how much the user liked an item. Moreover for non-observed user  X  item interactions we cannot be certain as to whether the user did not consider the items or if the user considered the items and simply chose not to interact with the items (reflecting a negative feedback). Hence we cannot ignore these entries as this would lead to a recom-mender that would be overly optimistic with regard to user preferences.

The matrix factorization approach for implicit data intro-duced in [7] uses a trick that exploits the sparse structure of the data (dominated by non-observed entries) to speed up the optimization process. Here we introduce a general-ized version of this trick applied to N -dimensional tensor factorization for the optimization of the Djinn model. Im-plicit feedback factor models were also introduced in [9] and [10], where once again the sparsity of the data was exploited in order to speed up optimization. However, none of these implicit feedback based methods utilize any form of context information.

Woerndl et al. [11] explores the use of location to recom-mend mobile apps. Their system works by recommending apps that others users have installed or used frequently at a given location. AppJoy [12] supports personalized mobile app recommendations by combining item-based collaborat-ing filtering with data on how the user actually uses his/her installed apps. More recently, a wide range of commercial services have emerged. For example, Appolicious ranks and recommends apps using reviews, friend recommendations and the apps currently installed by the end user. Apps-Fire and Zwapp support discovery of apps among friends. Smokin Apps and AppBrain for Android match users with apps they would like based on apps similar to those the user has currently installed. Finally, AppSpot facilitates recom-mendation based on the apps you already have, as well as apps you have searched for in the past. Overall existing research has relied heavily on explicit user ratings, recom-mendations from friends or weak implicit data such as app installation.
N -dimensional TF extends CF methods to N -dimensional data where the additional dimensions represent the con-text of the recommendation. In the example of figure 1, we depict the case of mobile app recommendation with lo-cation as an additional context variable. In this example three users { u 1 = Mary ,u 2 = John ,u 3 = Elen } interact with the apps { m 1 = Barcode ,m 2 = Task Killer ,m 3 Angry Birds ,m 4 = Facebook } in context location { c 1 Work ,c 2 = Home ,c 3 = Car } . The resulting tensor Y  X  N n  X  r  X  l , where n is the number of users, r the number of Figure 1: Illustration of the (3-dimensional) tensor factorization Djinn model. items and l the number of context categories, contains the frequency (represented by integer values) of interaction be-tween the users, apps and the location i.e the number of times a user interacted with an app at a particular location. An absence of an interaction is signaled with a 0.

The main idea of the Djinn model X  X  algorithm is to decom-pose this tensor into three matrices U  X  R n  X  d , M  X  R r  X  d and C  X  R l  X  d (see figure 1), using the Candecomp-Parafac (CP) model [6] which corresponds to learned factors that form a profile for each user, app, and context variable re-spectively. We denote by U i  X  the entries of the i th row of matrix U . The decision function that would provide a score for the recommendation engine for a user u i , item m j , con-text c k is given by For the sake of simplicity, we will describe the model for a single contextual variable C . In fact, our method allows for an arbitrary number of context variables to be included into the model.
In the Djinn model observed user  X  item  X  context in-teractions p ijk are signalled with a 1 and unobserved with a 0. Y ijk are the interaction counts between the user u i , item m j under context c k as a user often interacts several times with the same item, e.g. clicking on a news article or using an app. Our confidence in the 0 values is low as these val-ues could represent negative feedback or they could indicate that the user simply did not consider the item.

We take these counts to reflect the confidence we have in the feedback from the user i.e. an item that is repeatedly used/consumed should reflect a greater confidence in the preferences of the user over an item that is used/consumed only once. We transform the counts of usage of an item to  X  X onfidence X  by introducing a new variable w ijk given by: w parameter which we set to 0 . 8 for all our experiments. The first term in eq. 2 reflects the confidence regarding items that are often consumed while the second term reflects the fact that confidence in items should be high only if very few items are used.
 The aim of the model is to compute the factors for the user U n  X  d , item M r  X  d and context C l  X  d matrices using historical consumption data. Once the factors have been calculated a prediction can be computed using eq. 1. In the proposed TF model we compute these factors by minimizing the following objective function: regularization.
We optimize the objective function for the Djinn model (eq. 3) using Alternating Least Squares (ALS). When op-timizing over a single factor matrix e.g. U while keeping the remaining factor matrices fixed, we observe that the cost function becomes quadratic and there is an analytic solution. We illustrate how to optimize the objective with respect to the user factor matrix U . We differentiate the objective function and set the derivative to zero. Solving with respect to a single user u i factor vector gives:
U where is the Hadamar or element-wise product and I the identity matrix of size d . Directly computing this ex-pression would scale O (( nl ) 2 d ) which would be prohibitively expensive even for relatively small datasets. We can achieve a very significant speedup by rewriting this expression as: dependent of the user and can be precomputed at the be-ginning of the iteration over each user factor matrix. In the second part P r j P l k [ M j  X  C k  X  ] T ( w ijk  X  1) [ M expression ( w ijk  X  1) is 0 for all the non-observed values in the tensor Y , which are the vast majority of entries in the tensor, and thus we can compute it over the non-zero val-ues S u + i of user u i in the tensor Y . This vastly improves computation time and scalability to O (( d ) 2 n u i + + d n i + the number of positive feedback items for user u i and assuming cubic scalability for the matrix inversion. We can thus rewrite this expression as: Since we need to compute this over each user the scalability becomes O ( d 2 K + d 3 n ). We speed up the computations using C
T C since matrix libraries handle these type of operations (matrix multiplications and element-wise products) very ef-ficiently. We can compute the item M and context factors C in a similar manner.

The optimization procedure is repeated over each fac-tor matrix until convergence. The whole algorithm scales O ( d 2 K + d 3 ( n + r + l )) i.e linearly to the number of ob-served entries K and usually K ( n + r + l ). Appazaar recommends mobile apps to its users from the Android Market. Along with tracing mobile app usage, ap-pazaar also tracks available context information from the phones sensors. This context information is currently not used by appazaar to facilitate context-aware recommenda-tions [2]. In total, the appazaar dataset contains 3,260 users, 18,205 items and 3.7 million records about the usage of apps. Apart from the user and app id X  X  the features that can be extracted are: Note that we have 4 contextual factors plus user and item dimensions thus we model the data with a 6-dimensional tensor.

We temporally order the data and split it with the first 80% of the data forming the training set and the remaining 20% the test set. The data was then aggregated for each contextual combination found. For example, user u i application m j while being still at home, between 6pm to 6am on a Weekend 25 times. In order to facilitate the com-parison to non-context aware methods we filtered the test set so that for each user  X  item combination, only one context combination is included in the test set.

For the testing procedure we adopt a similar strategy to [5]. We first randomly select 1000 additional apps that the user did not use. We assume that these items are not of in-terest to user u i . We predict the scores for the test items for user u i in an associated context and for the additional 1000 items. We form a ranked list by ordering all the items ac-cording to their predicted scores. This lists over all users are then used to produce Precision-Recall plots. Moreover, we also compute the Mean Average Precision evaluation mea-sure. . We used validation set to tune the parameters of the model.
We conduct 5 runs for each experimental setup and av-erage the results. We do not report on the variance of the results since it was insignificant in our experiments. More-over, all differences between Djinn and the other methods are statistically significant with p  X  value &lt; 0 . 001.
First, we compare our results against a standard regular-ized matrix factorization method (denoted MF ) (based on Simon Funk X  X  3 approach) where the non-observed 0 values are ignored and a regression is performed on the p ijk values derived from eq. 2. Naturally, MF also ignores the contex-tual information. We also implemented a method proposed in [7] which is essentially matrix factorization for implicit feedback data (denoted iMF ). iMF takes into account only users and items and ignores additional context but treats the 0 values of the non-observed user  X  item pairs as negative feedback. Moreover we implemented a Poisson regression (denoted Poisson ) based on [3] where contextual informa-tion is used as a feature vector x to predict the usage counts y for each item m j . As a baseline we used the overall pop-ularity of the apps for recommending items to the users (de-noted AVG ).
We first compute the MAP of all the methods after tun-ing their parameters, the summary of the results is shown in Table 1. Djinn improves MAP over the non-context aware method, iMF , by 28%. This clearly indicates significant ben-efits of using context in the mobile domain for app recom-mendations. Interestingly, MF which is currently considered state-of-the-art in rating-based datasets shows poor perfor-mance. This is in line with the findings of [5]. The poor performance of non-personalized methods such as AVG or Poisson indicates the huge differences of app usage between users and the need for personalization.
 Table 1: MAP of the methods on appazaar data.

The precision-recall plots for all methods, on the appazaar data are shown in Figure 2. Our results are consistent with the previous experiment, that is, Djinn outperforms all other methods and that the addition of context has a substantial impact on performance. The most interesting results can be found on the left side of the graph which shows precision. In mobile recommendation precision is more important than recall given the need for recommending a short list of the most relevant apps. We again observe that methods that take into account negative feedback ( Djinn , iMF ) in the form of the non-observed entries outperform methods that ignore this feedback ( MF ). http://sifter.org/~simon/journal/20061211.html Figure 2: Precision/recall plots for appazaar data. Djinn outperforms all other methods and methods that take into account negative feedback perform better then those that do not.
