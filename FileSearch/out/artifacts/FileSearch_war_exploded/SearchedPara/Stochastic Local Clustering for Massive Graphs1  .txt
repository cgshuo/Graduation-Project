 Many practical applications of information processing involve massive amounts of data, much of which tends to be noise, and only a small fraction contains semantically interesting information. In general, clustering is the process of or-ganizing such data into meaningful groups in order to interpret properties of the data. Some general clustering methods operate online [2, 9], but practically all existing methods require some parameters in addition to a distance measure, such as the number of clusters to produce. In graph clustering, the data consists of a set of n vertices V connected by a set of m edges E .A cluster in a graph G =( V, E ) is considered to be a set of vertices that have relatively many con-nections among themselves with respect to the graph structure on a global scale. The existing methods are mostly global and rely on the full adjacency relation of the graph or a derived measure, such as the graph X  X  eigenvalue spectrum [3]. For many applications, only a small subset of vertices needs to be clustered instead of the whole graph. These include locating documents or genes closely related to a given  X  X eed X  data set. This motivates the use of a local approach for finding a good cluster containing a specified vertex or a set of vertices by exam-ining only a limited number of vertices at a time, proceeding in the  X  X icinity X  of the seed vertex. The scalability problem is avoided, as the graph as a whole never needs to be processed and clusters for different seeds may be obtained by parallel computation.
 is a set of vertices C X  V .The order of the cluster is the number of vertices included in the cluster, denoted by |C| . Two vertices u and v are said to be neighbors if ( u, v )  X  E . Following common criteria [3, 5, 8], we want the clusters to be vertex sets that are connected in G by many internal connections and only few connections outside. We define the internal degree of a cluster C to be the number of edges connecting vertices in C to each other: The local density 1 of a cluster C is Clearly, optimizing  X   X  [0 , 1] alone makes small cliques superior to larger but slightly sparser subgraphs, which is often impractical. For clusters to have only a few connections to the rest of the graph, one may optimize the relative density  X  ( C ) (see [6] and the references therein); it is defined in terms of the internal degree deg int (Equation 1) and external degree of a cluster C , as the ratio of the internal degree to the number of edges incident to the cluster, which favors subgraphs with few connections to other parts of the graph. Possible combinations of the above measures are numerous; in this paper we use the product as a cluster quality measure: The complexity of optimizing Equation 5 can be studied through the decision problem of whether a given graph G has a k -vertex subgraph C for which f ( C )  X   X  for some fixed k  X  N and  X   X  [0 , 1]. Especially, we are interested to know whether there is such a subgraph that contains a given vertex v . Both  X  ( C )and  X  ( C ) alone correspond to NP-complete decision problems; the complexities of these and other cluster fitness measures are discussed in a separate paper [11]. 2.1 Computation by Local Search Calculation of the proposed fitness measure only requires the adjacency lists of the included vertices. Therefore, a good approximation of the optimal cluster for a given vertex can be obtained by local search . To locate a cluster containing a given vertex v  X  V fromagraph G =( V, E ), we stochastically examine subsets of V containing v , and choose the candidate with maximal f as C ( v ). The initial cluster C ( v )ofavertex v contains v itself and all vertices adjacent to v . Each search step may either add a new vertex that is adjacent to an already included vertex, or remove an included vertex. Upon the removal of u  X  X  ( v ), u = v , the connected component containing v becomes the next cluster candidate. Redefining deg ext = |{ u, v  X  E | u  X  X  ,v  X  V \C}| allows clustering directed graphs. Our clustering of a 32,148-vertex directed graph representing the Chilean inter-domain link structure is discussed in [12].
 stored as adjacency lists, v : w 1 ,w 2 ,...,w deg( v ) , only one such entry at a time needs to be retrieved from memory. For n vertices, the entries can be organized into a search tree with O (log n ) access time. The search needs to maintain only the following information: (a) the list of currently included vertices C , (b) the current internal degree deg int ( C ) (Equation 1), and (c) the current external degree deg ext ( C ) (Equation 3).
 When a vertex v is considered for addition into the current cluster candidate C , its adjacency list is retrieved and the degree counts for the new candidate C = C X  X  v } are calculated as follows: where k = |C X   X  ( v ) | and = deg( v )  X  k ,  X  ( v ) denoting the set of neighbors of vertex v . The removal of vertices from a cluster candidate is done analogously, subtracting from the internal degree the lost connections and adding them to the external degree. The memory consumption is determined by the local structure of the graph. The order of the initial cluster is limited from above by the maximum degree of the graph  X  plus one; in natural graphs, usually  X  n and |C| n . Hence examining the adjacency lists of the vertices included in the final cluster candidate takes O (  X   X |C| ) operations. The extent to which the graph is traversed depends on the local search method applied. We have conducted experiments on natural and generated nonuniform random graphs. As natural data, in addition to the web graph discussed in Section 2, we used collaboration graphs [7]. We guide the local search with simulated an-nealing [4]. For generalized caveman graphs [13] consisting of a set of intercon-nected dense subgraphs of varying order, the method correctly identifies any dense  X  X ave X  regardless of the starting point; an example is shown in Figure 1. For illustrations of collaboration graph clusterings, see [13]. In other work [14], we also discuss the applicability of the clustering method in mobile ad hoc net-works for improved routing.
 in the graph or revisiting parts of the graph, it is interesting to examine whether the extent to which the search traverses the graph has a significant effect on the clusters that the algorithm chooses. We clustered the largest connected compo-nent of a scientific collaboration graph with 108,624 vertices and 333,546 edges. We varied the number of independent restarts R  X  X  20 , 40 ,..., 100 } per search vertex and the number of cluster modification steps S (from 200 to 1,000 in increments of 100) taken after each restart for simulated annealing. The Fig-ure 2 shows the ratio of the number of vertices visited during the search to the final cluster order, averaged over 100 vertices selected uniformly at ran-dom; the final orders are plotted for reference. Figure 2 plots the ratio of the number of vertices visited and the final order of the selected cluster using R restarts of S steps averaged over 50 randomly selected vertices. The extent to which the graph is traversed grows much slower than the number of modifica-tion steps taken, implying high locality of the search. As the iteration count is increased, the relative difference gets smaller, which indicates that the number of vertices visited practically stops growing if the increasing possibility for ran-dom fluctuations is ignored. The distributions of the cluster orders over three R/S -pairs of the same graph are shown on the right in Figure 2; the distribution changes very little as the parameters are varied, indicating high stability of the method.
 ings of GMC (Geometric Minimum Spanning Tree Clustering) with additional linear-time post-processing and ICC (Iterative Conductance Cutting) [1] for cave-man graphs of different orders. For each graph, we compared the clusters of each vertex obtained with the three methods by calculating what fraction (shown in percentages) of the vertices of a cluster A determined by one method are also included in the cluster B determined by another method. Table 1 shows the results for a caveman graph with 1,533 vertices and 50,597 edges; the results for the smaller graphs allow the same conclusions. ICC splits the caves into small clusters, which is a sign that it fails to recognize the cave boundary on which the density jump takes place. GMC and the local method agree in a majority of cases exactly in cluster selection, and even when they differ, one is usually a subset of the other. GMC and ICC agree poorly with each other.
 In this paper we have defined a local method for clustering. The method requires no parameters to be determined by the user, nor does it estimate parameters from the dataset; only the local search method being employed may require pa-rameters. No knowledge of the structure of the graph as a whole is required, and the implementation of the method can be done efficiently. The experiments show that approximate clustering with our measure produces intuitively rea-sonable clusters without extensive traversing of the graph. Employing a local method in the presented way is likely to produce an approximation of some global clustering method; we hope to determine as further work how our local method relates to other methods, such as spectral clustering discussed in [3]. For another local method, see our recent paper [10].
 This research was supported by the Academy of Finland under grant 206235 and the Nokia Foundation. We thank Marco Gaertler for providing the GMC and ICC clusterings, Kosti Rytk  X  onen for the assisted use of his graph visualization software, and Pekka Orponen and Christos Faloutsos for their valuable comments on this work.

