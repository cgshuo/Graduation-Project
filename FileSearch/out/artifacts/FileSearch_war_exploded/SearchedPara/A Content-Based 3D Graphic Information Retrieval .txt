 As more image and graphic data are used in applications, the methods that support content-based retrievals of 3D graphic information are desired. Most current 3D graphic systems focus on visualizing 3D images. They usually model a 3D image using lines and polygons with information on their placements in the space. One prob-lem with this approach is that it is difficult to store semantics of 3D objects in a scene. domain object separately from others. 
We have developed a 3D graphic data model that supports a content-based retrieval for 3D scenes. This paper presents the data model and a web-based information re-trieval system based on it. The 3D graphic data model, called 3DGML (3-Dimensional Graphical Markup language), allows the semantics of 3D objects to be component objects, semantic or spatial relationships among objects and composition hierarchies of objects. 
In 3DGML, scenes are modeled as compositions of 3D graphic objects. A set of primitive 3D objects is used as building blocks for modeling 3D scenes. Larger 3D objects are defined through a composition of other objects. The user can search scenes using various 3D graphic features such as inclusion of a given object, object X  X  shape, descriptive information and spatial relations of 3D objects they contain. The 3D graphic retrieval system presented in this paper was implemented using XML. 
The remainder of this paper is organized as follows. The next chapter discusses previous research related to our work. Chapter 3 describes modeling 3D images with 3DGML. Chapter 4 presents the information retrieval system for 3D graphic informa-tion that we developed. Chapter 5 concludes the paper. Research on 3D graphics has mainly concerned about the visualization of data to provide the user with a 3D feel [1, 2, 3]. Existing graphic systems treat a 3D object as a collection of lines and polygons rather than a unit of manipulation. It prevents them from supporting content-based retrievals or manipulations of 3D objects. 
MPEG standard committees have been worked on the issues of modeling 3D im-ages [4, 5]. MPEG-4 SNHC (Synthetic, Natural, and Hybrid Coding) aims to develop techniques for representing synthetic images with natural objects efficiently. 3D ob-as color, texture, etc. However, modeling 3D objects as semantic units is not ad-dressed by MPEG. 
X3D (eXtensible 3D) is an Open Standards XML-enabled 3D file format and re-lated access services for describing interactive 3D objects and worlds [6, 7]. It enables real-time communication of 3D data across all applications and network applications. X3D does not also consider the representation of semantics in 3D graphic modeling, which are used to retrieve 3D images from the database. 
There have been some efforts to model the spatial relations of objects for 3D scenes. Xiong and Wang described a technique supporting similarity search for a chemical application [8]. They represent a 3D object as a 3D graph consisting of one or more substructures of connected subgraphs. Similarity of two objects is determined by comparing their substructures and ed ges. Gudivada and Jung p roposed an algo-their image representation scheme, an image is converted to an iconic image with human assistance. This method also determines the spatial relation of objects using the connectivity of graphs. 
While the works discussed above considered geometrical similarity, they did not discuss modeling the semantics of 3D objects and querying based on the contents of 3D images. In order to address the problems discussed above a new data model is needed that treats 3D objects as first class objects in modeling. The new model should represent 3D data using semantic units rather than primitive geometrical objects. We first present the 3D graphic data model with an example 3DGML document that models a 3D scene. A 3D scene is modeled using three types of components: 3D system-defined 3D graphic object such as box, cone, cylinder and sphere. An object of an arbitrary shape that is difficult to model with basic objects only is defined using one or more polygons. Such an object is called a user-defined shape . A complex 3D object is modeled as a composition of shapes, user-defined shapes, and other complex objects. Every 3D object within a scene exists in the form of a Gobject (Graphic object). A object that is used as a prototype of other objects. We called it Aobject . It is a template defining abstract objects first. In many cases, abstract objects represent semantic units such as desk, chair, etc that are germane to an application domain. 
Fig. 1 shows a 3D scene of furniture in an office that will be used in our discussion Gobject refers to. 
Fig. 2 is a stripped version of a document that models the scene in 3DGML. The model in Fig. 2 defines the scene  X  X FFICE_01. X  It contains two major blocks: the Definition block that defines abstract objects used in the scene and the Display block that defines the actual contents of the scene. 
The Display block contains the definitions of Gobjects G001 through G 009 which model the objects labeled in Fig. 1, correspondingly. Object G001 is an example of a Gobject defined using A001, an abstract object , as its prototype. It is a concrete exten-sion of A001 with a translation. 
We now narrow our discussion to the modeling of bookcase G001. The 3DGML model shown in Fig. 2 defines bookcase G001 in a two-step process. It first defines an abstract object, A001 and defines G001 as a Gobject by declaring A001 to be its pro-totype and specifying transformation information needed to create a concrete graphic object to be inserted in the scene. 
According to the definition of the abstract object A001, it consists of many basic shapes including a cylinder. The information defined by the shape object in the ab-the information needed by A001. This example defines the relative location and scal-values may need to be modified or complemented with further information to fit it in a specific scene. The definition of A001 contains one descriptor, which describes it as a bookcase. The Contour element of A001 contains a vector value of the contour object for A001. 
The Td_string element defines the spatial relation for the objects contained in this scene. A 3D string can express the concepts such as A is located to the left of B, A is above B, and A is closer than B [10, 11]. A 3D string is a 3-tuple (u, v, w), where u, v, and w represent the 1D strings obtained when objects are projected to the X, Y, and Gobjects G001 thro ugh G 009. For example, the u value of the 3D string specifies the G001 is located to the left of G002. Since G003, G004, and G005 are on the same represented as  X  X 003=G004=G005&lt;G006. X  The implementation of the 3D graphic information retrieval system discussed so far is based on the XML technology. It has been implemented and runs with IIS(Internet Information Server) on the Windows NT platform. The XML parser was implemented in ASP using DOM API [12]. Parsed XML documents are stored in Oracle 9i. The system consists of the semantic editor, 3D object manager, the query coordinator and the database wrapper as shown in Fig. 3. file like 3D Max. Then, the semantic editor converts the VRML document to a 3DGML document. The database wrapper parses the generated 3DGML document part of 3DGML structure that is used querying 3D images. The output generator con-verts the 3DGML document to a VRML document to display its 3D image on the Web browser. graphical user interface so that users can enter a Query-By-Example style query. Our system supports queries involving descriptors, graphic features and the existence of objects. First, the description on a scene or an object can be used querying database. 3D graphic features such as color, contour and spatial relations can be also used as a query condition. Finally, user can retrieve scenes based on a hierarchical relationship given shape or find a scene that contains a given Aobject or Gobject. Finding Gob-jects that is defined by using a given Aobject is possible too. 
A sample query on the 3D database system is now described, which retrieves the scenes that contain a lamp on a desk. Fig. 4 shows the screens displayed by the sys-enters queries. lect Aobject X  buttons. When  X  X elect Object X  button is pressed, the object selection window of Fig. 4(b) is popped up for the expression of conditions. The conditions of Fig. 4(b) mean an object whose descriptor contains a word  X  X ESK X  and contour ob-ject is the same shape as the given box object. If  X  X elect Aobject X  button is pressed, the Aobject list window of Fig. 4(c) is shown. The user selects an Aobject to be used as a query condition from the list. A lamp object is selected in our example. For each time the user specifies a search condition for an object, a conditioned object is added to  X  X elected object X  part of the user interface. 
After expressing all conditions on objects, the user states 3D string conditions in above. The scenes shown in Fig. 4(d) are returned as the result of the query. We presented a web-based 3D graphic information retrieval system that offers a con-tent-based retrieval of 3D scenes. Our model separates the implementation details of a 3D object from its semantic usage and supports modeling scenes in an object-oriented way. The concept of 3D string that we came up with allows the system to formally objects on our system was described using an example. Search may be based on 3D shapes and spatial relations. useful for many graphics applications that require 3D semantics. For future work, we are planning on providing more elaborate algorithm to represent the contour informa-scenes. We also consider the indexing methods that help fast searching of 3D graphic data using their features. This work was supported by the Internet information Retrieval Research Center (IRC) in Hankuk Aviation University. IRC is a Regional Research Center of Gyeong-gi Province, designated by ITEP and Ministry of Commerce, Industry and Energy. 
