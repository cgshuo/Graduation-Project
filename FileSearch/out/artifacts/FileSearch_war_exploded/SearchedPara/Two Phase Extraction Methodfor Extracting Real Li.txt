 Many information sharing services currently exist, such as community knowledge sharing sites, blogs, and microblogs. Twitter is one of the most widely spread microblogs. Articles in Twitter are posted very easily within 140 characters. Users post their experiences, opinions, and other events that arise in their daily life.

Most articles in Twitter are both useful and timely because they are written based on current events. For example, co mmuter train delay information posted by a passenger is timely and useful for wa iting passengers. Supermarket sales and bargain information is also useful for neighborhood consumers. Such information has highly regionality and freshness. Thus, we call such posts  X  X eal Life Tweets X . Extracting real life tweets from a sea of t weets is quite an important research issue for supporting life activities.

The Great East Japan Earthquake Disaster, which occurred in March of 2011, is a perfect example of the benefits of rea l life tweets. There was a great amount of confusion in the stricken area immedi ately following the earthquake. There was a lack of food, suspension of water supply, and train service cancellations. At that time, useful tweets reported the location of water supplies and food distribution, as well as the service status of trains, demonstrating that such real life tweets helped the users in the devastated region[1].
 As mentioned above, highly useful real life tweets are increasingly posted on Twitter. However, users posts various types of tweets.  X  X od X  and sympathetic phrases frequently appear on Twitter. For example,  X  X hank you X  and  X  X  see X  often appear in posts. These posts do not directly support the real life situations of other users. We believe that users want a method of locating beneficial tweets on Twitter. These types of nods and sympathies simply impede the discovery of substantive tweets.

Information is used in various aspects of life. Real life tweets can accommo-date such aspects. For example, tweets such as  X  X he train is not coming! X  are categorized in the  X  X raffic X  aspect and will support users who want to ride the train. Posts such as  X  X oday, bargain sale items are 50% off! X  are categorized as  X  X xpense X  aspects and will support users who are going shopping. In our previous research, we detected 14 aspects o f real life[2]. These 14 aspects, listed in Table 1, are obtained from  X  X ocal Community X  1 and  X  X ife X  2 in the Japanese version of Wikipedia.

In this paper, we propose a two phase extraction method for extracting real life tweets. In the first phase, many topics are extracted from a sea of tweets using Latent Dirichlet Allocation (LDA). In the second phase, associations between many topics and fewer aspects, shown i n Table 1, are constructed using the weight of feature terms calculated with information gain. Real life tweets consist of both the experiences and knowledge of users and re-gional information. Several studies with experience mining have been conducted to extract experiences from documents. Kurashima et al. [3] reported that human experience can be divided into five areas: T ime, space, action, object, and feeling. Inui et al. [4] described a method of indexing personal experience information from the viewpoint of time, polarity, and speaker modality. This information is indexed as Topic object, Experiencer, Event expression, Event type, and Factu-ality. These mining methods are effective for relatively long documents such as blogs. Hence, these methods are not appropriate for Twitter posts, which consist of many short sentences. In addition, experience mining would be much more difficult because subjects and objects in sentences are often omitted in Twitter.
The study of Twitter is flourishing. Ramage et al. [5] used large scale topic models to represent Twitter feeds and us ers, showing improved performance on tasks, such as post and user recommendations. Bollen et al. [6] analysed sentiment on Twitter according to a six-dimensional mood (tension, depression, anger, vigor, fatigue, and confusion) representation, determining that sentiment on Twitter correlates with real-world values such as stock prices and coincides with cultural events. Diakopoulous and Shamma [7] conducted inspirational work in this vein, demonstrating the use of timeline analytics to explore the 2008 Presidential debates through Twitter sentiment. Sakaki et al. [8] assumed that Twitter users act as sensors, discovering an event occurring in real time in the real world. Zhao et al. [9] suggested a model, called Twitter-LDA, based on the hypothesis that one tweet expresses o ne content of a topic. They classified tweets into appropriate topics and extracted keywords to express the contents of the topic. Mathioudakis et al. [10] extracted burst keywords in tweets collected automatically. They found a trend fluctuating in real time by creating groups using the co-occurrence of keywords.

Our paper contends that the informati on is not only based on user experience, but also user knowledge, which we believe to be useful in real life. Real life tweets contain the various asp ects mentioned in Section 1. Therefore, it is difficult to enumerate keywords related into whole aspects. Moreover, the rule-based parsing approach using experience mining does not work well because twitter posts are comprised of very short sentences.

We propose a two phase extraction method, shown in Figure 1. In the first phase, a large number of topics are extracted from a sea of tweets using LDA. LDA is an unsupervised learning model for clustering large amounts of docu-ments [11]. In the second phase, we constru ct an association between the topics and aspects. 3.1 Association Building Using Labeled Tweets For building associations, we prepare a small set of labeled tweets. A set of extraction terms from tweets labeled aspect ap is W ap . To calculate the weight of terms that represent each aspect, we use information gain. Information gain provides feature choice and represents a good feature. The information gain of term w is calculated as follows: where AP denotes all aspects. P ( w ) is the probability of term w  X  X  appearance in all tweets. P (  X  w ) is the probability of term w not appearing in all tweets. H ( AP | w ) is the conditional entropy of all aspects AP that appear in term w . H ( AP |  X  w ) is the conditional entropy of all aspects AP that do not appear in term w .When IG ( w ) has a high value, w is a good feature.

Relevance R ( ap, k ) between topics k and aspects ap is then calculated as follows: where p w,k denotes term w of occurrence probability in topic k . length ( W ap )is the size of the terms set. Note that this equation calculates the relevance using the occurrence probability and information gain of terms.

To fold in value 0 to 1, we normalize R ( ap, k ) in each aspect. Normalized relevance  X  R ( ap, k ) is shown as follows: where T denotes all topics extracted using LDA.

We make an association between topics and aspects when  X  R ( ap, k ) exceeds a threshold  X  ( ap ). The threshold value in each aspect is calculated as follows: d varies for maximum extraction precision in Section 4. 3.2 Real Life Tweet Extraction To extract real life tweets, we use the a ssociations between topics and aspects. The score between tweets and aspects is calculated as follows: where W denotes a set of terms extracted from an unknown tweet and p w,k , denotes the term w of occurrence probability in topic k .
 The selected aspect in each unknown tweet is as follows: We evaluate the precision of the aspect selected by equation (6). After that, we should clarify why we drew a differ ence between high precision and lower precision. Because of this, we carefully ob serve the association between topics and aspects of varying thresholds d . 4.1 Datasets and Parameters Setting Datasets: We used datasets of tweets posted from April 15, 2012 to August 14, 2012 in the Japanese location information of  X  X sukuba X  or  X  X . The number of tweets is 2,900,819. This large dataset is classified into topics using LDA.
We also prepared a small set of tweets lab eled with each aspect. The collection term and condition are the same as above. The number of tweets in each aspect is 200. We also prepared 200 un-real life tweets to confirm classification. These sets of tweets are used for building the association.
 Parameters Setting: LDA requires some hyper parameters. According to re-lated works[12], we set  X  at 50/ T and  X  at 0.1. The iterative calculation count in LDA is 100 times in every case. We set the number of topics at 500. Extraction Precisions: We evaluate the precisions by using 10-fold cross-validation. Thus, 180 tweets in each aspect are used for building association and the remaining 20 tweets are used for testing.
 4.2 Experimental Results Extraction Precisions: The extraction precision s of every aspect are shown in Figure 2. The horizontal axis is threshold d that decides the association be-tween topics and aspects. In some aspect s, i.e., Appearance, Eating, and Traffic, maximum extraction precision is achieved at the minimum value of d ( d =1).In some aspects, i.e., Contact, Event, and H ealth, maximum extra ction precision is achieved at the maximum value of d ( d = 20).

To analyze the association between topi cs and aspects, we evaluate the number of connections from topics to each aspect. The number of topics against threshold d is shown in Figure 3. In every topic, the number of topics is increased according to d . The five aspects of Eating, Living, Expense, Disaster, and Working mostly connect one topic until d  X  12. On the other hand, the Contact and Event aspects are rapidly reached to connect whole topics. According to Figure 2, Living, Eating, Disaster, and Expense achieved the high-est precisions. These four a spects are associated with fewer topics, as shown in Figure 3, even if parameter d was increased. Association details between each aspect and topics are shown in Figure 4. These ten topics in the figure have a larger sum of relevances  X  R from topics to aspects. In this figure, we confirm that these four aspects have strong relevance to the specific topics, Living to Topic418, Disaster to Topic144, and so on, respectively.
 The worst cases, Event and Contact, have a lower precision value as shown in Figure 2. These aspects were associated with many topics even if d was small. In particular, Contact is associated with the same topics, Topic297, Topic383, and Topic479, as Eating. Moreover, the values of  X  R are smaller than Eating. Event is associated with the same topics, Topi465 and Topic320, as Locality. In this paper, we propose a two phase extraction method for extracting real life tweets. In the first phase, many topics are extracted from a sea of tweets using LDA. In the second phase, associations be tween many topics and fewer aspects are constructed using a small set of la beled tweets. To enhance accuracy, the weight of the feature terms is calculated with information gain.

Based on the experimental evaluation results, our prototype system demon-strates that our proposed method can e xtract aspects of each unknown tweet. We confirm that high precision aspects are associated with fewer topics that are similar to the aspects. However, low pr ecision aspects are associated with many topics. In this case, many topics are asso ciated with many aspects. In the future, we should consider evaluating the KL Div ergence from aspect to aspect in order to enhance separation among the aspects.
 Acknowledgement. This work was partly supported by Research Projects of Faculty of Library and Information and Media Science, University of Tsukuba.
