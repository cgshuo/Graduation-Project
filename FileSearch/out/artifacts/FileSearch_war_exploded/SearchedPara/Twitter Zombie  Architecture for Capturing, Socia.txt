 Social computational systems emerge in the wild on popular social networking sites like Facebook and Twitter, but there remains confusion about the relationship between social interactions and the technical traces of interaction left behind through use. Twitter interactions and social experience are particularly challenging to make sense of because of the wide range of tools used to access Twitter (text message, website, iPhone, TweetDeck and others), and the emergent set of practices for annotating message context (has htags, reply to X  X  and direct messaging). Further, Twitter is used as a back channel of communication in a wide range of contexts, ranging from disaster relief to watching television. Our study examines Twitter as a transport protocol that is used differently in different socio-technical contexts, and presents an analysis of how researchers might begin to approach studies of Twitter interactions with a more reflexive stance toward the application programming interfaces (APIs) Twitter provides. We conduct a careful review of existing literature examining socio-technical phenomena on Twitter, revealing a collective inconsistency in the description of data gathering and analysis methods . In this paper, we present a candidate architecture and methodological approach for examining specific parts of the Twittersphere. Our contribution begins a discussion among social media researchers on the topic of how to systematically and consis tently make sense of the social phenomena that emerge through Tw itter. This work supports the comparative analysis of Twitter studies and the development of social media theories. H.5.3 [ Group and Organization Interfaces ]: Web-based Interaction Algorithms, Design, Experiment ation, Standardization. Twitter, data collection, data management, methods, social media There are recognized empirical and theoretical gaps in the application of social science theories to raw, electronic trace data like that retrievable from Twitter [23]; a record of interaction through technology does not necessarily act as a proxy for social interaction. Such gaps are further exacerbated by the opaqueness of Twitter X  X  API for retrieving data, and different choices researchers make about how to retrieve, store and analyze data from Twitter. Each peer reviewed study of Twitter interactions, in domains ranging from disaster relief , to sports view ing, political action and celebrity engagement with fans, presents an explanation of how data is captured, analyzed and related to findings within the individual study. The explicitness of these descriptions is variable. C onsequently, comparisons across Twitter studies and aggregation of findings leading to more comprehensive theories of social media interaction are difficult because of the lack of a shared view of well understood and documented methods for gathering a nd analyzing electronic traces from social media, including Twitter. A few papers have attempted to build community understanding of how to select and use different Twitter application programming interfaces (APIs) for research. Zhao et al. [50] , for example, contrast the three main APIs provided by Twitter  X  the REST, Search and Streaming APIs  X  but their paper is either out of date a year after publication, or incorrect in its interpretation of Twitter X  X  API X  X . Scholarship that references, do cuments or contrasts different social media platform APIs, including Twitter X  X , face the challenge of working to reverse engineer a system whose traits may be shifting over time. What we report on today with regards to the Twitter API may not be sustained over time by the Twitter platform. The two key gaps in anal ysis of social media generally, and Twitter in particular, then, ar e 1) Each study constructs it X  X  own approach to gathering Twitter data and 2) Attempts to explain the Twitter API through an alysis are difficult to verify because the data delivered by API may be changing over time. We see three potential ways of overcoming the challenges we identify. First, social media ve ndors could make the completeness of data retrieved through their API X  X  more transparent. This is stifled by privacy and compe tiveness concerns. Second, individual studies of Twitter ma y begin to follow a standard methodology for gathering data, appropriate to the problem context, and referencing articl es focused on these methodological approaches. Third, the community might consider a standard architecture for the capture of social media, which would constitute a technical architecture to ensure consistency of social science results; in a sense, using computers for what they are good at, and people for what they are best at. Fully developed solutions to these challenges are an important, long-range goal for the social media research community. In this paper we present a modest, but integrated methodological approach and technology architect ure for the standard capture, social transformation and analysis of Twitter interactions using the Search API. We contrast this API with the other two, describe the results of experiments conduc ted using our tools, which we call Twitter Zombie, explain our process of social transformation, and describe a pilot visualization and analysis project using this methodological approach and toolset. We conclude with a road map for methodological enhancemen ts to social media research. Twitter research has evolved from the time when Twitter was first introduced in 2006. Early research on Twitter attempted to characterize user behavior in the technology. Java et al. [26] found that individuals used Twitter to discuss daily routines and to exchange news. At the same time, other researchers attempted to characterize user behavior on Twitter and identify specific behavior around Twitter X  X  numerous affordances [29]. The three most common affordances in twitter are the hashtag, retweet and @-mention. Hashtags ar e used to highlight streams of discourse for others to attend to [24; 42] and retweets are a mechanism of forwarding another user X  X  message in one X  X  own Twitter stream [8]. In addition to the inclusion of hashtags and retweets, the inclusion of @-mentions (@ followed by a username) signifies a direct addr essal to or highlighting of a message to someone else and may be indicative of targeted information sharing or discourse [22]. In addition to these technological affordances, researchers are able to collect the device or application that a user utilized to send a tweet. Analysis of the device activ ity can highlight the utilization of different technological acce ss mechanisms for different purposes [48]. We illustrate such differences in the description of our pilot study in section five. When coupled with geographic location from the user profile, or from where the tweet originated, researchers can identify geographically specific information such as localized discourse [39] or attempt to identify the overall happiness of people in certain geographic areas [41]. Unlike other forms of social media, only 22% of Twitter relationships are reciprocal [30]. This creates an environment of  X  X ontext collapse X  in which a user has multiple audiences for their tweets, and the user may not be aware of who is in those audiences [33]. As a result of this asymmetric network structure, information diffusion is significantly different on Twitter than in social networking platforms that have symmetric relationships [31]. Substantial prior research utilizes the follower/following relationships to characterize user behavior on Twitter [28]. Measuring the number of followers an individual has (as in-degree influence) illustrates popularity, but does little to measure their ability to influence others [9]. Though follower/following relationships are important for understanding initial information diffusion, collecting and characterizing actual user behavior such as retweet behavior, the number of mentions and reply-to X  X , and the content of tweets are much better indicators of influence [3; 6]. Influence in Twitter is also shown to be the result of long-term reputation building in a network of individuals [9]. One of the more commonly used affordances in Twitter is the retweet. A retweet is the process of an individual further propagating another X  X  message by copying it into their Twitter stream. Prior studies illustrate that 16% of tweets on a daily basis on Twitter are retweets [38]. In specific domains, such as political discourse, the percentage of retweets can be as high as 56%, depending on the topic [38]. Kwak et al. [30] found that 75% of retweets occur within th e first hour of the original tweet, but that 10% of retweets occur a month later. This illustrates a different intent and purpose of retweeting and a different trajectory of information diffusion. There are many reasons that individuals retweet messages, which include: to propagate information, to illustrate that they are  X  X resent X  in the conversation or in the space, and to attempt to return favors to other individuals to prop up their twitter followers [8]. In addition to these reasons, retweets are seen as a mechanism of conversation that takes on different characteristics depending on the use r X  X  network and the content of the original tweet. One study found that positive messages are more likely to be retweeted than negative messages, illustrating how content can affect information diffusion through the network through the retweet mechanism [17]. Honeycutt and Herring [22] identif y the technological affordance of @, which directs a message towa rds someone else, as a form of addressivity [46] in Twitter. In their analysis, they found that close to 90% of the instances of @ were someone addressing another individual in a conversa tion and these conversations on average lasted 3-5 messages. Of the larger sample that included tweets with both @ and without, they found that thos e tweets with @ tended to be more interactive in their content. For example, they found that messages that employed the @-mention affordance received a response 31% of the time, which is higher than previous studies of technol ogically mediated communication. This number is also a conservati ve estimate, as it does not take into account the possibility that a reply may have been sent in another channel [49]. One of the most significant areas of research on Twitter has been the use of sentiment analysis a nd other modeling techniques to examine, explain, or predict offline events [2; 4]. Some research has indicated that the brevity of Twitter messages affords more reliable sentiment classifications [5]. These approaches have been applied to predicting the directi on of the US Stock market [7], analyzing debate performance in a 2008 US Presidential Debate [13] understanding the outcome of 2011 Portuguese Presidential elections [14] and identifying general public opinion [1]. Further research indicates that the volume of Twitter activity may mirror box office performance, but may not be as representative of stock market activity [34]. These findi ngs indicate possible different uses of Twitter in different social domains, and also may represent a demographic difference in us er activity. Understanding sentiment on Twitter has also been used to further understand sporting events such as the Olympics [17] and Brazilian Soccer Leagues [18]. The medical community has also studied Twitter as a way to understand whether or not the public adopts certain terminology in the context of a Pandemic [10]. In this instance, the researchers were interested in whether the pub lic used the term  X  X wine flu X  or the more medically formal te rm,  X  X 1N1. X  Early research analyzing medical information diffusion on Twitter has also attempted to identify the mechanis ms that users utilize to judge trust and validity of medical in formation. This research has demonstrated that the originati ng user and the content of the message is likely to be a signifi cant factor in how individuals assess the validity of information. [36]. Researchers have also attempted to identify influenza outbreaks through the monitoring of Twitter for certain keywords, but have had limited success [12]. One of the greatest areas of research on Twitter is the analysis of political activity and participation in Twitter. Researchers identify partisan clusters in retweet beha vior illustrative of echo chambers of ideas in information diffusion in Twitter [11]. These researchers also find examples of  X  X ontent injection X  that identifies users adopting partisan hashtags or keywords to broadcast material that may be counter to the ideology of the party to proliferate a message. Similar activ ity is also been noted in the context of the conservative hashtag #tcot (Top Conservatives on Twitter) [32]. Additionally, researchers show how multi-dimensional scaling can be used to classify users based on hashtag and @-mention usage [19]. Researchers in the U.K. found a difference in adoption of Twitter based on partisan affiliation of members of parliament (Williamson et al 2010). Additionally, many of the studies focused on the utilization of Twitter by the US Congress found that members used Twitter for self-promotion as oppos ed to communicating directly and specifically to citizens [16]. Analysis of political activity in Korea has found that  X  X esource-deficient politicians X  may be more likely to engage with followers a nd use it as a mode of connecting to citizens [28]. Research has identified similar behavior in the United in the 2010 US midterm election where the conservative minority was more effective at using social media to build support [32] and challengers tended to interact more with the public than incumbents [40]. Using hashtags to analyze political discourse on Twitter has been done across cultures as well. German researchers used politically oriented hashtags to identify 2009 election discourse [27]. During this election, German Twitter users were encouraged to use party related hashtags followed by + or  X  to illustrate agreement or disagreement with the message. Through this hashtag valence the researchers were better able to u nderstand the network structure of individuals and identify  X  X mall worlds X  of connected individuals had similar political viewpoints. In addition to understanding ho w politicians, candidates and the significant amount of work that has attempted to illustrate how social media may be able to predict elections [45; 47]. A review of this work illustrates fundamenta l flaws in the approaches and illustrates the lack of comparison to traditional mechanisms of prediction and analysis such as polling or historical evidence, illustrating that the incumbent wins close to 90% of the time in United States Congressional election [35]. Metaxas et al. further extend this critique by identifying th at much of this  X  X rediction X  occurs after the election and may actually be worse than traditional models. When attempting to repeat experiments that  X  X redicted X  wins in electoral races, Metaxas et al. [35] were unable to reproduce the results. The contrast between planned and unplanned events is one that has been explored in the context of crisis informatics on social media such as Twitter. Research that compared national political events and natural disasters have found th at Twitter is used as a way to broadcast information out to the public and in the case of natural disasters Twitter is used as a frequent way to share links with the public [25]. Twitter has also been instrumental in understanding crisis events and natural disasters. One of the reasons that individuals use Twitter during a crisis event is to relay information from the place where the activity is happening and also to synthesize current information to proliferate it through the network of individuals [43]. Researchers have studied the use of Twitter for information diffusion and sense making related to unplanned, social and violent events like school shootings [21]. Research on the 2007 wildfires in California illustrate d how social media  X  Twitter in particular  X  can be an important source of information for citizens and described how broadcast media turned to Twitter to get information about what was happening [44]. Our survey of the existing literature that we discuss above reveals a significant variation in how individuals collect Twitter data. Currently, Twitter provides three API X  s to collect data, with the two most popular being the Search API and Streaming API. Our review of the literature shows that studies that look at specific affordances such as hashtags, @-mentions or other keywords contained within tweets tended to use the Search API to access data about specific attempt to look at longitudinal opinions of movies, politics and other domains use the Streaming API to access data [6; 19; 34]. The differences between how data is collected by these two API X  X  may significantly alter the type of dataset collected by researchers, though these differences are not discussed in detail in empirical studies of Twitter. In addition to lab developed access mechanisms that query the Twitter API directly, there are other tools such as NodeXL [20] that provide an interface for users to access data, and statistical libraries such as twitteR for the statistical program R [15]. In addition to these access mechanisms, Twitter also provides feeds of the Twitter stream to some organizations. Th ese feeds are described by Twitter as a random sample of a percentage of the overall Twitter stream. We found only one explicit mention to this access mechanism in our survey of the literature and th at was the Twitter  X  X arden hose X  which provides a sample of 10% of all tweets. This access was used by the individuals of the Truthy project at Indiana for a series of papers [11; 35; 37; 38] Our review of the literature illustrates the domain breadth, affordance diversity and methodological approach differences associated with prior Twitter resear ch. We show that social media research in general, and Twitter res earch specifically presents with a diverse set of approaches for gathering and analyzing socio-technical phenomena that share Twitter as a social media platform. Twitter literature to date illustrates that there is not a consistent, repeatable set of tools for collecting, analyzing and reporting on Twitter facilitated social groups. Fu rther, different studies present and explain their methods of capture and analysis with an inconsistent level of clarity and specificity. These gaps make it difficult to draw comparisons across studies of similar phenomena in Twitter, and impair the development of broader social media theories. The contribution we make to address the challenges presented is a methodological approach and technical tool (Twitter Zombie) for Twitter data collection and analysis. Our Twitter Zombie system for capturing data from Twitter and the associated experiments we present provide a repeatable fou ndation for the community to use for social media capture verification and our pilot study illustrating our methodological approach illustrates the collection idiosyncrasies associated with certain collection parameters, and how different parameters can alter the collected datasets. If played out over time and across studies, these small diffe rences may be significant and alter findings. Presently, as we noted, such differences are seldom surfaced in empirical studies of social phenomena on Twitter. We invite other researchers to share their experiences with their specific systems as an important methodological step in addressing the opaque nature of the Twitter API structure. Twitter offers three primary me thods for allowing software developers access to Twitter data: the Streaming API, the REST (Representational State Transfer) API and the Search API. The Streaming API relies upon a continuously open network connection between Twitter and the receiving host and is designed to support significant volumes of da ta transfer. By contrast, the REST API follows a typical clie nt-server request and response communication pattern where connections between Twitter and the requesting host are dynamicall y created on a per-request basis. Both APIs return data in JSON (JavaScript Object Notation) format, a compact human-readable data interchange format akin to an XML document representation, though less verbose. Twitter Zombie utilizes the third publically available API, known as the Twitter Search API. The Search API employs a REST communications pattern and provid es a mechanism to query the real-time index of tweets. The index contains tweets that are six or fewer days old and may include tweets up to nine days old. In addition to temporal limitations, the search API imposes a number of important performance constraints. First, a query request can be rejected if it is too complex, a lthough complexity is not publically defined. Also, results from the Search API are rate limited. Unfortunately, the parameters related to these limitations are unpublished. Finally, queries submitted via the search API are limited to a maximum of the 1,500 results, which may contain less than the most recent six days of tweets depending on how prolific the user is. Selecting an API is an important decision for researchers, but one that is often not specified in empirical work and not rationalized in the face of research questions as illustrated in our previous review of existing literature. For this application, the Search API offers a number of advantages ov er the REST or Streaming APIs. The Search API does not impose explicit rate limits as does the REST API. Perhaps most importantly, batch use of the Search API allows Twitter Zombie to maintain distinct result sets from each search, even when a unique tw eet is returned multiple times in response to diffe rent query strings. We access the Search API using a software system we developed in PHP, called Twitter Zombie. Data collected by Twitter Zombie is stored in a MySQL relational database management system. Twitter Zombie is designed to gather data from Twitter by executing a series of independent search jobs on a continual basis, 24 hours a day, 7 days a week. The execution interval for each search can be controlled independently through a rudimentary job management system. Each search job can be programmed to execute once every n minutes (where n &gt;= 1) using a run interval value. This allows us to run searches for high volume queries (those returning many tweets) more frequently than those associated with low volume result sets. High volume queries are typically run every minute or two, while some low volume search jobs are scheduled to execute only once each day (or every 1440 minutes). The search job control system also allows us to stop, restart, and change execution intervals on the fly. The workflow for creating a new Twitter Zombie search job begins at Twitter X  X  advanced sear ch web page. This simple page provides a text input field for the user X  X  query string as well as access to a handy pop-up reference that lists search operators along with usage examples. Thes e operators include OR, the minus sign (-) for negation, the ampersand (@) for referencing people, the pound sign (#) for locating Twitter hash tags,  X  X ear X  and  X  X ithin X  for geo-based searches, and others including attitudinal and temporal operators. To develop a new search job, we begin by entering a query into the advanced search page and executing it. If no results are returned, this is generally an indication of a malformed query. If results are produced, they are inspected for face validity. This process is repeated until a suitable query is constructed and tested. At that point, the URL encoded search string is copied from our web browser X  X  address field for later entry into the Twitter Zombie job control system. In effect, we are using Twitter facilities to help develop, pre -flight and encode our queries. Once a new query string is successful ly tested, it can be entered into Twitter Zombie X  X  job table. This table contains one record for each search job (active or inactive). Each record represents a complete search job definition that includes a run interval value, a human readable job description, the ID of the last collected tweet for this search and the encoded query string. Storing the Twitter supplied ID of the most recentl y collected tweet allows Twitter Zombie to request only those tweet s that have been created since the last time the search job was executed which greatly improves overall collection efficiency. The Twitter Zombie PHP code is executed each minute by the Linux time-based job scheduler, cron. During each running of Twitter Zombie, the entire search job table is scanned to determine which queries should be executed. If a search job X  X  run interval value indicates that it X  X  time to execute the query, a request is made to Twitter. The Twitter Zombie control architecture can therefore be tho ught about as two loop constructs, one inside the other. The outer control loop responsible for repeatedly executing Twitter Zomb ie is managed by cron, while the inner search job loop is managed by the PHP code, which references the job table. In addition to storing and manipul ating search job control data, the MySQL database is also used to store the collected tweets and associated metadata. The database schema is optimized for insertion efficiency. This is important in the context of a system that may be called upon to handle sudden unanticipated surges in tweet volume. Unforeseeable surges are common in disaster relief scenarios or when a news story breaks that impacts a large number of Twitter users. In terms of a design tradeoff, we have chosen to optimize the efficiency of data writes at the expense of storage consumption by forgoing a more space conserving, fully normalized database schema. Much of Twitter Zombie X  X  utility as a research tool stems from its ability to capture the hierarchical relationships in the data returned by Twitter. The search results are run through a tool we call the  X  X etwork translator X  which performs post collection processing and records the results in the database. The complete tweet text and all related entities (e.g. hashtags and mentions) are stored separately. We explain this furthe r in section 4.1, which describes our conceptualization of how to socially transform raw Twitter data to reflect interactions be tw een people, and between people and artifacts. Preserving the data X  X  original structure allows us to leverage the power of SQL (Structured Query Language) to perform post hoc data transformati on in order to answer specific research questions. Social media researchers make implicit or explicit choices about whether or not to include the full character set for non-English languages; or multi-byte languages like Arabic, Chinese or others at all. This is due to the wa y Twitter handles character encoding, and the subsequent handling of that encoding by common software tools. Twitter stores the text strings that comprise tweets and other data as UTF-8 encoded characters. This means that tweets may include a variety of characters not represented in the ASCII (American Standard Code for Information Interchange) encoding scheme. UTF-8 encoding allows Twitter to handle the entire Unicode character set, but this affordance comes at the cost of complexity. Because UTF-8 is a variable-width encoding scheme (where a single character may be represented by two or more bytes), visually counting characters does not necessarily reveal the number of bytes required to store a given string. This uncertainty is exacerbated by the fact that some words with accented characters can be encoded using more than one representation. In order to not disadvantage users of non-English characters, Twitter employs Unicode Normalization Form C order to compute character c ount. This reality has obvious implications for the Twitter Zombie database design. In order to ensure that the full text of a tweet is faithfully recorded, the field containing the tweet string must be able to store four bytes for each character for a total of 560 bytes (i.e. 140 characters * 4 bytes per Unicode code point). In order to alleviate the need for all of our downstream analysis tools (and even some basic system utilities) to support UTF-8 encoding, Twitter Zombie is capable of performing transliteration. This process maps Unicode characters that cannot be represented in ASCII to a suitable character or character string substitute. For example the euro sign would be replaced with the string  X  X UR X  when transliteration is enabled. In future versions of the tool, full support for UTF-8 will be developed. Our review of dozens of previous Twitter studies reveals no explicit mention of how multi-byte Tweets are handled. In addition to receiving the raw text of a tweet, Twitter provides a wealth of metadata that is ca ptured by Twitter Zombie. This invaluable metadata includes the time and date of a tweet and the tweet language expressed as a two-letter code defined by the ISO 639-1 standard. Tweet search results also include a source field that names the application used to create each tweet. Some tweets (the vast minority, unfortunately) are returned with geo-location data expressed as a point in terms of longitude and latitude. Entities such as hashtags, mentions, and URLs are returned as distinct elements within the JSON representation. Each entity is further described by metadata that identifies its exact location within the tweet text. The metadata indicates the beginning and ending character positions for each entity providing a simple mechanism to calculate entity length. http://unicode.org/reports/tr15/#Norm_Forms Finally, each tweet returned to Twitter Zombie carries information regarding the author (i.e. sender). A unique Twitter ID as well as a long and a short user name identifies the tweet X  X  creator. Tweets that are directed to a particular Twitter user also contain ID and name data for the intended recipient. Twitter employs processes to rem ove duplicate and near-duplicate tweets from search results. The duplication detect ion technique relies on the MinHash algorithm . A number of signatures are computed for each tweet. These signature sequences are only four bytes in length. A tweet is consid ered a duplicate if it shares a set of signatures with another tweet. Twitter filters the results delivered by both the Streaming and the Search APIs in order to exclude tweets that are deemed low quality. While the filtering algorithm is unpublished, and therefore, is likely to change without warning, Twitter does provide some insight into the filtering methodology. Frequent tweets that are considered repetitious are targeted for filtering. Twitter also filters tweets from suspended accounts and tweets that fail to meet other vaguely defined standards. When working with the search API, the result set may have also been culled based upon relevance. Twitter returns only the most relevant tweets pertaining to the query based upon unpublished criteria. The relevance filtering process is not imposed on results returned from the Streaming API. We performed several experiments using Twitter Zombie in order to better understand the operational characteristics of the Twitter Search API. The search terms  X  X ports X  and  X  X ex X  were chosen as they represent high tweet volume subjects, each returning hundreds of tweets per minute during most hours of the day. 
Experiment Collection interval (min.) API Query 1 1 q=sex 1 2 q=sex 1 3 q=sex 2 1 q=sports 2 2 q=sports 2 4 q=sports 3 1 q=sex 3 1 q=sex In experiment number one, the same query was performed with different collection time intervals. All three search jobs were started at the same time. The graph in Figure 2 shows that the number of tweets colle cted each hour tracks closely across the three search jobs over a 24-hour period. Figure 2  X  Tweets per hour for q=sex at 1, 2, and 3 min. collection intervals Despite the close agreement in hourly tweet counts, there appeared to be a slight but consistent drop-off in the number of tweets collected when using coll ection intervals longer than one minute (the baseline interval). Figure 3 shows the reduction in tweet counts for search jobs run at two and three minute intervals as a percentage of tweets collected with the same search performed each minute. Figure 3  X  Percentage drop-off for q=sex at 1, 2, and 3 min. collection intervals As was true for experiment one , the number of tweets collected over a 24-hour period, this time using one, two and four minute collection intervals, tracked ove r time as shown in Figure 4. Figure 4 -Tweets per hour for q=sports at 1, 2, and 4 min. collection intervals The pattern of recovering fewer tweets when using longer collection intervals appears again in experiment two. These results show the phenomenon more clearly than in experiment one due to the use of a longer maximum collection interval (4 min. versus 3 min. in experiment one). While the mechanism or mechanisms responsible for reducing the number of tweets returned from Twitter when using longer collection intervals is unknown, one obvious potential source of the discrepancy is user delete d tweets. This highlights an important difference between the Search and Streaming APIs. The Streaming API provides tweet de letion messages that signal receiving software to discard previously recorded tweets. By contrast, the Search API provides no information regarding deleted tweets. Figure 5 -Percentage drop-off for q=sports at 1, 2, and 4 min. collection intervals Experiment three continues the e ffort to characterize the Twitter Search API. Twitter Zombie was used to run two identical search jobs both starting at the same time. Figure 6 shows how closely the hourly counts of returned tweets agree. The percentage differences are detailed in Figure 7 . Figure 6 -Tweets per hour for q=sex at 1 min. intervals Figure 7 -Percent difference for q=sex at 1 min. and 1 min. collection intervals We use the metadata of Tweets, described in Section 3.3.2 to transform the raw Twitter data into a representation of interactions. These social interaction representations take the form of social networks around four key affordances: one each for direct mentions, retweets, devices and hashtags. These representations surface the social structure that is implicit in tweets containing traces of these user affordances, and transform them into easily analyzable node pairs in a table. This aspect of Twitter Zombie further enables statistical analysis of Twitter metadata with relative ease. Direct mentions and retweets are stored as node pairs of individual Twitter users in the analysis tables. Device information and hashtags are stored as bipartite networks, where one node type is a person, and the other is a device type or hashtag respectively. Our extraction of social metadata from the tweet string enables Twitter Zombie to swiftly visualize social and device information about Twitter activity related to planned and unplanned events that emerge in the Twittersphere. To illustrate the utility of this aspect of the Twitter Zombie Ar chitecture, we conducted a pilot study, which we describe in following section. We utilized the Twitter Zombie Collection Architecture and methodological approach to study Twitter activity around the US Republican Party Presidential Primary Debate in South Carolina on January 16 th , 2012. In an effort to focus our collection efforts only on data related to that specific debate we collected Twitter messages that contained the hash tag #SCDebate. In addition to that hashtag, the debate sponsor, FOX News, encouraged individuals to tweet the candidate  X  X  name along with the hashtag #answer or #dodge when a question was asked to identify whether the public believed that the candi date was providing an answer to the question or dodging the question. In order to facilitate this activity, FOX News created a page on their website where individuals were able to use a button specifically created to facilitate the tweeting of #answer and #dodge. The following communication networks and the adoption of specific technological applications for different purposes. The methodological approach expl ained earlier in this article allowed us to identify several in teresting characteristics of the public Twitter behavior surrounding the debate. Utilizing the #scdebate collection we are able to analyze reply-to and retweet networks to illustrate two distin ctly different behaviors. Figure 2 illustrates the diffuse network of reply-to behavior in the #scdebate data. We see that ther e are a lot of disconnected groups of discourse indicative of an unstructured set of Tweets directed towards other individuals. On the other hand, we see in the retweet network (F igure 3) that there is a significant amount of disconnected retweet behavior similar to the reply to network, but we also identify a set of clusters that illustrate concentrated retweet behavior. The most retweeted individuals are: BorowitzReport, TheFix, BretBaier and washingtonpost. These accounts all represent journa listic entities tweeting about the deba te, with BretBaier be ing the moderator. The below distribution of devices that are used to tweet in our dataset illustrates that the  X  X eb X  was the most popular mechanism for tweeting followed by Tweetdeck for the hashtag #scdebate. In our second stage of analysis we examined the dataset of collected tweets using #answer and #dodge. The hashtags #answer and #dodge did not need to be tw eeted with #scdebate indicating that there did not need to be overlap between the two datasets. The device distribution of #answer and #dodge is quite different from that of #scdebate. Figure five illustrates the device uses for the #answer button. Figure six illustrates the device usage for the #dodge button. You can see that 90% of people answering,  X  X nswer X  used the Fox News web page, while 85% of people saying  X  X odge X  did. . The Tweet Button on the http:/ /www.foxnews.com website was the most dominant technique for tweeting using those hashtags. The contrast in device distri bution between the dataset of #scdebate and #answer and #dodge iden tified two distinct areas of discourse that warranted deeper an alysis of the individual activity within each dataset to highlight the differences of the behavior related to one event using different hashtags. Table one, below, illustrates the number of unique participants relative to the number of tweets. The lower the percentage, the higher number the number of repeat participants. Based on the statistics, individua ls using #answer and #dodge posted more times than those that used #scdebate. This is indicative of the more focused purpose of the #answer and #dodge hashtags, relative to the more general discourse happening with the #scdebate hashtag. This higher leve l of repeat participation could also be a result of a concentrated technological mechanism to utilize those hashtags such as the Fox News website. We wanted to extend this line of inquiry further and understand the participation rates between the #answer and #dodge hashtags. Our findings indicate that close to 37% of the individuals posted a tweet using both #answer and #dodge . This demonstrates that some participants were interested in participating in discourse relative to candidates using bot h #answer and #dodge, but that close to 63% of the total participants only participat ed using either #Answer or #Dodge.
 In an effort to identify if there were distinct discourse communities we compared the user composition of the two datasets (#scdebate versus #a nswer and #dodge). We treated the individuals that contributed usi ng #scdebate as one dataset and individuals using either #answer or #dodge as the other dataset. Our analysis identified that only 13% of the individuals that used the #SCDebate hashtag participat ed in the #Answer vs. #Dodge exercise. This low percentage of participat ion in both the general discourse and the #Answer versus #Dodge exercise illustrates that there were two different discourse communities active on Twitter, participating in social media in relation to the January 16 This distinction is illustrated by the differences in device utilization as well as the differences in user overlap across the two distinct hashtag sets. Our pilot study illustrates the power of the Twitter Zombie toolset for providing rapid, consistent an alysis of planned and unplanned events as represented through Twitter discourse. The architecture, social transformation and analys is software system developed here helps to close an impor tant gap of consistency and transparency in social media research. Twitter is participatory mass media. Our architecture and methodological approach paves the way for other researchers to examine emergent, social phenomena on Twitter. We enable this continued inquiry with a tool cal led Twitter Zombie, which gives social media researchers, like other social science researchers before us, a transparent framework for data gathering, analysis and reporting. As Howison et al point out [23], electronic trace data is not representative of soci al interaction, even though people are responsible for its creation. How people interact through a particular socio-technical milieu of tools, affordances and practices is different in each instance. Our validation of the results of using our tool shows that differences and assumptions about data returned must be carefully and regularly examined. We do not know if our findings with re lation to the Twitter API are a result of shifts in the API over time, or shortcomings in the methods of other researchers or, plau sibly, us. The inability of the social media research community to speak with authority about these kinds of data completene ss and quality issues is at once expected at the dawn of a research era, where we are now, but is also essential to address in orde r to ensure increasingly useful, valid and relevant results for soci ety. Our demonstration of the use of the Twitter Zombie in a pilot study illustrates how powerful validated tools can be. Some elements of research method complexity are specific to the social media platform. In the case of Twitter, the selection of API is demonstrated here to play a si gnificant role in filtering data. For the social science researcher these choices, like decisions of methodological approaches such as survey sampling, ethnography site selection or theory for classic social science researchers, will influence the resulting findings and ensuing development of theory. When a phenomenon is new, as soci al media has been for the past decade, inductive research methods are called for to define the salient constructs for future inquiry. In the case of social media research, which often includes the examination of electronic trace data, and other quantitative methods of inquiry, the road map for inductive research is ill define d from prior phenomena. We are now moving into an era where key constructs, like the socio-technical interaction, the technical interaction and others, are clearly defined by prior literature. We are also entering an era where we can look back on a decade of research on social media in general, and six years of research on Twitter, to discern the inconsistencies in our approaches . These inconsistencies, while expected as inquiry begins, are important to iron out as inquiry advances. We do not claim to have built the ultimate, or even the penultimate data collection, transformation and analysis software system and methodological approach for Twitter research. Instead, we put forth this exam ple as a reference for other researchers to use. The work presented here should inspire critique from over 100 researchers whose work we build on, but upon whom we also call to advance the field. We make our collection, transfor mation and analytical processes for Twitter available for scrutiny and use by other researchers Our hope is that the social media research community, as a whole, will rise up to the challenge of building corpora of comparative studies looking at social computational phenomena across the Twittersphere. Through this approach, our findings will grow, theory will emerge and our c ontribution to an increasingly technologically mediated world will possibly find easier translation. We would like to thank Leysia Palen for her assistance in understanding the challenges associat ed with data collection and management in Twitter research. Thanks to Nora McDonald for providing numerous reviews of this paper X  X  drafts. We also thank link included in final vers ion (blind review omitted) Scott Robertson and Ravi Vatripu for their insights on data collection and management in social media research. [1] Akcora, C. G., Bayir, M. A., Demirbas, M., and [2] Bae, Y. and Lee, H. 2011 . A Sentiment Analysis of [3] Bakshy, E., Hofman, J. M., Mason, W. A., and Watts, D. [4] Barbosa, L. and Feng, J. 2010. Robust Sentiment [5] Bermingham, A. and Smeaton, A. 2010. Classifying [6] Bigonha, C. A. S., Cardoso, T. N. C., Moro, M. M., [7] Bollen, J., Mao, H., a nd Zeng, X. 2011. Twitter mood [8] boyd, d., Golder, S., and Lotan, G. 2010. Tweet, Tweet, [9] Cha, M., Haddadi, H., Benevenuto, F., and Gummadi, K. [10] Chew, C. and Eysenbach, G. 2010. Pandemics in the Age [11] Conover, M. D., Ratkiewicz, J., Francisco, M., Goncalves, [12] Culotta, A. 2010. Towards detecting influenza epidemics [13] Diakopoulos, N. A. and Shamma, D. A. 2010. [14] Fonseca, A. 2011. Modeling Political Opinion Dynamics [15] Gentry, J. 2012. twitteR package for R. [16] Golbeck, J., Grimes, J. M. , and Rogers, A. 2010. Twitter [17] Gruzd, A., Doiron, S., and Mai, P. 2011. Is Happiness [18] Guerra, P. H. C., Veloso, A., Meira, W., and Almeida, V. [19] Hanna, A., Sayre, B., Bode, L., Yang, J., and Shah, D. [20] Hansen, D., Schneiderm an, B., and Smith, M. A. 2011 [21] Heverin, T. and Zach, L. 2011. Use of Microblogging for [22] Honeycutt, C. and Herring, S. C. 2009. Beyond [23] Howison, J., Wiggins, A., and Crowston, K. 2012. [24] Huang, J., Thornton, K. M., and Efthimiadis, E. 2010. [25] Hughes, A. L. and Palen, L. 2009. Twi tter Adoption and [26] Java, A., Song, X., Finin, T., and Tseng, B. 2007. Why We [27] Jurgens, P., Jungherr, A., and Schoen, H. 2011. Small [28] Kim, M. and Park, H. W. 2012. Measuring Twitter-Based [29] Krishnamurthy, B., Gill, P., and Arlitt, M. 2008. A Few [30] Kwak, H., Lee, C., Park, H., and Moon, S. 2010. What is [31] Lerman, K. and Ghosh, R. 2010. Information Contagion: [32] Livne, A., Simmons, M. P., Adar, E., and Adamic, L. A. [33] Marwick, A. E. and boyd, d. 2011. I tweet honestly, I [34] Meador, C. and Gluck, J. 2009. Analyzing the [35] Metaxas, P. T., Mustafar aj, E., and Gayo-Avello, D. 2011. [36] Murthy, D., Gross, A., and Oliveira, D. 2011. [37] Mustafaraj, E., Finn, S., Whitlock, C., and Metaxas, P. T. [38] Mustafaraj, E. and Metaxa s, P. T. 2011. What Edited [39] Naaman, M., Becker, H., and Gravano, L. 2011. Hip and [40] Pole, A. and Xenos, M. 2011. Like, Comments and [41] Quercia, D., Ellis, J., Ca pra, L., and Crowcroft, J. 2012. [42] Romero, D. M., Meeder, B., and Kleinberg, J. 2011. [43] Starbird, K., Palen, L., Hughes, A. L., and Vieweg, S. [44] Sutton, J., Palen, L., and Shklovski, I. 2008. Backchannels [45] Tumasjan, A., Sprenger, T. O., Sandner, P. G., and Welpe, [46] Werry, C. C. 1996 Linguistic and interactional features of [47] Williams, C. and Gulati, G. J. 2008. What is a Social [48] Wohn, D. Y. and Na, E. K. 2011. Tweeting about TV: [49] Zelenkauskaite, A. and Herring, S. C. 2008. Television-[50] Zhao, S., Zhong, L., Wickra masuriya, J., and Vasudevan, 
