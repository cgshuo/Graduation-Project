 User search query logs have proven to be very useful, but have vast potential for misuse. Several incidents have shown that sim-ple removal of identifiers is insufficient to protect the identity of users. Publishing such inadequately anonymized data can cause se-vere breach of privacy. While significant effort has been expended on coming up with anonymity models and techniques for micro-data, there is little corresponding work for query log data. Query logs are different in several important aspects, such as the diversity of queries and the causes of privacy breach. This necessitates the need to design privacy models and techniques specific to this en-vironment. This paper takes a first cut at tackling this challenge. Our main contribution is to define effective anonymization models for query log data along with proposing techniques to achieve such anonymization. We analyze the inherent utility and privacy trade-off, and experimentally validate the performance of our techniques. Categories and Subject Descriptors: H.2.0 [Database Manage-ment]: Security, integrity, and protection; H.3.m [Information Stor-age and Retrieval] General Terms: Security Keywords: Privacy
Of all the data collected by search engines, the queries submitted by users are among the most valuable. Indeed, query logs can give great insight into human intent and have numerous diverse uses. However, they also have immense potential for misuse. Publishing of user query logs has become a sensitive issue. Similar to other data releases involving individual records such as microdata, the potentially personal content of query logs raises genuine privacy concerns [3, 8]. In particular, the recent incident involving AOL [3] has increased the public awareness of how the information in the query log file can be used to profile a single user without their knowledge. On the other hand, these search data, if published, are
This work is supported in part by the National Science Foundation under Grant No. CNS-0746943.
 invaluable for researchers and law enforcement [8]. Thus, the chal-lenge is to develop anonymization methods to publish query log data without breaching privacy or diminishing utility.

Indeed, query logs differ in several important characteristics, and their anonymization problem involves new challenges. First, the causes of privacy breach are not the same. Privacy breaches oc-cur in released tabular data mainly due to the identification of an individual by combining quasi-identifiers in the data with other ex-ternal knowledge or the value inferences of sensitive attributes. In the query logs, however, one of the big causes of privacy leaks is that the queries issued by a particular user unintentionally and inherently connote much individual identifying and sensitive infor-mation. In addition, even a single user usually conducts hundreds of searches over a short period of time. Putting these searches to-gether may easily reveal the identity of the user. Moreover, un-like relational data, user queries are typically quite unstructured As such, it is clear that we cannot directly apply the techniques devel-oped for anonymizing typical tabular data to the anonymization of query logs. Another problem is due to the diversity of queries  X  two users with the same information needs may easily formulate queries quite differently. Most queries are imprecise and short with average length of 2-3 words. This implies that it might not be practical to try to find exactly matching queries issued by a number of different users. However, it is possible to cluster similar queries [4, 2]. We can use this to measure similarity, and then define anonymization models using it.

In the most general sense, the query log anonymization problem is simply to transform a given query log QL into another query log QL 0 satisfying some privacy requirements. The framework of k -anonymity[11, 12] guarantees that every individual is hidden in a group of size k with respect to the quasi-identifiers. While it has some limitations, its applicability is widely accepted, and it does provide a measure of privacy. In this paper, we first follow the spirit of k -anonymity and define the anonymization problem of query logs. By following this formulation, we can ensure that a person cannot be uniquely identified from the searches.

However, k-anonymity cannot be directly applied to the query log anonymization problem, due to the fundamental difference in the domain. The key problem is that, for query logs, the quasi-identifiers which uniquely identify an individual are unstructured. At best, the similarity of users can be defined based on the similar-ity of the set of query records issued by each user. As a result, we introduce a similarity parameter  X  (formally defined later), which indicates the degree of query similarity between users.

D EFINITION 1. ( k  X  -A NONYMITY ) A query log QL satisfies k anonymity if for every user u who has a set of query records in QL , there exist at least k  X  1 other users who are  X  -similar to user u based on their query records in QL .
To reduce loss of utility, we must first define similarity met-rics between queries and users. Similar queries may be identified through clustering. However, users are related to both queries and clicked URLs through a bipartite graph. We then define a measure for user similarity based on both of these.
In the graph based iterative clustering approach of [4], the query log click-through data is used to construct a bipartite graph, with unique queries on one side, and unique URLs on the other side, with links indicating a co-occurrence of a query and a URL in the same query log record. Let N ( x ) denote the set of vertices neighboring vertex x in a graph. Intuitively, vertex y is  X  X imilar X  to vertex x if N ( x ) and N ( y ) have a large overlap. Formally, the similarity sim ( x, y ) between vertices x and y is defined by vertices x and y is defined as follows: d ( x, y ) := 1  X  sim ( x, y ) . It is easy to prove that d ( x, y ) is metric. Based on this metric, we are able to cluster queries. Assume that c 1 , c 2 , . . . , c resulting clusters after clustering all queries ( q 1 , q tive of users, and m is the total number of clusters. To bound the diversity of queries belonging to a single cluster, we now define the diameter of a cluster:
D EFINITION 2. Let d ( q i , q j )( q i , q j  X  c l ) be the distance be-tween queries q i and q j . The diameter of cluster c l is
The diameter parameter  X  is used to decide whether to merge queries into a cluster (note that all pairs of queries in a cluster have to be within  X  of each other). Thus, the distance between any two arbitrary queries in the same cluster is no greater than  X  . The al-gorithm iteratively creates clusters from the unclustered queries, growing each cluster to include as many queries as possible. While we use this method, the clustering approach used is orthogonal to our work, and any alternative algorithm could also be followed. Finally, if there are any clusters whose sizes are quite small, say smaller than a specified threshold, we can eliminate such clusters with rare queries that may potentially be quite identifying. Due to the ambiguity in query terms (e.g. does  X  X un X  stand for Sun, the company or Sun, the star?), the clicked links can represent the query objects with more precision. We thus prefer to quantify the similarity of query objects using the vector of numeric clicked URLs at the first step. Since the total number of query objects is-sued by each user varies, the count of clicked URLs is normalized, as follows: For each user u x , the normalized clicked URL vector v x = v x ( i ) N x , where v x ( i ) is the count of the ith unique URL for u x and N x represents the number of user x  X  X  total query objects. The dimension of each user X  X  vector depends on how many unique URLs that user has clicked in a particular query log. Furthermore, we should try to find out the combination of these two elements (queries and clicked URLs). Since each query object includes ex-actly one clicked URL and one query that belongs to a unique clus-ter, we can decompose each user x  X  X  vector v 0 x into a fraction matrix that consists of several vectors. The number of columns is given by the number of query clusters while the number of rows is the same as the number of unique URLs. Each element (in ith row and jth column) in the matrix represents the normalized number of entered queries in the ith cluster which link to the jth document. We can formally define this new matrix as follows: Given a user X  X  normalized URL vector v 0 of size n and query clus-ters C = { c 1 , . . . , c m } , the user X  X  Query-URL Matrix M is an m  X  n matrix with the element m ij = v 0 ( j )  X  fr ij where fr resents the fraction of queries with URL j belonging to cluster c There exist: Since two users generally have different set of unique clicked URLs, the number of dimensions and corresponding URLs in the two vectors v 0 x and v 0 y are probably distinct. Thus, to measure the difference, we need to transform the two users  X  X uery-URL X  ma-trices into a consistent format. Essentially, we can transform each user X  X  normalized Query-URL matrix into a consistent Query-URL matrix whose columns consist of the union of the columns of the original two matrices. This way, corresponding cells of both matri-ces represent the same query-url combination.

Now, the matrix-based distance metric for user similarity is de-fined as follows. For users u x and u y , their distance can be defined in terms of their transformed matrices M 0 x and M 0 y as follows: where m 0 ij ( x ) and m 0 ij ( y ) represent the value of element in the ith row and jth column of M 0 x and M 0 y , and the distance between u x and u y is calculated by summing over all the absolute differ-ences of two values in the same position of M 0 x and M 0 D ( u x , u y ) is a metric. The smaller the value of D ( u more similar the users are. Since D ( u x , u y ) is the sum of all ab-solute difference values of every element in M 0 x and M 0 is no common clicked URL in those two query vectors or the com-mon clicked URLs are associated with queries in totally different clusters, then D ( u x , u y ) has the range [0 , 1] . The assumption here is that if users submit more similar set of queries and click more similar set of URLs, we consider them to be more similar. Recall that we have defined k  X  -Anonymity based on the  X  -similarity of users, which is now defined below.
 u y are said to be  X  -similar if the metric D ( u x , u y ) = 0 and the diameter of their query clusters is less than or equal to  X  .
Given an existing set of queries with specified k and  X  , anonymiza-tion is carried out to satisfy k  X  -anonymity. The anonymization pro-cess consists of the following two steps. First, we form groups of similar users with size no less than k . The second step involves making all of the users in a group indistinguishable from each other. Specifically, we try to add similar query objects and suppress dis-similar query objects so that each user in a group has the same nor-malized Query Cluster-URL matrix. That is, the normalized por-tion of queries falling in each clusters along with the associations with their clicked URLs is the same.
The first procedure is to group users such that each group in-cludes at least k users. Obviously, we would like to group similar users together as much as possible. We first select one user as the centroid user of the group, calculate the similarity between this centroid user and all the other un-clustered users, and select users with their raw query objects from the top most similar users until the number of clustered users exceed or equal to k in one group. In this process, the diameter among all users X  query clusters should be less than  X  , so the similarity between users is indirectly constrained by  X  . However, the user-clustering process turns out to be primar-ily determined by the similarities of users, so we can consider the diameter of query clusters as the first constraint for grouping users. Meanwhile, we must ensure that every group has at least k users. Thus, we can define our user clustering approach as centroid-based user clustering method with constraints.
For any arbitrary pair of users, u x and u y , there may be some unique URLs (denoted as the set URL 1 ) that are clicked by u but not by u y ; alternatively, there may exist some unique URLs, denoted URL 2 which are clicked by u y but not u x ; and there ex-ist some common unique URLs, URL 3 for both of them as well. Similarly, there may exist three different kinds of unique query sets Q , Q 2 and Q 3 for u x and u y . If u x is the centroid user , we should definitely add URL 1 and Q 1 , suppress URL 2 and Q 2 and adjust URL 3 and Q 3 (add or suppress) for u y to make the final normal-ized matrices similar. Therefore, we need both addition and sup-pression on original query logs during the anonymizing process. Let U = { u 1 , . . . , u k } be a group of k closest users. We first explain how we anonymize a pair of users, say u x , u y  X  U . As discussed earlier, our aim is to make D ( u x , u y ) = 0 , which is es-sentially equivalent to make all m 0 ij ( x ) = m 0 ij ( y ) ( i  X  [1 , m ] and j  X  [1 , n ] ). For instance, we let u x  X  X  query objects Q and modify u y  X  X  query objects Q y according to Q x . Without loss of generality, suppose that, after clustering and decomposing nor-malized clicked URLs, we have m 0 ij ( x ) &gt; m 0 ij ( y ) (Alternatively, if m 0 ij ( x ) &lt; m 0 ij ( y ) , we can compute the suppression in a simi-lar way). Let n ij ( y ) be the number of query objects in cluster c with a fixed URL url j to be added to Q y . We can then derive the following equation: N ( ij ) is the number of query objects in which all queries are dis-tributed into cluster c i and all the clicked URLs are url we have n ij ( y ) = d m 0 ij ( x )  X  N y  X  N y ( ij ) e (we add more similar query objects if possible), and the number of addition on URLs is the same as n ij ( y ) as well. Alternatively, if m ij ( x ) &lt; m n ij ( y ) represents the number of suppression for a specified c url j , we have the following equation: Then, we have n ij ( y ) = b N y ( ij )  X  m 0 ij ( x )  X  N less similar query objects if possible) for c i and url j
When modifying the query log, remember that a URL is gener-ally associated with queries from more than one cluster. It is pos-sible that one of clusters may require addition of it while another cluster requires suppression. If we add and suppress URLs and queries, respectively, the relationship between them would be dis-organized that leads to increased inaccuracy and reduces the utility of the anonymized query log. In our method, we initialize a query object ( q  X  c i , url j ) for anonymizing query objects in a specific query cluster c i and a fixed URL url j . If this query object is cre-ated as addition, the query q can be an arbitrary query in cluster c Otherwise, the query q should be found in the non-centroid user X  X  set of query objects. Also, how to add and suppress should also be considered. If we first add URL 1 for u y until all the normalized vectors of clicked URLs in URL 1 are equal to the centroid user  X  X , then suppress all URL 2 , and eventually adjust URL 3 , the u tal number of URLs may be greatly changed, and the final result of the similarity/distance may be not accurate (in many cases, we cannot obtain D ( u x , u y )  X  0 ). In order to enhance the accuracy of similarity between anonymized query log and centroid user  X  X  query log along with the similarity between anonymized query log and original query log for the same user (which also expresses good utility of anonymized query log), we can keep the total number of query objects from every user invariant and calculate the required addition and suppression. The actual queries to add or suppress are chosen equiprobably from among the candidates available.
We extracted data from a large-scale query log to evaluate our approach and examine both privacy and utility behavior.
Figure 2(a) shows that it is easier to find more similar users as the total number of users increases (the number of groups with at least k users continually increases, while the number of groups with less than k users shows a much smaller increase).

After clustering the users, the next stage in anonymization is adding and suppressing queries. FIgure 1(a) shows that the total number of added or suppressed queries for all users clearly in-creases with the number of users, though the number of queries per user decreases. This decrease is due to the increased similarity between users. Figure 1(b) plots the average number of queries that have to be added and suppressed for varying values of k . Similarly, Figure 1(c) plots the decreasing average number of total query ob-jects for addition and suppression for varying values of  X  due to the increasing similarity.
We also tested the utility of our anonymized query objects in terms of the query diversity. Figure 2(b) shows the percentage of suppression against the number of users. The percentage of sup-ber of unique queries or URLs while N 0 represents the number of anonymized ones. We can see that as the number of users increases, p decreases as well. We can conclude that the diversity would not be significantly impacted if the query log is large enough.
One of the most important applications of query log mining is query suggestion[5]. This requires accurately knowing the most frequent queries and clicked URLs, and in fact their co-occurrences. In this sense, the top frequent queries and clicked URLs reveal more utility than unusual queries and clicked URLs. We extracted the top 50 queries and clicked URLs that are frequently submitted from the tested query objects. Then, we count how many of them remain the top 50 of the anonymized query log. Figure 2(c) shows an increasing trend on these 50 queries and URLs in our experi-ments. With 1000 users, there are 24 common queries in the top 50 frequent queries in the original query log and anonymized query log. As for top 50 frequent URLs, the common URLs are 28 out of 50 . Again, the figure also indicates that, if the size of the query log keeps increasing, these two top frequent query (URL) sets will become extremely similar. In general, we also observed that in many cases, the approximate ordering of the popular URLs/links is maintained. This indicates that we can achieve good utility using our proposed query log anonymization model.
Following the AOL query log incident, recently there has been work on anonymizing query logs. Kumar et al.[10] propose a token-(a) User clustering on varying number of users based hashing approach to anonymize query logs. In particular, each query in the log is tokenized, and then a secure hash function applied to produce hashes that are inverted. However, inversion cannot be done using just the token frequencies. It turns out that their token-based approach does not work since serious leaks are possible even when the order of tokens is hidden. Adar [1] pro-poses a secret sharing scheme, where a query must appear at least t (number of shares) times before it can be decoded. While this is empirically effective to a certain extent, it may potentially remove too many harmless queries, thus reducing data utility. Cooper [6] provides a survey on the query log privacy-enhancing techniques from a policy perspective, including log deletion, hashing queries, identifier deletion, hashing identifiers, etc. However, no methods are provided for anonymizing query logs. Recently, Korolova et al. [9] propose an algorithm to select and publish a subset of search query logs providing sound privacy guarantees (based on Differen-tial Privacy[7]). However, we resolve this problem in a different way, and our work is complementary to that work. Samarati and
Sweeney [11] first introduced the concept of k -anonymity to pro-tect privacy. k -anonymity is the standard privacy model used, for example, by HIPAA and the European Union Data Directive. ing user behavior analysis, query characterization, among others.
While such statistical analyses prove useful, releasing them without proper anonymization may compromise privacy of persons as query logs can potentially contain users X  personal information. Since tra-ditional anonymization techniques data are not directly applicable to query logs, in this paper, we present an anonymization model for query logs by extending the notion of k -anonymity and providing metrics for user similarity and query similarity. Our experimental results show that it is possible to achieve high user similarity in the anonymized logs quite efficiently.

In the future, we intend to test the suitability of our methods to different query log mining applications, and to develop methods specifically adapted for important applications. Since k -anonymity is also known to have several limitations, we will explore the appli-cability of other privacy models to this domain.
