 Majid Janzamin mjanzami@uci.edu Animashree Anandkumar a.anandkumar@uci.edu Keywords: High-dimensional covariance estimation, sparse graphical model selection, sparse covariance models, sparsistency, convex optimization. Covariance estimation is a classical problem in multi-variate statistics. The idea that second-order statistics capture important and relevant relationships between a given set of variables is natural. Finding the sample covariance matrix based on observed data is straight-forward and widely used (Anderson, 1984). However, the sample covariance matrix is ill-behaved in high-dimensions, where the number of dimensions p is typi-cally much larger than the number of available samples n ( p n ). Here, the problem of covariance estimation is ill-posed since the number of unknown parameters is larger than the number of available samples, and the sample covariance matrix becomes singular in this regime.
 Various solutions have been proposed for high-dimensional covariance estimation. Intuitively, by re-stricting the class of covariance models to those with a limited number of free parameters, we can successfully estimate the models in high dimensions. A natural mechanism to achieve this is to impose a sparsity con-straint on the covariance matrix, which implies that the variables under consideration satisfy marginal in-dependence , corresponding to the zero pattern of the covariance matrix (Kauermann, 1996) (and we refer to such models as independence models). In many settings, however, marginal independence is too re-strictive and does not hold. For instance, consider the dependence between the monthly stock returns of various companies listed on the S&amp;P 100 index. It is quite possible that a wide range of complex (and unobserved) factors such as the economic climate, in-terest rates etc., affect the returns of all the companies. Thus, it is not realistic to model the stock returns of various companies through a sparse covariance model. A popular alternative sparse model, based on conditional independence relationships, has gained widespread acceptance in recent years (Lauritzen, 1996). In this case, sparsity is imposed not on the covariance matrix, but on the inverse covariance or the precision matrix. It can be shown that the zero pattern of the precision matrix corresponds to a set of conditional-independence relationships and such mod-els are referred to as graphical or Markov models. Go-ing back to the stock market example, a first-order approximation is to model the companies in different divisions 1 as conditionally independent given the S&amp;P 100 index variable, which captures the overall trends of the stock returns, and thus removes much of the dependence between the companies in different divi-sions. However, sparse Markov models may not be always sufficient to capture all the relationships be-tween the variables. Going back to the stock market example, the approximation of using the S&amp;P index node to capture the dependence between companies of different divisions may not be enough. For instance, there can still be a large residual dependence between the companies in manufacturing and mining divisions, which cannot be accounted by the S&amp;P index node. In this paper, we make the above notion precise, and model the variables as a linear combination of samples from an independence and a Markov model. In other words, the covariance matrix of the resulting model is a linear combination of a sparse covariance and a sparse precision matrix, see Fig.1. This forms a richer class of models which can faithfully capture complex rela-tionships, such as in the stock market example above, and yet retain parsimony in the representation. Summary of Contributions We consider joint estimation of Markov and indepen-dence models, given observed data in a high dimen-sional setting. Our contributions in this paper are three fold. First, we derive a set of sufficient restric-tions, under which there is a unique decomposition into the two domains, viz., the Markov and the inde-pendence domains, thereby leading to an identifiable model. Second, we propose novel and efficient esti-mators for obtaining the decomposition, under both exact and sample statistics. Third, we provide strong theoretical guarantees for high-dimensional learning, both in terms of norm guarantees and sparsistency in each domain, viz., the Markov and the independence domain.
 Our learning method is based on convex optimization. We adapt the popular ` 1 -penalized maximum likeli-hood estimator (MLE), proposed originally for sparse Markov model selection. This estimator is widely used, and theoretical guarantees on consistent estimation have been proven. Here, an ` 1 penalty is imposed on the precision matrix, which is a convex relaxation of the ` 0 penalty, in order to encourage sparsity in the precision matrix. It is well known that the Lagrangian dual of this program is a maximum entropy solution which approximately fits the given sample covariance matrix. We modify this program to our setting as fol-lows: we incorporate an additional ` 1 penalty term involving the residual covariance matrix (correspond-ing to the independence model) in the max-entropy program. This term can be viewed as encouraging sparsity in the independence domain, while fitting a maximum entropy Markov model to the rest of the sample correlations (after incorporating the indepen-dence model). We characterize the optimal solution of the above program, and also provide intuitions on the class of Markov and independence model combinations which can be incorporated under this framework. As a byproduct of this analysis, we obtain a set of condi-tions for identifiability of the two model components. We provide strong theoretical guarantees for our pro-posed method under a set of sufficient conditions. We establish that it is possible to obtain sparsistency and norm guarantees in both the Markov and the inde-pendence domains, which is somewhat surprising. We establish that the number of samples n is required to scale as n =  X ( d 2 log p ) for consistency, where p is the number of variables, and d is the maximum degree in the Markov graph. The set of sufficient conditions for successful recovery are based on the so-called notion of mutual incoherence , which controls the dependence be-tween different sets of variables, See (Ravikumar et al., 2011). Our conditions are similar to those previously characterized for consistent graphical model selection, and are only slightly stronger. Our consistency proofs borrow ideas from (Ravikumar et al., 2011), and at the same time, require new ideas to carefully control the errors in the two domains, viz., the Markov and the independence domains. This is because the pro-posed optimization method only ensures that the over-all combination of the Markov and the independence models is close to the sample covariance matrix, and does not limit the individual perturbations in the two domains. We consider a careful partitioning of the variables, and impose a set of mutual incoherence con-ditions, and provide consistency guarantees in high di-mensions.
 The idea that a combination of Markov and indepen-dence models can provide good model-fitting is not by itself new, see (Choi et al., 2010). However, the pre-vious approach has several deficiencies, including lack of theoretical guarantees, assumption of a known spar-sity support for the Markov model, use of expectation maximization (EM) which has convergence issues, and so on. In contrast, we develop convex optimization methods for decomposition , and also provide theoret-ical guarantees for successful recovery. In summary, in this paper, we provide an in-depth study of efficient methods and guarantees for joint estimation of a com-bination of Markov and independence models.
 Our experiments validate our theoretical results and demonstrate that our method is able to learn a richer class of models, compared to sparse graphical model selection, while requiring similar number of samples. In particular, our method is able to provide better es-timates for the overall precision matrix, which is dense in general, while the performance of ` 1 -based opti-mization is worse since it attempts to approximate the dense matrix via a sparse estimate. Additionally, we demonstrate that our estimated models have better ac-curacy under simple distributed inference algorithms such as loopy belief propagation (LBP). This is be-cause the Markov components of the estimated mod-els tend to be more walk summable (Malioutov et al., 2006), since some of the correlations can be  X  X rans-ferred X  to the residual matrix. Thus, in addition to learning a richer model class, incorporating sparsity in both covariance and precision domains, we also learn models amenable to efficient inference. Notation: For any vector v  X  R p and a real number a  X  [1 ,  X  ), the notation k v k a refers to the ` a norm of vector v given by k v k a := trix U  X  R p  X  p , the operator norm is given by ||| U ||| ically, we use the `  X  operator norm which is equiva-||| U ||| 1 = ||| U T |||  X  . We also use the `  X  element-wise norm notation k U k  X  to refer to the maximum abso-lute value of the entries of matrix U . The trace in-ner product of two matrices is denoted by  X  U, V  X  := Tr( U T V ) = for some constant c &gt; 0 and f ( n ) = O ( g ( n )) if f ( n )  X  c 0 g ( n ) for some constant c 0 &lt;  X  . 2.1. Gaussian Graphical Models A Gaussian graphical model is a family of jointly Gaussian distributions which factor in accordance to a given graph. Given a graph G = ( V, E ), with V = { 1 , . . . , p } , consider a vector of Gaussian ran-dom variables X = [ X 1 , X 2 , . . . , X p ], where each node i  X  V is associated with a scalar Gaussian random variable X i . A Gaussian graphical model Markov on G has a probability density function (pdf) that may be parameterized as f X ( x )  X  exp  X  1 2 x T J x + h T x , where J is a positive-definite symmetric matrix whose sparsity pattern corresponds to that of the graph G . More precisely, J ( i, j ) = 0 iff ( i, j ) /  X  G. The matrix J is known as the potential or concentration matrix, the non-zero entries J ( i, j ) as the edge potentials, and the vector h as the potential vector. This parameteriza-tion is known as the information form and is related to the standard mean-covariance parameterization of the Gaussian as  X  = J  X  1 h ,  X  = J  X  1 , where  X  := E [ X ] is the mean vector and  X  := E [( X  X   X  )( X  X   X  ) T ] is the covariance matrix.
 We say that a jointly Gaussian random vector X with joint pdf f ( x ) satisfies local Markov property with re-spect to a graph G if f ( x i | x N ( i ) ) = f ( x i | x for all nodes i  X  V , where N ( i ) denotes the set of neighbors of node i  X  V and, V \ i denotes the set of all nodes excluding i . More generally, we say that X satisfies the global Markov property, if for all disjoint sets A, B  X  V , we have where set S is a separator 2 of A and B . The local and global Markov properties are equivalent for non-degenerate Gaussian distributions (Lauritzen, 1996). In this paper, we consider models which are charac-terized by a combination of Markov and independence graphs. In particular, we model the covariance matrix as a linear combination of Markov and independence models:  X  where Supp(  X  ) denotes the set of non-zero (off-diagonal) entries, G M denotes the Markov graph and G
R , the independence graph. 2.2. Problem Statement We now give a detailed description of our problem statement, which consists of the covariance decompo-sition problem (given exact statistics) and covariance estimation problem (given a set of samples). Covariance Decomposition Problem: A funda-mental question to be addressed is the identifiability of the model parameters.
 Definition 1 (Identifiability) . A parametric model { P  X  :  X   X   X  } is identifiable with respect to a measure  X  if there do not exist two distinct parameters  X  1 6 =  X  such that P  X  Thus, if a model is not identifiable, there is no hope of estimating the model parameters from observed data. A Gaussian graphical model (with no hidden variables) belongs to the family of standard exponential distri-butions (Wainwright &amp; Jordan, 2008). Under non-degeneracy conditions, it is also in the minimal form, and as such is identifiable (Brown, 1986). In our set-ting in (2), however, identifiability is not straightfor-ward to address, and forms an important part of the covariance decomposition problem, described below. Decomposition Problem: Given the covariance matrix  X   X  = J  X  M  X  1 +  X   X  R as in (2), where J  X  M is an unknown concentration matrix and  X   X  R is an unknown residual covariance matrix, how and under what con-ditions can we uniquely recover J  X  M and  X   X  R from  X   X  ? In other words, we want to address whether the ma-trices J  X  M and  X   X  R are identifiable , given  X   X  , and if so, how can we design efficient methods to recover them. If we do not impose any additional restrictions, there exists an equivalence class of models which form solu-tions to the decomposition problem. For instance, we can model  X   X  entirely through an independence model ( X  However, in most scenarios, these extreme cases are not desirable, since they result in dense models, while we are interested in sparse representations with a par-simonious use of edges in both the graphs, viz., the Markov and the independence graphs. In Section 3.1, we provide a sufficient set of structural and parametric conditions to guarantee identifiability of the Markov and the independence components, and in Section 3.2, we propose an optimization program to obtain them. Covariance Estimation Problem: In the above decomposition problem, we assume that the exact co-variance matrix  X   X  is known. However, in practice, we only have access to samples, and we describe this setting below.
 Denote b  X  n as the sample covariance matrix b  X  n := observations of a zero mean Gaussian random vector X  X  N (0 ,  X   X  ), where X := ( X 1 , ..., X p ). Now the estimation problem is described below.
 Estimation Problem: Assume that there exists a unique decomposition  X   X  = J  X  M  X  1 +  X   X  R where J  X  M is an unknown concentration matrix with bounded en-tries and  X   X  R is an unknown sparse residual covariance matrix given a set of constraints. Given the sample covariance matrix b  X  n , our goal is to find estimates of J
M and  X  In the sequel, we relate the exact and the sample ver-sions of the decomposition problem. In Section 4, we propose a modified optimization program to obtain ef-ficient estimates of the Markov and independence com-ponents. Under a set of sufficient conditions, we pro-vide guarantees in terms of sparsistency , sign consis-tency , and norm guarantees, defined below.
 Definition 2 (Estimation Guarantees) . We say that an estimate ( b J M , b  X  R ) to the decomposition problem in (2) , given a sample covariance matrix b  X  n , is sparsis-tent or model consistent, if the supports of b J M and b  X  coincide with the supports of J  X  M and  X   X  R respectively. It is said to be sign consistent, if additionally, the re-spective signs coincide. The norm guarantees on the estimates is in terms of bounds on k b J M  X  J  X  M k and k b
 X  R  X   X   X  R k , under some norm k X k . 3.1. Assumptions under Exact Statistics We first provide a set of sufficient conditions under which we can guarantee that the decomposition of  X   X  in (2) into concentration matrix J  X  M and residual ma-trix  X   X  R is unique. We impose the following set of constraints on the two matrices: (A.0) J  X  M is a positive definite matrix: J  X  M 0. (A.1) Off-diagonal entries of J  X  M are bounded from (A.2) Diagonal entries of  X   X  R are zero: ( X   X  R ) ii = 0, and (A.3) For any i, j , we have In the sequel, we propose an efficient method to re-cover the respective matrices J  X  M and  X   X  R under con-ditions (A.0)-(A.3) and then establish the uniqueness of the decomposition. Finally, note that we do not impose any sparsity constraints on the concentration matrix J  X  M , and in fact, our method and guarantees allow for dense matrices J  X  M , when the exact covari-ance matrix  X   X  is available. However, when only sam-ples are available, we limit ourselves to sparse J  X  M and provide learning guarantees in the high-dimensional regime, where the number of samples can be much smaller than the number of variables. 3.2. Formulation of the Optimization Program We now propose a method based on convex optimiza-tion for obtaining ( J  X  M ,  X   X  R ) given the covariance ma-trix  X   X  in (2). Consider the following program where k X k 1 , off denotes the ` 1 norm of the off-diagonal entries, which is the sum of the absolute values of the off-diagonal entries, and (  X  ) d denotes the diagonal en-tries. Intuitively, the parameter  X  imposes a penalty on large residual covariances, and under favorable con-ditions, can encourage sparsity in the residual matrix. The program in (4) can be recast for some constant C (  X  ) depending on  X  . The objec-tive function in the above program corresponds to the entropy of the Markov model (modulo a scaling and a shift factor) (Cover &amp; Thomas, 2006), and thus, intuitively, the above program looks for the optimal Markov model with maximum entropy subject to an ` 1 constraint on the residual matrix.
 We declare the optimal solution b  X  R in (4) as the es-timate of the residual matrix  X   X  R , and b J M := b  X   X  1 the estimate of the Markov concentration matrix J  X  M . The justification behind these estimates is based on the fact that the Lagrangian dual of the program in (4) is (see long version on arXiv) where k X k  X  , off denotes the `  X  element-wise norm of the off-diagonal entries, which is the maximum ab-solute value of the off-diagonal entries. Further, we show in the long version that the following relations exist between the optimal primal 3 solution b J M and the optimal dual solution b  X  M , b  X  R : b J M = b  X   X  1 thus b J  X  1 M + b  X  R =  X   X  is a valid decomposition of the covariance matrix  X   X  .
 Remark: Notice that when the `  X  constraint is re-moved in the primal program in (6), which is equiv-alent to letting  X   X   X  , the program corresponds to the maximum likelihood estimate, and the optimal so-lution in this case is b J M =  X   X   X  1 and b  X  R = 0. At the other extreme, when  X   X  0, b J M is a diagonal matrix, and the residual matrix b  X  R is in general, a full matrix. (except for the diagonal entries). Thus, the parameter  X  allows us to carefully tune the contributions of the Markov and residual components. 3.3. Guarantees and main results The main decomposition result is as follows. The proofs can be found in the extended version on arXiv. Theorem 1 (Uniqueness of Decomposition) . Under (A.0) X (A.3), given a covariance matrix  X   X  , if we set the parameter  X  = k J  X  M k  X  , off in the optimization pro-gram in (4) , then the optimal solutions of primal-dual optimization programs (6) and (4) are given by b J M , b  X  R = J  X  M ,  X   X  R , and the decomposition is unique.
 Thus, we establish that the proposed optimization pro-grams in (4) and (6) uniquely recover the Markov con-centration matrix J  X  M and the residual covariance ma-trix  X   X  R given  X   X  under conditions (A.0) X (A.3). 4.1. Optimization Program We have so far provided guarantees on unique decom-position given the exact covariance matrix  X   X  . We now consider the case, when n i.i.d. samples are avail-able from N (0 ,  X   X  ). We now modify the primal-dual pair (6) and (4), considered in the previous section, to incorporate the sample covariance matrix b  X  n . b J M := arg min It is shown that the dual of above program is We further establish that b  X  M = b J  X  1 M and thus, Comparing the above with the exact decomposition  X  version, we do not exactly fit the Markov and the resid-ual models with the sample covariance matrix b  X  n , but allow for some divergence, depending on  X  . Similarly, the primal program in (7) has an additional ` 1 penalty term on b J M , which is absent in (6). Having a non-zero  X  in the above programs enables us to impose a spar-sity constraint on b J M , which in turn, enables us to estimate the matrices in the high dimensional regime, under a set of sufficient conditions given below. 4.2. Assumptions under Sample Statistics The additional assumptions for successful recovery in high dimensions are based on the Hessian of the ob-jective function in the optimization program in (7), with respect to the variable J M , evaluated at the true Markov model J  X  M . The Hessian of this function is given by (Boyd &amp; Vandenberghe, 2004) where  X  denotes the Kronecker matrix product. Thus  X   X  is a p 2  X  p 2 matrix indexed by the node pairs. Based on the results for exponential families (Brown, 1986),  X  interpreted as an edge-based alternative to the usual covariance matrix  X   X  M . Define K M as the `  X  operator norm of the covariance matrix of the Markov model: K M := |||  X   X  M |||  X  . We now denote the supports of the Markov and residual models. Denote E M := { ( i, j )  X  V  X  V | i 6 = j, J  X  M ij 6 = 0 } as the edge set of Markov matrix J  X  M . Define Thus, the set S M includes diagonal entries and also all edges of the Markov graph corresponding to J  X  M . Also, recall from (A.2) that the diagonal entries of  X   X  R are set to zero, and that the support set S R is contained in S
M , i.e., S R  X  S M . Let S c M and S c R denote the respec-tive complement sets. Define S := S M  X  S c R , so that { S This partitioning plays a crucial role in being able to provide learning guarantees. Define the maximum node degree for Markov model J  X  M as Finally, for any two subsets T and T 0 of V  X  V ,  X   X  T T 0 denotes the submatrix of  X   X  indexed by T as rows and T 0 as columns. We now impose various constraints on the submatrices of the Hessian in (10), limited to each of the sets { S R , S, S c M } . (A.4) Mutual Incoherence : These conditions impose (A.5) Covariance control : For the same  X  specified Assumption (A.4) controls the pairwise effects of edges in different sets S , S R and S c M to each other. 4.3. Guarantees and Main Results We are now ready to provide the main result. Theorem 2. Consider a Gaussian distribution with covariance matrix  X   X  = J  X  M  X  1 +  X   X  R satisfying con-ditions (A.0)-(A.5). Given a sample covariance ma-trix b  X  n using n i.i.d. samples from the Gaussian model, let b J M , b  X  R denote the unique optimal solu-tions of the primal-dual pair (7) and (8) , with pa-rameters  X  = C 1 some constants C 1 , C 2 &gt; 0 , where  X   X  := k J  X  M k
 X  bounded as then with probability greater than 1  X  1 /p c  X  1 (for some c &gt; 0 ), we have: a) The estimates b J M and b  X  R satisfy `  X  bounds b) The estimate b  X  R is sparsistent and sign consistent Remark 1 (Non-asymptotic sample complex-ity bounds): In the above theorem, we establish that the number of samples is required to scale as n =  X ( d 2 log p ). In fact, the result is non-asymptotic which is provided in the extended version on arXiv. Remark 2 (Comparison with sparse graphical model selection): The high dimensional covariance estimation problem which is investigated in (Raviku-mar et al., 2011) involves similar mutual incoherence conditions and gives similar consistency results. Re-garding the final result, sample complexity and con-vergence rate of estimated models are exactly the same as results in (Ravikumar et al., 2011) with only some minor differences in coefficients. But regarding the in-coherence conditions, since their program is a special case of ours, the required conditions are less restrictive in their case. It is natural that we need some more incoherence conditions in order to be able to recover both the Markov and residual models. In this section we provide experimental results for the proposed algorithm. We term our proposed optimiza-tion program as ` 1 + `  X  method and compare it with the well-known ` 1 method which is a special case of the proposed algorithm when  X  =  X  . The optimiza-tion programs are implemented by YALMIP (Lofberg, 2004) and SDPT3 (Toh et al., 1999) packages for MAT-LAB. We also compare the performance of applying belief propagation to exact models.
 Synthetic Data : We build a Markov + residual syn-thetic model in the following way. The underlying graph for the Markov part is an 8  X  8 2-D grid struc-ture (4-nearest neighbor grid). We choose the off-diagonal nonzero entries in J  X  M (corresponding to the grid edges) randomly from set { X  0 . 5 , 0 . 5 } . Then we ensure that J  X  M is positive definite by adding some uniform diagonal weighting. We choose 0.2 fraction of Markov edges randomly to introduce residual edges. The value of these nonzero entries in  X   X  R are chosen from { X  0 . 2 , 0 . 2 } such that the sign of residual entry is opposite of the sign of overlapping Markov entry (as-sumption (A.3)). We also generate a random mean in the interval [0 , 1] for each node.
 We apply ` 1 + `  X  and ` 1 methods to a random realiza-tion of the above described model  X   X  = J  X  M  X  1 +  X   X  R The edit distance between estimated and exact Markov model b J M and J  X  M is plotted in figure 2.a for differ-ent number of samples. First observation is that by increasing the number of samples, the edit distance decreases which is consistent with theoretical results. We also see that the behaviour of ` 1 + `  X  method is very close to ` 1 method which suggests that spar-sity pattern of J  X  M can be estimated efficiently under either methods. The edit distance between b  X  R and  X 
R is plotted in figure 2.b. We see again decreasing trend for ` 1 + `  X  method here with increasing num-ber of samples. But since there is not any off-diagonal `  X  constraints in ` 1 method, it can not recover the residual matrix  X   X  R . Finally the `  X  -elementwise norm of error between estimated precision matrix b J and the exact precision matrix J  X  is sketched for both methods in figure 2.c. We observe the advantage of proposed ` + `  X  method in estimating the overall model preci-sion matrix J  X  =  X   X   X  1 .
 Next the results of running Loopy Belief Propagation (LBP) on the models are presented. We compare the result of applying LBP to the same J  X  and J  X  M mod-els generated in the learning discussion above. The log of average mean and variance errors over all nodes are sketched in figure 3 throughout the iterations. We observe that LBP does not converge for J  X  model. It is shown by Malioutov et al. (2006) that if a model is walk-summable then the mean estimates under LBP converge and are accurate. The spectral norms of the partial correlation matrices are k R M k = 0 . 9443 and k R k = 6 . 9191 for J  X  M and J  X  models respectively. Thus, the matrix J  X  is not walk-summable and there-fore its convergence under LBP is not guaranteed and this is seen in figure 3. On the other hand, LBP is ac-curate for J  X  M matrix. Thus, our method learns models which are better suited for inference under loopy belief propagation. In this paper, we provided an in-depth study of convex optimization methods and guarantees for high-dimensional covariance decomposition into sparse Markov and independence domains. We provide con-sistency guarantees for estimation in both the Markov and the independence domains, and establish efficient sample complexity results for our method. These find-ings open up many future directions to explore. One important aspect is to relax the sparsity constraints imposed in the two domains, and to develop new meth-ods to enable decomposition of such models. Other considerations include extension to discrete models and other models for the residual covariance matrix (e.g. low rank matrices). Such findings will push the envelope of efficient models for high-dimensional esti-mation. It is worth mentioning while in many scenar-ios it is important to incorporate latent variables, in our framework it is challenging to incorporate both la-tent variables as well as marginal independencies, and provide learning guarantees, and we defer it to future work.

