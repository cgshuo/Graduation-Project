 Ranjitha Kumar ranju@cs.stanford.edu Stanford University, Stanford, CA Jerry O. Talton jerry.o.talton@intel.com Intel Corporation, Hillsboro, OR Salman Ahmad saahmad@mit.edu Massachusetts Institute of Technology, Cambridge, MA Scott R. Klemmer srk@cs.stanford.edu Stanford University, Stanford, CA The Web provides an enormous repository of design knowledge: every page represents a concrete example of human creativity and aesthetics. Given the ready availability of Web data, how can we leverage it to help designers? This note outlines three machine learning applications which enable new interaction mechanisms for Web design: structured prediction for rapid re-targeting, deep learning for design-based search, and probabilistic program induction for operationalizing design patterns.
 All of these techniques leverage structure that is intrin-sic to Web designs. In machine learning applications, working with structured representations a ff ords signif-icant advantages over unstructured data sets, such as images or text ( Socher et al. , 2011 ). On the Web, ev-ery page is associated with a Document Object Model (DOM) tree, which can be used along with render-time information to bootstrap a visual information hierar-chy for designs.
 To apply machine learning techniques to Web design, we need to collect a corpus of training examples. Al-though traditional Web crawlers make it easy to scrape content from pages, acquiring and managing all the resources necessary to preserve a page X  X  render-time appearance is much more di ffi cult. Furthermore, with the advent of client-and server-side scripting and dy-namic HTML, many modern Web pages are mutable and may change between accesses, frustrating algo-rithms that expect consistent training data. To overcome these challenges, we have constructed a new kind of Web repository. The repository is popu-lated via a bespoke Web crawler, which requests pages through a caching proxy backed by an SQL database. As a page is crawled, all requested resources are ver-sioned and stored, its DOM tree is processed to pro-duce a static visual hierarchy of the page X  X  structure, and a set of semantic and vision-based features are cal-culated on each constituent page component. These structures are then exposed through a RESTful API, allowing fast component-wise queries on features. We have found that this design repository enables the rapid development of a diverse set of machine learning applications that support creative work. People frequently rely on templates when designing Web sites. While templates provide a simple mecha-nism for rendering content in di ff erent layouts, their rigidity often limits customization and yields cookie-cutter designs. Bricolage is a structured prediction algorithm that allows any page on the Web to serve as a design template ( Kumar et al. , 2011a ). The al-gorithm works by matching visually and semantically similar elements in pages to create coherent mappings between them. Once constructed, these mappings are used to automatically transfer the content from one page into the style and layout of another (Figure 1 ). Bricolage learns correspondences between pages by training on a set of human mappings gathered via crowdsourcing. It learns how to flexibly optimize vi-sual, semantic, and structural considerations using the generalized perceptron algorithm ( Kumar et al. , 2011b ). Our experiments show that flexibly preserving structure is essential for predicting human-like map-pings. The method enables a diverse set of design interactions, including rapid prototyping, retargeting between form factors, and measuring the similarity of Web designs. Designers leverage examples during ideation to under-stand the space of possible designs and learn imple-mentation techniques ( Buxton , 2007 ). However, mod-ern search engines o ff er little support for design-based search, making it di ffi cult to find relevant examples. Text-based search engines process queries e ffi ciently by computing bag-of-words representations of documents; no such natural vector space describes page designs. Instead, we can construct a meaningful search space via deep learning, using recent work on recursive neu-ral networks (RNNs) to induce a fixed-dimensional, structurally-sensitive embedding for each element in a page X  X  visual hierarchy ( Socher et al. , 2011 ). The RNN framework leverages a set of canonical features to bootstrap a continuous vector space representation for each variable-sized region in a page.
 By using this representation in a standard cosine similarity framework, users could  X  X uery-by-part X  to search for pages containing similar design elements. Moreover, by augmenting each node in the RNN with softmax layers, the system could train text-based la-bels across the corpus, allowing users to perform key-word searches on stylistic ( e.g. minimal, fun) or struc-tural ( e.g. header, logo) semantics. When building sites, skilled designers often rely on for-malized knowledge about design patterns, typically en-capsulated in books or style guides ( van Duyne et al. , 2002 ). Such rules for good design, however, are di ffi -cult to enumerate and operationalize. A more attrac-tive proposition is to learn these rules from data by inducing a generative probabilistic model of pages. Re-cent work on concept learning and Bayesian program induction provides a promising avenue for learning de-sign patterns from structured representations ( Hwang et al. , 2011 ).
 Inducing a formal language of page designs from a corpus of exemplars would allow many complex de-sign tasks to be formulated as probabilistic inference problems and solved using standard Monte Carlo tech-niques. For instance, a designer could construct a par-tial specification of a Web page, and a design tool could  X  X utocomplete X  the page by conditioning the model on the specification and performing MAP estimation. We believe that data-driven Web design is an area ripe for future research. We thank our collaborators; find out more about our work at http://bricolage. stanford.edu .

