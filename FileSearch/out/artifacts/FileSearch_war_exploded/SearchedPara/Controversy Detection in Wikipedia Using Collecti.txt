 Concerns over personalization in IR have sparked an inter-est in detection and analysis of controversial topics. Ac-curate detection would enable many beneficial applications, such as alerting search users to controversy. Wikipedia X  X  broad coverage and rich metadata offer a valuable resource for this problem. We hypothesize that intensities of contro-versy among related pages are not independent. Thus, we propose a stacked model which exploits the dependencies among related pages. Our approach improves classification of controversial web pages when compared to a model that examines each page in isolation, demonstrating that contro-versial topics exhibit homophily. Using notions of similarity to construct a subnetwork for collective classification, rather than using the default network present in the relational data, leads to improved classification with wider applications for semi-structured datasets, with the effects most pronounced when a small set of neighbors is used.
Critical literacy, civic discourse and trustworthy informa-tion are not immediate results of effective information re-trieval. Controversies proliferate online, but the  X  X ilter bub-ble X  effect encourages confirmation bias by offering users the answers they want to hear [11]. Exposure to diverse opinions can potentially improve civic discourse, but these benefits will only be available to users who can detect controversial topics. Automated tools performing such detection can sup-port users in their browsing and search experience [6].
Prior work on controversy detection focused on Wikipedia (cf. [9, 12]), analyzing each page in isolation or studying its editors. We hypothesize that controversies occur in neigh-borhoods of related topics. Thus, advanced ML techniques that take relational data into account, such as collective and stacked inference [7, 10], can improve controversy detection by exploiting the dependencies among related pages. In a departure from most work on collective inference, we also hypothesize that a definition of  X  X elatedness X  that incorpo-rates textual or topical similarity will hold more predictive power than pre-existing relationships such as hyperlinks. If so, using a constructed network based on similarity will out-perform collective models based on explicit relations. Our research questions are: What is the relative performance of intrinsic versus collective classification for detecting contro-versy in Wikipedia? And, what types of page relationships most improve the classification? We hypothesize that collec-tive models will substantially outperform intrinsic models, and particularly when related pages are defined in terms of their textual or topical similarity to the classified page.
The related work falls broadly under three themes: the need for controversy detection, methods for controversy de-tection, and collective and stacked inference.

The Need for Controversy Detection . Increasing per-sonalization reduces exposure to diverse opinions, which is a serious risk for the tenets of deliberative democracy. Search engines and social media use personalization to tailor results to the users X  opinions, creating a  X  X ilter Bubble X  [11] which can further exacerbate confirmation bias. It is increasingly evident that digesting material about controversies is a chal-lenging task for end users. These concerns have sparked con-troversy analysis and detection, a research area of growing interest (for a survey of prior work, challenges and impor-tant implications, see Dori-Hacohen et al.[6]). Accurately and automatically distinguishing between controversial and noncontroversial topics is one such challenge which is cur-rently within technical reach, yet far from a solved problem. Our paper focuses on automatically detecting controversial topics in Wikipedia, a task proposed by Kittur et al. [9], which can also serve as a crucial step in other algorithms (cf. [4]).
 Methods for Controversy Detection in Wikipedia . Of the relatively sparse prior work on automatically de-tecting controversy, most focuses on Wikipedia, since its rich user-generated content base offers a wealth of semi-structured data (for a survey and comparative study, see Table 1: Data set size and annotations (Wikipedia Articles) Algorithm 1 Cross-validation stacked training procedure Algorithm 2 Cross-validation stacked inference procedure [12]). Most of this work has used an approach that classifies each page in isolation [9, 14]. In contrast, this paper exam-ines networks of pages that are topically related, and argues that controversy detection can be improved by considering a page in the context of its neighbors. While some recent work has alluded to the possibility that controversies occur in neighborhoods of related topics [4] or demonstrated such clusters anecdotally [8], this potential connection has yet to be tested or used to improve controversy detection.
Web-page Classification and General Collective Clas-sification Approaches . Collective and relational inference are ML techniques that can be applied to relational data, which have been successful on many complex problems such as hyperlink categorization [3], by exploiting homophily be-tween related objects [7]. Stacked models are a type of col-lective classification that avoids the need for computation-ally intensive inference procedures, and is particularly useful in situations where there is a lack of extensive ground truth data for the neighborhood of a page [10]. In stacked mod-els, an intrinsic classifier , relying only on the features of the data instance being evaluated, is trained first, and then applied to generate predictions for the neighbors of every in-stance in the set. These predictions are then aggregated into an extended dataset and used as features of the instance. Finally, a stacked model is trained by using this extended dataset, as in regular collective inference. In other words, the collective inference classifier is  X  X tacked X  over the intrin-sic classifier (see e.g. Algorithms 1 and 2 below). Instead of using known truth labels of neighbors, a stacked model uses the outputs of an intrinsic classifier. Stacked models have been demonstrated to be effective at collective classification due to a reduction in bias [7].

When stacked models are used in semistructured datasets, they are usually applied in a relational manner: relatedness is defined directly in the structured data. In several do-mains, however, a relational link between two objects does not imply a strong connection between them. Inspired by the needs of our task, we propose explicitly constructing a subnetwork of relationships for the purpose of improving stacked classification. Using features of the semi-structured dataset, such as relation directionality and object similarity, we construct a more useful notion of relationship; we thus depart from most stacked classification approaches that as-sume that the dataset contains a fixed relational schema (cf. [7, 10]). Our work is distinct from Probabilistic Similar-ity Logic [2], which reasons about similarity for inference purposes; we propose to construct an induced subgraph of relationships based directly on similarity measures.
We will classify Wikipedia pages as controversial or not, using a combination of intrinsic features of a page, as well as predictions of controversy from pages related to it. There are two novel parts to our approach (described below): first, we construct a subnetwork of relations based on similarity, and then proceed to use a stacked model on top of this con-structed network. The training procedure for the intrinsic model is the standard fashion. Following Kou and Cohen [10], our stacked training procedure creates neighbor predic-tions in a cross-validated manner with 10 folds. The main difference from their approach is the use of a subset of the neighbors, rather than all neighbors. The training proce-dure is applied to the i -th fold, as seen in Algorithm 1. At inference time, the stacked model pipeline is applied to the i -th fold in an analogous manner, as seen in Algorithm 2.
Constructing a Subnetwork . We examine the neigh-borhood of each Wikipedia page, for stacked classification and to evaluate whether homophily exists for controversial topics. The effectiveness of collective inference relies on ho-mophily between related instances. Presumably, if a page is controversial, then the pages related to it are likely to be controversial. The controversy level of related pages, there-fore, can be used as a feature to the collective model. How-ever, links in Wikipedia are noisy, and not necessarily the best indication of relatedness. We expect stacked classifi-cation to be more useful when applied specifically to more relevant links. We thus do not consider every hyperlink to be an equally valid neighbor, but instead apply a similarity function to generate a relative ranking among all neighbors. Additionally, we argue that links pointing into, and out of, an article, should be viewed as separate types of relation-ships. Incoming links consist of a zipfian-like distribution which grows on a logarithmic scale, while outgoing links ex-hibit a more linear relationship. Specifically, we construct a subnetwork by applying a TF-IDF-based pairwise cosine similarity function on the text of the page, and then select-ing the top-scoring neighbors (taken as two separate lists, for in-links and out-links) as most  X  X elated X  to the center page.

Creating a Stacked Model . To evaluate our hypothe-ses, we create intrinsic and collective models of controversy. Name Description Stacked -Ranked -k Intrinsic A classifier using only intrinsic features Stacked -All Stacked -Random -k N eighbors -Only -k Prior work See Sepehri Rad &amp; Barbosa [12] for details We compare an intrinsic classifier that classifies each page independently, and a collective inference classifier that assumes dependence between controversy values of related pages.
We would like to examine the following hypotheses: (1) using a subset of chosen neighbors, based on a similarity ranking, represents an improvement upon using all neigh-bors; (2) using this subset also represents an improvement upon using the same amount of random neighbors. We will describe the datasets used, the model features and setup, and finally the alternative systems we created in order to examine our hypotheses.
We use two datasets for this work, as described in Table 1, which were created by two independent groups. The first dataset is the publicly available 1 Wikipedia Web Contro-versy dataset (denoted DHA [5]). The second is a collection provided on request (denoted SRMRB [12]). The incidence of controversy is different in the two sets (about 15% in DHA and exactly 50% in SRMRB). While it is quite challenging to estimate the precise incidence of controversy in the wild, we believe that an unbalanced setting is more realistic -in general, noncontroversial topics far outnumber controversial topics. In order to partially mitigate the challenges of train-ing on an imbalanced set (DHA), we applied weights to all the instances in the training folds, such that the sum of weights of all controversial pages was equal to the sum of weights for the noncontroversial pages. For both the intrinsic and the stacked models, we use the Random Forest classifier provided by Weka, set to use 100 trees, and the default behavior for all other settings. For training and inference, we used 10-fold cross-validation, as described in Section 3.

Similarity for Subnetwork Construction . In order to generate the collective model, we observed all Wikipedia pages linking into, and out of, the center page. We ranked all these pages by pairwise, TF-IDF based cosine similarity (ignoring stop words), then chose the top k in-links and the Table 4: Results for compared models with k = [10 , 300] top k out-links of the central page. We considered several al-ternatives for thresholding the similarity. In the experiments described below, we simply pick the top k ranked neighbors for incoming links, as well as the top k for outgoing links, where k is either 10 or 300.

Features . The features of both of the intrinsic and stacked models are displayed in Table 2. Intrinsic Features follow prior work that used metadata features of the Wikipedia pages [9, 12]. All intrinsic features are extracted from the May 2014 Wikipedia dump 2 . A subset of the features were extracted using JWPL 3 . We use the intrinsic model to gener-ate predictions (probabilities of controversy) for each neigh-bor in the subnetwork described above. Collective inference requires that the relevant features of pages be aggregated in order to use them: we use the aggregate functions in Table 2, applied separately to in-links and out-links. In total, 14 Stacked Features were added (7 aggregates each, which were applied to the top k in-links and out-links separately). Our proposed system described above, which we denote Stacked -Ranked -k , uses a similarity function to induce a subnetwork for the purpose of stacked inference. In order to test our hypotheses, we construct several alternative sys-tems (see Table 3). In each case, we train the model on the same intrinsic and stacked features described above (as ap-propriate for that system). Where possible, we compare our results to several baselines from prior work [1, 9, 13, 14], as reported in a recent comparative study [12].
We discuss some differences in data imbalance between the two datasets and our choice of metrics, and our findings: using similar neighbors improve stacked inference, neighbors can provide good inference even without intrinsic features, and a stacked model outperforms existing classifiers.
Data Imbalance and Metrics . The results of our ex-periments are displayed in Table 4. Due to the unbalanced https://github.com/dkpro/dkpro-jwpl nature of the DHA dataset, neither F1 nor accuracy are rep-resentative metrics for classification. Thus, we focus most of our subsequent discussion on Area under ROC (AUC), a metric commonly used to evaluate unbalanced sets, as it is insensitive to dataset imbalance. We report F1 and accuracy results for comparison with prior work.

Similar Neighbors Improve Results, particularly for the first few neighbors . The predictive power of the stacked model grows with the number of neighbors. Results increase substantially within the first 25 neighbors, with diminishing returns afterwards. The Stacked classifier outperforms both the Intrinsic and Neighbor-only models, for both datasets and all metrics presented (see Table 4). For most values of k , our proposed system (which chooses neighbors according to a similarity metric), outperforms a random selection of the same number of neighbors, with the difference clearest when a small number of neighbors is used (figure omitted due to lack of space). As the number of neighbors increase and approach all neighbors of the page, the subnetwork ap-proach converges to a  X  X egular X  stacked approach.

Neighbors Provide Quality Inference Without In-trinsic Features . As expected, each stacked model outper-forms its equivalent Neighbors-only version, which ignores the intrinsic features of the page. Interestingly, in some cases the Neighbors-only model outperforms an intrinsic classifier (see Table 4), despite not receiving any features of the page itself. Further work is needed to examine this phenomenon.
Stacked Models Outperform Prior Work . There are some challenges in comparing our results to prior work on controversy detection in the SRMRB dataset, chief of which is that our results are reported on a more up-to-date Wikipe-dia dump (see [12] for comprehensive comparative analysis of controversy classification). Unfortunately, these results were reported only in terms of accuracy (percent correct) with no AUC or other metrics reported. With these constraints in mind, our result of 74.4% accuracy outperforms the Basic method (60%, [13]), the bipolarity method (56%, [1]), and the Mutual Reverts method (67%, [14]) -all results as re-ported in [12] 4 . Our result of 74.4% is slightly lower than the Meta classifier [9] (75%) 5 . Notably, stacked models are ensemble methods and agnostic to the choice of intrinsic classifier for the problem, so any intrinsic classifier can be enhanced by applying our stacked classifier on top of it.
We present a novel stacked collective inference approach to detecting controversy in Wikipedia. By demonstrating that collective inference improves classification for this problem, we show that controversial articles exist in topical neigh-borhoods of controversy (i.e. exhibit homophily). Addition-aly, we demonstrate that a subnetwork constructed based on similarity can yield better classification results than the de-fault relationship in the dataset or randomly selected neigh-bors, particularly when a small subset of neighbors is used. This subnetwork approach can be generalized to other prob-lem domains and is an effective way of incorporating sim-ilarity in collective and stacked inference. Depending on the degree of nodes and the tradeoffs between the compu-tational cost of calculating pairwise similarity and those of running inference on all the neighbors, using similar neigh-bors may be preferable to all neighbors; we leave analysis of such tradeoffs to future work. The resulting stacked model improved over models using randomly selected neighbors, as well as over prior work. Future improvements in intrin-sic classification of controversy can translate to additional improvements in the stacked model. Future work in col-lective classification could explore other similarity construc-tions. Automated detection of controversy holds promise for increased civic participation and a better informed public, by raising awareness and encouraging search users to con-sider alternative perspectives.

