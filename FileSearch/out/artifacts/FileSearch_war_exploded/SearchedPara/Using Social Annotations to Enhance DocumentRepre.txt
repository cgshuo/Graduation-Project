 , Mokrane Bouzeghoub  X  , Athena Vakali  X  In this paper, we present a contribution to IR modeling. We propose an approach that computes on the fly, a Per-sonalized Social Document Representation (PSDR) of each document per user based on his social activities. The PS-DRs are used to rank documents with respect to a query. This approach has been intensively evaluated on a large public dataset, showing significant benefits for personalized search.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Systems]: Information Search and Retrieval General Terms: Algorithms, Experimentation.
 Keywords: Information Retrieval, Social networks.
Nowadays, with the huge amount of available information on the Web, finding relevant information remains harder for end-users as: (i) usually, the user doesn X  X  necessarily know what he is looking for until he finds it, and (ii) even if the user knows what he is looking for, he doesn X  X  always know how to formulate the right query to find it (unless in case of navigational queries [7]). In existing IR systems, queries are and/or ontologies, which are hidden to the user. The result-ing documents are not necessarily relevant from an end-user perspective, in spite of the ranking provided by the Web search engine.

One way to improve the IR process and reduce the amount of irrelevant documents is to improve the IR model, which is the focus of this work. Modeling in IR consists of two main tasks: (i) the definition of a conceptual model to represent documents and queries and (ii) the definition of a ranking function to quantify the similarities among documents and  X  T his work has been mainly done when the authors was at Bell Labs France, Centre de Villarceaux. resources.
 queries. We believe that enhancing the representation of documents with social information while personalizing them is expected to improve web search. Our motivations to im-prove the IR model are mainly driven by the following ob-servations: 1.  X  X ocial contextual summarization X  is required due to 2.  X  X ommon collaborative vocabularies X  are needed to 3.  X  X elevance relativeness X  X s needed since relevance is ac-The approach we are proposing relies on social annotations as source of social information, which are associated to doc-uments in bookmarking systems. These latter are based on the techniques of social tagging . The principle is to pro-vide the user with a mean to freely annotate resources on the Web with tags, e.g. URIs in delicious , or images in flickr . These annotations can be shared with others. This unstructured approach to classification is often referred to as a folksonomy.

The intuition behind the approach is that textual content of a document is expected to be a shared and a common rep-resentation for all users, while the social annotations used by a given user represent his own and personal understanding of its content, i.e. personal representation of this document. In this paper, our objective can then be formulated by the fol-lowing question: How to formalize a personal representation of a document in a social collaborative setting to improve web search? Our contributions are the following: 1. A document representation called Personalized Social 2. A ranking function of documents using their PSDRs 3. An evaluation study of our approach and a comparison The rest of this paper is organized as follows: in Section 2 we introduce the PSDR approach and the way it is used for ranking documents w.r.t a query. Section 3 presents the different experiments for evaluating our approach against the closest state of the art approaches. Finally, we conclude and provide some future directions in Section 4.
T o illustrate our approach, let X  X  consider a user Bob, who issues a query for which a number of web pages are retrieved, e.g. YouTube.com . Our approach intends to create a PSDR for each of these web pages according to Bob based on social annotations. For a given web page, the only consideration of the user X  X  tags as his personalized representation will result either in: (i) ignoring this web page if he did not annotate it (a user doesn X  X  tag all web pages) or (ii) assigning it an inappropriate ranking score (since the representation is only based on his own perspective, it may be poor). Our goal is then to use other users X  annotations to enrich the personal-ized representation of the query issuer enabling him to: (i) benefit from others X  experiences and feedbacks, (ii) promote used/visited resources even if they are not well classified, and (iii) discover new resources. Our approach proceeds into three main phases as illustrated in Figure 1: 1. Representing each document that matches the query 2. Using a matrix factorization process to infer the PSDR 3. Finally, ranking documents based on their PDSR. This Figure 1: Process of creating a PSDR of a web page.
The objective in this first step is to gather as much use-ful information as possible around the user and the relatives who may serve to construct and enrich the PSDR. As illus-trated in Figure 1, each web page can be represented using an m  X  n Users-Tags matrix M d U,T of m users who annotate the web page and the n tags that they used to annotate it. Each entry w ij represents the number of times the user u used the term t j to annotate the considered web page. Note that a stemming is performed over terms before building the Users-Tags matrix.

Instead of using all users X  feedback to infer a PSDR of the considered web page to Bob , we propose to choose only the most representative ones. Therefore, we use a ranking func-tion to rank users from the most relevant to the less relevant ones, and select the top users as the most representative to both the query issuer and the considered web page (see Step 2 of Figure 1). This is to filter out irrelevant users who may represent noise. The ranking score of a user u according to a document d and the query issuer u q is computed as: where | D | and | D u | are respectively the number of doc-uments, and the number of documents tagged by u , | T d | and | T u,d | are respectively the number of tags of d , and the number of tags used by u to annotate d , Cos ( u, u q ) denotes the cosine similarity between a user who annotates d and the query issuer based on the tags they used, and  X  is a weight set to 0.5.

Once we get a ranked list of users, we select the top k as the most representative ones to both the considered docu-ment and the query issuer. Then, we select their tags to build a new (smaller) Users-Tags matrix M d U,T . Finally, we add the query issuer as a new entry in the Users-Tags matrix M
U,T as well as his tags, if any (see step 3 of Figure 1).
Our approach relies on its ability to compute for a given document d , an m  X  n Users-Tags matrix of m users and n tags where w ij represents the extent to which the user u believes that the term t j is associated to the document d . The main challenge here is how to effectively estimate the personal weight of a tag t j in a document d according to a user u i ? We propose to use an adaptation of the well-known tf-idf measure to estimate this weight as follows: where n d u d (computed after stemming), and | D u i ,t i | is the number of documents tagged by u using t i .

At the end of this step, we obtain a relatively smaller matrix capturing the closest users (and their tags) to the query issuer for each document that matches the query. In-tuitively, the query issuer may have never annotated one of these documents, since the distribution of web pages over users follow a power law in folksonomies [14]. Given that, and due to the fact that a user is in average expected to use few terms to annotate a web page, we propose to in-fer a PSDR of a web page to a user based on other user X  X  feedback, translated by the inference of missing values in the Users-Tags matrix. This inference process is operated through matrix factorization as detailed in the next section.
Matrix factorization has proven its effectiveness in both quality prediction and scalability to predict missing values in sparse matrices [9, 10, 11]. This technique is based on the reuse of other users experience. Hence, to predict missing values in the Users-Tags matrix, it is first factorized into two latent matrices of features of users and tags by identifying weighting patterns. These latent features matrices are then used to make further missing values prediction. Therefore, t he Users-Tags matrix M d U,T of a web page is factorized using M
U  X  M d T , where the matrix M d U denotes the user latent features, and M d T represents the tag latent features.
As an example, if we use 2 dimensions to factorize the matrix obtained in Step 4 of Figure 1 for weighting predic-tion, we obtain the matrices illustrated in Step 5 of Figure 1. Note that M d u the latent feature vectors of user u i and tag t j for the web page Youtube.com , respectively. Then we can predict miss-ing values w ij using M  X  d u matrix represents the PSDR of the i th user of this web page. Notice that even if a user doesn X  X  annotate a web page, this approach still can predict reasonable weightings. A matrix factorization seeks to approximate the Users-Tags matrix M d U,T constructed above by a multiplication of l-rank factors, minimizing the sum-of-squared-errors objective function over the observed entries as follows: where M d U  X  R l  X  m and M d T  X  R l  X  n , I ij is is equal to 1 if u used t j to annotate the d i and equal to 0 otherwise.
The optimization problem in Equation 3 minimizes the sum-of-squared-errors between observed and predicted weight-ings. A gradient-based algorithm can be easily applied to minimize this function. Once M d U,T factorized, we can pre-dict missing values using M  X  d U  X  M d T . Then, we consider:
Proposition 1 : The row that corresponds to the query issuer in the predicted matrix M  X  d U  X  M d T corresponds to his PSDR of the considered document.

Storing the PSDR of each document for each user is not suitable in fact. This is like creating and storing an in-dex structure for each user, which is disk space consuming. Therefore, we propose to execute this factorization process on the fly, i.e. at query time. The complexity analysis, per-formed in Section 2.4, shows that this approach scales lin-early with the number of documents that match the query.
In this paper, we consider a retrieval process in which we retrieve documents whose textual content includes all the query terms. The Apache Lucene search engine currently handles this process in our implementation. Hence, with respect to this process, we propose to compute a ranking score of a document d that potentially match the terms of a query q issued by a user u as follows: where,  X  is a weight that satisfies 0  X   X   X  1, SES (  X  X  X  q , the Search Engine Score that express the similarity between the document d and the query q (computed by Lucene ), is the PSDR of the document d according to the user u .
Inspired by the Vectorial Model, queries, documents and their PSDRs are modeled as vectors. Hence, similarities be-tween these vectors are computed using the cosine measure. At the end of this process we obtain a list of ranked docu-ments according to (i) a matching between the textual con-tent of documents and the query, and (ii) the social interest of the user extracted from close relatives in the folksonomy.
As pointed in [10], since the distribution of tags and users over documents in folksonomies follows a power law, the Users-Tags matrix is expected to be extremely sparse. Hence, the total computational complexity in one iteration of the gradient descent algorithm is O (  X  ), where  X  is the number of nonzero entries in the Users-Tags matrix. Consequently, for factorizing one document, the computational complexity is estimated to be O ( i  X   X  ), where i is the number of iteration of the gradient algorithm ( i  X  10). Finally, the computational complexity for evaluating a query that match m documents is estimated to O ( m  X  i  X   X  ). Since i and  X  are estimated to very low values, we can say that the complexity scale linearly with the number of retrieved documents. By using parallel computation, we can easily and considerably reduce the execution time. This is part of our future work.
In this section, we describe the dataset we used, the eval-uation methodology and the evaluations we have performed.
To evaluate our approach, we have selected a public deli-cious dataset, which is described and analyzed in [14]. Be-fore the experiments, we performed four data preprocessing tasks: (1) We remove annotations that are too personal or meaningless, e.g.  X  X oread X ,  X  X mported IE Fa-vorites X , etc. (2) The list of terms undergoes a stemming by means of the Porter X  X  algorithm in such a way to eliminate the differences between terms having the same root. (3) We downloaded all the available web pages while removing those, which are no longer available using the cURL command line tool. (4) Finally, we removed all the non-English web pages. Table 1 gives a description of the resulted dataset:
M aking evaluations for personalized search is a challenge since relevance judgements can only be assessed by end-users themselves, which is difficult to achieve at a large scale. However, different efforts [3, 4] state that the tagging be-havior of a user of folksonomies closely reflects his behavior of search on the Web. In other words, if a user tags a docu-ment d with a tag t , he will choose to access the document d if it appears in the result obtained by submitting t as query to a search engine. Thus, we can easily state that any triple ( u, t, d ) that represents a user u who tagged a document d with tag t , can be used as a test query for evaluations. The main idea of these experiments is based on the following as-sumption: For a query q = { t } issued by user u with term t , relevant documents are those tagged by u with t .
Hence, for each evaluation, we randomly select 2000 pairs ( u, t ), which are considered to form a personalized query set. For each corresponding pair ( u, t ), we remove all the triplets ( u, t, d ) in order to not promote the document d in the results obtained by submitting t as a query in our algorithm and the considered baselines. For each pair, the user u sends the query q = { t } to the system. Then, we retrieve and rank all the documents that match this query u sing our approach or a specific baseline, where documents are indexed using the Apache Lucene. Finally, according to the previous assumption, we compute the Mean Average Precision (MAP) and the Mean Reciprocal Rank (MRR) over the 2000 queries. The random selection was carried out 10 times independently, and we report the average results.
In a previous evaluation that we performed for studying the impact of the top k closest users, we conclude that op-timal performance is obtained while selecting two users for building the Users-Tags matrix. Thus, our approach is eval-uated using the most two related users, and 5 dimensions for the factorization process. We compare our approach to several personalized and non-personalized baselines, in which the social based score is merged with the textual based matching score using a linear function with a  X  parameter. The results are illustrated in Figure 2, while varying  X  . (a) Mean Average Precision We compare our approach to: SocialPageRank (SPR) [1], Dmitriev06 [8], and the Lucene naive score. We also com-pare our approach to an approach where the matching score is computed as in Equation 4, but the social representation of documents is based on all annotations weighted using the tf-idf measure (BLQ). The last approach use LDA [5], where we model queries and documents. Then, for each document that match a query, we compute a similarity between its topic and the topic of the query using the cosine measure. The obtained value is merged with the textual ranking score as in Equation 4 (LDA-Q).

The results show that our approach is much more efficient than all the non-personalized approaches for all values of  X  . Hence, we conclude that the personalization efforts intro-duced by our approach in the representation of documents with respect to each user bring a considerable improvement of the search quality. We also notice that most of the non-personalized approaches decease their performance for high values of  X  . This is certainly due to the fact that they are not designed for personalized search, since these approaches fail in discriminating between users in spite of their preferences.
Here we compare our approach to: Xu08 [15], Noll07 [12], tf-if [13], and Semantic Search [2]. We also propose an ap-proach based on LDA to model users and documents, in which for each document that match a query, we compute a similarity between its topic and the topic of the user profile using the cosine measure. The obtained value is merged with the textual ranking score (LDA-P). The obtained results also show that our approach is much more efficient than all the baselines for all values of  X  . Especially, our approach out-perform the LDA-P approach and the Xu08 approach, which we consider as the closest works to our. We also notice that the Noll07 and the tf-if approaches give poor results. This is certainly due to the fact that they fail in ranking documents that doesn X  X  share tags with the query issuer.
This paper discusses a contribution to the area of IR mod-eling while leveraging the social dimension of the web. We proposed a Personalized Social Document Representation approach, an attempt to use social information to enhance and improve documents for users. When a user submits a query, we construct, on the fly, a PDSR of all documents that potentially match the query based on other users expe-rience. Then, we rank these documents with respect to the computed PSDR. The experiments that we have performed on a delicious dataset show the benefit of such an approach.
Currently, we are investigating ways to add social regu-larization terms to the objective function to constrain it and reduce the solution space. The temporal dimension of social users X  behavior has not been investigated yet and is part of our future work. Finally, performing an online user evalu-ation to validate our results is on-going. PSDR has been developed and integrated to the LAICOS [6] platform.
