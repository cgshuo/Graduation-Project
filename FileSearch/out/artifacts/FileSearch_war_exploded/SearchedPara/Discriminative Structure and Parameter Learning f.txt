 Raymond J. Mooney MOONEY @ CS . UTEXAS . EDU Statistical relational learning (SRL) concerns the induc-tion of probabilistic knowledge that supports accurate prediction for multi-relational structured data (Getoor &amp; Taskar, 2007). Markov Logic Networks (MLNs) are a re-cently developed SRL model that generalizes both full first-order logic and Markov networks (Richardson &amp; Domin-gos, 2006). An MLN is represented as a set of weighted clauses in first-order logic, and learning an MLN decom-poses into structure learning , learning the logical clauses, and parameter learning , setting the weight of each clause. Existing structure-learning algorithms for MLNs (Kok &amp; Domingos, 2005; Mihalkova &amp; Mooney, 2007) are non-discriminative and attempt to learn a set of clauses that is equally capable of predicting the truth value of all predi-cates given an arbitrary set of evidence. However, in many learning problems, there is a specific target predicate that must be inferred given evidence data about other back-ground predicates used to describe the input data. Most tra-ditional Inductive Logic Programming (ILP) methods fo-cus on discriminative relational learning (Dzeroski, 2007); however, they do not address the issue of uncertainty. Dis-criminative methods have been developed for parameter learning in MLNs (Singla &amp; Domingos, 2005; Lowd &amp; Domingos, 2007); however, they do not address structure learning.
 We have found that existing MLN structure learning meth-ods perform very poorly when tested on several bench-mark ILP problems on relating the activity of chemical compounds to their structure (King et al., 1995). This led us to develop new discriminative structure and param-eter learning algorithms for MLNs whose performance on these problems surpasses that of traditional ILP methods. The overall approach is to use traditional ILP methods to construct a large number of potentially useful clauses, and then use discriminative MLN parameter learning methods to properly weight them, preferring to assign zero weights to clauses that do not contribute significantly to overall pre-dictive accuracy, thereby eliminating them. Our structure learning component utilizes many of the clauses considered during the search conducted by a specific configuration of A
LEPH (Srinivasan, 2001). Our parameter learning com-ponent utilizes an exact probabilistic inference algorithm for MLNs with only non-recursive definite clauses. Our parameter learner also uses L 1 -regularization (Lee et al., 2006) instead of the normal L 2 in order to encourage as-signing zero weights to clauses, thereby simplifying the theory. We present experimental results that demonstrate that all three of these enhancements contribute significantly to improving the performance of our system over existing MLN and ILP methods.
 The remainder of the paper is organized as follows. Section 2 provides some background on MLNs, A LCHEMY (Kok et al., 2005), and A LEPH . Section 3 presents our new struc-ture and parameter learning algorithms. Section 4 presents our experimental evaluation of these methods. Section 5 discusses related work, and section 6 presents our conclu-sions.
 2.1. ILP and Aleph Traditional ILP systems discriminatively learn logical Horn-clause rules (logic programs) for inferring a given tar-get predicate given information provided by a set of back-ground predicates. These purely logical definitions are in-duced from Horn-clause background knowledge and a set of positive and negative tuples of the target predicate. A
LEPH is a popular and effective ILP system primarily based on P ROGOL (Muggleton, 1995). The basic A LEPH algorithm consists of four steps. First, it selects a positive example to serve as the  X  X eed X  example. Then, it constructs the most specific clause, the  X  X ottom clause X , that entails that selected example. The bottom clause is formed by conjoining all known facts about the seed example. Next, A
LEPH finds generalizations of this bottom clause by per-forming a general to specific search. These generalized clauses are scored using a chosen evaluation metric, and the clause with the best score is added to the final theory. This process is repeated until it finds a set of clauses that covers all the positive ex-amples. A LEPH allows users to customize each of these steps, and thereby supports a variety of specific algorithms. 2.2. MLNs and Alchemy An MLN consists of a set of weighted first-order formulae (also called clauses or rules). It provides a way of softening first-order logic by making situations in which not all for-mulae are satisfied less likely but not impossible (Richard-son &amp; Domingos, 2006). More formally, let X be the set of all propositions describing a world (i.e. the set of all the ground atoms 1 ), F be the set of all clauses in the MLN, w be the weight associated with clause f i  X  F , G f i be the set of all possible groundings of clause f i , and Z be the nor-malizing constant. Then the probability of a particular truth assignment x to the variables in X is given by the formula (Richardson &amp; Domingos, 2006): where g ( x ) is 1 if g is satisfied and 0 otherwise, and n that are satisfied given the current truth assignments to the variables in X . In order to perform inference for an MLN, L , one needs to produce its corresponding ground Markov network. As de-scribed by Richardson and Domingos (2006), this is done by including a node for every possible grounding of the predicates in L and an edge between two nodes if they ap-pear together in a grounding of a clause in L . The nodes appearing together in a ground clause form a clique. In general, exact inference in MLNs is intractable, so to cal-culate the probability that a ground atom or a set of them has a particular truth assignment given some evidence, one needs to run an approximate inference algorithm such as MCMC on this ground Markov network. MC-SAT (Poon &amp; Domingos, 2006) is currently the best inference method for MLNs.
 As previously mentioned, learning an MLN consists of two tasks: structure learning and weight learning. The weight learning component is independent of the structure learn-ing one. It can learn weights for clauses produced by struc-ture learning or written by a human expert. There are two approaches to weight learning: generative and discrimina-tive. The former is used when there is no specific target predicate, and the latter when we know which predicate is to be queried. The current state-of-the-art discriminative weight learner is preconditioner scaled conjugate gradient (PSCG) (Lowd &amp; Domingos, 2007). This algorithm uses samples from MC-SAT to approximate the intractable ex-pected counts of satisfied clauses w.r.t. the current model. These counts are needed to compute the gradient and Hes-sian of the conditional log-likelihood (CLL) of an MLN. The inverse diagonal Hessian is used as the preconditioner in this method.
 Regarding structure learning, there are currently two al-gorithms for learning clauses for MLNs. The first algo-rithm was proposed by Kok and Domingos (2005). This algorithm uses a top-down approach and can perform ei-ther beam-search or shortest-first search over the space of clauses. The candidate clauses are scored using weighted pseudo log-likelihood (WPLL) (Kok &amp; Domingos, 2005). In contrast, the second algorithm, B USL (Mihalkova &amp; Mooney, 2007) follows a more bottom-up approach. It first constructs Markov network templates from the data and then generates candidate clauses from these network templates. All candidate clauses are also evaluated using WPLL, and added to the final MLN in a greedy manner. Both of these algorithms can be constrained to only learn clauses that contain a given target predicate by setting their  X  X e X  (non-evidence) parameter to that predicate. However, they are not designed for discriminative learning since they try to find a set of clauses which maximizes WPLL, a non-discriminative measure.
 A
LCHEMY (Kok et al., 2005) is an open source software system for MLNs. It has implementations of all the ex-isting algorithms for structure learning, generative weight learning, discriminative weight learning, and inference for MLNs. It is also a framework for developing new algo-rithms for MLNs. Our proposed algorithm is implemented in this framework. In this section, we describe our two-step process for dis-criminatively learning both the structure and parameters of an MLN. The first step uses A LEPH to learn a large set of potential clauses. The second step learns the weights for these clauses, preferring to eliminate useless clauses by giving them zero weight. 3.1. Discriminative Structure Learning Ideally, the search for discriminative MLN clauses would be directly guided by the goal of maximizing their con-tribution to the predictive accuracy of a complete MLN. However, this would require evaluating every proposed re-finement to the existing set of learned clauses by relearn-ing weights for all of the clauses and performing full prob-abilistic inference to determine the CLL of each of the query atoms. This process is computationally expensive and would have to be repeated for each of the combinatori-ally large number of potential clause refinements. Evaluat-ing clauses in standard ILP is quicker since each clause can be evaluated in isolation based on the accuracy of its logi-cal inferences about the target predicate. Consequently, we take the heuristic approach of using a standard ILP method to generate clauses; however, since the logical accuracy of a clause is only a rough approximation of its value in a fi-nal MLN, we generate a large number of candidates whose accuracy is at least markedly greater than random guessing and allow subsequent weight learning to determine their value to an overall MLN.
 In order to find a set of potentially good clauses for an MLN, we use a particular configuration of A LEPH . Specif-ically, we use the induce cover command and m-estimate evaluation function. The induce cover command imple-ments a variant of P ROGOL  X  X  MDIE greedy covering al-gorithm (Muggleton, 1995) which does not remove previ-ously covered examples when scoring a new clause. The normal A LEPH induce command scores a clause based only on its coverage of currently uncovered positive exam-ples. However, this scoring is not reflective of its use in a final MLN, and we found that the induce cover approach produces a larger set of more useful clauses that signif-icantly increases the accuracy of our final learned MLN. The m -estimate (D  X  zeroski, 1991) is a Bayesian estimation of the accuracy of a clause (Cussens, 2007). The m param-eter defining the underlying prior distribution is automat-ically set to the maximum likelihood estimate of its best value. The output of induce cover is a theory, a set of high-scoring clauses that cover all the positive examples. How-ever, these clauses were selected based on an m -estimate of their accuracy under a purely logical interpretation, and may not be the best ones for an MLN. Therefore, in ad-dition to these clauses, we also save all generated clauses whose m -estimate is greater than a predefined threshold (set to 0.6 in our experiments). This provides a large set of clauses of potential utility for an MLN. We use the name A
LEPH ++ to refer to this version of A LEPH . 3.2. Discriminative Weight Learning Compared to A LCHEMY  X  X  current discriminative weight learning method (Lowd &amp; Domingos, 2007), our method embodies two important modifications: exact inference and L -regularization . This section describes these two modi-fications.
 First, given the restricted nature of the clauses constructed by A LEPH , we can use an efficient exact probabilistic infer-ence method when learning their weights instead of the ap-proximate inference algorithm that A LCHEMY uses to han-dle the general case. Since these clauses are non-recursive definite clauses in which the target predicate only appears once, multiple query atoms will not appear together in any grounding of any clause. For MLNs, this means that the Markov blanket of a query atom only contains evidence atoms. Consequently, the query atoms are independent given the evidence. Let Y be the set of query atoms and X be the set of evidence atoms, the conditional log likeli-hood of Y given X in this case is: and, P ( Y j = y j | X = x ) = exp ( P where F Y j is the set of all MLN clauses with at least one grounding containing the query atom Y j , n i ( x,y [ Y is the number groundings of the i th clause that evaluate to true when all the evidence atoms in X and the query atom Y j are set to their truth values, and similarly for n respectively. Then the gradient of the CLL is:
X Notice that the sum of the last two terms in the gradient is the expected count of the number of true grounding of the i  X  X h formula. In general, computing this expected count re-quires performing approximate inference under the model. For example, Singla and Domingos (2005) ran MAP in-ference and used the counts in the MAP state to approxi-mate the expected counts. However, in our case, using the standard closed world assumption for evidence predicates, all the n i  X  X  can be computed without approximate infer-ence since there is no ground atom whose truth value is un-known. This is a result of restricting the structure learner to non-recursive definite clauses. In fact, this result still holds even when the clauses are not Horn clauses. The only re-striction is that the target predicate appears only once in every clause. Note that given a set of weights, computing the conditional probability P ( y | x ) , the CLL, and its gradi-ent requires only the n i counts. So, in our case, the con-ditional probability P ( Y j = y j | X = x ) , the CLL, and its gradient can be computed exactly. In addition, these counts only need to be computed once, and A LCHEMY provides an efficient method for computing them. A LCHEMY also provides an efficient way to construct the Markov blanket of a query atom, in particular it ignores all ground formulae whose truth values are unaffected by the value of the query atom. In our case, this helps reduce the size of the Markov blanket of a query atom significantly since many ground clauses are satisfied by the evidence. As a result, our exact inference is very fast even when the MLN contains thou-sands of clauses.
 Given a procedure for computing the CLL and its gra-dient, standard gradient-based optimization methods can be used to find a set of weights that optimizes the CLL. However, to prevent overfitting and select only the best clauses, we follow the approach suggested by Lee et al. (2006) and introduce a Laplacian prior with zero mean, P ( w i ) = (  X / 2)  X  exp (  X   X  | w i | ) , on each weight, and then optimize the posterior conditional log likehood instead of the CLL. The final objective function is: log P ( Y | X ) P ( w ) = log P ( Y | X ) + log P ( w ) There is now an additional term  X  P i | w i | in the objec-tive function, which penalizes each non-zero weight w i by  X  | w i | . So, the larger  X  is (corresponding to a smaller vari-ance of the prior distribution), the more we penalize non-zero weights. Therefore, placing a Laplacian prior with zero mean on each weight is equivalent to performing an L -regularization of the parameters. An important property of L 1 -regularization is its tendency to force parameters to zero by strongly penalizing small terms (Lee et al., 2006). In order to learn weights that optimize the L 1 -regularized CLL, we use the OWL-QN package which implements the Orthant-Wise Limited-memory Quasi-Newton algorithm (Andrew &amp; Gao, 2007).
 This approach to preventing over-fitting contrasts with the standard L 2 -regularization used in previous work on learn-ing weights for MLNs, which is equivalent to assuming a Guassian prior with zero mean on each weight and does not penalize non-zero weights as severely. Since A LEPH generates a very large number of potential clauses, L regularization encourages eliminating the less useful ones by setting their weights to zero. In agreement with prior re-sults on L 1 -regularization (Ng, 2004; Dud  X   X k et al., 2007), our experiments confirm that it results in simpler and more accurate learned models compared to L 2 -regularization. In this section, we present experiments that were designed to answer the following questions: 1. How does our method compare to existing methods, 2. How does each of our system X  X  major novel compo-4.1. Data We employed four benchmark data sets previously used to evaluate a variety of ILP and relational learning algo-rithms. They concern predicting the relative biochemical activity of variants of Tacrine, a drug for Alzheimer X  X  dis-ease (King et al., 1995). 2 The data contain background knowledge about the physical and chemical properties of substituents such as their hydrophobicity and polarity, the relations between various physical and chemical constants, and other relevant information. The goal is to compare var-ious drugs on four important biochemical properties: low toxicity , high acetyl cholinesterase inhibition, good rever-sal of scopolamine-induced memory impairment, and inhi-bition of amine re-uptake. For each property, the positive and negative examples are pairwise comparisons of drugs. For example, less toxic ( d 1 ,d 2 ) means that drug d 1  X  X  tox-icity is less than d 2  X  X . These ordering relations are transi-tive but not complete (i.e. for some pairs of drugs it is un-known which one is better). Therefore, this is a structured (a.k.a. collective) prediction problem since the output la-bels should form a partial order. However, previous work has ignored this structure and just predicted the examples separately as distinct binary classification problems. In this work, in addition to treating the problem as independent classification, we also use an MLN to perform structured prediction by explicitly imposing the transitive constraint on the target predicate. Table 1 shows some background facts and examples from one of the datasets, and Table 2 summarizes information about all four datasets.
 4.2. Methodology To answer the above questions, we ran experiments with the following systems: A
LCHEMY : Uses the structure learning (Kok &amp; Domin-B USL : Uses B USL (Mihalkova &amp; Mooney, 2007) and A
LEPH : Uses A LEPH  X  X  standard settings with a few mod-A LEPH PSCG: Uses the discriminative weight learner A
LEPH ExactL2 : Uses the limited-memory BFGS al-A
LEPH ++PSCG: Like A LEPH PSCG, but learns weights A
LEPH ++ExactL2: Like A LEPH ExactL2, but learns A
LEPH ++ExactL1: Our full proposed approach using ex-To force the predictions for the target predicate to prop-erly constitute a partial ordering, we also tried adding to the learned MLNs a hard constraint (i.e. a clause with in-finite weight) stating the transitive property of the target predicate, and used the MC-SAT algorithm to perform pre-diction on the test data. This exploits the ability of MLNs to perform collective classification (structured prediction) for the complete set of test examples.
 In testing, only the background facts are provided as evi-dence to ensure that all predictions are based on the chem-ical structure of a drug. For all systems except A LEPH , a threshold of 0.5 was used to convert predicted probabilities into boolean values. The predictive accuracy of these algo-rithms for the target predicate were compared using 10-fold cross-validation. The significance of the results were eval-uated using a two-tailed paired t-test test with a 95% confi-dence level. To compare the quality of the predicted prob-abilities, we also report the average area under the ROC curve (AUC-ROC) for all probabilistic systems by using the AUCCalculator package (Davis &amp; Goadrich, 2006). 4.3. Results and Discussion Tables 3 and 4 show the average accuracy and AUC-ROC with standard deviation for each system running on each data set. Our complete system (A
LEPH ++ ExactL1 ) achieves significantly higher accu-racy than both A LCHEMY and B USL on all 4 data sets and significantly higher than A LEPH on all except the memory data set, answering questions 1(a) and 1(b). In turn, A LEPH has been shown to give higher accuracy on these data sets than other standard ILP systems like F OIL (Landwehr et al., 2007). A LCHEMY  X  X  existing non-discriminative structure learners find only a few (3 X 5) simple clauses. Two of them are unit clauses for the target predicate, such as great ne(a1,a1) and great ne(a1,a2) ; the others capture the transitive nature of the target relation. Therefore, even af-ter they are discriminatively weighted, their predictions are not significantly better than random guessing.
 The ablations that remove components from our over-all system demonstrate the important contribution of each component. Regarding question 2(b), the systems using general approximate inference (A LEPH PSCG and A LEPH ++ PSCG ) perform much worse than the corresponding versions that use exact inference (A
LEPH ExactL2 and A LEPH ++ ExactL2 ). Therefore, when there is a target predicate that can be accurately inferred using non-recursive definite clauses, exploiting this restriction to perform exact inference is a clear win. Regarding question 2(a), A LEPH ++ ExactL2 performs sig-nificantly better than A LEPH ExactL2 , demonstrating the advantage of learning a large set of potential clauses and combining them with learned weights in an overall MLN. Across the four datasets, A LEPH ++ returns an average of 6 , 070 clauses compared to only 10 for A LEPH .
 Table 5 presents average accuracies with standard devia-tions for the MLN systems when we include a transitivity clause for the target predicate. This constraint improves the accuracies of A LEPH ExactL2 , A LEPH ++ ExactL2 , and A
LEPH ++ ExactL1 , but sometimes decreases the accuracy of other systems, such as A LEPH PSCG . This can be ex-plained as follows. Since most of the predictions of A
LEPH ++ ExactL1 are correct, enforcing transitivity can correct some of the wrong ones. However, A LEPH PSCG produces many wrong predictions, so forcing them to obey transitivity can produce additional incorrect predictions. Due to space constraints, we do not report the correspond-ing AUC-ROC results, which are qualitatively similar. Regarding question 2(c), using L 1 -regularization gives sig-nificantly higher accuracy and AUC-ROC than using stan-dard L 2 -regularization. This comparison was only per-formed for A LEPH ++ since this is when the weight-learner must choose from a large set of candidate clauses by en-couraging zero weights. Table 6 compares the average number of clauses learned (after zero-weight clauses are removed) for L 1 and L 2 regularization. As expected, the final learned MLNs are much simpler when using L 1 regularization. On average, L 1 -regularization reduces the size of the final set of clauses by 26% compared to L regularization.
 Regarding question 1(c), several researchers have tested  X  X dvanced X  ILP systems on our datasets. Table 7 compares our best results to those reported for T FOIL (a combina-tion of FOIL and tree augmented naive Bayes), kFOIL (a kernelized version of FOIL), and R UMBLE (a max-margin approach to learning a weighted rule set). Our results are competitive with these recent systems. Additionally, unlike MLNs, these methods do not create  X  X eclarative X  theories that have a well-defined possible worlds semantics. Using an off-the-shelf ILP system to learn clauses for MLNs is not a new idea. Richardson and Domingos (2006) used C LAUDIEN , an non-descriminative ILP system that can learn arbitrary first-order clauses, to learn MLN struc-ture and to refine the clauses from a knowledge base. Kok and Domingos (2005) reported experimental results com-paring their MLN structure learner to learning clauses us-ing C LAUDIEN , FOIL, and A LEPH . However, since this previous work used the relatively small set of clauses pro-duced by these unaltered ILP systems, the performance was not very good. ILP systems have also been used to learn structures for other SRL models. The S AYU system (Davis et al., 2005) used A LEPH to propose candidate features for a Bayesian network classifier. Muggleton(2000) used P ROGOL , another popular ILP system, to learn clauses for Stochastic Logic Programs (SLPs).
 When restricted to learning non-recursive clauses for clas-sification, our approach is equivalent to using A LEPH construct features for use by L 1 -regularized logistic re-gression. Under this view, our approach is closely related to M ACCENT (Dehaspe, 1997), which uses a greedy ap-proach to induce clausal constraints that are used as fea-tures for maximum-entropy classification. One difference between our approach and M ACCENT is that we use a two-step process instead of greedily adding one feature at a time. In addition, our clauses are induced in a bottom-up manner while M ACCENT uses top-down search; and our weight learner employs L 1 -regularization which makes it less prone to overfitting. Unfortunately, we could not compare experimentally to M ACCENT since  X  X nly an im-plementation of a propositional version of MACCENT is available, which only handles data in attribute-value (vec-tor) format X  (Landwehr et al., 2007). Additionally, MLNs are a more expressive formalism that also allows for struc-tured prediction, as demonstrated by our results that in-clude a transitivity constraint on the target relation. We have found that existing methods for learning Markov Logic Networks perform very poorly when tested on sev-eral benchmark ILP problems in drug design. We have pre-sented a new approach to constructing MLNs that discrim-inatively learns both their structure and parameters to opti-mize predictive accuracy for a stated target predicate when given evidence specified with a defined set of background predicates. It uses a variant of an existing ILP system (A
LEPH ) to construct a large number of potential clauses and then effectively learns their parameters by altering ex-isting discriminative MLN weight-learning methods to uti-lize exact inference and L 1 regularization. Experimental results show that the resulting system outperforms existing MLN and ILP methods and gives state-of-the-art results for the Alzheimer X  X -drug benchmarks.
 We thank the anonymous reviewers for their helpful com-ments. We also thank Niels Landwehr for helping us set up the experiment with A LEPH . This research is spon-sored by the Defense Advanced Research Projects Agency (DARPA) and managed by the Air Force Research Labo-ratory (AFRL) under contract FA8750-05-2-0283. Most of the experiments were run on the Mastodon Cluster, pro-vided by NSF Grant EIA-0303609. The first author also thanks the Vietnam Education Foundation (VEF) for its sponsorship. The views and conclusions contained in this document are those of the authors and should not be in-terpreted as necessarily representing the official policies, either expressed or implied of DARPA, AFRL, VEF, or the United States Government.

