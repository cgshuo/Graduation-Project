 We describe our work on extracting attribute and value pairs from textual product descriptions. The goal is to augment databases of products by representing each product as a set of attribute-value pairs. Such a representation is beneficial for tasks where treating the product as a set of attribute-value pairs is more useful than as an atomic entity. Examples of such applications include demand fore-casting, assortment optimization, product recommendations, and assortment comparison across retailers and manufacturers. We deal with both implicit and explicit attributes and formulate both kinds of extractions as classification problems. Using single-view and multi-view semi-supervised learning algorithms, we are able to ex-ploit large amounts of unlabeled data present in this domain while reducing the need for initial labeled data that is expensive to obtain. We present promising results on apparel and sporting goods prod-ucts and show that our system can accurately extract attribute-value pairs from product descriptions. We describe a variety of applica-tion that are built on top of the results obtained by the attribute extraction system. Retailers have been collecting large amounts of data from various sources. Most retailers have data warehouses of transaction data containing customer information and related transactions. These data warehouses also contain product information but surprisingly that information is often very sparse and limited. For example, most retailers treat their products as atomic entities with very few ucts as atomic entities hinders the effectiveness of many applica-tions that businesses currently use transactional data for such as demand forecasting, assortment optimization, product recommen-dations, assortment comparison across retailers and manufacturers, or product supplier selection. If a business could represent their products as attributes and attribute values, all of the above applica-tions could be improved significantly.
 Suppose a grocery store wanted to forecast sales of Tropicana Low Pulp Vitamin-D Fortified Orange Juice 1-liter plastic bottle . Typi-cally, they would use sales of the same product from the same time last year and adjust that number based on some new information. Now suppose that this particular product is new and there is no data available from previous years. Representing the product as a set of attribute-value pairs ( Brand: Tropicana, Pulp: Low, Fortified with: retailers currently trying to use transactional data for data mining. Vitamin-D, Size: 1 liter, Bottle Type: Plastic ) would enable the re-tailer to use data from other products having similar attributes and forecast more accurately. Even if the product was not new, repre-senting it in terms of attribute-value pairs would allow comparison with other related products and improve any sales forecasts. The same holds true in the other applications mentioned earlier. Many retailers have realized this recently and are trying to enrich their product databases with corresponding attributes and values for each product. In our discussions with retail experts, we found that in most cases, this is being done manually by looking at (nat-ural language) product descriptions that are available in an internal database or on the web or by looking at the actual physical product packaging in the store. Our goal is to make the process of extract-ing attribute-value pairs from product descriptions more efficient and cheaper by developing an interactive tool that can help human experts with this task. It is somewhat surprising that the problem we tackle in this paper actually exists. One would expect prod-uct manufacturers and retailers to have a database of products and their corresponding attributes. Unfortunately, no such data sources exists for most product categories.
 In this paper, we describe two systems: one that extracts implicit (semantic) attributes and one that extracts explicit attributes from product descriptions and populates a knowledge base with these products and attributes. This work was motivated by discussions with CRM experts and retailers who currently analyze large amounts of transactional data but are unable to systematically  X  X nderstand X  their products. For example, a clothing retailer would know that a particular customer bought a shirt and would also know the SKU, date, time, price, and size of a particular shirt that was purchased. While there is some value to this data, there is a lot of information not being captured: characteristics (e.g., logo printed on the back ), as well as semantic properties (e.g., trendiness , formality ). Some of the attributes, e.g., printed logo , are often explicit in the product descriptions that can be found on retailer web sites, whereas others, such as  X  X rendiness X , are implicit. We describe our work on a sys-tem capable of inferring both kinds of attributes to enhance product databases.
 We also describe several applications of an enriched product data-base including recommender systems and competitive intelligence tools and provide evidence that our approach can successfully build a product database with accurate facts which can then be used to create profiles of individual products, groups of products, or entire retail stores. Similarly, we can create profiles of individual cus-tomers or groups of customers. Another possible application is a retailer comparison system that allows a retailer to compare its as-sortment with that of a competitor X  X , e.g., to determine how many high-end products each retailer offers.
 There has been significant research on extracting information from text documents but we are not aware of any any system that ad-dresses the same task as we are addressing in this paper. A related task that has received attention recently is that of extracting product features and their polarity from online user reviews. [1] describe a system that consists of two parts: the first part fo-cuses on extracting relevant product attributes, such as  X  X ocus X  in the domain of digital cameras. These attributes are extracted by use of a rule miner, and are restricted to noun phrases. The second phase deals with extraction of polarized descriptors, e.g.,  X  X ood X ,  X  X oo small X , etc. [16] describe a similar approach: they extract at-tributes by first extracting noun phrases, and then computing the pointwise mutual information between the noun phrases and salient context patterns (such as  X  X canner has X  ). Similarly to [1], the ex-traction phase is followed by an opinion word extraction and polar-ity detection phase. This work is related to our work on extracting explicit attributes: in both cases, a product is expressed as a vec-tor of attributes. The difference is that our work focuses not only on attributes, but also on extracting values, and on associating the extracted attributes with the extracted values to form pairs. Also, the attributes that are extracted from user reviews are often differ-ent (and described differently) than the attributes of the products that retailers would mention. For example, a review might mention photo quality as an attribute but specifications of cameras would probably use megapixels or lens manufacturer in the specifications. Information extraction with the goal of filling templates, e.g., [11; 15], is related to the approach in this paper in that we extract certain parts of the text as relevant facts. It however also differs from such tasks in several ways, notably because we do not have a definitive list of  X  X emplate slots X  available for explicit attributes. For the ex-traction of implicit attributes, we fill a pre-defined template list, but nothing is explicitly extracted from the descriptions themselves. Recent work in bootstrapping for information extraction using semi-supervised learning has focused on the task of named entity ex-traction [7; 10; 4] which only deals with the first part of our task (classifying the words/phrase as attributes or values independently of each other) and not with associating the extracted attributes with the corresponding extracted values. At a high level, our system deals with text associated with products to infer a predefined set of semantic attributes for each product. These attributes can generally be extracted from any information related to the product but in this paper, we only use the descriptions associated with each item. The attributes extracted are then used to populate a product database. The process is described below. We constructed a web crawler to visit web sites of several large ap-parel retail stores and extract names, URLs, descriptions, prices and categories of all products available. This was done very cheaply by exploiting regularities in the html structure of the websites and by lection of data from websites where we can construct wrappers; although automatically extracting names and descriptions of prod-ucts from arbitrary websites would be an interesting application area for information extraction or segmentation algorithms [11], we took the html content of web pages into account and extracted spe-cific pieces of information. decided to take the manual approach. The extracted items and at-tributes were placed in a database and a random subset was chosen to be labeled. After discussions with domain experts, we defined a set of seman-tic attributes that would be useful to extract for each product. We believe that the choice of attributes should be made with particular applications in mind and that extensive domain knowledge should be used. We currently infer values for 8 kinds of attributes for each item; more attributes that are potentially interesting could be added. The attributes we use are Age Group, Functionality, Price point, Formality, Degree of Conservativeness, Degree of Sportiness, De-gree of Trendiness , and Degree of Brand Appeal .
 The last four attributes (conservative, sportiness, trendiness, and brand appeal) have five possible values 1 to 5 where 1 corresponds to low and 5 is the highest (e.g., for trendiness , 1 would be not trendy at all and 5 would be extremely trendy). The data (product name, descriptions, categories, price) collected by crawling websites of apparel retailers was placed into a database and a small subset (  X  600 products) was given to a group of fashion-aware people to label with respect to each of the attributes described in the previous section. They were presented with the description of the predefined set of attributes and the possible values that each feature could take (see above). We treat the learning problem as a traditional text classification problem and create one text classifier for each semantic attribute. For example, in the case of the Age Group attribute, we classify the product into one of five classes ( Juniors, Teens, GenX, Mature, All Ages ). We use Na  X   X ve Bayes as commonly used for text clas-sification tasks as the initial approach for this supervised learning problem. In our initial data collection phase, we collected names and de-scriptions of thousands of women X  X  apparel items from websites. Since the labeling process was expensive, we only labeled about 600 of those, leaving the rest as unlabeled. Recently, there has been much interest in learning algorithms that combine informa-tion from labeled and unlabeled data. Such approaches include us-ing Expectation-Maximization to estimate maximum a posteriori parameters of a generative model [14], using a generative model built from unlabeled data to perform discriminative classification [8], and using transductive inference for support vector machines to optimize performance on a specific test set [9]. These results have shown that using unlabeled data can significantly decrease classifi-cation error, especially when labeled training data are sparse. For the case of textual data in general, and product descriptions in particular, obtaining the data is very cheap. A simple crawler can be built and large amounts of unlabeled data can be collected for very little cost. Since we had a large number of product descriptions that were collected but unlabeled, we decided to use the Expectation-Maximization algorithm to combine labeled and unlabeled data for our task. If we extend the supervised learning setting to include unlabeled data, Na  X   X ve Bayes is no longer adequate to find maximum a pos-teriori parameter estimates. The Expectation-Maximization (EM) technique can be used to find locally maximum parameter esti-mates.
 EM is an iterative statistical technique for maximum likelihood es-timation in problems with incomplete data [5]. Given a model of data generation, and data with some missing values, EM will lo-cally maximize the likelihood of the parameters and give estimates for the missing values. The Na  X   X ve Bayes generative model allows for the application of EM for parameter estimation. In our scenario, the class labels of the unlabeled data are treated as the missing val-ues. In order to evaluate the effectiveness of the algorithms described above for building an accurate knowledge base, we calculated clas-sification accuracies using the labeled product descriptions and 5 fold cross-validation. The evaluation was performed for each at-tribute and the table below (Table 1) reports the accuracies. The first row in the table (baseline) gives the accuracies if the most fre-quent attribute value was predicted as the correct class. The ex-periments with Expectation-Maximization were run with the same amount of labeled data as Na  X   X ve Bayes but with an additional 3500 unlabeled product descriptions.
 We can see that Na  X   X ve Bayes outperforms our baseline for all the attributes. Using unlabeled data and combining it from the initially labeled product descriptions with EM helps improve the accuracy even further. The results reported earlier in Table 1 are extremely encouraging but are indicative of the performance of the algorithms on a test set that follows a similar distribution as the training set. Since we first extracted and labeled product descriptions from a retail website and then used subsets of that data for training and testing (using 5 fold cross-validation), the results may not hold for test data that is drawn from a different distribution or a different retailer.
 The results we report in Table 2 are obtained by training the algo-rithm on the same labeled data set as before but testing it on a small (125 items) new labeled data set collected from a variety of retail-ers that were different from initial training (both labeled and unla-beled) set. As we can observe, the results are consistently better than baseline and in some cases, even better than in Table 1. This results enables us to hypothesize that our system can be applied to a wide variety of data and can adapt to different distributions of test sets using the unlabeled data. The first part of this paper dealt with extracting soft, semantic at-tributes that are implicitly mentioned in descriptions. Another class of attributes associated with products are explicit physical attributes such as size and color. The second part of this paper discusses the task of extracting these explicit attributes, i.e., attribute-value pairs that are explicitly mentioned in the data.
 As mentioned above, our discussions with retail experts led us to conclude that in most cases, this is being done today manually by looking at (natural language) product descriptions that are available in an internal database or on the web or by looking at the actual physical product packaging in the store. The work presented in this paper is motivated by the need to make the process of extracting attribute-value pairs from product descriptions more efficient and cheaper by developing an interactive tool that can help human ex-perts with this task. We begin with an overview of our system: We formulate the extraction as a classification problem and use Na  X   X ve Bayes combined with a multi-view semi-supervised algo-rithm (co-EM). The extraction system requires very little initial user supervision and is able to automatically extract automatically initial seed list for training using the unlabeled data. The output of the unsupervised seed extraction algorithm is combined with the unlabeled data and used by co-EM to extract product attributes and values which are then linked together using dependency informa-tion and correlation scores. We present promising results on multi-ple categories of sporting goods products and show that our system can accurately extract attribute-value pairs from product descrip-tions. 1. Data Collection from an internal database or from the web 2. Seed Generation either by generating them automatically or 3. Attribute-Value Entity Extraction using a semi-supervised 4. Attribute-Value Pair Relationship Extraction by associat-5. User Interaction to correct the results as well as to provide The modular design allows us to break the problem into smaller steps, each of which can be addressed by various approaches. We only focus on tasks 1-4 in this paper. In the following sections, we describe our approach to each of the four tasks in greater detail. The data required for extracting product attributes and values can come from a variety of sources. The product descriptions can re-side in an internal product database or they may be found on the retailer website. For the experiments reported in this paper, we developed a web crawler that crawls retailer websites and extracts product descriptions.
 For the work presented in this paper, we crawled the web site of a esting and relatively challenging domain because unlike categories such as electronics, the attributes are not easy and straightforward to detect. For example, a camera has a relatively well-defined list of attributes ( resolution, zoom, memory-type , etc.). In contrast, a base-ball bat would have some typical attributes such as brand, length, material as well as others that might be harder to identify as at-tributes and values ( aerodynamic construction, curved hitting sur-face , etc.).
 The input to our system is a set of product descriptions. Some examples of entries in these descriptions are: 1 tape cutter 4 rolls white athletic tape Audio/Video Input Jack Vulcanized latex outsole construction is lightweight and flexible It can be seen from these examples that the entries are not often full sentences. This makes the extraction task more difficult, because most of the phrases contain a number of modifiers, e.g., cutter be-ing modified both by 1 and by tape . For this reason, there is often labeled and unlabeled data.
 new set of retailers no definitive answer as to what the extracted attribute-value pair should be, even for humans inspecting the data. The product descriptions collected by the web crawler are pre-processed in several steps. First, the data is tagged with parts of speech using the Brill tagger [3]. Second, the data is stemmed, using the Porter stemmer [17], in order to normalize the data by mapping morphological variations of words to the same token. In order to generalize the observed data to the appropriate level of generalization, and in order to increase the amount of training data available for a given pattern or context, we replace all numbers (in any notation, e.g., scientific, floating point, etc.) with a unique token ( #number# ). For the same reason, all measures (e.g., liter, kg ) are replaced by a unique token ( #uom# ).
 Additionally, we compute several correlation scores between all pairs of words: we compute Yule X  X  Q statistic, mutual information, precision. Once the data is collected and processed, the next step is to provide labeled seeds for the learning algorithms to learn from. The extrac-tion algorithm is seeded in two ways: with a list of known values and attributes, as well as by an unsupervised, automated algorithm that extracts a set of seed attribute-value pairs from the unlabeled data. Both of these seeding mechanisms are designed to facilitate scaling to other domains. We use a very small amount of labeled training data in the form of generic and domain-specific value lists for colors, materials, coun-tries, and units of measures ( kg, oz. , etc.). In addition to the generic value list, we use a list of domain-specific (in our case, sports) val-ues and attributes. The values consist of sports teams (such as Pitts-burgh Steelers ), and contains 82 entries. Aside from these easily replaceable generic and domain-specific lists, the first four phases of the system (as specified in the overview above) work in an unsu-pervised fashion. Our unsupervised seed generation method extracts few, but rela-tively accurate attribute-value pairs from the training data. The ap-proach uses correlation scores to find candidates, and makes use of POS tags by excluding certain words from being candidates for extraction. Unsupervised seed extraction is performed after the pre-processing steps described above.
 Extracting attribute-value pairs is related to the problem of phrase recognition in that both methods aim at extracting pairs of highly correlated words. There are however differences between the two problems, the biggest being that attributes generally have more than one possible value, e.g.,  X  X ront pockets X ,  X  X ide pockets X ,  X  X ipper pockets X , etc. We exploit this observation to automatically extract high-quality seeds by defining a modified mutual information met-ric as follows.
 We consider all bigrams w i w i +1 as candidates for pairs, where is a candidate value, and w i +1 is a candidate attribute, a reason-able heuristic. Suppose word w (in position i + 1 ) occurs with n unique words w 1 ...n in position i . We rank the words by their conditional probability of occuring right before word p ( w j | w ) , w j  X  w 1 ...n , where the word w j with the highest condi-tional probability is ranked highest.
 The words w j that have the highest conditional probability are can-didates for values for the candidate attribute w . We are interested in cases where few words account for a high proportion of the proba-bility mass. For example, both Steelers and on will not be good can-didates for being attributes. Steelers only occurs after Pittsburgh so all of the conditional probability mass will be distributed on one value whereas on occurs with many words with the mass distrib-uted over too many values. This intuition is captured in two phases: in the first phase, we retain enough words w j to account for a part z, 0 &lt; z &lt; 1 of the conditional probability mass In the experiments reported here, z was set to 0.5.
 In the second phase, we compute the cumulative modified mutual information for all candidate attribute-value pairs.: Let p ( w, w 1 ...k ) =  X  is a user-specified parameter, where 0 &lt;  X  &lt; 1 . We have ex-perimented with several values, and have found that setting yields robust results.
 Table 3 lists several examples of extracted attribute-value pairs. Not all extracted pairs are actual attribute-value pairs. One typical example of an extracted incorrect pair are first name -last name pairs. We could use a list of common names to filter out these seeds but during our experiments, we found that the incorrectly extracted examples are rare enough that they do not have much impact on subsequent steps. The current metric accomplishes about 65% accuracy in the tennis category and about 68% accuracy in the football category. We have experimented with manually correcting the seeds by eliminating all those that were incorrect. This did not result in any improvement of the final extraction performance, leading us to conclude that our algorithm is robust to noise and able to deal with noisy seeds. After generating initial seeds, the next step is to use the seeds as labeled training data to extract attributes and values from the un-labeled data. In this phase, we treat each word separately with two exceptions: one, if a phrase is listed in the generic or domain-specific seed lists, we treat the entire phrase as an atom. Second, if an n-gram is recognized with high certainty as a phrase, as mea-sured by Yule X  X  Q, mutual information, and  X  2 scores, it is again treated as an atomic entity.
 We formulate the extraction as a classification problem where each word (or phrase) can be classified in one of three classes: attribute, value, or neither. We treat it as a supervised learning problem and use Na  X   X ve Bayes as our first approach. The initial seeds gener-ated (as described in the previous section) are used to label training data which Na  X   X ve Bayes uses to train a classifier. Since our goal is to create a system that minimizes human effort required to train the system, we use semi-supervised learning to improve the per-formance of Na  X   X ve Bayes by exploiting large amounts of unlabeled data available for free on the web. Gathering product descriptions (from retail websites) is a relatively cheap process using simple web crawlers. The expensive part is labeling the words in the de-scriptions as attributes or values. We augment the initial seeds (la-beled data) with the all the unlabeled product descriptions collected in the data collection phase and use semi-supervised learning (co-EM [13] with Na  X   X ve Bayes) to improve attribute-value extraction performance. The classification algorithm is described in the sec-tions below. The initial labeling of data items (words or phrases) is based on whether they match the labeled data. We define four classes to classify words into: unassigned, attribute, value, or neither . The probability distribution for each word defaults to  X  X nassigned X . If the unlabeled example does match the labeled data, then we simply assign it this label. If the word appears on a stoplist, it is tagged as neither , if it appears on the list of known attributes or values, it is tagged accordingly. We apply the extracted and generic lists to the unlabeled data in order to assign labels to as many words as possible, as described in the previous section. These labeled words are then used as train-ing data for Na  X   X ve Bayes that classifies each word or phrase in the unlabeled data as an attribute, value, or neither.
 The features used for classification are the words of each unlabeled data item, plus the surrounding 8 words and their corresponding parts of speech. With this feature set, we capture each word, its context, as well as the parts of speech in its context. The availability of a small amount of labeled training data and a large amount of unlabeled data allows us to use the semi-supervised learning setting. We use the multi-view or co-training [2] setting, where each example can be described by multiple views (e.g., the word itself and the context in which it occurs). The specific al-gorithm we use is co-EM: a multi-view semi-supervised learning algorithm, proposed by Nigam &amp; Ghani [13], that combines fea-tures from both co-training [2] and EM. co-EM is iterative, like EM, but uses the feature split present in the data, like co-training. The separation into feature sets we used is that of the word to be classified and the context in which it occurs. co-EM with Na  X   X ve Bayes has been applied to classification, e.g., by [13], but so far as we are aware, not in the context of information extraction. co-EM is a multi-view algorithm, and requires two views for each learning example. Each word or phrase is expressed in view1 by the stemmed word or phrase itself, and the parts of speech as assigned by the Brill tagger. The view2 for this data item is a context of window size 8, i.e. up to 4 words (plus parts of speech) before and up to 4 words (plus parts of speech) after the word or phrase in view1 . co-EM proceeds by initializing the view1 classifier using the labeled data only. Then this classifier is used to probabilistically label all the unlabeled data. The context ( view2 ) classifier is then trained using the original labeled data plus the unlabeled data with the labels provided by the view1 classifier. Similarly, the view2 classifier then relabels the data for use by the view1 classifier, and this process iterates for a number of iterations or until the classifiers converge. After the classification algorithm has assigned a (probabilistic) la-bel to all unlabeled words, a final important step remains: using these labels to tag attributes and values in the actual product de-scriptions, and finding correspondences between words or phrases tagged as attributes and values. The classification phase assigns a probability distribution over all the labels to each word (or phrase). This is not enough, because aside from n-grams that are obviously phrases, some consecutive words that are tagged with the same la-bel should be merged to form an attribute or a value. Addition-ally, the system must establish links between attributes (or attribute phrases) and their corresponding values (or value phrases), so as to form attribute-value pairs. Some unlabeled data items contain more than one attribute-value pair, so that it is important to find the correct associations between them. We do this by first establish-ing attribute-value pairs using the seed pairs that are extracted at the beginning of the learning process. We then use the labels that were assigned during the classification stage together with correla-tion scores to merge words into phrases, and to establish attribute-value links using a set of selection criteria. Attributes and values are then linked into pairs using the dependencies given by Mini-par. We add additional attributes that are not present in the data, but were contained in the initial list of seeds (colors, countries, and materials). Finally, some unlinked attributes are retained as binary attributes. In the process of establishing attribute-value pairs, we exclude words of certain parts of speech, namely most closed-class items. For example, prepositions, conjunctions, etc., are not good candidates for attributes or values, and thus are not extracted. The pair finding algorithm proceeds in seven steps: In this section, we present evaluation results for experiments per-formed on tennis and football categories. The tennis category con-tains 3194 unlabeled data items (i.e., individual phrases from the list of product descriptions), the football category 72825 items. Ta-ble 4 shows a sample list of extracted attribute-value pairs, together with the phrases that they were extracted from. This is to give an idea of what kinds of attributes are extracted, and is supplemented with a more quantitative evaluation in the following section. Table 4: Examples of extracted pairs for system run with co-EM We ran our system in the following three settings to gauge the effec-tiveness of each component: 1) only using the automatically gener-ated seeds and the generic lists ( X  X eeds X  in the tables), 2) with the baseline Na  X   X ve Bayes classifier ( X  X B X ), and 3) co-EM with Na  X   X ve Bayes ( X  X o-EM X ). In order to make the experiments comparable, we do not vary pre-processing or seed generation, and keep the pair identification steps constant as well.
 The evaluation of this task is not straightforward. The main prob-lem is that people often do not agree on what the  X  X orrect X  attribute-value pair should be. Consider the following example: Audio/JPEG navigation menu This phrase can be expressed as an attribute-value pair in multi-ple ways, e.g., navigation menu (attribute) and Audio/JPEG (value) or menu (attribute) and Audio/JPEG navigation (value) or as the whole phrase forming a binary attribute.
 All three pairs are possibly useful attribute-value pairs. The im-plication is that a human annotator will make one decision, while the system may make a different decision (with both of them being consistent). For this reason, we have to give partial credit to an au-tomatically extracted attribute-value pair that is correct, even if it does not completely match the human annotation. To measure precision, we evaluate how many automatically ex-tracted pairs match manual pairs completely, partially, or not at all. If the system extracts a pair that has no overlap with any human extracted pair for this data item, then the pair would be counted as fully incorrect.
 We report percentages of fully correct, partially correct, and incor-rect pairs as well as the percentage of pairs that are fully or par-tially correct. The last metric is useful especially in the context of human post-processing: partially correct pairs are corrected faster than completely incorrect pairs. Tables 5 and 6 list the results. # corr pairs 252 264 316 # part corr pairs 202 247 378 % fully correct 54.90 51.16 44.44 % full or part cor-rect % incorrect 1.08 0.97 2.39 # corr pairs 4704 5055 6639 # part corr pairs 8398 10256 13435 % fully correct 35.39 31.85 32.04 % part or full cor-rect % incorrect 1.44 3.52 3.12 When the system extracts a partially correct pair that is also ex-tracted by the human annotator, this pair is considered recalled. The results for this metric can be found in tables 7 and 8. # recalled 451 502 668 % recalled 51.25 57.05 75.91 As the training data contains many duplicates, it is more important to extract correct pairs for the most frequent pairs than for the less frequent ones. In this section, we report precision results for the most frequent data items. This is done by sorting the training data by frequency, and then manually inspecting the pairs that the sys-tem extracted for the most frequent 300 data items. This was done only for the system run that includes co-EM classification. We re-port precision results for the two categories ( tennis and football ) in two ways: first, we do a simple evaluation of each unique data item. # recalled 12629 14617 17868 % recalled 39.21 45.38 55.48 # correct 123 702 178 21362 % fully correct 51.25 55.89 51.90 60.01 # flip to correct 29 253 33 3649 % flip to correct 12.08 20.14 9.62 10.25 # flip to partially correct 7 22 3 761 % flip to partially correct 2.92 1.75 0.87 2.14 # partially correct 79 273 121 9245 % partially correct 32.92 21.74 35.27 25.98 # incorrect 2 6 8 579 % incorrect 0.83 0.48 2.33 1.63 Table 9: Non-weighted and Weighted Precision Results for Tennis and Football Categories.  X  X  X  stands for tennis ,  X  X  X  is football ,  X  X W X  non-weighted , and  X  X  X  is weighted Then we weight the precision results by the frequency of each sen-tence. In order to be consistent with the results from the previous section, we define five categories that capture very similar informa-tion to the information provided above. The five categories contain fully correct and incorrect . Another category is Flip to correct , meaning that the extracted pair would be fully correct if attribute and value were flipped. Flip to partially correct refers to pairs that would be partially correct if attribute and value were flipped. Finally, we define partially correct as before. Table 9 shows the results. The results presented in the previous section show that we can learn product attribute-value pairs in a largely unsupervised fashion with encouraging results. It is not straightforward to evaluate the perfor-mance of our system, but by using a variety of metrics, we can de-tect several trends in the results. First, the automatically extracted seeds plus the generic lists (without classification) result in a high-precision system, but with very low recall. Learning from these seeds by adding supervised learning (Na  X   X ve Bayes) into the process results in somewhat higher recall of pairs with only small drops in precision if any. Exploiting unlabeled data by using co-EM im-proves the recall even more while keeping precision comparable. Especially in the tennis category, recall improves dramatically as a result of co-EM learning. The system we presented in this paper is used to augment product databases with attributes and corresponding values for each prod-uct. Such an augmented product database can be used for a va-riety of applications. Demand Forecasting, Assortment Optimiza-tion, Product Recommendations, Assortment comparison across re-tailers and manufacturers, and Product Supplier Selection are just some of the applications that can be improved using the augmented product database. In this section we describe some specific appli-cations that we have developed on top of our system. Being able to analyze the text associated with products and map it to a set of attributes and values in real-time gives us the ability to create instant profiles of customers shopping in an online store. As the shopper browses products in a store, the system running in the background can extract the name and description of the items and using the trained system, can infer implicit (semantic) and explicit features of that product. This process can be used to create instant profiles based on viewed items without knowing the identity of the shopper or the need to retrieve previous transaction data. The sys-tem can then be used to suggest subsequent products to new and infrequent customers for whom past transactional data may not be available. Of course, if historical data is available, our system can use that to build a better profile and recommend potentially more targeted products. We believe that this ability to engage and tar-get new customers tackles one of the challenges currently faced by commercial recommender systems [18] and can help retain new customers.
 We have built a prototype of a recommender system for women X  X  apparel items by using our knowledge base of product attributes. More details about the recommender system can be found in [6]. The user profile is stored in terms of probabilities for each attribute value which allows us flexibility to include mixture models in fu-ture work in addition to being more robust to changes over time. Our recommender system improves on collaborative filtering as it would work for new products which users haven X  X  browsed yet and can also present the user with explanations as to why they were rec-ommended certain products (in terms of the attributes). We believe that our system also performs better than standard content-based systems. Although content-based systems also use the words in the descriptions of the items, they traditionally use those words to learn one scoring function. In contrast, our system changes the fea-ture space from words (thousands of features) to only the implicit and/or explicit attributes that were extracted. The ability to extract attributes for products is not only useful for customer profiling but also for product marketing. In our discus-sions with retailers, we realized that an important component of product marketing is the product description that is used in a cat-alog or website. We built the CopyWriters Marketing Assistant to help marketing professionals position the product correctly by helping them write the product descriptions. The writers select a set of target attributes that they intend to convey to the customer about that product and then write a description that is intended to convey those attributes. The description is then passed through the attribute extraction system which gives the attributes that the de-scription  X  X ctually X  contains or conveys. The system compares the actual attributes with the intended ones given by the writers and gives suggestions about what kinds of concepts and words to add in order to move the descriptions towards the intended attributes. For example, if the writers intended the marketing to convey that the product is extremely classic but the current description is rated by the extraction system as trendy, it would suggest using words such as timeless or seasonless. Multiple systems can be trained by obtaining labeled examples from different groups of people (dif-ferent customer segments for example) which would allow the tool to give feedback about what a particular group of people would think of a particular product description. We have shown this tool to several retailers and have received encouraging feedback about its utility and effectiveness. We also have a prototype that profiles retailers to build competi-tive intelligence applications. For example, by closely tracking the product offerings we can notice changes in the positioning of a re-tailer. We can track changes in the industry as a whole or specific competitors and compare it to the performance of retailers. By pro-filing their aggregate offerings, our system can enable retailers to notice changes in the positioning of product lines by competitor re-tailers and manufacturers. This ability to profile retailers enables strategic applications such as competitive comparisons, monitoring brand positioning, tracking trends over time, etc.
 Our assortment comparison tool is used to compare assortment be-tween different retailers. It allows the user to explore the assort-ment, as expressed by attribute-value pairs, in a variety of ways: for example, the user can visualize how many products a retailer offers with a certain value for an attribute. The user can also com-pare what proportion of one retailer X  X  products fall into a specific category as expressed by an attribute-value pair, e.g., what propor-tion of the clothing offered by the retailer are children X  X  clothing and compare it with that of a competing retailer.
 Another application of our system is assortment optimization. A retailer can express each product as a vector of attribute-value pairs, and can then run regression algorithms using sales data. This can provide quantitative information about the monetary value of each attribute and what makes certain customer buy certain products. We described our work on a system capable of inferring implicit and explicit attributes of products enabling us to enhance prod-uct databases for retailers. Treating products as sets of attribute-value pairs rather than as atomic entities can boost the effective-ness of many business applications such as demand forecasting, as-sortment optimization, product recommendations, assortment com-parison across retailers and manufacturers, or product supplier se-lection. Our system allows a business to represent their products in terms of attributes and attribute values without much manual effort.The system learns these attributes by applying supervised and semi-supervised learning techniques to the product descrip-tions found on retailer web sites. The system can be bootstrapped from a small number of labeled training examples utilizes the large number of cheaply obtainable unlabeled examples (product descrip-tions) available from retail websites.
 The completed work leaves many avenues for future work. Most immediate future work will focus on adding an interactive step to the extraction algorithm that will allow users to correct extracted pairs as quickly and efficiently as possible. We are working on ac-tive learning algorithms that are able to utilize the unlabeled data in order to most effectively learn from user feedback.While future work remains, we have shown the usefulness of the approaches in many prototype applications that we have built at Accenture Tech-nology Labs. We believe that the work described in this paper not only improves the state of data mining in the retail industry by aug-menting product databases with attributes and values, but also pro-vides interesting challenges to the research community working on information extraction, semi-supervised and active learning tech-niques. [1] M. H. Bing Liu and J. Cheng. Opinion observer: Analyzing [2] A. Blum and T. Mitchell. Combining labeled and unlabeled [3] E. Brill. Transformation-based error-driven learning and nat-[4] M. Collins and Y. Singer. Unsupervised Models for Named [5] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum like-[6] R. Ghani and A. E. Fano. Building recommender systems us-[7] R. Ghani and R. Jones. A comparison of efficacy of bootstrap-[8] T. Jaakkola and D. Haussler. Exploiting generative models in [9] T. Joachims. Transductive inference for text classification us-[10] R. Jones. Learning to Extract Entities from Labeled and Un-[11] A. M. Kristie Seymore and R. Rosenfeld. Learning hidden [12] D. Lin. Dependency-based evaluation of MINIPAR. In Work-[13] K. Nigam and R. Ghani. Analyzing the effectiveness and ap-[14] K. Nigam, A. McCallum, S. Thrun, and T. Mitchell. Text clas-[15] F. Peng and A. McCallum. Accurate information extraction [16] A.-M. Popescu and O. Etzioni. Extracting product features [17] M. F. Porter. An algorithm for suffix stripping. Program , [18] J. Schafer, J. Konstan, and J. Riedl. Electronic commerce rec-
