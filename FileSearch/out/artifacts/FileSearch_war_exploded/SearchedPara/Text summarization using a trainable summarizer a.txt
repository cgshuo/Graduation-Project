 1. Introduction
With the advent of the information age, people are beset with unprecedented problems because of the abundanceofinformation.Oneoftheseproblemsisthelackofanefficientandeffectivemethodtofindthe required information. Text search and text summarization are two essential technologies to address this while text summarizers play the role of information spotters to help users spot a final set of desired documents (Gong &amp; Liu, 2001).

In general, automatic text summarization takes a source text (or source texts) as input, extracts the essence of the source(s), and presents a well-formed summary formallydefinedautomatic textsummarization astheprocessofdistilling themostimportantinformation from a source (or sources) to produce an abridged version for a particular user (or users) and task (or tasks). The process can be decomposed into three phases: analysis , transformation , and synthesis . The formstheresultsofanalysisintoasummaryrepresentation.Finally,thesynthesisphasetakesthesummary representation, and produces an appropriate summary corresponding to users X  needs. In the overall pro-cess, compression rate , which is defined as the ratio between the length of the summary and that of the original, is an important factor that influences the quality of the summary. As the compression rate de-creases,the summary will be more concise; however, more information is lost. While the compression rate increases,thesummarywillbemorecopious;relatively,moreinsignificantinformationiscontained.Infact, when the compression rate is 5 X 30%, the quality of the summary is acceptable (Hahn &amp; Mani, 2000; Kupiec, Pedersen, &amp; Chen, 1995; Mani &amp; Maybury, 1999).

Text summarization had its inception in 1950s. Due to the lack of powerful computers and difficulty in naturelanguageprocessing(NLP),earlyworkfocusedonthestudyoftextgenressuchassentenceposition andcuephrase(Edmundson,1969;Luhn,1958).From1970stoearly1980s,artificialintelligence(AI)had been applied (Azzam, Humphreys, &amp; Gaizauskas, 1999; DeJong, 1979; Graesser, 1981; McKeown &amp; sentations, for example, frames or templates, to identify conceptual entities from a text and to extract relationships between entities by inference mechanisms. The major drawback is that limitedly-defined framesortemplatesmayleadtoincompleteanalysisofconceptualentities.Sincetheearly1990stopresent, information retrieval (IR) is employed (Aone, Okurowski, Gorlinsky, &amp; Larsen, 1997; Goldstein, Kant-Bloedorn,1999;Salton,Singhal,Mitra,&amp;Buckley,1997;Teufel&amp;Moens,1997;Yeh,Ke,&amp;Yang,2002).
SimilartothetasksofIR,textsummarizationcanberegardedashowtofindoutsignificantsentencesfrom a document. However, most IR techniques that have been exploited in text summarization focus on symbolic-levelanalysis,andtheydonottakeintoaccountsemanticssuchassynonymy,polysemy,andterm dependency (Hovy &amp; Lin, 1997).

Inthispaper,weproposetwonovelmethodstoachieveautomatictextsummarization:modifiedcorpus-basedapproach(MCBA),andLSA-basedT.R.M.approach(LSA+T.R.M.).Thefirstisbasedonascore functioncombinedwiththeanalysisofsalientfeatures,andthegeneticalgorithm(GA)(Russell&amp;Norvig, 1995) is employed to discover suitable combinations of feature weights. The second one exploits latent semantic analysis(LSA) (Deerwester, Dumais, Furnas, Landauer,&amp;Harshman, 1990;Landauer,Foltz,&amp;
Laham, 1998) and a text relationship map (T.R.M.) (Salton et al., 1997) to derive semantically salient structuresfromadocument.Bothapproachesconcentrateonsingle-documentsummarizationandgenerate the text-summarization process.

Theremainderofthispaperisorganizedasfollows.Section2introducessomerelatedstudies.Sections3 and4giveadetaildescriptionofourproposedapproaches.Section5presentstheempiricalresultsachieved byourproposedmethodsandcomparedwiththatofpreviouswork.Finally,Section6concludesthispaper. 2. Related work
Inrecentyears,avarietyoftextsummarizationmethodshasbeenproposedandevaluated.Accordingto the level of text processing, Mani and Maybury (1999) categorized text summarization approaches into thatmeasuresthesignificanceofinformation(Kupiecetal.,1995;Lin,1999;Mayeng&amp;Jang,1999;Teufel co-occurrence,co-reference,etc.,anddeterminesalientinformationbasedonthetext-entitymodel(Azzam etal.,1999;McKeown&amp;Radev,1995).Discourse-levelapproachesmodeltheglobalstructure X  X  X ocument format,rhetoricalstructure,etc. X  X  X fthetextanditsrelationtocommunicativegoals(Barzilay&amp;Elhadad, 1997; Silber &amp; McCoy, 2000).

On the other hand, text summarization can be roughly classified into two categories according to how much domain-knowledge is involved (Hahn &amp; Mani, 2000). Knowledge-poor approaches do not consider anyknowledgepertainingtothedomaintowhichtextsummarizationisapplied;therefore,knowledge-poor approachescanbeeasilyappliedtoanydomain(Abracos&amp;Lopes,1997;Gong&amp;Liu,2001;Hovy&amp;Lin, 1997;Kupiec etal.,1995;Lin,1999;Mayeng&amp;Jang,1999;Salton etal.,1997;Mitra, Singhal,&amp;Buckley, 1997). The foundation of knowledge-rich approaches is the assumption that understanding of the meaning
Elhadad, 1997; Hovy &amp; Lin, 1997; McKeown &amp; Radev, 1995). Knowledge-rich approaches rely on a sizeable knowledge base of rules, which must be acquired, maintained, and then adapted to any domain.
In general, surface-level approaches are known as knowledge-poor approaches, while entity-level and discourse-level approaches are known as knowledge-rich approaches.

Theformatofsummariesisanothercriteriontodifferentiatetext-summarizationapproaches.Usually,a summarycanbeanextractoranabstract.Infact,amajorityofresearcheshavebeenfocusedonsummary extraction, which selects salient pieces (keywords, sentences or paragraphs) from the source to yield a summary. Hovy and Lin (1997) further distinguished summaries as indicative vs. informative; generic vs.
Lin (1999) exploited a selection function for extraction, and used a machine-learning algorithm to automatically learn a goodfunctionto combine severalheuristics. Aone etal. (1997),Kupiec etal. (1995), and Mayeng and Jang (1999) regarded the task as a classification problem, and employed Bayesian clas-sifiers to determine which sentence should be included in the summary. Barzilay and Elhadad (1997), and
Silber and McCoy (2000) created summaries by finding lexical chains, relying on word distribution and lexical links among them to approximate content, and providing a representation of the lexical cohesive structureofthetext.Azzametal.(1999)usedco-referencechainstomodelthestructureofadocumentand to indicate sentences for inclusion in a summary. Gong and Liu (2001) proposed two methods: one used relevance measure to rank sentence relevance, and the other used latent semantic analysis to identify semanticallyimportantsentences.HovyandLin(1997)attemptedtocreatearobustsummarizationsystem, extracted topics are fused into one or more unifying concept(s). The generation stage reformulates the extracted and fused concepts and then generates an appropriate summary.

The following subsections briefly describe the two approaches on the basis of which our algorithms are developed. 2.1. Corpus-base dapproaches Nowadays, corpus-based approaches play an important role in text summarization (Hovy &amp; Lin, 1997; correspondingsummaries.Ingeneral,mostcorpus-basedmethodsadoptaweightingmodel. of corpus-based text summarization consists of two phases: the training phase and the test phase . The training phase extracts salient features from the training corpus and then generates rules by a learning algorithm.Thetestphaseappliestheruleslearnedfromthetrainingphaseonthetestcorpusandgenerates the corresponding summaries. The major advantage is that corpus-based approaches are easy to imple-ment. However, a trainable summarizer cannot guarantee that the summaries are useful, due to its defi-ciency of coherence and cohesion.

Kupiecetal.(1995)proposedatrainablesummarizerbasedonBayesianclassifiers.Foreachsentence s , the probability that it belongs to the summary S , given k features F pressedasEq.(1),where P  X  F j j s 2 S  X  istheprobabilitythat F ratioofthenumberofsummarysentencestothetotalnumberofsentencesintheoriginalcorpus,and P  X  F corpus.
 paragraph,thematicword,anduppercaseword.Theirresultsshowedthatpositionwasthemostimportant 2.2. Text summarization using a text relationship map
Salton et al. (1997) employed the techniques for inter-document link generation to produce intra-doc-ument links between passages of a document, and obtained a text relationship map according to the intra-documentlinks.Fig.1illustratesanexampleofthemap.Eachnodeonthemapstandsforaparagraphand larity, which is typically computed as the inner product between the vectors of the corresponding para-
Bushiness of a paragraph is defined to measure its significance. The bushiness of a paragraph is the numberoflinksconnectingittootherparagraphs.Forexample,thebushinessof P linksto P 1 , P 2 , P 3 , P 4 ,and P 6 .Ahighlybushynodelinkstomanyothernodes;inotherwords,ithasalotof overlappingvocabularywithothers;therefore,ahighlybushynodeislikelytodiscussmaintopicsthatare covered in many other paragraphs.

Asfortextsummarization,theyproposedthreeheuristicmethodstogeneratethesummaryaccordingto heuristic methods all identify paragraphs with high bushiness but traverse them in different text order.
OnthebasisofthemethodproposedbySaltonetal.(1997),Kim,Kim,andHwang(2000)measuredthe importance of a paragraph by aggregate similarity. Instead of counting the number of links connecting a node (paragraph) to other nodes, aggregate similarity sums the weights on the links. They found that the performance ofaggregatesimilarity surpassedthat ofbushy pathsin thedomainoftechniquearticles,but wasclosetothatofbushypathsinthedomainofnews.Theattractivenessofaggregatesimilarityisthatitis easy to adapt to new applications since it does not have to set link-threshold parameters. 3. Modified corpus-based approach
In this section, we propose a novel trainable summarizer, which takes into account several kinds of the title , to generate summaries. Two new ideas are employed to improve conventional corpus-based text summarization. First, sentence positions are ranked to emphasize the significances of different sentence obtain a suitable combination of feature weights. 3.1. Feature extraction given the following features. f 1 : Position  X  X  X mportantsentences,whichshouldbeincludedinthesummary,areusuallylocatedatsome particularpositions.Forexample,thefirstsentenceineachparagraphalwaysintroducesthemaintopicsthat theparagraphdescribes,andthelastsentencealwayssummarizeswhattheparagraphdiscusses.Moreover, itisbelievedthatevenfortwosentencesbothinthesummary,theirsignificancesaredifferentbecauseoftheir positions.Toemphasizethesignificancesofdifferentsentencepositions,eachsentenceinthesummariesof the training corpus is given a rank ranging from 1 to R (in our implementation, R is 5), where a smaller f : Positive keyword  X  X  X incewordsarethebasicelementsofasentence,themorecontent-bearingkeywordsa sentence has, the more important it is. Hence, positive keywords are defined as the keywords frequently included in the summary. Suppose that a sentence s contains n different keywords, Keyword
Keyword 2 ; ... ; Keyword n ,thenthepositive-keywordscoreof s isdefinedasEq.(3),where tf frequencyof Keyword i in s .

InEq.(3),toavoidthebiasofthesentencelength, 4 thisscoreisnormalizedbythelengthof s ,whichisthe number of keywords in s . f 3 : Negative keyword  X  X  X ncontrastto f 2 ,negativekeywordsarethekeywordsthatareunlikelytooccurin the summary. Suppose that a sentence s contains n different keywords, Keyword then the negative-keyword score of s is defined as Eq. (4), where tf Keyword i in s .
 sentence length. f 4 : Centrality  X  X  X hecentralityofasentenceimpliesitssimilaritytoothers,whichcanbemeasuredasthe degree of vocabulary overlapping between it and other sentences. In other words, if a sentence contains
Hence,themoreoverlappingkeywordsasentencehaswiththetitle,themoreimportantitis.Forasentence s , this score is defined as Eq. (6).

Inourimplementationforthosekeyword-based features ( f 2 , f keywords. The major drawback of dictionary look-up is that it is easy to misidentify keywords because of newkeywordsthatarenotinthedictionary.Toamelioratethisshortcoming, mutual information asshown constitute a new keyword. that x and y occurs adjacently in the corpus. We consider those new keywords when computing scores of keyword-based features, in order to alleviate the impacts of keyword misidentification. 3.2. Summary generation
Forasentence s ,aweighted scorefunction,asshown inEq.(8),isemployedtointegrateallthefeature scores mentioned above, where w i indicates the weight of f calculated from Eq. (8), and a designated number of the top-score sentences are picked out to form the summary.

Moreover, the genetic algorithm (GA) is exploited to obtain an appropriate set of feature weights. A chromosome isrepresented as the combinationof all feature weights in the form as  X  w measure the effectiveness of each genome, we define fitness as the average F -measure genome when the summarization process is applied on the training corpus. When performing the genetic algorithm, we produce 1000 genomes for each generation, evaluate fitness of each genome, and retain the fittest 10 genomes to mate for new ones in the next generation. In our experiments, 100 generations are evaluated to obtain steady combinations of feature weights.

ByapplyingGA,asuitablecombinationoffeatureweightscouldbefound.Itcannotbeguaranteedthat nevertheless,ifthegenreofthetestcorpusisclosetothatofthetrainingcorpus,wecanmakeaprediction thatthescorefunctionwillworkwell.Inotherwords,theperformanceofsuchascorefunctiondependson the similarity of the genre of the test corpus and that of the training corpus. 4. LSA+T.R.M. approach
Latent semantic analysis (LSA) is a mathematical technique for extracting and inferring relations of expectedcontextualusageofwordsinpassagesofdiscourse(Deerwesteretal.,1990;Landaueretal.,1998).
LSAisemployedinthispapertoderivelatentstructuresfromadocument.Inthissection,themethodused to derive semanticrepresentationby LSA iselaborated, andamethod to generate the summaryaccording to semantic representation is proposed. 4.1. Process of LSA + T.R.M.

The overall process shown in Fig. 2 consists of four phases: (1) preprocessing, (2) semantic model analysis, (3) text relationship map construction, and (4) sentence selection.

Preprocessing delimits each sentence by punctuation. Furthermore, it segments each sentence into keywords with a toolkit,named AutoTag (Academia Sinica,1999). Semantic model analysis representsthe input document (LSA in single-document level) or the whole corpus (LSA in corpus level) as a word-by-sentence matrix and reconstructs the corresponding semantic matrix via singular value decomposition (SVD)anddimensionreduction. Text relationship map construction createsthetextrelationshipmapbased on semantic sentence representation derived from the semantic matrix. Finally, sentence selection estab-lishes a global bushy path (Salton et al., 1997) according to the map and selects important sentences to compose a summary. 4.2. Semantic sentence/wor drepresentation
To analyze the impacts of expected contextual usage of words in different levels, we construct two semantic matrices, one for single-document level, and the other for corpus level. On one hand, single-document level considers words and sentences in the same document to construct the semantic matrix; on the other hand, corpus level considers words and sentences in the whole corpus to model the word-by-sentence matrix.
 The following elucidates how to construct the word-by-sentence matrix for the single-document level. Let D beadocument, W  X j W j X  M  X  bethesetofkeywordsin D ,and S  X j S j X  N  X  bethesetofsentencesin D .
A word-by-sentence matrix, 6 A , is constructed as Eq. (9), where S keyword.Inourwork,onlynounsandverbsaretakenintoaccountinthattheycarryessentialinformation about the meaning of a sentence.
In A , a i ; j isdefinedasEq.(10),where L ij isthelocalweightof W
L ij isdefinedas L ij  X  log 1  X  in S j , n j is the number of words in S j ,and E i is the normalized entropy of W
E
Wethenperformsingularvaluedecomposition(SVD)to A .TheSVDof A isdefinedas A  X  UZV T ,where U is an M N matrix of left singular vectors, Z is an N N diagonal matrix of singular values, and V is an N N matrix of right singular vectors.

Finally,theprocessof dimension reduction isappliedto Z bydeletingafewentriesinit,andtheresultof from A , U 0  X  X  u 0 i isamatrixofleftsingularvectorswhose i thvector u matrix of right singular vectors whose j th vector v 0 j represents S
Each column of A 0 denotes the semantic sentence representation, and each row denotes the semantic word representation. We use the semantic sentence representations for summary generation.
As to constructing the word-by-sentence matrix for corpus level, D represents all documents in the corpus. Furthermore, the value of G i for a i ; j in Eq. (10) is the global weight of W 4.3. Summary generation
Salton et al. (1997) proposed a text relationship map to represent the structure of a document and generated the summary according to the map. One problem of their map is the lack of the type or the contextofalink.Totakeintoaccountthecontextofalink,weintegratethemapandtheabove-mentioned semanticsentencerepresentationto promotetext summarization from keyword-levelanalysistosemantic-level analysis.

Inourmethod,asentence S i isrepresentedbythecorrespondingsemanticsentencerepresentation(Section 4.2),insteadoftheoriginalkeyword-basedfrequencyvector.Thesimilaritybetweenapairofsentences S
S isevaluatedtodetermineiftheyaresemanticallyrelated.ThesimilarityisdefinedasEq.(12).
Wealsousea map density parameter(Saltonetal.,1997)todecidewhetheralinkshouldbeconsideredasa 1 : 5 n best links on the map, where n is the number of sentences).

The significance of a sentence is measured by counting the number of links that it has. A global bushy path(Saltonetal.,1997)isestablishedbyarrangingthe k bushiestsentencesintheorderthattheyappearin theoriginaldocument.Finally,adesignatednumberofsentencesareselectedfromtheglobalbushypathto generate a summary. 5. Evaluation
In this section, we report our experimental results. 5.1. Data corpus One hundred articles in the domain of politics were collected from New Taiwan Weekly (New Taiwan Inc., 2003) and were partitioned into five sub-collections, named Set 1, Set 2, ... , and Set 5.
The summaries of the articles were created by three independent human annotators. Each sentence summaries, each sentence received a maximum rank among the three annotated ranks. Then, the top 30% of sentences for each document were selected as its summary. Table 2 shows the statistics of the data corpus. 5.2. Evaluation methods
There are two sorts of methods to evaluate the performance of text summarization: extrinsic evaluation quality of a summarybased onhow itaffects other task(s), andintrinsic evaluation judges the quality of a summary based on the coverage between it and the manual summary. We chose intrinsic evaluation and machine-generated summaries. Assume that T is the manual summary and S is the machine-generated summary, the measurements are defined as Eq. (13) (Baeza-Yates &amp; Ribeiro-Neto, 1999). 5.3. Modified corpus-based approach
First of all, we explain the symbols used in the following evaluation results.  X  CR : compression rate,  X  POS : position  X  f 1  X  ,  X  PK : positive keyword  X  f 2  X  ,  X  NK : negative keyword  X  f 3  X  ,  X  C : centrality  X  f 4  X  ,  X  TR : resemblance to the title  X  f 5  X  ,  X  CBA : original corpus-based approach,  X  MCBA : modified corpus-based approach,  X  MCBA + GA : MCBA with GA to find a suitable score function.
 We measured the performance of our first approach in the way called k -fold cross-validation (Han &amp; Kamber,2001).Inourexperiments,trainingandtestingwasperformedfivetimes(i.e., k  X  5).Initeration i , outperforms CBA about 2.0%, 3.5%, and 3.0% 7 when CR is 10%, 20%, and 30%, respectively. The result toPK,MCBAoutperformsCBAwhenCRis20%and30%.Theresultshowsthatthesentencelengthmay bias the score, and make the summarizer misjudge the importance of sentences. Furthermore, for C, and
TR, the result reveals that considering new keywords when computing scores of keyword-based features mayinfluencetheimportanceofkeywords,becausebothCandTRinCBAdonotconsidernewkeywords.
Table 4 gives the performance results when different heuristic functions are considered. For example,  X  X  X llfeatures X  X  X ndicatesthatPOS,PK,NK,C,andTRareallconsidered,while X  X  X ithoutPOS X  X  X eansall butthePOS areused.Inthis experiment,theweightofeachfeature issettobe1.The resultshowsthatC andTRaretwoessentialfeatures.WithoutCandTR,theperformancedeterioratesseverely.Forexample, whenCRis30%,Cdeclinesabout14.1%forCBAand16.8%forMCBA,whileTRdeclinedabout5.8%for
CBAand5.0%forMCBA.Ontheotherhand,theresultindicatesthatPOSandPKaretwolessimportant features, because the performance tends to worsen without them, but the differences are not great. We conjecture that POS and PK are neutral features for the test corpus since C and TR dominate the per-formance.Inaddition,NKisnotagoodfeatureeitherforCBAorMCBAbecausewithoutNK,theoverall performance improves. Therefore, we conclude that POS+PK+C+TR is the best combination of features. Tables 5 X 7 show the performance when POS, PK, C, and TR are considered. It can be seen that
F -measure of MCBA outperforms that of CBA about 2.7%, 6.2%, and 3.6%, when CR is 10%, 20%, and 30% respectively.

Table 8 lists feature weights obtained by GA when CR is 30%. In this table, we list as well the fitness ( F -measure)whenthefeatureweightsareappliedtothetrainingcorpus.Tables9 X 11showtheperformance when the feature weights in Table 8 are applied to the test corpus (i.e., MCBA+GA). It can be observed thatwhen F -measureisconsidered,onaverage,MCBA+GAoutperformsMCBAabout12.3%,9.6%,and 5.0% 8 when CR is 10%, 20%, and 30% respectively. This illustrates the benefits of employing GA in training.TheprimaryadvantageofGAliesinprovidingapreliminaryanalysisofthecorpusandprovidesa referral to tune the score function. However, GA does not guarantee that the obtained score function alwaysperformswellforthetest corpus. Forexample,whenCRis20%,theperformanceofSet2declines about 0.4%, and when CR is 30%, the performance of Set 5 declines about 1.0% (Table 11). We conclude that the performance of the GA-trained score function depends on the similarity of the genre of the test corpus and that of the training corpus. In spite of this, GA does provide a way to address the situation when we are indecisive about a good combination of feature weights. 5.4. LSA + T.R.M. approach when considering in single-document level
In this experiment, the feasibility of applying LSA to text summarization is evaluated. Tables 12 X 14 show the performance of our approach. For different test corpuses, the dimension reduction ratios (DR) differ;forexample,whenCRis10%,thebestDRforSet1is0.7(i.e.,iftherankofthesingularvaluematrix compression rate is 10%, 20%, and30%, the average DR is about 0.8, 0.7, and0.6 respectively. Regarding
F -measure on average LSA+T.R.M. outperforms Keyword+T.R.M. (Salton et al., 1997) about 29.0%, 18.9%, and 20.5% 9 when CR is 10%, 20%, and 30% respectively.

Table15showstheimpactofdifferentDR X  X whenCRis30%.TheresultindicatesthatwhenDRranges from 0.6 to 0.8, LSA+T.R.M. achieves better performance. Similarly, when CR is 10% and 20%,
LSA+T.R.M. achieves better performance as well when DR ranges from 0.6 to 0.8. Table 16 shows the performance of different sub-collections when the best DR is considered for each document. The result reveals that when CR is 10%, 20%, and 30%, we get an F -measure of 0.4247, 0.5039, and 0.5477 respec-tively. This indicates an upper-bound performance of our LSA+T.R.M. method. To sum up, with the appropriateDR,LSA+T.R.M.workswell.Thus,weconcludethatLSAcanbeemployedtopromotetext summarization from keyword-level analysis to semantic-level analysis.

TheeffectofLSAintextsummarizationisillustratedwithanexampleshowninTable17.Theprecedent 1 means that the following sentence belongs to the manual summary, the precedent 2 means a summary sentence created by Keyword+T.R.M., and precedent 3 means a summary sentence created by
LSA+T.R.M.Table18showsthetextrelationshipmapscreatedbyKeyword+T.R.M.andLSA+T.R.M. respectively.

In this example, when CR is 30%, LSA+T.R.M. achieves F -measure of 0.8, and Keyword+T.R.M. achieves F -measure of zero. Probing into the cause of the result, we find that LSA+T.R.M. sorts all sentences in the order of {P9S1, P1S1, P8S3, P8S2, P4S2, P3S1, P6S1, P10S1, P3S2, P11S2, P11S1, P8S1, P7S1, P5S1, P4S1, P2S1}, while Keyword+T.R.M. sorts all sentences in the order of {P3S1, P7S1, P5S1,
P3S2, P10S1, P8S3, P2S1, P11S2, P9S1, P8S2, P4S2, P4S1, P1S1, P8S1, P6S1, P11S1}. LSA+T.R.M. has fouroverlappingsentenceswiththemanualsummaryinthetop30%sentences,butKeyword+T.R.M.has no overlapping sentences with the manual summary. Hence, LSA+T.R.M. gets a better result. This phenomenon explains that LSA can derive more precise semantic meanings from a text. 5.5. LSA + T.R.M. when considering in corpus level
In contrast to the previous experiments that consider LSA+T.R.M. in single-document level (Section 5.4),inthisexperiment,weapplyLSA+T.R.M.incorpuslevelinordertoanalyzetheimpactsofexpected contextualusageofwordsinthewholecorpus.Tables19 X 21showtheevaluationresults.WhenCRis10%, 20%,and30%,theaverageDRisabout0.5,0.5,and0.4respectively.SimilartoTables12 X 14,regarding F -measure, our LSA+T.R.M. outperforms Keyword+T.R.M. about 19.6%, 16.7%, and 13.4% when CR is 10%, 20%, and 30% respectively. However, the scale of relative improvements does not surpass that of LSA+T.R.M. in single-document level (Table 14, Table 21).

Table 22shows theperformance when thebestDR isconsidered foreach document. When CR is10%, 20%, and 30%, we get an F -measure of 0.3064, 0.4047, and 0.4532 respectively. This indicates an upper-boundperformanceofourLSA+T.R.M.methodincorpus-level.Similarly,theresultdoesnotsurpassthat ofLSA+T.R.M.insingle-documentlevel.AsmentionedinHofmann(2001),LSAisnotabletoexplicitly capture multiple senses of a word, nor does it take into account that every word occurrence is typically intendedtorefertoonlyonemeaningatatime.Inotherwords,conceptualrepresentationobtainedbyLSA isunabletohandlepolysemy.WeconcludetwocausesthatmayaffecttheperformanceofLSA+T.R.M.in some common words with different meanings existing in different documents. Take  X  X   X  X  for example, occurrenceamongwords.Apropername,suchasaperson X  X nameoranorganization X  X name,mayoccurin differentdocumentsthatdescribedifferentevents;therefore,wordswithdifferentmeaningbutco-occurring with the proper name, may be bound together in the semantic space even though they do not have any relationswitheachother.Consequently,theresultofLSAincorpuslevelcannotreflectthetruerelationsof expected contextual usage of words. 5.6. Comparison between MCBA an dLSA + T.R.M.

Comparing our two proposed approaches, we find that the performance of LSA+T.R.M. approach in single-document level is close to that of MCBA though it does not surpass it (Tables 5 X 7, Tables 12 X 14).
ThemajorattractivenessofLSA+T.R.M.insingle-documentleveloverMCBAisthatitconcernsasingle document; hence, itiseasytoimplement sinceitneedsnopreprocessing.Moreover,whenthebestDRfor each document is considered, the upper-bound performance of LSA+T.R.M. even exceeds that of
MCBA+GA about 19.4%, 7.1%, and 6.3% when CR is 10%, 20%, and 30% respectively (Table 11, Table 16). This responds to the nature of LSA that if we can find the best DR, LSA+T.R.M. performs better than other keyword-based methods. Hence, we conclude that LSA can be employed to promote text summarization from keyword-level analysis to semantic-level analysis. Furthermore, compare LSA+ T.R.M. in single-document and LSA+T.R.M. in corpus level (Tables 12 X 14, Tables 19 X 21), the average DR of LSA+T.R.M. in corpus level is smaller that of LSA+T.R.M. in single-document level. This out-come reveals that when the dimension of the word-by-sentence matrix is large, we have to remove more
CRisstilltheimportantfactorthataffectsthequalityofthesummary.TheresultsrevealthatasCRrises, we get better performance in both approaches.
 Another important issue that we want to mention in particular is which approach is preferred,
MCBA+GA or LSA+T.R.M. We first consider MCBA+GA in several folds: (1) since it is a learning algorithm,theselectionofsalientfeaturesextremelyaffectsthequalityofthesummary,(2)theperformance dependsonthegeneofdocuments(e.g.,youcannotexpectabrilliantperformancewhenlearningthescore functionfromadatacorpusinthedomainoffinance,butapplyingitinthedomainofpolitics),and(3)the time to compute the summarization for a document is modest because the score function and the feature values are obtained in advance. In contrast to MCBA+GA, LSA+T.R.M. derives semantic structures from documents; we believe that it performs better in terms of semantics. However, it is difficult to determine the best dimension reduction ratio and hard to explain the effects of LSA (Hofmann, 2001). In addition, the computation time of SVD is much expensive. In conclusion, it depends on the situation to choose MCBA+GA or LSA+T.R.M. for achieving a better performance. As the above-mentioned, it is obvious that MCBA+GA is more suitable when you deal with a fixed-domain corpus, and is also appropriate for an on-line application. As for LSA+T.R.M., it is more preferred when you concern the qualityofthesummarysinceittakesintoaccountsemanticsinnature.Besides,bothofourapproachesare language independent. When applying the algorithms, the most important thing is the selection of salient terms, and to take more semantics, such as named entities and noun phrases, into consideration. 6. Conclusion
In this paper, we propose two text summarization approaches: modified corpus-based approach (MCBA) and LSA-based T.R.M. approach (LSA+T.R.M.). The first is a trainable summarizer, which ventionalcorpus-basedapproaches.Firstofall,sentencepositionsarerankedtoemphasizethesignificance ofdifferentsentencepositions.Inaddition,documentfeaturesarecombinedbyaweightingscorefunction, and the genetic algorithm (GA) is employed to obtain a suitable combination of feature weights. The seconduseslatentsemanticanalysis(LSA)toderivethesemanticmatrixofadocument(insingle-document relationshipmap.WeevaluateLSA+T.R.M.bothinsingle-documentlevelandcorpusleveltoinvestigate the competence of LSA in text summarization.

The two approaches were measured at several compression rates on a data corpus composed of 100 political articles.Whenthecompression rate was30%,theaverage F -measureof49%forMCBA,52%for
MCBA+GA, 44% for LSA+T.R.M. in single-document level and 40% for LSA+T.R.M. in corpus level two dominant features, and the best combination of features is sentence positions, positive keywords, centrality, and resemblance to the title. The performance of MCBA+GA indicates that employing GA in training does provide an effective way to address the situation when we are indecisive about a good combination of feature weights. The results of LSA+T.R.M. show that either in single-document level or in corpus level, as the appropriate dimension reduction ratio is chosen, LSA+T.R.M. outperforms key-word-based text summarization approaches. We conclude that LSA can be employed to promote text summarization from keyword-level analysis to semantic-level analysis.
 Acknowledgements TheresearchwassupportedbytheSoftwareTechnologyforAdvancedNetwork Applicationprojectof Institute for Information Industry and sponsored by MOEA, ROC.
 References
