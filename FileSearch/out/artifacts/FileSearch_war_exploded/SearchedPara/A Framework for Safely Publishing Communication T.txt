 A communication trace is a detailed record of the com-munication between two entities. Communication traces are vital for research in computer networks and study of network protocols in various domains, but their release is severely constrained by privacy and security concerns. In this paper, we propose a framework in which a trace owner can match an anonymizing transformation with the require-ments of analysts. The trace owner can release multiple transformed traces, each customized to an analyst X  X  needs, or a single transformation satisfying all requirements. The framework enables formal reasoning about anonymization policies, for example to verify that a given trace has utility for the analyst, or to obtain the most secure anonymization for the desired level of utility. Because communication traces are typically very large, we also provide techniques that al-low efficient application of transformations using relational database systems.
 Categories and Subject Descriptors: H.2.m [Database Management]:Miscellaneous; K.4.1 [Computers and Society]: Public Policy Issues -Privacy General Terms: Security, Design, Performance.
A communication trace is a detailed record of the commu-nication between two entities. Communication traces arise in a variety of settings and include network traces, phone toll records, instant-messaging transcripts, among others. Each record in a communication trace typically identifies a source and a destination, along with descriptive fields such as time stamp, transmitted content, length of transmission, and communication ports.

Communication traces are vital to research into traffic analysis, communication protocols, routing in networks, and security of communication networks. Unfortunately the pub-lic release of communication traces remains highly constrained by privacy and security concerns and the lack of available traces is a serious concern for researchers [4, 13].
The safe release of communication traces is a significant challenge. First, communication traces are transactional in nature, with information about entities spread across multi-ple records, and correlations between records. Conventional k-anonymization [12, 14] and its extensions for transactional data [15] are focused on conceptions of utility that are in-appropriate and insufficient for communication traces. The second challenge to protecting communication traces is their massive size. Many proposed anonymization schemes sim-ply cannot scale to such large data sets.

Our approach In this work we propose an approach to communication trace publication emphasizing utility and scalability. We address the problem faced by a trace owner who wishes to allow a group of independent analysts to safely study a communication trace.

The first component of our approach is a set of simple, formally-defined transformation operators that are applied to the trace to remove or obscure information. These trans-formation operators can be combined to form composite transformations that can be applied to publish output traces, and can be thought of as a safe view of the original trace.
Unlike most approaches to trace anonymization (in which the trace owner generates a single anonymized trace) we provide a framework for the trace owner to anonymize a trace for the needs of a particular analysis, releasing mul-tiple traces. The published traces can be more secure be-cause they provide only the needed information, omitting everything else. Our publication framework is illustrated informally in Figure 1. The figure shows an original trace T transformed in four different ways, for use by different analysts. Trace T 1 contains sufficient information for both analysts A and B . Trace T 2 is devised for use exclusively by the analyst C , and trace T 3 is customized for the needs of analyst D . An alternative to publishing both trace T and T 3 is to derive the single trace T 23 which can support analysts C and D simultaneously.

The second component of our approach is input from the analyst. We assume the requesting trace analyst provides a description of the information needed for analysis. We propose a simple language for utility constraints which ex-press the need for certain relationships to hold between the original trace and the published trace.

The third component of our approach is the formal eval-uation of privacy and utility. Because both the transfor-mations and the utility requirements of analysts are spec-ified formally, it is possible for the trace owner to analyze Figure 1: The proposed trace protection framework: the original trace T may be transformed in multiple ways ( T 1 ,T 2 ,T 3 ,T 23 ) to support the requirements of different analysts. trace publication scenarios precisely. In particular, the trace owner can: (1) decide whether a composite trace transfor-mation satisfies an analyst X  X  requirements and guarantees perfect utility; (2) compute the most secure transform sat-isfying a given set of analyst requirements; (3) compare the security and collusion risks of various transforms that can meet requirements of all the analysts.

The result of our contributions is a framework in which basic trace transformation operations can be applied effi-ciently, and with a precise, formal understanding of their impact on trace utility and privacy. In the remainder of the paper, we describe components of our framework (Sec-tion 2), the formal analysis supported by framework (Sec-tion 3), the efficient implementation of the system (Section 4) and the related work (Section 5).
In this section we describe the two main objects of our framework: operators , used by the trace owner to define trace transformations, and constraints , used by analysts to express utility requirements.
The following transformation operators are applied to a trace in order to obscure, remove, or translate field values, making it more difficult for an adversary to attack, but also less useful for analysts. The trace owner may combine in-dividual operators to form composite transformations, bal-ancing utility and security considerations. The output of a composite transformation is released to the analyst. We consider a communication trace as a table consisting of records . Each record consists of fixed number of fields. Projection The projection is the simplest operator which is similar to relational projection operator but it retains the duplicates. It is denoted  X  X for retained attributes in X . Encryption The encryption operator is denoted E X ( Y ) , X  where X is a set of target fields whose values are replaced by ciphertext obtained by applying symmetric encryption function on string formed by concatenating values from X and Y , using  X  as the key. The values of Y are not affected. Canonical Ordering The canonical ordering operator re-places the values in fields by synthetic values that respect the ordering of the original values. The ordering operator is denoted O X ( Y ) where X is the set of target fields to be replaced. The optional set Y is used to form the groups agreeing on values in Y . The replaced values of X respects the ordering only within the group.
 Translation The translation operator, denoted T X ( Y ) trans-lates the values in columns of X by adding or subtracting a parameter whose value is determined using a function tak-ing values in Y as input. If the Y is empty set, all records are translated by some constant c .
 Scaling The scaling operator is denoted S X,k and it scales the values in target fields X by multiplying with a constant multiplier k .

It is sometimes convenient to consider the identity trans-formation, denoted I X , which does not transform field X , including it in the output without modification.
 The operators above can be combined to form composite transformations for a trace. We assume in the sequel that composite transformations  X  are represented in the following normal form: where  X  i X tribute set X i and for all i ,  X  i X the set of all such transformations  X . The last operation applied to the trace is the projection  X  X . Any operator act-ing on fields not present in X will be disregarded. Further we restrict our attention to composite operations in which each field in the trace is affected only by one operation:  X  i,j,X i  X  X j = {} . We have found that the simple set of operators described earlier can be used to generate safe com-posite transformations supporting a wide range of analyses. However, addition of additional operators to our framework is easy and requires only minor extensions to support other features of the framework.
In our framework, the analyst seeking access to a trace must specify their utility requirements formally. These re-quirements are expressed as a set of constraints asserting a given relationship between fields in the original trace and fields in the anonymized trace. The syntax of notation for the constraint is as follows: where 0 expr 0 can be any acceptable arithmetic expression obtained using operators (+ ,  X  ,/,  X  ) or it can be any boolean expression obtained using operators (&amp;&amp; , || ,  X  ,  X  , == , ! =) on fields in the trace.

The above constraint means that if there are one or more records in a trace that satisfy the boolean qualifying condi-tions given in  X  qualifier  X  , then the value of expression expr evaluated over these records must be equal to the value of same expression when evaluated over corresponding anonymized records.

We believe trace analysts will be able to use these con-straint rules to accurately describe the properties of a trace required for accurate analysis. The analyst could be as-sisted in this task by a GUI or semi-automated procedures, but this is beyond the scope of the current work.

As an example, in Table 1, we semi-formally describe the requirements as a set of constraints for a real study[6] from the area of network research. This study focuses on esti-Table 1: A semi-formal description of utility requirements sufficient to support the example TCP/IP network analysis.
Any tuple t Any tuples t 1 ,t 2 belonging to in trace same connection in trace PRESERVE( t.syn ) PRESERVE( t 1 .seq no  X  t 2 .seq no ) PRESERVE( t.ack ) PRESERVE( t 1 .seq no  X  t 2 .seq no ) PRESERVE( t.window ) PRESERVE( t 1 .ts  X  t 2 .ts ) where PRESERVE( expr )  X  expr T = expr  X  ( T ) i.e. value of expr evaluated over tuples in trace T must be equal to value when expr is evaluated over transformed tuples in  X  ( T ) mating the round trip time of a network packet using IP-level packet network traces (see Table 2(a) for illustration). An anonymization scheme to support this study can be ex-pressed as a composite transformation function  X  given by: Here C = { ip 1 ,ip 2 ,pt 1 ,pt 2 } . The records in the sample trace given in Table 2(a) are transformed using the above transformation function  X  , to obtain the anonymized view given in Table 2(b). The encrypted values have been re-placed by variables for clarity.
In this section, we briefly describe the important feature of the framework which allows the trace owner to reason for-mally about the anonymizing transformations and utility. In addition, it allows formal comparison of transformations and has its implications in computing most secure trans-formation , comparing alternative publication strategies and analyzing the impact of collusion.
In our framework, it is possible to test efficiently whether a given transformation  X  will always satisfy the utility re-quirements expressed by a set of constraints C . Checking utility constraint satisfaction is performed independently for each constraint rule in C by matching the conditions speci-fied in a constraint to the operators that impact the named fields. Recall that the constraint has an expression expr where it can be conjunctive normal form of one or more sub-expressions, or an arithmetic expression. In our frame-work, we maintain a look-up table consisting of possible sub-expressions along with the satisfying transformations and conditions. For each sub-expression in a constraint, we look for the corresponding entry in look-up table. If the compos-ite transform function  X  has a matching transformation in the table for each of the sub-expression, then the constraint is said to be satisfied by the transformation. The details of this process and can be found in our technical report [11].
Since each transformation operator removes information from the trace, some composite transformations can be com-pared with one another in terms of the amount of informa-tion they preserve. It can be shown that there is a natural partial order (denoted ) on transformations. Given two transformations  X  1 and  X  2 , we say that  X  1 is more strict than  X  2 or  X  1  X   X  2 if the information preserved by  X  contained within the information preserved by  X  2 .
The precise definition of strictness relation and the rela-tions for basic operators are given in our report [11].
Recall that  X  denotes the set of all composite transforma-tions. Then the following theorem show that the strictness relation has a number of convenient properties.

Theorem 1. ( X  , ) is a partially ordered set and forms a join-semilattice i.e. for any two transformations  X  1 and  X  there is another transformation in  X  , denoted lub(  X  which is the least upper bound of  X  1 and  X  2 .

Theorem 1 can be easily extended to conclude that any set of transforms has a unique least upper bound and this fact has a number of important consequences for the trace publisher:
Our system allows the trace owner to efficiently transform large traces in response to multiple requests from analysts. We use a relational database to store the original trace and to apply transformations, creating new traces to be released to users.
 In this system, the transformation operators from ( X  ,E, T,S,I ), can be applied in a single scan of the trace using SQL queries with user-defined functions (UDFs). The op-erators E,T,S , can be implemented efficiently using UDFs, and add only modest CPU overhead. The operators I and  X  are implemented using costless projection.

On the other hand, the canonical ordering operator O X ( Y ) can be applied using the DENSE RANK() function which was added to the SQL:2003 standard. This function com-putes the rank of the tuples in a relation based on the rank criteria provided in assisting clause. The operation O X ( Y ) can be done using following clause: DENSE RANK OVER (PARTITION BY Y ORDER BY X). Unlike scalar UDFs, this function requires sorting of the base relation. Thus, the cost of transformation increases linearly with the number of O -operators due to multiple scans of the trace.

In order to optimize the transformation cost for canonical ordering, we use vertical partitions of the trace where each Figure 2: The execution time vs number of parti-tions graph for varying data sizes varying from 20 million rows to 52 million rows. The query consisted of six rank operators. partition has fewer columns and is customized for specific O operators. The vertical partitions prevents redundant sorts of the various columns in trace and have low sorting costs due to smaller size. The results from different partitions are merged to provide a transformed trace. Figure 2 shows the reduction in execution time of a query with 6 dense rank functions as the number of vertical partitions increases.
Further optimization can be done by storing the ranks computed for a query in auxiliary tables and using them later for another query. The details of cost estimation, de-signing partitions for the workload and using auxiliary tables can be found in our technical report [11].
K-anonymity [12, 14] and variants [7] apply to the case where there is exactly one record per entity in the data. Ter-rovitis et al., have extended the definition of k-anonymity for the privacy-preserving publication of set-valued data con-taining multiple entries for the same entity [15]. Verykios et al [16] considered the privacy of transactional data in the context of data-mining where they wanted to prevent subsets of association rules from being learned. The communication traces are set-valued and transactional in nature. However, communication trace anonymization is significantly differ-ent because conventional analysis cannot depend on subtle ordering and correlation among entries.

For the special case of network traces, anonymization has received special attention by researchers, with IP packet traces the most common case. Proposed anonymization techniques include tcpurify [3], the tcpdpriv [2] and Crypto-PAn [5] tools (which can preserve prefix relationships among anonymized IP addresses), as well as frameworks for defining transformations, such as tcpmkpub [10]. The focus of these works is on IP address anonymization and do not analyze the utility of the transformations.

Slagell et al [13] recognized the need for a framework to support the trade-off between the security and utility of traces and provide multiple levels of anonymization. The framework proposed in [8] tries to achieve such a balance between utility and privacy but it is restricted to secure queries with aggregations. In [9], the authors require an ana-lyst to write the analysis program in the language supported by framework, but it has to be reviewed by the experts for privacy issues. The PREDICT [1] repository has been es-tablished to make network traces available for research. The access to respository is authorized only after the purpose and identity of researchers is reviewed and verified manually. Acknowledgements: This work was supported by NSF CNS 0627642, NSF DUE 0830876 and NSF CAREER Award 0643681.
