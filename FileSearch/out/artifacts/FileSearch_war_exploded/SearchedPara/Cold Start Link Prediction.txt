 In the traditional link prediction problem, a snapshot of a s o-cial network is used as a starting point to predict, by means of graph-theoretic measures, the links that are likely to ap-pear in the future. In this paper, we introduce cold start link prediction as the problem of predicting the structure of a social network when the network itself is totally missing while some other information regarding the nodes is avail-able. We propose a two-phase method based on the bootstrap probabilistic graph . The first phase generates an implicit so-cial network under the form of a probabilistic graph. The second phase applies probabilistic graph-based measures t o produce the final prediction. We assess our method empiri-cally over a large data collection obtained from Flickr, usin g interest groups as the initial information. The experiments confirm the effectiveness of our approach.
 Categories and Subject Descriptors H.2.8 [ Database Management ]: Database Applications -Data mining General Terms Algorithms, Experimentation Keywords Link prediction, probabilistic graph, social net-works
Link prediction , introduced by Liben-Nowell and Klein-berg [15], refers to a basic computational problem underly-ing social network evolution in time. Given a snapshot of a social network at time t and a future time t  X  , the prob-lem is to predict the new friendship links that are likely to appear in the network within the time interval [ t, t  X  ]. As Liben-Nowell and Kleinberg state, the link prediction prob-lem is about to what extent the evolution of a social network can be modeled using features intrinsic to the network itsel f. Indeed, in their framework, they consider only the features that are based on the link structure of the network.
In this paper, we tackle a similar, but fundamentally dif-ferent problem, which we dub the cold start link prediction problem: similar because we also aim at predicting links, but different because we aim at doing this without any, even partial, knowledge of an existing link structure. Herein, we assume that either the social network explicitly exists, but i s kept secret by its owner, or it does not exist at all. In both cases, we are interested in predicting possible links among the users of a service by exploiting other types of information available, e.g., interest groups, tags, sales data.
Consider, for instance, a company C selling music online and a general-purpose social networking service S . Suppose C and S have made the following agreement: (1) S offers a functionality so that users can make reviews of their fa-vorite songs and these reviews are made available to their contacts, and (2) when a user clicks on a song title, the user is redirected to the corresponding page in C  X  X  website, but (3) S keeps the structure of its social network as a trade secret (this may be a mandatory constraint due to privacy regulations). Thanks to this agreement, users of S might influence each other to buy songs, and the easiest way for them to purchase songs would be through the website of C . In this scenario, C only owns information about the buying history of its customers, but has no explicit knowledge of the social network implicitly underlying its set of customers.
The question tackled herein is the following: can C nev-ertheless infer the social network (to an acceptable level of accuracy), just using the information contained in the sales history?
This would be useful for many reasons. First, it would enable adoption of viral marketing strategies [8, 14]. Sec-ond, it would facilitate social-network-based services, suc h as providing personalized advertisement. Third, if C de-cides, in the future, to adopt its own explicit social network, this may be used to recommend possible friends to users, thus speeding up the initial growth of the network.
In this context, we propose a two-phase method based on the bootstrap probabilistic graph for cold start link predic-tion. In the first phase, based on some limited information (potentially, weakly correlated with the link structure of t he network), the method predicts the existence of links. The output of this phase is a probabilistic graph, i.e., a graph where each edge is labeled with a probability representing the confidence of the prediction, or in other terms, the un-certainty of the existence of a link. The second phase takes as input the probabilistic graph and refines it by adopting graph-theoretic measures as done in the classical link pre-diction setting. The difference is that, in our case, the inpu t graph is probabilistic and hence the traditional measures must be adapted to deal with this case [18].

We apply our method to a large data collection obtained from Flickr, a popular online community for image and video sharing. We keep the existing social network (made of di-rected arcs 1 ) as the ground truth for the link structure that we aim to predict. As the available auxiliary information, we use users X  memberships in interest groups.

Three observations are note-worthy. First, the cold start link prediction problem is intrinsically a very difficult bi-nary prediction problem due to the skewness of the target variable. In fact, assuming directed arcs as in our context, given n nodes, we have a universe of n 2  X  n possible links, of which only a very small fraction exists in the ground truth. In our data, the positive class (existing links) constitutes approximately 0.07% of all possible links.

The second observation is that we apply our method start-ing with  X  X ittle X  information, which provides a very small coverage of existing links. Indeed, in Flickr, interest group membership 2 is a very weak predictor of links, as a group gathers people interested in photos regarding a specific sub -ject or technique (e.g.,  X  X ikon Selfportrait X  ,  X  X DR Panora-mas X  ,  X  X at and Dog: not Cat or Dog X  ), and they are not groups of friends or small communities (as it is mostly the case in Facebook groups). More precisely, in our data, con-sidering only the users who belong to at least one group, we have approximately 28M links, of which only 1 . 9% (approx-imately 550K links) are among two users that share at least one common group. Despite the difficulty of our prediction task, our two-phase method based on the bootstrap proba-bilistic graph can achieve good prediction performance.
Finally, it is very important to note that, even though the first phase features used herein are geared to group member-ship information, the overall framework we propose is gen-eral and applicable to any input information. In some cases, the available auxiliary information could be much more pre-dictive than the one used in our experiments or more infor-mation might be available. If this is the case, all available information should be used in order to bootstrap the prob-abilistic graph as accurately as possible.

Our contributions can be summarized as follows:
We use the terms arc and link interchangeably. http://www.flickr.com/groups
The rest of the paper is organized as follows. In the next section, we discuss related work. In Section 3, we present the formal definition of the problem and the proposed two-phase method. In Section 4, we describe the data we use for assessing our method, which is then developed in Section 5 (phase 1) and Section 6 (phase 2). Finally, in Section 7, we discuss future research lines and conclude the paper.
Liben-Nowell and Kleinberg [15] introduce the link pre-diction problem and show that simple graph-theoretic mea-sures, such as the number of common neighbors, are suf-ficient to efficiently detect links that are likely to appear in a social network. Through the use of more elaborated measures that consider the ensemble of all paths between two nodes (e.g., the Katz measure), they further improve the prediction quality. The graph features presented in Sec-tion 6 are inspired by Liben-Nowell and Kleinberg X  X  work but they are adapted to probabilistic graphs.

Taskar et al . [21] apply link prediction to a social network of universities. They rely on machine learning techniques and use personal information of users (music, books, etc.) to increase the accuracy of predictions. Following a simi-lar approach, O X  X adadhain et al. [17] focus on predicting events between entities and use the geographic location as a feature. Clauset et al. [6] apply link prediction to biol-ogy and physics using hierarchical models in order to detect links that have not been observed during experimentation. All these approaches rely on the availability of an initial link structure for prediction while the method we present addresses the cold start problem, i.e., the case where no ini -tial link structure is available.

Several probabilistic models such as Markov logic [7], rela -tional Markov networks [21], Markov random fields [5], and probabilistic relational models [12] have been used to effi-ciently capture the relation in data. Unfortunately, these approaches have not been proved to scale as they have been tested only on small data sets.

Van der Aalst et al. [22] extract a social network from logs of interactions between workers in a company. Similar works include mining email communications [3] and proximity in-teractions [9]. In each case, the authors start with a very dense graph and the idea is to identify the social network in this graph. The difficulty of the task is due to the huge amount of data. In our problem, we have the opposite situ-ation: the information used to generate the bootstrap prob-abilistic graph, which enables link prediction, is very spa rse. Hence, the information needs to be spread, not pruned.
Since we deal with reconstructing information that might be considered sensitive (the links of a social network), our work has privacy implications. In fact, our method can be used by an attacker to threaten link privacy in a social net-work, thus it can be used to test the resilience of anonymiza-tion solutions. Several papers [2, 13, 16] study the prob-lem of social network anonymization and the impact of the available knowledge on the inference of hidden information that should remain secret. Zheleva et al. [26] consider a so-cial network in which some users hide their information and others make it public. The applications presented include predicting the country of Flickr users through their group membership information. Their results indicate that group membership is a weak predictor.
We are given a set U of users and a multiset G of groups of users. We denote the set of groups to which a user u belongs to, m ( u ) = { g  X  G| u  X  g, g  X  U} , as her membership set . Our task is to reconstruct the links of a social graph N = ( U , A ), where the nodes are the users and the arcs A  X  U  X U represent a (one-way) relation between two users. Reconstructing the social network N means to predict which of the links in U  X  U actually exist in A , or in other terms, to build a function f : U  X  U  X  { 0 , 1 } .
We propose a two-phase method based on the bootstrap probabilistic graph for cold start link prediction. During the first phase, we predict the existence of links based only on the group membership information. The output of the first phase is the bootstrap probabilistic graph, i.e., a directe d probabilistic graph BPG =( U , E, p 1 ), where E  X  U  X U , and every link ( u, v )  X  E is labeled with a probability p 1 representing the confidence (or uncertainty) about the link X  X  existence, i.e., p 1 : U  X  U  X  [0 , 1].

In particular, after the first phase, we have p 1 ( u, v )=0 and p ( v, u )=0 for every user pair ( u, v ), where m ( u )  X  m ( v )=  X  . This is because if two users have no groups in common, a prediction cannot be made about the existence of a link between them. Moreover, we have p 1 ( u, v ) &gt; 0 for every user pair ( u, v ) such that m ( u )  X  m ( v ) 6 =  X  (this will also hold for the reverse arc ( v, u )). Links with null probabilities do not exist in BPG .

The second phase takes as input the bootstrap probabilis-tic graph BPG , and it refines the probability distribution p into a new probability distribution p 2 , by means of graph-based features. Therefore, the output of the second phase is a probabilistic graph PG = ( U , E, p 2 ). After the second phase, some links that previously had p 1 ( u, v ) = 0 can now possibly have a non-null score, p 2 ( u, v ) &gt; 0, thus extending the overall recall of the method.
In most real-world social networks, the links in a social graph A form only a small fraction of the total number of possible links, i.e., |A|  X  |U| 2 . This means that accuracy is not a very meaningful measure in this context, given that, by predicting always 0 (the link does not exist), it is possible to achieve an accuracy of 99.93% in our data. Also, com-paring different predictors by means of precision and recall is not very appropriate, given the very low maximum recall achievable (only 0.037 in our data). Therefore, in order to compare the performance of different predictive functions by eliminating the skewness between possible and existing links, we adopt the ROC curve metric [19] as the main way of presenting our results. For the best predictor of each feature group, we also provide recall/fallout ratios. Recall is the ratio between the number of true positives (correctly predicted existing links) and positives (existing links) while fallout is the ratio between the number of false positives (links erroneously predicted to exist) and negatives (not ex-isting links). Given a predictor function f , we may interpret recall and fallout as the following probabilities, respect ively: suppose to have recall / fallout = 8 for a predictor f . This means that for two users ( u, v )  X  X  for whom a link exists, it is 8 times more likely to have f ( u, v )=1 than for two users who are not connected.
Flickr is a highly popular online social network, whose primary objective is to facilitate sharing of images among people. In Flickr, a user can place other users in three priv-ilege classes: contact , friend , and family . Depending on the class, the user can restrict access to its properties (e.g., im-ages, videos). In this work, unless otherwise stated, we work on the contact class. In Flickr, links are directed. In our data, we found that approximately only 1 / 3 of the links are unidirectional. Most of the features we use in Section 5 are symmetric. This means that we predict the same likelihood for links X  existence in both directions.
We sample a subset of the entire Flickr social network by applying the snowball sampling strategy, starting from a single, highly connected seed user and following the contac t links between users in an iterative manner. The adopted sampling strategy increases the chance of selecting more ac -tive users, who have higher connectivity in the network (i.e. , more links). In our case, this is desirable as users with few or no friends are relatively less interesting for our predic tion task. For each user in the sample set, we store all links and groups associated with the user as well as some other infor-mation in a MySQL database for latter processing. From the sampled set of users, we remove the ones who are not members of any group. This is because the proposed tech-niques are applicable to users who have at least one group membership.
After the above-mentioned pruning, we are left with 198,315 users. The type and number of existing links are reported in Table 1. The same table (second line) also re-ports how many of these existing links are among two users that have at least one common group: this is the maximum number of links predictable in the first phase, or in other terms, links for which we will have p 1 ( u, v ) &gt; 0. In the sec-ond phase, we use measures based on paths formed by the links between users. This means that we cannot predict the existence of a link between two users, each belonging to a different connected component of the bootstrap probabilis-tic graph. The maximum number of links predictable in the second phase is also reported in Table 1 (the third line). The number of groups we have is 69,793. Various properties of our dataset are displayed in Table 2. Table 3: Features evaluated in the bootstrap phase
According to Fig. 1 (left), the frequency of group sizes follows a highly skewed distribution, i.e., there are few, v ery large but many, very small groups. 35 . 3% of groups have only one member. Groups of size less than 3 constitute about half of the total number of groups. Frequency distribution for group membership is even more skewed. 47 . 0% of users are members in only one group. The number of users who are members in at most 10 groups constitutes 95 . 6% of the total number of users. A highly skewed distribution is also observed in frequency of users X  link counts (Fig. 1 (right)).
In the first phase, we bootstrap the probabilistic graph using the group membership information. In particular, we explore four types of features: number of groups , number of common groups , size of common groups , and difference in joining time . Since, in this phase, the probabilities are assigned to only the links between users who share at least one group, in the rest of this section, we report ROC curves computed only on this subset of links. For the recall/fallout curves, we instead use the whole dataset, as this gives a better idea about the discriminative power of a feature. Throughout this section, the reader may refer to Table 3 for definitions of the features. We denote by c ( u, v ) the set of groups that are common to both users u and v , i.e., c ( u, v ) = m ( u )  X  m ( v ). The absolute value of the difference in time that u and v joined group g is denoted by t ( u, v, g ).
The number of groups of a user might be a good indicator of the user X  X  level of engagement and activity in the social network. As the user is more active, he may tend to have more links. Fig. 2 shows how the number of links of a user Figure 1: (Left) Frequency distributions for group membership and group size. (Right) Frequency dis-tribution for the number of links that users have. changes as the number of group memberships increases. We observe a very linear behavior, which may indicate a correla-tion between the number of groups and the number of links. We also observe that the number of out-links increases at a slightly faster rate than in-links as users join more groups.
We evaluate two features based only on the number of groups. Given two users u and v , we define sum and prod , respectively, as the sum and product of | m ( u ) | and | m ( v ) | values. Obviously, as the feature values increase, the like-lihood of having a link increases. In Fig. 3, we report the recall/fallout ratio for different thresholds of prod . The plot gives an indication of how predictive the feature is. As an example, for two linked users u and v , it is 200 times more likely to have | m ( u ) | X | m ( v ) | X  1000 than two users without a link.

Fig. 4 shows the ROC curves for the two features: accord-ing to the plot, the performances of sum and prod are very close, but prod performs slightly better.
Intuitively, being a member of the same groups should be a strong indicator of the existence of a possible link. An active group member may influence his existing friends to join the group as new members. This means that members of the same group are more likely to have existing friendship links among themselves. From another perspective, groups may be a suitable medium to meet other users and form friendships, thus groups may lead to creation of new links.
Fig. 5 verifies this hypothesis by measuring the fraction of links among users having membership in the same groups. Specifically, for each value x of common groups, we compute As expected, the fraction of links increases as the users have more groups in common.

Fig. 6 reports the recall/fallout curve for different number s of common groups. We can observe that for two linked users, the probability of having more than 10 common groups is approximately 600 times larger than for two users that have no link. This number grows to 1800 for the probability of having no less than 24 common groups.

We evaluated five different features based on common groups: overlap , which is the number of common groups; frac_1 and frac_2 , which are the overlap normalized by Figure 2: Indegrees and outde-grees of users as their number of group memberships increases.
 Figure 5: Fraction of links between user pairs as their number of com-mon groups increases.
 the number of groups of the first and second users, respec-tively; jaccard , which is the Jaccard coefficient; and cos , indicating the cosine similarity commonly used in informa-tion retrieval. ROC curves of these five features are shown in Fig. 7. Interestingly, we observe that all features except for overlap perform worse than random prediction, which would correspond to the diagonal of the plot. This can be easily explained with the very high number of pairs of users being members of only one group. When two of such users are part of the same group, they receive the maximum value of frac_1 , frac_2 , jaccard , and cos although these two users are very likely to be not linked. We observed this ef-fect also for variations of these features, such as the weigh ted cosine similarity feature (using tf-idf weighting), and al so for some other features with normalization.
It can be claimed that two users are more likely to be friends if they are members of a small group than a large group as 1) group founders are more likely to prefer their friends over other users in invitations they send and 2) large groups are more likely to be general-purpose groups, attrac t-ing different users with equal likelihood. We verify this clai m in Fig. 8, which shows the density of links with increasing group size. The link density is computed as where the average link count for groups of size x is normal-ized with the maximum possible link count ( x  X  ( x +1)).
For contact and friend links, we observe a significant drop in density values at very small group sizes, followed by a linear drop as the group size increases. The density of famil y links is not affected much by the increase in the group size, potentially, due to the very low number of such links.
We try four different features based on the size of com-mon groups: min_s and avg_s denote the minimum and the average size of the common groups, respectively; the sum-mation of the reciprocal of size is denoted by sum_rec_s ; and Adamic/Adar-size is denoted by ad_ad_s . The last feature is inspired by the measure defined by Adamic and Adar in [1] for deciding when two personal home pages are strongly re-lated, and then borrowed and adapted by Liben-Nowell and Kleinberg [15] to deal with common neighbors in the context of link prediction. Here, we re-adapt this measure to deal with the size of common groups and compute Figure 8: Link density within a group as group size increases.
 Figure 11: Fraction of links with varying inter-arrival time.
 The recall/fallout curve for ad_ad_s is displayed in Fig. 9. We observe that the probability of having ad_ad_s ( u, v )  X  1 for an existing link ( u, v ) is approximately 200 times larger than for a non-existing link ( u, v ), and the ratio keeps grow-ing almost linearly.

Fig. 10 shows that features that are based on group size perform quite well, with ad_ad_s outperforming the others.
In the last set of features, we investigate the temporal coherency between linked users joining the same group. We may expect that friends are likely to inform each other from existence of a group just before (or just after) joining it. Hence, we may expect that linked users are likely to join the same group with small time gaps (inter-arrival time).
Fig. 11 shows the fraction of links with increasing inter-arrival time. For each possible inter-arrival time value x (discretized into days), we compute |{ u,v  X  X  , g  X  X  | ( u, v )  X  X   X  x = t ( u, v, g )  X  g  X  c ( u, v ) }|
According to the figure, as expected, linked users are more likely to join the same group with a small inter-arrival time . It is interesting to note that an increase is observed in the likelihood of having a link, around a year inter-arrival time. This may be explained by the existence of X  X easonal X  X roups, i.e., groups that refer to events held once per year and that attract new members in that period (e.g.,  X  X lastonbury Fes-tival X  or  X  X hristmas Worldwide X  ).

As the features, we try the same feature set we used for the group size, simply by replacing group size with inter-arrival time: min_t , avg_t , sum_rec_t , and ad_ad_t . As in the case of group size features, Adamic/Adar-time ( ad_ad_t ) performs the best among all features of this class (Figs. 12 and 13). The irregular shape of the ROC curve as well as of the recall/fallout curve are due to the seasonal behavior discussed before.
Next, we try to combine a number of features from pre-vious sections to create a single, hybrid feature with higher predictive power than the basic features. For this purpose, we evaluate various possible combinations of our best per-forming features, trying to find a good trade-off between pre-dictive power and simplicity (which also translates to gen-erality). The best performing combination turns out to be ad ad s  X  ad ad t  X  log prod , referred to as combined .
An important observation is that the features ad_ad_t , ad_ad_s , and prod perform relatively well for high, medium, and low confidence intervals, respectively. This is the rea-Figure 14: ROC curves for the best feature from each category and the best combined feature.
 son for the combined feature, which unifies them, to perform the best across all intervals. No features from the class usi ng the number of common groups is directly used in the com-bined feature as this is subsumed in the two Adamic/Adar features, which compute a sum over all common groups.
Fig. 14 compares combined against the best-performing feature from each of the four categories. We use combined to bootstrap the probabilistic graph, as shown next.
So far, we have proposed various measures and evaluated their predictive power. We have then combined them un-der a simple but yet effective feature. We now finalize the first phase of our method by producing the bootstrap prob-abilistic graph. To this end, we need to convert the scores provided by the combined feature into probabilities. This is a mandatory step to be able to combine the values of the edges in a meaningful way.

Converting scores to probabilities is not straightforward since the relation between them is often not linear. This problem has been studied for different kinds of classifiers [11 , 23, 24, 25], but with score distributions different from the one we observe in our case.

In Fig. 15, we observe a logarithmic shape in the distri-bution of probabilities with respect to scores. Using a curv e fitting algorithm, we could map the function to the data, but depending on the feature used, this mapping could be completely different. In our case, to remain general, we just assume the knowledge that it follows a logarithmic distribu-tion. We design a very simple function that maps the highest score output by the combined feature to a probability of 1 and assigns the remaining probabilities as Fig. 15 shows that our simple approximation is very rough. However, it is good enough as it will be shown in the next section. The probability distribution in the bootstrap pro b-abilistic graph is reported in Fig. 16. The graph consists of 1,238 connected components, of which 42 have more than 1,000 nodes, 10 have more than 5,000 nodes, and the largest connected component has more than 20,000 nodes.
In the first phase of our method, we have predicted, for some pairs of users, the probability to have a link. In the second phase, we refine and extend this prediction by consid-ering transitivity of contact relationship. As shown in [15] , users who have many common contacts are more likely to be friends. Using graph-based features, we can spread the link prediction to pairs of users who have no common groups but share contacts. Therefore, we compute graph-based mea-sures on the bootstrap probabilistic graph for all pairs of users who are in the same connected component. If two users are not connected by a path in the probabilistic graph, then they will have a null probability also after phase 2. In the following, we adapt to the probabilistic case three graph-based measures that are reported to perform well in [15]: common_neighbors , katz , and rooted_pagerank .
Having a high number of common contacts may be an indication of the existence of a link. We adapt this idea to our probabilistic graph in a straightforward way. For a given user pair ( u, v ), common_neighbors simply computes the sum of the probability that each node is connected to both u and v , i.e., A consequence of this definition is that all pairs of users who are more than two hops away in the graph are assigned a zero score. Recall that the probability p 1 computed in the first phase is symmetric, i.e., p 1 ( u, v )= p 1 ( v, u ).
The Katz measure computes a score between two users based on the number of paths existing between them, ex-ponentially damped by length to count short paths more heavily. In other words, a path of length  X  is weighted by  X  , where 0  X   X   X  1. We adapt this measure to deal with probabilistic graphs by further weighting each path by its existence probability, which is the product of the probabili -ties of the links that compose it. Figure 17: ROC curves for the common_neighbors .

Let path h  X  i u,v be the set of paths of length  X  between u and v in U and pathProb ( h ) be the existence probability of a path h . Then, katz is computed as
The rooted_pagerank feature computes a score between nodes u and v by running rooted PageRank, starting from u . We use an algorithm [10] based on random walks to get an estimation of PageRank scores. Inspired by [18], we adapt it to our probabilistic graph by sampling existing links at each step of a walk using the probabilities in the graph. The walk continues using an existing edge chosen at random as in the classic unweighted version of PageRank. We set a stopping probability  X  and run W walks for each node. rooted pagerank ( u, v ) is not null if at least one walk start-ing at u reaches v . Thus, a user u potentially has a positive score with all other users in his connected component. How-ever, if the number of walks and link probabilities are both very low, this may not be the case. If u and v are not in the same component, then the link ( u, v ) receives a null score.
We evaluate the three features by comparing our method based on the bootstrap probabilistic graph (BPG) with two alternative methods. These methods work on deterministic graphs (DG) obtained from BPG, by selecting only the links with a probability higher than a given threshold. Note that since the probability function we designed is monotonic, th is is equivalent to a score threshold. It is also worth noting tha t using a high threshold would compromise seriously the recal l of the method. Indeed, a larger threshold implies that fewer links will be selected, which in turn implies a smaller densit y for the resulting graph and thus a large number of small com-ponents. Since graph-based features produce scores only fo r pairs of users belonging to the same connected component, using a large threshold would give very small recall. There-fore, for the two alternative methods, we use 0 and 0 . 005 as the thresholds. The methods are accordingly named as DG 0 and DG 0.005. While DG 0 can achieve the same re-call as BPG, DG 0.005 can only predict a smaller number of links due to the lower density as discussed above. Fig. 17 displays the ROC curves for common_neighbors . Despite its simplicity, common_neighbors performs quite well with BPG as seen from the sharp rise in the true pos-itive rate for predictions with high confidence (early data points). The ROC curve of DG 0 remains always under the curve of BPG. DG 0.005 produces results closer to BPG, but at the price of a lower recall. In the figure, some por-tion of the curves are not displayed for better visibility of the rest (the last data point is (0 . 607 , 0 . 953) for DG 0 and BPG curves).

For katz , following [15], we set  X  to 0 . 005. For scalability reasons, we also set an upper bound on the path length. Since BPG is quite dense, the number of paths becomes important for large values. As  X  is small and thus long paths have very little weight, the impact on precision is negligib le. In our experiments, pairs that are more than two hops away in BPG receive a zero score. Fig. 18 shows the performance of katz . BPG still outperforms DG 0 and DG 0.005, but the gap is small, relative to common_neighbors .

For experiments on rooted_pagerank , we set  X  to 0.15 and W to 1000. According to the ROC curves shown in Fig. 19, rooted_pagerank performs poorly, relative to com-mon_neighbors and katz , in terms of both coverage of pre-dictions and their quality. Increasing W does not have a significant effect on the result quality, but it increases the coverage of predictions. We believe that rooted_pagerank can be efficiently applied on a given user to sort the other users by contact probability. However, the scores obtained through this measure are not comparable across different users. This is due to the fact that PageRank shares a fixed, total score among all users. A user with many potential neighbors is assigned a score lower than a more isolated one, resulting in poor quality predictions at a full graph scale.
Fig. 20 brings together the ROC curves for the combined feature and the three phase 2 features (assuming the BPG scenario). The plot demonstrates the gain achieved by phase 2 over the results of phase 1. The performance of katz is seen to be very close to common_neighbors .

As a representative, Fig. 21 shows the precision X  X ecall plo t for the katz feature. BPG achieves pretty high precision values relative to DG 0 and DG 0.005 under the equal recall constraint. Despite the difficulty of the problem, precision and recall values achieved by BPG indicate the validity of the proposed method (e.g., at a recall of 1%, we observe a precision around 31%). Figure 20: ROC curves for the three phase 2 features and the com-bined feature from phase 1.
 Figure 23: ROC curves for the common_neighbors (friends).

As another representative, Fig. 22 shows the recall/fallou t curve for the common_neighbors feature. BPG is able to leverage the low probability edges to increase recall with-out losing precision while non-probabilistic approaches e i-ther prune this noise and lose recall or use these edges but suffer from low precision.

We have also conducted experiments using friend links in-stead of contacts. We do not report results for family links due to space limitations. Figs. 23, 24, and 25 show perfor-mance of common_neighbors , katz , and rooted_pagerank , respectively, in predicting friend links. For all three tech -niques, higher prediction quality is achieved relative to con -tact links.

In this work, we have preferred not to combine the pre-dictive power of the three features of phase 2 (e.g., by means of machine learning techniques). The rationale be-hind this choice is two-fold. First, as we have explained before, rooted_pagerank is not suitable for prediction at a full graph scale. Second, common_neighbors can be seen as a special case of katz in which the maximum path length is 2 and  X  is set to 1. Therefore, we expect only little improve-ment in prediction accuracies by further combinations.
We presented the cold start link prediction problem and a two-phase method that enables link prediction in the ab-sence of a social network. The first phase of the proposed method generates a bootstrap probabilistic graph using any available feature while the second phase applies various li nk prediction algorithms to this probabilistic graph. We test ed our approach over a data set obtained from Flickr, by using group memberships as the only available information.
For the sake of generality, we applied our method to inter-est groups, a very simple and common kind of information in social networks. Thus, the features we present can be applied to other networks. Obviously, as more information is available, higher prediction accuracies can be achieved .
In the context of Flickr, we might use information that is more specific to photography in order to improve predic-tion performance. For instance, in [20], Singla and Weber study the impact of the social network on camera brands of Flickr users. We could leverage such information to create more accurate predictors. Similarly, as observed in [4], in -formation diffusion often follows the social network. This is known as the social cascade phenomena and can be observed in Flickr when users favorite others X  pictures and post com-ments about them. If this information is available, it can be used as a bootstrap feature to generate a probabilistic soci al graph that matches the observed social cascade.

As pointed in Section 2, we believe that our method can be applied as an attack against link privacy in social networks. Determining to which extent our approach can be combined with existing attacks to improve the predictive power of pub-licly available attributes is worth future research.
In this work, we have adapted the graph-theoretic algo-rithms in [15] to probabilistic graphs. Potamias et al. [18] introduces different measures of distances in probabilisti c graphs and present algorithms to compute k -nearest neigh-bor queries. We believe that probabilistic graphs are a pow-erful tool and designing algorithms to extract their charac-teristics can create new approaches also to other research problems. [1] L. Adamic and E. Adar. Friends and neighbors on the [2] L. Backstrom, C. Dwork, and J. Kleinberg. Wherefore [3] J. Baumes, M. Goldberg, M. Hayvanovych, [4] M. Cha, A. Mislove, and K.P. Gummadi. A [5] R. Chellappa and A. Jain. Markov random fields: [6] A. Clauset, C. Moore, and M. Newman. Hierarchical [7] P. Domingos and M. Richardson. Markov Logic: A [8] Pedro Domingos and Matt Richardson. Mining the [9] N. Eagle and A. Pentland. Reality mining: Sensing [10] D. Fogaras, B. R  X acz, K. Csalog  X any, and T. Sarl  X os. [11] Jing Gao and Pang-Ning Tan. Converting output [12] L. Getoor, N. Friedman, D. Koller, and B. Taskar. [13] Michael Hay, Gerome Miklau, David Jensen, [14] David Kempe, Jon M. Kleinberg, and  X  Eva Tardos. [15] D. Liben-Nowell and J. Kleinberg. The link-prediction [16] A. Narayanan and V. Shmatikov. De-anonymizing [17] J. O X  X adadhain, J. Hutchins, and P. Smyth.
 [18] Michalis Potamias, Francesco Bonchi, Aristides [19] Foster J. Provost, Tom Fawcett, and Ron Kohavi. The [20] A. Singla and I. Weber. Camera brand congruence in [21] B. Taskar, M.F. Wong, P. Abbeel, and D. Koller. Link [22] W.M.P. Van Der Aalst, H.A. Reijers, and M. Song. [23] Bianca Zadrozny and Charles Elkan. Obtaining [24] Bianca Zadrozny and Charles Elkan. Transforming [25] Jian Zhang and Yiming Yang. Probabilistic score [26] E. Zheleva and L. Getoor. To join or not to join: the
