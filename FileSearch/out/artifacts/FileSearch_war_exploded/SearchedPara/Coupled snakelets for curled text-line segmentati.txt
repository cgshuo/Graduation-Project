 ORIGINAL PAPER Syed Saqib Bukhari  X  Faisal Shafait  X  Thomas M. Breuel Abstract Camera-captured, warped document images usu-ally contain curled text-lines because of distortions caused by camera perspective view and page curl. Warped document images can be transformed into planar document images for improving optical character recognition accuracy and human readability using monocular dewarping techniques. Curled text-lines segmentation is a crucial initial step for most of the monocular dewarping techniques. Existing curled text-line segmentation approaches are sensitive to geometric and perspective distortions. In this paper, we introduce a novel curled text-line segmentation algorithm by adapting active contour (snake). Our algorithm performs text-line segmenta-tion by estimating pairs of x-line and baseline. It estimates a local pair of x-line and baseline on each connected compo-nent by jointly tracing top and bottom points of neighboring connected components, and finally each group of overlap-ping pairs is considered as a segmented text-line. Our algo-rithm has achieved curled text-line segmentation accuracy of above 95% on the DFKI-I (CBDAR 2007 dewarping contest) dataset, which is significantly better than previously reported results on this dataset.
 Keywords Curled text-line segmentation  X  Page segmentation  X  Camera-captured document image processing 1 Introduction Text-line segmentation is one of the important layout analysis steps in document image understanding systems. It is usually applied before feeding text to an optical character recognition (OCR) system. Text-lines information can also be used for implementing most of the other document image processing tasks such as binarization [ 1 ], document cleanup [ 2 ], skew correction [ 3  X  5 ], zone segmentation [ 6 ], indexing/retrieval bas on word and character recognition [ 7 ], dewarping of camera-captured warped document images [ 8 ]. Dewarping is relatively a new document image pre-processing step when compared to others which are mentioned here. It is a pro-cess of rectifying camera-captured document images that suffer from perspective and geometric distortions. It can be done either by applying stereo vision techniques [ 9 ]orby using monocular dewarping techniques [ 8 ] X  X  dewarping technique that is developed for images which are captured by single camera is called a monocular dewarping technique. Most of the stat-of-the-art monocular dewarping methods are based on text-line segmentation.
 Documents are traditionally digitized using scanners. When a page containing straight, horizontal text-lines is scanned, the resulting scanned image may have horizontal or skewed text-lines owing to the paper positioning distor-tions introduced by the scanning process, as shown in Fig. 1 . These types of document images are referred to as planar document images. There is a large number of state-of-the-art techniques for planar document image segmentation [ 10 ], such as projection profile [ 11 , 12 ], Hough transform [ 13 ], run-length smearing [ 14 ], Docstrum [ 6 ], branch and bound method [ 15 ]. Most of the commercial and open-source OCR systems work on the assumption that input document images are planar in nature.

Nowadays cameras are available widely at low cost and offerfast,flexible,andnon-contactdocumentimaging.These advantages make cameras a potential substitute of scanners for document digitization. Liang et al. [ 16 ] presented a brief comparison between scanners and cameras and concluded that camera-based document analysis systems are more flex-ible than scanner-based systems. The camera-captured docu-ment image of a planar document surface is shown in Fig. 2 a, where the captured image looks like a scanned image.
However, some image degradations come along with the flexibility of using digital cameras for document imaging. For a planar document surface, a digital camera can produce a distorted image due to perspective distortion that arises from the perspective viewpoint of the camera, as shown in Fig. 2 b. Furthermore, for a thick book page, a digital camera can produce a distorted image because of geometric distor-tion that is caused by the curled document surface. In such a case, the distorted image is composed of curled text-lines with multiple skew angles as shown in Fig. 2 c. Therefore, the quality of camera-captured document images generally declines due to perspective and/or geometric distortions.
Camera-captured document images that contain perspec-tive and/or geometric distortions are usually called warped document images . The main problem with a warped docu-ment image is that it reduces not only human readability, but also causes problems for document image processing, like layout analysis and character recognition. Consequently, dewarping is a necessary step in camera-captured docu-ment image processing. Most of the monocular dewarping techniques are based on text-line information [ 8 , 17  X  22 ]. Therefore,text-linesegmentationisanimportantstepincam-era-captured document image processing.

A text-line is composed of different typographic lines, i.e., ascender-line, x-line, baseline, and descender-line. For each connected component in a text-line, we defined its top point as the coordinate of its top most pixel and bottom point as the coordinate of its bottom most pixel. These terms, being fre-quently used in the rest of this paper, are illustrated in Fig. 3 for a sample text-line.

Curled text-line detection in warped, camera-captured document images (Fig. 2 c) is a challenging problem. Pla-nar document image segmentation techniques, like Doc-strum [ 6 ], X X  X  cut [ 12 ] cannot be robustly applied for curled text-line segmentation [ 23 ]. For example, Docstrum is one of the state-of-the-art and widely used planar/straight docu-ment image segmentation algorithms, but it performs poorly on warped document image segmentation as shown in Fig. 4 .
In recent years, several curled text-line finding methods are proposed in the literature [ 17  X  20 , 22 , 24  X  28 ] mainly in the context of monocular dewarping approaches. Most of these methods use nearest-neighbor X  X ased grouping of connected components for detecting text-lines, but these methods usually produce undersegmentation failures in the presence of high degree of curl/skew in document images. Another general observation about the previous approaches is that they estimate x-line and baseline pairs after segmenting text-lines by using regression over top and bottom points of seg-mented text-lines, respectively, that may result in inaccurate estimation. A brief overview of these methods is given in Sect. 2 .

In this paper, we present a curled text-line segmentation method applying active contours (snakes) [ 29 ]. We adapt snakes for estimating a local pair of x-line and baseline at each connected component in a document image, where each connected component may represent a character, a bro-ken piece of a character, or a bunch of joined characters. Afterward, each group of overlapping pairs is considered as a segmented text-line that also provides x-line and base-line information of the segmented text-line. Our curled text-line segmentation method is less sensitive to high degree of curl and skew in document images and produces better segmentation results than previous curled text-line segmen-tation approaches as shown in the performance evaluation section (Sect. 5 ). Furthermore, unlike other approaches, our algorithm performs segmentation of text-lines and estima-tion of their x-lines and baselines together at the same time, which also gives more precise x-lines and baselines informa-tion than regression-based methods.

Our text-line detection algorithm is designed for hand-held camera-captured images of isolated or bound pages that contain straight text-lines of typed-text Latin script. As men-tioned earlier, hand-held camera-captured images usually suffer from perspective distortion (due to camera view angle) and/or geometric distortion (due to curled document sur-face).Therefore,straighttext-linesindocuments(asshownin Fig. 2 a) are transformed into skewed and/or curled text-lines in camera-captured images (as shown in Fig. 2 b, c, respec-tively). Our algorithm can handle skew and/or curl angle up to  X  45  X  . It can also deal with variable character sizes within a document image with a minimum (average) character size (length/height) of 10 pixels. Our algorithm can also work in the presence of figures, tables, equations, and noise.
Part of the work presented in this paper was published in [ 30 ] for timely dissemination of this work. This paper is a substantially extended version of the previous conference publications. Here, we have described the method in more detail. We have also done an extensive experimental eval-uation of our method and its comparison with other state-of-the-art techniques.

The rest of this paper is organized as follows. A brief description of previous curled text-line segmentation approaches is presented in Sect. 2 . Our coupled snakelets model is described in Sect. 3 . Implementation details of our curled text-line segmentation algorithm applying coupled snakelets model are presented in Sect. 4 . Performance evalu-ation and experimental results are given in Sect. 5 , followed by a conclusion in Sect. 6 . 2 Related work Several curled text-line segmentation approaches are pro-posedintheliterature[ 17  X  20 , 22 , 24  X  28 ]forcamera-captured warped/curled document images. Most of these curled text-lines extraction approaches are mainly proposed as a pre-processing step of monocular dewarping of camera-captured document images. Some of these approaches are briefly dis-cussed here.

Goto and Aso [ 24 ] proposed a text-line segmentation method for a document image that may contain curved text-lines with arbitrary orientations. Their algorithm is based on linking of locally linear components. First, the primitive rectangles are estimated from the connected components of a document image. Then, these rectangles are grouped together on the basis of a predefined criteria to achieve segmented text-lines.

Zhang et al. [ 17 ] introduced a curled text-line finding algorithm using box-hand [ 31 ] approach. In this algorithm, connected components are first combined to form words using nearest-neighbor analysis. Then, a pair of left and right rectangular box-hands are attached with each word. Each chain of overlapping words is considered as a segmented text-line.
Loo and Tan [ 25 ] proposed a word and sentence extraction method for a document image that may contain a wide vari-ety of text-line orientations and layouts. Their algorithm is based on the irregular pyramid structure that help in merging characters into words and then words into sentences.
Lu and Tan [ 18 ] proposed a curled text-line segmenta-tion approach, where top and bottom points of connected components are first estimated by using morphological oper-ations. Then, text-line detection is performed by tracking either top or bottom points. For a point, left and right near-est-neighbors are searched and this process is repeated for neighbors until no more neighbor is found. The same process is repeated for remaining points. Each group of connected components is considered as a segmented text-line.
Gatos et al. [ 19 ] proposed a smearing-based curled text-line detection algorithm. In this approach, horizontal run-length smearing is used to combine characters into words. The height corresponding to the maximum peak of connected components X  height histogram ( H ) is used as a threshold for smearing. After smearing, left and right neighboring words are searched for each word within a limited distance ( D ) such that D &lt; 5 H , and the search is repeated until no more neigh-bors are found. The same process of grouping words together is repeated for the remaining words. Each group of words is referred to as a segmented text-line. We have observed that the algorithm works well on clean document images where the parameter H can be reliably estimated. However, in the presence of salt-and-pepper noise or a large number of bro-ken characters, the estimated value of H is usually too small. This badly affects the performance of their algorithm. We have proposed a slight modification in this algorithm such that if H is less than a predefined threshold ( T ), all values less than T are removed from the height histogram and the height corresponding to the maximum peak of the remain-ing histogram is selected as H .Thevalueof T can be set equal to the mean height of a character in a targeted dataset of document images.

Fu et al. [ 20 ] proposed a curled text-line segmentation technique using nearest-neighbor analysis over text-lines portions. In this approach, portions of text-lines are first estimated using wavelet-based enhancement technique [ 32 ]. These portions are then grouped together using nearest-neighbor approach, where each group is considered as a seg-mented text-line.

An active contour-based baby-snakes curled text-line seg-mentation algorithm is introduced by Bukhari et al. [ 26 ] that is different from coupled snakelets algorithm presented in this paper. Active contour (snake) [ 29 ] is one of the state-of-the-art photographic image segmentation techniques. Baby-snakes algorithm adapts active contour for curled text-line segmentation. In this algorithm, an input image is first smeared by using morphological operations. Then, open-curve slope-aligned snakes are initialized over the smeared connected components, which are called  X  X aby-snakes X . External energy using gradient vector flow (GVF) [ 33 ]is then calculated from smeared document image. This energy is used for baby-snakes deformation. After a few number of deformation steps, neighboring baby-snakes are joined together. Each group of joined snakes is considered as a seg-mented text-line.

Bukhari et al. [ 27 , 28 ] also introduced another curled text-line detection technique for grayscaling camera-captured document images, which can be equally applied on binary imagesaswell.Inthisapproach,Gaussianfilterbanksmooth-ing is first applied over a document image for enhanc-ing/smoothing its text-lines structure. Then, ridge detection method is applied on the smoothed image. Each detected ridge represents a segmented text-line.

Oliveria et al. [ 22 ] proposed a rule-based method for warped text-line segmentation. In this algorithm, a same-size nearest-neighbor is found for each connected compo-nent. All pairs are added into a priority-queue . Then, for each pair, nearest-neighbors are iteratively searched in both right and left directions using moving-window analysis which holds the following conditions: same-size , smaller than win-dow , in-between parallel line with offset , and distance is less than maximum distance between letters . Each group of con-nected components is referred to as a text-line. Afterward, detected text-lines are further improved by using the follow-ing steps. Each text-line is selected one by one in a decreasing text-line X  X  length priority order, and upper and lower text-lines are searched for its each component. Two upper and/or lower text-lines are merged together if they satisfy some pre-defined thresholding criteria. The final step is the removal of those text-lines that contain connected components less than some predefined threshold or contain connected compo-nent on 10% of image border. Together with some predefined threshold, all of the above italicized terms are defined using some empirically selected values.

Most of the above curled text-lines segmentation meth-ods (like [ 17  X  19 , 24 , 25 ]) are based on grouping of connected components using some predefined nearest-neighbor criteria. The main limitation of a nearest-neighbor-based curled text-line finding method is that it can only handle a moderate skew/curl angle, and it produces a number of over-and un-dersegmentation errors under a high degree of skew/curl. In contrast to nearest-neighbor-based text-line finding methods, our proposed method comparatively produces less number of undersegmentation errors. In baby-snakes method [ 26 ], the length of baby-snakes is a sensitive parameter; the method produces large number of oversegmentation errors for a small length and large number of undersegmentation errors for a comparatively big length. When compared to baby-snakes method, our presented method does not contain that prob-lem and results in a small number of oversegmentation and undersegmentation errors. The curled text-line segmenta-tion method of Oliveria et al. [ 22 ] performs well even in the presence of high degree of skew/curl, but it contains a large number of free parameters. Our proposed method con-tains around six free parameters, where most of them are non-sensitive. We have compared the performance (Sect. 5 ) of our coupled snakelets-based curled text-line segmenta-tion method with: (i) nearest-neighbors (Gatos et al. [ 19 ]), (ii) baby-snakes (Bukhari et al. [ 26 ]), (iii) ridges detection (Bukhari et al. [ 27 , 28 ]), and (iv) rule-based (Oliveria et al. [ 22 ]), and (v) Docstrum [ 6 ]. The main reason of selecting these method for comparison is to show the performance of different categories of curled text-line detection techniques on a common dataset. 3 Coupled snakelets for curled text-line segmentation Coupled snakelets model for curled text-line segmentation is based on active contour (snake) [ 29 ], which is one of the state-of-the-art image segmentation techniques in com-puter vision. First, a brief description of basic active con-tour (snake) model is presented in Sect. 3.1 , and then salient features of our coupled snakelets model are explained in Sect. 3.2 . 3.1 Review of active contours (snake) model Active contour (snake) was introduced by Kass et al. [ 29 ] for image segmentation. A snake is a closed-curve of points S ( s ) =[ x ( s ), y ( s ) ] , where s  X  X  0 , 1 ] , that moves through the spatial domain of an image to minimize the energy function ( E ): E = E =
The snake slithers toward a targeted object under the influ-ence of internal energy ( E int ) and external energy ( E where the internal energy is estimated from the snake points, and the external energy is computed from image contents. The internal energy tries to keep the snake X  X  points close to each other and the external energy tries to move the snake toward the boundary of a targeted object. These internal and external energies are defined in such a way that the snake deforms iteratively toward a targeted object and finally wraps around the object X  X  boundary. Internal energy is further decomposed into two factors: (i) S ( s ) (first-order derivative of S ( s ) ) represents tension within snake X  X  points, (ii) S (second-order derivative of S ( s ) ) represents rigidity within snake X  X  points. The weighted parameters  X  and  X  are used for controlling snake X  X  tension and rigidity, respectively. The snake remains more rigid for a big value of  X  thanasmall value.

The wight of the external energy can also be controlled by a free parameter that can take a value in between 1 to 0. In this paper, we have defined this parameter as  X  .TheEq. 1 can be rewritten as: E =
In general, external energy can be calculated from the edge map of an image by using gradient, Gaussian of gradi-ent or gradient vector flow (GVF) [ 33 ]. The gradient vectors or Gaussian of gradient vectors have large magnitudes only in the immediate vicinity of the edges; but these vectors are zero in homogeneous regions where image data are nearly constant. Therefore, the range of gradient or Gaussian of gradient-based external energy is limited and it only exists near the edges. In such a case, manual assistance is required for initializing snake near a targeted object. In contrast to these types of external energies, GVF is calculated by using the computational diffusion of gradient vectors iteratively, where it maintains the gradient vectors near the edges and at the same time extends these vectors farther away from the edges into homogeneous regions. Therefore, GVF covers a large range of energies (gradient vectors) around edges that helps to diverge the snake toward the boundary of a targeted object even if it is initialized far away from the object. In such a case, manual assistance is not required for snake ini-tialization.

A simple toy example to illustrate the basic concept of object X  X  boundary detection using active contour (snake) is illustrated in Fig. 5 . Traditional active contour mechanism of image segmentation, which is illustrated in Fig. 5 , cannot be directly applied for text-lines segmentation in document images as shown in the Fig. 6 . In this paper, we adapt active contour (snake) for text-line segmentation. For this purpose, we introduced a coupled snakelets model that is derived from active contour (snake) model. Detailed discussion about coupled snakelets model is given in the next section (Sect. 3.2 ). 3.2 Coupled snakelets model We have introduced and added some relevant features in the basic active contour (snake) model [ 29 ] for making it appli-cable for text-line segmentation problem. We refer to our adapted active contour (snake) model as coupled snakelets model. Some salient features of coupled snakelets model are explained below.  X  Open-Curve Snake: A text-line can be represented by  X  Multiple Snakes: Each text-line of a document image  X  Automatic Initialization of Pair of Snakes: Coupled  X  External Energy Calculation from Discrete Points:  X  Deformation of Snakes in Targeted Direction: In Latin  X  Evolving Snakes: Coupled snakelets model introduces  X  Weighted-Coupled Pair of Snakes: Two or more snakes 4 Curled text-line segmentation algorithm The steps of our curled text-line segmentation algorithm on the basis of above described coupled snakelets model are showninFig. 8 . Each of these steps is described here in detail.
Binarization and Noise Cleanup: An input grayscal-ing camera-captured document image is first binarized by using adaptive thresholding technique. The binarization method is defined as follows:  X  X or each pixel, the back-ground intensity B ( p ) is defined as the 0.8-quantile in a window shaped surrounding; the pixel is then classified as background if its intensity is above this constant fraction of B ( p )  X . It should be noted that this binarization scheme isthesameasusedin[ 37 ]. An example binarized image is shown in Fig. 9 a. The binarized document image may contain marginal as well as salt-and-pepper noise. A heu-ristic-based noise cleanup process is applied as follows.
Let H doc and W doc represent the height and width of the document image, respectively; H avg and W avg represent the mean height and width of connected components, respec-tively;  X  H and  X  W represent standard deviation of heights and widths of connected components, respectively. A con-nected component, whose height and width are represented by H cc and W cc , respectively, is removed as a large noisy component if any of the conditions specified in Eq. 4 is true or as a small noisy component if the condition specified in Eq. 5 is true:
After removing noisy connected components, let mean width and mean height of all the remaining connected com-ponents be represented by W and H , respectively.
Snakelets Initialization: All the connected components of the binarized document image are marked as unpro-cessed.Then,aconnectedcomponentisselectedrandomly.
A pair of horizontal open-curve snakes is initialized over the selected connected component, such that one snake is initialized at its top point and another one at its bottom point. By keeping the connected component at center, a small rectangular region is also selected around it. The initial length of the snakes ( L ) and the size of the rectan-gular region ( W R  X  H R ) are selected in such a way that both of them cover a few neighboring connected compo-nents around the selected connected component. Let H cc and W cc represent the height and width of the connected component, respectively. L , W R , and H R are defined as: L := W cc + 2  X  W W R := W cc + 4  X  W
H R := H cc + 2  X  H
The main reason of selecting the width greater than the height of the rectangular region is that text-lines in a doc-ument are usually horizontal in nature. An example of an initial pair of snakes and a selected rectangular region for a connected component is shown in Fig. 9 b.

Snakelets Deformation: Gradient vector flow (GVF) is calculated by using the top points of all connected com-ponents inside the selected region around the connected component. Then, the top snake is deformed by using the vertical components of the GVF with  X / 2(Eq. 3 ). Simi-larly, bottom snake is deformed by using the vertical com-ponent of the GVF with  X  , where the GVF is calculated form the bottom points of all connected components within the selected region.

Snakelets Coupling: The top and bottom snakes are com-posed of the same number of points with similar values of x -coordinates. For each common value of x -coordinate of the top and bottom snakes, absolute distance is calculated from the corresponding values of y -coordinates. Then, average distance is computed. Now, for each common value of x -coordinate of both snakes, the corresponding values of y -coordinates are increased or decreased pro-portionally such that the distance between them becomes equal to the average distance. Snakelets coupling proce-dure is illustrated in Fig. 10 .

Snakelets Extension: First, the average slope of the pair of snakes is calculated. Then, each of the top and bottom snake is extended by a length equal to the average width ( W ) from both left and right sides, and the slope of these extendedlengthsiskeptthesameastheaverageslope.Sim-ilarly, the rectangular region around the connected com-ponent is extended, such that its width and height become twice as big compared to its previous width and height after extension.

After snakelets deformation, coupling, and extension steps, the first deformation cycle of the snakes X  pair is com-pleted, which is shown in Fig. 9 c. The pair of snakes is further processed by a few number ( N ) of deformation cycles. We empirically found that three iterations of snakelets extension are sufficient for printed Latin script documents. The results of coupled snakelets for two more deformation cycles are shown in Fig. 9 d, e, respectively.

The pair of snakes approximates a local pair of x-line and baseline on the connected component, as shown in Fig. 9 e. Now all the connected components that are over-lapped/touchedbythepairofsnakesaremarkedasprocessed. Afterward, the same process is repeated for another unpro-cessed connected component and is continued until no more unprocessed connected components are left. Some exam-ple images with all computed pairs of coupled snakelets are showninFig. 11 . In these example images, each group of overlapping/touching pairs of snakes can be considered as a segmented text-line. In these example images, it is also vis-ible that our method can handle a high degree of curl/skew and different font sizes within a document image.
Coupledsnakelets-basedtext-linesegmentationalgorithm may also cause undersegmentation failures. Some examples of undersegmentation failures of our algorithm are shown in Fig. 12 a. Such type of segmentation failures occur because of some badly deformed pairs of snakes, as marked in Fig. 12 a. By badly deformed pairs of snakes, we mean those pairs of snakes that are not correct with respect to the estimation of their corresponding local x-line and baseline pairs and are not uniform with respect to their neighboring pairs of snakes. Such type of badly deformed pairs of snakes mainly occur because of some inherent properties of a document image:  X  a document image may contain text-lines with different  X  a document image may contain slightly big connected
We have introduced a post-processing step for cleaning up badly deformed pairs of snakes and for achieving better segmentation results.

Snakelets Cleaning (post-processing): We develop the following observations from a close examination of the coupled snakelets (pairs of snakes) in Fig. 12 a: (i) the slope of each pair, except the marked ones, is approximately the same as that of the neighboring pairs, (ii) the thick-ness (average distance) of each pair, except the marked ones, is approximately the same as that of other neigh-boring pairs. Both or either of these observations do not hold for badly deformed coupled snakelets as shown in
Fig. 12 a. Therefore, badly deformed coupled snakelets can be removed by using slope-and thickness-based statisti-cal analysis. Each coupled snakelet is removed as a badly deformed pair if the difference between its slope and the mean slope of neighboring-coupled snakelets is greater than a predefined threshold, or if the difference between its thickness value and the mean thickness value of neighbor-ing coupled snakelets is greater than a predefined thresh-old. The slope threshold can be set equal to a small value such as 10  X  or 15  X  and can be represented by T S . The thick-ness threshold can be relatively selected with respect to the average height of connected components ( H ) and can be represented by T T  X  H . The height and length of the neighboring window for estimating the mean thickness and mean slope can also be relatively selected with respect to H and can be represented by R pp  X  H . Altogether, our snak-elets cleaning (post-processing) step contains three free parameters: T S , T T , and R pp . The snakelets cleaning pro-cess is applied to the examples in Fig. 12 a for predefined values of these free parameters, and the remaining cou-pled snakelets are shown in Fig. 12 b. It is clearly visible from these examples that our post-processing cleaning step removed badly deformed coupled snakelets and overcame undersegmentation failures. Furthermore, in performance evaluation (Sect. 5 ), we have evaluated our text-line seg-mentationalgorithmfor different possiblevalues of T S , T and R pp .

Text-Lines Labeling: As shown in Figs. 11 and 12 b, each group of overlapping or touching pairs of snakes represents a group of connected components that belong to a par-ticular text-line. Each group of connected components is assigned a unique text-line label. Each small noisy compo-nentsthatwasremovedinthenoisecleanupstepisassigned the label of its nearest text-line. A few example results of curled text-lines segmentation using coupled snakelets algorithmfollowedbypost-processingandtext-lineslabel-ing are shown in Fig. 13 .
 Behavior of Coupled Snakelets under Challenging
Conditions: Our algorithm is designed for text-lines seg-mentation which cannot handle tables and/or formulas seg-mentation, but it detects text-lines correctly even in the presence of tables and/or formulas as shown in Fig. 14 a, b, respectively. Grayscaling camera-captured document images are usually composed of shadows that are cap-tured using a hand-held camera in an unconstrained envi-ronment. A local adaptive thresholding produces a small amount of noise from shadows, but a global threshold-ing technique produces a large amount of shadow-based noise. Our text-line detection algorithm starts with binari-zation step using a local adaptive thresholding technique, and then, it performs cleanup step in order to remove noise (that are originated from shadows, borders, etc.) and other non-text components (like graphics, drawings). It is also possible that the cleanup process is unable to remove noise and/or non-text components completely. Our algo-rithm works well even in the presence of the remaining amount of non-text noise and/or shadow noise as shown in Fig. 14 c, d, respectively. A binarized camera-captured document image may contain broken or joined characters.
Coupled snakelets algorithm can give satisfactory text-lines segmentation result under these conditions as shown in Fig. 14 e, f, respectively, until characters are broken into a large number of pieces and/or a large number of characters are joined together. In the presence of big connected com-ponents of joined characters, text-line segmentation results can further be improved by using a character segmenta-tion algorithm like dynamic-programming-based curved-cut segmentation [ 38 ]. 5 Performance evaluation We have evaluated our coupled snakelets-based curled text-line segmentation algorithm on publicly available DFKI-I (CBDAR 2007 dewarping contest) dataset [ 39 ] by using Sha-fait et al. [ 10 ] performance evaluation metrics. This section is further divided into the following three subsections: (1) description of hand-held camera-captured document images DFKI-I dataset that was used in CBDAR 2007 dewarping contest, (2) performance evaluation methodology, and (3) performance evaluation and experimental results. 5.1 DFKI-I (CBDAR 2007 dewarping contest) dataset DFKI-I (CBDAR 2007 dewarping contest) dataset contains 102 grayscaling and binarized document images of pages from several technical books captured by an off-the-shelf hand-held digital camera in a normal office environment. The captured documents were binarized using a local adaptive thresholding technique, which is described in [ 37 ]. Docu-ment images in this dataset consist of warped text-lines with high degree of curl, different directions of curl within an image, non-text (graphics, halftone, etc.) components, and a lot of textual and non-textual border noise. The average size of a document image in this dataset is equal to 7.8 mega-pixels. The values of mean and standard deviation of the length ( L ) and height ( H ) of connected components in this dataset are as follows:  X  L = 19 pixels,  X  L = 10 pixels,  X  information about the font sizes of characters in this dataset, because most of the connected components in this dataset belong to text class.

Together with ASCII-text ground-truth, this dataset also contains pixel-based ground-truth for zones, text-lines, formulas, tables, and figures. These pixel-based ground-truth images are embedded in color-coded form, where red chan-nel contains zone class information, blue channel contains zone number (in reading order) information, and green chan-nel contains text-line number information. Textual and non-textual border noise are marked as noise with black color. For the performance evaluation of text-lines segmentation algo-rithms, we generated text-line-based ground-truth images from the original ground-truth images. A text-lines-based ground-truth image contains labeling only for text-lines, and all the other foreground objects, like formulas, tables, and figures, are marked as noise with black color. We did it auto-matically by using original ground-truth information as fol-lows: in an original ground-truth image, green color channel value is zero for all pixels except those that belong to text-lines. We marked all pixels, that contain zero value for green color channel, as noise. An example image and its corre-sponding text-lines-based ground-truth image is shown in Fig. 15 . 5.2 Performance evaluation methodology Performanceevaluationofatext-linesegmentationalgorithm is based on vectorial performance evaluation metric that was presented by Shafait et al. [ 10 ]. One of the importance of these vectorial metric is that it not only represents one-to-one segmentation accuracy, but also represents most important classes of segmentation errors, such as over-, under-, and miss-segmentation.
 Performance evaluation metrics are described as follows. Consider we have two segmented images, the ground-truth G and hypothesized segmentation H . We can com-pute a weighted bipartite graph called  X  X ixel-correspondence graph X  between G and H for evaluating the quality of the seg-mentation algorithm. Each node in G represents a text-line ( ground-truth component ), and each node in H represents a segmented text-line ( segmented component ). An edge is constructed between two nodes such that the weight of the edge equals the number of foreground pixels in the intersec-tion of the regions covered by the two segments represented by the nodes. The matching between G and H is considered perfect if there is only one edge incident to each compo-nent of G or H , otherwise it is not perfect, i.e., each node in G or H may have multiple edges. The edge incident to a node is significant if the value of w i / P  X  t r and w i where w i is the edge-weight, P is the number of pixels cor-responding to a node (segment), t r is a relative threshold, and t a is an absolute threshold. In practice, t r = 0 . 1 and t = 100 are good choices for text-lines-based performance evaluation for typed-text document images [ 10 ]. We have also used same parameter values for the performance evalua-tion of our coupled snakelets and other text-line segmentation algorithms.
Let N g represents total number of ground-truth compo-nents, and N s represents total number of segmented com-ponents. Based on the above description, the performance evaluation metrics are:  X  Total correct segmentation ( N o2o ): the number of one- X  Oversegmented components ( N ocomp ): the number of  X  Undersegmented components ( N ucomp ): the number of  X  Missed components ( N mcomp ): the number of ground- X  Total oversegmentations ( N oseg ): the number of signifi- X  Total undersegmentations ( N useg ): the number of sig- X  False alarms ( N falarm ): the number of components in the 5.3 Performance evaluation results Our coupled snakelets-based curled text-line segmentation algorithm contains three free/tunable parameters (  X ,  X  , and  X  ) for the coupled snakelets estimation, and three parameters ( T parameters have been explained in detail in Sect. 3 .Abrief description of these parameters are as follows. Parameters  X  and  X  are used to control snake X  X  internal energy during deformation, and  X  is used to control snake X  X  external energy. The parameter  X  is usually set to a value like 0 . 05 , 0 The parameter  X  is set to a small value when no stiffness is required and to a large value when high snake X  X  stiffness is required during deformation steps (like our coupled snak-elets model). The possible range of values for parameter  X  is in between 0 to 1. The parameter T S is the slope thresh-old, T T is the relative thickness threshold (with respect to the mean height of connected components in a document image H ), and R pp is the relative window size with respect to H . Experimental results show that the post-processing step does not require a very small value (like 0  X  ) or a comparatively large value (like 45  X  ) for parameter T S . Similarly, the relative values for T T and R pp can be set in between 1 to 10.
For optimization of these parameters and showing their effects on text-line detection accuracy, we have evaluated our coupled snakelets-based curled text-line segmentation algo-rithm on 11 images from the DFKI-I (CBDAR 2007 dewar-ping contest) dataset (that start with name dsc00 ) for different values of these free parameters. The one-to-one text-line seg-mentation accuracy ( P o2o ) of our algorithm for the different values of these free parameters is shown in Fig. 16 . Here, we have adopted a sequential procedure for evaluating and optimizing the performance of our text-line detection method with respect to the different values of these parameters. In Fig. 16 a, the text-line detection accuracy is shown for dif-ferent values of  X  and  X  with empirically chosen values for other parameters (  X  = 1 , T S = 10  X  , T T = 30 pixels (abso-lute value), R pp = 150 pixels (absolute value)). Similarly, in Fig. 16 b, the text-line detection accuracy is represented for different values of  X  with optimized values for  X  = 0 . 05 and  X  = 10 , 000 (from Fig. 16 a), and chosen values for other parameters ( T S = 10  X  , T T = 30 pixels, R pp = 150 pix-els). Likewise, in Fig. 16 c, the text-line detection accuracy is shown for different values of T T and T S with optimized values for  X  = 0 . 05 , X  = 10 , 000, and  X  = 1 (from Fig. 16 a, b), and chosen value for R pp = 150 pixels. Finally, in Fig. 16 d, the text-line detection accuracy is shown for different values of R pp with optimized values for others ( and  X  = 1 , T T = 1 and T S = 10  X  ; from Fig. 16 a X  X ).
From Fig. 16 , we can conclude that the performance of our text-line segmentation method is not sensitive to the values of most of the free parameters (like  X ,  X  , T T and R pp ), except  X  and T S . The optimized values of these parameters for a subset of 11 images from DFKI-I (CBDAR 2007 dewarping contest) dataset are as follows:  X  = 0 . 05 , X  = 1 , 000 , X  = T
We have compared the performance of our coupled snak-elets-based curled text-line segmentation algorithm on the complete dataset of DFKI-I (CBDAR 2007 dewarping con-test) dataset with other previously reported curled text-line segmentation algorithms: (i) nearest-neighbors (Gatos et al. [ 19 ]), (ii) baby-snakes (Bukhari et al. [ 26 ]), (iii) ridges detection (Bukhari et al. [ 27 , 28 ]), (iv) rule-based (Oliveria we also proposed a minor modification for the nearest-neighbor-basedalgorithm[ 19 ]byintroducingthefreeparam-eter T . The average height of a connected components in DFKI-I (CBDAR 2007 dewarping contest) dataset is approx-imately equal to 20; therefore, we set T = 20 for the modified version of nearest-neighbor-based algorithm [ 19 ]. We also evaluated a straight text-line segmentation algo-rithm (Docstrum [ 6 ]) for curled text-line segmentation from camera-captured document images. Docstrum is one of the state-of-the-art page segmentation algorithm for scanned document images with straight text-lines. The main reason of including it here is to show that how challenging the dataset is, and that straight text-lines segmentation algorithms cannot be directly applied for curled document images. Performance evaluationresultsofallalgorithmsforDFKI-I(CBDAR2007 dewarping contest) dataset are shown in Table 1 .
Among all curled text-line segmentation algorithms that are shown in Table 1 , our coupled snakelets algorithm achieved the highest percentage of one-to-one segmenta-tion accuracy and the lowest percentages of oversegmenta-tion and missed text-line errors. Our algorithm also achieved the second lowest percentage of undersegmentation errors. Almost all of the algorithms have produced large numbers of false-alarm errors. In general, a large number of false alarms can be reduced by using an appropriate pre-processing or post-processing step, for example a page boundary detection method [ 2 , 40 ] can help in removing textual and non-textual border noise.

A few sample documents from the DFKI-I (CBDAR 2007 dewarping contest) dataset having the largest number of text-line segmentation errors for our coupled snakelets algorithm are shown in the top row of Fig. 17 , and for comparison, the corresponding results of modified nearest-neighbor-based algorithm [ 19 ] are shown in the bottom row of Fig. 17 . Even in these examples, our algorithm has overall performed better than modified nearest-neighbor-based algorithm [ 19 ]. The document image in Fig. 17 a contains total 43 text-lines, and our method detected 35 of them correctly. In this exam-ple, most of the errors belong to oversegmentation category. These oversegmentation errors mainly occur because of big gaps between words within some text-lines, which can be seen in the middle of the page. The document image of Fig. 17 b contains very small gaps between text-lines, result-ing in undersegmentation errors. For this image, our cou-pled snakelets method detected 39 text-lines correctly out of 44 text-lines and produced some undersegmentation errors, which can be seen in the top area of the document image in Fig. 17 b.

The average size of a document image in DFKI-I (CBDAR 2007 dewarping contest) dataset is around 8 Mega-pixels, and the average size of a character is this dataset is 19 pixels wide(withastandarddeviationof 11pixels) and25pixels tall (with a standard deviation of 9 pixels). The execution time of our text-line detection method is directly proportional to the size and the number of connected components in a doc-ument image. The main problem with active contour model is that it takes large amount of execution time because of a large number of deformation cycles. Our coupled snakelets model processes many snakes sequentially, and therefore it also takes a large amount of processing time. On weighted averagewithrespecttothenumberofconnectedcomponents, our algorithm takes around 38min per page with text-line detection accuracy of around 95%. We have implemented the code using Python programming language without using any Python-specific and/or active contour X  X pecific optimiza-tion techniques. The execution time can be reduced by using these types of optimization techniques, which is one of our futureresearchgoals.Here,wehavetestedabasicstrategyfor reducing the execution time of our method such that a docu-ment image is downscaled for coupled snakelets calculation and then the estimated snakelets are upscaled proportion-ally for text-lines labeling step. Figure 18 shows the text-line detection accuracy of our coupled snakelets method and the corresponding average execution time for different size of downscaled images for DFKI-I (CBDAR 2007 dewarping contest) dataset. This process also demonstrates how well our text-line segmentation algorithm can perform for small character sizes. We have achieved around 3 times speed up gain (i.e., 13min per page) with around 1% reduction in text-line detection accuracy (i.e., 94%) for around 2 times image downscaling factor. It also shows that our algorithm can work gracefully up to a minimum character size of around 10 pixels wide and around 12 pixels tall. 6 Conclusion Hand-held camera-captured document images usually con-tain warped/curled text-lines because of geometric and/or perspective distortions. In this paper, we introduced a novel curled text-line segmentation algorithm by adapting active contour (snake) [ 29 ]. We refer to our adapted active con-tour (snake) model for text-line segmentation as coupled snakelets . Our algorithm uses only top and bottom points of connected components within a document image for detect-ing text-lines. It jointly estimates a local pair of x-line and baseline on each connected component using top and bottom points, and then each group of overlapping and/or touching pairs of x-line and baseline is considered as a segmented text-line. We used DFKI-I (CBDAR 2007 dewarping con-test) dataset [ 21 ] for performance evaluation and compared our results with other state-of-the-art approaches: (i) near-est-neighbors X  X riginal (Gatos et al. [ 19 ]) and our proposed modified version, (ii) baby-snakes (Bukhari et al [ 26 ]), (iii) ridges detection (Bukhari et al. [ 27 , 28 ]), (iv) rule-based (Oliveria et al. [ 22 ]), and (v) Docstrum [ 6 ]. Our algorithm is less sensitive to a high degree of curl and skew and produces a less number of over-and undersegmentation errors when compared to other state-of-the-art curled text-line segmen-tation methods. Unlike previous approaches, our algorithm performs text-lines segmentation and their x-line and base-line pairs estimation simultaneously that results in improved segmentation with better estimation of x-lines and baseline than other approaches. The performance evaluation results are shown in Table 1 . Our algorithms achieve the highest one-to-one text-line segmentation accuracy when compared to other methods. It also yields the lowest oversegmentation and missed text-lines errors, and a smaller number of un-dersegmentation errors. Our method contains 6 free/tunable parameters. Most of these parameters are non-sensitive with respect to the performance the presented method.
 References
