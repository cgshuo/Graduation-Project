
Text mining applies the same analytical functions of data mining to the domain of textual information, relying on sophisticated text analysis techniques that distill information from free-text documents. IBM X  X  Intelligent Miner for Text provides the necessary tools to unlock the business information that is  X  X rapped X  in email, insurance claims, news feeds, or other document repositories. It has been successfully applied in analyzing patent portfolios, customer complaint letters, and even competitors X  Web pages. After defining our notion of  X  X ext mining X , we focus on the differences between text and data mining and describe in some more detail the unique technologies that are key to successful text mining. 
Text mining, feature extraction, text categorization, clustering, customer relationship management  X  X here is gold hidden in your companies data X  -and data mining promises to help you finding it. And in fact, many successful mining addresses only a very limited part of a company X  X  total data assets: the structured information available in databases. 
Probably more than 90% of a companies data are never being looked at: letters from customers, email correspondence, recordings of phone calls with customers, contracts, technical documentation, patents, . . . With ever dropping prices of mass storage, companies collect more and more of such data online. 
But what can we get from all this data? More often than not, the only way the data is made usable -outside of very specific applications for subsets of that data -is by making it accessible and searchable in a companies intranet. But today there is more you can do: text mining helps to dig out the hidden gold from textual information. Text mining leaps from old-fashioned information retrieval to information and knowledge discovery. KDD-99 San Diego CA USA 
The first challenge in text mining is that information in unstructured textual form is not readily accessible to be used by computers. It has been written for human readers and requires natural language (NL) interpretation. The information really is buried inside the text. Although a full-blown interpretation of even just factual knowledge stated in unrestricted natural language is still out of reach with current technology, there are tools using pattern recognition techniques and heuristics that are capable of extracting valuable bits of information from arbitrary free-text. Extracted information ranges here from identifying what companies or dates are mentioned in a document to summaries of a document. 
But there is more to text mining than just extracting information pieces from single documents. Where the mining task in the sense of data mining comes in is when one has to deal with huge collections of documents. Tools performing that task generally support classification -either in a supervised or in an unsupervised fashion -on the documents seen as objects that are characterized by features extracted from their contents. 
We use the  X  X ining X  metaphor for both knowledge discovery processes described above: the extraction of codified information (features) from single documents as well as the analysis of the feature distribution over whole collections to detect interesting phenomena, patterns, or trends. Any non-trivial application of  X  X ext mining X  necessarily involves both of those mining phases. 
Data mining generally involves the steps. 1. Identification of a collection 2. Preparation and feature selection 3. Distribution analysis. preparatory phase the very complex feature extraction function. 
Moreover, the cardinality of the feature set that can be extracted from a document collection usually is very high, easily running into several thousands. There are two consequences of this affecting the overall text mining process. 1. The feature selection task is quite different, since it is no 2. The distribution analysis step must be able to handle highly text mining: the Intelligent Miner for Text*. It is a software development toolkit -not a ready-to-run application -for building text mining applications. It addresses system integrators, solution providers, and application developers. The toolkit contains the necessary components for  X  X eal text mining X : feature extraction, clustering, categorization, and more. But there are also more traditional components, e.g., the IBM Text Search Engine, the IBM Web Crawler, and drop-in Intranet search solutions. We will These components are essential to build applications that use the information generated in a mining process, e.g., in an Intranet portal for the company. The task of feature extraction is to recognize and classify significant vocabulary items in unrestricted natural language texts. Examples of vocabulary found are shown in Figure 1. The process is fully automatic -the vocabulary is not predefined. Nevertheless, as the figure shows, the names and other multiword terms that are found are of high quality and in fact correspond closely to the characteristic vocabulary used in the domain of the documents being analyzed. In fact, what is found is to a large degree the vocabulary in which concepts occurring in the collection are expressed. 
In general, our implementation of feature extraction relies on linguistically motivated heuristics (cf. [2]) and pattern matching together with a limited amounts of lexical information, such as part-of-speech information. We neither use huge amounts of lexicalized information, nor do we perform in-depth syntactic and semantic analyses of texts. This decision allows us to achieve two major goals: 1. Very fast processing to be able to deal with mass data 2. Domain-independence for general applicability 
The extracted information will be automatically classified into the following categories: . Names of persons, organizations and places like Mrs. M. Albright, National Organization of Women 
Business Owners, or Dheli, India . Multiword terms like joint venture, online document, or central processing unit . Abbreviations like EEPROM for Electrical erasable programmable read-only memory . Relations like Jack Smith-age-42, John Miller-own-Knowledge Corp., 
Janet Pema-General Manager-Database Management . Other useful stuff numerical or textual forms of numbers, percentages, dates, currency amounts, etc. 
We always assign a so-called canonical form to each feature we find. Simple, but very useful examples include normalized forms of dates, numbers etc. This allows applications to use that kind of information very easily, even though, e.g., a number was written in words in a text. A canonical form also abstracts from different morphological variants of a single term, e.g., singular and plural forms of the same expression are mapped to the same canonical form. 
More complex processing is done in the case of names. All the names that refer to the same entity, for example President Clinton, 
Mr. Clinton and Bill Clinton, are recognized as referring to the same person. Each such group of variant names is assigned a canonical name, (e.g.,  X  X ill Clinton X ) to distinguish it from other groups referring to other entities ( X  X linton, New Jersey X ). The canonical name is the most explicit, least ambiguous name constructed from the different variants found in the document. 
Associating a particular occurrence of a variant with a canonical name reduces the ambiguity of variants. For example, in one document,  X  X RA X  is associated with the Irish Republican Army, while in another it may be associated with an Individual Retirement Account. 
Optionally, the tool computes statistical data on the distribution of features in documents and document collections. This allows, document with respect to the statistical background properties of the whole document collection. 
With the mapping of documents to feature vectors that describe them in place, we can perform document classification in either of 
Clustering is a fully automatic process, which partitions a given collection into groups of documents similar in contents, i.e., in 1 For more information also on other components, please refer to httn:Nwww.software.ibm.comldata/iminer/fortext predetermined based on a user-provided taxonomy. their feature vectors. Intelligent Miner for Text includes two clustering engines employing algorithms that are useful in different kinds of applications. The Hierarchical Clustering tool orders the clusters into a tree reflecting various levels of similarity. The Binary Relational Clustering tool uses  X  X elational 
Analysis X  (cf. [l]) to produce a flat clustering together with relationships of different strength between the clusters reflecting group by listing terms or words that are common in the documents in the group. Thus, clustering is a great means to get an overview of the contents of a collection. The second kind of classification is called (text) categorization. 
The Topic Categorization tool assigns documents to preexisting categories, sometimes called  X  X opics X  or  X  X hemes X . The categories are chosen to match the intended use of the collection. In the 
Intelligent Miner for Text those categories are simply defined by providing a set of sample documents for each category. All the analysis of the categories, feature extraction and choice of features, i.e., key words and phrases, to characterize each category, is done automatically. This  X  X raining X  phase produces a special index, called the categorization schema, which is subsequently used to categorize new documents. The categorization tool returns a list of category names and confidence levels for each document being categorized. Documents can be assigned to more than one category. If the confidence level is low, then typically the document would be put aside so that a human categorizer can make the final decision. 
Tests have shown that, provided the set of defined categories does match the subject matter of incoming documents, the Topic 
Categorization tool agrees with human categorizers to the same degree as human categorizers agree with one another. 
As is the case with data mining technology, one of the primary application areas of text mining is collecting and condensing facts as a basis for decision support. The main advantages of mining technology over a traditional  X  X nformation broker X  business are: . The ability to quickly process large amounts of textual data .  X  X bjectivity X  and customizability of the process -i.e. the . Possibility to automate labor-intensive routine tasks and 
Taking advantage of these properties, text mining applications are typically used to: . Extract relevant information from a document . Gain insights about trends, relations between . Classify and organize documents according to their content; . Organize repositories of document-related meta-information 
