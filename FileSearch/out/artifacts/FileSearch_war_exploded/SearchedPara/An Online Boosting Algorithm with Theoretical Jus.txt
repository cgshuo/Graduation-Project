 Shang-Tse Chen  X  b95100@csie.ntu.edu.tw Hsuan-Tien Lin  X  htlin@csie.ntu.edu.tw Chi-Jen Lu  X  cjlu@iis.sinica.edu.tw
Institute of Information Science, Academia Sinica, Taipei, Taiwan Boosting is one of the most powerful and popular ensemble-learning techniques in the setting of batch learning. The technique is an important topic from both the theoretical and practical perspective. On the theoretical side, boosting identifies the least (weak-est) assumption on the learner to make learning pos-sible (Freund &amp; Schapire, 1996; Schapire et al., 1998; Mukherjee et al., 2011), and the assumption can be used to facilitate the analysis of existing algorithms and the design of new ones. On the practical side, boosting allows re-using of existing (weak) learning algorithms in an efficient manner to improve perfor-mance, which matches the needs of many real-world applications (Schapire &amp; Singer, 2000; Kudo et al., 2004; He &amp; Thiesson, 2007).
 Online learning, as opposed to batch learning, is an-other important topic in machine learning. Online learning does not require a fixed set of training data on hand but processes streaming examples one by one, which also fits the needs of many real-world applica-tions. For example, a spam filtering system might need to continuously adjust its filtering rules based on the ever-changing spam tactics. Online learning also has its advantages in handling large-scale data sets, since it does not need to load the whole data set into the memory. The success of boosting in batch learning and the many merits of online learning inspire the study of online boosting  X  a combination of the two. For in-stance, consider an online spam classifier that has been working reasonably well, can we  X  X oost X  the perfor-mance by combining a couple of those classifiers? The work of Oza &amp; Russell (2001) is one of the first to use boosting in the online setting, and it was ar-gued that the given algorithm under some condition could converge to the popular Adaptive Boosting ap-proach (AdaBoost; Freund &amp; Schapire, 1997) as the number of weak learners and training examples ap-proaches infinity. Online boosting also achieved great success in many real-world applications, especially in the field of computer vision (Grabner &amp; Bischof, 2006), due to its simplicity and efficiency. Many other on-line boosting algorithms have been proposed to tackle different application needs, such as semi-supervised learning (Grabner et al., 2008), multi-instance learn-ing (Babenko et al., 2009b), and feature selection (Liu &amp; Yu, 2007).
 Nevertheless, relatively few existing studies discuss the theoretical behaviors of online boosting algorithms, as opposed to their offline counterparts. While many works on online boosting try to approximate AdaBoost or other batch boosting algorithms as closely as possi-ble, they ignore the intrinsic differences between online learning and batch learning. In this paper, we care-fully compare these differences, which in turn leads to different design strategies of the algorithms. We start by re-examining the foundation of boosting algorithms  X  the weak learning assumption, which says that under any distribution of the data, the weak learner can perform better than random guess-ing. While this is a slightly strong but reasonable as-sumption in the batch setting, it is far from realistic in the online setting because the online weak learners are more restricted regarding the information avail-able. We thus propose a new and more reasonable assumption that requires the online weak learners to perform well only with respect to  X  X moother X  distri-butions. Based on this new assumption, we try to find a boosting algorithm that assigns example weights in a more  X  X onservative X  and online manner. One partic-ular boosting algorithm that not only fits our require-ments with slight modifications but also comes with simple and elegant theoretical analysis is SmoothBoost (Servedio, 2003). In this paper, we extend it to an online boosting algorithm.
 Another difficulty of online boosting is that we have to determine beforehand the number of weak learn-ers we would like to combine. The danger is that if we include too many weak learners, the outcome may be dominated by the poor predictions made by the many redundant weak learners which do not learn well. We mitigate this problem by giving different vot-ing weights to different weak learners and we deter-mine these weights dynamically using Online Convex Programming (Zinkevich, 2003) and the framework of Predicting with Expert Advice (Cesa-Bianchi &amp; Lugosi, 2006), both of which are well-established techniques in online learning.
 Our final online boosting algorithms have the nice fea-ture that theoretical guarantees can actually be shown, just as in the batch setting. In particular, we show that given online weak learners which can predict slightly better than random guessing with respect to  X  X mooth X  distributions, our online boosting algorithms can com-bine them to achieve a small error rate. In addition, we also perform experiments on several benchmark data sets, and the results show that our algorithms not only are theoretically well-founded, but also work well em-pirically on these real-world data sets. We consider the online learning problem in which an online learner must process a stream of examples ( x 1 ,y 1 ) ,..., ( x T ,y T )  X  R d  X { X  1 , 1 } in the following way. In step t , the online learner receives x t and is required to predict its label, and after the prediction the true label y t is revealed. We study the possibility of designing such an online learner using the boost-ing approach. That is, if we have online weak learners which can make predictions slightly better than ran-dom guessing, can we combine them to obtain an on-line strong learner which can make correct predictions for all but a small fraction of the examples? Before formally describing our online boosting frame-work, let us first recall that of batch boosting. In the batch setting, the whole set S of labeled examples is available at the beginning, and the boosting algorithm proceeds for some N rounds as follows. In round i , it chooses a distribution p ( i ) over S and gives S and p ( i ) to a batch weak learner, which has the whole S and p ( i ) available and produces a weak hypothesis h ( i ) . Af-ter the N rounds, it combines the N weak hypotheses to produce the final strong hypothesis, which takes the form of H ( x ) = sign( P N i =1  X  ( i ) h ( i ) ( x )), where  X  is the voting weight of h ( i ) . There are boosting algo-rithms which can achieve a small error rate, defined as a positive advantage, defined as P T t =1 p ( i ) t y t h Now, in our online boosting framework, the exam-ples of S only become available one at a time, and the boosting algorithm as well as the weak learners must work in an online fashion. Thus, the boost-ing algorithm cannot call the weak learner sequen-tially in N rounds as in the batch setting and must run N weak learners in parallel. That is, for each re-ceived example ( x t ,y t ), the boosting algorithm must update the N weak learners right away before see-ing the remaining examples. To do that, one would like the boosting algorithm to send a measure p ( i ) t of ( x t ,y t ) to the i -th weak learner. However, it does not seem easy to determine a good  X  X easure X  of an example without seeing the remaining examples, and a somewhat easier but sufficient task is to send a  X  X eight X  w ( i ) t of ( x t ,y t ), so that w ( i ) t / P responds to the measure p ( i ) t of ( x t ,y t ) for the i -th weak learner. Then, after the update, the i -th weak learner returns a weak hypothesis h ( i ) t +1 , and the boosting algorithm predicts the next example x t +1  X  t +1  X  R is the voting weight of h setting, we would like to have an online boosting al-gorithm which can achieve a small error rate, defined However, there appear to be some difficulties in de-signing such an online boosting algorithm. First, for each example, its weight for each weak learner must be determined before seeing the remaining examples. This rules out the use of the weighting schemes of some batch boosting algorithms. Next, the weights must satisfy some additional property in order to expect an online weak learner to have a positive advantage. To see this, if we take the extreme case that the first ex-ample has weight 1 and all others have weight 0, it is unrealistic to expect an online weak learner to have a positive advantage. Note that this would not be a problem in the batch setting, since the weak learner can read all the examples as well as their labels before coming up with a hypothesis. Finally, it is not clear how the online boosting algorithm can choose the ap-propriate number N of weak learners. We only know an upper bound for N which may be much larger than the appropriate one, but if we combine too many weak learners, the result may be dominated by the poor pre-dictions of the many weak learners which should not be included. This is not a problem in the batch setting, as the boosting algorithm proceeds in rounds, including a new hypothesis in each round, and stops once the new weak hypothesis fails to have the required advantage. For simplicity, let us assume that each x t lies within the unit L 2 -ball, so that k x t k 2  X  1, and each weak hy-pothesis h ( i ) t comes from some set H of functions map-ping from the unit L 2 -ball to the interval [  X  1 , 1]. We will use the notation [ T ] to denote the set { 1 ,...,T } for a positive integer T . In this section, we address the second difficulty dis-cussed in the previous section and study the condition for an online weak learner to have a positive advantage. Let us consider the case that H , the weak hypotheses space, consists of linear functions, so that each h  X  X  can be seen as a vector in R d , with h ( x ) defined as  X  h,x  X  , the inner product of the vectors h and x . For simplicity, let us assume k h k 2  X  1 for every h  X  X  . We can reduce the problem of finding a good online weak learner to the well-known online linear optimiza-tion problem as follows. With the T examples of S arriving sequentially, the weak learner in round t is given the data x t as well as its weight w t , and it then produces a hypothesis h t  X  H and after that receives a reward r t ( h t ) = w t y t h t ( x t ) = w t y t  X  h t the reward function r t is linear in h t . Therefore, we can apply the gradient descent algorithm of (Zinke-vich, 2003) to produce h t in round t , and a standard regret analysis shows that for some constant c &gt; 0, for any fixed hypothesis h  X  H chosen by an offline algorithm. Let | w | = P T t =1 w t , and by dividing both sides above by | w | , we have where p t = w t / | w | is the measure of ( x t ,y t ). The term P t =1 p t y t h t ( x t ) is the advantage of the online weak learner. The term P T t =1 p t y t h ( x t ) is the advantage of the offline hypothesis h , and let us assume for now that this advantage is at least 3  X  &gt; 0. Moreover, suppose the weights are large in the sense that they satisfy the following condition: where c is the constant in (1). Then the advantage of the online weak learner becomes where in the inequality we use P T t =1 w 2 t  X | w | as w [0 , 1]. Note that in addition to being sufficient, one can also show that the condition (2) is necessary to guarantee (3), using standard approaches for proving regret lower bounds. This motivates us to introduce the following assumption.
 Assumption 1. There exists an online weak learner which can achieve advantage 2  X  &gt; 0 for any sequence of examples and weights satisfying the condition (2). Based on the discussion above, we have the following. Lemma 1. Suppose for any sequence of examples and weights satisfying the condition (2), there exists an of-fline linear hypothesis with advantage 3  X  &gt; 0 . Then Assumption 1 holds.
 Note that large weights satisfying (2) give rise to dis-tributions which are  X  X mooth X  in the sense that each example has measure at most 1 / | w |  X   X  2 /c . This ex-cludes the extreme case discussed in the previous sec-tion and makes possible for an online weak learner to have a positive advantage. The concept of smoothness has also been applied to boosting in several frame-works, such as noise-tolerant learning (Servedio, 2003) and agnostic learning (Feldman, 2010), but to the best of our knowledge, this is the first work that incorpo-rates this idea into the problem of online boosting. In this section, we show how to choose weights for examples and how to combine hypotheses from weak learners in order to obtain an online boosting algo-rithm. Recall the framework of online boosting de-scribed in Section 2. Suppose Assumption 1 holds and let WL be such an online weak learner with advan-tage 2  X  . We will run N copies of WL as our N weak learners, for some N to be determined later.
 First, we would like to produce weights satisfying the condition (2). It is known that AdaBoost does not always produce such weights (Bshouty et al., 2002). One may try to scale up or down the weights to satisfy the condition, but the scaling factors often can only be determined after seeing all the examples, which does not work in the online setting. Fortunately, we can adopt the weighting scheme similar to SmoothBoost (Servedio, 2003) by choosing and z (0) t = 0 for t  X  [ T ]. It is easy to verify that given ( x t ,y t ) at step t , one can compute the weights w t ,...,w that we only need hypotheses from those weak learners associated with large weights.
 Lemma 2. For any i  X  [ N ] and t  X  [ T ] , define f t ( x ) = Let  X   X  [0 , 1] and let k be the largest number such that | w ( i ) | X   X T for every i &lt; k . Then 1
T The idea is that the algorithm assigns large weights to those incorrectly predicted examples, so there can not be many of them if the sum of weights is small. Note that when T  X  c/ (  X  X  2 ), for the constant c in (2), the weights for the i -th weak learner, for i &lt; k , are then large enough to satisfy the condition (2) since bound for the parameter k .
 Lemma 3. Suppose Assumption 1 holds and T  X  c/ (  X  X  2 ) . Then the parameter k in Lemma 2 is at most O (1 / (  X  X  2 )) .
 We omit the proofs of these two lemmas because they are almost identical to those for Theorem 2 and The-orem 3 in Servedio (2003) respectively.
 Lemma 3 provides us an upper bound on the num-ber N of weak learners. However, the problem in the online setting is that we have to determine N before-hand, and empirically we see that setting N to this upper bound and using the function H ( N ) in Lemma 2 for prediction would not get very good performance. The reason is that if N exceeds the actual number k in Lemma 3, we could include too many weak learners which receive examples with small weights and would not update much. These weak learners might not learn well enough and taking them into the ensemble would therefore hinder the performance. Next, we describe two approaches to solve this problem.
 The first is to give different voting weights for differ-ent weak learners, intuitively with larger weights to better weak learners. We set N to the upper bound given in Lemma 3, and at step t , we find some voting weight  X  ( i ) t for the i -th weak learner, and predict x by To find appropriate  X  t = (  X  (1) t ,..., X  ( N ) t ), we reduce the task to the Online Convex Programming (OCP) problem, using the N -dimensional probability simplex as the feasible set and defining the loss function at step t as which is a convex function of  X  = (  X  (1) ,..., X  ( N ) From Lemma 2, we know the existence of an  X   X  = (  X   X  for i  X  k , such that Thus, if we use the gradient descent algorithm of (Zinkevich, 2003) to produce  X  t at step t , we can have To relate this bound with the error rate of H t , note |{ t : H t ( x t ) 6 = y t }| X  1 The complete algorithm is given in Algorithm 1. Algorithm 1 Online Boosting with OCP
Input: streaming examples ( x 1 ,y 1 ) ,..., ( x T ,y T )
Initialize: z (0) t = 0 for t  X  [ T ] for t = 1 to T do end for The second approach to combine weak learners is to use the framework of Predicting with Expert Advice . However, if we simply use each weak learner as an expert, we can only perform comparably to the best weak learner, which is inadequate for our goal of com-peting with the best combination of weak learners. So we instead construct another N experts, with the i -th expert using the function H ( i ) t in Lemma 2 to predict x . Then, by running the weighted majority algorithm (Littlestone &amp; Warmuth, 1994; Freund &amp; Schapire, 1997) on these N experts, the expected regret with respect to the best expert is at most 2 the best expert according to Lemma 3 has error rate at most  X  , the expected error rate of our algorithm is thus at most  X  + 2 p (ln N ) /T . The resulting boosting algo-rithm based on this approach can be easily modified from Algorithm 1.
 We summarize our result as follows.
 Theorem 1. Suppose Assumption 1 holds and T  X  c/ (  X  X  2 ) for a large enough constant c . Then there is an online boosting algorithm which uses O (1 / (  X  X  2 copies of weak learners and achieves an error rate of O (  X  ) .
 Theorem 1 works for any set of weak hypotheses, as-suming the existence of online weak learners which can predict with such hypotheses with a positive advan-tage when given examples with large enough weights (Assumption 1). When specialized to linear weak hy-potheses, we can lift the assumption of having an algo-rithm for finding good hypotheses, and replace it with the assumption of the mere existence of good hypothe-ses. More precisely, using Lemma 1 together with The-orem 1, we have the following.
 Corollary 1. Suppose for any sequence of examples and weights satisfying the condition (2), there is an offline linear hypothesis with advantage 3  X  , and T  X  c/ (  X  X  2 ) for a large enough constant c . Then there is an online algorithm which achieves an error rate of O (  X  ) . In this section, we compare the empirical performance of the proposed algorithms with two other leading ones in online boosting. We do not compare with some other leading algorithms because of the different set-tings between those and our proposed ones. For in-stance, Grbovic &amp; Vucetic (2011) proposed the incre-mental boosting algorithm, which is allowed to store previous examples while our proposed algorithms only rely on the newest arriving example. Another case is the algorithm in Pelossof et al. (2008), which as-sumes the weak learners to be static, i.e. pre-trained offline, and only updates the weights for combining the learners, while our proposed algorithms allows on-line, dynamic weak learners. Yet another family of online boosting algorithms are proposed in Babenko et al. (2009a), which requires the weak learners to be updated using stochastic gradient descent so that the weak learners can be chained with optimizing a choice of loss function, while our proposed algorithms treat weak learners in a black-box manner with minimum assumptions. Below we briefly describe the two algo-rithms we compare with. 5.1. Compared Algorithms 1. Online AdaBoost (Oza &amp; Russell, 2001) uses 2. Online GradientBoost (Leistner et al., 2009) 5.2. Weak Learners We choose two different weak learners in our experi-ments in order to take a closer look at the boosting ability of our proposed algorithms. The first one is Perceptron (Rosenblatt, 1962), a standard and famous online learning algorithm which, like our analysis in Section 3, takes a hypothesis set of linear functions. The second weak learner we choose is Naive Bayes , which is a lossless online algorithm, a crucial condi-tion for ensuring the convergence of OzaBoost. 5.3. Results We tested our algorithms using 12 binary classifica-tion benchmark data sets (Frank &amp; Asuncion, 2010), downloaded in the processed format from the LIBSVM repository. 1 For each online boosting algorithm, we couple it with 100 weak learners and record its er-ror in an online setting for 5 trials, where each trial consists of a different random ordering of the exam-ples. We then report the average error over the 5 tri-als. We have tried some different values of  X  and have confirmed that the performance of the proposed algo-rithms is quite stable to the choice of  X  . Therefore, for simplicity we only show the results with  X  = 0 . 1. We first show that our algorithm can really boost the performance of the two different weak learners and outperform the other online boosting algorithms for most data sets, which are summarized in Tables 1 and 2. The proposed algorithm, when using only the uniform weighting scheme, is denoted as OSBoost (On-line Smooth-Boost). Other variants will be examined later in this section. The bold entries in the OSBoost column indicates that OSBoost improves the perfor-mance over a single weak learner, and a  X * X  in the col-umn indicates the best performing boosting algorithm. For the Perceptron weak learner in Table 1, our pro-posed OSBoost is consistently better than a single weak learner across all the data sets. Furthermore, on 8 out of the 12 data sets, OSBoost is better than the other two leading algorithms in online boosting. The performance difference is especially evident on large data sets. For the Naive Bayes weak learner in Table 2, our proposed OSBoost remains to be the best choice: boosting the performance of a single weak learner and continuing to be superior to the other two algorithms with a big difference in performance.
 We then discuss the effectiveness of OSBoost.OCP and OSBoost.EXP, the two variants of our algorithm us-ing Online Convex Programming and Predicting with Expert Advice as described in Section 4, respectively. The results are shown in Table 3 and 4. The bold entries in the OCP and EXP columns indicate that the variant improves the performance of the basic, uniformly-weighted OSBoost. First of all, we see that the basic OSBoost readily performs quite well, while the variants can sometimes result in a marginal gain of performance. The improvements of OSBoost.EXP over the basic OSBoost is more prominent when the data set is small, which is because OSBoost.EXP can be implicitly adapted to use fewer weak learners in a randomized manner to avoid overfitting the small set. The improvements of OSBoost.OCP over the ba-sic OSBoost, on the other hand, happen mostly on larger data sets, which is in accordance to our analysis since the average error would diminish in Online Con-vex Programming only when the number of rounds T is large enough.
 While having a clear advantage in performance, our al-gorithms also run as fast as other online boosting algo-rithms. In fact, each iteration of all our algorithms ex-cept OSBoost.OCP can be carried out easily in O ( N ) time with N weak learners. For OSBoost.OCP, an ex-tra projection step is needed, for which we implement an O ( N log N )-time algorithm by Duchi et al. (2008); in fact, a more sophisticated method in Duchi et al. (2008) can achieve this in expected O ( N ) time. We propose a novel online boosting algorithm. The al-gorithm is simple in its formulation, but nevertheless carefully designed from the theoretical perspective to avoid many intrinsic difficulties when adapting boost-ing algorithms to the online setting. In particular, we define the notion of weak learning for online boost-ing, and exploit the notion to extend one promising offline boosting algorithm to its online version. We also tackle the problem of choosing a suitable num-ber of weak learners with a careful use of established theoretical results.
 The proposed algorithm is not only solid in its theoret-ical justifications, but leads to promising experimental results. We demonstrate that the proposed algorithm can indeed boost online weak learners on real-world data sets. Most importantly, the proposed approach is significantly better than existing approaches while they do not come with such solid theoretical justifi-cations. Future works include extending the proposed approach to other problems, including online multi-class or multi-label classification.
 We thank Ching-Hua Yu for providing the idea of us-ing the framework of Predicting with Expert Advice . We also thank the anonymous reviewers for valuable suggestions. This work is supported by the National Science Council (NSC 100-2628-E-002-010 and NSC 100-2221-E-001-008-MY3) of Taiwan.
 Babenko, B., Yang, M., and Belongie, S. A Family of Online Boosting Algorithms. In 3rd IEEE ICCV
Workshop on On-line Learning for Computer Vi-sion , pp. 1346 X 1353, 2009a.
 Babenko, B., Yang, M., and Belongie, S. J. Visual tracking with online multiple instance learning. In Proceedings of CVPR , pp. 983 X 990, 2009b.
 Bshouty, N. H., Gavinsky, D., and Long, M. On boosting with polynomially bounded distributions. JMLR , 3:483 X 506, 2002.
 Cesa-Bianchi, N. and Lugosi, G. Prediction, learning, and games . Cambridge University Press, 2006. Duchi, John, Shalev-Shwartz, Shai, Singer, Yoram, and Chandra, Tushar. Efficient projections onto the l1-ball for learning in high dimensions. In Proceed-ings of ICML , pp. 272 X 279, 2008.
 Feldman, Vitaly. Distribution-specific agnostic boost-ing. In Proceedings of ICS , pp. 241 X 250, 2010. Frank, A. and Asuncion, A. UCI machine learning repository, 2010. URL http://archive.ics.uci. edu/ml .
 Freund, Y. and Schapire, R. E. Game theory, on-line prediction and boosting. In Proceedings of COLT , pp. 325 X 332. ACM Press, 1996.
 Freund, Y. and Schapire, R. E. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sci-ences , 55(1):119 X 139, 1997.
 Friedman, J. H. Greedy function approximation: A gradient boosting machine. Annals of Statistics , 29: 1189 X 1232, 2000.
 Grabner, H. and Bischof, H. On-line boosting and vision. In Proceedings of CVPR , volume 1, pp. 260 X  267, 2006.
 Grabner, H., Leistner, C., and Bischof, H. Semi-supervised on-line boosting for robust tracking. In Proceedings of ECCV , pp. 234 X 247, 2008.
 Grbovic, M. and Vucetic, S. Tracking concept change with incremental boosting by minimization of the evolving exponential loss. In Proceedings of ECML/PKDD , pp. 516 X 532, 2011.
 He, J. and Thiesson, B. Asymmetric gradient boosting with application to spam filtering. In Proceedings of CEAS , 2007.
 Kudo, T., Maeda, E., and Matsumoto, Y. An applica-tion of boosting to graph classification. In Proceed-igns of NIPS , 2004.
 Leistner, C., Saffari, A., Roth, P. M., and Bischof, H. On Robustness of On-line Boosting -A Competitive Study. In 3rd IEEE ICCV Workshop on On-line Learning for Computer Vision , pp. 1362 X 1369, 2009. Littlestone, N. and Warmuth, M. K. The weighted majority algorithm. Information and Computation , 108(2):212 X 261, 1994.
 Liu, X. and Yu, T. Gradient feature selection for online boosting. In Proceedings of ICCV , pp. 1 X 8, 2007. Mukherjee, I., Rudin, C., and Schapire, R. E. The rate of convergence of adaboost. JMLR W&amp;CP , 19: 537 X 558, 2011.
 Oza, N. C. and Russell, S. Online bagging and boost-ing. In Proceedings of AISTATS , pp. 105 X 112, 2001. Pelossof, R., Jones, M., Vovsha, I., and Rudin, C. On-line Coordinate Boosting. Oct 2008. URL http: //arxiv.org/abs/0810.4553 .
 Rosenblatt, F. Principles of Neurodynamics: Percep-trons and the Theory of Brain Mechanisms . Spar-tan, 1962.
 Schapire, R. E. and Singer, Y. Boostexter: A boosting-based system for text categorization. Machine Learning , pp. 135 X 168, 2000.
 Schapire, R. E., Freund, Y., Bartlett, P., and Lee,
W. S. Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods. The An-nals of Statistics , 26(5):1651 X 1686, 1998.
 Servedio, R. A. Smooth boosting and learning with malicious noise. JMLR , 4:473 X 489, 2003.
 Zinkevich, M. Online convex programming and gener-alized infinitesimal gradient ascent. In Proceedings
