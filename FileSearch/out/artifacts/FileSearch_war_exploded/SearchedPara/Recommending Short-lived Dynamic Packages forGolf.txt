 We introduce an approach to recommending short-lived dy-namic packages for golf booking services. Two challenges are addressed in this work. The first is the short life of the items, which puts the system in a state of a permanent cold start. The second is the uninformative nature of the package attributes, which makes clustering or figuring la-tent packages challenging. Although such settings are fairly pervasive, they have not been studied in traditional recom-mendation research, and there is thus a call for original ap-proaches for recommender systems. In this paper, we intro-duce a hybrid method that leverages user analysis and its relation to the packages, as well as package pricing and en-vironmental analysis, and traditional collaborative filtering. The proposed approach achieved appreciable improvement in precision compared with baselines.
 H.3.3 [ Information Search and Retrieval ]: Information Filtering Experimentation, Measurement, Verification Dynamic packages, cold-start, recommendation, field study, user analysis
Consider the booking or renting of a particular place on a reservation site. Specifically, we consider booking a round of golf through a golf booking service. Golf courses can be booked by users with a variety of options and prices: party size, a caddie to carry golf clubs, lunch, a guarantee of two-person pair parties, a competition option for several parties, and a certain start time, among many other options. c  X  We would like to recommend to users not only courses they may like, but also priced packages of options that they may like on top of recommended parent courses.

Such options as described above are wide ranging. Ex-tensive options are provided not only for golf courses on Rakuten GORA, but hotels as well: rooms on Rakuten Travel can be booked with many options ranging from break-fast/lunch/dinner to late checkout, and an outdoor bath. Additionally, coupons can be considered as short-lived dy-namic packages that target regular E-commerce products. Car rental services also use such packages. In the present pa-per, we refer to these packages as short-lived dynamic book-ing packages . Recommendations exist in the form of adver-tisement for this type of item in golf, but a preliminary sur-vey 1 tells us that non-trivial recommendation systems seem not to exist. Considering the scale of the target industry given its user mass 2 as well as its average order value 3 recommendation of packages is essential for business success. However, to the best of our knowledge, such recommenda-tions have not been studied in traditional research.
There are two main challenges in recommending such pack-ages. The first relates to their short-lived aspect; on a B2B2C site, merchants (e.g., golf course owners or hotel owners) input the packages for their course and set different prices according to options, season, trends, and target cus-tomers. We found that most such packages expire in a month after the start of their active period, including very short time-limited special offers (Figure 1). Moreover, the price trends is what makes the packages dynamic (Figure 2). This puts the package recommendation system under a regime of a permanent cold start. Ratings, the objective variable most favored by classical collaborative filtering approaches for atomic items, are not available. Co-counting using pur-chasing/browsing history is also very limited, as customers book an average of 4.5 courses per year, i.e., one package ev-ery 2.7 months. This means that they do not book packages fast enough on average for traditional models to be learned and used in the short term.

In recommendation, the straightforward approach under a cold start regime or working on long-tailed items is to turn to content-based methods of information retrieval. This gives rise to the second challenge: uninformative data. Package
Survey conducted in 2013 on the following websites: Alba (Japan), GDO (Japan), Golf-Jalan (Japan), GolfDigest (US), TeeOffTimes (UK).
On the order of 3 million users on Rakuten GORA alone, approximately 2.5% of the population of Japan.
The AOV is approximately 90 USD per golf reservation. Figure 1: Histogram of package lifespans in the pe-riod of June 2012 through May 2013. contents comprise flags and categorical variables for vari-ous options, but analysis of the items alone based on their content results in poor clusters or latent packages, because options have different importance to the package value from the point of view of the user. Thus, direct application of clustering using similarities such as the Jaccard index, where every attribute is weighed the same, performs poorly.
In addressing the challenges mentioned, we leverage reser-vation histories enriched with package and course data to assess user behavior, and conduct an analysis of package pricing. This allows us to construct a similarity score that performs well. Our approach is threefold, in that we: 1. extract user behavioral characteristics, 2. conduct collaborative filtering on parent items, and 3. perform content-based information retrieval using user preferences and the package price.
Plan data themselves are uninformative for similarity (as shown in Section 3.1 by Jaccard X  X  poor precision). We ana-lyze packages through users, enriching their reservation his-tory with package and course data. The data were aggre-gated to build user behavior vectors, which we Z-transformed and clustered using Euclidean k-means. Figure 3 shows vastly different behaviors with regard to package options and price (e.g., spending deviation growing with the spend-ing average), and a need to develop adequate similarity met-rics. We define the user-weighed option similarity score for a package p with respect to a user u as where k belongs to the subset O of vector indices of p de-noting flags or dummy-coded categorical attributes, and P is a logistic factor such as Figure 3: Cluster centroids of users having booked at least two courses. Pairs and friends each comprise 35% of users, while the others each comprise 10%.
 Table 1: Weights of logistic models predicting occur-rence of options in the next booking. Only weights that are over 10  X  1 for a response (in bold) are shown. where  X  0 ,S u and  X  1 ,S u are respectively the intercept and coefficient vector for cluster S u to which u belongs after clustering. This probability corresponds to user u choosing the option p k for the next booking. P ( P k | U ) is learned by leaving the last package p ( last ) booked by a user and us-ing its p ( last ) k  X  O as dependent variables and the user vector as independent variable for learning. We show example logis-tic weights for three output probabilities in Table 1, each predicting the future occurrence of an option 4 .
The reference package is used mainly to compute the price similarity described in Section 2.4. It is also necessary to perform the subsequent experiments of this paper for the
We used Weka version 5.3.001 for computing logistic re-gression (http://www.cs.waikato.ac.nz/ml/weka/). Figure 4: True prices vs. predictions for a course. Table 2: Sets of features for the linear model of price. The final set is { m } X { d } X  A  X  P .
 Set Features Temporal Month of year (m), day of week (d)
Attributes (A) Lunch, caddie, competition, Promotional (P) Promotion type, shortness of package Jaccard baseline (Section 3.1). We first extract the refer-ence course that was played the most in the season closest to the target season, using a simple scoring function. For example, if we would like to recommend packages in June, a course played twice around June scores higher than one played twice in December. This is based on the assumption that a user likes a course if he has booked it several times, and the observation that users have affinities to courses that are seasonal. Once the reference course is selected, we sim-ply select the last package booked as the reference package.
Collaborative filtering should be leveraged wherever pos-sible, even if impractical for the granularity of packages. In our case, there are 1,951 courses in our system, each generating packages that we want to recommend on top of them to users. This gives us a parent course item/item co-occurrence matrix for courses of rank 1,951. Because we have at least 100,000 active users in the period to populate the co-occurrence matrix, the matrix is very dense, which works well with collaborative filtering. As the course recom-mender already performs well on Rakuten GORA, we choose to use it in a collaborative filtering step to filter courses of interest to the user.
To improve the scoring function, we develop a similarity component based on package price, which should be lever-aged because our analyses reveal two important patterns: 1. 90% of users do not deviate by more than 30% from their average spending (the remaining 10% belong to the cluster of refined users in Figure 3), and 2. the price itself contains enough information about the package to make it a potent similarity measure.

To demonstrate point (2), we run a regression on a course in the data that has generated many packages. Using the Cartesian feature set of Table 2, we build a linear model that gives prices of packages that are fairly close to the truth (see Figure 4). Note that the plot in Figure 4 is heteroscedastic, which shows that pricing becomes loose at the high end, as consistently does spending (Section 2.1). We define price similarity score for a package p with respect to a user u and a reference plan p ( ref ) selected from his/her history as  X 
S and p ( ref ) compensating for seasonal trends,  X  is a currency scaling factor, and  X  ( u ) price is the user X  X  spending deviation.
The final score is defined as  X  where  X  S c is the parent course score after filtering (Section 2.3), and w p , w o and w c are weights whose optimal values can be found through hill-climbing with respect to EMP@n.
This section details the offline and online evaluation. For offline evaluation, we compared the precision of our ap-proach with that of the basic similarity method, and tested three different options. We then launched an e-mail cam-paign for online evaluation. None of our data contains per-sonal information such as names or addresses.
We tested our proposed methods on golf booking data col-lected from June 2012 to May 2013. The number of unique users in this period is 521,442 and the total number of book-ings is 2,499,678. We used the booking history from June 2012 to May 2013 to generate the package recommendations. We then checked what packages users actually booked from 1 June 2013 to 15 June 2013. We call this evaluation index the expected minimum precision (EMP), because the num-ber of booked packages would increase if users interact with our recommendation results. This setting has been widely used in the evaluation of recommender systems; e.g., [5]. The EMP is defined as
We test four settings in this experiment: 1. the Jaccard score computed as in place of S price and S opt , where the p values are here used to denote the attribute sets, 2. the user-weighed option similarity S opt without S price 3. the final score incorporating S opt and S price without r 4. the final score incorporating S opt and S price with r for price adjustment. Figure 5: EMP@n curves for each tested method.
 Each of these settings incorporate the same reference course and package selection step (Section 2.2) and course filtering step (Section 2.3).

Figure 5 shows that the scores incorporating price similar-ity perform best, independently of price trend adjustment. User-weighed similarity performs reasonably well but not nearly as well as when price is incorporated. Finally, the Jaccard baseline shows very poor performance. For a top-five returned list, the EMP of the proposed method is 25% more efficient than that of user-weighed similarity, and 30% more than that of the Jaccard baseline.
We performed online evaluation by conducting a person-alized e-mail campaign. We sent e-mails that contained six recommended packages on one day in December 2014 and evaluated the click-to-open-rate (CTOR) and conversion-to-open-rate (CVR). Here, the CVR refers to the event that a customer clicked on the recommended package and made a reservation. We compared the performance to that of pre-vious and following e-mail campaigns. E-mails in these two campaigns contained approximately 100 packages selected by specialists based on their contents and target demograph-ics. Our approach achieved the highest CTOR and CVR with the maximum improvement in the CTOR was 200%.
We briefly describe previous research on dynamic items and a cold start. Schein et al. [4] raised the cold-start prob-lem in recommendation. To overcome the lack of user prefer-ence information that is essential for collaborative filtering, they proposed a probabilistic model that combines content and collaborative filtering. Chu and Park [1] combined user and item profiles in a dynamic bilinear model for time-aware recommendation for the Today module on the Yahoo! front page. Matrix factorization techniques that solve a cold-start problem were also proposed in several works [2, 3].
The crucial difference between short-lived dynamic items and the items in the research body on permanent cold-start regimes is their short life-span and non-retrievable aspects. To be more specific, short-lived items will expire within a month after the start of their active period, as is shown by our observations (Figure 1). Such items cannot be retrieved (i.e., booked, searched for, browsed, or recommended) by/to users once they expire. They also have generally poor sta-tistical value in a user/item matrix because of their capped counts, especially when this matrix does not embody a no-tion of time and relevance to the present.

On the other hand, Zhu et al. [5] proposed the bundle recommendation problem in e-commerce. According to the observation that users usually buy more than one item on e-commerce sites and that displaying related items together improves conversion, they proposed a recommender system that maximizes the reward function (conversion rate and revenue/profit of the bundle). This work is different from ours in that it focused on creating bundles, whereas our work focuses on recommending packages that are created by merchants using different values of limited attributes such as lunch, and competition.
In this work, we identified a pervasive subset of items that ought to be the subject of a recommendation research: short-lived dynamic booking packages. We showed that the problem is unique in terms of the short lifespan of items and the uninformative nature of the data, which calls for an original recommendation approach. We performed an exper-iment over a subset of users that resulted in appreciable im-provements in EMP when leveraging user analysis and price analysis of the package to define adequate scoring functions. We also performed an actual A/B test for a mail recommen-dation and found that the click-to-open rate was twice that achieved with human selection of packages. In further work, we would like to refine the metrics and address a third chal-lenge, namely that booking packages are designed to book a parent item, which inherently adds a notion of schedule to the problem constraints and makes recommendation chal-lenging when the user schedule is unknown.
 We would like to thank Satoko Marumoto, Takahiro Kuroda, Yusuke Sasamori, Ryo Yoneda, Yoshiro Matsuda, Yu Hirate, and all contributors to this research for their support.
