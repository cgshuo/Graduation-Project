 We investigate the task of finding links from Wikipedia pages to external web pages. Such external links significantly extend the information in Wikipedia with information from the Web at large, while retaining the encyclopedic organization of Wikipedia. We use a language modeling approach to create a full-text and anchor text runs, and experiment with different document priors. In addi-tion we explore whether social bookmarking site Delicious can be exploited to further improve our performance. We have constructed a test collection of 53 topics, which are Wikipedia pages on differ-ent entities. Our findings are that the anchor text index is a very effective method to retrieve home pages. Url class and anchor text length priors and their combination leads to the best results. Using Delicious on its own does not lead to very good results, but it does contain valuable information. Combining the best anchor text run and the Delicious run leads to further improvements.
 Categories and Subject Descriptors: H.3.3 [Information Search and Retrieval] General Terms: Experimentation, Measurement, Performance. Keywords: Link Detection, Entity Search, Wikipedia.
Wikipedia is a natural starting point for information on almost any topic. As a result, Wikipedia is one of the top ranked results for all queries matching an article X  X  title. But where to go if you want to know more? Can we point searchers directly to other relevant web pages? For this purpose, many Wikipedia pages contain  X  X xternal Links X  to web pages. According to the guidelines, 1 the links in the External Links section should link to sites that contain neutral and accurate material that is relevant to an encyclopedic understanding of the subject. For example, pa ges about en tities should link to its official home page, and pages about media to a site hosting a copy of the work.

However, only some 45% of all Wikipedia pages have an  X  X xter-nal links X  section. Hence, our research question is: To evaluate how well we can find external links for Wikipedia pages, we construct a test collection by removing the currently ex-isting links in Wikipedia, and using these links as our ground truth. This is similar to the INEX Link-the-Wiki task [2] where the task consists of finding links between Wikipedia pages. Our task is to http://en.wikipedia.org/wiki/Wikipedia:External_links find links from Wikipedia pages to external web pages. We use the Clueweb category B, consisting of 50 million English web pages as our test collection to find the external web pages.

To validate that Wikipedia X  X  external links indeed correspond to official home pages, we use the assessments of the 2009 TREC en-tity ranking task. These assessments contain 60 relevant Wikipedia pages with at least one linked website in the Clueweb collection. When we consider the entity as a query, and urls found in  X  X xternal links X  as ranked pages a Mean Reciprocal Rank of 0.768 is attained for finding the home pages. That is, there is a high level of agree-ment between the External Links in Wikipedia and the independent judgment of a TREC assessor on w hat constitutes t he home page for an entity.
Our task is defined as follows: Given a topic, i.e. a Wikipedia page, return the external web pages which should be linked in the  X  X xternal Links X  section. We have created a topic set by reusing rel-evant entities found in the TREC En tity Ranking task. The topic set contains 53 topics with 84 relevant home pages. A topic can have more than one relevant home page, because the Clueweb collec-tion contains duplicate pages, i.e. pages with the same normalized url. We match the urls of the existing external links on the Wiki-pedia pages with the urls in the Clueweb collection. External links on entity pages are split into two parts, the first external link is a home page, the other links are usually informational pages. In our experiments we only use the home pages.
We experiment with three approaches. First, our baseline ap-proach is a language model with a full-text index. Secondly, we make an anchor text index, which has proved to work well for home page finding [1]. We experiment with different document priors for both indexes. We construct priors for the document length, anchor text length, and the url class [3]. To determine the url class, we first apply a number of url normalization rules, such as removing trailing slashes, and removing suffixes like  X  X ndex.html X . Since we have no training data, we cannot estimate prior pr obabilities of url classes based on the distribution of home pages in the training col-lection. Instead we use only two url classes: root pages (a domain name not followed by any directories) receive a prior probability a 100 times larger than non-root pages, which is a conservative prior compared to the previous work [3]. Our third approach ex-ploits information of social bookmarking site Delicious . Delicious ranks search results by relevance, taking into account bookmark titles, notes, and tags, among other things. We send a search re-Prior MRR Suc @5 MRR Suc @5 None 0.0385 0.0364 0.5865 0.7091 Doc. length 0.0085  X  0.0000 0.4178  X  0.5455  X  Anchor length 0.0853  X  0.1636 0.6131 0.6909 Url class 0.2348  X  0.2727  X  0.6545 0.7273 Anch.length + Url 0.2555  X  0.2909  X  0.6774  X  0.7636 quest to the site and match the first 250 results with the urls in the Clueweb collection to create a ranking. As retrieval score we use the (inverted) ranks. To make combinations with our language model runs we normalize all scores using the Z-score and make a linear combination of the normalized scores.

For our experiments we use the Indri toolkit. We build two indexes: an anchor text and a full text index. Both indexes are stemmed with the Krovetz stemmer. We have created document priors for document length, anchor text length, and url class. For all our runs we apply Dirichlet document smoothing. To construct the query we always use the title of the Wikipedia page. We use Mean Reciprocal Rank ( MRR ) and Success at 5 ( Suc @5 )toeval-uate our runs.
Results of our experiments using the language modeling approach are shown in Table 1. The anchor text index leads to much better results than the full-text index. Home pages often contain a lot of links, pictures, and animations, and not so much actual text, so it was to be expected that the anchor text index is more effective. For the same reason, applying a document length prior deteriorates the results: longer documents are not more likely to be a relevant home page.

The two other document priors do lead to improvements. The full-text index run has much more room for improvement, and in-deed the priors lead to a major increase in performance, e.g. using the url class prior increases the MRR from 0.0385 to 0.2348. The improvements on the anchor text runs are smaller. The anchor text length prior does not affect the results much. A reason for this can be that the Dirichlet smoothing also takes into account the docu-ment length, which equals the anchor text length for the anchor text run. Despite its simplicity, the url class prior leads to signifi-cant improvements for both the full-text and the anchor text runs. Since we did not have training data available, we did not optimize the url class prior probabilities, but used a conservative prior on only two classes. Combining the full-text runs and the anchor text runs does not lead to improvements over the anchor text run. We experimented also with including different parts of the Wikipedia page in the query, such as the first sentence and the page categories, but none of these runs improved over using only t he title of the page. By analyzing the failure cases, we identify three causes for not finding a relevant page: the external link on the Wikipedia page is not a home page, the identified home page is redirected or varies per country, and the Wikipedia title contains am biguous words or acronyms.

Besides the internal evidence, we also looked for external evi-dence to find home pages. The results of the run using Delicious, and a combination with the best anchor text run can be found in Ta-ble 2. The Delicious run performs better than the full-text run, but not as good as the anchor text run. One disadvantage of the Deli-cious run is that it does not return results for all topics. Some topics with long queries do not return any results, other topics do return results, but none of the results exists in the Clueweb collection. For 49 topics Delicious returns at least one result, for 41 topics at least one Clueweb page is returned. Around half of all returned results are part of the Clueweb collection. When we combine the Delicious run with the best anchor text run we do get better results, so Deli-cious is a useful source of evidence. Most of the weight (0.9) in the combination is on the anchor text run though. The Delicious run retrieves 68 relevant home pages, which is more than the 58 pages the anchor text run retrieves. The Delicious run however contains more duplicate pages, because it searches for all pages matching the normalized url retrieved by searching Delicious. In the com-bination of runs, pages found both by Delicious and by the anchor text run, end up high in the ranking.

When we compare our results to previous home page finding work, we can make the following remarks. Most differences can be attributed to the test collections. Clueweb is crawled in 2009, and in comparison to older test collections the full-text index performs much worse. Modern home pages contain less relevant text and more pictures, photos and animations, making the full-text index less informative. The anchor text index on the other hand, performs better than ever before. The Clueweb collection is larger than pre-vious collections, and has a higher link density, so there is more anchor text available for more pages.
In this paper, we investigate the task of finding external links for Wikipedia pages. We have constructed a test collection of top-ics about different entities, with th eir corresponding relevant home pages. Two language modeling approaches, one based on a full-text index, and one based on an anchor text index have been inves-tigated. In addition a run based on the Delicious bookmarking site is made. All anchor text runs perform much better than the full-text index runs. Useful document priors are the anchor text length and the url class. Delicious on itself does not perform so well, but it is a useful addition when it is combined with an anchor text run. We can conclude our system is effective at predicting the external links for Wikipedia pages.
 [1] N. Craswell, D. Hawking, and S. Robertson. Effective site find-[2] D. W. Huang, Y. Xu, A. Trotman, and S. Geva. Overview of [3] W. Kraaij, T. Westerveld, and D. Hiemstra. The importance of
