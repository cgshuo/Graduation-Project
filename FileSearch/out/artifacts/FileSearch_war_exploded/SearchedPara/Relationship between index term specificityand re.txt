 1. Introduction Specificity has been one of the core concepts in librarianship and information science from its earliest days.
The concern about specificity emerged as a practical issue for cataloguing, especially in allocating subject headings or descriptors to each documentary unit. In 1876, Cutter wrote,  X  X  Enter a work under its subject head-ing, not under the headings of a class, which includes that subject  X  X  (p. 37). Since then, specificity has been dis-cussed usually as a criterion for identifying index terms or descriptors. A common focus of the previous research on specificity is on its discriminating ability, which is the ability to distinguish a class of documents from other classes of documents, or one subclass from another. Such a distinguished class should be a class of documents related to a user X  X  criteria for her/his relevant judgment, which is based on her/his information need. Therefore, a salient research question emerges: What is the impact of specificity on a user X  X  relevance judgment? Because relevance judgment is a basis for evaluation of effectiveness of an information retrieval system, the impact of specificity, if it exists, is also a factor for effective information retrieval. Although some previous research has focused on the impact of specificity on some notions based on relevance judgment, such as recall and precision ( Soergel, 1994; Sparck Jones, 1972; Svenonius, 1971 ), no research has been identified which addresses the impact of specificity on relevance judgment.

However, several concepts of specificity have been used in research, but these have not been consistent as the list below indicates: (1)  X  X ndexing X  is more specific than  X  X nformation retrieval X  to a book titled (2)  X  X at X  is more specific than  X  X omestic animal X , because  X  X at X  is semantically narrower (3)  X  X ancer-Chemotherapy-Congresses X  is more specific than  X  X ancer X , because the (4)  X  X hesaurus X  is more specific than  X  X ndexing X  in a bibliographic database named
This diversity in the meaning of the term has affected research on specificity, and shows different charac-teristics between the concepts. For instance, Weinberg and Cunningham (1984, 1985) point out that hierarchi-cal specificity is not always positively correlated with posting specificity when using two groups of terms: core terms and peripheral terms in a subject area. Also, Khosh-Khui (1987) indicates that statement specificity is not related to posting specificity at all. The existence of various concepts of index term specificity allows us to refine and expand the research question, as follows (1) Do the above concepts of specificity affect users X  rele-vance judgments? (2) What are the relationships among the concepts? (3) Does a combination of the concepts affect relevance judgments more than any single concept?
In spite of the diversity, researchers generally agree on the characteristics of specificity as a relationship in terms of subject, topic, meaning, and/or theme, and as a degree. This means that a specific term indicates that the term is involved in a topical relationship with a document, another term, or a set of documents, and that one term may be more or less specific than another term. This helps to set a framework for the discussion of specificity.

The main purpose of this study is the identification of the significant relationship between relevance judg-ment and specificity. Also, reliable and acceptable ways to measure types of specificity are explored. This study is purposely done using selected subject areas with a limited number of queries in each area. The unit of ana-lysis is the term and this provides for a large enough sample to suggest that results might be generalizable; however, it is not intended that this, in fact, be done. In effect, this is a methodological study focusing on relevance and specificity. Four concepts of specificity are identified in the next section and, following that, is the report of an experiment investigating relationships between specificity and relevance judgments of users. 2. Concepts of specificity
It is important to distinguish among the four concepts of specificity: term-document specificity, hierarchical specificity, statement specificity, and posting specificity. Term-document specificity focuses on the topical rela-tionship between an index term and a document indexed with the term. The question regarding this specificity is how accurately the term represents the topic of the document which is indexed with the term. Due to the semantic characteristics of term-document specificity, this is quite complicated to estimate, and automatic methods to assess this, beyond human intelligence, have not been successful.

Hierarchical specificity is based on the term X  X  own meaning and is defined in a generic-specific hierarchical structure of terms, such as a thesaurus, by a human being. It is a relationship between terms, and it is easily measured in the hierarchy. The assumption for this specificity is that a narrower term is more specific than a broader term in a term hierarchy. Human knowledge can be organized into hierarchies of terms. In the hier-archies, a child or leaf item (narrower term) can be defined as a more specific one than its parent or root item (broader term), and this relationship is fixed. In this sense, the opposite concept of specificity would be generalization, with specificity X  X  synonym being specialization.

Statement specificity is based on the assumption that a string of terms, as in a subject heading or in a search statement, is more specific than a single term. This concept has usually been discussed in cataloguing, in which subject headings can be modified with various tools, such as modified terminology, modifiers, parentheses, and subdivisions ( Steinweg, 1979 ). It can be easily measured by the number of terms in a statement. Posting specificity is based on the assumption that if the number of documents which are indexed with term
A is smaller than the number of documents indexed with term B in a set of documents, then term A is more specific than term B . Its meaning is similar to the uniqueness of a term in a set of documents so that it is a relationship between a term and a set of documents. It can easily be measured with the number of documents indexed with a term (document frequency).

Previous research on specificity can be categorized into four groups based on the four definitions of spec-ificity as seen in Table 1 . In this table, Mary D. Wilson (Wilson, M.) and Patrick Wilson (Wilson, P.) are listed under three concepts: term-document, hierarchical, and statement specificity. This signifies that although these authors did not clearly define the concept of specificity in their studies, their concept of specificity can be seen as a combination of the three concepts mentioned here. This is a common view of specificity in cataloguing. In cases where a researcher discusses multiple definitions of specificity, only one definition, which is the focus of the discussion, is identified. For instance, even though Svenonius (1971) discusses seven definitions of speci-ficity, her focus is on posting specificity. Similarly, among the five definitions in Balnaves (1976) , term-docu-ment specificity is the focus.

Term-document specificity is the innate definition of specificity. When Cutter (1876) emphasized filing and locating a document under its specific subject heading, his concept of specificity was term-document specific-ity, because he focused on appropriate representation of a document using a specific subject heading. Balnaves (1976) also discussed term-document specificity with other definitions. He concluded that this specificity is the most promising one among the definitions according to the general theory of indexing, and that specificity deals with the accuracy of document representation. When Anderson and Pe  X  rez-Carballo (2000) discussed specificity, they defined it as  X  X  a degree of closeness between the meanings of an index term and the topics that are discussed in messages, or between the meanings and the features that a message, a text, or a document exhibits or possesses  X  X .

Among the four types of specificity, statement specificity is not applied to index terms, but to compound subject headings and search statements. Since the interest of this study is on specificity in index terms, state-ment specificity is excluded. Therefore, term-document specificity, posting specificity, and hierarchical speci-ficity are investigated in terms of users X  relevance judgment. 3. Experiments 3.1. Data description The current data uses data collected in an experiment by Saracevic and his colleagues ( Saracevic, 1989;
Saracevic, Mokros, Su, &amp; Spink, 1991 ) for investigating interaction between users and intermediaries. The ori-ginal study design called for users to search 40 questions in various subject areas; a total of 6225 documents were retrieved. The relevance of each retrieved document to the users X  information need was judged by the users using a three-point measurement scale: non-relevant, partially-relevant, and relevant. There were four intermediaries at various Rutgers libraries covering science, medicine, humanities, and social sciences. Each intermediary was specialized in databases on a given subject; their average online experience was 8.5 years. The data set provides relevance judgments for each retrieved document by end users.

Databases were selected according to each query X  X  subject area. Among the data, three questions were selected for this analysis based on the subject area of the query. The subject areas of the queries are critical, because a specificity estimator should be linked to a specialization in a subject area. Some features of data are shown in Table 2 which includes the database searched and the number of items retrieved. The total number of retrieved documents for this subset of questions is 175.

A query may consist of several terms and Boolean operators. A term is defined as a string of words wrapped by the Boolean operators in the experiment. For example, when a query is: process , and writing instruction . The average number of terms per query is 2.06. A sample retrieved document is provided in Appendix . 3.2. Variables
The user X  X  relevance judgment, which is called relevance, is defined here as a dependent variable and it is scored by end users who originally develop the questions. The three-point scale of non-relevant, partially-relevant, and relevant are coded as 0, .5, and 1.

There are three types of specificities: term-document specificity, postings specificity, and hierarchical spec-ificity. Henceforth these are called t-spec , p-spec ,and h-spec , respectively. t-spec is defined as an independent variable and it is measured as follows. Each document has its bibliographic data, including abstracts. A query consists of multiple terms and Boolean operators. t-spec in this situation indicates how well a document is represented by each term in a query. It is measured by human estimators. The number of levels for the spec-ificity measurement is set as three: non-specific, somewhat specific, and specific. In order to reduce possible subjectivity from an estimator, two estimators, who are former librarians, were employed to measure the specificity. The retrieved document did not include the results of the original relevance judgment to keep the specificity estimate separate from the user judgment.

Prior to the main analysis, consistency of the measured t-spec scores between the two estimators was ana-lyzed to determine the final t-spec scores for each term. The number of possible cases of the difference in scores between the two estimators is three: 0 (no difference), 1 (1 scale difference), and 2 (2 scales difference). When there is no difference (0) in scores between the two estimators, the scores are consistent. Two hundred and seven out of 360 terms (57.5%) were in this case. When there is 1 scale difference, the scores between the two are not perfectly consistent, but show the same tendency between the two. In this case, a mean score between the two would be accepted as a final t-spec score and this was applicable to 122 terms (33.9%). Only for 31 terms (8.6%), the differences in scores between the two estimators are at a 2 scale level. The correlation scores from the two estimators are positively related with a notable effect size ( r reasonable to assume that a mean score between t-spec scores by the two estimators can be employed as a final score. The range of the t-spec scores goes from 0 to 1, where 1 indicates that the term was the most specific to the document. p-spec is a ratio between the number of documents in the databases and the number of documents which include a specific term. For instance, ERIC had 714,826 documents in 1989, when the data were gathered, and the number of documents which included the term elementary was 150,382. In this case, p-spec for the term elementary might be assumed to be 150,382/714,826. However it can be proposed that the smaller the number of documents which include a term, the higher the p-spec. Thus, the p-spec for this situation would then be equal to 1 (150,382/714,826) which is (1 .21) or .79. Note that a p-spec distribution is negatively skewed. h-spec is measured from the thesaurus of each database used, such as ERIC, PsycInfo, and MEDLINE.
The thesauri have hierarchical structures. It is measured as a ratio between depth of a term hierarchy, which includes a term, and the number of levels of the term from the top of the hierarchy. For example, when the term perception is at the second level from the top of a hierarchy, whose depth is four levels, the h-spec for perception is 2/4 (which is .5). This situation is described in Fig. 1 . As expected, the distribution of h-spec is also negatively skewed, like p-spec.

The unit of analysis in this experiment is a term. For the three questions, 175 documents were retrieved and 360 terms were matched to the documents. Among them, two documents were not judged for relevance. The four terms attached to these two documents were eliminated. Thus, the number of terms, equal to the sample size, which were evaluated for specificity, was 356 terms. Selected descriptive statistics for the samples are shown in Table 3 .

As seen in the table, distributions of p-spec and h-spec values are not assumed to be normal. However the reasons for the skewed distributions differ. The distribution of h-spec shows that end-users and intermediaries tend to select specific terms as search terms, because other terms in the databases are expected to have diverse values of h-spec, from 0 to 1. The distribution of p-spec found in this study is, however, similar to a typical distribution for p-spec for terms in any database. This means that, as a rule, p-spec for a term is supposed to have a small value, because, with the exception of stopwords, any term should occur in a small number of documents in the databases. In other words, the h-spec distribution shows selected search term characteristics, but the p-spec distribution shows characteristics of all index terms in the databases. Therefore, p-spec values are artificially compressed due to scale limitations; moreover, in order to get productive results, p-spec needs to be transformed to fit a normal distribution. The p-spec was transformed as follows. where d is a number of documents, which include the term, n is the total number of documents in a database, and C is a constant greater than the maximum value of the numerator. In the case of PsycInfo, one of the used databases, the total number of documents in 1989 was 714,826. When a term occurs in only one document, the numerator is limited to a maximum value of about 5.83. With C set as 6, the range then goes from 0 to 1. In the former example, p-spec for the term elementary is calculated as
Therefore, the statistical characteristics for the new p-spec become normal: M = .47, SD = .22, skewness is .56, and kurtosis is .46. The new p-spec will be called as same as old one, p-spec. 3.3. Statistical methodologies in analyses
The resultant research questions in the introduction section can be briefly described as follows: (1) Are there relationships between the types of specificity? If so, what are they? And, (2) Are there relationships between the types of specificity (t-spec, p-spec, and h-spec) and relevance? These research questions are visually shown in Fig. 2 .

Note that the case of strong relationships between the types of specificity (the first research question) is not assumed to be ideal. When the types are strongly related to each other, they tend to represent the same reality and such overlap is less explanatory than showing complementary contributions of shared variability. Also, they are not expected to be maximally correlated because they emanate from different theoretical bases, as described in the previous section. The relationship between the types of specificity is analyzed using correlation methodology.

The effect of the types of specificity on relevance is an immediate concern. t-spec is expected to affect rel-evance, because it represents the topical relationship between an index term and a document, and the topical relationship is one addressing important aspects affecting human relevance judgment. The topical aspect has been frequently studied in the area of relevance. In Mizzaro X  X  historical review (1997) , many authors in rele-vance research have specified the topical aspect as one of the core elements in relevance investigations. p-spec is also expected to affect relevance judgments based on previous research ( Soergel, 1994; Sparck Jones, 1972;
Svenonius, 1971 ), which shows that p-spec improves retrieval effectiveness, such as recall and precision. But, h-spec can be expected to function in another way. Because of the inconsistency between p-spec and h-spec ( Weinberg &amp; Cunningham, 1984, 1985 ), it may not affect relevance judgments.

Some statistical concerns emerge upon the analysis of the variables since some of the variables are repre-sented by non-normal distributions. Furthermore, the number of relevance scales is only three, leaving corre-lation analysis of limited value in understanding the relationship between relevance and the types of specificity.
Nonetheless, analysis of variance (ANOVA) is a good alternative for showing the differences between rele-vance groups with the different types of specificity. The effect size produced by ANOVA does not, however,
To show the effect of specificity on relevance, there are two alternatives: logistic regression (LOGIT) and dis-criminant function analysis (DA). Both are used for testing the effect of continuous predictors on a categorical dependent variable, but LOGIT has fewer assumptions, not strictly requiring normality of independent vari-ables and homoschedasticity; furthermore, LOGIT can include categorical predictors. Since the distributions of a variable, h-spec, is non-normal (refer to Table 3 ), and since h-spec may not be expected to affect relevance judgments, both LOGIT and DA are adopted to show the effect. Therefore, ANOVA, LOGIT, and DA are used for showing group differences and for predicting group membership.

In addition, even though one of the purposes in both LOGIT and DA is to predict group membership of each case, the correct prediction rate and the effect size are not supposed to be high, because relevance judg-ment is affected by a lot of factors other than specificity and/or topicality. Here, the focus is not to identify almost all factors affecting user X  X  relevance judgment, not to predict the group membership of cases (terms) as well as possible, but to show what type of specificity affects more significantly on the user X  X  relevance judg-ment. In other words, the focus is rather on specificity than on relevance. 4. Results
All statistical analyses were done using the Statistical Package of the Social Sciences. The relationships between three types of specificity (t-spec, p-spec, and h-spec) were analyzed using Pearson product X  X oment correlations.
To control Type I error across the three correlations, the Bonferroni approach was used, and the required p -value was set at less than .016 (.05/3). The results of the correlation analyses are presented in Table 4 .
The only statistically significant correlation is between p-spec and h-spec, and the correlation coefficient is .26 ( p &lt; .001 with effect size, r 2 = .07). This result was expected because terms located at lower levels of the term hierarchies are likely to occur less frequently in the database. Although there is a significant result of the correlation between p-spec and h-spec, the small effect size (7%) indicates the relationship between the two types of specificity does not explain shared variability, and it might be surmised that each type of spec-ificity is affected more by other factors than by the other type of specificity. On the other hand, the relationship between the two can be expected to be non-linear, rather than linear, because the distribution of h-spec is non-normal. Therefore, these analyses indicate that the three types of specificity are, as expected, not closely lin-early related to each other, as confirmed by the small effect size.

The investigation of the relationships between relevance and the types of specificity were separated into two stages. The first stage was to analyze the differences in each of the types of specificity, which was grouped by relevance. In this stage, one-way ANOVA was used. The second stage was to analyze the effects of the types of specificity on relevance judgments using LOGIT and DA.

In the first stage, the results of a series of ANOVA are shown in Table 5 . The results show that t-spec and p-spec do significantly affect relevance. Between them, t-spec affects relevance more than p-spec, based on the
F -values. Interestingly, there is a difference in follow-up results, which are reported in the last column in Table 5 , labeled  X  X bserved significant difference X . According to the ANOVA results, t-spec can divide the document into two groups: a group of non-relevant documents and the other group of partially-relevant and relevant documents. Note that there is no significant difference between partially-relevant and relevant groups of doc-uments. However, the division by p-spec is between a group of partially-relevant documents and the other group of non-relevant and relevant documents, noting here that there is no significant difference between non-relevant and relevant documents. Those results are shown in Fig. 3 . Note that Table 5 does not include effect size because the placement of the variables is reversed from their usual order, obviating the need to report on variance explained. In this stage, the main focus is to show if and where group differences in spec-ificity exist. In the second stage, the effect sizes for specificity are given.
 In the second stage, there are two concerns: the number of variables and the number of levels of relevance.
According to the results of the first stage, h-spec is not significant in relation to relevance, so we consider the two types of specificity as independent variables: t-spec and p-spec. In previous research on relevance ( Janes, 1993 ), the distribution of relevance judgments tend to be bi-polar: relevant and non-relevant. Also, Saracevic,
Kantor, Chamis, and Trivison (1988) use two-leveled relevance judgment in their analysis, even though they defined their original variable as having three levels (non-relevant, partially-relevant, and relevant) in their experiment. In the current study, both two-leveled and three-leveled relevance judgment were considered.
The results of DA are shown in Table 6 and the results of LOGIT are shown in Table 7 . The results show that statistical significance is enhanced with the inclusion of more levels of relevance, thus producing better results. The percentage of correctly classified cases increases with fewer levels, because of different base lines.
When there is two-leveled relevance judgment, if a case is randomly placed into one of the two levels, the per-centage of correctly classified cases is 50% by chance. And when there is three-leveled relevance judgment, the percentage is 33.3% by chance. Thus, 59.6% of correctly classified cases in three-leveled DV in Tables 6 and 7 means 26.3% (59.6 33.3%) of improvement of prediction by the two variables, t-spec and p-spec, from by chance. In the case of two-leveled relevance judgment, the percentage of improvement is 14.3% (from 50% by chance to 64.3% by the two variables). The results from both analyses are similar to each other with similar effect sizes even though variance explained in computed differently within each method. 5. Discussion
According to the results of correlation analysis, the three types of specificity have their own characteristics and it is potentially useful if these are distinguished from each other. The results of ANOVA, LOGIT, and DA show that t-spec is most significant in relation to relevance, and h-spec is not significant at all. t-spec can identify non-relevant documents from partially-relevant and relevant ones, but it does not distinguish between relevant and partially-relevant documents. It shows that partially-relevant and relevant documents can occur in one category in terms of term-document specificity. These results reflect the bi-polar characteristics of relevance judgments ( Janes, 1993 ). A series of results from DA and LOGIT also shows that when the number of scales in relevance decreases from 3 to 2, there is an increase in the percentage of correctly classified cases going from 59% to 64% of cases correctly classified. p-spec can distinguish partially-relevant document from non-relevant and relevant document, but it does not distinguish between relevant and non-relevant documents, based on ANOVA results. That is, when relevance is continuous, the relationship between relevance and p-spec is not linear but curvilinear. How does p-spec significantly affect relevance in the second stage with its curvilinear relationship to relevance? The significant relationship in the second stage is derived from the non-normal distribution of relevance. Among 356 samples, 208 are non-relevant, and 42 are relevant. Because of the very small number of relevant docu-ments, the curvilinear relationship does not affect the statistical significance of the linear relationship.
Though the results are significant, the effect size is not very large. In other words, there are features other than specificity which affect the relevance judgments. An obvious feature discovered is language. Among the 175 retrieved documents, four documents were written in languages other than English. All four documents were judged as non-relevant documents without any relationship to specificity. Another feature could be found from the distribution of users X  relevance judgments (refer to Table 8 ).

Interestingly, the distribution of non-relevant and partially-relevant judgments of Subject 08 is the opposite of the distribution shown by Subject 21. According to the presearch questionnaire, both searches were for the subjects X  dissertation research. However, the working stages of their research differ. The working stage of
Subject 08 was the second out of five stages. On the contrary, Subject 21 was on his/her first stage. Accord-ing to Kuhlthau (1993) , the information seeking process consists of six stages: task initiation, topic selection, prefocus exploration, focus formulation, information collection, and search closure. Since the subjects had already completed focus formulation for their dissertation research, their working stages would not be matched to initiation, selection, or exploration. The working stage of Subject 08 would be matched to infor-mation collection, and that of Subject 21 would be matched to focus formulation. This shows that the stage in a search process could affect relevance judgment decision-making.

Even though specificity was not expected as the only feature linked to users X  relevance judgment, specificity was proven to be one of the significant features of an index term for retrieving relevant documents, especially term-document specificity (t-spec). In other words, this study affirms a long held assumption that documents should be indexed with specific terms in order to be retrieved as relevant documents. In order to apply the results to automatic indexing, the operationalization of term-document specificity should be investigated.
As pointed out previously, the only drawback of term-document specificity is its inability to be measured by automatic means. However, the consistency of term-document specificity estimation between two parti-cipators in the experiment indicates that this reveals the presence of a method to measure term-document specificity in a text automatically. 6. Conclusions
This experimental study is the first attempt to investigate the impact of specificity of index terms on users X  relevance judgment, and eventually on effective information retrieval. In previous research on specificity, sev-eral concepts of specificity have existed concurrently. Therefore, the concept of specificity is investigated on the basis of previous research. The identified types of specificity are term-document, posting, hierarchical, and statement specificity. Of these, statement specificity was not used to assign index terms. Thus, statement specificity cannot be an object in the current study since it does not link to subject headings and search state-ments. The remaining types of specificity can be used in this experiment.

Since this study is a first attempt to investigate the relationship of term specificity and relevance judgments, the methodological aspects of the study have also been elaborated. A way to measure the term-document spec-ificity, i.e., with a three-scaled measure by multiple human estimators, is proposed and used. Though it does not provide the means to measure term-document specificity in an automatic way, it shows that there is a con-sistent concept of term-document specificity.

The results of the experiment show that each of the three types of specificity, term-document specificity, posting specificity, and hierarchical specificity, has its own characteristics, and each is independent from the others. Term-document specificity is shown to affect relevance judgments. Moreover, hierarchical specificity is not shown as a significant variable related to relevance judgments. Interestingly, despite its curvilinear char-acteristics, posting specificity affects relevance judgments significantly, albeit reflecting a non-normal distribu-tion of relevance judgments.

The results of discriminant function analyses and logistic regression analysis show that accurate classifica-tion or prediction of a document occurs when the relevance judgments are bi-level (non-relevant and relevant), and when both term-document and postings specificity are used, v cases are correctly classified. The medium effect size of our analysis indicates that there are other possible vari-ables affecting relevance judgments. Two of them are identified in our discussion: language and those emanat-ing from the information seeking process.

In future studies, it is suggested that work be undertaken to develop a way to measure term-document specificity automatically, in order to improve effective information retrieval. Because specificity has been differentiated from the other related concepts, and because it is still measurable by human beings, studies could explore the indexing phenomena with attention on the evidence available to measure specificity. The problem of the measuring specificity should be done prior to other specificity research.
 Acknowledgements
Many thanks to Professor James D. Anderson in SCILS, Rutgers University for his assistance. Thanks also to Professor Tefko Saracevic for his warm provision of the raw data for our study, and to Professor Daniel O. O X  X onnor for his advice on statistics.
 Appendix. A sample of a retrieved document
Question ID :08 An analysis of student attitudes toward writing Query ID :01 ( &lt; elementary school students &gt; OR &lt; grade 4 &gt; ) Document ID :05 References
Terms matched :elementary school students, grade 4
Relevance judgment :relevant (1) t-spec :elementary school students -1 p-spec :elementary school students -.30 h-spec :elementary school students -1 (4/4)
