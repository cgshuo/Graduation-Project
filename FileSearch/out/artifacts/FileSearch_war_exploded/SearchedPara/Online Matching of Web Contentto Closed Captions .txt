 IntoNow is a mobile application that provides a second-screen experience to television viewers. IntoNow uses the microphone of the companion device to sample the audio coming from the TV set, and compares it against a database of TV shows in order to identify the program being watched.
The system we demonstrate is activated by IntoNow for specific types of shows. It retrieves information related to the program the user is watching by using closed captions, which are provided by each broadcasting network along the TV signal. It then matches the stream of closed captions in real-time against multiple sources of content. More specifi-cally, during news programs it displays links to online news articles and the profiles of people and organizations in the news, and during music shows it displays links to songs. The matching models are machine-learned from editorial judg-ments, and tuned to achieve approximately 90% precision. [ Information systems ]: Data stream mining; Document filtering; Algorithms Second screen, television companion, news retrieval
A second-screen experience refers to the use of a compan-ion device, smartphone or tablet, while watching TV. The habit of using a companion device while watching TV is well-established: almost 70% of tablet and smartphone owners use their devices while watching TV [2]. Smart TV sets and  X  Work done while at Yahoo! Research.
 Text pre-processing. The closed captions arrive as times-tamped streams of plain text that we process by segment-ing into sentences and performing named entity recognition. First, to segment the captions into sentences we use a series of heuristics which include detecting a change of speaker, conventionally signaled by a text marker ( X  &gt;&gt;  X ), using the presence of full stops, and using time-based rules. For in-stance, a pause of several seconds indicates a new sentence.
Second, we extract named entities by using a named en-tity tagger that performs named entity resolution and rank-ing [4]. Recognized named entities are associated to weights and represented by URLs of Wikipedia pages.
 Example. The input data is similar to this: The output of our text pre-processing is similar to this:
In the output, several lines of closed captions have been joined together to create longer sentences, and named enti-ties such as LeBron and NBA have been tagged.
 News matching. IntoNow obtains the type of each pro-gram from an online TV guide. For news matching, we con-sider programs of type newscast , and four genres of news: general , sports , entertainment and finance .

We match the processed captions to recent online news articles obtained from hundreds of sources via the Yahoo! News aggregator. Captions are matched in the same genre, e.g., sentences in sports are matched to news in the sports section of the news aggregator. News in the aggregator that are older than a genre-specific threshold are ignored.
The matching happens in two steps. In the first step, we employ a per-genre classification model trained on thou-sands of examples labeled by editors. In this model, the two classes are  X  X ame story X  and  X  X ifferent story X , and each ex-ample consists of a sentence and a news story. The features for the classifier are computed from each sentence-story pair by applying the named entity tagger previously described on both elements of the pair, and then by looking at en-tity co-occurrences. The models are fine-tuned to have high precision of about 90%, with recall between 50% and 60%.
In the second step, recall is improved by aggregating mul-tiple sentence-level matchings that occur in a short time period to form a  X  X ualified matching X . This step allows to leverage the presence of multiple matchings with low confi-dence close together in time, in order to generate a higher-confidence matching.

