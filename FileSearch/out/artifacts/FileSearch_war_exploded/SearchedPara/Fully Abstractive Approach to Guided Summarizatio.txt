 In the last decade, automatic text summarization has been dominated by extractive approaches that rely purely on shallow statistics. In the latest evalu-ation campaign of the Text Analysis Conference 1 (TAC), the top systems were considered only  X  X arely acceptable X  by human assessment (Owczarzak and Dang, 2011). The field is also getting saturated near what appears to be a ceiling in performance. Sys-tems that claim to be very different from one an-other have all become statistically indistinguishable in evaluation results. An experiment (Genest et al., 2009) found a performance ceiling to pure sentence extraction that is very low compared to regular (ab-stractive) human summaries, but not that much bet-ter than the current best automatic systems.
Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al., 2009), and a generation-based approach that could be called sentence split-ting (Genest and Lapalme, 2011). They are all rewriting techniques based on syntactical analysis, offering little improvement over extractive methods in the content selection process.

We believe that a fully abstractive approach with a separate process for the analysis of the text, the con-tent selection, and the generation of the summary has the most potential for generating summaries at a level comparable to human. For the foreseeable fu-ture, we think that such a process for full abstraction is impossible in the general case, since it is almost equivalent to perfect text understanding. In specific domains, however, an approximation of full abstrac-tion is possible.

This paper shows that full abstraction can be ac-complished in the context of guided summarization. We propose a methodology that relies on Informa-tion Extraction and Natural Language Generation, and discuss our early results. The stated goal of the guided summarization task at TAC is to motivate a move towards abstractive approaches. It is an oriented multidocument sum-marization task in which a category is attributed to a cluster of 10 source documents to be summa-rized in 100 words or less. There are five cate-gories: Accidents and Natural Disasters, Attacks, Health and Safety, Endangered Resources, and In-vestigations/Trials. Each category is associated with a list of aspects to address in the summary. Figure 1 shows the aspects for the Attacks category. We use this specification of categories and aspects to accom-plish domain-specific summarization. Guided summarization categories and aspects define an information need, and using Information Extrac-tion (IE) seems appropriate to address it. The idea to use an IE system for summarization can be traced back to the FRUMP system (DeJong, 1982), which generates brief summaries about various kinds of stories; (White et al., 2001) also wrote abstractive summaries using the output of an IE system applied to events such as natural disasters. In both cases, the end result is a generated summary from the informa-tion available. A lot of other work has instead used IE to improve the performance of extraction-based systems, like (Barzilay and Lee, 2004) and (Ji et al., 2010).

What is common to all these approaches is that the IE system is designed for a specific purpose, sep-arate from summarization. However, to properly ad-dress each aspect requires a system designed specifi-cally for that task. To our knowledge, tailoring IE to the needs of abstractive summarization has not been done before. Our methodology uses a rule-based, custom-designed IE module, integrated with Con-tent Selection and Generation in order to write short, well-written abstractive summaries.

Before tackling these, we perform some prepro-cessing on the cluster of documents. It includes: cleaning up and normalization of the input using reg-ular expressions, sentence segmentation, tokeniza-tion and lemmatization using GATE (Cunningham et al., 2002), syntactical parsing and dependency parsing (collapsed) using the Stanford Parser (de Marneffe et al., 2006), and Named Entity Recogni-tion using Stanford NER (Finkel et al., 2005). We have also developed a date resolution engine that fo-cuses on days of the week and relative terms. 3.1 Information Extraction Our architecture is based on Abstraction Schemes . An abstraction scheme consists of IE rules, con-tent selection heuristics and one or more genera-tion patterns, all created by hand. Each abstrac-tion scheme is designed to address a theme or sub-category. Thus, rules that extract information for the same aspect within the same scheme will share a similar meaning. An abstraction scheme aims to an-swer one or more aspects of its category, and more than one scheme can be linked to the same aspect.
Figure 2 shows two of the schemes that we have created. For the scheme killing , the IE rules would match X as the perpetrator and Y as a victim for all of the following phrases: X killed Y , Y was assassinated by X , and the murder of X by Y . Other schemes have similar structure and pur-pose, such as wounding , abducting , damaging and destroying . To create extraction rules for a scheme, we must find several verbs and nouns shar-ing a similar meaning and identify the syntactical position of the roles we are interested in. Three re-sources have helped us in designing extraction rules: a thesaurus to find semantically related nouns and verbs; VerbNet (Kipper et al., 2006), which provides amongst other things the semantic roles of the syn-tactical dependents of verbs; and a hand-crafted list of aspect-relevant word stems provided by the team that made CLASSY (Conroy et al., 2010).

Schemes and their extraction rules can also be quite different from this first example, as shown with the scheme event . This scheme gathers the basic in-formation about the attack event: WHAT category of attack, WHEN and WHERE it occurred. A list of key word s is used to identify words that imply an attack event, while a list of EVENT NOUN s is used to iden-tify specifically words that refer to a type of attack. 3.2 Content Selection A large number of candidates are found by the IE rules for each aspect. The content selection module selects the best ones and sends them to the genera-tion module. The basic heuristic is to select the can-didate most often mentioned for an aspect, and simi-larly for the choice of a preposition or a verb for gen-eration. More than one candidate may be selected for the aspect WHO AFFECTED, the victims of the attack. Several heuristics are used to avoid re-dundancies and uninformative answers.

News articles may contain references to more than one event of a given category, but our sum-maries describe only one. To avoid mixing candi-dates from two different event instances that might appear in the same cluster of documents, we rely on dates. The ancestors of a date in the dependency tree are associated with that date, and excluded from the summary if the main event occurs on a different date. 3.3 Generation The text of a summary must be fluid and feel natu-ral, while being straightforward and concise. From our observation of human-written summaries, it also does not require a great deal of originality to be considered excellent by human standards. Thus, we have designed straightforward generation pat-terns for each scheme. They are implemented us-ing the SimpleNLG realizer (Gatt and Reiter, 2009), which takes a sentence structure and words in their root form as input and gives a sentence with re-solved agreements and sentence markers as output. The greatest difficulty in the structure is in realizing noun phrases. The content selection module selects a lemma that should serve as noun phrase head, and its number, modifiers and specifier must be deter-mined during generation. Frequencies and heuristics are again used to identify appropriate modifiers, this time from all those used with that head within the source documents. We apply the constraint that the combination of number and modifiers chosen must appear at least once as an IE rule match.

As for any generated text, a good summary also requires a text plan (Hovy, 1988) (McKeown, 1985). Ours consists of an ordering of the schemes. For ex-ample, an Attack summary begins with the scheme event . This ordering also determines which scheme to favor in the case of redundancy, e.g. given that a building was both damaged and destroyed, only the fact that is was destroyed will be mentioned. We have implemented this fully abstractive summa-rization methodology. The abstraction schemes and text plan for the Attack category are written in an XML document, designed to easily allow the addi-tion of more schemes and the design of new cate-gories. The language processing of the source docu-ments and the domain-specific knowledge are com-pletely separate in the program.

Our system, which is meant as a proof of concept, can generate useful summaries for the Attack cate-gory, as can be seen in Figure 3. The key elements of information are present in each case, stated in a way that is easy to understand.

These short summaries have a high density of in-formation, in terms of how much content from the source documents they cover for a given number of words. For example, using the most widely used content metric, Pyramid (Nenkova et al., 2007), the two sentences generated for the cluster D1001A-A contain 8 Semantic Content Units (SCU) for a weighted total of 30 out of a maximum of 56, for a raw Pyramid score of 0.54. Only 3 of the 43 auto-matic summaries beat this score on this cluster that year (the average was 0.31). Note that the sum-maries that we compare against contain up to 100 words, whereas ours is only 21 words long. We con-clude that our method has the potential for creating summaries with much greater information density than the current state of the art.

In fact, our approach does not only have the po-tential to increase a summary X  X  coverage, but also its linguistic quality and the reader satisfaction as well, since the most relevant information now appears at the beginning of the summary. We have developed and implemented a fully abstrac-tive summarization methodology in the context of guided summarization. The higher density of infor-mation in our short summaries is one key to address the performance ceiling of extractive summarization methods. Although fully abstractive summarization is a daunting challenge, our work shows the feasibil-ity and usefulness of this new direction for summa-rization research.

We are now expanding the variety and complexity of the abstraction schemes and generation patterns to deal with more aspects and other categories. We should then be able to compare on a greater scale the output of our system with the ones produced by other automatic systems and by humans on all the clusters used at TAC 2010 and 2011. The authors want to thank Dr. Eduard Hovy, of ISI, and Prof. Kathy McKeown, of Columbia Univer-sity, for fruitful discussions on abstractive summa-rization, and Dr. Judith Schlesinger and Dr. John Conroy, both of the IDA / Center for Computing Sci-ences, for providing us with their hand-crafted list of category-and aspect-relevant keywords.
