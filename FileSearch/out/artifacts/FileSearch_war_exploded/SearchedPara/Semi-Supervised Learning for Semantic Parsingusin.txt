 Semantic parsing is the task of mapping a natu-ral language (NL) sentence into a complete, for-mal meaning representation (MR) which a computer program can execute to perform some task, like answering database queries or controlling a robot. These MRs are expressed in domain-specific unam-biguous formal meaning representation languages (MRLs). Given a training corpus of NL sentences annotated with their correct MRs, the goal of a learn-ing system for semantic parsing is to induce an ef-ficient and accurate semantic parser that can map novel sentences into their correct MRs.

Several learning systems have been developed for semantic parsing, many of them recently (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005; Kate and Mooney, 2006). These systems use supervised learning methods which only utilize annotated NL sentences. However, it requires considerable human effort to annotate sen-tences. In contrast, unannotated NL sentences are usually easily available. Semi-supervised learning methods utilize cheaply available unannotated data during training along with annotated data and of-ten perform better than purely supervised learning methods trained on the same amount of annotated data (Chapelle et al., 2006). In this paper we present, to our knowledge, the first semi-supervised learning system for semantic parsing.

We modify K RISP , a supervised learning sys-tem for semantic parsing presented in (Kate and Mooney, 2006), to make a semi-supervised system we call S EMISUP -K RISP . Experiments on a real-world dataset show the improvements S EMISUP -K
RISP obtains over K RISP by utilizing unannotated sentences. This section briefly provides background needed for describing our approach to semi-supervised seman-tic parsing. 2.1 K RISP : The Supervised Semantic Parsing K
RISP (Kernel-based Robust Interpretation for Se-mantic Parsing) (Kate and Mooney, 2006) is a su-pervised learning system for semantic parsing which takes NL sentences paired with their MRs as train-ing data. The productions of the formal MRL grammar are treated like semantic concepts. For each of these productions, a Support-Vector Ma-chine (SVM) (Cristianini and Shawe-Taylor, 2000) classifier is trained using string similarity as the ker-nel (Lodhi et al., 2002). Each classifier can then estimate the probability of any NL substring rep-resenting the semantic concept for its production. During semantic parsing, the classifiers are called to estimate probabilities on different substrings of the sentence to compositionally build the most probable meaning representation (MR) of the sentence.
K RISP trains the classifiers used in semantic pars-ing iteratively. In each iteration, for every produc-tion in the MRL grammar, K RISP collects pos-itive and negative examples. In the first iteration, the set of positive examples for production con-tains all sentences whose corresponding MRs use the production in their parse trees. The set of neg-ative examples includes all of the other training sen-tences. Using these positive and negative examples, an SVM classifier is trained for each production using a string kernel. In subsequent iterations, the parser learned from the previous iteration is applied to the training examples and more refined positive and negative examples, which are more specific sub-strings within the sentences, are collected for train-ing. Iterations are continued until the classifiers con-verge, analogous to iterations in EM (Dempster et al., 1977). Experimentally, K RISP compares favor-ably to other existing semantic parsing systems and is particularly robust to noisy training data (Kate and Mooney, 2006). 2.2 Transductive SVMs SVMs (Cristianini and Shawe-Taylor, 2000) are state-of-the-art machine learning methods for clas-sification. Given positive and negative training ex-amples in some vector space, an SVM finds the maximum-margin hyperplane which separates them. Maximizing the margin prevents over-fitting in very high-dimensional data which is typical in natural language processing and thus leads to better general-ization performance on test examples. When the un-labeled test examples are also available during train-ing, a transductive framework for learning (Vapnik, 1998) can further improve the performance on the test examples.

Transductive SVMs were introduced in (Joachims, 1999). The key idea is to find the labeling of the test examples that results in the maximum-margin hyperplane that separates the positive and negative examples of both the training and the test data. This is achieved by including variables in the SVM X  X  objective function repre-senting labels of the test examples. Finding the exact solution to the resulting optimization problem is intractable, however Joachims (1999) gives an approximation algorithm for it. One drawback of his algorithm is that it requires the proportion of positive and negative examples in the test data be close to the proportion in the training data, which may not always hold, particularly when the training data is small. Chen et al. (2003) present another approximation algorithm which we use in our system because it does not require this assumption. More recently, new optimization methods have been used to scale-up transductive SVMs to large data sets (Collobert et al., 2006), however we did not face scaling problems in our current experiments.
Although transductive SVMs were originally de-signed to improve performance on the test data by utilizing its availability during training, they can also be directly used in a semi-supervised setting (Ben-nett and Demiriz, 1999) where unlabeled data is available during training that comes from the same distribution as the test data but is not the actual data on which the classifier is eventually to be tested. This framework is more realistic in the context of se-mantic parsing where sentences must be processed in real-time and it is not practical to re-train the parser transductively for every new test sentence. In-stead of using an alternative semi-supervised SVM algorithm, we preferred to use a transductive SVM algorithm (Chen et al., 2003) in a semi-supervised manner, since it is easily implemented on top of an existing SVM system. We modified the existing supervised system K RISP , described in section 2.1, to incorporate semi-supervised learning. Supervised learning in K RISP involves training SVM classifiers on positive and negative examples that are substrings of the anno- X  X  training algorithm tated sentences. In order to perform semi-supervised learning, these classifiers need to be given appropri-ate unlabeled examples. The key question is: Which substrings of the unannotated sentences should be given as unlabeled examples to which productions X  classifiers? Giving all substrings of the unannotated sentences as unlabeled examples to all of the clas-sifiers would lead to a huge number of unlabeled examples that would not conform to the underly-ing distribution of classes each classifier is trying to separate. S EMISUP -K RISP  X  X  training algorithm, de-scribed below and shown in Figure 1, addresses this issue.

The training algorithm first runs K RISP  X  X  exist-ing training algorithm and obtains SVM classifiers for every production in the MRL grammar. Sets of positive and negative examples that were used for training the classifiers in the last iteration are col-lected for each production. Next, the learned parser is applied to the unannotated sentences. During the parsing of each sentence, whenever a classifier is called to estimate the probability of a substring rep-resenting the semantic concept for its production, that substring is saved as an unlabeled example for that classifier. These substrings are representative of the examples that the classifier will actually need to handle during testing. Note that the MRs obtained from parsing the unannotated sentences do not play a role during training since it is unknown whether or not they are correct. These sets of unlabeled ex-amples for each production, along with the sets of positive and negative examples collected earlier, are then used to retrain the classifiers using transductive SVMs. The retrained classifiers are finally returned and used in the final semantic parser. We compared the performance of S EMISUP -K RISP and K RISP in the G EOQUERY domain for semantic parsing in which the MRL is a functional language used to query a U.S. geography database (Kate et al., 2005). This domain has been used in most of the previous work. The original corpus contains NL queries collected from undergraduate students and annotated with their correct MRs (Zelle and Mooney, 1996). Later, were collected from real users of a web-based inter-face and annotated (Tang and Mooney, 2001). We used this data as unannotated sentences in our cur-rent experiments. We also collected an additional of
The systems were evaluated using standard 10-fold cross validation. All the unannotated sentences were used for training in each fold. Performance was measured in terms of precision (the percent-age of generated MRs that were correct) and recall (the percentage of all sentences for which correct MRs were obtained). An output MR is considered correct if and only if the resulting query retrieves the same answer as the correct MR when submit-ted to the database. Since the systems assign confi-dences to the MRs they generate, the entire range of the precision-recall trade-off can be obtained for a system by measuring precision and recall at various confidence levels. We present learning curves for the best F-measure (harmonic mean of precision and re-Figure 2: Learning curves for the best F-measures on the G EOQUERY corpus. call) obtained across the precision-recall trade-off as the amount of annotated training data is increased. Figure 2 shows the results for both systems. The results clearly show the improvement S
EMISUP -K RISP obtains over K RISP by utilizing unannotated sentences, particularly when the num-ber of annotated sentences is small. We also show the performance of a hand-built semantic parser G
EOBASE (Borland International, 1988) for com-parison. From the figure, it can be seen that, on average, K RISP achieves the same performance as G while S EMISUP -K RISP reaches this level given only annotation effort. This paper has presented a semi-supervised ap-proach to semantic parsing. Our method utilizes unannotated sentences during training by extracting unlabeled examples for the SVM classifiers it uses to perform semantic parsing. These classifiers are then retrained using transductive SVMs. Experimental results demonstrated that this exploitation of unla-beled data significantly improved the accuracy of the resulting parsers when only limited supervised data was provided.
 This research was supported by a Google research grant. The experiments were run on the Mastodon cluster provided by NSF grant EIA-0303609.

