 Among the considerable problems in query-translation-based CLIR, the most crucial one is the proper sel ection of translation candida tes. Given a conceivable situation in which a user is not familiar with the target languages, the CLIR system should be able to automatically and accurately translate user queries. To this end, several approaches have been pursued [9], including the incorpora-tion of (pseudo-)relevance-feedback, application of statistical language models, utilization of off-the-shelf MT sys tems, and combinations of these.
On another extreme, a different scenario can be drawn, if an interactive search setting is possible: the user is able to select appropriate translations by consulting the clues provided by the system [10]. Here, the clues should not be dependent on the target language; they should be language independent and preferably intuitive. Along the lines of this interactive scenario, The authors proposed to present images gathered from the Web (hereafter, Web images) as a clue for the word senses of a translated query t erm, and experimentally showed that an interactive CLIR interface using such W eb images could help users select relevant query translations correctly and efficiently [6].

Although the results are substantially informative, it has not been very clear what kind of query concepts (word senses) can be effectively illustrated by Web images . Therefore this paper further explores the visual annotatability of word senses based on a human assessment experiment on the relevance of Web images. The results acquired through statistical analyses from the viewpoints of semantic class and word sense familiarity will provide insights that should be considered in the design of an interactive CLIR system , as well as a principled way to construct atestqueryset. Figure 1 shows the system organization of the experimental interactive CLIR interface that we have proposed in [6] . The system accepts queries in a source language and searches for relevant information in user-designated target lan-guages by invoking a target Web search engine that is external to the system.
The system first analyzes the input query and assigns translation candidates for each term extracted from the query . A set of translation resources such as bilingual dictionaries is utilized to retrieve translation candidates in the target languages.

The system then invokes an external image search engine on the Web in order to collect Web images for each of the translation candidates. To do this, each translation candidate is employed as a query term submitted to the image search engine, resulting in multiple invocations of the external image search.
The resulted Web images, each accompan ied by a check-box, as shown in Fig-ure 2, are then presented to the user so that he or she can generate a query formula to be submitted to the target Web search engine. The point is that the Web images should be presented in an intelligible yet concise manner. Thumb-nails provided by Web image search engines fulfill this requirement nicely. Figure 3 illustrates the general flow of the experiment to collect human assess-ments of the relevance of Web images, in which we envision Japanese-to-English retrieval. Each of the steps is described as follows. 1. Japanese term selection: To conduct the experiment, we first need to construct a reasonable set of Japanes e target terms. We selected these terms from the Japanese lexical resource Le xeed [11], first by applying the follow-ing conditions.  X  the term is a noun  X  it has at least two and at most five word senses after filtering out unfa-The first condition is not essential, but we limited ourselves to nominal concepts to initiate the presented lin e of research. The second, on the other hand, is crucial: a monosemous term i s of less interest, but one with too many senses may be highly abstract and thus difficult to handle. Fortunately, every entry in Lexeed is sufficiently annotated with grammatical information (POS), semantic information (word senses distinction and the corresponding semantic categories in the semantic hierarchy system given in [8]), and word sense familiarity scores . A word sense familiarity score that shows how a word sense is familiar to native speakers is assigned to every word sense of every word entry in Lexeed. These scores were determined by averaging ratings (on 7-point scale) acquired through carefully designed psychological experiments [2] involving around 50 Japanese participants. Lexeed is also valuable in the sense that it gathers a set of 28,113 basic words (45,691 word senses total) that were identified through the experiments as the most essential vocabulary of Japanese language. 2. Translation candidate extraction: English translation candidates for the selected Japanese terms were extracted by looking up bilingual translation resources: edict 1 and the EDR Electronic Dictionary 2 . Translation candi-dates that were recognized as Mu lti-Word Expressions (MWEs) carded, because it was expected that appropriate Web images are hardly assigned to the complex concept denoted by an MWE. Moreover, Japanese terms with unique translation candidates in English, even polysemous in Lexeed, were excluded. After applying these filters, a set of 2,380 Japanese target terms (5,540 word senses total) were obtained by setting the word sense familiarity score threshold to 4.3. 3. Translation selection: Based on the translation candidates obtained through the above mentioned process, alignments between Japanese tar-get word senses and the English translations were determined by human assessors. Only 37 word senses were left unaligned with appropriate transla-tions after allowing the assessors to make minor revisions to the translation candidates. 4. Web image gathering: A set of Web images was gathered for each word-sense/English-translation pair by using Google Images 4 .Herewesimply supplied Google Images with the English translation as a query term with-out performing any query expansions or refinements. We retained only the images acquired from the first screen returned by Google Images . 5. Relevance annotation: Finally, the participants were asked to annotate rel-evance of the Web image set obtained for each Japanese word-sense/English translation pair. The relevance score was given according to the following four point scale.  X 3: A number of relevant images are presented in higher ranks.  X 2: Around four or five relevant images are presented in the set.  X 1: At least one relevant image is found in the set.  X 0: There are no relevant images found in the set.
 Three participants in all took part in the annotation work. Of these, one lead person was responsible for deter mining the final relevance scores. 4.1 Overall Result Table 1 summarizes the distribution of the relevance scores of the target Japanese word senses. As shown, almost two-thirds of the word senses were successfully annotated by the associated Web image set. We hereafter classify the Japanese word senses into two groups: pos for those whose relevance score is greater than zero, and neg for those whose relevance score is zero.
 4.2 Semantic Class and Relevance To examine the results in terms of noun semantics, we made a two-by-two con-tingency table (Table 2), that shows the relationships between binary semantic classes ( abstract , concrete ) and the relevance groups ( neg , pos ). A chi-square test of independence was performed on the contingency table. The result was statistically significant (  X  2 = 364 . 69) with p-level ( p&lt;. 001), indicating that word senses that represent a concrete object are better annotated with the Web images 5 compared to those that repre sent an abstract object.
Note here that we can obtain corresponding semantic classes in Goi-Taikei[8] for each word sense in Lexeed thanks to the semantic links between these two lexical resources. Figure 4 illustrates the upper part of the noun semantic hierar-chy in Goi-Taikei, in which all Japanese nouns are first classified into concrete or abstract , then further classified into more specific classes
This result may agree with our intuition: objects that have a shape/figure can be visualized. However to further explore the relationships, we broke down the binary semantic classes into 14 more specific semantic classes, which are represented by shaded nodes in Fig. 4. We again conducted a chi-square test of independence and also performed Haberman X  X  adjusted residual analysis in order to see which semantic classes exhibit a remarkable tendency.
The result detailed in Table 3 was again statistically significant (  X  with p-level ( p&lt;. 001), indicating that word senses that belong to particular semantic classes are significantly better or worse being annotated with Web images. In Table 3, each cell shows the o bserved frequency and expected fre-quencies; the expected frequency is mar ked by either * or ** if it is statistically significant with p-level ( p&lt;. 005 or p&lt;. 001).

Table 3 reveals the following anomalies.  X  organization (  X  concrete) : Although the observed pos number exceeds the expected number, it is not statisti cally significant even with p-level ( p&lt; . 0 . 05). This is because the semantic class includes nouns that exhibit so-called systematic polysemy , such as  X  X ead office X  or  X  X ecca X  (the attractive place sense), which are hard to visualize.  X  activity (  X  abstract) : Although the observed neg number exceeds the expected number, it is not statis tically significant with p-value 0 . 096. This is conceivable, because the semantic class includes many human activities that can be photographed or illustrated. Examples include physical activities such as  X  X ump X  and  X  X ishing X  and mental activities such as  X  X urprise X  and  X  X orgiveness. X  The formers can be photographed while the latters are tend to be illustrated.  X  natural phenomenon (  X  abstract) : This class exhibits the most promi-nent anomaly. In spite of belonging to abstract class, the observed pos number significantly exceeds the expected number, meaning more word senses were annotated with Web images than expected. We can ac-cept this apparent anomaly, if we look further into the semantic sys-tem. The semantic class natural phenomenon is sub-categorized into non-life phenomenon or life phenomenon . The former semantic class, for example, includes meteorological phenomenon , and the latter includes physiological phenomenon ; many items in these two classes are pho-tographable or can be illustrated. 4.3 Familiarity and Relevance Given that the target Japanese word senses are annotated with the word sense familiarity scores, we also examined the relationship between the familiarity level and the relevance of the Web images. Here the familiarity level was derived for each word sense by discretizing the assigned familiarity score f .Weonce again constructed a contingency table (Table 4) and applied statistical tests. As the both variables are deemed as ordered categorical variables, we applied the asymptotic linear-by-linear association test (lbl test in [7]) as well as a standard chi-square test.

Statistical significance was once again confirmed with p-level ( p&lt;. 005) by the lbl test (  X  2 = 127 . 61) as well as by the standard chi-squre test (  X  thus showing that familiarity levels can affect the relevance of the associated Web images. We again added stars in the table to the expected numbers, that show statistical significance through the residual analysis.

The results shown in the table are quite impressive, because they clearly indicate that:  X  the highest relevance (r3) was achieved largely by highly familiar word senses (c6 and c7),  X  whereas the lowest relevance (r0) was brought about by less familiar word senses (c5, c4, and c3);  X  middle-level relevance (r1, r2) was almost independent of the familiarity levels. Further, it can be said that a nearly 70% of word senses located at the highest familiarity levels (c6 or c7) are well annotated ( rs  X  2). Although this result might not be incompatible with our intuition, it should be further investigated. One of the possibilities is hidden dependency between semantic class and the word sense familiarity score. For example, many words in concrete semantic class could have higher familiarity scores; hence they are likely to be well vi-sualized. The results from a chi-square test of dependence, however, were not statistically significant, suggesting that some words in some abstract classes still can have higher familiarity scores. At the same time, the results show that some concrete classes, such as animal , are tend to have higher average famil-iarity scores. Therefore it could be said that familiar word senses, in general, can be well visualized. As Table 1 shows, around one-third of the word senses were not adequately annotated with the set of Web images gathered by the described simple image gathering method. This difficulty can be mainly attributed to the following two reasons. In either case, any member of the presented set of Web images had nothing to do with the intended word sense. 1. Some word senses might be intrinsically un-visualizable: As discussed in this paper, some of the word senses of this type can be predicted by using the semantic class and the familiarity score. In an actual interactive CLIR system, a translated query term with this kind of word sense can be flagged for the user. 2. Relevant images may exist on the Web, but not included in the presented set of images: This can happen when the translated query term is polyse-mous, and the intended word sense is minor in a sense on the Web. It is quite natural that the frequency distribution of a word X  X  senses is not bal-anced, rather biased [5] reflecting some c haracteristics of the Web. Although it has not been as serious as expected in our experiment, we should note a prominent problematic pattern here by citing an example: when we con-ducted Google Images with the query  X  X eaver X , intending it in the sense of  X  X  craftsman who weaves cloth X  (WordNet gloss), the search returned only a set of pictures of Sigourney Weaver , a famous actress. This problem can be partly addressed if a term is recognized as one of the frequently used names on the Web. The system then can let the user know the term of this kind, or even suggest a disambiguation strategy. For instance, the query  X  X eaver -sigourney X  (with the term exclusion prefix  X - X ) can greatly improve the Web image set to annotate the intended sense. This paper examined the possibility of Web images as an intuitive and effective clue for for representing the word sense s of a translated query term in CLIR. We designed an experiment to collect huma n assessments of the relevance of Web images. Statistical analyses applied to the assessment data provided insights that should be considered in the design of an i nteractive CLIR system. These insights include: (1) the semantic class of a word sense together with familiarity is a good indicator for predicting the applicability of the Web images as a word sense clue; (2) Web biases should be considered wh en gathering Web images, particularly for terms used as the name of an entity.
 Although the presented research has been conducted in relation to an interactive CLIR interface, it obviously pertains to research efforts on image sense disambigua-tion [1] and lexical resource enrichment [4]. In particular, the results from the lat-ter research should be appreciated: by using lexical semantic relations encoded in monolingual lexical resour ces, they perform a kind of query expansion to overcome the Web bias issue in gathering appropriate images even for minor word senses. By doing similarly, a translated query term whose Web images are predicted to be less applicable can be annotated with a better set of Web images.

