 Alignment modelling for Statistical Machine Translation (SMT) is the task of determining translational correspon-dences between the words in pairs of sentences in parallel text. Given a source language word sequence f J tar get language word sequence e I tion probability as P( e I able a I sitions to source word positions such that e i is aligned to f 1993).

Pre vious work on statistical alignment modelling has not tak en into account the source word conte xt when de-termining translations of that word. It is intuiti ve that a word in one conte xt, with a particular part-of-speech and particular words surrounding it, may translate dif ferently when in a dif ferent conte xt. We aim to tak e adv antage of this information to pro vide a better estimate of the word' s translation. The challenge of incorporating con-text information is maintaining computational tractability of estimation and alignment, and we develop algorithms to overcome this.

The development of efcient estimation procedures for conte xt-dependent acoustic models revolutionised the eld of Automatic Speech Recognition (ASR) (Young et al., 1994). Clustering is used extensi vely for impro v-ing parameter estimation of triphone (and higher order) acoustic models, enabling rob ust estimation of param-eters and reducing the computation required for recog-nition. Kannan et al. (1994) introduce a binary tree-gro wing procedure for clustering Gaussian models for triphone conte xts based on the value of a lik elihood ra-tio. We adopt a similar approach to estimate conte xt-dependent translation probabilities.
 We focus on alignment with IBM Model 1 and HMMs. HMMs are commonly used to generate alignments from which state of the art SMT systems are built. Model 1 is used as an intermediate step in the creation of more pow-erful alignment models, such as HMMs and further IBM models. In addition, it is used in SMT as a feature in Min-imum Error Training (Och et al., 2004) and for rescor -ing lattices of translation hypotheses (Blackw ood et al., 2008). It is also used for lexically-weighted phrase ex-traction (Costa-juss a and Fonollosa, 2005) and sentence segmentation of parallel text (Deng et al., 2007) prior to machine translation. 1.1 Ov erview We rst develop an extension to Model 1 that allo ws the use of arbitrary conte xt information about a source word to estimate conte xt-dependent word-to-w ord translation probabilities. Since there is insuf cient training data to accurately estimate translation probabilities for less fre-quently occurring conte xts, we develop a decision tree clustering algorithm to form conte xt classes. We go on to develop a conte xt-dependent HMM model for alignment.
In Section 3, we evaluate our conte xt-dependent mod-els on Arabic-English parallel text, comparing them to our baseline conte xt-independent models. We perform morphological decomposition of the Arabic text using MAD A, and use part-of-speech taggers on both lan-guages. Alignment quality is measured using Alignment Error Rate (AER) measured against a manually-aligned parallel text. Section 4 uses alignments produced by our impro ved alignment models to initialise a statistical machine translation system and evaluate the quality of translation on several data sets. We also apply part-of-speech tagging and decision tree clustering of conte xts to Chinese-English parallel text; translation results for these languages are presented in Section 4.2. 1.2 Pr evious and related work Bro wn et al. (1993) introduce IBM Models 1-5 for align-ment modelling; Vogel et al. (1996) propose a Hidden Mark ov Model (HMM) model for word-to-w ord align-ment, where the words of the source sentence are vie wed as states of an HMM and emit tar get sentence words; Deng and Byrne (2005a) extend this to an HMM word-to-phrase model which allo ws man y-to-one alignments and can capture dependencies within tar get phrases.
Habash and Sadat (2006) perform morphological de-composition of Arabic words, such as splitting of pre-x es and suf x es. This leads to gains in machine trans-lation quality when systems are trained on parallel text containing the modied Arabic and processing of Arabic text is carried out prior to translation. Nieflen and Ne y (2001a) perform pre-processing of German and English text before translation; Nieflen and Ne y (2001b) use mor -phological information of the current word to estimate hierarchical translation probabilities.

Ber ger et al. (1996) introduce maximum entrop y mod-els for machine translation, and use a windo w either side of the tar get word as conte xt information. Varea et al. (2002) test for the presence of specic words within a windo w of the current source word to form features for use inside a maximum entrop y model of alignment.
Toutano va et al. (2002) use part-of-speech informa-tion in both the source and tar get languages to estimate alignment probabilities, but this information is not in-corporated into translation probabilities. Popo vi X  c and Ne y (2004) use the base form of a word and its part-of-speech tag during the estimation of word-to-w ord transla-tion probabilities for IBM models and HMMs, but do not dened conte xt-dependent estimates of translation prob-abilities.

Stroppa et al. (2007) consider conte xt-informed fea-tures of phrases as components of the log-linear model during phrase-based translation, but do not address align-ment. Consider the alignment of the tar get sentence e = e I the source sentence f = f J ments of the tar get words to the source words. Let c j be the conte xt information of f j for j = 1 ,...,J . This con-text information can be any information about the word, e.g. part-of-speech, pre vious and next words, part-of-speech of pre vious and next words, or longer range con-text information.

We follo w Bro wn et al. (1993), but extend their mod-elling frame work to include information about the source word from which a tar get word is emitted. We model the alignment process as:
P( e I We introduce word-to-w ord translation tables that depend on the source language conte xt for each word, i.e. the probability that f translates to e given f has conte xt c t ( e j f,c ) . We assume that the conte xt sequence is given for a source word sequence. This assumption can be relax ed to allo w for multiple tag sequences as hidden processes, but we assume here that a tagger generates a single conte xt sequence c J This corresponds to the assumption that, for a conte xt se-quence  X  c J P( For Model 1, ignoring the sentence length distrib ution,
Estimating translation probabilities separately for ev-ery possible conte xt of a source word indi vidually leads to problems with data sparsity and rapid gro wth of the translation table. We therefore wish to cluster source con-texts which lead to similar probability distrib utions. Let C f denote the set of all observ ed conte xts of source word f . A particular clustering is denoted where K f is a partition of C f . We dene a class mem-bership function  X  f such that for any conte xt c ,  X  f ( is the cluster containing c . We assume that all conte xts in a cluster give rise to the same translation probability distrib ution for that source word, i.e. for a cluster K t ( e j f,c ) = t ( e j f,c 0 ) for all conte xts c,c 0 2 K and all tar get words e ; we write this shared translation probabil-ity as t ( e j f,K ) .

The Model 1 sentence translation probability for a given alignment (Equation 2) becomes P For HMM alignment, we assume that the transition prob-and the sentence translation probability is P Section 2.1.1 describes how the conte xt classes are deter -mined by optimisation of the EM auxiliary function. Al-though the translation model is signicantly more com-ple x than that of conte xt-independent models, once class membership is x ed, alignment and parameter estimation use the standard algorithms. 2.1 EM parameter estimation We train using Expectation Maximisation (EM), optimis-ing the log probability of the training set f e ( s ) , f ( s ) (Bro wn et al., 1993). Given model parameters  X  0 , we es-timate new parameters  X  by maximisation of the EM aux-iliary function
X We assume the sentence length distrib ution and align-ment probabilities do not depend on the conte xts of the source words; hence the rele vant part of the auxiliary function is where  X  0 ( e j f,c ) = Here  X  0 can be computed under Model 1 or the HMM, and is calculated using the forw ard-backw ard algorithm for the HMM. 2.1.1 Parameter estimation with cluster ed contexts
We can re-write the EM auxiliary function (Equation 5) in terms of the cluster -specic translation probabilities:
Follo wing the usual deri vation, the EM update for the class-specic translation probabilities becomes Standard EM training can be vie wed a special case of this, with every conte xt of a source word grouped into a sin-gle cluster . Another way to vie w these clustered conte xt-dependent models is that conte xts belonging to the same cluster are tied and share a common translation proba-bility distrib ution, which is estimated from all training examples in which any of the conte xts occur . 2.2 Decision trees for context clustering The objecti ve for each source word is to split the conte xts into classes to maximise the lik elihood of the training data. Since it is not feasible to maximise the lik elihood of the observ ations directly , we maximise the expected log lik elihood by considering the EM auxiliary function, in a similar manner to that used for modelling conte xtual variations of phones for ASR (Young et al., 1994; Singer and Ostendorf, 1996). We perform divisi ve clustering in-dependently for each source word f , by building a binary decision tree which forms classes of conte xts which max-imise the EM auxiliary function. Questions for the tree are dra wn from a set of questions Q = f q 1 ,...,q |Q| g concerning the conte xt information of f .
 Let K be any set of conte xts of f , and dene
L ( K ) = This is the contrib ution to the EM auxiliary function of source word f occurring in the conte xts of K . Let q be a binary question about the conte xt of f , and consider the effect on the partial auxiliary function (Equation 6) of splitting K into two clusters using question q . Dene K q be the set of conte xts in K which answer `yes' to q and K  X  q be the conte xts which answer `no'. Dene the objecti ve function When the node is split using question q , the increase in objecti ve function is given by We choose q to maximise this.

In order to build the decision tree for f , we tak e the set of all conte xts C f as the initial cluster at the root node. We then nd the question  X  q such that Q f,q ( C f ) is maxi-mal, i.e. This splits C f , so our decision tree now has two nodes. We iterate this process, at each iteration splitting (into two further nodes) the leaf node that leads to the great-est increase in objecti ve function. This leads to a greedy search to optimise the log lik elihood over possible state clusterings.

In order to control the gro wth of the tree, we put in place two thresholds:
For each leaf node l and set of conte xts K l at that node, we nd the question q l that, when used to split K l , pro-duces the lar gest gain in objecti ve function: We then nd the leaf node for which splitting gives the lar gest impro vement: If the follo wing criteria are both satised at that node, we split the node into two parts, creating two leaf nodes in its place: We perform such clustering for every source word in the parallel text. Our models were built using the MTTK toolkit (Deng and Byrne, 2005b). Decision tree clustering was imple-mented and the process parallelised to enable thousands of decision trees to be built. Our conte xt-dependent (CD) Model 1 models trained on conte xt-annotated data were compared to the baseline conte xt-independent (CI) mod-els trained on untagged data.
 The models were trained using data allo wed for the NIST 08 Arabic-English evaluation 1 , excluding the UN collections, comprising 300k parallel sentence pairs, a to-tal of 8.4M words of Arabic and 9.5M words of English.
The Arabic language incorporates into its words sev-eral prex es and suf x es which determine grammatical features such as gender , number , person and voice. The MAD A toolkit (Habash and Sadat, 2006) was used to perform Arabic morphological word decomposition and part-of-speech tagging. It determines the best analysis for each word in a sentence and splits word prex es and suf x es, based on the alternati ve analyses pro vided by BAMA (Buckw alter , 2002). We use tok enisation scheme `D2', which splits certain prex es and has been reported to impro ve machine translation performance (Habash and Sadat, 2006). The alignment models are trained on this processed data, and the prex es and suf x es are treated as words in their own right; in particular their conte xts are examined and clustered.

The TnT tagger (Brants, 2000), used as distrib uted with its model trained on the Wall Street Journal portion of the Penn treebank, was used to obtain part-of-speech tags for the English side of the parallel text. Marcus et al. (1993) gives a complete list of part-of-speech tags pro-duced. No morphological analysis is performed for En-glish.

Automatic word alignments were compared to a manually-aligned corpus made up of the IBM Arabic-English Word Alignment Corpus (Ittycheriah et al., 2006) and the word alignment corpora LDC2006E86 and LDC2006E93. This contains 28k parallel text sentences pairs: 724k words of Arabic and 847k words of English. The alignment links were modied to reect the MAD A tok enisation; after modication, there are 946k word-to-word alignment links.

Alignment quality was evaluated by computing Align-ment Error Rate (AER) (Och and Ne y, 2000) relati ve to the manual alignments. Since the links supplied con-tain only `sure' links and no `possible' links, we use the follo wing formula for computing AER given reference alignment links S and hypothesised alignment links A : 3.1 Questions about contexts The algorithm presented in Section 2 allo ws for any infor -mation about the conte xt of the source word to be consid-ered. We could consider general questions of the form `Is the previous wor d x?' and `Does wor d y occur within n wor ds of this one?' . To maintain computational tractabil-ity, we restrict the questions to those concerning the part-of-speech tag assigned to the current, pre vious and next words. We do not ask questions about the identities of the words themselv es. For each part-of-speech tag T , we ask the question `Does w have tag T?' . In addition, we group part-of-speech tags to ask more general questions: e.g. the set of conte xts which satises `Is w a noun?' contains those that satisfy `Is w a proper noun?' and `Is w a sin-gular or mass noun?' . We also ask the same questions of the pre vious and next words in the source sentence. In English, this gives a total of 152 distinct questions, each of which is considered when splitting a leaf node. The MAD A part-of-speech tagger uses a reduced tag set, which produces a total of 68 distinct questions.
Figure 1 sho ws the links of the English source word selling in two dif ferent conte xts where it links to dif ferent words in Arabic, which are both forms of the same verb . The part-of-speech of the pre vious word is useful for dis-criminating between the two cases, whereas a conte xt-independent model would assign the same probability to both Arabic words. 3.2 Training Model 1 Training is carried out in both translation directions. For Arabic to English, the Arabic side of the parallel text is tagged and the English side remains untagged; we vie w the English words as being generated from the Arabic words and questions are ask ed about the conte xt of the Arabic words to determine clusters for the translation ta-ble. For English to Arabic, the situation is reversed: we used tagged English text as the source language and un-tagged Arabic text, with morphological decomposition, as the tar get language.

Standard CI Model 1 training, initialised with a uni-form translation table so that t ( e j f ) is constant for all source/tar get word pairs ( f,e ) , was run on untagged data for 10 iterations in each direction (Bro wn et al., 1993; Deng and Byrne, 2005b). A decision tree was built to cluster the conte xts and a further 10 iterations of training were carried out using the tagged words-with-conte xt to produce conte xt-dependent models (CD Model 1). The English question Fr equency Is Ne xt Preposition 1523 Is Pre v Determiner 1444 Is Pre v Preposition 1209 Is Pre v Adjecti ve 864 Is Ne xt Noun Singular Mass 772 Is Pre v Noun Singular Mass 690 Is Ne xt Noun Plural 597 Is Ne xt Noun 549 Arabic question Fr equency Is Pre v Preposition 1110 Is Ne xt Preposition 993 Is Pre v Noun 981 Is Ne xt Noun 912 Is Pre v Coordinating Conjunction 627 Is Pre v Noun SingularMass 607 Is Ne xt Punctuation 603 Is Ne xt Adjecti ve Adv erb 559 models were then evaluated using AER at each train-ing iteration. A number of impro vement thresholds T imp were tested, and performance compared to that of models found after further iterations of CI Model 1 training on the untagged data. In both alignment directions, the log probability of the training data increases during training (see Figure 2). As expected, the training set lik elihood increases as the threshold T imp is reduced, allo wing more clusters and closer tting to the data. 3.2.1 Analysis of frequently used questions
Table 1 sho ws the questions used most frequently at the root node of the decision tree when clustering con-texts in English and Arabic. Because the y are used rst, these are the questions that indi vidually give the great-est ability to discriminate between the dif ferent conte xts of a word. The list sho ws the importance of the left and right conte xts of the word in predicting its translation: of the most common 50 questions, 25 concern the pre vious word, 19 concern the next, and only 6 concern the part-of-speech of the current word. For Arabic, of the most frequent 50 questions, 21 concern the pre vious word, 20 concern the next and 9 the current word. 3.2.2 Alignment Err or Rate
Since MT systems are usually built on the union of the two sets of alignments (K oehn et al., 2003), we consider the union of alignments in the two directions as well as those in each direction. Figure 3 sho ws the change in AER of the alignments in each direction, as well as the alignment formed by taking their union at corresponding thresholds and training iterations.

T imp Arabic-English (%) English-Arabic (%) 10 30601 (25.33) 26011 (39.87) 20 11193 (9.27) 18365 (28.15) 40 1874 (1.55) 9104 (13.96) 100 307 (0.25) 1128 (1.73) 3.2.3 Variation of impr ovement thr eshold T imp
There is a trade-of f between modelling the data accu-rately , which requires more clusters, and eliminating data sparsity problems, which requires each cluster to contain conte xts that occur frequently enough in the training data to estimate the translation probabilities accurately . Use of a smaller threshold T imp leads to more clusters per word and an impro ved ability to t to the data, but this can lead to reduced alignment quality if there is insuf cient data to estimate the translation probability distrib ution accu-rately for each cluster . For lower thresholds, we observ e over-tting and the AER rises after the second iteration of CD training, similar to the beha viour seen in Och (2002). Setting T imp = 0 results in each conte xt of a word having its own cluster , which leads to data sparsity problems.
Table 2 sho ws the percentage of words for which the conte xts are split into multiple clusters for CD Model 1 with varying impro vement thresholds. This occurs when there are enough training data examples and suf cient variability between the conte xts of a word that splitting the conte xts into more than one cluster increases the EM auxiliary function. For words where the conte xts are not split, all the conte xts remain in the same cluster and pa-rameter estimation is exactly the same as for the unclus-tered conte xt-independent models. 3.3 Training HMMs Adding source word conte xt to translation has so far led to impro vements in AER for Model 1, but the perfor -mance does not match that of HMMs trained on untagged data; we therefore train HMMs on tagged data.

We proceed with Model 1 and Model 2 trained in the usual way, and conte xt-independent (CI) HMMs were trained for 5 iterations on the untagged data. Statistics were then gathered for clustering at various thresholds, after which 5 further EM iterations were performed with tagged data to produce conte xt-dependent (CD) HMMs. The HMMs were trained in both the Arabic to English and the English to Arabic directions. The log lik elihood of the training set varies with T imp in much the same way as for Model 1, increasing at each iteration, with greater lik elihood at lower thresholds. Figure 4 sho ws how the AER of the union alignment varies with T imp during training. As with Model 1, the clustered HMM models produce alignments with a lower AER than the baseline model, and there is evidence of over-tting to the training data. 3.3.1 Alignment precision and recall The HMM models include a null transition probability , p , which can be modied to adjust the number of align-ments to the null tok en (Deng and Byrne, 2005a). Where a tar get word is emitted from null, it is not included in the alignment links, so this tar get word is vie wed as not being aligned to any source word; this affects the preci-sion and recall. The results reported abo ve use p 0 = 0 . for English-Arabic and p 0 = 0 . 4 for Arabic-English; we can tune these values to produce alignments with the low-est AER. Figure 5 sho ws precision-recall curv es for the CD HMMs compared to the CI HMMs for both transla-tion directions. For a given value of precision, the CD HMM has higher recall; for a given value of recall, the CD HMM has higher precision.

We do not report F-score (Fraser and Marcu, 2006) since in our experiments we have not found strong cor -relation with translation performance, but we note that these results for precision and recall should lead to im-pro ved F-scores as well. We have sho wn that the conte xt-dependent models pro-duce a decrease in AER measured on manually-aligned data; we wish to sho w this impro ved model performance leads to an increase in translation quality , measured by BLEU score (Papineni et al., 2001). In addition to the Arabic systems already evaluated by AER, we also report results for a Chinese-English translation system.
Alignment models were evaluated by aligning the training data using the models in each translation direc-tion. HiFST , a WFST -based hierarchical translation sys-tem described in (Iglesias et al., 2009), was trained on the union of these alignments. MET (Och, 2003) was carried out using a development set, and the BLEU score evaluated on two test sets. Decoding used a 4-gram lan-guage model estimated from the English side of the entire MT08 parallel text, and a 965M word subset of monolin-gual data from the English Giga word Third Edition.
For both Arabic and English, the CD HMM models were evaluated as follo ws. Iteration 5 of the CI HMM was used to produce alignments for the parallel text train-ing data: these were used to train the baseline system. The same data is aligned using CD HMMs after two further iterations of training and a second WFST -based translation system built from these alignments. The mod-els are evaluated by comparing BLEU scores with those of the baseline model. 4.1 Arabic to English translation Alignment models were trained on the NIST MT08 Arabic-English parallel text, excluding the UN portion. The null alignment probability was chosen based on the AER, resulting in values of p 0 = 0 . 05 for Arabic to English and p 0 = 0 . 10 for English to Arabic. We per -form experiments on the NIST Arabic-English transla-tion task. The mt02 05 tune and mt02 05 test data sets are formed from the odd and even numbered sentences of the NIST MT02 to MT05 evaluation sets respecti vely; each contains 2k sentences and 60k words. We use mt02 05 tune as a development set and evaluate the sys-tem on mt02 05 test and the newswire portion of the MT08 set, MT08-nw . Table 3 sho ws a comparison of the system trained using CD HMMs with the baseline sys-tem, which was trained using CI HMM models on un-tagged data. The conte xt-dependent models result in a gain in BLEU score of 0.3 for mt02 05 test and 0.6 for MT08-nw . 4.2 Chinese to English translation The Chinese training set was 600k random parallel text sentences of the newswire LDC collection allo wed for NIST MT08, a total of 15.2M words of Chinese and 16.6M words of English. The Chinese text was tagged us-ing the MXPOST maximum-entrop y part of speech tag-ging tool (Ratnaparkhi, 1996) trained on the Penn Chi-nese Treebank 5.1; the English text was tagged using the TnT part of speech tagger (Brants, 2000) trained on the Wall Street Journal portion of the English Penn treebank.
The development set tune-nw and validation set test-nw contain a mix of the newswire portions of MT02 through MT05 and additional developments sets created by trans-lation within the GALE program. We also report results on the newswire portion of the MT08 set. Again we see an increase in BLEU score for both test sets: 0.5 for test-Alignments tune mt02 05 test MT08-nw CI HMM 50.0 49.4 46.3 CD HMM 50.0 49.7 46.9 Alignments tune test-nw MT08-nw CI HMM 28.1 28.5 26.9 CD HMM 28.5 29.0 27.7 nw and 0.8 for MT08-nw . We have introduced conte xt-dependent Model 1 and HMM alignment models, which use conte xt information in the source language to impro ve estimates of word-to-w ord translation probabilities. Estimation of parame-ters using these conte xts without smoothing leads to data sparsity problems; therefore we have developed decision tree clustering algorithms to cluster source word conte xts based on optimisation of the EM auxiliary function. Con-text information is incorporated by the use of part-of-speech tags in both languages of the parallel text, and the EM algorithm is used for parameter estimation.
We have sho wn that these impro vements to the model lead to decreased AER compared to conte xt-independent models. Finally , we compare machine translation sys-tems built using our conte xt-dependent alignments. For both Arabic-and Chinese-to-English translation, we report an increase in translation quality measured by BLEU score compared to a system built using conte xt-independent alignments.

This paper describes an initial investigation into conte xt-sensiti ve alignment models, and there are man y possible directions for future research. Clustering the probability distrib utions of infrequently occurring may produce impro vements in alignment quality , dif ferent model training schemes and extensions of the conte xt-dependence to more sophisticated alignment models will be investigated. Further translation experiments will be carried out.
 This work was supported in part by the GALE program of the Defense Adv anced Research Projects Agenc y, Con-tract No. HR0011-06-C-0022. J. Brunning is supported by a Schif f Foundation graduate studentship. Thanks to Yanjun Ma, Dublin City Uni versity , for training the Chi-nese part of speech tagger .
