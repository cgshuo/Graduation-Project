 University of Melbourne, Australia DFKI GmbH and Saarland University, Germany Federal University of Rio Grande do Sul, Brazil, and University of Bath, UK 1. Introduction Prepositions 1  X  X s well as prepositional phrases (PPs) and markers of various sorts X  have a mixed history in computational linguistics (CL), as well as related fields such as artificial intelligence, information retrieval (IR), and computational psycholinguistics: On the one hand they have been championed as being vital to precise language un-derstanding (e.g., in information extraction), and on the other they have been ignored on the grounds of being syntactically promiscuous and semantically vacuous, and relegated to the ignominious rank of  X  X top word X  (e.g., in text classification and IR). sitions have received attention, there are still many issues to be addressed. For example, in machine translation, generating a preposition (or  X  X ase marker X  in languages such as Japanese) incorrectly in the target language can lead to critical semantic divergences over the source language string. Equivalently in information retrieval and information extraction, it would seem desirable to be able to predict that bookon NLP and bookabout NLP mean largely the same thing, but paranoidabout drugs and paranoidon drugs suggest very different things.
 based on the British National Corpus (BNC; Burnard 2000), four out of the top-ten most-frequent words in English are prepositions ( of , to , in ,and for ). In terms of both parsing and generation, therefore, accurate models of preposition usage are essential to avoid repeatedly making errors. Despite their frequency, however, they are notoriously difficult to master, even for humans (Chodorow, Tetreault, and Han 2007). For example, Lindstromberg (2001) estimates that less than 10% of upper-level English as a Second
Language (ESL) students can use and understand prepositions correctly, and Izumi et al. (2003) reported error rates of English preposition usage by Japanese speakers of up to 10%.
 across the spectrum of computational linguistics, focusing on computational syntax and semantics. More importantly, however, we hope to reignite interest in the systematic treatment of prepositions in applications. To this end, this article is intended to present a cross-section view of research on prepositions and their use in NLP applications. We begin by outlining the syntax of prepositions and its relevance to NLP applications, focusing on PP attachment and prepositions in multiword expressions (Section 2). Next, we discuss formal and lexical semantic aspects of prepositions, and again their rele-vance to NLP applications (Section 3), and describe instances of applied research where prepositions have featured prominently (Section 4). Finally, we outline the contributions of the papers included in this special issue (Section 5) and conclude with a discussion of research areas relevant to prepositions which we believe are ripe for further exploration (Section 6). 2. Syntax
There has been a tendency for prepositions to be largely ignored in the area of syntactic research as  X  X n annoying little surface peculiarity X  (Jackendoff 1973, page 345). In com-putational terms, the two most important syntactic considerations with prepositions are: (1) selection (Fillmore 1968; Bennett 1975; Tseng 2000; Kracht 2003), and (2) valence (Huddleston and Pullum 2002).
 governor (usually a verb) as part of its argument structure. An example of a selected preposition is with in dispense with introductions , where introductions is the object of the verb dispense , but must be realized in a prepositional phrase headed by with (c.f. *dispense introductions ). Conventionally, selected prepositions are specified uniquely (e.g., dispense with ) or as well-defined clusters (e.g., chuckle over/at ), and have bleached semantics.
Selected prepositions contrast with unselected prepositions, which do not form part of the argument structure of a governor and do have semantic import (e.g., live in
Japan ). Unsurprisingly, there is not a strict dichotomy between selected and unselected prepositions (Tseng 2000). For example, in the case of rely on Kim , on is specified in the argument structure of rely but preserves its directional semantics; similarly, in putit and the preposition is semantically transparent.
 syntax X  X emantics interface, that is, that overtly translates surface strings onto semantic representations, or vice versa (e.g., information extraction or machine translation using some form of interlingua). It forms a core component of subcategorization learning (Manning 1993; Briscoe and Carroll 1997; Korhonen 2002), and poses considerable chal-lenges when developing language resources with syntactico-semantic mark-up (Kipper, Snyder, and Palmer 2004).
 prepositions (often referred to as  X  X articles X ) are valence-saturated, and as such do not take arguments. They occur most commonly as: (a) components of larger multiword expressions (e.g., verb particle constructions, such as pick it up ), (b) copular predicates (e.g., thedoctorisin ), or (c) prenominal modifiers (e.g., anoff day ). Transitive prepositions, 120 on the other hand, select for (usually noun phrase) complements to form PPs (e.g., at home ). The bare term  X  X reposition X  traditionally refers to a transitive preposition, but in this article is used as a catch-all for prepositions of all valences.
 ature but has been a latent feature of all work on part of speech (POS) tagging and parsing over the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), as the Penn PO Stagset distinguishes between transitive prepositions ( IN ), selected intransitive prepositions ( RP ), and unselected intransitive prepositions ( RB , along with a range of other adverbials). 2 There have been only isolated cases of research where a dedicated approach has been used to distinguish between these three sub-usages, in the interests of optimizing overall PO Stagging or parsing performance ( Shaked 1993; Toutanova and Manning 2000; Klein and Manning 2003; MacKinlay and Baldwin 2005).
 attachment and (b) prepositions in multiword expressions, which are discussed in the following sections. Although this article will focus largely on the syntax of preposi-tions in English, prepositions in other languages naturally have their own challenges. Notable examples which have been the target of research in computational linguistics are adpositions in Estonian (Muischnek, M  X  u  X  urisep, and Puolakainen 2005), adpositions in Finnish (Lestrade 2006), short and long prepositions in Polish (Tseng 2004), and the French ` a and de (Abeill  X  e et al. 2003). 2.1 PP Attachment PP attachment is the task of finding the governor for a given PP. For example, in the following sentence: (1) Kim eats pizza with chopsticks there is syntactic ambiguity, with the PP with chopsticks being governed by either the noun pizza (i.e., as part of the NP pizza with chopsticks , as indicated in Example (2)), or the verb eats (i.e., as a modifier of the verb, as indicated in Example (3)). (2) S (3) S
Of these, the latter case of verb attachment (i.e., Example (3)) is, of course, the correct analysis.
 unbounded. One special case of note is a sequence of PPs such as Kim eats pizza withchopsticks onWednesdays atPapaGino X  X  , where the number of discrete analyses for a sequence of n PPs is defined by the corresponding Catalan number C n (Church and Patil 1982). The bulk of PP attachment research, however, has focused exclusively on the case of a single PP occurring immediately after an NP, which in turn is immediately preceded by a verb. As such, we will focus our discussion predominantly on this syntactic context.
To simplify discussion, we will refer to the verb as v , the head noun of the immediately proceeding NP as n 1 , the preposition as p , and the head noun of the NP object of the preposition as n 2 . Returning to our earlier example, the corresponding 4-tuple is eat v , pizza n 1 , with p , chopsticks n 2 .
 nomenon when parsing languages such as English, and hence a major cause of parser errors (Lin 2003). As such, it has implications for any task requiring full syntactic analysis or a notion of constituency, such as prosodic phrasing (van Herwijnen et al. 2003). Languages other than English with PP attachment ambiguity which have been the target of research include Dutch (van Herwijnen et al. 2003), French (Gaussier and Cancedda 2001; Gala and Lafourcade 2005), German (Hartrumpf 1999; Volk 2001, 2003;
Foth and Menzel 2006), Spanish (Calvo, Gelbukh, and Kilgarriff 2005), and Swedish (Kokkinakis 2000; Aasa 2004; Volk 2006).
 the course of the last three decades, and been the target of interest of theoretical syntax, AI, psycholinguistics, statistical NLP, and statistical parsing.
 to model human processing strategies, based on analysis of the competing parse trees independent of lexical or discourse context (Frazier 1979; Sch  X  utze 1995). For example,
Minimal Attachment was the strategy of choosing the attachment site which  X  X ini-mizes X  the parse tree, as calculated by its node membership; assuming the parse trees provided for Example (1), this would be unable to disambiguate between Examples (2) and (3) as they both contain the same number of nodes. Late Attachment, on the other hand, was the strategy of attaching  X  X ow X  in the parse tree, corresponding to Exam-ple (2). Ford, Bresnan, and Kaplan (1982) proposed an alternative heuristic strategy, based on the existence of p in a subcategorization frame for v . In later research, Pereira (1985) described a method for incorporating Right Association and Minimal Attachment 122 into a shift-reduce parser, and Whittemore and Ferrara (1990) developed a rule-based algorithm to combine various attachment preferences on the basis of empirical evalua-tion of the predictive power of each.
 ment, and largely ineffectual in predicting the difference in PP attachment between Kim eats pizza with chopsticks (verb attachment) and Kim eats pizza with anchovies (noun attachment), for example. This led to a shift away from syntactic methods in the 1980s towards AI-inspired techniques which used world knowledge to resolve PP attachment ambiguity. In the case of Example (1), for example, the knowledge that chopsticks are an eating implement would suggest a preference for verb attachment, and similarly the knowledge that they are not a foodstuff would suggest a dis preference for noun attach-ment. Wilks, Huang, and Fass (1985) attempted to capture this type of world knowledge using hand-coded  X  X referential semantics X  of each of v , n 1 , p ,and n 2 .Dahlgrenand McDowell (1986) simplified this analysis to use only p and n 2 , still in the form of hand-coded rules. Hirst (1987) used his model of  X  X ommonsense semantics X  to resolve PP attachment ambiguity, based on verb-guided preferences (i.e., valence properties of the verb) and plausibility relative to a knowledge base. In this same vein, Jensen and Binot (1987) used the dictionary definitions of v and n 2 as a  X  X nowledge base X  to resolve PP attachment based on approximate reasoning, for example, by determining that chopsticks is an instrument which is compatible with eat .
 experimental evidence to suggest that PP attachment resolution interacts dynamically with discourse context, and that ambiguity is resolved on the basis of the interdepen-dence between structure and the mental representation of that context. This suggested that computational research on PP attachment resolution needed to take into account the discourse context, in addition to syntax and world knowledge. Spivey-Knowlton and Sedivy (1995) later used psycholinguistic experiments to demonstrate that verb-specific attachment properties and NP definiteness both play important roles in the human processing of PP attachment. Importantly, this work motivated the need for verb classes to resolve PP attachment ambiguity.
 Hindle and Rooth (1993), who were the harbingers of statistical NLP and large-scale empirical evaluation. Hindle and Rooth challenged the prevailing view at the time that lexical semantics and/or discourse modeling were needed to resolve PP attachment, in proposing a distributional approach, based simply on estimation of the probability of p attaching high or low given v and n 1 (ignoring n 2 ). The method uses unambiguous cases of PP attachment (e.g., cases of n 1 being a pronoun [high attachment], or the PP post-modifying n 1 in subject position [low attachment]) to derive smoothed estimates respectively. The proposed method was significant in demonstrating the effectiveness of simple co-occurrence probabilities, without explicit semantics or discourse processing, and also in its ability to operate without explicitly annotated training data. tioned on the semantics of the noun object of the preposition in the PP, as can be seen in our earlier example of Kim eats pizza with chopsticks/anchovies where chopsticks leads to verb attachment and anchovies to noun attachment. Although they were unable to come up with a model which was empirically superior to existing methods which did not represent the semantics of the noun object, this paved the way for a new wave of research using the full 4-tuple of v , n 1 , p , n 2 .
Roukos (1994), who in the process established a benchmark PP attachment data set upon which most of the subsequent research has been based. The data set, colloquially known as the  X  X RR X  data set, was automatically extracted from the Wall Street Journal section of the Penn Treebank, and is made up of 20,801 training and 3,097 test 4-tuples of type v , n 1 , p , n 2 , each of which is annotated with a binary label for verb or noun attachment. 3 Also of significance was the fact that Ratnaparkhi, Reynar, and Roukos were able to come up with a  X  X lass X  representation for words, based on distributional similarity, that outperformed a simple word-based model.
 and the RRR data set, defined the task of PP attachment for over a decade. It has been tackled using a variety of smoothing methods and machine learning algorithms, includ-ing backed-off estimation (Collins and Brooks 1995), instance-based learning (Zavrel,
Daelemans, and Veenstra 1997; Zhao and Lin 2004), log-linear models (Franz 1996), maximum entropy learning (Ratnaparkhi, Reynar, and Roukos 1994), decision trees (Merlo, Crocker, and Berthouzoz 1997), neural networks (Sopena, Lloberas, and Moliner 1998; Alegre, Sopena, and Lloberas 1999), and boosting (Abney, Schapire, and Singer 1999). In addition to the four lexical and class-based features provided by the 4-tuple v , n 1 , p , n 2 , researchers have used noun definiteness, distributional similarity, noun number, subcategorization categories, word proximity in corpus data, and PP semantic class (Stetina and Nagao 1997; Yeh and Vilain 1998; Pantel and Lin 2000; Volk 2002). The empirical benchmark for the data set was achieved by Stetina and Nagao (1997), who used WordNet (Fellbaum 1998) to explicitly model verb and noun semantics.

Japanese translations of English verb and noun attachment involve distinct construc-tions. This allowed them to automatically identify instances of PP attachment ambiguity in a parallel English X  X apanese corpus, complete with attachment information. They used this data to disambiguate PP attachment in English inputs, and demonstrated that, the quality of English X  X apanese machine translation improved significantly as a result. ods based on the RRR data set, on the grounds that it is based on the availability of a gold-standard parse tree for a given input. They proposed that, instead, PP attachment be evaluated as a means of post-processing over the raw output of an actual parser, and produced results to indicate: (a) that a state-of-the-art parser (Bikel 2004) does remarkably well at PP attachment without a dedicated PP attachment module; but also (b) that post-processing based on a range of methods developed over the RRR data set (Collins and Brooks 1995; Toutanova, Manning, and Ng 2004; Olteanu and
Moldovan 2005) generally improves parser accuracy. In addition, they developed a variant of the RRR data set (RRR-sent) which contains full sentential contexts of possible
PP attachment ambiguity. Others who have successfully built PP re-attachment models for specific parsers are Olteanu (2004) and Foth and Menzel (2006). Agirre, Baldwin, and Martinez (2008) used the evaluation methodology of Atterer and Sch  X  utze (2007) to confirm the finding from the original RRR data set that lexical semantics (in various guises) can enhance PP attachment accuracy relative to a baseline parser. As part of this effort, they developed a standardized data set for exploration of the interaction between lexical semantics and parsing/PP attachment accuracy. 124 to generate a richer semantic characterisation of the PP is the work of Merlo (2003) and Merlo and Esteve Ferrer (2006), who included classification of the PP as an argument or adjunct, making for a four-way classification task. In this context, they found that PP attachment resolution for argument PPs is considerably easier than is the case for adjunct PPs.
 configurations, Merlo, Crocker, and Berthouzoz (1997) applied backed-off estimation to the problem of multiple PP attachment, in the form of 14 discrete syntactic config-urations. Unsurprisingly, they found the task considerably harder than the basic V NP PP case, due to increased ambiguity and data sparseness. Mitchell (2004) similarly per-formed an extensive analysis of the Penn Treebank to investigate the different contexts PP attachment ambiguities occur in, and the relative ability of different PP attachment methods to disambiguate each.
 example, in the area of biomedicine (Hahn, Romacker, and Schulz 2002; Pustejovsky et al. 2002; Leroy, Chen, and Martinez 2003; Schuman and Bergler 2006). 2.2 The Syntax of Prepositional Multiword Expressions Prepositions are also often found as part of multiword expressions (MWEs), such as verb-particle constructions ( break down ), prepositional verbs ( rely on ), determinerless PPs ( in hospital ), complex prepositions ( by means of ) and compound nominals ( affairs of state ). MWEs are lexical items which are composed of more than one word and are lexically, syntactically, semantically, pragmatically, and/or statistically idiosyncratic in some way (Sag et al. 2002). In this section, we present a brief overview of the syntax of the key prepositional MWEs in English, and discuss a cross-section of some of the recent research done in the area.
 complex prepositions undergo no inflection, internal modification, or word order vari-ation (e.g., in addition to ) and are best analyzed as  X  X ords with spaces X  (Sag et al. 2002). Others optionally allow internal modification (e.g., with [due/particular/special/...] regard to ) or determiner insertion (e.g., on [the] top of ) and are considered to be semi-fixed expressions (Villada Moir  X  on 2005). Compound nominals are similarly semi-fixed expressions, in that they have rigid constraints on word order and lexical composition, but allow morphological inflection (e.g., part(s)ofspeech ).
 English, in terms of their relative frequency and tendency for syntactic variation, are: 1. verb-particle constructions (VPCs), where the verb selects for an 2. prepositional verbs (PVs), where the verb selects for a transitive 3. determinerless PPs (PP X  X s), where a PP is made up of a preposition and All three MWE types undergo limited syntactic variation (Sag et al. 2002). For exam-ple, transitive verb particle constructions generally undergo the particle alternation, whereby the particle may occur either adjacent to the verb (e.g., tear up the letter ), or be separated from the verb by the NP complement (e.g., tear the letter up ). Some VPCs readily occur with both orders (like tear up ), while others have a strong preference for a particular order (e.g., take off  X  X nder the interpretation of having the day off X  X ends to occur in the particle-final configuration in usages such as take Friday off vs. ?take off
Friday ). 4 In addition, many VPCs undergo limited internal modification by adverbials, where the adverb pre-modifies the particle (e.g., comestraightover ).
 basic forms: (1) fixed preposition PVs (e.g., come across ), where the verb and selected preposition must be strictly adjacent; and (2) mobile preposition PVs (e.g., refer to ), where the selected preposition is adjacent to the verb in the canonical word order, but undergoes limited syntactic alternation. For example, mobile preposition PVs allow limited coordination of PP objects (e.g., refer to the book and to the DVD ), and the NP object of the selected preposition can be passivized (e.g., thebooktheyreferredto ). noun in the PP X  X  is often strictly countable (e.g., off screen , on break ), resulting in syntactic markedness as, without a determiner, the noun does not constitute a saturated
NP. This in turn dictates the need for a dedicated analysis in a linguistically motivated grammar in order to be able to avoid parse failures (Baldwin et al. 2004; van der Beek 2005). Additionally, there is considerable variation in the internal modifiability of deter-minerless PPs, with some not permitting any internal modification (e.g., of course )and others allowing optional internal modification (e.g., atconsiderablelength ). There are also, however, cases of obligatory internal modification (e.g., at considerable/great expense vs. *atexpense ) and highly restricted internal modification (e.g., atlonglast vs. *atgreat/short last ). Balancing up these different possibilities in terms of over-and undergeneration in a grammar is far from trivial (Baldwin et al. 2006).
 with their own syntactic complexities. Notable examples to have received attention in the computational linguistics literature are Dutch  X  X ollocational prepositional phrases X  (Villada Moir  X  on 2005), German complex prepositions (Trawi  X  nski 2003; Trawinski, Sailer, and Soehn 2006), German particle verbs (Schulte im Walde 2004; Rehbein and van
Genabith 2006), and Polish preposition X  X ronoun contractions (Trawi  X  nski 2005, 2006). 2.2.1 Prepositional MWEs in NLP. The syntactic variation of prepositional MWEs leads to difficulties for NLP applications. To start with, there is the problem of identifying their token occurrences, for example, for semantic indexing purposes. As with simplex words, a given MWE may appear with different subcategorization frames (e.g., giveup vs. give up [something] ), but added to that, the order of the elements may be flexible or internally modified (see previous discussion), and some elements may be optional (e.g., out in make a big thing (out) of [something] ). Additionally, they conspire with PP attachment ambiguity to compound structural ambiguity. For example, handthepaperin today is ambiguous between a V NP PP analysis ([ V hand ][ NP thepaper ][ PP intoday ]), a
VNPanalysis([ V hand ][ NP the paper in today ]), and a transitive VPC analysis ([ V hand ] [ NP thepaper ][ P in ][ NP today ]); of these, the final analysis is, of course, correct. 126 for linguistically motivated parsers. First, a representation must be arrived at which is sufficiently expressive to encode the syntactic subtleties of each MWE instance (Sag et al. 2002; Calzolari et al. 2002; Copestake et al. 2002; Odijk 2004). Second, the lexicon must be populated in order to ensure adequate parser coverage over prepositional MWEs. Due to the high productivity and domain specificity of prepositional MWEs, a number of lexical acquisition approaches have been developed, usually customized to a particular prepositional MWE type in a specific language.
 their automatic extraction from raw text corpora, on the basis of a PO Stagger, chunker, and chunk grammar, and finally the combined output of the three along with various linguistic and frequency features. Baldwin (2005a) expanded on this work to extract VPCs complete with valence information, to produce a fully specified lexical item. In both cases, it was found that 100% recall was extremely hard to achieve due to the power-law distribution of VPC token frequencies in corpus data. That is, around half of the VPC lexical items found in pre-existing lexical resources occurred in the BNC at most 2 times.
 productively in semantically coherent clusters, based on (near-)synonymy of the head verb (e.g., clear/clean/drain up and break/rip/cut/tear up ). As a result, she expanded a seed set of VPCs based on class-based verb semantic information, and used Web-based statistics to filter false positives out of the resultant VPC candidate set. namely, identifying each individual VPC token instance in corpus data, based on a set of hand-crafted regular expressions. Although they report very high precision and recall for their method, it has the obvious disadvantage that the regular expressions must be manually encoded, and it is not clear that the proposed method is superior to an off-the-shelf parser. Kim and Baldwin (2006, in press) attempted to automate the process of identification by post-processing the output of the RASP parser, and demonstrated (a) that the RASP parser (Briscoe, Carroll, and Watson 2006) is highly effective at VPC identification, and (b) that the incorporation of lexicalized models of selectional preferences can lead to modest improvements in parser accuracy. combination of statistical measures and linguistic diagnostics, and demonstrated that the combination of statistics with linguistic diagnostics achieved the best extraction performance.
 and Evert (2001) and Evert and Krenn (2005) on the extraction of German PP X  X erb collocations (which are similar to verbal idioms/verb X  X oun combinations in English [Fazly, Cook, and Stevenson 2009]) based on a range of lexical association measures. Pecina (2008) further extended this work using a much broader set of lexical association measures and classifier combination. Looking at German, D  X  omges et al. (2007) analyzed the productivity of PP X  X s headed by unter , and used their results to motivate a syntactic analysis of the phenomenon. For Dutch, van der Beek (2005) worked on the extraction of PP X  X s from the output of a parser, once again using a range of statistical measures. Sharoff (2004) described a semi-automatic approach to classifying prepositional MWEs in Russian, based on statistical measures and manual filtering using knowledge about the structure of Russian prepositional phrases.
 tional (and general) MWE extraction was the release of a number of standardized data sets for MWE extraction evaluation as part of an LREC 2008 Workshop. This includes data sets for English VPCs (Baldwin 2008) and German PP X  X erbs (Krenn 2008). 3. Semantics
There are three diametrically opposed views to the semantics of prepositions: (1) prepo-sitions are semantically vacuous and unworthy of semantic representation (a view commonly subscribed to in the information retrieval community: Baeza-Yates and
Ribeiro-Neto [1999], Manning, Raghavan, and Sch  X  utze [2008]); (2) preposition semantics is a function of the words that select them and they in turn select, such that it is impos-sible to devise a standalone semantic characterization of preposition semantics (Tseng 2000; Old 2003); and (3) prepositional semantics is complex but can be captured in a standalone resource (Kipper, Dang, and Palmer 2000; Saint-Dizier and Vazquez 2001;
Litkowski and Hargraves 2005). Kipper, Snyder, and Palmer (2004, page 23) elegantly summarized this third position as  X  X t is precisely because the preposition X  X emantics relationship is so complex that properly accounting for it will lead to a more robust natural language resource. X  Turning the clock back 16 years, Zelinski-Wibbelt (1993, page 1) observed that  X  X e are now witnessing a veritable plethora of investigations into the semantics of preposition semantics X  and speculated that  X  X he time has come to see how natural language processing (NLP) can benefit from the insights of theoretical linguistics. X  Although these prognostications were perhaps overly optimistic at the time, they are now being progressively fulfilled.
 tional (or regular/productive) and non-compositional (or irregular/collocational) se-mantics. Preposition usages with compositional semantics transparently preserve the standalone semantics of the preposition (e.g., They met on Friday ), whereas those with non-compositional semantics involve some level of semantic specialization or diver-gence from the standalone semantics (e.g., They got on famously ). In terms of formal semantics, the complement vs. adjunct distinction 5 is also relevant for determining the logical form for a given input.
 tions, and the semantics of prepositional MWEs. 3.1 Formal Semantic Approaches to Prepositions
Research on the formal semantics of prepositions has focused predominantly on devis-ing representations for temporal, spatial, and locative usages, the three most productive and coherent classes of prepositions.
 duration of a proposition. Normally, three types of information are identified: (1) the duration of the preposition, (2) its duration relative to the time of reference of the dis-course, and (3) its absolute location on the time axis. Some prepositions convey all three types of information, and others convey only one. Within each information type, the 128 semantic input of temporal prepositions can vary considerably: They can distinguish between existential and universal quantification over time, indicate whether or not the extremes of the period are to be included, and mark the motion through time. is coming up with a representation which can adequately encode the different semantics of temporal prepositions (Bennett 1975; Miller and Johnson-Laird 1976; R  X  ohrer 1977; Kamp 1981; Allen 1984; Richards et al. 1989; Br  X  ee and Smit 1986; Durrell and Br  X  ee 1993). Another concern has been the ability to support compositional semantic interpretation of temporal PPs, with emphasis on their quantificational role. For English, Pratt and Francez (1997), for instance, proposed generalized temporal quantifiers to represent temporal NPs, temporal PPs, and sentences.
 semantic representations that capture both the functional relationships between the objects, and human interaction with those objects. Along these lines, Kelleher and Costello (2009) propose computational models of spatial preposition semantics for use in visually situated dialogue systems.
 they should decompose into three semantic elements: a locative relation, a reference entity, and a place value. Each locative expression (e.g., a PP or NP) is generally assumed to have a unique locative relation and place value. Thus, combinations of pure locative relation markers and prepositions which are specified for place values are ruled out, and no embedded locative relations are allowed in the semantic structure of a single locative expression. Some locative prepositions are underspecified for a place value, however, and thus are able to co-occur with a second preposition that specifies a place value (e.g., out from under the table ). The specific locative relation denoted by a preposition is generally considered not to be specified in the lexicon, but instead to vary with eventuality types.
 framework (Copestake et al. 2005) as the basis for a language-independent represen-tation of semantics of locative prepositions. They applied the proposed representa-tion to English and Norwegian locative prepositions, and demonstrated its utility for Norwegian X  X nglish machine translation. Hellan and Beermann (2005) similarly used the MR Sframework to capture the locative and spatial semantics of Norwegian prepo-sitions. Ramsay (2005) proposed a unified theory of preposition semantics, where the semantics of temporal usages of prepositions are predicted naturally from abstract relational definitions. Arsenijevi  X  c (2005) developed a formal semantic analysis of prepo-sitions in terms of event structure and applied it to a natural language generation task.
 motion complexes in English (e.g., Kim ran to the library ), and developed an analysis based on the conclusion that the preposition is often semantically rather than syn-tactically determined. This lends support to arguments for a systematic account of preposition semantics.
 alternations, and proposed an MR Sanalysis of indirect prepositional arguments based on English, German, and Modern Greek data. Specifically, she showed that a robust formal semantic framework like MR Sprovides an appropriate theoretical basis for a linguistically motivated account of indirect prepositional arguments, and also the necessary formal generalizations for the analysis of such arguments in a multilingual context (as a result of MR Sstructures being easily comparable across languages). 3.2 Lexical Semantic Resources for Prepositions
A number of lexical semantic resources have been developed specifically for prepo-sitions, four of which are outlined here: (1) the English LC SLexicon, (2) the Preposition Project, (3) PrepNet, and (4) VerbNet.

Structure (based on work by Jackendoff [1983, 1990] 6 ) to encode lexical knowledge using a typed directed graph of semantic primitives and fields. In addition to a large lexicon of verbs, it includes 165 English prepositions classified into 122 intransitive and 375 transitive senses. For example, the LC Srepresentation for the directional sense of up (as in up thestairs )is: (4) (toward Loc (nil 2) (UP Loc (nil 2) (  X  Thing 6))) where the numbers indicate the logical arguments of the predicates. This representation indicates that the logical subject of the PP (indexed by  X 2 X ; e.g., the piano in move the piano up the stairs ) is relocated up in the direction of the logical argument (indexed by  X 6 X ; e.g., the stairs in our example), which is in turn a concrete thing. The LC SLexicon was developed from a theoretical point of view and isn X  X  directly tied to corpus usage. an attempt to develop a comprehensive semantic database for English prepositions, intended for NLP applications. The project took the New Oxford Dictionary of English (Pearsall 1998) as its source of preposition sense definitions, which it then fine-tuned based on cross-comparison with both functionally tagged prepositions in FrameNet (Baker, Fillmore, and Lowe 1998) and the account of preposition semantics in a de-scriptive grammar of English (Quirk et al. 1985); it also draws partially on Dorr X  X 
LC Sdefinitions of prepositions. Importantly, the Preposition Project is building up a significant number of tagged preposition instances through analysis of the preposition data in FrameNet, which it then uses to characterize the noun selectional preferences of each preposition sense and also the attachment properties to verbs of different types. At the time of writing, 673 preposition senses for 334 prepositions (mostly phrasal prepo-sitions) have been annotated. In tandem with developing type-level sense definitions of prepositions, the Preposition Project has sense annotated over 27,000 occurrences of the 56 most common prepositions, based on functionally tagged prepositions in FrameNet.
To date, the primary application of the Preposition Project has been in a SemEval 2007 task on the word sense disambiguation of prepositions (see Section 3.3).

Dizier 2005, 2008) is an attempt to develop a compositional account of preposition semantics which interfaces with the semantics of the predicate (e.g., verb or predicative noun). Similarly to the English LCS Lexicon, it uses LCS as the descriptive language, in conjunction with typed  X  -calculus and underspecified representations. Noteworthy elements of PrepNet are that it attempts to capture selectional constraints, metaphor-ical sense extension, and complex arguments. PrepNet was originally developed over
French prepositions, but has since been applied to the analysis of instrumentals across a range of languages (Saint-Dizier 2006b).
 hierarchy of 50 spatial prepositions, classified into five categories. The hierarchy is 130 derived from pioneering work by Sp  X  arck Jones and Boguraev (1987), which is in turn derived from Wood (1979). The preposition sense inventory was used as the basis for extending VerbNet and led to significant redevelopment of the verb class set (Kipper, Snyder, and Palmer 2004), in a poignant illustration of how preposition semantics impinges on verb semantics.
 sitions into 16 classes. Lersundi and Agirre (2003) applied a similar methodology to Dorr and Habash (2002) in developing a multilingual sense inventory for Basque post-positions and English and Spanish prepositions. Fort and Guillaume (2007) developed a syntactico-semantic lexicon of French prepositions, partly based on PrepNet; their particular interest was in enhancing parsing performance. Old (2003) analyzed Roget X  X  Thesaurus and arrived at the conclusion that it was not a good source of standalone preposition semantics. Beavers (2003) analyzed the aspectual and path properties of goal-marking postpositions in Japanese, and proposed an analysis based on predicate and event restrictions. Boonthum, Toida, and Levinstein (2005, 2006) defined a general-purpose sense inventory of seven prepositions (but purportedly applicable to all prepo-sitions), taking the LC Slexicon as a starting point and expanding the sense inventory by consulting Quirk et al. (1985) and Barker (1996). Finally, as part of a more general attempt to capture lexical semantics in the formalism of Multilayered Extended Seman-tic Networks (MultiNet), Helbig (2006) developed a semantic treatment of prepositions, focusing primarily on German.
 cognitive linguistics (Talmy 1988), in the form of  X  X chemas. X  Schemas are an attempt to visualize the relation between the object of the preposition (the Trajector, or TR) and its cognitive context (the Landmark, or LM). They provide a language-independent repre-sentation, and have been used to analyze crosslinguistic correspondences in preposition semantics. For example, Tyler and Evans (2003)used schemas to capture the semantics of English prepositions, arguing that all meanings are grounded in human spatio-physical experience. Schemas have also been used as the basis of crosslinguistic analysis of preposition semantics, for example, by Brala (2000) to describe the senses of on and in in English and Croatian, Kna  X  s (2006) to motivate a sense inventory for at in English and Polish, and Cosme and Gilquin (2008) to contrast with and avec in English and French. prepositions for machine translation purposes, in a lexicalist framework. 3.3 Automatic Classification of Preposition Sense Only a modest amount of research has been carried out on the sense disambiguation of prepositions, largely because until recently, there haven X  X  been lexical semantic re-sources and sense-tagged corpora for prepositions that could be used for this purpose. Classification of preposition sense has been motivated as a standalone task in appli-cations such as machine translation, and also as a means of improving the general performance of semantic tasks such as semantic role labeling.
 sense disambiguation (WSD) task, based on the semantic roles in the Penn Treebank. They collapsed the semantic roles into seven basic semantic classes, and built a decision tree classifier based on a set of contextual features similar to those used in WSD systems. O X  X ara and Wiebe (2009) is an updated version of this original research, using a broader range of resources. Ye and Baldwin (2006) also built on the earlier research, in attempt-ing to enhance the accuracy of semantic role labeling with dedicated PP disambiguation.
They demonstrated the potential for accurate preposition labeling to contribute to large-scale improvements in overall semantic role labeling performance.

WSD of prepositions at SemEval 2007, as a spinoff of the Preposition Project. The task focused on 34 prepositions, with a combined total of 332 senses. Similarly to a lexical sample WSD task, participants were required to disambiguate token instances of each preposition relative to the provided discrete sense inventory. Three teams participated in the task (Popescu, Tonelli, and Pianta 2007; Ye and Baldwin 2007; Yuret 2007), with all systems outperforming two baselines over both fine-and coarse-grained sense invento-ries, through various combinations of lexical, syntactic, and semantic features. The best-performing system achieved F-scores of 0.818 and 0.861 over fine-and coarse-grained senses, respectively (Ye and Baldwin 2007).
 (2005, 2006) proposed a semantic collocation-based approach to preposition interpre-tation, and demonstrated the import of the method in a paraphrase recognition task.
Alam (2003, 2004) used decision trees to disambiguate 12 senses of over , distinguishing between senses which are determined by their governor and those which are deter-mined by their NP complement.
 tributional hypothesis, based on latent semantic analysis (LSA; Deerwester et al. 1990). He derived gold-standard preposition-to-preposition similarities using each of Dorr X  X 
LC Slexicon (based on the method of Resnik and Diab [2000]) and Roget X  X  Thesaurus , and compared them to the similarities predicted by LSA, in each case using either valence specification (considering intransitive and transitive prepositions separately) or valence underspecification (considering both preposition valences together). His results indicated higher correlation when valence specification is used, suggesting not only that there is a significant difference in semantics between transitive and intransitive usages of a given preposition, but that it is sufficiently marked in the context of use that distributional methods are able to pick up on it.
 of up in VPCs based on cognitive grammar, and classified token instances based on a combination of linguistic and word co-occurrence features.
 unification to perform target language disambiguation over his classification of spatial prepositions.
 named entities. 3.4 The Semantics of Prepositional MWEs Prepositional MWEs X  X ocusing primarily on the English MWE types of VPCs, PVs, PP X 
Ds, and compound nominals X  X opulate the spectrum from fully compositional to fully non-compositional (Dixon 1982; McCarthy, Keller, and Carroll 2003). For instance, put up (as in putthepictureup ) is fully compositional, whereas makeout (as in KimandSandy made out ) is fully non-compositional. Compositionality can be viewed relative to each component word (Bannard 2005) or holistically for the MWE as a single unit (McCarthy,
Keller, and Carroll 2003). With play out (as in see how the match playsout ), for example, we might claim that play is non-compositional but out is (semi-)compositional, and that as a whole the VPC is non-compositional. The question of compositionality is confused 132 somewhat by productive constructions such as the resultative up (e.g., eat/beat/finish/... up ) and the manner by (e.g., by train/car/broomstick/... ), which have specialized semantics relative to their simplex usages but occur relatively freely with this semantics within a given construction (VPC and PP X  X , respectively, in our examples).
 nard (2005, 2006) considered VPC compositionality at the component word level, and proposed a distributional approach that assumes there is a positive correlation between compositionality and the distributional similarity of each component to simplex usages of that same word. McCarthy, Keller, and Carroll (2003) opted for a holistic notion of compositionality and used a range of approaches based on the distributional  X  X he-saurus X  of Lin (1998) to model compositionality, for example, in calculating the overlap in the top-N similar words for a given VPC and its head verb. They also examined the use of statistical tests such as mutual information in modeling compositionality, and found the similarity-based methods to correlate more highly with the human judgments. Baldwin et al. (2003) used LSA to analyze the compositionality of VPCs (and compound nouns), and once again demonstrated that there is a positive correlation between compositionality and the distributional similarity between a given VPC and its head word. Kim and Baldwin (2007) predicted the compositionality of VPCs based on a combination of the McCarthy, Keller, and Carroll (2003) and Bannard (2006) data sets, and analysis of verb X  X article co-occurrence patterns. Taking a different approach to the task, Patrick and Fletcher (2005) classified token instances of verb X  X reposition pairs according to the three classes of decomposable (syntactic dependence between the P and V, with compositional semantics), non-decomposable (syntactic dependence between the P and V, with idiomatic semantics), and independent (no syntactic dependence between the P and V).
 nouns, through the notion of compatibility with paraphrases incorporating preposi-tions. For example, baby chair can be paraphrased as chair for (a) baby , indicating com-patibility with the FOR class. In her original research, Levi used four prepositions, in combination with a set of verbs (for relative clause paraphrases) and semantic roles (for nominalizations). Lauer (1995) extended this research in developing an exclusively preposition-based set of seven semantic classes. For example, Levi would interpret truck driver as PATIENT , in the sense that truck is the patient of the underlying verb of the head noun to drive , whereas Lauer would interpret it as OF (c.f., driver of (the) truck ). Girju (2007, 2009) leveraged translation data to improve the accuracy of compound noun interpretation, based on the observation that the choice of preposition in Ro-mance languages is often indicative of the semantics of the compound noun. Con-versely, Johnston and Busa (1996) used Qualia structure from the Generative Lexicon (Pustejovsky 1995) to interpret the prepositions in Italian complex nominals, such as macchina da corsa  X  X ace car X . Jensen and Nilsson (2003) used (Danish) prepositions as the basis of a finite set of role relations with which to describe the meaning content of nominals, and demonstrated the utility of the resultant ontology in disambiguating nominal phrases. 4. Applications Prepositions have tended to be overlooked in NLP applications, but there have been isolated examples of prepositions being shown to be worthy of dedicated treatment. In particular, applications requiring some level of syntactic abstraction tend to benefit from the inclusion of prepositions. Similarly, applications which incorporate an element of natural language generation or realization need to preserve prepositions in the interests of producing well-formed outputs.
 fication, and demonstrated that dependency tuples incorporating prepositions are a more effective document representation than simple words. In a direct challenge to the prevalent  X  X top word X  perception of prepositions in information retrieval, Hansen (2005) and Lassen (2006) placed emphasis on not only prepositions but preposi-tion semantics in a music retrieval system and ontology-based text search system, respectively.
 sially crucial to system accuracy, in terms of the role they play in named entities (Cucchiarelli and Velardi 2001; Toral 2005; Kozareva 2006) and in IE patterns, in linking the elements in a text (Appelt et al. 1993; Muslea 1999; Ono et al. 2001; Leroy and Chen 2002).
 system. In the context of cross-language question answering (CLQA), Hartrumpf,
Helbig, and Osswald (2006) used MultiNet to interpret the semantics of German prepositions, and demonstrated that in instances where the answer passage contained a different preposition to that included in the original question, preposition semantics boosted the performance of their CLQA system.
 method in a paraphrase recognition task, namely, predicting that Kimcoveredthebabyin blankets and Kimcoveredthebabywith blankets have essentially the same semantics. They proposed seven general senses of prepositions (e.g., P ARTICIPANT ,I NSTRUMENT ,and
Q UALITY ), and annotated prepositions occurring in 120 sentences for each of 10 prepo-sitions. They evaluated a WSD method over this data, and sketched how the preposition sense information could then be used for paraphrase recognition.
 cations which require explicit representation of 3D space, such as robotics, animated agents, and virtual reality, in the context of interpreting the spatial information of prepositions. For example, Xu and Badler (2000) developed a geometric definition of the motion trajectories of prepositions, whereas Tokunaga, Koyama, and Saito (2005) use potential functions to estimate the spatial extent of Japanese spatial nouns (which combine with postpositions to have a similar syntactic and semantic profile to Eng-lish spatial prepositions). Kelleher and van Genabith (2003) proposed a method for interpreting in front of and behind in a virtual reality environment based on different frames of reference. Hying (2007) carried out an analysis of preposition semantics in the HRCR Map Task corpus, and used it to evaluate two models of projective prepositions. Kelleher and Kruijff (2005) developed a model for grounding spatial expressions in visual perception and also for modeling proximity, and Reichelt and
Verleih (2005) developed the B3D system for generating a computational representation of prepositions in geospatial applications. Furlan, Baldwin, and Klippel (2007) used preposition occurrence in Web data as a means of classifying landmarks for use in route directions. Finally, Kelleher and Costello (2009) proposed computational models of topological and projective spatial prepositions for use in a visually situated dialogue system.
 received a moderate amount of attention, particularly in the context of interlingua-and transfer-based MT. Dorr and Voss (1993) mapped prepositions onto 5-place spatial 134 predicates in the context of interlingua-based MT, building on the work of Talmy (1985) and Jackendoff (1983, 1990). N  X  ubel (1996) developed a set of interlingual predicates for adjunct PPs in English  X  German MT, incorporating a dialogue component which can be used to disambiguate prepositions relative to the discourse context. Bond, Ogura, and Uchino (1997) developed a dedicated type hierarchy for the generation of preposi-tions associated with temporal expressions in Japanese  X  English machine translation. Kumar Naskar and Bandyopadhyay (2006) proposed a transfer-based method for trans-lating English prepositions into Bengali postpositions/inflectional markers, focusing on spatial, temporal, and also idiomatic usages. Bond (1998) proposed an algorithm for translating Japanese spatial nouns into English prepositions based on semantic fields. Trujillo (1995) used his classification of spatial prepositions as the basis of an English  X  Spanish translation system using bilingual lexical rules. Haji  X  c et al. (2002) proposed a method for inserting prepositions into tectogrammatical representations in Czech  X  English MT, although they did not manage to integrate the predictions into their final MT system. Husain, Sharma, and Reddy (2007) achieved promising results using an explicit model of preposition semantics as the basis for preposition selection in Hindi/Telugu  X  English machine translation.
 tified that case marker (= postposition) generation poses a significant challenge for stan-dard phrase-based methods in English  X  Japanese translation, identifying case marker errors in 16% of outputs. They proposed an n -best reranking method to improve case marker generation performance, whereby they expand the n -best list to include extra case marker variations, and perform case marker prediction for each bunsetsu . 7 In eval-uation, they demonstrated that their proposed method significantly outperforms both the baseline SMT system (Quirk, Menezes, and Cherry 2005) and a comparable n -best reranking method without dedicated case marker candidate expansion. The significance of this research is that it demonstrates that dedicated handling of postpositions can enhance SMT performance, a result which has promise for adpositions and markers in other languages.
 master, and are a frequent source of errors in English as a Second Language (ESL) prose. Errors can take the form of incorrect preposition selection (e.g., *Kim stayed in home ), erroneous preposition insertion (e.g., *Kim played at outside ), or erroneous preposition omission (e.g., *Kim went  X  the conference ) (Tetreault and Chodorow 2008b). Tetreault and Chodorow (2008b) proposed a combined detection/correction method based on a supervised model. For each preposition in a text, they predict the most likely candidate from 34 candidates, based on local word context. If the most likely candidate differs from the original preposition selection, an error is predicted and correction proposed. In evaluation over ESL texts, they found that their method performs at high precision but low recall. Separately, they found that the same method performs considerably better when applied to preposition selection over native English text, and also that it is important to have multiple annotators correct ESL text in order to avoid skewing the data (Tetreault and Chodorow 2008a). In other research, Gamon et al. (2008) performed preposition selection in terms of both selection and insertion, but over a smaller set of prepositions. De Felice and Pulman (2007) similarly proposed a method for preposition correction, but only evaluated their model over five prepositions and native
English text. 5. Introduction to the Articles in This Special Issue
For this special issue we invited submissions that brought a theoretical basis to research on prepositions in lexical resources and NLP tasks. The number of submissions re-ceived reflects the interest in prepositions at this time, with a total of 16 submissions.
On the basis of a rigorous review process, we selected four articles for inclusion in the special issue, covering: the use of semantic resources to disambiguate preposition semantics, for use in lexical acquisition (O X  X ara and Wiebe 2009); a crosslingual lexical semantic analysis of prepositions to interpret nominal compounds (Girju 2009); a formal semantic analysis of preposition semantics, and its possible application in Norwegian X 
English machine translation (J X rgensen and L X nning 2009); and a computational model for preposition semantics for use in a dialogue system (Kelleher and Costello 2009). We now outline each of these articles.
 to be highly polysemous and have a number of closely related senses.
 in lexical acquisition, in semi-automatically extending lexical resources. They investi-gate the utility of information learned from resources such as the Penn Treebank and
FrameNet, to perform semantic role disambiguation of PPs. The proposed methodology is evaluated in a series of experiments, and different sense granularities are contrasted in task-based evaluation.
 usage in a given language (hence the difficulty of non-native speakers in learning to use prepositions correctly). However, there are instances of cross-linguistic regularities in their linguistic realizations. For example, when translating English nominal compounds of the type Noun Preposition Noun (N P N) and Noun Noun (N N) into Romance languages, these are often translated into N P N compounds, where the choice of prepo-sition is (semi-)predictable from the semantics of the compound. Girju investigates the role of the syntactic and semantic properties of prepositions in English and Romance languages in the automatic semantic interpretation of English nominal compounds.
On the basis of an extensive corpus analysis of the distribution of semantic relations in nominal compounds in English and five Romance languages, she attempts to dis-ambiguate the semantic relations in English nominal compounds. She focuses on non-equative compositional nominal compounds, and empirically tests the contribution of prepositions to the task of semantic interpretation, using a supervised, knowledge-intensive model.
 equivalent constructions) could potentially impact on a number of NLP applications. In machine translation, for example, a formal description of the crosslinguistic semantic properties of prepositions could provide the basis for an interlingua. This is the topic of the third article in this special issue: J X rgensen and L X nning propose a unification-based grammar implementation of a formal semantic analysis of preposition semantics, and demonstrate its application in Norwegian  X  English MT.
 tant in dialogue systems, as prepositions are often used to refer to entities in the physical environment of system interaction. The last article in this special issue addresses this 136 topic: Kelleher and Costello present computational models of spatial preposition semantics for use in visually situated dialogue systems. The proposed models of topological and projective spatial prepositions can be used for both interpretation and generation of prepositional expressions in complex visual environments containing multiple objects, and are able to account for the contextual effect which other distractor objects can have on the region described by a preposition. The evaluation is done in terms of psycholinguistic tests evaluating the approach to distractor interference on prepositional semantics. The models are employed in a human X  X obot dialogue system to interpret locative expressions containing a topological preposition and to generate spatial references in visually situated contexts. 6. Discussion and Conclusion As we hope to have demonstrated in this introduction, prepositions have led a mixed existence in computational linguistics and related fields, particularly in the context of applications. In applications requiring spatial interpretation (e.g., situated dialogue systems), they have been the focus of dedicated research, and in applications which incorporate a language generation component such as MT, there have been isolated instances exemplifying the need for dedicated handling of prepositions/case markers. In general, however, they tend to have been relegated to the sidelines in applied NLP research.
 tions in a particular language, often as a one-off research task which has failed to make broader impact in the field of computational linguistics. PP attachment X  X specially in English X  X as been an exception, in the sense that the RRR data set has given rise to an active strand of research centered around prepositions. We hope that variants of the RRR data set from Atterer and Sch  X  utze (2007) and Agirre, Baldwin, and Martinez (2008) will reinvigorate interest in PP attachment, in a situated parsing context. Similarly, the emer-gence of resources such as the Preposition Project, and the data set made available for the SemEval 2007 task on the word sense disambiguation of prepositions (Litkowski and Hargraves 2007), provide the means for more detailed analysis of preposition semantics. In addition to standalone word sense disambiguation tasks, however, there needs to be more research on the interaction of preposition semantics with other semantic tasks, such as semantic role labeling and the word sense disambiguation of content words. The increasing availability of large-scale parallel corpora paves the way for crosslinguistic research on preposition syntax. Areas of particular promise in this regard are methods for generating prepositions in MT, and automatic error correction of preposition usage in non-native speaker text. Following the lead of Saint-Dizier (2006b), J X rgensen and L X nning (2009), and others, we also hope to see more crosslinguistic and typological research on the lexical semantics of prepositions. Although there has been a steady proliferation of WordNets for different languages, linked variously to English WordNet (e.g., EuroWordNet for several European languages [Vossen 1998], BALKANET for Balkan languages [Stamou et al. 2002], HowNet for Chinese [Dong and Dong 2006], and Japanese WordNet for Japanese [Isahara et al. 2008]), they have tended to follow the lead of English WordNet and focus exclusively on content words. Given the increasing maturity of resources such as the Preposition Project and PrepNet, the time seems right to develop preposition sense inventories for more languages, linked back to English. On the basis of currently available resources and future efforts such as these, we believe there will be a steady lowering of the barrier to including a more systematic handling of prepositions in NLP applications. search that has been done on prepositions in computational linguistics, focusing on computational syntax and semantics. In particular, we have aimed to highlight applied research which has focused specifically on prepositions. It is our hope that through this special issue, we will rekindle interest in prepositions and motivate greater awareness of prepositions in various applications.
 Acknowledgments References 138 140 142 144 146 148
