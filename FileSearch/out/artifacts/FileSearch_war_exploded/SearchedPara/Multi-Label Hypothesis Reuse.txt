 Multi-label learning arises in many real-world tasks where an object is naturally associated with multiple concepts. It is well-accepted that, in order to achieve a good performance, the relationship among labels should be exploited. Most existing approaches require the label relationship as prior knowledge, or exploit by counting the label co-occurrence. In this paper, we propose the MAHR approach, which is able to automatically discover and exploit label relationship. Our basic idea is that, if two labels are related, the hypothesis generated for one label can be helpful for the other label. MAHR implements the idea as a boosting approach with a hypothesis reuse mechanism. In each boosting round, the base learner for a label is generated by not only learning on its own task but also reusing the hypotheses from other labels, and the amount of reuse across labels provides an es-timate of the label relationship. Extensive experimental re-sults validate that MAHR is able to achieve superior perfor-mance and discover reasonable label relationship. Moreover, we disclose that the label relationship is usually asymmetric. I.2.6 [ Artificial Intelligence ]: Learning; H.2.8 [ Database Management ]: Database Applications X  Data mining ; I.5.2 [ Pattern Recognition ]: Design Methodology X  classifier design and evaluation Algorithm, Experimentation Multi-label learning, label relationship, hypothesis reuse
This research was supported by the 973 Program (2010CB327903), NSFC (61073097, 60975043), JiangsuSF (BK2011566) and Baidu fund.
In traditional supervised classification, one instance is as-sociated with one target concept, whereas in many real-world applications, one instance is naturally associated with multiple concepts. For example, in scene classifications (e.g., [1]) a natural scene picture can be annotated as sky , trees , mountains , lakes and water simultaneously; in text cate-gorizations (e.g., [25]) a piece of news on global warming issue can be categorized as global warming , environment , economics and politics .
 Multi-label learning tries to address such kind of tasks. The most straightforward solution to multi-label learning is to decompose the task into a series of binary classification problems, each for one label [1]; however, such a solution ne-glects the relationship among labels, whereas previous stud-ies [8, 16] have revealed that the label relationship is quite helpful and should be considered. Later on, most multi-label learning approaches try to exploit label relationship explicitly. Some approaches [4, 12, 19, 5] rely on external knowledge resources, such as knowledge on label hierarchies from which the label relationship is derived; label relation-ship obtained in this way is generally helpful, however, label hierarchies are often unavailable in real applications. Some other approaches [10, 24] try to exploit label relationship by counting the co-occurrence of labels in training data; al-though such approaches can be effective in some cases, there are high risks of overfitting the training data.

In this paper, we propose a novel multi-label learning approach named MAHR (Multi-lAbel Hypothesis Reuse), which is able to discover and exploit label relationship au-tomatically in the learning process. Our basic idea is that, if two labels are related, the hypothesis generated for one label can be helpful for the other. MAHR implements the idea as a boosting approach with a hypothesis reuse mech-anism. It trains multiple boosted learners simultaneously, each for one label. In each boosting round, in addition to generating a base learner for each label from its own hypoth-esis space, MAHR tries to reuse the hypotheses generated for other labels. The reuse process takes into account all trained hypotheses from all other labels via weighted com-bination, and helpful hypotheses are identified and reused with large weights through minimizing the loss on the con-cerned label. The reuse score , which is calculated from the weights of cross-label hypothesis reuse throughout the boost-ing process, provides an estimate of label relationship.
Extensive experiments show that the MAHR approach is superior or highly competitive to state-of-the-art multi-label learning approaches. In addition to the superior predictive performance, as a prominent advantage, MAHR is able to discover reasonable label relationship. Moreover, it is worth mentioning that our study disclose that the label relation-ship is usually asymmetric, quite different from symmetric label relationship assumed in many previous studies.
The rest of the paper is organized as follows. Section 2 introduces related work, Section 3 presents MAHR, Section 4 reports on experiments, and Section 5 concludes.
During the past few years, many multi-label approaches have been developed [17], such as the decomposition-based approaches [1], ranking-based approaches [3], common sub-space approaches [14], generative approaches [16, 25], etc.
Some approaches assume that the label relationship can be provided by external knowledge resources as prior knowl-edge. For example, label hierarchies are required by [4, 19, 5], and a label similarity matrix is required as an input in [12]. In most real-world tasks, however, prior knowledge of label relationship is often unavailable.

Some approaches try to model the label relationship di-rectly. For example, Ghamrawi and McCallum [10] tried to model the impact of an individual feature on the co-occurrence probability of label pairs. Sun et al. [23] used a hypergraph to model the correlation information of labels. Zhang and Zhang [28] used Bayesian network structure to encode the conditional dependencies of both the labels and feature sets. Usually, the label relationship is estimated by considering the co-occurrence or some kinds of equivalence of the labels, and is easy to overfitting the training data.
Tsoumakas et al. [24] proposed the 2BR approach and utilized label relationship to prune stacked single-label clas-sifiers. The label relationship can be measured based on co-occurrence, or their proposed  X  -coefficient. The  X  -coefficient for two labels L i and L j is defined as  X  ( i, j )=( AD  X  ( A + B )( C + D )( A + C )( B + D ), where A , B , C and D are the frequency counts of L i  X  L j , L i  X  X  L j ,  X  L i  X 
L i  X  X  L j , respectively. We will employ the 2BR approach as a test bed to compare the effectiveness of the reuse score generated by our MAHR approach with that of the label co-occurrence and the  X  -coefficient.

Boosting is a family of learning algorithms with sound theoretical foundation and wide applications. In [20], two boosting approaches for multi-label learning, AdaBoost.MH and AdaBoost.MR, were proposed. They both train additive models to directly optimize multi-label losses, i.e., hamming loss for AdaBoost.MH and ranking loss for AdaBoost.MR. AdtBoost.MH [6], an extension of AdaBoost.MH, is able to produce a set of comprehensible rules through employing al-ternating decision trees. MSSBoost [27] maintains a shared pool of base classifiers to reduce the redundancy among la-bels, where each base classifier is trained in a random sub-space and with a random sample; in each round, it selects the best classifier from the pool and takes it as the base classifier for all the labels.

A common idea of these boosting approaches lies in the fact that, in each learning round, one base classifier is gen-erated for all the labels (while only the output threshold may be adjusted for each label). Such a process may suffer from some deficiencies. First, in many cases, especially when there are lots of labels, it is quite difficult to generate a base classifier that can deal well with all the labels simultane-ously. Second, it is rare that all labels are strongly related [13], and thus it is not very reasonable to try to generate one base classifier for all labels. In contrast, our MAHR approach generates one base classifier for each label in each round, and does not assume that all labels are strongly re-lated. Moreover, MAHR does not require label relationship as input, and instead, it will produce estimate of the label relationship as output.
We denote by D = { ( x 1 ,Y 1 ) , ( x 2 ,Y 2 ) ,  X  X  X  , ( x multi-label data set of m instances and L possible labels, where x i is the i -th instance and the corresponding Y i label vector of dimension L , Y i ( l )=1ifthe l -th label is a proper label of x i ,and  X  1 otherwise.
MAHR, as shown in Algorithm 1, maintains the general outline of boosting. MAHR generates base hypotheses in an iterative manner (the loop from line 3 to line 12). In the round t , it generates a base hypothesis for each label (the loop from line 4 to line 11). For the l -th label, it firstly trains a hypothesis  X  h t,l from its own hypothesis space (line 5), and then invokes a reuse function R (line 6) to generate another hypothesis h t,l from both  X  h t,l and the reuse of the hypotheses in the candidate set Q t,l .Afterthat, h t,l is treated as the base hypothesis for label l in round t ,andthe edge of its training error (i.e., 0.5 minus the training error) and the combination weight are calculated (line 7). The training set is then updated for the next round (line 8). Note that the candidate set for reuse in round t +1onlabel l is defined as Q t +1 ,l = { H t,k | k = l } X  X  X  H t,k | k = l } (line 10), where H t,k is the combined hypothesis for label k up to round t (line 9). Here,  X  H t,k is included in Q t +1 ,l for simplicity of optimization.

The reuse function R is utilized to combine multiple hy-potheses, and it can be implemented in different ways. In this paper, we implement R via weighted linear combination. Such a simple implementation leads to decent performance in experiments, and a better implementation of R may even improve the performance. Formally, given a hypothesis pool Q t,l and a newly generated hypothesis  X  h t,l at the t -th round on the l -th label, we define a parameterized reuse function R where  X  t,l is a vector of reuse weights to be determined and  X  t,l ( H ) denotes the element of  X  t,l corresponding to H .Dif-ferent strategies can be employed to solve the parameter  X  , aiming to minimize different multi-label losses (e.g., ham-ming loss and ranking loss).

For hamming loss, which concerns about how each pre-dicted label is consistent with the ground-truth label addi-tively,  X  t,l can be obtained by: Algorithm 1 The MAHR algorithm 1: Input: Training set D = { ( x i ,Y i ) } m i =1 ,baselearning 2: D 1 ,l ( i )= 1 m ,Q 1 ,l =  X  ( i =1 ,  X  X  X  ,m, l =1 ,  X  X  X  3: for t =1 to T do 4: for l =1 to L do 6: h t,l  X  R (  X  h t,l ,Q t,l ) such that h t,l (  X  )  X  [ 11: end for 12: end for 13: Output: H l ( x )= T t =1  X  t,l h t,l ( x )( l =1 ,  X  X  X  For ranking loss, which concerns about whether the relevant labels are ordered before irrelevant ones, we can obtain  X  with the following optimization problem, which enforces the combined hypothesis to order the label pairs correctly: s.t. ( Y i ( l )  X  Y i ( j ))( R  X  t,l ( x i )  X  H t  X  1 ,j In this paper, we focus on hamming loss, and implement MAHR according to Eq. 2.

We then look into the combination weight and the distri-bution update rule shown in line 7 and line 8, respectively. To optimize the hamming loss, we can equivalently optimize the zero-one loss on each label. The zero-one loss, however, is hard to optimize directly, and thus we try to optimize the logistic loss for each label instead: which is a surrogate loss function for zero-one loss. By differ-entiating the logistic loss function, the combination weight and the update rule can be derived, as similarly done in Fil-terBoost [2]. One can use other surrogate loss functions such as the exponential loss. Also, as similar as FilterBoost, the distribution of MAHR in line 8 is a probability distribution, and thus normalization is not needed.

Note that the MAHR approach trains L models each for one label, these models may or may not have common base hypotheses, depending on the learning task. In contrast, other multi-label boosting approaches, such as MSSBoost, AdaBoost.MH and AdaBoost.MR, use the same base hy-pothesis for all the labels. This is a significant difference between MAHR and other approaches. The constraint that all labels share the same base hypothesis might be overly restrictive, and it may even injure the learning performance when some of the labels are not closely related.

For a test instance, we follow the training order and calcu-late the predictions of base hypotheses round-by-round until the final prediction is obtained. In such a way, the output of any hypothesis needs to be calculated only once, and there is no extra computational cost in the test phase comparing with multiple single-label boosting.
Since MAHR reuses hypotheses across labels, the amount of reuse can be considered as a measure of label relationship. If two labels are independent, the hypothesis for one label may have a large error on the other label, and thus the reuse function for the other label will assign a very small weight to that hypothesis; if two labels are strongly related, the hypothesis for one label may have a small error on the other label, and thus the reuse function will assign a large weight to incorporate the hypothesis. Therefore, we assess the label relationship by the reuse weight, i.e., the  X  in Eq. 1. We define the reuse score from label j to i as
S ( i, j )= T where  X  t,i (  X  )isweightedby  X  t,i (the weight of h t,i ). Here, t starts from 2 because there is no hypothesis for reuse in the first round. Note that  X  t,i (  X  ) is constrained to be positive in the optimization, and  X  t,i (  X  H  X  ,j ), the weight of the negation of H  X  ,j , actually reflects the degree of label j being negatively reused by label i , and therefore, we do subtraction in Eq. 4.
The reuse score S ( i, j ) assesses how much label j can help the learning of label i . It is worth noting that, unlike the commonly used relationship, such as co-occurrence and  X  -coefficient, the reuse score is not constrained to be symmet-ric, i.e., S ( i, j ) does not necessarily equal S ( j, i ).
Suppose the multi-label learning task has L underlying hy-potheses ( f 1 ,  X  X  X  ,f L ), each corresponds to one label. Given the training set and a hypothesis space H , an algorithm tries to find a set of hypotheses, each approximating one of the underlying hypothesis. We concern about the training ham-and the generalization hamming loss err hl = E ( x ,Y ) [ I ( sign ( H l ( x )) = Y ( l ))], where I (  X  ) denotes the indicator function.

Lemma 1. [2] Let  X  =min t |  X  t | ,where  X  t is the edge of h , and let be the target error. If the number of boosting rounds T&gt; 2 ln (2) // (1  X  2 1 / 4  X   X  2 ) ,then err t some t, 1  X  t  X  T . Particularly it is true for T&gt; ln (2)
With Lemma 1, we get Theorem 1 which guarantees the convergence rate of MAHR on the training set.

Theorem 1. Let  X  =min t,l |  X  t,l | , for any &gt; 0 , MAHR achieves the hamming loss err hl &lt; on the training set within the number of rounds T&gt; 0 . 5ln2  X   X  1  X   X   X  2 .
Proof. When MAHR achieves the zero-one loss on every label, it also achieves hamming loss because the hamming loss is the average of the zero-one loss over all labels. Therefore, we focus on the number of rounds for MAHR to achieve zero-onelossonalabel;itisatmost 0 . 5ln2  X   X  1  X   X   X  2 according to Lemma 1.

Theorem 1 shows that MAHR efficiently achieves a train-ing hamming loss. Then, based on Lemma 2, we get Theo-rem 2 for the generalization ability of MAHR.
Lemma 2. [9] Let H be a class of binary functions of VC-dimension d  X  2 . Then the VC-dimension of  X  T ( H ) is at most 2( d +1)( T +1)log 2 ( e ( T +1)) (where e isthebaseofthe natural logarithm). Therefore, if the hypotheses generated by weak learner are chosen from a class of VC-dimension d  X  2 , then the final hypotheses after T iterations belong to a class of VC-dimension at most 2( d +1)( T +1)log 2 [ e ( T +1)] .
Theorem 2. Let  X  =min t,l |  X  t,l | and d be the VC-dimension of the hypothesis space H . For any &gt; 0 ,withprobability  X  the generalization hamming loss of MAHR is bounded by
Proof. The generalization inequality is directly adapted from the Theorem 6.7 in [26]. The capacity D of the learning system depends on the complexity of the base hypothesis space and the number of hypotheses combined. The VC-dimension d of H and the total number of hypotheses T  X  L results in the capacity 2( d +1)( 0 . 5ln2  X   X  2 +1)log 2 according to Lemma 2. Moreover, the reuse of the other L  X  labels through linear combination results in the capacity L . Therefore, quantity of D in Theorem 2 is derived. Note that Theorems 1 and 2 are derived for a general case. We then analyze how the hypothesis reuse can be helpful. We characterize the ground-truth label relationship between two labels l 1 and l 2 by their output correlation Then we have the generalization bound in Theorem 3, which shows that the hypothesis reuse in MAHR can utilize the la-bel relationship to reduce the capacity of the learning system and thus leads to a better generalization ability.
Theorem 3. Let  X  =min t,l |  X  t,l | , d be the VC-dimension of the hypothesis space H ,  X   X  =min l 1 ,l 2  X  ( l 1 ,l the minimum weight and the maximum training error among all the cross-label hypotheses, respectively. For any &gt; 0 , with probability  X  the generalization hamming loss of MAHR is bounded by
Proof. Suppose we have obtained the hypothesis h l for the l -th label ( l =2 ,  X  X  X  ,L ) such that where h l ( x i )  X  X  +1 ,  X  1 } .Thus,wehave Then, we want to learn the first label up to the error 1 . According to the reuse function, the hypothesis for the first dition should be satisfied: 1 m By the constraint of Eq. 2, it holds that w 1  X  h 1 + L l =2 [  X  1 , 1], and thus we can get a stronger requirement to guar-antee the error:  X   X  1 where the last derivation is obtained by applying Eqs. 5 and 6 together. Here, A  X  B means that A can be guaranteed if B holds. The last inequality implies that we only need to learn the hypothesis  X  h 1 to approximate f 1 up to the error than 1 when  X  (1 ,l ) is large and l is small. Incorporating the error into Theorem 2, we get Theorem 3.
 Theorem 3 suggests that the hypothesis reuse mechanism works when the labels are not independent and the num-ber of rounds in MAHR is large, such that we have fit some labels well enough for reuse. Correspondingly, the number of rounds for achieving the error on one label is from the proof of Theorem 3 we can find that with the re-lated and well-learned hypotheses on other labels, the learn-ing of the base hypothesis becomes easier. Note that if labels are independent, Theorem 3 is as same as Theorem 2.
MAHR requires more computational cost than other boost-ing approaches such as AdaBoost.MH, because in each round of boosting, the optimization of Eq. 2 needs to be addressed for each label. Fortunately, the optimization is a linear pro-gramming problem, and thus it can be solved efficiently. MAHR may train more base classifiers than other boost-ing approaches, however, this can be compensated in a par-allel computing system. Unlike other boosting approaches that are relatively hard to be parallelized, in each round of MAHR, the line 5 to line 10 of Algorithm 1 can be executed for each label in parallel, because there is no interaction among labels in one round. Thus, the total execution time of the default implementation of MAHR can be close to that of AdaBoost.MH.

Moreover, since MAHR employs logistic loss, it can uti-lize the filtering mechanism of FilterBoost [2] to deal with large-scale data efficiently. We can have a filtering version of the MAHR algorithm: given the data set for training and evaluating the base hypothesis, it uses a Filter function to collect a set of training instances according to the number of training instances m , the target training error  X  (0 , 1), the confidence  X   X  (0 , 1) upper-bounding the probability of failure, and the error in edge estimation  X   X  (0 , 1).
We introduce the experimental settings in Section 4.1 ,and then compare MAHR with state-of-the-art multi-label learn-ing approaches in Section 4.2 .InSection 4.3 , we study the label relationship discovered by MAHR. We also study the influence of the number of boosting rounds in Section 4.4 , and the computational cost in Section 4.5 .
To examine the effectiveness of hypothesis reuse, we com-pare MAHR with a degenerated version MAHR-id, which is as same as MAHR except that it does not reuse hy-pothesis (i.e., it does not invoke the reuse function) and learns every label independently. We also compare MAHR with state-of-the-art multi-label learning approaches that are divided into two groups: the boosting group including AdaBoost.MH [20], AdaBoost.MR [20], AdtBoost.MH [6] and MSSBoost [27], and the non-boosting group includ-ing ML-k NN [29] which considers the first-order correlation, RankSVM [8] which considers the second-order correlation, and ECC [18] which considers higher-order correlation. For the compared approaches, the best parameters reported in their corresponding literatures [20, 6, 27, 29, 8, 18] are used. For MAHR, the base learning algorithm is decision stump implemented in Weka [11], the number of rounds, i.e., the parameter T in Algorithm 1 is set as default to 2  X  # feature for all the data sets. Note that the influence of the number of learning rounds will be studied in Section 4.4.
There are different criteria for evaluating the performances of multi-label learning. In our experiments, we employ five commonly used criteria, i.e., hamming loss , one error , cov-erage , ranking loss and average precision . The definition of these criteria can be found in [21, 7, 30].

Seventeen data sets are used in our experiments. These data sets spanned a broad range of applications: Image [29], Image2 [30] and Scene [1] for image classification, Reuters [22] for text categorization, Yeast [8] for gene function pre-diction, Enron [15] for email analysis, and Yahoo [25] for web page categorization. Note that Yahoo consists of 11 indepen-dent data sets, i.e., Arts , Business , Computers , Education , Entertainment , Health , Recreation , Reference , Science , So-cial and Society .For Yahoo , the data sets are pre-separated into training and test sets [25]; for the other data sets, we randomly select 1,500 instances for training and use the re-maining data for testing. The data partition is repeated randomly for thirty times, and the average results as well as standard deviations over the thirty repetitions are recorded.
The comparison results are shown in Table 1. Due to page limit, for Yahoo we only report the average results over the eleven data sets. Note that we are mostly interested in hamming loss because the current implementation of MAHR is designed for this loss.

Comparing with MAHR-id, MAHR achieves significantly better performance over all the five criteria on all the data sets. This validates the usefulness of the hypothesis reuse mechanism on exploiting label relationship.

Comparing with other approaches, MAHR achieves the best performance on hamming loss in most cases; particu-larly, it outperforms AdaBoost.MH and AdtBoost.MH that were also designed for optimizing hamming loss. For the other four criteria, MAHR also achieves excellent perfor-mances although it was not implemented to optimize these criteria. It is superior to the compared approaches on both one error and average precision in most cases. On coverage, it performs better than ECC, comparable with other ap-proaches, worse than only AdaBoost.MH. On ranking loss, it outperforms ECC and achieves comparable performances with other approaches.

Overall, by exploiting label relationship with the hypoth-esis reuse mechanism, MAHR drastically improves the per-formance of its non-reuse counterpart MAHR-id over all cri-teria. Comparing with other approaches, MAHR is the best approach for optimizing hamming loss, and is highly com-petitive over the other criteria. These observations suggest that label relationship does help multi-label learning, and the hypothesis reuse mechanism is useful. Note that, cur-rently we just implement R in a simple form of linear com-bination, and it is expected that better performance can be obtained with better designs of reuse functions. Also, one can incorporate different multi-label learning mechanisms or optimize different objectives in Eq. 2 when other evaluation criteria rather than hamming loss are concerned.
To examine whether the reuse score reflects reasonable label relationship, since we were not given with ground-truth label relationship for real-world data, we first study three synthetic data sets, for which we know the ground-truth label relationship. All the three data sets have five labels, L 1 to L 5 , and the 5-th label is assigned to an instance if it has none of L 1 to L 4 .In data-inde , the first four labels are independent to each other, each label is associated with five different features, and a label is assigned to an instance if the summed value of the corresponding five features is larger than a specified threshold. In data-equal , L 1 = L L 3 = L 4 .In data-union , the labels L 2 to L 4 are independent to each other, and L 1 is assigned to an instance if it has at least one of L 2 to L 4 , i.e., L 1 = L 2  X  L 3  X  L 4 . We generate 10,000 instances, and randomly divide them into two parts of equal size, using one part for training and the other for testing. The experiments are repeated for 10 times, each with a random partition of the data set, and the average reuse scores are recorded in Tables 2 to 4 for the three data sets, respectively. Note that the values are normalized such that each label has a reuse score 1 for itself.
 It is obvious that all the diagonal entries of the tables are Table 2: Reuse score on data-inde ( L 1 to L 4 are in-dependent) Table 3: Reuse score on data-equal ( L 1 = L 2 , L 3 = L 4 Table 4: Reuse score on data-union ( L 1 = L 2  X  L 3  X  L 4 larger than the other entries, implying that each boosted learner mainly relies on its own task. It can be found that in the last row of all three tables, when learning L 5 ,ittakes the other labels as negative references. This is in our ex-pectation because L 5 is assigned to an instance when no other label is assigned. Excluding the diagonal entries, in Table 2, the entries in the first four rows of the first four columns are close to zero, indicating that L 1 to L 4 are not helpful to each other; this is consistent with the ground-truth that these labels are independent. In Table 3 the entries S ( L 1 ,L 2 ) ,S ( L 2 ,L 1 ) ,S ( L 3 ,L 4 )and S ( L relatively large positive values, and in Table 4 the entries ues; these results are consistent with the ground-truth label relationship. Particularly, in Table 4 the sum of S ( L 1 S ( L 1 ,L 3 )and S ( L 1 ,L 4 ) exceeds the entry S ( L 1 ing the great impact of labels L 2 to L 4 on L 1 .
As shown in Tables 2 to 4, unlike co-occurrence or  X  -coefficient, the reuse score is asymmetric. In data-union , since we set L 1 to appear if any of L 2 , L 3 and L 4 appears, L 2 to L 4 are helpful for determining L 1 ; however, the inverse is not true. Table 4 shows that the reuse scores clearly re-flect this asymmetric relationship. In real-world tasks, label relationship is usually asymmetric, for example, the label  X  X ake X  implies the label  X  X ater X , but the inverse may not be true. Therefore, asymmetric relationship is more consistent with realistic situations.

We also examine the reuse scores on two real data sets, i.e., Image and Enron . Image contains five labels: desert , mountains , sea , sunset and trees .Figure1showssomeex-ample images, each column for one label. The reuse scores are shown in Table 5. Again, all the entries at the diagonal are large positive values. An interesting observation is that most elements are negative, suggesting that the mutually Desert Mountains Sea Sunset Trees
Target label desert mount. sea sunset trees desert 1.00 -0.08 -0.05 -0.11 -0.03 mountains -0.06 1.00 -0.10 -0.07 -0.06 sea -0.16 -0.10 1.00 0.01 -0.14 sunset -0.04 -0.07 -0.00 1.00 -0.06 trees -0.02 0.06 -0.09 -0.11 1.00 exclusive relationship among labels is important when deal-ing with multi-label image classification tasks, and is worth paying more attention. Besides the diagonal entries, there are two positive entries. The entry S ( trees , mountains )is relatively large, which can be understand by the fact that when there are mountains in an image, trees are likely to ap-pear, as can be recognized from Figure 1. On the contrary, the entry S ( mountains , trees ) is negative, because trees do not imply mountains , which again shows asymmetric prop-erty of label relationship. Similarly, the entry S ( sea , sunset ) is positive, which may be understand by the fact that the sunset photos are often taken at sea ; meanwhile, sea does not imply sunset , as can be recognized from Figure 1. It is noticed that strong negative entries imply relationship as well. For example, when desert occurs in an image, it is unlikely to find sea in the image; this explains the strong negative entry S ( sea , desert ).

Enron is a collection of email messages written by the em-ployees of Enron. Different from the results on Image data, there are more positive reuse scores than negative ones in Enron , and the absolute values of the negative scores are relatively small. So, we focus on the positive relationship. Since there are too many labels, we only show the results on a part of example labels. Table 6 presents the three most positively related labels for each example label. It can be seen that the discovered relationship is reasonable. For ex-ample, an email about company business , newsletters and secrecy is usually sent to alliance members or partners ;the emotion pride is likely to come through an email about ju-bilation , contributions and admiration ; etc. It is also worth noting that MAHR discovers high-order relationship among labels; for example, with different accompanying labels, the label talking points can be positively related with admiration as well as sadness, despair .

While the results on the two real data sets provide an in-tuitive evaluation of the reuse score, we can further have a quantitative evaluation. The 2BR approach [24] trains mul-Table 6: Top 3 positively related labels for some example labels in Enron data set Figure 2: Comparison of three kinds of label rela-tionships with the 2BR approach tiple classifiers, each for one label, and then prunes some classifiers and uses the remaining ones for a second-level stacking classifier. The pruning is based on the label rela-tionship. Therefore, we can incorporate different label rela-tionships into 2BR, and then evaluating the performances. Here, three kinds of relationships are compared, i.e., the reuse score returned by MAHR, the co-occurrence relation-ship, and the  X  -coefficient relationship which is used in [24]. As in [24], we report the results on Yeast and Enron which have many labels for pruning. Decision tree implemented in Weka is used for the base-level and the stacking classifiers. Figure 2 shows the hamming loss with varied number of stacked classifiers. According to [24], the number of stacked classifiers increases from 3 to 12 for Yeast and from 3 to 19 for Enron .

First, we observe that pruning based on any of the three relationships improves the performance of stacking all the classifiers (corresponding to the dashed line in Figure 2). Comparing with the baselines, MAHR lead to the best per-Figure 3: Hamming loss of MAHR, MAHR-id and AdaBoost.MH under varying number of base hy-potheses formance, particularly when the number of stacked classi-fiers is not too small. This observation further validates the advantage of MAHR on exploiting label relationship.
An important parameter of boosting algorithms is the number of learning rounds, or in other words, the number of base hypotheses. According to the analysis in [9], to achieve a good performance, the classifier should have low train-ing error and a small number of base hypotheses, whereas a large number of base hypotheses will make the classifier overly complex and may lead to overfitting.

Considering that MAHR and MAHR-id train L (label size) times more hypotheses than the other boosting ap-proaches in each round, to be fair, we compare their perfor-mances with the same number of hypotheses. We evaluated three boosting approaches, i.e., MAHR, MAHR-id and Ad-aBoost.MH, all optimizing hamming loss, up to involving 3,000 base hypotheses for Image , Scene , Reuters and Yeast , and 10,000 base hypotheses for Yahoo and Enron . The ham-ming loss curves are plotted in Figure 3. (figure for Image2 is similar with that of Image , and thus is not presented due to page limit).

As shown in Figure 3, MAHR significantly improves the performance of MAHR-id with various number of boost-ing rounds. Contrasting with AdaBoost.MH, MAHR can achieve a better performance after sufficient boosting rounds. Moreover, while MAHR-id and AdaBoost.MH seem suffer-ing from overfitting after a number of rounds, MAHR keeps on improving performance in most cases. We attribute this phenomenon to the fact that MAHR considers high-order relationship among labels, as illustrated in the previous sub-section, and thus it can tolerant more complex models. Table 7: Average CPU time (in seconds) of boosting-style approaches We study the time cost of multi-label boosting approaches. All the experiments are performed with MATLAB 7.6 on a machine with 8  X  2 . 60 GHz CPUs and 16GB main memory. The average time cost of each round on one label for MAHR-id and MAHR are 0.73 and 0.91 seconds, respectively, con-firming that the hypothesis reuse procedure is efficient. The average CPU time (in seconds) of each boosting approach on each data set is shown in Table 7. It can be seen that AdtBoost.MH is relatively time consuming, and MSSBoost costs more time on some data sets because it employs SVM as base classifier. Benefitting from parallel computing, al-though MAHR performs more boosting rounds, its compu-tational cost is comparable with other boosting approaches.
In this paper, we propose a novel multi-label learning ap-proach, MAHR, which does not require the input of label relationship but it is able to discover reasonable label rela-tionship automatically, in addition to achieving a high pre-dictive performance. The key of MAHR is a hypothesis reuse mechanism which offers an effective way to discover and ex-ploit label relationship. This mechanism is implemented as a boosting style approach, where multiple boosted learners are trained, each for one label; each learner not only looks into its own single-label task, but also reuses the trained hypotheses from other labels.

Experiments validate that MAHR is superior or highly competitive to state-of-the-art multi-label approaches, and it drastically improves the performance of MAHR-id, which learns single-label tasks independently. Moreover, experi-ments show that MAHR discovers reasonable and useful la-bel relationship, and suffers little from overfitting even with a large number of base hypotheses. It is worth noting that our study disclose that the label relationship is usually asym-metric, quite different from symmetric label relationship as-sumed by previous studies.

It is not difficult to develop variant algorithms of MAHR to optimize other multi-label losses, such as the ranking loss, and it is also possible to reuse hypotheses in forms other than weighted combination in the future. [1] M. R. Boutell, J. Luo, X. Shen, and C. M. Brown. [2] J. K. Bradley and R. E. Schapire. Filterboost: [3] K. Brinker and E. H  X  ullermeier. Case-based multilabel [4] L. Cai and T. Hofmann. Hierarchical document [5] N. Cesa-Bianchi, C. Gentile, and L. Zaniboni. [6] F. D. Comit  X  e, R. Gilleron, and M. Tommasi. Learning [7] A. de Carvalho and A. Freitas. A tutorial on [8] A. Elisseeff and J. Weston. A kernel method for [9] Y. Freund and R. Schapire. A decision-theoretic [10] N. Ghamrawi and A. Mccallum. Collective multilabel [11] M. Hall, E. Frank, G. Holmes, B. Pfahringer, [12] B. Hariharan, L. Zelnik-Manor, S. V. N.
 [13] S.-J. Huang and Z.-H. Zhou. Multi-label learning by [14] S. Ji, L. Tang, S. Yu, and J. Ye. Extracting shared [15] B. Klimt and Y. Yang. Introducing the enron corpus. [16] A. McCallum. Multi-label text classification with a [17] J. Petterson and T. Caetano. Submodular multi-label [18] J. Read, B. Pfahringer, G. Holmes, and E. Frank. [19] J. Rousu, C. Saunders, S. Szedmak, and [20] R. E. Schapire and Y. Singer. Improved boosting [21] R. E. Schapire and Y. Singer. BoosTexter: A [22] F. Sebastiani. Machine learning in automated text [23] L. Sun, S. Ji, and J. Ye. Hypergraph spectral learning [24] G. Tsoumakas, A. Dimou, E. Spyromitros, and [25] N. Ueda and K. Saito. Parametric mixture models for [26] V. N. Vapnik. Estimation of Dependences Based on [27] R. Yan, J. Te X  si  X  c,andJ.R.Smith.Model-shared [28] M.-L. Zhang and K. Zhang. Multi-label learning by [29] M.-L. Zhang and Z.-H. Zhou. ML-kNN: A lazy [30] Z.-H. Zhou, M.-L. Zhang, S.-J. Huang, and Y.-F. Li.
