 The rapid growth of Internet and modern technologies has brought data involving objects of multiple types that are related to each other, called as multi-type relational data . Traditional clustering methods for single-type data rarely work well on them, which calls for more advanced clustering techniques to deal with multiple types of data simultaneously to utilize their interrelatedness. A major challenge in developing simultaneous clustering methods is how to effectively use all available information contained in a multi-type relational data set including inter-type and intra-type relationships. In this paper, we propose a Symmetric Nonnegative Matrix Tri-Factorization (S-NMTF) framework to cluster multi-type relational data at the same time. The proposed S-NMTF approach employs NMTF to simultaneously cluster different types of data using their inter-type relationships, and incorporate the intra-type information through manifold regularization. In order to deal with the symmet-ric usage of the factor matrix in S-NMTF, we present a new generic matrix inequality to derive the solution algorithm, which involves a fourth-order matrix polynomial, in a principled way. Promising experimental results have validated the proposed approach. H.3.3 [ Information Storage And Retrieval ]: Information Search and Retrieval X  Clustering ; I.2.6 [ Artificial Intelligence ]: Learn-ing Algorithms, Experimentation, Performance Clustering, Multi-Type Relational Data, Web, Nonnegative Matrix Tri-Factorization
Clustering aims to partition a set of objects into groups or clus-ters such that objects in a same cluster are similar while those in different clusters are dissimilar. Most traditional clustering algo-rithms concentrate on dealing with homogeneous data, in which all the objects are of one single type. Recently, the rapid progress of Internet and computational technologies have brought data much richer in structure, involving objects of multiple types that are re-lated to each other. For example, in a Web search system in Fig-ure 1, we have four different types of data objects including words, Web pages, search queries and Web users. Each of the four types of entities have their own attributes. Meanwhile different types of data are also interrelated to each other by various means, e.g ., Web pages and words are related via co-occurrences. Due to their high hetero-geneity and close interrelationships, these data are called as multi-type relational data [10]. The information contained in a multi-type relational data set typically appears in two forms as follows: Inter-type relationships appear exclusively in multi-type relational data, while intra-type information, due to its homogeneity, appears in both multi-type relational data and traditional single-type data.
The rich structures of multi-type relational data provide a poten-tial opportunity to improve the clustering accuracy, which, how-ever, also present a new challenge on how to take advantage of all available information. In this paper, we tackle this new, yet impor-tant, problem to simultaneously cluster multiple types of relational data. Our goal is to make full use of the both forms of information of a multi-type relational data set.
Because each type of a multi-type relational data set can be viewed as homogeneous data, one may argue that clustering heterogeneous data can be solved using traditional methods to cluster each type of objects independently. However, this may not work well.
First, various data types in a multi-type relational data set are interrelated to each other. Clustering each data type independently will lose these interaction information, such as that conveyed by internet hyper-links or co-occurrences, which are essential to gain a full understanding of the Web data.

Second, in practice the clustering of a data type may not be the one based on the intra-type relationships ( i.e ., the similarity of fea-objects in a same data type. tures) but the one based on the inter-type relationships between this data type and others. For example, in the Web search system in Figure 1, instead of the similarity between Web pages themselves, people are often interested in the relationships between user groups and Web page styles.

Last, but not least, heterogeneous data contain different types of objects. Processing and interpreting them in one single way may not be appropriate and presents a major challenge. Ad hoc integra-tion or normalization ( e.g ., concatenating different features into a vector of fixed length) rarely works.

As a result, recent research has advanced swiftly from simple clustering of one type of data to simultaneous clustering of multi-ple types of data, for both two data types (pairwise co-clustering) [3, 6, 7, 16] and multiple (more than two) data types (high-order co-clustering) [10, 12, 15]. Through simultaneous clustering, one can discover the hidden global structures in the heterogeneous data, which seamlessly integrates multiple data types to provide a better picture of the underlying data distribution.
Given the inter-type relationships and the intra-type information, we present a Symmetric Nonnegative Matrix Tri-Factorization (S-NMTF) framework for simultaneous clustering of multi-type rela-tional data. In our new approach, we use NMTF to simultaneously cluster different types of data upon their inter-type relationship ma-trices. Meanwhile, users are allowed to provide optional intra-type information for different types of data in form of pairwise affinity, which is incorporated as manifold regularization to NMTF. Promis-ing empirical results in extensive experiments validate the proposed method. We summarize our contributions as following. 1. We present a simple, yet effective, framework to tackle the complicated problem of simultaneous clustering of multi-type rela-tional data, which aims to fully exploit all available information. 2. Existing NMF algorithms usually deal with asymmetric (rect-angle data-feature) matrix factorization [4, 6, 12 X 14] and optimize one factor matrix at a time, which only involve second-order matrix polynomials. When dealing with symmetric matrix factorization, a fourth-order matrix polynomial is involved, which is much harder to be dealt with and heuristics are usually used in existing works. In this paper, as an important theoretical contribution, we present a new generic matrix inequality (in Lemma 4), such that the difficulty is tackled in a principled way.
In this section, we first briefly review NMTF based co-clustering of two-type relational data, from which we gradually develop the proposed S-NMTF approach for simultaneous clustering of multi-type relational data. Our approach employs both inter-type rela-tionships as well as intra-type information.
We first formalize the problem of simultaneous clustering of multi-type relational data.

We denote a K -type relational data set as X = {X 1 , X 2 where X k = x k 1 , x k 2 , . . . , x k n k -th type. Suppose that we are given a set of relationship matrices objects, and we have R kl = R T lk . Our goal is to simultaneously partition the data objects in X 1 , X 2 , . . . , X K into c disjoint clusters respectively.

Most existing simultaneous clustering algorithms only rely on inter-type relationships, i.e ., R ij . However, in practice we may also have intra-type information for each type of data. For the k -th type of data, for example, we usually have pairwise affinities W we aim to make full use of both inter-type relationships R Section 2.3) and intra-type information W k (in Section 2.4).
Throughout this paper, we denote A ( ij ) as the entry at the i -th row and j -th column of a matrix A .
The close connection between Nonnegative Matrix Factorization (NMF) and clustering [4] provides the potential theory to develop co-clustering methods. Ding et al . proposed to use NMTF [6] to si-multaneously cluster the rows and columns of an input nonnegative relationship matrix R 12 by decomposing it into three nonnegative factor matrices, which minimizes the following objective:
J 1 = k R 12  X  G 1 S 12 G T 2 k 2 , s.t. G 1  X  0 , G 2  X  0 , S where kk denotes the Frobenius norm of a matrix, G 1  X  X  X  n and G 2  X   X  n 2  X  c 2 + are the cluster indicator matrices for X X 2 respectively, and S 12  X   X  c 1  X  c 2 + absorbs the different scales of R 12 , G 1 and G 2 . Note that, the original NMF problem [9] requires R 12 to be nonnegative. In co-clustering scenarios, this constraint (thereby the nonnegativity constraint on S 12 ), however, can be re-laxed [5], which leads to the semi-NMTF problem to minimize: Simultaneous clustering on X 1 and X 2 is then achieved by solving Eq. (2). Because the rows of the resulted G k ( k  X  X  1 , 2 } ) (with normalization) can be interpreted as the posterior probability for clustering on X k [4,6], the cluster label of x k i is obtained by
A natural generalization of the co-clustering objective in Eq. (2) to simultaneous clustering of multi-type relational data is to solve the following optimization problem [10,12]:
However, it is not straightforward to solve Eq. (4) by general-izing existing iterative multiplicative NMTF solution algorithms. Motivated by [3] that deals with bipartite graphs, we propose to solve the optimization problem in Eq. (4) by solving an equivalent Symmetric NMTF problem.
 We first introduce the following useful lemma.

L EMMA 1. T he optimization problem in Eq. (2) can be equiva-lently solved by the following S-NMTF problem: in which
R =
G = where the superscripts denote the matrix sizes, and R 21 = R S
P ROOF . Following the definitions of R , G a nd S , we can derive k R  X  GSG T k 2 = which proves the lemma.
 Based upon Lemma 1, we have the following theorem.

T HEOREM 1. I t is equivalent to solve Eq. (4) and to solve in which The proof of Theorem 1 can be easily obtained by generalizing the proof of Lemma 1 to multi-type relational data.

Theorem 1 presents a general framework via S-NMTF to simul-taneously cluster multi-type relational data using the mutual rela-tionship matrices. However, the symmetric usage of the factor ma-trix G in NMTF leads to a fourth-order matrix polynomial when deriving the iterative algorithm, which is harder to be dealt with compared to the second-order matrix polynomials involved in stan-dard (asymmetric) NMTF. In Section 3, we will introduce a new matrix inequality in Lemma 4 to solve this problem.
The optimization objectives in Eq. (2) and Eq. (7) only involve the inter-type relationships of a multi-type relational data set, whereas the intra-type information, though often available, are not used. We incorporate them through Laplacian regularization [2,7].
For a two-type relational data set, given the intra-type informa-tion in form of the pairwise affinity matrices W 1 and W 2 X 2 respectively, we can incorporate them into Eq. (2) as following: J = k R 12  X  G 1 S 12 G T 2 k 2 + 2  X  h tr G T 1 L 1 G 1 + tr G where D k is the diagonal degree matrix with D k ( ii ) = P and L k = D k  X  W k is the corresponding graph Laplacian. Because L k is the discrete approximation of the Laplace-Beltrami operator on the underlying data manifold [1], the last two terms reflects the label smoothness of the two types of data points. The smoother the data labels are with respect to the underlying data manifolds, the smaller their values will be.
 Using R , S and G defined in Eq. (8), and denote we approach simultaneous clustering on multi-type relational data by solving the following optimization problem: min J S-NMTF = k R  X  GSG T k 2 + 2  X  tr h G T ( D  X  W ) G where D is the diagonal degree matrix with D ( ii ) = P j call Eq. (11) as our proposed S-NMTF approach. As can be seen, the complicated problem of simultaneous clustering of multi-type relational data is finally modeled by a very simple mathematical formulation, which is the first contribution of this work.
The computational algorithm for the proposed S-NMTF approach is listed in Algorithm 1. Upon solution, the final cluster labels are obtained from the resulted G k using Eq. (3).

The main challenge to derive Algorithm 1 is the fourth-order ma-trix polynomial incurred by the symmetric usage of G in Eq. (11). Existing works [4, 6, 12] tackle this difficulty in an intuitive way: solve the problem as a standard NMF problem with two different factor matrices and set them as same in the solution. In this work, as a theoretical contribution, we present a new matrix inequality in Lemma 4 to tackle this difficulty in a principled way. Algorithm 1: Algorithm to solve S-NMTF in Eq. (11) The following theorem guarantees the correctness of Algorithm 1.
T HEOREM 2. I f the updating rules of G and S in Algorithm 1 converges, the final solution satisfies the KKT optimal condition.
P ROOF . For the objective in Eq. (11), following the standard t heory of constrained optimization, we introduce the Lagrangian multipliers 4 X  and minimize the Lagrangian function as follows: which gives  X  X   X  X   X  X   X  X  Fixing G , letting  X  X / X  X  = 0 , from Eq. (14) we obtain
The KKT complementary condition for the nonnegativity of G gives G ij  X  ij = 0 . Setting  X  X / X  X  = 0 , from Eq. (13) we have:  X  4 RGS + 4 GSG T GS  X  4  X W G + 4 DG This is the fixed point relationships that the solution must satisfy.
At convergence, G (  X  ) = G ( t +1) = G ( t ) , thus we can derive which is identical to Eq. (16) and proves Theorem 2.
Now, we analyze the convergence of Algorithm 1 using the aux-iliary function approach [9].

L EMMA 2. [ 9] Z ( h, h  X  ) is an auxiliary function of F ( h ) if the conditions Z ( h, h  X  )  X  F ( h ) and Z ( h, h  X  ) = F ( h ) are satisfied. [9] If Z is an auxiliary function for F , then F is non-increasing under the update h ( t +1) = arg min h Z ( h, h  X  ) .

L EMMA 3. [ 6] For any matrices A  X   X  n  X  n + , B  X   X  k  X  k S  X   X  n  X  k + and S  X   X   X  n  X  k + , and A and B are symmetric, the following inequality holds:
As one of our contribution, we prove the following generic ma-trix inequality to analyze objective functions involving 4 -th order matrix polynomials, such as that our S-NMTF objective in Eq. (11).
L EMMA 4. F or any nonnegative symmetric matrices A  X  X  X  and B  X  X  X  k  X  k + , for H  X  X  X  n  X  k + the following inequality holds: P ROOF . Let H i k = H  X  ik u ik . The 1st term in RHS of Eq. (18) is X Now, switching indexes: i  X  j, p  X  q, r  X  k , we obtain X The 2nd term in RHS of Eq. (18) is X Now, switching indexes: i  X  j, p  X  q, r  X  k , we obtain X
A careful examination of the RHS of the above four equations shows that they are identical except u 4 terms. Thus, the RHS of Eq. (18) is For any a, b, c, d &gt; 0 , we have a 4 + b 4 + c 4 + d 4 c d 2 )  X  4( ab )( cd ) , thus u ik u jr u jq u ip  X  u 4 ik which proves Lemma 4.
 Based upon the above lemmas, we prove the following theorem. T HEOREM 3. L et then the following function
Z G, G  X  =  X  2 X is an auxiliary function of J S-NMTF ( G ) . Furthermore, it is a convex function in G and its global minimum is
P ROOF . By applying Lemma 4, we have Because of Lemma 3 and the inequality of 2 ab &lt; a 2 + b tr  X  G T DG  X  X
Because z  X  1 + log z,  X  z &gt; 0 , we have
Summing over all these bounds, we get Z ( G, G  X  ) , which clearly satisfies (1) Z ( G, G  X  )  X  J S-NMTF ( G ) and (2) Z ( G, G ) = J Therefore, Z ( G, G  X  ) is an auxiliary function of J S-NMTF
Following the same derivations as in [5 X 7,12,13], it can be ver-ified that the Hessian matrix of Z ( G, G  X  ) is a positive definite di-agonal matrix (we skip the derivations due to space limit). Thus Z ( G, G  X  ) is a convex function of G . We can obtain the global min-imum of Z ( G, G  X  ) by setting  X  X  ( G, G  X  ) / X  X  ij = 0 and solving for G , from which we can get Eq. (21). This completes the proof of Theorem 3.

T HEOREM 4. U pdating G using the rule in Algorithm 1 mono-tonically decreases J S-NMTF ( G ) in Eq. (20) .
 P ROOF . According to Lemma 2 and Theorem 3, we can get that J Thus J S-NMTF ( G ) is monotonically decreasing.
 Because of Eqs. (14 X 15), in each iteration step of Algorithm 1 S Theorem 3 and 4, guarantees the convergence of Algorithm 1, be-cause J ( G ) in Eq. (11) is obviously lower bounded by 0.
In this section, we experimentally evaluate the proposed S-NMTF approach. Our new method has only one parameter  X  in Eq. (11). Empirically, we set it as  X  = 0 . 01 .
We first evaluate the proposed method on two-type relational data, the simplest multi-type relational data. We use the following three data sets: Newsgroup4 data set, WebKB4 data set, WebACE data set, whose details can be found in [7].
For co-clustering of two-type relational data, we need two in-puts from a data set: the relationship matrix between the two types of data, and the pairwise affinity matrices for each type of data. We obtain the relationship matrices directly from the testing data sets. We construct neighborhood graphs from the both sides of the relationship matrix following [7] to obtain the pairwise affinity ma-trices for the both types of the entities, where, following [7], the neighborhood size is set as 10.

We compare the proposed S-NMTF approach against two related clustering methods that combine NMF and Laplacian regulariza-tion: graph regularized NMF (GNMF) [2] method and dual regu-larized co-clustering (DRCC) [7] method. These two methods are Methods Newsgroup4 WebKB4 WebACE GNMF 0.889 0.731 0.513 DRCC 0.931 0.738 0.568 PMF 0.923 0.727 0.566 CKMeans 0.643 0.594 0.477 S-NMTF 0.937 0.783 0.613 Table 2: Normalized mutual information in co-clustering tasks. Methods Newsgroup4 WebKB4 WebACE GNMF 0.716 0.462 0.618 DRCC 0.782 0.491 0.629 PMF 0.758 0.488 0.602 CKMeans 0.612 0.375 0.491
S-NMTF 0.795 0.554 0.643 largely same, except that the former uses two-factor factorization and imposes Laplacian regularization on one side factor, while the latter uses the three-factor factorization and imposes Laplacian reg-ularizations on the both side factors. Following [7], two graphs are built on both feature side and data point side for DRCC method, and its parameters are set as  X  =  X  which is same as in [7].
In addition, we also compare our approach against the following two methods: penalized matrix factorization (PMF) [12] method and constrained K -means (CKmeans) [11] method.

To evaluate the clustering results, we adopt two standard mea-sures widely used for clustering [2]: clustering accuracy and nor-malized mutual information (NMI).
The clustering performance measured by clustering accuracy and normalized mutual information of the compared methods on the three data sets are listed in Table 1 and Table 2. The results show that the proposed S-NMTF approach consistently outperforms the other methods, sometimes very significantly, which demonstrate the effectiveness of the proposed S-NMTF approach in co-clustering of two-type relational data.
Finally we evaluate the proposed S-NMTF approach for simul-taneous clustering on multi-type relational data by using both inter-type relationships and intra-type information, which is the ultimate goal of this work.
For the data set and experimental settings in this subsection, we largely follow those in [12] (We acknowledge the author of [12] for sharing the data).

We use a data set sampled from the Bulletin Board Systems (BBS) in [8]. In a BBS system, the users first register IDs. Us-ing their IDs, the users can read others X  published messages and leave their own messages. The whole system consists of many dis-cussion fields, each of which contains many boards with similar themes. The boards are named to reflect the contents of the arti-cles in them [8]. Once an ID posts a new article (initial article) on one board, the others can show their opinions by replying the ini-tial article using reply articles. The initial article and reply articles Table 3: A subset of data sampled from a BBS data set [8]. Table 4: The F1 measure of the four compared algorithms. constitute a topic. Each board contains many topics. Each topic connects with several IDs through articles.

We use a subset of the BBS data in [8], in which several boards are sampled from several discussion fields. In each board, 80 topics are sampled randomly. The names of the fields and boards that we use are listed in Table 3. The user IDs related to these topics and boards are found out. Then the tensor is constructed by the co-occurrence of these three data types.
In the experiments, there exist three data types: topics ( X IDs ( X 2 ) and boards ( X 3 ). The topic-user matrix ( R structed with the number of articles each user posted in each topics with TF-IDF normalization. The topic-board matrix ( R 13 ) is con-structed such that if a topic belongs to a board, then the correspond-ing entry of R 13 is 1. R 23 is constructed such that if the user had posted any articles on that board, then the corresponding element of R 23 is set to 1. Finally the elements of R 23 are also normalized using TF-IDF scheme.

We only use the pairwise affinity matrices W 1 and W 2 for X and X 2 , which are constructed using R 12 in a same way as in Sec-tion 4.1. We set W 3 = I to simulate the case in real applications when the intra-type information for X 3 is not available.
Besides our approach, the results of applying the Spectral Rela-tional Clustering (SRC) [10] method and Multiple Latent Semantic Analysis (MLSA) [15] method, and PMF method are also included for comparison. All these three methods are for simultaneous clus-tering on multi-type relational data.

The evaluation metric is the F1 score computed using the clus-tering results on topics, the ground truth of which is set to be the classes corresponding to the field names they belong to.
The experimental results are shown in Table 4, in which the value of d represent different number of clusters. From the table we can clearly see the superiority of the proposed S-NMTF approach. Be-sides, we also see that PMF method is always better than the other two methods. By examining the implementation details, we can see that these results are consistent with the information used by these methods: MLSA and SRC methods only use the inter-type relationships, while our S-NMTF approach additionally utilizes the intra-type information. In this paper, we presented a general Symmetric Nonnegative Matrix Tri-Factorization (S-NMTF) framework to simultaneously cluster multi-type relational data. Our approach clusters differ-ent types of data at the same time using inter-type relationships by transforming the original problem into a symmetric NMF prob-lem, into which we can optionally incorporate the intra-type infor-mation. In order to deal with the symmetric usage of the factor matrix in S-NMTF, we presented a new generic matrix inequality to derive the solution algorithm, which involves a fourth-order ma-trix polynomial, in a principled way. Extensive empirical studies in evaluating various aspects of our approach have demonstrated encouraging results, which validate the usefulness of the proposed S-NMTF approach.
 This research was supported by NSF-IIS 1117965, NSFCCF-0830780, NSF-DMS-0915228, NSF-CCF-0917274. [1] M. Belkin, P. Niyogi, and V. Sindhwani. On manifold [2] D. Cai, X. He, J. Han, and T. S. Huang. Graph regularized [3] I. Dhillon. Co-clustering documents and words using [4] C. Ding, X. He, and H. Simon. On the equivalence of [5] C. Ding, T. Li, and M. Jordan. Convex and semi-nonnegative [6] C. Ding, T. Li, W. Peng, and H. Park. Orthogonal [7] Q. Gu and J. Zhou. Co-clustering on manifolds. In SIGKDD , [8] Z. Kou and C. Zhang. Reply networks on a bulletin board [9] D. Lee and H. Seung. Algorithms for non-negative matrix [10] B. Long, Z. Zhang, X. Wu, and Y. P. Spectral clustering for [11] K. Wagstaff, C. Cardie, S. Rogers, and S. Schr X dl. [12] F. Wang, T. Li, and C. Zhang. Semi-supervised clustering via [13] H. Wang, H. Huang, F. Nie, and C. Ding. Cross-language [14] H. Wang, F. Nie, H. Huang, and C. Ding. Dyadic transfer [15] X. Wang, J. Sun, Z. Chen, and C. Zhai. Latent semantic [16] H. Zha, X. He, C. Ding, H. Simon, and M. Gu. Bipartite
