 We seek to integrate knowledge from multiple information sources. Traditional ensemble methods such as bagging, boosting and model averaging are known to have improved accuracy and robustness over a single model. Their potential, however, is limited in applications which have no access to raw data but to the meta-level model output. For example, due to privacy, companies or agencies may not be willing to share their raw data but their final models. So information fusion needs to be conducted at the decision level. Furthermore, different data sources may have different formats, for example, web video classification based on image, audio and text features. In these scenarios, we have to combine incompatible information sources at the coarser level (predicted class labels) rather than learn the joint model from raw data.
 In this paper, we consider the general problem of combining output of multiple supervised and unsu-pervised models to improve prediction accuracy. Although unsupervised models, such as clustering, do not directly generate label predictions, they provide useful constraints for the classification task. The rationale is that objects that are in the same cluster should be more likely to receive the same class label than the ones in different clusters. Furthermore, incorporating the unsupervised clustering models into classification ensembles improves the base model diversity, and thus has the potential of improving prediction accuracy. Suppose we have a set of data points X = { x 1 , x 2 , . . . , x n } from c classes. There are m models that provide information about the classification of X , where the first r of them are (supervised) classifiers, and the remaining are (unsupervised) clustering algorithms. Consider an example where X = { x 1 , . . . , x 7 } , c = 3 and m = 4 . The output of the four models are: where M 1 and M 2 assign each object a class label, whereas M 3 and M 4 simply partition the objects into three clusters and assign each object a cluster ID. Each model, no matter it is supervised or unsupervised, partitions X into groups, and objects in the same group share either the same predicted class label or the same cluster ID. We summarize the data, models and the corresponding output by a bipartite graph. In the graph, nodes at the left denote the groups output by the m models with some labeled ones from the supervised models, nodes at the right denote the n objects, and a group and an object are connected if the object is assigned to the group by one of the models. For the aforementioned toy example, we show the groups obtained from a classifier M 1 and a clustering model M 3 in Figure 1, as well as the group-object bipartite graph in Figure 2.
 The objective is to predict the class label of x i  X  X , which agrees with the base classifiers X  pre-dictions, and meanwhile, satisfies the constraints enforced by the clustering models, as much as possible. To reach maximum consensus among all the models, we define an optimization problem over the bipartite graph whose objective function penalizes deviations from the base classifiers X  pre-dictions, and discrepancies of predicted class labels among nearby nodes. In the toy example, the consensus label predictions for X should be { 1 , 1 , 1 , 2 , 2 , 3 , 2 } .
 Related Work. We summarize various learning problems in Figure 3, where one dimension repre-sents the goal  X  from unsupervised to supervised, and the other dimension represents the method  X  single models, ensembles at the raw data, or ensembles at the output level. Our proposed method is a semi-supervised ensemble working at the output level, where little work has been done. Many efforts have been devoted to develop single-model learning algorithms, such as Support Vector Machines and logistic regression for classification, K-means and spectral clustering for clustering. Recent studies reveal that unsupervised information can also be utilized to improve the accuracy of supervised learning, which leads to semi-supervised [29, 8] and transductive learning [21]. Although our proposed algorithm works in a transductive setting, existing semi-supervised and transductive learning methods cannot be easily applied to our problem setting and we discuss this in more de-tail at the end of Section 2. Note that all methods listed in Figure 3 are for single task learning. On the contrary, multi-task learning [6, 9] deals with multiple tasks simultaneously by exploiting dependence among tasks, which has a different problem setting and thus is not discussed here. In Figure 3, we divide ensemble methods into two categories depending on whether they require access to raw data. In unsupervised learning, many clustering ensemble methods [12, 17, 25, 26] have been developed to find a consensus clustering from multiple partitionings without accessing the features. In supervised learning, however, only majority voting type algorithms work on the model output level, and most well-known classification ensemble approaches [2, 11, 19] (eg. bagging, boosting, bayesian model averaging) involve training diversified classifiers from raw data. Methods top of the model output, however, they still need the labels of the raw data as feedbacks, so we position them as an intermediate between raw data ensemble and output ensemble. In multi-view learning [4, 13], a joint model is learnt from both labeled and unlabeled data from multiple sources. Therefore, it can be regarded as a semi-supervised ensemble requiring access to the raw data. Summary. The proposed consensus maximization problem is a challenging problem that cannot be solved by simple majority voting. To achieve maximum agreement among various models, we must seek a global optimal prediction for the target objects. In Section 2, we formally define the graph-based consensus maximization problem and propose an iterative algorithm to solve it. The proposed solution propagates labeled information among neighboring nodes until stabilization. We to incorporate feedbacks obtained from a few labeled target objects into the framework in Section 4. An extensive experimental study is carried out in Section 5, where the benefits of the proposed approach are illustrated on 20 Newsgroup, Cora research papers, and DBLP publication data sets. Suppose we have the output of r classification algorithms and ( m  X  r ) clustering algorithms on a data set X . For the sake of simplicity, we assume that each point is assigned to only one class or cluster in each of the m algorithms, and the number of clusters in each clustering algorithm is c , same as the number of classes. Note that cluster ID z may not be related to class z . So each base algorithm partitions X into c groups and there are totally v = mc groups, where the first s = rc groups are generated by classifiers and the remaining v  X  s groups are from clustering algorithms. Before proceeding further, we introduce some notations that will be used in the following discussion: B n  X  m denotes an n  X  m matrix with b ij representing the ( ij ) -th entry, and of row i and column j , respectively. See Table 1 for a summary of important symbols.
 We represent the objects and groups in a bipartite graph as shown in Figure 2, where the object nodes x this graph summarizes the output of m algorithms on X : We aim at estimating the conditional probability of each object node x i belonging to c classes. As a nuisance parameter, the conditional probabilities at each group node g j are also estimated. These conditional probabilities are denoted by U n  X  c for object nodes and Q v  X  c for group nodes: Since the first s = rc groups are obtained from supervised learning models, they have some initial class label estimates denoted by Y v  X  c where Let k j = problem on the graph: where || . || and | . | denote a vector X  X  L2 and L1 norm respectively. The first term ensures that if an object x i is assigned to group g j by one of the algorithm, their conditional probability estimates must be close. When j = 1 , . . . , s , the group node g j is from a classifier, so k j = 1 and the second term puts the constraints that a group g j  X  X  consensus class label estimate should not deviate much from its initial class label prediction.  X  is the shadow price payment for violating the constraints. When j = s + 1 , . . . , v , g j is a group from an unsupervised model with no such constraints, and therefore each component must be greater than or equal to 0 and the sum equals to 1.
 We propose to solve this problem using block coordinate descent methods as shown in Algorithm 1. At the t -th iteration, if we fix the value of U , the objective function is a summation of v quadratic components with respect to ~q j  X  . The corresponding Hessian matrix is diagonal with entries equal to Algorithm 1 BGCM algorithm P global minimum of the cost function with respect to ~q j  X  in Eq. (2). Similarly, fixing Q , the unique global minimum with respect to ~u i  X  is also obtained.
The update formula in matrix forms are given in Algorithm 1. D v = diag D n = diag cates the existence of constraints on the group nodes. During each iteration, the probability estimate at each group node (i.e., Q ) receives the information from its neighboring object nodes while retains its initial value Y , and in return the updated probability estimates at group nodes propagate the in-formation back to its neighboring object nodes when updating U . It is straightforward to prove that In [14], we proposed a heuristic method to combine heterogeneous information sources. In this pa-per, we bring up the concept of consensus maximization and solve the problem over a bipartite graph representation. Our proposed method is related to graph-based semi-supervised learning (SSL). But existing SSL algorithms only take one supervised source (i.e., the labeled objects) and one unsu-pervised source (i.e., the similarity graph) [29, 8], and thus cannot be applied to combine multiple models. Some SSL methods [16] can incorporate results from an external classifier into the graph, but obviously they cannot handle multiple classifiers and multiple unsupervised sources. To apply SSL algorithms on our problem, we must first fuse all supervised models into one by some ensem-ble approach, and fuse all unsupervised models into one by defining a similarity function. Such a compression may lead to information loss, whereas the proposed method retains all the information and thus consensus can be reached among all the based model output. In this part, we explain the proposed method from two independent perspectives.
 Constrained Embedding. Now we focus on the  X  X ard X  consensus solution, i.e., each point is assigned to exactly one class. So U and Q are indicator matrices: u iz = 1 if the ensemble assigns x i to class z , and 0 otherwise; similar for q jz  X  X . For group nodes from classification algorithms, we will treat their entries in Q as known since they have been assigned a class label by one of the classifiers, that is, q jz = y jz for 1  X  j  X  s .
 Because U represents the consensus, we should let group g j correspond to class z if majority of the objects in group g j correspond to class z in the consensus solution. The optimization is thus: s.t. Here, the two indicator matrices U and Q can be viewed as embedding x 1 , . . . , x n (object nodes) ~q objects group g j contains, ~q j  X  can be regarded as the group representative in this new space, and thus it should be close to the group mean: algorithms, we know their  X  X deal X  embedding, as represented in the constraints in Eq. (5). We now relate this problem to the optimization framework discussed in Section 2. a ij can only take value of 0 or 1, and thus Eq. (3) just depends on the cases when a ij = 1 . When a ij = 1 , no matter q jz is 1 or 0, we have | q jz Suppose the groups found by the base models have balanced size, i.e., constant for  X  j . Then the objective function can be approximated as: Therefore, when the classification and clustering algorithms generate balanced groups, with the same set of constraints in Eq. (4) and Eq. (5), the constrained embedding problem in Eq. (3) is equivalent to: min Q,U problem we propose in Section 2 with two relaxations: 1) We transform hard constraints in Eq. (5) to soft constraints where the ideal embedding is expressed in the initial labeling matrix Y and the 1, instead of either 0 or 1, and quadratic cost functions replace the L1 norms. So they are probability estimates rather than class membership indicators, and we can embed them anywhere on the plane. Though with these relaxations, we build connections between the constrained embedding framework as discussed in this section with the one proposed in Section 2. Therefore, we can view our proposed method as embedding both object nodes and group nodes into a hyperlane so that object nodes are close to the group nodes they link to. The constraints are put on the group nodes from supervised models to penalize the embedding that are far from the  X  X deal X  ones.
 Ranking on Consensus Structure. Our method can also be viewed as conducting ranking with re-spect to each class on the bipartite graph, where group nodes from supervised models act as queries. Suppose we wish to know the probability of any group g j belonging to class 1, which can be regarded as the relevance score of g j with respect to example queries from class 1. Let w j = Algorithm 1, the relevance scores of all the groups are learnt using the following equation: where the v  X  v diagonal matrices D  X  and D 1  X   X  have ( j, j ) entries as w j w Consider collapsing the original bipartite graph into a graph with group nodes only, then A T A is its represent the probability of jumping to node j from node i . The groups that are predicted to be in class 1 by one of the supervised models have 1 at the corresponding entries in ~y  X  1 , therefore these group nodes are  X  X ueries X  and we wish to rank the group nodes according to their relevance to them. Comparing our ranking model with PageRank model [24], there are the following relationships: 1) show our preference towards the query nodes, so the resulting scores would be biased to reflect the relevance regarding class 1. 2) In PageRank, the weights D  X  and D 1  X   X  are fixed constants  X  and 1  X   X  , whereas in our model D  X  and D 1  X   X  give personalized damping factors, where each group has a damping factor  X  j = w j w number of outlinks at each node, whereas our ranking model does not normalize p ij on its outlinks, and thus can be viewed as an un-normalized version of personalized PageRank [18, 28]. When each base model generates balanced groups, both  X  j and outlinks at each node become constants, and the proposed method simulates the standard personalized PageRank. The relevance scores with respect to class 1 for group and object nodes will converge to ~q respectively. I v and I n are identity matrices with size v  X  v and n  X  n . The above arguments hold for the other classes as well, and thus each column in U and Q represents the ranking of the nodes with respect to each class. Because each row sums up to 1, they are conditional probability estimates of the nodes belonging to one of the classes. Thus far, we propose to combine the output of supervised and unsupervised models by consensus. When the true labels of the objects are unknown, this is a reliable approach. However, incorporating labels from even a small portion of the objects may greatly refine the final hypothesis. We assume that labels of the first l objects are known, which is encoded in an n  X  c matrix F : We modify the objection function in Eq. (1) to penalize the deviation of ~u i  X  of labeled objects from the observed label: where h i = consensus class label estimate should be close to its observed label with a shadow price  X  . When objective function. To update the condition probability for the objects, we incorporate their prior labeled information: In matrix forms, it would be U t = ( D n +  X H n )  X  1 ( AQ t +  X H n F ) with H n = diag during the updates, with the rationale that the observed labels are just random samples from some instead of totally relying on them. We evaluate the proposed algorithms on eleven classification tasks from three real world applica-algorithms are performed on this target set to obtain the grouping results. On the other hand, we learn classification models from some training sets that are in the same domain or a relevant domain with respect to the target set. These classification models are applied to the target set as well. The proposed algorithm generates a consolidated classification solution for the target set based on both classification and clustering results. We elaborate details of each application in the following. 20 Newsgroup categorization. We construct six learning tasks, each of which involves four classes. The objective is to classify newsgroup messages according to topics. We used the version [1] where the newsgroup messages are sorted by date, and separated into training and test sets. The test sets are our target sets. We learn logistic regression [15] and SVM models [7] from the training sets, and apply these models, as well as K-means and min-cut clustering algorithms [22] on the target sets. Cora research paper classification. We aim at classifying a set of research papers into their areas [23]. We extract four target sets, each of which includes papers from around four areas. The train-ing sets contain research papers that are different from those in the target sets. Both training and target sets have two views, the paper abstracts, and the paper citations. We apply logistic regression classifiers and K-means clustering algorithms on the two views of the target sets.
 DBLP data. We retrieve around 4,000 authors from DBLP network [10], and try to predict their research areas. The training sets are drawn from a different domain, i.e., the conferences in each research field. There are also two views for both training and target sets, the publication network, and the textual content of the publications. The amount of papers an author published in the conference can be regarded as link feature, whereas the pool of titles that an author published is the text feature. target set. We manually label the target set for evaluation.
 The details of each learning task are summarized in Table 2. On each target set, we apply four models M 1 to M 4 , where the first two are classification models and the remaining two are clus-tering models. We denote the proposed method as Bipartite Graph-based Consensus Maximization ( BGCM ), which combines the output of the four models. As shown in Figure 3, only clustering ensembles, majority voting methods, and the proposed BGCM algorithm work at the meta output level where raw data are discarded and only prediction results from multiple models are available. However, majority voting can not be applied when there are clustering models because the cor-respondence between clusters and classes is unknown. Therefore, we compare BGCM with two clustering ensemble approaches ( MCLA [26] and HBGF [12]), which ignore the label information from supervised models, regard all the base models as unsupervised clustering, and integrate the output of the base models. So they only give clustering solutions, not classification results. To evaluate classification accuracy, we map the output of all the clustering algorithms (the base models, and the ensembles) to the best possible class predictions with the help of hungarian method [5], where cluster IDs are matched with class labels. Actually, it is  X  X heating X  because the true class labels are used to do the mapping, and thus it should be able to generate the best accuracy from these unsupervised models. As discussed in Section 4, we can incorporate a few labeled objects, which are drawn from the same domain of the target set, into the framework and improve accuracy. This improved version of the BGCM algorithm is denoted as BGCM-L , and the number of labeled objects used in each task is shown in Table 2. On each task, we repeat the experiments 50 times, each of which has randomly chosen target and labeled objects, and report the average accuracy. Due to space limit, we only show the standard deviation ( STD ) for BGCM-L method. The baselines share very similar standard deviation with the reported one on each task.
 Accuracy. In Table 3, we summarized the classification accuracy of all the baselines and the pro-posed approach on the target sets of eleven tasks. The two single classifiers ( M 1 and M 2 ), and the two clustering single models ( M 3 and M 4 ) usually have low accuracy. By combining all the base models, the clustering ensemble approaches (MCLA and HBGF) can improve the performance over each single model. However, these two methods are not designed for classification, and the reported accuracy is the upper bound of their  X  X rue X  accuracy. The proposed BGCM method always outper-forms the base models, and achieves better or comparable performances compared with the upper bound of the baseline ensembles. By incorporating a small portion (around 10%) of labeled objects, the BGCM-L method further improves the performances. The consistent increase in accuracy can be observed in all the tasks, where the margin between the accuracy of the best single model and that of the BGCM-L method is from 2% to 10%. Even when taking variance into consideration, the results demonstrate the power of consensus maximization in accuracy improvements.
 Sensitivity. As shown in Figure 4 (a) and (b), the proposed BGCM-L method is not sensitive to the parameters  X  and  X  . To make the plots clear, we just show the performance on the first task of each application.  X  and  X  are the shadow prices paid for deviating from the estimated labels of groups and observed labels of objects, so they should be greater than 0.  X  and  X  represent the confidence of our belief in the labels of the groups and objects compared with 1. The labels of group nodes are obtained from supervised models and may not be correct, therefore, a smaller  X  usually achieves better performance. On the other hand, the labels of objects can be regarded as groundtruths, and thus the larger  X  the better. In experiments, we find that when  X  is below 4, and  X  greater than 4, good performance can be achieved. We let  X  = 2 and  X  = 8 to get the experimental results shown in Table 3. Also, we fix the target set as 80% of all the objects, and use 1% to 20% as the labeled objects to see how the performance varies, and the results are summarized in Figure 4 (c). In general, more labeled objects would help the classification task where the improvements are more visible on Cora data set. When the percentage reaches 10%, BGCM-L X  X  performance becomes stable.
 Number of Models. We vary the number of base models incorporated into the consensus frame-work. The BGCM-L method on two models is denoted as 2-L , where we average the performance of the combined model obtained by randomly choosing one classifier and one clustering algorithm. Similarly, the BGCM-L method on three models is denoted as 3-L . From Table 3, we can see that BGCM-L method using all the four models outperforms the method incorporating only two or three models. When the base models are independent and each of them obtains reasonable accuracy, combining more models would benefit more because the chances of reducing independent errors increase. However, when the new model cannot provide additional information to the current pool of models, incorporating it may not improve the performance anymore. In the future, we plan to identify this upper bound through experiments with more input sources. In this work, we take advantage of the complementary predictive powers of multiple supervised and unsupervised models to derive a consolidated label assignment for a set of objects jointly. We propose to summarize base model output in a group-object bipartite graph, and maximize the con-sensus by promoting smoothness of label assignment over the graph and consistency with the initial labeling. The problem is solved by propagating labeled information between group and object nodes through their links iteratively. The proposed method can be interpreted as conducting an embedding of object and group nodes into a new space, as well as an un-normalized personalized PageRank. When a few labeled objects are available, the proposed method uses them to guide the propagation and refine the final hypothesis. In the experiments on 20 newsgroup, Cora and DBLP data, the proposed consensus maximization method improves the best base model accuracy by 2% to 10%. Acknowledgement The work was supported in part by the U.S. National Science Foundation grants IIS-08-42769, IIS-09-05215 and DMS-07-32276, and the Air Force Office of Scientific Research MURI award FA9550-08-1-0265.
