 Hand-crafted textual patterns have been the mainstay device of prac-tical relation extraction for decades. However, there has been little work on reducing the manual effort involved in the discovery of effective textual patterns for relation extraction. In this paper, we propose a clustering-based approach to facilitate the pattern dis-covery for relation extraction. Specifically, we define the notion of semantic signature to represent the most salient features of a tex-tual fragment. We then propose a novel clustering algorithm based on semantic signature, S2C , and its enhancement S2C+ . Experi-ments on two real-world data sets show that, when compared with k -means clustering, S2C and S2C+ are at least an order of magni-tude faster, while generating high quality clusters that are at least comparable to the best clusters generated by k -means without re-quiring any manual tuning. Finally, a user study confirms that our clustering-based approach can indeed help users discover effective textual patterns for relation extraction with only a fraction of the manual effort required by the conventional approach.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Linguistic processing ; I.2.7 [ Artificial Intelligence ]: Natural language processing X  text analysis Algorithms, Experimentation, Human Factors Information Extraction, Clustering, Pattern Discovery  X  Work was done while visiting IBM Research -Almaden.

Relation extraction refers to the task of detecting and classifying meaningful relations between two or more entities in text. For ex-ample, the text fragment  X  please call Alice from CompanyA Inc. at her cell phone (123) 456-7890  X  contains the E MPLOYEE O F relation  X  Alice from CompanyA Inc.  X  and the P ERSON P HONE relation  X  Alice ... at her cell phone (123) 456-7890  X . Relation extraction is impor-tant for many applications, ranging from information retrieval and question answering to text entailment.

Most information extraction systems rely on knowledge engi-neering or machine learning to generate the  X  X ask model X  for rela-tion extraction. In the knowledge engineering approach, the model is usually in the form of manually created extraction rules. In the machine learning approach, the model is learned automatically from a manually labeled training data in a supervised or semi-supervised fashion. The machine learning approach has been popu-lar in the research community in recent years (e.g. [1, 5, 12, 24, 32, 39, 40]). At the same time, the knowledge engineering approach remains a widely adopted practical solution for relation extraction due to its transparency, customizability, and maintainability. These properties are highly valued by emerging enterprise text analytics applications (e.g. compliance and semantic search) [9, 11, 14, 31].
In the knowledge engineering approach, a developer creating rules for a binary relationship (e.g. pairs of P ERSON
N UMBER ) typically starts by manually examining the contexts between the pairs. She then determines whether each pair forms a meaningful relation and manually discovers textual patterns in-dicating the desired relation. Finally she writes rules to incorpo-rate the patterns observed. These rules, when applied to a training corpus, usually generate a large number of results. The developer examines a (typically small) sample of the results, and determines whether each one is positive or negative. She then discovers po-tential improvements to the rules by examining the relationship be-tween the results, the original context strings, and the applicable patterns. She iterates through the process until she is satisfied with the precision and recall of the relation extraction annotator. The following example illustrates one step in this process.
 tifying the P ERSON P HONE relation is  X  P ERSON followed by  X  at  X  followed by a P HONE N UMBER within the same sentence X , repre-can correctly identify valid P ERSON P HONE relation such as  X  Alice at (123) 456-7890  X  and  X  Bob can be reached at (111) 222-3333 X   X , it not only produces incorrect matches such as  X  John X  X  assistant at x1234  X  but also fails to identify correct matches such as  X  Jane X  X  cell: (222) 333-4444  X . In order to account for precision and re-call, a rule developer needs to refine P 1 (e.g. P 2 =  X   X  P additional patterns (e.g. P 3 =  X   X  P ERSON  X   X  X  (cell|office|home)? :
As can be seen, this is an extremely tedious and error-prone man-ual process that can take days or even weeks of work to develop rules for a single relation. The focus of this work is to reduce the human effort involved in writing rules for relation extraction. In this paper, we propose a novel formulation of clustering algorithm called Semantic-Signature Clustering (short as S2C ) to facilitate the discovery of patterns for relation extraction. In the rest of the section, we first summarize our contributions and then discuss in detail the related work.
In a key departure from prior formulations, the clustering prob-lem presented in this work not only clusters similar strings, but also generates meaningful patterns. These patterns are similar to the manually generated ones used in relation extraction rules. Our specific contributions are:
Conventional text clustering algorithms (e.g. k -means [27]) are based on computing the similarity of context strings among each other or between each context string and a cluster representative. Context strings are mapped to a space (e.g. converted to a numeric vector) in which such a distance can be computed. For large scale relation extraction, both the numbers of context strings (depend-ing on the size of the corpus) and potential clusters representatives (one needed for each way to express a relation) grow rapidly to large sizes and causes the number of comparisons to grow rapidly. As we will show later, our clustering method saves these compar-isons by only requiring a rule-based local transformation on the context strings. Furthermore, unlike conventional clustering algo-rithms, our clustering method requires no extensive manual tuning on the parameters. To further motivate our approach, we now dis-cuss prior work with a focus on related work in the area of cluster-ing for relation extraction and the limitations of these techniques.
Textual patterns play an important role in relation extraction [6, 21]. As discussed earlier, learning of patterns for relation extrac-tion is typically a supervised process in learning-based systems or a tedious manual process in knowledge-engineering-based systems. Several semi-supervised systems were developed to enable relation extraction using a large unlabeled corpus and a small set of seeds [1, 4, 16, 18, 37].

A number of recent works focus on unsupervised relation iden-tification. [20, 7] discover relations of co-occurring named entities by clustering based on the words that appear between each pair. [13] groups textual occurrences based on the so-called hook words and then uses statistical correlation between the related entities contained in the textual examples to generate meaningful groups. Another clustering based method was proposed by [33] where the goal is to identify relations by clustering pairs of entities. Classical sequence patterns are mined as part of this approach to generate features for clustering. The SNE system [25] clusters the subject-verb-object triples generated by an Open Information Extraction system[3] into semantically coherent relations by probabilistically modeling the triples in second-order Markov logic and applying a co-clustering algorithm.

While unsupervised relation identification can reduce the labor cost of semi-supervised systems by automatically generating seeds [34], little work has been done for the building of relation extrac-tion patterns used by the knowledge-engineering-based systems. Our work seeks to fill this gap. It takes advantage of the unsuper-vised nature of clustering method similar to unsupervised relation identification, but with the goal of facilitating pattern discovery for relation extraction for knowledge-engineering-based systems. Our clustering method is configurable by the user using intuitive fea-tures, as the default clustering may or may not produce the granu-larity desirable to a user.

Our frequency-based pattern generation technique was motivated by the vGram approach [26] which performs fuzzy string match-ing by means of an automatically mined set of variable length sub-sequence. Our approach is based on a modification of the Apriori algorithm [2]. A similar approach is applied to web usage log min-ing in [29]. Their technique is based on task-specific pruning of the pattern candidate space. We extend their technique to mine interest-ing pairs of sequences. The underlying generalization of Apriori is described in [35]. An application of a more basic sequence mining technique to sentiment detection in texts can be found in [23].
In this work, we are primarily concerned with the task of cluster-ing the contexts extracted from the vicinity of relation candidates to assist the discovery of patterns used for relation extraction. Once these clusters are formed the patterns may be generated either man-ually by an annotator developer or automatically by existing tech-niques such as [6, 16]. This second phase will not be discussed further here, but we do present user study results in the experimen-tal section to demonstrate the effectiveness of the generated clusters in assisting annotator developers.

For pedagogical convenience, in the rest of the paper we restrict our attention to only consider binary relations and only context strings between the two entities in the relation. It will be obvi-ous that the techniques presented here are applicable to more gen-eral situations. For example, the context string could include the complete sentence(s) in which the two entities appear, which may extend to the left and right of both entities.

Under the above restrictions, the clustering problem for a target Figure 2: Example input, relation candidates and context strings relation R can be described as follows. We are given two sets of entities E 1 and E 2 , a set of relation candidates C  X  E and a set of content strings S C associated with C . Each string s  X  S C is extracted from the vicinity of a candidate c = ( e C according to predefined rules. The goal of the clustering task is to generate disjoint clusters C = C 1  X  C 2  X  ...  X  C so that each cluster C i is associated strongly with either R or its complement. These clusters serve as hints for positive and negative patterns for the relation R . The special cluster O t (for  X  X rphan X ) is a conglomerate of all those clusters smaller than a threshold t .
Our strategy for generating these clusters is to associate each C with a distinct Semantic Signature G i . This process (dubbed S2C ) consists of two stages: (1) Generating first level semantic signa-tures; and (2) further clustering of these semantic signatures. The first stage utilizes the statistical correlations of the context strings. The second stage utilizes textual similarities of the context strings. These stages are described in Section 3 and 4 respectively.
The semantic signature generation stage consists of several steps, as illustrated in Figure 1. We describe details of each step in this section. Figure 2 provides three example inputs. We use data in the first row to construct a running example for this entire section. Figure 3 shows the results of the transformations in each step. The goal of this step is to map the context strings to a reduced set of sequences that are intended to capture the most salient fea-tures of the context strings. This mapping is done in the following process with three parameters: a tokenization procedure T , an in-teger l for maximum length of sequence, and an integer f for min-imum frequency of the sequence. The steps are: (1) Tokenizing each context string s c by T into a token sequence s . (2) Collecting all subsequences of s with length no more than l generated from all s c  X  S C . (3) Retaining all those with at least f occurrences in the corpus. The result is a frequent sequence set S C,T,l,f implementation, a single pass through the data is sufficient.
Once each context string is reduced to a set of sequences, we can collect statistics to compute the correlation between sequences. By discovering the correlation between sequences, similar sequences within the same set can be removed. This results in a semantic sig-nature that represents the key elements of the context string. Differ-ent measure of correlation can be used in this step. In this paper, we choose uncertainty coefficient [38] to be the measure of correlation between two sequences.

For each ordered pair of frequent sequences x and y , the propor-tion of information in x that is shared with y can be measured by the uncertainty coefficient where I ( x,y ) is the mutual information between x and y , and H ( x ) is the entropy of x . If U ( x | y ) is close to unity, dropping x in the presence of y will not remove a significant portion of available information. In practice, we can approximately compute I ( x,y ) = and p ( x,y ) are the empirical probabilities of occurrences and co-occurrence. The definitions of I ( x,y ) and H ( x ) involve summing over the probabilities of occurrence and non-occurrence. However, since our interest here is only in the effect of occurrences of the se-quences, and since the probability of non-occurrence is much larger than that of occurrence, terms for non-occurrences can be ignored.
For each pair of x,y  X  S C,T,l,f , if U ( x | y ) is larger than a pre-defined threshold t we generate a  X  X rop rule X  DROP ( x | y ) . They are stored in decreasing order of corresponding U ( x | y ) . Figure 4 provides an example of some uncertainty coefficients and the cor-responding drop rules generated. These will be used later in our running example.

To further remove noise from the semantic signature, we remove those sequences x in the presence of other sequences y if the origi-nal string for x is found within the original string of y . Simply put, if the original string of x is a substring of the original string of y , x is considered to be subsumed by y and thus removed from the sequence set.

Consider the example in Figure 3, where the given context string is  X  X n Event Manager \n tel: X  . The sequences {\n tel:} and {tel:} are subsumed by {manager \n tel:} since they are from the same sub-string. These are then removed. resulting the final sequence set {\n; manager \n tel:} .
 The drop rules are applied to remove non-informative sequences. As described earlier, these rules were generated to indicate that one sequence is not informative in the presence of another sequence. For instance, the current set {\n; manager \n tel:} results in {manager \n tel:} when the rule DROP ( \n|manager \n tel ) is applied.
The rules are applied in their stored order, which is determined by the correlation measure associated with each rule. Applying the drop rules in this order guarantees that the sequence with less useful information is dropped. For instance, if both and DROP ( y | x ) exist where DROP ( x | y ) has a higher measure of uncertainty, then if the sequence set includes { x,y } , x is removed from the set and DROP ( y | x ) has no effect. An example of this appears in the following step.

One may wonder why we chose to apply the drop rules after removing subsumed sequences, instead of before. When gener-ating statistics, the results are generated based on the correlation between all pairs of sequences without considering the subsumed relationship. However, when applying the rules, we take a conser-vative approach and require a subsequence to be as important by itself as it is with other subsequences. If rules are applied before, essentially a higher weight is given to each subsequence and im-portant sequences can be lost. Take, for example, the sequence set { a,ab,c } where ab represent a sequence comprised of the subse-quences a and b . If DROP ( c | a ) is applied before subsumed, the resulting signature is { ab } and c is lost. However, if subsumed is applied first, which removes a due to the presence of ab , the re-sulting signature is { ab,c } , preserving c . Only an explicit rule like DROP ( c | ab ) would remove c .

For certain sequences, a second pass with the drop rules is re-quired, after all larger sequences are split into subsequences of length 1. This captures cases where a sequence of length 1 is ca-Figure 5: Sample entries of two clusters generated by S2C Figure 6: Example of three similar clusters generated by S2C , which are merged into one cluster by S2C+ pable of describing the entire context string, but has been stored together with a second sequence of less importance.

For the previous sequence set {\n; manager \n tel:} , the only rule that would apply is D 1 = DROP ( \n|manager \n tel: ). However, by splitting the larger sequences, the rules in Figure 4, can now remove sequences that do not contribute meaningful information to the final semantic signature. Applying the rules, in stored order, results in a final sequence string of {\n; tel:} . Notice that when the rules are applied in stored order, {manager} was dropped as opposed to {tel:} .
We call the resulting sequence of tokens representing each con-text string the semantic signature of the original string.
Once we obtain the semantic signature of each context string for all the relation candidates, the clustering of context strings S straightforward  X  all the relation candidates associated with the same semantic signatures form one cluster. Candidates with differ-ent semantic signatures are in different clusters. In addition, any cluster with size smaller than a predefined threshold t is reassigned to a special cluster O t . We refer to this clustering method as S2C .
Figture 5 illustrates sample entries from two clusters of relation candidates generated by S2C . As can be seen, the entries in each cluster are indeed semantically similar to each other, as represented by their sematic signature, {number} , {at} , respectively.
In this section, we discuss the issues of applying the S2C results to assist in annotator development.
One remaining problem with the S2C algorithm is that the  X  X r-phan X  cluster O t can be a non-trivial size. Recall that O glomerate of all clusters with size smaller than t . It is clear that the content of O t is very diverse and difficult to discover mean-ingful patterns from. Consequently, when O t is large the resulting relational annotator developed with the help of this clustering may have a poorer recall. In order to reduce the size of O t the observation that the semantic signatures of many small clusters are often similar to those of larger ones. For instance, Figure 6 lists three different clusters created by S2C , with different but similar semantic signatures. If we merge some of the small clusters with larger ones, the total number of clusters stays the same, but the size of O t will decrease. As long as the semantic signatures of the merged clusters are similar, the clusters can still assist the pattern discovery for relation extraction.

Merging small clusters into larger clusters, rather than simply discarding them, improves the results in two ways. First, after merging we still retain the set of original semantic signatures. This provides the user with very useful hints on the possible variations of semantic signatures. Second, the user can also drill down to all these clusters to see actual examples, which is a very crucial re-quirement in example-based rule development.

We measure the distance between two clusters by the distance between their respective semantic signatures, which are sets of to-ken sequences. There are several ways to measure the (dis)similarity between them. For example, we can use the Jaccard distance on these two sets [22]. Given such a distance d , we proceed in the fol-lowing steps: (1) For all the small clusters C that went into O look for those with size smaller than re-clustering threshold t (2) If there exists a cluster C j with size larger than t d ( C,C j ) &gt; s , remove C from O t to C j . When there are multi-ple C j satisfying the condition, we pick the largest among them. Other policies might be advantageous in certain aspects and further research is needed to quality them.
 For example, when given t s = 3 , t l = 9 and d the Jaccard Distance, the three clusters in Figure 6 are merged into one.
The computation in S2C involves several pass through the data points (context strings). In step 1 (generating frequent sequence), the set has O ( nml ) cost, where n is the number of data points, m is the average number of tokens generated from each context string, and l is the maximum length subsequences allowed. Steps 2 and 3 (computing uncertainty coefficients and drop rules) have O ( ns cost, where s &lt; ml is the average number of frequent subse-quences for each context string. Seps 4 and 5 (removing subsumed subsequences and of applying drop rules) each also has O ( ns cost. Step 6 (applying drop rules on split strings) has an O ( nms ) cost. The final clustering step has O ( ns ) cost. Therefore the total cost is O ( ns 2 )+ O ( nms ) . Note that both m and s are only depen-dent on the distribution of the context strings and the parameters used in the algorithm. They do not depend on the size of the data set. Therefore the cost of this algorithm is essentially linear in the size of its input data.

The computation in S2C + involves sweeping through the small clusters and computing their distance to each of the large clusters. The cost is O ( k 1 k 2 d ) , where k 1 and k 2 are the numbers of large and small clusters, and d is the cost of calculating a distance be-tween two semantic signatures. If we choose the cutoff threshold t by limiting the number of large clusters to at most L , then the cost is bounded by O ( nLd ) . Since L and d are independent of the data size, the cost of S2C + is also linear in the size of input data.
In summary the computational complexity of the S2C and S2C + algorithms are both linear in the input data size.
 In contrast, the k -means algorithm is known to have a complexity O ( Iknt ) , where I is the number of iterations, and t is the time needed to calculate the distance between two points.
We designed a novel GUI to facilitate the exploration of the clus-ters generated by S2C or S2C+ for pattern discovery [8]. See the screenshot in Figure 7. The basic idea is to allow a developer to quickly identify a cluster of interest based on its size and seman-tic signature and then have the ability to drill down and explore the actual relation candidate contained by the cluster. In addition, through the GUI, the user should be able to exploit any labeling information available.

One of the most important design decision of the S2C system is that it can be a useful tool in the development cycle of annotator development. This imposes a constraint on system response time. As will be shown in the experimental section, S2C is at least an or-der of magnitude faster than k -means. In addition, as many of the steps in the S2C process are reusable, the actual responses time of S2C embedded in an annotator development environment is much shorter than the end-to-end running time. In many cases, the com-putation of frequent sequences and drop rules need to be computed only once. The user adjustable parameters are the thresholds for ap-plying drop rules, for the orphan group, and for merging the small groups. Re-computation when these parameters change are almost instantaneous and are easily controlled in the GUI. In this section, we present an empirical study of the S2C and S2C+ algorithms over two real-life data sets. The main goal of the study is answer the following questions: (1) Do the algorithms generate high quality clusters for relation extraction? (2) Are the algorithms effective in reducing manual effort in discovering tex-tual patterns for high-quality relation extraction? (3) How do the algorithms compare with existing clustering algorithms, in both the quality of the clusters created as well as runtime performance?
For the experiments, we used two different real-life text corpora:  X  Bio : A collection of 2,068 biographies from 456 SEC Form  X  Email : A collection of 37,939 email messages from the pub-
The former contains formal clean text, while the latter contains mostly informal noisy messages.
Tthe data set is now publicly available at URL.
For each data set, we chose a real-life relation extraction task that has been previously implemented for commercial products via a knowledge-based approach. Specifically, for the Bio data set, we chose the task of identifying P OSITION I N O RG and for the Email data set, we chose the task of identifying P ERSON goal of our study is to compare the patterns produced manually, with ones crafted with the assistance of S2C and S2C+ in terms of the extraction quality of patterns as well as the amount of manual effort required to derive these patterns.
We obtained the labeled data via the use of Amazon Mechani-cal Turk (MTurk), which has been shown to produce high quality annotations for a variety of natural language processing tasks [36]. Following the practice by [17], we first used existing state-of-the-art NER annotators [10] to identify Person and PhoneNumber over Email , Position and Organization over Bio . We then obtained noisy potential relation candidates by extracting  X  Person , PhoneNum-ber  X  and  X  Position , Organization  X  pairs from the data sets, with each pair of entities within 40 tokens of each other. 2 We then sub-mitted each candidate along with its context as a Human Intelli-gence Task (HIT) to MTurk and asked the workers to select from three annotation options: the candidate (1) represents the relation, (2) does not represents the relation, or (3) not applicable.
We initially launched a pilot study with 100 HITs (i.e., 100 rela-tion candidates). Upon the completion of the pilot and verification of the quality of the result, we then deployed the full study for all the relation candidates. Each HIT was assigned to five unique workers for a cost of $0.02 each. A total of 5171 HITs were submit-ted for Bio and 5771 HITS for Email . The majority vote of workers decided the final labeling. We also used known control answers to identify spurious responses and unreliable users to filter out noisy labels. Each rejected assignment was then resubmitted to MTurk until high quality answers were obtained. 3 In our experiments we evaluated both S2C and its enhancement S2C+ with t s = 3 and t l = 10 . We also compared them to k -means [27], a popular generic clustering algorithm, using the im-plementation from WEKA [19]. Note that the results of k -means is sensitive to k , the number of clusters to be generated. Since we do not know about the optimal number of k , we set k of k -means to be the number of clusters found automatically by S2C and S2C+ , denoted as k -means 1 and k -means 2 respectively. For all the clus-tering algorithms, we posed the threshold for orphan cluster t = 5 and move all the clusters with size smaller than t into a special orphan cluster. We ran all our experiments on a Windows-based PC with Intel Core 2 Duo processor with a single core speed of 2.20GHz and total RAM of 3.0 GB.
We first examined the quality of the clusters generated by S2C and S2C+ in two aspects: (1) the total number of clusters that the
For fair comparison, we used the same token boundary limit as that used in the existing annotators.
We rejected 1.8% of the answers for the P OSITION I N O RG over Bio and 5.1% of the answers for P ERSON P HONE Email . Figure 8: Quality of clusters Generated by S2C , S2C+ , k -means 1 , and k -means 2 over Bio Corpus algorithm generates, which determines the number of textual pat-terns required to develop the relation extraction annotator; (2) the overall quality of the clusters.
Intuitively, the quality of a cluster correlates with how reliable a (positive or negative) textual pattern can be generated based on the cluster. Therefore, given the precision of a cluster C Precision ( C ) = | C | , where G is the gold standard, the closer Precision ( C ) to 1 or 0, the higher the quality of C . Following this intuition, we propose a new metric called Plausible Reliability (short as PR ) to measure the quality of C , based on how close P ( C ) is to 1 or 0, defined as follows: Hence, the value of PR ( C ) for a cluster C is between 0.5 and 1. The higher the value of PR ( C ) is, the better the quality of C .
To measure the overall quality of a set of clusters C = C we can use their average PR , defined as follows:
We first analyze the results obtained over Bio for the four dif-ferent techniques. Figure 8(a) shows the histogram of clusters of Figure 9: Average PR and data coverage of clusters generated by k -means with varying k different plausible reliability. For all four techniques, the number of clusters is not large, ranging from 70 for S2C and S2C+ and 89 for k -means 1 . More importantly, the majority of the clusters (rang-ing from 68.5% for S2C+ to 80 . 0% for k -means 1 ) are high quality clusters with PR higher than 0.9. Furthermore, the vast majority of the clusters (around 90% across the board) are at least good clus-ters, i.e. clusters with PR higher than 0.8.

Another important aspect of the quality of the clusters is their coverage, especially of the high quality ones. Figure 8(b) depicts the distribution of data by plausible reliability. As we can see, the high quality clusters generated by all techniques cover the majority of the data (ranging from 72% to 76%). Furthermore, good quality clusters, i.e. clusters with PR higher than 0.8, cover the major of the remaining data. Recall that in the experiment, we provide k -means the cluster sizes found using S2C and S2C+ for k -means 1 means 2 correspondingly. We found that on this data set, k -means and k -means 2 produced higher number of high quality clusters than S2C and S2C+ respectively. We also found that the clusters pro-duced by k -means 1 and k -means 2 have higher coverage than those produced by S2C and S2C+ respectively, but the advantage is very small.

We can see from Figure 8 that as expected, S2C+ has produced fewer high quality clusters than S2C , as more noise has been in-troduced into the clusters when merging small clusters with larger ones in S2C+ . Meanwhile, we also observe that S2C+ has effec-tively reduced the size of the orphan cluster and evidently improved the coverage of the clusters over S2C .

Since the result of k -means is sensitive to the given value of k , in order to verify that the automatically found cluster sizes were rea-sonable parameters for k -means, we evaluated the performance of k -means on the Bio corpus with varying k -parameters. The results are summarized in Figure 9. As can be seen, the average PR of (weighted by the number of entries contained by each cluster) the clusters produced by k -means increases gradually with the increase of k , while the coverage of the clusters drops steadily as well. The graph also indicates that the size automatically discovered by S2C+ provides a good trade off between the coverage of the clusters and the overall quality of the clusters.
The performance of the algorithm over the Email set are analyzed similarly and the results are shown in Figure 10. Similar to their Figure 10: Quality of clusters generated by S2C , S2C+ , k -means 1 , and k -means 2 over Email Corpus cluster sizes found using S2C and S2C+ respectively . performance over Bio , all algorithms generate relatively small num-bers of clusters, with most being high quality clusters that together cover most data. Compared to the results over Bio , the number of high quality clusters generated by all techniques increases. How-ever, their coverage drops considerably across the board. The drop is especially significant for k -means 1 and k -means 2 , both from a coverage of lower 70% over Bio to that of lower 40% over Email . When taking good quality clusters into consideration, the coverage of k -means 1 and k -means 2 over Email remains lower than that over Bio . However, the coverage of S2C and S2C+ actual improves from around 70% on Email to nearly 80% on Bio .

S2C and S2C+ consistently outperform k -means 1 and k -means respectively both in terms of the good quality clusters generated and in terms of the coverage of the clusters. The advantage is espe-cially pronounced when we consider the coverage for clusters with PR higher than 0.8, where the coverage of good quality clusters of k -means 1 and k -means 2 is drastically lower than ones generated by S2C and S2C+ . The decay of the performance of k -means k -means 2 on Email is not surprising  X  Email is much more noisy than Bio , and as a result, clustering blindly based on all the string content leads to less reliable clusters.

Once again, S2C+ does introduce noise to the clusters, with the coverage of high quality clusters dropping slightly from 56.8% to 54.5%. But at the same time, it effectively reduces the number of clusters that the developer needs to evaluate.
Results of Experiment 1 indicate that S2C and S2C+ are able to automatically generate high quality clusters with good coverage without requiring manual tuning. Intuitively, the clusters generated, such as shown in Figure 11, should be able to help a rule developer generate high quality extraction patterns with reduced manual cost. To evaluate whether this main goal of our work is achieved, we conducted the following user study on the effectiveness of S2C al-gorithms.

In this experiment, each data set is randomly partitioned into 80% training and 20% test data. Two rule developers were asked to independently write the P ERSON P HONE annotator for Email and P
OSITION I N O RG annotator for Bio based on the clusters generated by S2C+ over the training data. To quantify the amount of man-ual effort involved in the annotator development, each developer was given 2 hours for each task. We then compared the extrac-tion quality of the annotators developed with the help of S2C+ with the corresponding product-quality annotators developed previously using conventional purely manual approach over the entire data set.
The results are summarized in Table 1 and 2. As can be seen, even though the developer using the purely manual approach was given much longer time (2 to 3 weeks vs. 2 hours) than the de-velopers using the S2C+ -assisted approach, the extraction quality of the annotators created in the conventional approach ( Manual and Manual email ) is significantly lower than that of the annota-tors developed with the assistance of S2C+ ( S2C bio and S2C in recall and F-measure 4 . In addition, the precision of the anno-tators developed by S2C -assisted approach is at least comparable to, if not better than, the precision of the conventional manual ap-proach. Specifically, the precision of Manual bio is slightly better than that of S2C bio , while the precision of Manual email siderably lower than that of the annotator developed with assist of S2C ( S2C email ). The results confirm that our S2C algorithms are indeed effective in reducing the manual effort required for develop-ing high quality relation annotators.

In addition, Figures 12 and 13 show the progression of improve-ment each time the developer added a new pattern. As one can see, the recall on both data sets steadily increases while precision is held consistently high. Furthermore, Table 3 lists the quality results of the annotators over both training and test data on Bio . The quality of the annotator over the test data set are comparable to that over the training data set, implying that no over fitting has occurred.
As discussed earlier, one motivation of our work on developing the new S2C -based clustering algorithms is to be able to produce clusters with high efficiency. We therefore also measured the run-time performance of k -means and S2C in our comparison study.
We found that for both Bio and Email , it took k -means at least one order of magnitude longer to return results than S2C or S2C+ .  X  is set to 0.5 to reflect the practical emphasis on precision. Annotator Precision (%) Recall (%) F 0 . 5 (%) Manual bio 98.37 53.68 84.33 S2C bio Expert 1 97.83 90.42 96.25 S2C bio Expert 2 98.20 84.86 95.21 Annotator Precision (%) Recall (%) F 0 . 5 (%) Manual email 90.44 63.36 83.30 S2C email Expert 1 92.69 68.96 86.72 S2C email Expert 2 91.70 89.26 91.20 Data Set Precision (%) Recall (%) F 0 . 5 (%) Expert 1 Training 97.36 88.97 95.56 Expert 1 Test 97.83 90.42 96.25 Expert 2 Training 97.39 86.03 94.88 Expert 2 Test 98.20 84.86 95.21 For instance, over the Email corpus, it took k -means 50 minutes to generate all the clusters compared to the 5 minutes needed for S2C . Such long delay in generating results is problematic, since the clustering algorithms are embedded in an interactive annotator development tool where developers may desire to make changes to the configuration parameters to generate optimal clusters. Fur-thermore, S2C can often reuse the statistics previously computed to further speed up the cluster generation process based on various optimization techniques similar to database optimization. For in-stance, if the developer only makes the threshold for uncertainty coefficient stricter, the algorithm can determine that the only steps from drop rule generation need to be recomputed. Finally, k -means requires the user to run the clustering multiple times to find the op-timal k-parameter and can potentially cause further delay in cluster generation.

We also observed that k -means tends to consume much more heap-based memory that S2C . When running our more compli-cated data set Email , often times k -means would not return a re-sult because it would eventually consume over 1.5 GB of memory. In contrast, S2C never consumes over 1 GB of memory through-out our experiments. One reason is that our intermediate steps are saved to a database to conserve heap memory.

Given the fact that most of our annotator development are done on a laptop-based environment similar to the one used in our exper-iments, we can see that S2C is more suitable to assist the pattern Figure 12: Changes of precision and recall of P OSITION I annotator over the iterations. The dotted lines are the results of the manually constructed annotators. discovery task for relation extraction for both its faster response time and lower memory consumption. In Experiment 2, the annotators developed with the assist of S2C+ significantly outperform those developed in the conventional approach, while requiring a fraction of the development effort. The high quality clusters and their informative semantic signatures pro-vided effectively assistance in the pattern discovery process, re-ducing the development time for a high-quality relation extraction annotator from weeks using the conventional purely manual ap-proach 5 to merely hours using our new approach. Two additional issues were identified that may further speed up the development process, as will be discussed briefly in the following.

One issue concerns the usability of the clustering-based pattern discovery tool. Both expert annotator developers found that our GUI was effective in helping them understand and explore the clus-ters. However, they reported difficulty in keeping track of clusters that are already covered by their existing patterns, which resulted in wasted time developing additional patterns. One way to address this issue is to integrate the tool into the annotator development en-vironment, so that the coverage of the patterns crafted by the devel-oper is reflected automatically in the visualization of the clusters.
According to an internal third-party report, the minimum amount of time required for the development of a product-quality relation annotator is 2 to 3 weeks. Figure 13: Changes of precision and recall of P ERSON P HONE annotator over the iterations. The dotted lines are the results of the manually constructed annotators.

The other issue is that while the semantic signature of a cluster provides valuable starting point for the generation of the patterns for the cluster, the actual pattern generation is still a manual pro-cess. A promising future direction is to generate those patterns in an automatic or semi-automatic fashion. As we have discussed in the relation work, there are a number of existing works on pattern induction based on a small number of seeds [4, 6, 15, 18, 30, 37]. It would be interesting to integrate those techniques into the context of a more interactive pattern discovery tool.
We proposed a clustering-based approach to assist the pattern discovery process, and presented two novel algorithms, S2C and its enhancement S2C+ , to automatically cluster relation candidates based on their semantic signatures. Our extensive experimental study has confirmed the practical impact of this approach  X  with the assist of the clusters, a rule developer can craft product-quality annotators for relation extraction with significantly lower manual effort than that required by the conventional manual approach. Fur-thermore, S2C and S2C+ not only run an order of magnitude faster with less memory required than k -means, they also generate clus-ters of a comparable or better quality.

As described earlier, we have fully implemented our semantic-signature-based clustering algorithms with a user-friendly GUI. In fact, this pattern discovery tool is being transferred into a commer-cial product. For future work, we plan to focus on the two issues discussed in Section 5.5 to further improve the usability of this tool and to explore the feasibility of automating the pattern generation process based on the clusters. [1] E. Agichtein and L. Gravano. Snowball: extracting relations [2] R. Agrawal and R. Srikant. Fast algorithms for mining [3] M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and [4] S. Brin. Extracting patterns and relations from the world [5] R. Bunescu and R. Mooney. Learning to extract relations [6] M. Califf and R. Mooney. Relational learning of pattern [7] J. Chen, D. Ji, C. L. Tan, and Z. Niu. Unsupervised feature [8] C.-F. Chiang, L. Chiticariu, V. Chu, S. Dasgupta, T. Goetz, [9] L. Chiticariu, R. Krishnamurthy, Y. Li, S. Raghavan, F. R. [10] L. Chiticariu, R. Krishnamurthy, Y. Li, F. Reiss, and [11] L. Chiticariu, Y. Li, S. Raghavan, and F. Reiss. Enterprise [12] A. Culotta and A. McCallum. Confidence estimation for [13] D. Davidov and A. Rappoport. Unsupervised discovery of [14] A. Doan, R. Ramakrishnan, and S. Vaithyanathan. Managing [15] D. Downey, O. Etzioni, S. Soderland, and D. Weld. Learning [16] O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu, [17] M. R. Gormley, A. Gerber, M. Harper, and M. Dredze. [18] M. A. Greenwood and M. Stevenson. Improving [19] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, [20] T. Hasegawa, S. Sekine, and R. Grishman. Discovering [21] M. A. Hearst. Automatic acquisition of hyponyms from large [22] P. Jaccard.  X tude comparative de la distribution florale dans [23] N. Jindal and B. Liu. Mining comparative sentences and [24] N. Kambhatla. Combining lexical, syntactic, and semantic [25] S. Kok and P. Domingos. Extracting semantic networks from [26] C. Li, B. Wang, and X. Yang. Vgram: Improving [27] J. B. MacQueen. Some methods for classification and [28] E. Minkov, R. C. Wang, and W. W. Cohen. Extracting [29] A. Nanopoulos, D. Katsaros, and Y. Manolopoulos. A data [30] D. Ravichandran and E. Hovy. Learning surface text patterns [31] F. Reiss, S. Raghavan, R. Krishnamurthy, H. Zhu, and [32] E. Riloff and R. Jones. Learning dictionaries for information [33] B. Rosenfeld and R. Feldman. Clustering for unsupervised [34] B. Rozenfeld and R. Feldman. High-performance [35] L. Schmidt-Thieme and W. Gaul. Frequent generalized [36] R. Snow, B. O X  X onnor, D. Jurafsky, and A. Y. Ng. Cheap and [37] M. Stevenson and M. Greenwood. A semantic approach to [38] H. Theil. On the estimation of relationships involving [39] D. Zelenko, C. Aone, and A. Richardella. Kernel methods [40] S. Zhao and R. Grishman. Extracting relations with
