 The builders of affective lexica face the vexing task of distilling the many and varied pragmatic uses of a word or concept into an overall semantic measure of affect. The task is greatly complicated by the fact that in each context of use, speakers may implicitly agree to focus on just a subset of the salien t features of a concept, and it is these fe a-tures that determine contextual affect. Natura l ly, disagreements arise when speakers do not implici t-ly arrive at such a consensus, as when people dis a-gree about hackers : advocates often focus on qualities that em phasize curiosity or technical vi r-tuosity, while opponents focus on qualities that e m phasize criminality and a disregard for the law. In each case, it is the same concept, Hac k er , that is being described, yet speakers can focus on diffe r-ent qualities to ar rive at different affective stances.
Any gross measure of affect (such as e.g., that hackers are good or bad ) must thus be grounded in a nuanced model of the stereotypical properties and behaviors of the underlying word -concept. As different stereotypical qualities are highlighted or de -emphasized in a given context  X  a particular metaphor, say, might describe hackers as terro r ists or hackers as artists  X  we need to be able to re -calculate the perceived affect of the word -concept.
This paper presents such a stereotype -grounded model of the affective lexicon. After reviewing the relevant background in section 2, we present the basis of the model in section 3. Here we describe how a large body of feature -rich stereotypes is a c-quired from the web and from local n -grams. The model is evaluated in section 4. We conclude by showing the utility of the model to that most co n-textual of NL P phenomena  X  affective met a phor. In its simplest form, an affect lexicon assigns an affective score  X  along one or more dimensions  X  to each word or sense. For instance, Whissell X  X  (1989) Dictionary of Affect ( or DoA ) assigns a trio of scores to each of its 8000+ words to describe three psycholinguistic dimensions: plea s antness , activation and imagery . In the Do A, the lowest pleasantness score of 1.0 is assigned to words like abnormal and ugly , while the highest, 3.0, is a s-signed to words like wedding and wi n ning . Though Whissell X  X  DoA is based on human ra t ings, Turney (2002) shows how affective valence can be de rived from m easures of word association in w eb texts. cal affect. For reliable results on a larg e -scale, M o-hammad &amp; Turney (2010) and Moham mad &amp; Yang (2011 ) thus used the Mechanical Turk to elicit human rating s of the emotional content of words. Ratings were sought along the eight dime n-si ons identified in Plutchik (1980 ) as primary em o-tions: trust , anger , anticipation , disgust , fear , joy , sadness and surprise . Automated tests were use d to exclude unsuitable ra ters. I n all, 24,000+ word -sense pairs were annotated by five different raters. al affective model that uses the six basic emotion cat egories of Ekman (1993 ) as its dimensions: happy, sad, angry, fearful, di s gusted and surprised . These authors base estimates of affect on the co n-tents of Open Mind , a c ommon -sense knowledge -base (Singh, 2002 ) harvested from contributions of web volunteers. These contents are treated as se n-tential objects, and a range of NLP mode ls is used to d e rive affective labels for the subset of contents (~10%) that appear to convey an emotio n al stance. These labels are then propagated to related co n-cepts (e.g., excitement is propagated from rolle r-coasters to amusement parks ) so that the impl icit affect of many other concepts can be dete r mined. of a f fective annotations for a subset of WordNet X  X  synsets in a resource called Wordnet -affect . The annotation labels, called a -labels , focus on the cogni tive d y namics of emotion, allowing one to distinguish e.g. between words that denote an em o-tion -eliciting situation and those than denote an emotional r e sponse . Esuli and Sebastiani (2006 ) also build directly on WordNet as their lexical pla t-form, using a s emi -supervised learning algorithm to a s sign a trio of numbers  X  positivity , negativity and neutrality  X  to word senses in their newly d e-rived resource, SentiWordN et . ( Wordnet -affect also su p ports these three dimensions as a -labels, and adds a fourth, ambig uous ). Esuli &amp; Sebastiani (2007 ) improve on their affect scores by running a variant of the PageRank algorithm (see also Miha l-cea and Tarau, 2004) on the graph structure that ta c itly connects word -senses in WordNet to each other via the words used in their textual glosses. pr o file of a word/sense when it is used in its most normative and stereotypical guise, but they do so without an explicit model of stereotypical mea n-ing. Veale &amp; Hao (2007 ) describe a w eb -bas ed a p proach to acquiring such a model. They note that since the simile pattern  X  X s ADJ as DET NOUN X  presupposes that NOUN is an exemplar of ADJ ness , it follows that ADJ must be a highly s a-lient property of NOUN. Veale &amp; Hao ha r vested tens of thousands of i nstances of this pattern from the Web, to extract sets of adjectival prope r ties for thousands of commonplace nouns. They show that if one estimates the pleasantness of a term like snake or artist as a weighted average of the plea s-antness of its properties (like sneaky or creative ) in a resource like Whissell X  X  DoA, then the estimated scores show a reliable correlation with the DoA X  X  own scores. It thus makes computational sense to calc u late the affect of a word -concept as a function of the affect of its mos t salient proper ties. Veale (2011 ) later built on this work to show how a pro p-erty -rich stereotypical representation could be used for non -literal matching and retrieval of creative texts, such as metaphors and analogies.
 argue for the importance of common -sense knowledge in the determination of affect. We i n-corporate ideas from both here, while choosing to build mainly on the latter, to construct a nuanced, two -level model of the affective lex i con. We construct the stereotype -based lexicon in two stages. For the first layer , a large collection of st e-reotypical d e sc riptions is harvested from the w eb. As in Liu et al . (2003), our goal is to acquire a lightweight common -sense re presentation of many everyday concepts. For the second layer , we link th e se common -sense qualities in a support graph that captures how they mutually su p port each other in their co -description of a stereotyp i cal idea. From this graph we can estimate pleasa ntness and u n-pleasantness valence scores for each property and b e havior, and for the stereotypes that exhibit them .
Expanding on the approach in Veale (2011 ), we use two kinds of query for h arvesting stere o types from the w eb. The first,  X  X s ADJ as a NOUN X , a c-quires typical adjectival properties for noun co n-cepts; the second,  X  X ERB +ing like a NOUN X  and  X  X ERB + ed like a NOUN X , acquires typical verb behaviors. Rather than use a wildcard * in both positions (ADJ and NOUN, or VERB and NOUN), which gives limited r esults with a search engine like Google, we generate fully instantiated similes from hypotheses generated via the Google n -grams (Brants &amp; Franz, 2006) . Thus, from the 3 -gram  X  X  drooling zombie X  we generate the query  X  X roo l ing like a zombie X , and from the 3 -gram  X  X  min d less zombie X  we generate  X  as mindless as a zombie X . Web documents via the Google API indicate the most promising associations. This still gives us over 250,000 web -validated simile associations for our stereotypical model , and we filter these man u-ally, to ensure that the lexicon is both reusable and of the highest quality. W e obtain rich d e scriptions for many stereotypical id e as, such as B aby , which is described via 163 typical properties and beha v-i ors like crying , drooling and guileless . After this phase, the lexicon maps each of 9 , 479 stereotypes to a mix of 7 , 898 properties and beha v iors. automatically linking these properties and beha v-iors to each o ther in a support graph. The intuition here is that properties which reinforce each other in a single description (e.g.  X  X s lush and green as a jungle X  or  X  X s hot and humid as a sauna X ) are more likely to have a similar affect than properties which do not support each other. We first gather all Google 3 -grams in which a pair of stereotypical properties or behaviors X and Y are linked via c o-ordination, as in  X  hot and h u mid  X  or  X  kicking and screaming  X . A bidirectional link between X and Y is added to the supp ort graph if one or more stere o-types in the lexicon contain both X and Y. If this is not so, we also ask whether both descriptors ever reinforce each other in Web similes, by po s ing the w eb query  X  as X and Y as  X . If this query has non -zero hit s , we still a dd a link between X and Y. note the set of neighboring terms to p , that is, the set of properties and behaviors that can mutually support a property p . Since every edge in N repr e-sents an affective context, we ca n estimate the lik e-lihood that p is ever used in a positive or negative context if we know the positive or negative affect of enough members of N( p ). So i f we label enough vertices of N with + /  X  labels, we can i n terpolate a positive/negative affect for a ll vert i ces p in N . negative words, and a set +R of typically positive words. Given a few seed members of -R (such as sad , evil , etc.) and a few seed members of +R (such as happy , wonderful , etc.), we find many other candidates to add to +R and -R by conside r-ing neighbors of these seeds in N . After just three iterations, +R and -R contain ~ 2000 words each.
For a property p , we define N + ( p ) and N -( p ) as We assign pos/neg valence scores to each prope r ty p by interpolating from reference values to their neighbors in N . Unlike that of Takamura et al . (2005), the approach is non -iterative and i n volves no feedback between the nodes of N , and thus, no i n ter -dependence between adjacent a f fect scores: If a term S denotes a stereotypical idea and is d e-scribed via a set of typical properties and behaviors t ypical(S ) in the lex i con, then: Thus, (5) and (6) calculate the mean affect of the properties and behaviors of S , as represented via typical(S ) . We can now use (3) and (4) to separate typica l(S ) into those elements that are more neg a-tive than positive (putting a n unpleasant spin on S in context ) and those that are more positive than negative (putting a pleasant spin on S in context ): In the process of populating +R and -R , we ident i-fy a reference set of 478 positive stereotype noun s (such as saint and hero ) and 677 negative stere o-type noun s (such as tyrant a nd monster ). We can use these reference stereotypes to test the effe c-tiveness of (5) and (6), and thus, indirectly, of (3) and (4) and of the affective lexicon itself . Thus, w e find that 96.7% of the stereotypes in +R are co r-rectly a s signed a positivity sc ore greater than 0.5 ( pos(S) &gt; neg(S ) ) by (5), while 96.2% of the ster e-otypes in -R are correctly assigned a negativ i ty score greater than 0.5 ( neg(S) &gt; pos(S ) ) by (6).
We can also use +R and -R as a gold standard for evaluating the separation of typical ( S ) into di s-tinct positive and negative subsets posTyp i cal(S ) and negTypical(S) via (7) and (8) . The lexicon co n-tains 6,230 stereotypes with at least one property in +R  X  -R . O n average, +R  X  -R co n tains 6.51 of the propertie s of each of these stereotypes, where , on a v erage, 2.95 are in +R while 3.56 are in -R .
In a perfect separation, (7) should yield a pos i-tive subset that contains only those properties in typical ( S )  X  +R , while (8) should yield a negative su b set that contains only those in typical ( S )  X  -R . Table 1. Average P/R/F1 scores for the affective retrieval of +/ -properties from 6,230 stereotypes. Viewing the problem as a ret rieval task then , in which (7) and (8) are used to retrieve distinct pos i-tive and negative property sets for a stere o type S , we report the encouraging results of Table 1 above . The Google n -grams are a rich source o f affective metaphors of the form Target is Source , such as  X  X ol i ticians are crooks X ,  X  X pple is a cult X ,  X  X acism is a disease X  and  X  X teve Jobs is a god X . Let src(T) denote the set of stereotypes that are co m monly used to d e scribe T, where commonality is de fined as the presence of the corresponding copula met a-phor in the Google n -grams. Thus, for e x ample: src (racism) = { problem, disease, po i son, sin , src (Hitler) = { monster , criminal , tyrant , idiot , Let srcTypical (T) denote the aggr e gation of all properties ascribable to T via met a phors in src (T): We can also use the posTypical and negTypical var i ants in (7) and (8) to focus only on metaphors that pr oject positive or negative qual i ties onto T. for a topic T as viewed through the prism of met a-phor. This is useful when the source S in the met a-phor T is S is not a known stereotype in the lexicon, as happen s e.g. in Apple is Sciento l ogy . We can also estimate whether a given term S is more positive than negative by taking the average pos/neg valence of src (S ) . Such estimates are 87% correct when evaluated using +R and -R e x amples. The properties and behaviors that are context u ally relevant to the interpretation of T is S are gi v en by In the context of T is S , the figurative perspective M  X  src (S)  X  src ( T )  X  {S} is deemed apt for T if: and the degree to which M is apt for T is given by: We can construct an inte rpretation for T is S by considering not just {S}, but the stereotypes in src (T) that are apt for T in the context of T is S , as well as the stereotypes that are commonly used to describe S  X  that is, src (S)  X  that are also apt for T: (13) interpretat ion (T, S) The elements { M i } of interpretation (T, S) can now be sorted by aptness ( M i T, S ) to produce a ranked list of interpretations (M 1 , M 2 ... M n ). For any i n-terpretation M, the salient features of M are thus: So interpretation (T, S) is an expansion of the a f-fective metaphor T is S that includes the common metaphors that are consistent with T qua S. For instance,  X  Google is -Microsoft  X  ( where -indi cates a negative spin ) produces {monopoly, threat, bully, giant, dinosaur, demon, ...} . For each M i in inte r-pretation (T, S), salient (M i , T, S ) is an e x pansion of M i that includes all of the qualities that are apt for T qua M i (e.g. threatening , sprawling , ev il , etc.). Metaphor is the perfect tool for influencing the perceived af fect of words and concepts in co n text . The web application Metaphor Magnet provides a proof -of -concept demon stration of this re -shaping process at work, using the st ereotype lexicon of  X 3 , th e sele c tive highlighting of (7)  X  (8), and the model of metaphor in (9)  X  (14) . It can be a c cessed at : http:// boundin a nutshell.com/metaphor -magnet This research was supported by the WCU (World Class Univers ity) program under the National R e-search Fou n dation of Korea, and funded by the Ministry of Education, Science and Tec h nology of Korea (Project No: R31 -30007).

