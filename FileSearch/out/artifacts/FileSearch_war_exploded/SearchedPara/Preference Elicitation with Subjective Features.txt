 Utility or preference elicitation is a critical component in many rec-ommender and decision support systems. However, most frame-works for elicitation assume a predefined set of features (e.g., as derived from catalog descriptions) over which user preferences are expressed. Just as user preferences vary considerably, so too can the features over which they are most comfortable expressing these preferences. In this work, we consider preference elicitation in the presence of subjective or user-defined features . We treat the prob-lem of learning a user X  X  feature definition as one of concept learn-ing , but whose goal is to learn only enough about the concept defi-nition to enable a good decision to be made. This is complicated by the fact that user preferences are unknown. We describe computa-tional procedures for identifying optimal alternatives w.r.t minimax regret in the presence of both utility and concept uncertainty; and develop several heuristic query strategies that focus on reduction of relevant concept and utility uncertainty. Computational experi-ments verify the efficacy of these strategies.
 I.2 [ Artificial Intelligence ]: Miscellaneous; H.5.2 [ User Inter-faces ]: interaction styles Algorithms, Human Factors preference elicitation, concept learning, minimax regret, version space, recommender systems
Assessing the preferences of users is a critical component in any decision support or recommender system: the ability to tailor rec-ommendations to the needs and desires of a particular user is in-deed a hallmark of intelligent decision support. Within AI, decision analysis, and operations research, a variety of systems and method-ologies have been developed for preference elicitation : engaging in some  X  X ialog X  with a user to determine her preferences. These range from conversational recommender systems [4, 10] that pro-vide considerable navigational control to a user as they explore the space of possible products/options, to adaptive elicitation systems that ask the user a sequence of questions about her preferences or utility function [2]. Here we focus primarily on elicitation.
Typically one assumes the existence of a set of universal or cata-log features over which user preferences are specified. For instance, in product configuration, preferences are assumed to be defined in terms of product features and specifications (e.g., color, engine size, fuel economy, available options, etc. in the case of a car). However, users can exhibit significant variation in the features over which their preferences are most naturally expressed, and these features may not be present among the set of catalog features. For instance, in the automotive domain, some users may be concerned about the  X  X egree of safety X  of a car, but different users may have different notions of safety in mind. 1 In recent work [3] we have developed a model for subjective feature elicitation that queries users about the feature in question, so that preference tradeoffs can be made involving the new feature. This model casts the problem as one of concept learning [1, 5]. However, unlike traditional concept learn-ing, the aim is to learn just enough about the concept definition to make a good or optimal decision on the user X  X  behalf. Specifically, it is assumed that the user X  X  underlying utility function is known and can be used to render judgements of relevance [3].
 In this paper, we extend this model to allow utility uncertainty. Indeed, while subjective feature elicitation is an important compo-nent of the process, genuine preference elicitation in the presence of subjective features requires interacting with a user when both the feature definitions and user preferences are unknown.

We present a model for preference elicitation with subjective fea-tures that allows for the simultaneous elicitation of user utility and user features, making appropriate tradeoffs between the two types of information. We use minimax regret [2, 9] as our decision cri-terion given concept and utility uncertainty, allowing good or opti-mal decisions to be made without complete specification of either component. We present several heuristic techniques for querying concept definitions and utility functions that reduce minimax regret quickly. In contrast to standard concept learning models, we aim to reduce  X  X elevant X  concept uncertainty w.r.t. the utility model, rather than learn an accurate concept definition for its own sake. And par-tially elaborated concept definitions influence the choice of utility queries as well. This provides a fully integrated preference elicita-tion methodology that allows a user to dynamically (and partially) specify their own utility-bearing product features.
E.g., a driver with a young family may define safety in terms of tires, air bags, child restraints, etc., while a high-performance driver refers to the braking system, roll bars, etc.

We consider subjective features that are  X  X bjectively X  definable using catalog attributes, but where the definition varies fr om user to user. For instance, the notion of a safe car may be different for a parent with small children, a young, single professional in terested in high-performance vehicles, and a family that takes frequ ent trips to the mountains. The concept in question, namely, safety, has per-sonalized definitions . 2 The user also has preferences for safety (as she does for other car attributes) represented in the form of a util-ity function: it is both the user X  X  utility function over thi s extended attribute space, as well as her personal definition of safety , that de-termines the optimal vehicle. As such, the recommender syst em must engage in both preference elicitation and feature elicitation to make a suitable recommendation. 3
This leads to interesting tradeoffs in elicitation. One cou ld en-gage in feature elicitation using well-known concept learn ing tech-niques [1] and then, with a full definition in hand, move to pre fer-ence elicitation (e.g., using techniques mentioned above) ; but this could be wasteful. For instance, suppose we learn that safet y re-quires attribute X i to be true (e.g., have side airbags) but know nothing else about the concept. If we engaged in preference e lic-itation simultaneously and ascertained that no cars in the u ser X  X  price range satisfy X i  X  X r that other more important features must be sacrificed to attain X i  X  X hen the full concept definition is not needed for optimal allocation. Conversely, we could engage in preference elicitation, using the subjective feature as an attribute without knowing its definition, and then engage in feature el icita-tion to determine a final recommendation. However, without s ome idea of the concept definition much more preference informat ion will be elicited than necessary. This suggests that interleaved fea-ture and utility elicitation can be much more effective.
Assume features X = { X 1 , ...X n } , which we take to be Boolean for ease of exposition, and a feasible product set X  X  Dom ( X ) . The user X  X  utility for any product x  X  X is decomposed into two components. First, the user has some utility or reward w.r.t. catalog features. We denote this by function r ( x ; w ) where w are the pa-rameters of this reward function. In what follows, we assume r is additive over X (this is not critical, only that r is linear in whatever parameterization w we adopt).

The user also has a preference for configurations satisfying some target concept c . Concept c is an unknown Boolean function over ticular function class/hypothesis space H (e.g., the set of conjunc-tive concepts). We treat identification of c as a problem of concept learning [1], with some query set Q that can be used to refine the target concept. For instance, membership queries would be q uite natural (e.g.,  X  X o you consider the following car to be safe?  X ). value or bonus w b is associated with any x s.t. c ( x ) holds, repre-senting user utility for concept satisfaction. We treat w another utility parameter (element of w ).
A distinct form of subjective feature involves aesthetic ju dge-ments or subjective tastes ( X  X ggressive X  or  X  X ute X  in the ca r do-main). Collaborative filtering techniques [7] are best-sui ted to help-ing users navigate through products with such features.
In cases where a very small number of definitions exist that te nd to apply to specific user types , one could imagine predefining these features and quickly discriminating them. However, our aim is to allow more open-ended feature definition.
Allowing multivalued concepts is straightforward.
Other query types (e.g., equivalence queries) are less natu ral in this domain, but may play a role in others.

Assuming utility independence for concept satisfaction re lative to other preferences, we define the utility of x under concept c and reward/bonus weight vector (or utility parameters) w to be: In other words, the utility of x is its reward, plus the bonus w satisfies c . The optimal configuration is x  X  w,c = arg max u ( x ; w, c ) .
Since c is definable in terms of catalog features, we could in prin-ciple elicit utilities using only catalog features. Howeve r, allowing a user to articulate her preferences in terms of natural comp osite features can reduce the burden of elicitation; furthermore , the ad-dition of such aggregate features with suitable definitions can in-crease the degree of (conditional) utility independence in a model.
During preference elicitation, we are uncertain about the t rue utility w and the true user concept c . As a result, we cannot gener-ally identify the optimal product x  X  w,c ; but we can still make a deci-sion with partial utility and concept information. Let W be the set of feasible utility functions, those consistent with any pr ior infor-mation we have about user preferences and user query respons es. W is generally a convex polytope given by linear constraints o n utility parameters (as discussed below). Let version space V  X  H represent our current set of consistent hypotheses w.r.t. c [8], i.e., those that respect any prior knowledge about the concept and re-sponses to queries (as discussed below). Define minimax regret w.r.t. utility and feature uncertainty: Definition 1 Given utility space W and version space V , the max regret of x  X  X , the minimax regret of ( W, V ) and the minimax optimal configuration are:
MR ( x ; W, V ) = max Should we recommend option x , max regret MR ( x ; W, V ) bounds (tightly) how far this decision could be from optimal. Intui tively, an adversary selects the user X  X  utility function w and the intended subjective feature definition c to maximize the difference in util-ity between our choice x and the optimal choice x  X  w,c (notice that the adversary X  X  maximizing configuration must be optimal un der ( w, c ) ). A minimax optimal choice is any product that minimizes max regret in the presence of such an adversary, and its max re gret is the minimax regret given our current uncertainty.
We assume that the underlying configuration problem is repre -sented as a MIP max x  X  X u ( x ) . We can then incorporate utility uncertainty (in the form of a bounded polytope W ) into the MIP following [2], and feature uncertainty in the form of a versi on space V following [3]. However, in the latter case, the formulation de-pends critically on the form of the concept and query classes one admits. We illustrate the formulation for the case of (nonmo notone) conjunctive concepts with membership queries.

Assume target c is a conjunction of literals over variables X Membership queries ask whether x  X  c for some product x . Let E + ( E  X  ) be the set of positive (negative) examples acquired by these queries, and (nonempty) V the induced version space. Instead of representing V using most general and most specific concepts, we encode E + and E  X  directly in our MIP (e.g., negative examples can directly represent most general concepts [6]).
 Constraint Generation We formulate the minimax problem Eq. 2 as a semi-infinite minimization. Let ( X 1 , , X n ) be configura-tion variables over our n features: its instantiation will denote the minimax optimal product. Let constant b ( x , w, c ) = w b and 0 otherwise. Let indicator variable I c , for each c  X  V , de-note that configuration ( X 1 , , X n ) satisfies c ; and write x (resp., x j  X  c ) to denote that variable X j occurs positively (resp., negatively) in c . Then MMR ( V ) is given by:
For any fixed concept c and utility function w  X  W , the adversary maximizes the regret of configuration ( X 1 , , X n ) with witness product x  X  w,c . The MIP above chooses a configuration that min-imizes against the  X  X orst-case X  choice of the adversary (wi th (4) ensuring MMR is as great as regret given any c  X  V, w  X  W ; and (5, 6) encoding whether ( X 1 , , X n ) satisfies c ).

Regret constraints for most w  X  W, c  X  V will be inactive, so we use constraint generation to search through the space of a dver-sarial utility functions and concepts. Let Gen  X  W  X  V be a (small) set of ( w, c ) -pairs (initially a single pair); we solve a re-laxed MIP using only constraints for those ( w, c )  X  Gen . Let  X  and x  X  be the solution to the relaxed MIP. We test for violated constraints by solving the max regret problem MR ( x  X  ; W, V ) , de-tailed below. If MR ( x  X  , W, V ) &gt;  X   X  , the utility-concept pair ( w  X  , c  X  )  X  X roduced as a witness in max regret computation X  X ffers larger regret for x  X  than any ( w, c )  X  Gen ; indeed, it corresponds to the maximally violated constraint in the relaxed MIP. So w e add ( w  X  , c  X  ) to Gen and resolve. If MR ( x  X  ; W, V ) =  X   X  , x optimal solution to MMR ( W, V ) .
 Generating Violated Constraints We compute the maximally violated constraint for the MIP above by solving the max regr et problem MR ( x  X  ; W, V ) for the current relaxed solution x too can be formulated as a MIP that, given x  X  , chooses an (adver-sarial) concept c , utility w and configuration. Details are omitted, but we use a standard reformulation to convert quadratic ter ms into a continuous variable, giving us a linear objective (simila r to [2]). All positive and negative examples are encoded directly in t he MIP, as in [3], thus constraining the adversary X  X  choice of conce pt.
While minimax regret provides an appealing means for making recommendations under utility and feature uncertainty, ou r aim is to learn enough about a user X  X  preferences and underlying co ncept to make good (or even optimal) recommendations, while askin g as few queries as possible. In this section, we develop several heuristic query strategies that can quickly reduce MMR ( W, V ) . We begin with a discussion of several forms of queries.
 Query Types With respect to explicit concept queries we restrict attention to membership queries of the form  X  X oes x satisfy con-cept c ? X  (e.g.,  X  X o you consider car x to be safe? X ). Each member-ship query gives rise to a positive or negative concept examp le, and the version space can be encoded in a variety of ways dependin g on the hypothesis class [6]. To elicit utility information, we adopt comparison queries : a user is asked if she prefers one product x to another y . Such comparisons can be localized to specific subsets of attributes as well, depending on the form of the utility mo del and can be generalized to choice sets over more than two products .
Responses to these and other common queries impose linear co n-straints on W when subjective features are absent. But the situa-tion becomes more complicated when feature uncertainty is a dded. If a user states that she prefers x to y in response to a compari-son query, we can no longer impose simple constraints on W . The greater utility of x could be due to its satisfaction of the subjective feature; but this cannot be reflected in the weight vector alo ne, as this can tie W and V together. One simple solution to this problem is to ask concept queries whenever one asks a comparison quer y. More precisely, if a user is asked whether she prefers x or y , a membership query can be asked of each outcome at the same time (e.g.,  X  X s x safe? X ). This is reasonably natural, since the assess-ment of preference likely involves some cognitive assessme nt of the subjective feature in question. We call such a query a combined comparison/membership (CCM) query. This allows us to impose simple valid linear constraints; e.g., if x is preferred and satisfies the concept, while y does not, then we have w x + b  X  w y &gt; 0 .
If we want a pure comparison query without the corresponding membership queries, we can still impose valid (and complete ) con-ditional constraints on W , based on the whether x , y satisfy the concept, thus linking W and V . With conjunctive concepts, we can linearize these conditional constraints without intro ducing new variables. The constraint above, e.g., is encoded as: w x + b  X  w y &gt; [ X where  X   X  &lt; 0 is any lower bound on the max difference in utility of any two outcomes (further details are provided in the full paper). Elicitation Strategies We now develop elicitation strategies for simultaneous utility/feature uncertainty. For compariso n queries, we adopt the (comparison) current solution strategy (CCSS) [2]: given the minimax optimal solution x  X  W,V and the adversarial wit-ness x a , the user is asked which of these two products is preferred.
To select membership queries, we examine two methods explor ed in [3]. The first is a simple halving strategy adapted from stan-dard conjunctive concept learning: we ask random membershi ps queries until a positive example is found; then queries are a sked by negating literals one by one in the (unique) most specific con junc-tive hypothesis. Once a positive example is found, this conv erges to the true conjunctive concept using a number of queries lin ear in the number of catalog features. We also explore the (member-ship) current solution strategy (MCSS) : this selects a query based on which of the optimal product x  X  W,V and/or witness x a the adversary X  X  choice of concept c a in the current solution. If x
W,V , x a  X  c a , then MCSS asks membership query x a ; if x c , x a  X  c a , then MCSS asks query x  X  W,V ; otherwise MCSS asks a query depending on the whether x a is V -consistent (see [3] for fur-ther details and motivation). MCSS will never ask a membersh ip query if the product in question is  X  X ertain X  (i.e., has its c oncept status determined unambiguously by V ).

Unlike the cases of pure utility or pure feature elicitation , in the simultaneous case we must make a decision at each stage regar ding which type of query to ask, membership or comparison. In our  X  in-terleaved X  strategies below, we decompose max regret of the cur-rent solution into reward regret and concept regret and use these measures to determine whether to ask a comparison (utility) query or a membership (concept) query, depending on which is large r. Let ( x  X  , x a , w, c ) be the current solution. Max regret of x (reward regret plus concept regret), where
Given this, we examine five query strategies. Two are phased strategies that first attempt to learn the concept and then refine Figure 1: Minimax Regret vs. Number of Queries (30 variables, 90 the utility function. The first is dubbed Ph(H,CCSS) and initially uses the halving algorithm (membership queries) to determi ne the precise concept definition, and then uses CCSS (comparisons ) to refine utility function uncertainty. The second phased stra tegy is Ph(MCSS,CCSS) and has the same form as the first, but uses MCSS to generate membership queries. Of course, MCSS can  X  X tall X  if the current solution is such that minimax optimal and adversari al prod-ucts are V -certain. In such a case, a comparison query is asked. As such, we can view Ph(MCSS,CCSS) as a form of interleav-ing (see below), but with an absolute preference for members hip queries if an MCSS-membership query is not vacuous. Our inter-leaved strategies ask membership queries if concept regret exceeds reward regret at the current solution, and a comparison quer y if re-ward regret is greater. They always use CCSS to generate comp ar-isons; but the first, I(H,CCSS) , generates membership queries via halving, while the second, I(MCSS,CCSS) , uses MCSS. Finally, the CCM strategy uses our combined comparison-membership queries , using CCSS to generate the comparison, and asking membershi p queries of both alternatives, x  X  and x a .
We experimented with the five query strategies above, compar -ing them on randomly generated configuration problems. Quer ies are posed to simulated users, each of which possesses a rando mly generated utility function and subjective feature used to a nswer queries. We measured the effectiveness of our strategies by the con-sidering regret reduction in function of the total number of queries.
Large configuration problems were randomly generated, defin ed on 30 variables with 90 random binary constraints; and conju nctive concepts were generated from a pool of 10 variables, with an a v-erage concept size of 6.67 conjuncts. Fig. 1 illustrates the results when the bonus weight bound set to 10% of the utility uncertai nty.
We see that both interleaved strategies dominate the phased strate-gies by a significant margin. Both interleaved strategies st art by asking the same comparison queries, so their effectiveness is iden-tical until the concept regret becomes dominant. When this h ap-pens, MCSS membership queries are more effective than halvi ng queries, but only by a small margin. After 80 queries, max reg ret is reduced to about a third of its original value. In contrast, t he phased strategies fail to reduce regret significantly. The combine d strat-egy CCM performs worse than the interleaved strategies, but is still better than either phased approach. In this strategy each in teraction counts as three queries, since the user must answer a compari son and two membership queries. However, one asks about the same three outcomes, thus the cognitive cost might be significant ly less than 3 queries. A  X  X eftward compression X  of the CCM curve wou ld make the strategy seem somewhat more competitive.

The number of queries asked is quite small given the size of th e product space (30 vars) and the complexity of the concept (av g. 6.67 vars). The anytime profile is also very encouraging with max regret of the recommended product dropping by about half in 2 0 queries using interleaved strategies. Experiments on smal ler prob-lems often require far fewer queries. It is also important to note that max regret is an upper bound on actual error: experiments mea sur-ing true regret of the recommended product (w.r.t. the user X  X  true utility function) show that it is typically much lower than m ax re-gret. Finally, we observe that minimax regret computation i s ini-tially very fast (less than 1 s.), but is greatly affected by c onditional constraints (with 50 comparisons, regret computation take s more than a minute). From this perspective, the CCM query strateg y of-fers the fastest computation time.

Our results suggest that MMR is a robust means of determining good decisions in the face of simultaneous utility and featu re un-certainty and an effective driver of elicitation: the flexib ility of our interleaved strategies is advantageous. More refined heuri stics for selecting queries could make these even more robust.
We have presented a model for preference elicitation that al lows a user to define her own subjective features over which she can express her preferences. Our interleaved strategies are es pecially effective at simultaneous elicitation of concepts and util ities, us-ing regret to make appropriate choices among the different t ypes of queries. Furthermore, optimal or near-optimal product r ecom-mendation is generally possible with far from complete conc ept definitions and utility information.
 A number of important directions for future research remain . Further development of query strategies is critical. Addit ional em-pirical and theoretical analysis of tradeoffs between memb ership and comparison queries is ongoing, as is the generalization of our models to richer hypothesis spaces, and additional forms of concept and utility queries.
