 Barry Smyth  X  Evelyn Balfe
Abstract We present an innovative approach to Web search, called collaborative search , that seeks to cope with the type of vague queries that are commonplace in Web search.
We do this by leveraging the search behaviour of previous searchers to personalize future result-lists according to the implied preferences of a community of like-minded individuals.
This technique is implemented in the I-SPY meta-search engine and we present the results of a live-user trial which indicates that I-SPY can offer improved search performance when compared to a benchmark search engine, across a variety of performance metrics. In addition,
I-SPY achieves its level of personalization while preserving the anonymity of individual users, and we argue that this offers unique privacy benefits compared to alternative approaches to personalization.

Keywords Web search . Social search . Personalization 1. Introduction
The World-Wide Web represents a formidable information retrieval (IR) challenge. Every day approximately 60 terabytes of new content, in a wide variety of formats, is added to its 10 billion or so indexable pages, without any real quality control (Roush, 2004); to put this in perspective, the print collections of the U.S. Library of Congress account for about 10 terabytes. Web search engines are the main way that end-users locate information within this dynamic information space. Commercial search engines have evolved rapidly beyond their IR origins to take specific advantage of the unique characteristics of the Web, and the particular way that Web users search for information. For instance, early on researchers recognised the advantages of combining the results of many individual search engines to produce so-called meta-search engines with improved coverage and accuracy characteristics (Dreilinger and
Howe, 1997; Selberg and Etzioni, 1995). More recently, Google (Brin and Page, 1998) has famously incorporated information about the Web X  X  topology X  X he connectivity of individual pages X  X s a way to recognise and rank authoritative pages; Kleinberg X  X  Clever system (Kleinberg, 1998) also uses connectivity information in a complementary manner.

For all the successes of modern Web search, many challenges remain and current search engine technology is struggling to match the needs of today X  X  searchers. One of the most pressing problems has to do with the type of queries that are commonplace in Web search:
Web users are not information retrieval experts and as a result they tend to formulate poor queries that do not adequately capture their search needs, often omitting important contextual cues that are required to focus search. For example, does the query  X  X aguar X  refer to the car, the cat or the operating system? Or does the query  X  X ichael Jordan X  refer to the basketball star, the Berkeley professor or the EDS chairman? These vague queries play havoc with the term-matching technology at the heart of all Web search engines, and studies indicate that the average Web query contains only 1 to 3 terms, so vague queries such as the above are commonplace (Lawrence and Giles, 1999a). As a way of addressing this problem many researchers have recently focused on ways to exploit context in Web search as a means of resolving the ambiguity associated with vague queries; see for example the work of (Lawrence, 2000; Glover et al., 2001; Eric J. Glover, 2001; Budzik and Hammond, 2000; Haveliwala, 2002; Rhodes and Starner, 1996) which builds upon on earlier initiatives by the IR community, such as (Croft and Thompson, 1987; Fox, 1987).

In this paper we will describe a novel approach to Web search, called collaborative search , which also seeks to address the vague query problem by using context-sensitive and personalized search techniques. We do this by inferring implicit context information from communities of like-minded searchers, and we will describe how this is achieved by the
I-SPY system, a meta-search engine that personalizes its result-lists for these communities of users. I-SPY achieves this level of personalization by mining the selection patterns of similar previous searches in order to re-rank the results of future searches, promoting those results that have been selected for similar queries in the past. We use live-user data to show that significant performance advantages are possible, compared to a standard meta-search engine benchmark, and we evaluate a number of different variations when it comes to the way that similar queries are identified. Importantly, I-SPY personalizes without the need to track individual users, and therefore offers vital anonymity advantages to privacy-conscious
Web searchers. 2. Related work
Recent search engine advances have, for the most part, focused on developing ways of improving existing indexing and ranking techniques. For example, in the past few years many researchers have turned to the connectivity of Web pages as a valuable source of indexing and ranking knowledge (e.g. Brin and Page, 1998; Kleinberg, 1998). However, the prevalence of vague queries remains an important challenge facing even the leading search engines. For example, consider the intentionally vague query  X  X ava X . At the time of writing the first 200 Google results (that is the first 20 pages of results) all refered to the Java programming language, without a single reference to other meanings of the term, leaving the non-programming, coffee-loving, travel enthusiast without a relevant result. Context-based search techniques seek to remedy this problem by adding new terms to such vague queries in order to help to identify the user X  X  context or their personal preferences.

The vague query problem and the potential benefits of using context-based tech-niques have been recognised since the 1980s, in more traditional information retrieval environments, and long before the advent of Web search as we know it today. For example,
Croft and Thompson (1987) describe the I 3 R system which is motivated by the fact that user queries rarely accurately specify the type of documents that the searcher is interested in locating. I 3 R is designed to act as an expert intermediary for search and includes a range of features aimed at helping the system to acquire better descriptions of a searcher X  X  informa-tion needs. I 3 R  X  X  query formulation phase attempts to elaborate a searcher X  X  initial query by developing a request model that includes information from the system X  X  domain knowledge and user models. This additional information serves to contextualise the initial query and has been shown to improve the effectiveness of I 3 R  X  X  core search strategies; see also the work of Fox (1987) for related early work on context in information retrieval systems.
Of course relative to more traditional information retrieval environments, which benefit from controlled document collections and more sophisticated searchers, the vague query problem is even more acute in Web search, and as a result researchers have recently returned to the ideas of context-based search with renewed enthusiasm (see also Lawrence, 2000). One of the central themes of this research area concerns the identification of the context terms that are to be used to influence search. Two basic approaches have come to dominate according to whether the terms are explicitly provided by the user or search engine, or whether they are implicitly inferred from the local search environment. We will review both of these strategies in the following sections together with complementary work on query reuse and we will also consider the important issue of user privacy in the light of techniques that propose to profile user preferences as a route to improved search. 2.1. Capturing explicit context
Perhaps the easiest way to identify relevant context terms is to simply ask the searcher to provide them as part of their query. For example, the meta-search engine Inquirus 2 (Glover et al., 2001) expects searchers to select from a set of search categories such as  X  X esearch paper X  or  X  X omepage X  that are provided as part of the search interface and then uses the selected context categories to choose target search engines for the user X  X  query. The category information can also be used for query modification (e.g. a query for research papers on  X  web search  X  might be modified to include terms such as  X  references  X ).

At the time of writing, Google had just launched its prototype personalized search service ( labs.google.com/personalized ), designed to use information about a user X  X  personal prefer-ences to guide search. This preference information is explicitly captured by requesting the user to complete a preferences form by selecting from among a variety of basic categories and Google uses these terms to re-rank a limited set of search results (the first page of results only), promoting results that relate to these categories.

An alternative way to capture context explicitly is through the use of a specialised search engine whose index has been designed to cover a restricted information domain (e.g. www.invisibleweb.com, www.MP3.com, www.ireland.com etc.). By opting to use such an engine the searcher is broadly establishing their the context prior to searching. Some spe-cialised search engines automatically maintain their indexes by using information extraction techniques to locate and index relevant content (Kushmerick, 1997). Good examples include
CiteSeer (Lawrence and Giles, 1999b), for searching scientific literature, and DEADLINER (Kruger et al., 2000), for conference and workshop information. For example, CiteSeer crawls the Web looking for scientific articles in a variety of document formats (HTML, PDF, Postscript etc.) and builds an index that is well suited to literature searching. 2.2. Inferring implicit context
Of course expecting searchers to provide context information explicitly as part of their search is not ideal. Many users are simply unwilling to provide this type of additional information and even asking for it can lead to frustration X  X ertainly asking the user for anything close to personal information is liable to alienate many users because of legitimate privacy concerns (see Kobsa (2002) and Section 2.3). Moreover, searchers often do not have enough knowledge available to them to explicitly express such context information even if they were inclined to do so; this refers to the so-called labelling effect where searchers often formulate their queries in a compromised way causing their interests to be misrepresented to an intermediary (the search engine in this case); (see Ingwersen, 1992). As a result many researchers have focused on ways to discover context information by less intrusive means, by automatically inferring the information from the searchers behaviour and from external or local context sources.

A key intuition in this regard is that searchers rarely perform searches in isolation. It is more likely that the search will be related to some other task that the searcher is currently engaged in, such as reading a Web page, replying to an email, or writing a document. During this time the user may need to perform a search which is related to the core activity and by taking advantage of a user X  X  activity immediately prior to the search it may be possible to determine a suitable search context. This is the objective of systems such as Watson (Budzik and Hammond, 2000), the Remembrance Agent (Rhodes and Starner, 1996), IntelliZap (Finkelstein et al., 2001) and Letizia (Lieberman, 1995).

Watson and the Remembrance Agent provide just-in-time information access by deriv-ing context from everyday application usage. For example, as a user edits a document in
Microsoft Word, or browses in Internet Explorer, Watson attempts to identify informative terms in the target document by using a heuristic term-weighting algorithm. If the user then searches with an explicit query, Watson modifies this query by adding these newly derived ment that he/she is viewing, and the search is then guided by the text in the local region of the marked query terms; this local text serves as a definition of the user X  X  implied context.
Similarly, Letizia analyses the content of Web pages that the user is currently browsing, extracting informative keywords using similar term-weighting heuristics, and proactively browsing assistant than a search assistant but it does exploit context in a similar manner; incidentally, Watson can also operate in this mode by continually searching the Web for related documents based on query terms extracted from the current document that the user is working on.
 The work of Haveliwala (2002) proposes a method that uses categories from the Open
Directory Project (ODP) (www.dmoz.org) as a source of context to guide a topic-sensitive version of PageRank (Brin and Page, 1998). Briefly, the URLs below each of the 16 top-level ODP categories are used to generate 16 PageRank vectors that are biased with respect to each category. These biased vectors are used to generate query-specific importance scores for ranking pages at query-time that are more accurate than generic PageRank scores. Similarly, for searches performed in context (e.g. when a user performs a search by highlighting words in a Web page), context-sensitive PageRank scores can be computed based on the terms and topics in the region of the highlighted terms.

The above all use external sources of context. Techniques also exist for the exploitation of local sources of context by using the results of a search as the basis for context assessment, extracting useful context terms that can then be used to supplement the user X  X  original query.
Typically these context terms are those terms that are highly correlated in the initial search results. For example, the technique proposed by (Mitra et al., 1998) extracts correlated terms from the top-ranking search results to focus context on the most relevant search results as opposed to the entire set. This idea of using the local search context can be extended beyond a single search episode. Many users will perform a sequence of searches on a specific topic and their response to the results can provide valuable context information. Thus, by monitoring and tracking queries, results and user actions it may be possible to model search context over an extended search session or even across multiple search sessions. For example (Bharat, 2000) describes the SearchPad system which extracts context information, in the form of useful queries and promising result-lists, from multiple search sessions. Similarly, (Bradley et al. 2000) describes the CASPER search engine for job advertisements, which maintains client-side user profiles that include job cases that users have been liked and disliked in previous searches. These profiles are used to classify and re-rank the results of future searches. For example, CASPER can learn that a given user is interested in Dublin software-engineering jobs that require more than 5 years experience because in the past they have liked job cases in the Dublin region and consistently avoided jobs with lower experience requirements. 2.3. Personalization vs. privacy
It should be clear from the above that many attempts to improve search quality are based on the idea that improved search results can be offered to the user if additional information about the user (their context or personal preferences) can be determined. One issue that is all too often swept aside, in the quest for more personalized or context-sensitive search techniques, is the issue of privacy (Kobsa, 2002). For example, in all of the approaches discussed above, especially those concerned with capturing information about the individual user, the issue of privacy will come to play a central role in any determination of which techniques are likely to prove successful beyond the research laboratory. Indeed the willingness of users to be profiled in a laboratory environment is often mistaken as their tacit acceptance of profiling in the main. We believe that this is an unwise assumption to make and in our opinion it is unlikely to hold true in the real-world.

If we are to bring personalized or context-sensitive search techniques to the Web on a large-scale then it is likely that privacy will play a vital role. Indeed we believe that any technique that requires users to explicitly provide information about their personal preferences, or any technique that appears to track user behaviour on a user-by-user basis, is only likely to be acceptable to an extremely restricted audience; the vast majority of privacy-conscious Web users choosing their anonymity over improved search accuracy. For instance, up to 87% of users indicate that they are very concerned about privacy threats on the Internet and 41% of users claim to have left sites that require registration information, with many users admitting to having faked the information that they have provided; (see Kobsa, 2002) for a recent review of privacy and personalization. It is worth noting that many governments are introducing (or have already introduced) data protection laws that may ultimately outlaw many approaches to personalization that require the maintenance of rich user profiles, or at best require users to provide their explicit consent for such information to be recorded or used; see for example www.dataprivacy.ie .

The real goal then must be to offer users search improvements that provide the right balance search technique may offer a unique advantage: by combining a level of personalization (community personalization rather that personalization for the individual) with effective anonymity, collaborative search can offer improved search quality without compromising privacy. 3. Collaborative web search
Our approach to Web search is inspired by the hypothesis that like-minded searchers tend to use similar queries to look for similar information items and they tend to select similar results in response to these queries. Consequently, we believe that when responding to a new search query a search engine should be informed by the past selections of searchers for any similar queries X  X hat by doing so it will be possible to deliver a search service that is better adapted to the needs of these searchers X  X nd in this section we will describe our approach as it is implemented by the I-SPY search engine.
 3.1. Architecture and method Fig. 1 outlines the basic I-SPY architecture. Technically I-SPY is not a search engine at all.
It is a meta-search engine, drawing on the results produced by a set of underlying search engines (in our implementation these include Google, HotBot, WiseNut, AllTheWeb among others). Thus, when I-SPY receives a new query, qT , from some user, it submits this query to each of its underlying search engines ( S 1 ,..., S n ) and combines the result-lists that are returned ( R 1 ,..., R n ). To do this I-SPY must first adapt the new query so that it conforms to the query interface of the underlying search engine. In addition, the result-lists returned by each underlying search engine are transformed into a common result format, to produce a modified set of result-lists ( R 1 ,... R n ), so that they may be combined into a single result-list.
This combination process is similar to the manner in which standard meta-search engines combine separate result-lists. Specifically, for each result r we calculate its score for a specific result-list R k to be its position in that result-list; where the first result in a result-list is at position 0. If r is not present in R k then its score for that list is set to be the size of the result-list, | R k | ; see Eq. (1).

In practice we configure I-SPY to retrieve a preset maximum number of results from each of the underlying search engines and the overall score for a result r is calculated as a normalised sum of its scores for each of the transformed result-lists R
The combined result-list ( R m ) produced is then ordered by increasing overall scores. In this way, results that appear high-up in the result-lists of many search engines are preferred over results that appear lower-down in the result-lists or results that are not present in many result-lists.
 Overall Score ( r , R 1 ,..., R n ) =  X  k = 1 ... n
I-SPY X  X  key innovation stems from its ability to personalize search results by re-ranking result-lists based on the selection history of previous searchers, effectively transforming the meta-search result-list R m in to a modified result-list, R more likely to be relevant to q T , on the basis that they have been selected for this and similar queries in the past, are promoted within the combined result-list. Indeed, results that have been selected in the past, but that might not be present in the combined result-list, can also be included and promoted. When a result is selected by a user in response to a query we can assume a certain level of interest by the user in that result for that query. And if certain results are consistently selected for certain queries then we can assume a certain degree of relevance.
To achieve this we rely on the following key features, which we will elaborate in the following sections. 1. The ability to store the anonymous interaction patterns of searchers in terms of the queries that they submit and the results that they select. 2. The ability to locate past queries and result selections that are related to a current query. 3. The ability to rank search results based on the relevance of these results, to the current query, in terms of their selection histories over a set of similar queries. 4. The ability to separate the interaction patterns of different communities of searchers. 5. The ability to provide this level of personalization without the need to profile individual users in such a way that their identity of privacy needs to be compromised. 3.2. Profiling search histories
The hit-matrix, H , is a key data structure for I-SPY. It is a record of the results selected in past search sessions. Each time a searcher selects page ( p j ) for some target query ( q H is incremented. Thus, H Tj can be viewed as the number of times that p as a result for query q T . The row of H that corresponds to q of the relative number of all page selections for this query over all search sessions that have used this query. It is important to note that there is no record kept of the individual users that have performed the searches or made the resulting selections. Thus search histories cannot be related back to individual users; an individual row of the hit-matrix is likely to be made up of the search histories of many different users, but none of these users can be identified from the recorded information.

Importantly, I-SPY maintains separate hit-matrices for separate communities of users; see Section 3.5. This limits the growth of each hit-matrix according to the activity-level and scope of a particular community of users. For example, a small community of users with a narrow topic focus might result in the evolution of a modest hit-matrix of per-haps a few thousand queries and page selections. Larger, more broadly focused commu-nities are likely to result in the development of much larger hit-matrices with perhaps tens or hundreds of thousands of queries, although relevant page selections, in our ex-perience, tend to remain limited. The query-page hit-matrix data-structure is closely re-lated to the type of term-document index tables maintained by standard search engines, although this latter type of index is obviously likely to be many orders of magnitude larger than any of I-SPY X  X  community focused hit-matrices. In addition the hit-matrix structure can be efficiently implemented in modern databases and offer enterprise-level scalability.
 An important issue in relation to the hit-matrices concerns their maintenance over time.
For example, in reality Web pages change frequently and their relevance to certain queries may change over time as a result. In addition, older pages are likely to have gathered more hits than newer pages and so will be at a distinct advantage when it comes to relevance calculation and promotion, even if they are not as relevant as a newer page.
To cope with this problem in I-SPY we propose to decay hit-values over time so that older pages must continue to be selected if they are to maintain their relevance values.
If they have become obsolete then users are unlikely to select them and so their hit-values will gradually diminish until such time as they are no longer promoted for the query in question.

A related maintenance issue concerns the presence of pages that have been deleted from the Web. Such pages may remain in the hit-matrix for some time after their deletion, and may be selected by users if promoted. Obviously the continued promotion of non-existent pages is undesirable and the solution for I-SPY is to provide for a garbage-collection type facility that periodically validates all those pages that are stored in the various hit-matrices.
Obviously a similar strategy is regularly adopted by standard search engines, although I-SPY benefits from the need to consider a much smaller subset of pages to validate since only those pages that have been selected by users are actually stored in its hit-matrix. In addition the relative hit-values associated with pages can be used to prioritise pages for validation, so that pages that have been frequently selected in the past are checked more often than less popular pages.
 3.3. Reusing similar queries
When a searcher submits a new target query ( q T ) I-SPY must first locate each row of the hit-matrix that relates to a similar candidate query; these are the rows that contain search behaviours that may be useful to guide the ranking of the new result-list. To do this we compute the overlap between the terms used in q T and the terms used in each candidate query q c recorded in the hit-matrix, as shown in Eq. (3); see Section 5 for further discussion on query similarity.

Sim ( q T , q c ) =
I-SPY then selects all queries that exceed a given similarity threshold to produce its list of related queries. For instance, setting a similarity threshold of of all queries that share at least one term with the current query. Of course, such a lenient threshold is likely to result in the selection of unrelated queries which may interfere with result quality. Alternatively we could configure I-SPY to select the top Q queries rather than all queries above a certain similarity threshold. We will return to this issue in a later section. 3.4. Result relevancy
The relevance of a result-page, p j , to a query, q T , can be estimated directly from the hit-matrix entries for q T . Equation (4) calculates relevance as the number of page selections that have occurred for p j in response to query q T (that is, H number of page selections that have occurred for all pages selected in response to q is,  X  i H Ti ). For example, a relevance of 0.25 for p j and q selections from result-lists for q T have been for this page, p Relevance ( p j , q T ) =
I-SPY X  X  key innovation is this ability to exploit the hit-matrix as a direct source of relevancy information; after all, the hit-matrix entries reflect the level of interest that users have had in given pages and can be interpreted as concrete relevancy judgments by users with respect to query-page mappings; of course some of these selections may not be reliable relevance indicators but we argue that reliable selections are likely to dominate in the main and are readily identifiable as consistent selections for certain pages with respect to certain queries.
Most search engines, on the other hand, rely on indirect relevancy judgments based on overlaps between query and page terms.

Of course if multiple similar queries are available and selected for a target query, then there are potentially multiple search histories to inform the relevance of a given page. For example, the page www.sun.com may have a high relevance value (let X  X  say, 0.8) for a past query  X  X ava language X  but it may have a lower relevance for another past query  X  X ava X  (let X  X  say 0.33). It is then a matter of combining these individual relevance values to produce a single relevance score for this page relative to the target query, say  X  X ava inventor X .
We propose a normalised weighted relevance metric that combines the relevance scores for individual page-query combinations. This is achieved using the weighted-sum of the individual relevance scores, such that each score is weighted by the similarity of its corre-sponding query to the target query. Thus, in our example above, the relevance of the page www.sun.com is 0.516: the sum of 0.264 (that is, 0.8 page relevance to query  X  X ava language X , multiplied by the 0.33 query similarity between this query and the target,  X  X ava inventor X ) and 0.165 (0 . 33  X  0 . 5 for the past query,  X  X ava X ), divided by 0.83, the sum of the query similarities.
Equation (5) provides the details of this weighted relevance metric with respect to a page, p a target query, q T , and a set of retrieved similar queries q a flag that is set to 1 when p j is one of the result pages selected for query, q 3.5. Communities and collaboration
The above approach is likely to work as long as the query-space is limited to a relatively narrow and uniform context. One of the fundamental ideas in I-SPY, and the reason for the term  X  X ollaborative search X , is that a hit-matrix should be populated with queries and selections from a community of users operating within a specific domain of interest. As such
I-SPY facilitates the creation of multiple hit-matrices. This affords different communities of users access to a search service that is adapted for their query-space and its preferred pages.
For example, a motoring Web site might configure a hit-matrix for its users. I-SPY facilitates this through a simple form-based Web interface and in doing so, provides the Web site with access to a search interface that is associated with this new hit-matrix. In this way the visitors to this motoring site form an ad-hoc community. As the community uses its search service, their queries and page selections will populate the hit-matrix and I-SPY X  X  ranking metric will help to disambiguate vague queries by promoting previously preferred pages for repeated queries. The query  X  X aguar X  is likely to result in the prioritisation of pages related to the car manufacturer rather than sites related to wildlife or the Apple operating system: previous searches for this term are far more likely to result in the selection of these car pages since the users will have been searching from a motoring Web site.

A large Web portal might create a range of different hit-matrices, and place corresponding search boxes in different parts of the portal (e.g. News, Sports, Entertainment, Business sections) on the grounds that searchers are more likely to submit queries that are related to the content that is found within this portal section. Alternatively, more formal communities of searchers can be formed by setting up private I-SPY groups that are only made accessible to individuals by invitation. 3.6. An example
By way of an example, Figs. 2 X 4 show a number of screen-shots of the I-SPY system. They come from an I-SPY community associated with a certain laboratory of HDip and MSc students within the Department of Computer Science at University College Dublin. Thus, when users of this laboratory use I-SPY, their queries and result selections update a specific hit-matrix. Fig. 2 presents the I-SPY homepage for the HDip/MSc community. It looks and operates like a normal search engine start-page, with a standard text box for queries. However in addition, the community members are with a range of search information that is related to their community. For instance, lists of the community X  X  recent and popular queries, and those Web pages that have been recently selected or commonly selected in response to queries, are shown. In addition, lists of other popular and recently accessed communities are also shown.
The user can replay these queries, select the web pages, or join other communities directly from these lists.

The query and Web pages lists provide a useful way for users to understand recent search activity within their own community. And the community lists help users to appreciate if other communities exist that might help with more specialised queries that they might have.
For example, one of our HDip/MSc students might be better using the  X  X ava programming language X  community if they have a java specific query. A user can view longer versions of these lists by selecting the  X  X iew all X  buttons. Finally, it is also worth highlighting the  X  X rivate X  tick-box beside the query-box. This allows users to exclude their search queries from being presented to other community members.

Figs. 3 and 4 show the different I-SPY results for the query  X  CBR  X  (indicating case-based reasoning). The results in Fig. 3 were generated shortly after this community was established, before any significant search behavior was tracked, and consequently its results are not personalized to this community X  X  needs, showing a range of interpretations of  X  X BR X ; in fact none of the top results relate to case-based reasoning. In contrast, Fig. 4 shows the results for the same query after the community had been in operation for a number of weeks, by which time significant search activity had been logged by community members on a range of topics. This allowed I-SPY to adapt to the query-result patterns of the community and we see that now all of the top-listed results relate to case-based reasoning because of the past searches carried out by the HDip/MSc students.

The top-listed results have been promoted from far down the  X  X BR X  result-list or the result-lists of related queries; promoted results are indicated with the I-SPY  X  X yes X  icons beside their titles. For example, the top result (the popular AI-CBR portal) was promoted from position 15 in the original, non-personalized result-list. As an aside, we also see that results can be associated with other related queries, by the community members, that have caused that particular result to be selected. For instance, Fig. 4 shows that the 3rd result has also been selected for the related query,  X  case-based reasoning  X . 4. Evaluating collaborative web search
In this section we will explore the practical benefits of our I-SPY approach. We will use live-user search data and compare I-SPY X  X  performance to a standard meta-search engine that will serve as our benchmark. Our main hypothesis is that the I-SPY approach will result in significant improvements in search performance. We believe that result precision and recall will benefit from I-SPY X  X  intelligent reuse of previous search histories and that reuse of any irrelevant queries will be easily compensated for by a greater number of relevant, related queries in a typical search session. 4.1. Trial setup
The data used in this evaluation was collected during a live-user experiment that involved 92 computer science students from the Department of Computer Science at University Col-lege Dublin in October 2003. The experiment was designed to evaluate the benefits of the
I-SPY system relative to a standard meta-search engine, and in the context of a fact-finding or question-answering exercise. To frame the search task, we developed a set of 25 general-knowledge AI and computer science questions, each requiring the student to find out a particular fact (time, place, person X  X  name, system name etc.); see Table 1 for sample ques-tions. We chose to ask these fact-finding questions rather than broader questions in order to facilitate the easy recognition of correct results, that is, result pages that contained a correct answer to a specific question. In addition most search engines are relatively good at locating relevant results for fact-finding tasks rather than more open-ended searches.

The students were randomly divided into two groups. Group 1 contained 45 students and Group 2 contained the remaining 47. Group 1 served as the training group for I-SPY; although their search histories were used to populate the I-SPY hit-matrix, no re-ranking of their search results occurred. This group also served as a control against which to judge the search behaviour of the second group of users, who served as the test group .

Each group formulated their own queries based on the test questions and searchers were allowed to submit as many query variations as necessary in order to locate a desired answer.
Students were permitted to skip questions if they so desired and were allowed to attempt questions in any order; each student received a random ordering of questions to begin with.
In total the Group 1 users produced 1049 individual queries and selected a combined total of 1046 pages, while the Group 2 users used 1705 queries and selected 1624 pages. In terms of the type of queries used by the trial users we find that the Group 1 users used an average of 2.5 terms per query, whereas the Group 2 users used slightly fewer terms (2.2) per query.
As a result we can expect these queries to be vague; 2 or 3 query terms are rarely sufficient to specify a user X  X  search requirements.

The log-data from this live-user trial provides the following key information: the queries submitted by each user; the pages that they selected from the subsequent result-lists; the position of these pages within the result-list; the pages where they located a correct answer to a particular question; and the hit-matrix produced by the Group 1 users. This data forms the basis of our current evaluation. We  X  X e-run X  the live-user experiment to test different query thresholds, allowing I-SPY to base its results on different numbers of related queries.
Specifically, we use 5 variations of I-SPY that work by retrieving the top Q most similar queries (or cases ) in each search session as a source of result-selection data, where Q is set to 1, 5, 10, 15, or 20. Each Group 2 user query is replayed and the I-SPY results (for the different Q thresholds) are computed and compared against a ground-truth of known correct results for each query. This ground-truth was independently prepared by manual inspection of the live-trial result-lists. It provides a strong measure of relevance in the sense that we only consider a page to be relevant for a query if it contains the correct answer to the test question that the query was designed to satisfy. Obviously, weaker notions of relevance might have been considered; a page might have been partially relevant without necessarily answering the target question. However, we believe that it is appropriate to focus on this stronger measure of relevance, given the search task used in our evaluation. 4.2. Successful searches and failed sessions
Perhaps the most basic measure of search engine accuracy is its ability to return a single relevant result (a result that contains the answer to the target question) in a result-list; we will look at more refined accuracy measures that focus on the number of relevant results and their positions in due course, but for now we will focus on this minimal accuracy requirement.
To measure the overall accuracy for each search engine X  X he 5 I-SPY variations and the standard Meta-search variation described at the beginning of Section 3.1. Ee compare the full result-lists returned by these search engines, for the 1705 test set of Group 2 queries, to the list of known correct results associated with these queries (the ground-truth), and we compute the percentage of these result-lists that contain at least one correct result. Of course in reality there may be more than one correct result per question, which we will consider in the next section.

For now, the results are presented in Fig. 5 as a graph of the overall percentage accuracy against the value of Q . Each plot corresponds to a single search strategy (I-SPY vs. Meta). The plot for Meta remains flat at 65%; it is unaffected by variations in the number of queries retrieved by I-SPY. The results clearly show the accuracy benefits of the I-SPY method: at
Q = 20 and Q = 15, I-SPY returns a correct result page in 93% of sessions. This is a relative improvement of 43% over Meta.

The benefit here is derived from the fact that I-SPY is able to include additional pages beyond those found by the underlying search engines in the result-lists returned for a given query. These additional results come from the result-lists contained within the selection patterns of the related queries, and the extra results frequently contain new relevant pages. In contrast, Meta is effectively limited to those results returned by the underlying (base-level) search engines and 35% of the time (approximately 597 of the test search sessions) these results on their own do not include any results that are relevant to the user X  X  query. The additional results found by I-SPY add relevant results to many of these 597 failed sessions; in fact by increasing accuracy from Meta X  X  65 to 93%, I-SPY must be adding new relevant results to 478 (80%) of these failed sessions.

We see too that most of the I-SPY benefit, in terms of this accuracy metric at least, appears to be unlocked once we move beyond Q = 1 as our maximum related query threshold. In other words, most of the additional new relevant results are being made available from the selection histories of the top 5 or so related queries. However, it is worth pointing out that a maximum related query threshold of Q does not necessarily mean that Q queries will actually be retrieved in a given session. It is possible that this number of related queries (queries with a non-zero similarity to the target query) may not be available. To check this we graph the average actual number of related queries retrieved for different values of Q in Fig. 6. For low values of Q ( &lt; 10) the actual numbers of queries retrieved are close to the maximum set by Q , but far fewer additional related queries are found, on average, for higher values of Q .
This does not necessarily mean that there is little point in attempting to retrieve more than 10 related queries per search session. For instance, even though Q related queries per search session on average, many of the search sessions do deliver higher numbers of related queries. In fact, in the next section we will see that these higher values of
Q do result in significant increases in other measures of result-list accuracy such as precision and recall. 4.3. Precision vs. recall
The standard objective test of search engine accuracy is the precision and recall test. The former computes the percentage of returned results that are relevant while the latter computes the percentage of relevant results that are returned. We measure the precision and recall values for each of the techniques for different result-list sizes ( k
The results for the 5 I-SPY variations and Meta are presented as precision and recall graphs, in Figs. 7 and 8. As expected we find that precision tends to fall-off with increasing result-list sizes; typically the number of relevant results is much less than k , and the majority of these relevant results should be positioned near the top of result-lists. The critical point is that, once again the performance benefits due to I-SPY are clear, especially at larger values of Q . For example, in Fig. 12 we see that I-SPY X  X  best precision varies between 26% (at k = 5 and for Q = 20) to 11% (at k = 30 for the same value of Q ). This is compared to precision values between 12% and 3% for Meta. These results indicate that I-SPY benefits from a precision improvement of between 117% and 266%, relative to Meta, when retrieving the top 20 queries ( Q = 20).

The recall results tell a similar story. The recall for I-SPY (at Q imately 38% ( k = 5) to just over 95% ( k = 30). At the same result-list sizes Meta X  X  recall only grows from 16 to 25%. Obviously the I-SPY method is locating a far greater portion of the relevant pages than Meta and it is gaining access to these additional relevant pages from the result-lists of its similar queries.

In these precision and recall experiments we see that the I-SPY benefits increase with larger values of Q , the maximum number of related queries retrieved for a typical session. At
Q = 1 relatively minor precision and recall improvements are available to I-SPY, but these improvements increase significantly for values of Q = 5 and above. The benefit increases begin to level off for Q &gt; 10. We expect this because our previous analysis shows that for
Q &gt; 10, the actual number of related queries retrieved begins to level-off, so although Q allows I-SPY to retrieve an additional 5 related queries per search, compared to the Q setting, in reality these 5 queries are not usually available (see Fig. 6). Also, as Q increases, the similarity of the queries to the test query decreases. Thus, their reliability as providers of relevant selection results is likely to be compromised. Nevertheless, the improved precision and recall values for the highest values of Q indicate that real accuracy improvements are available at these thresholds. 4.4. Overall accuracy
To compliment the precision and recall results above, and in recognition of the normal trade-off that exists between precision and recall, in this section we look at two common performance metrics that seek to combine precision and recall into a single performance metric in a way that balances precision and recall. The first is the well-known F-measure (VanRijsbergen, 1979), which computes the harmonic mean between precision and recall; see Eq. (6). The second is the breakeven point , which is the point at which precision equals recall.

F  X  measure = 2
The F-measure and breakeven point results are presented in Figs. 9 and 10. In each graph that normally the breakeven point is not present in experimental data, and so the results presented here have been produced by interpolating between the actual precision and recall data available. In both cases the experimental results help to clarify the benefits of I-SPY X  X  collaborative search technique. The F-measure scores for I-SPY (at Q (at k = 5) and 3.8 (at k = 30) times greater than the Meta F-measure scores. Similarly, the maximum breakeven point for I-SPY (which occurs for the Q 3 times greater than Meta X  X  breakeven point. 5. Beyond simple query similarity
So far we have assumed a basic model of query similarity, namely the term overlap metric (as shown in Eq. (3)). In this section we will describe and evaluate a number of feasible alternatives that fall into two basic categories: Term-based techniques estimate query simi-larity by examining the differences between the terms used in two queries; Behaviour-based techniques, on the other hand, examine the results of searches or, more accurately in our case, the behaviour of searchers in terms of the results they select for queries. 5.1. Term-based query similarity
Examining the terms of two queries is perhaps the most obvious way to measure their similarity. The overlap metric is just one way to do this by measuring the proportion of shared terms between queries. But this metric appears to be far from satisfactory. For example, it makes no attempt to consider term-order during similarity assessment. In addition, the simple overlap metric views individual terms as atomic units and as such cannot cope with minor term variations such as plurals; for example,  X  X nternet inventor X  is deemed to be only 50% similar to  X  X nternet inventors X .

Using the well-known Levenshtein Distance (LD) (also known as edit-distance ) metric, as an alternative, is one way to address these issues. The LD of two strings is the minimum number of edit operations needed to transform one string into the other where an operation is either an element (in this case an individual character) insertion, deletion or substitution. For example, the LD between  X  X iver Phoenix Pictures X  and  X  X hoenix Pictures River X  is 18.
We propose the use of a normalised version of LD, as shown in Eq. (7), which measures the similarity between a target query, q T , and a related query, q related queries, q 1 ,..., q n which share at least one term in common with q
Edit Distance ( q T , q i ) =
We can also combine the similarities produced by these two term-based metrics to produce instance, we propose to combine them using the harmonic mean so as to give preference to those queries that enjoy high term-overlap values and high edit-distance values X  X ee
Eq. (8) X  X nd penalising those queries that suffer from differing overlap and edit-distance scores.
 Harmonic Mean ( q T , q i ) = 5.2. Behaviour-based query similarity
The data that I-SPY collects on the search behaviour of its communities permits another type of query similarity approach, one that considers two queries to be similar if they result in the same type of user behaviour. For instance, we might consider two queries to be similar if users tend to select the same results from their respective result-lists. Accordingly we propose two behaviour-based metrics. The first is another simple overlap metric: the similarity of two queries is estimated by the percentage overlap between the sets of pages that have been selected for these queries, during past search sesssions. We call this the Page Overlap metric and it is presented as Eq. (9) between a target query, q T
Selecti on Set ( q ) refers to the set of pages that have been previously selected for query q ; that is the set of pages that have hit values in the hit-matrix for q .

PageOverlap ( q T , q i ) =
This page overlap metric is not without its problems. For instance, it gives no credit to the relative number of times that individual result pages have been selected for the two queries.
Hence, we propose an alternative that uses the correlation between the number of times that overlapping pages have been selected for two queries as a measure of query similarity. We call this the Page Correlation metric as shown in Eq. (10). In this formula Correl refers to the standard Pearson X  X  correlation formula, the set p 1 ,..., that have been selected for both q T and q i and H i , k refers to the number of hits that p received for q i .
 PageCorrelation ( q T , q i ) = Correl ( { H T , 1 ,..., H 5.3. Evaluating query similarity metrics
The above suggests 5 different similarity metrics, 3 that are term-based and 2 that are behaviour-based. While many of these are proposed in the hope of improving upon the standard term-based overlap benchmark, it is not yet clear to what extent they will deliver such performance improvements, if indeed they will at all. In this section we will consider this by evaluating each of these metrics by repeating the experiments described in Section 4. 5.3.1. Methodology
Accordingly, we  X  X e-run X  the live-user experiment by responding to Group 2 queries with a new set of result-lists that are recommended by 5 versions of I-SPY that use the 5 different query similarity metrics. Once again, we also consider the result-lists that correspond standard meta-search engine, as a baseline against which to judge the relative impact of I-SPY X  X  result promotion and re-ranking.

In keeping with our earlier evaluation, we test our different metrics for different query selection thresholds, this time limiting I-SPY to the selection the top 5, 10 and 20 related queries. Thus, each Group 2 test query is replayed and the results (for the different Q thresh-olds) are computed and compared against the ground-truth of known correct results for that query. 5.3.2. Overall accuracy
Once again we start by examining the ability of each variation of I-SPY to return a result-list that contains at least one relevant result (see Section 4.2). To measure this for each technique ( Overlap, EditDist, Harmean, PgOverlap, PgCorrel and Meta ), we compare each of the full result-lists returned for the 1705 test queries, to the list of known correct results associated for these queries. We compute the percentage of result-lists that contain at least one correct result among the top 30 returned.
 The results are shown in Fig. 11(a) as a graph of overall accuracy against each Q threshold.
Each plot corresponds to a single query similarity metric. As before the plot for Meta remains flat at 65%; it is unaffected by variations in the number of similar queries retrieved. Looking at the similarity-based query reuse techniques we see a general picture of improved accuracy. For example, Overlap returns a correct result in at least 90% of the sessions across all values of
Q ; this corresponds to the previous results for I-SPY reported in Section 4.2. Interestingly, the new EditDist and Harmean metrics perform worse, but only slightly, achieving an accuracy of 88%. These 3 term-based techniques are clearly managing to identify similar queries and these similar queries are making useful result-list contributions above and beyond those made by the standard Meta search-engine.

The behaviour-based techniques do not perform quite so well. The PgCorrel metric achieves an accuracy of approximately 75%, still a significant improvement on Meta , but the PgOverlap metric does little better than the Meta benchmark, except at the higher values of
Q , but even then only marginally. This suggests that either the behaviour-based techniques are fundamentally less accurate measures of query similarity than the term-based methods or, alternatively, that the data they rely on is simply not rich enough to derive reliable similarity scores.

Once again we can test this by looking at the number of similar queries retrieved by each of the 5 metrics, averaged over the 1705 sessions, for each different Q threshold. The results (see Fig. 11(b)) show that there is a big difference between the term-based methods and the behaviour-based methods. The former retrieve many more related queries than the latter, on average, and this suggests that the behaviour-based techniques suffer from a lack of behavioural data on which to base their similarity estimates. For instance, at Q term-based metrics retrieve about 6 X 7 related queries on average, compared to less than 2 queries for the behaviour-based metrics. 5.3.3. Precision vs. recall
The percentage precision and recall values for each of the techniques under review are presented in Fig. 12(a, b and c) for the different values of Q . Each graph presents the plot of precision against recall for the 5 similarity metrics, along with Meta, for different sizes of result-lists, k . As expected we find that precision tends to fall-off with increasing result-list sizes; typically the number of relevant results is much less than k , and the majority of these relevant results should be positioned near the top of result-lists.

At Q = 5, the performance of EditDist is significantly better than any of the other tech-niques and it is notable that the differences in performance are most pronounced for small result-list sizes; this may make EditDist especially useful for search interfaces with limited screen-space, on mobile devices for example. In Fig. 12(a) we see that EditDist precision varies between almost 30% (at k = 5) to about 7% (at k = 30). This is compared to pre-cision values of between 24% and 6% for Overlap and values of between 12% and 3% for Meta . These results indicate that EditDist benefits from a precision improvement of be-tween 25% and 16%, relative to I-SPY X  X  default Overlap metric and between 150% and 133%, relative to Meta . The recall results tell a similar story with a relative improvement in performance for EditDist to Overlap of between 17% and 9% and to Meta of between 156% and 128%.

However, as Q increases, the performance benefits of EditDist tends to dimin-ish in comparison to the competing term-based methods and it is worth noting that when Q = 20 we see that the Overlap metric eventually outperforms the other con-tenders. In general, for all values of Q we find that the term-based techniques continue to outperform the behaviour-based metrics highlighting the fact that these behaviour-based approaches lack the availability of sufficient data to inform reliable similarity estimations. 5.3.4. The impact of Q
It appears, therefore, that the term-based similarity metrics deliver far greater performance improvements for I-SPY than the behavioural approaches. But it is not immediately obvious how the setting of Q impacts on these improvements. If we set Q to be too low then we run the risk of missing related queries with relevant result selections. But if we set Q to be too high then too many unrelated queries may be retrieved and the final result-lists may become contaminated with irrelevant pages. For this reason, in Fig. 13 we present separate graphs of precision and recall (at k = 10) for varying levels of Q .

Clearly, these results indicate that setting Q to be too low does limit its precision and recall improvements. The default I-SPY Overlap metric is especially sensitive to this. For instance the precision of Overlap grows from 16 to 21% as Q increases from 5 to 10, a relative increase of more than 30%. A similar but less pronounced increase is found for the EditDist and Harmean metrics. Interestingly a similar increase is not found when we increase
Q beyond 10 to 20. This suggests that relevant additional queries are being selected as Q is increased from 5 to 10 but that fewer relevant queries that are capable of contributing new relevant results are being selected as Q increases to 20. The behaviour-based techniques are far less sensitive to Q mainly because increasing Q beyond 5 has no real impact on the number of related queries retrieved because there simply aren X  X  enough queries with behavioural Overlaps. 5.3.5. Query terms vs. search behaviour
In summary then term-based query-similarity techniques appear to offer better performance than behaviour-based metrics, in general, and the more sophisticated edit-distance metric appears to offer some precision and recall advantages when compared the simpler Overlap metric that we have been using in the deployed version of I-SPY; these advantages are most pronounced for small result-list sizes ( k = 5) and fall away for larger result-lists ( k
However, in saying this it must be appreciated that the edit-distance metric is computationally far less efficient than simple term Overlap . This limits the practical scalability of this metric, especially the hit-matrix grows in size. For this reason we believe that the term Overlap technique is likely to offer the best compromise between search efficiency and result relevance in practice. 6. Discussion The I-SPY approach to Web search represents a significant departure from more traditional
IR-based approaches. Instead of relying solely on overlaps between query terms and docu-ment terms X  X he traditional IR perspective X  X -SPY attempts to leverage the selection patterns of users. Traditional Web search engines rely on a document index that relates document terms to documents. This index is static for a fixed set of documents. We can view the I-SPY hit-matrix as a new type of search engine index, one that relates query terms to documents and one that is constantly evolving, even for a fixed set of documents, as it tracks the selection behavior of users over these query terms. This supplementary index allows I-SPY to con-stantly adapt to its users X  behaviours and our results have clarified the potential performance benefits that this offers.

For all of its potential advantages however, the I-SPY approach introduces a new set trustworthiness of users, efficiency concerns, and, given that search behaviours are being tracked and recorded, the privacy of searchers. 6.1. Trust, reliability and DirectHit
Traditional Web search engines are open to abuse and it is relatively easy for content creators to manipulate a search engine X  X  index by loading a page with preferred keywords and index terms, regardless of the page X  X  topic. Even Google X  X  link-based indexing has been subject to abuse as authors create dummy networks to build up the PageRank of target pages. Our collaborative search technique is also open to abuse if determined users (or agents) repeatedly select target pages to give the impression of user selections.

In fact it is worth highlighting a previous attempt at leveraging user selections in the pursuit of better result rankings that fell foul to just this type of problem. In the late 1990 X  X  a search engine known as DirectHit sought to rank results on the basis of the selection popularity. However, DirectHit was a generic search engine and as such did not benefit from the community focus of I-SPY and this limited the success of its popularity based ranking approach. In addition, DirectHit was highly susceptible to malicious users and fraudulent selections.

We believe that I-SPY enjoys at least some protection in the sense that malicious users must separately target individual communities in order to influence the ranking of target results across the board. That said, obviously safe-guards are still needed in order to protect against more determined attacks and so we are currently exploring a number of options to actively protect I-SPY from malicious activity. This work ranges from simple strategies such as the discounting of sequences of selections that occur in a short period of time, or from the same source, to more sophisticated approaches to detecting malicious activity; see also related work concerned with protecting collaborative filtering recommenders from rogue users (see O X  X ahony et al., 2003). 6.2. Efficiency concerns
It may seem that I-SPY adds yet another layer of computational complexity to a world where instant search responses are demanded. However, I-SPY can be configured to deliver faster results than the underlying search engines by compiling its two sets of results X  one set from the underlying search engines (the remote results ) and one set from the hit-matrix (the local results ) X  X n parallel. The second set is computed locally and, because search engine. In this sense I-SPY X  X  hit matrix acts as a form of results-cache that is in-dexed by query terms allowing these cached local results to be returned to the user al-most immediately. And of course these local results are likely to be better candidates than the remote results anyway, because they have been considered relevant in the past for similar queries. 6.3. Profiling and privacy
One of the key objectives behind I-SPY is to offer users a more personalized search ex-perience; this is generally accepted as a key objective for today X  X  one-size-fits-all search engines. The traditional approach to personalization is dominated by what might be termed the  X  X ne-user-one-profile X  philosophy. Accordingly, most personalized information services and recommender systems track the behaviour of individual users, or request these users to provide personal profile information. The resulting profiles are then used to filter, select and recommend items of information that are likely to be preferred by individuals according to their profiled needs and preferences; for example, Google X  X  experimental foray into personal-ized search involves the searcher declaring their personal preferences up-front, as discussed earlier.

Of course the benefits of personalization come at a cost. More accurate recommendations may help us to locate relevant information more efficiently but, as individuals, we are faced with the prospect of revealing personal information to third-parties. The I-SPY approach strikes a novel and effective balance between personalization and privacy. From a personal-ization viewpoint, I-SPY offers communities of like-minded individuals the opportunity to benefit from search results that are adapted to their usage patterns and collective community preferences. Crucially this is achieved without the need for profiling at the level of individual users thereby maintaining the privacy of searchers. While the search histories of a community of users are recorded, I-SPY does not tag the search patterns of individual community mem-bers. Nor does I-SPY need to maintain a record of which members form part of a community; ad-hoc communities operate without the need for user logins, cookies or any other form of individual user tracking. 7. Conclusions
The size, heterogeneity and dynamic nature of the Web make it a challenging information retrieval environment, but Web search is made all the more difficult because searchers are prone to vague queries. In this paper we have described a technique that we call collaborative search, which is designed to address the vague-query problem by inferring context infor-mation from the search behaviour of a community of like-minded searchers. Collaborative search is a form of social search; it is sensitive to the needs and preferences of a specific community of users operating within a particular topical domain, personalizing search results for the community as a whole. Social search is an increasingly important topic for the search industry and many commentators have predicted that it will become the  X  X ext big thing X .
In this paper we have described our own implementation of social search, called I-SPY, but other similar services such as Eurekster (www.eurekster.com) are rapidly emerging to try to take advantage of this social dimension to search. Indeed, it is worth speculating about the intentions of Google in this regard, especially since they have launched their own social networking service (www.orkut.com) but have yet to announce how they plan to integrate it with the Google search engine.

Collaborative search, as implemented in I-SPY, has been shown to perform impressively in live-user trials when compared to a benchmark meta-search engine that uses leading commercial search engines as the basis for its result-lists. Although these trials have been limited to a modest number of searchers and restricted in scope to a focused search task, the results nevertheless point to a clear performance benefit when it comes to the generation of relevant result-lists. Of course the I-SPY technology can also be used to personalize the ranking of sponsored search listings, thereby offering significant business benefits to commercial search engines and sponsored listings providers.

Finally, I-SPY achieves its level of personalization in an anonymous fashion, without recording any individual user profiles. This combination of efficient personalization and effective anonymity provides I-SPY with a unique opportunity to provide a personalized search service that is likely to be attractive to search companies, listings providers and end-users alike.
 References
