 We design a space efficient algorithm that approximates the transitivity (global clustering coefficient) and total triangle count with only a single pass through a graph given as a stream of edges. Our procedure is based on the classic prob-abilistic result, the birthday paradox . When the transitivity is constant and there are more edges than wedges (common properties for social networks), we can prove that our algo-rithm requires O ( provide accurate estimates. We run a detailed set of experi-ments on a variety of real graphs and demonstrate that the memory requirement of the algorithm is a tiny fraction of the graph. For example, even for a graph with 200 million edges, our algorithm stores just 60,000 edges to give accu-rate results. Being a single pass streaming algorithm, our procedure also maintains a real-time estimate of the transi-tivity/number of triangles of a graph, by storing a miniscule fraction of edges.
 F.2.2 [ Nonnumerical Algorithms and Problems ]: Com-putations on Discrete Structures; G.2.2 [ Graph Theory ]: Graph Algorithms Algorithms, Theory  X 
This work was funded by the DOE ASCR Complex Inter-connected Distributed Systems (CIDS) program and San-dia X  X  Laboratory Directed Research &amp; Development (LDRD) program. Sandia National Laboratories is a multi-program laboratory managed and operated by Sandia Corporation, a wholly owned subsidiary of Lockheed Martin Corporation, for the U.S. Department of Energy X  X  National Nuclear Secu-rity Administration under contract DE-AC04-94AL85000.  X 
Work done while the author was interning at Sandia Na-tional Labs, Livermore.
 Streaming algorithms, Triangle counting
Triangles are one of the most important motifs in real world networks. Whether the networks come from social in-teraction, computer communications, financial transactions, proteins, or ecology, the abundance of triangles is pervasive and it is critical feature that distinguishes real graphs from random graphs. There is a rich body of literature on anal-ysis of triangles and counting algorithms. Social scientists graph mining applications such as spam detection and find-ing common topics on the WWW use triangle counts [ 18 , 7]; motif detection in bioinformatics often count the frequency of triadic patterns [ 25 ]. Nevertheless, counting triangles con-tinues to be a challenge due to sheer size of the graphs (easily in the order of billions of edges).

Many massive graphs come from modeling interactions in a dynamic system. People call each other on the phone, exchange emails, or become part of a tight unit (e.g, co-authoring a paper); computers exchange messages; animals come in the vicinity of each other; companies trade with each other. These interactions manifest as a stream of edges . The edges appear with timestamps, or  X  X ne at a time. X  The network (graph) that represents the system is an accumu-lation of the observed edges. There are many methods to deal with such massive graphs, such as random sampling [ 29 , 36 , 31 ], MapReduce paradigm [32 , 27], distributed-memory parallelism [ 4, 12 ], adopting external memory [13 , 3], and multithreaded parallelism [ 9].

But all of these methods need to store at least a large frac-tion of the data. A small space streaming algorithm main-tains a very small (using some randomness) set of edges, called the  X  X ketch X  at any given time, and updates this sam-ple as edges appear. Based on the sketch and some aux-iliary data structures, the algorithm computes an accurate estimate for the number of triangles for the graph seen so far. The sketch size is orders of magnitude smaller than the total graph. Furthermore, it can be updated rapidly when new edges arrive, and hence maintains a real-time estimate of the number of triangles. We also want a single pass al-gorithm, so it only observes each edge once (think of it as making a single scan of a log file). The algorithm cannot revisit edges that it has forgotten.
Let G be a simple undirected graph with n vertices and m edges. Let T denote the number of triangles in the graph and W be the number of wedges , where a wedge is a path of length 2. A common measure is the transitivity  X  = 3 T/W [38], a measure of how often friends of friends are also friends. (This is also called the global clustering coefficient [ 31 ].)
Formally, a single pass streaming algorithm is defined as follows. Consider a sequence of (distinct) edges e 1 ,e 2 Let G t be the graph at time t , formed by the edge set { e i | i  X  t } . The stream of edges can be thought of as a se-quence of edge insertions into the graph. (Vertex insertions can be trivially handled.) We do not know the number of vertices ahead of time, and simply see each edge as a pair ( u,v ) of vertex labels. So new vertices are implicitly added as new labels. There is no assumption on the order of edges in the stream. Edges incident to a single vertex do not nec-essarily appear together.

In this paper, we do not consider edge/vertex deletions or repeated edges. In that sense, this is a simplified version of the full-blown streaming model. Nonetheless, previous work on counting triangles focuses primarily of this model [ 6, 21, 10 , 1, 22 ].

A streaming algorithm has a small memory M , and sees the edges in stream order. At each edge e t , the algorithm can choose to update data structures in M (using the edge e ). Then the algorithm proceeds to e t +1 , and so on. The algorithm is never allowed to recall an edge that has already passed by. The memory M is much smaller than m , so the algorithm keeps a small  X  X ketch X  of the edges it has seen. The aim is to estimate the number of triangles in G := G m at the end of the stream. Usually, we desire the more stringent guarantee of maintaining a running estimate of triangles and transitivity of G t at time t . We denote these quantities respectively as T t and  X  t .
We present a single pass, O ( m/ provably estimate the transitivity (with arbitrary additive error) in a streaming graph. Streaming algorithms for count-ing triangles or computing the transitivity have been stud-ied before, but no previous algorithm attains this space guarantee. (Buriol et al [10] give a single pass algorithm with a stronger relative error guarantee that requires space O ( mn/T ). We discuss in more detail later.)
Although our theoretical result is interesting asymptoti-cally, the constant factors and dependence on error in our bound are large. Our main result is a practical streaming algorithm (based on the theoretical one) for computing  X  and T , using some additional probabilistic heuristics. We perform an extensive empirical analysis of our algorithm on a variety of datasets (many thanks to SNAP [41 ], for their extensive collection of downloadable graphs). The salient features of our algorithm are:  X  Theoretical basis: Our algorithm is based on the clas-sic birthday paradox : if we choose 23 random people, the probability that 2 of them share a birthday is at least 1 / 2 (Chap. II.3 of [19 ]). We extend this analysis for sampling wedges in a large pool of edges. The final streaming algo-rithm is designed by using reservoir sampling with wedge sampling [31 ] for estimating  X  . We prove a space bound of O ( m/ tions for social networks.
 While our theory appears to be a good guide in designing the algorithm and explaining its behavior, it should not be used to actually decide space bounds in practice. Also, we point out that for graphs where T is small, our algorithm does not provide good guarantees for small space (since m/ large).  X  Accuracy and scalability with small sketches: We test our algorithm on a variety of graphs from different sources. In all instances, we get accurate estimates for  X  and T by storing at most 40K edges. This is even for graphs where m is in the order of millions. Our relative errors on  X  and the number of triangles are mostly less than 5%. (In a graph with very few triangles where  X  &lt; 0 . 01, our triangle estimate has relative error of 12%.) Our algorithm processes extremely large graphs. Our experiments include a run on a streamed Orkut social network with 200M edges (by storing only 40K edges, relative errors are at most 4%). We get similar results on streamed Flickr and Live-journal graphs with tens of millions of edges.
 We run detailed experiments on some test graphs (with 1-3 million edges) with varying parameters to show convergence of our algorithm. Comparisons with previous work [10] show that our algorithm gets within 5% of the true answer, while the previous algorithm is off by more than 50%.  X  Real-time tracking: For a temporal graph, our algo-rithm precisely tracks both  X  t and T t with less storage. By storing 60K edges of the past, we can track this informa-tion for a patent citation network with 16 million edges [41]. Refer to Fig. 1 . We maintain a real-time estimate of both the transitivity and number of triangles with a single pass, storing less than 1% of the graph. We see some fluctuations in the transitivity estimate due to the randomness of the algorithm, but the overall tracking is fairly accurate.
Enumeration of all triangles is a well-studied problem [ 14 , 30 , 24 , 16, 8, 15 , 32, 4]. Eigenvalue/trace based methods have also been used [ 33 , 5] to compute estimates of the total and per-degree number of triangles. A long line of work on sparsification methods [ 23 , 35 , 40 , 26 ] started with Tsourakakis et al. [ 34].

Theoretical streaming algorithms for counting triangles were initiated by Bar-Yossef et al. [6 ]. Subsequent improve-ments were given in [ 21, 10 , 1, 22 ]. The space bounds achieved are of the form mn/T . Note that m/ whenever T  X  n 2 (which is a reasonable assumption for sparse graphs). These algorithm are rarely practical, since T is often much smaller than mn . (Some multi-pass streaming algorithms give stronger guarantees, but we will not discuss them here.)
Buriol et al. [ 10 ] give an implementation of their algo-rithm. For almost all of their experiments on graphs, with storage of 100K edges, they get fairly large errors (always more than 10%, and often more than 50%). Buriol et al pro-vide an implementation in the incidence list setting, where all neighbors of a vertex arrive together. In this case, their algorithm is quite pratical since the errors are quite small. Our algorithm scales to sizes (100 million edges) larger than their experiments. We get better accuracy with far less stor-age, without any assumption on the ordering of the data stream. Furthermore, our algorithm performs accurate real-time tracking. Becchetti et al. [ 7] gave a semi-streaming algorithm for counting the triangles incident to every ver-tex. Their algorithm uses clever methods to approximate Jaccard similarities, and requires multiple passes over the data.

Wedge-sampling based algorithms for various triadic mea-sures on graphs [ 29 , 31] work by sampling random wedges of the graph. These algorithms are extremely accurate, but the random sampling require the entire graph to be present. Our algorithm can be thought of as a streaming variant of wedge-sampling. The birthday paradox argument has been connected to triangle counts, but in an entirely different con-text. Alon et al [2 ] use this to prove lower bounds for finding triangles in graphs.
We begin in  X  4 by providing an intuitive high-level expla-nation of the algorithm.  X  5 gives a formal description of our implemented algorithm (denoted Streaming-Triangles ). The theoretical analysis is done in  X  6, for an idealized (and inefficient) variant called Single-Bit . We stress that Single-Bit is a thought experiment to highlight the theoretical as-pects of our result, and we do not actually implement it. In  X  6.1 , we explain the heuristics used to get Streaming-Triangles . The remainder of  X  6 gives a mathematical anal-ysis of Single-Bit .
 Finally, in  X  7, we give results on our runs of Streaming-Triangles on real graphs.
The starting point is the idea of wedge sampling to esti-mate  X  [31]. A wedge is closed if it participates in a triangle and open otherwise. Note that  X  = 3 T/W is exactly the probability that a uniform random wedge is closed. This gives a simple randomized algorithm for estimating  X  (and T ), by generating a set of (independent) uniform random wedges and finding the fraction that are closed. But how do we sample wedges from a stream of edges? Suppose we just sampled a uniform random set of edges. How large does this set need to be to get a wedge? The birth-day paradox can be used to deduce that (as long as W  X  m , pretty much always true for real networks) O ( suffice. A more sophisticated result, given in Lem. 1 , pro-vides (weak) concentration bounds on the number of wedges generated by a random set of edges. A  X  X mall X  number of uniform random edges can give enough wedges to perform wedge sampling (which in turn is used to estimate  X  ).
A set of uniform random edges can be maintained by the standard method of reservoir sampling [37]. From these edges, we generate a random wedge by doing a second level of reservoir sampling. This implicitly treats the wedges cre-ated in the edge reservoir as a stream, and performs reser-voir sampling on that. Overall, this approximates uniform random wedge sampling.

As we maintain our reservoir wedges, we check for closure by the future edges in the stream. But there are closed wedges that cannot be verified, because the closing edge may have already appeared in the past. A simple observation used by past streaming algorithms saves the day [ 21 , 10 ]. In each triangle, there is exactly one wedge whose closing edge appears in the future. So we try to approximate the fraction of these  X  X uture closed X  wedges, which is exactly one-third of the fraction of closed wedges. (Hence, the factor 3 that pops up in Streaming-Triangles .)
Finally, to estimate T from  X  , we need an estimate on the total number of wedges W . This can be obtained by reverse engineering the birthday paradox: given the number of wedges in our reservoir sample of edges, we can estimate W (again, using the workhorse Lem. 1 ).
The streaming algorithm maintains two primary sets of data: the edge reservoir and the wedge reservoir . These are sets of edges and wedges that the algorithm stores from the past. The parameters for the streaming algorithm are the respective sizes of these sets, denoted by s e and s w spectively. The main algorithm is described in Streaming-Triangles , although most of the technical computation is performed in Update (which is invoked every time a new edge appears). After processing edge e t , the algorithm com-putes running estimates for  X  t and T t . These values do not have to be stored, so they are immediately output and for-gotten. We describe the main data structures of the algo-rithm Streaming-Triangles .
Algorithm 1: Streaming-Triangles ( s e ,s w ) 1 Initialize edge res of size s e and wedge res of size s
For each edge e t in stream, 2 Call Update ( e t ). 3 Let  X  be the fraction of entries in isClosed set to true . 4 Set  X  t = 3  X  . 5 Set T t = [  X t 2 /s e ( s e  X  1)]  X  tot wedges .

Algorithm 2: Update ( e t ) 1 For every reservoir wedge wedge res [ i ] closed by e t isClosed [ i ] = true . 2 Flip a coin with heads probability = 1  X  (1  X  1 /t ) s e . If it flips to tails, stop and proceed to the next edge in stream. (So remaining code is processed only if coin comes heads.) 3 Choose a uniform index i  X  [ s e ]. Set edge res [ i ] = e 4 Determine N t and let new wedges = |N t | . 5 Update tot wedges , the number of wedges formed by edge res . 6 Set q = new wedges / tot wedges . 7 For each index i  X  [ s w ], 8 Flip coin with heads probability q . 9 If tails, continue to next index in loop. 10 Pick uniform random w  X  X  t that involves e t . 11 Replace wedge res [ i ] = w . Reset isClosed [ i ] = false . Computing  X  t and T t are simple and require no overhead. We maintain edge res as a time-variable subgraph. Each time edge res is updated, the subgraph undergoes an edge insert and edge delete. Suppose e t = ( u,v ). Wedges in N t are given by the neighbors of u and v in this subgraph. From random access to the neighbor lists of u and v , we can generate a random wedge from N t efficiently.

Updates to edge res are very infrequent. At time t , the probability of an update is 1  X  (1  X  1 /t ) s e . By linearity of expectation, the total number of times that N t is non-empty is For a fixed s e , this increases very slowly with m . So for most steps, we neither update edge res or sample a new wedge.
The total number of edges that are stored from the past is s e + s w . The edge reservoir explicitly stores edges, and at most s w edges are implicitly stored (for closure). Regardless of the implementation, the extra data structures overhead is at most twice the storage parameters s e and s w . Since these are at least 2 orders of magnitude smaller than the graph, this overhead is easy to pay for.
The algorithm called Single-Bit is an idealized variant of
Streaming-Triangles that we can formally prove theo-rems about. It requires more memory and expensive up-dates, but explains the basic principles behind our algo-rithm. We later give the memory reducing heuristics that take us from Single-Bit to Streaming-Triangles .

The procedure Single-Bit has a single space parameter s and outputs a single (random) bit at each t . The ex-pectation of this bit is related to the transitivity  X  will describe Single-Bit in a more mathematical fashion. Single-Bit maintains a set of edges R t of size s . The set of wedges constructed from R t is W t . Formally, W t { wedge ( e,e 0 ) | e,e 0  X  X  t } . For every e t , Single-Bit all wedges closed by this edge. Single-Bit maintains a set C , the set of wedges in W t for which it has detected a closing edge . (Note that this is a subset of all closed wedges in W This set is easy to update as R t changes.

Algorithm 3: Single-Bit ( s ) 1 Initialize R 0 as a set of s dummy edges. 2 For each e t in stream, 3 For each edge in R t  X  1 , replace it (independently) by e t with probability 1 /t . This yields R t . 4 Construct the set of wedges W t . 5 Let C t be the set of all wedges in W t closed by e t 6 Add all wedges in C t  X  1 to C t . If W t is empty, output b t = 0 and continue to next edge. 7 Pick a uniform random wedge in W t . 8 Output b t = 1 if this wedge is in C t and b t = 0 otherwise.

For convenience, we state this theorem for the final time step. However, it also holds (with an identical proof) for any large enough time t .

Theorem 1. Suppose s  X  cm/ (  X  3 ciently large constant c . Set est = m 2 |W m | / ( s ( s  X  1)) . Then |  X / 3  X  E [ b m ] | &lt;  X  and with probability &gt; 1  X   X  , | W  X  est | &lt;  X W .

We now show that m/ smaller for heavy tailed graphs) when W  X  m . Denote the degree of vertex v by d v . In this case, we can bound 2 W = P v d v ( d v  X  1) = P v d 2 v  X  2 m  X  P v d 2 v  X  2 W , so W  X  P v d 2 v / 4. By 2 m = P v d v and the Cauchy-Schwartz inequality, Using the above bound, we get m/ p 3 n/ X  . Hence, when W  X  m and  X  is a constant (both reasonable assumptions for social networks), we require only O (  X  Single-Bit has two main problems, which are handled in Streaming-Triangles by heuristic arguments.

Thm. 1 immediately gives a small sublinear space stream-ing algorithm for estimating  X  . The output of Single-Bit has the right expectation. We can run many independent invocations of Single-Bit and take the fraction of 1s out-put to estimate E [ b m ] (which in turn is close to  X / 3). A Chernoff bound tells us that O (1 / 2 ) invocations suffice to estimate E [ b m ] within additive error . The total space be-comes O ( m/ ( tice. Even though m/ value of = 0 . 01, the storage cost blows up by a factor of 10 4 . This is the standard method used in previous work for streaming triangle counts.

This blowup is avoided in Streaming-Triangles by reusing the same reservoir of edges for sampling wedges. Note that Single-Bit is trying to generate a single uniform random wedge from G , and we use independent reservoirs of edges to generate multiple samples. Lem. 1 says that for a reservoir of km/ get &gt; 1 / 2 wedges. Since the reservoir contains a large set of wedges, we could just use a subset of these for estimating E [ b m ]. Unfortunately, these wedges are correlated with each other, and we cannot theoretically prove the desired concen-tration. In practice, it appears that these wedges are suffi-ciently uncorrelated that we get excellent results by reusing the reservoir. This is an important distinction from past streaming work [ 21, 10 ]. We can multiply our space by 1 / to (heuristically) get error , but this is not possible through previous algorithms. Their space is multiplied by 1 / 2 .
The second issue is that Single-Bit requires a fair bit of bookkeeping. We need to generate a random wedge from the large set W t . While this is possible by storing edge res as a subgraph, we have a nice (at least in the authors X  opinion) heuristic fix that avoids these complications.
 Suppose we have a uniform random wedge w  X  W t  X  1 . We can convert it to an  X  X lmost X  uniform random wedge in W t . If W t = W t  X  1 is true (so N t =  X  which is true most of of the time), then w is also uniform in W t . Suppose not. Note that W t is constructed by removing some wedges from W t  X  1 and inserting N t . Since w is uniform random in W t  X  1 , if w is also present in W t , then it is uniform random in W t \N t . Replacing w by a uniform random wedge in N with probability |N t | / |W t | yields a uniform random wedge in W t . This is precisely what Streaming-Triangles does.
When w /  X  W t , then the edge replaced by e t must be in w . We approximte this as a low probability event and simply ignore this case. Hence, in Streaming-Triangles , we simply assume that w is always in W t . This is technically incorrect, it appears to have little effect on the accuracy in practice. And it leads to a cleaner, efficient implementation.
Due to space considerations and for clarity X  X  sake, we pro-vide proof sketches in this version. Mathematical details can be found in the online full version [ 20 ].

We begin with some preliminaries. First, the set R t is a set of s uniform i.i.d. samples from { e 1 ,e 2 ,...,e t consequence of reservoir sampling. Next, we define future-closed wedges. Take the final graph G and label all edges with their timestamp. For each triangle, the wedge formed by the earliest two timestamps is a future-closed wedge . In then the wedge { e i ,e j } is future-closed. The number of future-closed wedges is exactly T , since each triangle con-tains a single such wedge. We now have a simple yet impor-tant claim about the output of Single-Bit .

Claim 1. The set C m is exactly the set of future closed wedges in W m .

Proof. Consider some wedge { e i ,e j } ,i &lt; j in W m . This wedge was formed at time j , and remains in all W t for j  X  t  X  m . If this wedge is future closed (say by edge e t 0 t &gt; j ), then at time t 0 , the wedge will be detected to be closed. Since this information is maintained by Single-Bit the wedge will be in C m . If the wedge is not future closed, then no closing edge will be found for it after time j . Hence, it will not be in C m .
 Consider the situation of the data structures at the end. The main technical effort goes into showing that the number of wedges formed (by edges) in R m (this is precisely |W m can be used to determine the actual number of wedges in G m . Furthermore, the number of future closed wedges in R m (precisely |C m | , by Claim 1 ) can be used to estimate T .
This is formally expressed in the next lemma. Roughly, if s = km/ We also get weak concentration bounds for the quantity. A similar bound (with somewhat weaker concentration) holds even when we consider the set of future closed wedges.
Lemma 1 (Birthday paradox for wedges). Let G be a graph with m edges and S be some fixed subset of wedges in G . Let R be a set of s uniformly and independently selected edges (with replacement) from G . Let X be the random vari-able denoting the number of wedges in S formed by edges in R . 1. E [ X ] = s 2 (2 |S| /m 2 ) . 2. Let  X  &gt; 0 be a parameter. If s  X  3 m/ (  X  3 p
Proof sketch. The first part is an adaptation of the birth-day paradox calculation. Let the set R = { r 1 ,r 2 ,...,r We define random variables X i,j for each i,j  X  [ s ] with i &lt; j . Let X i,j = 1 if the wedge { r i ,r j } belongs to S and 0 otherwise. Then X = P i&lt;j X i,j .

Since R consists of uniform i.i.d. edges from G , the fol-lowing holds: for every i &lt; j and every (unordered) pair of edges { e  X  ,e  X  } from E , Pr[ { r i ,r j } = { e  X  This implies Pr[ X i,j = 1] = 2 |S| /m 2 . By linearity of ex-pectation, we have E [ X ] = s 2 E [ X i,j ] = s 2 Pr[ X = s 2 (2 |S| /m 2 ), as required.
 The second part is obtained by bounding the variance of X and using the Chebyschev inequality. It is a fairly tech-nical proof that can be found in the full version.

We now sketch the proof of Thm. 1. (As mentioned ear-lier, the complete rigorous proof can be found in the full Table 1: Properties of the graphs used in the experiments version [20 ].) At the end of the stream, the output bit b 1 if |W m | &gt; 0 and a wedge from C m is sampled. Note that both |W m | and |C m | are random variables.

To deal with the first event, we apply Lem. 1 with S being the set of all wedges. So, E [ |W m | ] = s 2 (2 W/m s  X  cm/ (  X  3 large number). Intuitively, the probability that |W m | = 0 should be very small, and this can be bounded using the concentration bound of Lem. 1 .

For this informal discussion, let us just assume that |W m 0 happens. Now, the probability that b m = 1 (which is E [ b m ]) is exactly the fraction |C m | / |W m | . Suppose both these behave like their expectation. By Claim 1, C m is the set of future closed wedges. The number of future closed wedges is T , so Lem. 1 tells us that E [ |C m | ] = s 2 (2 T/m Hence, E [ |C m | ] / E [ |W m | ] = T/W =  X / 3.

In general, the value of |C m | / |W m | might be quite different from E [ |C m | ] / E [ |W m | ]. Note that E [ |C m | ]  X  c of s . Using the concentration bounds of Lem. 1 , we can argue that the deviation of |C m | / |W m | from E [ |C m | ] / E [ |W most  X  with probability &gt; 1  X   X  .
We implemented our algorithm in C++ and ran our ex-periments on a MacBook Pro laptop equipped with a 2.8GHz Intel core i7 processor and 8GB memory. The vital statistics of all the graphs that we experiment upon are provided in Tab. 1. For our case studies, we focus on the web-NotreDame and amazon0505 graphs, having 1M and 3M edges respec-tively.

Effects of storage on estimates: We explore the effect that the parameters s e ,s w (referred to as the edge reservoir and wedge reservoir sizes) have on the quality of the esti-mates for  X  and T . Both of these graphs have around 1M edges. Each of these is converted into a random stream of edges.

We set s e to be 10K, 20K, and 40K, and vary s w from 10K to 70K in increments of 10K. For each setting of the param-eters, we perform a single run of Streaming-Triangles on these streamed graphs. This is to give a true indication of the behavior of Streaming-Triangles . The results are shown in Fig. 3 and Fig. 4 , both for the transitivity and tri-angle counts for web-NotreDame and amazon0505. We fix a setting of s e and increase s w . In terms of the theory, a large Figure 2: Output of a single run of Streaming-Triangles on various orderings of the data stream for web-NotreDame. The true value is given by the thick black line. s helps generate wedges that are closer to uniform. A larger s w then helps to get a sharper estimate for the fraction of future closed wedges.

Observe that the algorithm is almost always within 10% of the true answer. The statistical deviation is larger from edge reservoirs of 10K and 20K, but it quite small for 40K. Indeed for s e =40K, the output is well within 5%. In gen-eral, these figures show that the algorithm does not have wild statistical fluctations and is fairly well behaved as we increase the space. Increasing the space gives a predictable improvement in the estimate.

Comparison with previous work: The streaming al-gorithm of Buriol et al [10 ] was implemented and run on real graphs. In general, they get fairly large error even with storage of 100K edges. We provide comparisons with an im-plementation of their algorithm for arbitrary streams (they also have a version only for incidence streams, but we do not compare with that). The basic sampling procedure involves sampling a random edge and a random vertex and trying the complete a triangle. This is repeatedly independently in par-allel to get an estimate for the number of triangles. Buriol et al provide various heuristics to speed up their algorithm, but the core sampling procedure is what was described above.
In Fig. 5, we compare runs of Streaming-Triangles with their algorithm for our test graphs. For convenience, we just refer to their algorithm as  X  X uriol et al X . The x -axis is the space used, and the y -axis gives the triangle estimate. For simplicity, we fix s e = 20K and increase s w in Streaming-Triangles . For Buriol et al, we count the storage of a single edge and vertex a single unit of space. (We ignore the extra two edges needed to complete the triangle, and sim-ply count the number of samples used.) While the previous algorithm has estimates off by 50% or more, Streaming-Triangles is much more accurate over all of its runs. (In-deed, the figure is zoomed out so much that the statistical flucations of Streaming-Triangles are barely visible.) For amazon0505, the estimate give by Buriol et al is zero till 80K samples. We note that these results are consistent with those given in [10 ].

Runs on various graphs: We run Streaming-Triangles on a variety of graphs obtained from the SNAP database [41]. We simply set s e as 20K and s w as 20K for all our runs. Each graph is converted into a stream by taking a random ordering on the edges. In Fig. 6 , we show our re-Figure 3: web-NotreDame detailed runs: We fix the edge reservoir, s reservoir size, s w , from 10K to 70K and track the output of counts. Figure 4: amazon0505 detailed runs: We fix the edge reservoir, s , to 10K, 20K, and 40K. Then we increase the wedge reservoir size, s w , from 10K to 70K and track the output of Streaming-Triangles sults for estimating both  X  and T . The absolute values are plotted for  X  together with the true values. For triangles, we plot the relative error (so | est  X  T | /T , where est is the algorithm output) for each graph, since the true values can vary over orders of magnitude. Observe that the transitiv-ity estimates are very accurate. The relative error for T is mostly below 8%, and often below 4%.

All the graphs listed have millions of edges, so our stor-age is always 2 orders of magnitude smaller than the graph. Most dramatically, we get accurate results on the Orkut so-cial network, which has 220M edges. The algorithm stores only 30K edges, a 0.0001-fraction of the graph. Also observe the results on the Flickr and Livejournal graphs, which also run into tens of millions of edges.

Effect of stream ordering: It is not possible to check that our algorithm works for all orderings of the stream. So we generate a different orderings of the edges in web-NotreDame and run Streaming-Triangles on all the or-derings. The results are given in Fig. 2 . As before, we fix the edge and wedge reservoir to 20K. We discuss the different orderings below.

We first have two random orderings. Next, we generate a stream through a bfs as follows. We take a bfs tree from a random vertex and list out all edges in the tree. Then, we list the remaining edges in random order. Since the average degree of web-NotreDame is around 3, the tree has about one-third of the total edges. So this ordering is fairly differ-ent from a random ordering. Our fourth ordering involves taking a dfs from a random vertex and list out edges in order as seen by the dfs. Finally, we sort the vertices by degree and list all edges incident to a vertex (this is an incidence stream).

Streaming-Triangles performs reasonably on all these different orderings. There is little deviation in the transitiv-ity values. There is somewhat more difference in the triangle numbers, but it never exceeds 10% relative error. This seems to be simply deviations in repeated runs of Streaming-Triangles .
 Real-time tracking: A major benefit of Streaming-Triangles is that it can maintain a real-time estimate of  X  and T t . We take a real-world temporal graph, cit-Patents , which contains patent citation data over decades. The edges reservoir and variable wedge reservoir for our storage. The plot on the right gives the relative error of Streaming-Triangles error for T is mostly below 8%, and often below 4%. are time stamped with the year of citation, and hence give a stream of edges. Using more storage of an edge reservoir of 40K and wedge reservoir of 15K, we accurately track these values over time (refer to Fig. 1 ). Note that this is still orders of magnitude smaller than the full size of the graph, which is 16M edges. The errors of our estimates are overall quite small. (The true values are only given for the year ends.) [1] K. J. Ahn, S. Guha, and A. McGregor. Graph [2] N. Alon, T. Kaufman, and M. Krivelevich. Testing [3] L. Arge, M. Goodrich, and N. Sitchinava. Parallel [4] S. M. Arifuzzaman, M. Khan, and M. Marathe.
 [5] H. Avron. Counting triangles in large graphs using [6] Z. Bar-Yossef, R. Kumar, and D. Sivakumar.
 [7] L. Becchetti, P. Boldi, C. Castillo, and A. Gionis. [8] J. Berry, L. Fosvedt, D. Nordman, C. A. Phillips, and [9] J. Berry, B. Hendrickson, S. Kahan, and P. Konecny. [10] L. S. Buriol, G. Frahling, S. Leonardi, [11] R. S. Burt. Structural holes and good ideas. American [12] D. R. Chakrabarti, P. Banerjee, H.-J. Boehm, P. G. [13] Y.-J. Chiang, M. T. Goodrich, E. F. Grove, [14] N. Chiba and T. Nishizeki. Arboricity and subgraph [15] S. Chu and J. Cheng. Triangle listing in massive [16] J. Cohen. Graph twiddling in a MapReduce world. [17] J. S. Coleman. Social capital in the creation of human [18] J.-P. Eckmann and E. Moses. Curvature of co-links [19] W. Feller. An Introduction to probability theory and [20] M. Jha, C. Seshadhri, and A. Pinar. A space efficient [21] H. Jowhari and M. Ghodsi. New streaming algorithms [22] D. M. Kane, K. Mehlhorn, T. Sauerwald, and H. Sun. [23] M. N. Kolountzakis, G. L. Miller, R. Peng, and [24] M. Latapy. Main-memory triangle computations for [25] R. Milo, S. Shen-Orr, S. Itzkovitz, N. Kashtan, [26] R. Pagh and C. Tsourakakis. Colorful triangle [27] T. Plantenga. Inexact subgraph isomorphism in [28] A. Portes. Social capital: Its origins and applications [29] T. Schank and D. Wagner. Approximating clustering [30] T. Schank and D. Wagner. Finding, counting and [31] C. Seshadhri, A. Pinar, and T. G. Kolda. Fast triangle [32] S. Suri and S. Vassilvitskii. Counting triangles and the [33] C. Tsourakakis. Fast counting of triangles in large real [34] C. Tsourakakis, P. Drineas, E. Michelakis, I. Koutis, [35] C. Tsourakakis, M. N. Kolountzakis, and G. Miller. [36] C. E. Tsourakakis, U. Kang, G. L. Miller, and [37] J. Vitter. Random sampling with a reservoir. ACM [38] S. Wasserman and K. Faust. Social Network Analysis: [39] B. F. Welles, A. V. Devender, and N. Contractor. Is a [40] J.-H. Yoon and S.-R. Kim. Improved sampling for [41] Stanford Network Analysis Project (SNAP). Available
